<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Neuroinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Neuroinformatics</journal-id>
    <journal-title-group>
      <journal-title>Neuroinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1539-2791</issn>
    <issn pub-type="epub">1559-0089</issn>
    <publisher>
      <publisher-name>Springer US</publisher-name>
      <publisher-loc>New York</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">5797201</article-id>
    <article-id pub-id-type="publisher-id">9352</article-id>
    <article-id pub-id-type="doi">10.1007/s12021-017-9352-y</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Software Original Article</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>NiftyPET: a High-throughput Software Platform for High Quantitative Accuracy and Precision PET Imaging and Analysis</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-3114-0773</contrib-id>
        <name>
          <surname>Markiewicz</surname>
          <given-names>Pawel J.</given-names>
        </name>
        <address>
          <email>p.markiewicz@ucl.ac.uk</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Ehrhardt</surname>
          <given-names>Matthias J.</given-names>
        </name>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Erlandsson</surname>
          <given-names>Kjell</given-names>
        </name>
        <xref ref-type="aff" rid="Aff3">3</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Noonan</surname>
          <given-names>Philip J.</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Barnes</surname>
          <given-names>Anna</given-names>
        </name>
        <xref ref-type="aff" rid="Aff3">3</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Schott</surname>
          <given-names>Jonathan M.</given-names>
        </name>
        <xref ref-type="aff" rid="Aff4">4</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Atkinson</surname>
          <given-names>David</given-names>
        </name>
        <xref ref-type="aff" rid="Aff5">5</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Arridge</surname>
          <given-names>Simon R.</given-names>
        </name>
        <xref ref-type="aff" rid="Aff6">6</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Hutton</surname>
          <given-names>Brian F.</given-names>
        </name>
        <xref ref-type="aff" rid="Aff3">3</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Ourselin</surname>
          <given-names>Sebastien</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ISNI">0000000121901201</institution-id><institution-id institution-id-type="GRID">grid.83440.3b</institution-id><institution>Translational Imaging Group, CMIC, Department of Medical Physics, Biomedical Engineering, </institution><institution>University College London, </institution></institution-wrap>London, UK </aff>
      <aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ISNI">0000000121885934</institution-id><institution-id institution-id-type="GRID">grid.5335.0</institution-id><institution>Department for Applied Mathematics and Theoretical Physics, </institution><institution>University of Cambridge, </institution></institution-wrap>Cambridge, UK </aff>
      <aff id="Aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ISNI">0000000121901201</institution-id><institution-id institution-id-type="GRID">grid.83440.3b</institution-id><institution>Institute of Nuclear Medicine, </institution><institution>University College London, </institution></institution-wrap>London, UK </aff>
      <aff id="Aff4"><label>4</label><institution-wrap><institution-id institution-id-type="ISNI">0000000121901201</institution-id><institution-id institution-id-type="GRID">grid.83440.3b</institution-id><institution>Dementia Research Centre, </institution><institution>University College London, </institution></institution-wrap>London, UK </aff>
      <aff id="Aff5"><label>5</label><institution-wrap><institution-id institution-id-type="ISNI">0000000121901201</institution-id><institution-id institution-id-type="GRID">grid.83440.3b</institution-id><institution>Centre for Medical Imaging, </institution><institution>University College London, </institution></institution-wrap>London, UK </aff>
      <aff id="Aff6"><label>6</label><institution-wrap><institution-id institution-id-type="ISNI">0000000121901201</institution-id><institution-id institution-id-type="GRID">grid.83440.3b</institution-id><institution>Centre for Medical Image Computing (CMIC), </institution><institution>University College London, </institution></institution-wrap>London, UK </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>26</day>
      <month>12</month>
      <year>2017</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>26</day>
      <month>12</month>
      <year>2017</year>
    </pub-date>
    <pub-date pub-type="ppub">
      <year>2018</year>
    </pub-date>
    <volume>16</volume>
    <issue>1</issue>
    <fpage>95</fpage>
    <lpage>115</lpage>
    <permissions>
      <copyright-statement>Â© The Author(s) 2017</copyright-statement>
      <license license-type="OpenAccess">
        <license-p><bold>Open Access</bold>This article is distributed under the terms of the Creative Commons Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made.</license-p>
      </license>
    </permissions>
    <abstract id="Abs1">
      <p id="Par1">We present a standalone, scalable and high-throughput software platform for PET image reconstruction and analysis. We focus on high fidelity modelling of the acquisition processes to provide high accuracy and precision quantitative imaging, especially for large axial field of view scanners. All the core routines are implemented using parallel computing available from within the Python package <italic>NiftyPET</italic>, enabling easy access, manipulation and visualisation of data at any processing stage. The pipeline of the platform starts from MR and raw PET input data and is divided into the following processing stages: (1) list-mode data processing; (2) accurate attenuation coefficient map generation; (3) detector normalisation; (4) exact forward and back projection between sinogram and image space; (5) estimation of reduced-variance random events; (6) high accuracy fully 3D estimation of scatter events; (7) voxel-based partial volume correction; (8) region- and voxel-level image analysis. We demonstrate the advantages of this platform using an amyloid brain scan where all the processing is executed from a single and uniform computational environment in Python. The high accuracy acquisition modelling is achieved through span-1 (no axial compression) ray tracing for true, random and scatter events. Furthermore, the platform offers uncertainty estimation of any image derived statistic to facilitate robust tracking of subtle physiological changes in longitudinal studies. The platform also supports the development of new reconstruction and analysis algorithms through restricting the axial field of view to any set of rings covering a region of interest and thus performing fully 3D reconstruction and corrections using real data significantly faster. All the software is available as open source with the accompanying wiki-page and test data.</p>
    </abstract>
    <kwd-group xml:lang="en">
      <title>Keywords</title>
      <kwd>PET</kwd>
      <kwd>Quantification</kwd>
      <kwd>Image reconstruction</kwd>
      <kwd>Uncertainty</kwd>
      <kwd>Bootstrap</kwd>
      <kwd>Scatter correction</kwd>
      <kwd>Random events estimation</kwd>
      <kwd>Partial volume correction</kwd>
      <kwd>Normalisation</kwd>
    </kwd-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">https://doi.org/10.13039/100007065</institution-id>
            <institution>Nvidia</institution>
          </institution-wrap>
        </funding-source>
        <award-id>TESLA K20</award-id>
        <principal-award-recipient>
          <name>
            <surname>Markiewicz</surname>
            <given-names>Pawel J.</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">https://doi.org/10.13039/501100000266</institution-id>
            <institution>Engineering and Physical Sciences Research Council</institution>
          </institution-wrap>
        </funding-source>
        <award-id>EP/K005278/1</award-id>
        <principal-award-recipient>
          <name>
            <surname>Hutton</surname>
            <given-names>Brian F.</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">https://doi.org/10.13039/501100000266</institution-id>
            <institution>Engineering and Physical Sciences Research Council</institution>
          </institution-wrap>
        </funding-source>
        <award-id>EP/J020990/1</award-id>
        <principal-award-recipient>
          <name>
            <surname>Ourselin</surname>
            <given-names>Sebastien</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">https://doi.org/10.13039/501100000265</institution-id>
            <institution>Medical Research Council</institution>
          </institution-wrap>
        </funding-source>
        <award-id>MRC (MR/J01107X/1</award-id>
        <principal-award-recipient>
          <name>
            <surname>Ourselin</surname>
            <given-names>Sebastien</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">https://doi.org/10.13039/501100000265</institution-id>
            <institution>Medical Research Council</institution>
          </institution-wrap>
        </funding-source>
        <award-id>CSUB19166</award-id>
        <principal-award-recipient>
          <name>
            <surname>Ourselin</surname>
            <given-names>Sebastien</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">https://doi.org/10.13039/501100000266</institution-id>
            <institution>Engineering and Physical Sciences Research Council</institution>
          </institution-wrap>
        </funding-source>
        <award-id>EP/H046410/1</award-id>
        <principal-award-recipient>
          <name>
            <surname>Ourselin</surname>
            <given-names>Sebastien</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">https://doi.org/10.13039/501100000266</institution-id>
            <institution>Engineering and Physical Sciences Research Council</institution>
          </institution-wrap>
        </funding-source>
        <award-id>EP/K005278/1</award-id>
        <principal-award-recipient>
          <name>
            <surname>Ourselin</surname>
            <given-names>Sebastien</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">https://doi.org/10.13039/501100000265</institution-id>
            <institution>Medical Research Council</institution>
          </institution-wrap>
        </funding-source>
        <award-id>EP/K005278/1</award-id>
        <principal-award-recipient>
          <name>
            <surname>Ourselin</surname>
            <given-names>Sebastien</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">https://doi.org/10.13039/501100000272</institution-id>
            <institution>National Institute for Health Research</institution>
          </institution-wrap>
        </funding-source>
        <award-id>BW.mn.BRC10269</award-id>
        <principal-award-recipient>
          <name>
            <surname>Ourselin</surname>
            <given-names>Sebastien</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
      <award-group>
        <funding-source>
          <institution>EU-FP7</institution>
        </funding-source>
        <award-id>FP7-ICT-2011-9-601055</award-id>
        <principal-award-recipient>
          <name>
            <surname>Ourselin</surname>
            <given-names>Sebastien</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">https://doi.org/10.13039/501100000265</institution-id>
            <institution>Medical Research Council</institution>
          </institution-wrap>
        </funding-source>
        <award-id>MR/N025792/1</award-id>
        <principal-award-recipient>
          <name>
            <surname>Ourselin</surname>
            <given-names>Sebastien</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">https://doi.org/10.13039/100010663</institution-id>
            <institution>H2020 European Research Council</institution>
          </institution-wrap>
        </funding-source>
        <award-id>ID115952</award-id>
        <award-id>H2020-EU.3.1.7</award-id>
      </award-group>
    </funding-group>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>Â© Springer Science+Business Media, LLC, part of Springer Nature 2018</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="Sec1">
    <title>Introduction</title>
    <p id="Par2">One of the key aspects of positron emission tomography (PET) is its quantitative capability which allows measurements to be represented in absolute units of radiotracer concentration (e.g., kBq per mL of tissue). Such quantitative measurements have proven to have a significant impact on assessing the response to treatment of many pathologies, such as cancer (Doot et al. <xref ref-type="bibr" rid="CR15">2014</xref>) or neurodegenerative disease (Camus et al. <xref ref-type="bibr" rid="CR9">2012</xref>). Furthermore, good PET quantitative accuracy and precision are crucial in clinical trials of new therapies (Kinahan et al. <xref ref-type="bibr" rid="CR31">2015</xref>; Meikle and Badawi <xref ref-type="bibr" rid="CR42">2005</xref>).</p>
    <p id="Par3">However, achieving high quantitative accuracy is dependent on all data correction being performed to the highest possible standard. The correction for photon attenuation has a major impact on quantification, which is not easy to perform, especially in the case of PET/MR scanners where the direct measurement of electron density is not available (electrons are the main cause of photon attenuation and scattering for the photon energy in PET). Other factors, which can significantly undermine quantitative accuracy are detector dead time, variable detector efficiencies, scatter and random coincidence events as well as limited image resolution, which fails to accurately resolve small tissue regions (Meikle and Badawi <xref ref-type="bibr" rid="CR42">2005</xref>).</p>
    <p id="Par4">In the following sections, we will comprehensively describe all these factors beginning from the data acquisition through to image reconstruction and analysis, providing advanced computational models and software solutions together with their validation for obtaining high quantitative accuracy and precision.</p>
    <p id="Par5">A number of publicly available software packages have already been proposed, offering a wide choice of reconstruction algorithms. For example, ASPIRE, which is a set of ANSI C routines developed at the University of Michigan for image reconstruction in emission and transmission tomography as well as magnetic resonance imaging (MRI) (Fessler <xref ref-type="bibr" rid="CR19">2013</xref>). Another example is NiftyRec, which provides a number of reconstruction algorithms with GPU-accelerated routines for various modalities of emission and transmission computed tomography (Pedemonte et al. <xref ref-type="bibr" rid="CR52">2010</xref>). Another important package is the software for tomographic image reconstruction (STIR), which is written in C++ and provides a rich open source library of routines for static and dynamic imaging coupled with scatter correction (Thielemans et al. <xref ref-type="bibr" rid="CR58">2012</xref>).</p>
    <p id="Par6">In contrast and in a complimentary manner to the already available software packages, the proposed software platform in the current stage of development puts greater emphasis on high quantitative accuracy and precision obtained through detailed modelling of PET acquisition physics. This is delivered through advanced and computationally expensive models for data correction using high-throughput parallel computing on graphical processing units (GPU). This parallel implementation allows efficient generation of bootstrap replicates of the list-mode data followed by multiple image reconstructions for uncertainty (precision) estimation of any image statistic. The estimation of precision of any image biomarker has become an important factor in the quantitative accuracy of PET, especially in the case of clinical trials and longitudinal imaging in neurodegeneration and cancer (Kinahan et al. <xref ref-type="bibr" rid="CR31">2015</xref>). For example, it has been shown that the changes of amyloid deposition over time are very subtle and often within the test/retest variability of PET (Landau et al. <xref ref-type="bibr" rid="CR32">2015</xref>). Therefore, the provided knowledge of uncertainty of any image statistic can be of significant value in preventing false positive findings.</p>
    <p id="Par7">Based on the high accuracy quantitative reconstruction, the platform is easily extended to image post-processing, which we demonstrate as an example application on amyloid brain imaging. Similar quantification software is available from Siemens, called â<italic>syngo</italic>
<sup>Â®;</sup>.PET Amyloid Plaqueâ, or the CortexID Suite by GE Healthcare, which both facilitate quantification of amyloid plaque deposits in the brain (Siemens; Peyrat et al. <xref ref-type="bibr" rid="CR53">2012</xref>). The image analysis we propose here differs in that it delivers the highest possible quantitative accuracy with precision (uncertainty distributions) of any regional/voxel value in the native PET image space (as opposed to the MNI space used in Peyrat et al. (<xref ref-type="bibr" rid="CR53">2012</xref>)). It estimates the precision through multiple list-mode bootstrap replicates, for each of which the whole process of quantifying amyloid is repeated many times (Markiewicz et al. <xref ref-type="bibr" rid="CR41">2016a</xref>). Every processing stage of this pipeline is fully controlled from within Python, allowing for quality control and validation of all PET data corrections as well as fine tuning for any given imaging task. In addition, the acquisition model can be limited to an arbitrary number of detector rings, thus while still supporting real measurements, it allows for extremely fast data processing which is useful for the discovery of new computational algorithms and quantitative imaging methods (Ehrhardt et al. <xref ref-type="bibr" rid="CR16">2016</xref>).</p>
    <p id="Par8">In the following sections we expand on all the stages of data processing for accurate PET acquisition modelling, image reconstruction and analysis within the proposed uniform computational Python environment. We start with the acquired raw data and end with accurate estimates of amyloid deposition in the brain accompanied with the estimated precision of the deposition.</p>
  </sec>
  <sec id="Sec2">
    <title>Methods: Stages of Quantitative Data Processing</title>
    <p id="Par9">All the processing stages are presented within the complete infrastructure depicted in Fig.Â <xref rid="Fig1" ref-type="fig">1</xref> using an amyloid brain scan acquired on the Siemens Biograph mMR. The participant was taking part in âInsight 46ââa neuroscience sub-study of the Medical Research Council National Survey of Health and Development (Lane et al. <xref ref-type="bibr" rid="CR33">2017</xref>). The input data include the attenuation coefficient maps (<italic>Î¼</italic>-maps) of the hardware and subject (stage <italic>A</italic>), normalisation component data (stage <italic>B</italic>) and the list-mode data (stage <italic>C</italic>). Optionally, T1 and/or T2 weighted MR images are provided for brain parcellation (Cardoso et al. <xref ref-type="bibr" rid="CR10">2015</xref>) used in partial volume correction (PVC) and regional analysis as well as for generating a more accurate subject <italic>Î¼</italic>-map (Burgos et al. <xref ref-type="bibr" rid="CR8">2015</xref>). In this work, we put a greater emphasis on the quantitative image reconstruction and analysis in: forward and back projectors for image reconstruction (stage <italic>D</italic>); fully 3D estimation of scatter events (stage <italic>E</italic>); and voxel-wise partial volume correction using MRI brain parcellations (stage <italic>F</italic>).
<fig id="Fig1"><label>Fig. 1</label><caption><p>Infrastructure for standalone PET image reconstruction and analysis of PET/MR brain data using amyloid PET tracer. Section <italic>A</italic> presents the image input data with necessary processing for generating accurate hardware and object <italic>Î¼</italic>-maps as well as parcellation of the brain image into standard anatomical regions (used in reconstruction and analysis sections <italic>D</italic> and <italic>F</italic>). In section <italic>B</italic> the normalisation component data is used to generate single factors for each sinogram bin, with the use of bucket singlesâthe output from list-mode (LM) processing in section <italic>C</italic>. Apart from singlesâ buckets, the LM processing in section <italic>C</italic> generates prompt and delayeds sinograms, and fan sums, which are used for estimating low noise randoms in each sinogram bin. In stage <italic>D</italic> image reconstruction and analysis takes place with a heavy use of forward and back projectors. Note that the attenuation factors are generated with the forward projector. Section <italic>E</italic> contains scatter estimation which is coupled with image reconstructionâthe scatter is updated every time a better image estimation of the radiotracer distribution is available. Using the parcellation from <italic>A</italic> and the systemâs point spread function (PSF), the reconstructed image is corrected for the partial volume effect in section <italic>F</italic>. <sup>â</sup>
<italic>External software packages</italic>
</p></caption><graphic xlink:href="12021_2017_9352_Fig1_HTML" id="MO1"/></fig>
</p>
    <sec id="Sec3">
      <title>List-mode Data Processing</title>
      <p id="Par10">The list-mode data are rich in spatio-temporal information, which typically require a large amount of memory, in the order of GB, for a clinical study. Since it is challenging to process such an amount of data in a fast and efficient way, we have devised a novel method using the GPU for rapid processing of list-mode datasets (Fig.Â <xref rid="Fig1" ref-type="fig">1</xref>c), details of which are covered in our previous publication (Markiewicz et al. <xref ref-type="bibr" rid="CR41">2016a</xref>). Here we will present a concise outline of this method with some additional details.</p>
      <p id="Par11">The workflow of the list-mode (LM) data processing is depicted in Fig.Â <xref rid="Fig2" ref-type="fig">2</xref>. The key aspect of fast LM processing is the concurrent execution of device kernels (GPU functions) using 32 CUDA streams (Harris <xref ref-type="bibr" rid="CR21">2012a</xref>), while copying the next chunks of LM data in advance from disk to the host (CPU) buffer and then to the device (GPU) memory. The overlapped data transfer and execution allows the exploitation of data transfer lag for GPU processing (Harris <xref ref-type="bibr" rid="CR22">2012b</xref>). In our current implementation the buffer size is around 1.6 GB and divided into 32 data chunks of 50 MB each, processed by the corresponding 32 CUDA streams.
<fig id="Fig2"><label>Fig. 2</label><caption><p>Workflow of concurrent list-mode (LM) processing. The LM data is divided into data chunks and processed by 32 CUDA streams at any given time. On processing completion by any stream, a new LM data chunk is read from the disk and processed asynchronously until all LM data is read and processed</p></caption><graphic xlink:href="12021_2017_9352_Fig2_HTML" id="MO2"/></fig>
</p>
      <p id="Par12">The output of the LM processing includes the following: <inline-formula id="IEq1"><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\blacktriangleright $\end{document}</tex-math><mml:math id="M2"><mml:mo>â¸</mml:mo></mml:math><inline-graphic xlink:href="12021_2017_9352_Article_IEq1.gif"/></alternatives></inline-formula>
<italic>Prompt and delayed sinograms for static or dynamic acquisitions</italic> in (i) span-1 with no axial compression resulting in 4084 sinograms for the Biography mMR scanner; (ii) span-11 with axial compression resulting in 837 sinograms; or (iii) using single slice rebinning (SSR) with only 127 sinograms. <inline-formula id="IEq2"><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\blacktriangleright $\end{document}</tex-math><mml:math id="M4"><mml:mo>â¸</mml:mo></mml:math><inline-graphic xlink:href="12021_2017_9352_Article_IEq2.gif"/></alternatives></inline-formula>
<italic>The head curve</italic>, which is the total counts per second for the prompt and delayed events recorded in the list data. <inline-formula id="IEq3"><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\blacktriangleright $\end{document}</tex-math><mml:math id="M6"><mml:mo>â¸</mml:mo></mml:math><inline-graphic xlink:href="12021_2017_9352_Article_IEq3.gif"/></alternatives></inline-formula>
<italic>General motion detection</italic> is obtained based on the centre of the radioactivity mass in the axial dimension. <inline-formula id="IEq4"><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\blacktriangleright $\end{document}</tex-math><mml:math id="M8"><mml:mo>â¸</mml:mo></mml:math><inline-graphic xlink:href="12021_2017_9352_Article_IEq4.gif"/></alternatives></inline-formula>
<italic>Fan sums for delayed events.</italic> The fan sums are used as an input for generating reduced-noise randoms estimates using maximum likelihood with the Poisson model for random events (cf. â<xref rid="Sec9" ref-type="sec">Estimation of Random Events</xref>â). <inline-formula id="IEq5"><alternatives><tex-math id="M9">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\blacktriangleright $\end{document}</tex-math><mml:math id="M10"><mml:mo>â¸</mml:mo></mml:math><inline-graphic xlink:href="12021_2017_9352_Article_IEq5.gif"/></alternatives></inline-formula>
<italic>Bucket singles rates</italic> are reported approximately every other second for each bucket (8 buckets axially Ã 28 buckets transaxially =â224) and used for detector dead time correction. <inline-formula id="IEq6"><alternatives><tex-math id="M11">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\blacktriangleright $\end{document}</tex-math><mml:math id="M12"><mml:mo>â¸</mml:mo></mml:math><inline-graphic xlink:href="12021_2017_9352_Article_IEq6.gif"/></alternatives></inline-formula>
<italic>Sagittal and coronal dynamic projection views</italic> are created every fourth second of acquisition. These views are used to generate videos for visual assessment of the acquisition for quality control. An example video for a case with significant motion is available at <ext-link ext-link-type="uri" xlink:href="https://vimeo.com/129831482">https://vimeo.com/129831482</ext-link>.</p>
    </sec>
    <sec id="Sec4">
      <title>Detector Normalisation</title>
      <p id="Par13">The sensitivity of each detector (including crystals and electronics), and thus the sensitivity of each line of response (LOR), varies significantly. This causes considerable quantitative errors and visual artefacts, mostly of high frequency (Meikle and Badawi <xref ref-type="bibr" rid="CR42">2005</xref>). Therefore, for high quantitative accuracy imaging these effects have to be corrected and a dedicated normalisation scan is performed to obtain all the necessary normalisation components (factors) reflecting the variable detection sensitivity. The overall normalisation coefficients for each LOR are modelled as a product of transaxial and axial components which include, among others, the geometric effects and intrinsic crystal efficiencies (Casey et al. <xref ref-type="bibr" rid="CR11">1996</xref>; Badawi and Marsden <xref ref-type="bibr" rid="CR2">1999</xref>). These components are provided by the scanner for each PET acquisition with some of the components being independently calculated within the <italic>NiftyPET</italic> package for imaging without axial compression of the projection data (not supported by the vendor). By combining these components with the single rates from LM data, full normalisation factor sinograms are calculated.</p>
      <sec id="Sec5">
        <title>Transaxial Normalisation Factors</title>
        <p id="Par14">The transaxial components include: <inline-formula id="IEq7"><alternatives><tex-math id="M13">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\blacktriangleright $\end{document}</tex-math><mml:math id="M14"><mml:mo>â¸</mml:mo></mml:math><inline-graphic xlink:href="12021_2017_9352_Article_IEq7.gif"/></alternatives></inline-formula>
<italic>Geometric effects</italic> factors, which account for the efficiency differences associated with the distance of the LOR from the transaxial iso-centre of the scanner. Note that these factors apply only to the true events and not scatter events. <inline-formula id="IEq8"><alternatives><tex-math id="M15">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\blacktriangleright $\end{document}</tex-math><mml:math id="M16"><mml:mo>â¸</mml:mo></mml:math><inline-graphic xlink:href="12021_2017_9352_Article_IEq8.gif"/></alternatives></inline-formula>
<italic>Crystal interference:</italic> These capture the varying detection efficiency due to the relative position of one crystal within a block of detectors. <inline-formula id="IEq9"><alternatives><tex-math id="M17">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\blacktriangleright $\end{document}</tex-math><mml:math id="M18"><mml:mo>â¸</mml:mo></mml:math><inline-graphic xlink:href="12021_2017_9352_Article_IEq9.gif"/></alternatives></inline-formula>
<italic>Detector efficiencies:</italic> These describe the random variations in crystal efficiencies due to the slightly varying crystal quality, as well as different photodetector gains when converting the weak crystal light output into a corresponding electrical signal. <inline-formula id="IEq10"><alternatives><tex-math id="M19">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\blacktriangleright $\end{document}</tex-math><mml:math id="M20"><mml:mo>â¸</mml:mo></mml:math><inline-graphic xlink:href="12021_2017_9352_Article_IEq10.gif"/></alternatives></inline-formula>
<italic>Detector dead time:</italic> These characterise the drop of efficiency at higher count rates. The drop is caused by the minimum amount of time, which is required to elapse between two events in order for them to be recorded as two distinct events. For high count rates it is more probable that the events will not be separated and likely to be rejected altogether. The dead-time is modelled by two components (Meikle and Badawi <xref ref-type="bibr" rid="CR42">2005</xref>; Evans <xref ref-type="bibr" rid="CR18">1955</xref>): the <italic>paralysable</italic> and <italic>non-paralysable</italic> components modulated by the detector single rates, which are measured at the buckets level to capture the spatially variant dead-time effect (see â<xref rid="Sec3" ref-type="sec">List-mode Data Processing</xref>â and Markiewicz et al. <xref ref-type="bibr" rid="CR41">2016a</xref>).</p>
      </sec>
      <sec id="Sec6">
        <title>Axial Normalisation Factors</title>
        <sec id="FPar1">
          <title>Axial effects for true events</title>
          <p id="Par15">Axial factors capture the varying efficiency of each direct or oblique sinogram due to the axial block profile, with the assumption that the transaxial block profile (crystal interference above) is accounted for. For the Biograph mMR, the component is provided as an array of 837 factors for each axially compressed sinogram in span-11. Each compressed sinogram can consist of up to 6 uncompressed (span-1) sinograms. Axial sampling in span-1 and span-11 can well be represented by the Michelogram (Bailey <xref ref-type="bibr" rid="CR3">2005</xref>) (see Fig.Â <xref rid="Fig3" ref-type="fig">3</xref>c; cf. â<xref rid="Sec12" ref-type="sec">Results and Discussion</xref>â, Fig.Â <xref rid="Fig9" ref-type="fig">9</xref>a). Since, by default, the scanner does not output span-1 axial factors, these are derived here from a very high statistics acquisition of the <sup>68</sup>Ge cylindrical phantom, scanned for 24 hours, and from the provided axial factors for span-11. The contribution of span-1 axial factors to the given span-11 axial factors, <italic>ð</italic>
<italic>u</italic>
<italic>v</italic>(11), is âdecodedâ according to the following formula:
<disp-formula id="Equ1"><label>1</label><alternatives><tex-math id="M21">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \epsilon_{uv}^{(1)} = N_{uv} \epsilon_{uv}^{(11)} P_{uv}^{(1)} / P_{uv}^{(11)}, $$\end{document}</tex-math><mml:math id="M22"><mml:msubsup><mml:mrow><mml:mi>ð</mml:mi></mml:mrow><mml:mrow><mml:mi>u</mml:mi><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>u</mml:mi><mml:mi>v</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mrow><mml:mi>ð</mml:mi></mml:mrow><mml:mrow><mml:mi>u</mml:mi><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mn>11</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:msubsup><mml:msubsup><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>u</mml:mi><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:msubsup><mml:mo>/</mml:mo><mml:msubsup><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>u</mml:mi><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mn>11</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:msubsup><mml:mo>,</mml:mo></mml:math><graphic xlink:href="12021_2017_9352_Article_Equ1.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq11"><alternatives><tex-math id="M23">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$P_{uv}^{(1)}$\end{document}</tex-math><mml:math id="M24"><mml:msubsup><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>u</mml:mi><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="12021_2017_9352_Article_IEq11.gif"/></alternatives></inline-formula> is the span-1 Michelogram of the emission phantom prompt data between rings <italic>u</italic> and <italic>v</italic> (cf. â<xref rid="Sec12" ref-type="sec">Results and Discussion</xref>â, Fig.Â <xref rid="Fig9" ref-type="fig">9</xref>b; note the varying efficiencies across the detector blocks [8x8 crystals]), <inline-formula id="IEq12"><alternatives><tex-math id="M25">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$P_{uv}^{(11)}$\end{document}</tex-math><mml:math id="M26"><mml:msubsup><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>u</mml:mi><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mn>11</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="12021_2017_9352_Article_IEq12.gif"/></alternatives></inline-formula> is its span-11 equivalent and <italic>N</italic>
<sub><italic>u</italic><italic>v</italic></sub> is the number of sinograms contributing to the span-11 group containing rings <italic>u</italic> and <italic>v</italic>.
<fig id="Fig3"><label>Fig. 3</label><caption><p><bold>Forward projection model used in forward and back projection:</bold> Ray-driven calculations are decomposed into transaxial (<italic>A</italic>) and axial (<italic>B</italic>) components. For a chosen transaxial voxel position, all the computations are performed axially, leading to storing the projection data along the Michelogram diagonals (<italic>C</italic>) (shown is Michelogram patch with sampling along the direct [<italic>R</italic>
<italic>D</italic> =â0] and oblique [<italic>R</italic>
<italic>D</italic> = Â±â8] sinograms)</p></caption><graphic xlink:href="12021_2017_9352_Fig3_HTML" id="MO3"/></fig>
</p>
        </sec>
        <sec id="FPar2">
          <title>Customisable axial FOV</title>
          <p id="Par16">The above extension from span-11 to span-1 normalisation made possible the customisation of the axial FOV (64 rings) into smaller setups of detector rings. This enables significantly faster reconstruction times, which is particularly useful for developing new reconstruction and analysis methods when a large number of tests have to be carried out.</p>
        </sec>
        <sec id="FPar3">
          <title>Axial effects for scatter events</title>
          <p id="Par17">The presented software includes a novel voxel-based single scatter model (see â<xref rid="Sec10" ref-type="sec">Fully 3D Scatter Model</xref>â), which requires specific axial normalisation factors to account for the scatter specific block effects. The normalisation is performed in the span-1 or span-11 sinogram space, while the scatter scaling to the prompt data is performed using single slice rebinned (SSR) data for higher counting statistics. The normalisation factors are found as ratios between the SSR data and the corresponding span-1/span-11 sinogram data, using the long 24 hour phantom acquisition to ensure good statistics.</p>
        </sec>
      </sec>
    </sec>
    <sec id="Sec7">
      <title>Generation of the <italic>Î¼</italic>-map (Specific to PET/MR Scanners)</title>
      <p id="Par18">The accurate spatial distribution of the linear attenuation coefficient (also known as the <italic>Î¼</italic>-map in units of cm<sup>ââ1</sup>) is crucial for quantitative PET imaging. Since MR cannot measure electron density accurately (like the CT scans in PET/CT scanners or transmission scans in older PET scanners), there are specific workarounds for generating hardware and subject <italic>Î¼</italic>-maps for use in PET/MR scanners.</p>
      <sec id="FPar4">
        <title>The hardware <italic>Î¼</italic>-map</title>
        <p id="Par19">Since the bed cannot be imaged with MR, high resolution CT images of the patient bed (table) and the MR coils are supplied with the scanner. The images of different hardware components can be found in the scannerâs file system with hardware components such as the head and neck coil, the spine coil and the patient bed. The specific part of the hardware <italic>Î¼</italic>-map for any given image study has to be separately generated based on additional information about the table position relative to the iso-centre of the scanner. Depending on the imaging settings, only some parts of the hardware are in the field of view and only those parts have to be included in the <italic>Î¼</italic>-map by appropriate image resampling of the high resolution CT-based images into the PET space.</p>
      </sec>
      <sec id="FPar5">
        <title>The patient <italic>Î¼</italic>-map</title>
        <p id="Par20">In addition to the hardware <italic>Î¼</italic>-map, information about the objectâs electron density is required for attenuation correction. For brain imaging, the software offers a choice between the <italic>Î¼</italic>-map provided by the scanner or the <italic>Î¼</italic>-map generated using the pseudo-CT (pCT) synthesis from T1 and T2 weighted (T1w/T2w) MR images (Burgos et al. <xref ref-type="bibr" rid="CR8">2015</xref>). The multi-atlas CT synthesis method provides a significant improvement in PET quantitative accuracy when compared to the ultra-short echo time (UTE)-based attenuation correction (as provided by the vendor). In this method, atlases of multiple pairs of aligned MR and CT images from different subjects are used to generate a synthetic CT image, called also a pCT image in the original, target MR space. It is possible to generate pseudo-CT images using a web application: <ext-link ext-link-type="uri" xlink:href="http://cmictig.cs.ucl.ac.uk/niftyweb/program.php?p=PCT">http://cmictig.cs.ucl.ac.uk/niftyweb/program.php?p=PCT</ext-link> with the output image in NIfTI format, in the T1w/T2w image space. The CT values, which are expressed in HU, are converted to linear attenuation coefficients using a piecewise linear transformation (Burger et al. <xref ref-type="bibr" rid="CR6">2002</xref>).</p>
        <p id="Par21">Since it is likely that patient motion will occur between the T1w/T2w and PET acquisitions, the software allows creation of a reference PET image (an average image or any dynamic time frame), which is reconstructed without attenuation correction, and to which the MR images are then registered (Modat et al. <xref ref-type="bibr" rid="CR43">2014</xref>). The resulting transformation is used to resample the pCT image into the correct position and resolution of the PET image of the time frame.</p>
      </sec>
    </sec>
    <sec id="Sec8">
      <title>Forward Model for Iterative Image Reconstruction</title>
      <p id="Par22">The quantitative information about the spatial distribution of radioactivity is carried by photons travelling along straight paths between two detectors without interacting with the matter of the patient body or the scanner hardware (e.g., the table and coils). In this work the continuous radioactivity distribution <italic>f</italic> is discretised and approximated by a set of <italic>J</italic> voxels, i.e., <inline-formula id="IEq13"><alternatives><tex-math id="M27">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$f(\mathbf {x}) = {\sum }_{j = 1}^{J}n_{j}v_{j}(\mathbf {x})$\end{document}</tex-math><mml:math id="M28"><mml:mi>f</mml:mi><mml:mo>(</mml:mo><mml:mi mathvariant="bold">x</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mo>â</mml:mo></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>J</mml:mi></mml:mrow></mml:msubsup><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi mathvariant="bold">x</mml:mi><mml:mo>)</mml:mo></mml:math><inline-graphic xlink:href="12021_2017_9352_Article_IEq13.gif"/></alternatives></inline-formula>, with <italic>n</italic>
<sub><italic>j</italic></sub> being the radioactivity concentration within the finite volume of voxel <italic>j</italic> defined by a 3D top-hat function <italic>v</italic>
<sub><italic>j</italic></sub>(<bold>x</bold>) (Leahy and Qi <xref ref-type="bibr" rid="CR34">2000</xref>). The underlying radioactivity distribution is commonly estimated using iterative methods, which have the key advantage of the ability to include more sophisticated models of the PET acquisition process (Alessio et al. <xref ref-type="bibr" rid="CR1">2006</xref>), based on the discrete formulation:
<disp-formula id="Equ2"><label>2</label><alternatives><tex-math id="M29">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ q_{i} = \sum\limits_{j = 1}^{J} p_{ij}n_{j}, $$\end{document}</tex-math><mml:math id="M30"><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:munderover accent="false" accentunder="false"><mml:mrow><mml:mi>â</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>J</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:math><graphic xlink:href="12021_2017_9352_Article_Equ2.gif" position="anchor"/></alternatives></disp-formula>where <italic>q</italic>
<sub><italic>i</italic></sub> is the expected data in the <italic>i</italic>-th LOR from the distribution {<italic>n</italic>
<sub><italic>j</italic></sub>}<sub><italic>j</italic>=â1,â¦,<italic>J</italic></sub>, and <italic>p</italic>
<sub><italic>i</italic><italic>j</italic></sub> is an element of the system matrix <bold>P</bold> representing the probability of positron emission in voxel <italic>j</italic> resulting in detection of an event by <italic>i</italic>-th LOR. These methods require computationally costly forward and back projections from the image to projection space and vice versa, using integrals along the LORs. Such calculations are especially costly for large axial field of view (FOV) scanners, like the Biograph mMR scanner. However, since there are many forward and back projections for which the integral calculations are independent, parallel computing architectures based on graphics processing units (GPUs) can be successfully employed allowing very fast implementations (Markiewicz et al. <xref ref-type="bibr" rid="CR40">2014</xref>; Ha et al. <xref ref-type="bibr" rid="CR20">2013</xref>).</p>
      <p id="Par23">The very large number of LORs and voxels, especially in the large axial field of view scanners, prohibits storing the system matrix in the computer memory for subsequent reuse. Therefore, the coefficients of the system matrix are calculated on the fly using the ray-driven Siddon algorithm (Jacobs et al. <xref ref-type="bibr" rid="CR27">1998</xref>; Siddon <xref ref-type="bibr" rid="CR55">1985</xref>). The algorithm allows for exact calculations of the intersection length of photon trajectories passing through any voxel along the path between both detectors of an LOR (Fig.Â <xref rid="Fig3" ref-type="fig">3</xref>a and b).</p>
      <p id="Par24">For the large number of detector rings (64 in the Biograph mMR scanner), the ray tracing was decomposed into axial and transaxial components. The transaxial component consists of voxel intersections on the <italic>x</italic> â <italic>y</italic> image plane, which are the same for any axial voxel row through which photon rays are traced (Fig.Â <xref rid="Fig3" ref-type="fig">3</xref>b). The transaxial component is pre-computed first and then stored in memory to be then used for actual 3D ray-tracing by projecting the transaxial intersections onto all possible <italic>z</italic> directions defined by an allowed ring difference (<italic>R</italic>
<italic>D</italic> = <italic>r</italic>
<sub>1</sub> â <italic>r</italic>
<sub>0</sub>, <italic>R</italic>
<italic>D</italic> â¤â60). Note, that all ray tracing is calculated independently for each detector pair, and thus, for span-11 the ray tracing is always performed in span-1, followed by ray compression to form span-11 sinograms.</p>
      <p id="Par25">Although, the Biograph mMR scanner is used here, <italic>NiftyPET</italic> allows other cylindrical geometries to be added through a simple parametrisation of scanner geometry decomposed into the transaxial and axial parts. For the axial part, it requires the number of detector rings and their size, while for the transaxial part, it requires the ring diameter, number of detector blocks and their size as well as the number of crystals per block and their size.</p>
      <p id="Par26">In this work, images were reconstructed using the ordered subsets expectation maximisation (OS EM) algorithm (Hudson and Larkin <xref ref-type="bibr" rid="CR25">1994</xref>). For the Biograph mMR, <italic>N</italic> =â14 balanced subsets were used, obtained by dividing the projection data along sinogram angles (252) into <italic>N</italic> subsets. Therefore, each subset consisted of 18 sinogram angles Ã 344 radial bins Ã 4084 direct/oblique sinograms. The correction for randoms (â<xref rid="Sec9" ref-type="sec">Estimation of Random Events</xref>â) and scatter (â<xref rid="Sec10" ref-type="sec">Fully 3D Scatter Model</xref>â) was performed using two additive terms to the forward model of Eq.Â (<xref rid="Equ2" ref-type="">2</xref>) in the reconstruction procedure (Tamal et al. <xref ref-type="bibr" rid="CR57">2006</xref>). The scatter estimate is updated at each iteration of image reconstruction.</p>
      <sec id="FPar6">
        <title>GPU Implementation</title>
        <p id="Par27">To achieve high throughput processing, the projection and image data are reorganised in the device memory allowing high bandwidth (coalesced) memory access. The image and projection data are rearranged such that the fastest changing index for the image and projection data is along axial direction. Therefore, this leads to axially-driven calculations, which allow more efficient use of the L2 cache. Consider an axial image row (127 voxels for the Biograph mMR) of fixed transaxial position as shown in Fig.Â <xref rid="Fig3" ref-type="fig">3</xref>b and a pair of transaxial detectors forming a set of possible LORs intersecting the image row. The axial intersections for these voxels are calculated for all oblique and direct sinograms, after combining them with a single pre-calculated transaxial intersection length for one such axial row (cf. Fig.Â <xref rid="Fig3" ref-type="fig">3</xref>a). This process is then repeated for all voxels being intercepted by the chosen LOR, which leads to the projection data being stored consecutively along the diagonals of the Michelogram and thus ensuring coalesced load and store operations (NVIDIA <xref ref-type="bibr" rid="CR47">2017a</xref>) (Fig.Â <xref rid="Fig3" ref-type="fig">3</xref>c).</p>
        <p id="Par28">Since the projection paths in the cylindrical scanner geometry vary depending on the radial projection position, the computational load will vary correspondingly for each projection bin (Hong et al. <xref ref-type="bibr" rid="CR24">2007</xref>). Therefore, to keep threads well-balanced with similar workload, and thus maintaining high throughput by minimising idle threads, the projection data are first sampled along sinogram angles followed by the radial projection sampling. The reason for this is that the same radial projection position will have similar intersection length through a circular FOV for any sinogram angle, and hence threads with similar calculation load are bundled together and executed in parallel more efficiently.</p>
      </sec>
      <sec id="FPar7">
        <title>Technical specifications for the Biograph mMR projector</title>
        <p id="Par29">Forward and back projections are executed in three parts: (i) the 64 direct sinograms are executed by a grid of 68516 CUDA blocks, whose number corresponds to the total number of sinogram bins without crystal gaps and each block is comprised of 64 threads (see documentation (NVIDIA <xref ref-type="bibr" rid="CR47">2017a</xref>) for details); (ii) the next 1024 oblique sinograms are executed by a grid of 68516 CUDA blocks, each with 1024 threads (maximum number of threads per block for NVIDIA architectures with a compute capability of 3.5); (iii) the remaining oblique sinograms are executed with the same parameters as (ii). Forward projection takes around 3 seconds on the NVIDIA K20 Tesla. The back projection takes 3 seconds more due to the resolving of race hazards using the CUDA atomic operations (race hazards are created by multiple projection bins accessing the same image voxel at the same time). Currently, no symmetries are used for speeding up the calculations as in Hong et al. (<xref ref-type="bibr" rid="CR24">2007</xref>), but such an approach is under development.</p>
      </sec>
    </sec>
    <sec id="Sec9">
      <title>Estimation of Random Events</title>
      <sec id="FPar8">
        <title>Measurement of random events</title>
        <p id="Par30">For quantitative imaging, the random coincidences have to be accurately measured for each detector pair. For the Siemens Biograph mMR scanner, the random coincidences are measured using the delayed time window method (Meikle and Badawi <xref ref-type="bibr" rid="CR42">2005</xref>) (p.96), in which the true and scatter coincidences are eliminated from such a delayed acquisition, leaving only the estimate of randoms. Since such estimates can be very noisy, especially for short time frames (Hogg et al. <xref ref-type="bibr" rid="CR23">2002</xref>) (cf. Fig.Â <xref rid="Fig7" ref-type="fig">7</xref>b in â<xref rid="Sec12" ref-type="sec">Results and Discussion</xref>â), we implemented a maximum likelihood method for reducing the noise of the random events estimates.
</p>
      </sec>
      <sec id="FPar9">
        <title>GPU-based random events estimation</title>
        <p id="Par31">The rate of measured random events between detectors <italic>i</italic> and <italic>j</italic> within the time coincidence window 2<italic>Ï</italic> can be approximated using singles rates <italic>S</italic>
<sub><italic>i</italic></sub> and <italic>S</italic>
<sub><italic>j</italic></sub>:
<disp-formula id="Equ3"><label>3</label><alternatives><tex-math id="M31">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ R_{ij} \simeq 2\tau S_{i}S_{j}. $$\end{document}</tex-math><mml:math id="M32"><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>â</mml:mo><mml:mn>2</mml:mn><mml:mi>Ï</mml:mi><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mn>.</mml:mn></mml:math><graphic xlink:href="12021_2017_9352_Article_Equ3.gif" position="anchor"/></alternatives></disp-formula>Since the random events follow Poisson statistics, the expected values of the estimated random data are found using the maximum likelihood (ML) approach based on (<xref rid="Equ3" ref-type="">3</xref>) (Panin et al. <xref ref-type="bibr" rid="CR51">2007</xref>):
<disp-formula id="Equ4"><label>4</label><alternatives><tex-math id="M33">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ S_{i}^{(k + 1)} = \frac{1}{2} S_{i}^{(k)} + \frac{1}{2} \frac{ {\sum}_{j\in \mathbb{J}_{i}} d_{ij} }{ {\sum}_{j\in \mathbb{J}_{i}} 2\tau S_{j}^{(k)} }, $$\end{document}</tex-math><mml:math id="M34"><mml:msubsup><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac><mml:msubsup><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>k</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mo>â</mml:mo></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>â</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="double-struck">J</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>â</mml:mo></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>â</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="double-struck">J</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mn>2</mml:mn><mml:mi>Ï</mml:mi><mml:msubsup><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>k</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:math><graphic xlink:href="12021_2017_9352_Article_Equ4.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq17"><alternatives><tex-math id="M35">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}${\sum }_{j{\in }\mathbb {J}_{i}}d_{ij}$\end{document}</tex-math><mml:math id="M36"><mml:msub><mml:mrow><mml:mo>â</mml:mo></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>â</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="double-struck">J</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12021_2017_9352_Article_IEq17.gif"/></alternatives></inline-formula> are the fan sums found while processing the list-mode data for delayed events (for more details see â<xref rid="Sec3" ref-type="sec">List-mode Data Processing</xref>â and Markiewicz et al. (<xref ref-type="bibr" rid="CR41">2016a</xref>) and Panin et al. (<xref ref-type="bibr" rid="CR51">2007</xref>)). The fan sums in the denominator of Eq.Â <xref rid="Equ4" ref-type="">4</xref> are calculated at each iteration on the GPU exploiting inter-thread communication for very fast reductions using CUDA <italic>shuffle instructions</italic> (Luitjens <xref ref-type="bibr" rid="CR37">2014</xref>). The 3D fan sums are found first for axial fans as shown in Fig.Â <xref rid="Fig4" ref-type="fig">4</xref> and then for transaxial fan sums for any given detector <italic>i</italic>. The random event sinograms in span-1 are found by applying (<xref rid="Equ3" ref-type="">3</xref>) to each sinogram bin (span-11 sinograms are found by reducing span-1 sinograms accordingly).
<fig id="Fig4"><label>Fig. 4</label><caption><p><bold>Calculation of 3D fan sums for each detector</bold><bold><italic>i</italic></bold>: The sum is first calculated axially by forming axial fans of 64 rings and then transaxially by forming transaxial fans, such that all detectors <inline-formula id="IEq14"><alternatives><tex-math id="M37">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\mathbb {J}_{i}$\end{document}</tex-math><mml:math id="M38"><mml:msub><mml:mrow><mml:mi mathvariant="double-struck">J</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12021_2017_9352_Article_IEq14.gif"/></alternatives></inline-formula> in coincidence with detector <italic>i</italic> are summed (three axial fans are shown within the detector rings where two of the fans are on extreme ends). One axial fan sum is calculated by two CUDA warps (see the figure on the right), where each warp consists of 32 CUDA threads executed in parallel. The values stored in 32 registers (one register per thread) are reduced to one sum through fast parallel reductions obtained through rapid communications between the threads and facilitated by CUDA <italic>shuffle instructions</italic> (Luitjens <xref ref-type="bibr" rid="CR37">2014</xref>). The same is done for the other warp to form one axial fan sum. Repeating it over all transaxial detectors will constitute a full fan sum for detector <italic>i</italic>
</p></caption><graphic xlink:href="12021_2017_9352_Fig4_HTML" id="MO6"/></fig>
</p>
      </sec>
    </sec>
    <sec id="Sec10">
      <title>Fully 3D Scatter Model</title>
      <p id="Par32">Another key component for accurate quantitative imaging is scatter correction. In this work we adopted a fully 3D, voxel-driven scatter model (VSM) which is based on single scatter simulation. The key difference of this model to the established methods of Ollinger (<xref ref-type="bibr" rid="CR49">1996</xref>) and Watson (<xref ref-type="bibr" rid="CR61">2000</xref>) and their newer extensions (Iatrou et al. <xref ref-type="bibr" rid="CR26">2006</xref>; Kim and Ye <xref ref-type="bibr" rid="CR29">2011</xref>), which use a line of response (LOR) driven approach, is that in the proposed voxel-driven approach each emission voxel is treated independently resulting in a separate 3D probability scatter sinogram for each emission voxel. The global scatter response is found by summing all the scatter contributions from each emitting voxel. This feature can prove useful in modelling the scatter component in the system matrix (Tamal et al. <xref ref-type="bibr" rid="CR57">2006</xref>; Markiewicz et al. <xref ref-type="bibr" rid="CR39">2007</xref>), and enables more accurate TOF scatter estimates (Markiewicz et al. <xref ref-type="bibr" rid="CR38">2016b</xref>). Furthermore, it allows greater control over the input emission (its resolution and the radioactivity concentration threshold, over which voxels are considered for scatter estimation).
</p>
      <sec id="FPar10" sec-type="methods">
        <title>Methods</title>
        <p id="Par33">Consider a positron emission at <italic>E</italic> giving rise to a photon pair emitted such that one photon is detected unscattered at <italic>A</italic> while the other one is incident on scattering patch <italic>S</italic>. The unscattered photon trajectory (<inline-formula id="IEq18"><alternatives><tex-math id="M39">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\hat {\mathbf {a}}=-\hat {\mathbf {u}}$\end{document}</tex-math><mml:math id="M40"><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold">a</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mo>â</mml:mo><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math><inline-graphic xlink:href="12021_2017_9352_Article_IEq18.gif"/></alternatives></inline-formula>) is defined by detector <italic>A</italic> and emission location <italic>E</italic> (shown in the sagittal plane in Fig.Â <xref rid="Fig5" ref-type="fig">5</xref>a). The probability of photons being incident on <italic>S</italic> is:
<disp-formula id="Equ5"><label>5</label><alternatives><tex-math id="M41">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ P_{\mathrm{i}}(SEA) = \varepsilon_{A} \exp\left[-{\int}_{-r_{A}}^{r_{S}} \mu(l \hat{\mathbf{a}} + \mathbf{e})\mathrm{d} l\right], $$\end{document}</tex-math><mml:math id="M42"><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi mathvariant="italic">SEA</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>Îµ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>exp</mml:mo><mml:mfenced close="]" open="[" separators=""><mml:mrow><mml:mo>â</mml:mo><mml:msubsup><mml:mrow><mml:mo>â«</mml:mo></mml:mrow><mml:mrow><mml:mo>â</mml:mo><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>S</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msubsup><mml:mi>Î¼</mml:mi><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold">a</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover><mml:mo>+</mml:mo><mml:mi mathvariant="bold">e</mml:mi><mml:mo>)</mml:mo><mml:mi mathvariant="normal">d</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:mfenced><mml:mo>,</mml:mo></mml:math><graphic xlink:href="12021_2017_9352_Article_Equ5.gif" position="anchor"/></alternatives></disp-formula>where <italic>Îµ</italic>
<sub><italic>A</italic></sub> is the geometric efficiency of detecting a photon emitted at <italic>E</italic> (specified by position vector <bold>e</bold>), <italic>r</italic>
<sub><italic>A</italic></sub> is the distance between <italic>E</italic> and the opposing detector along path <inline-formula id="IEq19"><alternatives><tex-math id="M43">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\hat {\mathbf {u}}$\end{document}</tex-math><mml:math id="M44"><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math><inline-graphic xlink:href="12021_2017_9352_Article_IEq19.gif"/></alternatives></inline-formula> and <italic>r</italic>
<sub><italic>S</italic></sub> is the distance between <italic>E</italic> and the beginning of patch <italic>S</italic> along path <inline-formula id="IEq20"><alternatives><tex-math id="M45">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\hat {\mathbf {a}}$\end{document}</tex-math><mml:math id="M46"><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold">a</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math><inline-graphic xlink:href="12021_2017_9352_Article_IEq20.gif"/></alternatives></inline-formula>. Each scatter patch is represented by a single point, <bold>s</bold> = (<italic>s</italic>
<sub><italic>x</italic></sub>,<italic>s</italic>
<sub><italic>y</italic></sub>,<italic>s</italic>
<sub><italic>z</italic></sub>), from which photons are assumed to be scattered. Therefore, the absolute probability that a photon emitted around <italic>E</italic> will scatter at <italic>S</italic> (i.e., along the length <italic>l</italic>
<sub><italic>S</italic></sub> of the scattering patch) while the other photon will be received unscattered at crystal <italic>A</italic> is given by
<disp-formula id="Equ6"><label>6</label><alternatives><tex-math id="M47">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ P_{\mathrm{s}}(SEA) = P_{\mathrm{i}}(SEA) \left\{ 1 - \exp\left[-{\int}_{-l_{\mathrm{s}}/2}^{l_{s}/2} \mu(l\hat{\mathbf{a}}+\mathbf{s})\mathrm{d} l\right] \right\}. $$\end{document}</tex-math><mml:math id="M48"><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi mathvariant="italic">SEA</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi mathvariant="italic">SEA</mml:mi><mml:mo>)</mml:mo><mml:mfenced close="}" open="{" separators=""><mml:mrow><mml:mn>1</mml:mn><mml:mo>â</mml:mo><mml:mo>exp</mml:mo><mml:mfenced close="]" open="[" separators=""><mml:mrow><mml:mo>â</mml:mo><mml:msubsup><mml:mrow><mml:mo>â«</mml:mo></mml:mrow><mml:mrow><mml:mo>â</mml:mo><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow></mml:msub><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mi>Î¼</mml:mi><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold">a</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover><mml:mo>+</mml:mo><mml:mi mathvariant="bold">s</mml:mi><mml:mo>)</mml:mo><mml:mi mathvariant="normal">d</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced><mml:mn>.</mml:mn></mml:math><graphic xlink:href="12021_2017_9352_Article_Equ6.gif" position="anchor"/></alternatives></disp-formula>The probability of photons scattering from <italic>S</italic> towards a given detector <italic>B</italic> is found using the Klein-Nishina (K-N) cross-section, d<italic>Ï</italic>
<sub>e</sub>/dÎ©, for unpolarised radiation and the solid angle Î©<sub><italic>B</italic></sub> subtended by detector <italic>B</italic> at <italic>S</italic>, leading to the total absolute probability <italic>P</italic>
<sub>s</sub>(<italic>B</italic>
<italic>S</italic>
<italic>E</italic>
<italic>A</italic>) that a positron emitted at <italic>E</italic> will result in an unscattered photon detected at <italic>A</italic> and the paired scattered photon at <italic>B</italic>:
<disp-formula id="Equ7"><label>7</label><alternatives><tex-math id="M49">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ P_{\mathrm{s}}(BSEA) \,=\, P_{\mathrm{s}}(SEA) \frac{{\Omega}_{B}}{\sigma_{\mathrm{e}}} \left( \frac{\mathrm{d} \sigma_{\mathrm{e}}}{\mathrm{d} {\Omega}_{B}}\right) \exp\left[-c_{B}{\int}_{0}^{r_{B}} \mu(l\hat{\mathbf{s}}_{i} + \mathbf{s})\mathrm{d} l\right], $$\end{document}</tex-math><mml:math id="M50"><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi mathvariant="italic">BSEA</mml:mi><mml:mo>)</mml:mo><mml:mspace width="0.3em"/><mml:mo>=</mml:mo><mml:mspace width="0.3em"/><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi mathvariant="italic">SEA</mml:mi><mml:mo>)</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>Î©</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>Ï</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">d</mml:mi><mml:msub><mml:mrow><mml:mi>Ï</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi><mml:msub><mml:mrow><mml:mi>Î©</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced><mml:mo>exp</mml:mo><mml:mfenced close="]" open="[" separators=""><mml:mrow><mml:mo>â</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mrow><mml:mo>â«</mml:mo></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msubsup><mml:mi>Î¼</mml:mi><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi mathvariant="bold">s</mml:mi><mml:mo>)</mml:mo><mml:mi mathvariant="normal">d</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:mfenced><mml:mo>,</mml:mo></mml:math><graphic xlink:href="12021_2017_9352_Article_Equ7.gif" position="anchor"/></alternatives></disp-formula>where <italic>Ï</italic>
<sub>e</sub> is the total K-N electronic cross-section, <italic>c</italic>
<sub><italic>B</italic></sub> is the factor accounting for the changed photon energy after scattering towards <italic>B</italic>. The 3D scatter response to emission point <italic>E</italic> is found by accounting for all detectors receiving unscattered photons. This procedure is repeated for all the possible emission voxels to estimate the full scatter sinogram.
<fig id="Fig5"><label>Fig. 5</label><caption><p><bold>Scatter modelling and validation setup</bold>. <bold>a:</bold> Voxel-driven scatter model (VSM) based on single scatter simulation. It assumes that photons emitted at <italic>E</italic> (shown in the sagittal plane) along <inline-formula id="IEq15"><alternatives><tex-math id="M51">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\hat {\mathbf {u}}$\end{document}</tex-math><mml:math id="M52"><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math><inline-graphic xlink:href="12021_2017_9352_Article_IEq15.gif"/></alternatives></inline-formula> are unscattered and detected while the opposing photons emitted along <inline-formula id="IEq16"><alternatives><tex-math id="M53">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\hat {\mathbf {a}}$\end{document}</tex-math><mml:math id="M54"><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold">a</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math><inline-graphic xlink:href="12021_2017_9352_Article_IEq16.gif"/></alternatives></inline-formula> are assumed scattered from the original trajectory and then detected on the detector ring. <bold>b:</bold> Validation Monte Carlo setup using SimSET with <sup>18</sup>F-florbetapir and the Siemens Biograph mMR geometry. Top row includes the transaxial and sagittal <italic>Î¼</italic>-map images whereas the bottom row consists of the corresponding emission images for brain and point source (marked point <italic>E</italic>) simulations</p></caption><graphic xlink:href="12021_2017_9352_Fig5_HTML" id="MO8"/></fig>
</p>
      </sec>
      <sec id="FPar11">
        <title>Implementation</title>
        <p id="Par34">In this model, a sub-sample <italic>K</italic>
<sub>S</sub> of all available detectors <italic>K</italic> are considered to receive the unscattered photons and their paired scattered photons, all emitted at the vicinity of any point <italic>E</italic>. The model requires as an input the current estimate of radioactivity distribution and the <italic>Î¼</italic>-map images. Due to the efficient and high-throughput computational model, both images can be represented in high resolution, allowing high accuracy and precision. For <sup>18</sup>F-florbetapir radiotracer, the <italic>Î¼</italic>-map was down-scaled by a factor of two (from [127 Ã 344 Ã 344] to [63 Ã 172 Ã 172] using 4 mm<sup>3</sup> voxels) to allow high accuracy of photon attenuation calculations. The radioactivity image was down-scaled independently from the <italic>Î¼</italic>-map by a factor of 3, resulting in [43 Ã 114 Ã 114] images. The independent scaling allows for greater control of the trade-off between accuracy and computational time.</p>
        <p id="Par35">One of the advantages of this voxel-driven approach is its suitability for multi-level parallel GPU computing (or using other parallel computing architectures), with all the emission voxels being separated and calculated independently in the top level of parallelism. Then, in the lower level of parallelism, all the detectors receiving unscattered photons are considered separately: first axially with 8 detector rings out of all 64 rings (resulting in 1:8 axial sampling) and then transaxially with 64 detectors out of 448 (resulting in 1:7 transaxial sampling, similar to the axial sampling using the Siemens Biograph mMR geometry). The next (lower) level of parallelism is used for calculating the paths of scattered photons detected by 8 axial rings and 32 transaxial detectors, which form a 3D fan of the <italic>basic scatter distribution</italic> originating at scattering point <italic>S</italic> on trajectory <inline-formula id="IEq21"><alternatives><tex-math id="M55">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\hat {\mathbf {a}}$\end{document}</tex-math><mml:math id="M56"><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold">a</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math><inline-graphic xlink:href="12021_2017_9352_Article_IEq21.gif"/></alternatives></inline-formula> and ending on the detector ring (Fig.Â <xref rid="Fig5" ref-type="fig">5</xref>). The lowest level of parallelism is employed on each CUDA warp (a group of 32 CUDA threads scheduled and executed simultaneously) with fast reductions using <italic>shuffle instructions</italic> introduced in the NVIDIAâs Kepler architecture, facilitating rapid tracing of photon rays through the attenuating medium (NVIDIA <xref ref-type="bibr" rid="CR46">2012</xref>).</p>
        <p id="Par36">The tracing involves calculating the survival probability of photons arriving at scattering patch <italic>S</italic> or a detector, for both scattered and unscattered photons. The photon tracing along rays from each voxel to any detector is calculated once and stored in a look-up table (LUT) in the device memory using 16-bit integer format with a global floating point scaling factor. Since only a subset of axial and transaxial detectors are used in scatter estimation, the full size scatter sinograms are found using intra-sinogram bi-cubic interpolation for individual sinograms and inter-sinogram bi-linear interpolation performed in the Michelogram space. Dedicated scatter normalisation efficiencies are used for each individual oblique sinogram (see â??â).</p>
        <p id="Par37">The last step is to scale the scatter sinogram to the prompt data to account for multiple scatter and scatter from outside the FOV. Since all the quantitative proportions between scatter sinograms are maintained within the 3D model, the scaling factors are obtained using the weighted least squares method applied to reduced sinograms for high count levels. Finally, this process is followed by scatter specific normalisation in span-1 or span-11 (cf. â<xref rid="Sec6" ref-type="sec">Axial Normalisation Factors</xref>â).</p>
      </sec>
      <sec id="FPar12">
        <title>Monte Carlo Validation</title>
        <p id="Par38">The proposed scatter model was validated using Monte Carlo simulation toolkit SimSET (Lewellen et al. <xref ref-type="bibr" rid="CR35">1998</xref>) with two setups: (i) a point source within an attenuating medium and (ii) simulated amyloid <sup>18</sup>F-florbetapir brain scan (Fig.Â <xref rid="Fig5" ref-type="fig">5</xref>b). In both cases the geometry of the Siemens Biograph mMR was used. The <italic>Î¼</italic>-map for both setups is taken from a real amyloid brain scan, including the patientâs head and neck, the table and the head coil. The location of the simulated point source is marked with point <italic>E</italic> in Fig.Â <xref rid="Fig5" ref-type="fig">5</xref>b, whereas the whole brain simulated radioactivity is taken from a real reconstructed <sup>18</sup>F-florbetapir brain scan. In the case of the point source, a total of 2 Ã 10<sup>10</sup> events were simulated. For the brain scan, a total of 3 Ã 10<sup>10</sup> events were simulated across the whole brain.</p>
      </sec>
    </sec>
    <sec id="Sec11">
      <title>Partial Volume Correction</title>
      <sec id="FPar13" sec-type="methods">
        <title>Methods</title>
        <p id="Par39">Partial volume correction (PVC) is applied in order to improve both the qualitative and quantitative aspects of the reconstructed PET images by correcting for the degrading effects of the limited spatial resolution. While many PVC methods have been proposed (see e.g., Erlandsson et al. <xref ref-type="bibr" rid="CR17">2012</xref> for review), here we have chosen to implement the âiterative Yangâ (iY) method, an iterative version of a method proposed by Yang et al. (<xref ref-type="bibr" rid="CR62">1996</xref>). This method utilises a segmented anatomical image to correct for the spill-over between different regions on a voxel-by-voxel basis, as modelled by the PSF of the scanner. There is no correction for blurring between voxels within the same region, however. For these reasons the method does not suffer from the excessive noise-amplification and ringing artefacts associated with standard de-convolution algorithms, and produces results similar to those of the RBV method (Thomas et al. <xref ref-type="bibr" rid="CR59">2011</xref>). The iY method can be described as follows
<disp-formula id="Equ8"><label>8</label><alternatives><tex-math id="M57">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \hat{f}^{(k)}(\mathbf{x}) = g(\mathbf{x})\frac{b^{(k-1)}(\mathbf{x})} {h(\mathbf{x}) \ast b^{(k-1)}(\mathbf{x})} $$\end{document}</tex-math><mml:math id="M58"><mml:msup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>k</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup><mml:mo>(</mml:mo><mml:mi mathvariant="bold">x</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mi>g</mml:mi><mml:mo>(</mml:mo><mml:mi mathvariant="bold">x</mml:mi><mml:mo>)</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>k</mml:mi><mml:mo>â</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:msup><mml:mo>(</mml:mo><mml:mi mathvariant="bold">x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>h</mml:mi><mml:mo>(</mml:mo><mml:mi mathvariant="bold">x</mml:mi><mml:mo>)</mml:mo><mml:mo>â</mml:mo><mml:msup><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>k</mml:mi><mml:mo>â</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:msup><mml:mo>(</mml:mo><mml:mi mathvariant="bold">x</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mfrac></mml:math><graphic xlink:href="12021_2017_9352_Article_Equ8.gif" position="anchor"/></alternatives></disp-formula>with
<disp-formula id="Equ9"><label>9</label><alternatives><tex-math id="M59">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ b^{(k)}(\mathbf{x}) = \sum\limits_{i = 1}^{N} a^{(k)}_{i} I_{i}(\mathbf{x}) $$\end{document}</tex-math><mml:math id="M60"><mml:msup><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>k</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup><mml:mo>(</mml:mo><mml:mi mathvariant="bold">x</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:munderover accent="false" accentunder="false"><mml:mrow><mml:mi>â</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:msubsup><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>k</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup><mml:msub><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi mathvariant="bold">x</mml:mi><mml:mo>)</mml:mo></mml:math><graphic xlink:href="12021_2017_9352_Article_Equ9.gif" position="anchor"/></alternatives></disp-formula>and
<disp-formula id="Equ10"><label>10</label><alternatives><tex-math id="M61">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ a^{(k)}_{i} = \frac{\int I_{i}(\mathbf{x}) \hat{f}^{(k)}(\mathbf{x}) d\mathbf{x} } {\int I_{i}(\mathbf{x}) d\mathbf{x}}; i = 1,...,N, $$\end{document}</tex-math><mml:math id="M62"><mml:msubsup><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>k</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mo>â«</mml:mo><mml:msub><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi mathvariant="bold">x</mml:mi><mml:mo>)</mml:mo><mml:msup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>k</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup><mml:mo>(</mml:mo><mml:mi mathvariant="bold">x</mml:mi><mml:mo>)</mml:mo><mml:mi>d</mml:mi><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mo>â«</mml:mo><mml:msub><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi mathvariant="bold">x</mml:mi><mml:mo>)</mml:mo><mml:mi>d</mml:mi><mml:mi mathvariant="bold">x</mml:mi></mml:mrow></mml:mfrac><mml:mo>;</mml:mo><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>...</mml:mn><mml:mo>,</mml:mo><mml:mi>N</mml:mi><mml:mo>,</mml:mo></mml:math><graphic xlink:href="12021_2017_9352_Article_Equ10.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq22"><alternatives><tex-math id="M63">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\hat {f}^{(k)}(\mathbf {x})$\end{document}</tex-math><mml:math id="M64"><mml:msup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>k</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup><mml:mo>(</mml:mo><mml:mi mathvariant="bold">x</mml:mi><mml:mo>)</mml:mo></mml:math><inline-graphic xlink:href="12021_2017_9352_Article_IEq22.gif"/></alternatives></inline-formula> is the corrected image after <italic>k</italic> iterations, <italic>g</italic>(<bold>x</bold>) is the original image, <italic>h</italic>(<bold>x</bold>) is the PSF of the system, <italic>I</italic>
<sub><italic>i</italic></sub>(<bold>x</bold>) is the indicator function for region <italic>i</italic>, <italic>N</italic> is the number of regions (which is unlimited), <bold>x</bold> is a 3D spatial coordinate, â represents the convolution operator, and the integral is evaluated over the entire FOV. The procedure is initialised with: <inline-formula id="IEq23"><alternatives><tex-math id="M65">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\hat {f}^{(0)}(\mathbf {x}) = g(\mathbf {x})$\end{document}</tex-math><mml:math id="M66"><mml:msup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mn>0</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:msup><mml:mo>(</mml:mo><mml:mi mathvariant="bold">x</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mi>g</mml:mi><mml:mo>(</mml:mo><mml:mi mathvariant="bold">x</mml:mi><mml:mo>)</mml:mo></mml:math><inline-graphic xlink:href="12021_2017_9352_Article_IEq23.gif"/></alternatives></inline-formula> and typically converges after approximately 10 iterations.</p>
      </sec>
      <sec id="FPar14">
        <title>Implementation</title>
        <p id="Par40">In practice, PVC is performed in the MRI domain with binary parcellations (Fig.Â <xref rid="Fig6" ref-type="fig">6</xref>), so the PET image first needs to be up-sampled, as the voxel-size is typically smaller in MRI than in PET. The parcellation is obtained using a multi-atlas segmentation propagation strategy (Cardoso et al. <xref ref-type="bibr" rid="CR10">2015</xref>) based on a T1w MR image which was parcellated into 144 regions of interest (ROI), which are then grouped into relevant ROIs for amyloid imaging, including: the cerebellar white and great matter, pons, brain stem, cingulate gyrus, hippocampus, precuneus, parietal and temporal lobes and the whole neocortex. The previously obtained global transformations (from the T1w MR to the PET space, see â<xref rid="Sec7" ref-type="sec">Generation of the <italic>Î¼</italic>-map (Specific to PET/MR Scanners)</xref>â) were then used to propagate the regions of interest from the MRI space to the PET space.
<fig id="Fig6"><label>Fig. 6</label><caption><p>Brain parcellation based on T1w MR image for partial volume correction</p></caption><graphic xlink:href="12021_2017_9352_Fig6_HTML" id="MO7"/></fig>
</p>
        <p id="Par41">The most computationally expensive operation in this PVC algorithm is the 3D convolution, which is expensive for the higher resolution input images (the PET image is upsampled to a resolution of at least that of the T1w MR). The convolution was implemented on the GPU using the method of separable kernels (see the NVIDIAâs CUDA SDK algorithm of 2D separable filters, which we extended to 3D PET images (Podlozhnyuk <xref ref-type="bibr" rid="CR54">2007</xref>)). The 3D kernel is decomposed into three one-dimensional filters: one for the transaxial image rows, one for the transaxial columns and one for the axial rows. Therefore, a separable kernel convolution can be divided into three consecutive one-dimensional convolution operations. It requires only <italic>U</italic> + <italic>V</italic> + <italic>W</italic> multiplications for each output voxel as opposed to the standard convolution requiring <italic>U</italic> â <italic>V</italic> â <italic>W</italic> multiplications (<italic>U</italic>,<italic>V</italic>,<italic>W</italic> are the sizes of the kernel in <italic>x</italic>,<italic>y</italic>,<italic>z</italic> directions, respectively). The kernel itself is based on point source measurements on the Biograph mMR scanner, followed by parametrisation of the measured kernel shape through fitting two Gaussians for each one-dimensional kernel.</p>
      </sec>
    </sec>
  </sec>
  <sec id="Sec12">
    <title>Results and Discussion</title>
    <p id="Par42">To demonstrate and validate the quantitative accuracy of <italic>NiftyPET</italic> package as a whole, we used two list-mode datasets acquired on the Biograph mMR: (i) a 24-hour acquisition of a <sup>68</sup>Ge cylindrical phantom, with a diameter of 20cm; and (ii) a brain scan in an amyloid negative participant using the <sup>18</sup>F-florbetapir radiotracer. The long acquisition phantom data is useful for testing all the quantitative corrections, particularly scatter (when done correctly it will result in uniform images) and normalisation (any high frequencies in the reconstructed image would suggest normalisation inaccuracies). Using the brain scan dataset, we will demonstrate the whole chain of brain imaging and analysis, including: (i) quantitative data modelling, (ii) image reconstruction followed by (iii) partial volume correction and (iv) voxel/regional-level image analysis for amyloid brain deposition. Furthermore, the capabilities of the <italic>NiftyPET</italic> package go beyond the usual point-estimate image reconstruction offering estimates of the distributions of regional and voxel value uncertainties through the use of list-mode bootstrapping. All the presented results here will be shared through Jupyter Notebooksâan excellent and free tool for sharing, communicating, and most of all, replicating data analysis.</p>
    <sec id="FPar15">
      <title>List-mode data processing output</title>
      <p id="Par43">Example output is shown for an amyloid (<sup>18</sup>F-florbetapir) brain scan in Fig.Â <xref rid="Fig7" ref-type="fig">7</xref> (for a comprehensive description see Markiewicz et al. (<xref ref-type="bibr" rid="CR41">2016a</xref>)). FigureÂ <xref rid="Fig7" ref-type="fig">7</xref>a and b show the prompt and delayed event sinograms for the last 10 minute time frame of the total 60 minute acquisition. FigureÂ <xref rid="Fig7" ref-type="fig">7</xref>c shows two radioactivity centre of mass curves for a subject with minimal motion (black curve) and a subject with significant motion (grey). It can be noted that motion patterns are distinct from the patterns of slowly changing tracer kinetics. FigureÂ <xref rid="Fig7" ref-type="fig">7</xref>d shows the dynamic readout of the singles rates per bucket (image <italic>y</italic>-axis) over acquisition time (image <italic>x</italic>-axis).
<fig id="Fig7"><label>Fig. 7</label><caption><p><bold>Selected output of list-mode processing</bold>: <bold>(a, b)</bold> prompt and delayed sinograms for a 10 minute <sup>18</sup>F-florbetapir acquisition. <bold>c</bold> Fast motion detection based on the centre of mass of axial radioactivity distributionâshown for subject with motion (grey curve) and without motion (black curve) over the 60 minute acquisition. <bold>d</bold> Dynamic singles rates reported as 224 buckets for the whole acquisition over time</p></caption><graphic xlink:href="12021_2017_9352_Fig7_HTML" id="MO5"/></fig>
</p>
    </sec>
    <sec id="FPar16">
      <title>Transaxial normalisation factors</title>
      <p id="Par44">Sinogram profiles of all the transaxial components are shown in Fig.Â <xref rid="Fig8" ref-type="fig">8</xref>, including the geometric factors, crystal efficiencies, crystal interference, and detector dead-time. The geometric sinogram pattern (<italic>a</italic>) is repeated over all sinogram angles. The crystal efficiencies (<italic>b</italic>) are provided for each crystal separately, from which a unique normalisation factor is produced using two crystal efficiencies for a given sinogram bin. A sinogram pattern for transaxial crystal interference (<italic>c</italic>) is periodical due to the detector block repetition in the ring. A sinogram profile of dead-time factors only (<italic>d</italic>) is shown for three cases: (i) the first 15 seconds of amyloid acquisition where there are high single rates, (ii) the last 10 minutes and (iii) the overall average over the whole acquisition of 60 minutes. The greatest variability of the dead-time factors can be noticed in case (i) due to high singles rate variability. The gaps in the curves in Fig.Â <xref rid="Fig8" ref-type="fig">8</xref> correspond to the LORs which have at least one dead crystal (acting as a gap between detector blocks).
<fig id="Fig8"><label>Fig. 8</label><caption><p><bold>Transaxial sinogram profiles of normalisation factors for four different components</bold>: <bold>a</bold> in-plane geometric effects; <bold>b</bold> crystal efficienciesâfor each sinogram bin the factor is a sum of products of two crystal efficiencies per each LOR contributing to the sinogram bin; <bold>c</bold> crystal interference (transaxial block effects); <bold>d</bold> detector dead time for each detector sinogram bin which can be a combination of multiple LORs. For this correction bucket <italic>single rates</italic> are required and are obtained from list-mode processing (cf. â<xref rid="Sec3" ref-type="sec">List-mode Data Processing</xref>â). <bold>Note</bold> that the discontinuities in the plots stem from the dead crystals acting as gaps between detector blocks</p></caption><graphic xlink:href="12021_2017_9352_Fig8_HTML" id="MO9"/></fig>
</p>
    </sec>
    <sec id="FPar17">
      <title>Axial normalisation factors</title>
      <p id="Par45">The axial geometric component is captured within the general axial effects component, provided in the normalisation file for axial compression of span-11, whose organisation is demonstrated in the Michelogram space in Fig.Â <xref rid="Fig9" ref-type="fig">9</xref>a. Such axial compression makes image reconstruction faster and less memory demanding at the cost of some accuracy. FiguresÂ <xref rid="Fig9" ref-type="fig">9</xref>b and c show the Michelogram for the statistically rich prompt data of the <sup>68</sup>Ge cylindrical phantom represented in span-1 and span-11, respectively. FigureÂ <xref rid="Fig9" ref-type="fig">9</xref>d shows the derived span-1 axial normalisation factors according to Eq.Â (<xref rid="Equ1" ref-type="">1</xref>), whereas Fig.Â <xref rid="Fig9" ref-type="fig">9</xref>e shows the Michelogram of the normalised emission data, where the patterns of slight imperfections can be noticed for the provided span-11 axial normalisation factors. To achieve best accuracy, all modelling (i.e., ray tracing) is always performed without any axial compression, that is in span-1, and hence using span-11 does not speed up computations, but instead it reduces data transfer times through lower memory usage.
<fig id="Fig9"><label>Fig. 9</label><caption><p><bold>Derivation of span-1 axial normalisation factors.</bold><bold>a</bold> Portion of Michelogram showing two native span-11 groups of five and six sinograms in segment â0â. For each group one normalisation axial factor is provided by the vendor (as shown for segment â+â1â). <bold>b</bold> Michelogram of 24-hour cylindrical phantom acquisition in span-1. <bold>c</bold> Michelogram of the same phantom acquisition as in (b), but in span-11. <bold>d</bold> Michelogram of axial efficiencies derived using the phantom data and the vendor span-11 axial efficiencies according to Eq.Â (<xref rid="Equ1" ref-type="">1</xref>). <bold>e</bold> Axially normalised phantom acquisition</p></caption><graphic xlink:href="12021_2017_9352_Fig9_HTML" id="MO4"/></fig>
</p>
      <p id="Par46">The axial factors for span-11 (provided by the vendor) and the derived factors for span-1 are shown in Fig.Â <xref rid="Fig10" ref-type="fig">10</xref> for true and scatter events. The span-1 factors for true and scatter events as derived in â<xref rid="Sec6" ref-type="sec">Axial Normalisation Factors</xref>â (Fig.Â <xref rid="Fig9" ref-type="fig">9</xref>) are shown only for the first three segments, i.e., for 190 out of 4084 sinograms. There are 11 segments for span-11, while for span-1 there are 121 segments, cupped by the maximum ring difference of 60. For reduced axial FOV imaging, using a subset of detector rings, span-1 normalisation factors are used. Note that the sensitivity of the restricted ring system will be reduced compared to the full ring set, as fewer LORs will sample the image space. Consequently, the reconstructed images will exhibit higher noise levels compared to the full system. Alternatively, to prevent the reduction in sensitivity while achieving fast calculations, it is possible to compress span-1 data into single-slice rebinned (SSR) data and perform fast calculations on the compressed data. This, however, will reduce the accuracy and resolution of the system, while the proposed customisation maintains the resolution and accuracy, albeit at the cost of sensitivity and higher noise levels (the noise can be reduced by increasing the duration of acquisition in some cases).
<fig id="Fig10"><label>Fig. 10</label><caption><p><bold>Axial normalisation factors for span-1 and span-11</bold>. <bold>a</bold>: Span-1 axial factors for the true events, derived from a long phantom acquisition and the provided span-11 axial factors; shown only for the first 190 sinogram planes (which constitute the first three segments of 64 + 2Ã63 sinogram planes) out of the total of 4084 sinograms. <bold>b</bold>: Span-11 geometric axial factors provided with the component normalisation file. <bold>c</bold>: Scatter specific span-1 axial factors derived from a high statistics phantom acquisition (only the first 190 sinogram plane factors are shown). <bold>d</bold>: Scatter span-11 axial factors, also derived from a phantom acquisition</p></caption><graphic xlink:href="12021_2017_9352_Fig10_HTML" id="MO10"/></fig>
</p>
      <p id="Par47">The scatter axial factors are derived by reducing the span-1 scatter factors to span-11. Note that the scatter scaling in routine imaging not only appropriately scales the estimated scatter to the real data, but also accounts for the axial effects and outside FOV scatter specific for each scan, while the derived scatter normalisation accounts for the high frequency axial effects of detector blocks.</p>
    </sec>
    <sec id="FPar18">
      <title>Generation of the <italic>Î¼</italic>-map</title>
      <p id="Par48">The accurate quantification is mostly dependent on the quality of the <italic>Î¼</italic>-map. FigureÂ <xref rid="Fig11" ref-type="fig">11</xref> presents the composite <italic>Î¼</italic>-map including: (i) the patient table together with the attached (ii) upper and lower head and neck coils, which were resampled to the PET FOV and image resolution; (iii) the high accuracy pCT-based <italic>Î¼</italic>-map of the head and neck for the amyloid brain scan. To account for head motion between time frames, the synthesised subject <italic>Î¼</italic>-map is coregistered to each PET time frame using reconstructed images without attenuation correction for better delineation of the head and more robust coregistration. Despite the high accuracy of the pCT-based <italic>Î¼</italic>-map, the coregistration of the <italic>Î¼</italic>-map to the PET image may introduce additional uncertainty caused by the limited precision of coregistration.
<fig id="Fig11"><label>Fig. 11</label><caption><p><bold>Full composite</bold><bold><italic>Î¼</italic></bold><bold>-map of the patient and hardware.</bold> Shown are transaxial, sagittal and coronal views, respectively</p></caption><graphic xlink:href="12021_2017_9352_Fig11_HTML" id="MO11"/></fig>
</p>
    </sec>
    <sec id="FPar19">
      <title>Noise reduction of the estimated random events</title>
      <p id="Par49">The noise reduction of estimated randoms events allows for better quantitative precision. The extent to which the noise is reduced can be seen in a single span-11 sinogram profile for a 10 minute brain amyloid scan (50-60 minutes) shown in Fig.Â <xref rid="Fig12" ref-type="fig">12</xref>a. To check if the estimation is biased, all the direct and oblique sinograms (837 in total) were summed and the same sinogram profile location is shown in Fig.Â <xref rid="Fig12" ref-type="fig">12</xref>b. This demonstrates an unbiased random events estimation supported by the excellent agreement with the measured (summed for high statistics) counts of delayed coincidences in each sinogram bin.
<fig id="Fig12"><label>Fig. 12</label><caption><p><bold>Sinogram profiles of estimated randoms and measured delayed events</bold>. <bold>a</bold>: Single sinogram profile for the measured delayeds and estimated random events of a 10 minute brain amyloid scan. <bold>b</bold>: The same profile but with all sinograms summed axially to obtain better statistics and demonstrate a good agreement of the measured delayeds and the estimated random events</p></caption><graphic xlink:href="12021_2017_9352_Fig12_HTML" id="MO12"/></fig>
</p>
    </sec>
    <sec id="FPar20">
      <title>Voxel-based scatter model validation</title>
      <p id="Par50">The performance of the proposed fully 3D scatter model relative to the Monte Carlo (MC) simulation is presented in Fig.Â <xref rid="Fig13" ref-type="fig">13</xref>. The MC simulated single scatter sinograms were either summed axially to form one scatter sinogram with very good statistics or single-slice rebinned (SSR) to maintain some information of the axial scatter distribution at the cost of statistics. FigureÂ <xref rid="Fig13" ref-type="fig">13</xref>a shows the agreement of the proposed VSM model (red) with the MC (black) for sinogram <italic>profile 1</italic> as marked in the axially summed MC scatter sinogram in Fig.Â <xref rid="Fig13" ref-type="fig">13</xref>e. FigureÂ <xref rid="Fig13" ref-type="fig">13</xref>b shows the same but for sinogram <italic>profile 2</italic>. The corresponding axially summed VSM scatter sinogram is shown in Fig.Â <xref rid="Fig13" ref-type="fig">13</xref>f. The comparison with SSR scatter sinograms for sinogram <italic>profile 1</italic> is shown in Fig.Â <xref rid="Fig13" ref-type="fig">13</xref>c (fewer statistics in the MC sinograms with more axial specificity). Sinogram <italic>profile 1</italic> for the whole brain scan simulation is show in Fig.Â <xref rid="Fig13" ref-type="fig">13</xref>d as marked in the MC SSR sinogram in Fig.Â <xref rid="Fig13" ref-type="fig">13</xref>g. The corresponding VSM sinogram is shown in Fig.Â <xref rid="Fig13" ref-type="fig">13</xref>h. The VSM sinogram was fitted to the MC simulated multiple scatter in Fig.Â <xref rid="Fig13" ref-type="fig">13</xref>d. The presented figures demonstrate that the proposed scatter modelling can recover the scatter response with absolute probabilistic quantification for each emission voxel separately.
<fig id="Fig13"><label>Fig. 13</label><caption><p><bold>Scatter validation using Monte Carlo (MC) SimSET simulations:</bold><bold>a</bold> Single scatter response to a point source <italic>E</italic> (see Fig.Â <xref rid="Fig5" ref-type="fig">5</xref>b) as estimated through the proposed VSM model (red) and the MC (dotted black) for sinogram <italic>profile 1</italic> as marked in (e); the sinograms were summed axially for good MC statistics. <bold>b</bold> The same as (a) but for sinogram <italic>profile 2</italic>. <bold>c</bold> The same sinogram <italic>profile 1</italic> as in (a) but the sinograms are single-slice rebinned (SSR). <bold>d</bold> Scaling of VSM estimate to multiple scatter MC sinogram for SSR sinogram <italic>profile 1</italic>. <inline-formula id="IEq24"><alternatives><tex-math id="M67">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\blacklozenge $\end{document}</tex-math><mml:math id="M68"><mml:mo>â¦</mml:mo></mml:math><inline-graphic xlink:href="12021_2017_9352_Article_IEq24.gif"/></alternatives></inline-formula>
<bold>e</bold> The sum of all MC simulated single scatter sinograms with marked <italic>profiles 1</italic> and <italic>2</italic> for reference; <bold>f</bold> the corresponding VSM estimated scatter sinogram. <bold>g</bold> An SSR sinogram of the full brain MC simulation with marked <italic>profile 1</italic> for reference; <bold>h</bold> the corresponding full brain VSM estimated scatter sinogram (SSR summed)</p></caption><graphic xlink:href="12021_2017_9352_Fig13_HTML" id="MO13"/></fig>
</p>
      <p id="Par51">The trade-off between the accuracy of the model and the computational time is controlled by the resolution of the input <italic>Î¼</italic>-map and the current estimate of the emission image. In current settings for amyloid imaging, the input emission image is down-sampled by a factor of 3, resulting in a â¼ 6 mm emission voxel size, whereas for higher accuracy attenuation path calculations, the <italic>Î¼</italic>-map is down-sampled by a factor of two, resulting in a â¼ 4 mm voxel size. These settings result in the GPU computational time of 16 seconds per one iteration of the scatter forward modelling using the Tesla K20 graphics card. The scatter distribution as a response to a point source, contains high frequencies, mainly due to the sharp edges of the attenuating table and head coil (Fig.Â <xref rid="Fig13" ref-type="fig">13</xref>e and f). Despite the fact that the proposed scatter model uses only a limited set of transaxial and axial detectors, the high frequencies are well recovered at the point source response level. In practical settings, most scans consist of multiple point sources for which the high frequencies will likely disappear in the global scatter sinogram as can be seen in Fig.Â <xref rid="Fig13" ref-type="fig">13</xref>g and h. However, this will depend on the spatial distribution of the radiotracer. Furthermore, as shown in Fig.Â <xref rid="Fig13" ref-type="fig">13</xref>d, the proposed single scatter model can approximate multiple scatter by simple scaling to the scatter prompt data. This proves that for brain imaging single scatter modelling is sufficient even in the presence of the head coil.</p>
    </sec>
    <sec id="Sec13">
      <title>Uniform and Artefact Free Image Reconstruction</title>
      <p id="Par52">Apart from the individual validations of attenuation, scatter and randoms, the software components are validated as a whole package with the long phantom acquisition. FigureÂ <xref rid="Fig14" ref-type="fig">14</xref> shows the transaxial (<italic>a</italic>) and coronal (<italic>b</italic>) image profiles of the reconstructed images shown on the right of the profiles. Note, that with this reconstruction it is possible to recover the global quantification of radioactivity per tissue volume [Bq/mL]. Furthermore, it was possible to obtain artefact free reconstructions indicating good performance of the normalisation component. The images and the profiles in Fig.Â <xref rid="Fig14" ref-type="fig">14</xref>a and b demonstrate good transaxial and axial uniformity, confirming accurate scatter and attenuation correction. In case of scatter inaccuracies, the images and profiles would most likely show a bump in the centre (scatter underestimation) or a dip (scatter overestimation). In the case of attenuation correction, note that the <italic>Î¼</italic>-map is not measured in the PET image space and hence has to be aligned precisely as otherwise even 0.5 mm will make visible non-uniformities in the image (visible at high count levels). Note the greater noise at the ends of axial FOV in Fig.Â <xref rid="Fig14" ref-type="fig">14</xref>b due to lower scanner sensitivity at those ends. In addition, the accuracy of the scatter and randoms estimates are shown in the projection space for one sinogram profile shown in Fig.Â <xref rid="Fig14" ref-type="fig">14</xref>c. The accuracy of the scatter estimate can be observed in the scatter-and-randoms-only regions, at both ends of the true component peak; whereas the fit of the estimated randoms can be seen at the far ends of the profile.
<fig id="Fig14"><label>Fig. 14</label><caption><p><bold>Quantitative validation using the 20 cm</bold><sup><bold>68</bold></sup><bold>Ge cylindrical phantom:</bold><bold>a</bold> Transaxial image profile with its position marked by arrows in the image on the right. <bold>b</bold> Axial image profile with marked position in the coronal image on the right. <bold>c</bold> Direct sinogram profile corresponding to the transaxial image plane (<italic>a</italic>). The sinogram profile contains prompt data and the estimated scatter and randoms events with its agreement in the scatter-and-randoms-only regions. Note the detector gaps in the profile</p></caption><graphic xlink:href="12021_2017_9352_Fig14_HTML" id="MO14"/></fig>
</p>
      <p id="Par53">The absolute quantification in Bq/mL was achieved with a uniform cylindrical phantom scan with an independently and accurately measured sample from the phantom to obtain a single scaling factor, while ensuring high accuracy corrections for photon attenuation, scatter, detector normalization and dead time (Bailey et al. <xref ref-type="bibr" rid="CR4">1991</xref>). Although, such calibration is needed for some studies, it may not be needed for other studies, which use reference tissue regions for quantification (e.g., static standardised uptake value ratio [SUVR] or dynamic simplified reference tissue model estimates) (Meikle and Badawi <xref ref-type="bibr" rid="CR42">2005</xref>). In addition, the projector, together with the scatter model, can be used for simulating realistic PET projection data with different noise levels for any given digital phantom. Such comprehensively simulated data can then be reconstructed using <italic>NiftyPET</italic> in the research of optimal neuroimaging methods.</p>
    </sec>
    <sec id="Sec14">
      <title>Brain Imaging with Partial Volume Correction and Uncertainty Estimation</title>
      <p id="Par54">The presented methodology allows for a critical evaluation of the impact of PET count statistics on every part of the image reconstruction and analysis chain, including attenuation, scatter and randoms corrections, image registration (between MR and PET spaces), image interpolation (when resampling images due to registration and PVC), image segmentation/parcellation and PVC. This was achieved by resampling the list-mode data and generating 50 replications of the dataset, followed by repeating the image reconstruction and analysis chain in exactly the same way 50 times. This generated the distributions (uncertainties) of the estimated statistics of amyloid deposition at voxel and regional levels.</p>
      <p id="Par55">FigureÂ <xref rid="Fig15" ref-type="fig">15</xref> shows the results of the reconstructed images, normalised to the average of grey matter cerebellum, without (top row) and with the PVC (third row), producing SUVr images. The T1w image, acquired simultaneously with the source PET image on the Biograph mMR, was first parcellated with the specific regions of interest for amyloid imaging. Since the scanned participant was amyloid negative, most of the tracer uptake was in the white matter. The most conspicuous effect of the PVC is the improved delineation of the WM region, while the information about the tracer distribution within the region is preserved. This PVC correction is helpful in eliminating false positive amyloid measurements due to the spilling of WM radioactivity into GM regions.
<fig id="Fig15"><label>Fig. 15</label><caption><p><bold>Voxel-wise uncertainty estimation for PVC and non-PVC reconstructed images:</bold><bold>Top two rows:</bold> Four iterations of OSEM with 14 subsets (grey-scale) and the corresponding standard error image (copper-scale) after 50 bootstrap replications. <bold>Bottom two rows:</bold> The same as above but with added post-reconstruction PVC correction using the iterative Yang method (Erlandsson et al. <xref ref-type="bibr" rid="CR17">2012</xref>)</p></caption><graphic xlink:href="12021_2017_9352_Fig15_HTML" id="MO15"/></fig>
</p>
      <p id="Par56">Using the bootstrapping within the processing chain it was possible to generate standard error images (in copper colour scale) for both casesâwith and without the PVC. Note, that despite the greater quantitative accuracy, the PVC introduces additional variability which can be explained by: (i) increased signal in the cortical regions from surrounding regions and thus increasing the variance, as well as (ii) the image registration which is slightly different for the various noise realisations of the PET data, consequently leading to the spatial variance of the brain parcellation. After normalising the standard error images by the corresponding mean images, it was observed that such normalised images for the cases with and without PVC are almost identical apart from the boundaries of the predefined ROIs where the variability is higher, likely due to the imprecision of MR-PET coregistration.</p>
      <p id="Par57">The voxel uncertainties, which can be quantified within <italic>NiftyPET</italic>, are greater at the end of the axial FOV due to the lower scanner sensitivity at this location. The presented voxel-level uncertainties can be reduced by considering larger regions instead of voxels.</p>
      <p id="Par58">With this capability of uncertainty estimation, it is possible to ascertain the impact of limited counting statistics in PET on all the different stages of image reconstruction and analysis, i.e., the image registration being inadvertently affected by the PET image noise, which consequently has an effect on attenuation and scatter corrections, partial volume correction and regional quantitative analysis. Furthermore, the counting statistics will have a direct impact on the scatter estimates and its scaling to the prompt data especially for short and noisy dynamic time frames. The same applies to the estimates of random events based on the measured delayed coincidences which are resampled the same way as the prompt events. All these aspects of error propagation through all of the image generation stages with their intricate dependencies are accounted for in the presented infrastructure using the efficient list-mode bootstrap resampling (cf. Markiewicz et al. <xref ref-type="bibr" rid="CR41">2016a</xref>). This may be useful in estimating the magnitude of errors in the measurement of FDG uptake in tumours (Kinahan and Fletcher <xref ref-type="bibr" rid="CR30">2010</xref>) or measuring the change in amyloid deposition in longitudinal studies of neurodegeneration (Landau et al. <xref ref-type="bibr" rid="CR32">2015</xref>); however such analyses go beyond the scope of this paper and constitute our future work. Currently, the software package is being further developed to include a richer library of reconstruction methods (Ehrhardt et al. <xref ref-type="bibr" rid="CR16">2016</xref>).</p>
    </sec>
    <sec id="Sec15">
      <title>Execution Timings</title>
      <p id="Par59">The performance was evaluated on three GPU cards. Two of the cards (NVidiaâs Tesla K20 and TITAN Xp) were hosted separately on a Dell workstation (Precision T7600; 6-core Intel Xeon CPU E5-2630 @ 2.3 GHz; RAM: 64 GB @1333 MHz) and the other GPU (GeForce GTX 1080) was hosted in a Dell Alienware 17 R4 laptop (8-core Intel Core i7-7820HK CPU @ 2.90 GHz; RAM: 16 GB DDR4 @ 2667 MHz). The computational times were decomposed into four main stages and presented for the processing chain starting with the generation of the <italic>Î¼</italic>-map and finishing with a PVC image (see TableÂ <xref rid="Tab1" ref-type="table">1</xref>). Note that the laptop is newer than the Dell workstation, having a more efficient processor and faster memory and hence the execution times tend to be faster (transfers between CPU and GPU memory are faster). Scatter interpolation is the biggest bottleneck due to a CPU Python routine (not yet implemented on the GPU).
<table-wrap id="Tab1"><label>Table 1</label><caption><p>Execution timings in seconds</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left"/><th align="left" colspan="3">Host/Device</th></tr><tr><th align="left">Processing stage</th><th align="left">Workstation/Tesla K20</th><th align="left">Workstation/TITAN Xp</th><th align="left">Laptop/GTX 1080</th></tr></thead><tbody><tr><td align="left"><italic>Î¼</italic>-map generation<sup>â</sup></td><td align="left">78.6</td><td align="left">72.2</td><td align="left">65.83</td></tr><tr><td align="left">LM processing <sup>â</sup>
</td><td align="left">9.1</td><td align="left">7.6</td><td align="left">7.3</td></tr><tr><td align="left">Image reconstruction<sup>â¡</sup>
</td><td align="left">217.7</td><td align="left">258.0</td><td align="left">188.3</td></tr><tr><td align="left">Scatter modelling</td><td align="left">47.5</td><td align="left">37.1</td><td align="left">37.5</td></tr><tr><td align="left">Scatter interpolation</td><td align="left">190.4</td><td align="left">193.7</td><td align="left">122.87</td></tr><tr><td align="left">PVC<sup>â </sup>
</td><td align="left">70.4</td><td align="left">77.2</td><td align="left">67.6</td></tr></tbody></table><table-wrap-foot><p><sup>â</sup> Includes resampling of the UTE-based object and CT-based hardware <italic>Î¼</italic>-maps</p><p><sup>â</sup> Includes histogramming, bucket singles processing and motion detection.</p><p><sup>â¡</sup> OSEM with 14 subsets and 4 iterations. Scatter correction is performed within the reconstruction.</p><p><sup>â </sup> Includes PET image upsampling, trimming and PET-MR image coregistration.</p></table-wrap-foot></table-wrap>
</p>
    </sec>
    <sec id="Sec16">
      <title>Current and Future Developments</title>
      <p id="Par60">The <italic>NiftyPET</italic> package at this stage is available for Linux (e.g., Ubuntu, CentOS) and Windows systems. The package requires CUDA toolkit from NVIDIA (the latest version is available at <ext-link ext-link-type="uri" xlink:href="https://developer.nvidia.com/cuda-downloads">https://developer.nvidia.com/cuda-downloads</ext-link>) and Python 2.7 (preferably Anaconda from Continuum Analytics, <ext-link ext-link-type="uri" xlink:href="https://www.continuum.io/downloads">https://www.continuum.io/downloads</ext-link>). The GPU routines require a GPU card with the compute capability of at least 3.5 (NVIDIA <xref ref-type="bibr" rid="CR48">2017b</xref>).</p>
      <p id="Par61">The package is currently being extended to support all the PET/MR scanners (with and without TOF) deployed in the United Kingdom within the Dementias Platform UK network (DPUK), for harmonised image reconstruction and analysis in multi-centre clinical trials. <italic>NiftyPET</italic> is actively being developed to support TOF-PET, with already added support for TOF scatter estimation (Markiewicz et al. <xref ref-type="bibr" rid="CR38">2016b</xref>), which needs further validation. Also, a separate module for accurate and robust motion detection is under development to expand upon previous work on the Microsoft Kinect (Noonan et al. <xref ref-type="bibr" rid="CR45">2015</xref>) for frame-by-frame and direct list-mode reconstruction.</p>
      <p id="Par62">At this stage, <italic>NiftyPET</italic> supports only Siemens mMR PET/MR scanners, nevertheless, it can readily be adapted to other Siemens scanners as they share the same list-mode data format and similar technological solutions. For full quantification with <italic>NiftyPET</italic>, it is recommended that each scanner is calibrated against a laboratory standard, e.g., using a uniform phantom scan and relating it to a well-counter (Bailey et al. <xref ref-type="bibr" rid="CR4">1991</xref>). The support for GE scanners (including the GE Signa PET/MR scanner) is actively being developed. The support of Philips scanners can be added when all the necessary scannerâs specifications are available. While not covered in this paper, <italic>NiftyPET</italic> supports dynamic LM processing (Markiewicz et al. <xref ref-type="bibr" rid="CR41">2016a</xref>) and reconstruction, and is under further development to incorporate advanced kinetic modelling based on either independent time-frame reconstruction (a fast option) or joint estimation of kinetic parameters with head motion (slower and computationally demanding, see Jiao et al. (<xref ref-type="bibr" rid="CR28">2017</xref>)). Although developed primarily for brain imaging and analysis using PET/MR scanners, <italic>NiftyPET</italic> can be used for whole body imaging, including PET/CT scanners.</p>
      <p id="Par63">Currently, the <italic>NiftyPET</italic> package only allows for EM (or OSEM) reconstruction. However, as the software package is very modular and python interfaces are available, it can be used in conjunction with other packages (e.g., ODL; <ext-link ext-link-type="uri" xlink:href="https://github.com/odlgroup/odl">https://github.com/odlgroup/odl</ext-link>) to reconstruct from PET data with any reconstruction model, such as maximum a-posteriori reconstruction (Tsai et al. <xref ref-type="bibr" rid="CR60">2015</xref>; Comtat et al. <xref ref-type="bibr" rid="CR14">2002</xref>; Ehrhardt et al. <xref ref-type="bibr" rid="CR16">2016</xref>) or Bregman iterations (MÃ¼ller et al. <xref ref-type="bibr" rid="CR44">2011</xref>; Benning et al. <xref ref-type="bibr" rid="CR5">2013</xref>; Osher et al. <xref ref-type="bibr" rid="CR50">2005</xref>) with any kind of prior (Burger and Osher <xref ref-type="bibr" rid="CR7">2013</xref>; Ehrhardt et al. <xref ref-type="bibr" rid="CR16">2016</xref>; Liao and Qi <xref ref-type="bibr" rid="CR36">2007</xref>) or algorithm (Chambolle and Pock <xref ref-type="bibr" rid="CR13">2016</xref>; Chambolle et al. <xref ref-type="bibr" rid="CR12">2017</xref>; Tsai et al. <xref ref-type="bibr" rid="CR60">2015</xref>; Comtat et al. <xref ref-type="bibr" rid="CR14">2002</xref>).</p>
    </sec>
  </sec>
  <sec id="Sec17">
    <title>Conclusions</title>
    <p id="Par64">We have presented an open source Python package <italic>NiftyPET</italic> for image reconstruction and analysis with high quantitative accuracy and precision as well as with uncertainty estimation, while facilitating high-throughput parallel processing using GPU computing. We put a particular emphasis on the softwareâs high quantitative accuracy for brain imaging using the PET/MR scannersâin particular, the attenuation correction using accurate <italic>Î¼</italic>-maps, fully 3D scatter modelling with high resolution ray tracing, randoms estimation, and fast image convolutions for PVC. The rapid list-mode data processing enables generation of independent bootstrap realisations, which in turn allow fast uncertainty estimation of any image statistic. We have also extended the Siemens default span-11 image reconstruction to span-1 (no axial compression), which is particularly useful when reducing the large axial FOV of the PET/MR scanner to a narrower FOV and thus enabling much faster reconstructions with real dataâa unique feature which is useful for validating new reconstruction or analysis methods (e.g., kinetic analysis) through multiple noise realisations (rapidly generated by the bootstrap).</p>
  </sec>
  <sec id="Sec18">
    <title>Information Sharing Statement</title>
    <p id="Par65">All the presented software is open-source and available at <ext-link ext-link-type="uri" xlink:href="https://github.com/pjmark/NiftyPET">https://github.com/pjmark/NiftyPET</ext-link> (RRID:SCR_015873), which contains a wiki on installation and usage. The PET/ MR data used here will also be available for download, which, together with the provided Jupyter Notebook files, will enable independent recreation of the presented figures in a straightforward manner.</p>
  </sec>
</body>
<back>
  <ack>
    <title>Acknowledgements</title>
    <p>Special thanks go to Catherine Scott for her overall assistance. The Tesla K20 and Titan X Pascal used for this research were donated by the NVIDIA Corporation. The Florbetapir PET tracer was provided by AVID Radiopharmaceuticals (a wholly owned subsidiary of Eli Lilly &amp; Co). Support for this work was received from the MRC Dementias Platform UK (MR/N025792/1), the MRC (MR/J01107X/1, CSUB19166), the EPSRC (EP/H046410/1, EP/J020990/1, EP/K005278, EP/M022587/1), AMYPAD (European Commission project ID: ID115952, H2020-EU.3.1.7. - Innovative Medicines Initiative 2), the EU-FP7 project VPH-DARE@IT (FP7-ICT-2011-9-601055), the NIHR Biomedical Research Unit (Dementia) at UCL and the National Institute for Health Research University College London Hospitals Biomedical Research Centre (NIHR BRC UCLH/UCL High Impact Initiative- BW.mn.BRC10269), the NIHR Queen Square Dementia BRU, Wolfson Foundation, ARUK (ARUK- Network 2012-6-ICE; ARUK-PG2014-1946), European Commission (H2020-PHC-2014-2015-666992), the Dementia Research Centre as an ARUK coordinating centre. M. J. Ehrhardt acknowledges support by the Leverhulme Trust project âBreaking the non-convexity barrierâ, EPSRC grant âEP/M00483X/1â, EPSRC centre âEP/N014588/1â, the Cantab Capital Institute for the Mathematics of Information, and from CHiPS (Horizon 2020 RISE project grant).</p>
  </ack>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Alessio</surname>
            <given-names>AM</given-names>
          </name>
          <name>
            <surname>Kinahan</surname>
            <given-names>PE</given-names>
          </name>
          <name>
            <surname>Lewellen</surname>
            <given-names>TK</given-names>
          </name>
        </person-group>
        <article-title>Modeling and incorporation of system response functions in 3-D whole body pet</article-title>
        <source>IEEE Transactions on Medical Imaging</source>
        <year>2006</year>
        <volume>25</volume>
        <issue>7</issue>
        <fpage>828</fpage>
        <lpage>837</lpage>
        <pub-id pub-id-type="doi">10.1109/TMI.2006.873222</pub-id>
        <?supplied-pmid 16827484?>
        <pub-id pub-id-type="pmid">16827484</pub-id>
      </element-citation>
    </ref>
    <ref id="CR2">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Badawi</surname>
            <given-names>RD</given-names>
          </name>
          <name>
            <surname>Marsden</surname>
            <given-names>PK</given-names>
          </name>
        </person-group>
        <article-title>Developments in component-based normalization for 3D pet</article-title>
        <source>Physics in Medicine and Biology</source>
        <year>1999</year>
        <volume>44</volume>
        <issue>2</issue>
        <fpage>571</fpage>
        <pub-id pub-id-type="doi">10.1088/0031-9155/44/2/020</pub-id>
        <?supplied-pmid 10070802?>
        <pub-id pub-id-type="pmid">10070802</pub-id>
      </element-citation>
    </ref>
    <ref id="CR3">
      <mixed-citation publication-type="other">Bailey, D.L. (2005). Data acquisition and performance characterization in PET (pp. 41â62). London: Springer.. 10.1007/1-84628-007-9_3</mixed-citation>
    </ref>
    <ref id="CR4">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Bailey</surname>
            <given-names>DL</given-names>
          </name>
          <name>
            <surname>Jones</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Spinks</surname>
            <given-names>TJ</given-names>
          </name>
        </person-group>
        <article-title>A method for measuring the absolute sensitivity of positron emission tomographic scanners</article-title>
        <source>European Journal of Nuclear Medicine</source>
        <year>1991</year>
        <volume>18</volume>
        <issue>6</issue>
        <fpage>374</fpage>
        <lpage>379</lpage>
        <pub-id pub-id-type="doi">10.1007/BF02258426</pub-id>
        <?supplied-pmid 1879443?>
        <pub-id pub-id-type="pmid">1879443</pub-id>
      </element-citation>
    </ref>
    <ref id="CR5">
      <mixed-citation publication-type="other">Benning, M., Brune, C., Burger, M., &amp; MÃ¼ller, J. (2013). Higher-Order TV Methods - enhancement via Bregman iteration. 54.</mixed-citation>
    </ref>
    <ref id="CR6">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Burger</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Goerres</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Schoenes</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Buck</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Lonn</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>von Schulthess</surname>
            <given-names>G</given-names>
          </name>
        </person-group>
        <article-title>PET attenuation coefficients from CT images: experimental evaluation of the transformation of CT into PET 511-keV attenuation coefficients</article-title>
        <source>European Journal of Nuclear Medicine and Molecular Imaging</source>
        <year>2002</year>
        <volume>29</volume>
        <issue>7</issue>
        <fpage>922</fpage>
        <lpage>927</lpage>
        <pub-id pub-id-type="doi">10.1007/s00259-002-0796-3</pub-id>
        <?supplied-pmid 12111133?>
        <pub-id pub-id-type="pmid">12111133</pub-id>
      </element-citation>
    </ref>
    <ref id="CR7">
      <mixed-citation publication-type="other">Burger, M., &amp; Osher, S. (2013). A guide to the TV zoo. In <italic>Level set and PDE based reconstruction methods in imaging, vol. 2090 of lecture notes in mathematics</italic> (pp. 1â70). Cham: Springer International Publishing.</mixed-citation>
    </ref>
    <ref id="CR8">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Burgos</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Cardoso</surname>
            <given-names>MJ</given-names>
          </name>
          <name>
            <surname>Thielemans</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Modat</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Dickson</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Schott</surname>
            <given-names>JM</given-names>
          </name>
          <name>
            <surname>Atkinson</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Arridge</surname>
            <given-names>SR</given-names>
          </name>
          <name>
            <surname>Hutton</surname>
            <given-names>BF</given-names>
          </name>
          <name>
            <surname>Ourselin</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>Multi-contrast attenuation map synthesis for PET/MR scanners: assessment on FDG and florbetapir PET tracers</article-title>
        <source>European Journal of Nuclear Medicine and Molecular Imaging</source>
        <year>2015</year>
        <volume>42</volume>
        <issue>9</issue>
        <fpage>1447</fpage>
        <lpage>1458</lpage>
        <pub-id pub-id-type="doi">10.1007/s00259-015-3082-x</pub-id>
        <?supplied-pmid 26105119?>
        <pub-id pub-id-type="pmid">26105119</pub-id>
      </element-citation>
    </ref>
    <ref id="CR9">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Camus</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Payoux</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>BarrÃ©</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Desgranges</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Voisin</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Tauber</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>La Joie</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Tafani</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Hommet</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>ChÃ©telat</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Mondon</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>de La Sayette</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Cottier</surname>
            <given-names>JP</given-names>
          </name>
          <name>
            <surname>Beaufils</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Ribeiro</surname>
            <given-names>MJ</given-names>
          </name>
          <name>
            <surname>Gissot</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Vierron</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Vercouillie</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Vellas</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Eustache</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Guilloteau</surname>
            <given-names>D</given-names>
          </name>
        </person-group>
        <article-title>Using PET with 18F-AV-45 (florbetapir) to quantify brain amyloid load in a clinical environment</article-title>
        <source>European Journal of Nuclear Medicine and Molecular Imaging</source>
        <year>2012</year>
        <volume>39</volume>
        <issue>4</issue>
        <fpage>621</fpage>
        <lpage>631</lpage>
        <pub-id pub-id-type="doi">10.1007/s00259-011-2021-8</pub-id>
        <?supplied-pmid 22252372?>
        <pub-id pub-id-type="pmid">22252372</pub-id>
      </element-citation>
    </ref>
    <ref id="CR10">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Cardoso</surname>
            <given-names>MJ</given-names>
          </name>
          <name>
            <surname>Modat</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Wolz</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Melbourne</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Cash</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Rueckert</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Ourselin</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>Geodesic information flows: Spatially-variant graphs and their application to segmentation and fusion</article-title>
        <source>IEEE Transactions on Medical Imaging</source>
        <year>2015</year>
        <volume>34</volume>
        <issue>9</issue>
        <fpage>1976</fpage>
        <lpage>1988</lpage>
        <pub-id pub-id-type="doi">10.1109/TMI.2015.2418298</pub-id>
        <?supplied-pmid 25879909?>
        <pub-id pub-id-type="pmid">25879909</pub-id>
      </element-citation>
    </ref>
    <ref id="CR11">
      <mixed-citation publication-type="other">Casey, M.E., Gadagkar, H., &amp; Newport, D. (1996). A component based method for normalization in volume PET. In Grangeat, P., &amp; Amans, J.L. (Eds.) <italic>Three-Dimensional image reconstruction in radiology and nuclear medicine, Kluwer Academic</italic> (pp. 66â71).</mixed-citation>
    </ref>
    <ref id="CR12">
      <mixed-citation publication-type="other">Chambolle, A., Ehrhardt, M.J., RichtÃ¡rik, P., &amp; SchÃ¶nlieb, C.-B. (2017). Stochastic primal-dual hybrid gradient algorithm with arbitrary sampling and imaging applications. Technical report.</mixed-citation>
    </ref>
    <ref id="CR13">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chambolle</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Pock</surname>
            <given-names>T</given-names>
          </name>
        </person-group>
        <article-title>An introduction to continuous optimization for imaging</article-title>
        <source>Acta Numerica</source>
        <year>2016</year>
        <volume>25</volume>
        <fpage>161</fpage>
        <lpage>319</lpage>
        <pub-id pub-id-type="doi">10.1017/S096249291600009X</pub-id>
      </element-citation>
    </ref>
    <ref id="CR14">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Comtat</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Kinahan</surname>
            <given-names>PE</given-names>
          </name>
          <name>
            <surname>Fessler</surname>
            <given-names>JA</given-names>
          </name>
          <name>
            <surname>Beyer</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Townsend</surname>
            <given-names>DW</given-names>
          </name>
          <name>
            <surname>Defrise</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Michel</surname>
            <given-names>CJ</given-names>
          </name>
        </person-group>
        <article-title>Clinically feasible reconstruction of 3D whole-body PET/CT data using blurred anatomical labels</article-title>
        <source>Physics in Medicine and Biology</source>
        <year>2002</year>
        <volume>47</volume>
        <issue>1</issue>
        <fpage>1</fpage>
        <lpage>20</lpage>
        <pub-id pub-id-type="doi">10.1088/0031-9155/47/1/301</pub-id>
        <?supplied-pmid 11814220?>
        <pub-id pub-id-type="pmid">11814220</pub-id>
      </element-citation>
    </ref>
    <ref id="CR15">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Doot</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>McDonald</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Mankoff</surname>
            <given-names>D</given-names>
          </name>
        </person-group>
        <article-title>Role of PET quantitation in the monitoring of cancer response to treatment: review of approaches and human clinical trials</article-title>
        <source>Clinical and Translational Imaging</source>
        <year>2014</year>
        <volume>2</volume>
        <issue>4</issue>
        <fpage>295</fpage>
        <lpage>303</lpage>
        <pub-id pub-id-type="doi">10.1007/s40336-014-0071-1</pub-id>
        <?supplied-pmid 25229053?>
        <pub-id pub-id-type="pmid">25229053</pub-id>
      </element-citation>
    </ref>
    <ref id="CR16">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ehrhardt</surname>
            <given-names>MJ</given-names>
          </name>
          <name>
            <surname>Markiewicz</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Liljeroth</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Barnes</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Kolehmainen</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Duncan</surname>
            <given-names>JS</given-names>
          </name>
          <name>
            <surname>Pizarro</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Atkinson</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Hutton</surname>
            <given-names>BF</given-names>
          </name>
          <name>
            <surname>Ourselin</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Thielemans</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Arridge</surname>
            <given-names>SR</given-names>
          </name>
        </person-group>
        <article-title>PET reconstruction with an anatomical MRI prior using parallel level sets</article-title>
        <source>IEEE Transactions on Medical Imaging</source>
        <year>2016</year>
        <volume>35</volume>
        <issue>9</issue>
        <fpage>2189</fpage>
        <lpage>2199</lpage>
        <pub-id pub-id-type="doi">10.1109/TMI.2016.2549601</pub-id>
        <?supplied-pmid 27101601?>
        <pub-id pub-id-type="pmid">27101601</pub-id>
      </element-citation>
    </ref>
    <ref id="CR17">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Erlandsson</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Buvat</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Pretorius</surname>
            <given-names>PH</given-names>
          </name>
          <name>
            <surname>Thomas</surname>
            <given-names>BA</given-names>
          </name>
          <name>
            <surname>Hutton</surname>
            <given-names>BF</given-names>
          </name>
        </person-group>
        <article-title>A review of partial volume correction techniques for emission tomography and their applications in neurology, cardiology and oncology</article-title>
        <source>Physics in Medicine and Biology</source>
        <year>2012</year>
        <volume>57</volume>
        <issue>21</issue>
        <fpage>R119</fpage>
        <pub-id pub-id-type="doi">10.1088/0031-9155/57/21/R119</pub-id>
        <?supplied-pmid 23073343?>
        <pub-id pub-id-type="pmid">23073343</pub-id>
      </element-citation>
    </ref>
    <ref id="CR18">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Evans</surname>
            <given-names>RD</given-names>
          </name>
        </person-group>
        <source>The atomic nucleus</source>
        <year>1955</year>
        <publisher-loc>New York</publisher-loc>
        <publisher-name>McGraw-Hill, Inc</publisher-name>
      </element-citation>
    </ref>
    <ref id="CR19">
      <mixed-citation publication-type="other">Fessler, J.A. (2013). Users guide for ASPIRE 3D image reconstruction software. <ext-link ext-link-type="uri" xlink:href="http://web.eecs.umich.edu/fessler/papers/files/tr/97,310,ugf.pdf">http://web.eecs.umich.edu/fessler/papers/files/tr/97,310,ugf.pdf</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR20">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ha</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Matej</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Ispiryan</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Mueller</surname>
            <given-names>K</given-names>
          </name>
        </person-group>
        <article-title>GPU-accelerated forward and back-projections with spatially varying kernels for 3D direct TOF PET reconstruction</article-title>
        <source>IEEE Transactions on Nuclear Science</source>
        <year>2013</year>
        <volume>60</volume>
        <issue>1</issue>
        <fpage>166</fpage>
        <lpage>173</lpage>
        <pub-id pub-id-type="doi">10.1109/TNS.2012.2233754</pub-id>
        <?supplied-pmid 23531763?>
        <pub-id pub-id-type="pmid">23531763</pub-id>
      </element-citation>
    </ref>
    <ref id="CR21">
      <mixed-citation publication-type="other">Harris, M. (2012a). How to optimize data transfers in CUDA C/C+ +. <ext-link ext-link-type="uri" xlink:href="http://devblogs.nvidia.com/parallelforall/how-optimize-data-transfers-cuda-cc/">http://devblogs.nvidia.com/parallelforall/how-optimize-data-transfers-cuda-cc/</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR22">
      <mixed-citation publication-type="other">Harris, M. (2012b). How to overlap data transfers in CUDA C/C+ +. <ext-link ext-link-type="uri" xlink:href="http://devblogs.nvidia.com/parallelforall/how-overlap-data-transfers-cuda-cc/">http://devblogs.nvidia.com/parallelforall/how-overlap-data-transfers-cuda-cc/</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR23">
      <mixed-citation publication-type="other">Hogg, D., Thielemans, K., Mustafovic, S., &amp; Spinks, T. (2002). A study of bias for various iterative reconstruction methods in PET. In <italic>Nuclear science symposium conference record, 2002 IEEE</italic>, (Vol. 3 pp. 1519â1523).</mixed-citation>
    </ref>
    <ref id="CR24">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hong</surname>
            <given-names>IK</given-names>
          </name>
          <name>
            <surname>Chung</surname>
            <given-names>ST</given-names>
          </name>
          <name>
            <surname>Kim</surname>
            <given-names>HK</given-names>
          </name>
          <name>
            <surname>Kim</surname>
            <given-names>YB</given-names>
          </name>
          <name>
            <surname>Son</surname>
            <given-names>YD</given-names>
          </name>
          <name>
            <surname>Cho</surname>
            <given-names>ZH</given-names>
          </name>
        </person-group>
        <article-title>Ultra fast symmetry and simd-based projection-backprojection (SSP) algorithm for 3-D PET image reconstruction</article-title>
        <source>IEEE Transactions on Medical Imaging</source>
        <year>2007</year>
        <volume>26</volume>
        <issue>6</issue>
        <fpage>789</fpage>
        <lpage>803</lpage>
        <pub-id pub-id-type="doi">10.1109/TMI.2007.892644</pub-id>
        <?supplied-pmid 17679330?>
        <pub-id pub-id-type="pmid">17679330</pub-id>
      </element-citation>
    </ref>
    <ref id="CR25">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hudson</surname>
            <given-names>HM</given-names>
          </name>
          <name>
            <surname>Larkin</surname>
            <given-names>RS</given-names>
          </name>
        </person-group>
        <article-title>Accelerated image reconstruction using ordered subsets of projection data</article-title>
        <source>IEEE Transactions on Medical Imaging</source>
        <year>1994</year>
        <volume>13</volume>
        <issue>4</issue>
        <fpage>601</fpage>
        <lpage>609</lpage>
        <pub-id pub-id-type="doi">10.1109/42.363108</pub-id>
        <?supplied-pmid 18218538?>
        <pub-id pub-id-type="pmid">18218538</pub-id>
      </element-citation>
    </ref>
    <ref id="CR26">
      <mixed-citation publication-type="other">Iatrou, M., Manjeshwar, R.M., Ross, S.G., Thielemans, K., &amp; Stearns, C.W. (2006). 3D implementation of scatter estimation in 3D PET. In <italic>2006 IEEE nuclear science symposium conference record</italic>, (Vol. 4 pp. 2142â2145).</mixed-citation>
    </ref>
    <ref id="CR27">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Jacobs</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Sundermann</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Sutter</surname>
            <given-names>BD</given-names>
          </name>
          <name>
            <surname>Christiaens</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Lemahieu</surname>
            <given-names>I</given-names>
          </name>
        </person-group>
        <article-title>A fast algorithm to calculate the exact radiological path through a pixel or voxel space</article-title>
        <source>Journal of Computing and Information Technology</source>
        <year>1998</year>
        <volume>6</volume>
        <fpage>89</fpage>
        <lpage>94</lpage>
      </element-citation>
    </ref>
    <ref id="CR28">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Jiao</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Bousse</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Thielemans</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Burgos</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Weston</surname>
            <given-names>PSJ</given-names>
          </name>
          <name>
            <surname>Schott</surname>
            <given-names>JM</given-names>
          </name>
          <name>
            <surname>Atkinson</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Arridge</surname>
            <given-names>SR</given-names>
          </name>
          <name>
            <surname>Hutton</surname>
            <given-names>BF</given-names>
          </name>
          <name>
            <surname>Markiewicz</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Ourselin</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>Direct parametric reconstruction with joint motion estimation/correction for dynamic brain PET data</article-title>
        <source>IEEE Transactions on Medical Imaging</source>
        <year>2017</year>
        <volume>36</volume>
        <issue>1</issue>
        <fpage>203</fpage>
        <lpage>213</lpage>
        <pub-id pub-id-type="doi">10.1109/TMI.2016.2594150</pub-id>
        <?supplied-pmid 27576243?>
        <pub-id pub-id-type="pmid">27576243</pub-id>
      </element-citation>
    </ref>
    <ref id="CR29">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kim</surname>
            <given-names>KS</given-names>
          </name>
          <name>
            <surname>Ye</surname>
            <given-names>JC</given-names>
          </name>
        </person-group>
        <article-title>Fully 3D iterative scatter-corrected OSEM for HRRT PET using a GPU</article-title>
        <source>Physics in Medicine and Biology</source>
        <year>2011</year>
        <volume>56</volume>
        <issue>15</issue>
        <fpage>4991</fpage>
        <pub-id pub-id-type="doi">10.1088/0031-9155/56/15/021</pub-id>
        <?supplied-pmid 21772080?>
        <pub-id pub-id-type="pmid">21772080</pub-id>
      </element-citation>
    </ref>
    <ref id="CR30">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kinahan</surname>
            <given-names>PE</given-names>
          </name>
          <name>
            <surname>Fletcher</surname>
            <given-names>JW</given-names>
          </name>
        </person-group>
        <article-title>Positron emission tomography-computed tomography standardized uptake values in clinical practice and assessing response to therapy</article-title>
        <source>Seminars in Ultrasound, CT and MRI</source>
        <year>2010</year>
        <volume>31</volume>
        <issue>6</issue>
        <fpage>496</fpage>
        <lpage>505</lpage>
        <pub-id pub-id-type="doi">10.1053/j.sult.2010.10.001</pub-id>
        <?supplied-pmid 21147377?>
        <pub-id pub-id-type="pmid">21147377</pub-id>
      </element-citation>
    </ref>
    <ref id="CR31">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kinahan</surname>
            <given-names>PE</given-names>
          </name>
          <name>
            <surname>Mankoff</surname>
            <given-names>DA</given-names>
          </name>
          <name>
            <surname>Linden</surname>
            <given-names>HM</given-names>
          </name>
        </person-group>
        <article-title>The value of establishing the quantitative accuracy of PET/CT imaging</article-title>
        <source>Journal of Nuclear Medicine</source>
        <year>2015</year>
        <volume>56</volume>
        <issue>8</issue>
        <fpage>1133</fpage>
        <lpage>1134</lpage>
        <pub-id pub-id-type="doi">10.2967/jnumed.115.159178</pub-id>
        <?supplied-pmid 26089552?>
        <pub-id pub-id-type="pmid">26089552</pub-id>
      </element-citation>
    </ref>
    <ref id="CR32">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Landau</surname>
            <given-names>SM</given-names>
          </name>
          <name>
            <surname>Fero</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Baker</surname>
            <given-names>SL</given-names>
          </name>
          <name>
            <surname>Koeppe</surname>
            <given-names>RA</given-names>
          </name>
          <name>
            <surname>Mintun</surname>
            <given-names>MA</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Reiman</surname>
            <given-names>EM</given-names>
          </name>
          <name>
            <surname>Jagust</surname>
            <given-names>WJ</given-names>
          </name>
        </person-group>
        <article-title>Measurement of Longitudinal Î²-Amyloid Change with 18F-Florbetapir PET and Standardized Uptake Value Ratios</article-title>
        <source>Journal of Nuclear Medicine</source>
        <year>2015</year>
        <volume>56</volume>
        <issue>4</issue>
        <fpage>567</fpage>
        <lpage>574</lpage>
        <pub-id pub-id-type="doi">10.2967/jnumed.114.148981</pub-id>
        <?supplied-pmid 25745095?>
        <pub-id pub-id-type="pmid">25745095</pub-id>
      </element-citation>
    </ref>
    <ref id="CR33">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lane</surname>
            <given-names>CA</given-names>
          </name>
          <name>
            <surname>Parker</surname>
            <given-names>TD</given-names>
          </name>
          <name>
            <surname>Cash</surname>
            <given-names>DM</given-names>
          </name>
          <name>
            <surname>Macpherson</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Donnachie</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Murray-Smith</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Barnes</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Barker</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Beasley</surname>
            <given-names>DG</given-names>
          </name>
          <name>
            <surname>Bras</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Brown</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Burgos</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Byford</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Jorge Cardoso</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Carvalho</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Collins</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>De Vita</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Dickson</surname>
            <given-names>JC</given-names>
          </name>
          <name>
            <surname>Epie</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Espak</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Henley</surname>
            <given-names>SMD</given-names>
          </name>
          <name>
            <surname>Hoskote</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Hutel</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Klimova</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Malone</surname>
            <given-names>IB</given-names>
          </name>
          <name>
            <surname>Markiewicz</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Melbourne</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Modat</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Schrag</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Shah</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Sharma</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Sudre</surname>
            <given-names>CH</given-names>
          </name>
          <name>
            <surname>Thomas</surname>
            <given-names>DL</given-names>
          </name>
          <name>
            <surname>Wong</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Hardy</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Zetterberg</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Ourselin</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Crutch</surname>
            <given-names>SJ</given-names>
          </name>
          <name>
            <surname>Kuh</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Richards</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Fox</surname>
            <given-names>NC</given-names>
          </name>
          <name>
            <surname>Schott</surname>
            <given-names>JM</given-names>
          </name>
        </person-group>
        <article-title>Study protocol: Insight 46 â a neuroscience sub-study of the MRC national survey of health and development</article-title>
        <source>BMC Neurology</source>
        <year>2017</year>
        <volume>17</volume>
        <issue>1</issue>
        <fpage>75</fpage>
        <pub-id pub-id-type="doi">10.1186/s12883-017-0846-x</pub-id>
        <?supplied-pmid 28420323?>
        <pub-id pub-id-type="pmid">28420323</pub-id>
      </element-citation>
    </ref>
    <ref id="CR34">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Leahy</surname>
            <given-names>RM</given-names>
          </name>
          <name>
            <surname>Qi</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Statistical approaches in quantitative positron emission tomography</article-title>
        <source>Statistics and Computing</source>
        <year>2000</year>
        <volume>10</volume>
        <issue>2</issue>
        <fpage>147</fpage>
        <lpage>165</lpage>
        <pub-id pub-id-type="doi">10.1023/A:1008946426658</pub-id>
      </element-citation>
    </ref>
    <ref id="CR35">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Lewellen</surname>
            <given-names>TK</given-names>
          </name>
          <name>
            <surname>Harrison</surname>
            <given-names>RL</given-names>
          </name>
          <name>
            <surname>Vannoy</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <source>Monte carlo calculations in nuclear medicine</source>
        <year>1998</year>
        <publisher-loc>Philadelphia</publisher-loc>
        <publisher-name>Institute of Physics Publishing, chapter The SimSET program, in Monte Carlo calculations</publisher-name>
      </element-citation>
    </ref>
    <ref id="CR36">
      <mixed-citation publication-type="other">Liao, J., &amp; Qi, J. (2007). PET image reconstruction with anatomical prior using multiphase level set method. In <italic>IEEE nuclear science symposium and medical imaging conference</italic> (pp. 4163â4168).</mixed-citation>
    </ref>
    <ref id="CR37">
      <mixed-citation publication-type="other">Luitjens, J. (2014). Faster Parallel Reductions on Kepler. <ext-link ext-link-type="uri" xlink:href="https://devblogs.nvidia.com/parallelforall/faster-parallel-reductions-kepler/">https://devblogs.nvidia.com/parallelforall/faster-parallel-reductions-kepler/</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR38">
      <mixed-citation publication-type="other">Markiewicz, P.J., Ehrhardt, M.J., Atkinson, D., Arridge, S.R., Hutton, B.F., &amp; Ourselin, S. (2016b). Uniform acquisition modelling across PET imaging systems: unified scatter modelling. In <italic>2016 IEEE nuclear science symposium conference record</italic>.</mixed-citation>
    </ref>
    <ref id="CR39">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Markiewicz</surname>
            <given-names>PJ</given-names>
          </name>
          <name>
            <surname>Tamal</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Julyan</surname>
            <given-names>PJ</given-names>
          </name>
          <name>
            <surname>Hastings</surname>
            <given-names>DL</given-names>
          </name>
          <name>
            <surname>Reader</surname>
            <given-names>AJ</given-names>
          </name>
        </person-group>
        <article-title>High accuracy multiple scatter modelling for 3D whole body PET</article-title>
        <source>Physics in Medicine and Biology</source>
        <year>2007</year>
        <volume>52</volume>
        <issue>3</issue>
        <fpage>829</fpage>
        <pub-id pub-id-type="doi">10.1088/0031-9155/52/3/021</pub-id>
        <?supplied-pmid 17228124?>
        <pub-id pub-id-type="pmid">17228124</pub-id>
      </element-citation>
    </ref>
    <ref id="CR40">
      <mixed-citation publication-type="other">Markiewicz, P.J., Thielemans, K., Ehrhardt, M.J., Jiao, J., Burgos, N., Atkinson, D., Arridge, S.R., Hutton, B.F., &amp; Ourselin, S. (2014). High throughput CUDA implementation of accurate geometric modelling for iterative reconstruction of PET data. In <italic>2014 IEEE nuclear science symposium and medical imaging conference (NSS/MIC)</italic> (pp. 1â4).</mixed-citation>
    </ref>
    <ref id="CR41">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Markiewicz</surname>
            <given-names>PJ</given-names>
          </name>
          <name>
            <surname>Thielemans</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Schott</surname>
            <given-names>JM</given-names>
          </name>
          <name>
            <surname>Atkinson</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Arridge</surname>
            <given-names>SR</given-names>
          </name>
          <name>
            <surname>Hutton</surname>
            <given-names>BF</given-names>
          </name>
          <name>
            <surname>Ourselin</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>Rapid processing of PET list-mode data for efficient uncertainty estimation and data analysis</article-title>
        <source>Physics in Medicine &amp; Biology</source>
        <year>2016</year>
        <volume>61</volume>
        <issue>13</issue>
        <fpage>N322</fpage>
        <pub-id pub-id-type="doi">10.1088/0031-9155/61/13/N322</pub-id>
        <pub-id pub-id-type="pmid">27280456</pub-id>
      </element-citation>
    </ref>
    <ref id="CR42">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Meikle</surname>
            <given-names>SR</given-names>
          </name>
          <name>
            <surname>Badawi</surname>
            <given-names>RD</given-names>
          </name>
        </person-group>
        <source>Quantitative Techniques in PET</source>
        <year>2005</year>
        <publisher-loc>London</publisher-loc>
        <publisher-name>Springer</publisher-name>
        <fpage>93</fpage>
        <lpage>126</lpage>
      </element-citation>
    </ref>
    <ref id="CR43">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Modat</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Cash</surname>
            <given-names>DM</given-names>
          </name>
          <name>
            <surname>Daga</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Winston</surname>
            <given-names>GP</given-names>
          </name>
          <name>
            <surname>Duncan</surname>
            <given-names>JS</given-names>
          </name>
          <name>
            <surname>Ourselin</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>Global image registration using a symmetric block-matching approach</article-title>
        <source>Journal of Medical Imaging</source>
        <year>2014</year>
        <volume>1</volume>
        <issue>2</issue>
        <fpage>024003</fpage>
        <pub-id pub-id-type="doi">10.1117/1.JMI.1.2.024003</pub-id>
        <?supplied-pmid 26158035?>
        <pub-id pub-id-type="pmid">26158035</pub-id>
      </element-citation>
    </ref>
    <ref id="CR44">
      <mixed-citation publication-type="other">MÃ¼ller, J., Brune, C., Sawatzky, A., Koesters, T., SchÃ¤fers, K.P., &amp; Burger, M. (2011). Reconstruction of short time PET scans using bregman iterations. In <italic>IEEE nuclear science symposium and medical imaging conference, Valencia</italic> (pp. 2383â2385).</mixed-citation>
    </ref>
    <ref id="CR45">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Noonan</surname>
            <given-names>PJ</given-names>
          </name>
          <name>
            <surname>Howard</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Hallett</surname>
            <given-names>WA</given-names>
          </name>
          <name>
            <surname>Gunn</surname>
            <given-names>RN</given-names>
          </name>
        </person-group>
        <article-title>Repurposing the Microsoft Kinect for Windows v2 for external head motion tracking for brain PET</article-title>
        <source>Physics in Medicine &amp; Biology</source>
        <year>2015</year>
        <volume>60</volume>
        <issue>22</issue>
        <fpage>8753</fpage>
        <pub-id pub-id-type="doi">10.1088/0031-9155/60/22/8753</pub-id>
        <pub-id pub-id-type="pmid">26528727</pub-id>
      </element-citation>
    </ref>
    <ref id="CR46">
      <mixed-citation publication-type="other">NVIDIA. (2012). NVIDAâs Next Generation CUDA Compute Architecture: Kepler GK110. White Paper.</mixed-citation>
    </ref>
    <ref id="CR47">
      <mixed-citation publication-type="other">NVIDIA. (2017a). CUDA C Programming Guide. <ext-link ext-link-type="uri" xlink:href="http://docs.nvidia.com/cuda/cuda-c-programming-guide/">http://docs.nvidia.com/cuda/cuda-c-programming-guide/</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR48">
      <mixed-citation publication-type="other">NVIDIA. (2017b). CUDA C Programming Guide. <ext-link ext-link-type="uri" xlink:href="http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#compute-capability">http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#compute-capability</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR49">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ollinger</surname>
            <given-names>JM</given-names>
          </name>
        </person-group>
        <source>Model-based scatter correction for fully 3D PET</source>
        <year>1996</year>
        <volume>41</volume>
        <fpage>153</fpage>
        <lpage>76</lpage>
      </element-citation>
    </ref>
    <ref id="CR50">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Osher</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Burger</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Goldfarb</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Xu</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Yin</surname>
            <given-names>W</given-names>
          </name>
        </person-group>
        <article-title>An iterative regularization method for total variation-based image restoration</article-title>
        <source>Multiscale Modelling and Simulation</source>
        <year>2005</year>
        <volume>4</volume>
        <issue>2</issue>
        <fpage>460</fpage>
        <lpage>489</lpage>
        <pub-id pub-id-type="doi">10.1137/040605412</pub-id>
      </element-citation>
    </ref>
    <ref id="CR51">
      <mixed-citation publication-type="other">Panin, V., Chen, M., &amp; Michel, C. (2007). Simultaneous update iterative algorithm for variance reduction on random coincidences in PET. In <italic>Nuclear science symposium conference record, 2007. NSS â07, IEEE</italic>, (Vol. 4 pp. 2807â2811).</mixed-citation>
    </ref>
    <ref id="CR52">
      <mixed-citation publication-type="other">Pedemonte, S., Bousse, A., Erlandsson, K., Modat, M., Arridge, S., Hutton, B.F., &amp; Ourselin, S. (2010). GPU accelerated rotation-based emission tomography reconstruction. In <italic>IEEE nuclear science symposuim medical imaging conference</italic> (pp. 2657â2661).</mixed-citation>
    </ref>
    <ref id="CR53">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Peyrat</surname>
            <given-names>J-M</given-names>
          </name>
          <name>
            <surname>Joshi</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Mintun</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Declerck</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>An automatic method for the quantification of uptake with florbetapir imaging</article-title>
        <source>Journal of Nuclear Medicine</source>
        <year>2012</year>
        <volume>53</volume>
        <issue>supplement 1</issue>
        <fpage>210</fpage>
      </element-citation>
    </ref>
    <ref id="CR54">
      <mixed-citation publication-type="other">Podlozhnyuk, V. (2007). Image convolution with CUDA, NVIDIA White Paper pp. 0â21. <ext-link ext-link-type="uri" xlink:href="http://docs.nvidia.com/cuda/cuda-samples/index.html#cuda-separable-convolution">http://docs.nvidia.com/cuda/cuda-samples/index.html#cuda-separable-convolution</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR55">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Siddon</surname>
            <given-names>RL</given-names>
          </name>
        </person-group>
        <article-title>Fast calculation of the exact radiological path for a three-dimensional CT array</article-title>
        <source>Medical Physics</source>
        <year>1985</year>
        <volume>12</volume>
        <issue>2</issue>
        <fpage>252</fpage>
        <lpage>255</lpage>
        <pub-id pub-id-type="doi">10.1118/1.595715</pub-id>
        <?supplied-pmid 4000088?>
        <pub-id pub-id-type="pmid">4000088</pub-id>
      </element-citation>
    </ref>
    <ref id="CR56">
      <mixed-citation publication-type="other">Siemens, (n.d.) First Comprehensive Amyloid Imaging Solution. <ext-link ext-link-type="uri" xlink:href="https://www.healthcare.siemens.de/molecular-imaging/first-comprehensive-amyloid-imaging-solution/quantitative-accuracy">https://www.healthcare.siemens.de/molecular-imaging/first-comprehensive-amyloid-imaging-solution/quantitative-accuracy</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR57">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Tamal</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Reader</surname>
            <given-names>AJ</given-names>
          </name>
          <name>
            <surname>Markiewicz</surname>
            <given-names>PJ</given-names>
          </name>
          <name>
            <surname>Julyan</surname>
            <given-names>PJ</given-names>
          </name>
          <name>
            <surname>Hastings</surname>
            <given-names>DL</given-names>
          </name>
        </person-group>
        <article-title>Noise properties of four strategies for incorporation of scatter and attenuation information in PET reconstruction using the EM-ML algorithm</article-title>
        <source>IEEE Transactions on Nuclear Science</source>
        <year>2006</year>
        <volume>53</volume>
        <issue>5</issue>
        <fpage>2778</fpage>
        <lpage>2786</lpage>
        <pub-id pub-id-type="doi">10.1109/TNS.2006.880973</pub-id>
      </element-citation>
    </ref>
    <ref id="CR58">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Thielemans</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Tsoumpas</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Mustafovic</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Beisel</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Aguiar</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Dikaios</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Jacobson</surname>
            <given-names>MW</given-names>
          </name>
        </person-group>
        <article-title>STIR: software for tomographic image reconstruction release 2</article-title>
        <source>Physics in Medicine and Biology</source>
        <year>2012</year>
        <volume>57</volume>
        <issue>4</issue>
        <fpage>867</fpage>
        <pub-id pub-id-type="doi">10.1088/0031-9155/57/4/867</pub-id>
        <?supplied-pmid 22290410?>
        <pub-id pub-id-type="pmid">22290410</pub-id>
      </element-citation>
    </ref>
    <ref id="CR59">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Thomas</surname>
            <given-names>BA</given-names>
          </name>
          <name>
            <surname>Erlandsson</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Modat</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Thurfjell</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Vandenberghe</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Ourselin</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Hutton</surname>
            <given-names>BF</given-names>
          </name>
        </person-group>
        <article-title>The importance of appropriate partial volume correction for PET quantification in Alzheimerâs disease</article-title>
        <source>European Journal of Nuclear Medicine and Molecular Imaging</source>
        <year>2011</year>
        <volume>38</volume>
        <issue>6</issue>
        <fpage>1104</fpage>
        <lpage>1119</lpage>
        <pub-id pub-id-type="doi">10.1007/s00259-011-1745-9</pub-id>
        <?supplied-pmid 21336694?>
        <pub-id pub-id-type="pmid">21336694</pub-id>
      </element-citation>
    </ref>
    <ref id="CR60">
      <mixed-citation publication-type="other">Tsai, Y.-J., Bousse, A., Ehrhardt, M.J., Hutton, B.F., Arridge, S.R., &amp; Thielemans, K. (2015). Performance evaluation of MAP algorithms with different penalties, object geometries and noise levels. In <italic>IEEE nuclear science symposium and medical imaging conference</italic> (pp. 1â3).</mixed-citation>
    </ref>
    <ref id="CR61">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Watson</surname>
            <given-names>CC</given-names>
          </name>
        </person-group>
        <source>New, faster, image-based scatter correction for 3D PET</source>
        <year>2000</year>
        <volume>47</volume>
        <fpage>1587</fpage>
        <lpage>94</lpage>
      </element-citation>
    </ref>
    <ref id="CR62">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Yang</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Huang</surname>
            <given-names>SC</given-names>
          </name>
          <name>
            <surname>Mega</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Lin</surname>
            <given-names>KP</given-names>
          </name>
          <name>
            <surname>Toga</surname>
            <given-names>AW</given-names>
          </name>
          <name>
            <surname>Small</surname>
            <given-names>GW</given-names>
          </name>
          <name>
            <surname>Phelps</surname>
            <given-names>ME</given-names>
          </name>
        </person-group>
        <article-title>Investigation of partial volume correction methods for brain FDG PET studies</article-title>
        <source>IEEE Transactions on Nuclear Science</source>
        <year>1996</year>
        <volume>43</volume>
        <issue>6</issue>
        <fpage>3322</fpage>
        <lpage>3327</lpage>
        <pub-id pub-id-type="doi">10.1109/23.552745</pub-id>
      </element-citation>
    </ref>
  </ref-list>
</back>
