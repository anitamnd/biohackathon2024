<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1 20151215//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.1?>
<?ConverterInfo.XSLTName jp2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Database (Oxford)</journal-id>
    <journal-id journal-id-type="iso-abbrev">Database (Oxford)</journal-id>
    <journal-id journal-id-type="publisher-id">databa</journal-id>
    <journal-title-group>
      <journal-title>Database: The Journal of Biological Databases and Curation</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1758-0463</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">7243926</article-id>
    <article-id pub-id-type="pmid">31725862</article-id>
    <article-id pub-id-type="doi">10.1093/database/bax091</article-id>
    <article-id pub-id-type="publisher-id">bax091</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Original Article</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Leveraging word embeddings and medical entity extraction for biomedical dataset retrieval using unstructured texts</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Wang</surname>
          <given-names>Yanshan</given-names>
        </name>
        <xref ref-type="aff" rid="bax091-aff1"/>
        <xref ref-type="corresp" rid="bax091-cor1"/>
        <!--<email>wang.yanshan@mayo.edu</email>-->
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Rastegar-Mojarad</surname>
          <given-names>Majid</given-names>
        </name>
        <xref ref-type="aff" rid="bax091-aff1"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Komandur-Elayavilli</surname>
          <given-names>Ravikumar</given-names>
        </name>
        <xref ref-type="aff" rid="bax091-aff1"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Liu</surname>
          <given-names>Hongfang</given-names>
        </name>
        <xref ref-type="aff" rid="bax091-aff1"/>
        <xref ref-type="corresp" rid="bax091-cor2"/>
        <!--<email>wang.yanshan@mayo.edu</email>-->
      </contrib>
    </contrib-group>
    <aff id="bax091-aff1">Department of Health Sciences Research, Mayo Clinic, Rochester, MN 55901, USA</aff>
    <author-notes>
      <corresp id="bax091-cor1">Corresponding author: Tel: +1 507-293-1382; Fax: +1 507-284-1516; Email: <email>wang.yanshan@mayo.edu</email></corresp>
      <corresp id="bax091-cor2">Correspondence may also be addressed to Hongfang Liu. Tel: +1 507-293-0057; Fax: +1 507-284-1516; Email: <email>liu.hongfang@mayo.edu</email></corresp>
      <fn id="bax091-FM1">
        <p>Citation details: Wang,Y., Rastegar-Mojarad,M., Komandur-Elayavilli,R. <italic>et al.</italic> Leveraging word embeddings and medical entity extraction for biomedical dataset retrieval using unstructured texts. <italic>Database</italic> (2017) Vol. 2017: article ID bax091; doi:10.1093/database/bax091</p>
      </fn>
    </author-notes>
    <pub-date pub-type="collection">
      <year>2017</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2017-12-20">
      <day>20</day>
      <month>12</month>
      <year>2017</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>20</day>
      <month>12</month>
      <year>2017</year>
    </pub-date>
    <!-- PMC Release delay is 0 months and 0 days and was based on the <pub-date pub-type="epub"/>. -->
    <volume>2017</volume>
    <elocation-id>bax091</elocation-id>
    <history>
      <date date-type="received">
        <day>17</day>
        <month>3</month>
        <year>2017</year>
      </date>
      <date date-type="rev-recd">
        <day>17</day>
        <month>10</month>
        <year>2017</year>
      </date>
      <date date-type="accepted">
        <day>14</day>
        <month>11</month>
        <year>2017</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2017. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2017</copyright-year>
      <license license-type="cc-by" xlink:href="http://creativecommons.org/licenses/by/4.0/">
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="bax091.pdf"/>
    <abstract>
      <title>Abstract</title>
      <p>The recent movement towards open data in the biomedical domain has generated a large number of datasets that are publicly accessible. The Big Data to Knowledge data indexing project, biomedical and healthCAre Data Discovery Index Ecosystem (bioCADDIE), has gathered these datasets in a one-stop portal aiming at facilitating their reuse for accelerating scientific advances. However, as the number of biomedical datasets stored and indexed increases, it becomes more and more challenging to retrieve the relevant datasets according to researchers’ queries. In this article, we propose an information retrieval (IR) system to tackle this problem and implement it for the bioCADDIE Dataset Retrieval Challenge. The system leverages the unstructured texts of each dataset including the title and description for the dataset, and utilizes a state-of-the-art IR model, medical named entity extraction techniques, query expansion with deep learning-based word embeddings and a re-ranking strategy to enhance the retrieval performance. In empirical experiments, we compared the proposed system with 11 baseline systems using the bioCADDIE Dataset Retrieval Challenge datasets. The experimental results show that the proposed system outperforms other systems in terms of inference Average Precision and inference normalized Discounted Cumulative Gain, implying that the proposed system is a viable option for biomedical dataset retrieval.</p>
      <p><bold>Database URL</bold>: <ext-link ext-link-type="uri" xlink:href="https://github.com/yanshanwang/biocaddie2016mayodata">https://github.com/yanshanwang/biocaddie2016mayodata</ext-link></p>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <named-content content-type="funder-name">National Institutes of Health</named-content>
          <named-content content-type="funder-identifier">10.13039/100000002</named-content>
        </funding-source>
        <award-id>R01LM011934</award-id>
        <award-id>R01GM102282</award-id>
        <award-id>U24AI117966</award-id>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="13"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec sec-type="intro">
    <title>Introduction</title>
    <p>The recent movement towards open data in the biomedical domain has generated a large number of datasets that are publicly accessible (<xref rid="bax091-B1" ref-type="bibr">1–3</xref>). It not only makes research transparent and reproducible, but also allows for more collaborative and rapid progress and enables the development of new questions by revealing previously hidden patterns and connections across datasets (<xref rid="bax091-B4" ref-type="bibr">4</xref>). Due to the lack of standards, however, integration and interconnection of datasets available in different repositories are major obstacles for biomedical research (<xref rid="bax091-B5" ref-type="bibr">5</xref>, <xref rid="bax091-B6" ref-type="bibr">6</xref>).</p>
    <p>There have been considerable efforts that attempt to address the integration issue. For example, a number of scientific journals have created policies about sharing data. Many projects have been funded to tackle the biomedical data integration problem, such as the OpenAIRE project (<ext-link ext-link-type="uri" xlink:href="http://www.openaire.eu/">http://www.openaire.eu/</ext-link>) in Europe and the Open Research Data project (<ext-link ext-link-type="uri" xlink:href="http://www.rcuk.ac.uk/research/opendata/">http://www.rcuk.ac.uk/research/opendata/</ext-link>) in UK. In the US, the National Institutes of Health has funded the biomedical and healthCAre Data Discovery Index Ecosystem (<ext-link ext-link-type="uri" xlink:href="http://biocaddie.ucsd.edu/">http://biocaddie.ucsd.edu/</ext-link>) (bioCADDIE) prototype through the Big Data to Knowledge program. The bioCADDIE is a data discovery index prototype providing a searchable index of biomedical study data, analogous to what PubMed and PubMed Central have achieved for medical literature (<xref rid="bax091-B4" ref-type="bibr">4</xref>, <xref rid="bax091-B7" ref-type="bibr">7</xref>). However, as bioCADDIE has ingested and indexed &gt;840 000 datasets from 23 different repositories across 10 different data types (<xref rid="bax091-B8" ref-type="bibr">8</xref>), it becomes more and more challenging to retrieve the datasets that meet the needs of the biomedical researchers.</p>
    <p>With this in mind, the bioCADDIE Dataset Retrieval Challenge (<xref rid="bax091-B9" ref-type="bibr">9</xref>) was initiated with a goal of addressing the dearth of tools to retrieve relevant datasets from a large collection of biomedical datasets, in order to facilitate the re-utilization of collected data, and to enable the replication of published results. Specifically, the task is an information retrieval (IR) task that is defined as follows: Given a biomedical researcher’s query, participants were challenged to retrieve 1000 biomedical datasets relevant for answering a specific instantiated query. Retrieved datasets will be manually judged by human annotators and categoried into three levels of relevance, i.e. relevant, partially relevant or not relevant, according to whether or not they meet all the constraints specified in the query. Multiple metadata, including structured, unstructured and semi-structured metadata, were given in the dataset collection, such as ‘title,’ ‘description,’ ‘platform,’ ‘repository’ and ‘species.’</p>
    <p>In this article, we describe an IR system for the bioCADDIE Dataset Retrieval Challenge and focus on using the unstructured textual data, specifically, ‘title’ and ‘description.’ The system utilizes a state-of-the-art IR model, medical named entity extraction techniques, query expansion with deep learning-based word embeddings and a re-ranking strategy to enhance the retrieval performance. In empirical experiments, we compared the proposed system with 11 baseline systems using the bioCADDIE Dataset Retrieval Challenge datasets.</p>
    <p>The article is organized as follows. First, we briefly review related work. Second, we described the proposed methods, including the IR model, medical entity extraction, query expansion with word embeddings and the re-ranking mechanism. Third, we present the experiments including the data given in the challenge, preprocessing, indexing and experimental results. Finally, we conclude the article with discussions, limitations and future directions.</p>
  </sec>
  <sec>
    <title>Related work</title>
    <p>In this big data era, we always find it challenging to find the most relevant documents to a query from a large collection of documents. IR has been studied to address this issue for decades. IR techniques have been adopted in every search engine for searching the World Wide Web. A typical scenario is that a user inputs a query into a search engine and the search engine retrieves answers in the form of a list of documents in ranked order (<xref rid="bax091-B10" ref-type="bibr">10</xref>). According to the classic definition of IR in (<xref rid="bax091-B11" ref-type="bibr">11</xref>), ‘IR is a field concerned with the structure, analysis, organization, storage, searching and retrieval of information.’ <xref ref-type="fig" rid="bax091-F1">Figure 1</xref> shows a high-level IR architecture, which consists of two major functions, indexing and querying. The indexing process creates the structures that make document contents searchable while querying takes a user’s query as input and uses retrieval algorithms and those indexing structures to produce relevant documents in the order of ranking scores.
</p>
    <fig id="bax091-F1" orientation="portrait" position="float">
      <label>Figure 1.</label>
      <caption>
        <p>A basic IR architecture.</p>
      </caption>
      <graphic xlink:href="bax091f1"/>
    </fig>
    <p>In the indexing process, text transformation and index creation are two major components. The conventional method of text transformation is to transform documents into index terms. An alternative is to use vectors for representing document contents. The vectors might refer to an index term or partial document. Vector Space Model (VSM) is the most widely used method in vector representations (<xref rid="bax091-B12" ref-type="bibr">12</xref>, <xref rid="bax091-B13" ref-type="bibr">13</xref>). There are different variants of VSM based on how the vectors are generated. Tf-idf is the simplest method that calculates the term frequency-inverse document frequency for each term (<xref rid="bax091-B12" ref-type="bibr">12</xref>, <xref rid="bax091-B13" ref-type="bibr">13</xref>). Latent Semantic Analysis (<xref rid="bax091-B14" ref-type="bibr">14</xref>, <xref rid="bax091-B15" ref-type="bibr">15</xref>) and Latent Dirichlet Allocation (<xref rid="bax091-B16" ref-type="bibr">16</xref>, <xref rid="bax091-B17" ref-type="bibr">17</xref>) are topic modeling methods that could capture some aspects of hidden conceptual information and represent such information in vectors.</p>
    <p>Unlike the VSM model that assumes words are independent of each other (i.e. bag-of-word assumption), the Markov Random Field (MRF) model is a state-of-the-art IR model that leverages Markov properties to take into account the relationships between terms (<xref rid="bax091-B18" ref-type="bibr">18</xref>). <xref ref-type="fig" rid="bax091-F2">Figure 2</xref> illustrates an example of the bag-of-word assumption and the MRF model with three dependency types. The MRF model explicitly represents three types of dependencies between query terms. It has been verified on a variety of IR tasks and the performance has shown promise compared to the conventional bag-of-word based models (<xref rid="bax091-B18" ref-type="bibr">18</xref>, <xref rid="bax091-B19" ref-type="bibr">19</xref>). Recently, Wang <italic>et al.</italic> proposed a Part-Of-Speech (POS) based MRF (POS-MRF) model, which is a variant of the MRF model that assigns different weights to different query terms according to the terms’ POS (<xref rid="bax091-B20" ref-type="bibr">20</xref>). It outperforms the conventional MRF model based on exhaustive experiments (<xref rid="bax091-B20" ref-type="bibr">20</xref>, <xref rid="bax091-B21" ref-type="bibr">21</xref>). Therefore, we also utilized the POS-MRF in our proposed system.
</p>
    <fig id="bax091-F2" orientation="portrait" position="float">
      <label>Figure 2.</label>
      <caption>
        <p>An example of bag-of-word assumption and MRF model.</p>
      </caption>
      <graphic xlink:href="bax091f2"/>
    </fig>
    <p>In the querying process, query transformation and ranking are two major components. Query transformation is important for the final retrieval performance since a raw query might not fully capture the linguistic variability of the information needs. Query transformation includes simple stopwords removal, stemming and more sophisticated spell checking and query term suggestion. In addition, query expansion is a commonly adopted technique in query transformation that expands an initial query using synonyms and semantically related words (<xref rid="bax091-B22" ref-type="bibr">22</xref>, <xref rid="bax091-B23" ref-type="bibr">23</xref>). However, it is still an open question how to find the most related words automatically. Some researchers use topic modeling to expand queries with terms having shared latent topics (<xref rid="bax091-B24" ref-type="bibr">24</xref>).</p>
    <p>Recently, deep learning has drawn researchers’ interest since it automatically learns features from data. Word embeddings are one of the widely used word representations that are trained by deep learning models, which represent words in a dense low-dimension vector that captures hidden features of the word. Having been verified by many winning systems in the Text Retrieval Conference (TREC) Clinical Decision Support (CDS), word embeddings have been shown to be effective for query expansion. The most commonly used model for generating word embeddings is word2vec (<xref rid="bax091-B25" ref-type="bibr">25</xref>). Many participants in the TREC CDS 2016 (<xref rid="bax091-B26" ref-type="bibr">26</xref>) have used word2vec to expand queries with semantically related terms (<xref rid="bax091-B27" ref-type="bibr">27</xref>, <xref rid="bax091-B28" ref-type="bibr">28</xref>). The difference between their methods is that distinct corpora were utilized to train the word2vec. Jo and Lee (<xref rid="bax091-B27" ref-type="bibr">27</xref>) and Gurulingappa <italic>et al.</italic> (<xref rid="bax091-B29" ref-type="bibr">29</xref>) used Wikipedia to train word embeddings while Greuter <italic>et al.</italic> used the TREC-supplied corpus. Diaz <italic>et al.</italic> (<xref rid="bax091-B30" ref-type="bibr">30</xref>) showed some substantial evidence that word embeddings trained on a global corpus, such as Wikipedia, under-performed those trained on local corpora for IR tasks, particularly for query expansion. Therefore, in our approach, we used word embeddings that were trained on the supplied corpus to expand queries.</p>
    <p>Ranking is another crucial component in the querying process since it determines the position of a relevant document in the final retrieval list. A ranking algorithm is able to rank the relevant documents at the top of the list. Many ranking algorithms have been proposed in the literature, such as BM25 (<xref rid="bax091-B31" ref-type="bibr">31</xref>) and a query likelihood ranking model (<xref rid="bax091-B32" ref-type="bibr">32</xref>). It has been shown that the Dirichlet smoothing-based query likelihood model performs better than other models (<xref rid="bax091-B33" ref-type="bibr">33</xref>). Thus, it was used in the proposed system.</p>
    <p>In the biomedical domain, IR tasks mainly focus on retrieving relevant biomedical literature to help physicians and clinicians make better decisions in patient care. The TREC CDS track is an IR shared task that aims to provide common biomedical datasets for participants and promote biomedical IR research (<xref rid="bax091-B34" ref-type="bibr">34</xref>). Most participants in the TREC CDS utilized medical knowledge to enhance their IR methods. The Unified Medical Language System (UMLS) was the most widely used medical knowledge base (<xref rid="bax091-B35" ref-type="bibr">35–37</xref>). Jo and Lee (<xref rid="bax091-B27" ref-type="bibr">27</xref>) utilized the UMLS to construct a clinical causal knowledge to re-rank retrieved documents. Other systems utilized UMLS to expand queries with its thesaurus (<xref rid="bax091-B29" ref-type="bibr">29</xref>, <xref rid="bax091-B38" ref-type="bibr">38</xref>). In addition to the UMLS, Medical Subject Headings (MeSH) (<xref rid="bax091-B39" ref-type="bibr">39</xref>), Systematized Nomenclature of Medicine–Clinical Terms (SNOMED CT) and Wikipedia were also utilized as medical knowledge bases. Mourao <italic>et al.</italic> (<xref rid="bax091-B40" ref-type="bibr">40</xref>) appended synonyms, alternative and preferential labels for all query terms using SNOMED CT and MeSH. Nikolentzos <italic>et al.</italic> (<xref rid="bax091-B41" ref-type="bibr">41</xref>) expanded queries with extracted terms from Wikipedia. All these studies showed improvement over their baselines without using a medical knowledge base.</p>
  </sec>
  <sec>
    <title>Materials and methods</title>
    <p>In this section, we present an overview of the proposed system and detail each component in the system.</p>
    <sec>
      <title>System overview</title>
      <p><xref ref-type="fig" rid="bax091-F3">Figure 3</xref> depicts an overview of the proposed system. Overall, the system contains three parts: query expansion, IR model and re-ranking. We describe each step below.
</p>
      <fig id="bax091-F3" orientation="portrait" position="float">
        <label>Figure 3.</label>
        <caption>
          <p>System overview of the proposed method.</p>
        </caption>
        <graphic xlink:href="bax091f3"/>
      </fig>
      <p>Query expansion. We utilized the corpus containing all the unstructured texts (i.e. ‘title’ and ‘description’) of the datasets and trained the skip-gram model (<xref rid="bax091-B25" ref-type="bibr">25</xref>), a word2vec model, to obtain the word embeddings. Then, we expanded each medical term in a query with the five nearest terms in the embedding space.</p>
      <p>IR model. We indexed the ‘title’ and ‘description’ from each dataset into two separate fields and utilized the POS-MRF model to query the two fields simultaneously to retrieve the relevant datasets. In this article, we also use <italic>document</italic> to represent the two fields of a specified dataset.</p>
      <p>Re-ranking. An ensemble of state-of-the-art named entity recognition and normalization tools were applied to extract medical entities, such as genes and chemical names, from both corpus and queries. Then we re-ranked the top 10 000 retrieved datasets in the previous step by counting the shared entities between documents and queries. By doing so, the datasets that contained more identical medical entities were ranked higher in the final 1000 documents.</p>
    </sec>
    <sec>
      <title>Retrieval model</title>
      <p>POS-MRF is a variant of the MRF model that leverages the grammatical property POS to assign weights to different words (<xref rid="bax091-B20" ref-type="bibr">20</xref>). <xref ref-type="fig" rid="bax091-F4">Figure 4</xref> shows an example graphical model of the POS-MRF model with three query terms. Similar to the MRF model, the POS-MRF model contains three dependency types, namely full independence (denoted as <italic>F</italic>), sequential dependence (denoted as <italic>O</italic>) and full dependence (denoted as <italic>U</italic>). Alternatively, a term weight, denoted as <inline-formula id="IE1"><mml:math id="IM1"><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, is assigned to each query term according to its POS category <inline-formula id="IE2"><mml:math id="IM2"><mml:mi>t</mml:mi></mml:math></inline-formula>. The joint probability function of POS-MRF becomes
<disp-formula id="E1"><mml:math id="M1"><mml:mi>p</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>Q</mml:mi><mml:mo>,</mml:mo><mml:mi>D</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>Z</mml:mi></mml:mrow></mml:mfrac><mml:mfenced open="{" close="}" separators="|"><mml:mrow><mml:mrow><mml:munder><mml:mo stretchy="true">∏</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mo>∈</mml:mo><mml:mo>{</mml:mo><mml:mi>F</mml:mi><mml:mo>,</mml:mo><mml:mi>O</mml:mi><mml:mo>,</mml:mo><mml:mi>U</mml:mi><mml:mo>}</mml:mo></mml:mrow></mml:munder><mml:mrow><mml:mrow><mml:munder><mml:mo stretchy="true">∏</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>∈</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mrow><mml:munder><mml:mo stretchy="true">∏</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mi>f</mml:mi><mml:msup><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>c</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>D</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mo>θ</mml:mo></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo stretchy="true">}</mml:mo></mml:mfenced><mml:mo>,</mml:mo></mml:math></disp-formula>
where <inline-formula id="IE3"><mml:math id="IM3"><mml:mi>c</mml:mi></mml:math></inline-formula> denotes the clique set associated with one of the three dependency types, <inline-formula id="IE4"><mml:math id="IM4"><mml:msub><mml:mrow><mml:mo>θ</mml:mo></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is the parameter associated with the clique set<inline-formula id="IE5"><mml:math id="IM5"><mml:mo> </mml:mo><mml:mi>c</mml:mi></mml:math></inline-formula>, <inline-formula id="IE6"><mml:math id="IM6"><mml:mi>f</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>c</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>D</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula> is the potential function associated with the query term <inline-formula id="IE7"><mml:math id="IM7"><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> in the clique set <inline-formula id="IE8"><mml:math id="IM8"><mml:mi>c</mml:mi></mml:math></inline-formula> and <inline-formula id="IE9"><mml:math id="IM9"><mml:mi>Z</mml:mi></mml:math></inline-formula> is the normalization function. Taking the logarithm of both sides of the above joint probability function and applying Bayes’ rule, we can get the probability of retrieving document <inline-formula id="IE10"><mml:math id="IM10"><mml:mi>D</mml:mi></mml:math></inline-formula> given query <inline-formula id="IE11"><mml:math id="IM11"><mml:mi>Q</mml:mi></mml:math></inline-formula>:
<disp-formula id="E2"><mml:math id="M2"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">log</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>(</mml:mo><mml:mi>D</mml:mi><mml:mo>|</mml:mo><mml:mi>Q</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:munder><mml:mo stretchy="true">∑</mml:mo><mml:mrow><mml:mo>∈</mml:mo><mml:mo>{</mml:mo><mml:mi>F</mml:mi><mml:mo>,</mml:mo><mml:mi>O</mml:mi><mml:mo>,</mml:mo><mml:mi>U</mml:mi><mml:mo>}</mml:mo></mml:mrow></mml:munder><mml:mrow><mml:msub><mml:mrow><mml:mo>θ</mml:mo></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mrow><mml:munder><mml:mo stretchy="true">∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>∈</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mrow><mml:munder><mml:mo stretchy="true">∑</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">log</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mi>f</mml:mi><mml:mo>(</mml:mo><mml:mi>c</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>D</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">log</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mi>Z</mml:mi></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">log</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>D</mml:mi></mml:mrow></mml:mfenced><mml:mo>.</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>
Since <inline-formula id="IE12"><mml:math id="IM12"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">log</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mi>Z</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE13"><mml:math id="IM13"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">log</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>D</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></inline-formula> do not influence the document ranking, we can define the ranking function as
<disp-formula id="E3"><mml:math id="M3"><mml:mi>r</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>Q</mml:mi><mml:mo>,</mml:mo><mml:mi>D</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mrow><mml:munder><mml:mo stretchy="true">∑</mml:mo><mml:mrow><mml:mo>∈</mml:mo><mml:mo>{</mml:mo><mml:mi>F</mml:mi><mml:mo>,</mml:mo><mml:mi>O</mml:mi><mml:mo>,</mml:mo><mml:mi>U</mml:mi><mml:mo>}</mml:mo></mml:mrow></mml:munder><mml:mrow><mml:msub><mml:mrow><mml:mo>θ</mml:mo></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mrow><mml:munder><mml:mo stretchy="true">∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>∈</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mrow><mml:munder><mml:mo stretchy="true">∑</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">log</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mi>f</mml:mi><mml:mo>(</mml:mo><mml:mi>c</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>D</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:math></disp-formula>
In our system, we utilized heuristics and set <inline-formula id="IE14"><mml:math id="IM14"><mml:msub><mml:mrow><mml:mo>θ</mml:mo></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> to 0.8, 0.1, 0.1 for dependency types <italic>F</italic>, <italic>O</italic> and <italic>U</italic>, respectively. We utilized the optimal <inline-formula id="IE15"><mml:math id="IM15"><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> which maximized the mean average precision (MAP) based on the TREC 2011 and 2012 Medical Records datasets. The optimal values are 0.5970, 0.2265, 0.3065, 0.2260, 0.3730, 0.1040, 0.8930 and 0.0 for nouns, plural nouns, past participle verbs, past tense verbs, adjectives, adverbs, singular proper nouns and all other POS categories, respectively.</p>
      <fig id="bax091-F4" orientation="portrait" position="float">
        <label>Figure 4.</label>
        <caption>
          <p>An example of the POS-MRF model.</p>
        </caption>
        <graphic xlink:href="bax091f4"/>
      </fig>
    </sec>
    <sec>
      <title>Medical entity extraction</title>
      <p>We extracted the medical entities from both queries and documents. We used an ensemble of the state-of-the-art named entity normalization tools, PubTator (<xref rid="bax091-B42" ref-type="bibr">42</xref>) and beCAS (<xref rid="bax091-B43" ref-type="bibr">43</xref>), supplemented by a dictionary-based lookup for identifying the entities and normalizing them to standard identifiers.</p>
      <p>First, we used the REST-API services provided by PubTator and beCAS to detect entities from the texts. Subsequently, we built a dictionary by compiling different dictionaries from multiple knowledge sources such as Entrez (<xref rid="bax091-B44" ref-type="bibr">44</xref>), UniProtKB (<xref rid="bax091-B45" ref-type="bibr">45</xref>), Gene ontology (<xref rid="bax091-B46" ref-type="bibr">46</xref>), CTD (<xref rid="bax091-B47" ref-type="bibr">47</xref>) and MeSH (<xref rid="bax091-B39" ref-type="bibr">39</xref>), and looked up gene, biological processes, cell component, chemical names and disease names in the composite dictionary. This dictionary lookup resolved three problems where PubTator and beCAS failed: (<xref rid="bax091-B1" ref-type="bibr">1</xref>) noun phrases lacking morphological features were detected (for example, PubTator and beCAS failed to detect ‘bone morphogenetic protein-2’ while the tokenization component in the dictionary lookup translated the phrase to ‘bone morphogenetic protein 2’ that could be exactly matched in the dictionary Entrez); (<xref rid="bax091-B2" ref-type="bibr">2</xref>) acronyms were detected and (<xref rid="bax091-B3" ref-type="bibr">3</xref>) strings with high surface similarity were detected [for example, both ‘Gialpha(<xref rid="bax091-B1" ref-type="bibr">1</xref>)’ and ‘Gi alpha(<xref rid="bax091-B2" ref-type="bibr">2</xref>)’ were detected by the dictionary lookup while PubTator failed to detect ‘Gi alpha(<xref rid="bax091-B2" ref-type="bibr">2</xref>)’].</p>
      <p>We had certain priority rules to resolve conflicts between the entity recognition systems. Specifically, we utilized the annotations of PubTator for genes/proteins, chemical and disease names when conflicts existed between PubTator and other systems. When PubTator failed to detect those entities, we considered beCAS and the dictionary lookup. Moreover, when a phrase was matched in more than one dictionary in the dictionary lookup, we chose the dictionary that exactly matched the phrase instead of those with partial matches. More details can be found in the BELMiner toolkit paper (<xref rid="bax091-B48" ref-type="bibr">48</xref>).</p>
    </sec>
    <sec>
      <title>Query expansion with word embeddings</title>
      <p>We utilized the skip-gram word2vec model to generate word embeddings. Suppose a word <inline-formula id="IE16"><mml:math id="IM16"><mml:mi>w</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and a context word <inline-formula id="IE17"><mml:math id="IM17"><mml:mi>c</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> are used as input where <inline-formula id="IE18"><mml:math id="IM18"><mml:msub><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula id="IE19"><mml:math id="IM19"><mml:msub><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> denote word and context vocabulary in the corpus, respectively. The corresponding embedding vectors are <inline-formula id="IE20"><mml:math id="IM20"><mml:mi mathvariant="bold">w</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> and <inline-formula id="IE21"><mml:math id="IM21"><mml:mi mathvariant="bold">c</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> where <inline-formula id="IE22"><mml:math id="IM22"><mml:mi>d</mml:mi></mml:math></inline-formula> is the dimension of the embedding vectors. The goal of word2vec is to predict the context words when given a word, i.e. <inline-formula id="IE23"><mml:math id="IM23"><mml:mi>p</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">w</mml:mi><mml:mi mathvariant="bold-italic">'</mml:mi><mml:mi mathvariant="bold-italic">c</mml:mi></mml:mrow></mml:msup><mml:mo>/</mml:mo><mml:mrow><mml:msub><mml:mo stretchy="true">∑</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mrow><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">w</mml:mi><mml:mi mathvariant="bold-italic">'</mml:mi><mml:mi mathvariant="bold-italic">c</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>. The embedding vectors could be learned by maximizing the log-likelihood on the training data. However, the intractability of computing <inline-formula id="IE24"><mml:math id="IM24"><mml:mrow><mml:msub><mml:mo stretchy="true">∑</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mrow><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">w</mml:mi><mml:mi mathvariant="bold-italic">'</mml:mi><mml:mi mathvariant="bold-italic">c</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>, Mikolov <italic>et al</italic>. (<xref rid="bax091-B49" ref-type="bibr">49</xref>) suggests maximizing the following objective likelihood function <inline-formula id="IE25"><mml:math id="IM25"><mml:mrow><mml:mrow><mml:mi mathvariant="italic">log</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>σ</mml:mo><mml:mo>(</mml:mo><mml:mi mathvariant="bold-italic">w</mml:mi><mml:mi mathvariant="bold-italic">'</mml:mi><mml:mi mathvariant="bold-italic">c</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mi>k</mml:mi><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi><mml:mo>∼</mml:mo><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>D</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">log</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>σ</mml:mo><mml:mfenced separators="|"><mml:mrow><mml:mo>-</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">w</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">'</mml:mi></mml:mrow></mml:msup><mml:mi mathvariant="bold-italic">c</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:mrow></mml:mfenced><mml:mo>,</mml:mo></mml:math></inline-formula> where <inline-formula id="IE26"><mml:math id="IM26"><mml:mo>σ</mml:mo><mml:mo>(</mml:mo><mml:mo>·</mml:mo><mml:mo>)</mml:mo></mml:math></inline-formula> is the sigmoid function, <inline-formula id="IE27"><mml:math id="IM27"><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>D</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is a probability measure on the words to sample false context words and <inline-formula id="IE28"><mml:math id="IM28"><mml:mi>k</mml:mi></mml:math></inline-formula> is the number of false context words for each <inline-formula id="IE29"><mml:math id="IM29"><mml:mi>w</mml:mi></mml:math></inline-formula>. The embedding vectors are then learned by maximizing the revised likelihood function.</p>
      <p>Since local embeddings that capture the nuances of topic-specific language perform better than global embeddings, and the latter usually under-perform the former for IR tasks. Therefore, we trained the skip-gram model on the given document collection, i.e. a collection of the ‘title’ and ‘description’ of all the datasets. One hidden layer was utilized and the dimension is set to 100 in the skip-gram model. Minor preprocessing was conducted for the corpus before training, including lowercasing and removing punctuation. Then the entire corpus was merged into one text document to train the word2vec model. We utilized the extracted medical entity terms described in the previous section for expansion. For each medical term, we calculated the cosine similarity in the embeddings and used the five nearest terms as the expansion.</p>
      <p>For example, take the query ‘Find data of all types on synaptic growth and remodeling related to glycolysis in the human brain across all databases.’ We first extracted medical entity terms ‘growth,’ ‘glycolysis,’ ‘human,’ ‘brain’ and found the five nearest terms in the embeddings for each term, i.e. ‘factor-i pressure lymphangiogenic factor-a factor-b’ for ‘growth,’ ‘glycolytic phenylpropanoid tca catabolism gluconeogenesis’ for ‘glycolysis,’ ‘murine mutz- mouse mutamouse tert-immortalized’ for ‘human’ and ‘subcortical brainstem thalamic cortical neurochemistry’ for ‘brain.’ As implied in the previous studies (<xref rid="bax091-B28" ref-type="bibr">28</xref>, <xref rid="bax091-B40" ref-type="bibr">40</xref>, <xref rid="bax091-B50" ref-type="bibr">50</xref>), low weights were usually given to the expanded query terms while high weights were given to the original query terms. Thus, in our system, we heuristically set the weight for the expanded query terms to 0.1 and original query terms to 0.9. In the previous example, the expanded query, i.e. ‘factor-i pressure lymphangiogenic factor-a factor-b glycolytic phenylpropanoid tca catabolism gluconeogenesis murine mutz- mouse mutamouse tert-immortalized subcortical brainstem thalamic cortical neurochemistry,’ was weighed 0.1 while the original query, i.e. ‘Find data of all types on synaptic growth and remodeling related to glycolysis in the human brain across all data-bases,’ was weighed 0.9. Note that we removed the stopwords from the original query in the retrieval system and added two words ‘find’ and ‘search’ into the stopword list for this specific challenge.</p>
    </sec>
    <sec>
      <title>Re-ranking</title>
      <p>Using the afore-mentioned retrieval models and query expansions, we retrieved the top 10 000 datasets for each query. Each document <inline-formula id="IE30"><mml:math id="IM30"><mml:mi>D</mml:mi></mml:math></inline-formula> was associated with a ranking score <inline-formula id="IE31"><mml:math id="IM31"><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>D</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and the highest ranking score (i.e. the ranking score of the document ranked at the first place) was denoted as <inline-formula id="IE32"><mml:math id="IM32"><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:mrow></mml:msub><mml:mo>.</mml:mo></mml:math></inline-formula> Then, we re-ranked the retrieved document <inline-formula id="IE33"><mml:math id="IM33"><mml:mi>D</mml:mi></mml:math></inline-formula> based on the number of entities <inline-formula id="IE34"><mml:math id="IM34"><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>D</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> that the document had in common with the query. In other words, we conducted an exact match between entities in the queries and those in the documents. We counted the number of shared unique entities between each retrieved document and the query. Using those numbers, we re-calculated the score of each retrieved document and ranked them again and returned the top 1000 documents. We used the following formula to calculate the final score of document <inline-formula id="IE35"><mml:math id="IM35"><mml:mi>D</mml:mi></mml:math></inline-formula><italic>:</italic><disp-formula id="E4"><mml:math id="M4"><mml:msubsup><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">'</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:mrow></mml:msub><mml:mo>*</mml:mo><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>D</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>D</mml:mi></mml:mrow></mml:msub><mml:mo>.</mml:mo></mml:math></disp-formula>
By doing this, we can assign larger weights to the documents that have more shared entities associated with a query.</p>
    </sec>
  </sec>
  <sec>
    <title>Experiments</title>
    <p>In this section, we describe the dataset provided by the BioCADDIE Dataset Retrieval Challenge and present the empirical results of 12 systems based on different settings, including five official participant systems in the challenge and seven comparative systems. These systems were measured by the official metrics and one additional metric. An error analysis is then provided for illustrating the pros and cons of the proposed system.</p>
    <sec>
      <title>Dataset</title>
      <p>The organizers generated the dataset collection from DataMed (<ext-link ext-link-type="uri" xlink:href="https://datamed.org/">https://datamed.org/</ext-link>), which was a prototype biomedical data search engine that contains numerous biomedical datasets from a variety of data repositories. The provided dataset collection was derived from a set of 23 individual repositories, which resulted in a total of 794 992 datasets (<xref rid="bax091-B51" ref-type="bibr">51</xref>). Multiple metadata, including structured, unstructured and semi-structured metadata, were given in the dataset collection, such as ‘title,’ ‘description,’ ‘platform,’ ‘repository’ and ‘species.’ Six queries with retrieved results for which the relevance judgments have been annotated were provided as training data and 15 queries were given as testing data.</p>
      <p>A dataset was judged as relevant if it captured all required concepts in the query and if it answered the query or there was a relationship between terms or key concepts. If each key term existed in the dataset title or description, but there was no relationship between terms, the dataset was marked as partially relevant. If no related terms or concepts exist, or the majority of the concepts are missing, the dataset is judged as not relevant. <xref rid="bax091-T1" ref-type="table">Table 1</xref> shows an example of a query and the relevant and partially relevant dataset. Though there are vast amounts of meta-data available, we observed that the annotation guidelines provided by the organizers implied that the human experts to a great extent annotated the dataset based on the free text in the ‘title’ and ‘description’ fields (see the annotation guidelines at <ext-link ext-link-type="uri" xlink:href="https://github.com/yanshanwang/biocaddie2016mayodata/blob/master/AnnotationGuidelineFinal.pdf">https://github.com/yanshanwang/biocaddie2016mayodata/blob/master/AnnotationGuidelineFinal.pdf</ext-link>). The released six queries with relevance judgments confirmed our observation (see <ext-link ext-link-type="uri" xlink:href="https://github.com/yanshanwang/biocaddie2016mayodata/blob/master/Example_with_Annotation_Qrels_100716_updated.zip">https://github.com/yanshanwang/biocaddie2016mayodata/blob/master/Example_with_Annotation_Qrels_100716_updated.zip</ext-link>). Bouadjenek and Verspoor’s study (<xref rid="bax091-B53" ref-type="bibr">53</xref>) also shows that querying the ‘title’ and ‘description’ fields provides the best retrieval performance since these two fields are the most common across the repositories. Therefore, in order to mimic human experts’ judgment, we only utilized the unstructured texts in ‘title’ and ‘description’ in our submissions.
<table-wrap id="bax091-T1" orientation="portrait" position="float"><label>Table 1.</label><caption><p>An example of a query and the corresponding relevant and partially relevant datasets</p></caption><table frame="hsides" rules="groups"><colgroup span="1"><col valign="top" align="left" span="1"/><col valign="top" align="left" span="1"/></colgroup><thead><tr><th align="left" rowspan="1" colspan="1"><italic>Query</italic></th><th align="left" rowspan="1" colspan="1">Find data on T-cell homeostasis related to multiple sclerosis across all databases</th></tr></thead><tbody><tr><td rowspan="1" colspan="1"><italic>Relevant dataset</italic></td><td rowspan="1" colspan="1"><italic>Partially relevant dataset</italic></td></tr><tr><td rowspan="1" colspan="1"><bold>Title</bold>: A Combination Trial of Copaxone Plus Estriol in Relapsing Remitting Multiple Sclerosis.</td><td rowspan="1" colspan="1"><bold>Title</bold>: Quorum sensing in CD4+ T cells homeostasis: IL-2 coordinates the interplay between IL-2p and regulatory T cells.</td></tr><tr><td rowspan="1" colspan="1"><bold>Description</bold>: Through their functional diversification, CD4+ T cells play key roles in both driving and constraining immune-mediated pathology. … Polymorphisms within the locus encoding a transcription factor BACH2 are associated with di-verse immune-mediated diseases including asthma2, multiple sclerosis3, Crohns disease4-5, coeliac disease6, vitiligo7 and type 1 diabetes8. A role for Bach2 in maintaining immune homeostasis, however, has not been established. Here, we define Bach2 as a broad regulator of immune activation that stabilizes im- munoregulatory capacity while repressing the differentiation programmes of mul- tiple effector lineages in CD4+ T cells. Bach2 was required for efficient forma- tion of regulatory (Treg) cells and consequently for suppression of lethal inflam- mation in a manner that was Treg cell dependent. Assessment of the genome- wide function of Bach2, however, revealed that it represses genes associated with effector cell differentiation. Consequently, its absence during Treg polarization resulted in inappropriate diversion to effector lineages. …</td><td rowspan="1" colspan="1"><bold>Description</bold>: Many species of bacteria use quorum sensing to sense the amounts of secreted metabolites and adapt their growth according to their population den- sity. We asked whether similar mechanisms would operate in lymphocyte home- ostasis. We investigated the regulation of the size of Interleukin-2-producing CD4+ T-cell (IL-2p) pool using different IL-2-reporter mice. We found that in the absence of either IL-2 or regulatory CD4+ T-cells (Treg) the number of IL-2p-cells increases. Administration of IL-2 decreases the number of cells of the IL-2p-cell subset and pertinently, abrogates their ability to produce IL-2 upon <italic>in vivo</italic> cognate stimulation, while increasing Treg-cell numbers. We propose that control of the IL-2p-cell numbers occurs via a quorum-sensing-like feedback loop where the produced IL-2 is sensed by both the activated CD4+ T-cell pool and by Treg-cells, which reciprocally regulate cells of the IL-2p-cell subset. In conclusion, IL-2 acts as a self-regulatory circuit integrating the homeostasis of activated and regulatory T cells as CD4+ T-cells restrain their growth by monitoring IL-2 levels thereby preventing uncontrolled responses and autoimmunity. Overall design: 2 populations of conventional CD4+ T cell are analysed. 5 replicates for each. GFP- is the control one.</td></tr><tr><td rowspan="1" colspan="1"><bold>Judgment rationale*:</bold> It doesn’t directly mention anything about T-cell homeostasis but Bach 2 is involved in regulation of level of Treg (Which is regulatory T-cells). Also, it mentions the role of Bach 2 in multiple diseases as highlighted.</td><td rowspan="1" colspan="1"><bold>Judgment rationale*:</bold> It talks about Multiple Sclerosis but doesn’t have anything related to T-cell homeostasis.</td></tr></tbody></table><table-wrap-foot><fn id="tblfn1"><label>*</label><p>Provided by the challenge organizers</p></fn></table-wrap-foot></table-wrap></p>
    </sec>
    <sec>
      <title>Baseline and evaluation</title>
      <p>In this empirical experiment, we evaluated 12 systems based on different settings of the proposed methods. <xref rid="bax091-T2" ref-type="table">Table 2</xref> lists the setting for each system. TFIDF (official run1), MRF (official run2) and POS-MRF (official run3) were three baseline systems that utilized the conventional tf-idf weighted VSM, MRF and POS-MRF as the retrieval models respectively. TFIDF + WE, MRF + WE and POS-MRF + WE (official run4) added the query expansion using word embeddings in each model. TFIDF + RR, MRF + RR and POS-MRF + RR added the re-ranking step after retrieving the documents. TFIDF + WE + RR, MRF + WE + RR and POS-MRF + WE + RR leveraged both query expansion and re-ranking in the retrieval models. TFIDF, MRF, POS-MRF, POS-MRF + WE and POS-MRF + WE + RR are the five official systems submitted to the BioCADDIE challenge. By comparing these systems, we were able to know the impact of each component on the retrieval system.
<table-wrap id="bax091-T2" orientation="portrait" position="float"><label>Table 2.</label><caption><p>Settings for the evaluated systems</p></caption><table frame="hsides" rules="groups"><colgroup span="1"><col valign="top" align="left" span="1"/><col valign="top" align="center" span="1"/><col valign="top" align="center" span="1"/><col valign="top" align="center" span="1"/><col valign="top" align="center" span="1"/><col valign="top" align="center" span="1"/></colgroup><thead><tr><th rowspan="1" colspan="1"/><th rowspan="1" colspan="1">TFIDF</th><th rowspan="1" colspan="1">MRF</th><th rowspan="1" colspan="1">POS-MRF</th><th rowspan="1" colspan="1">Word Embeddings</th><th rowspan="1" colspan="1">Re-ranking</th></tr></thead><tbody><tr><td rowspan="1" colspan="1">TFIDF (official run1)</td><td rowspan="1" colspan="1">•</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/></tr><tr><td rowspan="1" colspan="1">TFIDF+WE</td><td rowspan="1" colspan="1">•</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">•</td><td rowspan="1" colspan="1"/></tr><tr><td rowspan="1" colspan="1">TFIDF+RR</td><td rowspan="1" colspan="1">•</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">•</td></tr><tr><td rowspan="1" colspan="1">TFIDF+WE+RR</td><td rowspan="1" colspan="1">•</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">•</td><td rowspan="1" colspan="1">•</td></tr><tr><td rowspan="1" colspan="1">MRF (official run2)</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">•</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/></tr><tr><td rowspan="1" colspan="1">MRF+WE</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">•</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">•</td><td rowspan="1" colspan="1"/></tr><tr><td rowspan="1" colspan="1">MRF+RR</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">•</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">•</td></tr><tr><td rowspan="1" colspan="1">MRF+WE+RR</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">•</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">•</td><td rowspan="1" colspan="1">•</td></tr><tr><td rowspan="1" colspan="1">POS-MRF (official run3)</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">•</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/></tr><tr><td rowspan="1" colspan="1">POS-MRF+WE (official run4)</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">•</td><td rowspan="1" colspan="1">•</td><td rowspan="1" colspan="1"/></tr><tr><td rowspan="1" colspan="1">POS-MRF+RR</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">•</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">•</td></tr><tr><td rowspan="1" colspan="1">POS-MRF+WE+RR (official run5)</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">•</td><td rowspan="1" colspan="1">•</td><td rowspan="1" colspan="1">•</td></tr></tbody></table></table-wrap></p>
      <p>Five metrics, including inference Average Precision (infAP) (<xref rid="bax091-B52" ref-type="bibr">52</xref>), inference normalized Discounted Cumulative Gain (infNDCG) (<xref rid="bax091-B52" ref-type="bibr">52</xref>), NDCG@10 (NDCG at the top 10 documents), P@10(+partial) (precision at the top 10 document including partially relevant datasets) and P@10(-partial) (precision at the top 10 document excluding partially relevant datasets), were used by the challenge organizers to measure the submitted systems. We also computed the MAP as an additional metric. The evaluation scripts for computing these metrics are available at: <ext-link ext-link-type="uri" xlink:href="https://github.com/yanshanwang/biocaddie2016mayodata">https://github.com/yanshanwang/biocaddie2016mayodata</ext-link>.</p>
    </sec>
    <sec>
      <title>Preprocessing and indexing</title>
      <p>Minor preprocessing was conducted for the corpus, including lowercasing and stopwords removal. Two document types, namely json and xml, were provided in this shared task. We used the json format to extract the title and description fields to construct documents. After the preprocessing, we built an index using Elasticsearch (<ext-link ext-link-type="uri" xlink:href="https://www.elastic.co/">https://www.elastic.co/</ext-link>), which is an open source package for indexing and retrieving documents. Compared to other IR tools, Elasticsearch is much faster for indexing and searching. It has been adopted by many commercial companies, such as eBay, Dell and Facebook, to handle all kinds of search functionalities. We indexed the ‘title’ and ‘description’ into two fields in Elastic search and utilized both fields simultaneously for retrieval.</p>
    </sec>
  </sec>
  <sec sec-type="results">
    <title>Results</title>
    <p><xref rid="bax091-T3" ref-type="table">Table 3</xref> lists three examples of the original queries, and the associated extracted medical entities from the original queries and expanded query terms using word embeddings. We can see that the medical entity extraction method successfully extracted the medical entities that were the key medical concepts to understand the query. Since the identical method was applied to the corpus, these medical entities in each document could also be extracted. In the re-ranking step, the exact matching between the medical entities from the query and corpus could dramatically increase the ranking of the relevant datasets. We can also observe that expanded query terms using word embeddings added semantically related terms to the original query. For example, ‘phenylpropanoid’ and ‘gluconeogenesis’ are related to ‘glycolysis’; and ‘progesterone’ and ‘hormone’ are related to ‘estrogen’ for ‘women.’ Adding these related terms could increase the retrieval of relevant or partially relevant datasets. In our system, we assigned a lower weight (weight = 0.1) to the expanded query terms because we wanted the IR system to focus more on the original query terms. By doing so, we could not only reduce the impact of noisy information but also take advantage of the related terms.
<table-wrap id="bax091-T3" orientation="portrait" position="float"><label>Table 3.</label><caption><p>Examples of original queries, extracted medical entities from the original queries and expanded query terms using word embeddings</p></caption><table frame="hsides" rules="groups"><colgroup span="1"><col valign="top" align="left" span="1"/><col valign="top" align="left" span="1"/><col valign="top" align="left" span="1"/><col valign="top" align="left" span="1"/><col valign="top" align="left" span="1"/><col valign="top" align="left" span="1"/></colgroup><thead><tr><th rowspan="2" colspan="1">Original query</th><th colspan="3" rowspan="1">Extracted medical entity<hr/></th><th colspan="2" rowspan="1">Expanded query terms<hr/></th></tr><tr><th align="left" rowspan="1" colspan="1">Entity ID</th><th align="left" rowspan="1" colspan="1">Semantic type</th><th align="left" rowspan="1" colspan="1">Entity</th><th align="left" rowspan="1" colspan="1">Entity term</th><th align="left" rowspan="1" colspan="1">Expanded terms</th></tr></thead><tbody><tr><td rowspan="4" colspan="1">Find data of all types on synaptic growth and remodeling related to glycolysis in the human brain across all databases.</td><td rowspan="1" colspan="1">T0</td><td rowspan="1" colspan="1">PROC</td><td rowspan="1" colspan="1">Growth</td><td rowspan="4" colspan="1"><list list-type="simple"><list-item><p>Growth</p></list-item><list-item><p>Glycolysis</p></list-item><list-item><p>Human</p></list-item><list-item><p>Brain</p></list-item></list></td><td rowspan="4" colspan="1"><list list-type="simple"><list-item><p>Factor-i pressure lymphangiogenic factor-a factor-b</p></list-item><list-item><p>Glycolytic phenylpropanoid tca catabolism gluconeogenesis</p></list-item><list-item><p>Murine mutz- mouse mutamouse tertimmortalized</p></list-item><list-item><p>Subcortical brainstem thalamic cortical neurochemistry</p></list-item></list></td></tr><tr><td rowspan="1" colspan="1">T1</td><td rowspan="1" colspan="1">PROC</td><td rowspan="1" colspan="1">Glycolysis</td></tr><tr><td rowspan="1" colspan="1">T2</td><td rowspan="1" colspan="1">SPEC</td><td rowspan="1" colspan="1">Human</td></tr><tr><td rowspan="1" colspan="1">T3</td><td rowspan="1" colspan="1">ANAT</td><td rowspan="1" colspan="1">Brain</td></tr><tr><td rowspan="6" colspan="1">Search for data on BRCA gene mutations and the estrogen signaling pathway in women with stage I breast cancer.</td><td rowspan="1" colspan="1">T0</td><td rowspan="1" colspan="1">PROC</td><td rowspan="1" colspan="1">Gene mutations</td><td rowspan="6" colspan="1"><list list-type="simple"><list-item><p>Gene</p></list-item><list-item><p>Mutations</p></list-item><list-item><p>Estrogen</p></list-item><list-item><p>Signaling</p></list-item><list-item><p>Pathway</p></list-item><list-item><p>Women</p></list-item><list-item><p>Stage</p></list-item><list-item><p>Breast</p></list-item><list-item><p>Cancer</p></list-item></list></td><td rowspan="6" colspan="1"><list list-type="simple"><list-item><p>Expression differential microrna mirna profiles</p></list-item><list-item><p>Mutation truncating mutated deletions missense</p></list-item><list-item><p>Oestrogen progesterone androgen hormone progestins</p></list-item><list-item><p>Signaling autophagy jakstat jak-stat endocytosis</p></list-item><list-item><p>Signaling jakstat wnt\ub-catenin signaling nf-kb</p></list-item><list-item><p>Men premenopausal pre-menopausal desiring perimenopausal</p></list-item><list-item><p>ii-iii uicc iiiiv iiiciv iiic</p></list-item><list-item><p>Prostate colorectal ovarian er+ cancers</p></list-item><list-item><p>Prostate castrate-resistant breast non-metastatic colorectal</p></list-item></list></td></tr><tr><td rowspan="1" colspan="1">T1</td><td rowspan="1" colspan="1">PATH</td><td rowspan="1" colspan="1">Estrogen signaling pathway</td></tr><tr><td rowspan="1" colspan="1">T2</td><td rowspan="1" colspan="1">CHED</td><td rowspan="1" colspan="1">Estrogen</td></tr><tr><td rowspan="1" colspan="1">T3</td><td rowspan="1" colspan="1">PROC</td><td rowspan="1" colspan="1">Signaling pathway</td></tr><tr><td rowspan="1" colspan="1">T4</td><td rowspan="1" colspan="1">SPEC</td><td rowspan="1" colspan="1">Women</td></tr><tr><td rowspan="1" colspan="1">T5</td><td rowspan="1" colspan="1">DISO</td><td rowspan="1" colspan="1">Stage I breast cancer</td></tr></tbody></table></table-wrap></p>
    <p><xref rid="bax091-T4" ref-type="table">Table 4</xref> shows the experimental results using the official evaluation scripts in terms of infAP, infNDCG, NDCG@10, P@10(+partial), P@10(-partial) and MAP.
<table-wrap id="bax091-T4" orientation="portrait" position="float"><label>Table 4.</label><caption><p>Experimental results on the BioCADDIE dataset</p></caption><table frame="hsides" rules="groups"><colgroup span="1"><col valign="top" align="left" span="1"/><col valign="top" align="char" char="." span="1"/><col valign="top" align="char" char="." span="1"/><col valign="top" align="char" char="." span="1"/><col valign="top" align="char" char="." span="1"/><col valign="top" align="char" char="." span="1"/><col valign="top" align="char" char="." span="1"/></colgroup><thead><tr><th rowspan="1" colspan="1"/><th rowspan="1" colspan="1">infAP</th><th rowspan="1" colspan="1">infNDCG</th><th rowspan="1" colspan="1">NDCG@10</th><th rowspan="1" colspan="1">P@10(+partial)</th><th rowspan="1" colspan="1">P@10(-partial)</th><th rowspan="1" colspan="1">MAP</th></tr></thead><tbody><tr><td rowspan="1" colspan="1">TFIDF (official run1)</td><td rowspan="1" colspan="1">0.1393</td><td rowspan="1" colspan="1">0.3485</td><td rowspan="1" colspan="1">0.5735</td><td rowspan="1" colspan="1">0.7267</td><td rowspan="1" colspan="1">0.2600</td><td rowspan="1" colspan="1">0.1708</td></tr><tr><td rowspan="1" colspan="1">TFIDF+WE</td><td rowspan="1" colspan="1">0.1392</td><td rowspan="1" colspan="1">0.3470</td><td rowspan="1" colspan="1">0.5735</td><td rowspan="1" colspan="1">0.7267</td><td rowspan="1" colspan="1"><bold>0.2667</bold></td><td rowspan="1" colspan="1">0.1708</td></tr><tr><td rowspan="1" colspan="1">TFIDF+RR</td><td rowspan="1" colspan="1">0.1399</td><td rowspan="1" colspan="1">0.3404</td><td rowspan="1" colspan="1">0.5345</td><td rowspan="1" colspan="1">0.6933</td><td rowspan="1" colspan="1"><bold>0.2667</bold></td><td rowspan="1" colspan="1">0.1476</td></tr><tr><td rowspan="1" colspan="1">TFIDF+WE+RR</td><td rowspan="1" colspan="1">0.1484</td><td rowspan="1" colspan="1">0.3358</td><td rowspan="1" colspan="1">0.5418</td><td rowspan="1" colspan="1">0.7067</td><td rowspan="1" colspan="1">0.2467</td><td rowspan="1" colspan="1">0.1633</td></tr><tr><td rowspan="1" colspan="1">MRF (official run2)</td><td rowspan="1" colspan="1">0.1424</td><td rowspan="1" colspan="1">0.3516</td><td rowspan="1" colspan="1">0.5726</td><td rowspan="1" colspan="1"><bold>0.7467</bold></td><td rowspan="1" colspan="1">0.2533</td><td rowspan="1" colspan="1"><bold>0.1742</bold></td></tr><tr><td rowspan="1" colspan="1">MRF+WE</td><td rowspan="1" colspan="1">0.1424</td><td rowspan="1" colspan="1">0.3508</td><td rowspan="1" colspan="1"><bold>0.5901</bold></td><td rowspan="1" colspan="1"><bold>0.7467</bold></td><td rowspan="1" colspan="1">0.2533</td><td rowspan="1" colspan="1">0.1741</td></tr><tr><td rowspan="1" colspan="1">MRF+RR</td><td rowspan="1" colspan="1">0.1383</td><td rowspan="1" colspan="1">0.3439</td><td rowspan="1" colspan="1">0.5267</td><td rowspan="1" colspan="1">0.6933</td><td rowspan="1" colspan="1">0.2467</td><td rowspan="1" colspan="1">0.1463</td></tr><tr><td rowspan="1" colspan="1">MRF+WE+RR</td><td rowspan="1" colspan="1">0.1499</td><td rowspan="1" colspan="1">0.3381</td><td rowspan="1" colspan="1">0.5564</td><td rowspan="1" colspan="1">0.7267</td><td rowspan="1" colspan="1">0.2467</td><td rowspan="1" colspan="1">0.1659</td></tr><tr><td rowspan="1" colspan="1">POS-MRF (official run3)</td><td rowspan="1" colspan="1">0.1077</td><td rowspan="1" colspan="1">0.3006</td><td rowspan="1" colspan="1">0.4406</td><td rowspan="1" colspan="1">0.5333</td><td rowspan="1" colspan="1">0.2267</td><td rowspan="1" colspan="1">0.1273</td></tr><tr><td rowspan="1" colspan="1">POS-MRF+WE (official run4)</td><td rowspan="1" colspan="1">0.1423</td><td rowspan="1" colspan="1">0.3253</td><td rowspan="1" colspan="1">0.4453</td><td rowspan="1" colspan="1">0.5400</td><td rowspan="1" colspan="1">0.2333</td><td rowspan="1" colspan="1">0.1640</td></tr><tr><td rowspan="1" colspan="1">POS-MRF+RR</td><td rowspan="1" colspan="1">0.1382</td><td rowspan="1" colspan="1">0.3641</td><td rowspan="1" colspan="1">0.5105</td><td rowspan="1" colspan="1">0.6533</td><td rowspan="1" colspan="1">0.2533</td><td rowspan="1" colspan="1">0.1472</td></tr><tr><td rowspan="1" colspan="1">POS-MRF+WE+RR (official run5)</td><td rowspan="1" colspan="1"><bold>0.1628</bold></td><td rowspan="1" colspan="1"><bold>0.3933</bold></td><td rowspan="1" colspan="1">0.5243</td><td rowspan="1" colspan="1">0.6667</td><td rowspan="1" colspan="1">0.2600</td><td rowspan="1" colspan="1">0.1697</td></tr></tbody></table><table-wrap-foot><fn id="tblfn2"><p>Best performance for each metric is highlighted in bold.</p></fn></table-wrap-foot></table-wrap></p>
    <p>First, we observe that the POS-MRF model is inferior to TFIDF and MRF models. The reason is that the POS parser, a crucial part of the POS-MRF model (<xref rid="bax091-B20" ref-type="bibr">20</xref>), does not perform well on the given queries since these queries are not complete sentences. For example, a testing query is ‘Search for data of all types related to energy metabolism in obese M. musculus’ and the corresponding POS tagging result is ‘Search/NN for/IN data/NNS of/IN all/DT types/NNS related/VBN to energy/NN metabolism/NN in/IN obese/JJ M./NNP musculus/NNS’. 9 out of 13 terms are one of ‘NN,’ ‘NNS,’ ‘VBN,’ ‘JJ’ and ‘NNP’ that are assigned greater weights according to the POS-MRF. Moreover, ‘M.’ is parsed as ‘NNP’ and ‘search’ is mistakenly parsed as ‘NN,’ which are also weighted larger by the POS-MRF model. Documents containing more terms like ‘search’ or ‘M’ are eventually ranked higher than other documents. Thus, the POS-MRF fails to distinguish important terms from less important terms and parses ‘search’ as ‘NN.’ Future directions for improving the POS-MRF may include assigning different weighs to different terms having the same POS, and searching for multiword expressions like ‘M.musculus’ and training the POS tagger on a biomedical corpus.</p>
    <p>Second, we observe that adding the query expansion with word embeddings slightly decreases the performance of TFIDF and MRF in terms of infAP and infNDCG, while it slightly increases the performance of TFIDF in terms of P@10(-partial) and the performance of MRF in terms of NDCG@10. This means that expanding the query using word embeddings adds more relevant terms so that the relevant documents are ranked higher in the retrieval results (i.e. more relevant documents are ranked in the top 10). At the same time, we can also see that the query expansion also incorporates more noisy terms, which leads to more non-relevant documents being retrieved (low infAP and infNDCG). It is interesting that almost no changes are found when P@10(+partial) is used as the metric, which is consistent with the result that the most relevant documents are ranked higher using the query expansion. In addition, we observe that the performance of POS-MRF significantly increases (<italic>P</italic> &lt; 0.01 using Wilcoxon test) with the word embeddings based query expansion in terms of all metrics. This result is consistent with our findings that the expanded terms are important for retrieving relevant documents. Adding these terms into the original query alleviates the impact of POS-MRF on the important query terms.</p>
    <p>Third, the TFIDF + RR and the MRF + RR under-perform the TFIDF (or the TFIDF + WE) and the MRF (the MRF + WE), respectively, in terms of almost all of the metrics [except for TFIDF measuring by infAP and P@10(-partial)]. These results show that the re-ranking component does not positively improve the retrieval results for the TFIDF and MRF models. However, the POS-MRF + RR out-performs the POS-MRF in terms of all the metrics. The reason might be that the POS-MRF retrieved more relevant documents in the top 10 000 documents than the other two models (since the re-ranking is performed on the top 10 000 documents) but these relevant documents are ranked very low and the re-ranking could rank these relevant documents high into the top 1000 documents.</p>
    <p>Compared to using the query expansion or re-ranking alone, adding both components enhances all of the models (i.e. the TFIDF + WE + RR versus the TFIDF + WE or the TFIDF + RR, the MRF + WE + RR versus the MRF + WE or the MRF + RR and the POS-MRF + WE + RR versus the POS-MRF + WE or the POS-MRF + RR) in terms of infAP. However, when other metrics are used, the performance of using both components is superior to that of using only re-ranking but inferior to that of using only query expansion. This is clearly shown by comparing the MAP results of each model. For example, the MAP of TFIDF + WE + RR is 0.1633, which is between that of TFIDF + RR (0.1476) and that of TFIDF + RR (0.1708) and the MAP of MRF + WE + RR is 0.1659, which is between that of MRF + RR (0.1463) and that of MRF + WE (0.1741). This result is consistent with the above findings of the influence of re-ranking. However, the POS-MRF + WE + RR performs better than either the POS-MRF + WE or the POS-MRF-RR. This result shows that the POS-MRF model could take advantage of both the query expansion and the re-ranking.</p>
    <p>Finally, the POS-MRF + WE + RR has the best performance among the evaluated methods in terms of infAP and infNDCG, and competitive performance in terms of other metrics. The results indicate that the proposed system performs well overall. The MRF + WE model has the best NDCG@10 and P@10(+partial) and a competitive P@10(-partial). Therefore, it should be considered when only the top 10 retrieved documents are considered. It is also interesting that the simple TFIDF performs well in terms of NDCG@10, P@10(+partial) and P@10(-partial). The TFIDF is a keyword matching approach, which ranks highly the documents containing more matched query terms in the retrieval list. Particularly in the case of dataset retrieval, documents exactly matching the terminologies in a query are obviously judged as relevant according to the relevance judgment guideline. Therefore, when only the first 10 documents are considered, a simple keyword matching approach, such as TFIDF, usually has good performance.</p>
  </sec>
  <sec>
    <title>Conclusion and discussion</title>
    <p>In this article, we propose an IR system for biomedical dataset retrieval. The proposed system combines the state-of-the-art retrieval models and leverages the medical entity extraction method, the query expansion based on word embeddings and the re-ranking to enhance the biomedical dataset retrieval. We compared 12 approaches including our participation in the bioCADDIE Dataset Retrieval Challenge in the experiments. Overall, the proposed approach POS-MRF + WE + RR outperforms other approaches in terms of infAP and infNDCG. The MRF + WE model should be considered when only the top 10 retrieved documents are considered. In addition, we showed the impacts of query expansion and re-ranking on the retrieval performance for each approach.</p>
    <p>There are two typical cases in which the proposed approach may fail: (<xref rid="bax091-B1" ref-type="bibr">1</xref>) if there are no shared keywords or medical entities between a query and a relevant dataset, and the query expansion using word embeddings fails to find the relevant terms in the dataset, the proposed system will fail to retrieve the dataset; and (<xref rid="bax091-B2" ref-type="bibr">2</xref>) when the query contains inclusion or/and exclusion criteria, it is difficult for the proposed IR system to filter out the datasets that do not meet the criteria. <xref rid="bax091-T5" ref-type="table">Table 5</xref> illustrates two examples for both cases. In Example 1, ‘<italic>Escherichia coli</italic>’ is a specific bacteria that has bacterial ‘chemoraxis,’ thus the dataset is related to the query. Since the query does not contain ‘<italic>Escherichia coli</italic>’ and the query expansion using wording embeddings fails to find ‘<italic>Escherichia coli</italic>,’ the proposed system fails to retrieve this relevant dataset. In Example 2, the dataset is judged non-relevant to the query since the query is to ‘find data on Nuclear Factor-κB (NF-κB)’ in ‘Myasthenia gravis (MG) patients’ where ‘MG patients’ is the criteria for ‘NF-κB.’ However, due to the shared entities ‘NF-κB’ and ‘signaling pathway,’ the dataset was retrieved and ranked at the third position by the proposed system.
<table-wrap id="bax091-T5" orientation="portrait" position="float"><label>Table 5.</label><caption><p>Examples for error analysis</p></caption><table frame="hsides" rules="groups"><colgroup span="1"><col valign="top" align="left" span="1"/></colgroup><tbody><tr><td rowspan="1" colspan="1">Example 1: False negatives.
<list list-type="simple"><list-item><p><italic>Query</italic>: Find protein sequencing data related to <bold>bacterial chemotaxis</bold> across all databases.</p></list-item><list-item><p><italic>Dataset title</italic>: <bold><italic>Escherichia coli</italic></bold> 6.0172: <bold><italic>Escherichia coli</italic></bold> 6.0172 genome sequencing project.</p></list-item><list-item><p><italic>Dataset description:</italic> N/A</p></list-item></list></td></tr><tr><td rowspan="1" colspan="1">Example 2: False positives.
<list list-type="simple"><list-item><p><italic>Query</italic>: Find data on the <bold>NF-κB signaling pathway</bold> in <bold>MG patients</bold>.</p></list-item><list-item><p><italic>Dataset title</italic>: Ginger and its component ameliorated trinitrobenzene sulfonic acid-induced colitis in mice via modulation of NF-κB activity and interleukin-1β (IL-1β) <bold>signaling pathway</bold>.</p></list-item><list-item><p><italic>Dataset description</italic>: Colitis is the common pathological lesion of inflammatory bowel diseases, the major chronic inflammatory diseases of intestinal tracts in humans. In this study, we investigated the therapeutic effects of ginger extract and its component zingerone in mice with 2, 4, 6-trinitrobenzene sulfonic acid (TNBS)-induced colitis. Mice were administered with TNBS and/or various amounts of ginger and zingerone by an intrarectal route. The severity of colitis was evaluated by colonic weight/length ratio, macroscopic lesion, and histological examination. The mechanisms of ginger and zingerone were further elucidated by DNA microarray, ex vivo imaging, and immunohistochemical staining. Our data showed that treatment with ginger extract and zingerone ameliorated TNBS-induced colonic inflammation and injury in a dose-dependent manner. Pathway analysis of ginger- and zingerone-regulated gene expression profiles showed that ginger and zingerone significantly regulated cytokine-related pathways. Network analysis showed that <bold>NF-κB</bold> and IL-1β were key molecules involved in the expression of ginger- and zingerone-affected genes. Ex vivo imaging and immunohistochemical staining further verified that ginger and zingerone suppressed TNBS-induced <bold>NF-κB</bold> activation and decreased the <bold>NF-κB</bold> and IL-1β protein levels in the colon. In conclusion, our data showed that ginger improved the TNBS-induced colitis in mice via modulation of <bold>NF-κB</bold> activity and IL-1β <bold>signaling pathway</bold>. Moreover, zingerone might be the active component of ginger responsible for the amelioration of colitis induced by TNBS. Overall design: A total of 24 mice was randomly divided into four groups of six mice: mock, mice were given with 0.1 ml of 50% ethanol; TNBS, mice were given with 250 mg/kg TNBS in 0.1 ml of 50% ethanol; TNBS/ginger, mice were administered with mixtures containing 250 mg/kg TNBS and various amounts of ginger extract in 0.1 ml of 50% ethanol; TNBS/zingerone, mice were given with mixtures containing 250 mg/kg TNBS and various amounts of zingerone in 0.1 ml of 50% ethanol. Mice were sacrificed 7 days later for histochemical staining, RNA extraction, and ex vivo imaging.</p></list-item></list></td></tr></tbody></table><table-wrap-foot><fn id="tblfn3"><p>Keywords for relevance judgment are highlighted in bold.</p></fn></table-wrap-foot></table-wrap></p>
    <p>Based the error analysis above, there are a few future directions to improve the proposed system. First, we would like to develop more sophisticated approaches for query expansion using deep learning models. For example, we could use external resources to train word embeddings for query expansion. Though some studies show the local word embeddings are superior to global embeddings, Example 1 in our error analysis indicates that global word embeddings might find the related terms that cannot be found using the local word embeddings. Moreover, we can also take advantage of the semantic types for each extracted term and assign different weights to the expanded terms computed from word embeddings, similar to the approach proposed in Want <italic>et al</italic>.’s study (<xref rid="bax091-B54" ref-type="bibr">54</xref>). Second, we want to investigate how to take into account inclusion and exclusion criteria in the system. As shown in Example 2, in our error analysis, queries might have criteria that are crucial to exclude some non-relevant retrieved datasets. By doing so, false positives could be reduced in the final retrieved datasets.</p>
    <p>One limitation of this study is that the semi-structured and structured metadata provided in the dataset were not utilized for retrieval in the submitted systems. Scerri <italic>et al</italic>. (<xref rid="bax091-B55" ref-type="bibr">55</xref>) leveraged the semi-structured data to build entity dictionaries to match the user query, and achieved high retrieval performance. Bouadjenek and Verspoor (<xref rid="bax091-B53" ref-type="bibr">53</xref>) explicitly show that incorporating semi-structured metadata into retrieval mostly decreases the performance. However, they also show that using the metadata in the ‘gene’ field significantly improves the retrieval performance. Therefore, in our future study, we would like to investigate how to leverage the semi-structured and structured metadata in a dataset retrieval system.</p>
    <p>We find that the metrics used to evaluate the systems make the comparison difficult. Though different metrics indicate different aspects of an IR system, we observe that one might conclude differently when different metrics are used. For example, we see that the trend of MAP is consistent with that of infNDCG but mostly inconsistent with that of infAP. Another example is that TFIDF + RR out-performs TFIDF in terms of infAP but under-performs TFIDF in terms of infNDCG and MAP. The results of using the metrics considering only the top 10 documents [i.e. NDCG@10 and P@10(+partial)] are usually consistent, as shown in <xref rid="bax091-T4" ref-type="table">Table 4</xref>. Therefore, an IR system should be evaluated by different metrics to explicitly demonstrate the advantages and disadvantages. Moreover, novel metrics should be studied to measure IR systems, particularly for the IR system designed for specific tasks, such as the dataset retrieval task.</p>
  </sec>
  <sec>
    <title>Funding</title>
    <p>This work has been supported by the National Institutes of Health (NIH) grants R01LM011934 and R01GM102282. The bioCADDIE Dataset Retrieval Challenge was supported by the NIH grant U24AI117966.</p>
    <p><italic>Conflict of interest</italic>. None declared.</p>
  </sec>
</body>
<back>
  <ref-list>
    <title>References</title>
    <ref id="bax091-B1">
      <label>1</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Ohno-Machado</surname><given-names>L.</given-names></name>, <name name-style="western"><surname>Sansone</surname><given-names>S.-A.</given-names></name>, <name name-style="western"><surname>Alter</surname><given-names>G.</given-names></name></person-group><etal/> (<year>2017</year>) <article-title>Finding useful data across multiple biomedical data repositories using DataMed</article-title>. <source>Nature Genet.</source>, <volume>49</volume>, <fpage>816</fpage>–<lpage>819</lpage>.<pub-id pub-id-type="pmid">28546571</pub-id></mixed-citation>
    </ref>
    <ref id="bax091-B2">
      <label>2</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Collins</surname><given-names>F.S.</given-names></name>, <name name-style="western"><surname>Tabak</surname><given-names>L.A.</given-names></name></person-group> (<year>2014</year>) <article-title>NIH plans to enhance reproducibility</article-title>. <source>Nature</source>, <volume>505</volume>, <fpage>612.</fpage><pub-id pub-id-type="doi">10.1038/505612a</pub-id><pub-id pub-id-type="pmid">24482835</pub-id></mixed-citation>
    </ref>
    <ref id="bax091-B3">
      <label>3</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Wilkinson</surname><given-names>M.D.</given-names></name>, <name name-style="western"><surname>Dumontier</surname><given-names>M.</given-names></name>, <name name-style="western"><surname>Aalbersberg</surname><given-names>I.J.</given-names></name></person-group><etal/> (<year>2016</year>) <article-title>The FAIR Guiding Principles for scientific data management and stewardship</article-title>. <source>Sci. Data</source>, <volume>3</volume>, 160018.</mixed-citation>
    </ref>
    <ref id="bax091-B4">
      <label>4</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Edmunds</surname><given-names>S.C.</given-names></name>, <name name-style="western"><surname>Li</surname><given-names>P.</given-names></name>, <name name-style="western"><surname>Hunter</surname><given-names>C.I.</given-names></name></person-group><etal/> (<year>2017</year>) <article-title>Experiences in integrated data and research object publishing using GigaDB</article-title>. <source>Int. J. Digital Lib</source>., <volume>18</volume>, <fpage>99</fpage>–<lpage>111</lpage>.</mixed-citation>
    </ref>
    <ref id="bax091-B5">
      <label>5</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Bourne</surname><given-names>P.E.</given-names></name>, <name name-style="western"><surname>Bonazzi</surname><given-names>V.</given-names></name>, <name name-style="western"><surname>Dunn</surname><given-names>M.</given-names></name></person-group><etal/> (<year>2015</year>) <article-title>The NIH big data to knowledge (BD2K) initiative</article-title>. <source>J. Am. Med. Inform. Assoc</source>., <volume>22</volume>, <fpage>1114</fpage>–<lpage>1114</lpage>.<pub-id pub-id-type="pmid">26555016</pub-id></mixed-citation>
    </ref>
    <ref id="bax091-B6">
      <label>6</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Solbrig</surname><given-names>H.R.</given-names></name>, <name name-style="western"><surname>Jiang</surname><given-names>G.</given-names></name></person-group> (<year>2016</year>) Harmonizing bioCADDIE metadata schemas for indexing clinical research datasets using semantic web technologies. In: <source>Proceedings of the 15th International Semantic Web Conference (ISWC)</source>. Kobe, Japan.</mixed-citation>
    </ref>
    <ref id="bax091-B7">
      <label>7</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Lu</surname><given-names>Z.</given-names></name></person-group> (<year>2011</year>) <article-title>PubMed and beyond: a survey of web tools for searching biomedical literature</article-title>. <source>Database</source>, <volume>2011</volume>, <fpage>1</fpage>–<lpage>13</lpage>.</mixed-citation>
    </ref>
    <ref id="bax091-B8">
      <label>8</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Hua Xu</surname><given-names>J.S.G.</given-names></name>, <name name-style="western"><surname>Chen</surname><given-names>X.</given-names></name>, <name name-style="western"><surname>Liu</surname><given-names>R.</given-names></name></person-group><etal/> (<year>2016</year>) <article-title>DataMed by BioCADDIE–a data discovery index prototype to unleash biomedical research data</article-title>. <source>Sci. Data Con</source>.</mixed-citation>
    </ref>
    <ref id="bax091-B9">
      <label>9</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Roberts</surname><given-names>K.</given-names></name>, <name name-style="western"><surname>Gururaj</surname><given-names>A.E.</given-names></name>, <name name-style="western"><surname>Chen</surname><given-names>X.</given-names></name></person-group><etal/> (<year>2017</year>) <article-title>Information retrieval for biomedical datasets: the 2016 bioCADDIE dataset retrieval challenge</article-title>. <source>Database</source>, <volume>2017</volume>, <fpage>1</fpage>–<lpage>9</lpage>.</mixed-citation>
    </ref>
    <ref id="bax091-B10">
      <label>10</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Croft</surname><given-names>W.B.</given-names></name>, <name name-style="western"><surname>Metzler</surname><given-names>D.</given-names></name>, <name name-style="western"><surname>Strohman</surname><given-names>T.</given-names></name></person-group> (<year>2009</year>) Search engines: information retrieval in practice. Addison-Wesley Publishing Company, Lebanon.</mixed-citation>
    </ref>
    <ref id="bax091-B11">
      <label>11</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Salton</surname><given-names>G.</given-names></name></person-group> (<year>1968</year>) Automatic information organization and retrieval. McGraw Hill Text, New York.</mixed-citation>
    </ref>
    <ref id="bax091-B12">
      <label>12</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Salton</surname><given-names>G.</given-names></name>, <name name-style="western"><surname>McGill</surname><given-names>M.J.</given-names></name></person-group> (<year>1983</year>) Introduction to modern information retrieval. MuGraw-Hill, Auckland.</mixed-citation>
    </ref>
    <ref id="bax091-B13">
      <label>13</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Turney</surname><given-names>P.D.</given-names></name>, <name name-style="western"><surname>Pantel</surname><given-names>P.</given-names></name></person-group> (<year>2010</year>) <article-title>From frequency to meaning: vector space models of semantics</article-title>. <source>J. Artif. Intel. Res</source>., <volume>37</volume>, <fpage>141</fpage>–<lpage>188</lpage>.</mixed-citation>
    </ref>
    <ref id="bax091-B14">
      <label>14</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Deerwester</surname><given-names>S.</given-names></name>, <name name-style="western"><surname>Dumais</surname><given-names>S.T.</given-names></name>, <name name-style="western"><surname>Furnas</surname><given-names>G.W.</given-names></name></person-group><etal/> (<year>1990</year>) <article-title>Indexing by latent semantic analysis</article-title>. <source>J. Am. Soc. Inform. Sci</source>., <volume>41</volume>, <fpage>391</fpage>.</mixed-citation>
    </ref>
    <ref id="bax091-B15">
      <label>15</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Hofmann</surname><given-names>T.</given-names></name></person-group> (<year>1999</year>) Probabilistic latent semantic analysis. In: <italic>Proceedings of the 15th Conference on Uncertainty in Artificial Intelligence</italic> Morgan Kaufmann Publishers, Stockholm, Sweden, pp. <fpage>289</fpage>–<lpage>296</lpage>.</mixed-citation>
    </ref>
    <ref id="bax091-B16">
      <label>16</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Wang</surname><given-names>Y.</given-names></name>, <name name-style="western"><surname>Lee</surname><given-names>J.S.</given-names></name>, <name name-style="western"><surname>Choi</surname><given-names>I.C.</given-names></name></person-group> (<year>2016</year>) <article-title>Indexing by latent dirichlet allocation and an ensemble model</article-title>. <source>J. Assoc. Inform. Sci. Technol</source>., <volume>67</volume>, <fpage>1736</fpage>–<lpage>1750</lpage>.</mixed-citation>
    </ref>
    <ref id="bax091-B17">
      <label>17</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Blei</surname><given-names>D.M.</given-names></name>, <name name-style="western"><surname>Ng</surname><given-names>A.Y.</given-names></name>, <name name-style="western"><surname>Jordan</surname><given-names>M.I.</given-names></name></person-group> (<year>2003</year>) <article-title>Latent dirichlet allocation</article-title>. <source>J. Machine Learn. Res</source>., <volume>3</volume>, <fpage>993</fpage>–<lpage>1022</lpage>.</mixed-citation>
    </ref>
    <ref id="bax091-B18">
      <label>18</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Metzler</surname><given-names>D.</given-names></name>, <name name-style="western"><surname>Croft</surname><given-names>W.B.</given-names></name></person-group> (<year>2005</year>) <article-title>A Markov random field model for term dependencies. In: <italic>Proceedings of the 28th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</italic></article-title>. ACM, Salvador, Brazil, pp. <fpage>472</fpage>–<lpage>479</lpage>.</mixed-citation>
    </ref>
    <ref id="bax091-B19">
      <label>19</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Metzler</surname><given-names>D.</given-names></name>, <name name-style="western"><surname>Croft</surname><given-names>W.B.</given-names></name></person-group> (<year>2007</year>) Latent concept expansion using markov random fields. In: <italic>Proceedings of the 30th annual international ACM SIGIR conference on Research and development in information retrieval</italic> ACM, Amsterdam, Netherlands, pp. <fpage>311</fpage>–<lpage>318</lpage>.</mixed-citation>
    </ref>
    <ref id="bax091-B20">
      <label>20</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Wang</surname><given-names>Y.</given-names></name>, <name name-style="western"><surname>Wu</surname><given-names>S.</given-names></name>, <name name-style="western"><surname>Li</surname><given-names>D.</given-names></name></person-group><etal/> (<year>2016</year>) <article-title>A Part-Of-Speech term weighting scheme for biomedical information retrieval</article-title>. <source>J. Biomed. Inform</source>., <volume>63</volume>, <fpage>379</fpage>–<lpage>389</lpage>.<pub-id pub-id-type="pmid">27593166</pub-id></mixed-citation>
    </ref>
    <ref id="bax091-B21">
      <label>21</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Wang</surname><given-names>Y.</given-names></name>, <name name-style="western"><surname>Wu</surname><given-names>S.T.</given-names></name>, <name name-style="western"><surname>Liu</surname><given-names>H.</given-names></name></person-group> (<year>2016</year>) MayoNLPTeam at the 2016 CLEF eHealth information retrieval task 1. In: <source>Proceedings of the Conference and Labs of the Evaluation Forum (CLEF)</source>. Évora, Portugal, pp. <fpage>198</fpage>–<lpage>204</lpage>.</mixed-citation>
    </ref>
    <ref id="bax091-B22">
      <label>22</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Manning</surname><given-names>C.D.</given-names></name>, <name name-style="western"><surname>Raghavan</surname><given-names>P.</given-names></name>, <name name-style="western"><surname>Schütze</surname><given-names>H.</given-names></name></person-group> (<year>2008</year>) <source>Introduction to Information Retrieval</source>. <publisher-name>Cambridge University Press</publisher-name>, <publisher-loc>Cambridge</publisher-loc>.</mixed-citation>
    </ref>
    <ref id="bax091-B23">
      <label>23</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Xu</surname><given-names>J.</given-names></name>, <name name-style="western"><surname>Croft</surname><given-names>W.B.</given-names></name></person-group> (<year>1996</year>) Query expansion using local and global document analysis. In: <italic>Proceedings of the 19th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval.</italic> ACM, Zurich, Switzerland, pp. <fpage>4</fpage>–<lpage>11</lpage>.</mixed-citation>
    </ref>
    <ref id="bax091-B24">
      <label>24</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Andrzejewski</surname><given-names>D.</given-names></name>, <name name-style="western"><surname>Buttler</surname><given-names>D.</given-names></name></person-group> (<year>2011</year>) Latent topic feedback for information retrieval. In: <italic>Proceedings of the 17th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</italic> ACM, Dublin, Ireland, pp. <fpage>600</fpage>–<lpage>608</lpage>.</mixed-citation>
    </ref>
    <ref id="bax091-B25">
      <label>25</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Mikolov</surname><given-names>T.</given-names></name>, <name name-style="western"><surname>Chen</surname><given-names>K.</given-names></name>, <name name-style="western"><surname>Corrado</surname><given-names>G.</given-names></name></person-group><etal/> (<year>2013</year>) Efficient estimation of word representations in vector space. <italic>arXiv preprint arXiv</italic>: <italic>1301.3781</italic>.</mixed-citation>
    </ref>
    <ref id="bax091-B26">
      <label>26</label>
      <mixed-citation publication-type="other">Roberts,K., Demner-Fushman,D., Voorhees,E. <italic>et al.</italic> (<year>2016</year>) Overview of the TREC 2016 clinical decision support track. In: <source>Proceedings of the 2016 Text Retrieval Conference</source>. Gaithersburg, Maryland, USA.</mixed-citation>
    </ref>
    <ref id="bax091-B27">
      <label>27</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Zhang</surname><given-names>H.</given-names></name>, <name name-style="western"><surname>Liu</surname><given-names>L.</given-names></name></person-group> (<year>2016</year>) <article-title>NKU at TREC 2016: Clinical Decision Support Track. </article-title>. In: <source>Proceedings of the 2016 Text Retrieval Conference</source>. Gaithersburg, Maryland, USA.</mixed-citation>
    </ref>
    <ref id="bax091-B28">
      <label>28</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Greuter,S</surname><given-names>Junker,P.</given-names></name>, <name name-style="western"><surname>Kuhn</surname><given-names>L.</given-names></name></person-group><etal/> (<year>2016</year>) <article-title>ETH Zurich at TREC clinical decision support 2016</article-title>. In: <source>Proceedings of the 2016 Text Retrieval Conference</source>. Gaithersburg, Maryland, USA.</mixed-citation>
    </ref>
    <ref id="bax091-B29">
      <label>29</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Gurulingappa</surname><given-names>H.</given-names></name>, <name name-style="western"><surname>Toldo</surname><given-names>L.</given-names></name>, <name name-style="western"><surname>Schepers</surname><given-names>C.</given-names></name></person-group><etal/> (<year>2016</year>) <article-title>Semi-supervised information retrieval system for clinical decision support</article-title>. In: <source>Proceedings of the 2016 Text Retrieval Conference</source>. Gaithersburg, Maryland, USA.</mixed-citation>
    </ref>
    <ref id="bax091-B30">
      <label>30</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Diaz</surname><given-names>F.</given-names></name>, <name name-style="western"><surname>Mitra</surname><given-names>B.</given-names></name>, <name name-style="western"><surname>Craswell</surname><given-names>N.</given-names></name></person-group> (<year>2016</year>) <article-title>Query expansion with locally-trained word embeddings</article-title>. In: <source>Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</source>. Berlin, Germany, pp.<fpage>367</fpage>–<lpage>377</lpage>.</mixed-citation>
    </ref>
    <ref id="bax091-B31">
      <label>31</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Robertson</surname><given-names>S.E.</given-names></name>, <name name-style="western"><surname>Walker</surname><given-names>S.</given-names></name>, <name name-style="western"><surname>Jones</surname><given-names>S.</given-names></name></person-group><etal/> (<year>1995</year>) <article-title>Okapi at TREC-3</article-title>. <source>Nist. Special Publ. Sp</source>., <volume>109</volume>, <fpage>109</fpage>.</mixed-citation>
    </ref>
    <ref id="bax091-B32">
      <label>32</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Zhai</surname><given-names>C.</given-names></name>, <name name-style="western"><surname>Lafferty</surname><given-names>J.</given-names></name></person-group> (<year>2001</year>) Model-based feedback in the language modeling approach to information retrieval. In: <italic>Proceedings of the 10th International Conference on Information and Knowledge Management</italic> ACM, Atlanta, GA, USA, pp. <fpage>403</fpage>–<lpage>410</lpage>.</mixed-citation>
    </ref>
    <ref id="bax091-B33">
      <label>33</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Zhai</surname><given-names>C.</given-names></name>, <name name-style="western"><surname>Lafferty</surname><given-names>J.</given-names></name></person-group> (<year>2001</year>) A study of smoothing methods for language models applied to ad hoc information retrieval. In: <italic>Proceedings of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</italic> ACM, New Orleans, LA, USA, pp. <fpage>334</fpage>–<lpage>342</lpage>.</mixed-citation>
    </ref>
    <ref id="bax091-B34">
      <label>34</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Roberts</surname><given-names>K.</given-names></name>, <name name-style="western"><surname>Simpson</surname><given-names>M.</given-names></name>, <name name-style="western"><surname>Demner-Fushman</surname><given-names>D.</given-names></name></person-group><etal/> (<year>2016</year>) <article-title>State-of-the-art in biomedical literature retrieval for clinical cases: a survey of the TREC 2014 CDS track</article-title>. <source>Inform. Retrieval J</source>., <volume>19</volume>, <fpage>113</fpage>–<lpage>148</lpage>.</mixed-citation>
    </ref>
    <ref id="bax091-B35">
      <label>35</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Lindberg</surname><given-names>D.A.</given-names></name>, <name name-style="western"><surname>Humphreys</surname><given-names>B.L.</given-names></name>, <name name-style="western"><surname>McCray</surname><given-names>A.T.</given-names></name></person-group> (<year>1993</year>) <article-title>The unified medical language system</article-title>. <source>IMIA Yearbook</source>, <fpage>41</fpage>–<lpage>51</lpage>.<pub-id pub-id-type="pmid">27668467</pub-id></mixed-citation>
    </ref>
    <ref id="bax091-B36">
      <label>36</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Humphreys</surname><given-names>B.L.</given-names></name>, <name name-style="western"><surname>Lindberg</surname><given-names>D.A.</given-names></name>, <name name-style="western"><surname>Schoolman</surname><given-names>H.M.</given-names></name></person-group><etal/> (<year>1998</year>) <article-title>The unified medical language system</article-title>. <source>J. Am. Med. Inf. Assoc</source>., <volume>5</volume>, <fpage>1</fpage>–<lpage>11</lpage>.</mixed-citation>
    </ref>
    <ref id="bax091-B37">
      <label>37</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Campbell</surname><given-names>K.E.</given-names></name>, <name name-style="western"><surname>Oliver</surname><given-names>D.E.</given-names></name>, <name name-style="western"><surname>Shortliffe</surname><given-names>E.H.</given-names></name></person-group> (<year>1998</year>) <article-title>The unified medical language system</article-title>. <source>J. Am. Med. Inf. Assoc</source>., <volume>5</volume>, <fpage>12</fpage>–<lpage>16</lpage>.</mixed-citation>
    </ref>
    <ref id="bax091-B38">
      <label>38</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>George Drosatos</surname><given-names>S.R.</given-names></name>, <name name-style="western"><surname>Arampatzis</surname><given-names>A.</given-names></name>, <name name-style="western"><surname>Kaldoudi</surname><given-names>E.</given-names></name></person-group> (<year>2015</year>) <article-title>DUTH at TREC 2015 clinical decision support track</article-title>. In: <source>Proceedings of the 2015 Text Retrieval Conference</source>. Gaithersburg, Maryland, USA.</mixed-citation>
    </ref>
    <ref id="bax091-B39">
      <label>39</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Lipscomb</surname><given-names>C.E.</given-names></name></person-group> (<year>2000</year>) <article-title>Medical subject headings (MeSH)</article-title>. <source>Bull. Med. Lib. Assoc</source>., <volume>88</volume>, <fpage>265.</fpage><pub-id pub-id-type="pmid">10928714</pub-id></mixed-citation>
    </ref>
    <ref id="bax091-B40">
      <label>40</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Mourao</surname><given-names>A.</given-names></name>, <name name-style="western"><surname>Martins</surname><given-names>F.</given-names></name>, <name name-style="western"><surname>Magalhaes</surname><given-names>J.</given-names></name></person-group> (<year>2015</year>) <article-title>NovaSearch at TREC 2015 clinical decision support track</article-title>. In: <italic>Proceedings of the 2015 Text Retrieval Conference</italic>. Gaithersburg, Maryland, USA.</mixed-citation>
    </ref>
    <ref id="bax091-B41">
      <label>41</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Giannis Nikolentzos</surname><given-names>P.M.</given-names></name>, <name name-style="western"><surname>Liakis</surname><given-names>N.</given-names></name>, <name name-style="western"><surname>Vazirgiannis</surname><given-names>M.</given-names></name></person-group> (<year>2015</year>) <article-title>AUEB at TREC 2015: clinical decision support track</article-title>. In: <source>Proceedings of the 2015 Text Retrieval Conference</source>. Gaithersburg, Maryland, USA.</mixed-citation>
    </ref>
    <ref id="bax091-B42">
      <label>42</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Wei</surname><given-names>C.-H.</given-names></name>, <name name-style="western"><surname>Kao</surname><given-names>H.-Y.</given-names></name>, <name name-style="western"><surname>Lu</surname><given-names>Z.</given-names></name></person-group> (<year>2013</year>) <article-title>PubTator: a web-based text mining tool for assisting biocuration</article-title>. <source>Nucleic Acids Res</source>., <volume>41</volume>, <fpage>W518.</fpage><pub-id pub-id-type="pmid">23703206</pub-id></mixed-citation>
    </ref>
    <ref id="bax091-B43">
      <label>43</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Nunes</surname><given-names>T.</given-names></name>, <name name-style="western"><surname>Campos</surname><given-names>D.</given-names></name>, <name name-style="western"><surname>Matos</surname><given-names>S.</given-names></name></person-group><etal/> (<year>2013</year>) <article-title>BeCAS: biomedical concept recognition services and visualization</article-title>. <source>Bioinformatics</source>, <volume>29</volume>, <fpage>1915</fpage>–<lpage>1916</lpage>.<pub-id pub-id-type="doi">10.1093/bioinformatics/btt317</pub-id><pub-id pub-id-type="pmid">23736528</pub-id></mixed-citation>
    </ref>
    <ref id="bax091-B44">
      <label>44</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Maglott</surname><given-names>D.</given-names></name>, <name name-style="western"><surname>Ostell</surname><given-names>J.</given-names></name>, <name name-style="western"><surname>Pruitt</surname><given-names>K.D.</given-names></name></person-group><etal/> (<year>2005</year>) <article-title>Entrez Gene: gene-centered information at NCBI</article-title>. <source>Nucleic Acids Res</source>., <volume>33</volume>, <fpage>D54</fpage>–<lpage>D58</lpage>.<pub-id pub-id-type="pmid">15608257</pub-id></mixed-citation>
    </ref>
    <ref id="bax091-B45">
      <label>45</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Apweiler</surname><given-names>R.</given-names></name>, <name name-style="western"><surname>Bairoch</surname><given-names>A.</given-names></name>, <name name-style="western"><surname>Wu</surname><given-names>C.H.</given-names></name></person-group><etal/> (<year>2004</year>) <article-title>UniProt: the universal protein knowledgebase</article-title>. <source>Nucleic Acids Res</source>., <volume>32</volume>, <fpage>D115</fpage>–<lpage>D119</lpage>.<pub-id pub-id-type="pmid">14681372</pub-id></mixed-citation>
    </ref>
    <ref id="bax091-B46">
      <label>46</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Ashburner</surname><given-names>M.</given-names></name>, <name name-style="western"><surname>Ball</surname><given-names>C.A.</given-names></name>, <name name-style="western"><surname>Blake</surname><given-names>J.A.</given-names></name></person-group><etal/> (<year>2000</year>) <article-title>Gene Ontology: tool for the unification of biology</article-title>. <source>Nat. Genet</source>., <volume>25</volume>, <fpage>25</fpage>–<lpage>29</lpage>.<pub-id pub-id-type="pmid">10802651</pub-id></mixed-citation>
    </ref>
    <ref id="bax091-B47">
      <label>47</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Mattingly</surname><given-names>C.J.</given-names></name>, <name name-style="western"><surname>Colby</surname><given-names>G.T.</given-names></name>, <name name-style="western"><surname>Forrest</surname><given-names>J.N.</given-names></name></person-group><etal/> (<year>2003</year>) <article-title>The comparative toxicogenomics database (CTD)</article-title>. <source>Environ. Health Perspect</source>., <volume>111</volume>, <fpage>793.</fpage><pub-id pub-id-type="pmid">12760826</pub-id></mixed-citation>
    </ref>
    <ref id="bax091-B48">
      <label>48</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Ravikumar</surname><given-names>K.E.</given-names></name>, <name name-style="western"><surname>Rastegar-Mojarad</surname><given-names>M.</given-names></name>, <name name-style="western"><surname>Liu</surname><given-names>H.</given-names></name></person-group> (<year>2017</year>) <article-title>BELMiner: adapting a rule-based relation extraction system to extract biological expression language statements from bio-medical literature evidence sentences</article-title>. <source>Database</source>, <volume>2017</volume>, <fpage>1</fpage>–<lpage>12</lpage>.</mixed-citation>
    </ref>
    <ref id="bax091-B49">
      <label>49</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Mikolov</surname><given-names>T.</given-names></name>, <name name-style="western"><surname>Sutskever</surname><given-names>I.</given-names></name>, <name name-style="western"><surname>Chen</surname><given-names>K.</given-names></name></person-group><etal/> (<year>2013</year>) <article-title>Distributed representations of words and phrases and their compositionality</article-title>. <source>Adv. Neural Inf. Process. Syst</source>., Lake Tahoe, USA. pp. <fpage>3111</fpage>–<lpage>3119</lpage>.</mixed-citation>
    </ref>
    <ref id="bax091-B50">
      <label>50</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Palotti</surname><given-names>J.</given-names></name>, <name name-style="western"><surname>Hanbury</surname><given-names>A.</given-names></name></person-group> (<year>2015</year>) TUW @ TREC clinical decision support track 2015. In: <source>Proceedings of the 2015 Text Retrieval Conference</source>. Gaithersburg, Maryland, USA.</mixed-citation>
    </ref>
    <ref id="bax091-B51">
      <label>51</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Cohen</surname><given-names>T.</given-names></name>, <name name-style="western"><surname>Roberts</surname><given-names>K.</given-names></name>, <name name-style="western"><surname>Gururaj</surname><given-names>A.E.</given-names></name></person-group><etal/> (<year>2017</year>) A publicly available benchmark for biomedical dataset retrieval: the reference standard for the 2016 bioCADDIE dataset retrieval challenge. <italic>Database</italic>, <volume>2017</volume>, <fpage>1</fpage>–<lpage>10</lpage>.</mixed-citation>
    </ref>
    <ref id="bax091-B52">
      <label>52</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Yilmaz</surname><given-names>E.</given-names></name>, <name name-style="western"><surname>Kanoulas</surname><given-names>E.</given-names></name>, <name name-style="western"><surname>Aslam</surname><given-names>J.A.</given-names></name></person-group> (<year>2008</year>) A simple and efficient sampling method for estimating AP and NDCG. In: <italic>Proceedings of the 31st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</italic> ACM, Singapore, pp. <fpage>603</fpage>–<lpage>610</lpage>.</mixed-citation>
    </ref>
    <ref id="bax091-B53">
      <label>53</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Bouadjenek</surname><given-names>M.R.</given-names></name>, <name name-style="western"><surname>Verspoor</surname><given-names>K.</given-names></name></person-group> (<year>2017</year>) <article-title>Multi-field query expansion is effective for biomedical dataset retrieval</article-title>. <source>Database</source>, <volume>2017</volume>, <fpage>1</fpage>–<lpage>20</lpage>.</mixed-citation>
    </ref>
    <ref id="bax091-B54">
      <label>54</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Wang</surname><given-names>Y.</given-names></name>, <name name-style="western"><surname>Rastegar-Mojarad</surname><given-names>M.</given-names></name>, <name name-style="western"><surname>Komandur-Elayavilli</surname><given-names>R.</given-names></name></person-group><etal/> (<year>2016</year>) MayoNLPTeam at TREC 2016 clinical decision support track: an ensemble approach of clinical information extraction and retrieval. In: <italic>Proceedings of the 2016 Text Retrieval Conference.</italic> Gaithersburg, Maryland, USA.</mixed-citation>
    </ref>
    <ref id="bax091-B55">
      <label>55</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Scerri</surname><given-names>A.</given-names></name>, <name name-style="western"><surname>Kuriakose</surname><given-names>J.</given-names></name>, <name name-style="western"><surname>Deshmane</surname><given-names>A.A.</given-names></name></person-group><etal/> (<year>2017</year>) <article-title>Elsevier’s approach to the bioCADDIE 2016 dataset retrieval challenge</article-title>. <source>Database</source>, <volume>2017</volume>, <fpage>1</fpage>–<lpage>12</lpage>.</mixed-citation>
    </ref>
  </ref-list>
</back>
