<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">BMC Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">BMC Bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>BMC Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1471-2105</issn>
    <publisher>
      <publisher-name>BioMed Central</publisher-name>
      <publisher-loc>London</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">9158227</article-id>
    <article-id pub-id-type="publisher-id">4740</article-id>
    <article-id pub-id-type="doi">10.1186/s12859-022-04740-9</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Research</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Fitting Gaussian mixture models on incomplete data</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>McCaw</surname>
          <given-names>Zachary R.</given-names>
        </name>
        <address>
          <email>zmccaw@alumni.harvard.edu</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Aschard</surname>
          <given-names>Hugues</given-names>
        </name>
        <address>
          <email>hugues.aschard@pasteur.fr</email>
        </address>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Julienne</surname>
          <given-names>Hanna</given-names>
        </name>
        <address>
          <email>hanna.julienne@pasteur.fr</email>
        </address>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="GRID">grid.189504.1</institution-id><institution-id institution-id-type="ISNI">0000 0004 1936 7558</institution-id><institution>School of Public Health, </institution><institution>Harvard T.H. Chan, </institution></institution-wrap>677 Huntington Ave, Boston, MA 02115 USA </aff>
      <aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="GRID">grid.508487.6</institution-id><institution-id institution-id-type="ISNI">0000 0004 7885 7602</institution-id><institution>Department of Computational Biology, Institut Pasteur, </institution><institution>Université de Paris, </institution></institution-wrap>25-28 Rue du Dr Roux, 75015 Paris, France </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>1</day>
      <month>6</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>1</day>
      <month>6</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2022</year>
    </pub-date>
    <volume>23</volume>
    <elocation-id>208</elocation-id>
    <history>
      <date date-type="received">
        <day>27</day>
        <month>10</month>
        <year>2021</year>
      </date>
      <date date-type="accepted">
        <day>16</day>
        <month>5</month>
        <year>2022</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2022</copyright-statement>
      <license>
        <ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p><bold>Open Access</bold>This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>. The Creative Commons Public Domain Dedication waiver (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/publicdomain/zero/1.0/">http://creativecommons.org/publicdomain/zero/1.0/</ext-link>) applies to the data made available in this article, unless otherwise stated in a credit line to the data.</license-p>
      </license>
    </permissions>
    <abstract id="Abs1">
      <sec>
        <title>Background</title>
        <p id="Par1">Bioinformatics investigators often gain insights by combining information across multiple and disparate data sets. Merging data from multiple sources frequently results in data sets that are incomplete or contain missing values. Although missing data are ubiquitous, existing implementations of Gaussian mixture models (GMMs) either cannot accommodate missing data, or do so by imposing simplifying assumptions that limit the applicability of the model. In the presence of missing data, a standard <italic>ad hoc</italic> practice is to perform complete case analysis or imputation prior to model fitting. Both approaches have serious drawbacks, potentially resulting in biased and unstable parameter estimates.</p>
      </sec>
      <sec>
        <title>Results</title>
        <p id="Par2">Here we present missingness-aware Gaussian mixture models (MGMM), an R package for fitting GMMs in the presence of missing data. Unlike existing GMM implementations that can accommodate missing data, MGMM places no restrictions on the form of the covariance matrix. Using three case studies on real and simulated <italic>’omics</italic> data sets, we demonstrate that, when the underlying data distribution is near-to a GMM, MGMM is more effective at recovering the true cluster assignments than either the existing GMM implementations that accommodate missing data, or fitting a standard GMM after state of the art imputation. Moreover, MGMM provides an accurate assessment of cluster assignment uncertainty, even when the generative distribution is not a GMM.</p>
      </sec>
      <sec>
        <title>Conclusion</title>
        <p id="Par3">Compared to state-of-the-art competitors, MGMM demonstrates a better ability to recover the true cluster assignments for a wide variety of data sets and a large range of missingness rates. MGMM provides the bioinformatics community with a powerful, easy-to-use, and statistically sound tool for performing clustering and density estimation in the presence of missing data. MGMM is publicly available as an R package on CRAN: <ext-link ext-link-type="uri" xlink:href="https://CRAN.R-project.org/package=MGMM">https://CRAN.R-project.org/package=MGMM</ext-link>.</p>
      </sec>
      <sec>
        <title>Supplementary Information</title>
        <p>The online version contains supplementary material available at 10.1186/s12859-022-04740-9.</p>
      </sec>
    </abstract>
    <kwd-group xml:lang="en">
      <title>Keywords</title>
      <kwd>Clustering</kwd>
      <kwd>Missing data</kwd>
      <kwd>Gaussian mixture models</kwd>
    </kwd-group>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>© The Author(s) 2022</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="Sec1">
    <title>Background</title>
    <p id="Par4">Gaussian mixture models (GMMs) provide a flexible approach to multivariate density estimation and probabilistic clustering [<xref ref-type="bibr" rid="CR1">1</xref>]. Most implementations of GMMs in the R programming language, including mclust [<xref ref-type="bibr" rid="CR2">2</xref>] and mixtools [<xref ref-type="bibr" rid="CR3">3</xref>], require complete data. The few implementations that do allow for missing values, such as MixAll [<xref ref-type="bibr" rid="CR4">4</xref>], have limited applicability due to their restrictive simplifying assumptions. For example, MixAll assumes diagonal covariance matrices, which implies that the elements of the Gaussian vectors under consideration are mutually independent. In practice, both correlated and missing data are common. Our work was motivated by the problem of clustering summary statistics arising from genome-wide association studies (GWAS) of multiple correlated traits [<xref ref-type="bibr" rid="CR5">5</xref>]. Missing data arose because not every genetic variant was tested for association with every trait.</p>
    <p id="Par5">Although commonly applied, standard approaches for addressing missing data prior to clustering, including complete case analysis and imputation, have serious drawbacks. By discarding information from observations that are only partially observed, complete case analysis makes inefficient use of the data. This leads to unstable estimates of model parameters and cluster assignments that are susceptible to significant changes if the missingness pattern of the input data changes slightly. On the other hand, mean or median imputation introduces bias by making the incomplete observations appear less variable, and by shrinking the incomplete observations towards the complete data. This can result in inaccurate posterior membership probabilities that place excess weight on clusters with less missing data. Although a method has been described for estimating GMMs from incomplete data [<xref ref-type="bibr" rid="CR6">6</xref>], there are no existing implementations in R.</p>
    <p id="Par6">To fill this gap, we present MGMM [<xref ref-type="bibr" rid="CR7">7</xref>], a computationally efficient R package for maximum likelihood estimation of GMMs in the presence of missing data. Our package is carefully implemented and documented for ease of use. In contrast to complete case analysis, our approach makes full use of the available data; and in contrast to clustering after imputation, our approach is unbiased for estimating the parameters of the generative GMM, accurately assesses the posterior membership probabilities, and correctly propagates estimation uncertainty. Moreover, our implementation places no restrictions on the model’s covariance structures.</p>
    <p id="Par7">MGMM employs an expectation conditional maximization (ECM) algorithm [<xref ref-type="bibr" rid="CR8">8</xref>], which accelerates estimation by breaking direct maximization of the EM objective function into a sequence of simpler conditional maximizations, each of which is available in closed form. While EM algorithms are regularly used for estimating GMMs, for example by both mclust and mixtools, those implementations only address missingness of the true cluster assignments, and not missingness of elements from the input vectors. In contrast, our ECM algorithm handles both missingness of the cluster assignments and of elements from the input data. We present a comprehensive benchmark, including three case studies, demonstrating that when the underlying distribution is well-approximated by a GMM, MGMM is better able to recover the true cluster assignments than MixAll or than standard GMM applied after state of the art imputation (e.g. multiple imputation by chained equations, MICE [<xref ref-type="bibr" rid="CR9">9</xref>]). While we prioritized cluster assignments accuracy, our implementation also proves competitive in regard to running time for the missingness rates usually encountered in real data.</p>
  </sec>
  <sec id="Sec2">
    <title>Methods</title>
    <sec id="Sec3">
      <title>Model</title>
      <p id="Par8">This section provides an overview of the statistical model. For a detailed derivation and description of the ECM algorithm, see the Supporting Information.</p>
      <sec id="Sec4">
        <title>Statistical model overview</title>
        <p id="Par9">Consider <italic>n</italic> independent vectors <inline-formula id="IEq1"><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\varvec{y}}_{i}=\text {vec}(Y_{i1},\ldots ,Y_{id})$$\end{document}</tex-math><mml:math id="M2"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mtext>vec</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>Y</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>Y</mml:mi><mml:mrow><mml:mi mathvariant="italic">id</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4740_Article_IEq1.gif"/></alternatives></inline-formula> in <inline-formula id="IEq2"><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbb {R}}^{d}$$\end{document}</tex-math><mml:math id="M4"><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mi>d</mml:mi></mml:msup></mml:math><inline-graphic xlink:href="12859_2022_4740_Article_IEq2.gif"/></alternatives></inline-formula>, each arising from one of <italic>k</italic> distinct clusters. Although <italic>k</italic> is assumed known throughout this work, see "<xref rid="Sec2" ref-type="sec">Methods</xref>" section of the Supporting Information for an approach to choosing <italic>k</italic>. Let <inline-formula id="IEq3"><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Z_{ij}=1$$\end{document}</tex-math><mml:math id="M6"><mml:mrow><mml:msub><mml:mi>Z</mml:mi><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4740_Article_IEq3.gif"/></alternatives></inline-formula> if the <italic>i</italic>th observation belongs to cluster <italic>j</italic>, and define the <inline-formula id="IEq4"><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$k\times 1$$\end{document}</tex-math><mml:math id="M8"><mml:mrow><mml:mi>k</mml:mi><mml:mo>×</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4740_Article_IEq4.gif"/></alternatives></inline-formula> indicator vector <inline-formula id="IEq5"><alternatives><tex-math id="M9">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\varvec{z}}_{i}=\text {vec}(Z_{i1},\ldots ,Z_{ik})$$\end{document}</tex-math><mml:math id="M10"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">z</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mtext>vec</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>Z</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>Z</mml:mi><mml:mrow><mml:mi mathvariant="italic">ik</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4740_Article_IEq5.gif"/></alternatives></inline-formula>. Conditional on membership to the <italic>j</italic>th cluster, <inline-formula id="IEq6"><alternatives><tex-math id="M11">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\varvec{y}}_{i}$$\end{document}</tex-math><mml:math id="M12"><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_4740_Article_IEq6.gif"/></alternatives></inline-formula> follows a multivariate normal distribution, with cluster-specific mean <inline-formula id="IEq7"><alternatives><tex-math id="M13">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\varvec{\mu }}_{j}$$\end{document}</tex-math><mml:math id="M14"><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">μ</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_4740_Article_IEq7.gif"/></alternatives></inline-formula> and covariance <inline-formula id="IEq8"><alternatives><tex-math id="M15">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\varvec{\Sigma }}_{j}$$\end{document}</tex-math><mml:math id="M16"><mml:msub><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_4740_Article_IEq8.gif"/></alternatives></inline-formula>. Let <inline-formula id="IEq9"><alternatives><tex-math id="M17">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\pi _{j}$$\end{document}</tex-math><mml:math id="M18"><mml:msub><mml:mi>π</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_4740_Article_IEq9.gif"/></alternatives></inline-formula> denote the marginal probability of membership to the <italic>j</italic>th cluster. The observations can be viewed as arising from the following hierarchical model:<disp-formula id="Equ1"><label>1</label><alternatives><tex-math id="M19">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} \begin{aligned} {\varvec{z}}_{i} \sim \text {Multinomial}(1,{\varvec{\pi }}), \\ {\varvec{y}}_{i}\big |(Z_{ij}=1) \sim N\big ({\varvec{\mu }}_{j},{\varvec{\Sigma }}_{j}\big ). \end{aligned} \end{aligned}$$\end{document}</tex-math><mml:math id="M20" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">z</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>∼</mml:mo><mml:mtext>Multinomial</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">π</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mrow/><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em" stretchy="true">|</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>Z</mml:mi><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>∼</mml:mo><mml:mi>N</mml:mi><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em" stretchy="true">(</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">μ</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em" stretchy="true">)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="12859_2022_4740_Article_Equ1.gif" position="anchor"/></alternatives></disp-formula>Marginalized over the latent cluster assignment vector <inline-formula id="IEq10"><alternatives><tex-math id="M21">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\varvec{z}}_{i}$$\end{document}</tex-math><mml:math id="M22"><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">z</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_4740_Article_IEq10.gif"/></alternatives></inline-formula>, each observation <inline-formula id="IEq11"><alternatives><tex-math id="M23">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\varvec{y}}_{i}$$\end{document}</tex-math><mml:math id="M24"><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_4740_Article_IEq11.gif"/></alternatives></inline-formula> follows a <italic>k</italic> component Gaussian mixture model (GMM):<disp-formula id="Equ2"><label>2</label><alternatives><tex-math id="M25">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} f({\varvec{y}}_{i}) = \sum _{j=1}^{k}\pi _{j}f\big ({\varvec{y}}_{i}|{\varvec{\mu }}_{j},{\varvec{\Sigma }}_{j}\big ). \end{aligned}$$\end{document}</tex-math><mml:math id="M26" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>f</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>k</mml:mi></mml:munderover><mml:msub><mml:mi>π</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em" stretchy="true">(</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">μ</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em" stretchy="true">)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="12859_2022_4740_Article_Equ2.gif" position="anchor"/></alternatives></disp-formula>To perform estimation in the presence of missingness, we derive the EM objective function <inline-formula id="IEq12"><alternatives><tex-math id="M27">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Q({\varvec{\pi }},{\varvec{\theta }}|{\varvec{\pi }}^{(r)},{\varvec{\theta }}^{(r)})$$\end{document}</tex-math><mml:math id="M28"><mml:mrow><mml:mi>Q</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">π</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">θ</mml:mi></mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">π</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">θ</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4740_Article_IEq12.gif"/></alternatives></inline-formula>, which is the expectation of the complete data log likelihood, given the observed data and current parameter estimates (see the Supporting Information for complete derivation). The EM objective is optimized using a sequence of three conditional maximizations. Let <inline-formula id="IEq13"><alternatives><tex-math id="M29">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\hat{\gamma }}_{ij}^{(r)}$$\end{document}</tex-math><mml:math id="M30"><mml:msubsup><mml:mover accent="true"><mml:mi>γ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2022_4740_Article_IEq13.gif"/></alternatives></inline-formula> denote the <italic>responsibility</italic> of the <italic>j</italic>th cluster for the <italic>i</italic>th observation, which is the current conditional probability of membership to that cluster, given the observed data. In the first step, the cluster means are updated using the responsibility-weighted average of the working outcome vectors <inline-formula id="IEq14"><alternatives><tex-math id="M31">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\hat{{\varvec{y}}}_{ij}^{(r)}$$\end{document}</tex-math><mml:math id="M32"><mml:msubsup><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2022_4740_Article_IEq14.gif"/></alternatives></inline-formula>. In the next step, the cluster covariances are updated using the responsibility-weighted average of the working residual outer products. In the final step, the cluster responsibilities and marginal membership probabilities are updated using the new means and covariances. This process iterates until the improvement in the EM objective drops below the specified tolerance. Unbiased estimation of the model parameters requires that missingnesss in the outcome vector occur at random [<xref ref-type="bibr" rid="CR10">10</xref>]. This means that whether a particular element of the outcome vector is missing can depend on the values of those elements that are observed, but not upon the values of those elements that are missing. See section 1.3 of the Supporting Information for further discussion of the missing at random assumption.</p>
      </sec>
      <sec id="Sec5">
        <title>Imputation</title>
        <p id="Par10">Having fit the GMM in (<xref rid="Equ2" ref-type="">2</xref>) via maximum likelihood, the missing values <inline-formula id="IEq15"><alternatives><tex-math id="M33">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\varvec{y}}_{i}^{\text {miss}}$$\end{document}</tex-math><mml:math id="M34"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mtext>miss</mml:mtext></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2022_4740_Article_IEq15.gif"/></alternatives></inline-formula> of each observation <inline-formula id="IEq16"><alternatives><tex-math id="M35">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\varvec{y}}_{i}$$\end{document}</tex-math><mml:math id="M36"><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_4740_Article_IEq16.gif"/></alternatives></inline-formula> may subsequently be imputed. Note that, in contrast to the imputation <italic>before</italic> estimation procedure commonly used to address missing input data, MGMM performs imputation only <italic>after</italic> estimation. In this way, imputation has no effect on the final maximum likelihood estimates <inline-formula id="IEq17"><alternatives><tex-math id="M37">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$(\hat{{\varvec{\pi }}},\hat{{\varvec{\theta }}})$$\end{document}</tex-math><mml:math id="M38"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold-italic">π</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold-italic">θ</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4740_Article_IEq17.gif"/></alternatives></inline-formula>. To perform a deterministic single imputation, as is done by the FitGMM function, <inline-formula id="IEq18"><alternatives><tex-math id="M39">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\hat{{\varvec{y}}}_{i}^{\text {miss}}$$\end{document}</tex-math><mml:math id="M40"><mml:msubsup><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mtext>miss</mml:mtext></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2022_4740_Article_IEq18.gif"/></alternatives></inline-formula> may be set to its posterior expectation given <inline-formula id="IEq19"><alternatives><tex-math id="M41">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\varvec{y}}_{i}^{\text {obs}}$$\end{document}</tex-math><mml:math id="M42"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mtext>obs</mml:mtext></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2022_4740_Article_IEq19.gif"/></alternatives></inline-formula>:<disp-formula id="Equ3"><label>3</label><alternatives><tex-math id="M43">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} \hat{{\varvec{y}}}_{i}^{\text {miss}}&amp;\equiv {\mathbb {E}}\left( {\varvec{y}}_{i}^{\text {miss}}|{\varvec{y}}_{i}^{\text {obs}};\hat{{\varvec{\pi }}}, \hat{{\varvec{\theta }}}\right) \\&amp;= {\mathbb {E}}\left\{ {\mathbb {E}}\left( {\varvec{y}}_{i}^{\text {miss}}|z_{ij}=1,{\varvec{y}}_{i}^{\text {obs}};\hat{{\varvec{\pi }}}, \hat{{\varvec{\theta }}}\right) \right\} \\&amp;= \sum _{j=1}^{k}\hat{{\varvec{y}}}_{ij}^{\text {miss}}{\hat{\gamma }}_{ij}. \end{aligned}$$\end{document}</tex-math><mml:math id="M44" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:msubsup><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mtext>miss</mml:mtext></mml:msubsup></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mo>≡</mml:mo><mml:mi mathvariant="double-struck">E</mml:mi><mml:mfenced close=")" open="("><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mtext>miss</mml:mtext></mml:msubsup><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mtext>obs</mml:mtext></mml:msubsup><mml:mo>;</mml:mo><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold-italic">π</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold-italic">θ</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mfenced></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right"><mml:mrow/></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo><mml:mi mathvariant="double-struck">E</mml:mi><mml:mfenced close="}" open="{"><mml:mi mathvariant="double-struck">E</mml:mi><mml:mfenced close=")" open="("><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mtext>miss</mml:mtext></mml:msubsup><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mtext>obs</mml:mtext></mml:msubsup><mml:mo>;</mml:mo><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold-italic">π</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold-italic">θ</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mfenced></mml:mfenced></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right"><mml:mrow/></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>k</mml:mi></mml:munderover><mml:msubsup><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow><mml:mtext>miss</mml:mtext></mml:msubsup><mml:msub><mml:mover accent="true"><mml:mi>γ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow></mml:msub><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="12859_2022_4740_Article_Equ3.gif" position="anchor"/></alternatives></disp-formula>Here <inline-formula id="IEq20"><alternatives><tex-math id="M45">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\hat{\gamma }}_{ij}$$\end{document}</tex-math><mml:math id="M46"><mml:msub><mml:mover accent="true"><mml:mi>γ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_4740_Article_IEq20.gif"/></alternatives></inline-formula> is the final responsibility of cluster <italic>j</italic> for observation <italic>i</italic>, and:<disp-formula id="Equ5"><alternatives><tex-math id="M47">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} \hat{{\varvec{y}}}_{ij}^{\text {miss}} = \hat{{\varvec{\mu }}}_{\text {miss},j} + \hat{{\varvec{\Sigma }}}_{\text {miss},\text {obs},j}\hat{{\varvec{\Sigma }}}_{\text {obs},j}^{-1}\left( {\varvec{y}}_{i}^{\text {obs}} - \hat{{\varvec{\mu }}}_{\text {obs},j}\right) . \end{aligned}$$\end{document}</tex-math><mml:math id="M48" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow><mml:mtext>miss</mml:mtext></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold-italic">μ</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mtext>miss</mml:mtext><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mtext>miss</mml:mtext><mml:mo>,</mml:mo><mml:mtext>obs</mml:mtext><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mtext>obs</mml:mtext><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mfenced close=")" open="("><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mtext>obs</mml:mtext></mml:msubsup><mml:mo>-</mml:mo><mml:msub><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold-italic">μ</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mtext>obs</mml:mtext><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mfenced><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="12859_2022_4740_Article_Equ5.gif" position="anchor"/></alternatives></disp-formula>While single imputation to the posterior expectation is useful for visualization, drawing inferences from singly-imputed data is generally invalid [<xref ref-type="bibr" rid="CR10">10</xref>]. For subsequent inference, a multiple imputation procedure is necessary, wherein multiple stochastic imputations of the input data are generated, analyzed in parallel, and the resulting estimates combined. To generate a single stochastic imputation of <inline-formula id="IEq21"><alternatives><tex-math id="M49">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\varvec{y}}_{i}^{\text {miss}}$$\end{document}</tex-math><mml:math id="M50"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mtext>miss</mml:mtext></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2022_4740_Article_IEq21.gif"/></alternatives></inline-formula>, as is done by the GenImputation function, the latent cluster membership <inline-formula id="IEq22"><alternatives><tex-math id="M51">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\varvec{z}}_{i}$$\end{document}</tex-math><mml:math id="M52"><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">z</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_4740_Article_IEq22.gif"/></alternatives></inline-formula> is first drawn from a multinomial distribution over <inline-formula id="IEq23"><alternatives><tex-math id="M53">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\hat{{\varvec{\gamma }}}_{i} = {\mathbb {P}}({\varvec{z}}_{i} | {\varvec{y}}_{i}^{\text {obs}}; \hat{{\varvec{\pi }}}, \hat{{\varvec{\theta }}})$$\end{document}</tex-math><mml:math id="M54"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold-italic">γ</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi mathvariant="double-struck">P</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">z</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">|</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mtext>obs</mml:mtext></mml:msubsup><mml:mo>;</mml:mo><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold-italic">π</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold-italic">θ</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4740_Article_IEq23.gif"/></alternatives></inline-formula>:<disp-formula id="Equ6"><alternatives><tex-math id="M55">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} {\varvec{z}}_{i} \sim \text {Multinomial}(1, \hat{{\varvec{\gamma }}}_{i}). \end{aligned}$$\end{document}</tex-math><mml:math id="M56" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">z</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>∼</mml:mo><mml:mtext>Multinomial</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold-italic">γ</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="12859_2022_4740_Article_Equ6.gif" position="anchor"/></alternatives></disp-formula>Given the cluster assignment, <inline-formula id="IEq24"><alternatives><tex-math id="M57">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Z_{ij} = 1$$\end{document}</tex-math><mml:math id="M58"><mml:mrow><mml:msub><mml:mi>Z</mml:mi><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4740_Article_IEq24.gif"/></alternatives></inline-formula>, the missing elements <inline-formula id="IEq25"><alternatives><tex-math id="M59">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\varvec{y}}_{i}^{\text {miss}}$$\end{document}</tex-math><mml:math id="M60"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mtext>miss</mml:mtext></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2022_4740_Article_IEq25.gif"/></alternatives></inline-formula> are drawn from a normal distribution with mean:<disp-formula id="Equ7"><alternatives><tex-math id="M61">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} {\mathbb {E}}\left( {\varvec{y}}_{i}^{\text {miss}} | {\varvec{y}}_{i}^{\text {obs}}, Z_{ij} = 1; \hat{{\varvec{\pi }}}, \hat{{\varvec{\theta }}}\right) = \hat{{\varvec{\mu }}}_{j}^{\text {miss}} + \hat{{\varvec{\Sigma }}}_{\text {miss},\text {obs},j}\hat{{\varvec{\Sigma }}}_{\text {obs},\text {obs},j}\left( {\varvec{y}}_{i}^{\text {obs}} - \hat{{\varvec{\mu }}}_{\text {obs},j}\right) \end{aligned}$$\end{document}</tex-math><mml:math id="M62" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi><mml:mfenced close=")" open="("><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mtext>miss</mml:mtext></mml:msubsup><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mtext>obs</mml:mtext></mml:msubsup><mml:mo>,</mml:mo><mml:msub><mml:mi>Z</mml:mi><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>;</mml:mo><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold-italic">π</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold-italic">θ</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mfenced><mml:mo>=</mml:mo><mml:msubsup><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold-italic">μ</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mtext>miss</mml:mtext></mml:msubsup><mml:mo>+</mml:mo><mml:msub><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mtext>miss</mml:mtext><mml:mo>,</mml:mo><mml:mtext>obs</mml:mtext><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mtext>obs</mml:mtext><mml:mo>,</mml:mo><mml:mtext>obs</mml:mtext><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mfenced close=")" open="("><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mtext>obs</mml:mtext></mml:msubsup><mml:mo>-</mml:mo><mml:msub><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold-italic">μ</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mtext>obs</mml:mtext><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mfenced></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="12859_2022_4740_Article_Equ7.gif" position="anchor"/></alternatives></disp-formula>and covariance:<disp-formula id="Equ8"><alternatives><tex-math id="M63">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} {\mathbb {V}}\left( {\varvec{y}}_{i}^{\text {miss}} | {\varvec{y}}_{i}^{\text {obs}}, Z_{ij} = 1; \hat{{\varvec{\pi }}}, \hat{{\varvec{\theta }}}\right) = \hat{{\varvec{\Sigma }}}_{\text {miss},\text {miss},j} - \hat{{\varvec{\Sigma }}}_{\text {miss}, \text {obs}, j} \hat{{\varvec{\Sigma }}}_{\text {obs}, \text {obs}, j}^{-1}\hat{{\varvec{\Sigma }}}_{\text {obs}, \text {miss}, j} \end{aligned}$$\end{document}</tex-math><mml:math id="M64" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi mathvariant="double-struck">V</mml:mi><mml:mfenced close=")" open="("><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mtext>miss</mml:mtext></mml:msubsup><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mtext>obs</mml:mtext></mml:msubsup><mml:mo>,</mml:mo><mml:msub><mml:mi>Z</mml:mi><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>;</mml:mo><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold-italic">π</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold-italic">θ</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mfenced><mml:mo>=</mml:mo><mml:msub><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mtext>miss</mml:mtext><mml:mo>,</mml:mo><mml:mtext>miss</mml:mtext><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mtext>miss</mml:mtext><mml:mo>,</mml:mo><mml:mtext>obs</mml:mtext><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mtext>obs</mml:mtext><mml:mo>,</mml:mo><mml:mtext>obs</mml:mtext><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:msub><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mtext>obs</mml:mtext><mml:mo>,</mml:mo><mml:mtext>miss</mml:mtext><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="12859_2022_4740_Article_Equ8.gif" position="anchor"/></alternatives></disp-formula>An exposition of how to use multiple stochastic imputations for inference is presented in the Supporting Information.</p>
      </sec>
    </sec>
    <sec id="Sec6">
      <title>Benchmarking method</title>
      <p id="Par11">All analyses were performed in R 3.5.0 R [<xref ref-type="bibr" rid="CR11">11</xref>]. We designed a benchmarking procedure to compare the performance of MGMM against imputation followed by standard GMM (also implemented by MGMM) and another package that allows for missing values (MixAll). The imputation methods included in the benchmark were: naive mean and median imputation; k-nearest neighbors imputation, as implemented by the VIM package [<xref ref-type="bibr" rid="CR12">12</xref>]; multiple imputation by chained equations, as implemented by the MICE package [<xref ref-type="bibr" rid="CR9">9</xref>]; and random forest imputation, as implemented by the missforest package [<xref ref-type="bibr" rid="CR13">13</xref>]. We defined clustering performance as the capacity of the algorithm to recover the true cluster assignments when applied to example data sets. We assessed the quality of the clustering by calculating the adjusted rand index (ARI) between the recovered and true class assignments. The running time was defined as the time necessary to obtain cluster assignation starting with the data set with missing values. We applied the benchmarking procedure to four case studies: a simulated four component mixture of bivariate Gaussians, a cancer patient RNA-seq data set, simulated genome-wide association studies (GWAS) summary statistics, and summary statistics from GWAS for cardiovascular disease risk factors [<xref ref-type="bibr" rid="CR14">14</xref>].</p>
      <sec id="Sec7">
        <title>Missingness</title>
        <p id="Par12">For <italic>n</italic> observations on <italic>d</italic> dimensional data, a fraction of missing values <italic>m</italic> was introduced completely at random by setting <inline-formula id="IEq26"><alternatives><tex-math id="M65">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\lceil (m\times n \times d)\rceil$$\end{document}</tex-math><mml:math id="M66"><mml:mrow><mml:mo>⌈</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>m</mml:mi><mml:mo>×</mml:mo><mml:mi>n</mml:mi><mml:mo>×</mml:mo><mml:mi>d</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>⌉</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4740_Article_IEq26.gif"/></alternatives></inline-formula> elements of the data set to NA.</p>
      </sec>
      <sec id="Sec8">
        <title>Evaluation metric</title>
        <p id="Par13">The quality of clustering was evaluated using the ARI [<xref ref-type="bibr" rid="CR15">15</xref>, <xref ref-type="bibr" rid="CR16">16</xref>]. Briefly, the Rand Index (RI) is a measure of similarity that assesses the agreement between two partitions of a collection of <italic>n</italic> objects. All possible pairs of objects are examined, and the proportion of pairs that are either 1. in the same cluster or 2. in different clusters according to both partitions is calculated. ARI is a variation of the RI that is adjusted for chance, and is permutation invariant. A value near zero suggests the agreement between the two partitions is no better than expected by chance, while a value of one occurs when the two partitions are identical. We define the quality of clustering as the ARI between the reference or true clustering, established in the data set description, and the clustering performed in the presence of missingness.</p>
      </sec>
      <sec id="Sec9">
        <title>Benchmarking procedure</title>
        <p id="Par14">
          <fig id="Fig1">
            <label>Fig. 1</label>
            <caption>
              <p>Benchmark procedure schematic. The input data are continuous vectors with known class assignments. Missing values are introduced completely at random. GMMs were then fit to the incomplete data in several ways: 1. by using MGMM, which allows for missing values and arbitrary covariance structures; 2. by using MixAll, which allows for missing values but assumes a diagonal covariance structure; 3. by imputing the missing values, then fitting a standard GMM. The GMMs were evaluated based on the adjusted Rand index between the predicted and true cluster assignments. This procedure was repeated <inline-formula id="IEq27"><alternatives><tex-math id="M67">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$N=$$\end{document}</tex-math><mml:math id="M68"><mml:mrow><mml:mi>N</mml:mi><mml:mo>=</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4740_Article_IEq27.gif"/></alternatives></inline-formula> times</p>
            </caption>
            <graphic xlink:href="12859_2022_4740_Fig1_HTML" id="MO8"/>
          </fig>
        </p>
        <p id="Par15">We designed the benchmarking procedure outlined in Fig. <xref rid="Fig1" ref-type="fig">1</xref> and described in Algorithm 1 to compare the performance of MGMM with imputation followed by standard GMM.</p>
        <graphic position="anchor" xlink:href="12859_2022_4740_Figa_HTML" id="MO9"/>
      </sec>
    </sec>
    <sec id="Sec10">
      <title>Benchmark data sets</title>
      <sec id="Sec11">
        <title>Simulated Gaussian mixture</title>
        <p id="Par16">For the first clustering task, we consider data that were truly generated from a GMM, which is the setting in which MGMM should perform optimally. Data were simulated according to the hierarchical model in Eq. (<xref rid="Equ1" ref-type="">1</xref>). The dimensionality <italic>d</italic> was set to 2 and the number of cluster components <italic>k</italic> to 4. The marginal density of the data generating process was:<disp-formula id="Equ9"><alternatives><tex-math id="M69">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} \left( {\begin{array}{c}Y_{i1}\\ Y_{i2}\end{array}}\right) \sim \sum _{j=1}^{4}\pi _{j}N({\varvec{\mu }}_{j},{\varvec{\Sigma }}_{j}). \end{aligned}$$\end{document}</tex-math><mml:math id="M70" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mfenced close=")" open="("><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:msub><mml:mi>Y</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mrow/><mml:msub><mml:mi>Y</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mfenced><mml:mo>∼</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mn>4</mml:mn></mml:munderover><mml:msub><mml:mi>π</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">μ</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="12859_2022_4740_Article_Equ9.gif" position="anchor"/></alternatives></disp-formula>The means (<inline-formula id="IEq28"><alternatives><tex-math id="M71">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\varvec{\mu }}_{j}$$\end{document}</tex-math><mml:math id="M72"><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">μ</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_4740_Article_IEq28.gif"/></alternatives></inline-formula>) were drawn from a uniform distribution on the square:<disp-formula id="Equ10"><alternatives><tex-math id="M73">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} \{(x,y): -5\le x\le 5, -5\le y \le 5\}. \end{aligned}$$\end{document}</tex-math><mml:math id="M74" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>:</mml:mo><mml:mo>-</mml:mo><mml:mn>5</mml:mn><mml:mo>≤</mml:mo><mml:mi>x</mml:mi><mml:mo>≤</mml:mo><mml:mn>5</mml:mn><mml:mo>,</mml:mo><mml:mo>-</mml:mo><mml:mn>5</mml:mn><mml:mo>≤</mml:mo><mml:mi>y</mml:mi><mml:mo>≤</mml:mo><mml:mn>5</mml:mn><mml:mo stretchy="false">}</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="12859_2022_4740_Article_Equ10.gif" position="anchor"/></alternatives></disp-formula>The component variances were set to 0.9:<disp-formula id="Equ11"><alternatives><tex-math id="M75">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} \Sigma _{11,j} = {\mathbb {V}}(Y_{i1}|Z_{ij}=1) = \Sigma _{22,j} = {\mathbb {V}}(Y_{i2}|Z_{ij}=1) = 0.9. \end{aligned}$$\end{document}</tex-math><mml:math id="M76" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mn>11</mml:mn><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi mathvariant="double-struck">V</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>Y</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mi>Z</mml:mi><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mn>22</mml:mn><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi mathvariant="double-struck">V</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>Y</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mi>Z</mml:mi><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>0.9</mml:mn><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="12859_2022_4740_Article_Equ11.gif" position="anchor"/></alternatives></disp-formula>The covariance was uniformly sampled from the interval <inline-formula id="IEq29"><alternatives><tex-math id="M77">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$(-0.9,0.9)$$\end{document}</tex-math><mml:math id="M78"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>-</mml:mo><mml:mn>0.9</mml:mn><mml:mo>,</mml:mo><mml:mn>0.9</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4740_Article_IEq29.gif"/></alternatives></inline-formula>:<disp-formula id="Equ12"><alternatives><tex-math id="M79">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} \Sigma _{12,j} = {\mathbb {C}}(Y_{i1},Y_{i2}|Z_{ij}=1) \sim U(-0.9, 0.9). \end{aligned}$$\end{document}</tex-math><mml:math id="M80" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mn>12</mml:mn><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi mathvariant="double-struck">C</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>Y</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>Y</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mi>Z</mml:mi><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>∼</mml:mo><mml:mi>U</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>-</mml:mo><mml:mn>0.9</mml:mn><mml:mo>,</mml:mo><mml:mn>0.9</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="12859_2022_4740_Article_Equ12.gif" position="anchor"/></alternatives></disp-formula>Marginal membership to each cluster was equally likely, <inline-formula id="IEq30"><alternatives><tex-math id="M81">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\pi _{j}=0.25$$\end{document}</tex-math><mml:math id="M82"><mml:mrow><mml:msub><mml:mi>π</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0.25</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4740_Article_IEq30.gif"/></alternatives></inline-formula> for <inline-formula id="IEq31"><alternatives><tex-math id="M83">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$j\in \{1,\ldots ,4\}$$\end{document}</tex-math><mml:math id="M84"><mml:mrow><mml:mi>j</mml:mi><mml:mo>∈</mml:mo><mml:mo stretchy="false">{</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mn>4</mml:mn><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4740_Article_IEq31.gif"/></alternatives></inline-formula>. A sample of size <inline-formula id="IEq32"><alternatives><tex-math id="M85">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n=2000$$\end{document}</tex-math><mml:math id="M86"><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>2000</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4740_Article_IEq32.gif"/></alternatives></inline-formula> was generated using the rGMM function from MGMM. The true (generative) component memberships <inline-formula id="IEq33"><alternatives><tex-math id="M87">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$({\varvec{z}}_{i})$$\end{document}</tex-math><mml:math id="M88"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">z</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4740_Article_IEq33.gif"/></alternatives></inline-formula> were used as the reference when evaluating clustering performance on incomplete data.</p>
      </sec>
      <sec id="Sec12">
        <title>RNA sequence data from cancer patients</title>
        <p id="Par17">For the second clustering task, cancer gene expression data [<xref ref-type="bibr" rid="CR17">17</xref>] were retrieved from the University of California Irvine machine learning repository. These data consist of expression values for 20,531 genes from <inline-formula id="IEq34"><alternatives><tex-math id="M89">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n=801$$\end{document}</tex-math><mml:math id="M90"><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>801</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4740_Article_IEq34.gif"/></alternatives></inline-formula> patients having 1 of <inline-formula id="IEq35"><alternatives><tex-math id="M91">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$k=5$$\end{document}</tex-math><mml:math id="M92"><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4740_Article_IEq35.gif"/></alternatives></inline-formula> tumor types. Marginal analysis of variance was performed to identify the 20 most significantly differentially expressed genes (DEGs) across tumor types. The patient by DEG matrix was then decomposed via principal components analysis (PCA), and the final cluster task was performed on the <inline-formula id="IEq36"><alternatives><tex-math id="M93">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$d=5$$\end{document}</tex-math><mml:math id="M94"><mml:mrow><mml:mi>d</mml:mi><mml:mo>=</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4740_Article_IEq36.gif"/></alternatives></inline-formula> leading principal components. <inline-formula id="IEq37"><alternatives><tex-math id="M95">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Y_{il}$$\end{document}</tex-math><mml:math id="M96"><mml:msub><mml:mi>Y</mml:mi><mml:mrow><mml:mi mathvariant="italic">il</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_4740_Article_IEq37.gif"/></alternatives></inline-formula> represents the expression of patient <italic>i</italic> along the <italic>l</italic>th principal component. The patient’s observed tumor type was used as the reference when evaluating clustering performance on incomplete data. The tumor types are abbreviated as follows:<list list-type="bullet"><list-item><p id="Par18">BRCA: Breast carcinoma.</p></list-item><list-item><p id="Par19">COAD: Colon adenocarcinoma.</p></list-item><list-item><p id="Par20">KIRC: Kidney renal clear-cell carcinoma.</p></list-item><list-item><p id="Par21">PRAD: Prostate adenocarcinoma.</p></list-item><list-item><p id="Par22">LUAD: Lung adenocarcinoma.</p></list-item></list></p>
      </sec>
      <sec id="Sec13">
        <title>GWAS summary statistics</title>
        <p id="Par23">For the third clustering task, we consider summary statistics, both simulated and real, arising from GWAS for cardiovascular disease risk factors. In this setting, <italic>i</italic> indexes single nucleotide polymorphisms (SNPs) and <inline-formula id="IEq38"><alternatives><tex-math id="M97">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Y_{il}$$\end{document}</tex-math><mml:math id="M98"><mml:msub><mml:mi>Y</mml:mi><mml:mrow><mml:mi mathvariant="italic">il</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_4740_Article_IEq38.gif"/></alternatives></inline-formula> is the standardized score (i.e. Z-score) quantifying the magnitude of the observed association between SNP <italic>i</italic> and phenotype <italic>l</italic>. The SNPs may belong to one of <italic>k</italic> clusters, where the Z-scores of SNPs within a cluster may exhibit correlations due to the combination of environmentally-induced correlation of the traits and sample overlap between the GWAS in which the Z-scores were ascertained.</p>
        <p id="Par24">A simulated set of GWAS summary statistics was generated for <inline-formula id="IEq39"><alternatives><tex-math id="M99">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$d=3$$\end{document}</tex-math><mml:math id="M100"><mml:mrow><mml:mi>d</mml:mi><mml:mo>=</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4740_Article_IEq39.gif"/></alternatives></inline-formula> traits and 900 SNPs arising from 1 of <inline-formula id="IEq40"><alternatives><tex-math id="M101">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$k=3$$\end{document}</tex-math><mml:math id="M102"><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4740_Article_IEq40.gif"/></alternatives></inline-formula> clusters. The marginal density was:<disp-formula id="Equ13"><alternatives><tex-math id="M103">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} \begin{pmatrix} Y_{i1} \\ Y_{i2} \\ Y_{i3} \end{pmatrix} \sim \sum _{j=1}^{3}\pi _{j}N({\varvec{\mu }}_{j},{\varvec{\Sigma }}_{j}). \end{aligned}$$\end{document}</tex-math><mml:math id="M104" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mfenced close=")" open="("><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:msub><mml:mi>Y</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mrow/><mml:msub><mml:mi>Y</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mrow/><mml:msub><mml:mi>Y</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mfenced><mml:mo>∼</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mn>3</mml:mn></mml:munderover><mml:msub><mml:mi>π</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">μ</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="12859_2022_4740_Article_Equ13.gif" position="anchor"/></alternatives></disp-formula>The mean vectors (<inline-formula id="IEq41"><alternatives><tex-math id="M105">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\varvec{\mu }}_{j}$$\end{document}</tex-math><mml:math id="M106"><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">μ</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_4740_Article_IEq41.gif"/></alternatives></inline-formula>) were set to zero, and the cluster covariances (<inline-formula id="IEq42"><alternatives><tex-math id="M107">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\varvec{\Sigma }}_{j}$$\end{document}</tex-math><mml:math id="M108"><mml:msub><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_4740_Article_IEq42.gif"/></alternatives></inline-formula>) were set to:<disp-formula id="Equ14"><alternatives><tex-math id="M109">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} {\varvec{\Sigma }}_{1}&amp;= \begin{pmatrix} 2.5 &amp; 2 &amp; 0\\ 2 &amp; 2.5 &amp; 0 \\ 0 &amp; 0 &amp; 0.3 \end{pmatrix}\\ {\varvec{\Sigma }}_{2}&amp;= \begin{pmatrix} 2.25 &amp; -2 &amp; 0\\ -2 &amp; 2.25 &amp; 0 \\ 0 &amp; 0 &amp; 0.3 \end{pmatrix}\\ {\varvec{\Sigma }}_{3}&amp;= \begin{pmatrix} 0.2 &amp; 0 &amp; 0\\ 0 &amp; 0.2 &amp; 0 \\ 0 &amp; 0 &amp; 4.5 \end{pmatrix}. \end{aligned}$$\end{document}</tex-math><mml:math id="M110" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:msub><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo><mml:mfenced close=")" open="("><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mn>2.5</mml:mn></mml:mrow></mml:mtd><mml:mtd><mml:mn>2</mml:mn></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mrow/><mml:mn>2</mml:mn></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mn>2.5</mml:mn></mml:mrow></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mrow/><mml:mn>0</mml:mn></mml:mrow></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mrow><mml:mn>0.3</mml:mn></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mfenced></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mrow/><mml:msub><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo><mml:mfenced close=")" open="("><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mn>2.25</mml:mn></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mo>-</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mrow/><mml:mo>-</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mn>2.25</mml:mn></mml:mrow></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mrow/><mml:mn>0</mml:mn></mml:mrow></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mrow><mml:mn>0.3</mml:mn></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mfenced></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mrow/><mml:msub><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mn>3</mml:mn></mml:msub></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo><mml:mfenced close=")" open="("><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mn>0.2</mml:mn></mml:mrow></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mrow/><mml:mn>0</mml:mn></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mn>0.2</mml:mn></mml:mrow></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mrow/><mml:mn>0</mml:mn></mml:mrow></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mrow><mml:mn>4.5</mml:mn></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mfenced><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="12859_2022_4740_Article_Equ14.gif" position="anchor"/></alternatives></disp-formula>Marginal membership to each cluster was equally likely <inline-formula id="IEq43"><alternatives><tex-math id="M111">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\pi _{j}=0.33$$\end{document}</tex-math><mml:math id="M112"><mml:mrow><mml:msub><mml:mi>π</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0.33</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4740_Article_IEq43.gif"/></alternatives></inline-formula> for <inline-formula id="IEq44"><alternatives><tex-math id="M113">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$j\in \{1,\ldots ,3\}$$\end{document}</tex-math><mml:math id="M114"><mml:mrow><mml:mi>j</mml:mi><mml:mo>∈</mml:mo><mml:mo stretchy="false">{</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mn>3</mml:mn><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4740_Article_IEq44.gif"/></alternatives></inline-formula>. These covariance structures were chosen to represent a variety of situations: (1) pleiotropic SNPs whose effects are positively correlated for the two first traits (<inline-formula id="IEq45"><alternatives><tex-math id="M115">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\varvec{\Sigma }}_{1}$$\end{document}</tex-math><mml:math id="M116"><mml:msub><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_4740_Article_IEq45.gif"/></alternatives></inline-formula>); (2) pleiotropic SNPs whose effects are negatively correlated for the two first traits SNPs (<inline-formula id="IEq46"><alternatives><tex-math id="M117">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\varvec{\Sigma }}_{2}$$\end{document}</tex-math><mml:math id="M118"><mml:msub><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_4740_Article_IEq46.gif"/></alternatives></inline-formula>); (3) SNPs acting predominantly on the third traits (<inline-formula id="IEq47"><alternatives><tex-math id="M119">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\varvec{\Sigma }}_{3}$$\end{document}</tex-math><mml:math id="M120"><mml:msub><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mn>3</mml:mn></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_4740_Article_IEq47.gif"/></alternatives></inline-formula>). A sample of size <inline-formula id="IEq48"><alternatives><tex-math id="M121">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n=900$$\end{document}</tex-math><mml:math id="M122"><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>900</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4740_Article_IEq48.gif"/></alternatives></inline-formula> was generated using the rGMM function from the MGMM package. To emulate the omission of non-significant results, which frequently occurs when reporting GWAS summary statistics, the SNPs were filtered to those having evidence of association with the traits at <inline-formula id="IEq49"><alternatives><tex-math id="M123">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$p \le 0.05$$\end{document}</tex-math><mml:math id="M124"><mml:mrow><mml:mi>p</mml:mi><mml:mo>≤</mml:mo><mml:mn>0.05</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4740_Article_IEq49.gif"/></alternatives></inline-formula> via the omnibus test (9) detailed in the appendix. After filtering, <inline-formula id="IEq50"><alternatives><tex-math id="M125">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n=183$$\end{document}</tex-math><mml:math id="M126"><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>183</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4740_Article_IEq50.gif"/></alternatives></inline-formula> SNPs remained, with marginal cluster frequencies: <inline-formula id="IEq51"><alternatives><tex-math id="M127">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\pi _1 = 0.25$$\end{document}</tex-math><mml:math id="M128"><mml:mrow><mml:msub><mml:mi>π</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>0.25</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4740_Article_IEq51.gif"/></alternatives></inline-formula>, <inline-formula id="IEq52"><alternatives><tex-math id="M129">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\pi _2 = 0.42$$\end{document}</tex-math><mml:math id="M130"><mml:mrow><mml:msub><mml:mi>π</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>0.42</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4740_Article_IEq52.gif"/></alternatives></inline-formula>, <inline-formula id="IEq53"><alternatives><tex-math id="M131">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\pi _3 = 0.33$$\end{document}</tex-math><mml:math id="M132"><mml:mrow><mml:msub><mml:mi>π</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>0.33</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4740_Article_IEq53.gif"/></alternatives></inline-formula>. The topology of the resulting data set is presented in Fig. <xref rid="Fig2" ref-type="fig">2</xref>. The true (generative) component memberships <inline-formula id="IEq54"><alternatives><tex-math id="M133">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$({\varvec{z}}_{i})$$\end{document}</tex-math><mml:math id="M134"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">z</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4740_Article_IEq54.gif"/></alternatives></inline-formula> were used as the reference when evaluating clustering performance on incomplete data.<fig id="Fig2"><label>Fig. 2</label><caption><p>Scatter Plot of the Simulated GWAS-like Multivariate Z-scores. Observations are colored according to component membership. The left panel plots the second coordinate against the first, and the right panel plots the third coordinate against the second</p></caption><graphic xlink:href="12859_2022_4740_Fig2_HTML" id="MO16"/></fig></p>
        <p id="Par25">A set of real GWAS summary statistics for cardiovascular disease risk factors was prepared as described in [<xref ref-type="bibr" rid="CR14">14</xref>]. These traits were: body mass index (BMI), coronary artery disease (CAD), low density lipoprotein (LDL), triglycerides (TG), waist to hip ratio (WHR), and any strokes (AS). From this collection of traits, we formed three example data sets. The first included <inline-formula id="IEq55"><alternatives><tex-math id="M135">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\{$$\end{document}</tex-math><mml:math id="M136"><mml:mo stretchy="false">{</mml:mo></mml:math><inline-graphic xlink:href="12859_2022_4740_Article_IEq55.gif"/></alternatives></inline-formula>BMI, CAD, LDL<inline-formula id="IEq56"><alternatives><tex-math id="M137">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\}$$\end{document}</tex-math><mml:math id="M138"><mml:mo stretchy="false">}</mml:mo></mml:math><inline-graphic xlink:href="12859_2022_4740_Article_IEq56.gif"/></alternatives></inline-formula> only; the second included <inline-formula id="IEq57"><alternatives><tex-math id="M139">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\{$$\end{document}</tex-math><mml:math id="M140"><mml:mo stretchy="false">{</mml:mo></mml:math><inline-graphic xlink:href="12859_2022_4740_Article_IEq57.gif"/></alternatives></inline-formula>LDL, TG, BMI, AS, CAD<inline-formula id="IEq58"><alternatives><tex-math id="M141">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\}$$\end{document}</tex-math><mml:math id="M142"><mml:mo stretchy="false">}</mml:mo></mml:math><inline-graphic xlink:href="12859_2022_4740_Article_IEq58.gif"/></alternatives></inline-formula>; the third <inline-formula id="IEq59"><alternatives><tex-math id="M143">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\{$$\end{document}</tex-math><mml:math id="M144"><mml:mo stretchy="false">{</mml:mo></mml:math><inline-graphic xlink:href="12859_2022_4740_Article_IEq59.gif"/></alternatives></inline-formula>LDL, TG, BMI, AS, WHR<inline-formula id="IEq60"><alternatives><tex-math id="M145">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\}$$\end{document}</tex-math><mml:math id="M146"><mml:mo stretchy="false">}</mml:mo></mml:math><inline-graphic xlink:href="12859_2022_4740_Article_IEq60.gif"/></alternatives></inline-formula>. We selected independent SNPs that were genome-wide significant (p-value <inline-formula id="IEq61"><alternatives><tex-math id="M147">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\le 10^{-8}$$\end{document}</tex-math><mml:math id="M148"><mml:mrow><mml:mo>≤</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>-</mml:mo><mml:mn>8</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4740_Article_IEq61.gif"/></alternatives></inline-formula>) either marginally or via the omnibus test (9). These data sets contained 165, 166 and 179 SNPs respectively. For each example, a GMM with <inline-formula id="IEq62"><alternatives><tex-math id="M149">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$k=3$$\end{document}</tex-math><mml:math id="M150"><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4740_Article_IEq62.gif"/></alternatives></inline-formula> components was fit to the complete data (using FitGMM from the MGMM package), and the cluster assignments from this initial model were used as the reference when evaluating clustering performance on incomplete data. Because the reference clustering partition was directly derived from the data, the benchmark on these examples assess the robustness of the clustering rather than the ability to recover a true, underlying data class assignment.</p>
      </sec>
    </sec>
    <sec id="Sec14">
      <title>Imputation methods and <bold>MixAll</bold> parameter settings</title>
      <p id="Par26">Naive mean or median imputation refers to simply setting a missing value to the mean or median of the observed values along that coordinate. For kNN, a missing value was imputed to the (Euclidean) distance-weighted average of the 5 nearest observations with observed data along that coordinate. For MICE, a missing value was imputed to its conditional expectation given the observed coordinates via the method of predictive mean matching; the number of imputations was 10, and the maximum number of Gibbs sampling iterations was 50. For random forest imputation, the number of trees per forest was 100, and the maximum number of refinement iterations was 10. For MixAll, the default parameters of the clusterDiagGaussian function were adopted; this resulted in all available models being fit, and the best model, according to the integrated completed likelihood criterion, being returned.</p>
    </sec>
    <sec id="Sec15">
      <title>Filtering unassignable observations from MGMM and MICE</title>
      <p id="Par27">Since both MGMM and MICE provide an indication of the uncertainty in the cluster assignments, we created an additional clustering method in which observations with high assignment uncertainty were regarded as unassignable. This occurs when an observation could very plausibly has originated from more than one of the clusters, and may be exacerbated by excess missing data along a coordinate that helps to differentiate among clusters. This uncertainty can be assessed via the entropy of the posterior membership probabilities:<disp-formula id="Equ4"><label>4</label><alternatives><tex-math id="M151">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} H({\varvec{y}}_{i}) = \frac{1}{\ln (k)}\sum _{j=1}^{k}{\hat{\gamma }}_{ij}(-1)\ln ({\hat{\gamma }}_{ij}), \end{aligned}$$\end{document}</tex-math><mml:math id="M152" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>H</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mo>ln</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>k</mml:mi></mml:munderover><mml:msub><mml:mover accent="true"><mml:mi>γ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>ln</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>γ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="12859_2022_4740_Article_Equ4.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq63"><alternatives><tex-math id="M153">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\hat{\gamma }}_{ij}$$\end{document}</tex-math><mml:math id="M154"><mml:msub><mml:mover accent="true"><mml:mi>γ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_4740_Article_IEq63.gif"/></alternatives></inline-formula> is the final responsibility of cluster <italic>j</italic> for observation <italic>i</italic>.</p>
      <p id="Par28">For MGMM, the entropy of the posterior cluster responsibilities is calculated by FitGMM using (<xref rid="Equ4" ref-type="">4</xref>). For MICE, each input data set is multiply imputed, and each of these imputed data set results in one <italic>maximum a posteriori</italic> cluster assignment. The posterior probability of membership to each cluster (i.e. the responsibilities, <inline-formula id="IEq64"><alternatives><tex-math id="M155">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\hat{\gamma }}_{ij}$$\end{document}</tex-math><mml:math id="M156"><mml:msub><mml:mover accent="true"><mml:mi>γ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_4740_Article_IEq64.gif"/></alternatives></inline-formula>) may be approximated by the proportion of imputations on which an observation was assigned to each cluster.</p>
      <p id="Par29">In the filtered versions of MGMM and MICE, observations with high assignment uncertainty are identified via entropy and removed from consideration. For a given data set, such as the Cancer RNA-Seq data set, the distribution of entropy for MICE was typically right skewed (Supplementary Fig. <xref rid="MOESM1" ref-type="media">3</xref>-A). Consequently, for a fixed entropy threshold, the fraction of observations deemed unassignable is systematically higher for MICE than for MGMM (see Supplementary Fig. <xref rid="MOESM1" ref-type="media">3</xref>-B). To conduct a fair comparison of the two methods, we proceeded as follows: <list list-type="order"><list-item><p id="Par30">For MICE, filter out observations with entropy exceeding 0.2 and assess performance on the remaining data.</p></list-item><list-item><p id="Par31">Find the proportion of observations discarded by MICE.</p></list-item><list-item><p id="Par32">Set an entropy threshold for MGMM such that the same proportion of observations is excluded as was removed for MICE.</p></list-item><list-item><p id="Par33">Filter out observations with entropy exceeding the MGMM threshold and assess performance on the remaining data.</p></list-item></list>This procedure provides a fair comparison of MGMM-filtered and MICE-filtered by adaptively selecting the entropy threshold for MGMM in such a way that both methods remove the same fraction observations with high assignment uncertainty.</p>
    </sec>
  </sec>
  <sec id="Sec16">
    <title>Benchmark results</title>
    <sec id="Sec17">
      <title>Four component mixture of bivariate Gaussians</title>
      <p id="Par34">
        <fig id="Fig3">
          <label>Fig. 3</label>
          <caption>
            <p>Benchmarking for the Mixture of Gaussians Data Set. The top panel includes the observations as simulated, colored according to the mixture component. The bottom panel presents the adjusted Rand index as a function of the missing data proportion for 8 different approaches to handling missing data; a higher value indicates better agreement between the predicted and true cluster assignments, adjusting for chance. Error bars represent the standard error of the mean across 20 simulation replicates</p>
          </caption>
          <graphic xlink:href="12859_2022_4740_Fig3_HTML" id="MO18"/>
        </fig>
      </p>
      <p id="Par35">When the underlying distribution was in fact a GMM, MGMM uniformly dominated imputation plus GMM (Fig. <xref rid="Fig3" ref-type="fig">3</xref>) at recovering the true cluster assignments. GMM after imputation by kNN and GMM after MICE performed similarly. The performance of MixAll was relatively poor compared to MGMM, despite the data having truly been generated from a GMM. This underscores the disadvantages of an estimation procedure that incorrectly assumes a diagonal covariance structure. Interestingly, although non-parametric, random forest imputation was not competitive when the true data generating process was a GMM. Naive mean and median imputation strongly under-performed, and at elevated missingness created singularities in the data set that prevented the GMM from converging.</p>
    </sec>
    <sec id="Sec18">
      <title>RNA sequence data from cancer patients</title>
      <p id="Par36">
        <fig id="Fig4">
          <label>Fig. 4</label>
          <caption>
            <p>Benchmarking for the Cancer RNA-Seq Data Set. The top panel includes the projection of the expression data for <inline-formula id="IEq65"><alternatives><tex-math id="M157">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n=801$$\end{document}</tex-math><mml:math id="M158"><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>801</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4740_Article_IEq65.gif"/></alternatives></inline-formula> cancer patients onto the first two principal components. Observations are colored according to tumor type. The bottom panel presents the adjusted Rand index as a function of the missing data proportion; a higher value indicates better agreement between the predicted and true cluster assignments, adjusting for chance. Error bars represent the standard error of the mean across 20 simulation replicates</p>
          </caption>
          <graphic xlink:href="12859_2022_4740_Fig4_HTML" id="MO19"/>
        </fig>
      </p>
      <p id="Par37">For the Cancer RNA-Seq data set, where the true generative model is unlikely to be a GMM, MGMM remained highly effective at recovering the true tumor type of the patient (see Fig. <xref rid="Fig4" ref-type="fig">4</xref>). MixAll evinced the worst performance when the proportion of missing data was <inline-formula id="IEq66"><alternatives><tex-math id="M159">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\le 15\%$$\end{document}</tex-math><mml:math id="M160"><mml:mrow><mml:mo>≤</mml:mo><mml:mn>15</mml:mn><mml:mo>%</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4740_Article_IEq66.gif"/></alternatives></inline-formula>, however its performance deteriorated more slowly than the other methods, allowing it to become competitive when the proportion of missing data surpassed 35%. This may be because the simpler model assumed by MixAll is easier to fit when the data set is small and the proportion of missing values high. Random forests and kNN + GMM were competitive with MGMM, and outperformed when the proportion of missing data was <inline-formula id="IEq67"><alternatives><tex-math id="M161">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\ge 35\%$$\end{document}</tex-math><mml:math id="M162"><mml:mrow><mml:mo>≥</mml:mo><mml:mn>35</mml:mn><mml:mo>%</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4740_Article_IEq67.gif"/></alternatives></inline-formula>. Mean and median imputation were again not competitive, particularly when the proportion of missing data was <inline-formula id="IEq68"><alternatives><tex-math id="M163">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\ge 20\%$$\end{document}</tex-math><mml:math id="M164"><mml:mrow><mml:mo>≥</mml:mo><mml:mn>20</mml:mn><mml:mo>%</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4740_Article_IEq68.gif"/></alternatives></inline-formula>. MICE performed only slightly better than mean and median imputations. Linear imputation method may be ill-suited for separating the BRCA, LUDA, and PRAD tumor types.</p>
    </sec>
    <sec id="Sec19">
      <title>GWAS summary statistics</title>
      <p id="Par38">Finally, we considered clustering vectors of GWAS summary statistics arising when the same SNPs are tested for association with multiple traits. This analysis is of interest for identifying pleiotropy, individual SNPs that have effects on multiple traits, and polygenicity, collections of multiple SNPs that have effects on common traits. Such analyses are often performed by combining data from multiple independent studies, and missingness arises because not all SNPs or all traits were ascertained in all studies. Further, this analysis would generally only include SNPs that were significantly associated with at least one trait.<fig id="Fig5"><label>Fig. 5</label><caption><p>Benchmarking Simulated Multi-trait GWAS Summary Statistics. The left panel presents a heat map colored according to the normalized genetic effect, with SNPs as rows and traits as columns. The colorbar on the left represents the true cluster assignments. The right panel presents the adjusted Rand index as a function of the missing data proportion; a higher value indicates better agreement between the predicted and true cluster assignments, adjusting for chance. Error bars represent the standard error of the mean across 20 simulation replicates</p></caption><graphic xlink:href="12859_2022_4740_Fig5_HTML" id="MO20"/></fig></p>
      <p id="Par39">Here we discuss one simulated and one real data example; two additional real data examples are presented in the appendix. For the simulated summary statistics in Fig. <xref rid="Fig5" ref-type="fig">5</xref>, the clustering task is same as the one presented on Fig. <xref rid="Fig3" ref-type="fig">3</xref>. The three clusters are clearly separated. Yet, the task remains challenging due to the specific and unusual cluster topology arising from GWAS data. Since the underlying distribution was in fact a GMM, MGMM again performs very well, only falling off when the proportion of missing data reaches <inline-formula id="IEq69"><alternatives><tex-math id="M165">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\ge 40\%$$\end{document}</tex-math><mml:math id="M166"><mml:mrow><mml:mo>≥</mml:mo><mml:mn>40</mml:mn><mml:mo>%</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4740_Article_IEq69.gif"/></alternatives></inline-formula>. In this example, MixAll performed was competitive with MGMM, although MGMM did outperform until the proportion of missing data become high. For this simulation, the data generation process MixAll because the covariance structure is truly diagonal for the 3rd component of the mixture, and close to diagonal for the 2nd. As for the RNA-Seq example (Fig. <xref rid="Fig4" ref-type="fig">4</xref>), random forest and kNN were competitive with MGMM, outperforming at very high missingness. Surprisingly, MICE under-performed naive mean imputation, and was comparable to native median imputation.<fig id="Fig6"><label>Fig. 6</label><caption><p>Benchmarking Real Multi-trait GWAS Summary Statistics for 3 Cardiovascular Risk Factors. These were body mass index (BMI), coronary artery disease (CAD), and low density lipoprotein (LDL). The left panel presents a heat map colored according to the standardized genetic effect, with SNPs as rows and traits as columns. The colorbar on the left represents the true cluster assignments. The right panel presents the adjusted Rand index as a function of the missing data proportion; a higher value indicates better agreement between the predicted and true cluster assignments, adjusting for chance. Error bars represent the standard error of the mean across 20 simulation replicates</p></caption><graphic xlink:href="12859_2022_4740_Fig6_HTML" id="MO21"/></fig></p>
      <p id="Par40">An analogous clustering task applied to summary statistics from real GWAS of BMI, CAD, and LDL is presented in Fig. <xref rid="Fig6" ref-type="fig">6</xref>. The three clusters, identified by applying a 3-component GMM to the data before the introduction of missingness, appear well-differentiated on the heat map. kNN and random forests offered the best performance, followed by MGMM, whose performance deteriorated at missingness <inline-formula id="IEq70"><alternatives><tex-math id="M167">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\ge 35\%$$\end{document}</tex-math><mml:math id="M168"><mml:mrow><mml:mo>≥</mml:mo><mml:mn>35</mml:mn><mml:mo>%</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4740_Article_IEq70.gif"/></alternatives></inline-formula>. The deficit in performance of MGMM compared to kNN and random forests, even at low missingness, likely reflects a departure of the true data generating process from a GMM. Similarly, this departure likely explains the overall lower performance of MixAll for these data. As in the case of simulated GWAS summary statistics, MICE was not competitive, performing similarly to naive mean and median imputation. Two alternative examples with different set of traits are presented in Supplementary Material (see Supplementary Figs. <xref rid="MOESM1" ref-type="media">1</xref> and <xref rid="MOESM1" ref-type="media">2</xref>).</p>
    </sec>
    <sec id="Sec20">
      <title>Comparison of MICE-filtered and MGMM-filtered</title>
      <p id="Par41">By effectively removing poorly classifiable observations from consideration, filtering is expected to improve the clustering quality, but only if those observations with high assignment uncertainty are correctly identified. Therefore, the comparative performance of MGMM-filtered and MICE-filtered provides an indication of how well each strategy was able to identify those observations with high cluster assignment uncertainty. We present the performances of the two methods on four data sets in Fig. <xref rid="Fig7" ref-type="fig">7</xref>.<fig id="Fig7"><label>Fig. 7</label><caption><p>Performances of MICE-filtered and MGMM-filtered on four Benchmark Data Sets. The adjusted Rand index as a function of the missing data proportion for <bold>A</bold> the Four Component Mixture of Bivariate Gaussians simulation, <bold>B</bold> Cancer RNA-Seq Data Set, <bold>C</bold> Simulated Multi-trait GWAS Summary Statistics, <bold>D</bold> 2nd Example of Real Multi-trait GWAS Summary Statistics for Cardiovascular Risk Factors. Error bars represent the standard error of the mean across 40 simulation replicates</p></caption><graphic xlink:href="12859_2022_4740_Fig7_HTML" id="MO22"/></fig></p>
      <sec id="Sec21">
        <title>Four component mixture of bivariate Gaussians</title>
        <p id="Par42">For the Gaussian mixture simulation data set (Fig. <xref rid="Fig7" ref-type="fig">7</xref>A), filtering out unassignable observations strikingly improved the classification accuracy of both MICE and MGMM. However, MGMM-filtered performed better for all missing data ratios. Thus, when the data are in fact generated by a GMM, MGMM correctly assesses cluster assignment uncertainty, providing users with a mechanism for identifying observations with low-confidence cluster assignments.</p>
      </sec>
      <sec id="Sec22">
        <title>RNA sequence data from cancer patients</title>
        <p id="Par43">For the cancer RNA-Seq data set (Fig. <xref rid="Fig7" ref-type="fig">7</xref>B), entropy-based filtering again significantly improved the performance of both methods, suggesting that assignment entropy provides a reliable method for identifying unassignable observations. Note that the filtered data set contained sufficiently many observations to correctly evaluate performance (see Appendix 5). MGMM-filtered outperformed MICE-filtered at lower missingness, while MICE-filtered performed better when the missing data proportion exceeded 30%. The same trend was observed for the unfiltered versions of MGMM and MICE. This example demonstrates that even when the underlying distribution is not a GMM, MGMM is able to accurately assess cluster assignment uncertainty at practical missing ratios.</p>
      </sec>
      <sec id="Sec23">
        <title>GWAS summary statistics</title>
        <p id="Par44">For the GWAS summary statistic data sets, the comparative performances of the two methods depend on the structure of the data. On the simulated multi-trait GWAS summary statistics (Fig. <xref rid="Fig7" ref-type="fig">7</xref>C), filtering drastically improved the performance of MGMM, whereas filtering did little, if anything, to improve the performance of MICE. This suggest that MICE-based imputation entropy was not an effective gauge of assignment uncertainty for these data. The non-linearity and absence of correlation among the variables probably explains the poor performance of MICE.</p>
        <p id="Par45">On the 2nd example of real GWAS summary statistics for cardiovascular risk factors, MICE-filtered performed best overall, and entropy-based filtering improved the performance of MICE more so than the performance of MGMM. The unfiltered versions of MICE and MGMM performed comparably. The strong correlations among the traits studied likely explains the good performance of MICE-filtered for these data. It is also important to note that, for the GWAS data sets, the reference labels used to compute the adjusted rand index are not the true classes <italic>per se</italic>, but rather the clustering obtained on complete data (see the "<xref rid="Sec2" ref-type="sec">Methods</xref>" section). Therefore, the performance assessment in this example is more a measure of the robustness of the clustering procedure to the presence of missing data than a measure of the capacity to identify true underlying classes.</p>
      </sec>
      <sec id="Sec24">
        <title>Filtered observations</title>
        <p id="Par46">Importantly, filtering out unassignable observations based on entropy did not strongly enrich the remaining data for complete cases (see Supplementary Fig. <xref rid="MOESM1" ref-type="media">5</xref>). Therefore, the general improvements in performance observed with filtering cannot be trivially explained by the selective removal of incomplete observations, and point instead to the accurate identification of observations that could plausibly have arisen from more than 1 cluster.</p>
      </sec>
      <sec id="Sec25">
        <title>Running time benchmark</title>
        <p id="Par47">
          <fig id="Fig8">
            <label>Fig. 8</label>
            <caption>
              <p>Comparison of computation time for studied methods. The computation time as a function of the missing data proportion for <bold>A</bold> the Four Component Mixture of Bivariate Gaussians simulation, <bold>B</bold> Cancer RNA-Seq Data Set, <bold>C</bold> Simulated Multi-trait GWAS Summary Statistics, <bold>D</bold> 2nd Example of Real Multi-trait GWAS Summary Statistics for Cardiovascular Risk Factors. Error bars represent the standard error of the mean across 40 simulation replicates</p>
            </caption>
            <graphic xlink:href="12859_2022_4740_Fig8_HTML" id="MO23"/>
          </fig>
        </p>
        <p id="Par48">In terms of running time (see Fig. <xref rid="Fig8" ref-type="fig">8</xref>), simple and biased imputation scheme such as mean and median imputation were consistently fastest. The running time of k-NN and random forest remained low for all missing rate. Mixall was slower than MGMM on complete data and for realistic missing rate. MGMM was competitive for the missingness rates usually encountered in real data (<inline-formula id="IEq71"><alternatives><tex-math id="M169">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\overset{\sim }{1}0\%$$\end{document}</tex-math><mml:math id="M170"><mml:mrow><mml:mover><mml:mn>1</mml:mn><mml:mo>∼</mml:mo></mml:mover><mml:mn>0</mml:mn><mml:mo>%</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4740_Article_IEq71.gif"/></alternatives></inline-formula>) but its running time increased steeply as the proportion of missing data became large. MICE followed by MGMM was the slowest method overall and was slow even for low missingness rates. This naturally follows from needing to perform multiple rounds of imputation followed by GMM estimation with MICE. Although MICE and MGMM were generally the slowest methods, these are also the only methods that provide a mechanism for identifying and filtering out observations with high assignment uncertainty. Moreover, to put the computation cost into perspective, the longest observed running time was 344 seconds, which remains tractable (obtained with MICE on the Mixture of Bivariate Gaussians example, Fig. <xref rid="Fig8" ref-type="fig">8</xref>A).</p>
      </sec>
    </sec>
  </sec>
  <sec id="Sec26">
    <title>Discussion</title>
    <p id="Par49">We conducted a comparative benchmark to assess the capacity of MGMM versus MixAll and standard GMM after imputation to correctly identify true cluster assignments in data containing missing values. We established that for data sets following a distribution close to a GMM, MGMM is able to recover the true class assignment more accurately than imputation followed by standard GMM. When the underlying data generating process is in fact a GMM, then as a correctly specified maximum likelihood procedure, MGMM is optimal. MGMM consistently outperformed the other existing GMM implementation that allows for missing data (i.e. MixAll), except when the proportion of missing data became excessive. The better performance of MGMM at low levels of missingness is likely because MGMM places no restrictions on the form of the covariance matrix. At high levels of missingness, adopting the parsimonious assumption of a diagonal covariance structure, as is done by MixAll, can be advantageous. However, for a fixed proportion of missing data, MGMM should match or exceed the performance of MixAll as sample sizes increases. In addition, MGMM correctly assess its level of uncertainty in clustering assignments, providing a mechanism for identifying and separating out observations whose cluster assignments are unreliable.</p>
    <p id="Par50">GMMs are not well-suited to all clustering tasks. Direct application of MGMM was less effective than non-linear imputation, via kNN or random forests, followed by standard GMM in cases where the clusters present in the observed data were poorly differentiated, or the missingness was high (e.g. <inline-formula id="IEq72"><alternatives><tex-math id="M171">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$40\%$$\end{document}</tex-math><mml:math id="M172"><mml:mrow><mml:mn>40</mml:mn><mml:mo>%</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4740_Article_IEq72.gif"/></alternatives></inline-formula>). This observation emphasizes the need to assess the appropriateness of a GMM before applying MGMM to a clustering problem. Since kNN and random forest imputation, followed by standard GMM, were typically competitive with MGMM in the real data examples, these methods may be used to perform sensitivity analysis on the final cluster assignments. On the other hand, standard GMM following kNN or random forest imputation will not appropriately propagate uncertainty due to missing data. This can lead to inaccurate estimates of the posterior membership probabilities, particularly for observations with multiple missing elements, and failure to identify observations whose cluster assignments are unreliable. Thus, an approach such as MGMM-filtered, which accurately assesses assignment uncertainty and removes unclassifiable observations from consideration, may be more reliable. The framework proposed by [<xref ref-type="bibr" rid="CR6">6</xref>], and elaborated upon here, of using an EM-type algorithm to fit mixture models in the presence of both missing data and unknown class assignments, may be extended to estimates mixtures of non-Gaussian distributions. Extending MGMM to estimate such mixtures in the presence of missing data is among our future directions.</p>
  </sec>
  <sec id="Sec27">
    <title>Conclusion</title>
    <p id="Par51">We have presented MGMM, a powerful, general purpose R package for maximum likelihood-based estimation of GMMs in the presence of missing data, and demonstrated that MGMM often outperforms both MixAll and imputation followed by standard GMM on various real and simulated data sets. In contrast to estimation after imputation, MGMM uses the ECM algorithm to efficiently and unbiasedly obtain the maximum likelihood estimates of all model parameters while properly accounting for the uncertainty introduced by the presence of missing values; and in contrast to MixAll, which also employs maximum likelihood estimation, MGMM does not assume the data are uncorrelated. To our knowledge, MGMM is the only publicly available method for fitting GMMs that properly accounts for missing data without imposing simplifying assumptions, and our benchmark is the first extensive study of how estimating GMMs while properly accounting for missing data compares with the <italic>ad hoc</italic> procedure of estimation after imputation. In addition, the supporting information (Additional file <xref rid="MOESM1" ref-type="media">1</xref>) provides a clear step-by-step derivation of our ECM algorithm, providing a foundation for extending this work to missingness-aware mixtures of other distributions. The functionalities of the MGMM package [<xref ref-type="bibr" rid="CR7">7</xref>] are carefully documented and comprise: the generation of random data under a specified GMM, the fitting of GMMs to data sets containing missing values, the drawing of multiple imputations for a fitted model, and the computation of a panel of clustering criteria to identify the optimal number of clusters.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary information</title>
    <sec id="Sec28">
      <p>
        <supplementary-material content-type="local-data" id="MOESM1">
          <media xlink:href="12859_2022_4740_MOESM1_ESM.pdf">
            <caption>
              <p><bold>Additional file 1:</bold> Detailed derivation; discussion of assumptions, cluster-number selection, and multiple-imputation; additional simulation materials.</p>
            </caption>
          </media>
        </supplementary-material>
        <supplementary-material content-type="local-data" id="MOESM2">
          <media xlink:href="12859_2022_4740_MOESM2_ESM.zip">
            <caption>
              <p><bold>Additional file 2.</bold> Replication scripts and benchmark data.</p>
            </caption>
          </media>
        </supplementary-material>
      </p>
    </sec>
  </sec>
</body>
<back>
  <fn-group>
    <fn>
      <p>
        <bold>Publisher's Note</bold>
      </p>
      <p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
    </fn>
  </fn-group>
  <ack>
    <title>Acknowledgements</title>
    <p>The authors thank the anonymous reviewers for their valuable suggestions.</p>
  </ack>
  <notes notes-type="author-contribution">
    <title>Author contributions</title>
    <p>ZM Software Conception and implementation, manuscript writing and reviewing. HJ Benchmark conception and implementation, manuscript writing and reviewing. HA Manuscript reviewing. All authors read and approved the final manuscript.</p>
  </notes>
  <notes notes-type="funding-information">
    <title>Funding</title>
    <p>This work is supported in part by funds from the National Science Foundation (NSF: # 1636933 and # 1920920).</p>
  </notes>
  <notes notes-type="data-availability">
    <title>Availability of data and materials</title>
    <p>MGMM is available as an R package on CRAN: <ext-link ext-link-type="uri" xlink:href="https://CRAN.R-project.org/package=MGMM">https://CRAN.R-project.org/package=MGMM</ext-link>. The data used in this study are either publicly available or were randomly generated according to the procedure detailed in the Materials and Methods. We provide an archive (Additional file <xref rid="MOESM2" ref-type="media">2</xref>) containing replication scripts and data.</p>
  </notes>
  <notes>
    <title>Declaration</title>
    <notes id="FPar2">
      <title>Ethics approval and consent to participate</title>
      <p id="Par52">Not applicable.</p>
    </notes>
    <notes id="FPar3">
      <title>Consent for publication</title>
      <p id="Par53">Not applicable.</p>
    </notes>
    <notes id="FPar4" notes-type="COI-statement">
      <title>Competing interests</title>
      <p id="Par54">The authors declare no competing interests.</p>
    </notes>
  </notes>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <label>1.</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Murphy</surname>
            <given-names>KP</given-names>
          </name>
        </person-group>
        <source>Machine learning: a probabilistic perspective</source>
        <year>2012</year>
        <edition>1</edition>
        <publisher-loc>Cambridge</publisher-loc>
        <publisher-name>The MIT Press</publisher-name>
      </element-citation>
    </ref>
    <ref id="CR2">
      <label>2.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Fraley</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Raftery</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>mclust: software for model-based cluster analysis</article-title>
        <source>J. Classif.</source>
        <year>1999</year>
        <volume>16</volume>
        <fpage>297</fpage>
        <lpage>306</lpage>
        <pub-id pub-id-type="doi">10.1007/s003579900058</pub-id>
      </element-citation>
    </ref>
    <ref id="CR3">
      <label>3.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Benaglia</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Chauveau</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Hunter</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Young</surname>
            <given-names>D</given-names>
          </name>
        </person-group>
        <article-title>Mixtools: an r package for analyzing mixture models</article-title>
        <source>J. Stat. Softw.</source>
        <year>2009</year>
        <volume>32</volume>
        <issue>6</issue>
        <fpage>1</fpage>
        <lpage>29</lpage>
        <pub-id pub-id-type="doi">10.18637/jss.v032.i06</pub-id>
      </element-citation>
    </ref>
    <ref id="CR4">
      <label>4.</label>
      <mixed-citation publication-type="other">Iovleff S, Bathia P. MixAll: clustering and classification using model-based mixture models. R Foundation for Statistical Computing, Vienna, Austria 2019. R Foundation for Statistical Computing. <ext-link ext-link-type="uri" xlink:href="https://CRAN.R-project.org/package=MixAll">https://CRAN.R-project.org/package=MixAll</ext-link></mixed-citation>
    </ref>
    <ref id="CR5">
      <label>5.</label>
      <mixed-citation publication-type="other">Julienne H, Laville V, McCaw ZR, He Z, Guillemot V, Lasry C, Ziyatdinov A, Vaysse A, Lechat P, Ménager H, Goff WL, Dube MP, Kraft P, Ionita-Laza I, Vilhjálmsson BJ, Aschard H. Multitrait genetic-phenotype associations to connect disease variants and biological mechanisms. bioRxiv 2020. 10.1101/2020.06.26.172999</mixed-citation>
    </ref>
    <ref id="CR6">
      <label>6.</label>
      <mixed-citation publication-type="other">Ghahramani Z, Jordan M. Supervised learning from incomplete data via an em approach. In: Advances in neural information processing systems 6. Morgan-Kaufmann; 1994. pp. 120–127.</mixed-citation>
    </ref>
    <ref id="CR7">
      <label>7.</label>
      <mixed-citation publication-type="other">McCaw Z. MGMM: Missingness aware Gaussian mixture models. R Foundation for Statistical Computing, Vienna, Austria 2021. R Foundation for Statistical Computing. <ext-link ext-link-type="uri" xlink:href="https://CRAN.R-project.org/package=MGMM">https://CRAN.R-project.org/package=MGMM</ext-link></mixed-citation>
    </ref>
    <ref id="CR8">
      <label>8.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Meng</surname>
            <given-names>X-L</given-names>
          </name>
          <name>
            <surname>Rubin</surname>
            <given-names>DB</given-names>
          </name>
        </person-group>
        <article-title>Maximum likelihood estimation via the ECM algorithm: a general framework</article-title>
        <source>Biometrika</source>
        <year>1993</year>
        <volume>80</volume>
        <issue>2</issue>
        <fpage>267</fpage>
        <lpage>278</lpage>
        <pub-id pub-id-type="doi">10.1093/biomet/80.2.267</pub-id>
      </element-citation>
    </ref>
    <ref id="CR9">
      <label>9.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Buuren</surname>
            <given-names>SV</given-names>
          </name>
          <name>
            <surname>Groothuis-Oudshoorn</surname>
            <given-names>K</given-names>
          </name>
        </person-group>
        <article-title>mice: multivariate imputation by chained equations in r</article-title>
        <source>J Stat Softw</source>
        <year>2010</year>
        <volume>45</volume>
        <fpage>1</fpage>
        <lpage>68</lpage>
      </element-citation>
    </ref>
    <ref id="CR10">
      <label>10.</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Little</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Rubin</surname>
            <given-names>D</given-names>
          </name>
        </person-group>
        <source>Statistical analysis with missing data</source>
        <year>2002</year>
        <edition>2</edition>
        <publisher-loc>New York</publisher-loc>
        <publisher-name>Wiley</publisher-name>
      </element-citation>
    </ref>
    <ref id="CR11">
      <label>11.</label>
      <mixed-citation publication-type="other">R Core Team: R: A Language and Environment for Statistical Computing. R Foundation for Statistical Computing, Vienna, Austria 2017. R Foundation for Statistical Computing. <ext-link ext-link-type="uri" xlink:href="https://www.R-project.org/">https://www.R-project.org/</ext-link></mixed-citation>
    </ref>
    <ref id="CR12">
      <label>12.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kowarik</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Templ</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>Imputation with the r package vim</article-title>
        <source>J Stat Softw</source>
        <year>2016</year>
        <volume>74</volume>
        <issue>7</issue>
        <fpage>1</fpage>
        <lpage>16</lpage>
        <pub-id pub-id-type="doi">10.18637/jss.v074.i07</pub-id>
      </element-citation>
    </ref>
    <ref id="CR13">
      <label>13.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Stekhoven</surname>
            <given-names>DJ</given-names>
          </name>
          <name>
            <surname>Bühlmann</surname>
            <given-names>P</given-names>
          </name>
        </person-group>
        <article-title>Missforest-non-parametric missing value imputation for mixed-type data</article-title>
        <source>Bioinformatics</source>
        <year>2011</year>
        <volume>28</volume>
        <issue>1</issue>
        <fpage>112</fpage>
        <lpage>118</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btr597</pub-id>
        <pub-id pub-id-type="pmid">22039212</pub-id>
      </element-citation>
    </ref>
    <ref id="CR14">
      <label>14.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Julienne</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Lechat</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Guillemot</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Lasry</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Yao</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Araud</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Laville</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Vilhjalmsson</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Ménager</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Aschard</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <article-title>JASS: command line and web interface for the joint analysis of GWAS results</article-title>
        <source>NAR Genomics Bioinform</source>
        <year>2020</year>
        <volume>2</volume>
        <issue>1</issue>
        <fpage>003</fpage>
        <pub-id pub-id-type="doi">10.1093/nargab/lqaa003</pub-id>
      </element-citation>
    </ref>
    <ref id="CR15">
      <label>15.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Rand</surname>
            <given-names>WM</given-names>
          </name>
        </person-group>
        <article-title>Objective criteria for the evaluation of clustering methods</article-title>
        <source>J Am Stat Assoc</source>
        <year>1971</year>
        <volume>66</volume>
        <issue>336</issue>
        <fpage>846</fpage>
        <lpage>850</lpage>
        <pub-id pub-id-type="doi">10.1080/01621459.1971.10482356</pub-id>
      </element-citation>
    </ref>
    <ref id="CR16">
      <label>16.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hubert</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Arabie</surname>
            <given-names>P</given-names>
          </name>
        </person-group>
        <article-title>Comparing partitions</article-title>
        <source>J Classif</source>
        <year>1985</year>
        <volume>2</volume>
        <issue>1</issue>
        <fpage>193</fpage>
        <lpage>218</lpage>
        <pub-id pub-id-type="doi">10.1007/BF01908075</pub-id>
      </element-citation>
    </ref>
    <ref id="CR17">
      <label>17.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Weinstein</surname>
            <given-names>JN</given-names>
          </name>
          <name>
            <surname>Collisson</surname>
            <given-names>EA</given-names>
          </name>
          <name>
            <surname>Mills</surname>
            <given-names>GB</given-names>
          </name>
          <name>
            <surname>Shaw</surname>
            <given-names>KRM</given-names>
          </name>
          <name>
            <surname>Ozenberger</surname>
            <given-names>BA</given-names>
          </name>
          <name>
            <surname>Ellrott</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Shmulevich</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Sander</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Stuart</surname>
            <given-names>JM</given-names>
          </name>
          <name>
            <surname>Network</surname>
            <given-names>CGAR</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>The cancer genome atlas pan-cancer analysis project</article-title>
        <source>Nat Genet</source>
        <year>2013</year>
        <volume>45</volume>
        <issue>10</issue>
        <fpage>1113</fpage>
        <pub-id pub-id-type="doi">10.1038/ng.2764</pub-id>
        <pub-id pub-id-type="pmid">24071849</pub-id>
      </element-citation>
    </ref>
  </ref-list>
</back>
