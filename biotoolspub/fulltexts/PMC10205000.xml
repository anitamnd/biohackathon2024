<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Gigascience</journal-id>
    <journal-id journal-id-type="iso-abbrev">Gigascience</journal-id>
    <journal-id journal-id-type="publisher-id">gigascience</journal-id>
    <journal-title-group>
      <journal-title>GigaScience</journal-title>
    </journal-title-group>
    <issn pub-type="epub">2047-217X</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">10205000</article-id>
    <article-id pub-id-type="doi">10.1093/gigascience/giad036</article-id>
    <article-id pub-id-type="publisher-id">giad036</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Research</subject>
      </subj-group>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI00960</subject>
        <subject>AcademicSubjects/SCI02254</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>CoVEffect: interactive system for mining the effects of SARS-CoV-2 mutations and variants based on deep learning</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-5465-6182</contrib-id>
        <name>
          <surname>Serna García</surname>
          <given-names>Giuseppe</given-names>
        </name>
        <aff><institution>Dipartimento di Informazione, Elettronica e Bioingegneria, 20133 Milano Country: Italy</institution>, <country country="IT">Italy</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-5645-5886</contrib-id>
        <name>
          <surname>Al Khalaf</surname>
          <given-names>Ruba</given-names>
        </name>
        <aff><institution>Dipartimento di Informazione, Elettronica e Bioingegneria, 20133 Milano Country: Italy</institution>, <country country="IT">Italy</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0009-0002-5423-6978</contrib-id>
        <name>
          <surname>Invernici</surname>
          <given-names>Francesco</given-names>
        </name>
        <aff><institution>Dipartimento di Informazione, Elettronica e Bioingegneria, 20133 Milano Country: Italy</institution>, <country country="IT">Italy</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0003-0671-2415</contrib-id>
        <name>
          <surname>Ceri</surname>
          <given-names>Stefano</given-names>
        </name>
        <aff><institution>Dipartimento di Informazione, Elettronica e Bioingegneria, 20133 Milano Country: Italy</institution>, <country country="IT">Italy</country></aff>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0001-8016-5750</contrib-id>
        <name>
          <surname>Bernasconi</surname>
          <given-names>Anna</given-names>
        </name>
        <!--anna.bernasconi@polimi.it-->
        <aff><institution>Dipartimento di Informazione, Elettronica e Bioingegneria, 20133 Milano Country: Italy</institution>, <country country="IT">Italy</country></aff>
        <xref rid="cor1" ref-type="corresp"/>
      </contrib>
    </contrib-group>
    <author-notes>
      <corresp id="cor1">Correspondence address. Anna Bernasconi. Via Ponzio 34/5, 20133, Milano, Italy. E-mail: <email>anna.bernasconi@polimi.it</email></corresp>
    </author-notes>
    <pub-date pub-type="epub" iso-8601-date="2023-05-23">
      <day>23</day>
      <month>5</month>
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>23</day>
      <month>5</month>
      <year>2023</year>
    </pub-date>
    <volume>12</volume>
    <elocation-id>giad036</elocation-id>
    <history>
      <date date-type="received">
        <day>05</day>
        <month>12</month>
        <year>2022</year>
      </date>
      <date date-type="rev-recd">
        <day>11</day>
        <month>4</month>
        <year>2023</year>
      </date>
      <date date-type="accepted">
        <day>27</day>
        <month>4</month>
        <year>2023</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2023. Published by Oxford University Press GigaScience.</copyright-statement>
      <copyright-year>2023</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="giad036.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="abs1">
        <title>Background</title>
        <p>Literature about SARS-CoV-2 widely discusses the effects of variations that have spread in the past 3 years. Such information is dispersed in the texts of several research articles, hindering the possibility of practically integrating it with related datasets (e.g., millions of SARS-CoV-2 sequences available to the community). We aim to fill this gap, by mining literature abstracts to extract—for each variant/mutation—its related effects (in epidemiological, immunological, clinical, or viral kinetics terms) with labeled higher/lower levels in relation to the nonmutated virus.</p>
      </sec>
      <sec id="abs2">
        <title>Results</title>
        <p>The proposed framework comprises (i) the provisioning of abstracts from a COVID-19–related big data corpus (CORD-19) and (ii) the identification of mutation/variant effects in abstracts using a GPT2-based prediction model. The above techniques enable the prediction of mutations/variants with their effects and levels in 2 distinct scenarios: (i) the batch annotation of the most relevant CORD-19 abstracts and (ii) the on-demand annotation of any user-selected CORD-19 abstract through the CoVEffect web application (<ext-link xlink:href="http://gmql.eu/coveffect/" ext-link-type="uri">http://gmql.eu/coveffect</ext-link>), which assists expert users with semiautomated data labeling. On the interface, users can inspect the predictions and correct them; user inputs can then extend the training dataset used by the prediction model. Our prototype model was trained through a carefully designed process, using a minimal and highly diversified pool of samples.</p>
      </sec>
      <sec id="abs3">
        <title>Conclusions</title>
        <p>The CoVEffect interface serves for the assisted annotation of abstracts, allowing the download of curated datasets for further use in data integration or analysis pipelines. The overall framework can be adapted to resolve similar unstructured-to-structured text translation tasks, which are typical of biomedical domains.</p>
      </sec>
    </abstract>
    <kwd-group kwd-group-type="keywords">
      <kwd>deep learning</kwd>
      <kwd>language models</kwd>
      <kwd>machine learning interpretability</kwd>
      <kwd>CORD-19 dataset</kwd>
      <kwd>SARS-CoV-2</kwd>
      <kwd>viral variants</kwd>
      <kwd>viral mutations</kwd>
      <kwd>web interface</kwd>
    </kwd-group>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>NextGenerationEU program</institution>
          </institution-wrap>
        </funding-source>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="15"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec sec-type="intro" id="sec1">
    <title>Introduction</title>
    <p>The COVID-19 pandemic has made SARS-CoV-2 one of the most studied viruses in the world, with research on its variation, spread, and impacts on the host immune system. At the start of 2020, it was estimated that 200,000 coronavirus-related journal articles and preprints would be published by the end of the year [<xref rid="bib1" ref-type="bibr">1</xref>]. As of today, about 3 years since the beginning of the pandemic, more than 1 million articles have become available.</p>
    <p>This wide COVID-19–related literature is still largely unexplored but can be employed for data and text analysis. Most COVID-19 research outputs have been gathered within the COVID-19 Open Research Dataset (CORD-19 [<xref rid="bib2" ref-type="bibr">2</xref>]) by the Allen Institute. The corpus includes preprints and papers from Semantic Scholar up to mid-2022, sourced from PubMedCentral, PubMed, the World Health Organization’s Covid-19 Database, and the preprint servers bioRxiv, medRxiv, and arXiv.</p>
    <p>In parallel, there has been a worldwide spread of open data representing SARS-CoV-2 sequences (through the data sources GISAID [<xref rid="bib3" ref-type="bibr">3</xref>], GenBank [<xref rid="bib4" ref-type="bibr">4</xref>] and COG-UK [<xref rid="bib5" ref-type="bibr">5</xref>]), gathered on repositories by public and private institutes. The study of viral sequences has addressed several research questions related to the epidemiology and immunology aspects of the viral spread [<xref rid="bib6" ref-type="bibr">6–8</xref>]. Much attention has also been dedicated to identifying amino acid–level mutations (or groups of them—coordinated within variants) that lead to particular changes in the behavior of the virus and its ability to establish infections—when compared to the wild type [<xref rid="bib9" ref-type="bibr">9–11</xref>]. Note that, currently, it is hard to integrate data about sequences (with associated mutations) with information about variation effects, as the latter is not available in structured formats.</p>
    <p>Structured information can be retrieved resorting to Natural Language Processing (NLP) techniques. NLP models usually require a considerable quantity of training data to learn their tasks. However, recent breakthroughs with deep learning models such as the Generative Pretrained Transformer (e.g., GPT2 [<xref rid="bib12" ref-type="bibr">12</xref>]) allowed the design of multitask learners that use fewer data than classic supervised machine learning techniques.</p>
    <p>In this work, we use GPT2 to learn tuples that contain a SARS-CoV-2 variation, its effect and level, starting from CORD-19 abstracts. The model is trained on a small dataset that we carefully fabricated, as no such ready-to-use dataset was available. As our system enables expert users to provide more input annotations, it is preferable to use a model that dynamically and efficiently learns how to handle new annotations over time; in parallel, it is desirable to augment the training dataset in a continuous manner. To allow for this, we use a semiautomated data labeling system, which employs the predictive model to assist the human labeler, combining manual annotations with automatic tuples extraction. The model is used to recommend labels and automate basic functions in a labeling interface. The user can decide when to employ the generated labeled data for augmenting the training dataset and retraining the model. A user-friendly web interface CoVEffect allows expert users to annotate abstracts with variation effects without requiring any programming or data management knowledge.</p>
  </sec>
  <sec id="sec2">
    <title>Related Work</title>
    <p>Currently, the task of recognizing mutations and variants’ effects needs to be performed by hand. There are a very few resources that provide this kind of information; when this is the case, they are exclusively manually curated. FaviCoV and ESC [<xref rid="bib13" ref-type="bibr">13</xref>, <xref rid="bib14" ref-type="bibr">14</xref>], respectively, store SARS-CoV-2 genetic mutations that are functionally relevant and are associated with immune escape. The antigenic role of amino acid replacements in the context of the human immune response is also the focus of the COG-UK Mutation Explorer [<xref rid="bib15" ref-type="bibr">15</xref>], while a list from the World Health Organization (WHO) concentrates on specific replacements that characterize variants [<xref rid="bib16" ref-type="bibr">16</xref>]. Torrens-Fontanals et al.[<xref rid="bib17" ref-type="bibr">17</xref>] report on how variation impacts can be predicted. Online resources such as CoVariants [<xref rid="bib18" ref-type="bibr">18</xref>], European Centre for Disease Prevention and Control [<xref rid="bib19" ref-type="bibr">19</xref>], WHO [<xref rid="bib20" ref-type="bibr">20</xref>], and Centers for Disease Control and Prevention (CDC) [<xref rid="bib21" ref-type="bibr">21</xref>] explain variants’ effects, commenting on how they are reported in the literature. We previously made extensive curation of effects stored in CoV2K [<xref rid="bib22" ref-type="bibr">22</xref>], a knowledge base of data and knowledge about SARS-CoV-2; our cumbersome manual curation approach had quickly become unfeasible, prompting us to explore alternative solutions.</p>
    <p>Several NLP techniques have been used and adapted to bioinformatics-relevant problems, as reported in surveys such as [<xref rid="bib23" ref-type="bibr">23</xref>] or [<xref rid="bib24" ref-type="bibr">24</xref>]. Research applications concerned omics (e.g., prediction of protein classification/structure [<xref rid="bib25" ref-type="bibr">25</xref>], motifs [<xref rid="bib26" ref-type="bibr">26</xref>], or drugs to be developed [<xref rid="bib27" ref-type="bibr">27</xref>]) and biomedical imaging/signal processing [<xref rid="bib28" ref-type="bibr">28</xref>].</p>
    <p>Regarding biomedical text extraction, a wealth of studies is focused on clinical NLP, regarding electronic health records and clinical notes [<xref rid="bib29" ref-type="bibr">29–31</xref>]. For extracting phenotype–genotype relationships, Singhal et al. [<xref rid="bib32" ref-type="bibr">32</xref>] proposed a 3-step pipeline that (i) recognizes 3 different kinds of entities (mutations, diseases, genes) with entity-specific tools of PubTator [<xref rid="bib33" ref-type="bibr">33</xref>], (ii) links mutations with diseases using a Machine Learning (ML) binary classifier [<xref rid="bib34" ref-type="bibr">34</xref>], and (iii) interprets mutations in the context of specific genes.</p>
    <p>A very recent tool called ViMRT [<xref rid="bib35" ref-type="bibr">35</xref>] employs ad hoc optimized rules and regular expressions for the extraction of viral mutations; a whole infrastructure is built with this sole purpose, demonstrating the complexity of the task, whose resolution remains largely uncovered.</p>
    <p>Instead, the most recent approaches to biomedical text extraction tasks have employed transformer-based techniques, as reviewed in [<xref rid="bib36" ref-type="bibr">36</xref>] and [<xref rid="bib37" ref-type="bibr">37–39</xref>]; they report that current works are mainly focused on connections between entities [<xref rid="bib40" ref-type="bibr">40</xref>, <xref rid="bib41" ref-type="bibr">41</xref>]. Very few works addressed results’ explainability combined with transformers in this domain [<xref rid="bib42" ref-type="bibr">42</xref>, <xref rid="bib43" ref-type="bibr">43</xref>].</p>
    <p>In our past work [<xref rid="bib44" ref-type="bibr">44</xref>, <xref rid="bib45" ref-type="bibr">45</xref>], we employed deep learning transformer-based techniques for NLP to infer attributes from Gene Expression Omnibus [<xref rid="bib46" ref-type="bibr">46</xref>] experiment metadata, formulating the problem as a translation task. Cannizzaro et al. [<xref rid="bib44" ref-type="bibr">44</xref>] and Serna Garcia et al. [<xref rid="bib45" ref-type="bibr">45</xref>] achieved the result of translating Gene Expression Omnibus experiment descriptions into key:value pairs (e.g., cell line:K562, disease:myeloid leukemia, assembly:hg19, assay:Chip-Seq, target:H3K9me3).</p>
    <p>CoVEffect stems from this thread of works, but it is carefully adapted to solve a more complex task: that of predicting a series of tuples from SARS-CoV-2–related abstracts where we consider a variation, its effect, and the change of its level. Each of the currently available systems supports only one user-driven annotation [<xref rid="bib47" ref-type="bibr">47</xref>], predictions of single independent annotations with ontological terms [<xref rid="bib48" ref-type="bibr">48</xref>], or biomedical general-purpose triplets based on existing knowledge graphs [<xref rid="bib49" ref-type="bibr">49</xref>], especially targeted to protein–protein interactions [<xref rid="bib50" ref-type="bibr">50</xref>]. These correspond to different tasks than the one performed by CoVEffect, and the described approaches do not allow for online modifications of the training dataset. Our purpose is closer in spirit to the one targeted in Mahajan et al. [<xref rid="bib51" ref-type="bibr">51</xref>]; however, their work is focused on clinical aspects (text is extracted from electronic health records instead of research abstracts) and is not supported by a user-oriented interface.</p>
    <p>All in all, to the best of our knowledge, CoVEffect is one of the first transformer-based approaches applied to biomedical tasks, combined with explainability approaches.</p>
  </sec>
  <sec sec-type="materials|methods" id="sec3">
    <title>Materials and Methods</title>
    <p>Figure <xref rid="fig1" ref-type="fig">1</xref> captures the high-level architecture of the whole framework. As our input, we consider the wealth of information contained in the CORD-19 dataset. From the data corpus, we extract only abstracts that reach sufficient quality standards and provide essential metadata.</p>
    <fig position="float" id="fig1">
      <label>Figure 1:</label>
      <caption>
        <p>CoVEffect framework overview.</p>
      </caption>
      <graphic xlink:href="giad036fig1" position="float"/>
    </fig>
    <p>Two offline processes exploit the dataset: (i) <italic toggle="yes">data provisioning</italic>, where we perform data curation and prepare a dataset that supports indexed keyword-based search and similarity-based search, and (ii) <italic toggle="yes">prediction model setup</italic>, where we manually craft a dataset, use it for training the model, check its performances (through a validation dataset), and evaluate the need to change or augment the initial training dataset.</p>
    <p>The artifacts produced by these 2 processes are the indexed curated dataset of CORD-19 abstracts and the trained prediction model. They feed 2 possible modes of use, sharing standardized output formats:</p>
    <list list-type="bullet">
      <list-item>
        <p>an offline <italic toggle="yes">Batch Annotator</italic>, which provides annotated data for a selection of 7,230 relevant abstracts from the CORD-19 corpus, and</p>
      </list-item>
      <list-item>
        <p>an interactive online <italic toggle="yes">Web Application</italic> employed by expert users to annotate samples and inspect predicted annotations.</p>
      </list-item>
    </list>
    <sec id="sec3-1">
      <title>Data provisioning</title>
      <p>From the latest and final CORD-19 release (issued in June 2022), we collected <italic toggle="yes">metadata.csv</italic>, a table with metadata of all papers, and <italic toggle="yes">cord_19_embeddings.tar.gz</italic>, a collection of precomputed SPECTER [<xref rid="bib52" ref-type="bibr">52</xref>] document embeddings for each paper. The data provisioning pipeline aims to produce a curated set of abstracts (equipped with metadata) to support the activities of the learning framework.</p>
      <sec id="sec3-1-1">
        <title>Data curation</title>
        <p>As described by Wang et al. [<xref rid="bib2" ref-type="bibr">2</xref>], the CORD-19 dataset gathers COVID-19–related papers from several sources. In this dataset, papers are already harmonized and de-duplicated: in the metadata table, each <italic toggle="yes">cord_uid</italic> represents a cluster of papers with colliding identifiers, such as <italic toggle="yes">DOI</italic> or <italic toggle="yes">arxiv_id</italic>. For our system, we extracted a portion of the original CORD-19 dataset: we kept only 1 record for each paper, thereby avoiding duplicated entries and easing the annotation user experience. To this end, we designed a reconciliation step: for each cluster, we favored the entry with the longest abstract and promoted values from other members of the cluster to fill in the missing information; then, we removed the other members of the cluster, obtaining only 1 entry for each paper. We also removed those papers for which an abstract was not available. Additionally, we used <italic toggle="yes">langdetect</italic> [<xref rid="bib53" ref-type="bibr">53</xref>]—a language detection library ported from Google’s <italic toggle="yes">language-detection—</italic>to detect the language of the abstracts and filtered out the papers not written in English.</p>
      </sec>
      <sec id="sec3-1-2">
        <title>Abstract retrieval</title>
        <p>The curated dataset has been indexed to support search on the paper abstracts. Such a step is functional to the retrieval task of the learning system, where the user searches abstracts that are of interest. For the purpose, we built a search engine leveraging 2 existing libraries.</p>
        <list list-type="bullet">
          <list-item>
            <p>The <italic toggle="yes">keyword-based search</italic> is based on <italic toggle="yes">Whoosh</italic> [<xref rid="bib54" ref-type="bibr">54</xref>], a full-text indexing and searching library, to let users search the abstracts using combinations of keywords.</p>
          </list-item>
          <list-item>
            <p>The <italic toggle="yes">similarity-based discovery</italic> is based on <italic toggle="yes">Annoy</italic> [<xref rid="bib55" ref-type="bibr">55</xref>], an approximate nearest-neighbor search library, to let the users discover abstracts similar to those already selected. These recommendations are computed by exploiting the SPECTER embeddings of the papers, which are document-level vector representations originated from citation-based transformers. For our purpose, we dramatically reduced the dimensionality of the vector space from 768 to 100. The 100 dimensions were selected by means of a principal component analysis, resulting in a representation with an explained variance ratio of 74%. In line with the recommendation task overviewed in [<xref rid="bib52" ref-type="bibr">52</xref>], we chose cosine similarity as a similarity metric among papers by setting the distance parameter of the AnnoyIndex to “angular.”</p>
          </list-item>
        </list>
      </sec>
    </sec>
    <sec id="sec3-2">
      <title>Language model and task design</title>
      <sec id="sec3-2-1">
        <title>Model</title>
        <p>In this work, we favored text-generative transformer models over BERT-like models [<xref rid="bib56" ref-type="bibr">56</xref>] because of their ability to perform multitask learning [<xref rid="bib12" ref-type="bibr">12</xref>] and to easily adapt to new tasks. Indeed, text-generative models formulate multitask learning as a conditional distribution <italic toggle="yes">P</italic>(<italic toggle="yes">output</italic>|<italic toggle="yes">input,task</italic>), where the task to be performed can be easily expressed in the form of text. We also make a distinction between general and domain-specific pretrained models. General models are usually pretrained with large datasets aiming to be as general as possible (e.g., BookCorpus [<xref rid="bib57" ref-type="bibr">57</xref>] and English Wikipedia). Domain-specific models, instead, are further pretrained in order to fit a particular application (e.g., medicine, biology). In our case, the specific domain knowledge is represented by the CORD-19 dataset [<xref rid="bib2" ref-type="bibr">2</xref>]. In the past years, several new generative models have been proposed (e.g., T5, BART, GTP3, BLOOM). These models achieved increasingly better performances, mostly by increasing the size of the model parameters and the size of the pretraining datasets. As a trade-off, bigger models are significantly slower.</p>
        <p>In our work, the model is also used in an interactive way (with a domain expert), and thus we preferred smaller models to large models. Considering all these aspects, we opted for a domain-specific version of a gpt2-small model available on the huggingface model hub [<xref rid="bib58" ref-type="bibr">58</xref>]; it represents a reasonable compromise between model size and performances in a very specific domain. We propose it as a baseline for future works that could make use of our dataset.</p>
      </sec>
      <sec id="sec3-2-2">
        <title>Target data format</title>
        <p>Abstracts are annotated by recognizing structured tuples of the form ⟨<italic toggle="yes">type,entity,effect,level</italic>⟩. Possible <italic toggle="yes">types</italic> are “mutation” and “variant.” With <italic toggle="yes">mutation</italic>, we refer to amino acid changes within specific proteins, occurring in a position where a reference residue has been changed into an alternative residue. These changes correspond to nonsynonymous nucleotide mutations; we do not consider synonymous nucleotide mutations, as they typically do not influence the protein functionalities. In this work, we focus on substitutions, leaving aside insertions and deletions as they would require substantial additional training due to their very heterogeneous formulations. With <italic toggle="yes">variant</italic>, we denote forms of the SARS-CoV-2 that are considerably different from the original wild-type [<xref rid="bib59" ref-type="bibr">59</xref>], as they accumulated a set of amino acid changes that characterize their phenotypic characteristics [<xref rid="bib60" ref-type="bibr">60</xref>]. Variants are typically associated with a name to easily address them.</p>
        <p>In our tuples, <italic toggle="yes">entities</italic> are the names of mutations (e.g., Spike_N501Y or NSP12_P323L) or of variants—for example, Alpha, Delta, Omicron (as named by WHO [<xref rid="bib20" ref-type="bibr">20</xref>]) or B.1.1.7, B.1.617, B.1.519 (as named by Pangolin [<xref rid="bib61" ref-type="bibr">61</xref>]).</p>
        <p><italic toggle="yes">Effects</italic> are chosen from a taxonomy, that is, a controlled vocabulary of terms, including, for example, transmissibility, disease severity, resistance to antiviral drugs, or change in the protein kinetics (flexibility or stability properties). We previously proposed an initial version of this vocabulary [<xref rid="bib22" ref-type="bibr">22</xref>, <xref rid="bib62" ref-type="bibr">62</xref>], which has now evolved into a complete list of effects organized by category (“epidemiology,” “immunology,” “viral kinetics and dynamics,” or “diagnosis, prevention, and treatments”). The full list can be found the AdditionalFile1-effects-taxonomy [<xref rid="bib63" ref-type="bibr">63</xref>].</p>
        <p>Finally, each effect has an associated <italic toggle="yes">level</italic>, that is, higher, lower, unaffected, undefined, or no evidence (see AdditionalFile2levels-taxonomy [<xref rid="bib63" ref-type="bibr">63</xref>] for detailed definitions).</p>
      </sec>
      <sec id="sec3-2-3">
        <title>Task</title>
        <p>The macro-task performed by our prediction model is a text-to-table task, translating a full paper abstract into a table of tuples, each one with the fields described above. Each tuple is composed itself by solving 3 subtasks:</p>
        <list list-type="roman-lower">
          <list-item>
            <p>entity extraction of <italic toggle="yes">mutations/variants</italic> (from which also the <italic toggle="yes">type</italic> is inferred);</p>
          </list-item>
          <list-item>
            <p>classification of <italic toggle="yes">effects</italic>; and</p>
          </list-item>
          <list-item>
            <p>classification of <italic toggle="yes">levels</italic>.</p>
          </list-item>
        </list>
        <p>Tasks (ii) and (iii) are classic classification tasks, targeting a known set of values. Instead, the entity extraction task (i) is more complex than a classical Named-Entity-Recognition (NER) task: we extract mutations and variants with an associated effect and corresponding level. The complexity of this macro-task increases also because the number of tuples of the table output for each abstract is not fixed <italic toggle="yes">a priori</italic>. Instead, it depends on the number of extracted entities and on the number of effects exhibited by the entities. Text-generative models allow to fine-tune a single model that is able to perform this macro-task.</p>
        <p>Figure <xref rid="fig2" ref-type="fig">2</xref> illustrates the working principle of our prediction task on a real abstract [<xref rid="bib64" ref-type="bibr">64</xref>]. Three different tuples are recognized in the text, all referring to the Spike V367F mutation, but predicating on different effects with higher levels. Note that the information about the protein on which the mutation occurs is positioned in a part of the text that is far apart from the signature of the mutation. In the figure, we can also appreciate the difference between the predictions obtained by our approach versus the ones that a typical NER task could obtain.</p>
        <fig position="float" id="fig2">
          <label>Figure 2:</label>
          <caption>
            <p>Difference between tasks resolved by an NER approach (only recognizing entities from a text excerpt) and our translation-based approach (targeting entities with connected effects and levels). The abstract excerpt is extracted from a paper by Ou et al. in the <italic toggle="yes">Journal of Virology</italic> [<xref rid="bib64" ref-type="bibr">64</xref>]. Information used to form our tuples is connected through blue lines. Yellow identifies information on <italic toggle="yes">type</italic> and <italic toggle="yes">entity</italic>, gray on <italic toggle="yes">effect</italic>, and blue on <italic toggle="yes">level</italic>. Green rectangles identify the typical entity extraction performed by an NER approach.</p>
          </caption>
          <graphic xlink:href="giad036fig2" position="float"/>
        </fig>
      </sec>
      <sec id="sec3-2-4">
        <title>RegEx-based prediction filtering</title>
        <p>A common issue for text-generative models is the instability of the generated text (i.e., these models tend to repeat words or to generate meaningless words). To mitigate this effect, we make use of a filter based on regular expressions that only allows outputs of the model corresponding to predefined legal values. The RegEx filter is applied after the extraction of mutations and variants to include only predictions that follow these patterns:</p>
        <list list-type="bullet">
          <list-item>
            <p>Mutations: ^([A-Z0-9]+_)[A-Z]\d{1,4}[A-Z]$</p>
          </list-item>
          <list-item>
            <p>Variants: ^([A-Z]{1,2}\.[0–9]{1,3})(\.[0–9]{1,3}){,2}$</p>
          </list-item>
        </list>
      </sec>
    </sec>
    <sec id="sec3-3">
      <title>Prediction model setup</title>
      <p>The previously described task is more complex than a classical NER task, as it requires to connect different linked information. In biomedical literature, training datasets for supervised learning are typically available for general biomedical terms [<xref rid="bib38" ref-type="bibr">38</xref>], which are of no use for our purpose; therefore, we prepared our own training dataset. This operation requires a costly manual curation, operated by highly expert users. This is an inevitable effort to handle data scarcity, analyzed in [<xref rid="bib65" ref-type="bibr">65</xref>] in general terms, becoming even more relevant in biomedical fields [<xref rid="bib66" ref-type="bibr">66</xref>, <xref rid="bib67" ref-type="bibr">67</xref>]. To minimize such effort in our case, we implemented a process that supports the building of small high-quality training datasets.</p>
      <p>We started with a small number of initial abstracts (corresponding to a first set of 30 papers). Using this seed, we used an iterative process of 4 steps (represented in Fig. <xref rid="fig3" ref-type="fig">3</xref>):</p>
      <list list-type="order">
        <list-item>
          <p>Training dataset enhancement. Except for the first round (30 abstracts), at each iteration, we include (typically 5) new abstracts, allowing stronger training on insufficiently represented cases.</p>
        </list-item>
        <list-item>
          <p>Model training. This procedure includes parameter tuning and possible changes based on previously obtained results.</p>
        </list-item>
        <list-item>
          <p>Validation scores computation. The model prediction performances are evaluated on a validation dataset of 50 papers, carefully chosen to be as representative as possible of the problem at hand. By comparing expert-provided annotations and predicted annotations on the validation dataset, we compute performance scores.</p>
        </list-item>
        <list-item>
          <p>Evaluation of results and errors. The obtained scores are considered; the iteration is repeated until satisfactory scores are obtained.</p>
        </list-item>
      </list>
      <fig position="float" id="fig3">
        <label>Figure 3:</label>
        <caption>
          <p>Iterative process for the prediction model setup.</p>
        </caption>
        <graphic xlink:href="giad036fig3" position="float"/>
      </fig>
      <sec id="sec3-3-1">
        <title>Training dataset preparation</title>
        <p>The set of abstracts used for initial training was built by following a number of criteria:</p>
        <list list-type="bullet">
          <list-item>
            <p>priority was given to published articles over preprints, excluding papers that duplicated the same research;</p>
          </list-item>
          <list-item>
            <p>priority was given to simple abstracts over abstracts with numerous and complex annotations;</p>
          </list-item>
          <list-item>
            <p>a wide selection of mutations (from different proteins) and variants (both WHO- and Pangolin-based names) was employed;</p>
          </list-item>
          <list-item>
            <p>abstracts involving mutations of insertion/deletion types were excluded at this stage, due to their highly heterogeneous representations;</p>
          </list-item>
          <list-item>
            <p>abstracts associating effects to groups of mutations (rather than to a single mutation or variant) were also excluded not to overly complicate the prediction task; and</p>
          </list-item>
          <list-item>
            <p>no effect of our taxonomy (see AdditionalFile1-effects-taxonomy [<xref rid="bib63" ref-type="bibr">63</xref>]) was underrepresented in the dataset.</p>
          </list-item>
        </list>
        <p>Table <xref rid="tbl1" ref-type="table">1</xref> shows comprehensive counts of abstracts containing information on each effect of our taxonomy, both for the training and the validation datasets; AdditionalFile3-training_dataset_target [<xref rid="bib63" ref-type="bibr">63</xref>] contains the manual annotations associated with the 221 abstracts selected for training (after several iterations on the process shown in Fig. <xref rid="fig3" ref-type="fig">3</xref>).</p>
        <table-wrap position="float" id="tbl1">
          <label>Table 1:</label>
          <caption>
            <p>Number of abstracts representing each effect in the validation and train datasets</p>
          </caption>
          <table frame="hsides" rules="groups">
            <thead>
              <tr>
                <th rowspan="1" colspan="1">Category</th>
                <th rowspan="1" colspan="1">Effect</th>
                <th rowspan="1" colspan="1"># training abs</th>
                <th rowspan="1" colspan="1"># valid. abs</th>
                <th rowspan="1" colspan="1"># training tuples</th>
                <th rowspan="1" colspan="1"># valid. tuples</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td rowspan="1" colspan="1">Viral kin. and dyn.</td>
                <td rowspan="1" colspan="1">protein_flexibility</td>
                <td rowspan="1" colspan="1">8</td>
                <td rowspan="1" colspan="1">3</td>
                <td rowspan="1" colspan="1">16</td>
                <td rowspan="1" colspan="1">11</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1"/>
                <td rowspan="1" colspan="1">protein_stability</td>
                <td rowspan="1" colspan="1">29</td>
                <td rowspan="1" colspan="1">3</td>
                <td rowspan="1" colspan="1">47</td>
                <td rowspan="1" colspan="1">9</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1"/>
                <td rowspan="1" colspan="1">host–virus interactions</td>
                <td rowspan="1" colspan="1">5</td>
                <td rowspan="1" colspan="1">1</td>
                <td rowspan="1" colspan="1">12</td>
                <td rowspan="1" colspan="1">1</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1"/>
                <td rowspan="1" colspan="1">binding_to_host_receptor</td>
                <td rowspan="1" colspan="1">45</td>
                <td rowspan="1" colspan="1">7</td>
                <td rowspan="1" colspan="1">94</td>
                <td rowspan="1" colspan="1">10</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1"/>
                <td rowspan="1" colspan="1">binding_to_antibodies</td>
                <td rowspan="1" colspan="1">16</td>
                <td rowspan="1" colspan="1">3</td>
                <td rowspan="1" colspan="1">30</td>
                <td rowspan="1" colspan="1">3</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1"/>
                <td rowspan="1" colspan="1">viral_load</td>
                <td rowspan="1" colspan="1">27</td>
                <td rowspan="1" colspan="1">7</td>
                <td rowspan="1" colspan="1">30</td>
                <td rowspan="1" colspan="1">9</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1"/>
                <td rowspan="1" colspan="1">viral_incubation_period</td>
                <td rowspan="1" colspan="1">8</td>
                <td rowspan="1" colspan="1">1</td>
                <td rowspan="1" colspan="1">9</td>
                <td rowspan="1" colspan="1">1</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1"/>
                <td rowspan="1" colspan="1">viral_replication</td>
                <td rowspan="1" colspan="1">16</td>
                <td rowspan="1" colspan="1">2</td>
                <td rowspan="1" colspan="1">22</td>
                <td rowspan="1" colspan="1">2</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1"/>
                <td rowspan="1" colspan="1">viral_fitness</td>
                <td rowspan="1" colspan="1">14</td>
                <td rowspan="1" colspan="1">4</td>
                <td rowspan="1" colspan="1">21</td>
                <td rowspan="1" colspan="1">10</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1"/>
                <td rowspan="1" colspan="1">intermolecular_interactions</td>
                <td rowspan="1" colspan="1">20</td>
                <td rowspan="1" colspan="1">2</td>
                <td rowspan="1" colspan="1">0</td>
                <td rowspan="1" colspan="1">2</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1"/>
                <td rowspan="1" colspan="1">protein_functioning</td>
                <td rowspan="1" colspan="1">19</td>
                <td rowspan="1" colspan="1">2</td>
                <td rowspan="1" colspan="1">32</td>
                <td rowspan="1" colspan="1">5</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1"/>
                <td rowspan="1" colspan="1">protein_conformational_optimization</td>
                <td rowspan="1" colspan="1">28</td>
                <td rowspan="1" colspan="1">4</td>
                <td rowspan="1" colspan="1">60</td>
                <td rowspan="1" colspan="1">6</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1"/>
                <td rowspan="1" colspan="1">entry_efficiency</td>
                <td rowspan="1" colspan="1">9</td>
                <td rowspan="1" colspan="1">1</td>
                <td rowspan="1" colspan="1">14</td>
                <td rowspan="1" colspan="1">1</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">Immunology</td>
                <td rowspan="1" colspan="1">sensitivity_to_antibodies</td>
                <td rowspan="1" colspan="1">18</td>
                <td rowspan="1" colspan="1">9</td>
                <td rowspan="1" colspan="1">24</td>
                <td rowspan="1" colspan="1">20</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1"/>
                <td rowspan="1" colspan="1">sensitivity_to_convalescent_sera</td>
                <td rowspan="1" colspan="1">20</td>
                <td rowspan="1" colspan="1">6</td>
                <td rowspan="1" colspan="1">32</td>
                <td rowspan="1" colspan="1">10</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1"/>
                <td rowspan="1" colspan="1">sensitivity_to_vaccinated_sera</td>
                <td rowspan="1" colspan="1">20</td>
                <td rowspan="1" colspan="1">6</td>
                <td rowspan="1" colspan="1">35</td>
                <td rowspan="1" colspan="1">11</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1"/>
                <td rowspan="1" colspan="1">immune_escape</td>
                <td rowspan="1" colspan="1">35</td>
                <td rowspan="1" colspan="1">11</td>
                <td rowspan="1" colspan="1">69</td>
                <td rowspan="1" colspan="1">21</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">Epidemiology</td>
                <td rowspan="1" colspan="1">viral_transmission</td>
                <td rowspan="1" colspan="1">66</td>
                <td rowspan="1" colspan="1">18</td>
                <td rowspan="1" colspan="1">95</td>
                <td rowspan="1" colspan="1">33</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1"/>
                <td rowspan="1" colspan="1">infectivity</td>
                <td rowspan="1" colspan="1">44</td>
                <td rowspan="1" colspan="1">13</td>
                <td rowspan="1" colspan="1">65</td>
                <td rowspan="1" colspan="1">24</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1"/>
                <td rowspan="1" colspan="1">viral_virulence</td>
                <td rowspan="1" colspan="1">9</td>
                <td rowspan="1" colspan="1">3</td>
                <td rowspan="1" colspan="1">22</td>
                <td rowspan="1" colspan="1">5</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1"/>
                <td rowspan="1" colspan="1">disease_severity</td>
                <td rowspan="1" colspan="1">32</td>
                <td rowspan="1" colspan="1">8</td>
                <td rowspan="1" colspan="1">62</td>
                <td rowspan="1" colspan="1">15</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1"/>
                <td rowspan="1" colspan="1">risk_of_hospitalization</td>
                <td rowspan="1" colspan="1">10</td>
                <td rowspan="1" colspan="1">7</td>
                <td rowspan="1" colspan="1">26</td>
                <td rowspan="1" colspan="1">10</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1"/>
                <td rowspan="1" colspan="1">risk_of_reinfection</td>
                <td rowspan="1" colspan="1">11</td>
                <td rowspan="1" colspan="1">3</td>
                <td rowspan="1" colspan="1">11</td>
                <td rowspan="1" colspan="1">7</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1"/>
                <td rowspan="1" colspan="1">fatality_rate</td>
                <td rowspan="1" colspan="1">20</td>
                <td rowspan="1" colspan="1">9</td>
                <td rowspan="1" colspan="1">36</td>
                <td rowspan="1" colspan="1">12</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1"/>
                <td rowspan="1" colspan="1">infection_duration</td>
                <td rowspan="1" colspan="1">7</td>
                <td rowspan="1" colspan="1">1</td>
                <td rowspan="1" colspan="1">9</td>
                <td rowspan="1" colspan="1">1</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">Diag/Prev/Treatm.</td>
                <td rowspan="1" colspan="1">effectiveness_of_available_diagnostics</td>
                <td rowspan="1" colspan="1">13</td>
                <td rowspan="1" colspan="1">1</td>
                <td rowspan="1" colspan="1">23</td>
                <td rowspan="1" colspan="1">1</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1"/>
                <td rowspan="1" colspan="1">effectiveness_of_available_vaccines</td>
                <td rowspan="1" colspan="1">37</td>
                <td rowspan="1" colspan="1">13</td>
                <td rowspan="1" colspan="1">50</td>
                <td rowspan="1" colspan="1">29</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1"/>
                <td rowspan="1" colspan="1">effectiveness_of_available_antiviral_drugs</td>
                <td rowspan="1" colspan="1">23</td>
                <td rowspan="1" colspan="1">6</td>
                <td rowspan="1" colspan="1">50</td>
                <td rowspan="1" colspan="1">10</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1"/>
                <td rowspan="1" colspan="1">ct_value</td>
                <td rowspan="1" colspan="1">12</td>
                <td rowspan="1" colspan="1">2</td>
                <td rowspan="1" colspan="1">14</td>
                <td rowspan="1" colspan="1">2</td>
              </tr>
              <tr>
                <td colspan="2" align="center" rowspan="1">
                  <italic toggle="yes">No relevant tuples found</italic>
                </td>
                <td rowspan="1" colspan="1">9</td>
                <td rowspan="1" colspan="1">1</td>
                <td rowspan="1" colspan="1">—</td>
                <td rowspan="1" colspan="1">—</td>
              </tr>
              <tr>
                <td colspan="2" align="center" rowspan="1">
                  <bold>Distinct abstracts/tuples</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>221</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>50</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>1,051</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>282</bold>
                </td>
              </tr>
            </tbody>
          </table>
        </table-wrap>
      </sec>
      <sec id="sec3-3-2">
        <title>Model training</title>
        <p>In the iterative process, the “model training” phase is run in 2 different modes: (i) short-cycle training and (ii) long-cycle training:</p>
        <list list-type="roman-lower">
          <list-item>
            <p><italic toggle="yes">Long-cycle training</italic> employs the whole training dataset collected thus far to train the pretrained gpt2-model [<xref rid="bib58" ref-type="bibr">58</xref>] all at once. It is triggered when a relevant number of annotations (60) have been collected. A manual inspection of the learning curves is conducted to perform appropriate hyperparameter tuning; the number of epochs is determined by performing an early stopping (using the validation set). When the training concludes, we generate a model freezed version (checkpoint) to be used in the following phases (validation and errors checking).</p>
          </list-item>
          <list-item>
            <p><italic toggle="yes">Short-cycle training</italic> is triggered when 5 new abstracts are added to the training set, aiming to update the system as soon as the new annotations are available. Here, no hyperparameters are used, and the learning rate is set to half of the long-cycle training one, in order to avoid overfitting.</p>
          </list-item>
        </list>
        <p>In both modes, the used maximum token length is 1,000, and AdamW [<xref rid="bib68" ref-type="bibr">68</xref>] is used as the optimizer. The final model was trained for 12 epochs with a learning rate of 1<italic toggle="yes">e</italic> − 5 and a batch size of 1.</p>
      </sec>
      <sec id="sec3-3-3">
        <title>Scores computation</title>
        <p>The target annotations performed by our expert researchers are available at AdditionalFile4validation_dataset_target [<xref rid="bib63" ref-type="bibr">63</xref>] and are supported by the text document AdditionalFile5-validation_dataset_highlighted [<xref rid="bib63" ref-type="bibr">63</xref>], where we highlighted in yellow information used by experts to inform the annotation process and derive the target tuples.</p>
        <p>We compare the expert annotations with the predictions of the model (see AdditionalFile6-validation_dataset_prediction). Six scores are computed for 2 different scenarios: (i) we evaluate entities, effects, and levels separately (note that types are not included as they can easily be inferred from the syntax of the entity), and (ii) we evaluate whole tuples, including an entity with its linked effect and linked level. By comparing the target tuples—from zero to many in each abstract—with the predicted tuples, we assess the number of true positives, false positives, and false negatives. Based on these observations, we compute the <italic toggle="yes">accuracy</italic>, <italic toggle="yes">precision</italic>, and <italic toggle="yes">F1 score</italic> of each abstract. Then, we obtain 2 aggregate scores as a simple average of the single-abstract scores (i.e., each abstract contributes equally) and a weighted average (i.e., each abstract contributes proportionally to the number of contained target tuples).</p>
        <p>In Table <xref rid="tbl2" ref-type="table">2</xref>, we show the results on the 50 papers of the validation dataset. Evaluating fields separately and using a normal average, the trained model reached 0.79 F1 score on mutation/variants, 0.63 on the effects (independently on their link to an existing entity), and 0.76 on their levels (independently on their link to an existing entity or effect). Especially for entities and effects, precision was higher than recall, indicating that the model performed well in identifying actual positives. Specifically, out of all the predicted <italic toggle="yes">entities</italic>, almost 88% were actually present in the abstracts; out of all <italic toggle="yes">effects</italic>, 74% were actually present; and out of all <italic toggle="yes">levels</italic>, about 76% were actually present. Recall was slightly lower for entities and effects, indicating that the model missed some target information in the abstract. Specifically, recall was about 77% for <italic toggle="yes">entities</italic>, meaning that about 23% of actual entities were not recognized in abstracts; similarly, about 38% <italic toggle="yes">effects</italic> were not recognized and 24% <italic toggle="yes">levels</italic> were not recognized. Performances computed with the weighted average are generally lower, suggesting that simple abstracts (with few annotations) are the ones that contribute to improving the scores.</p>
        <table-wrap position="float" id="tbl2">
          <label>Table 2:</label>
          <caption>
            <p>Validation set results (run to set up the prediction model)</p>
          </caption>
          <table frame="hsides" rules="groups">
            <thead>
              <tr>
                <th rowspan="1" colspan="1"> Task</th>
                <th rowspan="1" colspan="1"> Measure</th>
                <th align="right" rowspan="1" colspan="1">F1 score</th>
                <th align="right" rowspan="1" colspan="1">Precision</th>
                <th align="right" rowspan="1" colspan="1">Recall</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td rowspan="1" colspan="1">
                  <bold>Entity</bold>
                </td>
                <td rowspan="1" colspan="1">Average <break/>Weighted average</td>
                <td align="right" rowspan="1" colspan="1">0.791<break/>0.668</td>
                <td align="right" rowspan="1" colspan="1">0.878<break/>0.806</td>
                <td align="right" rowspan="1" colspan="1">0.766<break/> 0.613</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">
                  <bold>Effect</bold>
                </td>
                <td rowspan="1" colspan="1">Average <break/>Weighted average</td>
                <td align="right" rowspan="1" colspan="1">0.626<break/> 0.561</td>
                <td align="right" rowspan="1" colspan="1">0.741<break/> 0.716</td>
                <td align="right" rowspan="1" colspan="1">0.617<break/> 0.531</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">
                  <bold>Level</bold>
                </td>
                <td rowspan="1" colspan="1">Average<break/>Weighted average</td>
                <td align="right" rowspan="1" colspan="1">0.762<break/> 0.702</td>
                <td align="right" rowspan="1" colspan="1">0.763<break/>0.705</td>
                <td align="right" rowspan="1" colspan="1">0.761<break/> 0.701</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">
                  <bold>Whole tuple</bold>
                </td>
                <td rowspan="1" colspan="1">Average<break/>Weighted average</td>
                <td align="right" rowspan="1" colspan="1">0.463<break/> 0.354</td>
                <td align="right" rowspan="1" colspan="1">0.588<break/> 0.519</td>
                <td align="right" rowspan="1" colspan="1">0.441<break/> 0.300</td>
              </tr>
            </tbody>
          </table>
        </table-wrap>
        <p>Finally, performances are considerably lower for the complex task of connecting the 3 fields in an atomic tuple (0.46 F1 score, 0.59 precision, 0.44 recall). We defend that—for such a composite task—it is more important to have higher precision (less wrong predicted annotations) at the expense of recall (missing some existing annotations). The model produces few results, but in general, they are of good quality. Performances can improve by augmenting the training dataset; this indeed occurs thanks to the use of the CoVEffect Web Application presented later in the article.</p>
      </sec>
    </sec>
  </sec>
  <sec sec-type="results" id="sec4">
    <title>Results</title>
    <p>Results include a double contribution: on the one hand, we provide complete predictions on a set of more than 7,000 abstracts from CORD-19 that are relevant to SARS-CoV-2 variation effects; on the other hand, we provide a user-friendly framework for expert users to annotate abstracts of interest and possibly contribute to additional training of the learning model.</p>
    <sec id="sec4-1">
      <title>Annotation of the biology-related CORD-19 cluster</title>
      <p>Abstracts informing about SARS-CoV-2 variation effects can be selected from CORD-19 via a 2-step process: (i) identification of a biology-related cluster and (ii) targeted search on the cluster based on particular keywords.</p>
      <p><italic toggle="yes">Clusters</italic>. We built a clustering model to partition in topic-based classes the CORD-19 dataset curated by our provisioning pipeline. For this purpose, we exploited the SPECTER document-level embeddings dataset distributed as part of CORD-19 (previously described in the <italic toggle="yes">similarity-based discovery</italic>). Because of the considerable size of the dataset, we opted for a representative-based clustering model (i.e., K-means). SPECTER embedding vectors are known to be effective in predicting the topic class associated with a paper [<xref rid="bib52" ref-type="bibr">52</xref>]. Differently from [<xref rid="bib52" ref-type="bibr">52</xref>], we did not know <italic toggle="yes">a priori</italic> the number of topic classes to be predicted. To choose an appropriate value for the number of clusters <italic toggle="yes">k</italic> of K-means, we plotted the silhouette score and the distortion for each candidate number of clusters, ranging from 2 to 50. The value K = 5 was chosen as it allowed us to visualize a spike in the plot of the silhouette score and an elbow-like shape in the plot of the distortion. For each of the 5 clusters, we generated <italic toggle="yes">WordCloud</italic> plots, including the most frequent words in papers’ titles abstracts and titles (top words common to clusters were excluded). This allowed us to manually recognize a 100 K abstracts cluster as the one mostly related to biological aspects.</p>
      <p><italic toggle="yes">Keywords</italic>. Out of the biology-related subset of CORD-19, we only targeted abstracts whose content relates to mutation and variants effects—the focus of CoVEffect. To this end, we described the subset of interest with a logical query expressed through the <italic toggle="yes">Whoosh</italic> search library [<xref rid="bib54" ref-type="bibr">54</xref>]—previously mentioned for the <italic toggle="yes">keyword-based search</italic> of the data provisioning pipeline. The library already includes simple lemmatization capabilities; additionally, we loaded the OperatorsPlugin (which adds logical operators such as AND, OR, NOT), the GroupPlugin (to group search clauses using parentheses), and the SingleQuotePlugin (to specify single terms containing spaces by enclosing them in single quotes). Finally, we added a union set operation for the papers retrieved with each single query (equivalent to having all the queries in OR but without overloading the parsing process of <italic toggle="yes">Whoosh</italic>).</p>
      <p>As a result of this procedure—employing the keyword-based query listed in the AdditionalFile7-keywords_query_list [<xref rid="bib63" ref-type="bibr">63</xref>]—we could extract 7,230 papers from the cluster on biological aspects (see AdditionalFile8-CORD-19_batch_dataset_metadata [<xref rid="bib63" ref-type="bibr">63</xref>]). We then ran the CoVEffect prediction on this dataset; the resulting predictions for the 7,230 abstracts are provided in AdditionalFile9-CORD-19_batch_dataset_prediction [<xref rid="bib63" ref-type="bibr">63</xref>] as a contribution to the scientific community.</p>
      <sec id="sec4-1-1">
        <title>Testing results</title>
        <p>Out of this batch, we tested the prediction performances on 100 randomly selected papers, ensuring that they did not overlap with the previously used training and validation sets. For these, we manually prepared target annotations (see AdditionalFile10-test_dataset_target [<xref rid="bib63" ref-type="bibr">63</xref>]). Then, we predicted the annotations of their abstracts using our model (see AdditionalFile11-test_dataset_prediction [<xref rid="bib63" ref-type="bibr">63</xref>]).</p>
        <p>In Table <xref rid="tbl3" ref-type="table">3</xref>, we show the results on the 100 papers of the test dataset, based on the comparison between target and predicted annotations. Reassuringly, performances were comparable to the ones obtained on the validation set. Indeed, they were only worse in the case of <italic toggle="yes">entities</italic>, whereas <italic toggle="yes">effects</italic>, <italic toggle="yes">levels</italic>, and also whole tuples improved their scores.</p>
        <table-wrap position="float" id="tbl3">
          <label>Table 3:</label>
          <caption>
            <p>Test set results (run to evaluate the predictions on 100 abstracts randomly selected from the CORD-19 biology-related cluster)</p>
          </caption>
          <table frame="hsides" rules="groups">
            <thead>
              <tr>
                <th rowspan="1" colspan="1">  Task</th>
                <th rowspan="1" colspan="1">  Measure</th>
                <th align="right" rowspan="1" colspan="1">F1 score</th>
                <th align="right" rowspan="1" colspan="1">Precision</th>
                <th align="right" rowspan="1" colspan="1">Recall</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td rowspan="1" colspan="1">
                  <bold>Entity</bold>
                </td>
                <td rowspan="1" colspan="1">Average <break/>Weighted average</td>
                <td align="right" rowspan="1" colspan="1">0.762<break/>0.688</td>
                <td align="right" rowspan="1" colspan="1">0.802<break/> 0.822</td>
                <td align="right" rowspan="1" colspan="1">0.755<break/>0.822</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">
                  <bold>Effect</bold>
                </td>
                <td rowspan="1" colspan="1">Average<break/>Weighted average</td>
                <td align="right" rowspan="1" colspan="1">0.792<break/>0.656</td>
                <td align="right" rowspan="1" colspan="1">0.855<break/>0.656</td>
                <td align="right" rowspan="1" colspan="1">0.781<break/>0.656</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">
                  <bold>Level</bold>
                </td>
                <td rowspan="1" colspan="1">Average<break/>Weighted average</td>
                <td align="right" rowspan="1" colspan="1">0.832<break/>0.624</td>
                <td align="right" rowspan="1" colspan="1">0.832<break/>0.625</td>
                <td align="right" rowspan="1" colspan="1">0.832<break/>0.624</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">
                  <bold>Whole tuple</bold>
                </td>
                <td rowspan="1" colspan="1">Average<break/>Weighted average</td>
                <td align="right" rowspan="1" colspan="1">0.578<break/>0.324</td>
                <td align="right" rowspan="1" colspan="1">0.631<break/>0.440</td>
                <td align="right" rowspan="1" colspan="1">0.569<break/>0.288</td>
              </tr>
            </tbody>
          </table>
        </table-wrap>
      </sec>
      <sec id="sec4-1-2">
        <title>Benchmarking considerations</title>
        <p>As mentioned in the “Related Work” section, Singhal et al. [<xref rid="bib32" ref-type="bibr">32</xref>] previously proposed a method for extracting entities and relationships from biomedical text; that approach is considered today’s state-of-the-art. We do not compare our results with that approach because CoVEffect performs a significantly different task, providing an output that could be read as the result of 4 separate steps: entity recognition (for mutations and variants), entity linking (protein with mutation), classification (effects and levels), and relation extraction (among the previously extracted information). In essence, CoVEffect should not be considered the best possible method for performing each one of these tasks. Instead, it offers an all-in-one annotation platform that allows experts to insert annotations manually or to inspect, correct, and eventually accept predictions of specific triples entity–effect–level. The proposed approach can be interpreted as a combination of automated extraction and crowdsourcing, as initially proposed in [<xref rid="bib69" ref-type="bibr">69</xref>].</p>
      </sec>
    </sec>
    <sec id="sec4-2">
      <title>The CoVEffect web application</title>
      <p>As a second output, we implemented the CoVEffect web application; its front end provides 2 main functionalities: (i) a search interface for finding papers of interest and (ii) an interactive interface to label abstracts with a semiautomated framework. The first functionality is based on a back-end retrieval module, which uses the methods described in the “Data provisioning” section (i.e., keyword-based search and similarity-based search of papers). The second functionality is fueled by a back-end extraction module, which uses the prediction model described in the “Language model and task design” section and implements a framework for semiautomated data labeling by users, as detailed in the following.</p>
      <sec id="sec4-2-1">
        <title>Semiautomated data labeling framework</title>
        <p>This framework aims to facilitate and accelerate the abstract annotation process operated by an expert researcher. A typical annotation session with iterative phases (shown in Fig. <xref rid="fig4" ref-type="fig">4</xref>) follows.</p>
        <list list-type="bullet">
          <list-item>
            <p>The user provides a list of abstracts.</p>
          </list-item>
          <list-item>
            <p>For each selected abstract: (i) the model generates a proposed labeling in the form of predicted tuples, and (ii) the user may edit each single prediction (i.e., 1 tuple field at a time).</p>
          </list-item>
          <list-item>
            <p>Once the editing session is over, the user is provided the choice of accepting the annotations and of retraining the model with the new provided annotations.</p>
          </list-item>
        </list>
        <fig position="float" id="fig4">
          <label>Figure 4:</label>
          <caption>
            <p>The iterative phases of the online semiautomated data labeling framework.</p>
          </caption>
          <graphic xlink:href="giad036fig4" position="float"/>
        </fig>
        <p>The user may modify or add abstracts to the list at any point in time. For each prediction (type, entity, effect, or level), the framework provides 2 types of visual feedback. First, it shows the prediction confidence value with a color code: <italic toggle="yes">green</italic> for high confidence predictions &gt;0.8, <italic toggle="yes">yellow</italic> for medium-confidence predictions between 0.6 and 0.8, and <italic toggle="yes">black</italic> for low-confidence predictions &lt;0.6. Second, it shows a saliency map built on the input abstract. Saliency maps are a machine learning interpretation mechanism born in the field of explainable artificial intelligence; they are maps over the input that highlight the portions of the text that contributed the most to the extraction of given attributes. Here, we exploited the generation of saliency maps that employ the Gradient technique [<xref rid="bib70" ref-type="bibr">70</xref>]. Such an idea was already proposed successfully in our previous work [<xref rid="bib45" ref-type="bibr">45</xref>] where such a mechanism was well evaluated by the users of the system, as it allow users to understand whether a given result is not only predicted correctly, but also predicted by exploiting a correct information. As an example, in Fig. <xref rid="fig5" ref-type="fig">5</xref>, we show the saliency map obtained for the prediction of the “infectivity” effect on the abstract of Ou et al. [<xref rid="bib64" ref-type="bibr">64</xref>] previously introduced in Fig. <xref rid="fig2" ref-type="fig">2</xref>.</p>
        <fig position="float" id="fig5">
          <label>Figure 5:</label>
          <caption>
            <p>The gradient-based saliency map implemented in the CoVEffect tool. The example shows the abstract of the paper by Ou et al. [<xref rid="bib64" ref-type="bibr">64</xref>] also used in Fig. <xref rid="fig2" ref-type="fig">2</xref> to motivate our task. The text fragments highlighted with different shades of blue are used by the model to predict the effect of the SPIKE_V367F mutation, here corresponding to the value “infectivity.”</p>
          </caption>
          <graphic xlink:href="giad036fig5" position="float"/>
        </fig>
      </sec>
      <sec id="sec4-2-2">
        <title>Application workflow and example</title>
        <p>The “Homepage” of CoVEffect accepts 2 kinds of input: a list of keywords or a single DOI. Suppose that we search for the keywords “Neutralization of Q677H” (as shown in Fig. <xref rid="fig6" ref-type="fig">6</xref>). The following workflow is explained by the activity diagram in Fig. <xref rid="fig7" ref-type="fig">7</xref>.</p>
        <fig position="float" id="fig6">
          <label>Figure 6:</label>
          <caption>
            <p>Homepage, with a section for keyword search and a section for DOI search.</p>
          </caption>
          <graphic xlink:href="giad036fig6" position="float"/>
        </fig>
        <fig position="float" id="fig7">
          <label>Figure 7:</label>
          <caption>
            <p>Activity diagram of the user’s interactions with the CoVEffect web application.</p>
          </caption>
          <graphic xlink:href="giad036fig7" position="float"/>
        </fig>
        <p>Once the search is performed, we reach the “Search result page,” whose results can be examined (based on their metadata and abstract) and exported as a tab-separated file. Extracted papers may be of interest for the user (especially when they are focused on mutations or variants effects), in which case they can be included in the prediction stack. For each paper, users may also explore similar papers by opening the “Similar papers tab”; as before, papers of interest can be selected. When the user closes the tab, they will have a complete list of the searched papers, where papers selected are marked in gray and papers added for the similar ones are marked in green. Figure <xref rid="fig8" ref-type="fig">8</xref> shows an example where, from the papers obtained in the previous search, we selected the paper with DOI “10.1128/mbio.02510–21” [<xref rid="bib71" ref-type="bibr">71</xref>] and its similar paper with DOI “10.1186/s12985-021-01,554–8” [<xref rid="bib72" ref-type="bibr">72</xref>].</p>
        <fig position="float" id="fig8">
          <label>Figure 8:</label>
          <caption>
            <p>Paper List screen, obtained after searching for “Neutralization of Q677H” and inspecting papers similar to the first one (DOI “10.1128/mbio.02510–21” [<xref rid="bib71" ref-type="bibr">71</xref>]). Papers that are selected by the user are highlighted in color: gray for the ones corresponding to the initial search, green for the ones corresponding to the similarity-based search.</p>
          </caption>
          <graphic xlink:href="giad036fig8" position="float"/>
        </fig>
        <p>By pressing the green arrow on the top-right corner of the screen, we reach the “Annotation page.” This page allows users to inspect results and suggest changes for one abstract at a time. For each abstract, the framework extracts a list of predicted tuples, each composed of 4 fields (type, entity, effect, and level). For each of such annotations, the user can inspect the saliency map and decide if the annotation is correct (thus should be approved) or needs correction. Missing annotations can also be added manually.</p>
        <p>Figure <xref rid="fig9" ref-type="fig">9</xref> represents the status of the “Annotation page” for paper [<xref rid="bib71" ref-type="bibr">71</xref>]. Panel A provides user utilities. Panel B shows the saliency map referring to the prediction of the value “higher” for the level of the first predicted tuple (selected in panel D). Panel C shows the metadata of the currently inspected paper and informs that the prediction stack contains 2 papers (of which none has yet been annotated, as we have not clicked on “SAVE”). Panel D shows predictions 1, 2, 3, 4, and 6 as produced by the prediction framework, with the exception of the level values of 2, 4, and 6 that have been manually corrected into the “lower” value (which had been wrongly predicted), by employing the drop-down menu in panel E.</p>
        <fig position="float" id="fig9">
          <label>Figure 9:</label>
          <caption>
            <p>Overview of the CoVEffect interface, with a top bar and 4 panels, captured during the annotation of a paper by Zeng et al. [<xref rid="bib71" ref-type="bibr">71</xref>]. Panel A includes the top bar; the commands on the left allow to return to the keyword search screen, open a new user session, save the current one, or load a previously closed one. The commands on the right allow to inspect the list of already processed papers or the list of papers selected through the keyword search. Panel B shows the abstract of the selected paper to be annotated, interactively highlighted using the gradient-based saliency map related to the tuple fragment selected in panel D. Panel C shows the metadata of the selected paper and the size of the stack of papers chosen by the user. Panel D shows the predicted tuples for the selected abstract, using the color-code for informing on the accuracy of the prediction. Panel E allows users to actively modify the prediction of the model and save the suggestions.</p>
          </caption>
          <graphic xlink:href="giad036fig9" position="float"/>
        </fig>
        <p>In addition, a full tuple annotation has been added (number 5) regarding the single mutation Spike Q677H, which leads to an increase in infectivity of the SARS-CoV-2 virus.</p>
        <p>When the user is satisfied with all the annotations associated with an abstract, these can be saved and are accordingly stored in the “Annotated Papers” list (panel A, top-right corner), where they can also be downloaded for further processing. Note that annotated abstracts that can be saved are the result of either a model prediction or of a user manual correction/addition.</p>
        <p>When saving annotations for the first time, the user is prompted to name the current session. Sessions can be downloaded as JSON files and reloaded at a later time. Then, the user is asked if they wish to retrain the model immediately. This process is computationally intensive and may require several minutes based on the occupation of the servers. Users may also wait to annotate additional papers and retrain the model only at a later stage. The application can be installed on other machines using the Docker distribution available on our GitHub repository.</p>
      </sec>
    </sec>
  </sec>
  <sec sec-type="discussion" id="sec5">
    <title>Discussion</title>
    <p>In this article, we described two contributions. On one hand, we provide the identification of SARS-CoV-2 variants and mutations’ effects over a relevant set of CORD-19 abstracts. On the other hand, we make this annotation extendable, as training data can be augmented by using the CoVEffect interface. The project stems from the need of providing a complete framework that supports semiautomatic extraction of structured information on SARS-CoV-2 variation effects. We had previously employed transformer-based text extraction for capturing key-value pairs from genomic experiments (from Gene Expression Omnibus). The task performed in this case is more complex, as it aims to identify attributes that are interdependent: mutation or variants with their effect and level.</p>
    <p>A considerable improvement of the initial GPT2 model was necessary to address this new challenge. In addition, no preexisting training dataset was available; we thus designed a methodology to build a small manually crafted dataset of good quality. The trajectory to evaluate the performances of our method is as follows: we chose an initial dataset with minimal size, and at each small delta increase, we evaluated the changes in performances on a test dataset until a satisfactory result was reached. This process was necessary to find a trade-off between 2 needs: the minimization of the effort of expert manual annotation and maximization of prediction performances. This effort has paid off in terms of recognizing single concepts; however, the linked tuple prediction still has much room for improvement.</p>
    <p>To inspect the most challenging aspects of the prediction task, we performed an error analysis divided into 3 categories: (i) entity name prediction (nonconstrained to any value, filtered with a RegEx filter), (ii) effect/level prediction (restricted to our taxonomy values), and (iii) association between entity, effect, and level. Table <xref rid="tbl4" ref-type="table">4</xref> presents an overview of the most representative errors each with an associated example.</p>
    <table-wrap position="float" id="tbl4">
      <label>Table 4:</label>
      <caption>
        <p>Typical issues detected in the prediction task. The first column groups issues by macro-category, the second describes the scenario that leads to an <italic toggle="yes">Issue</italic>, and the third and fourth provide the reference DOI to an abstract and a short text excerpt from the abstract. Words in orange show the relevant information for the expected values (Target) as opposed to the obtained prediction.</p>
      </caption>
      <table frame="hsides" rules="groups">
        <thead>
          <tr>
            <th rowspan="1" colspan="1"/>
            <th rowspan="1" colspan="1">Issue</th>
            <th rowspan="1" colspan="1">DOI</th>
            <th rowspan="1" colspan="1">Text excerpt from abstract</th>
            <th rowspan="1" colspan="1">Target</th>
            <th rowspan="1" colspan="1">Prediction</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td rowspan="9" colspan="1">Entity name prediction<break/> <break/> <break/> <break/> <break/> <break/> <break/> <break/> </td>
            <td rowspan="1" colspan="1">Uncommon naming (mutations/variants)</td>
            <td rowspan="1" colspan="1">[<xref rid="bib73" ref-type="bibr">73</xref>]</td>
            <td rowspan="1" colspan="1">The S:655Y substitution was transmitted more efficiently than …</td>
            <td rowspan="1" colspan="1">SPIKE_H655Y</td>
            <td rowspan="1" colspan="1">—</td>
          </tr>
          <tr>
            <td rowspan="3" colspan="1">Mutations/variants referred to as a group<break/> <break/> </td>
            <td rowspan="3" colspan="1">[<xref rid="bib71" ref-type="bibr">71</xref>]<break/> <break/> </td>
            <td rowspan="3" colspan="1">… major VOCs, including Alpha, Beta, and Gamma. We demonstrate that the Q677H mutation increases viral infectivity and syncytium formation, as well as enhancing resistance to neutralization for VOCs.<break/> <break/> </td>
            <td rowspan="1" colspan="1">Alpha</td>
            <td rowspan="1" colspan="1">Alpha</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">Beta</td>
            <td rowspan="1" colspan="1">Beta</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">Gamma</td>
            <td rowspan="1" colspan="1">—</td>
          </tr>
          <tr>
            <td rowspan="5" colspan="1">Mutations/variants reported as long lists<break/> <break/> <break/> <break/> </td>
            <td rowspan="5" colspan="1">[<xref rid="bib74" ref-type="bibr">74</xref>]<break/> <break/> <break/> <break/> </td>
            <td rowspan="5" colspan="1">To understand the impact of spike protein mutations on the binding interactions required for virus infection and the effectiveness of neutralizing monoclonal antibody (mAb) therapies, mutants D614G, N501Y, N439K, Y453F, and E484K were assessed.<break/> <break/> <break/> <break/> </td>
            <td rowspan="1" colspan="1">SPIKE_D614G</td>
            <td rowspan="1" colspan="1">—</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">SPIKE_N501Y</td>
            <td rowspan="1" colspan="1">SPIKE_N501Y</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">SPIKE_N439K</td>
            <td rowspan="1" colspan="1">—</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">SPIKE_Y453F</td>
            <td rowspan="1" colspan="1">SPIKE_Y453F</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">SPIKE_E484K</td>
            <td rowspan="1" colspan="1">SPIKE_E484K</td>
          </tr>
          <tr>
            <td rowspan="6" colspan="1">Effect and/or level prediction<break/> <break/> <break/> <break/> <break/> </td>
            <td rowspan="4" colspan="1">Effect terminology<break/> <break/> <break/> </td>
            <td rowspan="4" colspan="1">[<xref rid="bib75" ref-type="bibr">75</xref>]<break/> <break/> <break/> </td>
            <td rowspan="4" colspan="1">The increased ACE2-binding affinity of variants containing the N501Y or E484K mutations can be traced to the time-dependent disruption and/or formation of interfacial salt bridges, not necessarily apparent from structural models but detected by extensive molecular dynamics simulations.<break/> <break/> <break/> </td>
            <td rowspan="1" colspan="1">SPIKE_N501Y binding to host receptor</td>
            <td rowspan="1" colspan="1">SPIKE_N501Y binding to host receptor</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">SPIKE_N501Y intermolecular interactions</td>
            <td rowspan="1" colspan="1">SPIKE_N501Y protein conformational optimization.</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">SPIKE_E484K binding to host receptor</td>
            <td rowspan="1" colspan="1">SPIKE_E484K binding to host receptor</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">SPIKE_E484K intermolecular interactions</td>
            <td rowspan="1" colspan="1">SPIKE_E484 protein conformational optimization.</td>
          </tr>
          <tr>
            <td rowspan="2" colspan="1">Vague results presentation<break/> </td>
            <td rowspan="2" colspan="1">[<xref rid="bib73" ref-type="bibr">73</xref>]<break/> </td>
            <td rowspan="2" colspan="1">We demonstrate that the substitution S:655Y, represented in the Gamma and Omicron VOCs, enhances viral replication and spike protein cleavage. All VOCs tested exhibited increased spike cleavage and fusogenic capacity.<break/><break/> </td>
            <td rowspan="1" colspan="1">GAMMA viral replication</td>
            <td rowspan="1" colspan="1">GAMMA viral replication</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">GAMMA protein functioning</td>
            <td rowspan="1" colspan="1">-</td>
          </tr>
          <tr>
            <td rowspan="5" colspan="1">Association<break/> <break/> <break/> <break/> </td>
            <td rowspan="3" colspan="1">Multiple effects connected to same entity<break/> <break/> </td>
            <td rowspan="3" colspan="1">[<xref rid="bib76" ref-type="bibr">76</xref>]<break/> <break/> </td>
            <td rowspan="3" colspan="1">Infections caused by the delta variant increases the risk of hospitalization within 14 days after symptom onset, and the high viral load correlates with COVID-19 associated morbidity and mortality.<break/> <break/> </td>
            <td rowspan="1" colspan="1">DELTA, risk of hospitalization</td>
            <td rowspan="1" colspan="1">DELTA, risk of hospitalization</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">DELTA, viral load</td>
            <td rowspan="1" colspan="1">DELTA, viral load</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">DELTA, fatality rate</td>
            <td rowspan="1" colspan="1">-</td>
          </tr>
          <tr>
            <td rowspan="2" colspan="1">Different levels for same entity effect (not supported)<break/> </td>
            <td rowspan="2" colspan="1">[<xref rid="bib77" ref-type="bibr">77</xref>]<break/> </td>
            <td rowspan="2" colspan="1">Naturally occurring variants in Orf3a (Q57H) and nsp2 (T85I) were associated with poor replication in Vero-CCL81 cells but not in BEpCs.<break/> </td>
            <td rowspan="1" colspan="1">ORF3a_Q57H <break/>viral replication, lower</td>
            <td rowspan="1" colspan="1">-</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">ORF3a_Q57H <break/>viral replication, unaffected</td>
            <td rowspan="1" colspan="1">ORF3a_Q57H <break/>viral replication, unaffected</td>
          </tr>
        </tbody>
      </table>
    </table-wrap>
    <p>Types of errors captured in the <italic toggle="yes">entity name prediction</italic> mainly occurred when the abstract included:</p>
    <list list-type="bullet">
      <list-item>
        <p><italic toggle="yes">Mutation/variant named with uncommon terminology</italic>. The typical way to name a mutation is to declare the protein where the mutation occurred followed by a mutation signature (⟨reference amino acid, coordinate in protein, alternative amino acid⟩, e.g., Spike D614G). The most adopted terminologies to name a SARS-CoV-2 variant are Pango lineages [<xref rid="bib61" ref-type="bibr">61</xref>] or WHO Greek letters [<xref rid="bib20" ref-type="bibr">20</xref>]; however, there are other ways to refer to variants (e.g., GISAID or Nextstrain clades), which are currently not supported in CoVEffect. Table <xref rid="tbl4" ref-type="table">4</xref> shows an example from [<xref rid="bib73" ref-type="bibr">73</xref>] where a different naming scheme is used for a mutation of interest, which makes the model’s mission harder.</p>
      </list-item>
      <list-item>
        <p><italic toggle="yes">Effect/level associated with a named group of variants</italic>. The WHO has classified variants into variants of concern and other classes according to their impacts [<xref rid="bib20" ref-type="bibr">20</xref>]. In publications, we often find reference to effects studied on a group of variants, referred to with such terms. Table <xref rid="tbl4" ref-type="table">4</xref> shows one such case [<xref rid="bib71" ref-type="bibr">71</xref>], where CoVEffect can miss 1 or more entities in the list.</p>
      </list-item>
      <list-item>
        <p><italic toggle="yes">Mutations/variants written as long lists</italic>. Some publications—noticeably the ones using computational methods to analyze their variants of interest—tend to deal with long lists of mutations. CoVEffect model may miss some entities in such scenarios (as happened in [<xref rid="bib74" ref-type="bibr">74</xref>]).</p>
      </list-item>
    </list>
    <p>Moreover, issues occurring in the <italic toggle="yes">entity/level prediction</italic> mainly occurred when the abstract included:</p>
    <list list-type="bullet">
      <list-item>
        <p><italic toggle="yes">Effects misclassification</italic>. The model does not always recognize effects as they are expressed in our taxonomy, especially when there exist connections between different effects. This case may happen when an effect is a special case of another effect (e.g., binding to a host receptor is a special case of a host–virus interaction); in this case, only using a broad context and expert user knowledge does it become possible to understand the correct target effect. Table <xref rid="tbl4" ref-type="table">4</xref> shows 1 such example from [<xref rid="bib75" ref-type="bibr">75</xref>].</p>
      </list-item>
      <list-item>
        <p><italic toggle="yes">Levels misclassification</italic>. The changes of some effects are more easily expressible through the higher/lower comparators (i.e., higher transmissibility, lower severity). Unfortunately for other effects (e.g., protein conformational optimization), comparators are less used in text.</p>
      </list-item>
      <list-item>
        <p><italic toggle="yes">Unclear results presentations</italic>. Effects reported in abstracts with a vague presentation of the results can be missed. For example, some publications that report on the effectiveness of a specific therapeutic measure might not declare that the measure is indeed a drug. Other publications (see [<xref rid="bib73" ref-type="bibr">73</xref>] for an example) study the effect of a mutation on the functions of viral proteins without making explicit that the topic discussed is a protein function—making it hard for the model to predict the effect.</p>
      </list-item>
    </list>
    <p>Finally, problems occurring in predicting the <italic toggle="yes">association between an entity and its effect level</italic> mainly occurred when the abstract included:</p>
    <list list-type="bullet">
      <list-item>
        <p><italic toggle="yes">Multiple effects for 1 entity</italic>. The model can miss the association of 1 (or more) effects that are part of a list (as happened in [<xref rid="bib76" ref-type="bibr">76</xref>]).</p>
      </list-item>
      <list-item>
        <p><italic toggle="yes">Multiple levels for 1 entity effect</italic>. Given abstracts may include the specification of an entity and associated effect with multiple levels (e.g., in [<xref rid="bib77" ref-type="bibr">77</xref>]). This scenario is likely to be found when the specific effect has been studied under multiple conditions (e.g., measuring the viral loads of a variant in different tissues or studying the binding of a specific variant with a wide range of antibodies). CoVEffect current data model does not support multiple disagreeing levels for an entity–effect pair. This impacts on the recall of our results.</p>
      </list-item>
    </list>
    <p>Notably, the prediction model reached quite good performances, as shown in Tables <xref rid="tbl2" ref-type="table">2</xref> and <xref rid="tbl3" ref-type="table">3</xref>, and still has much space for improvement thanks to the expected enhancements on the training dataset. An interesting result is that mutation entities were very well predicted even when the protein information was far apart in the text from the mutation signature (see our motivating example in Fig. <xref rid="fig2" ref-type="fig">2</xref>, where Spike is far from V367F, but they are correctly associated); the interpretability mechanism of saliency maps is of great support to highlight these cases. Moreover, the model worked well in detecting our targets: protein amino acid–based mutations rather than genomic nucleotide-based mutations and lineages rather than clades.</p>
    <p>CoVEffect brings a number of tangible results to the scientific community, which we here describe. Immediate integrated use of our resulting annotated database was made within our CoV2K [<xref rid="bib22" ref-type="bibr">22</xref>] system by updating the AA_changes, Variant, and Effect entities. Other data-driven analysis resources developed by our group (such as VirusViz [<xref rid="bib78" ref-type="bibr">78</xref>] and ViruClust [<xref rid="bib79" ref-type="bibr">79</xref>]) could immediately benefit from the addition of structured tuples connecting mutations and effects. At the same time, any other resource employed in the current practice of virologists and phylogenetists (such as CoVSpectrum [<xref rid="bib80" ref-type="bibr">80</xref>] and Outbreak.info [<xref rid="bib81" ref-type="bibr">81</xref>]), studying the trend of specific mutations and variants, can benefit from the provisioning of a dataset with this structured information. Our output can be appreciated in the AdditionalFile9 [<xref rid="bib63" ref-type="bibr">63</xref>], containing the predicted annotations for the whole biology-related CORD-19 cluster. External users may also annotate other abstracts by installing CoVEffect through our Docker distribution and running the batch annotator (available as a Python notebook on our GitHub repository).</p>
    <p>Next, we aim to extend the scope of CoVEffect by including the possibility of recognizing also alternative formulations of mutation and variant names, tuples reporting on different levels for the same entity and effect, groups of mutations leading collaboratively to the same effect, insertions and deletions, the method used to establish the effect (epidemiological, experimental, computational or inferred), and effects reported with complex—possibly quantitative—formulations. We will also add a “mutation validation” module to check the semantic consistency of mutation signatures, on top of the RegEx-based check.</p>
    <p>In the future, we aim to apply CoVEffect to other subparts of the CORD-19 dataset as well as to expand to other literature corpuses, focusing on different, well-defined, and delimited domains. More in general, our framework is suitable to resolve similar problems where the prediction task attempts to recognize in text the associations between given entities and related values (within existing taxonomies). One additional possibility regards predicting tuples of individual mutations, with their associated genetic background, and their mutual interaction; this has been demonstrated to be important for SARS-CoV-2, possibly supporting the explanation/prediction of new variants.</p>
  </sec>
  <sec id="sec6">
    <title>Availability of Source Code and Requirements</title>
    <p>Project name: CoVEffectProject</p>
    <p>Homepage: <ext-link xlink:href="http://gmql.eu/coveffect/" ext-link-type="uri">https://gmql.eu/coveffect/</ext-link></p>
    <p>Code repository: <ext-link xlink:href="https://github.com/armando2603/coveffect/" ext-link-type="uri">https://github.com/armando2603/coveffect/</ext-link></p>
    <p>Operating system: Platform independent</p>
    <p>Programming language: The source code of the data provisioning module and the deep learning–based prediction framework are implemented in Python. The CoVEffect web interface to annotate abstracts is implemented in Python (Flask framework) and JavaScript (Vue framework).</p>
    <p>Other requirements: The application can be installed on any machine with its Docker image version.</p>
    <p>License: MIT</p>
    <p>
      <ext-link xlink:href="https://scicrunch.org/resolver/RRID:SCR_023415" ext-link-type="uri">RRID:SCR_023415</ext-link>
    </p>
    <p>biotools ID: CoVEffect</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material id="sup1" position="float" content-type="local-data">
      <label>giad036_GIGA-D-22-00331_Original_Submission</label>
      <media xlink:href="giad036_giga-d-22-00331_original_submission.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material id="sup2" position="float" content-type="local-data">
      <label>giad036_GIGA-D-22-00331_Revision_1</label>
      <media xlink:href="giad036_giga-d-22-00331_revision_1.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material id="sup3" position="float" content-type="local-data">
      <label>giad036_Response_to_Reviewer_Comments_Original_Submission</label>
      <media xlink:href="giad036_response_to_reviewer_comments_original_submission.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material id="sup4" position="float" content-type="local-data">
      <label>giad036_Reviewer_1_Report_Original_Submission</label>
      <caption>
        <p>Bahrad Sokhansanj -- 1/30/2023 Reviewed</p>
      </caption>
      <media xlink:href="giad036_reviewer_1_report_original_submission.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material id="sup5" position="float" content-type="local-data">
      <label>giad036_Reviewer_2_Report_Original_Submission</label>
      <caption>
        <p>Theo Sanderson -- 2/14/2023 Reviewed</p>
      </caption>
      <media xlink:href="giad036_reviewer_2_report_original_submission.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ack id="ack1">
    <title>Acknowledgement</title>
    <p>The authors thank Mark J. Carman for inspiring the first prototype of the semiautomated data labeling framework and Giuseppe Cannizzaro for building the first prototype of the transformer-based prediction model.</p>
  </ack>
  <sec sec-type="data-availability" id="sec7">
    <title>Data Availability</title>
    <p>All supporting data and materials are available in the <italic toggle="yes">GigaScience</italic> GigaDB database [<xref rid="bib63" ref-type="bibr">63</xref>] and on Zenodo [<xref rid="bib82" ref-type="bibr">82</xref>].</p>
  </sec>
  <sec sec-type="supplementary-material" id="sec8">
    <title>Additional Files</title>
    <p><bold>AdditionalFile1-effects-taxonomy</bold>. Descriptions of legal values for the “Effect” field, based on a categorized taxonomy.</p>
    <p><bold>AdditionalFile2-levels-taxonomy</bold>. Descriptions of legal values for the “Level” field.</p>
    <p><bold>AdditionalFile3-training_dataset_target</bold>. List of target tuples (manually annotated) of 221 abstracts considered for training the model. For each abstract, target tuples follow the schema ID, DOI, title, entity, effect, level, type (mutation or variant), and tuples_count (&gt;1 when an effect/level is shared by multiple entities, #abstracts containing the same effect described in the tuple).</p>
    <p><bold>AdditionalFile4-validation_dataset_target</bold>. List of target tuples (manually annotated) of 50 abstracts considered for validating the prepared prediction model. For each abstract, target tuples follow the schema defined for AdditionalFile3.</p>
    <p><bold>AdditionalFile5-validation_dataset_highlighted</bold>. Textual abstracts of the 50 manuscripts considered for validation; the text used to support the manual target annotations has been highlighted in yellow.</p>
    <p><bold>AdditionalFile6-validation_dataset_prediction</bold>. List of predicted annotations of 50 abstracts considered for validating the prepared prediction model; it contains 4 sheets, respectively for entity, effect, level, and whole tuple predictions.</p>
    <p><bold>AdditionalFile7-keywords_query_list</bold>. Keyword-based search run on the CORD-19 dataset to extract a relevant subset of abstracts regarding the scope of interest of CoVEffect. The Boolean logic used to combine keywords is explained in the section “Annotations of the biology-related CORD-19 cluster.”</p>
    <p><bold>AdditionalFile8-CORD-19_batch_dataset_metadata</bold>. Metadata of the 7,230 papers extracted by the keyword-based query in AdditionalFile7. These abstracts have been annotated by the prediction framework.</p>
    <p><bold>AdditionalFile9-CORD-19_batch_dataset_prediction</bold>. List of predicted annotations of 7,230 abstracts extracted from the biology-related cluster of CORD-19.</p>
    <p><bold>AdditionalFile10-test_dataset_target</bold>. List of target tuples (manually annotated) of 100 abstracts randomly selected from the 7,230 extracted as in AdditionalFile8. For each abstract, target tuples follow the schema defined for AdditionalFile3.</p>
    <p><bold>AdditionalFile11-test_dataset_prediction</bold>. List of predicted annotations of 100 abstracts considered for testing the prediction model on a subset of the CORD-19 biology-related cluster. As AdditionalFile6, it contains 4 sheets, respectively for entity, effect, level, and whole tuple predictions.</p>
  </sec>
  <sec id="sec9">
    <title>Abbreviations</title>
    <p>CDC: Centers for Disease Control and Prevention; CORD-19: COVID-19 Open Research Dataset; GPT2: Generative Pre-trained Transformer 2; NER: Named Entity Recognition; NLP: Natural Language Processing; WHO: World Health Organization.</p>
  </sec>
  <sec sec-type="COI-statement" id="h1content1684214244797">
    <title>Competing interests</title>
    <p>The authors declare that they have no competing interests.</p>
  </sec>
  <sec id="h1content1684214250825">
    <title>Funding</title>
    <p>This research is supported by the PNRR-PE-AI FAIR project funded by the NextGenerationEU program.</p>
  </sec>
  <sec id="h1content1684214022239">
    <title>Authors’ Contributions</title>
    <p>G.G.S.: formal analysis, investigation, methodology, software (back-end prediction model, front end, evaluation). R.A.K.: data curation, investigation, validation. F.I.: formal analysis, methodology, software (data provisioning, keyword search), validation. S.C.: funding acquisition, writing—review &amp; editing. A.B.: conceptualization, project administration, supervision, visualization, writing—original draft.</p>
  </sec>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="bib1">
      <label>1.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Else</surname><given-names>H</given-names></string-name></person-group>. <article-title>How a torrent of COVID science changed research publishing—in seven charts</article-title>. <source>Nature</source>. <year>2020</year>;<volume>588</volume>(<issue>7839</issue>):<fpage>553</fpage>–<lpage>4</lpage>.<pub-id pub-id-type="pmid">33328621</pub-id></mixed-citation>
    </ref>
    <ref id="bib2">
      <label>2.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Wang</surname><given-names>LL</given-names></string-name>, <string-name><surname>Lo</surname><given-names>K</given-names></string-name>, <string-name><surname>Chandrasekhar</surname><given-names>Y</given-names></string-name><etal>et al.</etal></person-group><article-title>CORD-19: the COVID-19 open research dataset</article-title>. In: <source>Proceedings of the 1st Workshop on NLP for COVID-19 at ACL 2020 Online</source>: <publisher-name>Association for Computational Linguistics</publisher-name>; <year>2020</year>. <comment><ext-link xlink:href="https://www.aclweb.org/anthology/2020.nlpcovid19-acl.1" ext-link-type="uri">https://www.aclweb.org/anthology/2020.nlpcovid19-acl.1</ext-link></comment></mixed-citation>
    </ref>
    <ref id="bib3">
      <label>3.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Shu</surname><given-names>Y</given-names></string-name>, <string-name><surname>McCauley</surname><given-names>J</given-names></string-name></person-group>. <article-title>GISAID: global initiative on sharing all influenza data–from vision to reality</article-title>. <source>Eurosurveillance</source>. <year>2017</year>;<volume>22</volume>(<issue>13</issue>).</mixed-citation>
    </ref>
    <ref id="bib4">
      <label>4.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sayers</surname><given-names>EW</given-names></string-name>, <string-name><surname>Cavanaugh</surname><given-names>M</given-names></string-name>, <string-name><surname>Clark</surname><given-names>K</given-names></string-name><etal>et al.</etal></person-group><article-title>GenBank 2023 update</article-title>. <source>Nucleic Acids Res</source>. <year>2023</year>;<volume>51</volume>:<issue>D1</issue>:<fpage>D141</fpage>–<lpage>D144</lpage>.<pub-id pub-id-type="pmid">36350640</pub-id></mixed-citation>
    </ref>
    <ref id="bib5">
      <label>5.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><collab>The COVID-19 Genomics UK (COG-UK) consortium</collab></person-group>. <article-title>An integrated national scale SARS-CoV-2 genomic surveillance network</article-title>. <source>Lancet Microbe</source>. <year>2020</year>;<volume>1</volume>(<issue>3</issue>):<fpage>e99</fpage>.<pub-id pub-id-type="pmid">32835336</pub-id></mixed-citation>
    </ref>
    <ref id="bib6">
      <label>6.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bernasconi</surname><given-names>A</given-names></string-name>, <string-name><surname>Mari</surname><given-names>L</given-names></string-name>, <string-name><surname>Casagrandi</surname><given-names>R</given-names></string-name><etal>et al.</etal></person-group><article-title>Data-driven analysis of amino acid change dynamics timely reveals SARS-CoV-2 variant emergence</article-title>. <source>Sci Rep</source>. <year>2021</year>;<volume>11</volume>(<issue>1</issue>):<fpage>1</fpage>–<lpage>10</lpage>.<pub-id pub-id-type="pmid">33414495</pub-id></mixed-citation>
    </ref>
    <ref id="bib7">
      <label>7.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chiara</surname><given-names>M</given-names></string-name>, <string-name><surname>Horner</surname><given-names>DS</given-names></string-name>, <string-name><surname>Gissi</surname><given-names>C</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Comparative genomics reveals early emergence and biased spatiotemporal distribution of SARS-CoV-2</article-title>. <source>Mol Biol Evol</source>. <year>2021</year>;<volume>38</volume>(<issue>6</issue>):<fpage>2547</fpage>–<lpage>65</lpage>.<pub-id pub-id-type="pmid">33605421</pub-id></mixed-citation>
    </ref>
    <ref id="bib8">
      <label>8.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Huang</surname><given-names>Q</given-names></string-name>, <string-name><surname>Zhang</surname><given-names>Q</given-names></string-name>, <string-name><surname>Bible</surname><given-names>PW</given-names></string-name>, <etal>et al.</etal></person-group><article-title>A new way to trace SARS-CoV-2 variants through weighted network analysis of frequency trajectories of mutations</article-title>. <source>Front Microbiol</source>. <year>2022</year>;<volume>13</volume>.</mixed-citation>
    </ref>
    <ref id="bib9">
      <label>9.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Korber</surname><given-names>B</given-names></string-name>, <string-name><surname>Fischer</surname><given-names>WM</given-names></string-name>, <string-name><surname>Gnanakaran</surname><given-names>S</given-names></string-name><etal>et al.</etal></person-group><article-title>Tracking changes in SARS-CoV-2 spike: evidence that D614G increases infectivity of the COVID-19 virus</article-title>. <source>Cell</source>. <year>2020</year>;<volume>182</volume>(<issue>4</issue>):<fpage>812</fpage>–<lpage>27</lpage>.<pub-id pub-id-type="pmid">32697968</pub-id></mixed-citation>
    </ref>
    <ref id="bib10">
      <label>10.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hodcroft</surname><given-names>EB</given-names></string-name>, <string-name><surname>Zuber</surname><given-names>M</given-names></string-name>, <string-name><surname>Nadeau</surname><given-names>S</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Spread of a SARS-CoV-2 variant through Europe in the summer of 2020</article-title>. <source>Nature</source>. <year>2021</year>;<volume>595</volume>(<issue>7869</issue>):<fpage>707</fpage>–<lpage>12</lpage>.<pub-id pub-id-type="pmid">34098568</pub-id></mixed-citation>
    </ref>
    <ref id="bib11">
      <label>11.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Li</surname><given-names>Q</given-names></string-name>, <string-name><surname>Wu</surname><given-names>J</given-names></string-name>, <string-name><surname>Nie</surname><given-names>J</given-names></string-name>, <etal>et al.</etal></person-group><article-title>The impact of mutations in SARS-CoV-2 spike on viral infectivity and antigenicity</article-title>. <source>Cell</source>. <year>2020</year>;<volume>182</volume>(<issue>5</issue>):<fpage>1284</fpage>–<lpage>94</lpage>.<pub-id pub-id-type="pmid">32730807</pub-id></mixed-citation>
    </ref>
    <ref id="bib12">
      <label>12.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Radford</surname><given-names>A</given-names></string-name>, <string-name><surname>Wu</surname><given-names>J</given-names></string-name>, <string-name><surname>Child</surname><given-names>R</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Language models are unsupervised multitask learners</article-title>. <source>OpenAI Blog</source>. <year>2019</year>;<volume>1</volume>(<issue>8</issue>):<fpage>9</fpage>.</mixed-citation>
    </ref>
    <ref id="bib13">
      <label>13.</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Rophina</surname><given-names>M</given-names></string-name>, <string-name><surname>Pandhare</surname><given-names>K</given-names></string-name>, <string-name><surname>Mangla</surname><given-names>M</given-names></string-name><etal>et al.</etal></person-group><article-title>FaviCoV-a comprehensive manually curated resource for functional genetic variants in SARS-CoV-2. OSF Preprints 2020</article-title>. <pub-id pub-id-type="doi">10.31219/osf.io/wp5tx</pub-id><pub-id pub-id-type="doi">10.31219/osf.io/wp5tx</pub-id></mixed-citation>
    </ref>
    <ref id="bib14">
      <label>14.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rophina</surname><given-names>M</given-names></string-name>, <string-name><surname>Pandhare</surname><given-names>K</given-names></string-name>, <string-name><surname>Shamnath</surname><given-names>A</given-names></string-name>, <etal>et al.</etal></person-group><article-title>ESC: a comprehensive resource for SARSCoV-2 immune escape variants</article-title>. <source>Nucleic Acids Res</source>. <year>2022</year>;<volume>50</volume>(<issue>D1</issue>):<fpage>D771</fpage>–<lpage>6</lpage>.<pub-id pub-id-type="pmid">34643704</pub-id></mixed-citation>
    </ref>
    <ref id="bib15">
      <label>15.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wright</surname><given-names>DW</given-names></string-name>, <string-name><surname>Harvey</surname><given-names>WT</given-names></string-name>, <string-name><surname>Hughes</surname><given-names>J</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Tracking SARS-CoV-2 mutations and variants through the COG-UK-mutation Explorer</article-title>. <source>Virus Evol</source>. <year>2022</year>;<volume>8</volume>(<issue>1</issue>):<fpage>veac023</fpage>.<pub-id pub-id-type="pmid">35502202</pub-id></mixed-citation>
    </ref>
    <ref id="bib16">
      <label>16.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Subissi</surname><given-names>L</given-names></string-name>, <string-name><surname>von Gottberg</surname><given-names>A</given-names></string-name>, <string-name><surname>Thukral</surname><given-names>L</given-names></string-name>, <etal>et al.</etal></person-group><article-title>An early warning system for emerging SARS-CoV-2 variants</article-title>. <source>Nat Med</source>. <year>2022</year>;<volume>28</volume>(<issue>6</issue>):<fpage>1110</fpage>–<lpage>5</lpage>.<pub-id pub-id-type="pmid">35637337</pub-id></mixed-citation>
    </ref>
    <ref id="bib17">
      <label>17.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Torrens-Fontanals</surname><given-names>M</given-names></string-name>, <string-name><surname>Peralta-García</surname><given-names>A</given-names></string-name>, <string-name><surname>Talarico</surname><given-names>C</given-names></string-name><etal>et al.</etal></person-group><article-title>SCoV2-MD: a database for the dynamics of the SARS-CoV-2 proteome and variant impact predictions</article-title>. <source>Nucleic Acids Res</source>. <year>2022</year>;<volume>50</volume>(<issue>D1</issue>):<fpage>D858</fpage>–<lpage>66</lpage>.<pub-id pub-id-type="pmid">34761257</pub-id></mixed-citation>
    </ref>
    <ref id="bib18">
      <label>18.</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Hodcroft</surname><given-names>EB.</given-names></string-name></person-group><article-title>Covariants: SARS-CoV-2 mutations and variants of interest</article-title>. <year>2021</year>. <comment><ext-link xlink:href="https://covariants.org/" ext-link-type="uri">https://covariants.org/</ext-link></comment>. Accessed 2023 April 11.</mixed-citation>
    </ref>
    <ref id="bib19">
      <label>19.</label>
      <mixed-citation publication-type="other">
        <comment>European Centre for Disease Prevention and Control. SARS-CoV-2 variants of concern. 2021.</comment>
        <comment>
          <ext-link xlink:href="https://www.ecdc.europa.eu/en/covid-19/variants-concern" ext-link-type="uri">https://www.ecdc.europa.eu/en/covid-19/variants-concern. Accessed 2023 April 11.</ext-link>
        </comment>
      </mixed-citation>
    </ref>
    <ref id="bib20">
      <label>20.</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><collab>World Health Organization</collab></person-group>. <article-title>Tracking SARS-CoV-2 variants</article-title>. <year>2021</year>; . <comment><ext-link xlink:href="https://www.who.int/en/activities/tracking-SARS-CoV-2-variants/" ext-link-type="uri">https://www.who.int/en/activities/tracking-SARS-CoV-2-variants/</ext-link></comment>. Accessed 2023 April 11.</mixed-citation>
    </ref>
    <ref id="bib21">
      <label>21.</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><collab>Centers for Disease Control and Prevention.</collab></person-group><article-title>SARS-CoV-2 variant classifications and definitions</article-title>. <year>2022</year>. <comment><ext-link xlink:href="https://www.cdc.gov/coronavirus/2019-ncov/variants/variant-info.html" ext-link-type="uri">https://www.cdc.gov/coronavirus/2019-ncov/variants/variant-info.html</ext-link></comment>. Accessed 2023 April 11.</mixed-citation>
    </ref>
    <ref id="bib22">
      <label>22.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Alfonsi</surname><given-names>T</given-names></string-name>, <string-name><surname>Al Khalaf</surname><given-names>R</given-names></string-name>, <string-name><surname>Ceri</surname><given-names>S</given-names></string-name>, <etal>et al.</etal></person-group><article-title>CoV2K model, a comprehensive representation of SARS-CoV-2 knowledge and data interplay</article-title>. <source>Sci Data</source>. <year>2022</year>;<volume>9</volume>:<fpage>260</fpage>.<pub-id pub-id-type="pmid">35650205</pub-id></mixed-citation>
    </ref>
    <ref id="bib23">
      <label>23.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Min</surname><given-names>S</given-names></string-name>, <string-name><surname>Lee</surname><given-names>B</given-names></string-name>, <string-name><surname>Yoon</surname><given-names>S</given-names></string-name></person-group>. <article-title>Deep learning in bioinformatics</article-title>. <source>Briefings Bioinf</source>. <year>2017</year>;<volume>18</volume>(<issue>5</issue>):<fpage>851</fpage>–<lpage>69</lpage>.</mixed-citation>
    </ref>
    <ref id="bib24">
      <label>24.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lan</surname><given-names>K</given-names></string-name>, <string-name><surname>Wang</surname><given-names>Dt</given-names></string-name>, <string-name><surname>Fong</surname><given-names>S</given-names></string-name>, <etal>et al.</etal></person-group><article-title>A survey of data mining and deep learning in bioinformatics</article-title>. <source>J Med Syst</source>. <year>2018</year>;<volume>42</volume>:<fpage>139</fpage>.<pub-id pub-id-type="pmid">29956014</pub-id></mixed-citation>
    </ref>
    <ref id="bib25">
      <label>25.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ofer</surname><given-names>D</given-names></string-name>, <string-name><surname>Brandes</surname><given-names>N</given-names></string-name>, <string-name><surname>Linial</surname><given-names>M.</given-names></string-name></person-group><article-title>The language of proteins: NLP, machine learning &amp; protein sequences</article-title>. <source>Computational Structural Biotechnol J</source>. <year>2021</year>;<volume>19</volume>:<fpage>1750</fpage>–<lpage>8</lpage>.</mixed-citation>
    </ref>
    <ref id="bib26">
      <label>26.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>He</surname><given-names>Y</given-names></string-name>, <string-name><surname>Shen</surname><given-names>Z</given-names></string-name>, <string-name><surname>Zhang</surname><given-names>Q</given-names></string-name>, <etal>et al.</etal></person-group><article-title>A survey on deep learning in DNA/RNA motif mining</article-title>. <source>Briefings Bioinf</source>. <year>2021</year>;<volume>22</volume>(<issue>4</issue>):<fpage>bbaa229</fpage>.</mixed-citation>
    </ref>
    <ref id="bib27">
      <label>27.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bhatnagar</surname><given-names>R</given-names></string-name>, <string-name><surname>Sardar</surname><given-names>S</given-names></string-name>, <string-name><surname>Beheshti</surname><given-names>M</given-names></string-name><etal>et al.</etal></person-group><article-title>How can natural language processing help model informed drug development? A review</article-title>. <source>JAMIA Open</source>. <year>2022</year>;<volume>5</volume>(<issue>2</issue>):<fpage>ooac043</fpage>.<pub-id pub-id-type="pmid">35702625</pub-id></mixed-citation>
    </ref>
    <ref id="bib28">
      <label>28.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pandey</surname><given-names>B</given-names></string-name>, <string-name><surname>Pandey</surname><given-names>DK</given-names></string-name>, <string-name><surname>Mishra</surname><given-names>BP</given-names></string-name>, <etal>et al.</etal></person-group><article-title>A comprehensive survey of deep learning in the field of medical imaging and medical natural language processing: challenges and research directions</article-title>. <source>J King Saud Univ</source>. <year>2022</year>;<volume>34</volume>(<issue>8</issue>):<fpage>5083</fpage>–<lpage>99</lpage>.</mixed-citation>
    </ref>
    <ref id="bib29">
      <label>29.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Velupillai</surname><given-names>S</given-names></string-name>, <string-name><surname>Suominen</surname><given-names>H</given-names></string-name>, <string-name><surname>Liakata</surname><given-names>M</given-names></string-name><etal>et al.</etal></person-group><article-title>Using clinical natural language processing for health outcomes research: overview and actionable suggestions for future advances</article-title>. <source>J Biomed Inform</source>. <year>2018</year>;<volume>88</volume>:<fpage>11</fpage>–<lpage>19</lpage>.<pub-id pub-id-type="pmid">30368002</pub-id></mixed-citation>
    </ref>
    <ref id="bib30">
      <label>30.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sheikhalishahi</surname><given-names>S</given-names></string-name>, <string-name><surname>Miotto</surname><given-names>R</given-names></string-name>, <string-name><surname>Dudley</surname><given-names>JT</given-names></string-name><etal>et al.</etal></person-group><article-title>Natural language processing of clinical notes on chronic diseases: systematic review</article-title>. <source>JMIR Med Inform</source>. <year>2019</year>;<volume>7</volume>(<issue>2</issue>):<fpage>e12239</fpage>.<pub-id pub-id-type="pmid">31066697</pub-id></mixed-citation>
    </ref>
    <ref id="bib31">
      <label>31.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wu</surname><given-names>H</given-names></string-name>, <string-name><surname>Wang</surname><given-names>M</given-names></string-name>, <string-name><surname>Wu</surname><given-names>J</given-names></string-name>, <etal>et al.</etal></person-group><article-title>A survey on clinical natural language processing in the United Kingdom from 2007 to 2022</article-title>. <source>NPJ Digital Med</source>. <year>2022</year>;<volume>5</volume>(<issue>1</issue>):<fpage>186</fpage>.</mixed-citation>
    </ref>
    <ref id="bib32">
      <label>32.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Singhal</surname><given-names>A</given-names></string-name>, <string-name><surname>Simmons</surname><given-names>M</given-names></string-name>, <string-name><surname>Lu</surname><given-names>Z</given-names></string-name></person-group>. <article-title>Text mining genotype-phenotype relationships from biomedical literature for database curation and precision medicine</article-title>. <source>PLoS Comput Biol</source>. <year>2016</year>;<volume>12</volume>(<issue>11</issue>):<fpage>e1005017</fpage>.<pub-id pub-id-type="pmid">27902695</pub-id></mixed-citation>
    </ref>
    <ref id="bib33">
      <label>33.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wei</surname><given-names>CH</given-names></string-name>, <string-name><surname>Kao</surname><given-names>HY</given-names></string-name>, <string-name><surname>Lu</surname><given-names>Z.</given-names></string-name></person-group><article-title>PubTator: a web-based text mining tool for assisting biocuration</article-title>. <source>Nucleic Acids Res</source>. <year>2013</year>;<volume>41</volume>(<issue>W1</issue>):<fpage>W518</fpage>–<lpage>22</lpage>.<pub-id pub-id-type="pmid">23703206</pub-id></mixed-citation>
    </ref>
    <ref id="bib34">
      <label>34.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Singhal</surname><given-names>A</given-names></string-name>, <string-name><surname>Simmons</surname><given-names>M</given-names></string-name>, <string-name><surname>Lu</surname><given-names>Z.</given-names></string-name></person-group><article-title>Text mining for precision medicine: automating disease-mutation relationship extraction from biomedical literature</article-title>. <source>J Am Med Inform Assoc</source>. <year>2016</year>;<volume>23</volume>(<issue>4</issue>):<fpage>766</fpage>–<lpage>72</lpage>.<pub-id pub-id-type="pmid">27121612</pub-id></mixed-citation>
    </ref>
    <ref id="bib35">
      <label>35.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tong</surname><given-names>Y</given-names></string-name>, <string-name><surname>Tan</surname><given-names>F</given-names></string-name>, <string-name><surname>Huang</surname><given-names>H</given-names></string-name><etal>et al.</etal></person-group><article-title>ViMRT: a text-mining tool and search engine for automated virus mutation recognition</article-title>. <source>Bioinformatics</source>. <year>2023</year>;<volume>39</volume>(<issue>1</issue>):<fpage>btac721</fpage>.<pub-id pub-id-type="pmid">36342236</pub-id></mixed-citation>
    </ref>
    <ref id="bib36">
      <label>36.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kalyan</surname><given-names>KS</given-names></string-name>, <string-name><surname>Rajasekharan</surname><given-names>A</given-names></string-name>, <string-name><surname>Sangeetha</surname><given-names>S.</given-names></string-name></person-group><article-title>AMMU: a survey of transformer-based biomedical pretrained language models</article-title>. <source>J Biomed Inform</source>. <year>2022</year>;<volume>126</volume>:<fpage>103982</fpage>.<pub-id pub-id-type="pmid">34974190</pub-id></mixed-citation>
    </ref>
    <ref id="bib37">
      <label>37.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kalyan</surname><given-names>KS</given-names></string-name>, <string-name><surname>Rajasekharan</surname><given-names>A</given-names></string-name>, <string-name><surname>Sangeetha</surname><given-names>S.</given-names></string-name></person-group><article-title>Ammus: a survey of transformer-based pretrained models in natural language processing</article-title>. <source>arXiv.</source><year>2021.</year>; <comment><ext-link xlink:href="https://arxiv.org/abs/2108.05542" ext-link-type="uri">https://arxiv.org/abs/2108.05542.</ext-link></comment></mixed-citation>
    </ref>
    <ref id="bib38">
      <label>38.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname><given-names>B</given-names></string-name>, <string-name><surname>Xie</surname><given-names>Q</given-names></string-name>, <string-name><surname>Pei</surname><given-names>J</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Pre-trained language models in biomedical domain: a systematic survey</article-title>. <source>arXiv.</source><year>2021</year>. <comment><ext-link xlink:href="https://arxiv.org/abs/2110.05006" ext-link-type="uri">https://arxiv.org/abs/2110.05006.</ext-link></comment></mixed-citation>
    </ref>
    <ref id="bib39">
      <label>39.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname><given-names>S</given-names></string-name>, <string-name><surname>Fan</surname><given-names>R</given-names></string-name>, <string-name><surname>Liu</surname><given-names>Y</given-names></string-name><etal>et al.</etal></person-group><article-title>Applications of transformer-based language models in bioinformatics: a survey</article-title>. <source>Bioinform Adv</source>. <year>2023</year>;<volume>3</volume>(<issue>1</issue>):<fpage>vbad001</fpage>.<pub-id pub-id-type="pmid">36845200</pub-id></mixed-citation>
    </ref>
    <ref id="bib40">
      <label>40.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Warikoo</surname><given-names>N</given-names></string-name>, <string-name><surname>Chang</surname><given-names>YC</given-names></string-name>, <string-name><surname>Hsu</surname><given-names>WL.</given-names></string-name></person-group><article-title>LBERT: lexically aware transformer-based bidirectional encoder representation model for learning universal bio-entity relations</article-title>. <source>Bioinformatics</source>. <year>2021</year>;<volume>37</volume>(<issue>3</issue>):<fpage>404</fpage>–<lpage>12</lpage>.<pub-id pub-id-type="pmid">32810217</pub-id></mixed-citation>
    </ref>
    <ref id="bib41">
      <label>41.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lai</surname><given-names>PT</given-names></string-name>, <string-name><surname>Lu</surname><given-names>Z.</given-names></string-name></person-group><article-title>BERT-GT: cross-sentence n-ary relation extraction with BERT and Graph Transformer</article-title>. <source>Bioinformatics</source>. <year>2021</year>;<volume>36</volume>(<issue>24</issue>):<fpage>5678</fpage>–<lpage>85</lpage>.<pub-id pub-id-type="pmid">33416851</pub-id></mixed-citation>
    </ref>
    <ref id="bib42">
      <label>42.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Clauwaert</surname><given-names>J</given-names></string-name>, <string-name><surname>Menschaert</surname><given-names>G</given-names></string-name>, <string-name><surname>Waegeman</surname><given-names>W</given-names></string-name></person-group>. <article-title>Explainability in transformer models for functional genomics</article-title>. <source>Briefings Bioinf</source>. <year>2021</year>;<volume>22</volume>(<issue>5</issue>):<fpage>Bbab060</fpage>.</mixed-citation>
    </ref>
    <ref id="bib43">
      <label>43.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sokhansanj</surname><given-names>BA</given-names></string-name>, <string-name><surname>Zhao</surname><given-names>Z</given-names></string-name>, <string-name><surname>Rosen</surname><given-names>GL</given-names></string-name></person-group>. <article-title>Interpretable and predictive deep neural network modeling of the SARSCoV-2 spike protein sequence to predict COVID-19 disease severity</article-title>. <source>Biology</source>. <year>2022</year>;<volume>11</volume>(<issue>12</issue>):<fpage>1786</fpage>.<pub-id pub-id-type="pmid">36552295</pub-id></mixed-citation>
    </ref>
    <ref id="bib44">
      <label>44.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Cannizzaro</surname><given-names>G</given-names></string-name>, <string-name><surname>Leone</surname><given-names>M</given-names></string-name>, <string-name><surname>Bernasconi</surname><given-names>A</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Automated integration of genomic metadata with sequence-to-sequence models</article-title>. In: <source>Joint European Conference on Machine Learning and Knowledge Discovery in Databases</source>. <publisher-name>Springer</publisher-name>; <year>2020</year>:<fpage>187</fpage>–<lpage>203</lpage>.. <pub-id pub-id-type="doi">10.1007/978-3-030-67670-4_12</pub-id></mixed-citation>
    </ref>
    <ref id="bib45">
      <label>45.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Serna Garcia</surname><given-names>G</given-names></string-name>, <string-name><surname>Leone</surname><given-names>M</given-names></string-name>, <string-name><surname>Bernasconi</surname><given-names>A</given-names></string-name><etal>et al.</etal></person-group><article-title>GeMI: interactive interface for transformer-based Genomic Metadata Integration</article-title>. <source>Database</source>. <year>2022</year>;<volume>2022</volume>:<fpage>baac036</fpage>.<pub-id pub-id-type="pmid">35657113</pub-id></mixed-citation>
    </ref>
    <ref id="bib46">
      <label>46.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Barrett</surname><given-names>T</given-names></string-name>, <string-name><surname>Wilhite</surname><given-names>SE</given-names></string-name>, <string-name><surname>Ledoux</surname><given-names>P</given-names></string-name>, <etal>et al.</etal></person-group><article-title>NCBI GEO: archive for functional genomics data sets—update</article-title>. <source>Nucleic Acids Res</source>. <year>2012</year>;<volume>41</volume>(<issue>D1</issue>):<fpage>D991</fpage>–<lpage>5</lpage>.<pub-id pub-id-type="pmid">23193258</pub-id></mixed-citation>
    </ref>
    <ref id="bib47">
      <label>47.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>He</surname><given-names>H</given-names></string-name>, <string-name><surname>Fu</surname><given-names>S</given-names></string-name>, <string-name><surname>Wang</surname><given-names>L</given-names></string-name>, <etal>et al.</etal></person-group><article-title>MedTator: a serverless annotation tool for corpus development</article-title>. <source>Bioinformatics</source>. <year>2022</year>;<volume>38</volume>(<issue>6</issue>):<fpage>1776</fpage>–<lpage>8</lpage>.<pub-id pub-id-type="pmid">34983060</pub-id></mixed-citation>
    </ref>
    <ref id="bib48">
      <label>48.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Feng</surname><given-names>Y</given-names></string-name>, <string-name><surname>Qi</surname><given-names>L</given-names></string-name>, <string-name><surname>Tian</surname><given-names>W.</given-names></string-name></person-group>. <article-title>PhenoBERT: a combined deep learning method for automated recognition of human phenotype ontology</article-title>. <source>IEEE/ACM Trans Comput Biol Bioinf</source>. <year>2022</year>.<volume>20</volume>:<issue>(2)</issue>: <fpage>1269</fpage>–<lpage>1277</lpage>.</mixed-citation>
    </ref>
    <ref id="bib49">
      <label>49.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Balabin</surname><given-names>H</given-names></string-name>, <string-name><surname>Hoyt</surname><given-names>CT</given-names></string-name>, <string-name><surname>Birkenbihl</surname><given-names>C</given-names></string-name><etal>et al.</etal></person-group><article-title>STonKGs: a sophisticated transformer trained on biomedical text and knowledge graphs</article-title>. <source>Bioinformatics</source>. <year>2022</year>;<volume>38</volume>(<issue>6</issue>):<fpage>1648</fpage>–<lpage>56</lpage>.<pub-id pub-id-type="pmid">34986221</pub-id></mixed-citation>
    </ref>
    <ref id="bib50">
      <label>50.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Balabin</surname><given-names>H</given-names></string-name>, <string-name><surname>Hoyt</surname><given-names>CT</given-names></string-name>, <string-name><surname>Gyori</surname><given-names>BM</given-names></string-name>, <etal>et al.</etal></person-group><article-title>ProtSTonKGs: a sophisticated transformer trained on protein sequences, text, and knowledge graphs</article-title>. In: <source>SWAT4HCLS</source>; <person-group person-group-type="editor"><string-name><surname>Wolstencroft</surname><given-names>K.</given-names></string-name>, <string-name><surname>Splendiani</surname><given-names>A.</given-names></string-name>, <string-name><surname>Scott</surname><given-names>M.</given-names></string-name></person-group>, et al. <publisher-name>CEUR Workshop Proceedings</publisher-name><year>2022</year>:<fpage>103</fpage>–<lpage>7</lpage>.. <ext-link xlink:href="https://ceur-ws.org/Vol-3127/ " ext-link-type="uri">https://ceur-ws.org/Vol-3127/ </ext-link></mixed-citation>
    </ref>
    <ref id="bib51">
      <label>51.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Mahajan</surname><given-names>D</given-names></string-name>, <string-name><surname>Liang</surname><given-names>JJ</given-names></string-name>, <string-name><surname>Tsou</surname><given-names>CH.</given-names></string-name></person-group><article-title>Toward understanding clinical context of medication change events in clinical narratives</article-title>. In: <source>AMIA Annual Symposium Proceedings</source>. <publisher-name>American Medical Informatics Association</publisher-name>; <year>2021</year>:<fpage>833</fpage>.</mixed-citation>
    </ref>
    <ref id="bib52">
      <label>52.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cohan</surname><given-names>A</given-names></string-name>, <string-name><surname>Feldman</surname><given-names>S</given-names></string-name>, <string-name><surname>Beltagy</surname><given-names>I</given-names></string-name>, <etal>et al.</etal></person-group><article-title>SPECTER: document-level representation learning using citation-informed transformers</article-title>. <source>arXiv.</source><year>2020.</year>; <comment><ext-link xlink:href="https://arxiv.org/abs/2004.07180" ext-link-type="uri">https://arxiv.org/abs/2004.07180</ext-link></comment>.</mixed-citation>
    </ref>
    <ref id="bib53">
      <label>53.</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Danilák</surname><given-names>M. </given-names></string-name></person-group><comment>Port of Nakatani Shuyo's language-detection library to Python. </comment><year>2022</year>. <comment><ext-link xlink:href="https://github.com/Mimino666/langdetect" ext-link-type="uri">https://github.com/Mimino666/langdetect</ext-link></comment>. <comment>Accessed 2023 April 11</comment>.</mixed-citation>
    </ref>
    <ref id="bib54">
      <label>54.</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Chaput</surname><given-names>M</given-names></string-name></person-group>. <article-title>Whoosh search engine library</article-title>. <year>2022</year>. <comment><ext-link xlink:href="https://github.com/mchaput/whoosh" ext-link-type="uri">https://github.com/mchaput/whoosh</ext-link></comment>. <comment>Accessed 2023 April 11</comment>.</mixed-citation>
    </ref>
    <ref id="bib55">
      <label>55.</label>
      <mixed-citation publication-type="other"><comment>Spotify. Annoy (Approximate Nearest Neighbors Oh Yeah). 2022</comment>. <comment><ext-link xlink:href="https://github.com/spotify/annoy" ext-link-type="uri">https://github.com/spotify/annoy</ext-link></comment>. <comment>Accessed 2023 April 11</comment>.</mixed-citation>
    </ref>
    <ref id="bib56">
      <label>56.</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Devlin</surname><given-names>J</given-names></string-name>, <string-name><surname>Chang</surname><given-names>M</given-names></string-name>, <string-name><surname>Lee</surname><given-names>K</given-names></string-name>, <etal>et al.</etal></person-group><article-title>BERT: pre-training of deep bidirectional transformers for language understanding</article-title>. <comment><italic toggle="yes">arXiv</italic></comment>. <year>2018</year>. <comment><ext-link xlink:href="http://arxiv.org/abs/1810.04805" ext-link-type="uri">http://arxiv.org/abs/1810.04805</ext-link></comment>.</mixed-citation>
    </ref>
    <ref id="bib57">
      <label>57.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhu</surname><given-names>Y</given-names></string-name>, <string-name><surname>Kiros</surname><given-names>R</given-names></string-name>, <string-name><surname>Zemel</surname><given-names>RS</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Aligning books and movies: towards story-like visual explanations by watching movies and reading books</article-title>. <source>arXiv.</source><year>2015</year>. <comment><ext-link xlink:href="http://arxiv.org/abs/1506.06724" ext-link-type="uri">http://arxiv.org/abs/1506.06724</ext-link></comment>.</mixed-citation>
    </ref>
    <ref id="bib58">
      <label>58.</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Romero</surname><given-names>M</given-names></string-name></person-group>. <comment>GPT-2-finetuned-CORD19</comment>. <comment><ext-link xlink:href="https://huggingface.co/mrm8488/GPT-2-finetuned-CORD19" ext-link-type="uri">https://huggingface.co/mrm8488/GPT-2-finetuned-CORD19</ext-link></comment>. <comment>Accessed 2023 April 11</comment>.</mixed-citation>
    </ref>
    <ref id="bib59">
      <label>59.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wu</surname><given-names>F</given-names></string-name>, <string-name><surname>Zhao</surname><given-names>S</given-names></string-name>, <string-name><surname>Yu</surname><given-names>B</given-names></string-name>, <etal>et al.</etal></person-group><article-title>A new coronavirus associated with human respiratory disease in China</article-title>. <source>Nature</source>. <year>2020</year>;<volume>579</volume>(<issue>7798</issue>):<fpage>265</fpage>–<lpage>9</lpage>.<pub-id pub-id-type="pmid">32015508</pub-id></mixed-citation>
    </ref>
    <ref id="bib60">
      <label>60.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lauring</surname><given-names>AS</given-names></string-name>, <string-name><surname>Hodcroft</surname><given-names>EB.</given-names></string-name></person-group><article-title>Genetic variants of SARS-CoV-2—What do they mean?</article-title>. <source>JAMA</source>. <year>2021</year>;<volume>325</volume>(<issue>6</issue>):<fpage>529</fpage>–<lpage>31</lpage>.<pub-id pub-id-type="pmid">33404586</pub-id></mixed-citation>
    </ref>
    <ref id="bib61">
      <label>61.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rambaut</surname><given-names>A</given-names></string-name>, <string-name><surname>Holmes</surname><given-names>EC</given-names></string-name>, <string-name><surname>O'Toole</surname><given-names>Á</given-names></string-name><etal>et al.</etal></person-group><article-title>A dynamic nomenclature proposal for SARS-CoV-2 lineages to assist genomic epidemiology</article-title>. <source>Nat Microbiol</source>. <year>2020</year>;<volume>5</volume>(<issue>11</issue>):<fpage>1403</fpage>–<lpage>7</lpage>.<pub-id pub-id-type="pmid">32669681</pub-id></mixed-citation>
    </ref>
    <ref id="bib62">
      <label>62.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Al Khalaf</surname><given-names>R</given-names></string-name>, <string-name><surname>Alfonsi</surname><given-names>T</given-names></string-name>, <string-name><surname>Ceri</surname><given-names>S</given-names></string-name>, <etal>et al.</etal></person-group><article-title>CoV2K: a knowledge base of SARS-CoV-2 variant impacts</article-title>. In: <person-group person-group-type="editor"><string-name><surname>Cherfi</surname><given-names>S</given-names></string-name>, <string-name><surname>Perini</surname><given-names>A</given-names></string-name>, <string-name><surname>Nurcan</surname><given-names>S</given-names></string-name></person-group>, editors. <source>Research Challenges in Information Science.</source><publisher-loc>Cham, Switzerland</publisher-loc>: <publisher-name>Springer International</publisher-name>; <year>2021</year>:<fpage>274</fpage>–<lpage>82</lpage>.</mixed-citation>
    </ref>
    <ref id="bib63">
      <label>63.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Serna Garcia</surname><given-names>G</given-names></string-name>, <string-name><surname>Al Khalaf</surname><given-names>R</given-names></string-name>, <string-name><surname>Invernici</surname><given-names>F</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Supporting data for "CoVEffect: Interactive System for Mining the Effects of SARS-CoV-2 Mutations and Variants Based on Deep Learning"</article-title>. <source>GigaScience Database</source>. <year>2023</year>. <pub-id pub-id-type="doi">10.5524/102386</pub-id></mixed-citation>
    </ref>
    <ref id="bib64">
      <label>64.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ou</surname><given-names>J</given-names></string-name>, <string-name><surname>Zhou</surname><given-names>Z</given-names></string-name>, <string-name><surname>Dai</surname><given-names>R</given-names></string-name>, <etal>et al.</etal></person-group><article-title>V367F mutation in SARS-CoV-2 spike RBD emerging during the early transmission phase enhances viral infectivity through increased human ACE2 receptor binding affinity</article-title>. <source>J Virol</source>. <year>2021</year>;<volume>95</volume>(<issue>16</issue>):<fpage>e00617</fpage>–<lpage>21</lpage>.<pub-id pub-id-type="pmid">34105996</pub-id></mixed-citation>
    </ref>
    <ref id="bib65">
      <label>65.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bansal</surname><given-names>MA</given-names></string-name>, <string-name><surname>Sharma</surname><given-names>DR</given-names></string-name>, <string-name><surname>Kathuria</surname><given-names>DM.</given-names></string-name></person-group><article-title>A systematic review on data scarcity problem in deep learning: solution and applications</article-title>. <source>ACM Computing Surveys (CSUR)</source>. <year>2022</year>;<volume>54</volume>(<issue>10</issue><issue>s</issue>):<fpage>1</fpage>–<lpage>29</lpage>.</mixed-citation>
    </ref>
    <ref id="bib66">
      <label>66.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tinn</surname><given-names>R</given-names></string-name>, <string-name><surname>Cheng</surname><given-names>H</given-names></string-name>, <string-name><surname>Gu</surname><given-names>Y</given-names></string-name><etal>et al.</etal></person-group><article-title>Fine-tuning large neural language models for biomedical natural language processing</article-title>. <source>Patterns</source>. <year>2023</year>;<volume>4</volume>:<fpage>100729</fpage>.<pub-id pub-id-type="pmid">37123444</pub-id></mixed-citation>
    </ref>
    <ref id="bib67">
      <label>67.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chen</surname><given-names>T</given-names></string-name>, <string-name><surname>Wu</surname><given-names>M</given-names></string-name>, <string-name><surname>Li</surname><given-names>H.</given-names></string-name></person-group><article-title>A general approach for improving deep learning-based medical relation extraction using a pre-trained model and fine-tuning</article-title>. <source>Database</source>. <year>2019</year>;<volume>2019</volume>:<fpage>baz116</fpage>.<pub-id pub-id-type="pmid">31800044</pub-id></mixed-citation>
    </ref>
    <ref id="bib68">
      <label>68.</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><collab>PyTorch</collab></person-group>. <year>2022</year>. <comment><ext-link xlink:href="https://pytorch.org/docs/stable/generated/torch.optim.AdamW.html" ext-link-type="uri">https://pytorch.org/docs/stable/generated/torch.optim.AdamW.html</ext-link></comment>. <comment>[Accessed 2023 April 11]</comment>.</mixed-citation>
    </ref>
    <ref id="bib69">
      <label>69.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Burger</surname><given-names>JD</given-names></string-name>, <string-name><surname>Doughty</surname><given-names>E</given-names></string-name>, <string-name><surname>Khare</surname><given-names>R</given-names></string-name><etal>et al.</etal></person-group><article-title>Hybrid curation of gene–mutation relations combining automated extraction and crowdsourcing</article-title>. <source><italic toggle="yes">Database</italic></source>. <year>2014</year>;<volume>2014</volume>:<fpage>bau094</fpage>.<pub-id pub-id-type="pmid">25246425</pub-id></mixed-citation>
    </ref>
    <ref id="bib70">
      <label>70.</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Atanasova</surname><given-names>P</given-names></string-name>, <string-name><surname>Simonsen</surname><given-names>JG</given-names></string-name>, <string-name><surname>Lioma</surname><given-names>C</given-names></string-name><etal>et al.</etal></person-group><article-title>A diagnostic study of explainability techniques for text classification</article-title>. <comment>EMNLP.</comment><year>2020.</year>; <comment><ext-link xlink:href="https://aclanthology.org/2020.emnlp-main.263" ext-link-type="uri">https://aclanthology.org/2020.emnlp-main.263</ext-link></comment>. [Last accessed 2023 April 9]</mixed-citation>
    </ref>
    <ref id="bib71">
      <label>71.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zeng</surname><given-names>C</given-names></string-name>, <string-name><surname>Evans</surname><given-names>JP</given-names></string-name>, <string-name><surname>Faraone</surname><given-names>JN</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Neutralization of SARS-CoV-2 variants of concern harboring Q677H</article-title>. <source>Mbio</source>. <year>2021</year>;<volume>12</volume>(<issue>5</issue>):<fpage>e02510</fpage>–<lpage>21</lpage>.<pub-id pub-id-type="pmid">34607452</pub-id></mixed-citation>
    </ref>
    <ref id="bib72">
      <label>72.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cheng</surname><given-names>L</given-names></string-name>, <string-name><surname>Song</surname><given-names>S</given-names></string-name>, <string-name><surname>Zhou</surname><given-names>B</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Impact of the N501Y substitution of SARS-CoV-2 Spike on neutralizing monoclonal antibodies targeting diverse epitopes</article-title>. <source>Virol J</source>. <year>2021</year>;<volume>18</volume>(<issue>1</issue>):<fpage>1</fpage>–<lpage>6</lpage>.<pub-id pub-id-type="pmid">33397387</pub-id></mixed-citation>
    </ref>
    <ref id="bib73">
      <label>73.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Escalera</surname><given-names>A</given-names></string-name>, <string-name><surname>Gonzalez-Reiche</surname><given-names>AS</given-names></string-name>, <string-name><surname>Aslam</surname><given-names>S</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Mutations in SARS-CoV-2 variants of concern link to increased spike cleavage and virus transmission</article-title>. <source>Cell Host Microbe</source>. <year>2022</year>;<volume>30</volume>(<issue>3</issue>):<fpage>373</fpage>–<lpage>87</lpage>.<pub-id pub-id-type="pmid">35150638</pub-id></mixed-citation>
    </ref>
    <ref id="bib74">
      <label>74.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Raghu</surname><given-names>D</given-names></string-name>, <string-name><surname>Hamill</surname><given-names>P</given-names></string-name>, <string-name><surname>Banaji</surname><given-names>A</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Assessment of the binding interactions of SARS-CoV-2 spike glycoprotein variants</article-title>. <source>J Pharm Anal</source>. <year>2022</year>;<volume>12</volume>(<issue>1</issue>):<fpage>58</fpage>–<lpage>64</lpage>.<pub-id pub-id-type="pmid">34545316</pub-id></mixed-citation>
    </ref>
    <ref id="bib75">
      <label>75.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cheng</surname><given-names>MH</given-names></string-name>, <string-name><surname>Krieger</surname><given-names>JM</given-names></string-name>, <string-name><surname>Banerjee</surname><given-names>A</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Impact of new variants on SARS-CoV-2 infectivity and neutralization: a molecular assessment of the alterations in the spike-host protein interactions</article-title>. <source>Iscience</source>. <year>2022</year>;<volume>25</volume>(<issue>3</issue>):<fpage>103939</fpage>.<pub-id pub-id-type="pmid">35194576</pub-id></mixed-citation>
    </ref>
    <ref id="bib76">
      <label>76.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kim</surname><given-names>JM</given-names></string-name>, <string-name><surname>Rhee</surname><given-names>JE</given-names></string-name>, <string-name><surname>Yoo</surname><given-names>M</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Increase in viral load in patients with SARS-CoV-2 delta variant infection in the Republic of Korea</article-title>. <source>Front Microbiol</source>. <year>2022</year>;<volume>13</volume>.</mixed-citation>
    </ref>
    <ref id="bib77">
      <label>77.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pohl</surname><given-names>MO</given-names></string-name>, <string-name><surname>Busnadiego</surname><given-names>I</given-names></string-name>, <string-name><surname>Kufner</surname><given-names>V</given-names></string-name>, <etal>et al.</etal></person-group><article-title>SARS-CoV-2 variants reveal features critical for replication in primary human cells</article-title>. <source>PLoS Biol</source>. <year>2021</year>;<volume>19</volume>(<issue>3</issue>):<fpage>e3001006</fpage>.<pub-id pub-id-type="pmid">33760807</pub-id></mixed-citation>
    </ref>
    <ref id="bib78">
      <label>78.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bernasconi</surname><given-names>A</given-names></string-name>, <string-name><surname>Gulino</surname><given-names>A</given-names></string-name>, <string-name><surname>Alfonsi</surname><given-names>T</given-names></string-name><etal>et al.</etal></person-group><article-title>VirusViz: comparative analysis and effective visualization of viral nucleotide and amino acid variants</article-title>. <source>Nucleic Acids Res</source>. <year>2021</year>;<volume>49</volume>(<issue>15</issue>):<fpage>e90</fpage>.<pub-id pub-id-type="pmid">34107016</pub-id></mixed-citation>
    </ref>
    <ref id="bib79">
      <label>79.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cilibrasi</surname><given-names>L</given-names></string-name>, <string-name><surname>Pinoli</surname><given-names>P</given-names></string-name>, <string-name><surname>Bernasconi</surname><given-names>A</given-names></string-name><etal>et al.</etal></person-group><article-title>ViruClust: direct comparison of SARSCoV-2 genomes and genetic variants in space and time</article-title>. <source>Bioinformatics</source>. <year>2022</year>;<volume>38</volume>(<issue>7</issue>):<fpage>1988</fpage>–<lpage>94</lpage>.<pub-id pub-id-type="pmid">35040923</pub-id></mixed-citation>
    </ref>
    <ref id="bib80">
      <label>80.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chen</surname><given-names>C</given-names></string-name>, <string-name><surname>Nadeau</surname><given-names>S</given-names></string-name>, <string-name><surname>Yared</surname><given-names>M</given-names></string-name>, <etal>et al.</etal></person-group><article-title>CoV-spectrum: analysis of globally shared SARS-CoV-2 data to identify and characterize new variants</article-title>. <source>Bioinformatics</source>. <year>2022</year>;<volume>38</volume>(<issue>6</issue>):<fpage>1735</fpage>–<lpage>7</lpage>.<pub-id pub-id-type="pmid">34954792</pub-id></mixed-citation>
    </ref>
    <ref id="bib81">
      <label>81.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gangavarapu</surname><given-names>K</given-names></string-name>, <string-name><surname>Latif</surname><given-names>AA</given-names></string-name>, <string-name><surname>Mullen</surname><given-names>JL</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Outbreak.Info genomic reports: scalable and dynamic surveillance of SARS-CoV-2 variants and mutations</article-title>. <source>Nat Methods</source>. <year>2023</year>;<volume>20</volume>(<issue>4</issue>):<fpage>512</fpage>–<lpage>22</lpage>.<pub-id pub-id-type="pmid">36823332</pub-id></mixed-citation>
    </ref>
    <ref id="bib82">
      <label>82.</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Serna Garcia</surname><given-names>G</given-names></string-name>, <string-name><surname>Al Khalaf</surname><given-names>R</given-names></string-name>, <string-name><surname>Invernici</surname><given-names>F</given-names></string-name><etal>et al.</etal></person-group> . <article-title>Supporting data for "CoVEffect: Interactive System for Mining the Effects of SARS-CoV-2 Mutations and Variants Based on Deep Learning" [Data set]</article-title>. .<year>2023</year>; <pub-id pub-id-type="doi">10.5281/zenodo.7817520</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
