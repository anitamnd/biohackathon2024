<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Gigascience</journal-id>
    <journal-id journal-id-type="iso-abbrev">Gigascience</journal-id>
    <journal-id journal-id-type="publisher-id">gigascience</journal-id>
    <journal-title-group>
      <journal-title>GigaScience</journal-title>
    </journal-title-group>
    <issn pub-type="epub">2047-217X</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">6857688</article-id>
    <article-id pub-id-type="pmid">31730697</article-id>
    <article-id pub-id-type="doi">10.1093/gigascience/giz134</article-id>
    <article-id pub-id-type="publisher-id">giz134</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Technical Note</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Deep learning for clustering of multivariate clinical patient trajectories with missing values</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0002-2097-0915</contrib-id>
        <name>
          <surname>de Jong</surname>
          <given-names>Johann</given-names>
        </name>
        <!--johann.dejong@ucb.com-->
        <xref rid="aff1" ref-type="aff">1</xref>
        <xref rid="cor1" ref-type="corresp"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Emon</surname>
          <given-names>Mohammad Asif</given-names>
        </name>
        <xref rid="aff2" ref-type="aff">2</xref>
        <xref rid="aff3" ref-type="aff">3</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Wu</surname>
          <given-names>Ping</given-names>
        </name>
        <xref rid="aff4" ref-type="aff">4</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Karki</surname>
          <given-names>Reagon</given-names>
        </name>
        <xref rid="aff2" ref-type="aff">2</xref>
        <xref rid="aff3" ref-type="aff">3</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Sood</surname>
          <given-names>Meemansa</given-names>
        </name>
        <xref rid="aff2" ref-type="aff">2</xref>
        <xref rid="aff3" ref-type="aff">3</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Godard</surname>
          <given-names>Patrice</given-names>
        </name>
        <xref rid="aff5" ref-type="aff">5</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Ahmad</surname>
          <given-names>Ashar</given-names>
        </name>
        <xref rid="aff3" ref-type="aff">3</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Vrooman</surname>
          <given-names>Henri</given-names>
        </name>
        <xref rid="aff6" ref-type="aff">6</xref>
        <xref rid="aff7" ref-type="aff">7</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Hofmann-Apitius</surname>
          <given-names>Martin</given-names>
        </name>
        <xref rid="aff2" ref-type="aff">2</xref>
        <xref rid="aff3" ref-type="aff">3</xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0002-5328-1243</contrib-id>
        <name>
          <surname>Fröhlich</surname>
          <given-names>Holger</given-names>
        </name>
        <!--frohlich@bit.uni-bonn.de-->
        <xref rid="aff1" ref-type="aff">1</xref>
        <xref rid="aff3" ref-type="aff">3</xref>
        <xref rid="cor2" ref-type="corresp"/>
      </contrib>
    </contrib-group>
    <aff id="aff1"><label>1</label><institution>UCB Biosciences GmbH</institution>, Alfred-Nobel-Strasse 10, 40789 Monheim, <country country="DE">Germany</country></aff>
    <aff id="aff2"><label>2</label><institution>Fraunhofer Institute for Algorithms and Scientific Computing</institution>, Schloss Birlinghoven, Konrad-Adenauer-Strasse, 53754 Sankt Augustin, <country country="DE">Germany</country></aff>
    <aff id="aff3"><label>3</label><institution>Bonn-Aachen International Center for IT, University of Bonn</institution>, Konrad-Adenauer-Strasse, 53115 Bonn, <country country="DE">Germany</country></aff>
    <aff id="aff4"><label>4</label><institution>UCB Pharma</institution>, Bath Road 216, Slough SL1 3WE, <country country="GB">UK</country></aff>
    <aff id="aff5"><label>5</label><institution>UCB Pharma</institution>, Chemin du Foriest 1, 1420 Braine-l’Alleud, <country country="BE">Belgium</country></aff>
    <aff id="aff6"><label>6</label><institution>Erasmus MC, University Medical Center Rotterdam</institution>, Department of Radiology, Doctor Molewaterplein 40, PO Box 2040, 3000 CA Rotterdam, <country country="NL">Netherlands</country></aff>
    <aff id="aff7"><label>7</label><institution>Erasmus MC, University Medical Center Rotterdam</institution>, Doctor Molewaterplein 40, Department of Medical Informatics, PO Box 2040, 3000 CA Rotterdam, <country country="NL">Netherlands</country></aff>
    <author-notes>
      <corresp id="cor1">Correspondence address. Johann de Jong, UCB Biosciences GmbH, Alfred-Nobel-Strasse 10, 40789 Monheim, Germany. E-mail: <email>johann.dejong@ucb.com</email></corresp>
      <corresp id="cor2">Correspondence address. Holger Fröhlich, Bonn-Aachen International Center for IT, University of Bonn, Konrad-Adenauer-Strasse, 53115 Bonn, Germany, E-mail: <email>frohlich@bit.uni-bonn.de</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <month>11</month>
      <year>2019</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2019-11-15">
      <day>15</day>
      <month>11</month>
      <year>2019</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>15</day>
      <month>11</month>
      <year>2019</year>
    </pub-date>
    <volume>8</volume>
    <issue>11</issue>
    <elocation-id>giz134</elocation-id>
    <history>
      <date date-type="received">
        <day>06</day>
        <month>6</month>
        <year>2019</year>
      </date>
      <date date-type="rev-recd">
        <day>23</day>
        <month>9</month>
        <year>2019</year>
      </date>
      <date date-type="accepted">
        <day>19</day>
        <month>10</month>
        <year>2019</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2019. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2019</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="giz134.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="abs1">
        <title>Background</title>
        <p>Precision medicine requires a stratification of patients by disease presentation that is sufficiently informative to allow for selecting treatments on a per-patient basis. For many diseases, such as neurological disorders, this stratification problem translates into a complex problem of clustering multivariate and relatively short time series because (i) these diseases are multifactorial and not well described by single clinical outcome variables and (ii) disease progression needs to be monitored over time. Additionally, clinical data often additionally are hindered by the presence of many missing values, further complicating any clustering attempts.</p>
      </sec>
      <sec id="abs2">
        <title>Findings</title>
        <p>The problem of clustering multivariate short time series with many missing values is generally not well addressed in the literature. In this work, we propose a deep learning–based method to address this issue, variational deep embedding with recurrence (VaDER). VaDER relies on a Gaussian mixture variational autoencoder framework, which is further extended to (i) model multivariate time series and (ii) directly deal with missing values. We validated VaDER by accurately recovering clusters from simulated and benchmark data with known ground truth clustering, while varying the degree of missingness. We then used VaDER to successfully stratify patients with Alzheimer disease and patients with Parkinson disease into subgroups characterized by clinically divergent disease progression profiles. Additional analyses demonstrated that these clinical differences reflected known underlying aspects of Alzheimer disease and Parkinson disease.</p>
      </sec>
      <sec id="abs3">
        <title>Conclusions</title>
        <p>We believe our results show that VaDER can be of great value for future efforts in patient stratification, and multivariate time-series clustering in general.</p>
      </sec>
    </abstract>
    <kwd-group kwd-group-type="keywords">
      <kwd>patient stratification</kwd>
      <kwd>deep learning</kwd>
      <kwd>multivariate time series</kwd>
      <kwd>multivariate longitudinal data</kwd>
      <kwd>clustering</kwd>
    </kwd-group>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Seventh Framework Programme</institution>
            <institution-id institution-id-type="doi">10.13039/100011102</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>FP7/2007-2013</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>European Federation of Pharmaceutical Industries and Associations</institution>
            <institution-id institution-id-type="doi">10.13039/100013322</institution-id>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Alzheimer's Disease Neuroimaging Initiative</institution>
            <institution-id institution-id-type="doi">10.13039/100007333</institution-id>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>National Institutes of Health</institution>
            <institution-id institution-id-type="doi">10.13039/100000002</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>U01 AG024904</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>National Institute on Aging</institution>
            <institution-id institution-id-type="doi">10.13039/100000049</institution-id>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>National Institute of Biomedical Imaging and Bioengineering</institution>
            <institution-id institution-id-type="doi">10.13039/100000070</institution-id>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>University of Southern California</institution>
            <institution-id institution-id-type="doi">10.13039/100006034</institution-id>
          </institution-wrap>
        </funding-source>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="14"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec id="sec1">
    <title>Findings</title>
    <sec id="sec1-1">
      <title>Background</title>
      <p>In precision medicine, patients are stratified on the basis of their disease subtype, risk, prognosis, or treatment response by means of specialized diagnostic tests. An important question in precision medicine is how to appropriately model disease progression and accordingly decide on the right type and time point of therapy for an individual. However, the progression of many diseases, such as neurological disorders, cardiovascular diseases, diabetes, and obesity [<xref rid="bib1" ref-type="bibr">1–5</xref>], is highly multifaceted and not well described by 1 clinical outcome measure alone. Classical univariate clustering methods are likely to miss the inherent complexity of diseases that demonstrate a highly multifaceted clinical phenotype. Accordingly, stratification of patients by disease progression translates into the challenging question of how to identify a clustering of a multivariate time series.</p>
      <p>Clustering is a fundamental and generally well-investigated problem in machine learning and statistics. Its goal is to segment samples into groups (clusters), such that there is a higher degree of similarity between samples of the same cluster than between samples of different clusters. Following Hastie et al. [<xref rid="bib6" ref-type="bibr">6</xref>], algorithms to solve clustering problems may be put into 3 main categories, (i) combinatorial algorithms, (ii) mixture modeling, and (iii) mode seeking. Within each of these 3 categories, a wide range of methods is available for a great diversity of clustering problems. Combinatorial algorithms do not assume any underlying probability model but work with the data directly. Examples are K-means clustering, spectral clustering [<xref rid="bib7" ref-type="bibr">7</xref>], and hierarchical clustering [<xref rid="bib8" ref-type="bibr">8</xref>]. Mixture models assume that the data can be described by some probabilistic model. An example is Gaussian mixture model clustering. Finally, in mode seeking one tries to directly estimate modes of the underlying multi-modal probability density. An important example here is the mean-shift algorithm [<xref rid="bib9" ref-type="bibr">9</xref>].</p>
      <p>For the clustering of multivariate time-series data, a few techniques have been developed [<xref rid="bib10" ref-type="bibr">10–14</xref>]. However, these approaches generally rely on time series of far greater length than available in most longitudinal clinical datasets. Moreover, these methods are not suited for the large numbers of missing values often found in clinical data.</p>
      <p>Missing values in clinical data can occur for different reasons: (i) patients drop out of a study, e.g., owing to worsening of symptoms; (ii) a certain diagnostic test is not taken at a particular visit (e.g., owing to lack of patient agreement), potentially resulting into missing information for entire variable groups; (iii) unclear further reasons, e.g., time constraints, data quality issues, etc. From a statistical point of view, these reasons manifest into different mechanisms of missing data [<xref rid="bib15" ref-type="bibr">15</xref>,<xref rid="bib16" ref-type="bibr">16</xref>]:
<list list-type="order"><list-item><p>Missing completely at random (MCAR): The probability of missing information is related neither to the specific value that is supposed to be obtained nor to other observed data. Hence, entire patient records could be skipped without introducing any bias. However, this type of missing data mechanism is probably rare in clinical studies.</p></list-item><list-item><p>Missing at random (MAR): The probability of missing information depends on other observed data but is not related to the specific missing value that is expected to be obtained. An example would be patient dropout due to worsening of certain symptoms, which are at the same time recorded during the study.</p></list-item><list-item><p>Missing not at random (MNAR): any reason for missing data that is neither MCAR nor MAR. MNAR is problematic because the only way to obtain unbiased estimates is to model missing data.</p></list-item></list></p>
      <p>Multiple-imputation methods have been proposed to deal with missing values in longitudinal patient data [<xref rid="bib16" ref-type="bibr">16</xref>]. However, any imputation method will result in certain errors, and if imputation and clustering are performed separately, these errors will propagate through to the following clustering procedure.</p>
      <p>To address the problem of clustering multivariate and relatively short time-series data with many missing values, in this article we propose an approach that uses techniques from deep learning. Autoencoder networks have been highly successful in learning latent representations of data (e.g., [<xref rid="bib17" ref-type="bibr">17–20</xref>]). Specifically for clustering, autoencoders can be first used to learn a latent representation of a multivariate distribution, to then independently find clusters [<xref rid="bib21" ref-type="bibr">21</xref>]. More recently, some authors have suggested simultaneously learning latent representations and cluster assignments. Interesting examples are deep embedded clustering [<xref rid="bib22" ref-type="bibr">22</xref>] and variational deep embedding (VaDE) [<xref rid="bib23" ref-type="bibr">23</xref>].</p>
      <p>Here, we present a new method for clustering multivariate time series with potentially many missing values, variational deep embedding with recurrence (VaDER). VaDER is in part based on VaDE [<xref rid="bib23" ref-type="bibr">23</xref>], a clustering algorithm based on variational autoencoder principles, with a latent representation forced towards a multivariate Gaussian mixture distribution. Additionally, VaDER (i) integrates 2 long short-term memory (LSTM) networks [<xref rid="bib24" ref-type="bibr">24</xref>] into its architecture, to allow for the analysis of multivariate time series; and (ii) adopts an approach of implicit imputation and loss reweighting to account for the typically high degree of missingness in clinical data.</p>
      <p>After a validation of VaDER via simulation and benchmark studies, we applied the method to the problem of patient stratification in Alzheimer disease (AD) and Parkinson disease (PD), using data from the Alzheimer’s Disease Neuroimaging Initiative (ADNI) [<xref rid="bib25" ref-type="bibr">25</xref>] and the Parkinson’s Progression Markers Initiative (PPMI) [<xref rid="bib26" ref-type="bibr">26</xref>], respectively. AD and PD are multifactorial and highly heterogeneous diseases, in both clinical and biological presentation, as well as in progression [<xref rid="bib27" ref-type="bibr">27–30</xref>]. For example, PD is characterized by motor symptoms and behavioral changes (e.g., sleeping disorders), as well as cognitive impairment [<xref rid="bib67_392_1572363658949" ref-type="bibr">31</xref>]. Cognitive impairment, one of the hallmarks of AD, is not straightforward to assess, because cognition itself is highly multifaceted, and described by, e.g., orientation, speech, and memory. Consequently, in the field of AD, a wide range of tests have been developed to assess different aspects of cognition.</p>
      <p>This heterogeneity presents one of the major challenges in understanding these diseases and developing new treatments. As such, better clustering (stratification) of patients by disease presentation could be of great help in improving disease management and designing better clinical trials that specifically focus on treating patients whose disease is rapidly progressing.</p>
      <p>Our analyses of the ADNI and PPMI data show that VaDER is highly effective at disentangling multivariate patient trajectories into clinically meaningful patient subgroups.</p>
    </sec>
    <sec sec-type="results" id="sec1-2">
      <title>Results</title>
      <sec id="sec1-2-1">
        <title>Variational autoencoders for clustering</title>
        <p>Our proposed VaDER method is in part based on VaDE [<xref rid="bib23" ref-type="bibr">23</xref>], a variational autoencoding clustering algorithm with a multivariate Gaussian mixture prior. In variational autoencoding algorithms, the training objective is to optimize the variational lower bound on the marginal likelihood of a data point <bold>x</bold> [<xref rid="bib31" ref-type="bibr">32</xref>]:
<disp-formula id="update299119_equ1"><label>(1)</label><tex-math id="TM0001" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
\begin{equation*}
\mathcal {L}({\bf x}) = \mathbb {E}_{{\it q}({\bf z}|{\bf x})} [\log (p({\bf x}|{\bf z}))] - D_{\mathrm{KL}}({\it q}({\bf z}|{\bf x})||p({\bf z})).
\end{equation*}\end{document}</tex-math></disp-formula></p>
        <p>This lower bound can be seen as composed of 2 parts. The first term corresponds to the likelihood of seeing <bold>x</bold> given a latent representation <bold>z</bold>. Its negative is often called the "reconstruction loss," and it forces the algorithm to learn good reconstructions of its input data. The negative of the second term is often called the "latent loss." It is the Kullback-Leibler divergence of the prior <italic toggle="yes">p</italic>(<bold>z</bold>) to the variational posterior <italic toggle="yes">q</italic>(<bold>z</bold>|<bold>x</bold>), and it regularizes the latent representation <bold>z</bold> to lie on a manifold specified by the prior <italic toggle="yes">p</italic>(<bold>z</bold>).</p>
        <p>In VaDE, this prior is a multivariate Gaussian mixture. Accordingly including a parameter for choosing a cluster <italic toggle="yes">c</italic>, the variational lower bound can then be written as follows:
<disp-formula id="update610119_update610119_equ2"><label>(2)</label><tex-math id="TM0002" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
\begin{equation*}
\mathcal {L}({\bf x}) = \mathbb {E}_{{\it q}({\bf z},{\it c}|{\bf x})} [\log (p({\bf x}|{\bf z}))] - D_{\mathrm{KL}}({\it q}({\bf z},{\it c}|{\bf x})||p({\bf z},{\it c})).
\end{equation*}\end{document}</tex-math></disp-formula></p>
        <p>By forcing the latent representation <bold>z</bold> towards a multivariate Gaussian mixture distribution, VaDE has the ability to simultaneously learn latent representations and cluster assignments of its input data. For more details on variational autoencoders and VaDE, we refer the reader to Jiang et al. [<xref rid="bib23" ref-type="bibr">23</xref>], Kingma and Welling [<xref rid="bib31" ref-type="bibr">32</xref>], and Doersch [<xref rid="bib32" ref-type="bibr">33</xref>].</p>
      </sec>
      <sec id="sec1-2-2">
        <title>VaDER</title>
        <p>VaDER is an autoencoder-based method for clustering multivariate time series with potentially many missing values. For simultaneously learning latent representations and cluster assignments of its input samples, VaDER uses the VaDE latent loss as described above and in Jiang et al. [<xref rid="bib23" ref-type="bibr">23</xref>].</p>
        <p>To model the auto- and cross-correlations in multivariate time-series data, we integrate peephole LSTM networks [<xref rid="bib24" ref-type="bibr">24</xref>,<xref rid="bib33" ref-type="bibr">34</xref>] into the autoencoder architecture (Fig. <xref rid="fig1" ref-type="fig">1</xref>).</p>
        <fig position="float" id="fig1">
          <label>Figure 1:</label>
          <caption>
            <p>VaDER architecture.</p>
          </caption>
          <graphic xlink:href="giz134fig1" position="float"/>
        </fig>
        <p>To deal with missing values, we directly integrate imputation into model training. As outlined in the Background, separating imputation from clustering can potentially introduce bias. To avoid this bias, we here propose an implicit imputation scheme, which is performed within VaDER training. Our approach to imputation bears some similarity to other approaches [<xref rid="bib34" ref-type="bibr">35</xref>,<xref rid="bib35" ref-type="bibr">36</xref>]. However, in contrast to Lipton et al. [<xref rid="bib34" ref-type="bibr">35</xref>], VaDER uses missingness indicators for implicit imputation as an integral part of neural network training. Additionally, in contrast to Manning et al. [<xref rid="bib35" ref-type="bibr">36</xref>], our method of imputation is also suited for MNAR data, which are often encountered in clinical datasets.</p>
        <p>We first define a weighted reconstruction loss on feature and sample level: imputed values are weighted to 0, non-imputed values are weighted to 1. To retain the balance with the latent loss, the resulting reconstruction loss is rescaled to match the original dimensions of the data. More formally, for a mean squared reconstruction loss, let <italic toggle="yes">L</italic> be the number of samples in our dataset, <bold>x</bold><sup><italic toggle="yes">l</italic></sup> a single input sample, and <inline-formula><tex-math id="TM0003" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$\hat{{\bf x}}^l$\end{document}</tex-math></inline-formula> its corresponding reconstructed output (<italic toggle="yes">l</italic> ∈ 1…<italic toggle="yes">L</italic>). <bold>x</bold><sup><italic toggle="yes">l</italic></sup> and <inline-formula><tex-math id="TM0004" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$\hat{{\bf x}}^l$\end{document}</tex-math></inline-formula> are matrices <inline-formula><tex-math id="TM0005" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$\in \mathbb {R}^{N\times M}$\end{document}</tex-math></inline-formula>, where <italic toggle="yes">N</italic> is the number of time points and <italic toggle="yes">M</italic> is the number of clinical outcome measures (e.g., cognitive assessments) for a particular patient. Then the unweighted mean reconstruction loss is
<disp-formula id="update410119_update299119_update299119_equ3"><label>(3)</label><tex-math id="TM0006" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
\begin{equation*}
\frac{1}{L} \sum\nolimits _{l=1}^{L} \sum\nolimits _{i=1}^{N} \sum\nolimits _{j=1}^{M} \left(x_{ij}^l - \hat{x}_{ij}^l\right)^2.
\end{equation*}\end{document}</tex-math></disp-formula>Now, let <inline-formula><tex-math id="TM0007" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$A := \lbrace x_{ij}^l|x_{ij}^l \textrm{is~missing}\rbrace$\end{document}</tex-math></inline-formula>, <bold>1</bold><sub><italic toggle="yes">A</italic></sub>(.) be the indicator function on set A, and |<italic toggle="yes">A</italic>| be the cardinality of <italic toggle="yes">A</italic>. Then, the weighted mean squared reconstruction loss is:
<disp-formula id="update410119_update299119_equ4"><label>(4)</label><tex-math id="TM0008" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
\begin{equation*}
\frac{N M}{|A|} \sum\nolimits _{l=1}^{L} \sum\nolimits _{i=1}^{N} \sum\nolimits _{j=1}^{M} {\bf 1}_A(x_{ij}^l) \left(x_{ij}^l - \hat{x}_{ij}^l\right)^2.
\end{equation*}\end{document}</tex-math></disp-formula></p>
        <p>In addition to the weighted reconstruction loss, we adopt an implicit imputation scheme, where imputed values are learned as an integral part of model training. More specifically, Let <bold>x</bold><sup><italic toggle="yes">l</italic></sup>, <italic toggle="yes">N</italic>, <italic toggle="yes">M</italic>, <inline-formula><tex-math id="TM0009" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$x_{ij}^l$\end{document}</tex-math></inline-formula>, <italic toggle="yes">A</italic>, and <bold>1</bold><sub><italic toggle="yes">A</italic></sub>(.) be defined as above. Also assume that all <inline-formula><tex-math id="TM0010" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$x_{ij}^l$\end{document}</tex-math></inline-formula> for which <inline-formula><tex-math id="TM0011" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
${\bf 1}_A(x_{ij}^l) = 1$\end{document}</tex-math></inline-formula> are initially imputed with arbitrary finite values. Then we add 1 additional layer before the input LSTM (Fig. <xref rid="fig1" ref-type="fig">1</xref>) as follows:
<disp-formula id="update309119_equ5"><label>(5)</label><tex-math id="TM0012" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
\begin{equation*}
\tilde{x}_{ij}^l = x_{ij}^l \times [1 - {\bf 1}_A(x_{ij}^l)] + b_{ij} \times {\bf 1}_A(x_{ij}^l).
\end{equation*}\end{document}</tex-math></disp-formula></p>
        <p>Here, <inline-formula><tex-math id="TM0013" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$x_{ij}^l$\end{document}</tex-math></inline-formula> is the actual observed (or missing) value of sample <italic toggle="yes">l</italic> at time points <italic toggle="yes">i</italic> and assessment <italic toggle="yes">j</italic>, and <inline-formula><tex-math id="TM0014" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$\tilde{x}_{ij}^l$\end{document}</tex-math></inline-formula> serves as input to the LSTM. In other words, if <inline-formula><tex-math id="TM0015" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$x_{ij}^l$\end{document}</tex-math></inline-formula> is missing, then it is replaced by <italic toggle="yes">b<sub>ij</sub></italic> in <inline-formula><tex-math id="TM0016" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$\tilde{{\bf x}}$\end{document}</tex-math></inline-formula>. Parameters <italic toggle="yes">b<sub>ij</sub></italic> are trained as an integral part of VaDER using stochastic gradient descent and can be considered (time, assessment)-specific expected values. Note that (i) the initial arbitrary imputation does not influence the eventual clustering and (ii) the implicitly imputed values are weighted to 0 in the reconstruction loss.</p>
      </sec>
      <sec id="sec1-2-3">
        <title>VaDER achieves high accuracy on simulated data</title>
        <p>As a first step in technically validating VaDER, we simulated data with a known ground truth clustering and assessed how well VaDER was able to recover these clusters. A natural framework to this end is the vector autoregressive (VAR) model because (i) it can express serial correlation between time points, (ii) it can express cross-correlation between variables, and (iii) given a fully parameterized VAR process, one can simulate random trajectories from that VAR process.</p>
        <p>More specifically, to generate clusters of multivariate time series, we simulated from VAR process mixtures, for different values of a clusterability parameter λ. The clusterability parameter λ influences how easily separable the simulated clusters are (see Section Simulation experiments). Sample data are provided in the <xref rid="sup7" ref-type="supplementary-material">Supplementary Figure S1</xref>. We used the cluster purity measure [<xref rid="bib36" ref-type="bibr">37</xref>] to record how well the true clustering could be recovered (for more details, see Methods).</p>
        <p>VaDER was able to highly accurately recover the simulated clusters, achieving a cluster purity of &gt;0.9 for λ ≈ 0.08, and converging to 1.0 for larger λ (Fig. <xref rid="fig2" ref-type="fig">2a</xref>). Moreover, even without extensive hyperparameter optimization, VaDER performed substantially better than hierarchical clustering using various distance measures, some of which were specifically designed for multivariate time series (multidimensional dynamic time warping [MD-DTW] [<xref rid="bib38" ref-type="bibr">38</xref>] and Global Alignment Kernels [GAK] [<xref rid="bib39" ref-type="bibr">39</xref>]) or short univariate time series (the STS distance [<xref rid="bib37" ref-type="bibr">40</xref>]). Only for λ &lt; 0.04 was VaDER outperformed by MD-DTW. This may be attributed to the fairly limited number of samples used for the simulation (<italic toggle="yes">n</italic> = 2,000), and omitting extensive optimization of VaDER’s hyperparameters.</p>
        <fig position="float" id="fig2">
          <label>Figure 2:</label>
          <caption>
            <p>VaDER performance on simulated data, with varying degrees of clusterability and missingness. (a) Cluster purity [<xref rid="bib36" ref-type="bibr">37</xref>] for clustering of simulated data as a function of the clusterability parameter λ, with higher λ implying a higher degree of similarity between profiles in the same cluster. Results are shown for VaDER as well as hierarchical clustering using 5 different distance measures, (i) Euclidean distance, (ii) Pearson correlation, (iii) the STS distance [<xref rid="bib37" ref-type="bibr">40</xref>], (IV) multi-dimensional dynamic time warping (MD-DTW), [<xref rid="bib38" ref-type="bibr">38</xref>] and (5) Global Alignment Kernels (GAK) [<xref rid="bib39" ref-type="bibr">39</xref>]. (b) Cluster purity as a function of the fraction θ of values missing completely at random (MCAR), for various levels of the clusterability parameter λ, for both VaDER with implicit imputation and VaDER with pre-imputation. Confidence intervals were determined by repeating the clustering 100 times using newly generated random data and missingness patterns. (c) Cluster purity as a function of the fraction θ of values missing not at random (MNAR) (see Methods for details), for various levels of the clusterability parameter λ, for both VaDER with implicit imputation and VaDER with pre-imputation. Confidence intervals were determined by repeating the clustering 100 times using newly generated random data and missingness patterns.</p>
          </caption>
          <graphic xlink:href="giz134fig2" position="float"/>
        </fig>
        <p>We used the same VAR framework to assess how varying degrees of missing values affect the performance of VaDER. Both MCAR and MNAR were simulated as described in the Methods. In the MCAR simulation, missing values were uniformly distributed across time and clinical outcome measures. In the MNAR simulation, the expected degree of missing values sigmoidally depended on time (see Methods). For varying clusterability levels λ, it can be seen that VaDER’s implicit imputation scheme is overall more robust against missing values than using VaDER with pre-imputation of missing values (Figs 2b and c).</p>
      </sec>
      <sec id="sec1-2-4">
        <title>VaDER achieves high accuracy on benchmark classification datasets</title>
        <p>As an additional validation step towards applying VaDER to real-world clinical data, we collected a number of real-world benchmark datasets for multivariate time-series classification (Table <xref rid="tbl1" ref-type="table">1</xref>). The datasets were normalized and processed to equal and/or shorter length as described in the Methods.</p>
        <table-wrap position="float" id="tbl1">
          <label>Table 1.</label>
          <caption>
            <p>Multivariate time-series classification datasets used in this study</p>
          </caption>
          <table frame="hsides" rules="groups">
            <thead>
              <tr>
                <th align="left" rowspan="1" colspan="1">Name</th>
                <th align="center" rowspan="1" colspan="1">
                  <italic toggle="yes">k</italic>
                </th>
                <th align="center" rowspan="1" colspan="1">
                  <italic toggle="yes">n</italic>
                </th>
                <th align="center" rowspan="1" colspan="1">
                  <italic toggle="yes">p</italic>
                </th>
                <th align="center" rowspan="1" colspan="1">
                  <italic toggle="yes">n<sub>t</sub></italic>
                </th>
                <th align="center" rowspan="1" colspan="1">
                  <inline-formula>
                    <tex-math id="TM0017" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$n^\prime _t$\end{document}</tex-math>
                  </inline-formula>
                </th>
                <th align="center" rowspan="1" colspan="1">Source</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td rowspan="1" colspan="1">ArabicDigits</td>
                <td rowspan="1" colspan="1">10</td>
                <td rowspan="1" colspan="1">8,800</td>
                <td rowspan="1" colspan="1">13</td>
                <td rowspan="1" colspan="1">4 - 93</td>
                <td rowspan="1" colspan="1">24</td>
                <td rowspan="1" colspan="1">UCI [<xref rid="bib40" ref-type="bibr">41</xref>]</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">JapaneseVowels</td>
                <td rowspan="1" colspan="1">9</td>
                <td rowspan="1" colspan="1">640</td>
                <td rowspan="1" colspan="1">12</td>
                <td rowspan="1" colspan="1">7 - 29</td>
                <td rowspan="1" colspan="1">15</td>
                <td rowspan="1" colspan="1">UEA/UCR [<xref rid="bib41" ref-type="bibr">42</xref>]</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">CharacterTrajectories</td>
                <td rowspan="1" colspan="1">20</td>
                <td rowspan="1" colspan="1">2,858</td>
                <td rowspan="1" colspan="1">3</td>
                <td rowspan="1" colspan="1">109 - 205</td>
                <td rowspan="1" colspan="1">23</td>
                <td rowspan="1" colspan="1">UCI [<xref rid="bib40" ref-type="bibr">41</xref>]</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">UWave</td>
                <td rowspan="1" colspan="1">8</td>
                <td rowspan="1" colspan="1">4,478</td>
                <td rowspan="1" colspan="1">3</td>
                <td rowspan="1" colspan="1">315</td>
                <td rowspan="1" colspan="1">25</td>
                <td rowspan="1" colspan="1">UCI [<xref rid="bib40" ref-type="bibr">41</xref>]</td>
              </tr>
            </tbody>
          </table>
          <table-wrap-foot>
            <fn id="tblfn5">
              <p><italic toggle="yes">k</italic>: number of classes; <italic toggle="yes">n</italic>: number of samples; <italic toggle="yes">p</italic>: number of variables; <italic toggle="yes">n<sub>t</sub></italic>: number of time points; <inline-formula><tex-math id="TM0018" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$n^\prime _t$\end{document}</tex-math></inline-formula>: number of samples after processing to equal and/or shorter length; UCI: University of California Irvine machine learning repository; UEA/UCR: University of East Anglia/University of California, Riverside time-series classification archive.</p>
            </fn>
          </table-wrap-foot>
        </table-wrap>
        <p>Comparing the ability of VaDER in recovering these a priori known classes to the other methods mentioned above reveals that VaDER consistently achieves better results (Fig. <xref rid="fig3" ref-type="fig">3a</xref>). Moreover, VADER’s approach of integrating imputation with model training again outperforms pre-imputation of missing values (Figs 3b and c).</p>
        <fig position="float" id="fig3">
          <label>Figure 3:</label>
          <caption>
            <p>VaDER performance on benchmark data, for varying degrees of missingness. (a) Cluster purity [<xref rid="bib36" ref-type="bibr">37</xref>] for clustering of benchmark data. Results are shown for VaDER as well as hierarchical clustering using 5 different distance measures, (i) Euclidean distance, (ii) Pearson correlation, (iii) the STS distance [<xref rid="bib37" ref-type="bibr">40</xref>], (iv) multi-dimensional dynamic time warping (MD-DTW) [<xref rid="bib38" ref-type="bibr">38</xref>], and (v) Global Alignment Kernels (GAK) [<xref rid="bib39" ref-type="bibr">39</xref>]. For each dataset, the best performance across methods is marked by a horizontal dotted line. Confidence intervals were determined by bootstrapping the clustering 10<sup>3</sup> times. (b) Cluster purity as a function of the fraction θ of values missing completely at random (MCAR), for both VaDER with implicit imputation and VaDER with pre-imputation. Confidence intervals were determined by repeating the clustering 5 times using newly generated random missingness patterns. (c) Cluster purity as a function of the fraction θ of values missing not at random (MNAR), for both VaDER with implicit imputation and VaDER with pre-imputation. Confidence intervals were determined by repeating the clustering 5 times using newly generated random missingness patterns.</p>
          </caption>
          <graphic xlink:href="giz134fig3" position="float"/>
        </fig>
      </sec>
      <sec id="sec1-2-5">
        <title>Application 1: VaDER identifies clinically diverse AD patient subgroups</title>
        <p>After the technical validation using simulated and benchmark data, we applied VaDER to clinical data for identifying meaningful patient subgroups. From ADNI [<xref rid="bib25" ref-type="bibr">25</xref>], we collected data from 689 patients who at some point received a diagnosis of dementia during the course of this study. Four different cognitive assessment scores were available at 8 different visits: ADAS13, CDRSB, MMSE, and FAQ. We pre-processed the data as described in the ADNI data preparation section. Overall, the fraction of missing values was ∼43%. We used VaDER to cluster patients by disease progression as measured using these cognitive assessments.</p>
        <p>Hyperparameter optimization was performed by random grid search as described in the Methods. For each number of clusters <italic toggle="yes">k</italic> ∈ {2…15}, the prediction strength [<xref rid="bib42" ref-type="bibr">43</xref>] of the corresponding optimal model was compared to a null distribution (see Section Hyperparameter optimization and choice of number of clusters), which is shown in <xref rid="sup7" ref-type="supplementary-material">Supplementary Figure S2</xref>.</p>
        <p>For most practical applications, determining an unambiguously correct number of clusters <italic toggle="yes">k</italic> is not possible, and a wide range of rules of thumb exist (see, e.g., [<xref rid="bib42" ref-type="bibr">43–47</xref>]). For our subsequent analyses, we chose <italic toggle="yes">k</italic> = 3. This demonstrated relatively high prediction strength, significantly different from the null distribution, while still allowing VaDER to demonstrate its ability to uncover potentially interesting statistical interactions between trajectories of different cognitive assessments. A statistical interaction between different cognitive assessments could, e.g., manifest in the ability to distinguish patient subgroups based on 1 cognitive assessment, while this is not possible on another assessment. Another example would be a permuted ordering of clusters with respect to different assessment scores.</p>
        <p>For ADNI data the resulting cluster mean trajectories are shown in Fig. <xref rid="fig4" ref-type="fig">4</xref> and demonstrate that (i) VaDER effectively clusters the data into patient subgroups showing divergent disease progression and (ii) VaDER is able to find interactions between the different cognitive assessments, which would be principally difficult to distill from univariate analyses of the assessments. For example, the patients in Cluster 1 are the patients whose disease is the most severely progressing when assessed using ADAS13, CDRSB, and MMSE. However, the FAQ assessment (instrumental activities of daily living) does not distinguish between these patients with severely progressing disease and the patients with more moderately progressing disease in Cluster 1.</p>
        <fig position="float" id="fig4">
          <label>Figure 4:</label>
          <caption>
            <p>Normalized cluster mean trajectories relative to baseline (<italic toggle="yes">x</italic>-axis in months), as identified by VaDER from the ADNI cognitive assessment data.</p>
          </caption>
          <graphic xlink:href="giz134fig4" position="float"/>
        </fig>
        <p>In addition to cognitive assessment measurements, ADNI presents a wealth of data on brain volume and various AD markers that we did not use for clustering. In these data, we identified numerous statistically significant associations with our patient subgroups. For example, the clusters strongly associated with time-to-dementia diagnosis relative to baseline, with Cluster 2 showing generally the shortest time and Cluster 0 the longest. The patients with relatively mildly progressing disease in cluster 0 also demonstrated on average a larger whole-brain volume at baseline, which moreover declined less steeply over time, compared to more patients with severely progressing disease. Especially the middle temporal gyri and fusiform gyri were larger (and shrinking more slowly over time), whereas the ventricles were smaller (and expanding more slowly over time). Indeed, atrophy of the middle temporal gyri and fusiform gyri, as well as ventricular enlargement, have been associated with AD progression [<xref rid="bib47" ref-type="bibr">48</xref>,<xref rid="bib48" ref-type="bibr">49</xref>]. As another example, the patients with more severely progressing disease (Cluster 1 and especially Cluster 2) demonstrated lower cerebral glucose uptake and lower cerebrospinal Abeta42 levels, again confirming the literature [<xref rid="bib49" ref-type="bibr">50</xref>,<xref rid="bib50" ref-type="bibr">51</xref>] (see Methods and <xref rid="sup7" ref-type="supplementary-material">Supplementary Figures S3-8</xref>). These observations demonstrate that the clinical differences between our patient subgroups reflect known AD aspects.</p>
      </sec>
      <sec id="sec1-2-6">
        <title>Application 2: VaDER identifies clinically diverse PD patient subgroups</title>
        <p>We additionally applied VaDER to clinical data from the Parkinson’s Progression Markers Initiative (PPMI) [<xref rid="bib26" ref-type="bibr">26</xref>]. From PPMI, we collected data from 362 <italic toggle="yes">de novo</italic> PD patients who had received a diagnosis within a period of 2 years before study onset and had initially not been treated. Nine variables on several motor and non-motor symptoms (UPDRS total, UPDRS1–3, tremor dominance [TD], postural instability and gait disturbance [PIGD], RBD, ESS, SCOPA-AUT) measured at either 5 or 10 time points were available. The data were pre-processed as described in the PPMI data preparation section. Overall, the fraction of missingness values was ∼17% (or ∼31%, when including time points entirely missing for some assessments). We again used VaDER to cluster patients according to disease progression as measured by these assessments.</p>
        <p>Hyperparameter optimization and selection of the number of clusters was performed in the same way as for ADNI (see <xref rid="sup7" ref-type="supplementary-material">Supplementary Figure S9</xref>), and we decided on <italic toggle="yes">k</italic> = 3 patient subgroups accordingly. The resulting cluster mean trajectories are shown in Fig. <xref rid="fig5" ref-type="fig">5</xref>. These again illustrate that (i) VaDER effectively clusters the data into clinically divergent patient subgroups, and (ii) VaDER is able to find interactions between the assessments that would principally be difficult to find based on univariate analyses alone. For example, Cluster 0 represents patients with a moderate progression in terms of mental impairment, behavior, and mood (UPDRS1) and autonomic dysfunction (SCOPA). However, these patients remain relatively stable, or even improve, on many other assessments, such as TD, the self-reported ability to perform activities of daily life (UPDRS2), and motor symptoms evaluation (UPDRS3).</p>
        <fig position="float" id="fig5">
          <label>Figure 5:</label>
          <caption>
            <p>Normalized cluster mean trajectories relative to baseline (<italic toggle="yes">x</italic>-axis in months), as identified by VaDER from the PPMI motor/non-motor score data.</p>
          </caption>
          <graphic xlink:href="giz134fig5" position="float"/>
        </fig>
        <p>Similar to ADNI, PPMI presents a wealth of additional data on brain volume and various PD markers that were not used for clustering. Aligning these data with our PD patient subgroups, we found numerous statistically significant associations that confirmed existing literature, many related to quality of life and physiological changes to the brain. For example, men were over-represented in cluster 1 and showed the most severe disease progression, confirming the literature on sex differences in PD (e.g., [<xref rid="bib51" ref-type="bibr">52</xref>]). Moreover, these patients with severely progressing disease showed an expected steeply declining ability to perform activities of daily living (modified Schwab and England score [<xref rid="bib52" ref-type="bibr">53</xref>]), as well as rapidly developing symptoms of depression (geriatric depression scale [<xref rid="bib53" ref-type="bibr">54</xref>]), common in patients with PD [<xref rid="bib54" ref-type="bibr">55</xref>]. Additionally, these patients demonstrated physiological differences in the brain when compared to patients with more mildly progressing disease. Examples are the caudate nucleus and putamen brain regions, which were smaller at baseline and during follow-up examinations in the patients with more severely progressing disease in Cluster 1 and, from the literature, are known to be subject to atrophy in PD [<xref rid="bib55" ref-type="bibr">56</xref>] (see Methods and <xref rid="sup7" ref-type="supplementary-material">Supplementary Figures S10-15</xref>). These observations demonstrate that the clinical differences between our patient subgroups reflect known aspects of PD disease progression.</p>
      </sec>
    </sec>
    <sec sec-type="conclusions|discussion" id="sec1-3">
      <title>Discussion and conclusions</title>
      <p>Identifying subgroups of patients with similar progression patterns can help to better elucidate the heterogeneity of complex diseases. Together with predictive machine learning methods, this might improve decision making on the right time and type of treatment for an individual patient, as well as the design of clinical studies. However, one of the main challenges is the multifaceted nature of progression in many areas of disease.</p>
      <p>In this article, we proposed VaDER, a method for clustering multivariate, potentially short, time series with many missing values, a setting that seems generally not well addressed in the literature so far but is nonetheless often encountered in clinical study data.</p>
      <p>We validated VaDER by showing the very high accuracy on clustering simulated and real-world benchmark data with a known ground truth. We then applied VaDER to data from (i) ADNI and (ii) PPMI, resulting in subgroups characterized by clinically highly divergent disease progression profiles. A comparison with other data from ADNI and PPMI, such as brain imaging and motor and cognitive assessment data, furthermore supported the observed patient subgroups.</p>
      <p>VaDER has 2 main distinctive features. One is that VaDER deals directly with missing values. For clinical research this is crucial because clinical datasets often show a very high degree of missing values [<xref rid="bib56" ref-type="bibr">57</xref>,<xref rid="bib57" ref-type="bibr">58</xref>]. The other main distinctive feature is that, as opposed to existing methods [<xref rid="bib10" ref-type="bibr">10–14</xref>], VaDER is specifically designed to deal with multivariate and relatively short time series that are typical for (observational) clinical studies. However, it is worthwhile to mention that the application of VaDER is not per se limited to longitudinal clinical study data or to time series of short length. Future applications (potentially requiring some adaptations) could, e.g., include data originating from electronic health records, multiple wearable sensors, video recordings, or time-series gene (co-)expression. Moreover, VaDER could be used as a generative model: given a trained model, it is possible to generate “virtual” patient trajectories.</p>
      <p>Altogether, we believe that our results show that VaDER has the potential to substantially enhance future patient stratification efforts and multivariate time series clustering in general.</p>
    </sec>
  </sec>
  <sec sec-type="methods" id="sec2">
    <title>Methods</title>
    <sec id="sec2-1">
      <title>Data preparation</title>
      <sec id="sec2-1-1">
        <title>ADNI data preparation</title>
        <p>Data used in the preparation of this article were obtained from the ADNI database (<ext-link xlink:href="http://adni.loni.usc.edu" ext-link-type="uri">adni.loni.usc.edu</ext-link>). The ADNI was launched in 2003 as a public-private partnership, led by Principal Investigator Michael W. Weiner, MD. The primary goal of ADNI has been to test whether serial magnetic resonance imaging (MRI), positron emission tomography, other biological markers, and clinical and neuropsychological assessment can be combined to measure the progression of mild cognitive impairment and early AD. For up-to-date information, see <ext-link xlink:href="http://www.adni-info.org" ext-link-type="uri">www.adni-info.org</ext-link>.</p>
        <p>The ADNIMERGE R-package [<xref rid="bib58" ref-type="bibr">59</xref>] contains mainly 2 categories of data, (i) longitudinal and (ii) non-longitudinal. These data represent 1,737 participants that include healthy controls and patients with a diagnosis of AD. The non-longitudinal features such as demographic characteristics and apolipoprotein E4 status were measured only once, at baseline. The longitudinal features (i.e., neuroimaging features, cerebrospinal fluid biomarkers, cognitive tests, and everyday cognition) were recorded over a span of 5 years.</p>
        <sec id="sec2-1-1-1">
          <title>Clinical data</title>
          <p>In the present study, we have focused on those participants who received a diagnosis of AD at baseline or during 1 of the follow-up visits. After this filtering step, we had a total of 689 patients. For these 689 patients, 4 cognitive assessments were selected for clustering:
<list list-type="bullet"><list-item><p>ADAS-13: Alzheimer's Disease Assessment Scale</p></list-item><list-item><p>CDRSB: Clinical Dementia Rating Sum of Box Score</p></list-item><list-item><p>FAQ: Functional Activities Questionnaire</p></list-item><list-item><p>MMSE: Mini–Mental State Examination</p></list-item></list></p>
          <p>The above assessments were taken at baseline and at 6, 12, 18, 24, 36, 48, and 60 months after baseline. For each of the 4 cognitive assessments, all time points were normalized relative to baseline by (i) subtracting the baseline mean across the 689 patients and (ii) dividing by the baseline standard deviation across the 689 patients.</p>
        </sec>
        <sec id="sec2-1-1-2">
          <title>Imaging data</title>
          <p>All available MRI scans (T1-weighted scans) from the ADNI database were quantified by an open-source, automated segmentation pipeline at the Erasmus University Medical Center, The Netherlands. The number of slices of the T1-weighted scans varied from 160 to 196 and the in-plane resolution was 256 × 256 on average, yielding an overall voxel size of 1.2 × 1.0 × 1.0 mm. From the 1,715 baseline ADNI scans, the volumes of 34 bilateral cortical brain regions, 68 structures in total, were calculated using a model- and surface-based automated image segmentation procedure, incorporated in the FreeSurfer Package (v.6.0 [<xref rid="bib68_215_1572542864951" ref-type="bibr">60</xref>]). Segmentation in Freesurfer was performed by rigid-body registration and nonlinear normalization of images to a probabilistic brain atlas. In the segmentation process, each voxel of the MRI volumes was labeled automatically as a corresponding brain region based on 2 different cortex parcellation guides [<xref rid="bib59" ref-type="bibr">61</xref>,<xref rid="bib60" ref-type="bibr">62</xref>], subdividing the brain into 68 and 191 regions, respectively.</p>
        </sec>
      </sec>
      <sec id="sec2-1-2">
        <title>PPMI data preparation</title>
        <p>Patients were selected if their PD diagnosis was &lt;2 years old at baseline and if follow-up data were available for ≥48 months (5–10 time points), resulting in a total of 362 patients. For these 362 patients, a set of 9 motor and non-motor symptoms were selected for clustering:
<list list-type="bullet"><list-item><p>TD: tremor dominance</p></list-item><list-item><p>PIGD: postural instability and gait disturbance</p></list-item><list-item><p>UPDRS1: Unified Parkinson Disease Rating Scale, part 1: mentation, behavior, and mood</p></list-item><list-item><p>UPDRS2: Unified Parkinson Disease Rating Scale, part 2: activities of daily living</p></list-item><list-item><p>UPDRS3: Unified Parkinson Disease Rating Scale, part 3: motor examination</p></list-item><list-item><p>UPDRS: Unified Parkinson Disease Rating Scale (UPDRS1 + UPDRS2 + UPDRS3)</p></list-item><list-item><p>RBD: REM sleep behavior disorder</p></list-item><list-item><p>ESS: Epworth Sleepiness Scale</p></list-item><list-item><p>SCOPA-AUT: Scales for Outcomes in Parkinson Disease: Assessment of Autonomic Dysfunction</p></list-item></list></p>
        <p>All scores were normalized relative to baseline by (i) subtracting the baseline mean across all patients and (ii) dividing by the baseline standard deviation across all patients.</p>
        <p>For some assessments, fewer time points were available. These were treated as missing values.</p>
      </sec>
      <sec id="sec2-1-3">
        <title>Benchmark datasets for multivariate time-series classification</title>
        <p>Because no benchmark datasets exist for multivariate time series clustering, we collected a number of benchmark datasets for multivariate time-series classification [<xref rid="bib40" ref-type="bibr">41</xref>,<xref rid="bib41" ref-type="bibr">42</xref>]. Because currently, VaDER still only works with equal-length time series (see also Section Discussion and conclusions), we pre-processed all samples to equal-length time series by linear interpolation between start and end point. Following [<xref rid="bib61" ref-type="bibr">63</xref>, <xref rid="bib62" ref-type="bibr">64</xref>], we chose constant lengths of <inline-formula><tex-math id="TM0019" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$\left\lceil {T_{\mathrm{max}}/ \left\lceil {\frac{T_{\mathrm{max}}}{25}}\right\rceil }\right\rceil$\end{document}</tex-math></inline-formula>, where <italic toggle="yes">T</italic><sub>max</sub> is the maximum length of the lengths of the samples in a given dataset.</p>
        <p>Moreover, all resulting time series were standardized to zero mean and unit variance.</p>
      </sec>
    </sec>
    <sec id="sec2-2">
      <title>VaDER</title>
      <p>The VaDER model is extensively described in the Results section. This section describes how VaDER was trained.</p>
      <sec id="sec2-2-1">
        <title>Pre-training</title>
        <p>Similar to Jiang et al. [<xref rid="bib23" ref-type="bibr">23</xref>], we pre-train VaDER by disregarding the latent loss during the first epochs, essentially fitting a non-variational LSTM autoencoder to the data. We then fit a Gaussian mixture distribution in the latent space of this autoencoder and use its parameters to initialize the final variational training of VaDER.</p>
      </sec>
      <sec id="sec2-2-2">
        <title>Hyperparameter optimization and choice of number of clusters</title>
        <p>We used prediction strength [<xref rid="bib42" ref-type="bibr">43</xref>] to select suitable values for VaDER’s hyperparameters. These comprise the following:
<list list-type="bullet"><list-item><p>number of layers (for both ADNI and PPMI: {1, 2})</p></list-item><list-item><p>number of nodes per hidden layer (for ADNI: {2<sup>0</sup>, 2<sup>1</sup>, 2<sup>2</sup>, 2<sup>3</sup>, 2<sup>4</sup>, 2<sup>5</sup>, 2<sup>6</sup>}; for PPMI: {2<sup>0</sup>, 2<sup>1</sup>, 2<sup>2</sup>, 2<sup>3</sup>, 2<sup>4</sup>, 2<sup>5</sup>, 2<sup>6</sup>, 2<sup>7</sup>})</p></list-item><list-item><p>learning rate (for both ADNI and PPMI: {10<sup>−4</sup>, 10<sup>−3</sup>, 10<sup>−2</sup>, 10<sup>−1</sup>})</p></list-item><list-item><p>mini-batch size (for both ADNI and PPMI: {2<sup>4</sup>, 2<sup>5</sup>, 2<sup>6</sup>, 2<sup>7</sup>})</p></list-item></list></p>
        <p>Hyperparameter optimization was performed via a random grid search (i.e., by randomly sampling a predefined hyperparameter grid) with repeated cross-validation (<italic toggle="yes">n</italic> = 20), using the reconstruction loss as objective. This was done during the pre-training phase of VaDER.</p>
        <p>After hyperparameter optimization we trained VaDER models for different numbers of clusters <italic toggle="yes">k</italic> ∈ {2…15}. For each <italic toggle="yes">k</italic>, prediction strength was computed by 2-fold cross-validation [<xref rid="bib42" ref-type="bibr">43</xref>]: for a given training and test dataset:
<list list-type="order"><list-item><p>Train VaDER on the training data (the training data model).</p></list-item><list-item><p>Assign clusters to the test data using the training data model.</p></list-item><list-item><p>Train VaDER on the test data (the test data model).</p></list-item><list-item><p>Assign clusters to the test data using the test data model.</p></list-item><list-item><p>Compare the resulting 2 clusterings: for each cluster of the test data model, compute the fraction of pairs of samples in that cluster that are also assigned to the same cluster by the training data model. Prediction strength is defined as the minimum proportion across all clusters of the test data model [<xref rid="bib42" ref-type="bibr">43</xref>].</p></list-item></list></p>
        <p>Prediction strength was then compared to an empirical null distribution of that measure. The null distribution of the prediction strength was computed by randomly permuting the predicted cluster labels 10<sup>3</sup> times, then recomputing the prediction strength, and eventually taking the average of the 10<sup>3</sup> prediction strength values. Doing this for all 20 repeats resulted in 20 values for the eventual null distribution, which were then compared to 20 actual prediction strength values (similarly, 1 for each repeat) by a paired Wilcoxon rank-sum test.</p>
      </sec>
    </sec>
    <sec id="sec2-3">
      <title>Simulation experiments</title>
      <sec id="sec2-3-1">
        <title>Overview of data-generating process</title>
        <p>To better understand the performance of VaDER we conducted an extensive simulation study: we simulated multivariate (short) time series via VAR processes [<xref rid="bib63" ref-type="bibr">65</xref>] because (i) they can model the auto-correlation between time points, (ii) they can model the cross-correlation between variables, and (iii) given a VAR, one can generate random trajectories from that VAR.</p>
        <p>We used mixtures of VAR processes to simulate multivariate time-series data of the same dimensions as the ADNI data: 4 variables measured over 8 time points. Given a clusterability factor λ, we generated trajectories as follows:
<list list-type="order"><list-item><p>Sample coefficient matrices for 3 VAR(8) processes, by randomly sampling the individual entries of each 4 × 4 matrix from the uniform distribution <inline-formula><tex-math id="TM0020" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$\mathcal {U}(-0.1, 0.1)$\end{document}</tex-math></inline-formula>. Multiply each of the matrix entries by λ.</p></list-item><list-item><p>Randomly sample 3 additional 4 × 4 matrices from <inline-formula><tex-math id="TM0021" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$\mathcal {U}(-0.1, 0.1)$\end{document}</tex-math></inline-formula> and multiply each by its own transpose. Let each of the results correspond to the variance-covariance matrix of 1 of the 3 VAR(8) processes.</p></list-item><list-item><p>Repeat 10<sup>3</sup> times:
<list list-type="order"><list-item><p>Randomly select 1 of the 3 VAR(8) processes (with equal probability).</p></list-item><list-item><p>Generate a random trajectory from the selected VAR(8) process.</p></list-item></list></p></list-item></list></p>
        <p>The above generates 1 set of random data. Given a value of λ, the entire sampling process was repeated 100 times, and each of the 100 datasets was clustered using both VaDER and hierarchical clustering.</p>
        <p>For computational reasons, hyper-parameters for VaDER were fixed and not further optimized during our simulation (10<sup>2</sup> epochs of both pre-training and training, learning rate: 10<sup>−4</sup>, 2 hidden layers: [36, 4], batch size: 64).</p>
      </sec>
      <sec id="sec2-3-2">
        <title>Comparison against hierarchical clustering</title>
        <p>We compared VaDER against a conventional hierarchical clustering (complete linkage), in which we flatten the <italic toggle="yes">N</italic> × <italic toggle="yes">M</italic> data matrices of each patient into vectors. We considered 3 distance measures for these vectors:
<list list-type="bullet"><list-item><p>Pearson correlation</p></list-item><list-item><p>Euclidean distance</p></list-item><list-item><p>STS distance [<xref rid="bib37" ref-type="bibr">40</xref>], a distance measure specifically developed for univariate short time series. The STS distance relies on the difference between adjacent time points. Here we first computed the STS distance for each of the different clinical outcome measures and then summed these up to arrive at an aggregated STS distance across the <italic toggle="yes">M</italic> clinical measures.</p></list-item></list></p>
        <p>Additionally, we compared VaDER against hierarchical clustering using 2 distance measures specifically designed for multivariate time series:
<list list-type="bullet"><list-item><p>MD-DTW [<xref rid="bib38" ref-type="bibr">38</xref>]</p></list-item><list-item><p>Fast GAK [<xref rid="bib39" ref-type="bibr">39</xref>]</p></list-item></list></p>
        <p>Given that VaDER is non-deterministic, we ran 100 replicates for each (simulated/benchmark) dataset and determined the consensus clustering by hierarchically clustering a consensus matrix listing, for each pair of samples, how often these 2 samples were clustered together across the 100 replicates.</p>
      </sec>
      <sec id="sec2-3-3">
        <title>Simulating missing data</title>
        <p>To test the ability of VaDER to deal with missing data we performed a separate set of simulations: Let <italic toggle="yes">L</italic> be the number of patients in our dataset and <inline-formula><tex-math id="TM0022" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
${\bf x}^l \in \mathbb {R}^{N \times M}$\end{document}</tex-math></inline-formula> a single patient trajectory (<italic toggle="yes">l</italic> ∈ 1…<italic toggle="yes">L</italic>), where <italic toggle="yes">N</italic> is the number of time points and <italic toggle="yes">M</italic> is the number of measured features. MCAR were simulated by an individual entry <inline-formula><tex-math id="TM0023" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
${\bf x}_{ij}^l$\end{document}</tex-math></inline-formula> to missing with probability θ.</p>
        <p>MNAR was simulated by letting the probability of a missing value for entry <inline-formula><tex-math id="TM0024" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
${\bf x}_{ij}^l$\end{document}</tex-math></inline-formula> depend on time. More specifically, each individual entry <inline-formula><tex-math id="TM0025" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
${\bf x}_{ij}^l$\end{document}</tex-math></inline-formula> was set to missing with probability <inline-formula><tex-math id="TM0026" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$1/(1 + e^{i_0 - i / k})$\end{document}</tex-math></inline-formula>, where <inline-formula><tex-math id="TM0027" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$i_0 = (1 + N)/2$\end{document}</tex-math></inline-formula> and <italic toggle="yes">k</italic> was varied to result in different overall missingness fractions θ.</p>
        <p>To compare VADER’s implicit imputation with pre-imputation, missing values generated using the above approach were additionally imputed using mean substitution: each missing value was substituted with the average conditioned on the relevant time point and variable.</p>
        <p>Given that VaDER is non-deterministic, we ran 20 replicates for each (simulated/benchmark) dataset and determined the consensus clustering by hierarchically clustering a consensus matrix listing, for each pair of samples, how often these 2 samples were clustered together across the 20 replicates. Confidence intervals were determined by repeating the aforementioned procedure 100 times (simulation experiments) or 5 times (benchmark experiments) with newly generated missingness patterns (simulation/benchmark experiments) and/or data (simulation experiments).</p>
      </sec>
      <sec id="sec2-3-4">
        <title>Estimating clustering performance</title>
        <p>For the simulation and benchmark datasets, the number of clusters is a priori known. Hence, an intuitive measure of comparing the performance between the different algorithms is cluster purity [<xref rid="bib36" ref-type="bibr">37</xref>]. Cluster purity can be interpreted as the fraction of correctly clustered samples and is calculated as follows:
<list list-type="order"><list-item><p>For each cluster, count the number of samples from the majority class in that cluster.</p></list-item><list-item><p>Sum the above counts.</p></list-item><list-item><p>Divide by the total number of samples.</p></list-item></list></p>
        <p>For the ADNI and PPMI data, the number of clusters is not a priori known. Hence, performance was recorded using the adjusted Rand index [<xref rid="bib64" ref-type="bibr">66</xref>, <xref rid="bib65" ref-type="bibr">67</xref>] for different values of λ in the interval [0.001, 0.25]. For λ ⪆ 0.25, generating coefficient matrices that lead to stable VARs becomes very difficult.</p>
      </sec>
    </sec>
    <sec id="sec2-4">
      <title>Post hoc analysis of patient clusters</title>
      <p>We collected a wide range of additional variables from ADNI and PPMI and assessed the association of the identified patient subgroups with a given variable by multinomial logistic regression. For any baseline variable <italic toggle="yes">x</italic>, we first fitted the following full model:
<disp-formula id="update319119_equ6"><label>(6)</label><tex-math id="TM0028" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
\begin{equation*}
\textrm{subgroup} \sim x + \textrm{confounders} .
\end{equation*}\end{document}</tex-math></disp-formula>Each of these full models was then compared to a null model:
<disp-formula id="equ7"><label>(7)</label><tex-math id="TM0029" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
\begin{equation*}
\textrm{subgroup} \sim \textrm{confounders}
\end{equation*}\end{document}</tex-math></disp-formula>by means of a likelihood ratio test.</p>
      <p>For any longitudinal variable <italic toggle="yes">x</italic> measured at time points <italic toggle="yes">t</italic>, we first fitted the following multinomial logistic regression model:
<disp-formula id="update319119_equ8"><label>(8)</label><tex-math id="TM0030" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
\begin{equation*}
\textrm{subgroup} \sim x + t + x \ast t + \textrm{confounders} .
\end{equation*}\end{document}</tex-math></disp-formula>We tested this model against the null model:
<disp-formula id="equ9"><label>(9)</label><tex-math id="TM0031" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
\begin{equation*}
\textrm{subgroup} \sim \textrm{confounders}
\end{equation*}\end{document}</tex-math></disp-formula>by performing a likelihood ratio test and applying a false discovery rate correction for multiple testing. If the above test was found to be significant (<italic toggle="yes">q</italic> &lt; 0.05), we tested the effects of the individual terms <italic toggle="yes">x</italic> *<italic toggle="yes">t</italic>, <italic toggle="yes">x</italic>, and <italic toggle="yes">t</italic> against the same null model above.</p>
      <p>Confounders considered were age, education, and sex but were only included when univariate results were significantly associated with subgroup. For ADNI, this was only age (<italic toggle="yes">P</italic> = 0.0029, ANOVA <italic toggle="yes">F</italic>-test). For PPMI, this was only sex (<italic toggle="yes">P</italic> = 0.0017, χ<sup>2</sup>test).</p>
      <p>In the post hoc analysis, only complete cases were included; i.e., patients with missing values were ignored.</p>
    </sec>
  </sec>
  <sec id="sec3">
    <title>Availability of Supporting Source Code and Requirements</title>
    <p>A complete implementation of VaDER in Python/Tensorflow: <ext-link xlink:href="https://github.com/johanndejong/VaDER" ext-link-type="uri">https://github.com/johanndejong/VaDER</ext-link>.</p>
    <p>An R-package for streamlining the processing of PPMI data: <ext-link xlink:href="https://github.com/patzaw/PPMI-R-package-generator" ext-link-type="uri">https://github.com/patzaw/PPMI-R-package-generator</ext-link>.</p>
    <p>Other code used for generating results presented in this article: <ext-link xlink:href="https://github.com/johanndejong/VaDER_supporting_code" ext-link-type="uri">https://github.com/johanndejong/VaDER_supporting_code</ext-link>.</p>
    <p>Snapshots of all the above code and other supporting data are also available in the GigaScience database, GigaDB [<xref rid="bib66" ref-type="bibr">68</xref>].</p>
  </sec>
  <sec sec-type="supplementary-material" id="sec4">
    <title>Additional Files</title>
    <p><bold>Supplementary information</bold>: Supplementary Methods and Results are available via the additional file associated with this article.</p>
    <p>Supplementary Figure S1 Multivariate short time series data simulated using vector autoregressive processes, for 4 variables, 8 time points and 3 clusters, and different levels of the similarity parameter λ.</p>
    <p>Supplementary Figure S2 ADNI: prediction strength of VaDER for each <italic toggle="yes">k</italic> (blue) and the corresponding permutation-based null distribution.</p>
    <p>Supplementary Figure S3 ADNI: associations of the VaDER clustering with a wide range of other baseline data available from ADNI.</p>
    <p>Supplementary Figure S4 ADNI: associations of the VaDER clustering with a wide range of other baseline data available from ADNI.</p>
    <p>Supplementary Figure S5 ADNI: associations of the VaDER clustering with a wide range of other baseline data available from ADNI.</p>
    <p>Supplementary Figure S6 ADNI: associations of the VaDER clustering with a wide range of other baseline data available from ADNI.</p>
    <p>Supplementary Figure S7 ADNI: associations of the VaDER clustering with a wide range of other baseline data available from ADNI.</p>
    <p>Supplementary Figure S8 ADNI: associations of the VaDER clustering with a wide range of other longitudinal data available from ADNI.</p>
    <p>Supplementary Figure S9 PPMI: prediction strength of VaDER for each <italic toggle="yes">k</italic> (blue) and the corresponding permutation-based null distribution.</p>
    <p>Supplementary Figure S10 PPMI: associations of the VaDER clustering with a wide range of other baseline data available from PPMI.</p>
    <p>Supplementary Figure S11 PPMI: associations of the VaDER clustering with a wide range of other baseline data available from PPMI.</p>
    <p>Supplementary Figure S12 PPMI: associations of the VaDER clustering with a wide range of other baseline data available from PPMI.</p>
    <p>Supplementary Figure S13 PPMI: associations of the VaDER clustering with a wide range of other longitudinal data available from PPMI.</p>
    <p>Supplementary Figure S14 PPMI: associations of the VaDER clustering with a wide range of other longitudinal data available from PPMI.</p>
    <p>Supplementary Figure S15 PPMI: associations of the VaDER clustering with a wide range of other longitudinal data available from PPMI.</p>
    <supplementary-material id="sup1" position="float" content-type="local-data">
      <label>giz134_GIGA-D-19-00209_Original_Submission</label>
      <media xlink:href="giz134_giga-d-19-00209_original_submission.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material id="sup2" position="float" content-type="local-data">
      <label>giz134_GIGA-D-19-00209_Revision_1</label>
      <media xlink:href="giz134_giga-d-19-00209_revision_1.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material id="sup3" position="float" content-type="local-data">
      <label>giz134_Response_to_Reviewer_Comments_Original_Submission</label>
      <media xlink:href="giz134_response_to_reviewer_comments_original_submission.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material id="sup4" position="float" content-type="local-data">
      <label>giz134_Reviewer_1_Report_Original_Submission</label>
      <caption>
        <p>Alexandr Kalinin -- 7/26/2019 Reviewed</p>
      </caption>
      <media xlink:href="giz134_reviewer_1_report_original_submission.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material id="sup5" position="float" content-type="local-data">
      <label>giz134_Reviewer_1_Report_Revision_1</label>
      <caption>
        <p>Alexandr Kalinin -- 10/8/2019 Reviewed</p>
      </caption>
      <media xlink:href="giz134_reviewer_1_report_revision_1.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material id="sup6" position="float" content-type="local-data">
      <label>giz134_Reviewer_2_Report_Original_Submission</label>
      <caption>
        <p>Karsten Borgwardt -- 8/14/2019 Reviewed</p>
      </caption>
      <media xlink:href="giz134_reviewer_2_report_original_submission.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material id="sup7" position="float" content-type="local-data">
      <label>giz134_Supplemental_Files</label>
      <media xlink:href="giz134_supplemental_files.zip">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
  <sec id="sec5">
    <title>Abbreviations</title>
    <p>AD: Alzheimer disease; ADAS-13: Alzheimer Disease Assessment Scale; ADNI: Alzheimer’s Disease Neuroimaging Initiative; ANOVA: analysis of variance; CDRSB: Clinical Dementia Rating Sum of Box Score; ESS: Epworth Sleepiness Scale; FAQ: Functional Activities Questionnaire; GAK: Global Alignment Kernels; LSTM: long short-term memory; MAR: missing at random; MCAR: missing completely at random; MD-DTW: multidimensional dynamic time warping; MMSE: Mini–Mental State Examination; MNAR: missing not at random; MRI: magnetic resonance imaging; PD: Parkinson disease; PIGD: postural instability and gait disturbance; PPMI: Parkinson’s Progression Markers Initiative; RBD: REM sleep behavior disorder; SCOPA: Scales for Outcomes in Parkinson's Disease; STS distance: short-time-series distance; TD: tremor dominance; UPDRS: Unified Parkinson's Disease Rating Scale; UPDRS1: Unified Parkinson's Disease Rating Scale, Part 1; UPDRS2: Unified Parkinson’s Disease Rating Scale, Part 2; UPDRS3: Unified Parkinson’s Disease Rating Scale, Part 3; UCI: University of California Irvine Machine Learning Repository; UEA/UCR: University of East Anglia/University of California, Riverside Time-Series Classification Archive; VaDE: variational deep embedding; VaDER: variational deep embedding with recurrence; VAR: vector autoregression; VCF: variant call format.</p>
  </sec>
  <sec sec-type="COI-statement" id="sec6">
    <title>Competing Interests</title>
    <p>J.d.J. and H.F. received salaries from UCB Biosciences GmbH. UCB Biosciences GmbH had no influence on the content of this work.</p>
  </sec>
  <sec sec-type="funding" id="sec7">
    <title>Funding</title>
    <p>The research leading to these results has received partial support from the Innovative Medicines Initiative Joint Undertaking under grant agreement No. 115568, resources of which are composed of financial contribution from the European Union’s Seventh Framework Programme (FP7/2007-2013) and EFPIA companies’ in kind contribution.</p>
    <p>Data collection and sharing for this project was funded by ADNI (National Institutes of Health Grant U01 AG024904) and DOD ADNI (Department of Defense award No. W81XWH-12-2-0012). ADNI is funded by the National Institute on Aging, the National Institute of Biomedical Imaging and Bioengineering, and through generous contributions from the following: AbbVie; Alzheimer’s Association; Alzheimer’s Drug Discovery Foundation; Araclon Biotech; BioClinica, Inc.; Biogen; Bristol-Myers Squibb Company; CereSpir, Inc.; Cogstate; Eisai, Inc.; Elan Pharmaceuticals, Inc.; Eli Lilly and Company; EuroImmun; F. Hoffmann-La Roche Ltd and its affiliated company Genentech, Inc.; Fujirebio; GE Healthcare; IXICO Ltd.; Janssen Alzheimer Immunotherapy Research &amp; Development, LLC; Johnson &amp; Johnson Pharmaceutical Research &amp; Development, LLC; Lumosity; Lundbeck; Merck &amp; Co., Inc.; Meso Scale Diagnostics, LLC; NeuroRx Research; Neurotrack Technologies; Novartis Pharmaceuticals Corporation; Pfizer, Inc.; Piramal Imaging; Servier; Takeda Pharmaceutical Company; and Transition Therapeutics. The Canadian Institutes of Health Research is providing funds to support ADNI clinical sites in Canada. Private sector contributions are facilitated by the Foundation for the National Institutes of Health (<ext-link xlink:href="http://www.fnih.org" ext-link-type="uri">www.fnih.org</ext-link>). The grantee organization is the Northern California Institute for Research and Education, and the study is coordinated by the Alzheimer’s Therapeutic Research Institute at the University of Southern California. ADNI data are disseminated by the Laboratory for Neuro Imaging at the University of Southern California.</p>
  </sec>
  <sec id="sec8">
    <title>Authors’ Contributions</title>
    <p>Method development: J.d.J., H.F.; implementation and testing: J.d.J.; Data preparation: M.A.E., P.W., R.K., M.S., A.A., P.G.; image analysis: H.V.; supervision: H.F., M.H.A.; definition of research project: H.F.</p>
  </sec>
</body>
<back>
  <ack id="ack1">
    <title>ACKNOWLEDGEMENTS</title>
    <p>Data used in the preparation of this article were obtained from the Parkinson’s Progression Markers Initiative (PPMI) database (<ext-link xlink:href="http://www.ppmi-info.org/data" ext-link-type="uri">www.ppmi-info.org/data</ext-link>). For up-todate information on the study, visit <ext-link xlink:href="http://www.ppmi-info.org" ext-link-type="uri">www.ppmi-info.org</ext-link>. PPMI - a public-private partnership - is funded by the Michael J. Fox Foundation for Parkinson’s Research and funding partners. A list of names of all of the PPMI funding partners can be found at <ext-link xlink:href="http://www.ppmi-info.org/about-ppmi/who-we-are/study-sponsors/" ext-link-type="uri">www.ppmi-info.org/about-ppmi/who-we-are/study-sponsors/</ext-link>.</p>
  </ack>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="bib1">
      <label>1.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hruby</surname><given-names>A</given-names></string-name>, <string-name><surname>Hu</surname><given-names>FB</given-names></string-name></person-group>. <article-title>The epidemiology of obesity: a big picture</article-title>. <source>Pharmacoeconomics</source>. <year>2015</year>;<volume>33</volume>(<issue>7</issue>):<fpage>673</fpage>–<lpage>89</lpage>.<pub-id pub-id-type="pmid">25471927</pub-id></mixed-citation>
    </ref>
    <ref id="bib2">
      <label>2.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>van Tilburg</surname><given-names>J</given-names></string-name>, <string-name><surname>van Haeften</surname><given-names>TW</given-names></string-name>, <string-name><surname>Pearson</surname><given-names>P</given-names></string-name>, <etal>et al</etal>.</person-group><article-title>Defining the genetic contribution of type 2 diabetes mellitus</article-title>. <source>J Med Genet</source>. <year>2001</year>;<volume>38</volume>(<issue>9</issue>):<fpage>569</fpage>–<lpage>78</lpage>.<pub-id pub-id-type="pmid">11546824</pub-id></mixed-citation>
    </ref>
    <ref id="bib3">
      <label>3.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cordell</surname><given-names>HJ</given-names></string-name>, <string-name><surname>Todd</surname><given-names>JA</given-names></string-name></person-group>. <article-title>Multifactorial inheritance in type 1 diabetes</article-title>. <source>Trends Genet</source>. <year>1995</year>;<volume>11</volume>(<issue>12</issue>):<fpage>499</fpage>–<lpage>504</lpage>.<pub-id pub-id-type="pmid">8533167</pub-id></mixed-citation>
    </ref>
    <ref id="bib4">
      <label>4.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ruppert</surname><given-names>V</given-names></string-name>, <string-name><surname>Maisch</surname><given-names>B</given-names></string-name></person-group>. <article-title>Genetics of human hypertension</article-title>. <source>Herz</source>. <year>2003</year>;<volume>28</volume>(<issue>8</issue>):<fpage>655</fpage>–<lpage>62</lpage>.<pub-id pub-id-type="pmid">14689098</pub-id></mixed-citation>
    </ref>
    <ref id="bib5">
      <label>5.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Poulter</surname><given-names>N</given-names></string-name></person-group>. <article-title>Coronary heart disease is a multifactorial disease</article-title>. <source>Am J Hypertens</source>. <year>1999</year>;<volume>12</volume>(<issue>10</issue>):<fpage>92S</fpage>–<lpage>5S</lpage>.<pub-id pub-id-type="pmid">10555607</pub-id></mixed-citation>
    </ref>
    <ref id="bib6">
      <label>6.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Hastie</surname><given-names>T</given-names></string-name>, <string-name><surname>Tibshirani</surname><given-names>R</given-names></string-name>, <string-name><surname>Friedman</surname><given-names>JH</given-names></string-name></person-group>. <source>The Elements of Statistical Learning: Data Mining, Inference, and Prediction</source>. <edition>2</edition>nd Ed. <comment>Springer Series in Statistics</comment>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Springer</publisher-name>; <year>2009</year>.</mixed-citation>
    </ref>
    <ref id="bib7">
      <label>7.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Kannan</surname><given-names>R</given-names></string-name>, <string-name><surname>Vempala</surname><given-names>S</given-names></string-name></person-group>. <article-title>On clusterings - good, bad and spectral</article-title>. In: <source>Proceedings 41st Annual Symposium on Foundations of Computer Science, Redondo Beach, CA</source>. <publisher-name>IEEE</publisher-name>; <year>2000</year>:<fpage>367</fpage>–<lpage>77</lpage>.</mixed-citation>
    </ref>
    <ref id="bib8">
      <label>8.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Jain</surname><given-names>A</given-names></string-name>, <string-name><surname>Dubes</surname><given-names>R</given-names></string-name></person-group>. <source>Algorithms for Clustering Data</source>. <publisher-loc>Englewood Cliffs, NJ</publisher-loc>: <publisher-name>Prentice-Hall</publisher-name>; <year>1988</year>.</mixed-citation>
    </ref>
    <ref id="bib9">
      <label>9.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fukunaga</surname><given-names>K</given-names></string-name>, <string-name><surname>Hostetler</surname><given-names>LD</given-names></string-name></person-group>. <article-title>The estimation of the gradient of a density function, with applications in pattern recognition</article-title>. <source>IEEE Trans Inf Theory</source>. <year>1975</year>;<volume>21</volume>:<fpage>32</fpage>–<lpage>9</lpage>.</mixed-citation>
    </ref>
    <ref id="bib10">
      <label>10.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Aghabozorgi</surname><given-names>S</given-names></string-name>, <string-name><surname>Seyed Shirkhorshidi</surname><given-names>A</given-names></string-name>, <string-name><surname>Ying Wah</surname><given-names>T</given-names></string-name></person-group>. <article-title>Time-series clustering - a decade review</article-title>. <source>Inf Syst</source>. <year>2015</year>;<volume>53</volume>(<issue>C</issue>):<fpage>16</fpage>–<lpage>38</lpage>.</mixed-citation>
    </ref>
    <ref id="bib11">
      <label>11.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rani</surname><given-names>S</given-names></string-name>, <string-name><surname>Sikka</surname><given-names>G</given-names></string-name></person-group>. <article-title>Recent techniques of clustering of time series data: a survey</article-title>. <source>Int J Comput Appl</source>. <year>2012</year>;<volume>52</volume>(<issue>15</issue>):<fpage>1</fpage>–<lpage>9</lpage>.</mixed-citation>
    </ref>
    <ref id="bib12">
      <label>12.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Liao</surname><given-names>TW</given-names></string-name></person-group>. <article-title>Clustering of time series data: a survey</article-title>. <source>Pattern Recognit</source>. <year>2005</year>;<volume>38</volume>(<issue>11</issue>):<fpage>1857</fpage>–<lpage>74</lpage>.</mixed-citation>
    </ref>
    <ref id="bib13">
      <label>13.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ghassempour</surname><given-names>S</given-names></string-name>, <string-name><surname>Girosi</surname><given-names>F</given-names></string-name>, <string-name><surname>Maeder</surname><given-names>A</given-names></string-name></person-group>. <article-title>Clustering multivariate time series using hidden Markov models</article-title>. <source>Int J Environ Res Public Health</source>. <year>2014</year>;<volume>11</volume>(<issue>3</issue>):<fpage>2741</fpage>–<lpage>63</lpage>.<pub-id pub-id-type="pmid">24662996</pub-id></mixed-citation>
    </ref>
    <ref id="bib14">
      <label>14.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sun</surname><given-names>J</given-names></string-name></person-group>. <article-title>Clustering multivariate time series based on Riemannian manifold</article-title>. <source>Electron Lett</source>. <year>2016</year>;<volume>52</volume>(<issue>2</issue>):<fpage>1607</fpage>–<lpage>9</lpage>.</mixed-citation>
    </ref>
    <ref id="bib15">
      <label>15.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rubin</surname><given-names>DB</given-names></string-name></person-group>. <article-title>Inference and missing data</article-title>. <source>Biometrika</source>. <year>1976</year>;<volume>63</volume>(<issue>3</issue>):<fpage>581</fpage>–<lpage>92</lpage>.</mixed-citation>
    </ref>
    <ref id="bib16">
      <label>16.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kang</surname><given-names>H</given-names></string-name></person-group>. <article-title>The prevention and handling of the missing data</article-title>. <source>Korean J Anesthes</source>. <year>2013</year>;<volume>64</volume>(<issue>5</issue>):<fpage>402</fpage>–<lpage>6</lpage>.</mixed-citation>
    </ref>
    <ref id="bib17">
      <label>17.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Mikolov</surname><given-names>T</given-names></string-name>, <string-name><surname>Sutskever</surname><given-names>I</given-names></string-name>, <string-name><surname>Chen</surname><given-names>K</given-names></string-name>, <etal>et al</etal>.</person-group><article-title>Distributed representations of words and phrases and their compositionality</article-title>. In: <source>Proceedings of the 26th International Conference on Neural Information Processing Systems - Volume 2 NIPS’13, Lake Tahoe, NV</source>. <publisher-name>Curran Associates Inc</publisher-name>; <year>2013</year>:<fpage>3111</fpage>–<lpage>9</lpage>.</mixed-citation>
    </ref>
    <ref id="bib18">
      <label>18.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hinton</surname><given-names>GE</given-names></string-name>, <string-name><surname>Salakhutdinov</surname><given-names>RR</given-names></string-name></person-group>. <article-title>Reducing the dimensionality of data with neural networks</article-title>. <source>Science</source>. <year>2006</year>;<volume>313</volume>(<issue>5786</issue>): <fpage>504</fpage>–<lpage>7</lpage>.<pub-id pub-id-type="pmid">16873662</pub-id></mixed-citation>
    </ref>
    <ref id="bib19">
      <label>19.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Frome</surname><given-names>A</given-names></string-name>, <string-name><surname>Corrado</surname><given-names>GS</given-names></string-name>, <string-name><surname>Shlens</surname><given-names>J</given-names></string-name>, <etal>et al</etal>.</person-group><article-title>DeViSE: A Deep Visual-Semantic Embedding Model</article-title>. In: <person-group person-group-type="editor"><string-name><surname>Burges</surname><given-names>CJC</given-names></string-name>, <string-name><surname>Bottou</surname><given-names>L</given-names></string-name>, <string-name><surname>Welling</surname><given-names>M</given-names></string-name><etal>et al</etal>., <etal>et al</etal>.</person-group>, eds. <source>Advances in Neural Information Processing Systems</source>. <publisher-name>Curran Associates</publisher-name>; <year>2013</year>:<fpage>2121</fpage>–<lpage>9</lpage>.</mixed-citation>
    </ref>
    <ref id="bib20">
      <label>20.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Asgari</surname><given-names>E</given-names></string-name>, <string-name><surname>Mofrad</surname><given-names>MRK</given-names></string-name></person-group>. <article-title>Continuous distributed representation of biological sequences for deep proteomics and genomics</article-title>. <source>PLoS One</source>. <year>2015</year>; <volume>10</volume>(<issue>11</issue>):<fpage>1</fpage>–<lpage>15</lpage>.</mixed-citation>
    </ref>
    <ref id="bib21">
      <label>21.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Trigeorgis</surname><given-names>G</given-names></string-name>, <string-name><surname>Bousmalis</surname><given-names>K</given-names></string-name>, <string-name><surname>Zafeiriou</surname><given-names>S</given-names></string-name>, <etal>et al</etal>.</person-group><article-title>A deep semi-NMF model for learning hidden representations</article-title>. In: <person-group person-group-type="editor"><string-name><surname>Xing</surname><given-names>EP</given-names></string-name>, <string-name><surname>Jebara</surname><given-names>T</given-names></string-name></person-group>, eds. <source>Proceedings of the 31st International Conference on Machine Learning, Beijing, China</source>. <publisher-name>PMLR</publisher-name>; <year>2014</year>:<fpage>1692</fpage>–<lpage>700</lpage>.</mixed-citation>
    </ref>
    <ref id="bib22">
      <label>22.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Xie</surname><given-names>J</given-names></string-name>, <string-name><surname>Girshick</surname><given-names>R</given-names></string-name>, <string-name><surname>Farhadi</surname><given-names>A</given-names></string-name></person-group>. <article-title>Unsupervised deep embedding for clustering analysis</article-title>. In: <source>Proceedings of the 33rd International Conference on International Conference on Machine Learning - Volume 48 ICML’16</source>. <publisher-name>JMLR</publisher-name>; <year>2016</year>:<fpage>478</fpage>–<lpage>487</lpage>.</mixed-citation>
    </ref>
    <ref id="bib23">
      <label>23.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Jiang</surname><given-names>Z</given-names></string-name>, <string-name><surname>Zheng</surname><given-names>Y</given-names></string-name>, <string-name><surname>Tan</surname><given-names>H</given-names></string-name>, <etal>et al</etal>.</person-group><article-title>Variational deep embedding: an unsupervised and generative approach to clustering</article-title>. In: <source>Proceedings of the Twenty-Sixth International Joint Conference on Artificial Intelligence (IJCAI-17)</source>. <year>2017</year>:<fpage>1965</fpage>–<lpage>72</lpage>.</mixed-citation>
    </ref>
    <ref id="bib24">
      <label>24.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hochreiter</surname><given-names>S</given-names></string-name>, <string-name><surname>Schmidhuber</surname><given-names>J</given-names></string-name></person-group>. <article-title>Long short-term memory</article-title>. <source>Neural Comput</source>. <year>1997</year>;<volume>9</volume>(<issue>8</issue>):<fpage>1735</fpage>–<lpage>80</lpage>.<pub-id pub-id-type="pmid">9377276</pub-id></mixed-citation>
    </ref>
    <ref id="bib25">
      <label>25.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Petersen</surname><given-names>RC</given-names></string-name>, <string-name><surname>Aisen</surname><given-names>PS</given-names></string-name>, <string-name><surname>Beckett</surname><given-names>LA</given-names></string-name>, <etal>et al</etal>.</person-group><article-title>Alzheimer’s Disease Neuroimaging Initiative (ADNI)</article-title>. <source>Neurology</source>. <year>2010</year>;<volume>74</volume>(<issue>3</issue>): <fpage>201</fpage>–<lpage>9</lpage>.<pub-id pub-id-type="pmid">20042704</pub-id></mixed-citation>
    </ref>
    <ref id="bib26">
      <label>26.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Marek</surname><given-names>K</given-names></string-name>, <string-name><surname>Jennings</surname><given-names>D</given-names></string-name>, <string-name><surname>Lasch</surname><given-names>S</given-names></string-name>, <etal>et al</etal>.</person-group><article-title>The Parkinson Progression Marker Initiative (PPMI)</article-title>. <source>Prog Neurobiol</source>. <year>2011</year>;<volume>95</volume>(<issue>4</issue>):<fpage>629</fpage>–<lpage>35</lpage>.<pub-id pub-id-type="pmid">21930184</pub-id></mixed-citation>
    </ref>
    <ref id="bib27">
      <label>27.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Komarova</surname><given-names>NL</given-names></string-name>, <string-name><surname>Thalhauser</surname><given-names>CJ</given-names></string-name></person-group>. <article-title>High degree of heterogeneity in Alzheimer’s disease progression patterns</article-title>. <source>PLoS Comput Biol</source>. <year>2011</year>;<volume>7</volume>(<issue>11</issue>), doi:<pub-id pub-id-type="doi">10.1371/journal.pcbi.1002251</pub-id>.</mixed-citation>
    </ref>
    <ref id="bib28">
      <label>28.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lam</surname><given-names>B</given-names></string-name>, <string-name><surname>Masellis</surname><given-names>M</given-names></string-name>, <string-name><surname>Freedman</surname><given-names>M</given-names></string-name>, <etal>et al</etal>.</person-group><article-title>Clinical, imaging, and pathological heterogeneity of the Alzheimer’s disease syndrome</article-title>. <source>Alzheimers Res Ther</source>. <year>2013</year>;<volume>5</volume>(<issue>1</issue>):<fpage>1</fpage>, doi:<pub-id pub-id-type="doi">10.1186/alzrt155</pub-id>.<pub-id pub-id-type="pmid">23302773</pub-id></mixed-citation>
    </ref>
    <ref id="bib29">
      <label>29.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lewis</surname><given-names>SJG</given-names></string-name>, <string-name><surname>Foltynie</surname><given-names>T</given-names></string-name>, <string-name><surname>Blackwell</surname><given-names>AD</given-names></string-name>, <etal>et al</etal>.</person-group><article-title>Heterogeneity of Parkinson’s disease in the early clinical stages using a data driven approach</article-title>. <source>J Neurol Neurosurg Psychiatry</source>. <year>2005</year>;<volume>76</volume>(<issue>3</issue>):<fpage>343</fpage>–<lpage>8</lpage>.<pub-id pub-id-type="pmid">15716523</pub-id></mixed-citation>
    </ref>
    <ref id="bib30">
      <label>30.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>von Coelln</surname><given-names>R</given-names></string-name>, <string-name><surname>Shulman</surname><given-names>LM</given-names></string-name></person-group>. <article-title>Clinical subtypes and genetic heterogeneity: of lumping and splitting in Parkinson disease</article-title>. <source>Curr Opin Neurol</source>. <year>2016</year>;<volume>29</volume>(<issue>6</issue>):<fpage>727</fpage>–<lpage>34</lpage>.<pub-id pub-id-type="pmid">27749396</pub-id></mixed-citation>
    </ref>
    <ref id="bib67_392_1572363658949">
      <label>31.</label>
      <mixed-citation publication-type="journal">Parkinson's Disease Information Page. <comment><ext-link xlink:href="https://www.ninds.nih.gov/Disorders/All-Disorders/Parkinsons-Disease-Information-Page" ext-link-type="uri">https://www.ninds.nih.gov/Disorders/All-Disorders/Parkinsons-Disease-Information-Page</ext-link></comment>.</mixed-citation>
    </ref>
    <ref id="bib31">
      <label>32.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Kingma</surname><given-names>DP</given-names></string-name>, <string-name><surname>Welling</surname><given-names>M</given-names></string-name></person-group>. <article-title>Auto-encoding variational Bayes</article-title>. <source>arXiv</source>. <year>2013</year>:<fpage>1312.6114</fpage>.</mixed-citation>
    </ref>
    <ref id="bib32">
      <label>33.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Doersch</surname><given-names>C</given-names></string-name></person-group>. <article-title>Tutorial on variational autoencoders</article-title>. <source>arXiv</source>. <year>2016</year>:<fpage>1606.05908</fpage>.</mixed-citation>
    </ref>
    <ref id="bib33">
      <label>34.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gers</surname><given-names>FA</given-names></string-name>, <string-name><surname>Schraudolph</surname><given-names>NN</given-names></string-name>, <string-name><surname>Schmidhuber</surname><given-names>J</given-names></string-name></person-group>. <article-title>Learning precise timing with LSTM recurrent networks</article-title>. <source>J Mach Learn Res</source>. <year>2003</year>;<volume>3</volume>:<fpage>115</fpage>–<lpage>43</lpage>.</mixed-citation>
    </ref>
    <ref id="bib34">
      <label>35.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Lipton</surname><given-names>ZC</given-names></string-name>, <string-name><surname>Kale</surname><given-names>DC</given-names></string-name>, <string-name><surname>Wetzel</surname><given-names>RC</given-names></string-name></person-group>. <article-title>Directly modeling missing data in sequences with RNNs: improved classification of clinical time series</article-title>. In: <source>Proceedings of the 1st Machine Learning for Healthcare Conference, PMLR 56</source>. <publisher-name>JMLR</publisher-name>; <year>2016</year>: <fpage>253</fpage>–<lpage>270</lpage>.</mixed-citation>
    </ref>
    <ref id="bib35">
      <label>36.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nazábal</surname><given-names>A</given-names></string-name>, <string-name><surname>Olmos</surname><given-names>PM</given-names></string-name>, <string-name><surname>Ghahramani</surname><given-names>Z</given-names></string-name>, <etal>et al</etal>.</person-group><article-title>Handling incomplete heterogeneous data using VAEs</article-title>. <source>arXiv</source>. <year>2018</year>:<fpage>1807.03653</fpage>.</mixed-citation>
    </ref>
    <ref id="bib36">
      <label>37.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Manning</surname><given-names>CD</given-names></string-name>, <string-name><surname>Raghavan</surname><given-names>P</given-names></string-name>, <string-name><surname>Schütze</surname><given-names>H</given-names></string-name></person-group>. <source>Introduction to Information Retrieval</source>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Cambridge University Press</publisher-name>; <year>2008</year>.</mixed-citation>
    </ref>
    <ref id="bib38">
      <label>38.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tormene</surname><given-names>P</given-names></string-name>, <string-name><surname>Giorgino</surname><given-names>T</given-names></string-name>, <string-name><surname>Quaglini</surname><given-names>S</given-names></string-name>, <etal>et al</etal>.</person-group><article-title>Matching incomplete time series with dynamic time warping: an algorithm and an application to post-stroke rehabilitation</article-title>. <source>Artif Intell Med</source>. <year>2008</year>;<volume>45</volume>(<issue>1</issue>):<fpage>11</fpage>–<lpage>34</lpage>.<pub-id pub-id-type="pmid">19111449</pub-id></mixed-citation>
    </ref>
    <ref id="bib39">
      <label>39.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Cuturi</surname><given-names>M</given-names></string-name></person-group>. <article-title>Fast global alignment kernels</article-title>. In: <person-group person-group-type="editor"><string-name><surname>Getoor</surname><given-names>L</given-names></string-name>, <string-name><surname>Scheffer</surname><given-names>T</given-names></string-name></person-group>, eds. <publisher-name>ICML Omnipress</publisher-name>; <year>2011</year>:<fpage>929</fpage>–<lpage>36</lpage>.</mixed-citation>
    </ref>
    <ref id="bib37">
      <label>40.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Möller-Levet</surname><given-names>CS</given-names></string-name>, <string-name><surname>Klawonn</surname><given-names>F</given-names></string-name>, <string-name><surname>Cho</surname><given-names>K</given-names></string-name>, <etal>et al</etal>.</person-group><article-title>Fuzzy clustering of short time-series and unevenly distributed sampling points</article-title>. In: <person-group person-group-type="editor"><string-name><surname>Berthold</surname><given-names>MR</given-names></string-name>, <string-name><surname>Lenz</surname><given-names>H</given-names></string-name>, <string-name><surname>Bradley</surname><given-names>E</given-names></string-name><etal>et al</etal>., <etal>et al</etal>.</person-group>, eds. <source>Advances in Intelligent Data Analysis V, 5th International Symposium on Intelligent Data Analysis, IDA 2003, Berlin, Germany</source>. <publisher-name>Springer</publisher-name>; <year>2003</year>:<fpage>330</fpage>–<lpage>40</lpage>.</mixed-citation>
    </ref>
    <ref id="bib40">
      <label>41.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Dua</surname><given-names>D</given-names></string-name>, <string-name><surname>Graff</surname><given-names>C</given-names></string-name></person-group>. <comment>UCI Machine Learning Repository</comment>. <year>2017</year>. <ext-link xlink:href="http://archive.ics.uci.edu/ml" ext-link-type="uri">http://archive.ics.uci.edu/ml</ext-link>.</mixed-citation>
    </ref>
    <ref id="bib41">
      <label>42.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Bagnall</surname><given-names>A</given-names></string-name>, <string-name><surname>Lines</surname><given-names>J</given-names></string-name>, <string-name><surname>Vickers</surname><given-names>W</given-names></string-name></person-group>. <comment>The UEA, UCR Time Series Classification Repository. <ext-link xlink:href="http://www.timeseriesclassification.com" ext-link-type="uri">http://www.timeseriesclassification.com</ext-link></comment>. Accessed 15 August 2019.</mixed-citation>
    </ref>
    <ref id="bib42">
      <label>43.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tibshirani</surname><given-names>R</given-names></string-name>, <string-name><surname>Walther</surname><given-names>G</given-names></string-name></person-group>. <article-title>Cluster validation by prediction strength</article-title>. <source>J Comput Graph Stat</source>. <year>2005</year>;<volume>14</volume>(<issue>3</issue>):<fpage>511</fpage>–<lpage>28</lpage>.</mixed-citation>
    </ref>
    <ref id="bib43">
      <label>44.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tibshirani</surname><given-names>R</given-names></string-name>, <string-name><surname>Walther</surname><given-names>G</given-names></string-name>, <string-name><surname>Hastie</surname><given-names>T</given-names></string-name></person-group>. <article-title>Estimating the number of clusters in a data set via the gap statistic</article-title>. <source>J R Stat Soc Series B Stat Methodol</source>. <year>2001</year>;<volume>63</volume>(<issue>2</issue>):<fpage>411</fpage>–<lpage>23</lpage>.</mixed-citation>
    </ref>
    <ref id="bib44">
      <label>45.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sugar</surname><given-names>CA</given-names></string-name>, <string-name><surname>James</surname><given-names>GM</given-names></string-name></person-group>. <article-title>Finding the number of clusters in a dataset: an information-theoretic approach</article-title>. <source>J Am Stat Assoc</source>. <year>2003</year>;<volume>98</volume>(<issue>463</issue>):<fpage>750</fpage>–<lpage>63</lpage>.</mixed-citation>
    </ref>
    <ref id="bib45">
      <label>46.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Thorndike</surname><given-names>RL</given-names></string-name></person-group>. <article-title>Who belongs in the family</article-title>. <source>Psychometrika</source>. <year>1953</year>;<volume>18</volume>(<issue>4</issue>):<fpage>267</fpage>–<lpage>76</lpage>.</mixed-citation>
    </ref>
    <ref id="bib46">
      <label>47.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rousseeuw</surname><given-names>PJ</given-names></string-name></person-group>. <article-title>Silhouettes: a graphical aid to the interpretation and validation of cluster analysis</article-title>. <source>J Comput Appl Math</source>. <year>1987</year>;<volume>20</volume>:<fpage>53</fpage>–<lpage>65</lpage>.</mixed-citation>
    </ref>
    <ref id="bib47">
      <label>48.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Convit</surname><given-names>A</given-names></string-name>, <string-name><surname>de Asis</surname><given-names>J</given-names></string-name>, <string-name><surname>de Leon</surname><given-names>MJ</given-names></string-name>, <etal>et al</etal>.</person-group><article-title>Atrophy of the medial occipitotemporal, inferior, and middle temporal gyri in non-demented elderly predict decline to Alzheimer’s disease</article-title>. <source>Neurobiol Aging</source>. <year>2000</year>;<volume>21</volume>(<issue>1</issue>):<fpage>19</fpage>–<lpage>26</lpage>.<pub-id pub-id-type="pmid">10794844</pub-id></mixed-citation>
    </ref>
    <ref id="bib48">
      <label>49.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nestor</surname><given-names>SM</given-names></string-name>, <string-name><surname>Rupsingh</surname><given-names>R</given-names></string-name>, <string-name><surname>Borrie</surname><given-names>M</given-names></string-name>, <etal>et al</etal>.</person-group><article-title>Ventricular enlargement as a possible measure of Alzheimer’s disease progression validated using the Alzheimer’s Disease Neuroimaging Initiative database</article-title>. <source>Brain</source>. <year>2008</year>;<volume>131</volume>(<issue>9</issue>):<fpage>2443</fpage>–<lpage>54</lpage>.<pub-id pub-id-type="pmid">18669512</pub-id></mixed-citation>
    </ref>
    <ref id="bib49">
      <label>50.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Butterfield</surname><given-names>DA</given-names></string-name>, <string-name><surname>Halliwell</surname><given-names>B</given-names></string-name></person-group>. <article-title>Oxidative stress, dysfunctional glucose metabolism and Alzheimer disease</article-title>. <source>Nat Rev Neurosci</source>. <year>2019</year>;<volume>20</volume>(<issue>3</issue>):<fpage>148</fpage>–<lpage>60</lpage>.<pub-id pub-id-type="pmid">30737462</pub-id></mixed-citation>
    </ref>
    <ref id="bib50">
      <label>51.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tapiola</surname><given-names>T</given-names></string-name>, <string-name><surname>Alafuzoff</surname><given-names>I</given-names></string-name>, <string-name><surname>Herukka</surname><given-names>SK</given-names></string-name>, <etal>et al</etal>.</person-group><article-title>Cerebrospinal fluid beta-amyloid 42 and tau proteins as biomarkers of Alzheimer-type pathologic changes in the brain</article-title>. <source>JAMA Neurol</source>. <year>2009</year>;<volume>66</volume>(<issue>3</issue>):<fpage>382</fpage>–<lpage>9</lpage>.</mixed-citation>
    </ref>
    <ref id="bib51">
      <label>52.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Moisan</surname><given-names>F</given-names></string-name>, <string-name><surname>Kab</surname><given-names>S</given-names></string-name>, <string-name><surname>Mohamed</surname><given-names>F</given-names></string-name>, <etal>et al</etal>.</person-group><article-title>Parkinson disease male-to-female ratios increase with age: French nationwide study and meta-analysis</article-title>. <source>J Neurol Neurosurg Psychiatry</source>. <year>2016</year>;<volume>87</volume>(<issue>9</issue>):<fpage>952</fpage>–<lpage>7</lpage>.<pub-id pub-id-type="pmid">26701996</pub-id></mixed-citation>
    </ref>
    <ref id="bib52">
      <label>53.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Schrag</surname><given-names>A</given-names></string-name>, <string-name><surname>Jahanshahi</surname><given-names>M</given-names></string-name>, <string-name><surname>Quinn</surname><given-names>N</given-names></string-name></person-group>. <article-title>What contributes to quality of life in patients with Parkinson’s disease?</article-title>. <source>J Neurol Neurosurg Psychiatry</source>. <year>2000</year>;<volume>69</volume>(<issue>3</issue>):<fpage>308</fpage>–<lpage>12</lpage>.<pub-id pub-id-type="pmid">10945804</pub-id></mixed-citation>
    </ref>
    <ref id="bib53">
      <label>54.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sheikh</surname><given-names>JI</given-names></string-name>, <string-name><surname>Yesavage</surname><given-names>JA</given-names></string-name></person-group>. <article-title>Geriatric Depression Scale (GDS): Recent evidence and development of a shorter version</article-title>. <source>Clinical Gerontol</source>. <year>1986</year>;<volume>5</volume>(<issue>1-2</issue>):<fpage>165</fpage>–<lpage>73</lpage>.</mixed-citation>
    </ref>
    <ref id="bib54">
      <label>55.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Marsh</surname><given-names>L</given-names></string-name></person-group>. <article-title>Depression and Parkinson’s disease: current knowledge</article-title>. <source>Curr Neurol Neurosci Rep</source>. <year>2013</year>;<volume>13</volume>(<issue>12</issue>):<fpage>409</fpage>.<pub-id pub-id-type="pmid">24190780</pub-id></mixed-citation>
    </ref>
    <ref id="bib55">
      <label>56.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pitcher</surname><given-names>TL</given-names></string-name>, <string-name><surname>Melzer</surname><given-names>TR</given-names></string-name>, <string-name><surname>MacAskill</surname><given-names>MR</given-names></string-name>, <etal>et al</etal>.</person-group><article-title>Reduced striatal volumes in Parkinson’s disease: a magnetic resonance imaging study</article-title>. <source>Transl Neurodegener</source>. <year>2012</year>;<volume>1</volume>(<issue>1</issue>):<fpage>17</fpage>.<pub-id pub-id-type="pmid">23210661</pub-id></mixed-citation>
    </ref>
    <ref id="bib56">
      <label>57.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pedersen</surname><given-names>AB</given-names></string-name>, <string-name><surname>Mikkelsen</surname><given-names>EM</given-names></string-name>, <string-name><surname>Cronin-Fenton</surname><given-names>D</given-names></string-name>, <etal>et al</etal>.</person-group><article-title>Missing data and multiple imputation in clinical epidemiological research</article-title>. <source>Clin Epidemiol</source>. <year>2017</year>;<volume>9</volume>:<fpage>157</fpage>–<lpage>66</lpage>.<pub-id pub-id-type="pmid">28352203</pub-id></mixed-citation>
    </ref>
    <ref id="bib57">
      <label>58.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Marston</surname><given-names>L</given-names></string-name>, <string-name><surname>Carpenter</surname><given-names>JR</given-names></string-name>, <string-name><surname>Walters</surname><given-names>KR</given-names></string-name>, <etal>et al</etal>.</person-group><article-title>Issues in multiple imputation of missing data for large general practice clinical databases</article-title>. <source>Pharmacoepidemiol Drug Saf</source>. <year>2010</year>;<volume>19</volume>(<issue>6</issue>):<fpage>618</fpage>–<lpage>26</lpage>.<pub-id pub-id-type="pmid">20306452</pub-id></mixed-citation>
    </ref>
    <ref id="bib58">
      <label>59.</label>
      <mixed-citation publication-type="book"><collab>ADNI Team</collab>. <comment>ADNIMERGE: Alzheimer’s Disease Neuroimaging Initiative</comment>. <year>2018</year>. <comment>R package version 0.0.1</comment>.</mixed-citation>
    </ref>
    <ref id="bib68_215_1572542864951">
      <label>60.</label>
      <mixed-citation publication-type="journal">FreeSurfer. <comment><ext-link xlink:href="http://surfer.nmr.mgh.harvard.edu/" ext-link-type="uri">http://surfer.nmr.mgh.harvard.edu/</ext-link></comment>.</mixed-citation>
    </ref>
    <ref id="bib59">
      <label>61.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Desikan</surname><given-names>R</given-names></string-name>, <string-name><surname>Ségonne</surname><given-names>F</given-names></string-name>, <string-name><surname>Fischl</surname><given-names>B</given-names></string-name>, <etal>et al</etal>.</person-group><article-title>An automated labeling system for subdividing the human cerebral cortex on MRI scans into gyral based regions of interest</article-title>. <source>NeuroImage</source>. <year>2006</year>;<volume>31</volume>(<issue>3</issue>):<fpage>968</fpage>–<lpage>80</lpage>.<pub-id pub-id-type="pmid">16530430</pub-id></mixed-citation>
    </ref>
    <ref id="bib60">
      <label>62.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Destrieux</surname><given-names>C</given-names></string-name>, <string-name><surname>Fischl</surname><given-names>B</given-names></string-name>, <string-name><surname>Dale</surname><given-names>AM</given-names></string-name>, <etal>et al</etal>.</person-group><article-title>Automatic parcellation of human cortical gyri and sulci using standard anatomical nomenclature</article-title>. <source>NeuroImage</source>. <year>2010</year>;<volume>53</volume>(<issue>1</issue>):<fpage>1</fpage>–<lpage>15</lpage>.<pub-id pub-id-type="pmid">20547229</pub-id></mixed-citation>
    </ref>
    <ref id="bib61">
      <label>63.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname><given-names>L</given-names></string-name>, <string-name><surname>Wang</surname><given-names>Z</given-names></string-name>, <string-name><surname>Liu</surname><given-names>S</given-names></string-name></person-group>. <article-title>An effective multivariate time series classification approach using echo state network and adaptive differential evolution algorithm</article-title>. <source>Expert Syst Appl</source>. <year>2016</year>;<volume>43</volume>(<issue>C</issue>):<fpage>237</fpage>–<lpage>49</lpage>.</mixed-citation>
    </ref>
    <ref id="bib62">
      <label>64.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Øyvind Mikalsen</surname><given-names>K</given-names></string-name>, <string-name><surname>Bianchi</surname><given-names>FM</given-names></string-name>, <string-name><surname>Soguero-Ruiz</surname><given-names>C</given-names></string-name>, <etal>et al</etal>.</person-group><article-title>Time series cluster kernel for learning similarities between multivariate time series with missing data</article-title>. <source>Pattern Recognit</source>. <year>2018</year>;<volume>76</volume>:<fpage>569</fpage>–<lpage>81</lpage>.</mixed-citation>
    </ref>
    <ref id="bib63">
      <label>65.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sims</surname><given-names>C</given-names></string-name></person-group>. <article-title>Macroeconomics and reality</article-title>. <source>Econometrica</source>. <year>1980</year>;<volume>48</volume>(<issue>1</issue>):<fpage>1</fpage>–<lpage>48</lpage>.</mixed-citation>
    </ref>
    <ref id="bib64">
      <label>66.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rand</surname><given-names>WM</given-names></string-name></person-group>. <article-title>Objective criteria for the evaluation of clustering methods</article-title>. <source>J Am Stat Assoc</source>. <year>1971</year>;<volume>66</volume>(<issue>336</issue>):<fpage>846</fpage>–<lpage>50</lpage>.</mixed-citation>
    </ref>
    <ref id="bib65">
      <label>67.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hubert</surname><given-names>L</given-names></string-name>, <string-name><surname>Arabie</surname><given-names>P</given-names></string-name></person-group>. <article-title>Comparing partitions</article-title>. <source>J Classif</source>. <year>1985</year>;<volume>2</volume>(<issue>1</issue>):<fpage>193</fpage>–<lpage>218</lpage>.</mixed-citation>
    </ref>
    <ref id="bib66">
      <label>68.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>de Jong</surname><given-names>J</given-names></string-name>, <string-name><surname>Emon</surname><given-names>MA</given-names></string-name>, <string-name><surname>Wu</surname><given-names>P</given-names></string-name>, <etal>et al</etal>.</person-group><article-title>Supporting data for “Deep learning for clustering of multivariate clinical patient trajectories with missing values.”</article-title>. <source>GigaScience Database</source>. <year>2019</year>. <pub-id pub-id-type="doi">10.5524/100662</pub-id>.</mixed-citation>
    </ref>
  </ref-list>
</back>
