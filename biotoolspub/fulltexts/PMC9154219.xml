<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id>
    <journal-id journal-id-type="publisher-id">bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1367-4803</issn>
    <issn pub-type="epub">1367-4811</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">9154219</article-id>
    <article-id pub-id-type="pmid">35435214</article-id>
    <article-id pub-id-type="doi">10.1093/bioinformatics/btac270</article-id>
    <article-id pub-id-type="publisher-id">btac270</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Applications Notes</subject>
        <subj-group subj-group-type="category-toc-heading">
          <subject>Bioimage Informatics</subject>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI01060</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Steer’n’Detect: fast 2D template detection with accurate orientation estimation</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-2859-9241</contrib-id>
        <name>
          <surname>Uhlmann</surname>
          <given-names>Virginie</given-names>
        </name>
        <xref rid="btac270-cor1" ref-type="corresp"/>
        <aff><institution>European Bioinformatics Institute, European Molecular Biology Laboratory (EMBL)</institution>, Cambridge, <country country="GB">UK</country></aff>
        <xref rid="btac270-FM1" ref-type="author-notes"/>
        <!--uhlmann@ebi.ac.uk-->
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Püspöki</surname>
          <given-names>Zsuzsanna</given-names>
        </name>
        <aff><institution>School of Engineering, Biomedical Imaging Group, Ecole Polytechnique Fédérale de Lausanne (EPFL)</institution>, Lausanne, <country country="CH">Switzerland</country></aff>
        <xref rid="btac270-FM1" ref-type="author-notes"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Depeursinge</surname>
          <given-names>Adrien</given-names>
        </name>
        <aff><institution>Institute of Information Systems, University of Applied Sciences Western Switzerland (HES-SO)</institution>, Sierre, <country country="CH">Switzerland</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Unser</surname>
          <given-names>Michael</given-names>
        </name>
        <aff><institution>School of Engineering, Biomedical Imaging Group, Ecole Polytechnique Fédérale de Lausanne (EPFL)</institution>, Lausanne, <country country="CH">Switzerland</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Sage</surname>
          <given-names>Daniel</given-names>
        </name>
        <aff><institution>School of Engineering, Biomedical Imaging Group, Ecole Polytechnique Fédérale de Lausanne (EPFL)</institution>, Lausanne, <country country="CH">Switzerland</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Fageot</surname>
          <given-names>Julien</given-names>
        </name>
        <aff><institution>School of Computer and Communication Sciences, AudioVisual Communications Laboratory, Ecole Polytechnique Fédérale de Lausanne (EPFL)</institution>, Lausanne, <country country="CH">Switzerland</country></aff>
      </contrib>
    </contrib-group>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Peng</surname>
          <given-names>Hanchuan</given-names>
        </name>
        <role>Associate Editor</role>
      </contrib>
    </contrib-group>
    <author-notes>
      <fn id="btac270-FM1">
        <label>†</label>
        <p>The authors wish it to be known that, in their opinion, Virginie Uhlmann and Zsuzsanna Püspöki should be regarded as Joint First Authors.</p>
      </fn>
      <corresp id="btac270-cor1">To whom correspondence should be addressed. <email>uhlmann@ebi.ac.uk</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <day>01</day>
      <month>6</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2022-04-18">
      <day>18</day>
      <month>4</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>18</day>
      <month>4</month>
      <year>2022</year>
    </pub-date>
    <volume>38</volume>
    <issue>11</issue>
    <fpage>3146</fpage>
    <lpage>3148</lpage>
    <history>
      <date date-type="received">
        <day>10</day>
        <month>12</month>
        <year>2021</year>
      </date>
      <date date-type="rev-recd">
        <day>04</day>
        <month>3</month>
        <year>2022</year>
      </date>
      <date date-type="editorial-decision">
        <day>07</day>
        <month>4</month>
        <year>2022</year>
      </date>
      <date date-type="accepted">
        <day>13</day>
        <month>4</month>
        <year>2022</year>
      </date>
      <date date-type="corrected-typeset">
        <day>06</day>
        <month>5</month>
        <year>2022</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2022. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2022</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="btac270.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Motivation</title>
        <p>Rotated template matching is an efficient and versatile algorithm to analyze microscopy images, as it automates the detection of stereotypical structures, such as organelles that can appear at any orientation. Its performance however quickly degrades in noisy image data.</p>
      </sec>
      <sec id="s2">
        <title>Results</title>
        <p>We introduce Steer’n’Detect, an ImageJ plugin implementing a recently published algorithm to detect patterns of interest at any orientation with high accuracy from a single template in 2D images. Steer’n’Detect provides a faster and more robust substitute to template matching. By adapting to the statistics of the image background, it guarantees accurate results even in the presence of noise. The plugin comes with an intuitive user interface facilitating results analysis and further post-processing.</p>
      </sec>
      <sec id="s3">
        <title>Availability and implementation</title>
        <p><ext-link xlink:href="https://github.com/Biomedical-Imaging-Group/Steer-n-Detect" ext-link-type="uri">https://github.com/Biomedical-Imaging-Group/Steer-n-Detect</ext-link>.</p>
      </sec>
      <sec id="s5">
        <title>Supplementary information</title>
        <p><xref rid="sup1" ref-type="supplementary-material">Supplementary data</xref> are available at <italic toggle="yes">Bioinformatics</italic> online.</p>
      </sec>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Swiss National Science Foundation (SNSF)</institution>
          </institution-wrap>
        </funding-source>
        <award-id>P400P2_194364</award-id>
        <award-id>200020_184646/1</award-id>
        <award-id>205320_179069</award-id>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="3"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 Introduction</title>
    <p>Rotated template matching is commonly used when analyzing microscopy images of biological structures as it allows automating the detection of objects of interest, such as organelles, that may appear at any random orientation (<xref rid="btac270-B2" ref-type="bibr">Lucas <italic toggle="yes">et al.</italic>, 2021</xref>). This approach requires a single training example, giving it a strong edge over machine learning-based methods whenever objects of interest vary little in appearance. Template matching performance, however, degrades in the presence of background noise, resulting in erroneous and missed detections. Here, we present Steer’n’Detect, an ImageJ plugin implementing our recently published algorithm (<xref rid="btac270-B1" ref-type="bibr">Fageot <italic toggle="yes">et al.</italic>, 2021</xref>) for fast template detection at any orientation in 2D images, relying on steerable filters. Steer’n’Detect is more robust to noise and faster than rotated template matching, while remaining equivalently accurate in its orientation estimation. As such, Steer’n’Detect can reliably be used in 2D microscopy images with high levels of background noise, where template matching would perform poorly.</p>
  </sec>
  <sec>
    <title>2 Approach and implementation</title>
    <p>The principle of the algorithm implemented in Steer’n’Detect is explained in <xref rid="btac270-B1" ref-type="bibr">Fageot <italic toggle="yes">et al.</italic> (2021)</xref>. We hereafter recall the main ideas of this approach.</p>
    <p>We model the input image as several copies of a template <italic toggle="yes">T</italic> occurring at various and unknown positions and orientations in some additive background noise <italic toggle="yes">S</italic>. Our method aims at recovering these unknown positions and orientations. The background noise <italic toggle="yes">S</italic> is assumed to be a 2D self-similar isotropic Gaussian random field, which is an appropriate model for microscopy images (<xref rid="btac270-B4" ref-type="bibr">Sage <italic toggle="yes">et al.</italic>, 2005</xref>). The power spectrum of <italic toggle="yes">S</italic> is then given by <inline-formula id="IE1"><mml:math id="IM1" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mo>σ</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:msup><mml:mrow><mml:mo>ω</mml:mo></mml:mrow><mml:mo>γ</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula>, where the variance <inline-formula id="IE2"><mml:math id="IM2" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mo>σ</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> reflects the noise intensity and the exponent <inline-formula id="IE3"><mml:math id="IM3" display="inline" overflow="scroll"><mml:mrow><mml:mo>γ</mml:mo><mml:mo>≥</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> characterizes its smoothness (higher values result in smoother noise). A detector can efficiently retrieve occurrences of <italic toggle="yes">T</italic> in the image if it responds strongly to the template while being maximally insensitive to the background noise <italic toggle="yes">S</italic>. Since we assume the template of interest <italic toggle="yes">T</italic> to be present in the image at an arbitrary unknown orientation, the detector must also be able to rotate at low computational cost. Taking this into account, the algorithm implemented in Steer’n’Detect designs steerable filters that achieve optimal detection performance while minimizing response to noise in a process called spectral shaping. Steerable filters have been used for the detection of symmetrical and directional structures in biological images (<xref rid="btac270-B3" ref-type="bibr">Püspöki <italic toggle="yes">et al.</italic>, 2016</xref>) and were recently demonstrated to be powerful tools to design detectors based on a template (<xref rid="btac270-B5" ref-type="bibr">Zhao and Blu, 2020</xref>). They can efficiently approximate any template up to a user-defined accuracy and can be continuously rotated at any arbitrary angle, resulting in computationally light detection pipelines.</p>
    <p>In Steer’n’Detect, the implementation of this approach involves of the following steps:
</p>
    <list list-type="order">
      <list-item>
        <p><bold>Detector design</bold>: The steerable detector is automatically constructed from a single template <italic toggle="yes">T</italic> provided as input. Spectral shaping is performed by tuning a self-similarity parameter <italic toggle="yes">γ</italic> to the image background <italic toggle="yes">S</italic>. Technical details, including the full derivation of the detector, are provided in (<xref rid="btac270-B1" ref-type="bibr">Fageot <italic toggle="yes">et al.</italic>, 2021</xref>). The value of <italic toggle="yes">γ</italic> can be estimated by different procedures, but getting it exactly right is not critical as good results can be obtained even for imprecise guesses (see <xref rid="btac270-F1" ref-type="fig">Fig. 1A</xref>).</p>
      </list-item>
      <list-item>
        <p><bold>Image processing</bold>: The orientation resulting in the strongest detector’s response, as well as the magnitude of the response itself, are computed for each pixel of the input image through an optimization process. At any location in the image, the output reflects to which extent the pattern of interest is present (through the magnitude of the detector’s response) and how it is oriented. Local non-maximum suppression is applied on the detector’s magnitude response map to prevent repeated detection of the same template occurrence.</p>
      </list-item>
      <list-item>
        <p><bold>Selection</bold> <bold>and</bold> <bold>visualization</bold>: Detection results meeting a user-defined quality threshold based on the magnitude of the detector’s response can be explored, visualized and exported for further processing.</p>
      </list-item>
    </list>
    <fig position="float" id="btac270-F1">
      <label>Fig. 1.</label>
      <caption>
        <p>(<bold>A</bold>) Performance comparison of template matching, adapted steerable filters (no spectral shaping), and Steer’n’Detect with <italic toggle="yes">γ</italic> = 1 (optimal) and <inline-formula id="IE4"><mml:math id="IM4" display="inline" overflow="scroll"><mml:mrow><mml:mo>γ</mml:mo><mml:mo>=</mml:mo><mml:mn>0.5</mml:mn></mml:mrow></mml:math></inline-formula> (suboptimal), measured by the Jaccard index <italic toggle="yes">J</italic> as a function of the amount of background noise (standard deviation <italic toggle="yes">σ</italic>). (<bold>B</bold>) Performance comparison of rotated template matching, adapted steerable filters (no spectral shaping) and Steer’n’Detect, measured by the Jaccard index <italic toggle="yes">J</italic> as a function of run time, for a fixed background signal (<italic toggle="yes">σ</italic> = 5). (<bold>C</bold>) Detection of rod-shaped bacteria with Steer’n’Detect (synthetic image degraded by self-similar Gaussian random field background noise). (<bold>D</bold>) Detection of spermatozoan axoneme with Steer’n’Detect (transmission electron microscopy image) (Reused from <ext-link xlink:href="http://www.cellimagelibrary.org/images/35970" ext-link-type="uri">http://www.cellimagelibrary.org/images/35970</ext-link>). Top left: image crop used as template; bottom left: resulting detector; right: detection results</p>
      </caption>
      <graphic xlink:href="btac270f1" position="float"/>
    </fig>
  </sec>
  <sec>
    <title>3 Results and validation</title>
    <p>Steer’n’Detect is best applicable to detect occurrences of a template repeated in 2D images at arbitrary location and orientation, and possibly buried in background noise. Steer’n’Detect can thus be used as a faster alternative to rotated template matching, and produce accurate results when the latter fails due to noise. To demonstrate this, we produced 480 × 480 synthetic images containing 100 occurrences of simulated rod-shaped structures akin to <italic toggle="yes">Escherichia</italic> <italic toggle="yes">coli</italic> bacteria or <italic toggle="yes">Schizosaccharomyces</italic> <italic toggle="yes">pombe</italic> yeasts. The position of the objects to be detected and their orientations are known as ground-truth. We then degrade these synthetic data with background noise based on the Gaussian random field introduced in Section 2. Using a linear assignment algorithm to pair the detections with ground-truth locations, we consider a detection to be a correct if its distance to the closest template occurrence is within a 5 pixels range. We then use the Jaccard index to quantify the overall detection performance and report it (in percentage) as a function of the amount of background noise in <xref rid="btac270-F1" ref-type="fig">Figure 1A</xref>, and as a function of algorithmic run time in <xref rid="btac270-F1" ref-type="fig">Figure 1B</xref>. Our experiment shows that, in the presence of background noise, the Steer’n’Detect provides better results than both template matching and adapted steerable filters, even when the self-similarity parameter is left to its default value. Template matching swept through all orientations slightly outperforms classical steerable filters (no spectral shaping) in low noise regime, since they only provide a rough approximation of the template. However, computation time is an order of magnitude longer for template matching than for any considered approach.</p>
    <p>In addition to detection performance, we also quantitatively compare the angular accuracy as a function of run time. To be able to focus solely on orientation estimation, we generate synthetic images containing a single rod-shaped structure at their center, rotated at a random angle. We then corrupt these images with background noise as previously. For each algorithm, we report the root mean square (RMS) difference between the retrieved orientation estimates and their corresponding ground truth values after 60 s of run time. We obtain an RMS difference of 0.515° for template matching and 0.343° for Steer’n’Detect. A comprehensive performance assessment and validation of the algorithm can be found in <xref rid="btac270-B1" ref-type="bibr">Fageot <italic toggle="yes">et al.</italic> (2021)</xref>.</p>
    <p>Finally, in <xref rid="btac270-F1" ref-type="fig">Figure 1D</xref>, we illustrate Steer’n’Detect results on real biological data: our method is able to accurately detect axoneme (and their orientation) on a transmission electron microscopy image of a <italic toggle="yes">Culex</italic> mosquito spermatozoa flagellum (Cell Image Library, CIL:35970).</p>
  </sec>
  <sec sec-type="data-availability">
    <title>Data availability</title>
    <p>The data underlying this article are available at <ext-link xlink:href="http://bigwww.epfl.ch/algorithms/steer_n_detect/" ext-link-type="uri">http://bigwww.epfl.ch/algorithms/steer_n_detect/</ext-link> and were partially derived from CC-BY sources from the Cell Image Library (cil:35970).</p>
  </sec>
  <sec>
    <title>Funding</title>
    <p>This work was supported by EMBL internal funding (V.U.) and the Swiss National Science Foundation (SNSF) [P400P2_194364 to J.F., 200020_184646/1 to M.U., 205320_179069 to A.D.].</p>
    <p><italic toggle="yes">Conflict of Interest</italic>: none declared.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material id="sup1" position="float" content-type="local-data">
      <label>btac270_Supplementary_Data</label>
      <media xlink:href="btac270_supplementary_data.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="btac270-B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fageot</surname><given-names>J.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2021</year>) <article-title>Principled design and implementation of steerable detectors</article-title>. <source>IEEE Trans. Image Process</source>., <volume>30</volume>, <fpage>4465</fpage>–<lpage>4478</lpage>.<pub-id pub-id-type="pmid">33861703</pub-id></mixed-citation>
    </ref>
    <ref id="btac270-B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lucas</surname><given-names>B.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2021</year>) <article-title>Locating macromolecular assemblies in cells by 2d template matching with cistem</article-title>. <source>Elife</source>, <volume>10</volume>, <fpage>e68946</fpage>.<pub-id pub-id-type="pmid">34114559</pub-id></mixed-citation>
    </ref>
    <ref id="btac270-B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Püspöki</surname><given-names>Z.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2016</year>) <article-title>Transforms and operators for directional bioimage analysis: a survey</article-title>. <source>Focus Bio-Image Inf</source>., <volume>219</volume>, <fpage>69</fpage>–<lpage>93</lpage>.</mixed-citation>
    </ref>
    <ref id="btac270-B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sage</surname><given-names>D.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2005</year>) <article-title>Automatic tracking of individual fluorescence particles: application to the study of chromosome dynamics</article-title>. <source>IEEE Trans. Image Process</source>., <volume>14</volume>, <fpage>1372</fpage>–<lpage>1383</lpage>.<pub-id pub-id-type="pmid">16190472</pub-id></mixed-citation>
    </ref>
    <ref id="btac270-B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhao</surname><given-names>T.</given-names></string-name>, <string-name><surname>Blu</surname><given-names>T.</given-names></string-name></person-group> (<year>2020</year>) <article-title>The Fourier–Argand representation: an optimal basis of steerable patterns</article-title>. <source>IEEE Trans. On Image Process</source>., <volume>29</volume>, <fpage>1</fpage>–<lpage>6371</lpage>.</mixed-citation>
    </ref>
  </ref-list>
</back>
