<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Brief Bioinform</journal-id>
    <journal-id journal-id-type="iso-abbrev">Brief Bioinform</journal-id>
    <journal-id journal-id-type="publisher-id">bib</journal-id>
    <journal-title-group>
      <journal-title>Briefings in Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1467-5463</issn>
    <issn pub-type="epub">1477-4054</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">9487607</article-id>
    <article-id pub-id-type="pmid">35988923</article-id>
    <article-id pub-id-type="doi">10.1093/bib/bbac343</article-id>
    <article-id pub-id-type="publisher-id">bbac343</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Problem Solving Protocol</subject>
      </subj-group>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI01060</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Benchmarks in antimicrobial peptide prediction are biased due to the selection of negative data</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0001-6576-9054</contrib-id>
        <name>
          <surname>Sidorczuk</surname>
          <given-names>Katarzyna</given-names>
        </name>
        <aff><institution>University of Wrocław, Faculty of Biotechnology</institution>, <country country="PL">Poland</country></aff>
        <xref rid="afn1" ref-type="author-notes"/>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0001-9077-439X</contrib-id>
        <name>
          <surname>Gagat</surname>
          <given-names>Przemysław</given-names>
        </name>
        <aff><institution>University of Wrocław, Faculty of Biotechnology</institution>, <country country="PL">Poland</country></aff>
        <xref rid="afn1" ref-type="author-notes"/>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0001-6218-9804</contrib-id>
        <name>
          <surname>Pietluch</surname>
          <given-names>Filip</given-names>
        </name>
        <aff><institution>University of Wrocław, Faculty of Biotechnology</institution>, <country country="PL">Poland</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-7187-6988</contrib-id>
        <name>
          <surname>Kała</surname>
          <given-names>Jakub</given-names>
        </name>
        <aff><institution>Warsaw University of Technology, Faculty of Mathematics and Information Science</institution>, <country country="PL">Poland</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0003-0925-1909</contrib-id>
        <name>
          <surname>Rafacz</surname>
          <given-names>Dominik</given-names>
        </name>
        <aff><institution>Warsaw University of Technology, Faculty of Mathematics and Information Science</institution>, <country country="PL">Poland</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-3213-2484</contrib-id>
        <name>
          <surname>Bąkała</surname>
          <given-names>Laura</given-names>
        </name>
        <aff><institution>Warsaw University of Technology, Faculty of Mathematics and Information Science</institution>, <country country="PL">Poland</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0003-3466-8933</contrib-id>
        <name>
          <surname>Słowik</surname>
          <given-names>Jadwiga</given-names>
        </name>
        <aff><institution>Warsaw University of Technology, Faculty of Mathematics and Information Science</institution>, <country country="PL">Poland</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-8145-579X</contrib-id>
        <name>
          <surname>Kolenda</surname>
          <given-names>Rafał</given-names>
        </name>
        <aff><institution>Quadram Institute Biosciences, Norwich Research Park</institution>, <addr-line>Norwich</addr-line>, <country country="GB">United Kingdom</country></aff>
        <aff><institution>Wrocław University of Environmental and Life Sciences, Faculty of Veterinary Medicine</institution>, <country country="PL">Poland</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-1441-6512</contrib-id>
        <name>
          <surname>Rödiger</surname>
          <given-names>Stefan</given-names>
        </name>
        <aff><institution>Brandenburg University of Technology Cottbus-Senftenberg, Faculty of Natural Sciences</institution>, <country country="DE">Germany</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-2482-5336</contrib-id>
        <name>
          <surname>Fingerhut</surname>
          <given-names>Legana C H W</given-names>
        </name>
        <aff><institution>Department of Molecular and Cell Biology, Centre for Tropical Bioinformatics and Molecular Biology, James Cook University</institution>, <country country="AU">Australia</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0001-6520-1397</contrib-id>
        <name>
          <surname>Cooke</surname>
          <given-names>Ira R</given-names>
        </name>
        <aff><institution>Department of Molecular and Cell Biology, Centre for Tropical Bioinformatics and Molecular Biology, James Cook University</institution>, <country country="AU">Australia</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0003-4855-497X</contrib-id>
        <name>
          <surname>Mackiewicz</surname>
          <given-names>Paweł</given-names>
        </name>
        <aff><institution>University of Wrocław, Faculty of Biotechnology</institution>, <country country="PL">Poland</country></aff>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0001-8926-582X</contrib-id>
        <name>
          <surname>Burdukiewicz</surname>
          <given-names>Michał</given-names>
        </name>
        <!--michalburdukiewicz@gmail.com-->
        <aff>
          <institution>Autonomous University of Barcelona, Institute of Biotechnology and Biomedicine</institution>
        </aff>
        <aff><institution>Medical University of Białystok, Clinical Research Centre</institution>, <country country="PL">Poland</country></aff>
        <xref rid="cor1" ref-type="corresp"/>
      </contrib>
    </contrib-group>
    <author-notes>
      <corresp id="cor1">Corresponding author: Michał Burdukiewicz; E-mail: <email>michalburdukiewicz@gmail.com</email></corresp>
      <fn id="afn1">
        <p>Katarzyna Sidorczuk and Przemysław Gagat contributed equally to this work.</p>
      </fn>
    </author-notes>
    <pub-date pub-type="collection">
      <month>9</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2022-08-21">
      <day>21</day>
      <month>8</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>21</day>
      <month>8</month>
      <year>2022</year>
    </pub-date>
    <volume>23</volume>
    <issue>5</issue>
    <elocation-id>bbac343</elocation-id>
    <history>
      <date date-type="received">
        <day>30</day>
        <month>5</month>
        <year>2022</year>
      </date>
      <date date-type="rev-recd">
        <day>7</day>
        <month>7</month>
        <year>2022</year>
      </date>
      <date date-type="accepted">
        <day>25</day>
        <month>7</month>
        <year>2022</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2022. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2022</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="bbac343.pdf"/>
    <abstract>
      <title>Abstract</title>
      <p>Antimicrobial peptides (AMPs) are a heterogeneous group of short polypeptides that target not only microorganisms but also viruses and cancer cells. Due to their lower selection for resistance compared with traditional antibiotics, AMPs have been attracting the ever-growing attention from researchers, including bioinformaticians. Machine learning represents the most cost-effective method for novel AMP discovery and consequently many computational tools for AMP prediction have been recently developed. In this article, we investigate the impact of negative data sampling on model performance and benchmarking. We generated 660 predictive models using 12 machine learning architectures, a single positive data set and 11 negative data sampling methods; the architectures and methods were defined on the basis of published AMP prediction software. Our results clearly indicate that similar training and benchmark data set, i.e. produced by the same or a similar negative data sampling method, positively affect model performance. Consequently, all the benchmark analyses that have been performed for AMP prediction models are significantly biased and, moreover, we do not know which model is the most accurate. To provide researchers with reliable information about the performance of AMP predictors, we also created a web server AMPBenchmark for fair model benchmarking. AMPBenchmark is available at <ext-link xlink:href="http://BioGenies.info/AMPBenchmark" ext-link-type="uri">http://BioGenies.info/AMPBenchmark</ext-link>.</p>
    </abstract>
    <kwd-group>
      <kwd>antimicrobial peptides</kwd>
      <kwd>benchmarks</kwd>
      <kwd>machine learning</kwd>
      <kwd>negative sampling</kwd>
      <kwd>prediction</kwd>
      <kwd>reproducibility</kwd>
    </kwd-group>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Warsaw University of Technology</institution>
            <institution-id institution-id-type="DOI">10.13039/501100004421</institution-id>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>European Union-NextGenerationEU</institution>
          </institution-wrap>
        </funding-source>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="12"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec id="sec1">
    <title>Introduction</title>
    <p>Antimicrobial peptides (AMPs) are short polypeptides, generally composed of up to 50 amino acids that are widespread in all forms of life, from microorganisms, i.e. bacteria, archaeans and one-celled eukaryotes, to multicellulars [<xref rid="ref1" ref-type="bibr">1</xref>, <xref rid="ref2" ref-type="bibr">2</xref>]. In microorganisms, they participate in self-protection and microbial competition [<xref rid="ref3" ref-type="bibr">3</xref>, <xref rid="ref4" ref-type="bibr">4</xref>]; in multicellulars, they are part of the first line of defence against microorganisms but also target viruses and cancer cells [<xref rid="ref5" ref-type="bibr">5</xref>, <xref rid="ref6" ref-type="bibr">6</xref>]. Despite their diversity in the primary amino acid sequence, AMPs are rich in cationic and hydrophobic residues. The positive charge and hydrophobicity allow them to fold into amphipathic secondary structures that preferentially disrupt negatively charged microbial/cancer cell membranes but not the healthy eukaryotic ones; the latter contain stabilizing cholesterol and their outer leaflet is composed of neutral phospholipids. AMPs can trigger transient membrane disruption by forming pores and micellization but, depending on the concentration, they may lead to cell death by osmotic shock [<xref rid="ref7" ref-type="bibr">7–10</xref>]. The alternative mechanisms of action, especially for the larger AMPs (about 100 amino acids long or longer), include binding to specific cytosolic macromolecules and thereby inhibiting synthesis of proteins, nucleic acids and components of the cell wall [<xref rid="ref11" ref-type="bibr">11</xref>, <xref rid="ref12" ref-type="bibr">12</xref>].</p>
    <p>AMPs have also been demonstrated to have lower selection for resistance compared with traditional antibiotics. A traditional antibiotic specifically targets a single enzyme but AMPs, most of all, interact non-specifically with many components of the cell membrane. This makes it more difficult for bacteria to develop resistance against them [<xref rid="ref13" ref-type="bibr">13–15</xref>].</p>
    <p>According to the World Health Organization, the antibiotic resistance is currently behind the death of at least 700 000 people each year; however, the forecast of the death toll of 10 million annually by 2050 makes the race for alternative therapeutics of the utmost importance [<xref rid="ref16" ref-type="bibr">16</xref>]. In light of their medical potential, AMPs are viewed as hopeful candidates for further experimental research. Consequently, we have recently observed a boom in computational tools for AMP prediction with the machine learning algorithms leading the way [<xref rid="ref17" ref-type="bibr">17</xref>].</p>
    <p>Traditionally, biological problems have first been approached by conventional, i.e. non-deep machine learning-based methods, such as random forests (RF) or support vector machines (SVM), which were then followed by more complex deep learning algorithms [<xref rid="ref17" ref-type="bibr">17</xref>]. In order to produce reliable predictions, the algorithms first require labelled training data to build a predictive model. The training data include a positive and a negative data set, in our case AMPs and non-AMPs, respectively. In order to make the sequences readable for machine learning, they have to be transformed into informative features (feature vectors) and this process is known as feature extraction. Depending on the method of feature extraction, the obtained feature space may require additional reduction, and consequently an appropriate feature selection method is applied, e.g. for AmpGram the initial feature set amounted to 33 620 n-grams (amino acid motifs of n elements) but was decreased with Quick Permutation Test to 13 087 most informative descriptors [<xref rid="ref18" ref-type="bibr">18</xref>].</p>
    <p>There are many databases with thousands of experimentally validated AMP sequences, such as DBAASP [<xref rid="ref19" ref-type="bibr">19</xref>], APD [<xref rid="ref20" ref-type="bibr">20</xref>], CAMP [<xref rid="ref21" ref-type="bibr">21</xref>], DRAMP [<xref rid="ref22" ref-type="bibr">22</xref>] or dbAMP [<xref rid="ref23" ref-type="bibr">23</xref>]; therefore, it is possible to create a representative positive data set. However, the authors of AMP classifiers, except for ampir [<xref rid="ref24" ref-type="bibr">24</xref>], do not take into account that there might be two types of sequences deposited in these databases: mature AMPs and precursor AMPs with cleavable N-terminal signal peptides; AMPs are mostly secretory proteins. Since the databases seem to contain generally mature AMPs, and moreover the developers often restrict the sequence length in their data sets, the algorithms are mainly trained on mature AMPs. Consequently, they are good at detecting mature AMPs but might have problems classifying longer sequences, including the precursor proteins [<xref rid="ref25" ref-type="bibr">25</xref>].</p>
    <p>The issue of identification of precursor and longer AMPs can be satisfactorily addressed because the data about these sequences are available in public databases, e.g. in UniProt [<xref rid="ref26" ref-type="bibr">26</xref>]. The real problem with AMP prediction lies with the negative data set as there are hardly any sequences annotated as non-AMPs. Interestingly, the lack of reliable negative samples also concerns other areas related to bioinformatics, e.g. prediction of disease genes [<xref rid="ref27" ref-type="bibr">27</xref>, <xref rid="ref28" ref-type="bibr">28</xref>], microRNAs [<xref rid="ref29" ref-type="bibr">29</xref>], bacterial virulence factors [<xref rid="ref30" ref-type="bibr">30</xref>]; identification of protein–protein [<xref rid="ref31" ref-type="bibr">31</xref>], protein–RNA/DNA [<xref rid="ref32" ref-type="bibr">32</xref>, <xref rid="ref33" ref-type="bibr">33</xref>] and protein–drug interaction sites [<xref rid="ref32" ref-type="bibr">32</xref>, <xref rid="ref34" ref-type="bibr">34</xref>]; as well as inferring protein sequence-function relationships [<xref rid="ref35" ref-type="bibr">35</xref>].</p>
    <p>In all these cases, the developers have to resort to: (i) one-class classification, (ii) positive-unlabelled learning or (iii) to somehow build a negative data set. In the first case, the model is trained on the positive sample, whereas in the second on the positive and unlabelled data; the unlabelled set includes both positive and negative examples. These two approaches aim at solving the problem of the negative sample by either not using it at all or applying a wide variety of strategies to obtain negative cases from the unlabelled set based on the positive sample, e.g. using distance measures (for details, see [<xref rid="ref36" ref-type="bibr">36</xref>, <xref rid="ref37" ref-type="bibr">37</xref>]). Interestingly, neither the one-class classification nor the positive-unlabelled learning have attracted the attention of developers working on AMP prediction. The majority of them created their negative sets by performing non-probability sampling on sequences deposited in UniProt [<xref rid="ref26" ref-type="bibr">26</xref>] or other databases (e.g. PDB [<xref rid="ref38" ref-type="bibr">38</xref>]) though they do not define it as such. In this approach, the negative examples are selected on the basis of clearly defined criteria dictated by the researcher, and these criteria represent a sampling method (for details, see section Materials and methods and <xref rid="TB1" ref-type="table">Table 1</xref>). In contrast to positive-unlabelled learning, dividing UniProt sequences between AMPs and non-AMPs does not require any complex methodology and is independent of the positive sample but for the length and number of sequences for some sampling methods. It is simply made by sequence filtering and then randomly selecting peptides for the final negative data set. For clarity purposes in this article, the name of the sampling method is always preceded by an abbreviation: SM (sampling method), TSM (sampling method used to generate the training set) or BSM (sampling method used to generate the benchmark set) and colon, e.g. SM:AmpGram, TSM:AmpGram and BSM:AmpGram, respectively.</p>
    <table-wrap position="float" id="TB1">
      <label>Table 1</label>
      <caption>
        <p>A comprehensive summary of the negative sampling methods implemented for AMP prediction</p>
      </caption>
      <table frame="hsides" rules="groups">
        <colgroup span="1">
          <col align="left" span="1"/>
          <col align="left" span="1"/>
          <col align="left" span="1"/>
          <col align="left" span="1"/>
          <col align="left" span="1"/>
          <col align="left" span="1"/>
          <col align="left" span="1"/>
        </colgroup>
        <thead>
          <tr>
            <th rowspan="1" colspan="1">Sampling method</th>
            <th rowspan="1" colspan="1">Excluded keywords</th>
            <th rowspan="1" colspan="1">Sequence lengths</th>
            <th rowspan="1" colspan="1">CD-HIT</th>
            <th rowspan="1" colspan="1">Additional filtering</th>
            <th rowspan="1" colspan="1">Balanced classes</th>
            <th rowspan="1" colspan="1">Reference</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td rowspan="1" colspan="1">Wang et al.</td>
            <td rowspan="1" colspan="1">secreted, antimicrobial</td>
            <td rowspan="1" colspan="1">similar to the length distribution of positive dataset</td>
            <td rowspan="1" colspan="1">0.7</td>
            <td rowspan="1" colspan="1"> </td>
            <td rowspan="1" colspan="1">no</td>
            <td rowspan="1" colspan="1">[<xref rid="ref41" ref-type="bibr">41</xref>]</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">CS-AMPpred</td>
            <td rowspan="1" colspan="1">antimicrobial</td>
            <td rowspan="1" colspan="1">16 - 90</td>
            <td rowspan="1" colspan="1">0.4</td>
            <td rowspan="1" colspan="1"> </td>
            <td rowspan="1" colspan="1">yes</td>
            <td rowspan="1" colspan="1">[<xref rid="ref42" ref-type="bibr">42</xref>]</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">iAMP-2L</td>
            <td rowspan="1" colspan="1">antimicrobial, antibiotic, fungicide, defensin</td>
            <td rowspan="1" colspan="1">5–100</td>
            <td rowspan="1" colspan="1">0.4</td>
            <td rowspan="1" colspan="1"> </td>
            <td rowspan="1" colspan="1">no</td>
            <td rowspan="1" colspan="1">[<xref rid="ref43" ref-type="bibr">43</xref>]</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">Gabere&amp;Noble (DAMPD dataset)</td>
            <td rowspan="1" colspan="1">antimicrobial</td>
            <td rowspan="1" colspan="1">equal to the length distribution of positive dataset</td>
            <td rowspan="1" colspan="1">no</td>
            <td rowspan="1" colspan="1">localization: golgi, cytoplasm, endoplasmic reticulum or mitochondria</td>
            <td rowspan="1" colspan="1">no</td>
            <td rowspan="1" colspan="1">[<xref rid="ref25" ref-type="bibr">25</xref>]</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">AMAP</td>
            <td rowspan="1" colspan="1">antimicrobial</td>
            <td rowspan="1" colspan="1">similar to the length distribution of positive dataset</td>
            <td rowspan="1" colspan="1">0.4</td>
            <td rowspan="1" colspan="1"> </td>
            <td rowspan="1" colspan="1">no</td>
            <td rowspan="1" colspan="1">[<xref rid="ref44" ref-type="bibr">44</xref>]</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">AMPScanner V2</td>
            <td rowspan="1" colspan="1">antimicrobial, antibiotic, antiviral, fungicide, secreted</td>
            <td rowspan="1" colspan="1">equal to the length distribution of positive dataset</td>
            <td rowspan="1" colspan="1">no</td>
            <td rowspan="1" colspan="1">localization: cytoplasm; removed sequences similar to any AMPs with BLAT [<xref rid="ref45" ref-type="bibr">45</xref>]</td>
            <td rowspan="1" colspan="1">yes</td>
            <td rowspan="1" colspan="1">[<xref rid="ref46" ref-type="bibr">46</xref>]</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">dbAMP</td>
            <td rowspan="1" colspan="1">transmembrane, toxin, secreted, defensin, antimicrobial, antibiotic, antiviral, fungicide</td>
            <td rowspan="1" colspan="1">10–100</td>
            <td rowspan="1" colspan="1">0.4</td>
            <td rowspan="1" colspan="1"> </td>
            <td rowspan="1" colspan="1">no</td>
            <td rowspan="1" colspan="1">[<xref rid="ref23" ref-type="bibr">23</xref>]</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">Witten&amp;Witten</td>
            <td rowspan="1" colspan="1">antimicrobial, antibiotic, antiviral, fungicide, secreted</td>
            <td rowspan="1" colspan="1">equal to the length distribution of positive dataset</td>
            <td rowspan="1" colspan="1">0.4</td>
            <td rowspan="1" colspan="1">localization: cytoplasm; only cysteine-free substrings</td>
            <td rowspan="1" colspan="1">yes</td>
            <td rowspan="1" colspan="1">[<xref rid="ref47" ref-type="bibr">47</xref>]</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">AmpGram</td>
            <td rowspan="1" colspan="1">antimicrobial, antibacterial, antiviral, fungicide, secreted, transit peptide</td>
            <td rowspan="1" colspan="1">equal to the length distribution of positive dataset</td>
            <td rowspan="1" colspan="1">no</td>
            <td rowspan="1" colspan="1"> </td>
            <td rowspan="1" colspan="1">yes</td>
            <td rowspan="1" colspan="1">[<xref rid="ref18" ref-type="bibr">18</xref>]</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">ampir-mature</td>
            <td rowspan="1" colspan="1">antimicrobial</td>
            <td rowspan="1" colspan="1">10–40</td>
            <td rowspan="1" colspan="1">0.9</td>
            <td rowspan="1" colspan="1"> </td>
            <td rowspan="1" colspan="1">no</td>
            <td rowspan="1" colspan="1">[<xref rid="ref24" ref-type="bibr">24</xref>]</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">AMPlify</td>
            <td rowspan="1" colspan="1">antimicrobial, antibiotic, defence, defensin, bacteriocin, fungicide</td>
            <td rowspan="1" colspan="1">equal to the length distribution of positive dataset</td>
            <td rowspan="1" colspan="1">no</td>
            <td rowspan="1" colspan="1">removed potential AMPs<sup>*</sup></td>
            <td rowspan="1" colspan="1">yes</td>
            <td rowspan="1" colspan="1">[<xref rid="ref48" ref-type="bibr">48</xref>]</td>
          </tr>
        </tbody>
      </table>
      <table-wrap-foot>
        <fn id="tblfn1">
          <p><sup>*</sup>UniProt sequences with keywords: antimicrobial, antibiotic, defence, defensin, bacteriocin, fungicide</p>
        </fn>
      </table-wrap-foot>
    </table-wrap>
    <p>The aim of this study was to elaborate on the impact of negative data sampling on model performance and benchmarking. We decided to explore this issue because each developer of an AMP predictor tested only one sampling method to build the optimal non-AMP class despite knowing that machine learning models heavily depend on the data sets they are trained on. They all overlooked the fact that various sampling methods could generate statistically different samples, thereby affecting the predictive power of their models. Moreover, and more importantly, we investigated how machine learning architectures perform when they are trained on a given data set but tested on a different one, a commonplace in model benchmarking (<xref rid="f1" ref-type="fig">Figure 1</xref><bold>A</bold>). This particular issue is of vital importance not only for the comparison of AMP predictors but for the evaluation of all machine learning models in general. We define the machine learning architecture as an approach to solve the problem of AMP prediction with all its parameters involved in the machine learning cycle. The architectures for our study were developed based on published models that we were able to reuse or reimplement; some might slightly deviate from the original methods (for details, see section Materials and methods and <xref rid="TB2" ref-type="table">Table 2</xref>, <xref rid="sup1" ref-type="supplementary-material">S2</xref>). For clarity purpose, the name of a given architecture always begins with a letter ‘A’ and colon, e.g. A:AmpGram. By the term machine learning model, we understand one specific instance of a given architecture, i.e. an architecture trained on the same positive and one of negative samples. Consequently, what we did was to generate 660 machine learning models using (i) 12 defined architectures, (ii) the same positive training data set and (iii) 11 different negative sampling methods each run five times (<xref rid="f1" ref-type="fig">Figure 1</xref><bold>B</bold>). To our knowledge, this was the first kind of such a research project undertaken, and moreover on such a scale.</p>
    <table-wrap position="float" id="TB2">
      <label>Table 2</label>
      <caption>
        <p>A comprehensive summary of the implemented architectures for AMP prediction</p>
      </caption>
      <table frame="hsides" rules="groups">
        <colgroup span="1">
          <col align="left" span="1"/>
          <col align="left" span="1"/>
          <col align="left" span="1"/>
          <col align="left" span="1"/>
          <col align="left" span="1"/>
          <col align="left" span="1"/>
          <col align="left" span="1"/>
          <col align="left" span="1"/>
        </colgroup>
        <thead>
          <tr>
            <th rowspan="1" colspan="1">Type</th>
            <th rowspan="1" colspan="1">Architecture</th>
            <th rowspan="1" colspan="1">Year</th>
            <th rowspan="1" colspan="1">Feature space size</th>
            <th rowspan="1" colspan="1">Feature extraction</th>
            <th rowspan="1" colspan="1">Feature selection</th>
            <th rowspan="1" colspan="1">Algorithm</th>
            <th rowspan="1" colspan="1">Reference</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td rowspan="1" colspan="1">Deep learning-based architectures</td>
            <td rowspan="1" colspan="1">AMPScanner V2</td>
            <td rowspan="1" colspan="1">2018</td>
            <td rowspan="1" colspan="1">128</td>
            <td rowspan="1" colspan="1">Embedding</td>
            <td rowspan="1" colspan="1">none</td>
            <td rowspan="1" colspan="1">DNN with convolutional, maximal pooling and LSTM layers</td>
            <td rowspan="1" colspan="1">[<xref rid="ref46" ref-type="bibr">46</xref>]</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1"> </td>
            <td rowspan="1" colspan="1">Deep-AmPEP30</td>
            <td rowspan="1" colspan="1">2020</td>
            <td rowspan="1" colspan="1">86</td>
            <td rowspan="1" colspan="1">PseKRAAC</td>
            <td rowspan="1" colspan="1">none</td>
            <td rowspan="1" colspan="1">CNN with two convolutional layers, two maximum pooling layers, and one fully connected hidden layer</td>
            <td rowspan="1" colspan="1">[<xref rid="ref49" ref-type="bibr">49</xref>]</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">Non-deep learning-based architectures</td>
            <td rowspan="1" colspan="1">CS-AMPpred</td>
            <td rowspan="1" colspan="1">2012</td>
            <td rowspan="1" colspan="1">9</td>
            <td rowspan="1" colspan="1"><inline-formula><tex-math notation="LaTeX" id="ImEquation1">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\alpha $\end{document}</tex-math></inline-formula>-helix, <inline-formula><tex-math notation="LaTeX" id="ImEquation2">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\alpha $\end{document}</tex-math></inline-formula>-helix propensity, <inline-formula><tex-math notation="LaTeX" id="ImEquation3">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\beta $\end{document}</tex-math></inline-formula>-sheet, loop formation, charge, hydrophobicity, flexibility, amphipathicity, hydrophobic moment</td>
            <td rowspan="1" colspan="1">PCA</td>
            <td rowspan="1" colspan="1">SVM</td>
            <td rowspan="1" colspan="1">[<xref rid="ref42" ref-type="bibr">42</xref>]</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1"> </td>
            <td rowspan="1" colspan="1">iAMP-2L</td>
            <td rowspan="1" colspan="1">2013</td>
            <td rowspan="1" colspan="1">40</td>
            <td rowspan="1" colspan="1">PseAAC</td>
            <td rowspan="1" colspan="1">none</td>
            <td rowspan="1" colspan="1">FKNN</td>
            <td rowspan="1" colspan="1">[<xref rid="ref43" ref-type="bibr">43</xref>]</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1"> </td>
            <td rowspan="1" colspan="1">SVM-LZ</td>
            <td rowspan="1" colspan="1">2015</td>
            <td rowspan="1" colspan="1">1000</td>
            <td rowspan="1" colspan="1">LZ complexity pairwise similarity scores</td>
            <td rowspan="1" colspan="1">none</td>
            <td rowspan="1" colspan="1">sequence alignment (blastp), SVM</td>
            <td rowspan="1" colspan="1">[<xref rid="ref50" ref-type="bibr">50</xref>]</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1"> </td>
            <td rowspan="1" colspan="1">MLAMP</td>
            <td rowspan="1" colspan="1">2016</td>
            <td rowspan="1" colspan="1">30</td>
            <td rowspan="1" colspan="1">PseAAC with grey model coefficients</td>
            <td rowspan="1" colspan="1">none</td>
            <td rowspan="1" colspan="1">RF</td>
            <td rowspan="1" colspan="1">[<xref rid="ref51" ref-type="bibr">51</xref>]</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1"> </td>
            <td rowspan="1" colspan="1">AmPEP</td>
            <td rowspan="1" colspan="1">2018</td>
            <td rowspan="1" colspan="1">23</td>
            <td rowspan="1" colspan="1">Selected distribution descriptors</td>
            <td rowspan="1" colspan="1">none</td>
            <td rowspan="1" colspan="1">RF</td>
            <td rowspan="1" colspan="1">[<xref rid="ref52" ref-type="bibr">52</xref>]</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1"> </td>
            <td rowspan="1" colspan="1">AMAP</td>
            <td rowspan="1" colspan="1">2019</td>
            <td rowspan="1" colspan="1">20</td>
            <td rowspan="1" colspan="1">AAC</td>
            <td rowspan="1" colspan="1">none</td>
            <td rowspan="1" colspan="1">SVM</td>
            <td rowspan="1" colspan="1">[<xref rid="ref44" ref-type="bibr">44</xref>]</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1"> </td>
            <td rowspan="1" colspan="1">AmPEPpy</td>
            <td rowspan="1" colspan="1">2020</td>
            <td rowspan="1" colspan="1">105</td>
            <td rowspan="1" colspan="1">CTD</td>
            <td rowspan="1" colspan="1">none</td>
            <td rowspan="1" colspan="1">RF</td>
            <td rowspan="1" colspan="1">[<xref rid="ref53" ref-type="bibr">53</xref>]</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1"> </td>
            <td rowspan="1" colspan="1">MACREL</td>
            <td rowspan="1" colspan="1">2020</td>
            <td rowspan="1" colspan="1">22</td>
            <td rowspan="1" colspan="1">relative position of the first occurrence of residues in three groups of amino acids defined by their free energy of transition in a peptide from a random coil in aqueous environment to an organized helical structure in a lipid phase, solvent accessibility, AAC, charge and solubility, instability, aliphaticity, propensity to bind to membranes, hydrophobicity</td>
            <td rowspan="1" colspan="1">none</td>
            <td rowspan="1" colspan="1">RF</td>
            <td rowspan="1" colspan="1">[<xref rid="ref54" ref-type="bibr">54</xref>]</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1"> </td>
            <td rowspan="1" colspan="1">AmpGram</td>
            <td rowspan="1" colspan="1">2020</td>
            <td rowspan="1" colspan="1">32 835–33 612</td>
            <td rowspan="1" colspan="1">n-grams</td>
            <td rowspan="1" colspan="1">QuiPT</td>
            <td rowspan="1" colspan="1">RF</td>
            <td rowspan="1" colspan="1">[<xref rid="ref18" ref-type="bibr">18</xref>]</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1"> </td>
            <td rowspan="1" colspan="1">ampir</td>
            <td rowspan="1" colspan="1">2020</td>
            <td rowspan="1" colspan="1">27</td>
            <td rowspan="1" colspan="1">PseAAC, amphiphilicity, hydrophobicity, isoelectric point, molecular weight, net charge</td>
            <td rowspan="1" colspan="1">none</td>
            <td rowspan="1" colspan="1">SVM</td>
            <td rowspan="1" colspan="1">[<xref rid="ref24" ref-type="bibr">24</xref>]</td>
          </tr>
        </tbody>
      </table>
    </table-wrap>
  </sec>
  <sec id="sec2">
    <title>Materials and methods</title>
    <sec id="sec2a">
      <title>Data sets</title>
      <p>To create the positive data set, we used DBAASP v3.0 [<xref rid="ref19" ref-type="bibr">19</xref>], a manually curated database for experimentally verified peptides with antimicrobial properties. We selected sequences with activity against Gram positive or Gram negative bacteria. Next, we removed those with non-standard amino acids or shorter than five. We used CD-HIT version 4.8.1 [<xref rid="ref39" ref-type="bibr">39</xref>, <xref rid="ref40" ref-type="bibr">40</xref>] to reduce the redundancy and eliminated sequences with the identity threshold higher than 90%. This threshold was most frequently used for the reduction of positive data in the algorithms selected for the reimplementation of negative sampling methods (<xref rid="sup1" ref-type="supplementary-material">Table S1</xref>). In total, we obtained 5190 AMP sequences. To prevent the information leakage, the positive data set was split, before sampling the negative set, into a training sample (80%, 4151 sequences) and a benchmark sample (20%, 1039 sequences).</p>
      <p>The negative data set used for sampling was created using sequences available in the UniProt database. The reviewed protein sequences (563 972) and their annotations were downloaded from the UniProtKB release 2020_06 [<xref rid="ref26" ref-type="bibr">26</xref>].</p>
      <p>We considered 26 methods of negative data sampling from literature (<xref rid="sup1" ref-type="supplementary-material">Table S2</xref>) and selected 11 well-described ones for reuse/reimplementation (<xref rid="TB1" ref-type="table">Table 1</xref>). Each method was run on the negative data set of UniProt sequences five times to create five replicates of the training and benchmark samples (<xref rid="sup1" ref-type="supplementary-material">Table S4</xref>, <xref rid="sup1" ref-type="supplementary-material">S5</xref>) to verify their repeatability. Some selected methods required modifications, e.g. removal of sequences with non-standard amino acids to make them readable for all architectures. We also took measures to prevent information leakage between the training and benchmark sets, especially for the sampling methods that did not depend on the positive data. The full description of changes is provided in the <xref rid="sup1" ref-type="supplementary-material">Supplementary Data</xref>.</p>
      <p>The selected sampling methods use combinations of keywords to search the negative data set of UniProt sequences. Generally the keywords are repetitive among the methods used. They allowed to filter out AMPs by naming their typical functions, e.g. ‘antimicrobial’, ‘antibacterial’, ‘antiviral’ and/or restrict the cellular compartment to cytoplasm since AMPs are mostly secretory proteins (<xref rid="TB1" ref-type="table">Table 1</xref>). The latter is, however, unfortunate because the predictive models focus then on differences between cytoplasmic and secretory peptides instead of detecting AMPs, i.e. they neglect the issue of (i) distinguishing AMPs from secretory non-AMPs and (ii) cytosolic AMPs. The number of the filtered-out sequences was small if only the function keywords were considered, e.g. about 1% of the negative data set of UniProt sequences for SM:CS-AMPPred, SM:AMAP and SM:iAMP-2L, but increased when the cytosolic or additional location, especially experimentally verified, was included to 65%, 70% and 98% for SM:Gabere&amp;Noble, SM:AMPScannerV2 and SM:Witten&amp;Witten, respectively.</p>
      <p>For five methods, SM:AmpGram, SM:AMPlify, SM: AMPScannerV2, SM:CS-AMPPred and SM:Witten&amp;Witten, the number of sequences in the negative sample depended on the positive one, i.e. the data sets were balanced. Two methods: SM:AMAP and SM:dbAMP generated only slightly imbalanced samples, the former due to the reduction of sequence redundancy with CD-HIT [<xref rid="ref40" ref-type="bibr">40</xref>] at the end of the sampling process but the latter by accident. The remaining methods produced imbalanced (SM:iAMP-2L, SM:Wang et. al) or highly imbalanced (SM:Gabere&amp;Noble) sets with the predominance of non-AMPs. The exception was SM:ampir-mature with minority of non-AMPs (<xref rid="TB1" ref-type="table">Table 1</xref>, <xref rid="sup1" ref-type="supplementary-material">S4</xref>, <xref rid="sup1" ref-type="supplementary-material">S5</xref>).</p>
      <p>Five negative sampling methods: SM:AmpGram, SM: AMPlify, SM:AMPScannerV2, SM:Gabere&amp;Noble and SM: Witten&amp;Witten produced non-AMPs that exactly matched in length peptides and proteins contained in the positive set, and they were mostly up to 50 amino acids long though the sequence maximum length was 190 amino acids. The negative samples of SM:AMAP and SM:Wang et. al were only similar in terms of length distribution to the AMP set because of CD-HIT [<xref rid="ref39" ref-type="bibr">39</xref>, <xref rid="ref40" ref-type="bibr">40</xref>] reduction at the end of sequence filtering. The SM:ampir-mature generated only short sequences, and each sequence length within the range of 10 to 40 amino acids was approximately equally represented (<xref rid="TB1" ref-type="table">Table 1</xref>, <xref rid="sup1" ref-type="supplementary-material">Figure S1</xref>). The other sampling methods focused on longer peptides and proteins though at the same time they rejected sequences longer than about 100 amino acids. These methods included SM:dbAMP, SM:CS-AMPPred and SM:iAMP-2L and their sequence length distribution resembled that of an upside-down isosceles triangle (<xref rid="TB1" ref-type="table">Table 1</xref>, <xref rid="sup1" ref-type="supplementary-material">Figure S1</xref>).</p>
      <p>All the negative data sampling methods generating sets with equal or similar length distribution to the positive sample selected their non-AMPs from peptide/protein fragment or fragments, while the other methods from uncut sequences of the negative UniProt data set.</p>
      <p>In order to avoid overrepresentation of highly similar sequences in the non-AMP samples, we used the clustering algorithm CD-HIT version 4.8.1 [<xref rid="ref40" ref-type="bibr">40</xref>] for seven sampling methods according to their description. We removed sequences above a certain identity threshold, and mostly it was 40% (<xref rid="TB1" ref-type="table">Table 1</xref>).</p>
      <p>Interestingly, SM:AMPlify, SM:AMPScanner V2 and SM:ampir-mature additionally verified whether the negative data set did not, by chance, contain sequences from the positive data set (<xref rid="TB1" ref-type="table">Table 1</xref>). This might arise as a result of: (i) non-AMPs generation from a protein fragment or fragments, and (ii) an improper/lack of annotation in UniProt [<xref rid="ref26" ref-type="bibr">26</xref>] for sequences that are indeed antimicrobial.</p>
      <p>The sampling methods generated sequences that greatly differed from those in the positive data set both in the amino acid composition (<xref rid="sup1" ref-type="supplementary-material">Figure S2</xref>–<xref rid="sup1" ref-type="supplementary-material">S6</xref>) and physicochemical properties (<xref rid="sup1" ref-type="supplementary-material">Figure S7</xref>). There were also some pronounced differences among the negative sets, but the five iterations of each method always produced similar samples (<xref rid="sup1" ref-type="supplementary-material">Figure S2</xref>–<xref rid="sup1" ref-type="supplementary-material">S8</xref>).</p>
      <fig position="float" id="f1">
        <label>Figure 1</label>
        <caption>
          <p>Schematic representation of the traditional model benchmarking <bold>(A)</bold> and the methodology employed in comparing the impact of different negative data sampling methods on model performance <bold>(B)</bold>. Models 1, 2 and 3 (colourful hexagons) were trained on data set A, B and C (colourful rectangles), respectively. Each data set was generated by an appropriate negative sampling method (white ovals) and a positive sample (blue rectangles). In the evaluation process, the models were compared only on the benchmark set C, built with the same method as the training set C, thereby introducing some bias in favour of Model 3 in the benchmark analysis <bold>(A)</bold>. Architectures were developed based on published models, and they represent the algorithm with all its parameters involved in the machine learning cycle (white parallelograms). Each architecture was trained on the same positive data set (the white rectangle) and a negative sample was generated by one of the 11 negative sampling methods (white ovals) five times to verify the repeatability. The training and benchmark sample are indicated as blue and red rectangles, respectively. The models (orange hexagons) represent instances of architectures trained on given data sets and were validated on each benchmark sample. The results of model performance were indicated as white clouds <bold>(B)</bold>.</p>
        </caption>
        <graphic xlink:href="bbac343f1" position="float"/>
      </fig>
    </sec>
    <sec id="sec2b">
      <title>Model architectures</title>
      <p>We considered 26 model architectures for the prediction of AMPs from literature (<xref rid="sup1" ref-type="supplementary-material">Table S2</xref>), and selected 12 for reimplementation, two deep learning and ten non-deep learning-based methods, the latter represent mainly RF and SVM algorithms (<xref rid="TB2" ref-type="table">Table 2</xref>). In our research, we chose algorithms described in detail that could be run locally and do not require any usage of web servers or other software for feature selection. Moreover, we focused on the classification task, i.e. the model ability to divide sequences into AMPs or non-AMPs. Consequently, we did not consider software that is trained using MIC (minimum inhibitory concentration) values, e.g. Witten&amp;Witten or multiclass models. However, if the multiclass algorithm was composed of two models: one predicting if a given sequence is or is not an AMP, and the second classifying an AMPs into functional groups, we did reimplement the first model, e.g. for A:iAMP-2L and A:MLAMP.</p>
      <p>For each model, sequences in the data sets were transformed (encoded) into features (descriptors) using an appropriate feature extraction method (<xref rid="TB2" ref-type="table">Table 2</xref>). In the case of non-deep learning architectures, the features can be defined by the researcher, based on the knowledge of AMP properties, whereas the deep learning architectures can automatically learn high-level features from the training data sets though A:Deep-AmPEP30 also employed developer-defined features.</p>
      <p>The simplest feature extraction method was used by A:AMAP, and it was based on the amino acid composition. Consequently, its feature space contained 20 descriptors, each reflecting the occurrence frequency of one of the 20 amino acids in a peptide sequence (<xref rid="TB2" ref-type="table">Table 2</xref>). Other architectures such as A:iAMP-2L, A:MLAMP, A:ampir and A:Deep-AmPEP30 used features based on pseudo-amino acid composition. Beyond the simple amino acid counts, they included various physicochemical and structural properties of amino acids to incorporate the information about the sequence order; their feature space increased accordingly (<xref rid="TB2" ref-type="table">Table 2</xref>). Four architectures, A:CS-AMPPred, A:MACREL, A:AmPEP and A:AmPEPpy, used features based on structural and physicochemical properties of peptide sequences, e.g. their <inline-formula><tex-math notation="LaTeX" id="ImEquation4">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\alpha $\end{document}</tex-math></inline-formula>-helix propensity, charge and hydrophobicity (<xref rid="TB2" ref-type="table">Table 2</xref>). A:SVM-LZ used pairwise similarity scores, and A:AmpGram n-grams. In the case of A:AMPScanner V2 the feature information was extracted in the embedding layer, and then the obtained embeddings fed the subsequent layers of the models (<xref rid="TB2" ref-type="table">Table 2</xref>).</p>
      <p>Five non-deep machine learning architectures used feature selection for feature space optimization, but we implemented it for only two architectures: A:CS-AMPpred and A:AmpGram. The former used principal component analysis and the latter Quick Permutation Test (<xref rid="TB2" ref-type="table">Table 2</xref>). For A:AmPEP and A:ampir, we used the reduced feature space indicated by their developers without computing Pearson correlation coefficients and rigorous recursive feature elimination, respectively. For A:AmPEPpy, we abandoned the reduction of feature space by stepwise feature selection because according to the authors it did not improve the predictive power of the model but only its size.</p>
      <p>Five of the selected architectures required only slight modifications in their already available codes, and seven were implemented based on the information provided by the authors either in their articles or personal communication. A comprehensive description of the implementations and the applied modifications are provided in the Supplementary Data, including <xref rid="sup1" ref-type="supplementary-material">Table S3</xref>.</p>
    </sec>
  </sec>
  <sec id="sec3">
    <title>Results</title>
    <sec id="sec3a">
      <title>The impact of data sampling on benchmarks</title>
      <p>In order to evaluate the impact of data sampling on benchmark analysis, the receiver operating characteristic (ROC) curves were plotted (<xref rid="sup1" ref-type="supplementary-material">Figure S9</xref>–<xref rid="sup1" ref-type="supplementary-material">S69</xref>) and values of the area under the ROC curve (AUC) were calculated for each of 660 models on each benchmark data set and then averaged for the appropriate architecture. The results of the analysis are presented in <xref rid="f2" ref-type="fig">Figure 2</xref><bold>(A)</bold>, <xref rid="sup1" ref-type="supplementary-material">S70</xref> and <xref rid="sup1" ref-type="supplementary-material">S71</xref>. They clearly indicate that all but two architectures, A:AmPEP and A:iAMP-2L, performed much better when the training and benchmark samples were generated by the same sampling method. A:SVM-LZ, A:AmpGram and A:CS-AMPPred showed only small improvement of 2.3%, 3.6% and 4.4%, respectively; however, A:AmpGram by far outperformed the other architectures. The mean value of AUC for A:AMAP and A:MACREL increased 7.5%, for A:ampir and A:AmPEPpy about 9.5% and for the rest architectures soared more than 10% (<xref rid="sup1" ref-type="supplementary-material">Table S6</xref>). A:AmPEP and A:iAMP-2L were the only architectures, which preferred dissimilar sampling methods for training and benchmarking, but both generally performed very poorly with mean AUC amounting to 0.65. The calculated differences were statistically significant for all comparisons but for iAMP-2L and SVM-LZ (Kruskal–Wallis test with Bonferroni correction, <italic toggle="yes">P</italic>-value &lt; 0.05, <xref rid="sup1" ref-type="supplementary-material">Table S7</xref>).</p>
      <fig position="float" id="f2">
        <label>Figure 2</label>
        <caption>
          <p>Model performance depending on the architecture and negative data sampling method used for training and benchmarking. The x-axis represents mean AUC for architectures trained and tested on sets generated by the same negative data sampling method. The y-axis represents mean AUC for architectures trained and tested on sets generated by different negative data sampling methods. The architectures on the right of the diagonal perform better when the training and benchmark sample are produced by the same method, while the architectures on the left when the methods are different <bold>(A)</bold>. Box plots with median and interquartile range differences in AUC for architectures <bold>(B)</bold>, training data set sampling method <bold>(C)</bold> and benchmark data set sampling method <bold>(D)</bold>.</p>
        </caption>
        <graphic xlink:href="bbac343f2" position="float"/>
      </fig>
      <fig position="float" id="f3">
        <label>Figure 3</label>
        <caption>
          <p>Architecture performance depending on the negative data sampling method used for training and benchmarking. Each of 12 heat maps represents an architecture, the x-axis and y-axis describe the training and benchmark method of negative data sampling, respectively. Each architecture was trained and benchmarked on five replicates of the training and benchmark sample. The mean value of AUC for the five replicates is indicated as shades of red, orange and yellow, and the standard deviation as black dots of varying sizes. The diagonals mark results for architectures trained and benchmarked on the data generated by the same sampling method.</p>
        </caption>
        <graphic xlink:href="bbac343f3" position="float"/>
      </fig>
      <p>The main conclusion from these analyses is that similar training and benchmark data set positively affect model performance. Accordingly, there was significant negative correlation between mean AUC value and the difference in amino acid composition between the training and benchmark sets, measured as the square root of the sum of the squared differences in the frequency of individual amino acids (Spearman correlation coefficient, <inline-formula><tex-math notation="LaTeX" id="ImEquation5">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\rho $\end{document}</tex-math></inline-formula> = −0.53, <italic toggle="yes">P</italic>-value &lt; 2.2e-16). There was also smaller but still significant negative correlation for mean AUC and the absolute difference between median length of the sets (<inline-formula><tex-math notation="LaTeX" id="ImEquation6">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\rho $\end{document}</tex-math></inline-formula> = −0.44, <italic toggle="yes">P</italic>-value &lt; 2.2e-16).</p>
    </sec>
    <sec id="sec3b">
      <title>The impact of architecture, training and benchmark data sampling method on model performance</title>
      <p>To visualize which of the three components of the machine learning model, architecture, training or benchmark data sampling method, bears the greatest importance for model performance, we compared box plots of AUC distribution for each of these features (<xref rid="f2" ref-type="fig">Figure 2</xref><bold>B</bold>–<bold>D</bold>). The plots clearly indicate the greatest variation of AUC for data grouped according to the architecture. We also calculated the ratio of between-group median absolute deviation (MAD) to within-group MAD to verify if the AUC dispersal between different architectures or training/benchmark data sampling methods is much greater than the AUC dispersal found inside a single architecture or method. The MAD ratios amounted to 1.29, 0.48 and 0.29 for architectures, training and benchmark data sampling methods, respectively, and express in numbers the relative AUC variation presented in the graphical form in the box plots (<xref rid="f2" ref-type="fig">Figure 2</xref><bold>B</bold>–<bold>D</bold>). Moreover, to further verify the importance of the three components, we conducted pairwise Wilcoxon test for paired samples (<xref rid="sup1" ref-type="supplementary-material">Table S8</xref>–<xref rid="sup1" ref-type="supplementary-material">S10</xref>). The statistically significant differences (after Bonferroni correction) were indicated for 86%, 60% and 62% comparisons for groups of architectures, training and benchmark data sampling methods, respectively.</p>
      <p>Unquestionably, the greatest differences in AUC are associated with the architecture indicating that this component is more important than the training and benchmark data sampling method for model performance. Among the five architectures with the median AUC value greater than 0.9, there were three using RF (A:AmpGram, A:MACREL and A:MLAMP), one SVM (A:ampir) and one deep learning algorithm (A:AMPScannerV2) (<xref rid="f2" ref-type="fig">Figure 2</xref><bold>B</bold>). The results emphasize the power of RF-based architectures in tackling the problem of AMP prediction. The only RF architecture that stood out with small median AUC value was A:AmPEP, which most probably results from the reduction of its feature space to 23; A:AmPEPy, a python implementation of A:AmPEP, with the full feature set of 105 performed quite well. The best architecture was A:AmpGram with the median AUC value of 0.93 and the narrowest box indicating low variance of AUC obtained for various combination of training and benchmark data (<xref rid="f2" ref-type="fig">Figure 2</xref><bold>B</bold>). About 73% models of this architecture obtained AUC greater than 0.9. The A:AmpGram performance suggests that short amino acid motifs might have greater discriminatory power than global amino acid composition or physicochemical and structural properties, such as charge or tendency to form <inline-formula><tex-math notation="LaTeX" id="ImEquation7">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\alpha $\end{document}</tex-math></inline-formula>-helices. The existence of well-conserved motifs typical for AMPs, e.g. lysine-tryptophan motifs, supports our observation. These motifs cannot be replaced without reducing the antimicrobial propensity even if the global amino acid composition stays the same [<xref rid="ref55" ref-type="bibr">55</xref>].</p>
      <p>We also noticed a certain trend in the distribution of AUC for the training data sampling methods (<xref rid="f2" ref-type="fig">Figure 2</xref><bold>C</bold>). The AUC values calculated for TSM:AmpGram, TSM:AMPlify, TSM:AMPScannerV2, TSM:Gabere&amp;Noble and TSM:Wang et. al were generally higher than for TSM:AMAP, TSM:ampir-mature and TSM:Witten&amp;Witten, and the lowest AUC values were for TSM:CS-AMPPred, TSM:dbAMP and TSM:iAMP-2L. Interestingly, the first five sampling methods produced data sets similar in terms of length distribution (<xref rid="sup1" ref-type="supplementary-material">Figure S1</xref>), amino acid composition (<xref rid="sup1" ref-type="supplementary-material">Figure S2</xref>–<xref rid="sup1" ref-type="supplementary-material">S6</xref>) and physicochemical properties (<xref rid="sup1" ref-type="supplementary-material">Figure S7</xref>) that deviated from the other sets, especially those with the lowest median AUC. Given that there was significant negative correlation between mean AUC value and the difference in amino acid composition and median length between the training and benchmark sets (see above), it is not surprising that architectures trained and benchmarked on the five similar sampling methods outperformed the others. They simply were advantaged classifying benchmark sequences in accordance with our finding that similar training and benchmark sample positively affect model performance.</p>
      <p>Contrary to the results presented in the prior paragraph, the sampling methods that performed worse as training sets (SM:dbAMP, SM:iAMP-2L, SM:CS-AMPPred and also SM:AMAP) turned out with the highest AUC as benchmark samples (<xref rid="f2" ref-type="fig">Figure 2</xref><bold>D</bold>). This can be explained by the fact that these methods generate sequences that not only differ from AMPs of the positive set in the amino acid content and physicochemical properties but are also generally much longer (<xref rid="sup1" ref-type="supplementary-material">Figure S1</xref>). The median values for sequences of SM:dbAMP, SM:iAMP-2L, SM:CS-AMPPred, SM:AMAP and the positive sample are: 79, 79, 72, 36 and 18, respectively. Accordingly, we found significant positive correlation between mean AUC and differences in the median length of the benchmark negative data sets and the benchmark positive sample (Spearman correlation coefficient, <inline-formula><tex-math notation="LaTeX" id="ImEquation8">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\rho $\end{document}</tex-math></inline-formula> = 0.74, <italic toggle="yes">P</italic>-value = 8.63e-11).</p>
    </sec>
    <sec id="sec3c">
      <title>Repeatability of prediction for the replicates of data sets</title>
      <p>To verify the repeatability of prediction, each architecture was trained and benchmarked on five replicates of the training and benchmark sample. Despite the fact that the replicates were very similar in terms of length (<xref rid="sup1" ref-type="supplementary-material">Figure S1</xref>), amino acid composition (<xref rid="sup1" ref-type="supplementary-material">Figure S2</xref>–<xref rid="sup1" ref-type="supplementary-material">S6</xref>) and physicochemical properties (<xref rid="sup1" ref-type="supplementary-material">Figure S7</xref>), they did affect the performance of our investigated architectures (<xref rid="f3" ref-type="fig">Figure 3</xref>), especially A:iAMP-2L, A:AMPScannerV2 and A:Deep-AmPEP30, for which mean standard deviation (SD) of AUC value amounted to 0.035, 0.019 and 0.014, respectively (<xref rid="sup1" ref-type="supplementary-material">Table S11</xref>). A:iAMP-2L generally resulted in poorly performing models and the majority of them were characterized by low repeatability. Similarly, A:Deep-AmPEP30 was not a very robust architecture and some models trained on the replicated data also produced significantly different AUC values, e.g. those trained on SM:ampir-mature, SM:AMPScannerV2 and SM:AMPlify, and benchmarked on SM:CS-AMPPred, SM:dbAMP and SM:iAMP-2L. In contrast, A:AMPScannerV2 was rather at the forefront of the investigated architectures, especially if the training and benchmark set were generated by the same sampling method (<xref rid="f2" ref-type="fig">Figure 2</xref><bold>A</bold>, <bold>B</bold>). In the case of A:AMPScannerV2, there is a clear pattern of overlapping low AUC and high SD distribution for models trained on replicated data generated by SM:ampir-mature, SM:CS-AMPPred, SM:dbAMP, SM:iAMP-2L and also SM:Witten&amp;Witten (<xref rid="f3" ref-type="fig">Figure 3</xref>). It looks like these training sets were not enough for deep learning models to learn features necessary to classify AMPs and non-AMPs correctly. This result concurs with other works reporting that shallow models have similar performance to deep ones for AMP prediction [<xref rid="ref56" ref-type="bibr">56</xref>].</p>
      <p>It is worth emphasizing that the most stable architectures included also the best ones: A:AmpGram, A: MACREL and A:ampir, as well as A:AmPEPpy (<xref rid="sup1" ref-type="supplementary-material">Table S11</xref>, <xref rid="f2" ref-type="fig">Figure 2</xref><bold>A</bold>, <xref rid="f2" ref-type="fig">2</xref><bold>B</bold>, <xref rid="f3" ref-type="fig">3</xref>, <xref rid="sup1" ref-type="supplementary-material">S70</xref>). Their mean SD of AUC value amounted to about 0.004. A:ampir implemented SVM and the rest RF algorithm indicating their superiority over deep learning architectures (A:AMPScannerV2 and A:Deep-AmPEP30) in tackling our data.</p>
      <p>We also noticed a certain trend in the distribution of AUC reflecting a previously formulated conclusion that similar training and benchmark data set positively affect model performance. It was less noticeable for poorly performing architectures: A:iAMP-2L, A:AmPEP and A:SVM-LZ, and A:AmpGram representing the top architecture in our studies (<xref rid="f3" ref-type="fig">Figure 3</xref>).</p>
    </sec>
  </sec>
  <sec id="sec4">
    <title>Discussion and conclusions</title>
    <p>Machine learning represents the most cost-effective method for novel AMP discovery. As a result, many computational tools for AMP prediction have been developed in recent years [<xref rid="ref17" ref-type="bibr">17</xref>] and each subsequent state-of-the-art model claims to outperform its predecessors. As a rule, the state-of-the-art model is evaluated with other software on a benchmark sample generated by the same method that was also used to produce its training set (<xref rid="f1" ref-type="fig">Figure 1</xref><bold>A</bold>). According to the presented research, this is a source of statistically significant bias in favour of the state-of-the-art model because the more similar the training and benchmark data set are the better the model performance (<xref rid="f2" ref-type="fig">Figure 2</xref><bold>A</bold>, <xref rid="f2" ref-type="fig">2</xref><bold>B</bold>, <xref rid="f3" ref-type="fig">3</xref>, <xref rid="sup1" ref-type="supplementary-material">S70</xref>). Consequently, we came to logical conclusions that (i) all the benchmark analyses that have been published for AMP prediction tools are unfair and (ii) we do not know which model is the most accurate.</p>
    <p>To provide researchers with reliable information about the performance of AMP predictors, we created a web server AMPBenchmark for fair benchmarking of AMP prediction models. Similarly to Kaggle, AMPBenchmark provides developers with public and private data sets for model training and validation that contain explicit and hidden data labels, respectively. The public data sets are the same samples that were used in the presented research. AMPBenchmark allows users to upload the prediction results for their AMP models, trained and benchmarked on the public data sets. It generates charts and tables comparing the performance of the uploaded architecture with those deposited in our database. The users can also upload prediction results for their AMP models, trained and benchmarked on the private data set, which is accessible after entering the e-mail address. The operator of AMPBenchmark will manually verify the results of the prediction and similarly provide charts and tables for comparative analysis.</p>
    <p>Our study has also vital importance for the ongoing debate about the reproducibility crisis in science [<xref rid="ref57" ref-type="bibr">57</xref>, <xref rid="ref58" ref-type="bibr">58</xref>]. In machine learning research, reproducibility means obtaining the same results to those presented in the original study using the same data and source code. Recently, Heil <italic toggle="yes">et al</italic>. [<xref rid="ref59" ref-type="bibr">59</xref>] proposed three standards for computational reproducibility: bronze, silver and gold, reflecting the time needed to recreate research. The minimal and most time-consuming bronze standard requires: (i) data, (ii) models and (iii) source code to be published and downloadable. From the 26 models for AMP prediction that we considered, only eight met the minimal bronze standard (<xref rid="sup1" ref-type="supplementary-material">Table S2</xref>). This means that about 70% models represented non-reproducible work and consequently are unreliable. Interestingly, this number is very consistent with the survey published in the journal Nature [<xref rid="ref58" ref-type="bibr">58</xref>] indicating that more than 70% researchers failed to reproduce other group’s experiments. Among the implemented models, five met the bronze standard: AmPEP, AmPEPpy, AmpGram, ampir and MACREL, and AmpScannerV2 was accessible upon request. These architectures, with the exception of A:AmPEP, also represent the top architectures investigated though A:AmpGram was clearly the most accurate and best at generalizing to other data sets.</p>
    <p>The developers that do not reveal all the details necessary to recreate their models, not to mention reuse them, shoulder the blame for the lack of fair benchmarks for AMP prediction software. Consequently, progress in the field is slowed, mistrust to bioinformatics is spreading and resources that could have been allocated to other projects are wasted. Our study represents the first unbiased approach to compare models for AMP prediction, and moreover, we made reproducible another six model architectures for further research. In total, we built a staggering number of 660 machine learning models from 12 architectures. Therefore, being fully aware of the difficulty of the task, we highly recommend all researchers to embrace the notion of fair benchmarking and reproducibility using AMPBenchmark web server and the recommendations provided by Heil <italic toggle="yes">et al</italic>. [<xref rid="ref59" ref-type="bibr">59</xref>].</p>
    <boxed-text id="box01" position="float">
      <sec id="sec14t">
        <title>Key Points</title>
        <list list-type="bullet">
          <list-item>
            <p>We review the performance of existing machine learning models for identification of AMPs.</p>
          </list-item>
          <list-item>
            <p>Our benchmark highlights the major methodological flaw in the construction of benchmarks as the data sampling impacts the quality of AMP prediction.</p>
          </list-item>
          <list-item>
            <p>We propose a solution for fair benchmarking of AMP-predicting models.</p>
          </list-item>
        </list>
      </sec>
    </boxed-text>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material id="sup1" position="float" content-type="local-data">
      <label>supplementary-materials_bbac343</label>
      <media xlink:href="supplementary-materials_bbac343.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ack id="ack1">
    <title>Acknowledgments</title>
    <p>We thank Henrik Nielsen (Technical University of Denmark) and Simon Rasmussen (University of Copenhagen) for their critical review of the draft and fruitful discussions.</p>
  </ack>
  <sec id="sec7">
    <title>Funding</title>
    <p>This work was partially supported by the National Science Centre grant 2017/26/D/NZ8/00444 to P.G., the National Science Centre grant 2018/31/N/NZ2/01338 to K.S., the National Science Centre grant 2019/35/N/NZ8/03366 to F.P. and the IDUB against COVID-19 project granted by Warsaw University of Technology under the program Excellence Initiative: Research University (IDUB) to M.B. M. B. was partially supported by the Maria Zambrano grant funded by the European Union-NextGenerationEU.</p>
  </sec>
  <sec id="sec6">
    <title>Code, software and data availability</title>
    <p>The code necessary to reproduce the whole analysis is available at <ext-link xlink:href="https://github.com/BioGenies/NegativeDatasets" ext-link-type="uri">https://github.com/BioGenies/NegativeDatasets</ext-link>. All architectures are located at <ext-link xlink:href="https://github.com/BioGenies/NegativeDatasetsArchitectures" ext-link-type="uri">https://github.com/BioGenies/NegativeDatasetsArchitectures</ext-link>. AMPBenchmark web server is available at <ext-link xlink:href="http://BioGenies.info/AMPBenchmark" ext-link-type="uri">http://BioGenies.info/AMPBenchmark</ext-link>.</p>
  </sec>
  <notes id="bio3">
    <title>Author Biographies</title>
    <p><bold>Katarzyna Sidorczuk</bold> received the M.Sc. degree in biotechnology from the University of Wrocław, Poland, in 2019. She is currently pursuing the Ph.D. degree in biological sciences at the University of Wrocław. Her research focuses on bioinformatics and machine learning approaches for the analysis and prediction of peptide functions, protein targeting sequences and bacterial adhesins.</p>
    <sec sec-type="author-bio" id="sec27b">
      <p><bold>Przemysław Gagat</bold> is an Assistant Professor in the Faculty of Biotechnology at the University of Wrocław in Poland, where he received his B.Sc., (2006) M.Sc. (2008) and PhD (2014) in biotechnology. He has been involved in research projects in the field of bioinformatics, molecular phylogeny, molecular biology and evolution. His research interests include particularly endosymbioses of primary and complex plastids, and recently antimicrobial and anticancer peptides.</p>
    </sec>
    <sec sec-type="author-bio" id="sec27c">
      <p><bold>Filip Pietluch</bold> graduated with both a Masters and a Bachelors degree in Biotechnology from the University of Wrocław, Poland. He is currently a PhD student at the University of Wrocław, exploring phylogenetics and AMPs evolution. His main research topics are in computational and evolutionary biology.</p>
    </sec>
    <sec sec-type="author-bio" id="sec27d">
      <p><bold>Jakub Kał,a</bold> received the M. Sc. Eng. degree in Data Science from the Warsaw University of Technology in 2021. His main research focuses on applications of machine learning in protein function prediction.</p>
    </sec>
    <sec sec-type="author-bio" id="sec27e">
      <p><bold>Dominik Rafacz</bold> is a M.Sc. student with his major in Data Science at the Warsaw University of Technology. He has contributed to several projects related to predicting properties of proteins. He is an active open-source developer, author and coauthor of several packages for the R programming language, including a framework for biological sequences storage and processing.</p>
    </sec>
    <sec sec-type="author-bio" id="sec27f">
      <p><bold>Laura Bąkała</bold> is another Data Science major at the Warsaw University of Technology, as well as a M.Sc. student. She has worked on a few open-source R packages together with Dominik Rafacz, among those being the aforementioned framework for handling biological sequences.</p>
    </sec>
    <sec sec-type="author-bio" id="sec27g">
      <p><bold>Jadwiga Słowik</bold> received her master’s in data science from Warsaw University of Technology. She is passionate about software development and competitive programming.</p>
    </sec>
    <sec sec-type="author-bio" id="sec27h">
      <p><bold>Rafał Kolenda</bold> graduated in veterinary medicine from Wrocław University of Environmental and Life Sciences, Poland, in 2013. He received Dr. med. vet. degree from Freie Universität, Berlin, Germany, in 2018. He is currently working as a research associate at the Department of Biochemistry and Molecular Biology of Wrocław University of Environmental and Life Sciences, Poland. In his research, he uses molecular microbiology and omics techniques to investigate the pathogenic actions of bacteria. Moreover, he is involved in the development of new tools for <italic toggle="yes">Escherichia coli</italic> adhesiome analysis.</p>
    </sec>
    <sec sec-type="author-bio" id="sec27i">
      <p><bold>Stefan Rödiger</bold> is Privatdozent at the Brandenburg University of Technology. He studied pharamabiotechnology and forensics and received the doctoral degree from the Charité. His research includes personalized medicine, bioinformatics and pharmacology.</p>
    </sec>
    <sec sec-type="author-bio" id="sec27j">
      <p><bold>Legana C H W Fingerhut</bold> graduated with a B.Sc degree in Ecology and Conservation and Zoology followed by a B.Biomed.Sc(Hons1) degree in Molecular Biology at James Cook University, Australia. She is currently a PhD candidate in bioinformatics examining antimicrobial peptide classification. She is the first author of the genome-wide antimicrobial peptide prediction R package, ampir.</p>
    </sec>
    <sec sec-type="author-bio" id="sec27k">
      <p><bold>Ira R Cooke</bold> received his PhD from the Australian National University in 2006 and is now a senior lecturer in bioinformatics at James Cook University, Australia. He is interested in the evolution and function of small secreted proteins in marine taxa, especially cephalopods and corals.</p>
    </sec>
    <sec sec-type="author-bio" id="sec27l">
      <p><bold>Paweı Mackiewicz</bold> is a professor at the University of Wrocław in Poland. He is an author and co-author of more than 180 scientific publications. He is involved in many interdisciplinary research projects in the field of bioinformatics, genomics, phylogenetics and molecular evolution. His research interests focus on endosymbiosis, genetic code optimization and evolution, computer simulation of genome evolution, as well as phylogeny at the level of genes, proteins, genomes and organisms including ancient DNA samples.</p>
    </sec>
    <sec sec-type="author-bio" id="sec27m">
      <p><bold>Michał Burdukiewicz</bold> received Ph.D. in biochemistry from the University of Wrocław in 2019. He is currently working as a post-doc at the Institute of Biotechnology and Biomedicine at the Autonomous University of Barcelona and a research assistant in the Centre for Clinical Research at the Medical University of Białystok. His research interests cover machine learning applications in the functional analysis of peptides and proteins, focusing on amyloids. Moreover, he is co-developing tools for proteomics, mainly hydrogen-deuterium exchange monitored by mass spectrometry.</p>
    </sec>
  </notes>
  <ref-list id="bib1">
    <title>References</title>
    <ref id="ref1">
      <label>1.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Maróti</surname><given-names>G</given-names></string-name>, <string-name><surname>Kereszt</surname><given-names>A</given-names></string-name>, <string-name><surname>Kondorosi</surname><given-names>E</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Natural roles of antimicrobial peptides in microbes, plants and animals</article-title>. <source>Res Microbiol</source><year>2011</year>;<volume>162</volume>(<issue>4</issue>):<fpage>363</fpage>–<lpage>74</lpage>.<pub-id pub-id-type="pmid">21320593</pub-id></mixed-citation>
    </ref>
    <ref id="ref2">
      <label>2.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Magrone</surname><given-names>T</given-names></string-name>, <string-name><surname>Russo</surname><given-names>MA</given-names></string-name>, <string-name><surname>Jirillo</surname><given-names>E</given-names></string-name></person-group>. <article-title>Antimicrobial peptides: phylogenic sources and biological activities. First of two parts</article-title>. <source>Curr Pharm Des</source><year>2018</year>;<volume>24</volume>(<issue>10</issue>):<fpage>1043</fpage>–<lpage>53</lpage>.<pub-id pub-id-type="pmid">29611476</pub-id></mixed-citation>
    </ref>
    <ref id="ref3">
      <label>3.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Raffatellu</surname><given-names>M</given-names></string-name></person-group>. <article-title>Learning from bacterial competition in the host to develop antimicrobials</article-title>. <source>Nat Med</source><year>2018</year>;<volume>24</volume>(<issue>8</issue>):<fpage>1097</fpage>–<lpage>1103</lpage>.<pub-id pub-id-type="pmid">30082869</pub-id></mixed-citation>
    </ref>
    <ref id="ref4">
      <label>4.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><given-names>Garima</given-names><surname>Suneja</surname></string-name>, <string-name><given-names>Sonam</given-names><surname>Nain</surname></string-name>, and <string-name><given-names>Rakesh</given-names><surname>Sharma</surname></string-name></person-group>. <part-title>Microbiome: A source of novel bioactive compounds and antimicrobial peptides</part-title>. In: Tulasi Satyanarayana, Bhavdish Narain Johri, Subrata Kumar Das (eds) <source>Microbial Diversity in Ecosystem Sustainability and Biotechnological Applications</source>, pages <fpage>615</fpage>–<lpage>30</lpage>.
<publisher-name>Springer Singapore</publisher-name>, <year>2019</year>.</mixed-citation>
    </ref>
    <ref id="ref5">
      <label>5.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ahmed</surname><given-names>A</given-names></string-name>, <string-name><surname>Siman-Tov</surname><given-names>G</given-names></string-name>, <string-name><surname>Hall</surname><given-names>G</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Human antimicrobial peptides as therapeutics for viral infections</article-title>. <source>Viruses</source><year>2019</year>;<volume>11</volume>(<issue>8</issue>):<fpage>704</fpage>.</mixed-citation>
    </ref>
    <ref id="ref6">
      <label>6.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mookherjee</surname><given-names>N</given-names></string-name>, <string-name><surname>Anderson</surname><given-names>MA</given-names></string-name>, <string-name><surname>Haagsman</surname><given-names>HP</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Antimicrobial host defence peptides: functions and clinical potential</article-title>. <source>Nat Rev Drug Discov</source><year>2020</year>;<volume>19</volume>(<issue>5</issue>):<fpage>1</fpage>–<lpage>22</lpage>.<pub-id pub-id-type="pmid">31907422</pub-id></mixed-citation>
    </ref>
    <ref id="ref7">
      <label>7.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Li</surname><given-names>J</given-names></string-name>, <string-name><surname>Koh</surname><given-names>J-J</given-names></string-name>, <string-name><surname>Liu</surname><given-names>S</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Membrane active antimicrobial peptides: translating mechanistic insights to design</article-title>. <source>Front Neurosci</source><year>2017</year>;<volume>11</volume>:<fpage>73</fpage>.<pub-id pub-id-type="pmid">28261050</pub-id></mixed-citation>
    </ref>
    <ref id="ref8">
      <label>8.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Travkova</surname><given-names>OG</given-names></string-name>, <string-name><surname>Moehwald</surname><given-names>H</given-names></string-name>, <string-name><surname>Brezesinski</surname><given-names>G</given-names></string-name></person-group>. <article-title>The interaction of antimicrobial peptides with membranes</article-title>. <source>Adv Colloid Interface Sci</source><year>2017</year>;<volume>247</volume>:<fpage>521</fpage>–<lpage>32</lpage>.<pub-id pub-id-type="pmid">28606715</pub-id></mixed-citation>
    </ref>
    <ref id="ref9">
      <label>9.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kumar</surname><given-names>P</given-names></string-name>, <string-name><surname>Kizhakkedathu</surname><given-names>JN</given-names></string-name>, <string-name><surname>Straus</surname><given-names>SK</given-names></string-name></person-group>. <article-title>Antimicrobial peptides: diversity, mechanism of action and strategies to improve the activity and biocompatibility in vivo</article-title>. <source>Biomolecules</source><year>2018</year>;<volume>8</volume>(<issue>1</issue>):<fpage>4</fpage>.</mixed-citation>
    </ref>
    <ref id="ref10">
      <label>10.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ahmed</surname><given-names>TAE</given-names></string-name>, <string-name><surname>Hammami</surname><given-names>R</given-names></string-name></person-group>. <article-title>Recent insights into structure–function relationships of antimicrobial peptides</article-title>. <source>J Food Biochem</source><year>2019</year>;<volume>43</volume>(<issue>1</issue>):<fpage>e12546</fpage>.<pub-id pub-id-type="pmid">31353490</pub-id></mixed-citation>
    </ref>
    <ref id="ref11">
      <label>11.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Le</surname><given-names>C-F</given-names></string-name>, <string-name><surname>Fang</surname><given-names>C-M</given-names></string-name>, <string-name><surname>Sekaran</surname><given-names>SD</given-names></string-name></person-group>. <article-title>Intracellular targeting mechanisms by antimicrobial peptides</article-title>. <source>Antimicrob Agents Chemother</source><year>2017</year>;<volume>61</volume>(<issue>4</issue>):e02340–16.</mixed-citation>
    </ref>
    <ref id="ref12">
      <label>12.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Li</surname><given-names>S</given-names></string-name>, <string-name><surname>Wang</surname><given-names>Y</given-names></string-name>, <string-name><surname>Xue</surname><given-names>Z</given-names></string-name>, <etal>et al.</etal></person-group><article-title>The structure-mechanism relationship and mode of actions of antimicrobial peptides: a review</article-title>. <source>Trends Food Sci Technol</source><year>2021</year>;<volume>109</volume>:<fpage>103</fpage>–<lpage>15</lpage>.</mixed-citation>
    </ref>
    <ref id="ref13">
      <label>13.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Andersson</surname><given-names>DI</given-names></string-name>, <string-name><surname>Hughes</surname><given-names>D</given-names></string-name>, <string-name><surname>Kubicek-Sutherland</surname><given-names>JZ</given-names></string-name></person-group>. <article-title>Mechanisms and consequences of bacterial resistance to antimicrobial peptides</article-title>. <source>Drug Resist Updat</source><year>2016</year>;<volume>26</volume>:<fpage>43</fpage>–<lpage>57</lpage>.<pub-id pub-id-type="pmid">27180309</pub-id></mixed-citation>
    </ref>
    <ref id="ref14">
      <label>14.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lázár</surname><given-names>V</given-names></string-name>, <string-name><surname>Martins</surname><given-names>A</given-names></string-name>, <string-name><surname>Spohn</surname><given-names>R</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Antibiotic-resistant bacteria show widespread collateral sensitivity to antimicrobial peptides</article-title>. <source>Nat Microbiol</source><year>2018</year>;<volume>3</volume>(<issue>6</issue>):<fpage>718</fpage>.<pub-id pub-id-type="pmid">29795541</pub-id></mixed-citation>
    </ref>
    <ref id="ref15">
      <label>15.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Spohn</surname><given-names>R</given-names></string-name>, <string-name><surname>Daruka</surname><given-names>L</given-names></string-name>, <string-name><surname>Lázár</surname><given-names>V</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Integrated evolutionary analysis reveals antimicrobial peptides with limited resistance</article-title>. <source>Nat Commun</source><year>2019</year>;<volume>10</volume>(<issue>1</issue>):<fpage>1</fpage>–<lpage>13</lpage>.<pub-id pub-id-type="pmid">30602773</pub-id></mixed-citation>
    </ref>
    <ref id="ref16">
      <label>16.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><collab>WHO et al</collab></person-group>. <source>No time to wait: securing the future from drug-resistant infections</source>. <publisher-loc>Geneva, Switzerland</publisher-loc>:
<publisher-name>World Health Organization</publisher-name>, <year>2019</year>.</mixed-citation>
    </ref>
    <ref id="ref17">
      <label>17.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Xu</surname><given-names>J</given-names></string-name>, <string-name><surname>Li</surname><given-names>F</given-names></string-name>, <string-name><surname>Leier</surname><given-names>A</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Comprehensive assessment of machine learning-based methods for predicting antimicrobial peptides</article-title>. <source>Brief. Bioinformatics</source><year>2021</year>;<volume>22</volume>(<issue>5</issue>):bbab083.</mixed-citation>
    </ref>
    <ref id="ref18">
      <label>18.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Burdukiewicz</surname><given-names>M</given-names></string-name>, <string-name><surname>Sidorczuk</surname><given-names>K</given-names></string-name>, <string-name><surname>Rafacz</surname><given-names>D</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Proteomic screening for prediction and design of antimicrobial peptides with AmpGram</article-title>. <source>Int J Mol Sci</source><year>2020</year>;<volume>21</volume>(<issue>12</issue>):<fpage>4310</fpage>.</mixed-citation>
    </ref>
    <ref id="ref19">
      <label>19.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pirtskhalava</surname><given-names>M</given-names></string-name>, <string-name><surname>Amstrong</surname><given-names>AA</given-names></string-name>, <string-name><surname>Grigolava</surname><given-names>M</given-names></string-name>, <etal>et al.</etal></person-group><article-title>DBAASP v3: database of antimicrobial/cytotoxic activity and structure of peptides as a resource for development of new therapeutics</article-title>. <source>Nucleic Acids Res</source><year>2021</year>;<volume>49</volume>(<issue>D1</issue>):<fpage>D288</fpage>–<lpage>97</lpage>.<pub-id pub-id-type="pmid">33151284</pub-id></mixed-citation>
    </ref>
    <ref id="ref20">
      <label>20.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname><given-names>G</given-names></string-name>, <string-name><surname>Li</surname><given-names>X</given-names></string-name>, <string-name><surname>Wang</surname><given-names>Z</given-names></string-name></person-group>. <article-title>APD3: the antimicrobial peptide database as a tool for research and education</article-title>. <source>Nucleic Acids Res</source><year>2016</year>;<volume>44</volume>(<issue>D1</issue>):<fpage>D1087</fpage>–<lpage>93</lpage>.<pub-id pub-id-type="pmid">26602694</pub-id></mixed-citation>
    </ref>
    <ref id="ref21">
      <label>21.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Waghu</surname><given-names>FH</given-names></string-name>, <string-name><surname>Barai</surname><given-names>RS</given-names></string-name>, <string-name><surname>Gurung</surname><given-names>P</given-names></string-name>, <etal>et al.</etal></person-group><article-title>CAMPR3: a database on sequences, structures and signatures of antimicrobial peptides</article-title>. <source>Nucleic Acids Res</source><year>2016</year>;<volume>44</volume>(<issue>D1</issue>):<fpage>D1094</fpage>–<lpage>7</lpage>.<pub-id pub-id-type="pmid">26467475</pub-id></mixed-citation>
    </ref>
    <ref id="ref22">
      <label>22.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kang</surname><given-names>X</given-names></string-name>, <string-name><surname>Dong</surname><given-names>F</given-names></string-name>, <string-name><surname>Cheng</surname><given-names>S</given-names></string-name>, <etal>et al.</etal></person-group><article-title>DRAMP 2.0, an updated data repository of antimicrobial peptides</article-title>. <source>Sci Data</source><year>2019</year>;<volume>6</volume>(<issue>1</issue>):<fpage>1</fpage>–<lpage>10</lpage>.<pub-id pub-id-type="pmid">30647409</pub-id></mixed-citation>
    </ref>
    <ref id="ref23">
      <label>23.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jhong</surname><given-names>J-H</given-names></string-name>, <string-name><surname>Chi</surname><given-names>Y-H</given-names></string-name>, <string-name><surname>Li</surname><given-names>W-C</given-names></string-name>, <etal>et al.</etal></person-group><article-title>dbAMP: an integrated resource for exploring antimicrobial peptides with functional activities and physicochemical properties on transcriptome and proteome data</article-title>. <source>Nucleic Acids Res</source><year>2019</year>;<volume>47</volume>(<issue>D1</issue>):<fpage>D285</fpage>–<lpage>97</lpage>.<pub-id pub-id-type="pmid">30380085</pub-id></mixed-citation>
    </ref>
    <ref id="ref24">
      <label>24.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fingerhut</surname><given-names>LCHW</given-names></string-name>, <string-name><surname>Miller</surname><given-names>DJ</given-names></string-name>, <string-name><surname>Strugnell</surname><given-names>JM</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Ampir: an R package for fast genome-wide prediction of antimicrobial peptides</article-title>. <source>Bioinformatics</source><year>2020</year>;<volume>36</volume>(<issue>21</issue>):<fpage>5262</fpage>–<lpage>3</lpage>.</mixed-citation>
    </ref>
    <ref id="ref25">
      <label>25.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gabere</surname><given-names>MN</given-names></string-name>, <string-name><surname>Noble</surname><given-names>WS</given-names></string-name></person-group>. <article-title>Empirical comparison of web-based antimicrobial peptide prediction tools</article-title>. <source>Bioinformatics</source><year>2017</year>;<volume>33</volume>(<issue>13</issue>):<fpage>1921</fpage>–<lpage>9</lpage>.<pub-id pub-id-type="pmid">28203715</pub-id></mixed-citation>
    </ref>
    <ref id="ref26">
      <label>26.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><collab>UniProt Consortium</collab></person-group>. <article-title>Uniprot: the universal protein knowledgebase in 2021</article-title>. <source>Nucleic Acids Res</source><year>2021</year>;<volume>49</volume>(<issue>D1</issue>):<fpage>D480</fpage>–<lpage>9</lpage>.<pub-id pub-id-type="pmid">33237286</pub-id></mixed-citation>
    </ref>
    <ref id="ref27">
      <label>27.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yang</surname><given-names>P</given-names></string-name>, <string-name><surname>Li</surname><given-names>X-L</given-names></string-name>, <string-name><surname>Mei</surname><given-names>J-P</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Positive-unlabeled learning for disease gene identification</article-title>. <source>Bioinformatics</source><year>2012</year>;<volume>28</volume>(<issue>20</issue>):<fpage>2640</fpage>–<lpage>7</lpage>.<pub-id pub-id-type="pmid">22923290</pub-id></mixed-citation>
    </ref>
    <ref id="ref28">
      <label>28.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Vasighizaker</surname><given-names>A</given-names></string-name>, <string-name><surname>Sharma</surname><given-names>A</given-names></string-name>, <string-name><surname>Dehzangi</surname><given-names>A</given-names></string-name></person-group>. <article-title>A novel one-class classification approach to accurately predict disease-gene association in acute myeloid leukemia cancer</article-title>. <source>PLoS One</source><year>2019</year>;<volume>14</volume>(<issue>12</issue>):<fpage>e0226115</fpage>.<pub-id pub-id-type="pmid">31825992</pub-id></mixed-citation>
    </ref>
    <ref id="ref29">
      <label>29.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bugnon</surname><given-names>LA</given-names></string-name>, <string-name><surname>Yones</surname><given-names>C</given-names></string-name>, <string-name><surname>Milone</surname><given-names>DH</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Genome-wide discovery of pre-mirnas: comparison of recent approaches based on machine learning</article-title>. <source>Brief Bioinformatics</source><year>2021</year>;<volume>22</volume>(<issue>3</issue>):<fpage>bbaa184</fpage>.<pub-id pub-id-type="pmid">34020552</pub-id></mixed-citation>
    </ref>
    <ref id="ref30">
      <label>30.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rentzsch</surname><given-names>R</given-names></string-name>, <string-name><surname>Deneke</surname><given-names>C</given-names></string-name>, <string-name><surname>Nitsche</surname><given-names>A</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Predicting bacterial virulence factors–evaluation of machine learning and negative data strategies</article-title>. <source>Brief. Bioinformatics</source><year>2020</year>;<volume>21</volume>(<issue>5</issue>):<fpage>1596</fpage>–<lpage>608</lpage>.<pub-id pub-id-type="pmid">32978619</pub-id></mixed-citation>
    </ref>
    <ref id="ref31">
      <label>31.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ben-Hur</surname><given-names>A</given-names></string-name>, <string-name><surname>Noble</surname><given-names>WS</given-names></string-name></person-group>. <article-title>Choosing negative examples for the prediction of protein-protein interactions</article-title>. <source>BMC Bioinform</source><year>2006</year>;<volume>7</volume>(<issue>1</issue>):<fpage>1</fpage>–<lpage>6</lpage>.</mixed-citation>
    </ref>
    <ref id="ref32">
      <label>32.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cheng</surname><given-names>Z</given-names></string-name>, <string-name><surname>Zhou</surname><given-names>S</given-names></string-name>, <string-name><surname>Guan</surname><given-names>J</given-names></string-name></person-group>. <article-title>Computationally predicting protein-RNA interactions using only positive and unlabeled examples</article-title>. <source>J Bioinform Comput Biol</source><year>2015</year>;<volume>13</volume>(<issue>03</issue>):<fpage>1541005</fpage>.<pub-id pub-id-type="pmid">25790785</pub-id></mixed-citation>
    </ref>
    <ref id="ref33">
      <label>33.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Le</surname><given-names>NQK</given-names></string-name>, <string-name><surname>Do</surname><given-names>DT</given-names></string-name>, <string-name><surname>Le</surname><given-names>QA</given-names></string-name>, <etal>et al.</etal></person-group><article-title>A sequence-based prediction of kruppel-like factors proteins using xgboost and optimized features</article-title>. <source>Gene</source><year>2021</year>;<volume>787</volume>:<fpage>145643</fpage>.<pub-id pub-id-type="pmid">33848577</pub-id></mixed-citation>
    </ref>
    <ref id="ref34">
      <label>34.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hung</surname><given-names>TNK</given-names></string-name>, <string-name><surname>Le</surname><given-names>NQK</given-names></string-name>, <string-name><surname>Le</surname><given-names>NH</given-names></string-name>, <etal>et al.</etal></person-group><article-title>An ai-based prediction model for drug-drug interactions in osteoporosis and paget’s diseases from smiles</article-title>. <source>Molecular Informatics</source><year>2022</year>;<volume>41</volume>(<issue>6</issue>):<fpage>2100264</fpage>.</mixed-citation>
    </ref>
    <ref id="ref35">
      <label>35.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Song</surname><given-names>H</given-names></string-name>, <string-name><surname>Bremer</surname><given-names>BJ</given-names></string-name>, <string-name><surname>Hinds</surname><given-names>EC</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Inferring protein sequence-function relationships with large-scale positive-unlabeled learning</article-title>. <source>Cell Syst</source><year>2021</year>;<volume>12</volume>(<issue>1</issue>):<fpage>92</fpage>–<lpage>101</lpage>.<pub-id pub-id-type="pmid">33212013</pub-id></mixed-citation>
    </ref>
    <ref id="ref36">
      <label>36.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bekker</surname><given-names>J</given-names></string-name>, <string-name><surname>Davis</surname><given-names>J</given-names></string-name></person-group>. <article-title>Learning from positive and unlabeled data: a survey</article-title>. <source>Mach Learn</source><year>2020</year>;<volume>109</volume>(<issue>4</issue>):<fpage>719</fpage>–<lpage>60</lpage>.</mixed-citation>
    </ref>
    <ref id="ref37">
      <label>37.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Li</surname><given-names>F</given-names></string-name>, <string-name><surname>Dong</surname><given-names>S</given-names></string-name>, <string-name><surname>Leier</surname><given-names>A</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Positive-unlabeled learning in bioinformatics and computational biology: a brief review</article-title>. <source>Brief Bioinformatics</source><year>2021</year>.</mixed-citation>
    </ref>
    <ref id="ref38">
      <label>38.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Berman</surname><given-names>HM</given-names></string-name>, <string-name><surname>Westbrook</surname><given-names>J</given-names></string-name>, <string-name><surname>Feng</surname><given-names>Z</given-names></string-name>, <etal>et al.</etal></person-group><article-title>The protein data bank</article-title>. <source>Nucleic Acids Res</source><year>2000</year>;<volume>28</volume>(<issue>1</issue>):<fpage>235</fpage>–<lpage>42</lpage>.<pub-id pub-id-type="pmid">10592235</pub-id></mixed-citation>
    </ref>
    <ref id="ref39">
      <label>39.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Li</surname><given-names>W</given-names></string-name>, <string-name><surname>Godzik</surname><given-names>A</given-names></string-name></person-group>. <article-title>Cd-hit: a fast program for clustering and comparing large sets of protein or nucleotide sequences</article-title>. <source>Bioinformatics</source><year>2006</year>;<volume>22</volume>(<issue>13</issue>):<fpage>1658</fpage>–<lpage>9</lpage>.<pub-id pub-id-type="pmid">16731699</pub-id></mixed-citation>
    </ref>
    <ref id="ref40">
      <label>40.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Limin</surname><given-names>F</given-names></string-name>, <string-name><surname>Niu</surname><given-names>B</given-names></string-name>, <string-name><surname>Zhu</surname><given-names>Z</given-names></string-name>, <etal>et al.</etal></person-group><article-title>CD-HIT: accelerated for clustering the next-generation sequencing data</article-title>. <source>Bioinformatics</source><year>2012</year>;<volume>28</volume>(<issue>23</issue>):<fpage>3150</fpage>–<lpage>2</lpage>.<pub-id pub-id-type="pmid">23060610</pub-id></mixed-citation>
    </ref>
    <ref id="ref41">
      <label>41.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname><given-names>P</given-names></string-name>, <string-name><surname>Lele</surname><given-names>H</given-names></string-name>, <string-name><surname>Liu</surname><given-names>G</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Prediction of antimicrobial peptides based on sequence alignment and feature selection methods</article-title>. <source>PLoS One</source><year>2011</year>;<volume>6</volume>(<issue>4</issue>):<fpage>e18476</fpage>.<pub-id pub-id-type="pmid">21533231</pub-id></mixed-citation>
    </ref>
    <ref id="ref42">
      <label>42.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Porto</surname><given-names>WF</given-names></string-name>, <string-name><surname>Pires</surname><given-names>ÁS</given-names></string-name>, <string-name><surname>Franco</surname><given-names>OL</given-names></string-name></person-group>. <article-title>CS-AMPPred: an updated SVM model for antimicrobial activity prediction in cysteine-stabilized peptides</article-title>. <source>PLoS One</source><year>2012</year>;<volume>7</volume>(<issue>12</issue>):<fpage>e51444</fpage>.<pub-id pub-id-type="pmid">23240023</pub-id></mixed-citation>
    </ref>
    <ref id="ref43">
      <label>43.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Xuan Xiao</surname><given-names>P</given-names></string-name>, <string-name><surname>Wang</surname><given-names>W-ZL</given-names></string-name>, <string-name><surname>Jia</surname><given-names>J-H</given-names></string-name>, <etal>et al.</etal></person-group><article-title>iAMP-2L: a two-level multi-label classifier for identifying antimicrobial peptides and their functional types</article-title>. <source>Anal Biochem</source><year>2013</year>;<volume>436</volume>(<issue>2</issue>):<fpage>168</fpage>–<lpage>77</lpage>.<pub-id pub-id-type="pmid">23395824</pub-id></mixed-citation>
    </ref>
    <ref id="ref44">
      <label>44.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gull</surname><given-names>S</given-names></string-name>, <string-name><surname>Shamim</surname><given-names>N</given-names></string-name>, <string-name><surname>Minhas</surname><given-names>F</given-names></string-name></person-group>. <article-title>AMAP: hierarchical multi-label prediction of biologically active and antimicrobial peptides</article-title>. <source>Comput Biol Med</source><year>2019</year>;<volume>107</volume>:<fpage>172</fpage>–<lpage>81</lpage>.<pub-id pub-id-type="pmid">30831306</pub-id></mixed-citation>
    </ref>
    <ref id="ref45">
      <label>45.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>James Kent</surname><given-names>W</given-names></string-name></person-group>. <article-title>BLAT-the BLAST-like alignment tool</article-title>. <source>Genome Res</source><year>2002</year>;<volume>12</volume>(<issue>4</issue>):<fpage>656</fpage>–<lpage>64</lpage>.<pub-id pub-id-type="pmid">11932250</pub-id></mixed-citation>
    </ref>
    <ref id="ref46">
      <label>46.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Veltri</surname><given-names>D</given-names></string-name>, <string-name><surname>Kamath</surname><given-names>U</given-names></string-name>, <string-name><surname>Shehu</surname><given-names>A</given-names></string-name></person-group>. <article-title>Deep learning improves antimicrobial peptide recognition</article-title>. <source>Bioinformatics</source><year>2018</year>;<volume>34</volume>(<issue>16</issue>):<fpage>2740</fpage>–<lpage>7</lpage>.<pub-id pub-id-type="pmid">29590297</pub-id></mixed-citation>
    </ref>
    <ref id="ref47">
      <label>47.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Witten</surname><given-names>J</given-names></string-name>, <string-name><surname>Witten</surname><given-names>Z</given-names></string-name></person-group>. <article-title>Deep learning regression model for antimicrobial peptide design</article-title>. <source>BioRxiv</source><year>2019</year>;<fpage>692681</fpage>.</mixed-citation>
    </ref>
    <ref id="ref48">
      <label>48.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Li</surname><given-names>C</given-names></string-name>, <string-name><surname>Sutherland</surname><given-names>D</given-names></string-name>, <string-name><surname>Hammond</surname><given-names>SA</given-names></string-name>, <etal>et al.</etal></person-group><article-title>AMPlify: attentive deep learning model for discovery of novel antimicrobial peptides effective against who priority pathogens</article-title>. <source>BMC Genomics</source><year>2020</year>;<volume>23</volume>:77. <pub-id pub-id-type="doi">10.1186/s12864-022-08310-4</pub-id>.</mixed-citation>
    </ref>
    <ref id="ref49">
      <label>49.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yan</surname><given-names>J</given-names></string-name>, <string-name><surname>Bhadra</surname><given-names>P</given-names></string-name>, <string-name><surname>Li</surname><given-names>A</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Deep-AmPEP30: improve short antimicrobial peptides prediction with deep learning</article-title>. <source>Mol Ther Nucleic Acids</source><year>2020</year>;<volume>20</volume>:<fpage>882</fpage>–<lpage>94</lpage>.<pub-id pub-id-type="pmid">32464552</pub-id></mixed-citation>
    </ref>
    <ref id="ref50">
      <label>50.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ng</surname><given-names>XY</given-names></string-name>, <string-name><surname>Rosdi</surname><given-names>BA</given-names></string-name>, <string-name><surname>Shahrudin</surname><given-names>S</given-names></string-name></person-group>. <article-title>Prediction of antimicrobial peptides based on sequence alignment and support vector machine-pairwise algorithm utilizing LZ-complexity</article-title>. <source>Biomed Res Int</source><year>2015</year>;<volume>2015</volume>:<fpage>212715</fpage>.<pub-id pub-id-type="pmid">25802839</pub-id></mixed-citation>
    </ref>
    <ref id="ref51">
      <label>51.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lin</surname><given-names>W</given-names></string-name>, <string-name><surname>Dong</surname><given-names>X</given-names></string-name></person-group>. <article-title>Imbalanced multi-label learning for identifying antimicrobial peptides and their functional types</article-title>. <source>Bioinformatics</source><year>2016</year>;<volume>32</volume>(<issue>24</issue>):<fpage>3745</fpage>–<lpage>52</lpage>.<pub-id pub-id-type="pmid">27565585</pub-id></mixed-citation>
    </ref>
    <ref id="ref52">
      <label>52.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bhadra</surname><given-names>P</given-names></string-name>, <string-name><surname>Yan</surname><given-names>J</given-names></string-name>, <string-name><surname>Li</surname><given-names>J</given-names></string-name>, <etal>et al.</etal></person-group><article-title>AmPEP: sequence-based prediction of antimicrobial peptides using distribution patterns of amino acid properties and random forest</article-title>. <source>Sci Rep</source><year>2018</year>;<volume>8</volume>(<issue>1</issue>):<fpage>1</fpage>–<lpage>10</lpage>.<pub-id pub-id-type="pmid">29311619</pub-id></mixed-citation>
    </ref>
    <ref id="ref53">
      <label>53.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lawrence</surname><given-names>TJ</given-names></string-name>, <string-name><surname>Carper</surname><given-names>DL</given-names></string-name>, <string-name><surname>Spangler</surname><given-names>MK</given-names></string-name>, <etal>et al.</etal></person-group><article-title>amPEPpy 1.0: a portable and accurate antimicrobial peptide prediction tool</article-title>. <source>Bioinformatics</source><year>2020</year>;<volume>37</volume>(<issue>14</issue>):<fpage>2058</fpage>–<lpage>60</lpage>.</mixed-citation>
    </ref>
    <ref id="ref54">
      <label>54.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Santos-Junior</surname><given-names>CD</given-names></string-name>, <string-name><surname>Pan</surname><given-names>S</given-names></string-name>, <string-name><surname>Zhao</surname><given-names>X-M</given-names></string-name>, <etal>et al.</etal></person-group><article-title>MACREL: antimicrobial peptide screening in genomes and metagenomes</article-title>. <source>PeerJ</source><year>2020</year>;<volume>8</volume>:<fpage>e10555</fpage>.<pub-id pub-id-type="pmid">33384902</pub-id></mixed-citation>
    </ref>
    <ref id="ref55">
      <label>55.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gopal</surname><given-names>R</given-names></string-name>, <string-name><surname>Seo</surname><given-names>CH</given-names></string-name>, <string-name><surname>Song</surname><given-names>PI</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Effect of repetitive lysine-tryptophan motifs on the bactericidal activity of antimicrobial peptides</article-title>. <source>Amino Acids</source><year>2013</year>;<volume>44</volume>(<issue>2</issue>):<fpage>645</fpage>–<lpage>60</lpage>.<pub-id pub-id-type="pmid">22914980</pub-id></mixed-citation>
    </ref>
    <ref id="ref56">
      <label>56.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>García-Jacas</surname><given-names>CR</given-names></string-name>, <string-name><surname>Pinacho-Castellanos</surname><given-names>SA</given-names></string-name>, <string-name><surname>García-González</surname><given-names>LA</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Do deep learning models make a difference in the identification of antimicrobial peptides?</article-title><source>Brief Bioinform</source><year>2022</year>;<volume>23</volume>(<issue>3</issue>):<fpage>bbac094</fpage>.<pub-id pub-id-type="pmid">35380616</pub-id></mixed-citation>
    </ref>
    <ref id="ref57">
      <label>57.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ioannidis</surname><given-names>JPA</given-names></string-name></person-group>. <article-title>Why most published research findings are false</article-title>. <source>PLoS Med</source><year>2005</year>;<volume>2</volume>(<issue>8</issue>):<fpage>e124</fpage>.<pub-id pub-id-type="pmid">16060722</pub-id></mixed-citation>
    </ref>
    <ref id="ref58">
      <label>58.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Baker</surname><given-names>M</given-names></string-name></person-group>. <article-title>1,500 scientists lift the lid on reproducibility</article-title>. <source>Nature</source><year>2016</year>;<volume>533</volume>(<issue>7604</issue>):<fpage>452</fpage>–<lpage>4</lpage>.<pub-id pub-id-type="pmid">27225100</pub-id></mixed-citation>
    </ref>
    <ref id="ref59">
      <label>59.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Heil</surname><given-names>BJ</given-names></string-name>, <string-name><surname>Hoffman</surname><given-names>MM</given-names></string-name>, <string-name><surname>Markowetz</surname><given-names>F</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Reproducibility standards for machine learning in the life sciences</article-title>. <source>Nat Methods</source><year>2021</year>;<volume>18</volume>(<issue>10</issue>):<fpage>1132</fpage>–<lpage>5</lpage>.<pub-id pub-id-type="pmid">34462593</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
