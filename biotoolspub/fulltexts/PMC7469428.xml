<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">BMC Genet</journal-id>
    <journal-id journal-id-type="iso-abbrev">BMC Genet</journal-id>
    <journal-title-group>
      <journal-title>BMC Genetics</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1471-2156</issn>
    <publisher>
      <publisher-name>BioMed Central</publisher-name>
      <publisher-loc>London</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">7469428</article-id>
    <article-id pub-id-type="publisher-id">881</article-id>
    <article-id pub-id-type="doi">10.1186/s12863-020-00881-z</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Software</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>mbend: an R package for bending non-positive-definite symmetric matrices to positive-definite</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-0339-5442</contrib-id>
        <name>
          <surname>Nilforooshan</surname>
          <given-names>Mohammad Ali</given-names>
        </name>
        <address>
          <email>mohammad.nilforooshan@lic.co.nz</email>
        </address>
        <xref ref-type="aff" rid="Aff1"/>
      </contrib>
      <aff id="Aff1"><institution-wrap><institution-id institution-id-type="GRID">grid.466921.e</institution-id><institution-id institution-id-type="ISNI">0000 0001 0251 0731</institution-id><institution>Livestock Improvement Corporation, </institution></institution-wrap>Private Bag 3016, Hamilton, 3240 New Zealand </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>3</day>
      <month>9</month>
      <year>2020</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>3</day>
      <month>9</month>
      <year>2020</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2020</year>
    </pub-date>
    <volume>21</volume>
    <elocation-id>97</elocation-id>
    <history>
      <date date-type="received">
        <day>16</day>
        <month>3</month>
        <year>2020</year>
      </date>
      <date date-type="accepted">
        <day>29</day>
        <month>6</month>
        <year>2020</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2020</copyright-statement>
      <license license-type="OpenAccess">
        <license-p><bold>Open Access</bold>This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>. The Creative Commons Public Domain Dedication waiver (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/publicdomain/zero/1.0/">http://creativecommons.org/publicdomain/zero/1.0/</ext-link>) applies to the data made available in this article, unless otherwise stated in a credit line to the data.</license-p>
      </license>
    </permissions>
    <abstract id="Abs1">
      <sec>
        <title>Background</title>
        <p id="Par1">R package mbend was developed for bending symmetric non-positive-definite matrices to positive-definite (PD). Bending is a procedure of transforming non-PD matrices to PD. The covariance matrices used in multi-trait best linear unbiased prediction (BLUP) should be PD. Two bending methods are implemented in mbend. The first is an unweighted bending with small positive values in a descending order replacing negative eigenvalues (LRS14), and the second method is a weighted (precision-based) bending with a custom small positive value (ϵ) replacing smaller eigenvalues (HJ03). Weighted bending is beneficial, as it relaxes low precision elements to change and it reduces or prohibits the change in high precision elements. Therefore, a weighted version of LRS14 was developed in mbend. In cases where the precision of matrix elements is unknown, the package provides an unweighted version of HJ03. Another unweighted bending method (DB88) was tested, by which all eigenvalues are changed (eigenvalues less than ϵ replaced with 100 × ϵ), and it is originally designed for correlation matrices.</p>
      </sec>
      <sec>
        <title>Results</title>
        <p id="Par2">Different bending procedures were conducted on a 5 × 5 covariance matrix (<bold>V</bold>), <bold>V</bold> converted to a correlation matrix (<bold>C</bold>) and an ill-conditioned 1000 × 1000 genomic relationship matrix (<bold>G</bold>). Considering weighted distance statistics between matrix elements before and after bending, weighting considerably improved the bending quality. For weighted and unweighted bending of <bold>V</bold> and <bold>C</bold>, HJ03–4 (HJ03, ϵ = 10<sup>−4</sup>) performed the best. HJ03–2 (HJ03, ϵ = 10<sup>−2</sup>) ranked better than LRS14 for <bold>V</bold>, but not for <bold>C</bold>. Though the differences were marginal, LRS14 performed the best for <bold>G</bold>. DB88–4 (DB88, ϵ = 10<sup>−4</sup>) was used for unweighted bending and it ranked the last. This method could perform considerably better with a lower ϵ.</p>
      </sec>
      <sec>
        <title>Conclusions</title>
        <p id="Par3">R package mbend provides necessary tools for transforming symmetric non-PD matrices to PD, using different methods and parameters. There were benefits in both weighted bending and small positive values in a descending order replacing negative eigenvalues. Thus, weighted LRS14 was implemented in mbend. Different bending methods might be preferable for different matrices, depending on the matrix type (covariance vs. correlation), number and the magnitude of negative eigenvalues, and the matrix size.</p>
      </sec>
    </abstract>
    <kwd-group xml:lang="en">
      <title>Keywords</title>
      <kwd>Matrix</kwd>
      <kwd>Positive-definite</kwd>
      <kwd>Bending</kwd>
      <kwd>Eigenvalue</kwd>
      <kwd>R</kwd>
    </kwd-group>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>© The Author(s) 2020</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="Sec1">
    <title>Background</title>
    <p id="Par11">Even in their simplest form, multivariate animal models rely on genetic and residual variance-covariance matrices across traits [<xref ref-type="bibr" rid="CR1">1</xref>]. These matrices are in the order of the number of traits in the model, and their inverses are incorporated in the mixed model equations. Inversion of a matrix is often done using Cholesky decomposition, which requires the matrix to be positive-definite (PD). For models including additional random effects (e.g., animal permanent environment, maternal genetic, and maternal permanent environment), additional covariance matrices and their inverses are also required. To date, restricted (or residual) maximum likelihood (REML) [<xref ref-type="bibr" rid="CR2">2</xref>] is the preferred method for estimating the variance components associated with the model. REML estimates are always PD, but the starting matrices need to be PD. Elements of these matrices are usually from different sources of information and the resulting matrices are, therefore, likely to be non-PD [<xref ref-type="bibr" rid="CR3">3</xref>].</p>
    <p id="Par12">Another complexity is the estimation of covariance matrices for several traits at a time. This complexity increases by both the number of traits, and the number of random effects. In many situations, there might not be enough data points to support accurate inferences about all the variance components, simultaneously. Therefore, when many traits are included, variance components are usually estimated for subsets of traits [<xref ref-type="bibr" rid="CR4">4</xref>]. The assembly of these small matrices to a large matrix, together with best guesses for missing elements (from literature or phenotypic covariances and heritabilities) can be non-PD.</p>
    <p id="Par13">The procedure of “bending”, which involves modifying eigenvalues of a non-PD matrix, was first introduced by Hayes and Hill [<xref ref-type="bibr" rid="CR5">5</xref>]. Latter studies in the field of animal breeding and genetics presented different bending procedures. Jorjani et al. [<xref ref-type="bibr" rid="CR4">4</xref>] introduced weighted bending, where a weight matrix is provided for the matrix to be bent. Meyer and Kirkpatrick [<xref ref-type="bibr" rid="CR6">6</xref>] developed a bending procedure, based on penalized maximum likelihood and reducing bias in the estimates of canonical heritabilities (the eigenvalues of <bold>P</bold><sup>−1</sup><bold>G</bold>, where <bold>P</bold> and <bold>G</bold> are the phenotypic and genetic covariance matrices, respectively). Also, Schaeffer [<xref ref-type="bibr" rid="CR3">3</xref>] introduced a bending procedure, which involves changing negative eigenvalues to small positive values and reconstructing the matrix. A bending method for correlation matrices (also called smoothing), used in the field of psychology, involves changing all eigenvalues [<xref ref-type="bibr" rid="CR7">7</xref>]. All these bending methods aim to produce a PD matrix, least deviated from the original non-PD matrix.</p>
    <p id="Par14">The aim of this study was to introduce R package mbend [<xref ref-type="bibr" rid="CR8">8</xref>], which is a free and open source tool for bending symmetric non-PD matrices to PD, based on eigenvalue modification of the non-PD matrix. Comparison of different methods were provided, using example covariance and correlation matrices, as well as an artificial ill-conditioned genomic relationship matrix (<bold>G</bold>). R package mbend covers methods of Jorjani et al. [<xref ref-type="bibr" rid="CR4">4</xref>] and Schaeffer [<xref ref-type="bibr" rid="CR3">3</xref>], as well as extensions to these methods.</p>
  </sec>
  <sec id="Sec2">
    <title>Implementation</title>
    <p id="Par15">R package mbend [<xref ref-type="bibr" rid="CR8">8</xref>] is written in R, and it is available on CRAN repository (<ext-link ext-link-type="uri" xlink:href="https://cran.r-project.org">https://cran.r-project.org</ext-link>) and can be installed, using the command install.packages(“mbend”). In this study, the functionality of this package was presented using the same 5 × 5 non-PD matrix used by Jorjani et al. [<xref ref-type="bibr" rid="CR4">4</xref>] and Schaeffer [<xref ref-type="bibr" rid="CR3">3</xref>].
<disp-formula id="Equa"><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \mathbf{V}=\left[\begin{array}{ccccc}100&amp; 95&amp; 80&amp; 40&amp; 40\\ {}&amp; 100&amp; 95&amp; 80&amp; 40\\ {}&amp; &amp; 100&amp; 95&amp; 80\\ {}&amp; &amp; &amp; 100&amp; 95\\ {} Sym.&amp; &amp; &amp; &amp; 100\end{array}\right] $$\end{document}</tex-math><mml:math id="M2" display="block"><mml:mi mathvariant="bold">V</mml:mi><mml:mo>=</mml:mo><mml:mfenced close="]" open="["><mml:mtable><mml:mtr><mml:mtd><mml:mn>100</mml:mn></mml:mtd><mml:mtd><mml:mn>95</mml:mn></mml:mtd><mml:mtd><mml:mn>80</mml:mn></mml:mtd><mml:mtd><mml:mn>40</mml:mn></mml:mtd><mml:mtd><mml:mn>40</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mn>100</mml:mn></mml:mtd><mml:mtd><mml:mn>95</mml:mn></mml:mtd><mml:mtd><mml:mn>80</mml:mn></mml:mtd><mml:mtd><mml:mn>40</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd/><mml:mtd><mml:mn>100</mml:mn></mml:mtd><mml:mtd><mml:mn>95</mml:mn></mml:mtd><mml:mtd><mml:mn>80</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd/><mml:mtd/><mml:mtd><mml:mn>100</mml:mn></mml:mtd><mml:mtd><mml:mn>95</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi mathvariant="italic">Sym</mml:mi><mml:mo>.</mml:mo></mml:mtd><mml:mtd/><mml:mtd/><mml:mtd/><mml:mtd><mml:mn>100</mml:mn></mml:mtd></mml:mtr></mml:mtable></mml:mfenced></mml:math><graphic xlink:href="12863_2020_881_Article_Equa.gif" position="anchor"/></alternatives></disp-formula></p>
    <p id="Par16">To study bending on a correlation matrix, <bold>C</bold> = <bold>V</bold>/100 was used. Jorjani et al. [<xref ref-type="bibr" rid="CR4">4</xref>] used a matrix of weighting factors (<bold>W</bold>) as the reciprocal of the number of animals involved in the estimation of variance components. The same matrix is also used in this study for weighted bending.
<disp-formula id="Equb"><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \mathbf{W}=1/\left[\begin{array}{ccccc}1000&amp; 500&amp; 20&amp; 50&amp; 200\\ {}&amp; 1000&amp; 500&amp; 5&amp; 50\\ {}&amp; &amp; 1000&amp; 20&amp; 20\\ {}&amp; &amp; &amp; 1000&amp; 200\\ {} Sym.&amp; &amp; &amp; &amp; 1000\end{array}\right] $$\end{document}</tex-math><mml:math id="M4" display="block"><mml:mi mathvariant="bold">W</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mfenced close="]" open="["><mml:mtable><mml:mtr><mml:mtd><mml:mn>1000</mml:mn></mml:mtd><mml:mtd><mml:mn>500</mml:mn></mml:mtd><mml:mtd><mml:mn>20</mml:mn></mml:mtd><mml:mtd><mml:mn>50</mml:mn></mml:mtd><mml:mtd><mml:mn>200</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mn>1000</mml:mn></mml:mtd><mml:mtd><mml:mn>500</mml:mn></mml:mtd><mml:mtd><mml:mn>5</mml:mn></mml:mtd><mml:mtd><mml:mn>50</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd/><mml:mtd><mml:mn>1000</mml:mn></mml:mtd><mml:mtd><mml:mn>20</mml:mn></mml:mtd><mml:mtd><mml:mn>20</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd/><mml:mtd/><mml:mtd><mml:mn>1000</mml:mn></mml:mtd><mml:mtd><mml:mn>200</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi mathvariant="italic">Sym</mml:mi><mml:mo>.</mml:mo></mml:mtd><mml:mtd/><mml:mtd/><mml:mtd/><mml:mtd><mml:mn>1000</mml:mn></mml:mtd></mml:mtr></mml:mtable></mml:mfenced></mml:math><graphic xlink:href="12863_2020_881_Article_Equb.gif" position="anchor"/></alternatives></disp-formula></p>
    <p id="Par17">For further comparisons, an ill-conditioned <bold>G</bold> matrix was constructed using random genotypes on 5000 SNP and 1000 animals, without any quality control checks, and 10 duplicated genotypes, which resulted in a <bold>G</bold> with 5 negative eigenvalues (ranging between –224e–17 to − 3.5e–17) and 357 eigenvalues between 0 and 1. Matrix <bold>G</bold> was constructed using method 1 of VanRaden [<xref ref-type="bibr" rid="CR9">9</xref>]. The code for constructing the <bold>G</bold> matrix together with all the (R) code used in this study are provided in the data repository.</p>
    <p id="Par18">R package mbend [<xref ref-type="bibr" rid="CR8">8</xref>] was used throughout this study. It provides different methods for weighted and unweighted bending of symmetric non-PD matrices to PD. Two bending methods of Jorjani et al. [<xref ref-type="bibr" rid="CR4">4</xref>] and Schaeffer [<xref ref-type="bibr" rid="CR3">3</xref>] and extensions to them are implemented in R package mbend [<xref ref-type="bibr" rid="CR8">8</xref>].</p>
    <sec id="Sec3">
      <title>Method of Jorjani et al. [<xref ref-type="bibr" rid="CR4">4</xref>]</title>
      <p id="Par19">This method (HJ03) is an iterative weighting procedure that converts a non-PD covariance matrix to a PD matrix at convergence. It considers different precision associated with different elements of the covariance matrix. Therefore, minimising the change in matrix elements with high accuracy, through a weight matrix. Given the non-PD covariance matrix <bold>V</bold>, the weight matrix <bold>W</bold>, and a small positive real number (e.g., ϵ = 10<sup>−4</sup>), the procedure is as follows:
<list list-type="order"><list-item><p id="Par20">Decompose <bold>V</bold><sub><italic>n</italic></sub> to <bold>U</bold><sub><italic>n</italic></sub><bold>D</bold><sub><italic>n</italic></sub><bold>U</bold><sub><italic>n</italic></sub>′, where <bold>U</bold><sub><italic>n</italic></sub> and <bold>D</bold><sub><italic>n</italic></sub> are the matrix of eigenvectors and diagonal matrix of eigenvalues, and <italic>n</italic> is the iteration number.</p></list-item><list-item><p id="Par21">Replace eigenvalues less than ϵ with ϵ in <bold>D</bold><sub><italic>n</italic></sub> to get <bold>Δ</bold><sub><italic>n</italic></sub>.</p></list-item><list-item><p id="Par22"><bold>V</bold><sub><italic>n</italic> + 1</sub> = <bold>V</bold><sub><italic>n</italic></sub> − [<bold>V</bold><sub><italic>n</italic></sub> − <bold>U</bold><sub><italic>n</italic></sub><bold>Δ</bold><sub><italic>n</italic></sub><bold>U</bold><sub><italic>n</italic></sub>′] ∘ <bold>W</bold>, where ∘ is the Hadamard function.</p></list-item><list-item><p id="Par23">Repeat until <bold>V</bold><sub><italic>n</italic> + 1</sub> is PD.</p></list-item></list></p>
      <p id="Par24">The smaller the <italic>w</italic><sub><italic>ij</italic></sub> (element in <bold>W</bold>), the higher the relative certainty about <italic>v</italic><sub><italic>ij</italic></sub> (element in <bold>V</bold>). Accordingly, to retain an element of the matrix fixed during bending, that element would receive a weight of zero. In comparison with the weighted procedure, in the unweighted procedure, <bold>V</bold><sub><italic>n</italic> + 1</sub> = <bold>U</bold><sub><italic>n</italic></sub><bold>Δ</bold><sub><italic>n</italic></sub><bold>U</bold><sub><italic>n</italic></sub>′. If no weight matrix is provided, the program performs an unweighted bending. Also, if the matrix is already PD, the program returns a message that “No action was required. The matrix is positive-definite”.</p>
      <p id="Par25">Jorjani et al. [<xref ref-type="bibr" rid="CR4">4</xref>] extended their weighted bending method for covariance matrices to correlation matrices. R package mbend took a different approach for correlation matrices. First, it automatically recognises correlation matrices by checking all diagonal values against 1. Second, it treats correlation matrices as covariance matrices that should keep their diagonal elements constant during bending, by setting <italic>w</italic><sub><italic>ii</italic></sub> = 0. To avoid this restriction for a non-correlation matrix with all diagonal elements of 1 (e.g., a phenotypic matrix with variables standardised for phenotypic variances of 1), simply the matrix is multiplied by a positive constant, and then the resulting bent matrix is divided by that constant. A different approach that could be used for correlation matrices was treating them as covariance matrices and transforming the bent matrix (<inline-formula id="IEq1"><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \hat{\mathbf{V}} $$\end{document}</tex-math><mml:math id="M6" display="inline"><mml:mover accent="true"><mml:mi mathvariant="bold">V</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover></mml:math><inline-graphic xlink:href="12863_2020_881_Article_IEq1.gif"/></alternatives></inline-formula>) to <inline-formula id="IEq2"><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \mathbf{T}\hat{\mathbf{V}}\mathbf{T}^{\prime } $$\end{document}</tex-math><mml:math id="M8" display="inline"><mml:mi mathvariant="bold">T</mml:mi><mml:mover accent="true"><mml:mi mathvariant="bold">V</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mi mathvariant="bold">T</mml:mi><mml:mo>′</mml:mo></mml:math><inline-graphic xlink:href="12863_2020_881_Article_IEq2.gif"/></alternatives></inline-formula>, where <inline-formula id="IEq3"><alternatives><tex-math id="M9">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ {\mathbf{T}}^2=\mathit{\operatorname{diag}}\left(1/\mathit{\operatorname{diag}}\left(\hat{\mathbf{V}}\right)\right) $$\end{document}</tex-math><mml:math id="M10" display="inline"><mml:msup><mml:mi mathvariant="bold">T</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>=</mml:mo><mml:mo mathvariant="italic">diag</mml:mo><mml:mfenced close=")" open="("><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mo mathvariant="italic">diag</mml:mo><mml:mfenced close=")" open="("><mml:mover accent="true"><mml:mi mathvariant="bold">V</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover></mml:mfenced></mml:mrow></mml:mfenced></mml:math><inline-graphic xlink:href="12863_2020_881_Article_IEq3.gif"/></alternatives></inline-formula>.</p>
    </sec>
    <sec id="Sec4">
      <title>Method of Schaeffer [<xref ref-type="bibr" rid="CR3">3</xref>]</title>
      <p id="Par26">This method (LRS14) is an unweighted bending procedure, which means that different matrix elements are of the same precision. Negative eigenvalues are replaced with small positive values that are in a descending order (unlike equal values for HJ03). In this method, each of the <italic>m</italic> negative eigenvalues (<italic>λ</italic><sub><italic>i</italic></sub>) is replaced with <italic>ρ</italic>(<italic>s</italic> − <italic>λ</italic><sub><italic>i</italic></sub>)<sup>2</sup>/(100<italic>s</italic><sup>2</sup> + 1), where <italic>ρ</italic> is the smallest positive eigenvalue and <inline-formula id="IEq4"><alternatives><tex-math id="M11">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ s=2\sum \limits_{i=1}^m{\lambda}_i $$\end{document}</tex-math><mml:math id="M12" display="inline"><mml:mi>s</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>m</mml:mi></mml:munderover><mml:msub><mml:mi>λ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12863_2020_881_Article_IEq4.gif"/></alternatives></inline-formula>. In R package mbend, a weighted bending derivate of LRS14 is implemented by combining this method with HJ03 [<xref ref-type="bibr" rid="CR8">8</xref>].</p>
    </sec>
    <sec id="Sec5">
      <title>Method of Bock et al. [<xref ref-type="bibr" rid="CR7">7</xref>]</title>
      <p id="Par27">This method (DB88) is used for bending correlation matrices [<xref ref-type="bibr" rid="CR7">7</xref>]. In this method, eigenvalues smaller than ϵ are replaced with 100 × ϵ. Also, unlike Jorjani et al. [<xref ref-type="bibr" rid="CR4">4</xref>] and Schaeffer [<xref ref-type="bibr" rid="CR3">3</xref>], eigenvalues greater than ϵ are changed to sum the number of those eigenvalues. The logic behind it might be that the sum of eigenvalues in a PD correlation matrix is equal to the size (trace) of the matrix. This method is implemented in function cor.smooth of R package psych (psych::cor.smooth) [<xref ref-type="bibr" rid="CR10">10</xref>]. As this method is designed for bending correlation matrices, covariance matrices are first transformed to correlation matrices, after bending, the resulting matrix is transformed back to a covariance matrix (i.e., <inline-formula id="IEq5"><alternatives><tex-math id="M13">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \mathbf{T}\hat{\mathbf{C}}\mathbf{T}^{\prime } $$\end{document}</tex-math><mml:math id="M14" display="inline"><mml:mi mathvariant="bold">T</mml:mi><mml:mover accent="true"><mml:mi mathvariant="bold">C</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mi mathvariant="bold">T</mml:mi><mml:mo>′</mml:mo></mml:math><inline-graphic xlink:href="12863_2020_881_Article_IEq5.gif"/></alternatives></inline-formula>, where <bold>T</bold><sup>2</sup> =  <italic>diag</italic> (<italic>diag</italic>(<bold>V</bold>))). That means, only the off-diagonal elements of the matrix change by bending.</p>
    </sec>
    <sec id="Sec6">
      <title>Deviation and correlation</title>
      <p id="Par28">R package mbend returns the following statistics:
<list list-type="order"><list-item><p id="Par29">Minimum deviation (<inline-formula id="IEq6"><alternatives><tex-math id="M15">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \hat{\mathbf{V}}-\mathbf{V} $$\end{document}</tex-math><mml:math id="M16" display="inline"><mml:mover accent="true"><mml:mi mathvariant="bold">V</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mo>−</mml:mo><mml:mi mathvariant="bold">V</mml:mi></mml:math><inline-graphic xlink:href="12863_2020_881_Article_IEq6.gif"/></alternatives></inline-formula>), together with matrix indices of the element</p></list-item><list-item><p id="Par30">Maximum deviation, together with matrix indices of the element</p></list-item><list-item><p id="Par31">Average deviation of the upper triangle elements</p></list-item><list-item><p id="Par32">Average absolute deviation of the upper triangle elements (AAD)</p></list-item><list-item><p id="Par33">Weighted AAD</p></list-item><list-item><p id="Par34">Correlation between the upper triangle elements</p></list-item><list-item><p id="Par35">Weighted correlation between the upper triangle elements</p></list-item><list-item><p id="Par36">Root of mean squared deviation of the upper triangle elements (RMSD)</p></list-item><list-item><p id="Par37">Weighted RMSD
<disp-formula id="Equc"><alternatives><tex-math id="M17">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ {\displaystyle \begin{array}{rr}\mathrm{AAD}&amp; =\frac{\sum_{i=1}^n{\sum}_{j=1,j\ge i}^n\left|{\hat{v}}_{ij}-{v}_{ij}\right|}{n\left(n+1\right)/2},\\ {}\mathrm{Weighted}\ {\mathrm{AAD}}_{\left({w}_{ij}&gt;0\right)}&amp; =\frac{\sum_{i=1}^n{\sum}_{j=1,j\ge i}^n\left|\left({\hat{v}}_{ij}-{v}_{ij}\right)/{w}_{ij}\right|}{\sum_{i=1}^n{\sum}_{j=1,j\ge i}^n\left(1/{w}_{ij}\right)},\\ {}\mathrm{RMSD}&amp; =\sqrt{\frac{\sum_{i=1}^n{\sum}_{j=1,j\ge i}^n{\left({\hat{v}}_{ij}-{v}_{ij}\right)}^2}{n\left(n+1\right)/2}},\\ {}{\mathrm{Weighted}\ \mathrm{RMSD}}_{\left({w}_{ij}&gt;0\right)}&amp; =\sqrt{\frac{\sum_{i=1}^n{\sum}_{j=1,j\ge i}^n{\left(\left({\hat{v}}_{ij}-{v}_{ij}\right)/{w}_{ij}\right)}^2}{\sum_{i=1}^n{\sum}_{j=1,j\ge i}^n\left(1/{w}_{ij}^2\right)}},\end{array}} $$\end{document}</tex-math><mml:math id="M18" display="block"><mml:mtable columnalign="right" displaystyle="true"><mml:mtr><mml:mtd><mml:mi>AAD</mml:mi></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>≥</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:mfenced close="|" open="|"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>v</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mi mathvariant="italic">ij</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mi mathvariant="italic">ij</mml:mi></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfenced><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mtext>Weighted</mml:mtext><mml:mspace width="0.25em"/><mml:msub><mml:mi>AAD</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mi mathvariant="italic">ij</mml:mi></mml:msub><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mfenced></mml:msub></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>≥</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:mfenced close="|" open="|"><mml:mrow><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>v</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mi mathvariant="italic">ij</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mi mathvariant="italic">ij</mml:mi></mml:msub></mml:mrow></mml:mfenced><mml:mo>/</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mi mathvariant="italic">ij</mml:mi></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>≥</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:mfenced close=")" open="("><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mi mathvariant="italic">ij</mml:mi></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mtext>RMSD</mml:mtext></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:msqrt><mml:mfrac><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>≥</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:msup><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>v</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mi mathvariant="italic">ij</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mi mathvariant="italic">ij</mml:mi></mml:msub></mml:mrow></mml:mfenced><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfenced><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mfrac></mml:msqrt><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mtext>Weighted RMSD</mml:mtext><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mi mathvariant="italic">ij</mml:mi></mml:msub><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mfenced></mml:msub></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:msqrt><mml:mfrac><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>≥</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:msup><mml:mfenced close=")" open="("><mml:mrow><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>v</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mi mathvariant="italic">ij</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mi mathvariant="italic">ij</mml:mi></mml:msub></mml:mrow></mml:mfenced><mml:mo>/</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mi mathvariant="italic">ij</mml:mi></mml:msub></mml:mrow></mml:mfenced><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>≥</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:mfenced close=")" open="("><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:msubsup><mml:mi>w</mml:mi><mml:mi mathvariant="italic">ij</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mfenced></mml:mrow></mml:mfrac></mml:msqrt><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math><graphic xlink:href="12863_2020_881_Article_Equc.gif" position="anchor"/></alternatives></disp-formula></p></list-item></list>where, <italic>n</italic> is the size of the matrix, and <italic>w</italic><sub><italic>ij</italic></sub>, <italic>v</italic><sub><italic>ij</italic></sub> and <inline-formula id="IEq7"><alternatives><tex-math id="M19">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ {\hat{v}}_{ij} $$\end{document}</tex-math><mml:math id="M20" display="inline"><mml:msub><mml:mover accent="true"><mml:mi>v</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mi mathvariant="italic">ij</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12863_2020_881_Article_IEq7.gif"/></alternatives></inline-formula> are the elements of <bold>W</bold>, <bold>V</bold> and <inline-formula id="IEq8"><alternatives><tex-math id="M21">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \hat{\mathbf{V}} $$\end{document}</tex-math><mml:math id="M22" display="inline"><mml:mover accent="true"><mml:mi mathvariant="bold">V</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover></mml:math><inline-graphic xlink:href="12863_2020_881_Article_IEq8.gif"/></alternatives></inline-formula>, respectively. The weighted statistics (weighted correlation, weighted AAD and weighted RMSD) are calculated for matrix elements with <italic>w</italic><sub><italic>ij</italic></sub> &gt; 0. For correlation matrices, upper triangle elements did not include diagonal elements. Thus,
<disp-formula id="Equd"><alternatives><tex-math id="M23">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ {\displaystyle \begin{array}{rr}\mathrm{AAD}&amp; =\frac{\sum_{i=1}^{n-1}{\sum}_{j=2,j\ge i}^n\left|{\hat{v}}_{ij}-{v}_{i\mathrm{j}}\right|}{n\left(n-1\right)/2},\\ {}\mathrm{Weighted}\ {\mathrm{AAD}}_{\left({w}_{ij}&gt;0\right)}&amp; =\frac{\sum_{i=1}^{n-1}{\sum}_{j=2,j\ge i}^n\left|\left({\hat{v}}_{ij}-{v}_{ij}\right)/{w}_{ij}\right|}{\sum_{i=1}^{n-1}{\sum}_{j=2,j\ge i}^n\left(1/{w}_{ij}\right)},\\ {}\mathrm{RMSD}&amp; =\sqrt{\frac{\sum_{i=1}^{n-1}{\sum}_{j=2,j\ge i}^n{\left({\hat{v}}_{ij}-{v}_{ij}\right)}^2}{n\left(n-1\right)/2}},\\ {}{\mathrm{Weighted}\ \mathrm{RMSD}}_{\left({w}_{ij}&gt;0\right)}&amp; =\sqrt{\frac{\sum_{i=1}^{n-1}{\sum}_{j=2,j\ge i}^n{\left(\left({\hat{v}}_{ij}-{v}_{ij}\right)/{w}_{ij}\right)}^2}{\sum_{i=1}^{n-1}{\sum}_{j=2,j\ge i}^n\left(1/{w}_{ij}^2\right)}}.\end{array}} $$\end{document}</tex-math><mml:math id="M24" display="block"><mml:mtable columnalign="right" displaystyle="true"><mml:mtr><mml:mtd><mml:mi>AAD</mml:mi></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>≥</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:mfenced close="|" open="|"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>v</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mi mathvariant="italic">ij</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfenced><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mtext>Weighted</mml:mtext><mml:mspace width="0.25em"/><mml:msub><mml:mi>AAD</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mi mathvariant="italic">ij</mml:mi></mml:msub><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mfenced></mml:msub></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>≥</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:mfenced close="|" open="|"><mml:mrow><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>v</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mi mathvariant="italic">ij</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mi mathvariant="italic">ij</mml:mi></mml:msub></mml:mrow></mml:mfenced><mml:mo>/</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mi mathvariant="italic">ij</mml:mi></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>≥</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:mfenced close=")" open="("><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mi mathvariant="italic">ij</mml:mi></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mtext>RMSD</mml:mtext></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:msqrt><mml:mfrac><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>≥</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:msup><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>v</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mi mathvariant="italic">ij</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mi mathvariant="italic">ij</mml:mi></mml:msub></mml:mrow></mml:mfenced><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfenced><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mfrac></mml:msqrt><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mtext>Weighted RMSD</mml:mtext><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mi mathvariant="italic">ij</mml:mi></mml:msub><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mfenced></mml:msub></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:msqrt><mml:mfrac><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>≥</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:msup><mml:mfenced close=")" open="("><mml:mrow><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>v</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mi mathvariant="italic">ij</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mi mathvariant="italic">ij</mml:mi></mml:msub></mml:mrow></mml:mfenced><mml:mo>/</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mi mathvariant="italic">ij</mml:mi></mml:msub></mml:mrow></mml:mfenced><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>≥</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:mfenced close=")" open="("><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:msubsup><mml:mi>w</mml:mi><mml:mi mathvariant="italic">ij</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mfenced></mml:mrow></mml:mfrac></mml:msqrt><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math><graphic xlink:href="12863_2020_881_Article_Equd.gif" position="anchor"/></alternatives></disp-formula></p>
    </sec>
    <sec id="Sec7">
      <title>Function “bend”</title>
      <p id="Par38">R package mbend has a function called bend that is used with the syntax: bend (inmat, wtmat, reciprocal = FALSE, max.iter = 10,000, small.positive = 0.0001, method = “hj”). If any of the last 4 arguments are missing, the function will use the default value (FALSE, 10000, 0.0001, and “hj”, respectively). Arguments inmat and wtmat are for the matrix to be bent and the weight matrix. If wtmat is missing, an unweighted bending is performed. Argument reciprocal takes TRUE or FALSE as input, and if TRUE, reciprocals of <bold>W</bold> elements are used. Where <italic>w</italic><sub><italic>ij</italic></sub> = 0, it would remain 0. This argument is ignored if no weight matrix is provided to the function. The maximum number of iterations is defined by max.iter. The argument small.positive is used for HJ03 and ignored for LRS14. It is a user-defined small positive value (ϵ) replacing smaller eigenvalues in <bold>D</bold> [<xref ref-type="bibr" rid="CR4">4</xref>]. Argument method takes “hj” or “lrs” for HJ03 and LRS14, respectively.</p>
      <p id="Par39">The function returns <inline-formula id="IEq9"><alternatives><tex-math id="M25">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \hat{\mathbf{V}} $$\end{document}</tex-math><mml:math id="M26" display="inline"><mml:mover accent="true"><mml:mi mathvariant="bold">V</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover></mml:math><inline-graphic xlink:href="12863_2020_881_Article_IEq9.gif"/></alternatives></inline-formula>, eigenvalues of <bold>V</bold> and <inline-formula id="IEq10"><alternatives><tex-math id="M27">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \hat{\mathbf{V}} $$\end{document}</tex-math><mml:math id="M28" display="inline"><mml:mover accent="true"><mml:mi mathvariant="bold">V</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover></mml:math><inline-graphic xlink:href="12863_2020_881_Article_IEq10.gif"/></alternatives></inline-formula>, and the statistics described in “Deviation and correlation”, all in a single list. Where weighted bending is applied, the number of upper triangle elements with <italic>w</italic><sub><italic>ij</italic></sub> &gt; 0 (w_gt_0) is reported, as the weighted statistics rely on these observations. An example of weighted bending a correlation matrix, using bend function of mbend package is provided in the Additional file <xref rid="MOESM1" ref-type="media">1</xref>.</p>
    </sec>
  </sec>
  <sec id="Sec8">
    <title>Results</title>
    <sec id="Sec9">
      <title>The covariance matrix (V)</title>
      <p id="Par40">Matrix <bold>V</bold> is a non-PD covariance matrix. The following command in R shows eigenvalues from the eigendecomposition of <bold>V</bold>.</p>
      <p id="Par41">&gt; round (eigen(V)$values, 2)</p>
      <p>[1] 399.48 98.52 23.65 -3.12 -18.52.</p>
      <p id="Par42">Table <xref rid="Tab1" ref-type="table">1</xref> shows deviations and correlations between <bold>V</bold> and <inline-formula id="IEq11"><alternatives><tex-math id="M29">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \hat{\mathbf{V}} $$\end{document}</tex-math><mml:math id="M30" display="inline"><mml:mover accent="true"><mml:mi mathvariant="bold">V</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover></mml:math><inline-graphic xlink:href="12863_2020_881_Article_IEq11.gif"/></alternatives></inline-formula> for unweighted bending, using HJ03–2 (HJ03, ϵ = 10<sup>−2</sup>), HJ03–4 (HJ03, ϵ = 10<sup>−4</sup>), LRS14 and DB88–4 (DB88, ϵ = 10<sup>−4</sup>). The unweighted HJ03 is like the iterative spectral method [<xref ref-type="bibr" rid="CR11">11</xref>], which is a simplified form of altering projections method [<xref ref-type="bibr" rid="CR12">12</xref>]. The difference between the unweighted HJ03 and the iterative spectral method is that, in the iterative spectral method, negative eigenvalues are replaced with the small positive value, but in HJ03, eigenvalues smaller than the small positive value are replaced with the small positive value. An unweighted HJ03 is equivalent to HJ03 with <bold>W</bold> = <bold>11</bold>′. Though some differences were small, the methods can be ranked from HJ03–4 being the best performer to HJ03–2, LRS14 and DB88–4. All the processes converged in 1 iteration.
<table-wrap id="Tab1"><label>Table 1</label><caption><p>Deviation and correlation between the upper triangle elements of <italic>V</italic><sub>(5 × 5)</sub> (the covariance matrix) and its unweighted bent matrix</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Statistics</th><th>HJ03–2<sup><italic>a</italic></sup></th><th>HJ03–4<sup><italic>b</italic></sup></th><th>LRS14<sup><italic>c</italic></sup></th><th>DB88–4<sup><italic>d</italic></sup></th></tr></thead><tbody><tr><td>Min (dev.)</td><td>−5.9320</td><td>−5.9296</td><td>−5.9370</td><td>−10.9546</td></tr><tr><td>Max (dev.)</td><td>6.5016</td><td>6.4973</td><td>6.5418</td><td>2.6427</td></tr><tr><td>Mean (dev.)</td><td>0.7241</td><td>0.7235</td><td>0.7330</td><td>−2.9890</td></tr><tr><td>AAD</td><td>3.3754</td><td>3.3727</td><td>3.4087</td><td>3.6937</td></tr><tr><td>Correlation</td><td>0.9856</td><td>0.9856</td><td>0.9855</td><td>0.9833</td></tr><tr><td>RMSD</td><td>3.9300</td><td>3.9275</td><td>3.9542</td><td>5.0784</td></tr><tr><td>Number of iterations</td><td>1</td><td>1</td><td>1</td><td>1</td></tr></tbody></table><table-wrap-foot><p>dev. = bend(<bold>V</bold>) – <bold>V</bold>; AAD = average absolute deviation; RMSD = root of mean squared deviation; <sup><italic>a</italic></sup> Method of Jorjani et al. [<xref ref-type="bibr" rid="CR4">4</xref>] with <italic>ϵ</italic> = 10<sup>−2</sup>; <sup><italic>b</italic></sup> Method of Jorjani et al. [<xref ref-type="bibr" rid="CR4">4</xref>] with <italic>ϵ</italic> = 10<sup>−4</sup>; <sup><italic>c</italic></sup> Method of Schaeffer [<xref ref-type="bibr" rid="CR3">3</xref>]; <sup><italic>d</italic></sup> Method of Bock et al. [<xref ref-type="bibr" rid="CR7">7</xref>] with <italic>ϵ</italic> = 10<sup>−4</sup></p></table-wrap-foot></table-wrap></p>
      <p id="Par43">Table <xref rid="Tab2" ref-type="table">2</xref> shows deviations and correlations between <bold>V</bold> and <inline-formula id="IEq12"><alternatives><tex-math id="M31">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \hat{\mathbf{V}} $$\end{document}</tex-math><mml:math id="M32" display="inline"><mml:mover accent="true"><mml:mi mathvariant="bold">V</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover></mml:math><inline-graphic xlink:href="12863_2020_881_Article_IEq12.gif"/></alternatives></inline-formula> for weighted bending, using HJ03–2, HJ03–4 and LRS14. The weighted bending procedures produced the same weighted correlation coefficients (0.9955) between the upper triangle elements of <bold>V</bold> and <inline-formula id="IEq13"><alternatives><tex-math id="M33">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \hat{\mathbf{V}} $$\end{document}</tex-math><mml:math id="M34" display="inline"><mml:mover accent="true"><mml:mi mathvariant="bold">V</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover></mml:math><inline-graphic xlink:href="12863_2020_881_Article_IEq13.gif"/></alternatives></inline-formula>. As expected, HJ03–4 performed better than HJ03–2. LRS14 produced the closest mean of deviation to zero. However, it performed worse than HJ03–2 (considering the range of deviations, weighted AAD, weighted RMSD, and the number of iterations to convergence). LRS14 took the maximum (787) number of iterations to converge. However, it was not a concern, as the convergence was made in less than 0.2 s, due to the small size of <bold>V</bold>.
<table-wrap id="Tab2"><label>Table 2</label><caption><p>Deviation and correlation between the upper triangle elements of <italic>V</italic><sub>(5 × 5)</sub> (the covariance matrix) and its weighted (using <italic>W</italic><sub>(5 × 5)</sub>) bent matrix</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Statistics</th><th>HJ03–2<sup><italic>a</italic></sup></th><th>HJ03–4<sup><italic>b</italic></sup></th><th>LRS14<sup><italic>c</italic></sup></th></tr></thead><tbody><tr><td>Min (dev.)</td><td>−20.0068</td><td>−20.0008</td><td>−19.9923</td></tr><tr><td>Max (dev.)</td><td>5.8467</td><td>5.8456</td><td>5.8638</td></tr><tr><td>Mean (dev.)</td><td>−1.7167</td><td>−1.7161</td><td>−1.7158</td></tr><tr><td>AAD</td><td>3.6262</td><td>3.6253</td><td>3.6338</td></tr><tr><td>Weighted AAD</td><td>0.6102</td><td>0.6100</td><td>0.6122</td></tr><tr><td>Correlation</td><td>0.9623</td><td>0.9623</td><td>0.9622</td></tr><tr><td>Weighted correlation</td><td>0.9955</td><td>0.9955</td><td>0.9955</td></tr><tr><td>RMSD</td><td>6.3706</td><td>6.3687</td><td>6.3748</td></tr><tr><td>Weighted RMSD</td><td>0.5328</td><td>0.5327</td><td>0.5347</td></tr><tr><td>Number of iterations</td><td>248</td><td>428</td><td>787</td></tr></tbody></table><table-wrap-foot><p>dev. = bend(<bold>V</bold>) – <bold>V</bold>; AAD = average absolute deviation; RMSD = root of mean squared deviation; <sup><italic>a</italic></sup> Method of Jorjani et al. [<xref ref-type="bibr" rid="CR4">4</xref>] with ϵ = 10<sup>−2</sup>; <sup><italic>b</italic></sup> Method of Jorjani et al. [<xref ref-type="bibr" rid="CR4">4</xref>] with ϵ = 10<sup>−4</sup>; <sup><italic>c</italic></sup> Method of Schaeffer [<xref ref-type="bibr" rid="CR3">3</xref>]</p></table-wrap-foot></table-wrap></p>
      <p id="Par44">The program provides weighted statistics for weighted bending. Those statistics were manually calculated for unweighted bending of <bold>V</bold> and <bold>C</bold> matrices. The code is available in the data repository, and the results are provided in Table S1. Comparing Tables <xref rid="Tab1" ref-type="table">1</xref>, <xref rid="Tab2" ref-type="table">2</xref> and S1 shows lower weighted AAD and weighted RMSD, and higher weighted correlation for weighted bending compared to unweighted bending, at the cost of greater deviations, AAD and RMSD, and lower correlation coefficients.</p>
    </sec>
    <sec id="Sec10">
      <title>The correlation matrix (C)</title>
      <p id="Par45">Table <xref rid="Tab3" ref-type="table">3</xref> shows deviations and correlations between <bold>C</bold> and <inline-formula id="IEq14"><alternatives><tex-math id="M35">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \hat{\mathbf{C}} $$\end{document}</tex-math><mml:math id="M36" display="inline"><mml:mover accent="true"><mml:mi mathvariant="bold">C</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover></mml:math><inline-graphic xlink:href="12863_2020_881_Article_IEq14.gif"/></alternatives></inline-formula> for unweighted bending, for different methods. The differences between results from different methods were marginal. Overall, the methods can be ranked from HJ03–4 being the best performer to LRS14, HJ03–2 and DB88–4. The criteria for this ranking were the mean of deviations, AAD and RMSD. Likely, DB88 with ϵ &lt; 10<sup>−4</sup> could perform as good as HJ03–4 and LRS14, because in this method, eigenvalues smaller than ϵ are replaced with 100 × ϵ.
<table-wrap id="Tab3"><label>Table 3</label><caption><p>Deviation and correlation between the upper triangle (excluding diagonal) elements of <italic>C</italic><sub>(5 × 5)</sub> (the correlation matrix) and its unweighted bent matrix</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Statistics</th><th>HJ03–2<sup><italic>a</italic></sup></th><th>HJ03–4<sup><italic>b</italic></sup></th><th>LRS14<sup><italic>c</italic></sup></th><th>DB88–4<sup><italic>d</italic></sup></th></tr></thead><tbody><tr><td>Min (dev.)</td><td>−0.0826</td><td>−0.0797</td><td>−0.0788</td><td>−0.1095</td></tr><tr><td>Max (dev.)</td><td>0.0725</td><td>0.0702</td><td>0.0717</td><td>0.0264</td></tr><tr><td>Mean (dev.)</td><td>−0.0200</td><td>−0.0194</td><td>−0.0204</td><td>−0.0448</td></tr><tr><td>AAD</td><td>0.0490</td><td>0.0475</td><td>0.0491</td><td>0.0554</td></tr><tr><td>Correlation</td><td>0.9841</td><td>0.9853</td><td>0.9854</td><td>0.9896</td></tr><tr><td>RMSD</td><td>0.0537</td><td>0.0520</td><td>0.0530</td><td>0.0622</td></tr><tr><td>Number of iterations</td><td>4</td><td>13</td><td>39</td><td>1</td></tr></tbody></table><table-wrap-foot><p>dev. = bend(<bold>V</bold>) – <bold>V</bold>; AAD = average absolute deviation; RMSD = root of mean squared deviation; <sup><italic>a</italic></sup> Method of Jorjani et al. [<xref ref-type="bibr" rid="CR4">4</xref>] with ϵ = 10<sup>−2</sup>; <italic>b</italic> Method of Jorjani et al. [<xref ref-type="bibr" rid="CR4">4</xref>] with ϵ = 10<sup>−4</sup>; <sup><italic>c</italic></sup> Method of Schaeffer [<xref ref-type="bibr" rid="CR3">3</xref>]; <sup><italic>d</italic></sup> Method of Bock et al. [<xref ref-type="bibr" rid="CR7">7</xref>] with ϵ = 10<sup>−4</sup></p></table-wrap-foot></table-wrap></p>
      <p id="Par46">Table <xref rid="Tab4" ref-type="table">4</xref> shows deviations and correlations between <bold>C</bold> and <inline-formula id="IEq15"><alternatives><tex-math id="M37">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \hat{\mathbf{C}} $$\end{document}</tex-math><mml:math id="M38" display="inline"><mml:mover accent="true"><mml:mi mathvariant="bold">C</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover></mml:math><inline-graphic xlink:href="12863_2020_881_Article_IEq15.gif"/></alternatives></inline-formula> for weighted bending, using HJ03–2, HJ03–4 and LRS14. HJ03–4 and LRS14 performed almost equally better than HJ03–2. It took LRS14 a considerably greater number of iterations to converge, which might be a challenge for large matrices.
<table-wrap id="Tab4"><label>Table 4</label><caption><p>Deviation and correlation between the upper triangle (excluding diagonal) elements of <italic>C</italic><sub>(5 × 5)</sub> (the correlation matrix) and its weighted (using <italic>W</italic><sub>(5 × 5)</sub>) bent matrix</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Statistics</th><th>HJ03–2<sup><italic>a</italic></sup></th><th>HJ03–4<sup><italic>b</italic></sup></th><th>LRS14<sup><italic>c</italic></sup></th></tr></thead><tbody><tr><td>Min (dev.)</td><td>−0.2056</td><td>−0.1995</td><td>−0.1994</td></tr><tr><td>Max (dev.)</td><td>0.0644</td><td>0.0630</td><td>0.0632</td></tr><tr><td>Mean (dev.)</td><td>−0.0293</td><td>−0.0284</td><td>−0.0284</td></tr><tr><td>AAD</td><td>0.0569</td><td>0.0554</td><td>0.0555</td></tr><tr><td>Weighted AAD</td><td>0.0146</td><td>0.0142</td><td>0.0142</td></tr><tr><td>Correlation</td><td>0.9428</td><td>0.9463</td><td>0.9462</td></tr><tr><td>Weighted correlation</td><td>0.9939</td><td>0.9943</td><td>0.9942</td></tr><tr><td>RMSD</td><td>0.0828</td><td>0.0803</td><td>0.0804</td></tr><tr><td>Weighted RMSD</td><td>0.0110</td><td>0.0107</td><td>0.0108</td></tr><tr><td>Number of iterations</td><td>88</td><td>286</td><td>694</td></tr></tbody></table><table-wrap-foot><p>dev. = bend(<bold>V</bold>) – <bold>V</bold>; AAD = average absolute deviation; RMSD = root of mean squared deviation; <sup><italic>a</italic></sup> Method of Jorjani et al. [<xref ref-type="bibr" rid="CR4">4</xref>] with ϵ = 10<sup>−2</sup>; <sup><italic>b</italic></sup> Method of Jorjani et al. [<xref ref-type="bibr" rid="CR4">4</xref>] with ϵ = 10<sup>−4</sup>; <sup><italic>c</italic></sup> Method of Schaeffer [<xref ref-type="bibr" rid="CR3">3</xref>]</p></table-wrap-foot></table-wrap></p>
      <p id="Par47">Like comparing Tables <xref rid="Tab1" ref-type="table">1</xref>, <xref rid="Tab2" ref-type="table">2</xref> and S1, comparing Tables <xref rid="Tab3" ref-type="table">3</xref>, <xref rid="Tab4" ref-type="table">4</xref> and S1 shows lower weighted AAD and weighted RMSD, and higher weighted correlation for weighted compared to unweighted bending, at the cost of greater deviations, AAD and RMSD, and lower correlation coefficients.</p>
    </sec>
    <sec id="Sec11">
      <title>The ill-conditioned genomic relationship matrix (G)</title>
      <p id="Par48">The <bold>G</bold> matrix was bent using HJ03–4, LRS14 and DB88–4. Assuming all genotypes of the same quality, unweighted bending was carried out. The distributions of the upper triangle elements of <inline-formula id="IEq16"><alternatives><tex-math id="M39">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \hat{\mathbf{G}}-\mathbf{G} $$\end{document}</tex-math><mml:math id="M40" display="inline"><mml:mover accent="true"><mml:mi mathvariant="bold">G</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mo>−</mml:mo><mml:mi mathvariant="bold">G</mml:mi></mml:math><inline-graphic xlink:href="12863_2020_881_Article_IEq16.gif"/></alternatives></inline-formula> are shown in Fig. <xref rid="Fig1" ref-type="fig">1</xref>, where <inline-formula id="IEq17"><alternatives><tex-math id="M41">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \hat{\mathbf{G}} $$\end{document}</tex-math><mml:math id="M42" display="block"><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">G</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:math><inline-graphic xlink:href="12863_2020_881_Article_IEq17.gif"/></alternatives></inline-formula> is the bent <bold>G</bold>. All the three methods performed well providing minimal deviations. DB88–4 showed larger deviations with 10 elements showing deviations between −0.0131 and −0.0135. LRS14 performed the best. The AAD values were 8.5e–15, 1e–7 and 1.47e–5, and the RMSD values were 11e–15, 4e–7 and 6.17e–5 for LRS14, HJ03–4 and DB88–4, respectively. It took HJ03–4, LRS14 and DB88–4, 6 s, 47 s and 3 s time to derive <inline-formula id="IEq18"><alternatives><tex-math id="M43">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \hat{\mathbf{G}} $$\end{document}</tex-math><mml:math id="M44" display="inline"><mml:mover accent="true"><mml:mi mathvariant="bold">G</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover></mml:math><inline-graphic xlink:href="12863_2020_881_Article_IEq18.gif"/></alternatives></inline-formula>, in 1, 8 and 1 iterations, respectively.
<fig id="Fig1"><label>Fig. 1</label><caption><p>Boxplot of the upper triangle elements of <inline-formula id="IEq19"><alternatives><tex-math id="M45">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \hat{G}-G $$\end{document}</tex-math><mml:math id="M46" display="inline"><mml:mover accent="true"><mml:mi>G</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mo>−</mml:mo><mml:mi>G</mml:mi></mml:math><inline-graphic xlink:href="12863_2020_881_Article_IEq19.gif"/></alternatives></inline-formula> for different methods. <inline-formula id="IEq20"><alternatives><tex-math id="M47">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \hat{\mathbf{G}} $$\end{document}</tex-math><mml:math id="M48" display="inline"><mml:mspace width="0.25em"/><mml:mover accent="true"><mml:mi mathvariant="bold">G</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover></mml:math><inline-graphic xlink:href="12863_2020_881_Article_IEq20.gif"/></alternatives></inline-formula> = bent <bold>G</bold>; <sup>a</sup> Method of Jorjani et al. [<xref ref-type="bibr" rid="CR4">4</xref>] with ϵ = 10<sup>−4</sup>; <sup>b</sup> Method of Schaeffer [<xref ref-type="bibr" rid="CR3">3</xref>]; <sup>c</sup> Method of Bock et al. [<xref ref-type="bibr" rid="CR7">7</xref>] with ϵ = 10<sup>−4</sup></p></caption><graphic xlink:href="12863_2020_881_Fig1_HTML" id="MO1"/></fig></p>
    </sec>
  </sec>
  <sec id="Sec12">
    <title>Discussion</title>
    <p id="Par49">The covariance (<bold>V</bold>), the correlation (<bold>C</bold>) and the genomic relationship (<bold>G</bold>) matrices were successfully bent using different methods. In situations where the precision of different matrix elements is known (e.g., the number of observations involved or the standard errors), weighted bending is highly recommended. It may cost an overall larger deviation between the original and the bent matrices, but minimising the deviations or preserving the elements with higher precision. The extension of LRS14 to a weighted bending worked perfectly and proved to be better than LRS14. An improvement made to HJ03 was changing <bold>W</bold> to <bold>W</bold>/max(<bold>W</bold>), internally [<xref ref-type="bibr" rid="CR8">8</xref>]. This reduced the number of iterations to convergence, by changing max(<bold>W</bold>) to 1. This practice is recommended as elements of [<bold>11</bold>′ – <bold>W</bold>] and <bold>W</bold> are positive and convex combinations of each other (i.e., <bold>V</bold><sub><italic>n</italic> + 1</sub> = <bold>V</bold><sub><italic>n</italic></sub> − [<bold>V</bold><sub><italic>n</italic></sub> − <bold>U</bold><sub><italic>n</italic></sub><bold>Δ</bold><sub><italic>n</italic></sub><bold>U</bold><sub><italic>n</italic></sub>′] ∘ <bold>W</bold> = <bold>V</bold><sub><italic>n</italic></sub> ∘ [<bold>11</bold> ′  − <bold>W</bold>] + [<bold>U</bold><sub><italic>n</italic></sub><bold>Δ</bold><sub><italic>n</italic></sub><bold>U</bold><sub><italic>n</italic></sub>′] ∘ <bold>W</bold>).</p>
    <p id="Par50">The unweighted bending of the covariance matrices (<bold>V</bold> and <bold>G</bold>) took an iteration to converge, except LRS14 for <bold>G</bold>, which took 8 iterations to converge. For the unweighted bending of the correlation matrix, except DB88–4, the other methods converged in more than 1 iteration. The reason was that unweighted bending for correlation matrices is equivalent to a weighted bending (except for DB88–4) with off-diagonal weights equal to 1, and diagonal weights equal to 0. As a result, correlation coefficients between the original and the bent matrix decreased from Table <xref rid="Tab1" ref-type="table">1</xref> to Table <xref rid="Tab3" ref-type="table">3</xref> (covariance to correlation), but it increased for DB88–4 from 0.9833 to 0.9896, because this method is mainly designed for bending correlation matrices. Probably for the same reason, it did not perform as good as HJ03–4 and LRS14 for bending <bold>G</bold> (Fig. <xref rid="Fig1" ref-type="fig">1</xref>). As a result of DB88 being designed for correlation matrices, when it comes to covariance matrices, the diagonal elements are not allowed to change, which puts more force on the off-diagonal elements to change. Contrary to weighted bending of the covariance matrix, weighted bending of the correlation matrix converged in fewer number of iterations.</p>
    <p id="Par51">The most important statistics to judge among different bending methods are absolute distance measures such as AAD and RMSD. Correlation coefficients between the original and the bent matrix are not important as such but showing the direction of changes corresponding to the value of elements in the original matrix. Where weighted bending is involved, weighted AAD and weighted RMSD should be considered.</p>
    <p id="Par52">Although, LRS14 is not based on any known statistical properties [<xref ref-type="bibr" rid="CR3">3</xref>], it performed close to HJ03–2 (slightly better for <bold>C</bold> and slightly worse for <bold>V</bold>) and it was the best performer for <bold>G</bold>. In the first iteration of bending <bold>C</bold> by LRS14, the eigenvalues −0.0312 and −0.1852 were replaced with 0.0019 and 0.0007, respectively. Therefore, the benefit over HJ03–2 may come from a combination of these values being in a descending (rather than equal) order and less than 10<sup>−2</sup>. In the first iteration of bending <bold>V</bold> by LRS14, the eigenvalues −3.1229 and −18.5235 were replaced with 0.2036 and 0.0774. Given these values are greater than 10<sup>−2</sup> (compared to HJ03–2), the benefit in replacing negative eigenvalues with small positive values in a decreasing order becomes evident. It would be interesting to see how LRS14 performs with increasing the denominator (100 <italic>s</italic><sup>2</sup> + 1).</p>
    <sec id="Sec13">
      <title>Other methods</title>
      <p id="Par53">There are many other bending methods used in other fields, such as psychology, economics, finance and engineering. Most of those are designed for bending correlation matrices. Therefore, applying them to covariance matrices would result in unchanged diagonal elements and consequently further changes in off-diagonal elements. Several of those methods are explained by Marée [<xref ref-type="bibr" rid="CR11">11</xref>], and Lorenzo-Seva and Ferrando [<xref ref-type="bibr" rid="CR13">13</xref>]. As examples, here, a few methods are explained briefly.</p>
      <p id="Par54">Rebonato and Jäckel [<xref ref-type="bibr" rid="CR14">14</xref>] used hypersphere decomposition methodology for creating a valid correlation matrix for the use in risk management and option pricing. In this trigonometric-based method, <inline-formula id="IEq21"><alternatives><tex-math id="M49">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \hat{\mathbf{C}}=\mathbf{BB}^{\prime } $$\end{document}</tex-math><mml:math id="M50" display="inline"><mml:mover accent="true"><mml:mi mathvariant="bold">C</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mi mathvariant="bold">BB</mml:mi><mml:mo>′</mml:mo></mml:math><inline-graphic xlink:href="12863_2020_881_Article_IEq21.gif"/></alternatives></inline-formula> and the row vectors of <bold>B</bold> are coordinates of angles (<italic>θ</italic><sub><italic>ij</italic></sub>) lying on a unit hypersphere. The elements of <bold>B</bold> are calculated as:
<disp-formula id="Eque"><alternatives><tex-math id="M51">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ {b}_{ij}=\left\{\begin{array}{ll}\cos {\theta}_{ij}&amp; \mathrm{for}\ j=1\\ {}\cos {\theta}_{ij}.{\varPi}_{k=1}^{j-1}\sin {\theta}_{ik}&amp; \mathrm{for}\ j=2\ \mathrm{to}\ n-1\\ {}{\varPi}_{k=1}^{j-1}\sin {\theta}_{ik}&amp; \mathrm{for}\ j=n\end{array}\right. $$\end{document}</tex-math><mml:math id="M52" display="block"><mml:msub><mml:mi>b</mml:mi><mml:mi mathvariant="italic">ij</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfenced open="{"><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:mo>cos</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi mathvariant="italic">ij</mml:mi></mml:msub></mml:mtd><mml:mtd><mml:mtext>for</mml:mtext><mml:mspace width="0.25em"/><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>cos</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi mathvariant="italic">ij</mml:mi></mml:msub><mml:mo>.</mml:mo><mml:msubsup><mml:mi>Π</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo>sin</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi mathvariant="italic">ik</mml:mi></mml:msub></mml:mtd><mml:mtd><mml:mtext>for</mml:mtext><mml:mspace width="0.25em"/><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mspace width="0.25em"/><mml:mtext>to</mml:mtext><mml:mspace width="0.25em"/><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msubsup><mml:mi>Π</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo>sin</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi mathvariant="italic">ik</mml:mi></mml:msub></mml:mtd><mml:mtd><mml:mtext>for</mml:mtext><mml:mspace width="0.25em"/><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mi>n</mml:mi></mml:mtd></mml:mtr></mml:mtable></mml:mfenced></mml:math><graphic xlink:href="12863_2020_881_Article_Eque.gif" position="anchor"/></alternatives></disp-formula></p>
      <p id="Par55">Rapisarda et al. [<xref ref-type="bibr" rid="CR15">15</xref>] simplified this method by reducing <bold>B</bold> to a lower triangle matrix. This method resembles deriving the Cholesky decomposition of a PD correlation matrix close to the non-PD correlation matrix. The elements of <bold>B</bold> are calculated as:
<disp-formula id="Equf"><alternatives><tex-math id="M53">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ {b}_{ij}=\left\{\begin{array}{ll}1&amp; \mathrm{for}\ i=j=1\\ {}\cos {\theta}_{ij}&amp; \mathrm{for}\ i\ge 2,j=1\\ {}{\varPi}_{k=1}^{j-1}\sin {\theta}_{ik}&amp; \mathrm{for}\ i=j,2\le i\le n\\ {}\cos {\theta}_{ij}{\varPi}_{k=1}^{j-1}\sin {\theta}_{ik}&amp; \mathrm{for}\ 2\le j\le i-1\\ {}0&amp; \mathrm{for}\ i+1\le j\le n\end{array}\right. $$\end{document}</tex-math><mml:math id="M54" display="block"><mml:msub><mml:mi>b</mml:mi><mml:mi mathvariant="italic">ij</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfenced open="{"><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:mn>1</mml:mn></mml:mtd><mml:mtd><mml:mtext>for</mml:mtext><mml:mspace width="0.25em"/><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>cos</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi mathvariant="italic">ij</mml:mi></mml:msub></mml:mtd><mml:mtd><mml:mtext>for</mml:mtext><mml:mspace width="0.25em"/><mml:mi>i</mml:mi><mml:mo>≥</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msubsup><mml:mi>Π</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo>sin</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi mathvariant="italic">ik</mml:mi></mml:msub></mml:mtd><mml:mtd><mml:mtext>for</mml:mtext><mml:mspace width="0.25em"/><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>≤</mml:mo><mml:mi>i</mml:mi><mml:mo>≤</mml:mo><mml:mi>n</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>cos</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi mathvariant="italic">ij</mml:mi></mml:msub><mml:msubsup><mml:mi>Π</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo>sin</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi mathvariant="italic">ik</mml:mi></mml:msub></mml:mtd><mml:mtd><mml:mtext>for</mml:mtext><mml:mspace width="0.25em"/><mml:mn>2</mml:mn><mml:mo>≤</mml:mo><mml:mi>j</mml:mi><mml:mo>≤</mml:mo><mml:mi>i</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mtext>for</mml:mtext><mml:mspace width="0.25em"/><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>≤</mml:mo><mml:mi>j</mml:mi><mml:mo>≤</mml:mo><mml:mi>n</mml:mi></mml:mtd></mml:mtr></mml:mtable></mml:mfenced></mml:math><graphic xlink:href="12863_2020_881_Article_Equf.gif" position="anchor"/></alternatives></disp-formula></p>
      <p id="Par56">Numpacharoen and Atsawarungruangkit [<xref ref-type="bibr" rid="CR16">16</xref>] introduced a method for obtaining the theoretical bounds of correlation coefficients and an algorithm for permuting random correlation matrices within those boundaries.</p>
      <p id="Par57">Bentler and Yuan [<xref ref-type="bibr" rid="CR17">17</xref>] developed a bending method via off-diagonal scaling of the matrix. The symmetric PD matrix is obtained as <inline-formula id="IEq22"><alternatives><tex-math id="M55">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \hat{\mathbf{V}}=\boldsymbol{\Delta} \left(\mathbf{V}-{\mathbf{D}}_V\right)\boldsymbol{\Delta} +{\mathbf{D}}_V $$\end{document}</tex-math><mml:math id="M56" display="inline"><mml:mover accent="true"><mml:mi mathvariant="bold">V</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mi mathvariant="bold">Δ</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:mi mathvariant="bold">V</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi mathvariant="bold">D</mml:mi><mml:mi>V</mml:mi></mml:msub></mml:mrow></mml:mfenced><mml:mi mathvariant="bold">Δ</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi mathvariant="bold">D</mml:mi><mml:mi>V</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12863_2020_881_Article_IEq22.gif"/></alternatives></inline-formula>, where <bold>D</bold><sub><italic>V</italic></sub> =  <italic>diag</italic> (<italic>diag</italic>(<bold>V</bold>)), <bold>Δ</bold> is a diagonal matrix such that <bold>0</bold> &lt; <bold>Δ</bold><sup>2</sup> <italic>diag</italic> (<italic>diag</italic>(<bold>V</bold> − <bold>D</bold>)) &lt; <bold>D</bold><sub><italic>V</italic></sub>, and <bold>D</bold> is a diagonal matrix such that <bold>V</bold> – <bold>D</bold> is PD. <bold>D</bold> can be a diagonal matrix of small negative values, or according to Bentler and Yuan [<xref ref-type="bibr" rid="CR17">17</xref>], it can be obtained by minimum trace factor analysis [<xref ref-type="bibr" rid="CR18">18</xref>, <xref ref-type="bibr" rid="CR19">19</xref>].</p>
      <p id="Par58">An alternative approach to bending is fitting a reduced rank factor-analytic model. Multi-trait BLUP can be reformulated by changing the covariance structure among <italic>n</italic> traits to the factor-analytic structure of <italic>n</italic> orthogonal factors [<xref ref-type="bibr" rid="CR20">20</xref>]. In a reduced rank factor-analytic model, specific factors (not explaining the common variance) are absent, by setting the corresponding eigenvalues to zero [<xref ref-type="bibr" rid="CR20">20</xref>].</p>
      <p id="Par59">Obviously, there should be some confidence around matrix elements. Neither a rank reduced factor-analytic model nor bending can solve the problem of major flaws in matrix elements. For both methodologies, the reference is the original matrix. In bending, only if uncertainty around some matrix elements causes non-PDness, the matrix is bent with as minimal as possible impact on the original matrix. Similarly, when it comes to <bold>G</bold> matrix, prevention (i.e., quality control and discarding problematic genotypes) is better than cure (i.e., bending).</p>
    </sec>
  </sec>
  <sec id="Sec14">
    <title>Conclusions</title>
    <p id="Par60">This study introduced a new R package for bending symmetric non-PD matrices to PD, with the flexibility of choosing between weighted and unweighted bending, two different bending methods, the smallest positive eigenvalue (for one of the methods), and direct or reciprocal use of the weight matrix elements for weighted bending. Together with the bent matrix, several bending performance statistics are provided by the program. Where precision of matrix elements is available, weighted bending is recommended. There was benefit in small positive values in a descending order replacing negative eigenvalues. This method can further benefit from the possibility of choosing the smallest positive eigenvalue, which can be a topic for future research. The differences between the performance of different methods were minor and the methods ranked differently for different matrices. Therefore, testing different methods, and ϵ values (for HJ03) are recommended. Bending methods may perform differently for different matrices, depending on whether a covariance or a correlation matrix is being bent, the number of negative eigenvalues and their magnitude relative to the smallest positive eigenvalue, and the size of the matrix (i.e., number of diagonal elements relative to all elements).</p>
    <p id="Par61">There are many bending methods available, and those have approached the problem in various ways. Some methods are preferable for correlation matrices. This study showed that eigendecomposition-based methods are simple, robust and computationally efficient. Finally, the application of bending and R package mbend is not limited to multi-trait BLUP, but also other multivariate mixed models, genetic selection indices [<xref ref-type="bibr" rid="CR5">5</xref>], or any situation, where a symmetric non-PD matrix needs to be transformed to a PD matrix.</p>
  </sec>
  <sec id="Sec15">
    <title>Availability and requirements</title>
    <p id="Par62">
      <list list-type="bullet">
        <list-item>
          <p id="Par63"><bold>Project name:</bold> R package mbend</p>
        </list-item>
        <list-item>
          <p id="Par64">
            <bold>Project home page:</bold>
            <ext-link ext-link-type="uri" xlink:href="https://cran.r-project.org/package=mbend">https://cran.r-project.org/package=mbend</ext-link>
          </p>
        </list-item>
        <list-item>
          <p id="Par65"><bold>Operating system(s):</bold> Platform independent</p>
        </list-item>
        <list-item>
          <p id="Par66"><bold>Programming language:</bold> R</p>
        </list-item>
        <list-item>
          <p id="Par67"><bold>Other requirements:</bold> None</p>
        </list-item>
        <list-item>
          <p id="Par68"><bold>License:</bold> GPL-3</p>
        </list-item>
        <list-item>
          <p id="Par69"><bold>Any restrictions to use by non-academics:</bold> None</p>
        </list-item>
      </list>
    </p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary information</title>
    <sec id="Sec16">
      <p>
        <supplementary-material content-type="local-data" id="MOESM1">
          <media xlink:href="12863_2020_881_MOESM1_ESM.pdf">
            <caption>
              <p><bold>Additional file 1 Appendix</bold>. Bending a correlation matrix using function bend from R package mbend. <bold>Table S1</bold>. Weighted statistics (using <italic>W</italic><sub>(5 × 5)</sub>) between the upper triangle elements of <italic>V</italic><sub>(5 × 5)</sub> (the covariance matrix) and <italic>C</italic><sub>(5 × 5)</sub> (the correlation matrix) and their unweighted bent matrices.</p>
            </caption>
          </media>
        </supplementary-material>
      </p>
    </sec>
  </sec>
</body>
<back>
  <glossary>
    <title>Abbreviations</title>
    <def-list>
      <def-item>
        <term>BLUP</term>
        <def>
          <p id="Par4">Best linear unbiased prediction</p>
        </def>
      </def-item>
      <def-item>
        <term>HJ03</term>
        <def>
          <p id="Par5">Method of Jorjani et al. (2003)</p>
        </def>
      </def-item>
      <def-item>
        <term>HJ03–2</term>
        <def>
          <p id="Par6">HJ03 with  ϵ = 10<sup>−2</sup></p>
        </def>
      </def-item>
      <def-item>
        <term>HJ03–4</term>
        <def>
          <p id="Par7">HJ03 with  ϵ = 10<sup>−4</sup></p>
        </def>
      </def-item>
      <def-item>
        <term>LRS14</term>
        <def>
          <p id="Par8">Method of Schaeffer (2014)</p>
        </def>
      </def-item>
      <def-item>
        <term>DB88</term>
        <def>
          <p id="Par9">Method of Bock et al. (1988)</p>
        </def>
      </def-item>
      <def-item>
        <term>DB88–4</term>
        <def>
          <p id="Par10">DB88 with  ϵ = 10<sup>−4</sup></p>
        </def>
      </def-item>
    </def-list>
  </glossary>
  <fn-group>
    <fn>
      <p>
        <bold>Publisher’s Note</bold>
      </p>
      <p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
    </fn>
  </fn-group>
  <sec>
    <title>Supplementary information</title>
    <p><bold>Supplementary information</bold> accompanies this paper at 10.1186/s12863-020-00881-z.</p>
  </sec>
  <ack>
    <title>Acknowledgements</title>
    <p>The author is thankful from Dr. Hossein Jorjani for fruitful discussions that led to the development of R package mbend.</p>
  </ack>
  <notes notes-type="author-contribution">
    <title>Author’s contributions</title>
    <p>MAN wrote the R package and the manuscript. He is the maintainer of the R package and the corresponding author of the article. MAN read and approved the final manuscript.</p>
  </notes>
  <notes notes-type="funding-information">
    <title>Funding</title>
    <p>Publication fund was provided by Livestock Improvement Corporation, Hamilton, New Zealand.</p>
  </notes>
  <notes notes-type="data-availability">
    <title>Availability of data and materials</title>
    <p>The datasets and code supporting the conclusions of this article are available in the Mendeley repository: 10.17632/kf3d8v8939.1.</p>
  </notes>
  <notes id="FPar1">
    <title>Ethics approval and consent to participate</title>
    <p id="Par70">Not applicable.</p>
  </notes>
  <notes id="FPar2">
    <title>Consent for publication</title>
    <p id="Par71">Not applicable.</p>
  </notes>
  <notes id="FPar3" notes-type="COI-statement">
    <title>Competing interests</title>
    <p id="Par72">The author declares that he has no competing interests.</p>
  </notes>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <label>1.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Schaeffer</surname>
            <given-names>LR</given-names>
          </name>
        </person-group>
        <article-title>Sire and cow evaluation under multiple trait models</article-title>
        <source>J Dairy Sci</source>
        <year>1984</year>
        <volume>67</volume>
        <issue>7</issue>
        <fpage>1567</fpage>
        <lpage>1580</lpage>
        <pub-id pub-id-type="doi">10.3168/jds.S0022-0302(84)81479-4</pub-id>
      </element-citation>
    </ref>
    <ref id="CR2">
      <label>2.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Patterson</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Thompson</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>Recovery of inter-block information when block sizes are unequal</article-title>
        <source>Biometrika</source>
        <year>1971</year>
        <volume>58</volume>
        <issue>3</issue>
        <fpage>545</fpage>
        <lpage>554</lpage>
        <pub-id pub-id-type="doi">10.2307/2334389</pub-id>
      </element-citation>
    </ref>
    <ref id="CR3">
      <label>3.</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Schaeffer</surname>
            <given-names>LR</given-names>
          </name>
        </person-group>
        <source>Making covariance matrices positive definite</source>
        <year>2014</year>
      </element-citation>
    </ref>
    <ref id="CR4">
      <label>4.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Jorjani</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Klei</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Emanuelson</surname>
            <given-names>U</given-names>
          </name>
        </person-group>
        <article-title>A simple method for weighted bending of genetic (co) variance matrices</article-title>
        <source>J Dairy Sci</source>
        <year>2003</year>
        <volume>86</volume>
        <issue>2</issue>
        <fpage>677</fpage>
        <lpage>679</lpage>
        <pub-id pub-id-type="doi">10.3168/jds.S0022-0302(03)73646-7</pub-id>
        <?supplied-pmid 12647974?>
        <pub-id pub-id-type="pmid">12647974</pub-id>
      </element-citation>
    </ref>
    <ref id="CR5">
      <label>5.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hayes</surname>
            <given-names>JF</given-names>
          </name>
          <name>
            <surname>Hill</surname>
            <given-names>WG</given-names>
          </name>
        </person-group>
        <article-title>Modifications of estimates of parameters in the construction of genetic selection indices ("bending")</article-title>
        <source>Biometrics</source>
        <year>1981</year>
        <volume>37</volume>
        <issue>3</issue>
        <fpage>483</fpage>
        <lpage>493</lpage>
        <pub-id pub-id-type="doi">10.2307/2530561</pub-id>
      </element-citation>
    </ref>
    <ref id="CR6">
      <label>6.</label>
      <mixed-citation publication-type="other">Meyer K, Kirkpatrick M. Better estimates of genetic covariance matrices by "bending" using penalized maximum likelihood. Genetics. 2010;185(3):1097–110. 10.1534/genetics.109.113381.</mixed-citation>
    </ref>
    <ref id="CR7">
      <label>7.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Bock</surname>
            <given-names>RD</given-names>
          </name>
          <name>
            <surname>Gibbons</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Muraki</surname>
            <given-names>E</given-names>
          </name>
        </person-group>
        <article-title>Full-information item factor analysis</article-title>
        <source>Appl Psychol Meas</source>
        <year>1988</year>
        <volume>12</volume>
        <issue>3</issue>
        <fpage>261</fpage>
        <lpage>280</lpage>
        <pub-id pub-id-type="doi">10.1177/014662168801200305</pub-id>
      </element-citation>
    </ref>
    <ref id="CR8">
      <label>8.</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Nilforooshan</surname>
            <given-names>MA</given-names>
          </name>
        </person-group>
        <source>mbend: Matrix bending. R package version 1.3.0</source>
        <year>2020</year>
      </element-citation>
    </ref>
    <ref id="CR9">
      <label>9.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>VanRaden</surname>
            <given-names>PM</given-names>
          </name>
        </person-group>
        <article-title>Efficient methods to compute genomic predictions</article-title>
        <source>J Dairy Sci</source>
        <year>2008</year>
        <volume>91</volume>
        <issue>11</issue>
        <fpage>4414</fpage>
        <lpage>4423</lpage>
        <pub-id pub-id-type="doi">10.3168/jds.2007-0980</pub-id>
        <?supplied-pmid 18946147?>
        <pub-id pub-id-type="pmid">18946147</pub-id>
      </element-citation>
    </ref>
    <ref id="CR10">
      <label>10.</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Revelle</surname>
            <given-names>W</given-names>
          </name>
        </person-group>
        <source>Procedures for Psychological, Psychometric, and Personality Research. R package version 1.9.12.31</source>
        <year>2020</year>
      </element-citation>
    </ref>
    <ref id="CR11">
      <label>11.</label>
      <mixed-citation publication-type="other">Marée SC. Correcting non positive definite correlation matrices. Netherlands: BSc thesis, Department of Applied Mathematics, Delft University of Technology; 2012. <ext-link ext-link-type="uri" xlink:href="http://resolver.tudelft.nl/uuid:2175c274-ab03-4fd5-85a9-228fe421cdbf">http://resolver.tudelft.nl/uuid:2175c274-ab03-4fd5-85a9-228fe421cdbf</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR12">
      <label>12.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Higham</surname>
            <given-names>N</given-names>
          </name>
        </person-group>
        <article-title>Computing the nearest correlation matrix – a problem from finance</article-title>
        <source>Numer Anal</source>
        <year>2001</year>
        <volume>22</volume>
        <issue>3</issue>
        <fpage>329</fpage>
        <lpage>343</lpage>
        <pub-id pub-id-type="doi">10.1093/imanum/22.3.329</pub-id>
      </element-citation>
    </ref>
    <ref id="CR13">
      <label>13.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lorenzo-Seva</surname>
            <given-names>U</given-names>
          </name>
          <name>
            <surname>Ferrando</surname>
            <given-names>PG</given-names>
          </name>
        </person-group>
        <article-title>Not positive definite correlation matrices in exploratory item factor analysis: causes, consequences and a proposed solution</article-title>
        <source>Struct Equ Model</source>
        <year>2020</year>
        <volume>27</volume>
        <fpage>1</fpage>
        <lpage>10</lpage>
        <pub-id pub-id-type="doi">10.1080/10705511.2020.1735393</pub-id>
      </element-citation>
    </ref>
    <ref id="CR14">
      <label>14.</label>
      <mixed-citation publication-type="other">Rebonato R, Jäckel P. The most general methodology for creating a valid correlation matrix for risk management and option pricing purposes. J Risk. 2000;2(2):17–27. 10.21314/JOR.2000.023.</mixed-citation>
    </ref>
    <ref id="CR15">
      <label>15.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Rapisarda</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Brigo</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Mercurio</surname>
            <given-names>F</given-names>
          </name>
        </person-group>
        <article-title>Parameterizing correlations: a geometric interpretation</article-title>
        <source>IMA J Manag Math</source>
        <year>2007</year>
        <volume>18</volume>
        <issue>1</issue>
        <fpage>55</fpage>
        <lpage>73</lpage>
        <pub-id pub-id-type="doi">10.1093/imaman/dpl010</pub-id>
      </element-citation>
    </ref>
    <ref id="CR16">
      <label>16.</label>
      <mixed-citation publication-type="other">Numpacharoen K, Atsawarungruangkit A. Generating correlation matrices based on the boundaries of their coefficients. PLoS One. 2012;7(11):e48902. 10.1371/journal.pone.0048902.</mixed-citation>
    </ref>
    <ref id="CR17">
      <label>17.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Bentler</surname>
            <given-names>PM</given-names>
          </name>
          <name>
            <surname>Yuan</surname>
            <given-names>K</given-names>
          </name>
        </person-group>
        <article-title>Positive definiteness via off-diagonal scaling of a symmetric indefinite matrix</article-title>
        <source>Psychometrika</source>
        <year>2011</year>
        <volume>76</volume>
        <issue>1</issue>
        <fpage>119</fpage>
        <lpage>123</lpage>
        <pub-id pub-id-type="doi">10.1007/s11336-010-9191-3</pub-id>
        <?supplied-pmid 21566679?>
        <pub-id pub-id-type="pmid">21566679</pub-id>
      </element-citation>
    </ref>
    <ref id="CR18">
      <label>18.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Bentler</surname>
            <given-names>PM</given-names>
          </name>
        </person-group>
        <article-title>A lower bound method for the dimension-free measurement of internal consistency</article-title>
        <source>Soc Sci Res</source>
        <year>1972</year>
        <volume>1</volume>
        <issue>4</issue>
        <fpage>343</fpage>
        <lpage>357</lpage>
        <pub-id pub-id-type="doi">10.1016/0049-089X(72)90082-8</pub-id>
      </element-citation>
    </ref>
    <ref id="CR19">
      <label>19.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Della Riccia</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Shapiro</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Minimum rank and minimum trace of covariance matrices</article-title>
        <source>Psychometrika</source>
        <year>1982</year>
        <volume>47</volume>
        <issue>4</issue>
        <fpage>443</fpage>
        <lpage>448</lpage>
        <pub-id pub-id-type="doi">10.1007/BF02293708</pub-id>
      </element-citation>
    </ref>
    <ref id="CR20">
      <label>20.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Meyer</surname>
            <given-names>K</given-names>
          </name>
        </person-group>
        <article-title>Factor-analytic models for genotype × environment type problems and structured covariance matrices</article-title>
        <source>Genet Sel Evol</source>
        <year>2009</year>
        <volume>41</volume>
        <fpage>21</fpage>
        <pub-id pub-id-type="doi">10.1186/1297-9686-41-21</pub-id>
        <?supplied-pmid 19284520?>
        <pub-id pub-id-type="pmid">19284520</pub-id>
      </element-citation>
    </ref>
  </ref-list>
</back>
