<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id>
    <journal-id journal-id-type="publisher-id">bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1367-4803</issn>
    <issn pub-type="epub">1367-4811</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">8289385</article-id>
    <article-id pub-id-type="pmid">33252662</article-id>
    <article-id pub-id-type="doi">10.1093/bioinformatics/btaa992</article-id>
    <article-id pub-id-type="publisher-id">btaa992</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Original Papers</subject>
        <subj-group subj-group-type="category-toc-heading">
          <subject>Sequence Analysis</subject>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI01060</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>MAGUS: Multiple sequence Alignment using Graph clUStering</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-7826-1214</contrib-id>
        <name>
          <surname>Smirnov</surname>
          <given-names>Vladimir</given-names>
        </name>
        <xref rid="btaa992-cor1" ref-type="corresp"/>
        <aff><institution>Department of Computer Science, University of Illinois at Urbana-Champaign</institution>, Urbana, IL 61801, <country country="US">USA</country></aff>
        <!--smirnov3@illinois.edu-->
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0001-7717-3514</contrib-id>
        <name>
          <surname>Warnow</surname>
          <given-names>Tandy</given-names>
        </name>
        <xref rid="btaa992-cor1" ref-type="corresp"/>
        <aff><institution>Department of Computer Science, University of Illinois at Urbana-Champaign</institution>, Urbana, IL 61801, <country country="US">USA</country></aff>
        <!--warnow@illinois.edu-->
      </contrib>
    </contrib-group>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Ponty</surname>
          <given-names>Yann</given-names>
        </name>
        <role>Associate Editor</role>
      </contrib>
    </contrib-group>
    <author-notes>
      <corresp id="btaa992-cor1">To whom correspondence should be addressed. <email>smirnov3@illinois.edu</email> or <email>warnow@illinois.edu</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <day>15</day>
      <month>6</month>
      <year>2021</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2020-11-30">
      <day>30</day>
      <month>11</month>
      <year>2020</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>30</day>
      <month>11</month>
      <year>2020</year>
    </pub-date>
    <volume>37</volume>
    <issue>12</issue>
    <fpage>1666</fpage>
    <lpage>1672</lpage>
    <history>
      <date date-type="received">
        <day>06</day>
        <month>7</month>
        <year>2020</year>
      </date>
      <date date-type="rev-recd">
        <day>24</day>
        <month>10</month>
        <year>2020</year>
      </date>
      <date date-type="editorial-decision">
        <day>13</day>
        <month>11</month>
        <year>2020</year>
      </date>
      <date date-type="accepted">
        <day>16</day>
        <month>11</month>
        <year>2020</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2020. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2020</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbynclicense">https://creativecommons.org/licenses/by-nc/4.0/</ali:license_ref>
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by-nc/4.0/">http://creativecommons.org/licenses/by-nc/4.0/</ext-link>), which permits non-commercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited. For commercial re-use, please contact journals.permissions@oup.com</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="btaa992.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Motivation</title>
        <p>The estimation of large multiple sequence alignments (MSAs) is a basic bioinformatics challenge. Divide-and-conquer is a useful approach that has been shown to improve the scalability and accuracy of MSA estimation in established methods such as SATé and PASTA. In these divide-and-conquer strategies, a sequence dataset is divided into disjoint subsets, alignments are computed on the subsets using base MSA methods (e.g. MAFFT), and then merged together into an alignment on the full dataset.</p>
      </sec>
      <sec id="s2">
        <title>Results</title>
        <p>We present MAGUS, Multiple sequence Alignment using Graph clUStering, a new technique for computing large-scale alignments. MAGUS is similar to PASTA in that it uses nearly the same initial steps (starting tree, similar decomposition strategy, and MAFFT to compute subset alignments), but then merges the subset alignments using the Graph Clustering Merger, a new method for combining disjoint alignments that we present in this study. Our study, on a heterogeneous collection of biological and simulated datasets, shows that MAGUS produces improved accuracy and is faster than PASTA on large datasets, and matches it on smaller datasets.</p>
      </sec>
      <sec id="s3">
        <title>Availability and implementation</title>
        <p>MAGUS: <ext-link xlink:href="https://github.com/vlasmirnov/MAGUS" ext-link-type="uri">https://github.com/vlasmirnov/MAGUS</ext-link></p>
      </sec>
      <sec id="s5">
        <title>Supplementary information</title>
        <p><xref rid="sup1" ref-type="supplementary-material">Supplementary data</xref> are available at <italic toggle="yes">Bioinformatics</italic> online.</p>
      </sec>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>National Science Foundation</institution>
            <institution-id institution-id-type="DOI">10.13039/100000001</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>ABI-1458652</award-id>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="7"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 Introduction</title>
    <p>Multiple sequence alignment (MSA) is a basic step in many bioinformatic pipelines, but accurate estimation of MSAs on large sequence datasets is challenging, especially for datasets characterized by low sequence identity and high rates of insertions and deletions (indels). Methods that scale to large datasets have been developed (<xref rid="btaa992-B5" ref-type="bibr">Garriga et al., 2019</xref>; <xref rid="btaa992-B10" ref-type="bibr">Lassmann, 2019</xref>; <xref rid="btaa992-B12" ref-type="bibr">Liu et al., 2009</xref>, <xref rid="btaa992-B13" ref-type="bibr">2012</xref>; <xref rid="btaa992-B15" ref-type="bibr">Mirarab et al., 2015</xref>; <xref rid="btaa992-B16" ref-type="bibr">Nguyen et al., 2015</xref>; <xref rid="btaa992-B21" ref-type="bibr">Sievers et al., 2011</xref>), some of which [e.g. SATé (<xref rid="btaa992-B12" ref-type="bibr">Liu <italic toggle="yes">et al.</italic>, 2009</xref>), SATé-II (<xref rid="btaa992-B13" ref-type="bibr">Liu <italic toggle="yes">et al.</italic>, 2012</xref>), and PASTA (<xref rid="btaa992-B15" ref-type="bibr">Mirarab <italic toggle="yes">et al.</italic>, 2015</xref>)] use divide-and-conquer: they decompose the input sequence dataset into subsets, align each subset using a base alignment method of choice [such as MAFFT (<xref rid="btaa992-B8" ref-type="bibr">Katoh et al., 2005</xref>)], and merge the alignments together (thus treating them as constraints) into an alignment on the full dataset.</p>
    <p>There are multiple benefits to divide-and-conquer: scalability to large datasets is one advantage, but <italic toggle="yes">improved accuracy</italic> is the main draw. The reason for this improvement is that most alignment methods, including top-performing methods like MAFFT, either degrade in accuracy with high rates of evolution and number of sequences, or simply cannot run on large datasets. Divide-and-conquer avoids this by only using these methods on smaller, more closely related subsets of sequences. Because the alignments on such subsets tend to be very accurate, they are treated as <italic toggle="yes">constraints</italic>. Hence, the accuracy of the final alignment significantly depends on the ability to merge constraint alignments. A tree can then be estimated on the alignment, and then the process can be iterated. By default, SATé-I, SATé-II, and PASTA each run for three iterations.</p>
    <p>SATé-II improved on SATé-I by changing the decomposition strategy and PASTA improved on SATé-II by changing the merger step. Each of these changes improved accuracy and scalability, so that PASTA is the state-of-the-art for this family of divide-and-conquer MSA pipelines. Furthermore, UPP (<xref rid="btaa992-B16" ref-type="bibr">Nguyen <italic toggle="yes">et al.</italic>, 2015</xref>), which is designed to produce good alignments in the presence of sequence length heterogeneity, uses PASTA to compute a ‘backbone’ alignment on sequences that are deemed ‘full length’, represents the backbone alignment using an ensemble of profile Hidden Markov Models, and then aligns the remaining sequences to the backbone alignment using the ensemble. Thus, while PASTA (like most other methods) is suitable for datasets without substantial sequence length heterogeneity, it is also used in methods for aligning heterogeneous sequence length datasets.</p>
    <p>Here, we present MAGUS, Multiple sequence Alignment using Graph clUStering, a new method to compute large-scale MSAs. MAGUS follows the same initial steps as the first iteration of PASTA, which has the following structure. PASTA computes an alignment using a fast technique (similar to UPP, but using a random selection of sequences for the backbone without consideration for sequence length) and FastTree2 (<xref rid="btaa992-B20" ref-type="bibr">Price et al., 2010</xref>) to compute a tree on the alignment, divides the sequences into disjoint subsets by deleting edges until all the subsets are below the maximum allowed (default 200), computes alignments on the subsets (default MAFFT), and then merges the alignments together [merging pairs of constraint alignments using Opal (<xref rid="btaa992-B26" ref-type="bibr">Wheeler and Kececioglu, 2007</xref>) or Muscle (<xref rid="btaa992-B4" ref-type="bibr">Edgar, 2004</xref>) and then completing the merger using transitivity]. PASTA then computes a tree on the merged alignment using FastTree, and can continue by iterating; by default, PASTA iterates three times. The two main ways that MAGUS differs from PASTA is that it combines the disjoint alignments using the Graph Clustering Merger (i.e. GCM, a new technique we present here) and it does not need to iterate.</p>
    <p>We explore MAGUS on a heterogeneous collection of sequence datasets, using both simulated and biological datasets. We find that just one iteration of MAGUS produces more accurate alignments than default PASTA (which uses three iterations) on nearly all datasets we explore; furthermore, MAGUS is faster, since it only needs one iteration.</p>
  </sec>
  <sec>
    <title>2 Approach</title>
    <p>We begin with a description of the overall strategy, and then discuss the merger step (where we run GCM) in detail.</p>
    <sec>
      <title>2.1 Divide-and-conquer strategy</title>
      <p>Given an input set <italic toggle="yes">S</italic> of unaligned sequences
</p>
      <list list-type="bullet">
        <list-item>
          <p>Step 1: Compute a starting tree for <italic toggle="yes">S</italic>. In PASTA, 100 sequences are selected at random and aligned; the remaining sequences are added into that alignment, and a tree is computed on the final alignment with FastTree2. In MAGUS, we follow nearly the same technique, except we select 300 sequences whose lengths are within 25% of 75th percentile; the hope is that using longer sequences will reduce the negative impact of short sequences in the input, and using more sequences will improve the accuracy of the starting alignment and tree.</p>
        </list-item>
        <list-item>
          <p>Step 2: Decompose the sequence dataset into disjoint subsets using the centroid edge decomposition (an option within PASTA), modified to enable the maximum number of subsets to not exceed a specified amount.</p>
        </list-item>
        <list-item>
          <p>Step 3: Compute alignments on the subsets; we use MAFFT -L-ins-i, the same technique as in PASTA.</p>
        </list-item>
        <list-item>
          <p>Step 4: Merge the alignments together using GCM, as described in Section 2.2.</p>
        </list-item>
      </list>
      <p>As PASTA enables the user to specify algorithmic parameter values for each of these steps, we expose them as well. Our experimental study (see below) presents results for different settings.</p>
    </sec>
    <sec>
      <title>2.2 GCM</title>
      <p>The main difference between PASTA and MAGUS is the use of GCM, which is the subject of this section. We begin by defining the MSA Merger problem and basic terminology that we will use throughout the article.</p>
      <sec>
        <title>The MSA merging problem</title>
        <list list-type="bullet">
          <list-item>
            <p>Input: a set <inline-formula id="IE1"><mml:math id="IM1" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="script">S</mml:mi><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msub><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> of MSAs, with <italic toggle="yes">S<sub>i</sub></italic> an MSA on a set <italic toggle="yes">X<sub>i</sub></italic> of sequences, <inline-formula id="IE2"><mml:math id="IM2" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>∩</mml:mo><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mo>∅</mml:mo></mml:mrow></mml:math></inline-formula> if <inline-formula id="IE3"><mml:math id="IM3" display="inline" overflow="scroll"><mml:mrow><mml:mi>i</mml:mi><mml:mo>≠</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:math></inline-formula>, and <inline-formula id="IE4"><mml:math id="IM4" display="inline" overflow="scroll"><mml:mrow><mml:mi>X</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mo>∪</mml:mo></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>.</p>
          </list-item>
          <list-item>
            <p>Output: An alignment <italic toggle="yes">A</italic> on the full set <italic toggle="yes">X</italic> of sequences that agrees with each of the input alignments; thus, the subalignment of <italic toggle="yes">A</italic> induced on <italic toggle="yes">X<sub>i</sub></italic> is identical to <italic toggle="yes">S<sub>i</sub></italic> (after removing columns containing only gaps).</p>
          </list-item>
        </list>
        <p>We will refer to the input set of alignments as ‘constraint alignments,’ to emphasize that the input set is treated as absolute constraints that must be induced by the merged alignment. This is always possible, as the constraint alignments are disjoint. The MSA Merging problem is a straightforward generalization of the well-studied problem of aligning two alignments (<xref rid="btaa992-B26" ref-type="bibr">Wheeler and Kececioglu, 2007</xref>).</p>
      </sec>
      <sec>
        <title> </title>
        <p><bold>High-level description of the GCM algorithm.</bold> The Graph Clustering Merger (GCM) can be used with nucleotide sequences or with amino acid sequences, and we will describe and test GCM for both types of input; hence, when we say ‘letter’ in a sequence, we allow this to refer to either a nucleotide or an amino acid.</p>
        <p>The basic idea of GCM is to merge our constraint alignments by using a library of ‘backbone alignments’ (also called ‘backbones’), which we compute using a selected ‘base MSA method’ (e.g. MAFFT) after sampling representative sequences from each constraint alignment. This approach is related to the MSA methods in <xref rid="btaa992-B5" ref-type="bibr">Garriga <italic toggle="yes">et al.</italic> (2019)</xref> and <xref rid="btaa992-B19" ref-type="bibr">Pei and Grishin (2007)</xref>, each of which merges a set of disjoint alignments by picking one representative sequence from each subset, aligning the set of selected sequences, and then using that new alignment to construct the merged alignment. However, in these methods, exactly one representative sequence per subset is selected and only one ‘backbone’ alignment of representative sequences is computed, so that there is a trivial merged alignment that induces all the subset alignments (<xref rid="btaa992-F1" ref-type="fig">Fig. 1</xref>).</p>
        <fig position="float" id="btaa992-F1">
          <label>Fig. 1.</label>
          <caption>
            <p>Overview of the GCM algorithm. The input is a set of constraint alignments. (i) We compute a set of backbone alignments with the same number of sequences from each constraint alignment. (ii) We construct the alignment graph. Each node represents a column from a constraint alignment, and weighted edges are derived from homologies inferred in the backbone alignments: thicker lines represent edges with higher weight. (iii) We cluster the alignment graph with MCL. This example shows two violations: the pink-outlined cluster contains two columns from the same (blue) constraint alignment, and there is no valid ordering between the pink- and green-outlined clusters (‘crisscrossing’). (iv) We resolve the violations and produce a valid trace, where each connected component is a column in our final alignment</p>
          </caption>
          <graphic xlink:href="btaa992f1" position="float"/>
        </fig>
        <p>We depart from these approaches by using more than one backbone, with each having more than one representative sequence from each constraint alignment. The backbone alignments are not constrained to be consistent with the input constraint alignments or with each other. Thus, in GCM there is much more information to use in merging the constraint alignments, but GCM must also deal with conflicts among the backbone and constraint alignments. This use of multiple backbone alignments introduces a whole new layer of challenges compared to these earlier approaches.</p>
        <p>Phase 1 computes a library of backbone MSAs that is then used to form a graph, where the vertices correspond to columns within the input constraint MSAs. In keeping with terminology introduced in previous literature (<xref rid="btaa992-B9" ref-type="bibr">Kececioglu, 1993</xref>), we refer to this as the <bold>‘alignment graph’</bold>. In <xref rid="btaa992-B9" ref-type="bibr">Kececioglu (1993)</xref>, each node in an alignment graph corresponds to one letter from one sequence; however, since we are ‘aligning alignments’, the nodes in our alignment graphs will represent columns of letters from our constraint alignments instead.</p>
        <p>Phase 2 clusters the vertices using the Markov Clustering (MCL) technique from <xref rid="btaa992-B24" ref-type="bibr">Van Dongen (2000)</xref>, which can be seen as extending the consistency principle in the MSA literature to longer paths in a way that is similar to the technique in Probcons (<xref rid="btaa992-B2" ref-type="bibr">Do et al., 2005</xref>) (please refer to the <xref rid="sup1" ref-type="supplementary-material">Supplementary Materials</xref> for a more detailed explanation). This results in a set of clusters, each of which is a set of nodes (vertices) in the graph, where the nodes correspond to columns from the constraint alignments. In order for this clustering to define a valid MSA [also called a ‘trace’ in <xref rid="btaa992-B9" ref-type="bibr">Kececioglu (1993)</xref>], for each cluster, the set of associated columns must contain at most one column from any constraint alignment, <italic toggle="yes">and</italic> it must be possible to order the clusters (from left-to-right) so that there are no ‘crossings’. Hence, the clustering obtained using MCL is only an <italic toggle="yes">initial</italic> guess for a final ‘trace’ that will give us a legal merged MSA. Consequently, Phase 3 ‘fixes and orders’ the clusters (breaking them apart, if needed) to form a legal MSA.</p>
      </sec>
      <sec>
        <title> </title>
        <p><bold>Phase 1: alignment graph construction.</bold> We pick a number <italic toggle="yes">M</italic> of backbone alignments and the target size <italic toggle="yes">L</italic> per backbone alignment. For each backbone, we randomly select the same number <inline-formula id="IE5"><mml:math id="IM5" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>⌊</mml:mo><mml:mrow><mml:mfrac><mml:mi>L</mml:mi><mml:mi>q</mml:mi></mml:mfrac></mml:mrow><mml:mo>⌋</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> of sequences from each constraint alignment (where <italic toggle="yes">q</italic> is the number of constraint alignments), to achieve approximately the desired target size <italic toggle="yes">L</italic>. We then compute alignments on each backbone set of sequences, thus producing the backbone alignment for that set, and the full set of such backbone alignments forms the backbone library.</p>
        <p>Given the backbone library, we construct the ‘alignment graph’, where the vertices correspond to columns (i.e. sites) in the constraint alignments, and edges are derived from the backbone alignments, as we now describe. Given a column <italic toggle="yes">j</italic> in constraint alignment <italic toggle="yes">i</italic>, we create vertex <italic toggle="yes">S<sub>ij</sub></italic>. The edge between vertices <italic toggle="yes">S<sub>ij</sub></italic> and <italic toggle="yes">S<sub>km</sub></italic> is included if and only if there is at least one pair of letters from constraint alignment columns <italic toggle="yes">S<sub>ij</sub></italic> and <italic toggle="yes">S<sub>km</sub></italic> in the same column in a backbone alignment, and the weight of each such edge is the number of such pairs. Self-loops are retained, as well as edges between different vertices from the same constraint alignment.</p>
      </sec>
      <sec>
        <title> </title>
        <p><bold>Phase 2: clustering the graph.</bold> The next phase takes the undirected graph <italic toggle="yes">G</italic> from Phase 1 and partitions the vertices into disjoint clusters. In essence, the purpose of this clustering phase is twofold: (i) to make analysis of the alignment graph more tractable by culling the most weakly supported edges and guiding the construction of the connected components used in our trace (we will call connected components ‘clusters’ from here on out), and (ii) to extend the consistency principle in the multiple sequence alignment literature to longer paths within <italic toggle="yes">G</italic>, and thus find evidence for homology beyond what can be inferred using just a single third sequence. To perform this clustering, we use the Markov Clustering Algorithm (MCL) (<xref rid="btaa992-B24" ref-type="bibr">Van Dongen, 2000</xref>), which has been used in other problems in bioinformatics [e.g. <xref rid="btaa992-B11" ref-type="bibr">Li et al. (2003)</xref>]. Very briefly, the MCL algorithm tries to capture graph structure through stochastic flow, or the concept that random walks from nodes in a cluster will frequently visit other nodes within the cluster, and rarely visit nodes outside of the cluster. This makes the algorithm a natural choice for the problem at hand. The chief algorithmic parameter in MCL is the inflation factor <italic toggle="yes">I</italic>, which roughly controls the granularity of the clustering in GCM; the guidelines for choosing <italic toggle="yes">I</italic> in <xref rid="btaa992-B25" ref-type="bibr">Von Dongen (2012)</xref> suggest four values between 1.4 and 6.</p>
      </sec>
      <sec>
        <title> </title>
        <p><bold>Phase 3: clean-up to produce a MSA.</bold> The final phase is meant to modify the clustering from the previous step to yield a valid MSA on the full set <italic toggle="yes">X</italic> of sequences. Our objective is to convert our given set of clusters (connected components) into an ordered set of (possibly different) clusters that form a valid trace. Thus, our task is somewhat similar to the Maximum Weight Trace problem (<xref rid="btaa992-B9" ref-type="bibr">Kececioglu, 1993</xref>). We need our modified set of clusters to satisfy two trace conditions. The first condition is the absence of vertical violations, where some <italic toggle="yes">S<sub>ij</sub></italic> and <italic toggle="yes">S<sub>ik</sub></italic> (i.e, two columns from the same constraint alignment) appear together in a cluster (if the clustering algorithm permits overlapping clusters, we must also deal with ‘horizontal’ violations, where the same <italic toggle="yes">S<sub>ij</sub></italic> appears in more than one cluster). The second condition requires a valid ordering, so that if cluster <italic toggle="yes">C</italic> comes before cluster <inline-formula id="IE6"><mml:math id="IM6" display="inline" overflow="scroll"><mml:mrow><mml:mi>C</mml:mi><mml:mo>′</mml:mo></mml:mrow></mml:math></inline-formula>, then <italic toggle="yes">j </italic>&lt;<italic toggle="yes"> k</italic> for every <inline-formula id="IE7"><mml:math id="IM7" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE8"><mml:math id="IM8" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:mi>C</mml:mi><mml:mo>′</mml:mo></mml:mrow></mml:math></inline-formula>.</p>
        <p>Producing this new set of ordered clusters may be achievable just through ordering the original set of clusters (produced in Phase 1), or may require breaking some of the original clusters into two or more parts. Our optimization criterion is <bold>to satisfy our requirements using the smallest number of cluster breaks.</bold> In other words, we want to retain the integrity of our constraint alignment column matching as much as possible, while teasing a valid trace out of it.</p>
      </sec>
      <sec>
        <title> </title>
        <p><bold>Step 1: eliminate cluster violations.</bold> We use a greedy approach, which can require breaking clusters apart.</p>
        <list list-type="bullet">
          <list-item>
            <p>While violations exist:</p>
            <list list-type="bullet">
              <list-item>
                <p>find the pair <inline-formula id="IE9"><mml:math id="IM9" display="inline" overflow="scroll"><mml:mrow><mml:mi>C</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, where <italic toggle="yes">C</italic> is a cluster and <italic toggle="yes">S<sub>ij</sub></italic> is a horizontally or vertically violating element in <italic toggle="yes">C</italic> that has the smallest sum-of-weights between <italic toggle="yes">S<sub>ij</sub></italic> and the other elements in <italic toggle="yes">C</italic> (excluding elements from the same constraint alignment).</p>
              </list-item>
              <list-item>
                <p>Remove <italic toggle="yes">S<sub>ij</sub></italic> from <italic toggle="yes">C</italic>.</p>
              </list-item>
            </list>
          </list-item>
        </list>
        <p>The removal of <italic toggle="yes">S<sub>ij</sub></italic> from the cluster <italic toggle="yes">C</italic> creates a new singleton cluster. However, singleton clusters (which define single columns in some constraint alignment) are not needed in the next stage, so we will throw out all singleton clusters as we proceed to Step 2. Afterwards, we can reinsert all of the removed columns in their proper locations (and not homologous to any other columns) using the ordering inferred in Step 2.</p>
      </sec>
      <sec>
        <title> </title>
        <p><bold>Step 2: order (and possibly fragment) the clusters.</bold> With these cluster violations removed, it remains to produce a legal ordering, which can also require breaking clusters apart; this proves to be the most non-trivial component of the algorithm. We formulate this task as a search problem, as we now describe. Each state in the search space is defined by two sets of clusters—a set of clusters that have already been ordered, and a set of remaining unordered clusters. Then, our starting state has an empty ordered set, and all given clusters in the unordered set. An end state is any state with an empty unordered set, meaning that the ordered set contains a complete, valid ordering. This state space has an exponential number of states, and so we do not construct the space explicitly, but rather perform an implicit search from the starting state.</p>
        <p>We transition from one state to another by removing a cluster from the unordered set and adding it to the ordered set, if such a move is legal. A cluster <italic toggle="yes">X</italic> in the unordered set can only be legally moved into the ordered set if it comes strictly ‘before’ every other cluster in the unordered set, element-wise. More formally, we say a move from state <inline-formula id="IE10"><mml:math id="IM10" display="inline" overflow="scroll"><mml:mrow><mml:mi>A</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>U</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> to <inline-formula id="IE11"><mml:math id="IM11" display="inline" overflow="scroll"><mml:mrow><mml:mi>B</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>U</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> (where <italic toggle="yes">C<sub>i</sub></italic> is a set of ordered clusters, and <italic toggle="yes">U<sub>i</sub></italic> is a set of unordered clusters) is <italic toggle="yes">legal</italic> if <inline-formula id="IE12"><mml:math id="IM12" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo>∪</mml:mo><mml:mo>{</mml:mo><mml:mi>X</mml:mi><mml:mo>}</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>U</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>U</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo>∖</mml:mo><mml:mo>{</mml:mo><mml:mi>X</mml:mi><mml:mo>}</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:math></inline-formula> and for all <inline-formula id="IE13"><mml:math id="IM13" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:mi>X</mml:mi></mml:mrow></mml:math></inline-formula>, there is no <italic toggle="yes">S<sub>ik</sub></italic> with <italic toggle="yes">k </italic>&lt;<italic toggle="yes"> j</italic> belonging to any cluster in <italic toggle="yes">U</italic><sub>2</sub>. If no legal moves exist, we can transition to another state by breaking one of the unordered clusters apart into two unordered clusters. We want to travel from our starting state to an end state with the smallest number of cluster breaks, which is our measure of distance.</p>
        <p>We use the A* algorithm (<xref rid="btaa992-B6" ref-type="bibr">Hart et al., 1968</xref>), a mainstay in pathfinding and graph search applications, to perform the search. A* is an extension of Dijkstra’s algorithm that uses both distance and heuristic measures to guide the search; in our case, the distance measure is simply the size of the ordered set, and the heuristic measure is the size of the unordered set (thus being a lower bound on the remaining distance to travel). This suffices to guarantee that A* will eventually find an optimal path.</p>
        <p>Unfortunately, if the given clusters are poorly formed and extensively ‘tangled’, A* will not be able to find an optimal path in a reasonable amount of time. We handle such situations by weighting the heuristic more heavily if progress is not being made [i.e. we switch to Weighted A* (<xref rid="btaa992-B18" ref-type="bibr">Pearl, 1984</xref>)]. This revokes the optimality guarantee, but allows A* to finish more quickly while still finding a reasonable solution.</p>
        <p>Once A* finishes, we use the ordering on the clusters to construct the MSA: each cluster contains a set of constraint alignment columns, which we stack together to form a column in the final MSA. The ordering of the columns follows the ordering of the clusters, with gaps added wherever needed. Finally, as noted above, the singleton clusters that were deleted in Step 1 are then inserted into the correct location (defined by the ordering), without making them homologous to any other columns.</p>
      </sec>
      <sec>
        <title> </title>
        <p><bold>Runtime complexity.</bold> The runtime of MAGUS is dominated by building backbone alignments, which we perform using MAFFT -L-ins-i. This portion is <inline-formula id="IE14"><mml:math id="IM14" display="inline" overflow="scroll"><mml:mrow><mml:mi>O</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msub><mml:msubsup><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mi>m</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:msubsup><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mi>l</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, where <italic toggle="yes">B<sub>n</sub></italic> is the number of backbone alignments, <italic toggle="yes">B<sub>l</sub></italic> is their average length and <italic toggle="yes">B<sub>m</sub></italic> is the maximum number of sequences in each backbone, and follows from the runtime complexity of MAFFT -L-ins-i (<xref rid="btaa992-B7" ref-type="bibr">Katoh and Toh, 2008</xref>). For additional details, see the <xref rid="sup1" ref-type="supplementary-material">Supplementary Materials</xref>.</p>
      </sec>
    </sec>
  </sec>
  <sec>
    <title>3 Evaluation</title>
    <sec>
      <title> </title>
      <p><bold>Overview.</bold> We performed three experiments. Experiment 1: We set default algorithmic parameters for a fast variant and a slower variant of MAGUS. Experiment 2: We compare both the fast and slow variants of MAGUS to PASTA run for varying numbers of iterations. Experiment 3: We evaluate the impact of following a PASTA analysis with a single iteration where GCM replaces Opal or Muscle for the alignment merger technique. We perform our evaluation study on the UIUC Campus Cluster. Our analyses are run on nodes with 16 cores, 64 GB of memory and a walltime limit of 4 h (except for 16S.B.ALL, where we use high memory nodes with a limit of 48 h). We provide an overview of representative results here. Commands and additional results are presented in the <xref rid="sup1" ref-type="supplementary-material">Supplementary Materials</xref>.</p>
    </sec>
    <sec>
      <title> </title>
      <p><bold>Datasets.</bold> Our evaluation explores a heterogeneous collection of simulated and biological datasets from prior studies, available in public websites [see <xref rid="btaa992-B22" ref-type="bibr">Smirnov (2020)</xref>]. For simulated datasets, we use ten 1000-sequence model conditions from <xref rid="btaa992-B12" ref-type="bibr">Liu <italic toggle="yes">et al.</italic> (2009)</xref>, ranging from 1000M1 (the most difficult) to 1000M4 (relatively easy). We also use 1000 and 10 000-sequence subsets of the RNASim dataset from <xref rid="btaa992-B15" ref-type="bibr">Mirarab <italic toggle="yes">et al.</italic> (2015)</xref>, which evolve under a non-standard model with positive selection. For the biological datasets, we include four large nucleotide datasets from <xref rid="btaa992-B1" ref-type="bibr">Cannone et al. (2002)</xref> and eight protein datasets from BAliBASE (<xref rid="btaa992-B23" ref-type="bibr">Thompson et al., 1999</xref>), where reference alignments are available based on structural features. Since PASTA (and most other alignment methods, other than UPP) is restricted to datasets without sequence length heterogeneity, these biological datasets were first modified to remove the outlier sequences (i.e. the ones that deviate in length from the median by more than 20%). The modified biological datasets range in size from 195 sequences to 24 246 sequences, and vary in the average pairwise sequence identity, percent of the matrix occupied by gaps and other empirical properties. See <xref rid="btaa992-T1" ref-type="table">Table 1</xref> for additional details.</p>
      <table-wrap position="float" id="btaa992-T1">
        <label>Table 1.</label>
        <caption>
          <p>Dataset properties</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="left" span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1">Dataset</th>
              <th rowspan="1" colspan="1">No. of Seqs</th>
              <th rowspan="1" colspan="1">Avg. <italic toggle="yes">P</italic>-dist.</th>
              <th rowspan="1" colspan="1">Max <italic toggle="yes">P</italic>-dist.</th>
              <th rowspan="1" colspan="1">% gaps</th>
              <th rowspan="1" colspan="1">Seq. length (avg)</th>
              <th rowspan="1" colspan="1">Type</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td colspan="7" rowspan="1">Nucleotide datasets</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"> 1000M1</td>
              <td rowspan="1" colspan="1">1000</td>
              <td rowspan="1" colspan="1">0.695</td>
              <td rowspan="1" colspan="1">0.769</td>
              <td rowspan="1" colspan="1">74</td>
              <td rowspan="1" colspan="1">1011</td>
              <td rowspan="1" colspan="1">sim NT</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"> 1000M2</td>
              <td rowspan="1" colspan="1">1000</td>
              <td rowspan="1" colspan="1">0.684</td>
              <td rowspan="1" colspan="1">0.762</td>
              <td rowspan="1" colspan="1">74</td>
              <td rowspan="1" colspan="1">1014</td>
              <td rowspan="1" colspan="1">sim NT</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"> 1000M3</td>
              <td rowspan="1" colspan="1">1000</td>
              <td rowspan="1" colspan="1">0.660</td>
              <td rowspan="1" colspan="1">0.741</td>
              <td rowspan="1" colspan="1">63</td>
              <td rowspan="1" colspan="1">1008</td>
              <td rowspan="1" colspan="1">sim NT</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"> 1000M4</td>
              <td rowspan="1" colspan="1">1000</td>
              <td rowspan="1" colspan="1">0.495</td>
              <td rowspan="1" colspan="1">0.606</td>
              <td rowspan="1" colspan="1">61</td>
              <td rowspan="1" colspan="1">1007</td>
              <td rowspan="1" colspan="1">sim NT</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"> 1000S1</td>
              <td rowspan="1" colspan="1">1000</td>
              <td rowspan="1" colspan="1">0.694</td>
              <td rowspan="1" colspan="1">0.768</td>
              <td rowspan="1" colspan="1">53</td>
              <td rowspan="1" colspan="1">1006</td>
              <td rowspan="1" colspan="1">sim NT</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"> 1000S2</td>
              <td rowspan="1" colspan="1">1000</td>
              <td rowspan="1" colspan="1">0.693</td>
              <td rowspan="1" colspan="1">0.768</td>
              <td rowspan="1" colspan="1">35</td>
              <td rowspan="1" colspan="1">1005</td>
              <td rowspan="1" colspan="1">sim NT</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"> 1000S3</td>
              <td rowspan="1" colspan="1">1000</td>
              <td rowspan="1" colspan="1">0.686</td>
              <td rowspan="1" colspan="1">0.763</td>
              <td rowspan="1" colspan="1">37</td>
              <td rowspan="1" colspan="1">1005</td>
              <td rowspan="1" colspan="1">sim NT</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"> 1000L1</td>
              <td rowspan="1" colspan="1">1000</td>
              <td rowspan="1" colspan="1">0.695</td>
              <td rowspan="1" colspan="1">0.769</td>
              <td rowspan="1" colspan="1">73</td>
              <td rowspan="1" colspan="1">1023</td>
              <td rowspan="1" colspan="1">sim NT</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"> 1000L2</td>
              <td rowspan="1" colspan="1">1000</td>
              <td rowspan="1" colspan="1">0.696</td>
              <td rowspan="1" colspan="1">0.769</td>
              <td rowspan="1" colspan="1">58</td>
              <td rowspan="1" colspan="1">1018</td>
              <td rowspan="1" colspan="1">sim NT</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"> 1000L3</td>
              <td rowspan="1" colspan="1">1000</td>
              <td rowspan="1" colspan="1">0.687</td>
              <td rowspan="1" colspan="1">0.763</td>
              <td rowspan="1" colspan="1">85</td>
              <td rowspan="1" colspan="1">1042</td>
              <td rowspan="1" colspan="1">sim NT</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"> RNASim</td>
              <td rowspan="1" colspan="1">1000</td>
              <td rowspan="1" colspan="1">0.411</td>
              <td rowspan="1" colspan="1">0.609</td>
              <td rowspan="1" colspan="1">68</td>
              <td rowspan="1" colspan="1">1555</td>
              <td rowspan="1" colspan="1">sim NT</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"> 16S.M</td>
              <td rowspan="1" colspan="1">740</td>
              <td rowspan="1" colspan="1">0.298</td>
              <td rowspan="1" colspan="1">0.694</td>
              <td rowspan="1" colspan="1">60</td>
              <td rowspan="1" colspan="1">947</td>
              <td rowspan="1" colspan="1">bio NT</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"> 16S.3</td>
              <td rowspan="1" colspan="1">5489</td>
              <td rowspan="1" colspan="1">0.307</td>
              <td rowspan="1" colspan="1">0.833</td>
              <td rowspan="1" colspan="1">77</td>
              <td rowspan="1" colspan="1">1505</td>
              <td rowspan="1" colspan="1">bio NT</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"> 16S.T</td>
              <td rowspan="1" colspan="1">5548</td>
              <td rowspan="1" colspan="1">0.306</td>
              <td rowspan="1" colspan="1">0.901</td>
              <td rowspan="1" colspan="1">83</td>
              <td rowspan="1" colspan="1">1501</td>
              <td rowspan="1" colspan="1">bio NT</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"> 16S.B.ALL</td>
              <td rowspan="1" colspan="1">24 246</td>
              <td rowspan="1" colspan="1">0.208</td>
              <td rowspan="1" colspan="1">0.769</td>
              <td rowspan="1" colspan="1">73</td>
              <td rowspan="1" colspan="1">1444</td>
              <td rowspan="1" colspan="1">bio NT</td>
            </tr>
            <tr>
              <td colspan="7" rowspan="1">Amino acid datasets</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"> BBA0039</td>
              <td rowspan="1" colspan="1">732</td>
              <td rowspan="1" colspan="1">0.364</td>
              <td rowspan="1" colspan="1">0.918</td>
              <td rowspan="1" colspan="1">69</td>
              <td rowspan="1" colspan="1">382</td>
              <td rowspan="1" colspan="1">bio AA</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"> BBA0067</td>
              <td rowspan="1" colspan="1">274</td>
              <td rowspan="1" colspan="1">0.779</td>
              <td rowspan="1" colspan="1">0.895</td>
              <td rowspan="1" colspan="1">56</td>
              <td rowspan="1" colspan="1">448</td>
              <td rowspan="1" colspan="1">bio AA</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"> BBA0081</td>
              <td rowspan="1" colspan="1">195</td>
              <td rowspan="1" colspan="1">0.860</td>
              <td rowspan="1" colspan="1">0.967</td>
              <td rowspan="1" colspan="1">63</td>
              <td rowspan="1" colspan="1">578</td>
              <td rowspan="1" colspan="1">bio AA</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"> BBA0101</td>
              <td rowspan="1" colspan="1">322</td>
              <td rowspan="1" colspan="1">0.778</td>
              <td rowspan="1" colspan="1">0.899</td>
              <td rowspan="1" colspan="1">51</td>
              <td rowspan="1" colspan="1">465</td>
              <td rowspan="1" colspan="1">bio AA</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"> BBA0117</td>
              <td rowspan="1" colspan="1">423</td>
              <td rowspan="1" colspan="1">0.750</td>
              <td rowspan="1" colspan="1">1.000</td>
              <td rowspan="1" colspan="1">46</td>
              <td rowspan="1" colspan="1">56</td>
              <td rowspan="1" colspan="1">bio AA</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"> BBA0134</td>
              <td rowspan="1" colspan="1">370</td>
              <td rowspan="1" colspan="1">0.710</td>
              <td rowspan="1" colspan="1">1.000</td>
              <td rowspan="1" colspan="1">70</td>
              <td rowspan="1" colspan="1">458</td>
              <td rowspan="1" colspan="1">bio AA</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"> BBA0154</td>
              <td rowspan="1" colspan="1">295</td>
              <td rowspan="1" colspan="1">0.662</td>
              <td rowspan="1" colspan="1">0.850</td>
              <td rowspan="1" colspan="1">51</td>
              <td rowspan="1" colspan="1">514</td>
              <td rowspan="1" colspan="1">bio AA</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"> BBA0190</td>
              <td rowspan="1" colspan="1">343</td>
              <td rowspan="1" colspan="1">0.697</td>
              <td rowspan="1" colspan="1">0.900</td>
              <td rowspan="1" colspan="1">56</td>
              <td rowspan="1" colspan="1">896</td>
              <td rowspan="1" colspan="1">bio AA</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn1">
            <p><italic toggle="yes">Note</italic>: We show the number of sequences, average and maximum <italic toggle="yes">P</italic>-distance (i.e. normalized Hamming distance), average unaligned sequence length, and whether the dataset is simulated or biological. The biological datasets were pre-processed to remove sequences of length more than 20% above or below the median length.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
    </sec>
    <sec>
      <title> </title>
      <p><bold>Criteria.</bold> We use SPFN and SPFP, computed using FastSP (<xref rid="btaa992-B14" ref-type="bibr">Mirarab and Warnow, 2011</xref>). SPFN denotes the Sum-of-Pairs False Negative rate, which is the fraction of pairs of homologous letters in the true alignment that are not aligned in the estimated alignment. SPFP is the corresponding Sum-of-Pairs False Positive rate, the fraction of pairs of aligned letters in the estimated alignment that are not in the true alignment. SPFN and SPFP are related to the SP-Score and Modeler scores (used sometimes in protein alignment evaluation) by the formulae: SP-score = 1-SPFN and Modeler Score = 1-SPFP. Due to space constraints, we show SPFN and SPFP in the <xref rid="sup1" ref-type="supplementary-material">supplementary materials</xref>, and report their average in the main article.</p>
      <p>Runtimes are reported for each process running start-to-finish on a single cluster node, with both PASTA and MAGUS exploiting multi-threading in a similar way (i.e. the MAFFT -L-ins-i runs are parallelized).</p>
    </sec>
  </sec>
  <sec>
    <title>4 Results</title>
    <sec>
      <title>4.1 Experiment 1: parameter tuning for MAGUS</title>
      <p>MAGUS has multiple algorithmic parameters: MCL inflation parameter for GCM, starting tree, number of constraint subsets, number and size of backbone alignments, and whether the backbone alignments are extended to full alignments using HMMER (<xref rid="btaa992-B3" ref-type="bibr">Eddy, 2020</xref>) (see <xref rid="sup1" ref-type="supplementary-material">Supplementary Materials</xref>). We performed extensive experiments on the 1000M1 model condition to evaluate the impact of how we set these parameters; we excluded one of the 20 replicates as a persistent outlier, and used performance on the other replicates for this experiment. This experiment determined default settings for two modes of MAGUS: a fast version, which does not include the HMM-extension technique, and a slow version that does. Both versions use the same settings for the other parameters: MCL inflation parameter 4, a starting tree that we have developed, 10 backbones of size 200 and divide the input sequence set into 25 subsets for constraint alignment creation. Here we show how changes to these selected parameters impact accuracy and running time. (The results for different inflation factors are provided in the <xref rid="sup1" ref-type="supplementary-material">supplementary materials</xref>, and are less interesting as they follow a standard recommendation in any event.)</p>
      <sec>
        <title> </title>
        <p><bold>Experiment 1(a): varying the size and number of backbone alignments and number of constraint alignments.</bold> We vary the number of constraint alignments, and the number and size of our backbones (<xref rid="btaa992-F2" ref-type="fig">Fig. 2</xref>). We use the MAGUS starting tree and fix the inflation parameter to 4.</p>
        <fig position="float" id="btaa992-F2">
          <label>Fig. 2.</label>
          <caption>
            <p>Experiment 1(a): Exploring the impact of varying the size and number of backbone alignments, and number of constraint alignments. ‘A × B’ indicates MAGUS being run with B backbones of size A in fast mode. Top: The error rates are the average of SPFN and SPFP, and are averaged over the 19 replicates of the 1000M1 model condition. Error bars indicate standard error. The <italic toggle="yes">x</italic>-axis shows the impact of changing the number of subsets. Bottom: Average running time (in minutes) over the 19 replicates of the 1000M1 model condition. Error bars indicate standard error. The <italic toggle="yes">x</italic>-axis shows the impact of changing the number of subsets</p>
          </caption>
          <graphic xlink:href="btaa992f2" position="float"/>
        </fig>
        <p>Note that the best accuracy is obtained using 25 constraint alignments and 15 backbones of size 200 or 300. Given the use of 25 constraint alignments and 15 backbones, there is no difference in accuracy between backbones of size 200 and 300, but that change does impact the running time. However, smaller backbones definitely increase error, and fewer than 10 backbones also increase error noticeably. There is only a small decrease in accuracy when using 10 instead of 15 backbone alignments, and so if running time is considered, the best default setting seems to be 25 constraint alignments and 10 backbones of size 200. If time permits, then 15 or even 20 backbones can be used, and such a setting might reasonably be used on much larger datasets, where the computation of constraint alignments would dominate the runtime anyway.</p>
      </sec>
      <sec>
        <title> </title>
        <p><bold>Experiment 1(b): varying the starting tree, number of constraint alignment subsets and HMM-extension.</bold> In this experiment we show the impact of the choice of starting tree and the use of HMM-extension (see <xref rid="sup1" ref-type="supplementary-material">Supplementary Materials</xref> for commands), while allowing the number of constraint alignments to change; all analyses use inflation factor <italic toggle="yes">I </italic>=<italic toggle="yes"> </italic>4 and we use 10 backbones of size 200.</p>
        <p>There is an advantage in alignment accuracy to using the MAGUS starting tree instead of the PASTA starting tree, and this advantage is present at every number of constraint alignments we examine (<xref rid="btaa992-F3" ref-type="fig">Fig. 3</xref>). The impact of using the HMM-extension to complete the backbone alignments (‘slow’ mode) is generally positive—improving accuracy with 25 or more constraint alignments and neutral on fewer constraint alignments. However, using the HMM-extension increases the runtime (e.g. the median runtime here increases by as much as 10 min). However, of perhaps greater concern is the high variance in the runtime when using the HMM-extension, which suggests that it may become very computationally expensive to use on large datasets.</p>
        <fig position="float" id="btaa992-F3">
          <label>Fig. 3.</label>
          <caption>
            <p>Experiment 1(b): Exploring the impact of starting tree, HMM-extension and subset number on MAGUS on 1000M1. Top: The error rates are the average of SPFN and SPFP, and are averaged over the 19 replicates of the 1000M1 model condition. Error bars indicate standard error. MAGUS(P0) uses the PASTA starting tree instead of the MAGUS starting tree. MAGUS(Slow) uses the HMM-extension. The x-axis shows the impact of changing the number of subsets. Bottom: Average running time (in minutes), averaged over the 19 replicates of the 1000M1 model condition. Error bars indicate standard error. The <italic toggle="yes">x</italic>-axis shows the impact of changing the number of subsets</p>
          </caption>
          <graphic xlink:href="btaa992f3" position="float"/>
        </fig>
      </sec>
    </sec>
    <sec>
      <title>4.2 Experiment 2: MAGUS versus PASTA</title>
      <p>The central experiment of our study is the comparison between MAGUS and PASTA. MAGUS(Fast) and MAGUS(Slow) differ in the use of the HMM-extension, but otherwise both use 25 constraint alignments and 10 backbones of size 200, and the same starting tree. Of the ten model conditions with 1000 sequences (<xref rid="btaa992-F4" ref-type="fig">Fig. 4</xref>), both versions of MAGUS have better accuracy on nine conditions and tie with PASTA on one condition. The largest differences are on the hardest model condition, 1000L3, where MAGUS (both versions) leads PASTA by about 6–7% (10–11% versus 17–18%). The difference narrows, but persists, under easier model conditions. The use of MAGUS(Slow) provides an accuracy benefit under the harder model conditions, and otherwise has very similar accuracy as MAGUS(Fast). Moreover, MAGUS(Slow) and MAGUS(Fast) are both much faster than PASTA, generally completing in about half the time (e.g. a reduction from about 40 min for PASTA to about 15 min for MAGUS on 1000M2, and from about 20 min to about 10 min on 1000M3). Lastly, the error bars indicate that MAGUS tends to have noticeably lower variability in its accuracy and runtime than PASTA under the harder model conditions.</p>
      <fig position="float" id="btaa992-F4">
        <label>Fig. 4.</label>
        <caption>
          <p>Experiment 2: MAGUS versus PASTA on the 1000-taxon datasets. Top: The error rates are the average of SPFN and SPFP. The <italic toggle="yes">x</italic>-axis shows the model condition; each model condition has 1000 sequences. Results are averaged over 20 replicates. Error bars indicate standard error. PASTA and MAGUS were run in default mode. Bottom: Average running time (in minutes). Results are averaged over 20 replicates. Error bars indicate standard error</p>
        </caption>
        <graphic xlink:href="btaa992f4" position="float"/>
      </fig>
      <p>On the larger datasets, ranging from 5489 to 24 246 sequences (<xref rid="btaa992-F5" ref-type="fig">Fig. 5</xref>), MAGUS’s accuracy is tied with PASTA on the 16S.3 dataset, but is about 1–2% better on the other three datasets. MAGUS is also much faster, often finishing in half the time as PASTA (e.g. on the 16S.B.ALL dataset with over 24 000 sequences, MAGUS completes in 3 h to PASTA’s 6). The differences between MAGUS and PASTA on small datasets (see Supplementary Figs S2–S4) are generally small, but also show an advantage for MAGUS: out of the nine datasets, there are three with a noticeable accuracy advantage for MAGUS (both Slow and Fast). PASTA and MAGUS(Fast) are effectively tied on the other six datasets, and MAGUS(Slow) is slightly worse on one of them. Notably, MAGUS(Slow) doesn’t enjoy any accuracy advantage over MAGUS(Fast). In terms of runtime, MAGUS is slower than PASTA on the smallest dataset (17 min versus 9 min), but this difference reverses by the time we reach the largest of the small datasets (10 min versus 18 min).</p>
      <fig position="float" id="btaa992-F5">
        <label>Fig. 5.</label>
        <caption>
          <p>Experiment 2: MAGUS versus PASTA on the larger nucleotide datasets. Top: The error rates are the average of SPFN and SPFP. The <italic toggle="yes">x</italic>-axis shows the dataset, with the number of taxa in parentheses. RNASim is simulated (results shown are averaged over 10 replicates, error bars indicate standard error); the other datasets are biological. PASTA was run in default mode; MAGUS was run with 50 constraint alignment subsets, except for 16S.B.ALL, where it was run with 200 constraint alignment subsets due to time limitations. Bottom: Average running time (in hours). Results for RNASim are averaged over 10 replicates, error bars indicate standard error</p>
        </caption>
        <graphic xlink:href="btaa992f5" position="float"/>
      </fig>
    </sec>
    <sec>
      <title>4.3 Experiment 3: evaluating PASTA+GCM</title>
      <p>Recall that default PASTA runs for three iterations; here we explore the impact of using GCM within PASTA instead of the standard options in PASTA for merging sets of alignments. Thus, we compare three pipelines: PASTA(3) (i.e. default PASTA, which runs for three iterations), PASTA(4) (i.e. running PASTA in default mode but allowing an additional iteration) and PASTA(3)+GCM (i.e. following PASTA(3) by an iteration where we replace the default merger strategy in PASTA by GCM).</p>
      <p>PASTA(3)+GCM outperforms PASTA(3) and PASTA(4) on the ten 1000-sequence model conditions (<xref rid="btaa992-F6" ref-type="fig">Fig. 6</xref>top). The improvement is largest for the most difficult model condition (1000L3) and this difference decreases as the rates of evolution decrease, so that PASTA(3)+GCM is strictly better on the nine hardest conditions and marginally worse on the easiest dataset. As expected, PASTA(3) and PASTA(4) are very close in accuracy, indicating that there is practically no accuracy benefit to running more than three PASTA iterations. Results on the largest datasets (<xref rid="btaa992-F6" ref-type="fig">Fig. 6  </xref>bottom) are nearly identical to their counterparts from Experiment 2: we see a tie between PASTA+GCM and PASTA on the 16S.3 dataset, and a 1–2% advantage to running a PASTA+GCM iteration on the other three datasets. As before, an additional PASTA iteration hardly makes a difference. Results on the smaller biological datasets (Supplementary Figs S7 and S8) show consistent trends: the PASTA+GCM iteration yields a sizeable benefit on one dataset and small gains on three others, with the remaining five being essentially tied. Thus, dataset size influences, but does not determine, whether using GCM within PASTA improves accuracy.</p>
      <fig position="float" id="btaa992-F6">
        <label>Fig. 6.</label>
        <caption>
          <p>Experiment 3: Alignment error (average of SPFN and SPFN) for PASTA(3), PASTA(4) and PASTA(3)+GCM. Top: results on the 1000-taxon simulated datasets. Bottom: results on the simulated RNASim datasets and three nucleotide biological datasets. The <italic toggle="yes">x</italic>-axis shows the dataset, with the number of taxa in parentheses. PASTA was run in default mode. Results for simulated datasets are averaged over the replicates (RNASim10K has 10 replicates, others have 20 replicates). Error bars indicate standard error</p>
        </caption>
        <graphic xlink:href="btaa992f6" position="float"/>
      </fig>
    </sec>
  </sec>
  <sec>
    <title>5 Discussion</title>
    <p>Both versions of MAGUS are generally at least as accurate as PASTA, with reliable improvements on the large, challenging datasets and a small advantage on the smaller datasets [i.e. MAGUS provided a small accuracy advantage for about half the smaller datasets and matched PASTA on the other datasets, with MAGUS(Slow) coming off slightly worse on one], and differences in running time are often relatively small. MAGUS is also faster than PASTA on the larger datasets (with 1000 or more sequences), and the running time advantage can result in a savings of several hours on the larger datasets. The improvement in running time is easily understood, since MAGUS requires only one iteration, whereas PASTA default uses three iterations. What is more noteworthy, therefore, is the improvement in accuracy.</p>
    <p>We did not expect to see any improvements on the small datasets, and so the general superior accuracy obtained by MAGUS compared to PASTA on these datasets is noteworthy. It is not clear why MAGUS has better accuracy on these data, and this is a question for future research. On the other hand, the improvement of MAGUS over PASTA on the larger datasets makes sense, since PASTA’s merger strategy is inherently limited: it uses Opal or Muscle to merge pairs of constraint alignments and then completes the merger using transitivity. While this approach ensures scalability, there is room for improvement by merging all the constraint alignments at once. Therefore, the improvements we see of MAGUS over PASTA on the larger datasets, especially when the alignments are complicated by high rates of substitutions and indels, seem fairly understandable.</p>
  </sec>
  <sec>
    <title>6 Conclusion</title>
    <p>MAGUS is a new method based on PASTA’s divide-and-conquer strategy for large-scale multiple sequence alignment. Our study, which evaluated MAGUS and PASTA under a heterogeneous collection of datasets, shows that MAGUS typically improves on the accuracy of default PASTA (which was optimized for accuracy), particularly under more difficult model conditions. MAGUS also runs for a single iteration, as opposed to PASTA’s three, which dramatically reduces the runtime. Thus, MAGUS’s ability to produce more accurate alignments in a much shorter amount of time offers a convincing improvement over PASTA, a method that has been surprisingly difficult to improve. Furthermore, following PASTA with a single iteration using GCM also yields improvements (and more than a single additional PASTA iteration), thus showing that GCM itself provides an advantage over the merging strategy in PASTA.</p>
    <p>Our study suggests several directions for future work. We only compared MAGUS to PASTA, but other methods have been developed that are designed for large datasets [e.g. <xref rid="btaa992-B5" ref-type="bibr">Garriga <italic toggle="yes">et al.</italic> (2019)</xref>; <xref rid="btaa992-B10" ref-type="bibr">Lassmann (2019)</xref>; <xref rid="btaa992-B21" ref-type="bibr">Sievers <italic toggle="yes">et al.</italic> (2011)</xref>], and we should compare MAGUS to these other methods. Finally, the main source of the improvement we obtain is due to the use of GCM, which merges all the constraint alignments (produced in the PASTA divide-and-conquer strategy) together, compared to PASTA’s default. GCM is not the only method that is capable of this [e.g. MAFFT –merge and T-Coffee –profile (<xref rid="btaa992-B17" ref-type="bibr">Notredame et al., 2000</xref>) also have this capability] and so future work should examine these methods for their impact within MAGUS and more generally.</p>
  </sec>
  <sec>
    <title>Funding</title>
    <p>This work was supported in part by National Science Foundation (NSF) [ABI-1458652 to T.W.].</p>
    <p><italic toggle="yes">Conflict of Interest:</italic> none declared.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material id="sup1" position="float" content-type="local-data">
      <label>btaa992_Supplementary_Data</label>
      <media xlink:href="btaa992_supplementary_data.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="btaa992-B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cannone</surname><given-names>J.J.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2002</year>) 
<article-title>The comparative RNA web (CRW) site: an online database of comparative sequence and structure information for ribosomal, intron, and other RNAs</article-title>. <source>BMC Bioinf</source>., <volume>3</volume>, <fpage>2</fpage>.</mixed-citation>
    </ref>
    <ref id="btaa992-B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Do</surname><given-names>C.B.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2005</year>) 
<article-title>Probcons: probabilistic consistency-based multiple sequence alignment</article-title>. <source>Genome Res</source>., <volume>15</volume>, <fpage>330</fpage>–<lpage>340</lpage>.<pub-id pub-id-type="pmid">15687296</pub-id></mixed-citation>
    </ref>
    <ref id="btaa992-B3">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Eddy</surname><given-names>S.R.</given-names></string-name></person-group> (<year>2020</year>) <italic toggle="yes">HMMER website</italic>. <ext-link xlink:href="http://hmmer.org/" ext-link-type="uri">http://hmmer.org/</ext-link> (25 September 2020, date last accessed).</mixed-citation>
    </ref>
    <ref id="btaa992-B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Edgar</surname><given-names>R.C.</given-names></string-name></person-group> (<year>2004</year>) 
<article-title>MUSCLE: a multiple sequence alignment method with reduced time and space complexity</article-title>. <source>BMC Bioinf</source>., <volume>5</volume>, <fpage>113</fpage>.</mixed-citation>
    </ref>
    <ref id="btaa992-B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Garriga</surname><given-names>E.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2019</year>) 
<article-title>Large multiple sequence alignments with a root-to-leaf regressive method</article-title>. <source>Nat. Biotechnol</source>., <volume>37</volume>, <fpage>1466</fpage>–<lpage>1470</lpage>.<pub-id pub-id-type="pmid">31792410</pub-id></mixed-citation>
    </ref>
    <ref id="btaa992-B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hart</surname><given-names>P.E.</given-names></string-name></person-group>  <etal>et al</etal> (<year>1968</year>) 
<article-title>A formal basis for the heuristic determination of minimum cost paths</article-title>. <source>IEEE Trans. Syst. Sci. Cyber</source>., <volume>4</volume>, <fpage>100</fpage>–<lpage>107</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa992-B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Katoh</surname><given-names>K.</given-names></string-name>, <string-name><surname>Toh</surname><given-names>H.</given-names></string-name></person-group> (<year>2008</year>) 
<article-title>Recent developments in the MAFFT multiple sequence alignment program</article-title>. <source>Brief. Bioinf</source>., <volume>9</volume>, <fpage>286</fpage>–<lpage>298</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa992-B8">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Katoh</surname><given-names>K.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2005</year>) 
<article-title>MAFFT version 5: improvement in accuracy of multiple sequence alignment</article-title>. <source>Nucleic Acids Res</source>., <volume>33</volume>, <fpage>511</fpage>–<lpage>518</lpage>.<pub-id pub-id-type="pmid">15661851</pub-id></mixed-citation>
    </ref>
    <ref id="btaa992-B9">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Kececioglu</surname><given-names>J.</given-names></string-name></person-group> (<year>1993</year>) <part-title>The maximum weight trace problem in multiple sequence alignment</part-title>. In: <source>Annual Symposium on Combinatorial Pattern Matching</source>. Berlin, Heidelberg: 
<publisher-name>Springer</publisher-name>, pp. <fpage>106</fpage>–<lpage>119</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa992-B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lassmann</surname><given-names>T.</given-names></string-name></person-group> (<year>2019</year>) 
<article-title>Kalign 3: multiple sequence alignment of large datasets</article-title>. <source>Bioinformatics</source>, <volume>36</volume>, <fpage>1928</fpage>–<lpage>1929</lpage>.<pub-id pub-id-type="pmid">31665271</pub-id></mixed-citation>
    </ref>
    <ref id="btaa992-B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Li</surname><given-names>L.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2003</year>) 
<article-title>OrthoMCL: identification of ortholog groups for eukaryotic genomes</article-title>. <source>Genome Res</source>., <volume>13</volume>, <fpage>2178</fpage>–<lpage>2189</lpage>.<pub-id pub-id-type="pmid">12952885</pub-id></mixed-citation>
    </ref>
    <ref id="btaa992-B12">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Liu</surname><given-names>K.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2009</year>) 
<article-title>Rapid and accurate large-scale coestimation of sequence alignments and phylogenetic trees</article-title>. <source>Science</source>, <volume>324</volume>, <fpage>1561</fpage>–<lpage>1564</lpage>.<pub-id pub-id-type="pmid">19541996</pub-id></mixed-citation>
    </ref>
    <ref id="btaa992-B13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Liu</surname><given-names>K.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2012</year>) 
<article-title>SATe-II: very fast and accurate simultaneous estimation of multiple sequence alignments and phylogenetic trees</article-title>. <source>Syst. Biol</source>., <volume>61</volume>, <fpage>90</fpage>.<pub-id pub-id-type="pmid">22139466</pub-id></mixed-citation>
    </ref>
    <ref id="btaa992-B14">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mirarab</surname><given-names>S.</given-names></string-name>, <string-name><surname>Warnow</surname><given-names>T.</given-names></string-name></person-group> (<year>2011</year>) 
<article-title>FastSP: linear time calculation of alignment accuracy</article-title>. <source>Bioinformatics</source>, <volume>27</volume>, <fpage>3250</fpage>–<lpage>3258</lpage>.<pub-id pub-id-type="pmid">21984754</pub-id></mixed-citation>
    </ref>
    <ref id="btaa992-B15">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mirarab</surname><given-names>S.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2015</year>) 
<article-title>PASTA: ultra-large multiple sequence alignment for nucleotide and amino-acid sequences</article-title>. <source>J. Comput. Biol</source>., <volume>22</volume>, <fpage>377</fpage>–<lpage>386</lpage>.<pub-id pub-id-type="pmid">25549288</pub-id></mixed-citation>
    </ref>
    <ref id="btaa992-B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nguyen</surname><given-names>N-p.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2015</year>) 
<article-title>Ultra-large alignments using phylogeny-aware profiles</article-title>. <source>Genome Biol</source>., <volume>16</volume>, <fpage>124</fpage>.<pub-id pub-id-type="pmid">26076734</pub-id></mixed-citation>
    </ref>
    <ref id="btaa992-B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Notredame</surname><given-names>C.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2000</year>) 
<article-title>T-Coffee: a novel method for fast and accurate multiple sequence alignment</article-title>. <source>J. Mol. Biol</source>., <volume>302</volume>, <fpage>205</fpage>–<lpage>217</lpage>.<pub-id pub-id-type="pmid">10964570</pub-id></mixed-citation>
    </ref>
    <ref id="btaa992-B18">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Pearl</surname><given-names>J.</given-names></string-name></person-group> (<year>1984</year>) <source>Intelligent Search Strategies for Computer Problem Solving</source>. Boston, MA: 
<publisher-name>Addison Wesley</publisher-name>.</mixed-citation>
    </ref>
    <ref id="btaa992-B19">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pei</surname><given-names>J.</given-names></string-name>, <string-name><surname>Grishin</surname><given-names>N.V.</given-names></string-name></person-group> (<year>2007</year>) 
<article-title>PROMALS: towards accurate multiple sequence alignments of distantly related proteins</article-title>. <source>Bioinformatics</source>, <volume>23</volume>, <fpage>802</fpage>–<lpage>808</lpage>.<pub-id pub-id-type="pmid">17267437</pub-id></mixed-citation>
    </ref>
    <ref id="btaa992-B20">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Price</surname><given-names>M.N.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2010</year>) 
<article-title>FastTree 2—approximately maximum-likelihood trees for large alignments</article-title>. <source>PLoS One</source>, <volume>5</volume>, <fpage>e9490</fpage>.<pub-id pub-id-type="pmid">20224823</pub-id></mixed-citation>
    </ref>
    <ref id="btaa992-B21">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sievers</surname><given-names>F.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2011</year>) 
<article-title>Fast, scalable generation of high-quality protein multiple sequence alignments using clustal omega</article-title>. <source>Mol. Syst. Biol</source>., <volume>7</volume>, <fpage>539</fpage>.<pub-id pub-id-type="pmid">21988835</pub-id></mixed-citation>
    </ref>
    <ref id="btaa992-B22">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Smirnov</surname><given-names>V.</given-names></string-name></person-group> (<year>2020</year>) <italic toggle="yes">Datasets for the MAGUS study</italic>. Illinois Data Bank website, <pub-id pub-id-type="doi">10.13012/B2IDB-2643961_V1</pub-id> (25 September 2020, date last accessed).</mixed-citation>
    </ref>
    <ref id="btaa992-B23">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Thompson</surname><given-names>J.D.</given-names></string-name></person-group>  <etal>et al</etal> (<year>1999</year>) 
<article-title>BAliBASE: a benchmark alignment database for the evaluation of multiple alignment programs</article-title>. <source>Bioinformatics</source>, <volume>15</volume>, <fpage>87</fpage>–<lpage>88</lpage>.<pub-id pub-id-type="pmid">10068696</pub-id></mixed-citation>
    </ref>
    <ref id="btaa992-B24">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Van Dongen</surname><given-names>S.M.</given-names></string-name></person-group> (<year>2000</year>) Graph clustering by flow simulation. Ph.D. thesis, University of Utrecht.</mixed-citation>
    </ref>
    <ref id="btaa992-B25">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Von Dongen</surname><given-names>S.M.</given-names></string-name></person-group> (<year>2012</year>). 
<article-title>MCL manual</article-title>. <ext-link xlink:href="https://micans.org/mcl/man/mcl.html" ext-link-type="uri">https://micans.org/mcl/man/mcl.html</ext-link>.</mixed-citation>
    </ref>
    <ref id="btaa992-B26">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wheeler</surname><given-names>T.J.</given-names></string-name>, <string-name><surname>Kececioglu</surname><given-names>J.D.</given-names></string-name></person-group> (<year>2007</year>) 
<article-title>Multiple alignment by aligning alignments</article-title>. <source>Bioinformatics</source>, <volume>23</volume>, <fpage>i559</fpage>–<lpage>i568</lpage>.<pub-id pub-id-type="pmid">17646343</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
