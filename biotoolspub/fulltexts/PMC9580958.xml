<?DTDIdentifier.IdentifierValue -//NLM//DTD Journal Publishing DTD v2.3 20070202//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName journalpublishing.dtd?>
<?SourceDTD.Version 2.3?>
<?ConverterInfo.XSLTName nlm2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Front Bioinform</journal-id>
    <journal-id journal-id-type="iso-abbrev">Front Bioinform</journal-id>
    <journal-id journal-id-type="publisher-id">Front. Bioinform.</journal-id>
    <journal-title-group>
      <journal-title>Frontiers in Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="epub">2673-7647</issn>
    <publisher>
      <publisher-name>Frontiers Media S.A.</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">9580958</article-id>
    <article-id pub-id-type="publisher-id">1019597</article-id>
    <article-id pub-id-type="doi">10.3389/fbinf.2022.1019597</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Bioinformatics</subject>
        <subj-group>
          <subject>Original Research</subject>
        </subj-group>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>SETH predicts nuances of residue disorder from protein embeddings</article-title>
      <alt-title alt-title-type="left-running-head">Ilzhöfer et al.</alt-title>
      <alt-title alt-title-type="right-running-head">
        <ext-link xlink:href="https://doi.org/10.3389/fbinf.2022.1019597" ext-link-type="uri">10.3389/fbinf.2022.1019597</ext-link>
      </alt-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Ilzhöfer</surname>
          <given-names>Dagmar</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="fn1" ref-type="author-notes">
          <sup>†</sup>
        </xref>
        <uri xlink:href="https://loop.frontiersin.org/people/1684205/overview"/>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Heinzinger</surname>
          <given-names>Michael</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="aff2" ref-type="aff">
          <sup>2</sup>
        </xref>
        <xref rid="c001" ref-type="corresp">*</xref>
        <xref rid="fn1" ref-type="author-notes">
          <sup>†</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Rost</surname>
          <given-names>Burkhard</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="aff3" ref-type="aff">
          <sup>3</sup>
        </xref>
        <xref rid="aff4" ref-type="aff">
          <sup>4</sup>
        </xref>
        <uri xlink:href="https://loop.frontiersin.org/people/1121341/overview"/>
      </contrib>
    </contrib-group>
    <aff id="aff1"><sup>1</sup><institution>Faculty of Informatics</institution>, <institution>TUM (Technical University of Munich)</institution>, <addr-line>Munich</addr-line>, <country>Germany</country></aff>
    <aff id="aff2"><sup>2</sup><institution>Center of Doctoral Studies in Informatics and Its Applications (CeDoSIA)</institution>, <institution>TUM Graduate School</institution>, <addr-line>Garching</addr-line>, <country>Germany</country></aff>
    <aff id="aff3"><sup>3</sup><institution>Institute for Advanced Study (TUM-IAS)</institution>, <institution>TUM (Technical University of Munich)</institution>, <addr-line>Garching</addr-line>, <country>Germany</country></aff>
    <aff id="aff4"><sup>4</sup><institution>TUM School of Life Sciences Weihenstephan (WZW)</institution>, <institution>TUM (Technical University of Munich)</institution>, <addr-line>Freising</addr-line>, <country>Germany</country></aff>
    <author-notes>
      <fn fn-type="edited-by">
        <p><bold>Edited by:</bold><ext-link xlink:href="https://loop.frontiersin.org/people/1549774/overview" ext-link-type="uri">Rachel Kolodny</ext-link>, University of Haifa, Israel</p>
      </fn>
      <fn fn-type="edited-by">
        <p><bold>Reviewed by:</bold><ext-link xlink:href="https://loop.frontiersin.org/people/1112712/overview" ext-link-type="uri">Castrense Savojardo</ext-link>, University of Bologna, Italy</p>
        <p><ext-link xlink:href="https://loop.frontiersin.org/people/762749/overview" ext-link-type="uri">Jianzhao Gao</ext-link>, Nankai University, China</p>
      </fn>
      <corresp id="c001">*Correspondence: Michael Heinzinger, <email>mheinzinger@rostlab.org</email>
</corresp>
      <fn fn-type="equal" id="fn1">
        <label>
          <sup>†</sup>
        </label>
        <p>These authors have contributed equally to this work</p>
      </fn>
      <fn fn-type="other">
        <p>This article was submitted to Protein Bioinformatics, a section of the journal Frontiers in Bioinformatics</p>
      </fn>
    </author-notes>
    <pub-date pub-type="epub">
      <day>10</day>
      <month>10</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2022</year>
    </pub-date>
    <volume>2</volume>
    <elocation-id>1019597</elocation-id>
    <history>
      <date date-type="received">
        <day>15</day>
        <month>8</month>
        <year>2022</year>
      </date>
      <date date-type="accepted">
        <day>20</day>
        <month>9</month>
        <year>2022</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>Copyright © 2022 Ilzhöfer, Heinzinger and Rost.</copyright-statement>
      <copyright-year>2022</copyright-year>
      <copyright-holder>Ilzhöfer, Heinzinger and Rost</copyright-holder>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.</license-p>
      </license>
    </permissions>
    <abstract>
      <p>Predictions for millions of protein three-dimensional structures are only a few clicks away since the release of <italic>AlphaFold2</italic> results for UniProt. However, many proteins have so-called intrinsically disordered regions (IDRs) that do not adopt unique structures in isolation. These IDRs are associated with several diseases, including Alzheimer’s Disease. We showed that three recent disorder measures of <italic>AlphaFold2</italic> predictions (pLDDT, “experimentally resolved” prediction and “relative solvent accessibility”) correlated to some extent with IDRs. However, expert methods predict IDRs more reliably by combining complex machine learning models with expert-crafted input features and evolutionary information from multiple sequence alignments (MSAs). MSAs are not always available, especially for IDRs, and are computationally expensive to generate, limiting the scalability of the associated tools. Here, we present the novel method SETH that predicts residue disorder from embeddings generated by the protein Language Model ProtT5, which explicitly only uses single sequences as input. Thereby, our method, relying on a relatively shallow convolutional neural network, outperformed much more complex solutions while being much faster, allowing to create predictions for the human proteome in about 1 hour on a consumer-grade PC with one NVIDIA GeForce RTX 3060. Trained on a continuous disorder scale (CheZOD scores), our method captured subtle variations in disorder, thereby providing important information beyond the binary classification of most methods. High performance paired with speed revealed that SETH’s nuanced disorder predictions for entire proteomes capture aspects of the evolution of organisms. Additionally, SETH could also be used to filter out regions or proteins with probable low-quality <italic>AlphaFold2</italic> 3D structures to prioritize running the compute-intensive predictions for large data sets. SETH is freely publicly available at: <ext-link xlink:href="https://github.com/Rostlab/SETH" ext-link-type="uri">https://github.com/Rostlab/SETH</ext-link>.</p>
    </abstract>
    <kwd-group>
      <kwd>protein disorder</kwd>
      <kwd>residue disorder</kwd>
      <kwd>IDP</kwd>
      <kwd>IDR</kwd>
      <kwd>protein structure prediction</kwd>
      <kwd>
        <italic>AlphaFold2</italic>
      </kwd>
      <kwd>protein language model</kwd>
    </kwd-group>
  </article-meta>
</front>
<body>
  <sec id="s1">
    <title>Introduction</title>
    <sec id="s1-1">
      <title>IDRs crucial for life</title>
      <p>Protein sequence determines protein three-dimensional (3D) structure, which, in turn, determines protein function. While this dogma usually refers to proteins folding into well-defined 3D structures, other proteins do not adopt unique 3D structures in isolation. Instead, these so-called intrinsically disordered proteins [IDPs (<xref rid="B18" ref-type="bibr">Dunker et al., 2013</xref>)] with intrinsically disordered regions (IDRs) sample their accessible conformational space, thereby expanding their functional spectrum (<xref rid="B111" ref-type="bibr">Wright and Dyson, 1999</xref>; <xref rid="B77" ref-type="bibr">Radivojac et al., 2004</xref>; <xref rid="B99" ref-type="bibr">Tompa et al., 2005</xref>; <xref rid="B97" ref-type="bibr">Tompa et al., 2006</xref>; <xref rid="B98" ref-type="bibr">Tompa et al., 2008</xref>; <xref rid="B100" ref-type="bibr">Uversky et al., 2009</xref>; <xref rid="B90" ref-type="bibr">Schlessinger et al., 2011</xref>) and possibly providing mechanisms to cope with evolutionary challenges (<xref rid="B96" ref-type="bibr">Tantos et al., 2009</xref>; <xref rid="B103" ref-type="bibr">Vicedo et al., 2015a</xref>; <xref rid="B104" ref-type="bibr">Vicedo et al., 2015b</xref>). The difference between long IDRs and long loops (neither helix nor strand) can be reliably predicted from sequences (<xref rid="B88" ref-type="bibr">Schlessinger et al., 2007b</xref>). For very short regions, IDRs and loops are technically not distinguishable in a predictive sense. Therefore, IDRs have to be longer than some minimal length Lmin for identification. While the precise value for Lmin remains obscure, Lmin = 10 is clearly too short and Lmin = 30 is clearly sufficient, as may be many values in between (<xref rid="B90" ref-type="bibr">Schlessinger et al., 2011</xref>). Using the more conservative Lmin = 30, about 20–50% of all proteins in an organism are predicted to contain IDRs, with higher abundance in eukaryotes, especially in mammals (<xref rid="B83" ref-type="bibr">Romero et al., 1998</xref>; <xref rid="B49" ref-type="bibr">Liu et al., 2002</xref>; <xref rid="B90" ref-type="bibr">Schlessinger et al., 2011</xref>). Additionally, every fourth protein has been predicted as completely disordered (<xref rid="B20" ref-type="bibr">Dunker et al., 2008</xref>). This ubiquitous nature of disorder highlights its importance for the correct functioning of cells and makes the identification of IDRs crucial for understanding protein function. Alzheimer’s disease and Huntington’s disease, which are related to malfunctioning of disordered proteins/IDRs upon mutation, further underline this importance (<xref rid="B21" ref-type="bibr">Dyson and Wright, 2005</xref>; <xref rid="B20" ref-type="bibr">Dunker et al., 2008</xref>).</p>
    </sec>
    <sec id="s1-2">
      <title>CheZOD scores best characterize IDRs experimentally</title>
      <p>The experimental study of protein disorder remains difficult. X-ray crystallography is challenged by the lack of rigidity and nuclear magnetic resonance (NMR) remains limited to proteins shorter than average [∼450 residues (<xref rid="B35" ref-type="bibr">Howard, 1998</xref>; <xref rid="B65" ref-type="bibr">Oldfield et al., 2013</xref>; <xref rid="B63" ref-type="bibr">Nwanochie and Uversky, 2019</xref>)]. An additional complication is that upon binding to substrates, IDRs may appear ordered (<xref rid="B60" ref-type="bibr">Nielsen and Mulder, 2019</xref>). Arguably, today’s best experimental approach toward capturing IDRs are NMR-derived chemical shift Z-scores (CheZOD scores), despite the length-limitation (<xref rid="B60" ref-type="bibr">Nielsen and Mulder, 2019</xref>). In contrast to binary measures such as “missing X-Ray coordinates” (<xref rid="B83" ref-type="bibr">Romero et al., 1998</xref>), CheZOD scores provide a well-calibrated measure for the nuances of per-residue disorder. CheZOD scores are computed from the difference of chemical shift values obtained in NMR spectroscopy (<xref rid="B35" ref-type="bibr">Howard, 1998</xref>) and computed random coil chemical shift values (<xref rid="B61" ref-type="bibr">Nielsen and Mulder, 2020</xref>).</p>
    </sec>
    <sec id="s1-3">
      <title>Many prediction methods available</title>
      <p>The limited scalability of labor-intensive and expensive wet-lab experiments has spawned many computational tools predicting IDRs, including (from old to new): PONDR (<xref rid="B83" ref-type="bibr">Romero et al., 1998</xref>; <xref rid="B69" ref-type="bibr">Peng et al., 2005</xref>), NORSp (<xref rid="B49" ref-type="bibr">Liu et al., 2002</xref>), DISOPRED2 (<xref rid="B108" ref-type="bibr">Ward et al., 2004</xref>), IUPred (<xref rid="B17" ref-type="bibr">Dosztanyi et al., 2005</xref>), FoldIndex (<xref rid="B73" ref-type="bibr">Prilusky et al., 2005</xref>), RONN (<xref rid="B113" ref-type="bibr">Yang et al., 2005</xref>), PrDOS (<xref rid="B38" ref-type="bibr">Ishida and Kinoshita, 2007</xref>), NORSnet (<xref rid="B87" ref-type="bibr">Schlessinger et al., 2007a</xref>), PreDisorder (<xref rid="B15" ref-type="bibr">Deng et al., 2009</xref>), MetaDisorder-MD (<xref rid="B89" ref-type="bibr">Schlessinger et al., 2009</xref>), ESpritz (<xref rid="B106" ref-type="bibr">Walsh et al., 2012</xref>), MetaDisorder (<xref rid="B43" ref-type="bibr">Kozlowski and Bujnicki, 2012</xref>), AUCpreD (<xref rid="B107" ref-type="bibr">Wang et al., 2016</xref>), SPOT-Disorder (<xref rid="B29" ref-type="bibr">Hanson et al., 2016</xref>), SPOT-Disorder-Single (<xref rid="B28" ref-type="bibr">Hanson et al., 2018</xref>), SPOT-Disorder2 (<xref rid="B27" ref-type="bibr">Hanson et al., 2019</xref>), rawMSA (<xref rid="B53" ref-type="bibr">Mirabello and Wallner, 2019</xref>), ODiNPred (<xref rid="B14" ref-type="bibr">Dass et al., 2020</xref>) and flDPnn (<xref rid="B36" ref-type="bibr">Hu et al., 2021</xref>). As for almost every phenotype since the introduction of the combination of machine learning and evolutionary information (EI), derived from multiple sequence alignments [MSAs (<xref rid="B85" ref-type="bibr">Rost and Sander, 1993</xref>)], MSA-based predictions out-performed methods not using MSAs (<xref rid="B60" ref-type="bibr">Nielsen and Mulder, 2019</xref>; <xref rid="B14" ref-type="bibr">Dass et al., 2020</xref>). However, using MSAs slows down inference and performs worse for proteins in small families. This complicates the prediction of IDRs, which are inherently difficult to align due to, e.g., reduced sequence conservation in comparison to structured regions (<xref rid="B76" ref-type="bibr">Radivojac et al., 2002</xref>; <xref rid="B44" ref-type="bibr">Lange et al., 2016</xref>).</p>
      <p>Besides these methods directly predicting disorder, <italic>AlphaFold2</italic> (<xref rid="B41" ref-type="bibr">Jumper et al., 2021</xref>), Nature’s method of the year 2021 (<xref rid="B52" ref-type="bibr">Marx, 2022</xref>), which provided a leap in the quality of protein structure predictions from MSAs and increases the width of structural coverage (<xref rid="B7" ref-type="bibr">Bordin et al., 2022</xref>), also provides measures indicative of IDRs. One of these, the pLDDT (predicted local distance difference test), estimates the performance of <italic>AlphaFold2</italic> depending on prediction strength, i.e., it measures prediction reliability as introduced for secondary structure prediction (<xref rid="B85" ref-type="bibr">Rost and Sander, 1993</xref>). However, instead of measuring it from the class output, <italic>AlphaFold2</italic> uses different objective functions and predicts its own reliability. The pLDDT distinguishes formidably well between trustworthy and less reliable predictions (<xref rid="B41" ref-type="bibr">Jumper et al., 2021</xref>). Additionally, low values for pLDDT have been suggested to predict IDRs rather accurately (<xref rid="B1" ref-type="bibr">Akdel et al., 2021</xref>; <xref rid="B109" ref-type="bibr">Wilson et al., 2021</xref>; <xref rid="B72" ref-type="bibr">Piovesan et al., 2022</xref>) or to predict non-existing proteins (<xref rid="B58" ref-type="bibr">Monzon et al., 2022</xref>). Furthermore, the “experimentally resolved” prediction of <italic>AlphaFold2</italic> should also contain information on disorder, since missing coordinates in experimentally recorded structures were an established definition of disorder (<xref rid="B19" ref-type="bibr">Dunker et al., 1998</xref>; <xref rid="B57" ref-type="bibr">Monastyrskyy et al., 2014</xref>). Lastly, the relative solvent accessible surface area of a residue [RSA (<xref rid="B12" ref-type="bibr">Connolly, 1983</xref>; <xref rid="B84" ref-type="bibr">Rost and Sander, 1994</xref>)] and its window average, calculated for <italic>AlphaFold2</italic> structure predictions, were also reported to be disorder predictors (<xref rid="B1" ref-type="bibr">Akdel et al., 2021</xref>; <xref rid="B72" ref-type="bibr">Piovesan et al., 2022</xref>; <xref rid="B80" ref-type="bibr">Redl et al., 2022</xref>).</p>
      <p>Here, we bypassed the problem of generating MSAs for IDRs, by using embeddings from pre-trained protein language models (pLMs). Inspired by recent leaps in Natural Language Processing (NLP), pLMs learn to predict masked amino acids (tokens) given their surrounding protein sequence (<xref rid="B3" ref-type="bibr">Asgari and Mofrad, 2015</xref>; <xref rid="B2" ref-type="bibr">Alley et al., 2019</xref>; <xref rid="B5" ref-type="bibr">Bepler and Berger, 2019</xref>; <xref rid="B31" ref-type="bibr">Heinzinger et al., 2019</xref>; <xref rid="B6" ref-type="bibr">Bepler and Berger, 2021</xref>; <xref rid="B23" ref-type="bibr">Elnaggar et al., 2021</xref>; <xref rid="B64" ref-type="bibr">Ofer et al., 2021</xref>; <xref rid="B82" ref-type="bibr">Rives et al., 2021</xref>; <xref rid="B112" ref-type="bibr">Wu et al., 2021</xref>). Toward this end, amino acids correspond to words/tokens in NLP, while sentences correspond to full-length proteins in most current pLMs. As no information other than the amino acid sequence is required at any stage (self-supervised learning), pLMs efficiently leverage large but unlabeled databases with billions of protein sequences, such as BFD with more than two billion sequences (<xref rid="B92" ref-type="bibr">Steinegger et al., 2019</xref>). The information learned by the pLM during so-called (pre-) training can be retrieved and transferred afterwards (transfer learning), by encoding a protein sequence in vector representations (embeddings). In their simplest form, embeddings mirror the last “hidden” states/values of pLMs. In analogy to NLPs implicitly learning grammar, embeddings from pLMs capture some aspects of the language of life as written in protein sequences (<xref rid="B2" ref-type="bibr">Alley et al., 2019</xref>; <xref rid="B31" ref-type="bibr">Heinzinger et al., 2019</xref>; <xref rid="B64" ref-type="bibr">Ofer et al., 2021</xref>; <xref rid="B82" ref-type="bibr">Rives et al., 2021</xref>), which suffices as exclusive input to many methods predicting aspects of protein structure and function (<xref rid="B3" ref-type="bibr">Asgari and Mofrad, 2015</xref>; <xref rid="B2" ref-type="bibr">Alley et al., 2019</xref>; <xref rid="B31" ref-type="bibr">Heinzinger et al., 2019</xref>; <xref rid="B46" ref-type="bibr">Littmann et al., 2021a</xref>; <xref rid="B47" ref-type="bibr">Littmann et al., 2021b</xref>; <xref rid="B48" ref-type="bibr">Littmann et al., 2021c</xref>; <xref rid="B23" ref-type="bibr">Elnaggar et al., 2021</xref>; <xref rid="B32" ref-type="bibr">Heinzinger et al., 2021</xref>; <xref rid="B51" ref-type="bibr">Marquet et al., 2021</xref>; <xref rid="B82" ref-type="bibr">Rives et al., 2021</xref>).</p>
      <p>First, we compared to which extent embeddings from five pLMs [ESM-1b (<xref rid="B82" ref-type="bibr">Rives et al., 2021</xref>), ProtBERT (<xref rid="B23" ref-type="bibr">Elnaggar et al., 2021</xref>), SeqVec (<xref rid="B31" ref-type="bibr">Heinzinger et al., 2019</xref>), ProtT5 (<xref rid="B23" ref-type="bibr">Elnaggar et al., 2021</xref>) and ProSE (<xref rid="B6" ref-type="bibr">Bepler and Berger, 2021</xref>)] could predict the degree of disorder of a residue as defined by CheZOD scores. Toward that end, we fit a minimal machine learning model (linear regression) on each of the five pLM embeddings. No pLM was fine-tuned in any way. The best performing embeddings served as input to partly a little more complex models, namely a logistic regression (LogReg), another linear regression (LinReg; trained on the full training set, as opposed to the linear regression used to compare pLMs, which was only trained on 90% of the training set), a two-layer neural network (ANN), and a two-layer convolutional neural network (CNN; dubbed SETH (<bold>S</bold>elf-supervised <bold>E</bold>mbeddings predic<bold>T</bold> chemical s<bold>H</bold>ift Z-scores)). By training regression and classification models, we also investigated the benefit of training on nuanced CheZOD scores compared to binary disorder classification. The combination of using a rather simplistic model and embeddings from single protein sequences enabled the final method SETH to predict disorder for the entire Swiss-Prot with over 566,000 proteins (<xref rid="B4" ref-type="bibr">The UniProt Consortium et al., 2021</xref>) in approximately 7 h on a machine with one RTX A6000 GPU with 48 GB vRAM.</p>
      <p>Since recent work showed that <italic>AlphaFold2’</italic>s (smoothed) pLDDT and (smoothed) RSA can be used to predict disorder (<xref rid="B1" ref-type="bibr">Akdel et al., 2021</xref>; <xref rid="B109" ref-type="bibr">Wilson et al., 2021</xref>; <xref rid="B72" ref-type="bibr">Piovesan et al., 2022</xref>; <xref rid="B80" ref-type="bibr">Redl et al., 2022</xref>), we tested <italic>AlphaFold2</italic> on CheZOD scores (following the advice of John Jumper, we also analyzed “experimentally resolved” predictions). Furthermore, we investigated the agreement between the disorder predictions of our best method and the pLDDT for 17 organisms, to establish SETH as a speed-up pre-filter for <italic>AlphaFold2</italic>. Lastly, we visually analyzed whether the predicted disorder spectrum carried any information about the evolution of 37 organisms.</p>
    </sec>
  </sec>
  <sec sec-type="methods" id="s2">
    <title>Methods</title>
    <sec id="s2-1">
      <title>Data sets</title>
      <sec id="s2-1-1">
        <title>CheZOD scores</title>
        <p>To streamline comparability to existing methods, we used two datasets available from ODiNPred (<xref rid="B14" ref-type="bibr">Dass et al., 2020</xref>) for training (file name CheZOD1325 in GitHub; 1,325 proteins) and testing (file name CheZOD in GitHub; 117 proteins). Each dataset contains protein sequences and CheZOD scores for each residue. The CheZOD score measures the degree of disorder of the residue and is calculated from the difference between chemical shift values obtained by NMR spectroscopy (<xref rid="B35" ref-type="bibr">Howard, 1998</xref>) and computed random coil chemical shifts (<xref rid="B61" ref-type="bibr">Nielsen and Mulder, 2020</xref>). These differences vary considerably between ordered and disordered residues, thereby continuously measuring the nuances of order/disorder for each residue (<xref rid="B61" ref-type="bibr">Nielsen and Mulder, 2020</xref>).</p>
      </sec>
      <sec id="s2-1-2">
        <title>Redundancy reduction (CheZOD1174 and CheZOD117)</title>
        <p>To avoid overestimating performance through pairs of proteins with too similar sequences between training and testing sets, we constructed non-redundant subsets. Firstly, we built profiles (position specific scoring matrices; PSSMs) from multiple sequence alignments (MSAs) for proteins in the test set, obtained through three iterations with <italic>MMSeqs2</italic> [(<xref rid="B94" ref-type="bibr">Steinegger and Söding, 2017</xref>); using default parameters, except for “--num-iterations 3”, an established number of iterations, also applied in ColabFold (<xref rid="B54" ref-type="bibr">Mirdita et al., 2022</xref>) and enabling sensitive but still fast sequence searches (<xref rid="B94" ref-type="bibr">Steinegger and Söding, 2017</xref>)] against proteins in the training set. Next, any protein in the training set with &gt;20% PIDE (percentage pairwise sequence identity) to any test set profile using bi-directional coverage [with default coverage threshold of 80%, focusing on joining proteins with similar domain composition (<xref rid="B30" ref-type="bibr">Hauser et al., 2016</xref>)] was removed using <italic>MMSeqs2</italic> high-sensitivity (--s 7.5) search. The value PIDE&lt;20% was, for simplicity, concluded from an earlier analysis of the reach of homology-based inference for the structural similarity of protein pairs (<xref rid="B86" ref-type="bibr">Rost, 1999</xref>). The training set had been constructed such that all protein pairs had &lt;50% PIDE (<xref rid="B14" ref-type="bibr">Dass et al., 2020</xref>), and we did not reduce the redundancy within the training set any further. Secondly, we removed all residues without valid CheZOD scores [indicated by CheZOD scores≥900; for all models apart from SETH, they were removed after embedding generation, while for SETH (CNN) they were removed before, to enable undisturbed passing of information from neighboring residues]. The resulting training set (dubbed <italic>CheZOD1174</italic>) contained 1,174 proteins with a total of 132,545 residues (at an average length of 113 residues, these proteins were about 3–4 times shorter than most existing proteins). The resulting dataset for testing (dubbed <italic>CheZOD117</italic>) contained 117 sequences with a total of 13,069 residues (average length 112). Consequently, we did not alter the test set published alongside ODiNPred, which has been used to evaluate 26 disorder prediction methods (<xref rid="B60" ref-type="bibr">Nielsen and Mulder, 2019</xref>), enabling a direct comparison of the results. However, we altered the training data published and used for ODiNPred, to reduce the overlap between training and testing.</p>
      </sec>
      <sec id="s2-1-3">
        <title>Dataset distributions</title>
        <p>After preparing the data, we analyzed the distributions of the CheZOD scores for both <italic>CheZOD117</italic> and <italic>CheZOD1174</italic> (<xref rid="s11" ref-type="sec">Supplementary Figure S1</xref>). The CheZOD scores in these sets ranged from -5.6 to 16.2. Nielsen and Mulder had previously established a threshold of eight to differentiate between disorder (CheZOD score≤8) and order (CheZOD score&gt;8) (<xref rid="B62" ref-type="bibr">Nielsen and Mulder, 2016</xref>). In both sets, the CheZOD score distributions were bimodal, but while there was an over-representation of ordered residues in the training set <italic>CheZOD1174</italic> (72% ordered), disordered residues were most prevalent in the test set <italic>CheZOD117</italic> (31% ordered). As artificial intelligence (AI) always optimizes for similar distributions in train and test, the train-test set discrepancy provided an additional safeguard against over-estimating performance.</p>
      </sec>
    </sec>
    <sec id="s2-2">
      <title>Input embeddings</title>
      <sec id="s2-2-1">
        <title>Five pLMs</title>
        <p>Protein sequences from both sets (<italic>CheZOD117</italic>, <italic>CheZOD1174</italic>) were encoded as distributed vector representations (embeddings) using five pLMs: 1) SeqVec (<xref rid="B31" ref-type="bibr">Heinzinger et al., 2019</xref>), based on the NLP algorithm ELMo (<xref rid="B71" ref-type="bibr">Peters et al., 2018</xref>), is a stack of bi-directional long short-term memory cells (LSTM (<xref rid="B33" ref-type="bibr">Hochreiter and Schmidhuber, 1997</xref>)) trained on a 50% non-redundant version of UniProt (<xref rid="B4" ref-type="bibr">The UniProt Consortium et al., 2021</xref>) [UniRef50 (<xref rid="B95" ref-type="bibr">Suzek et al., 2015</xref>)]. 2) ProtBERT (<xref rid="B23" ref-type="bibr">Elnaggar et al., 2021</xref>), based on the NLP algorithm BERT (<xref rid="B16" ref-type="bibr">Devlin et al., 2018</xref>), trained on BFD, the Big Fantastic Database (<xref rid="B93" ref-type="bibr">Steinegger and Söding, 2018</xref>; <xref rid="B92" ref-type="bibr">Steinegger et al., 2019</xref>), with over 2.1 billion protein sequences. 3) ESM-1b (<xref rid="B82" ref-type="bibr">Rives et al., 2021</xref>), conceptually similar to (Prot)BERT (both use a stack of Transformer encoder modules (<xref rid="B102" ref-type="bibr">Vaswani et al., 2017</xref>)), but trained on UniRef50. 4) ProtT5-XL-U50 (<xref rid="B23" ref-type="bibr">Elnaggar et al., 2021</xref>) (dubbed ProtT5 for simplicity), based on the NLP sequence-to-sequence model T5 (Transformer encoder-decoder architecture) (<xref rid="B78" ref-type="bibr">Raffel et al., 2020</xref>), trained on BFD and fine-tuned on Uniref50. 5) ProSE (<xref rid="B6" ref-type="bibr">Bepler and Berger, 2021</xref>), consisting of LSTMs trained on 76M unlabeled protein sequences in UniRef90 and additionally on predicting intra-residue contacts and structural similarity from 28k SCOPe proteins (<xref rid="B24" ref-type="bibr">Fox et al., 2014</xref>). While ProtBERT and ESM-1b were trained on reconstructing corrupted tokens/amino acids from non-corrupted (protein) sequence context (i.e., masked language modeling), ProtT5 was trained by teacher forcing, i.e., input and targets were fed to the model, with inputs being corrupted protein sequences and targets being identical to the inputs but shifted to the right (span generation with span size of one for ProtT5). In contrast, SeqVec was trained on predicting the next amino acid, given all previous amino acids in the protein sequence (referred to as auto-regressive pre-training). All pLMs, except for ProSE, were optimized only through self-supervised learning, i.e., exclusively using unlabeled sequences for pre-training. In contrast, ProSE was trained on three tasks simultaneously (multi-task learning), i.e., masked language modeling was used to train on 76M unlabeled sequences in UniRef90 and training to predict residue-residue contacts together with structural similarity was performed using 28k labeled protein sequences from SCOPe (<xref rid="B24" ref-type="bibr">Fox et al., 2014</xref>).</p>
      </sec>
      <sec id="s2-2-2">
        <title>Embeddings: Last hidden layer</title>
        <p>Embeddings were extracted from the last hidden layer of the pLMs, with ProtT5 per-residue embeddings being derived from the last attention layer of the model’s encoder-side using half-precision. The <italic>bio_embeddings</italic> package was used to generate the embeddings (<xref rid="B13" ref-type="bibr">Dallago et al., 2021</xref>). The resulting output is a single vector for each input residue, yielding an LxN-dimensional matrix (L: protein length, N: embedding dimension; <italic>N</italic> = 1,024 for SeqVec/ProtBERT/ProtT5; <italic>N</italic> = 1,280 for ESM-1b; <italic>N</italic> = 6,165 for ProSE).</p>
      </sec>
      <sec id="s2-2-3">
        <title>Choosing embeddings best suited for IDR prediction</title>
        <p>To find the most informative pLM embeddings for predicting IDRs/CheZOD score residue disorder, we randomly chose 90% of the proteins in <italic>CheZOD1174</italic> and trained a linear regression model on each of the five pLM embeddings to predict continuous CheZOD scores. To simplify the comparison and “triangulation” of our results, we also compared these five embedding-based models to inputting the standard one-hot encodings (i.e., 20 instead of 1,024/1280/6,165 input units per residue). One-hot encodings represent each residue/sequence position by a 20-dimensional vector, for the 20 standard amino acids essentially contained in all proteins. Each position in the vector corresponds to one amino acid, i.e., the elements of the vector are binary: one for the position in the vector corresponding to the encoded amino acid, zero otherwise. The special case “X” (unknown amino acid) was encoded in a 20-dimensional vector containing only 0s. The linear regressions were implemented with the <italic>LinearRegression</italic> module of scikit-learn (<xref rid="B68" ref-type="bibr">Pedregosa et al., 2011</xref>) with all parameters left at default values. We evaluated the models on the remaining 10% of <italic>CheZOD1174</italic> using the Spearman correlation coefficient (ρ; <xref rid="e2" ref-type="disp-formula">Eq. 2</xref>) and the AUC (area under the receiver operating characteristic curve; <xref rid="e3" ref-type="disp-formula">Eq. 3</xref>; see Methods <italic>Evaluation</italic>).</p>
      </sec>
      <sec id="s2-2-4">
        <title>Unsupervised embedding analysis</title>
        <p>Lastly, we analyzed the ProtT5 embeddings of <italic>CheZOD117</italic> in more detail by creating a t-distributed stochastic neighbor embedding [t-SNE (<xref rid="B101" ref-type="bibr">van der Maaten and Hinton, 2008</xref>)] using scikit-learn (<xref rid="B68" ref-type="bibr">Pedregosa et al., 2011</xref>). PCA (principle component analysis (<xref rid="B110" ref-type="bibr">Wold et al., 1987</xref>)) initialized the t-SNE to enable higher reliability of the resulting structure (<xref rid="B42" ref-type="bibr">Kobak and Berens, 2019</xref>). Furthermore, following a rule of thumb previously established (<xref rid="B42" ref-type="bibr">Kobak and Berens, 2019</xref>), the perplexity was chosen at the high value of 130 (1% of the sample size) to emphasize the global data structure (<xref rid="B42" ref-type="bibr">Kobak and Berens, 2019</xref>) in order to identify putative clusters of order or disorder (defaults for all other parameters).</p>
      </sec>
    </sec>
    <sec id="s2-3">
      <title>New disorder prediction methods</title>
      <p>We optimized four models to predict disorder: 1) linear regression (dubbed LinReg), 2) multi-layer artificial neural network (dubbed ANN), 3) two-layer CNN (dubbed SETH) and 4) logistic regression (dubbed LogReg). The models used throughout this work were deliberately kept simple to gain speed and avoid over-fitting. Three of our models were trained on regression (LinReg, ANN and SETH), while LogReg was trained on discriminating disordered from ordered residues (binary classification: disorder: CheZOD score≤8, order: CheZOD score&gt;8 (<xref rid="B62" ref-type="bibr">Nielsen and Mulder, 2016</xref>)).</p>
      <p>SETH was implemented in PyTorch (<xref rid="B67" ref-type="bibr">Paszke et al., 2019</xref>) using <italic>Conv2d</italic> for the convolutional layers, MSELoss as loss function and Adam as optimizer (learning rate of 0.001), activating amsgrad (<xref rid="B79" ref-type="bibr">Reddi et al., 2018</xref>). Additionally, we padded to receive one output per residue and set all random seeds to 42 for reproducibility. Lastly, we randomly split <italic>CheZOD1174</italic> into training (90% of proteins: optimize weights) and validation (10%: for early-stopping after 10 epochs without improvement, hyper-parameter optimization: of the best performing models, we chose that with the most constraints (<xref rid="s11" ref-type="sec">Supplementary Figure S3</xref>, red bar), resulting in a kernel size of (5,1), 28 output channels of the first convolutional layer, the activation function Tanh between the two convolutional layers and the weight decay parameter of 0.001 in the optimizer). Details for LinReg, ANN and LogReg are in <xref rid="s11" ref-type="sec">Supplementary Material S1.1</xref> and <xref rid="s11" ref-type="sec">Supplementary Figure S2</xref>.</p>
    </sec>
    <sec id="s2-4">
      <title>
AlphaFold2
</title>
      <p><italic>AlphaFold2</italic> (<xref rid="B41" ref-type="bibr">Jumper et al., 2021</xref>) predicts a reliability for each residue prediction, namely, the pLDDT. This score and its running average over a window of consecutive residues have been claimed to predict disorder (<xref rid="B1" ref-type="bibr">Akdel et al., 2021</xref>; <xref rid="B109" ref-type="bibr">Wilson et al., 2021</xref>; <xref rid="B72" ref-type="bibr">Piovesan et al., 2022</xref>; <xref rid="B80" ref-type="bibr">Redl et al., 2022</xref>). Another objective function predicted by AlphaFold2, namely, the “experimentally resolved” prediction (<xref rid="B41" ref-type="bibr">Jumper et al., 2021</xref>) is likely also informative, as missing coordinates in experimental structures have been used to define disorder (<xref rid="B19" ref-type="bibr">Dunker et al., 1998</xref>; <xref rid="B57" ref-type="bibr">Monastyrskyy et al., 2014</xref>). To analyze these <italic>AlphaFold2</italic> predictions against CheZOD scores, we applied <italic>ColabFold</italic> (<xref rid="B54" ref-type="bibr">Mirdita et al., 2022</xref>) to predict 3D structures for all proteins in <italic>CheZOD117</italic>. <italic>ColabFold</italic> speeds up <italic>AlphaFold2</italic> predictions 40-60x mostly by replacing jackhmmer (<xref rid="B39" ref-type="bibr">Johnson et al., 2010</xref>) and HHblits (<xref rid="B81" ref-type="bibr">Remmert et al., 2012</xref>) in the computationally expensive MSA generation by <italic>MMSeqs2</italic> (<xref rid="B94" ref-type="bibr">Steinegger and Söding, 2017</xref>) without losing much in performance. We generated MSAs by searching UniClust30 (<xref rid="B55" ref-type="bibr">Mirdita et al., 2017</xref>) and the environment database ColabFoldDB (<xref rid="B54" ref-type="bibr">Mirdita et al., 2022</xref>). We used neither templates nor Amber force-field relaxation (<xref rid="B34" ref-type="bibr">Hornak et al., 2006</xref>), as those do not significantly improve performance (<xref rid="B41" ref-type="bibr">Jumper et al., 2021</xref>; <xref rid="B54" ref-type="bibr">Mirdita et al., 2022</xref>) although increasing runtime manifold (especially the Amber relaxation). As <italic>ColabFold</italic> currently does not support outputting the “experimentally resolved” head, we added this feature by averaging over the sigmoid of the raw “experimentally resolved” logits output of <italic>AlphaFold2</italic> for each atom in a residue. After having generated the pLDDT values and the “experimentally resolved” predictions, we additionally calculated the smoothed pLDDT for each residue, using a sliding window of 21 consecutive residues following previous findings (<xref rid="B1" ref-type="bibr">Akdel et al., 2021</xref>). While sliding the window over the sequence, the center residue of the window was always assigned the mean of all values within the window (instead of padding, windows closer than 10 residues to the N- and C-terminus were shrunk asymmetrically, e.g., for the N-terminal position i (i = 1,…,10, starting at i = 1 at the N-terminus): averaging over (i-1) positions left of i).</p>
      <p>It has also been reported that the window-averaged RSA calculated from AlphaFold2’s 3D predictions correlates with IDRs (<xref rid="B1" ref-type="bibr">Akdel et al., 2021</xref>; <xref rid="B72" ref-type="bibr">Piovesan et al., 2022</xref>; <xref rid="B80" ref-type="bibr">Redl et al., 2022</xref>). Consequently, we also added this measure to our evaluation. With the pipeline provided alongside one of the analyses reporting the RSA as a disorder predictor (<xref rid="B72" ref-type="bibr">Piovesan et al., 2022</xref>), we calculated the RSA for the residues of the <italic>CheZOD117</italic> set, leaving all parameters at default. Then we smoothed the RSA by averaging over 25 consecutive residues as suggested elsewhere (<xref rid="B72" ref-type="bibr">Piovesan et al., 2022</xref>). While the use of the “experimentally resolved” predictions is new here (thanks to John Jumper for the recommendation), all other ways of processing <italic>AlphaFold2</italic> predictions to predict disorder were taken from other work.</p>
    </sec>
    <sec id="s2-5">
      <title>Evaluation</title>
      <p>We followed a previous analysis in evaluating our performance (same evaluation measures and test set) for easy comparability (<xref rid="B60" ref-type="bibr">Nielsen and Mulder, 2019</xref>). This allowed a direct comparison to (alphabetical list): AUCPred with and without evolution (<xref rid="B107" ref-type="bibr">Wang et al., 2016</xref>), DisEMBL (<xref rid="B45" ref-type="bibr">Linding et al., 2003</xref>), DISOPRED2 (<xref rid="B108" ref-type="bibr">Ward et al., 2004</xref>), DISOPRED3 (<xref rid="B40" ref-type="bibr">Jones and Cozzetto, 2015</xref>), DISpro (<xref rid="B10" ref-type="bibr">Cheng et al., 2005</xref>), DynaMine (<xref rid="B11" ref-type="bibr">Cilia et al., 2014</xref>), DISPROT/VSL2b (<xref rid="B105" ref-type="bibr">Vucetic et al., 2005</xref>), ESpritz (<xref rid="B106" ref-type="bibr">Walsh et al., 2012</xref>), GlobPlot (<xref rid="B45" ref-type="bibr">Linding et al., 2003</xref>), IUPred (<xref rid="B17" ref-type="bibr">Dosztanyi et al., 2005</xref>), MetaDisorder (<xref rid="B43" ref-type="bibr">Kozlowski and Bujnicki, 2012</xref>), MFDp2 (<xref rid="B56" ref-type="bibr">Mizianty et al., 2013</xref>), PrDOS (<xref rid="B38" ref-type="bibr">Ishida and Kinoshita, 2007</xref>), RONN (<xref rid="B113" ref-type="bibr">Yang et al., 2005</xref>), s2D (<xref rid="B91" ref-type="bibr">Sormanni et al., 2015</xref>), SPOT-Disorder (<xref rid="B29" ref-type="bibr">Hanson et al., 2016</xref>). We added results for flDPnn (<xref rid="B36" ref-type="bibr">Hu et al., 2021</xref>) and ODiNPred (<xref rid="B14" ref-type="bibr">Dass et al., 2020</xref>) using the publicly available web-servers. SPOT-Disorder2 (<xref rid="B27" ref-type="bibr">Hanson et al., 2019</xref>) predictions were custom-generated by the program’s developers for all but one protein in test set CheZOD117 (10010: failed run).</p>
      <p>We estimated the Spearman correlation, ρ, and its 95% confidence interval (CI) over <italic>n</italic> = 1,000 bootstrap sets in all cases (<xref rid="B22" ref-type="bibr">Efron and Tibshirani, 1991</xref>). For each bootstrap set, a random sample of the size of the test set (=m) was drawn with replacement from the test set. For each of these sampled sets, the ρ was calculated. If u<sub>i</sub> is the rank of the <italic>i</italic>th value in the ground truth CheZOD scores and v<sub>i</sub> the rank of the <italic>i</italic>th value in the predicted CheZOD scores (or the rank of the respective predictive values for LogReg and <italic>AlphaFold2</italic>) of the method, the ρ was calculated with <xref rid="e1" ref-type="disp-formula">Eq. (1)</xref>. The final ρ was derived from averaging over those 1,000 values and the 95% CI was estimated by computing the standard deviation of the ρ over the sampled sets and multiplying it by 1.96. The standard deviation was calculated with <xref rid="e2" ref-type="disp-formula">Eq. 2</xref>, where x<sub>i</sub> is the ρ of an individual bootstrap set and ⟨x⟩ is the average ρ over all bootstrap sets.<disp-formula id="e1"><mml:math id="m1" overflow="scroll"><mml:mrow><mml:mi>ρ</mml:mi><mml:mtext> </mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>S</mml:mi><mml:mi>p</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mtext> </mml:mtext><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>l</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:munderover><mml:mstyle displaystyle="true"><mml:mo>∑</mml:mo></mml:mstyle><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>m</mml:mi></mml:munderover><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:munderover><mml:mstyle displaystyle="true"><mml:mo>∑</mml:mo></mml:mstyle><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>m</mml:mi></mml:munderover><mml:msub><mml:mi>u</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>*</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>v</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:munderover><mml:mstyle displaystyle="true"><mml:mo>∑</mml:mo></mml:mstyle><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>m</mml:mi></mml:munderover><mml:msub><mml:mi>v</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:msqrt><mml:mrow><mml:mrow><mml:munderover><mml:mstyle displaystyle="true"><mml:mo>∑</mml:mo></mml:mstyle><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>m</mml:mi></mml:munderover><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:munderover><mml:mstyle displaystyle="true"><mml:mo>∑</mml:mo></mml:mstyle><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>m</mml:mi></mml:munderover><mml:msub><mml:mi>u</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mo>*</mml:mo><mml:mrow><mml:munderover><mml:mstyle displaystyle="true"><mml:mo>∑</mml:mo></mml:mstyle><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>m</mml:mi></mml:munderover><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>v</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:munderover><mml:mstyle displaystyle="true"><mml:mo>∑</mml:mo></mml:mstyle><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>m</mml:mi></mml:munderover><mml:msub><mml:mi>v</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mrow></mml:msqrt></mml:mfrac></mml:mrow></mml:math><label>(1)</label></disp-formula>
<disp-formula id="e2"><mml:math id="m2" overflow="scroll"><mml:mrow><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">d</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">d</mml:mi><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">d</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">v</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mo>=</mml:mo><mml:msqrt><mml:mfrac><mml:mrow><mml:munderover><mml:mstyle displaystyle="true"><mml:mo>∑</mml:mo></mml:mstyle><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mrow><mml:mo>〈</mml:mo><mml:mi>x</mml:mi><mml:mo>〉</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mi>n</mml:mi></mml:mfrac></mml:msqrt></mml:mrow></mml:math><label>(2)</label></disp-formula>
</p>
      <p>Furthermore, the AUC and its 95% CI were estimated for each model evaluated here, again, by applying the same bootstrapping procedure. As the AUC requires binarized ground truth class labels, continuous CheZOD scores were binarized using the threshold of eight (disorder CheZOD score≤8 and order CheZOD score&gt;8 (<xref rid="B62" ref-type="bibr">Nielsen and Mulder, 2016</xref>)) for the calculation of the AUC (<xref rid="e3" ref-type="disp-formula">Eq. (3)</xref>; scikit-learn implementation). In <xref rid="e3" ref-type="disp-formula">Eq. 3</xref>, I[.] is the indicator function, m<sup>+/-</sup> are the number of ordered/disordered samples in the test set (classifying the samples according to the ground truth class label) and y<sub>i</sub>
<sup>+/-</sup> is the <italic>i</italic>th predicted value in the ordered/disordered samples.<disp-formula id="e3"><mml:math id="m3" overflow="scroll"><mml:mrow><mml:mi mathvariant="normal">A</mml:mi><mml:mi mathvariant="normal">U</mml:mi><mml:mi mathvariant="normal">C</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:munderover><mml:mstyle displaystyle="true"><mml:mo>∑</mml:mo></mml:mstyle><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:msup><mml:mi>m</mml:mi><mml:mo>−</mml:mo></mml:msup></mml:munderover><mml:mrow><mml:munderover><mml:mstyle displaystyle="true"><mml:mo>∑</mml:mo></mml:mstyle><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:msup><mml:mi>m</mml:mi><mml:mo>+</mml:mo></mml:msup></mml:munderover><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>I</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msubsup><mml:mi>y</mml:mi><mml:mi>i</mml:mi><mml:mo>+</mml:mo></mml:msubsup><mml:mo>&gt;</mml:mo><mml:msubsup><mml:mi>y</mml:mi><mml:mi>j</mml:mi><mml:mo>−</mml:mo></mml:msubsup></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:msup><mml:mi>m</mml:mi><mml:mo>+</mml:mo></mml:msup><mml:mo>*</mml:mo><mml:msup><mml:mi>m</mml:mi><mml:mo>−</mml:mo></mml:msup></mml:mrow></mml:mfrac></mml:mrow></mml:math><label>(3)</label></disp-formula>
</p>
      <p>Lastly, we plotted the receiver operating characteristic curve for our models (SETH, LinReg/LinReg1D, ANN and LogReg), as well as for <italic>AlphaFold2</italic>’s pLDDT (<xref rid="s11" ref-type="sec">Supplementary Figure S5</xref>).</p>
    </sec>
    <sec id="s2-6">
      <title>Additional tests</title>
      <sec id="s2-6-1">
        <title>Runtime</title>
        <p>We analyzed the runtime for the best method introduced here (SETH), by clocking the predictions for the human proteome (20,352 proteins) and the Swiss-Prot database [566,969 proteins (<xref rid="B4" ref-type="bibr">The UniProt Consortium et al., 2021</xref>)]. This evaluation was performed on a machine with two AMD EPYC™ ROME 7352 CPUs at 2.30 GHz each with 24/48 cores, a 256 GB RAM (16 × 16 GB) DDR4-3200 MHz ECC, one RTX A6000 GPU with 48GB RAM, a 278 GB SSD scratch disk and a 7.3 TB HDD. However, the final model constituting SETH can also easily be deployed on any machine holding a GPU with ≥8 GB RAM at some cost in speed, allowing to run SETH, e.g., in <italic>Google Colab</italic>. To reflect this, we also benchmarked the speed for running the entire human proteome on a smaller GPU (single NVIDIA GeForce RTX 3060 with 12 GB vRAM). Lastly, we benchmarked the speed on our test set <italic>CheZOD117</italic> on an AMD Ryzen 5 5500U CPU, to reflect that SETH can even efficiently be run without a GPU for small sets. All values for runtime included all steps required: 1) load ProtT5, 2) load SETH model checkpoint, 3) read sequences from FASTA files, 4) create embeddings, 5) create predictions and 6) write results into a file.</p>
      </sec>
      <sec id="s2-6-2">
        <title>Comparison: CheZOD score predictions and pLDDT in 17 organisms</title>
        <p>From the AlphaFold database with 3D predictions (<xref rid="B41" ref-type="bibr">Jumper et al., 2021</xref>), we downloaded the available files ending in “F1-model-v2. pdb” for all proteins listed in UniProt (<xref rid="B4" ref-type="bibr">The UniProt Consortium et al., 2021</xref>) for 19 organisms (<xref rid="s11" ref-type="sec">Supplementary Table S2</xref>). A few files (0.3% of proteins) appeared with seemingly corrupted format (no separator between some values) and were removed. For all others, we extracted the pLDDT values.</p>
        <p>For three organisms (<italic>Leishmania infantum</italic>, <italic>Schistosoma mansoni</italic> and <italic>Plasmodium falciparum</italic>) we predicted disorder with SETH using the sequences provided in UniProt (<xref rid="B4" ref-type="bibr">The UniProt Consortium et al., 2021</xref>); for the remaining 16 organisms (<xref rid="s11" ref-type="sec">Supplementary Table S2</xref>) we used the sequences present in Swiss-Prot, due to already having generated this data (see <xref rid="s2-6-1" ref-type="sec">Runtime</xref>). Due to GPU resources, we did not predict disorder for proteins with &gt;9,000 residues (0% of <italic>Leishmania infantum</italic> + <italic>Schistosoma mansoni</italic>, 0.7% - 40 proteins - of <italic>Plasmodium falciparum</italic>, 0.004% - 25 proteins - of Swiss-Prot). None of the proteins for the CheZOD sets (CheZOD117, CheZOD1174) were that long (for obvious reasons related to the length-limitation of NMR).</p>
        <p>To compare disorder predictions and pLDDT, only the subset of the data where both <italic>AlphaFold2</italic> and disorder predictions were available were used. The resulting set contained 17 of the above downloaded 19 organisms (<xref rid="s11" ref-type="sec">Supplementary Table S2</xref>; two organisms: no overlap in the predictions available for <italic>AlphaFold2</italic> and SETH) with 105,881 proteins containing a total of 47M residues. We referred to this data set as the <italic>17-ORGANISM-set</italic>.</p>
      </sec>
      <sec id="s2-6-3">
        <title>Spectrum of predicted CheZOD score distributions for entire organisms</title>
        <p>The spectra of predicted subcellular location reveal aspects pertaining to the evolution of species (<xref rid="B50" ref-type="bibr">Marot-Lassauzaie et al., 2021</xref>). Consequently, we tried the same concept on predicted CheZOD scores for Swiss-Prot. For technical reasons (GPU memory), we excluded proteins longer than 9,000 residues from our analysis. In the entire Swiss-Prot, 0.004% of the proteins reached this length and were excluded. For the other 99.996%, we first converted all predicted CheZOD score distributions (consisting of all disorder predictions of all residues within one organism) of all Swiss-Prot organisms into vectors by counting CheZOD scores in eight bins (-15, -11.125, -7.25, -3.375, 0.5, 4.375, 8.25, 12.125, 16). After normalization (dividing raw counts by all residues in the organism), we PCA-plotted 37 organisms of Swiss-Prot with at least 1,500 proteins [(<xref rid="B110" ref-type="bibr">Wold et al., 1987</xref>); to keep clarity in the plot, some organisms with at least 1,500 proteins were neglected), using the standard implementation of R (prcomp (<xref rid="B75" ref-type="bibr">R Core Team, 2021</xref>)].</p>
      </sec>
    </sec>
  </sec>
  <sec sec-type="results" id="s3">
    <title>Results</title>
    <sec id="s3-1">
      <title>Success of minimalist: Single sequence, simple model</title>
      <p>While state-of-the-art (SOTA) methods usually rely on MSA input to predict IDRs, the methods introduced here use pLMs to encode single protein sequences as embeddings that served as the sole input feature for any prediction. To find the most informative pLM for IDRs, we predicted CheZOD scores through the minimalistic approach of linear regressions on top of embeddings from five pLMs (ProtT5 (<xref rid="B23" ref-type="bibr">Elnaggar et al., 2021</xref>), ProSE (<xref rid="B6" ref-type="bibr">Bepler and Berger, 2021</xref>), ESM-1b (<xref rid="B82" ref-type="bibr">Rives et al., 2021</xref>), ProtBERT (<xref rid="B23" ref-type="bibr">Elnaggar et al., 2021</xref>), SeqVec (<xref rid="B31" ref-type="bibr">Heinzinger et al., 2019</xref>). Following the recent assessment of 26 methods (<xref rid="B60" ref-type="bibr">Nielsen and Mulder, 2019</xref>), we calculated the Spearman correlation coefficient ρ between true and predicted CheZOD scores and the AUC for 10% of <italic>CheZOD1174</italic>, not used in training, to evaluate the models.</p>
      <p>Embeddings from all pLMs outperformed the random baseline and the one-hot encodings, both for the correlation (<xref rid="F1" ref-type="fig">Figure 1B</xref>; ρ) and the binary projection of CheZOD scores (<xref rid="F1" ref-type="fig">Figure 1A</xref>; AUC). The simplest pLM-type included here, namely <italic>SeqVec</italic>, performed consistently and statistically significantly worse than all other pLMs (<xref rid="F1" ref-type="fig">Figure 1</xref>). The other four embeddings (ProSE, ESM-1b, ProtT5, ProtBERT) did not differ to a statistically significant extent, given the small data set. However, since the linear regression trained on ProtT5 reached the numerical top both in ρ and AUC, we used only embeddings from ProtT5 for further analyses.</p>
      <fig position="float" id="F1">
        <label>FIGURE 1</label>
        <caption>
          <p>Performance estimates for training on 90% of <italic>CheZOD1174</italic> (<xref rid="B14" ref-type="bibr">Dass et al., 2020</xref>) and testing on the remaining 10% using linear regressions fed by 20-dimensional one-hot encodings or raw embeddings (without further optimization) from five protein language models (pLMs): ProtT5 (<xref rid="B23" ref-type="bibr">Elnaggar et al., 2021</xref>), ProtBERT (<xref rid="B23" ref-type="bibr">Elnaggar et al., 2021</xref>), ESM-1b (<xref rid="B82" ref-type="bibr">Rives et al., 2021</xref>), ProSE (<xref rid="B6" ref-type="bibr">Bepler and Berger, 2021</xref>), SeqVec (<xref rid="B31" ref-type="bibr">Heinzinger et al., 2019</xref>). The seventh row displays the performance of the baseline/random model computed on 1024-dimensional embeddings sampled randomly from a standard normal distribution. <bold>(A)</bold> required to first project predictions onto a binary state of disorder (CheZOD score≤8)/order (CheZOD score&gt;8) and measures the area under the receiver operating characteristic curve (AUC; <xref rid="e3" ref-type="disp-formula">Eq. 3</xref>), while <bold>(B)</bold> depicts the Spearman correlation coefficient (ρ; <xref rid="e2" ref-type="disp-formula">Eq. 2</xref>), calculated using the observed and predicted CheZOD scores. The errors mark the 95% confidence intervals approximated by multiplying 1.96 with the bootstrap standard deviation (Methods).</p>
        </caption>
        <graphic xlink:href="fbinf-02-1019597-g001" position="float"/>
      </fig>
    </sec>
    <sec id="s3-2">
      <title>ProtT5 captured disorder without any optimization</title>
      <p>Next, we analyzed which information about disorder ProtT5 had already learned during self-supervised pre-training, i.e., before seeing any disorder-related labels. Towards this end, t-SNE projected the 1024-dimensional embeddings onto two dimensions (<xref rid="F2" ref-type="fig">Figure 2</xref>). This suggested some level of separation between ordered (red) and disordered (blue) residues (<xref rid="F2" ref-type="fig">Figure 2A</xref>: red colors oriented toward the center in each cluster), indicating that even raw ProtT5 embeddings already captured some aspects of disorder without seeing any such annotations [ProtT5 only learned to predict masked amino acid tokens (<xref rid="B23" ref-type="bibr">Elnaggar et al., 2021</xref>)]. However, the major signal seemingly did not cluster the disorder/order phenotype. Instead, the primary 20 clusters corresponded to the 20 amino acids (<xref rid="F2" ref-type="fig">Figure 2B</xref>).</p>
      <fig position="float" id="F2">
        <label>FIGURE 2</label>
        <caption>
          <p>t-SNE dimensionality reduction (<xref rid="B101" ref-type="bibr">van der Maaten and Hinton, 2008</xref>) performed on the 1024-dimensional ProtT5 (<xref rid="B23" ref-type="bibr">Elnaggar et al., 2021</xref>) residue-level embeddings extracted from the last attention layer of ProtT5 for all sequences in test set <italic>CheZOD117</italic> [13,069 residues; (<xref rid="B14" ref-type="bibr">Dass et al., 2020</xref>)]. <bold>(A)</bold> shows the embeddings colored by order (CheZOD score&gt;8; red) and disorder [CheZOD score≤8, blue; (<xref rid="B62" ref-type="bibr">Nielsen and Mulder, 2016</xref>)]. <bold>(B)</bold> shows the same t-SNE projection but with coloring by the 20 standard amino acid types (here shown in one-letter code; A = Alanine, C=Cysteine, D = Aspartic acid, E = Glutamic acid, F=Phenylalanine, G = Glycine, H=Histidine, I=Isoleucine, K = Lysine, L = Leucine, M = Methionine, N=Asparagine, P=Proline, Q = Glutamine, R = Arginine, S=Serine, T = Threonine, V=Valine, W = Tryptophan, Y = Tyrosine).</p>
        </caption>
        <graphic xlink:href="fbinf-02-1019597-g002" position="float"/>
      </fig>
    </sec>
    <sec id="s3-3">
      <title>SETH (CNN) outperformed other supervised models</title>
      <p>Next, we trained four AI models, inputting ProtT5 embeddings: three predicted continuous CheZOD scores (LinReg, ANN, SETH), one predicted binary disorder (LogReg). We could add the performance of our methods to a recent method comparison (<xref rid="B60" ref-type="bibr">Nielsen and Mulder, 2019</xref>) since we used the same performance metrics and test set (<italic>CheZOD117;</italic>
<xref rid="F3" ref-type="fig">Figure 3</xref>). We also added the ODiNPred web application (<xref rid="B14" ref-type="bibr">Dass et al., 2020</xref>), the flDPnn webserver (<xref rid="B36" ref-type="bibr">Hu et al., 2021</xref>) and the performance of the new method ADOPT ESM-1b (<xref rid="B80" ref-type="bibr">Redl et al., 2022</xref>), which also uses pLM embeddings. Additionally, the program’s developers ran SPOT-Disorder2 (<xref rid="B27" ref-type="bibr">Hanson et al., 2019</xref>) for us, which, however, failed to run for one test set protein. The performance on the remaining 116 proteins was: ρ = 0.63 ± 0.01 and AUC = 0.88 ± 0.01. When considering the mean ρ (<xref rid="F3" ref-type="fig">Figure 3A</xref>), our methods SETH and ANN numerically outperformed all others, both those not using MSAs (below dashed line in <xref rid="F3" ref-type="fig">Figure 3</xref>), and those using MSAs (above dashed line in <xref rid="F3" ref-type="fig">Figure 3</xref>). When requiring a statistically significant difference at the 95% CI (±1.96 standard errors) for the ρ, our methods (SETH, ANN, LinReg and LogReg) significantly outperformed all others, except for ODiNPred and ADOPT ESM-1b. When evaluating the performance based on the mean AUC, SETH and the simplistic LinReg outperformed all other evaluated methods. Due to the already high AUC levels of many methods, the absolute improvement of our models (SETH, ANN, LinReg and LogReg) to SOTA methods in terms of AUC was often not statistically significant.</p>
      <fig position="float" id="F3">
        <label>FIGURE 3</label>
        <caption>
          <p>Data: set <italic>CheZOD117</italic> (<xref rid="B14" ref-type="bibr">Dass et al., 2020</xref>). Performances of all methods introduced here (SETH, ANN, LinReg, LogReg, LinReg1D) in orange, the ODiNPred web application in grey (<xref rid="B14" ref-type="bibr">Dass et al., 2020</xref>), ADOPT ESM-1b in grey (<xref rid="B80" ref-type="bibr">Redl et al., 2022</xref>), the fIDPnn server in grey (<xref rid="B36" ref-type="bibr">Hu et al., 2021</xref>) and four disorder measures derived from <italic>AlphaFold2</italic> (<xref rid="B41" ref-type="bibr">Jumper et al., 2021</xref>) in blue [these are: AlphaFold2_<italic>pLDDT</italic>, AlphaFold2_pLDDT21: smoothed over 21-consecutive residues (<xref rid="B1" ref-type="bibr">Akdel et al., 2021</xref>), AlphaFold2_exp_res: experimentally resolved prediction, AlphaFold2_rsa_25: running average over relative solvent accessibility averaged over 25 consecutive residues (<xref rid="B72" ref-type="bibr">Piovesan et al., 2022</xref>)]. All other performances were taken from the previous comparison (<xref rid="B60" ref-type="bibr">Nielsen and Mulder, 2019</xref>) using the same test set (see Methods <italic>Evaluation</italic>). While three of our models (SETH, ANN, LinReg/LinReg1D), ADOPT ESM-1b and ODiNPred were trained on continuous chemical shift Z-scores (CheZOD scores), the logistic regression, LogReg, was trained on a binary classification of order/disorder (CheZOD score&gt;8/≤8). ODiNPred and ADOPT ESM-1b used more proteins for training than our models. The horizontal dotted line separates models using MSAs (above line) from single sequence-based methods (below line). Error bars mark the 95% confidence interval, approximated by bootstrapping for our methods, <italic>AlphaFold2</italic>, the ODiNPred web application and the flDPnn server (Methods). Panel (A): Performance measured with the spearman correlation coefficient (ρ; <xref rid="e2" ref-type="disp-formula">Eq. 2</xref>) between the ground truth and the prediction. Panel (B): Performance measured with the area under the receiver operating characteristic curve (AUC; <xref rid="e3" ref-type="disp-formula">Eq. 3</xref>) after the binary projection of the ground truth CheZOD scores [order: CheZOD score&gt;8, disorder: CheZOD score≤8; (<xref rid="B62" ref-type="bibr">Nielsen and Mulder, 2016</xref>)].</p>
        </caption>
        <graphic xlink:href="fbinf-02-1019597-g003" position="float"/>
      </fig>
      <p>The differences between the models introduced here (LogReg, LinReg, ANN and SETH) were not statistically significant (neither for AUC nor for ρ). However, SETH had the highest mean ρ and, together with LinReg, the highest mean AUC. For a more detailed analysis, we plotted the true and predicted CheZOD scores (or for LogReg the true CheZOD scores and the predicted probability for the class “order”) for <italic>CheZOD117</italic> against each other in a 2D histogram for all four models (<xref rid="s11" ref-type="sec">Supplementary Figure S6</xref>). SETH, ANN and LinReg agreed well with the ground truth. However, the plots revealed that SETH, LinReg and ANN tended to overestimate residue order, as indicated by the higher prediction density above the diagonal. In contrast to our other models, most of the pairs of LogReg’s predicted order probability vs. observed CheZOD scores fell into two flat clusters at 0 and 1, confirming that LogReg tended to predict extreme values optimal for classification. The removal of short disordered residues (i.e. less than 30 consecutive residues with observed CheZOD scores≤8) did not change the Spearman correlation significantly (<xref rid="s11" ref-type="sec">Supplementary Figure S7</xref>).</p>
    </sec>
    <sec id="s3-4">
      <title>Shortcomings of SETH</title>
      <p>For SETH, our best model (outperforming all others in ρ and AUC; <xref rid="F3" ref-type="fig">Figure 3</xref>), we added another analysis classifying each residue in <italic>CheZOD117</italic> into one of three classes according to the observed CheZOD scores: ordered (CheZOD score&gt;8), long disorder (residues in a disorder (CheZOD score≤8) stretch with≥30 residues) and short disorder (disordered stretches with&lt;30 residues). Firstly, SETH clearly missed short disorder (<xref rid="F4" ref-type="fig">Figure 4</xref>: predicted values for this class were approximately uniformly distributed in (0,15), with a ρ of only 0.41 ± 0.04). Secondly, SETH overestimated order (<xref rid="F4" ref-type="fig">Figure 4</xref> and also <xref rid="s11" ref-type="sec">Supplementary Figure S6</xref>), as there was a shift of the distributions of ordered and long disordered residues to the right from the observed to the predicted scores. Thirdly, SETH predicted several residues as ordered, for which the ground truth CheZOD scores suggested long consecutive regions of disorder (<xref rid="F4" ref-type="fig">Figure 4B</xref>). For a subset of proteins, for which at least one-third of all residues were in long IDRs but SETH predicted order, <italic>AlphaFold2</italic>’s pLDDT largely supported our predictions of order (<xref rid="s11" ref-type="sec">Supplementary Figure S8</xref>). For two of these ten proteins, we found DisProt annotations (<xref rid="B74" ref-type="bibr">Quaglia et al., 2022</xref>), showing disorder to order transition regions (i.e., regions that can change from disorder to order, e.g., upon binding) overlapping with the regions of wrongly predicted order (<xref rid="s11" ref-type="sec">Supplementary Figure S8</xref>). Lastly, SETH’s predicted CheZOD scores&lt;0 indicated long IDRs (only this class has high counts below 0, <xref rid="F4" ref-type="fig">Figure 4</xref>). This suggested zero as a second more conservative threshold for classifying disorder, to filter out short linker regions falsely labeled as disorder.</p>
      <fig position="float" id="F4">
        <label>FIGURE 4</label>
        <caption>
          <p>Data: set <italic>CheZOD117</italic> (<xref rid="B14" ref-type="bibr">Dass et al., 2020</xref>). All residues in <italic>CheZOD117</italic> were classified into one of three classes: ordered (chemical shift Z-score (CheZOD score) &gt; 8), short disorder and long disorder (disordered residues (CheZOD score≤8) in a disordered region≥30), using the ground truth labels. <bold>(A)</bold> Distribution of the observed CheZOD scores (i.e., the ground truth labels) in the three classes. <bold>(B)</bold> Distribution of SETH’s predicted CheZOD scores in the three classes. SETH is a CNN trained on continuous chemical shift Z-scores and outperformed all state-of-the-art methods evaluated, as well as all our other methods.</p>
        </caption>
        <graphic xlink:href="fbinf-02-1019597-g004" position="float"/>
      </fig>
    </sec>
    <sec id="s3-5">
      <title>SETH blazingly fast</title>
      <p>Using SETH for analyzing proteins and proteomes requires top performance (<xref rid="F3" ref-type="fig">Figure 3</xref>) and speed. On a machine with one RTX A6000 GPU with 48GB RAM, predicting the nuances of disorder for each residue of the entire human proteome (20,352 proteins) from the individual protein sequences took approximately 23 min. For Swiss-Prot [566,969 proteins (<xref rid="B4" ref-type="bibr">The UniProt Consortium et al., 2021</xref>)], it took approximately 7 hours. As a rule of thumb, SETH could predict disorder for approximately 10–20 proteins in 1 s, depending on the protein length. Even on smaller GPUs such as a single NVIDIA GeForce RTX 3060 with 12 GB vRAM, computing predictions for the human proteome still took only an hour. Lastly, even on an AMD Ryzen 5 5500U CPU, performing predictions for our test set <italic>CheZOD117</italic> (average protein length 112) only took 12 min, showing that for small sets a GPU is not even necessary.</p>
    </sec>
    <sec id="s3-6">
      <title>One of 1,024 embedding dimension outperformed most methods (LinReg1D)</title>
      <p>After training, we also analyzed the regression coefficients of LinReg to better understand how ProtT5 embeddings affected the prediction. For the dimension with the highest regression coefficient (dimension 295 of 1,024; <xref rid="s11" ref-type="sec">Supplementary Figure S4</xref>), we subsequently plotted the raw embedding values against the true CheZOD scores (<xref rid="s11" ref-type="sec">Supplementary Figure S6E</xref>) to visualize the information on order/disorder in the embeddings without supervised training. The Spearman correlation for this single dimension (ρ = 0.61) was almost the same as that for LinReg (ρ = 0.69; LinReg used all 1,024 dimensions in training), showing that the pLM already learned aspects of disorder during self-supervised pre-training, i.e., without ever seeing such labels. However, in contrast to LinReg, the single dimension without supervised training avoided overestimating residue order (no accumulation of high density above the diagonal; <xref rid="s11" ref-type="sec">Supplementary Figure S6</xref>).</p>
      <p>To explicitly quantify the influence of this single most informative dimension, we additionally trained and evaluated a linear regression inputting only this 295th embedding dimension (dubbed LinReg1D). LinReg1D reached a ρ of 0.61 (LinReg ρ = 0.69) and an AUC of 0.87 (LinReg AUC = 0.91, <xref rid="F3" ref-type="fig">Figure 3</xref>). Therefore, this single dimension accounted for 89% or 96% of the performance of LinReg, when considering the ρ or the AUC respectively. As only a linear transformation was performed from the raw values to LinReg1D, both showed the same ρ when correlated with the true CheZOD scores.</p>
      <p>When comparing LinReg1D to the other methods evaluated in the large-scale comparison of disorder predictors (<xref rid="B60" ref-type="bibr">Nielsen and Mulder, 2019</xref>), ODiNPred and ADOPT ESM-1b, even this extremely reduced model outperformed all other methods not using MSAs apart from ADOPT ESM-1b and only fell short compared to the two best-performing methods using MSAs (SPOT-Disorder (<xref rid="B29" ref-type="bibr">Hanson et al., 2016</xref>) and ODiNPred), when looking at both the AUC and the ρ (<xref rid="F3" ref-type="fig">Figure 3</xref>). However, compared to our other methods (SETH, LinReg, ANN, LogReg) LinReg1D performed significantly worse.</p>
    </sec>
    <sec id="s3-7">
      <title><italic>AlphaFold2</italic> correlated less with CheZOD scores than top methods</title>
      <p><italic>AlphaFold2’s</italic> (smoothed) predicted reliability pLDDT and its (smoothed) predicted RSA have recently been reported to capture some aspects of IDRs (<xref rid="B1" ref-type="bibr">Akdel et al., 2021</xref>; <xref rid="B109" ref-type="bibr">Wilson et al., 2021</xref>; <xref rid="B72" ref-type="bibr">Piovesan et al., 2022</xref>; <xref rid="B80" ref-type="bibr">Redl et al., 2022</xref>). However, the ρ between <italic>AlphaFold2</italic>’s (smoothed) pLDDT and CheZOD scores clearly neither reached the levels of the top expert solutions (SETH, LinReg, ANN, LogReg, LinReg1D, ODiNPred or ADOPT ESM-1b; <xref rid="F3" ref-type="fig">Figure 3A</xref>) trained on CheZOD scores, nor that of many other methods using MSAs (<xref rid="B60" ref-type="bibr">Nielsen and Mulder, 2019</xref>). Looking at the correlation between pLDDT scores and CheZOD scores in more detail (<xref rid="s11" ref-type="sec">Supplementary Figure S6G</xref>) revealed that disordered residues (CheZOD score≤8) were occasionally predicted with high confidence (pLDDT&gt;80) explaining the rather low ρ. <italic>AlphaFold2’s</italic> “experimentally resolved” prediction (AlphaFold2_exp_res, <xref rid="F4" ref-type="fig">Figure 4</xref>) correlated better with CheZOD scores, reaching the top 10 methods. Even better was the smoothed RSA value (ρ = 0.64; AlphaFold2_rsa_25, <xref rid="F4" ref-type="fig">Figure 4</xref>), although still falling behind the top expert solutions (SETH, LinReg, ANN, LogReg, ODiNPred or ADOPT ESM-1b).</p>
    </sec>
    <sec id="s3-8">
      <title>SETH disorder predictions correlated with <italic>AlphaFold2</italic> pLDDT</title>
      <p>We analyzed the fitness of SETH as a fast pre-filter to distinguish between proteins/regions with low and high mean pLDDTs of <italic>AlphaFold2</italic> (<xref rid="F5" ref-type="fig">Figure 5</xref>). For proteins from 17 model organisms, SETH’s predictions correlated well with the <italic>AlphaFold2</italic> pLDDT (ρ = 0.67; <xref rid="F5" ref-type="fig">Figure 5A</xref>, per-organism details: <xref rid="s11" ref-type="sec">Supplementary Figure S10</xref>). This trend remained after binarizing disorder using a CheZOD threshold of 8 (<xref rid="F5" ref-type="fig">Figure 5B</xref>). If the goal were to predict the classification of all proteins into those with mean pLDDT≥70 (<italic>wanted</italic>) and pLDDT&lt;70 (<italic>unwanted</italic>), depending on the threshold in the mean predicted CheZOD score (number on the curve in <xref rid="F5" ref-type="fig">Figure 5C</xref>), this will result in different pairs of wanted proteins incorrectly missed (<italic>y</italic>-axis, <xref rid="F5" ref-type="fig">Figure 5C</xref>) given the proteins correctly ignored (<italic>x</italic>-axis, <xref rid="F5" ref-type="fig">Figure 5C</xref>). For instance, at a threshold of eight in the mean predicted CheZOD scores, a quarter of all proteins could be avoided at an error rate of only 5% (proteins missed with pLDDT≥70). The accuracy at this threshold was 0.86. This might be relevant to prioritize/filter data in large-scale <italic>AlphaFold2</italic> predictions.</p>
      <fig position="float" id="F5">
        <label>FIGURE 5</label>
        <caption>
          <p>SETH’s predictions correlated with AlphaFold2’s pLDDT. Data: 17-ORGANISM-set (47,400,204 residues from 105,881 proteins in 17 organisms). <bold>(A)</bold> 2-dimensional histogram of <italic>AlphaFold2</italic> pLDDT (<xref rid="B41" ref-type="bibr">Jumper et al., 2021</xref>) against SETH disorder predictions (black line: optimal regression fit, marginal histograms on each axis; number: overall Spearman correlation coefficient ρ, <xref rid="e2" ref-type="disp-formula">Eq. 2</xref>). <bold>(B)</bold> Histograms of the pLDDT of <italic>AlphaFold2</italic>, for the classes order (predicted CheZOD&gt;8) and disorder (predicted CheZOD≤8). <bold>(C)</bold> Cost versus gain analysis using SETH as a pre-filter for <italic>AlphaFold2</italic>. <italic>Y</italic>-axis—Cost: The percentage of proteins with a mean predicted CheZOD score below a certain threshold (thresholds marked as numbers on the curve), but mean pLDDT≥70 (FN) out of all proteins with mean pLDDT≥70 (P). This gives the percentage of proteins with a pLDDT≥70 missed using the SETH CheZOD score prediction as a pre-filter. <italic>X</italic>-axis—Gain: The percentage of proteins with mean CheZOD score &lt; threshold (FN + TN) out of all proteins (All). This is the percentage of proteins in the entire dataset for which <italic>AlphaFold2</italic> will not have to be run at all, or defines a list of priority: first run <italic>AlphaFold2</italic> on the proteins with lower SETH disorder. For instance, with threshold 8, a quarter of all <italic>AlphaFold2</italic> predictions can be avoided at an error rate of only 5%.</p>
        </caption>
        <graphic xlink:href="fbinf-02-1019597-g005" position="float"/>
      </fig>
      <p>More importantly, the comparison of the <italic>AlphaFold2</italic> pLDDT and SETH’s predictions could also be used to find out more about the causes of lacking reliable <italic>AlphaFold2</italic> predictions. For instance, a lack of reliable <italic>AlphaFold2</italic> predictions was often due to disorder in proteins since low pLDDT values were mostly present for disordered residues (<xref rid="F5" ref-type="fig">Figure 5B</xref>). However, providing <xref rid="F5" ref-type="fig">Figure 5B</xref> at the organism level (<xref rid="s11" ref-type="sec">Supplementary Figure S11</xref>) revealed that for some organisms, especially those with rather low mean pLDDT values (<xref rid="s11" ref-type="sec">Supplementary Figure S9</xref>), SETH predicted many residues as ordered for which <italic>AlphaFold2’s</italic> pLDDT was low. There were even cases, where nearly the entire protein was predicted to be ordered, but <italic>AlphaFold2</italic> could not predict any reliable 3D structure (<xref rid="s11" ref-type="sec">Supplementary Figure S12</xref>).</p>
    </sec>
    <sec id="s3-9">
      <title>Evolutionary information captured in CheZOD score distributions</title>
      <p>Encouraged by the finding that the spectrum of predicted subcellular locations (in 10 classes) captures aspects of evolution (<xref rid="B50" ref-type="bibr">Marot-Lassauzaie et al., 2021</xref>), here, we converted the CheZOD score predictions for an entire organism into a single 8-dimensional vector containing the binned normalized counts of predicted CheZOD scores. A simple PCA (<xref rid="B110" ref-type="bibr">Wold et al., 1987</xref>) on the resulting vectors for 37 organisms revealed a clear connection from the micro-molecular level of per-residue predictions of CheZOD-disorder to the macro-molecular level of species evolution (<xref rid="F6" ref-type="fig">Figure 6</xref>). Firstly, eukaryotes and prokaryotes (Bacteria + Archaea) were clearly separated. Secondly, even within these major groups, there appeared some relevant separation into phyla for the bacteria and into kingdoms for the eukaryotes. However, based on these limited samples, it also seemed like some groups could not be separated completely according to their disorder spectra, e.g., the fungi and the metazoa.</p>
      <fig position="float" id="F6">
        <label>FIGURE 6</label>
        <caption>
          <p>Evolution captured by spectrum of predicted CheZOD scores. Data: SETH predictions for proteins from 37 organisms taken from Swiss-Prot (<xref rid="B4" ref-type="bibr">The UniProt Consortium et al., 2021</xref>). The plot shows the PCA (<xref rid="B110" ref-type="bibr">Wold et al., 1987</xref>) of the binned spectrum of predicted CheZOD scores (8 bins, meaning 8-dimensional vectors; each vector describes one organism). The colors indicate the super-kingdoms (Eukaryota: reds, Bacteria: blues, Archaea: violet) as well as the Phyla for the Bacteria and the Kingdoms for the Eukaryotes, as given in UniProt (<xref rid="B4" ref-type="bibr">The UniProt Consortium et al., 2021</xref>). The organism names were shortened (for complete organism names see <xref rid="s11" ref-type="sec">Supplementary Table S4</xref>).</p>
        </caption>
        <graphic xlink:href="fbinf-02-1019597-g006" position="float"/>
      </fig>
    </sec>
  </sec>
  <sec sec-type="discussion" id="s4">
    <title>Discussion</title>
    <p>We introduced SETH, a shallow CNN, for predicting the continuum of residue disorder defined by CheZOD scores (i.e., the difference between observed chemical shifts from NMR and computed random coil chemical shifts (<xref rid="B61" ref-type="bibr">Nielsen and Mulder, 2020</xref>)). SETH’s exclusive input are embeddings from the pLM ProtT5 (<xref rid="B23" ref-type="bibr">Elnaggar et al., 2021</xref>). Using performance measures and data sets proposed in a recent analysis (<xref rid="B60" ref-type="bibr">Nielsen and Mulder, 2019</xref>), SETH outperformed three even simpler (fewer parameters) models introduced here, along with 26 other disorder prediction methods. Predictions of <italic>AlphaFold2</italic> have recently been shown to capture IDRs (<xref rid="B1" ref-type="bibr">Akdel et al., 2021</xref>; <xref rid="B109" ref-type="bibr">Wilson et al., 2021</xref>; <xref rid="B72" ref-type="bibr">Piovesan et al., 2022</xref>; <xref rid="B80" ref-type="bibr">Redl et al., 2022</xref>). However, we found the correlation between <italic>AlphaFold2</italic> predictions and CheZOD scores to be much lower than for SETH.</p>
    <sec id="s4-1">
      <title>Redundancy-reduction affects performance estimates, not performance</title>
      <p>We chose our datasets (training <italic>CheZOD1174</italic>, and testing <italic>CheZOD117</italic>) and performance measures (<xref rid="e2" ref-type="disp-formula">Eqn. (2) and (3</xref>) following a recent analysis (<xref rid="B60" ref-type="bibr">Nielsen and Mulder, 2019</xref>). However, since adequate redundancy-reduction is <italic>sine qua non</italic> to correctly estimate performance, we additionally removed 151 sequences from ODiNPred’s (<xref rid="B14" ref-type="bibr">Dass et al., 2020</xref>) training set which had, based on alignments with 80% coverage, over 20% pairwise sequence identity (PIDE) with proteins in the test set (see Methods 2.1). Unfortunately, the threshold of sequence identity T (here 20% PIDE) crucially depends on the phenotype (here disorder). In the lack of sufficiently large data sets to establish T for disorder (and many other phenotypes, including protein-protein interactions (<xref rid="B66" ref-type="bibr">Park and Marcotte, 2012</xref>; <xref rid="B26" ref-type="bibr">Hamp and Rost, 2015</xref>)), developers should be as conservative as possible. However, there is a trade-off: chose T too low, lose proteins for training/testing, chose T too high, risk substantially over-estimating performance. With our threshold, we try to balance both. However, we only removed proteins which were aligned with 80% coverage, meaning there might still be some information leakage on a smaller level (3 test proteins with PIDE&gt;20% to training proteins at a coverage of 10%; <xref rid="s11" ref-type="sec">Supplementary Table S5</xref>). However, this leakage should be negligible, since none of the aligned proteins lie above the HSSP-curve (<xref rid="B86" ref-type="bibr">Rost, 1999</xref>). Even if there would still be some minor leakage of information, this might only balance out the over-estimates of performance of other methods, since over-estimating performance has become many times more common with the rise of AI with immense numbers of free parameters (often 10-times more parameters than samples), which can often easily zoom into residual sequence similarity between train and test set. Also considering that we used a quite conservative T, other methods tested on the same test set might more likely overestimate their performance. We cannot answer whether this over-estimate of any method is statistically insignificant or significant. That depends on many aspects of the method.</p>
    </sec>
    <sec id="s4-2">
      <title>Supervised models picked up class imbalance</title>
      <p>The training and test sets resulting from redundancy reduction differed substantially in their distributions of CheZOD scores (<xref rid="s11" ref-type="sec">Supplementary Figure S1</xref>; note the test set <italic>CheZOD117</italic> had not been changed, only the training set). In a binary projection, the fraction of ordered residues was 72% for the training and 31% for the testing set. Our regression models did not use any notion of classes. Thus, we could not correct for class imbalance. This might explain why our supervised regression models trained on this imbalanced data (SETH, LinReg, LinReg1D and ANN) mildly over-predicted the degree of residue order compared to the raw embedding values of dimension 295 (<xref rid="s11" ref-type="sec">Supplementary Figure S6</xref>).</p>
    </sec>
    <sec id="s4-3">
      <title>Simple classification model LogReg struggled where SETH excelled</title>
      <p>We tested the effect of increasing the model complexity when inputting only embeddings. For an ideal prediction method observed and predicted CheZOD scores would perfectly correlate, i.e., in a scatter plot with observed on the <italic>x</italic>-axis and predicted on the <italic>y</italic>-axis, perfect methods would cluster all points around the diagonal (<xref rid="s11" ref-type="sec">Supplementary Figure S6</xref>). Qualitatively, our two most complex methods SETH and ANN came closest to this, followed by the simpler model LinReg, with more spread-out clusters (<xref rid="s11" ref-type="sec">Supplementary Figure S6A–C</xref>). In contrast to an ideal prediction, the simplest model LogReg generated two clusters, one around probability 0 (disorder) and the other around 1 (order; <xref rid="s11" ref-type="sec">Supplementary Figure S6D</xref>). Although such a bifurcation is expected for a logistic regression trained to classify, the off-diagonal shift of the data showed that LogReg struggled to capture subtle degrees of disorder/order. This qualitative analysis was supported by the ρ (<xref rid="F3" ref-type="fig">Figure 3A</xref>: SETH highest, LogReg lowest). Therefore, we established that the treatment of disorder as a regression problem (SETH, ANN, LinReg) improved over the supervised training on binary assignments (disorder/order; LogReg; <xref rid="F3" ref-type="fig">Figure 3</xref>). This was interesting because except for ODiNPred (<xref rid="B14" ref-type="bibr">Dass et al., 2020</xref>) and ADOPT (<xref rid="B80" ref-type="bibr">Redl et al., 2022</xref>), most SOTA disorder prediction methods realize a binary classification. However, the ρ was still similar between all our four models, including LogReg. Likewise, the performance on binarized CheZOD scores (order: CheZOD score&gt;8, disorder: CheZOD score≤8), measured with the AUC did also not vary significantly. Nonetheless, SETH was consistently superior by all criteria (<xref rid="F3" ref-type="fig">Figure 3</xref>).</p>
    </sec>
    <sec id="s4-4">
      <title>Simpler, better, faster</title>
      <p>The simplicity of a machine learning model can be proxied by the number of free parameters. Our top performing models SETH, ANN, LinReg and LogReg did not reach anywhere near the simplicity of earlier IDR prediction methods such as NORS (<xref rid="B49" ref-type="bibr">Liu et al., 2002</xref>) or IUPred (<xref rid="B17" ref-type="bibr">Dosztanyi et al., 2005</xref>) or recent adaptations of <italic>AlphaFold2</italic> predictions (<xref rid="B1" ref-type="bibr">Akdel et al., 2021</xref>; <xref rid="B109" ref-type="bibr">Wilson et al., 2021</xref>; <xref rid="B72" ref-type="bibr">Piovesan et al., 2022</xref>; <xref rid="B80" ref-type="bibr">Redl et al., 2022</xref>) when neglecting <italic>AlphaFold2’s</italic> training and only considering the disorder prediction from <italic>AlphaFold2’s</italic> output. Then, <italic>AlphaFold2</italic> binary disorder prediction would only need three parameters: choice of feature (e.g., RSA vs. pLDDT), averaging window (e.g., 25 for RSA) and a threshold (RSA &lt; T). However, we still constrained the size of our models (<xref rid="s11" ref-type="sec">Supplementary Table S3</xref>). The comparison to one-hot encodings clearly demonstrated the benefit of increasing model complexity by inputting high dimensional pLM embeddings (<xref rid="F1" ref-type="fig">Figure 1</xref>). Lastly, our simplification of LinReg (LinReg1D) based on one of the 1,024 dimensions of ProtT5 (<xref rid="B23" ref-type="bibr">Elnaggar et al., 2021</xref>), namely dimension 295 that carried 86%–96% of the signal of the entire 1024-dimensional vector (<xref rid="F3" ref-type="fig">Figure 3</xref>), reached the simplicity of very basic predictors. Still, it outperformed most complex methods.</p>
      <p>Two of our models numerically reached higher AUC values than all other methods compared (SETH and LinReg, <xref rid="F3" ref-type="fig">Figure 3B</xref>), irrespective of whether they use MSAs or not. When considering the ρ (<xref rid="F3" ref-type="fig">Figure 3A</xref>), again two of our methods (SETH and ANN) outperformed all others. In terms of statistical significance for the ρ at the CI = 95% level, all our models along with ODiNPred (<xref rid="B14" ref-type="bibr">Dass et al., 2020</xref>) and ADOPT ESM-1b (<xref rid="B80" ref-type="bibr">Redl et al., 2022</xref>) significantly outperformed all others. Of these top performers, only ODiNPred relies on MSAs, i.e., this is the only top performer for which we first need to create informative MSAs before we can analyze the disorder content of a newly sequenced proteome. Even using tools such as the blazingly fast <italic>MMseqs2</italic> (<xref rid="B94" ref-type="bibr">Steinegger and Söding, 2017</xref>), this will still slow down the analysis. In contrast, ADOPT ESM-1b also only requires pLM embeddings as input. Given the larger model used by ADOPT ESM-1b and the larger size of ESM-1b (<xref rid="B82" ref-type="bibr">Rives et al., 2021</xref>) compared to ProtT5 (<xref rid="B23" ref-type="bibr">Elnaggar et al., 2021</xref>) used by our tools, we expect the difference in speed to favor SETH more than that in performance.</p>
    </sec>
    <sec id="s4-5">
      <title><italic>AlphaFold2</italic> not competitive to pLM-based methods as proxy for CheZOD disorder</title>
      <p><italic>AlphaFold2’s</italic> pLDDT correlates with binary descriptions of IDRs (<xref rid="B1" ref-type="bibr">Akdel et al., 2021</xref>; <xref rid="B109" ref-type="bibr">Wilson et al., 2021</xref>; <xref rid="B72" ref-type="bibr">Piovesan et al., 2022</xref>). In principle, we confirmed this for CheZOD scores reflecting non-binary disorder (<xref rid="s11" ref-type="sec">Supplementary Figure S6G</xref>). However, we also found <italic>AlphaFold2</italic> to often be certain about a predicted structure (high pLDDT) even for regions where CheZOD scores suggest long IDRs (≥30 residues; <xref rid="s11" ref-type="sec">Supplementary Figure S7</xref>). One possible explanation for this might be that while <italic>AlphaFold2</italic> was only trained on single protein domains, some of these proteins were measured as homo- or heteromers. Consequently, the <italic>AlphaFold2</italic> predictions might be biased in regions that are disordered in isolation but become well-structured upon interaction. This hypothesis was supported by a very limited analysis comparing the pLDDT to DisProt annotations [(<xref rid="B74" ref-type="bibr">Quaglia et al., 2022</xref>); <xref rid="s11" ref-type="sec">Supplementary Figure S8</xref>]. Furthermore, the mean pLDDT is trivially higher for shorter than for longer proteins (<xref rid="B58" ref-type="bibr">Monzon et al., 2022</xref>). As proteins in the test set were shorter than average (mean sequence length in <italic>CheZOD117:</italic> 112), this trivial length-dependence might also explain some outliers.</p>
      <p>Comparing several ways to utilize <italic>AlphaFold2</italic> predictions as a direct means to predict CheZOD scores revealed the window-averaged of the RSA to correlate even better with CheZOD scores than the prediction of “experimentally resolved” and the (smoothed) pLDDT (<xref rid="F3" ref-type="fig">Figure 3</xref>). It outperformed all but two (ODiNPred (<xref rid="B14" ref-type="bibr">Dass et al., 2020</xref>), SPOT-dis (<xref rid="B29" ref-type="bibr">Hanson et al., 2016</xref>)) of the methods not based on pLMs. However, all four methods introduced here (SETH, ANN, LinReg, LogReg) and ADOPT ESM-1b (<xref rid="B80" ref-type="bibr">Redl et al., 2022</xref>) topped this.</p>
      <p>Concluding, given the many times higher runtime (we ran <italic>AlphaFold2</italic> (without the MSA generation step and using early stopping when one of five models reached a pLDDT≥85) and SETH on the machine with one RTX A6000 GPU with 48 GB RAM and <italic>AlphaFold2</italic> took approximately 170 times as long as SETH), SETH appeared by far a better method for predicting disorder as defined by CheZOD scores than <italic>AlphaFold2</italic>. Even for the many proteins where <italic>AlphaFold2</italic> predictions are already available, the degree to which SETH outperformed disorder measures derived from <italic>AlphaFold2</italic> and the speed of SETH suggest to always use SETH instead of <italic>AlphaFold2</italic> to predict CheZOD-like disorder.</p>
    </sec>
    <sec id="s4-6">
      <title>Agreement between SETH’s disorder predictions and <italic>AlphaFold2’s</italic> pLDDT</title>
      <p><italic>AlphaFold2</italic>’s recent release of structure predictions (28 July 2022), expanding the <italic>AlphaFold2</italic> database to over 200 million predictions, has considerably expanded the structural coverage in the protein Universe. However, each day new proteins and proteomes are discovered and will require <italic>AlphaFold2</italic> 3D predictions. Could SETH help to prioritize how to run <italic>AlphaFold2</italic>, e.g., choosing the proteins most likely to have high pLDDTs (i.e., ordered proteins) first and leaving the rest for later, or completely neglecting the rest (i.e., disordered proteins)? Toward this end, we analyzed a large set of residues from 17 organisms and found the correlation between SETH’s predictions and <italic>AlphaFold2</italic>’s pLDDT (<xref rid="F5" ref-type="fig">Figure 5A</xref>) to be much higher than the correlation between the pLDDT and the ground truth CheZOD scores (ρ(AlphaFold2_pLDDT, ground truth) = 0.56 vs. ρ(AlphaFold2_pLDDT, SETH) = 0.67). This confirmed the agreement in over-prediction of order for SETH and <italic>AlphaFold2</italic> (<xref rid="s11" ref-type="sec">Supplementary Figure S8</xref>) because if SETH and <italic>AlphaFold2</italic> make the same mistakes, a higher correlation is expected. These findings are at the base of using SETH to pre-filter or prioritize <italic>AlphaFold2</italic> predictions, e.g., using SETH protein mean CheZOD scores&lt;8 to deprioritize or exclude some proteins will reduce costs for <italic>AlphaFold2</italic> by one-quarter at an error rate of only 5%.</p>
      <p>The comparisons between SETH and <italic>AlphaFold2</italic> also might help to rationalize some predictions, e.g., for organisms with low mean pLDDT values, SETH often predicted order where <italic>AlphaFold2</italic> could not predict reliable 3D structures (<xref rid="s11" ref-type="sec">Supplementary Figures S9, 11</xref>). Such cases might suggest that there are some “principles of protein structure formation” not yet captured by the outstanding <italic>AlphaFold2</italic>. More detailed studies will have to address this speculation.</p>
    </sec>
    <sec id="s4-7">
      <title>CheZOD score disorder not equal to binary disorder</title>
      <p>Most methods developed in the field of disorder predictions are trained on binary data: <italic>disordered</italic> (IDR: intrinsically disordered regions/IDP: intrinsically disordered proteins) as opposed to <italic>well-structured</italic>/<italic>ordered</italic>. Although this is standard procedure for machine learning, the situation for disorder is slightly different. There, we assume the set of all experimentally known 3D structures as deposited in the PDB (<xref rid="B9" ref-type="bibr">Burley et al., 2019</xref>) to be more representative of all well-ordered proteins than DisProt (<xref rid="B105" ref-type="bibr">Vucetic et al., 2005</xref>; <xref rid="B74" ref-type="bibr">Quaglia et al., 2022</xref>) of all disordered proteins, as the diversity of disorder is much more difficult to capture experimentally. Thus, for disorder we have many reasons to doubt that today’s experimental data are representative. This creates a “Gordian knot”: how do we train on unknown data? In previous work, we tried cutting through this knot by training on data differing from DisProt data (long loops, low contact density), but testing on DisProt (<xref rid="B49" ref-type="bibr">Liu et al., 2002</xref>; <xref rid="B87" ref-type="bibr">Schlessinger et al., 2007a</xref>; <xref rid="B88" ref-type="bibr">Schlessinger et al., 2007b</xref>), as, for instance, the successful method IUPred did for contacts (<xref rid="B17" ref-type="bibr">Dosztanyi et al., 2005</xref>). Instead, here we used CheZOD scores (<xref rid="B62" ref-type="bibr">Nielsen and Mulder, 2016</xref>, <xref rid="B60" ref-type="bibr">2019</xref>; <xref rid="B14" ref-type="bibr">Dass et al., 2020</xref>) introduced by Nielsen and Mulder as the “secret order in disorder”. The CheZOD perspective appealed to us because of three reasons. Firstly, it provides details or nuances for each residue. Secondly, it partially eradicates the need for a minimal threshold of continuous regions: most loops (non-regular secondary structure) of, e.g., 5–15 residues are absolutely unrelated to what we consider disorder, while loops with over 30 consecutive residues clearly fall into two distinct classes of long-loops in regular structures and disordered regions (<xref rid="B87" ref-type="bibr">Schlessinger et al., 2007a</xref>). Thirdly, the non-binary classification allowed to describe an entire organism by an 8-dimensional vector that captured evolution (<xref rid="F6" ref-type="fig">Figure 6</xref>).</p>
      <p>A recent large-scale evaluation of disorder prediction methods (<xref rid="B60" ref-type="bibr">Nielsen and Mulder, 2019</xref>; <xref rid="B14" ref-type="bibr">Dass et al., 2020</xref>) and one of CAID’s [Critical Assessment of Protein Intrinsic Disorder Prediction, (<xref rid="B59" ref-type="bibr">Necci et al., 2021</xref>)] top methods SPOT-Disorder2 show that methods for binary disorder prediction capture information about CheZOD scores. Inversely, SETH, trained on CheZOD scores, appears to capture aspects of binary disorder (as suggested by some preliminary results from the second round of CAID). On the other hand, another one of the CAID-top methods for predicting binary disorder flDPnn (<xref rid="B36" ref-type="bibr">Hu et al., 2021</xref>), did not reach top rank for CheZOD scores (<xref rid="F3" ref-type="fig">Figure 3</xref>). Consequently, CheZOD scores might be the “secret order in disorder”, but they probably capture aspects somehow orthogonal to binary disorder.</p>
    </sec>
    <sec id="s4-8">
      <title>Spectra of predicted CheZOD-disorder capture rudimentary aspects of evolution</title>
      <p>Spectra of predicted protein location capture aspects of the evolution of eukaryotes (<xref rid="B50" ref-type="bibr">Marot-Lassauzaie et al., 2021</xref>). Additionally, the fraction of intrinsically disordered proteins in a proteome has been revealed as a marker for important aspects in the evolution of species (<xref rid="B19" ref-type="bibr">Dunker et al., 1998</xref>; <xref rid="B49" ref-type="bibr">Liu et al., 2002</xref>; <xref rid="B25" ref-type="bibr">Fuxreiter et al., 2008</xref>; <xref rid="B70" ref-type="bibr">Pentony and Jones, 2009</xref>; <xref rid="B100" ref-type="bibr">Uversky et al., 2009</xref>; <xref rid="B8" ref-type="bibr">Brown et al., 2011</xref>; <xref rid="B90" ref-type="bibr">Schlessinger et al., 2011</xref>; <xref rid="B103" ref-type="bibr">Vicedo et al., 2015a</xref>; <xref rid="B104" ref-type="bibr">Vicedo et al., 2015b</xref>). However, the single number (fraction of IDP in proteome) was too simplistic for analyses as applied to the location spectrum based on 10-dimensional vectors representing ten different subcellular compartments. The crucial step was the prediction of non-binary CheZOD scores and the idea to bin those into a spectrum with eight bins leading to 8-dimensional vectors subjected to straightforward PCA (<xref rid="B110" ref-type="bibr">Wold et al., 1987</xref>). Surprisingly, this already revealed a connection between the micro molecular level of per-residue CheZOD score predictions and the macro level of the evolution of species (<xref rid="F6" ref-type="fig">Figure 6</xref>). Minimally, this finding suggests that adjusting—increasing or reducing - the composition of disordered residues in proteins is a tracer of or proxy for evolutionary events. Possibly, these changes might play a role in speciation. However, at this point, the latter remains speculation. Clearly, the analysis revealed another interesting simple feature relating the micro and macro level, i.e., connecting the machinery of the proteins that shape life to the carriers of these molecular machines, namely the organisms.</p>
    </sec>
  </sec>
  <sec sec-type="conclusion" id="s5">
    <title>Conclusion</title>
    <p>We introduced four relatively simple novel methods exclusively using embeddings from the protein language model ProtT5 (<xref rid="B23" ref-type="bibr">Elnaggar et al., 2021</xref>) to predict per-residue protein disorder/order as proxied by NMR derived chemical shift Z-scores (CheZOD scores (<xref rid="B61" ref-type="bibr">Nielsen and Mulder, 2020</xref>)). The best approach, dubbed SETH, captured fine-grained nuances of disorder on a continuous scale and, in our hands, appeared to outperform all compared state-of-the-art methods [(<xref rid="B60" ref-type="bibr">Nielsen and Mulder, 2019</xref>; <xref rid="B14" ref-type="bibr">Dass et al., 2020</xref>; <xref rid="B80" ref-type="bibr">Redl et al., 2022</xref>); <xref rid="F3" ref-type="fig">Figure 3</xref>]. Our solutions were so successful because the unoptimized embeddings carried important information about disorder (<xref rid="F2" ref-type="fig">Figure 2</xref>), to the extent that mostly one of the 1,024 dimensions mattered (<xref rid="s11" ref-type="sec">Supplementary Figure S6E</xref>). Since SETH exclusively uses embeddings of single protein sequences, it easily scales to the analysis of entire proteomes, e.g (dis-) order of all human proteins can be predicted in about 1 hour on a consumer-grade PC with one NVIDIA GeForce RTX 3060. Therefore, it enables large-scale analyses of disorder, which allowed us to show that CheZOD score distributions capture evolutionary information (<xref rid="F6" ref-type="fig">Figure 6</xref>). Although the break-through <italic>AlphaFold2</italic> (<xref rid="B41" ref-type="bibr">Jumper et al., 2021</xref>) 3D predictions are now available for most proteins, and although we could show that disorder measures of <italic>AlphaFold2</italic> predictions correlate with CheZOD scores, the correlation was significantly inferior to the predictions of SETH, suggesting the investment of fewer than 3 min per 1,000 proteins.</p>
  </sec>
</body>
<back>
  <ack>
    <p>Particular thanks to Keith Dunker (Indiana U) for his help in realizing the importance of the topic of IDRs and IDPs. Further thanks primarily to Tim Karl (TUM) for invaluable help with hardware and software and to Inga Weise (TUM) for crucial support with many other aspects of this work. Thanks to Maria Littmann and Michael Bernhofer (both TUM) for listening, helping and contributing their insights in discussions and thank you to Konstantin Schütze (TUM) for his input in the review process. Also, thanks to the constructive criticism from the reviewers and to Dr. Yaoqi Zhou for contributing SPOT-Disorder2 results. Last, but not least, thanks to all those who contribute toward maintaining public databases, and to all experimentalists who enabled this analysis by making their data publicly available. The manuscript has been published as a preprint (<xref rid="B37" ref-type="bibr">Ilzhoefer et al., 2022</xref>).</p>
  </ack>
  <sec sec-type="data-availability" id="s6">
    <title>Data availability statement</title>
    <p>SETH is available to download at <ext-link xlink:href="https://github.com/Rostlab/SETH" ext-link-type="uri">https://github.com/Rostlab/SETH</ext-link> and available for online execution (no setup on your machine required) at <ext-link xlink:href="https://colab.research.google.com/drive/1vDWh5YI_BPxQg0ku6CxKtSXEJ25u2wSq?usp=sharing" ext-link-type="uri">https://colab.research.google.com/drive/1vDWh5YI_BPxQg0ku6CxKtSXEJ25u2wSq?usp=sharing</ext-link>. The predictions of SETH for Swiss-Prot (<xref rid="B4" ref-type="bibr">The UniProt Consortium et al., 2021</xref>) and the human proteome are available at <ext-link xlink:href="https://doi.org/10.5281/zenodo.6673817" ext-link-type="uri">https://doi.org/10.5281/zenodo.6673817</ext-link>. The datasets presented in this study (training set: CheZOD1174 and test set: CheZOD117) can be found in online repositories: <ext-link xlink:href="https://github.com/Rostlab/SETH" ext-link-type="uri">https://github.com/Rostlab/SETH</ext-link>.</p>
  </sec>
  <sec id="s7">
    <title>Author contributions</title>
    <p>MH provided the AlphaFold2 structures (including pLDDT and implementation to derive the “Experimentally resolved” prediction), relative solvent accessibility values calculated from AlphaFold2 predictions, Embeddings, SETH’s predictions, and performed the MMSeqs2 clustering. MH also provided a draft of the code provided at <ext-link xlink:href="https://github.com/Rostlab/SETH" ext-link-type="uri">https://github.com/Rostlab/SETH</ext-link> and at <ext-link xlink:href="https://colab.research.google.com/drive/1vDWh5YI_BPxQg0ku6CxKtSXEJ25u2wSq?usp=sharing" ext-link-type="uri">https://colab.research.google.com/drive/1vDWh5YI_BPxQg0ku6CxKtSXEJ25u2wSq?usp=sharing</ext-link>, which was refined by DI. DI trained and tested all models and analyzed the data with help of MH. DI wrote the first manuscript draft and generated the figures; iteratively, MH, DI, and BR refined the manuscript. BR helped in the study planning, design and setting the focus. All authors read and approved the final manuscript.</p>
  </sec>
  <sec id="s8">
    <title>Funding</title>
    <p>This work was supported by the Bavarian Ministry of Education through funding to the TUM and by a grant from the Alexander von Humboldt foundation through the German Ministry for Research and Education (BMBF: Bundesministerium für Bildung und Forschung), by two grants from BMBF [031L0168 and program “Software Campus 2.0 (TUM) 2.0” 01IS17049] as well as by a grant from Deutsche Forschungsgemeinschaft (DFG-GZ: RO1320/4-1).</p>
  </sec>
  <sec sec-type="COI-statement" id="s9">
    <title>Conflict of interest</title>
    <p>The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p>
  </sec>
  <sec sec-type="disclaimer" id="s10">
    <title>Publisher’s note</title>
    <p>All claims expressed in this article are solely those of the authors and do not necessarily represent those of their affiliated organizations, or those of the publisher, the editors and the reviewers. Any product that may be evaluated in this article, or claim that may be made by its manufacturer, is not guaranteed or endorsed by the publisher.</p>
  </sec>
  <sec id="s11">
    <title>Supplementary material</title>
    <p>The Supplementary Material for this article can be found online at: <ext-link xlink:href="https://www.frontiersin.org/articles/10.3389/fbinf.2022.1019597/full#supplementary-material" ext-link-type="uri">https://www.frontiersin.org/articles/10.3389/fbinf.2022.1019597/full#supplementary-material</ext-link>
</p>
    <supplementary-material id="SM1" position="float" content-type="local-data">
      <media xlink:href="DataSheet1.docx">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
  <sec id="s12">
    <title>Abbreviations</title>
    <p>3D, three-dimensional, i.e., coordinates of all atoms/residues in a protein; AI, artificial intelligence; <italic>AlphaFold2</italic>: AI-based method reliably predicting protein 3D structure from MSAs (<xref rid="B41" ref-type="bibr">Jumper et al., 2021</xref>); ANN, an artificial feed-forward neural network; AUC, area under the receiver operating characteristic curve; CheZOD scores, chemical shift Z-scores from NMR (<xref rid="B60" ref-type="bibr">Nielsen and Mulder, 2019</xref>); CI, confidence interval, here typically used as the 95% CI implying an interval between ±1.96*Standard Error; CNN, convolutional neural network; ColabFold, protocol for fast execution of <italic>AlphaFold2</italic> (<xref rid="B54" ref-type="bibr">Mirdita et al., 2022</xref>); GPU, graphical processing unit; IDP, intrinsically disordered proteins (<xref rid="B18" ref-type="bibr">Dunker et al., 2013</xref>); IDR, intrinsically disordered regions (<xref rid="B18" ref-type="bibr">Dunker et al., 2013</xref>); LinReg, a linear regression model; LogReg, a logistic regression model; MSA, multiple sequence alignment; NMR, nuclear magnetic resonance; PCA, principle component analysis; PIDE, percentage pairwise sequence identity; pLDDT, predicted local distance difference test from <italic>AlphaFold2</italic> (<xref rid="B41" ref-type="bibr">Jumper et al., 2021</xref>); pLM, protein Language Model; ProtT5, particular pLM (<xref rid="B23" ref-type="bibr">Elnaggar et al., 2021</xref>); RSA, relative solvent accessible surface area of a residue; SETH, a CNN for continuous disorder prediction (our best model); SOTA, state-of-the-art; t-SNE, t-distributed stochastic neighbor embedding; ρ, Spearman correlation coefficient.</p>
  </sec>
  <ref-list>
    <title>References</title>
    <ref id="B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Akdel</surname><given-names>M.</given-names></name><name><surname>Pires</surname><given-names>D. E. V.</given-names></name><name><surname>Porta Pardo</surname><given-names>E.</given-names></name><name><surname>Jänes</surname><given-names>J.</given-names></name><name><surname>Zalevsky</surname><given-names>A. O.</given-names></name><name><surname>Mészáros</surname><given-names>B.</given-names></name><etal/></person-group> (<year>2021</year>). <article-title>A structural biology community assessment of AlphaFold 2 applications</article-title>. <comment>bioRxiv, 2021.2009.2026.461876</comment>. <pub-id pub-id-type="doi">10.1101/2021.09.26.461876</pub-id>
</mixed-citation>
    </ref>
    <ref id="B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Alley</surname><given-names>E. C.</given-names></name><name><surname>Khimulya</surname><given-names>G.</given-names></name><name><surname>Biswas</surname><given-names>S.</given-names></name><name><surname>Alquraishi</surname><given-names>M.</given-names></name><name><surname>Church</surname><given-names>G. M.</given-names></name></person-group> (<year>2019</year>). <article-title>Unified rational protein engineering with sequence-based deep representation learning</article-title>. <source>Nat. Methods</source>
<volume>16</volume>, <fpage>1315</fpage>–<lpage>1322</lpage>. <pub-id pub-id-type="doi">10.1038/s41592-019-0598-1</pub-id>
<pub-id pub-id-type="pmid">31636460</pub-id></mixed-citation>
    </ref>
    <ref id="B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Asgari</surname><given-names>E.</given-names></name><name><surname>Mofrad</surname><given-names>M. R. K.</given-names></name></person-group> (<year>2015</year>). <article-title>Continuous distributed representation of biological sequences for deep proteomics and genomics</article-title>. <source>PLOS ONE</source>
<volume>10</volume>, <fpage>e0141287</fpage>. <pub-id pub-id-type="doi">10.1371/journal.pone.0141287</pub-id>
<pub-id pub-id-type="pmid">26555596</pub-id></mixed-citation>
    </ref>
    <ref id="B5">
      <mixed-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Bepler</surname><given-names>T.</given-names></name><name><surname>Berger</surname><given-names>B.</given-names></name></person-group> (<year>2019</year>). “<article-title>Learning protein sequence embeddings using information from structure</article-title>,” in <conf-name>The International Conference on Learning Representations</conf-name>, <conf-loc>New Orleans, United States</conf-loc>. <comment><italic>arXiv:1902.08661 [cs, q-bio, stat]</italic></comment>. </mixed-citation>
    </ref>
    <ref id="B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bepler</surname><given-names>T.</given-names></name><name><surname>Berger</surname><given-names>B.</given-names></name></person-group> (<year>2021</year>). <article-title>Learning the protein language: Evolution, structure, and function</article-title>. <source>Cell. Syst.</source>
<volume>12</volume>, <fpage>654</fpage>–<lpage>669.e3</lpage>. <comment>e653</comment>. <pub-id pub-id-type="doi">10.1016/j.cels.2021.05.017</pub-id>
<pub-id pub-id-type="pmid">34139171</pub-id></mixed-citation>
    </ref>
    <ref id="B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bordin</surname><given-names>N.</given-names></name><name><surname>Sillitoe</surname><given-names>I.</given-names></name><name><surname>Nallapareddy</surname><given-names>V.</given-names></name><name><surname>Rauer</surname><given-names>C.</given-names></name><name><surname>Lam</surname><given-names>S. D.</given-names></name><name><surname>Waman</surname><given-names>V. P.</given-names></name><etal/></person-group> (<year>2022</year>). <article-title>AlphaFold2 reveals commonalities and novelties in protein structure space for 21 model organisms</article-title>. <comment>bioRxiv, 2022.2006.2002.494367</comment>. <pub-id pub-id-type="doi">10.1101/2022.06.02.494367</pub-id>
</mixed-citation>
    </ref>
    <ref id="B8">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brown</surname><given-names>C. J.</given-names></name><name><surname>Johnson</surname><given-names>A. K.</given-names></name><name><surname>Dunker</surname><given-names>A. K.</given-names></name><name><surname>Daughdrill</surname><given-names>G. W.</given-names></name></person-group> (<year>2011</year>). <article-title>Evolution and disorder</article-title>. <source>Curr. Opin. Struct. Biol.</source>
<volume>21</volume>, <fpage>441</fpage>–<lpage>446</lpage>. <pub-id pub-id-type="doi">10.1016/j.sbi.2011.02.005</pub-id>
<pub-id pub-id-type="pmid">21482101</pub-id></mixed-citation>
    </ref>
    <ref id="B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Burley</surname><given-names>S. K.</given-names></name><name><surname>Berman</surname><given-names>H. M.</given-names></name><name><surname>Bhikadiya</surname><given-names>C.</given-names></name><name><surname>Bi</surname><given-names>C.</given-names></name><name><surname>Chen</surname><given-names>L.</given-names></name><name><surname>Di Costanzo</surname><given-names>L.</given-names></name><etal/></person-group> (<year>2019</year>). <article-title>RCSB protein data bank: Biological macromolecular structures enabling research and education in fundamental biology, biomedicine, biotechnology and energy</article-title>. <source>Nucleic Acids Res.</source>
<volume>47</volume>, <fpage>D464</fpage>–<lpage>D474</lpage>. <pub-id pub-id-type="doi">10.1093/nar/gky1004</pub-id>
<pub-id pub-id-type="pmid">30357411</pub-id></mixed-citation>
    </ref>
    <ref id="B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cheng</surname><given-names>J.</given-names></name><name><surname>Sweredoski</surname><given-names>M. J.</given-names></name><name><surname>Baldi</surname><given-names>P.</given-names></name></person-group> (<year>2005</year>). <article-title>Accurate prediction of protein disordered regions by mining protein structure data</article-title>. <source>Data Min. Knowl. Discov.</source>
<volume>11</volume>, <fpage>213</fpage>–<lpage>222</lpage>. <pub-id pub-id-type="doi">10.1007/s10618-005-0001-y</pub-id>
</mixed-citation>
    </ref>
    <ref id="B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cilia</surname><given-names>E.</given-names></name><name><surname>Pancsa</surname><given-names>R.</given-names></name><name><surname>Tompa</surname><given-names>P.</given-names></name><name><surname>Lenaerts</surname><given-names>T.</given-names></name><name><surname>Vranken</surname><given-names>W. F.</given-names></name></person-group> (<year>2014</year>). <article-title>The DynaMine webserver: Predicting protein dynamics from sequence</article-title>. <source>Nucleic Acids Res.</source>
<volume>42</volume>, <fpage>W264</fpage>–<lpage>W270</lpage>. <pub-id pub-id-type="doi">10.1093/nar/gku270</pub-id>
<pub-id pub-id-type="pmid">24728994</pub-id></mixed-citation>
    </ref>
    <ref id="B12">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Connolly</surname><given-names>M. L.</given-names></name></person-group> (<year>1983</year>). <article-title>Solvent-accessible surfaces of proteins and nucleic acids</article-title>. <source>Science</source>
<volume>221</volume>, <fpage>709</fpage>–<lpage>713</lpage>. <pub-id pub-id-type="doi">10.1126/science.6879170</pub-id>
<pub-id pub-id-type="pmid">6879170</pub-id></mixed-citation>
    </ref>
    <ref id="B13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dallago</surname><given-names>C.</given-names></name><name><surname>Schütze</surname><given-names>K.</given-names></name><name><surname>Heinzinger</surname><given-names>M.</given-names></name><name><surname>Olenyi</surname><given-names>T.</given-names></name><name><surname>Littmann</surname><given-names>M.</given-names></name><name><surname>Lu</surname><given-names>A. X.</given-names></name><etal/></person-group> (<year>2021</year>). <article-title>Learned embeddings from deep learning to visualize and predict protein sets</article-title>. <source>Curr. Protoc.</source>
<volume>1</volume>, <fpage>e113</fpage>. <pub-id pub-id-type="doi">10.1002/cpz1.113</pub-id>
<pub-id pub-id-type="pmid">33961736</pub-id></mixed-citation>
    </ref>
    <ref id="B14">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dass</surname><given-names>R.</given-names></name><name><surname>Mulder</surname><given-names>F. a. A.</given-names></name><name><surname>Nielsen</surname><given-names>J. T.</given-names></name></person-group> (<year>2020</year>). <article-title>ODiNPred: Comprehensive prediction of protein order and disorder</article-title>. <source>Sci. Rep.</source>
<volume>10</volume>, <fpage>14780</fpage>. <pub-id pub-id-type="doi">10.1038/s41598-020-71716-1</pub-id>
<pub-id pub-id-type="pmid">32901090</pub-id></mixed-citation>
    </ref>
    <ref id="B15">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Deng</surname><given-names>X.</given-names></name><name><surname>Eickholt</surname><given-names>J.</given-names></name><name><surname>Cheng</surname><given-names>J.</given-names></name></person-group> (<year>2009</year>). <article-title>PreDisorder: Ab initio sequence-based prediction of protein disordered regions</article-title>. <source>BMC Bioinforma.</source>
<volume>10</volume>, <fpage>436</fpage>. <pub-id pub-id-type="doi">10.1186/1471-2105-10-436</pub-id>
</mixed-citation>
    </ref>
    <ref id="B16">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Devlin</surname><given-names>J.</given-names></name><name><surname>Chang</surname><given-names>M.-W.</given-names></name><name><surname>Lee</surname><given-names>K.</given-names></name><name><surname>Toutanova</surname><given-names>K.</given-names></name></person-group> (<year>2018</year>). <source>Bert: Pre-Training of deep bidirectional transformers for language understanding</source>. <publisher-loc>Minneapolis, Minnesota</publisher-loc>: <publisher-name>Association for Computational Linguistics</publisher-name>. </mixed-citation>
    </ref>
    <ref id="B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dosztanyi</surname><given-names>Z.</given-names></name><name><surname>Csizmok</surname><given-names>V.</given-names></name><name><surname>Tompa</surname><given-names>P.</given-names></name><name><surname>Simon</surname><given-names>I.</given-names></name></person-group> (<year>2005</year>). <article-title>IUPred: Web server for the prediction of intrinsically unstructured regions of proteins based on estimated energy content</article-title>. <source>Bioinformatics</source>
<volume>21</volume>, <fpage>3433</fpage>–<lpage>3434</lpage>. <pub-id pub-id-type="doi">10.1093/bioinformatics/bti541</pub-id>
<pub-id pub-id-type="pmid">15955779</pub-id></mixed-citation>
    </ref>
    <ref id="B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dunker</surname><given-names>A. K.</given-names></name><name><surname>Babu</surname><given-names>M. M.</given-names></name><name><surname>Barbar</surname><given-names>E.</given-names></name><name><surname>Blackledge</surname><given-names>M.</given-names></name><name><surname>Bondos</surname><given-names>S. E.</given-names></name><name><surname>Dosztányi</surname><given-names>Z.</given-names></name><etal/></person-group> (<year>2013</year>). <article-title>What’s in a name? Why these proteins are intrinsically disordered: Why these proteins are intrinsically disordered</article-title>. <source>Intrinsically Disord. Proteins</source>
<volume>1</volume>, <fpage>e24157</fpage>. <pub-id pub-id-type="doi">10.4161/idp.24157</pub-id>
<pub-id pub-id-type="pmid">28516007</pub-id></mixed-citation>
    </ref>
    <ref id="B19">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dunker</surname><given-names>A. K.</given-names></name><name><surname>Garner</surname><given-names>E.</given-names></name><name><surname>Guilliot</surname><given-names>S.</given-names></name><name><surname>Romero</surname><given-names>P.</given-names></name><name><surname>Albrecht</surname><given-names>K.</given-names></name><name><surname>Hart</surname><given-names>J.</given-names></name><etal/></person-group> (<year>1998</year>). <article-title>Protein disorder and the evolution of molecular recognition: Theory, predictions and observations</article-title>. <source>Pac. Symp. Biocomput.</source>
<volume>3</volume>, <fpage>473</fpage>–<lpage>484</lpage>. </mixed-citation>
    </ref>
    <ref id="B20">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dunker</surname><given-names>A. K.</given-names></name><name><surname>Silman</surname><given-names>I.</given-names></name><name><surname>Uversky</surname><given-names>V. N.</given-names></name><name><surname>Sussman</surname><given-names>J. L.</given-names></name></person-group> (<year>2008</year>). <article-title>Function and structure of inherently disordered proteins</article-title>. <source>Curr. Opin. Struct. Biol.</source>
<volume>18</volume>, <fpage>756</fpage>–<lpage>764</lpage>. <pub-id pub-id-type="doi">10.1016/j.sbi.2008.10.002</pub-id>
<pub-id pub-id-type="pmid">18952168</pub-id></mixed-citation>
    </ref>
    <ref id="B21">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dyson</surname><given-names>H. J.</given-names></name><name><surname>Wright</surname><given-names>P. E.</given-names></name></person-group> (<year>2005</year>). <article-title>Intrinsically unstructured proteins and their functions</article-title>. <source>Nat. Rev. Mol. Cell. Biol.</source>
<volume>6</volume>, <fpage>197</fpage>–<lpage>208</lpage>. <pub-id pub-id-type="doi">10.1038/nrm1589</pub-id>
<pub-id pub-id-type="pmid">15738986</pub-id></mixed-citation>
    </ref>
    <ref id="B22">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Efron</surname><given-names>B.</given-names></name><name><surname>Tibshirani</surname><given-names>R.</given-names></name></person-group> (<year>1991</year>). <article-title>Statistical data analysis in the computer age</article-title>. <source>Science</source>
<volume>353</volume>, <fpage>390</fpage>–<lpage>395</lpage>. <pub-id pub-id-type="doi">10.1126/science.253.5018.390</pub-id>
</mixed-citation>
    </ref>
    <ref id="B23">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Elnaggar</surname><given-names>A.</given-names></name><name><surname>Heinzinger</surname><given-names>M.</given-names></name><name><surname>Dallago</surname><given-names>C.</given-names></name><name><surname>Rihawi</surname><given-names>G.</given-names></name><name><surname>Wang</surname><given-names>Y.</given-names></name><name><surname>Jones</surname><given-names>L.</given-names></name><etal/></person-group> (<year>2021</year>). <article-title>ProtTrans: Toward understanding the language of life through self-supervised learning</article-title>. <source>IEEE Trans. Pattern Anal. Mach. Intell.</source>
<volume>44</volume> (<issue>10</issue>), <fpage>7112</fpage>–<lpage>7127</lpage>. <pub-id pub-id-type="doi">10.1109/TPAMI.2021.3095381</pub-id>
</mixed-citation>
    </ref>
    <ref id="B24">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fox</surname><given-names>N. K.</given-names></name><name><surname>Brenner</surname><given-names>S. E.</given-names></name><name><surname>Chandonia</surname><given-names>J.-M.</given-names></name></person-group> (<year>2014</year>). <article-title>SCOPe: Structural Classification of Proteins--extended, integrating SCOP and ASTRAL data and classification of new structures</article-title>. <source>Nucleic Acids Res.</source>
<volume>42</volume>, <fpage>D304</fpage>–<lpage>D309</lpage>. <pub-id pub-id-type="doi">10.1093/nar/gkt1240</pub-id>
<pub-id pub-id-type="pmid">24304899</pub-id></mixed-citation>
    </ref>
    <ref id="B25">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fuxreiter</surname><given-names>M.</given-names></name><name><surname>Tompa</surname><given-names>P.</given-names></name><name><surname>Simon</surname><given-names>I.</given-names></name><name><surname>Uversky</surname><given-names>V. N.</given-names></name><name><surname>Hansen</surname><given-names>J. C.</given-names></name><name><surname>Asturias</surname><given-names>F. J.</given-names></name></person-group> (<year>2008</year>). <article-title>Malleable machines take shape in eukaryotic transcriptional regulation</article-title>. <source>Nat. Chem. Biol.</source>
<volume>4</volume>, <fpage>728</fpage>–<lpage>737</lpage>. <pub-id pub-id-type="doi">10.1038/nchembio.127</pub-id>
<pub-id pub-id-type="pmid">19008886</pub-id></mixed-citation>
    </ref>
    <ref id="B26">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hamp</surname><given-names>T.</given-names></name><name><surname>Rost</surname><given-names>B.</given-names></name></person-group> (<year>2015</year>). <article-title>More challenges for machine-learning protein interactions</article-title>. <source>Bioinformatics</source>
<volume>31</volume>, <fpage>1521</fpage>–<lpage>1525</lpage>. <pub-id pub-id-type="doi">10.1093/bioinformatics/btu857</pub-id>
<pub-id pub-id-type="pmid">25586513</pub-id></mixed-citation>
    </ref>
    <ref id="B27">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hanson</surname><given-names>J.</given-names></name><name><surname>Paliwal</surname><given-names>K. K.</given-names></name><name><surname>Litfin</surname><given-names>T.</given-names></name><name><surname>Zhou</surname><given-names>Y.</given-names></name></person-group> (<year>2019</year>). <article-title>SPOT-Disorder2: Improved protein intrinsic disorder prediction by ensembled deep learning</article-title>. <source>Genomics, Proteomics Bioinforma.</source>
<volume>17</volume>, <fpage>645</fpage>–<lpage>656</lpage>. <pub-id pub-id-type="doi">10.1016/j.gpb.2019.01.004</pub-id>
</mixed-citation>
    </ref>
    <ref id="B28">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hanson</surname><given-names>J.</given-names></name><name><surname>Paliwal</surname><given-names>K.</given-names></name><name><surname>Zhou</surname><given-names>Y.</given-names></name></person-group> (<year>2018</year>). <article-title>Accurate single-sequence prediction of protein intrinsic disorder by an ensemble of deep recurrent and convolutional architectures</article-title>. <source>J. Chem. Inf. Model.</source>
<volume>58</volume>, <fpage>2369</fpage>–<lpage>2376</lpage>. <pub-id pub-id-type="doi">10.1021/acs.jcim.8b00636</pub-id>
<pub-id pub-id-type="pmid">30395465</pub-id></mixed-citation>
    </ref>
    <ref id="B29">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hanson</surname><given-names>J.</given-names></name><name><surname>Yang</surname><given-names>Y.</given-names></name><name><surname>Paliwal</surname><given-names>K.</given-names></name><name><surname>Zhou</surname><given-names>Y.</given-names></name></person-group> (<year>2016</year>). <article-title>Improving protein disorder prediction by deep bidirectional long short-term memory recurrent neural networks</article-title>. <source>Bioinformatics</source>
<volume>33</volume>, <fpage>685</fpage>–<lpage>692</lpage>. <pub-id pub-id-type="doi">10.1093/bioinformatics/btw678</pub-id>
</mixed-citation>
    </ref>
    <ref id="B30">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hauser</surname><given-names>M.</given-names></name><name><surname>Steinegger</surname><given-names>M.</given-names></name><name><surname>Söding</surname><given-names>J.</given-names></name></person-group> (<year>2016</year>). <article-title>MMseqs software suite for fast and deep clustering and searching of large protein sequence sets</article-title>. <source>Bioinformatics</source>
<volume>32</volume>, <fpage>1323</fpage>–<lpage>1330</lpage>. <pub-id pub-id-type="doi">10.1093/bioinformatics/btw006</pub-id>
<pub-id pub-id-type="pmid">26743509</pub-id></mixed-citation>
    </ref>
    <ref id="B31">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Heinzinger</surname><given-names>M.</given-names></name><name><surname>Elnaggar</surname><given-names>A.</given-names></name><name><surname>Wang</surname><given-names>Y.</given-names></name><name><surname>Dallago</surname><given-names>C.</given-names></name><name><surname>Nechaev</surname><given-names>D.</given-names></name><name><surname>Matthes</surname><given-names>F.</given-names></name><etal/></person-group> (<year>2019</year>). <article-title>Modeling aspects of the language of life through transfer-learning protein sequences</article-title>. <source>BMC Bioinforma.</source>
<volume>20</volume>, <fpage>723</fpage>. <pub-id pub-id-type="doi">10.1186/s12859-019-3220-8</pub-id>
</mixed-citation>
    </ref>
    <ref id="B32">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Heinzinger</surname><given-names>M.</given-names></name><name><surname>Littmann</surname><given-names>M.</given-names></name><name><surname>Sillitoe</surname><given-names>I.</given-names></name><name><surname>Bordin</surname><given-names>N.</given-names></name><name><surname>Orengo</surname><given-names>C.</given-names></name><name><surname>Rost</surname><given-names>B.</given-names></name></person-group> (<year>2021</year>). <article-title>Contrastive learning on protein embeddings enlightens midnight zone</article-title>. <source>Bioinformatics</source>
<volume>4</volume> (<issue>2</issue>), <fpage>lqac043</fpage>. <pub-id pub-id-type="doi">10.1093/nargab/lqac043</pub-id>
</mixed-citation>
    </ref>
    <ref id="B33">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hochreiter</surname><given-names>S.</given-names></name><name><surname>Schmidhuber</surname><given-names>J.</given-names></name></person-group> (<year>1997</year>). <article-title>Long short-term memory</article-title>. <source>Neural Comput.</source>
<volume>9</volume>, <fpage>1735</fpage>–<lpage>1780</lpage>. <pub-id pub-id-type="doi">10.1162/neco.1997.9.8.1735</pub-id>
<pub-id pub-id-type="pmid">9377276</pub-id></mixed-citation>
    </ref>
    <ref id="B34">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hornak</surname><given-names>V.</given-names></name><name><surname>Abel</surname><given-names>R.</given-names></name><name><surname>Okur</surname><given-names>A.</given-names></name><name><surname>Strockbine</surname><given-names>B.</given-names></name><name><surname>Roitberg</surname><given-names>A.</given-names></name><name><surname>Simmerling</surname><given-names>C.</given-names></name></person-group> (<year>2006</year>). <article-title>Comparison of multiple Amber force fields and development of improved protein backbone parameters</article-title>. <source>Proteins.</source>
<volume>65</volume>, <fpage>712</fpage>–<lpage>725</lpage>. <pub-id pub-id-type="doi">10.1002/prot.21123</pub-id>
<pub-id pub-id-type="pmid">16981200</pub-id></mixed-citation>
    </ref>
    <ref id="B35">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Howard</surname><given-names>M. J.</given-names></name></person-group> (<year>1998</year>). <article-title>Protein NMR spectroscopy</article-title>. <source>Curr. Biol.</source>
<volume>8</volume>, <fpage>R331</fpage>–<lpage>R333</lpage>. <pub-id pub-id-type="doi">10.1016/s0960-9822(98)70214-3</pub-id>
<pub-id pub-id-type="pmid">9601630</pub-id></mixed-citation>
    </ref>
    <ref id="B36">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hu</surname><given-names>G.</given-names></name><name><surname>Katuwawala</surname><given-names>A.</given-names></name><name><surname>Wang</surname><given-names>K.</given-names></name><name><surname>Wu</surname><given-names>Z.</given-names></name><name><surname>Ghadermarzi</surname><given-names>S.</given-names></name><name><surname>Gao</surname><given-names>J.</given-names></name><etal/></person-group> (<year>2021</year>). <article-title>flDPnn: Accurate intrinsic disorder prediction with putative propensities of disorder functions</article-title>. <source>Nat. Commun.</source>
<volume>12</volume>, <fpage>4438</fpage>. <pub-id pub-id-type="doi">10.1038/s41467-021-24773-7</pub-id>
<pub-id pub-id-type="pmid">34290238</pub-id></mixed-citation>
    </ref>
    <ref id="B37">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ilzhoefer</surname><given-names>D.</given-names></name><name><surname>Heinzinger</surname><given-names>M.</given-names></name><name><surname>Rost</surname><given-names>B.</given-names></name></person-group> (<year>2022</year>). <article-title>SETH predicts nuances of residue disorder from protein embeddings</article-title>. <comment>bioRxiv, 2022.2006.2023.497276</comment>. </mixed-citation>
    </ref>
    <ref id="B38">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ishida</surname><given-names>T.</given-names></name><name><surname>Kinoshita</surname><given-names>K.</given-names></name></person-group> (<year>2007</year>). <article-title>PrDOS: Prediction of disordered protein regions from amino acid sequence</article-title>. <source>Nucleic Acids Res.</source>
<volume>35</volume>, <fpage>W460</fpage>–<lpage>W464</lpage>. <pub-id pub-id-type="doi">10.1093/nar/gkm363</pub-id>
<pub-id pub-id-type="pmid">17567614</pub-id></mixed-citation>
    </ref>
    <ref id="B39">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Johnson</surname><given-names>L. S.</given-names></name><name><surname>Eddy</surname><given-names>S. R.</given-names></name><name><surname>Portugaly</surname><given-names>E.</given-names></name></person-group> (<year>2010</year>). <article-title>Hidden Markov model speed heuristic and iterative HMM search procedure</article-title>. <source>BMC Bioinforma.</source>
<volume>11</volume>, <fpage>431</fpage>. <pub-id pub-id-type="doi">10.1186/1471-2105-11-431</pub-id>
</mixed-citation>
    </ref>
    <ref id="B40">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jones</surname><given-names>D. T.</given-names></name><name><surname>Cozzetto</surname><given-names>D.</given-names></name></person-group> (<year>2015</year>). <article-title>DISOPRED3: Precise disordered region predictions with annotated protein-binding activity</article-title>. <source>Bioinformatics</source>
<volume>31</volume>, <fpage>857</fpage>–<lpage>863</lpage>. <pub-id pub-id-type="doi">10.1093/bioinformatics/btu744</pub-id>
<pub-id pub-id-type="pmid">25391399</pub-id></mixed-citation>
    </ref>
    <ref id="B41">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jumper</surname><given-names>J.</given-names></name><name><surname>Evans</surname><given-names>R.</given-names></name><name><surname>Pritzel</surname><given-names>A.</given-names></name><name><surname>Green</surname><given-names>T.</given-names></name><name><surname>Figurnov</surname><given-names>M.</given-names></name><name><surname>Ronneberger</surname><given-names>O.</given-names></name><etal/></person-group> (<year>2021</year>). <article-title>Highly accurate protein structure prediction with AlphaFold</article-title>. <source>Nature</source>
<volume>596</volume>, <fpage>583</fpage>–<lpage>589</lpage>. <pub-id pub-id-type="doi">10.1038/s41586-021-03819-2</pub-id>
<pub-id pub-id-type="pmid">34265844</pub-id></mixed-citation>
    </ref>
    <ref id="B42">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kobak</surname><given-names>D.</given-names></name><name><surname>Berens</surname><given-names>P.</given-names></name></person-group> (<year>2019</year>). <article-title>The art of using t-SNE for single-cell transcriptomics</article-title>. <source>Nat. Commun.</source>
<volume>10</volume>, <fpage>5416</fpage>. <pub-id pub-id-type="doi">10.1038/s41467-019-13056-x</pub-id>
<pub-id pub-id-type="pmid">31780648</pub-id></mixed-citation>
    </ref>
    <ref id="B43">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kozlowski</surname><given-names>L. P.</given-names></name><name><surname>Bujnicki</surname><given-names>J. M.</given-names></name></person-group> (<year>2012</year>). <article-title>MetaDisorder: A meta-server for the prediction of intrinsic disorder in proteins</article-title>. <source>BMC Bioinforma.</source>
<volume>13</volume>, <fpage>111</fpage>. <pub-id pub-id-type="doi">10.1186/1471-2105-13-111</pub-id>
</mixed-citation>
    </ref>
    <ref id="B44">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lange</surname><given-names>J.</given-names></name><name><surname>Wyrwicz</surname><given-names>L. S.</given-names></name><name><surname>Vriend</surname><given-names>G.</given-names></name></person-group> (<year>2016</year>). <article-title>Kmad: Knowledge-based multiple sequence alignment for intrinsically disordered proteins</article-title>. <source>Bioinformatics</source>
<volume>32</volume>, <fpage>932</fpage>–<lpage>936</lpage>. <pub-id pub-id-type="doi">10.1093/bioinformatics/btv663</pub-id>
<pub-id pub-id-type="pmid">26568635</pub-id></mixed-citation>
    </ref>
    <ref id="B45">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Linding</surname><given-names>R.</given-names></name><name><surname>Russell</surname><given-names>R. B.</given-names></name><name><surname>Neduva</surname><given-names>V.</given-names></name><name><surname>Gibson</surname><given-names>T. J.</given-names></name></person-group> (<year>2003</year>). <article-title>GlobPlot: Exploring protein sequences for globularity and disorder</article-title>. <source>Nucleic Acids Res.</source>
<volume>31</volume>, <fpage>3701</fpage>–<lpage>3708</lpage>. <pub-id pub-id-type="doi">10.1093/nar/gkg519</pub-id>
<pub-id pub-id-type="pmid">12824398</pub-id></mixed-citation>
    </ref>
    <ref id="B46">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Littmann</surname><given-names>M.</given-names></name><name><surname>Bordin</surname><given-names>N.</given-names></name><name><surname>Heinzinger</surname><given-names>M.</given-names></name><name><surname>Schütze</surname><given-names>K.</given-names></name><name><surname>Dallago</surname><given-names>C.</given-names></name><name><surname>Orengo</surname><given-names>C.</given-names></name><etal/></person-group> (<year>2021a</year>). <article-title>Clustering FunFams using sequence embeddings improves EC purity</article-title>. <source>Bioinformatics</source>
<volume>37</volume>, <fpage>3449</fpage>–<lpage>3455</lpage>. <pub-id pub-id-type="doi">10.1093/bioinformatics/btab371</pub-id>
</mixed-citation>
    </ref>
    <ref id="B47">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Littmann</surname><given-names>M.</given-names></name><name><surname>Heinzinger</surname><given-names>M.</given-names></name><name><surname>Dallago</surname><given-names>C.</given-names></name><name><surname>Olenyi</surname><given-names>T.</given-names></name><name><surname>Rost</surname><given-names>B.</given-names></name></person-group> (<year>2021b</year>). <article-title>Embeddings from deep learning transfer GO annotations beyond homology</article-title>. <source>Sci. Rep.</source>
<volume>11</volume>, <fpage>1160</fpage>. <pub-id pub-id-type="doi">10.1038/s41598-020-80786-0</pub-id>
<pub-id pub-id-type="pmid">33441905</pub-id></mixed-citation>
    </ref>
    <ref id="B48">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Littmann</surname><given-names>M.</given-names></name><name><surname>Heinzinger</surname><given-names>M.</given-names></name><name><surname>Dallago</surname><given-names>C.</given-names></name><name><surname>Weissenow</surname><given-names>K.</given-names></name><name><surname>Rost</surname><given-names>B.</given-names></name></person-group> (<year>2021c</year>). <article-title>Protein embeddings and deep learning predict binding residues for various ligand classes</article-title>. <source>Sci. Rep.</source>
<volume>11</volume>, <fpage>23916</fpage>. <pub-id pub-id-type="doi">10.1038/s41598-021-03431-4</pub-id>
<pub-id pub-id-type="pmid">34903827</pub-id></mixed-citation>
    </ref>
    <ref id="B49">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>J.</given-names></name><name><surname>Tan</surname><given-names>H.</given-names></name><name><surname>Rost</surname><given-names>B.</given-names></name></person-group> (<year>2002</year>). <article-title>Loopy proteins appear conserved in evolution</article-title>. <source>J. Mol. Biol.</source>
<volume>322</volume>, <fpage>53</fpage>–<lpage>64</lpage>. <pub-id pub-id-type="doi">10.1016/s0022-2836(02)00736-2</pub-id>
<pub-id pub-id-type="pmid">12215414</pub-id></mixed-citation>
    </ref>
    <ref id="B50">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Marot-Lassauzaie</surname><given-names>V.</given-names></name><name><surname>Goldberg</surname><given-names>T.</given-names></name><name><surname>Armenteros</surname><given-names>J. J. A.</given-names></name><name><surname>Nielsen</surname><given-names>H.</given-names></name><name><surname>Rost</surname><given-names>B.</given-names></name></person-group> (<year>2021</year>). <article-title>Spectrum of protein location in proteomes captures evolutionary relationship between species</article-title>. <source>J. Mol. Evol.</source>
<volume>89</volume>, <fpage>544</fpage>–<lpage>553</lpage>. <pub-id pub-id-type="doi">10.1007/s00239-021-10022-4</pub-id>
<pub-id pub-id-type="pmid">34328525</pub-id></mixed-citation>
    </ref>
    <ref id="B51">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Marquet</surname><given-names>C.</given-names></name><name><surname>Heinzinger</surname><given-names>M.</given-names></name><name><surname>Olenyi</surname><given-names>T.</given-names></name><name><surname>Dallago</surname><given-names>C.</given-names></name><name><surname>Erckert</surname><given-names>K.</given-names></name><name><surname>Bernhofer</surname><given-names>M.</given-names></name><etal/></person-group> (<year>2021</year>). <article-title>Embeddings from protein language models predict conservation and variant effects</article-title>. <source>Hum. Genet.</source>
<pub-id pub-id-type="doi">10.1007/s00439-021-02411-y</pub-id>
</mixed-citation>
    </ref>
    <ref id="B52">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Marx</surname><given-names>V.</given-names></name></person-group> (<year>2022</year>). <article-title>Method of the year: Protein structure prediction</article-title>. <source>Nat. Methods</source>
<volume>19</volume>, <fpage>5</fpage>–<lpage>10</lpage>. <pub-id pub-id-type="doi">10.1038/s41592-021-01359-1</pub-id>
<pub-id pub-id-type="pmid">35017741</pub-id></mixed-citation>
    </ref>
    <ref id="B53">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mirabello</surname><given-names>C.</given-names></name><name><surname>Wallner</surname><given-names>B.</given-names></name></person-group> (<year>2019</year>). <article-title>rawMSA: End-to-end deep learning using raw multiple sequence alignments</article-title>. <source>PLOS ONE</source>
<volume>14</volume>, <fpage>e0220182</fpage>. <pub-id pub-id-type="doi">10.1371/journal.pone.0220182</pub-id>
<pub-id pub-id-type="pmid">31415569</pub-id></mixed-citation>
    </ref>
    <ref id="B54">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mirdita</surname><given-names>M.</given-names></name><name><surname>Schütze</surname><given-names>K.</given-names></name><name><surname>Moriwaki</surname><given-names>Y.</given-names></name><name><surname>Heo</surname><given-names>L.</given-names></name><name><surname>Ovchinnikov</surname><given-names>S.</given-names></name><name><surname>Steinegger</surname><given-names>M.</given-names></name></person-group> (<year>2022</year>). <article-title>ColabFold - making protein folding accessible to all</article-title>. <comment>bioRxiv, 2021.2008.2015.456425</comment>. </mixed-citation>
    </ref>
    <ref id="B55">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mirdita</surname><given-names>M.</given-names></name><name><surname>Von den driesch</surname><given-names>L.</given-names></name><name><surname>Galiez</surname><given-names>C.</given-names></name><name><surname>Martin</surname><given-names>M. J.</given-names></name><name><surname>Söding</surname><given-names>J.</given-names></name><name><surname>Steinegger</surname><given-names>M.</given-names></name></person-group> (<year>2017</year>). <article-title>Uniclust databases of clustered and deeply annotated protein sequences and alignments</article-title>. <source>Nucleic Acids Res.</source>
<volume>45</volume>, <fpage>D170</fpage>–<lpage>D176</lpage>. <pub-id pub-id-type="doi">10.1093/nar/gkw1081</pub-id>
<pub-id pub-id-type="pmid">27899574</pub-id></mixed-citation>
    </ref>
    <ref id="B56">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mizianty</surname><given-names>M. J.</given-names></name><name><surname>Peng</surname><given-names>Z.</given-names></name><name><surname>Kurgan</surname><given-names>L.</given-names></name></person-group> (<year>2013</year>). <article-title>MFDp2: Accurate predictor of disorder in proteins by fusion of disorder probabilities, content and profiles</article-title>. <source>Intrinsically Disord. Proteins</source>
<volume>1</volume>, <fpage>e24428</fpage>. <pub-id pub-id-type="doi">10.4161/idp.24428</pub-id>
<pub-id pub-id-type="pmid">28516009</pub-id></mixed-citation>
    </ref>
    <ref id="B57">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Monastyrskyy</surname><given-names>B.</given-names></name><name><surname>Kryshtafovych</surname><given-names>A.</given-names></name><name><surname>Moult</surname><given-names>J.</given-names></name><name><surname>Tramontano</surname><given-names>A.</given-names></name><name><surname>Fidelis</surname><given-names>K.</given-names></name></person-group> (<year>2014</year>). <article-title>Assessment of protein disorder region predictions in CASP10</article-title>. <source>Proteins.</source>
<volume>82</volume>, <fpage>127</fpage>–<lpage>137</lpage>. <pub-id pub-id-type="doi">10.1002/prot.24391</pub-id>
<pub-id pub-id-type="pmid">23946100</pub-id></mixed-citation>
    </ref>
    <ref id="B58">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Monzon</surname><given-names>V.</given-names></name><name><surname>Haft</surname><given-names>D. H.</given-names></name><name><surname>Bateman</surname><given-names>A.</given-names></name></person-group> (<year>2022</year>). <article-title>Folding the unfoldable: Using AlphaFold to explore spurious proteins</article-title>. <source>Bioinforma. Adv.</source>
<volume>2</volume>, <fpage>vbab043</fpage>. <pub-id pub-id-type="doi">10.1093/bioadv/vbab043</pub-id>
</mixed-citation>
    </ref>
    <ref id="B59">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Necci</surname><given-names>M.</given-names></name><name><surname>Piovesan</surname><given-names>D.</given-names></name><name><surname>Predictors</surname><given-names>C.</given-names></name><name><surname>Disprot</surname><given-names>C.</given-names></name><name><surname>Tosatto</surname><given-names>S. C. E.</given-names></name></person-group> (<year>2021</year>). <article-title>Critical assessment of protein intrinsic disorder prediction</article-title>. <source>Nat. Methods</source>
<volume>18</volume>, <fpage>472</fpage>–<lpage>481</lpage>. <pub-id pub-id-type="doi">10.1038/s41592-021-01117-3</pub-id>
<pub-id pub-id-type="pmid">33875885</pub-id></mixed-citation>
    </ref>
    <ref id="B60">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nielsen</surname><given-names>J. T.</given-names></name><name><surname>Mulder</surname><given-names>F. a. A.</given-names></name></person-group> (<year>2019</year>). <article-title>Quality and bias of protein disorder predictors</article-title>. <source>Sci. Rep.</source>
<volume>9</volume>, <fpage>5137</fpage>. <pub-id pub-id-type="doi">10.1038/s41598-019-41644-w</pub-id>
<pub-id pub-id-type="pmid">30914747</pub-id></mixed-citation>
    </ref>
    <ref id="B61">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Nielsen</surname><given-names>J. T.</given-names></name><name><surname>Mulder</surname><given-names>F. a. A.</given-names></name></person-group> (<year>2020</year>). “<article-title>Quantitative protein disorder assessment using NMR chemical shifts</article-title>,” in <source>Intrinsically disordered proteins</source>. Editors <person-group person-group-type="editor"><name><surname>Kragelund</surname><given-names>B. B.</given-names></name><name><surname>Skriver</surname><given-names>K.</given-names></name></person-group> (<publisher-loc>New York, NY</publisher-loc>: <publisher-name>Springer US</publisher-name>), <fpage>303</fpage>–<lpage>317</lpage>. </mixed-citation>
    </ref>
    <ref id="B62">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nielsen</surname><given-names>J. T.</given-names></name><name><surname>Mulder</surname><given-names>F. a. A.</given-names></name></person-group> (<year>2016</year>). <article-title>There is diversity in disorder—“In all chaos there is a cosmos, in all disorder a secret order”</article-title>. <source>Front. Mol. Biosci.</source>
<volume>3</volume>, <fpage>4</fpage>. <pub-id pub-id-type="doi">10.3389/fmolb.2016.00004</pub-id>
<pub-id pub-id-type="pmid">26904549</pub-id></mixed-citation>
    </ref>
    <ref id="B63">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nwanochie</surname><given-names>E.</given-names></name><name><surname>Uversky</surname><given-names>V. N.</given-names></name></person-group> (<year>2019</year>). <article-title>Structure determination by single-particle cryo-electron microscopy: Only the sky (and intrinsic disorder) is the limit</article-title>. <source>Int. J. Mol. Sci.</source>
<volume>20</volume>, <fpage>4186</fpage>. <pub-id pub-id-type="doi">10.3390/ijms20174186</pub-id>
</mixed-citation>
    </ref>
    <ref id="B64">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ofer</surname><given-names>D.</given-names></name><name><surname>Brandes</surname><given-names>N.</given-names></name><name><surname>Linial</surname><given-names>M.</given-names></name></person-group> (<year>2021</year>). <article-title>the language of proteins: NLP, machine learning &amp; protein sequences</article-title>. <source>Comput. Struct. Biotechnol. J.</source>
<volume>19</volume>, <fpage>1750</fpage>–<lpage>1758</lpage>. <pub-id pub-id-type="doi">10.1016/j.csbj.2021.03.022</pub-id>
<pub-id pub-id-type="pmid">33897979</pub-id></mixed-citation>
    </ref>
    <ref id="B65">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oldfield</surname><given-names>C. J.</given-names></name><name><surname>Xue</surname><given-names>B.</given-names></name><name><surname>Van</surname><given-names>Y.-Y.</given-names></name><name><surname>Ulrich</surname><given-names>E. L.</given-names></name><name><surname>Markley</surname><given-names>J. L.</given-names></name><name><surname>Dunker</surname><given-names>A. K.</given-names></name><etal/></person-group> (<year>2013</year>). <article-title>Utilization of protein intrinsic disorder knowledge in structural proteomics</article-title>. <source>Biochimica Biophysica Acta - Proteins Proteomics</source>
<volume>1834</volume>, <fpage>487</fpage>–<lpage>498</lpage>. <pub-id pub-id-type="doi">10.1016/j.bbapap.2012.12.003</pub-id>
</mixed-citation>
    </ref>
    <ref id="B66">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Park</surname><given-names>Y.</given-names></name><name><surname>Marcotte</surname><given-names>E. M.</given-names></name></person-group> (<year>2012</year>). <article-title>Flaws in evaluation schemes for pair-input computational predictions</article-title>. <source>Nat. Methods</source>
<volume>9</volume>, <fpage>1134</fpage>–<lpage>1136</lpage>. <pub-id pub-id-type="doi">10.1038/nmeth.2259</pub-id>
<pub-id pub-id-type="pmid">23223166</pub-id></mixed-citation>
    </ref>
    <ref id="B67">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Paszke</surname><given-names>A.</given-names></name><name><surname>Gross</surname><given-names>S.</given-names></name><name><surname>Massa</surname><given-names>F.</given-names></name><name><surname>Lerer</surname><given-names>A.</given-names></name><name><surname>Bradbury</surname><given-names>J.</given-names></name><name><surname>Chanan</surname><given-names>G.</given-names></name><etal/></person-group> (<year>2019</year>). in <source>PyTorch: An imperative style, high-performance deep learning library</source>. Editors <person-group person-group-type="editor"><name><surname>Wallach</surname><given-names>H.</given-names></name><name><surname>Larochelle</surname><given-names>H.</given-names></name><name><surname>Beygelzimer</surname><given-names>A.</given-names></name><name><surname>Alché-Buc</surname><given-names>F. D.</given-names></name><name><surname>Fox</surname><given-names>E.</given-names></name><name><surname>Garnett</surname><given-names>R.</given-names></name></person-group> (<publisher-loc>New York</publisher-loc>: <publisher-name>Curran Associates, Inc</publisher-name>). </mixed-citation>
    </ref>
    <ref id="B68">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pedregosa</surname><given-names>F.</given-names></name><name><surname>Varoquaux</surname><given-names>G.</given-names></name><name><surname>Gramfort</surname><given-names>A.</given-names></name><name><surname>Michel</surname><given-names>V.</given-names></name><name><surname>Thirion</surname><given-names>B.</given-names></name><name><surname>Grisel</surname><given-names>O.</given-names></name><etal/></person-group> (<year>2011</year>). <article-title>Scikit-learn: Machine learning in Python</article-title>. <source>J. Mach. Learn. Res.</source>
<volume>12</volume>, <fpage>2825</fpage>–<lpage>2830</lpage>. </mixed-citation>
    </ref>
    <ref id="B69">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Peng</surname><given-names>K.</given-names></name><name><surname>Vucetic</surname><given-names>S.</given-names></name><name><surname>Radivojac</surname><given-names>P.</given-names></name><name><surname>Brown</surname><given-names>C. J.</given-names></name><name><surname>Dunker</surname><given-names>A. K.</given-names></name><name><surname>Obradovic</surname><given-names>Z.</given-names></name></person-group> (<year>2005</year>). <article-title>Optimizing long intrinsic disorder predictors with protein evolutionary information</article-title>. <source>J. Bioinform. Comput. Biol.</source>
<volume>3</volume>, <fpage>35</fpage>–<lpage>60</lpage>. <pub-id pub-id-type="doi">10.1142/s0219720005000886</pub-id>
<pub-id pub-id-type="pmid">15751111</pub-id></mixed-citation>
    </ref>
    <ref id="B70">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pentony</surname><given-names>M. M.</given-names></name><name><surname>Jones</surname><given-names>D. T.</given-names></name></person-group> (<year>2009</year>). <article-title>Modularity of intrinsic disorder in the human proteome</article-title>. <source>Proteins.</source>
<volume>78</volume>, <fpage>212</fpage>–<lpage>221</lpage>. <pub-id pub-id-type="doi">10.1002/prot.22504</pub-id>
</mixed-citation>
    </ref>
    <ref id="B71">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Peters</surname><given-names>M. E.</given-names></name><name><surname>Neumann</surname><given-names>M.</given-names></name><name><surname>Iyyer</surname><given-names>M.</given-names></name><name><surname>Gardner</surname><given-names>M.</given-names></name><name><surname>Clark</surname><given-names>C.</given-names></name><name><surname>Lee</surname><given-names>K.</given-names></name><etal/></person-group> (<year>2018</year>). <source>Deep contextualized word representations</source>. <publisher-loc>New Orleans, Louisiana</publisher-loc>: <publisher-name>Association for Computational Linguistics</publisher-name>. </mixed-citation>
    </ref>
    <ref id="B72">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Piovesan</surname><given-names>D.</given-names></name><name><surname>Monzon</surname><given-names>A. M.</given-names></name><name><surname>Tosatto</surname><given-names>S. C. E.</given-names></name></person-group> (<year>2022</year>). <article-title>Intrinsic protein disorder, conditional folding and AlphaFold2</article-title>. <source>bioRxiv</source> [<comment>Preprint</comment>]. <comment>Available at: <ext-link xlink:href="https://www.biorxiv.org/content/10.1101/2022.03.03.482768v1" ext-link-type="uri">https://www.biorxiv.org/content/10.1101/2022.03.03.482768v1</ext-link>
</comment>. </mixed-citation>
    </ref>
    <ref id="B73">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Prilusky</surname><given-names>J.</given-names></name><name><surname>Felder</surname><given-names>C. E.</given-names></name><name><surname>Zeev-Ben-Mordehai</surname><given-names>T.</given-names></name><name><surname>Rydberg</surname><given-names>E. H.</given-names></name><name><surname>Man</surname><given-names>O.</given-names></name><name><surname>Beckmann</surname><given-names>J. S.</given-names></name><etal/></person-group> (<year>2005</year>). <article-title>FoldIndex(C): A simple tool to predict whether a given protein sequence is intrinsically unfolded</article-title>. <source>Bioinformatics</source>
<volume>21</volume>, <fpage>3435</fpage>–<lpage>3438</lpage>. <pub-id pub-id-type="doi">10.1093/bioinformatics/bti537</pub-id>
<pub-id pub-id-type="pmid">15955783</pub-id></mixed-citation>
    </ref>
    <ref id="B74">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Quaglia</surname><given-names>F.</given-names></name><name><surname>Mészáros</surname><given-names>B.</given-names></name><name><surname>Salladini</surname><given-names>E.</given-names></name><name><surname>Hatos</surname><given-names>A.</given-names></name><name><surname>Pancsa</surname><given-names>R.</given-names></name><name><surname>Chemes</surname><given-names>L. B.</given-names></name><etal/></person-group> (<year>2022</year>). <article-title>DisProt in 2022: Improved quality and accessibility of protein intrinsic disorder annotation</article-title>. <source>Nucleic Acids Res.</source>
<volume>50</volume>, <fpage>D480</fpage>–<lpage>D487</lpage>. <pub-id pub-id-type="doi">10.1093/nar/gkab1082</pub-id>
<pub-id pub-id-type="pmid">34850135</pub-id></mixed-citation>
    </ref>
    <ref id="B75">
      <mixed-citation publication-type="journal"><collab>R Core Team</collab> (<year>2021</year>). <article-title>R: A language and environment for statistical computing</article-title>. <source>MSOR Connect.</source>
<volume>1</volume>. </mixed-citation>
    </ref>
    <ref id="B76">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Radivojac</surname><given-names>P.</given-names></name><name><surname>Obradovic</surname><given-names>Z.</given-names></name><name><surname>Brown</surname><given-names>C. J.</given-names></name><name><surname>Dunker</surname><given-names>A. K.</given-names></name></person-group> (<year>2002</year>). “<article-title>Improving sequence alignments for intrinsically disordered proteins</article-title>,” in <source>Pacific symposium on biocomputing. Pacific symposium on biocomputing</source>. <publisher-loc>Lihue, HI, United States</publisher-loc>: <publisher-name>WorldScientific</publisher-name>, <fpage>589</fpage>–<lpage>600</lpage>. </mixed-citation>
    </ref>
    <ref id="B77">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Radivojac</surname><given-names>P.</given-names></name><name><surname>Obradovic</surname><given-names>Z.</given-names></name><name><surname>Smith</surname><given-names>D. K.</given-names></name><name><surname>Zhu</surname><given-names>G.</given-names></name><name><surname>Vucetic</surname><given-names>S.</given-names></name><name><surname>Brown</surname><given-names>C. J.</given-names></name><etal/></person-group> (<year>2004</year>). <article-title>Protein flexibility and intrinsic disorder</article-title>. <source>Protein Sci.</source>
<volume>13</volume>, <fpage>71</fpage>–<lpage>80</lpage>. <pub-id pub-id-type="doi">10.1110/ps.03128904</pub-id>
<pub-id pub-id-type="pmid">14691223</pub-id></mixed-citation>
    </ref>
    <ref id="B78">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Raffel</surname><given-names>C.</given-names></name><name><surname>Shazeer</surname><given-names>N.</given-names></name><name><surname>Roberts</surname><given-names>A.</given-names></name><name><surname>Lee</surname><given-names>K.</given-names></name><name><surname>Narang</surname><given-names>S.</given-names></name><name><surname>Matena</surname><given-names>M.</given-names></name><etal/></person-group> (<year>2020</year>). <source>Exploring the limits of transfer learning with a unified text-to-text transformer</source>. <publisher-name>Journal of Machine Learning Research</publisher-name>. <comment><italic>arXiv</italic></comment>. </mixed-citation>
    </ref>
    <ref id="B79">
      <mixed-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Reddi</surname><given-names>S. J.</given-names></name><name><surname>Kale</surname><given-names>S.</given-names></name><name><surname>Kumar</surname><given-names>S.</given-names></name></person-group> (<year>2018</year>). “<article-title>On the convergence of Adam and beyond</article-title>,” in <conf-name>The International Conference on Learning Representations</conf-name>, <conf-loc>Vancouver, BC, Canada</conf-loc>. </mixed-citation>
    </ref>
    <ref id="B80">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Redl</surname><given-names>I.</given-names></name><name><surname>Fisicaro</surname><given-names>C.</given-names></name><name><surname>Dutton</surname><given-names>O.</given-names></name><name><surname>Hoffmann</surname><given-names>F.</given-names></name><name><surname>Henderson</surname><given-names>L.</given-names></name><name><surname>Owens</surname><given-names>B. M. J.</given-names></name><etal/></person-group> (<year>2022</year>). <article-title>Adopt: Intrinsic protein disorder prediction through deep bidirectional transformers</article-title>. <comment>bioRxiv, 2022.2005.2025.493416</comment>. </mixed-citation>
    </ref>
    <ref id="B81">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Remmert</surname><given-names>M.</given-names></name><name><surname>Biegert</surname><given-names>A.</given-names></name><name><surname>Hauser</surname><given-names>A.</given-names></name><name><surname>Soding</surname><given-names>J.</given-names></name></person-group> (<year>2012</year>). <article-title>HHblits: Lightning-fast iterative protein sequence searching by HMM-HMM alignment</article-title>. <source>Nat. Methods</source>
<volume>9</volume>, <fpage>173</fpage>–<lpage>175</lpage>. <pub-id pub-id-type="doi">10.1038/nmeth.1818</pub-id>
</mixed-citation>
    </ref>
    <ref id="B82">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rives</surname><given-names>A.</given-names></name><name><surname>Meier</surname><given-names>J.</given-names></name><name><surname>Sercu</surname><given-names>T.</given-names></name><name><surname>Goyal</surname><given-names>S.</given-names></name><name><surname>Lin</surname><given-names>Z.</given-names></name><name><surname>Liu</surname><given-names>J.</given-names></name><etal/></person-group> (<year>2021</year>). <article-title>Biological structure and function emerge from scaling unsupervised learning to 250 million protein sequences</article-title>. <source>Proc. Natl. Acad. Sci. U. S. A.</source>
<volume>118</volume>, <fpage>e2016239118</fpage>. <pub-id pub-id-type="doi">10.1073/pnas.2016239118</pub-id>
<pub-id pub-id-type="pmid">33876751</pub-id></mixed-citation>
    </ref>
    <ref id="B83">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Romero</surname><given-names>P.</given-names></name><name><surname>Obradovic</surname><given-names>Z.</given-names></name><name><surname>Kissinger</surname><given-names>C. R.</given-names></name><name><surname>Villafranca</surname><given-names>J. E.</given-names></name><name><surname>Garner</surname><given-names>E.</given-names></name><name><surname>Guilliot</surname><given-names>S.</given-names></name><etal/></person-group> (<year>1998</year>). “<article-title>Thousands of proteins likely to have long disordered regions Pacific Symposium on Biocomputing</article-title>,” in <source>Pacific symposium on biocomputing</source>. <publisher-loc>Kapalua, Maui, Hawaii</publisher-loc>: <publisher-name>WorldScientific</publisher-name>, <fpage>437</fpage>–<lpage>448</lpage>. </mixed-citation>
    </ref>
    <ref id="B84">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rost</surname><given-names>B.</given-names></name><name><surname>Sander</surname><given-names>C.</given-names></name></person-group> (<year>1994</year>). <article-title>Conservation and prediction of solvent accessibility in protein families</article-title>. <source>Proteins.</source>
<volume>20</volume>, <fpage>216</fpage>–<lpage>226</lpage>. <pub-id pub-id-type="doi">10.1002/prot.340200303</pub-id>
<pub-id pub-id-type="pmid">7892171</pub-id></mixed-citation>
    </ref>
    <ref id="B85">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rost</surname><given-names>B.</given-names></name><name><surname>Sander</surname><given-names>C.</given-names></name></person-group> (<year>1993</year>). <article-title>Prediction of protein secondary structure at better than 70% accuracy</article-title>. <source>J. Mol. Biol.</source>
<volume>232</volume>, <fpage>584</fpage>–<lpage>599</lpage>. <pub-id pub-id-type="doi">10.1006/jmbi.1993.1413</pub-id>
<pub-id pub-id-type="pmid">8345525</pub-id></mixed-citation>
    </ref>
    <ref id="B86">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rost</surname><given-names>B.</given-names></name></person-group> (<year>1999</year>). <article-title>Twilight zone of protein sequence alignments</article-title>. <source>Protein Eng. Des. Sel.</source>
<volume>12</volume>, <fpage>85</fpage>–<lpage>94</lpage>. <pub-id pub-id-type="doi">10.1093/protein/12.2.85</pub-id>
</mixed-citation>
    </ref>
    <ref id="B87">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schlessinger</surname><given-names>A.</given-names></name><name><surname>Liu</surname><given-names>J.</given-names></name><name><surname>Rost</surname><given-names>B.</given-names></name></person-group> (<year>2007a</year>). <article-title>Natively unstructured loops differ from other loops</article-title>. <source>PLoS Comput. Biol.</source>
<volume>3</volume>, <fpage>e140</fpage>. <pub-id pub-id-type="doi">10.1371/journal.pcbi.0030140.eor</pub-id>
<pub-id pub-id-type="pmid">17658943</pub-id></mixed-citation>
    </ref>
    <ref id="B88">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schlessinger</surname><given-names>A.</given-names></name><name><surname>Punta</surname><given-names>M.</given-names></name><name><surname>Rost</surname><given-names>B.</given-names></name></person-group> (<year>2007b</year>). <article-title>Natively unstructured regions in proteins identified from contact predictions</article-title>. <source>Bioinformatics</source>
<volume>23</volume>, <fpage>2376</fpage>–<lpage>2384</lpage>. <pub-id pub-id-type="doi">10.1093/bioinformatics/btm349</pub-id>
<pub-id pub-id-type="pmid">17709338</pub-id></mixed-citation>
    </ref>
    <ref id="B89">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schlessinger</surname><given-names>A.</given-names></name><name><surname>Punta</surname><given-names>M.</given-names></name><name><surname>Yachdav</surname><given-names>G.</given-names></name><name><surname>Kajan</surname><given-names>L.</given-names></name><name><surname>Rost</surname><given-names>B.</given-names></name></person-group> (<year>2009</year>). <article-title>Improved disorder prediction by combination of orthogonal approaches</article-title>. <source>PLoS ONE</source>
<volume>4</volume>, <fpage>e4433</fpage>. <pub-id pub-id-type="doi">10.1371/journal.pone.0004433</pub-id>
<pub-id pub-id-type="pmid">19209228</pub-id></mixed-citation>
    </ref>
    <ref id="B90">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schlessinger</surname><given-names>A.</given-names></name><name><surname>Schaefer</surname><given-names>C.</given-names></name><name><surname>Vicedo</surname><given-names>E.</given-names></name><name><surname>Schmidberger</surname><given-names>M.</given-names></name><name><surname>Punta</surname><given-names>M.</given-names></name><name><surname>Rost</surname><given-names>B.</given-names></name></person-group> (<year>2011</year>). <article-title>Protein disorder—A breakthrough invention of evolution?</article-title>
<source>Curr. Opin. Struct. Biol.</source>
<volume>21</volume>, <fpage>412</fpage>–<lpage>418</lpage>. <pub-id pub-id-type="doi">10.1016/j.sbi.2011.03.014</pub-id>
<pub-id pub-id-type="pmid">21514145</pub-id></mixed-citation>
    </ref>
    <ref id="B91">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sormanni</surname><given-names>P.</given-names></name><name><surname>Camilloni</surname><given-names>C.</given-names></name><name><surname>Fariselli</surname><given-names>P.</given-names></name><name><surname>Vendruscolo</surname><given-names>M.</given-names></name></person-group> (<year>2015</year>). <article-title>The s2D method: Simultaneous sequence-based prediction of the statistical populations of ordered and disordered regions in proteins</article-title>. <source>J. Mol. Biol.</source>
<volume>427</volume>, <fpage>982</fpage>–<lpage>996</lpage>. <pub-id pub-id-type="doi">10.1016/j.jmb.2014.12.007</pub-id>
<pub-id pub-id-type="pmid">25534081</pub-id></mixed-citation>
    </ref>
    <ref id="B92">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Steinegger</surname><given-names>M.</given-names></name><name><surname>Mirdita</surname><given-names>M.</given-names></name><name><surname>Söding</surname><given-names>J.</given-names></name></person-group> (<year>2019</year>). <article-title>Protein-level assembly increases protein sequence recovery from metagenomic samples manyfold</article-title>. <source>Nat. Methods</source>
<volume>16</volume>, <fpage>603</fpage>–<lpage>606</lpage>. <pub-id pub-id-type="doi">10.1038/s41592-019-0437-4</pub-id>
<pub-id pub-id-type="pmid">31235882</pub-id></mixed-citation>
    </ref>
    <ref id="B93">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Steinegger</surname><given-names>M.</given-names></name><name><surname>Söding</surname><given-names>J.</given-names></name></person-group> (<year>2018</year>). <article-title>Clustering huge protein sequence sets in linear time</article-title>. <source>Nat. Commun.</source>
<volume>9</volume>, <fpage>2542</fpage>. <pub-id pub-id-type="doi">10.1038/s41467-018-04964-5</pub-id>
<pub-id pub-id-type="pmid">29959318</pub-id></mixed-citation>
    </ref>
    <ref id="B94">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Steinegger</surname><given-names>M.</given-names></name><name><surname>Söding</surname><given-names>J.</given-names></name></person-group> (<year>2017</year>). <article-title>MMseqs2 enables sensitive protein sequence searching for the analysis of massive data sets</article-title>. <source>Nat. Biotechnol.</source>
<volume>35</volume>, <fpage>1026</fpage>–<lpage>1028</lpage>. <pub-id pub-id-type="doi">10.1038/nbt.3988</pub-id>
<pub-id pub-id-type="pmid">29035372</pub-id></mixed-citation>
    </ref>
    <ref id="B95">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Suzek</surname><given-names>B. E.</given-names></name><name><surname>Wang</surname><given-names>Y.</given-names></name><name><surname>Huang</surname><given-names>H.</given-names></name><name><surname>Mcgarvey</surname><given-names>P. B.</given-names></name><name><surname>Wu</surname><given-names>C. H.</given-names></name><name><surname>Consortium</surname><given-names>U.</given-names></name></person-group> (<year>2015</year>). <article-title>UniRef clusters: A comprehensive and scalable alternative for improving sequence similarity searches</article-title>. <source>Bioinformatics</source>
<volume>31</volume>, <fpage>926</fpage>–<lpage>932</lpage>. <pub-id pub-id-type="doi">10.1093/bioinformatics/btu739</pub-id>
<pub-id pub-id-type="pmid">25398609</pub-id></mixed-citation>
    </ref>
    <ref id="B96">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tantos</surname><given-names>A.</given-names></name><name><surname>Friedrich</surname><given-names>P.</given-names></name><name><surname>Tompa</surname><given-names>P.</given-names></name></person-group> (<year>2009</year>). <article-title>Cold stability of intrinsically disordered proteins</article-title>. <source>FEBS Lett.</source>
<volume>583</volume>, <fpage>465</fpage>–<lpage>469</lpage>. <pub-id pub-id-type="doi">10.1016/j.febslet.2008.12.054</pub-id>
<pub-id pub-id-type="pmid">19121309</pub-id></mixed-citation>
    </ref>
    <ref id="B97">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tompa</surname><given-names>P.</given-names></name><name><surname>Dosztanyi</surname><given-names>Z.</given-names></name><name><surname>Simon</surname><given-names>I.</given-names></name></person-group> (<year>2006</year>). <article-title>Prevalent structural disorder in <italic>E. coli</italic> and <italic>S. cerevisiae</italic> proteomes</article-title>. <source>J. Proteome Res.</source>
<volume>5</volume>, <fpage>1996</fpage>–<lpage>2000</lpage>. <pub-id pub-id-type="doi">10.1021/pr0600881</pub-id>
<pub-id pub-id-type="pmid">16889422</pub-id></mixed-citation>
    </ref>
    <ref id="B98">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tompa</surname><given-names>P.</given-names></name><name><surname>Prilusky</surname><given-names>J.</given-names></name><name><surname>Silman</surname><given-names>I.</given-names></name><name><surname>Sussman</surname><given-names>J. L.</given-names></name></person-group> (<year>2008</year>). <article-title>Structural disorder serves as a weak signal for intracellular protein degradation</article-title>. <source>Proteins.</source>
<volume>71</volume>, <fpage>903</fpage>–<lpage>909</lpage>. <pub-id pub-id-type="doi">10.1002/prot.21773</pub-id>
<pub-id pub-id-type="pmid">18004785</pub-id></mixed-citation>
    </ref>
    <ref id="B99">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tompa</surname><given-names>P.</given-names></name><name><surname>Szasz</surname><given-names>C.</given-names></name><name><surname>Buday</surname><given-names>L.</given-names></name></person-group> (<year>2005</year>). <article-title>Structural disorder throws new light on moonlighting</article-title>. <source>Trends biochem. Sci.</source>
<volume>30</volume>, <fpage>484</fpage>–<lpage>489</lpage>. <pub-id pub-id-type="doi">10.1016/j.tibs.2005.07.008</pub-id>
<pub-id pub-id-type="pmid">16054818</pub-id></mixed-citation>
    </ref>
    <ref id="B4">
      <mixed-citation publication-type="journal"><collab>The UniProt Consortium</collab><person-group person-group-type="author"><name><surname>Bateman</surname><given-names>A.</given-names></name><name><surname>Martin</surname><given-names>M.-J.</given-names></name><name><surname>Orchard</surname><given-names>S.</given-names></name><name><surname>Magrane</surname><given-names>M.</given-names></name><name><surname>Agivetova</surname><given-names>R.</given-names></name><name><surname>Ahmad</surname><given-names>S.</given-names></name><etal/></person-group> (<year>2021</year>). <article-title>UniProt: The universal protein knowledgebase in 2021</article-title>. <source>Nucleic Acids Res.</source>
<volume>49</volume>, <fpage>D480</fpage>–<lpage>D489</lpage>. <pub-id pub-id-type="doi">10.1093/nar/gkaa1100</pub-id>
<pub-id pub-id-type="pmid">33237286</pub-id></mixed-citation>
    </ref>
    <ref id="B100">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Uversky</surname><given-names>V. N.</given-names></name><name><surname>Oldfield</surname><given-names>C. J.</given-names></name><name><surname>Midic</surname><given-names>U.</given-names></name><name><surname>Xie</surname><given-names>H.</given-names></name><name><surname>Xue</surname><given-names>B.</given-names></name><name><surname>Vucetic</surname><given-names>S.</given-names></name><etal/></person-group> (<year>2009</year>). <article-title>Unfoldomics of human diseases: Linking protein intrinsic disorder with diseases</article-title>. <source>BMC Genomics</source>
<volume>10</volume>, <fpage>S7</fpage>. <pub-id pub-id-type="doi">10.1186/1471-2164-10-s1-s7</pub-id>
</mixed-citation>
    </ref>
    <ref id="B101">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van der Maaten</surname><given-names>L.</given-names></name><name><surname>Hinton</surname><given-names>G.</given-names></name></person-group> (<year>2008</year>). <article-title>Visualizing Data using t-SNE</article-title>. <source>J. Mach. Learn. Res.</source>
<volume>9</volume>, <fpage>2579</fpage>–<lpage>2605</lpage>. </mixed-citation>
    </ref>
    <ref id="B102">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Vaswani</surname><given-names>A.</given-names></name><name><surname>Shazeer</surname><given-names>N.</given-names></name><name><surname>Parmar</surname><given-names>N.</given-names></name><name><surname>Uszkoreit</surname><given-names>J.</given-names></name><name><surname>Jones</surname><given-names>L.</given-names></name><name><surname>Gomez</surname><given-names>A. N.</given-names></name><etal/></person-group> (<year>2017</year>). “<article-title>Attention is all you need</article-title>,” in <source>Proceedings of the 31st international conference on neural information processing systems</source> (<publisher-loc>Long Beach, California, USA</publisher-loc>: <publisher-name>Curran Associates Inc</publisher-name>). </mixed-citation>
    </ref>
    <ref id="B103">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vicedo</surname><given-names>E.</given-names></name><name><surname>Gasik</surname><given-names>Z.</given-names></name><name><surname>Dong</surname><given-names>Y.-A.</given-names></name><name><surname>Goldberg</surname><given-names>T.</given-names></name><name><surname>Rost</surname><given-names>B.</given-names></name></person-group> (<year>2015a</year>). <article-title>Protein disorder reduced in <italic>Saccharomyces cerevisiae</italic> to survive heat shock</article-title>. <source>F1000Res.</source>
<volume>4</volume>, <fpage>1222</fpage>. <pub-id pub-id-type="doi">10.12688/f1000research.7178.1</pub-id>
<pub-id pub-id-type="pmid">26673203</pub-id></mixed-citation>
    </ref>
    <ref id="B104">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vicedo</surname><given-names>E.</given-names></name><name><surname>Schlessinger</surname><given-names>A.</given-names></name><name><surname>Rost</surname><given-names>B.</given-names></name></person-group> (<year>2015b</year>). <article-title>Environmental pressure may change the composition protein disorder in prokaryotes</article-title>. <source>PLoS One</source>
<volume>10</volume>, <fpage>e0133990</fpage>. <pub-id pub-id-type="doi">10.1371/journal.pone.0133990</pub-id>
<pub-id pub-id-type="pmid">26252577</pub-id></mixed-citation>
    </ref>
    <ref id="B105">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vucetic</surname><given-names>S.</given-names></name><name><surname>Obradovic</surname><given-names>Z.</given-names></name><name><surname>Vacic</surname><given-names>V.</given-names></name><name><surname>Radivojac</surname><given-names>P.</given-names></name><name><surname>Peng</surname><given-names>K.</given-names></name><name><surname>Iakoucheva</surname><given-names>L. M.</given-names></name><etal/></person-group> (<year>2005</year>). <article-title>DisProt: A database of protein disorder</article-title>. <source>Bioinformatics</source>
<volume>21</volume>, <fpage>137</fpage>–<lpage>140</lpage>. <pub-id pub-id-type="doi">10.1093/bioinformatics/bth476</pub-id>
<pub-id pub-id-type="pmid">15310560</pub-id></mixed-citation>
    </ref>
    <ref id="B106">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Walsh</surname><given-names>I.</given-names></name><name><surname>Martin</surname><given-names>A. J. M.</given-names></name><name><surname>Di Domenico</surname><given-names>T.</given-names></name><name><surname>Tosatto</surname><given-names>S. C. E.</given-names></name></person-group> (<year>2012</year>). <article-title>ESpritz: Accurate and fast prediction of protein disorder</article-title>. <source>Bioinformatics</source>
<volume>28</volume>, <fpage>503</fpage>–<lpage>509</lpage>. <pub-id pub-id-type="doi">10.1093/bioinformatics/btr682</pub-id>
<pub-id pub-id-type="pmid">22190692</pub-id></mixed-citation>
    </ref>
    <ref id="B107">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>S.</given-names></name><name><surname>Ma</surname><given-names>J.</given-names></name><name><surname>Xu</surname><given-names>J.</given-names></name></person-group> (<year>2016</year>). <article-title>AUCpreD: Proteome-level protein disorder prediction by AUC-maximized deep convolutional neural fields</article-title>. <source>Bioinformatics</source>
<volume>32</volume>, <fpage>i672</fpage>–<lpage>i679</lpage>. <pub-id pub-id-type="doi">10.1093/bioinformatics/btw446</pub-id>
<pub-id pub-id-type="pmid">27587688</pub-id></mixed-citation>
    </ref>
    <ref id="B108">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ward</surname><given-names>J. J.</given-names></name><name><surname>Sodhi</surname><given-names>J. S.</given-names></name><name><surname>Mcguffin</surname><given-names>L. J.</given-names></name><name><surname>Buxton</surname><given-names>B. F.</given-names></name><name><surname>Jones</surname><given-names>D. T.</given-names></name></person-group> (<year>2004</year>). <article-title>Prediction and functional analysis of native disorder in proteins from the three kingdoms of life</article-title>. <source>J. Mol. Biol.</source>
<volume>337</volume>, <fpage>635</fpage>–<lpage>645</lpage>. <pub-id pub-id-type="doi">10.1016/j.jmb.2004.02.002</pub-id>
<pub-id pub-id-type="pmid">15019783</pub-id></mixed-citation>
    </ref>
    <ref id="B109">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wilson</surname><given-names>C. J.</given-names></name><name><surname>Choy</surname><given-names>W.-Y.</given-names></name><name><surname>Karttunen</surname><given-names>M.</given-names></name></person-group> (<year>2022</year>). <article-title>AlphaFold2: A role for disordered protein/region prediction?</article-title>. <source>Int. J. Mol. Sci.</source>
<volume>23</volume> (<issue>9</issue>), <fpage>4591</fpage>. <pub-id pub-id-type="doi">10.3390/ijms23094591</pub-id>
<pub-id pub-id-type="pmid">35562983</pub-id></mixed-citation>
    </ref>
    <ref id="B110">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wold</surname><given-names>S.</given-names></name><name><surname>Esbensen</surname><given-names>K.</given-names></name><name><surname>Geladi</surname><given-names>P.</given-names></name></person-group> (<year>1987</year>). <article-title>Principal component analysis</article-title>. <source>Chemom. intelligent laboratory Syst.</source>
<volume>2</volume>, <fpage>37</fpage>–<lpage>52</lpage>. <pub-id pub-id-type="doi">10.1016/0169-7439(87)80084-9</pub-id>
</mixed-citation>
    </ref>
    <ref id="B111">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wright</surname><given-names>P. E.</given-names></name><name><surname>Dyson</surname><given-names>H. J.</given-names></name></person-group> (<year>1999</year>). <article-title>Intrinsically unstructured proteins: Re-assessing the protein structure-function paradigm</article-title>. <source>J. Mol. Biol.</source>
<volume>293</volume>, <fpage>321</fpage>–<lpage>331</lpage>. <pub-id pub-id-type="doi">10.1006/jmbi.1999.3110</pub-id>
<pub-id pub-id-type="pmid">10550212</pub-id></mixed-citation>
    </ref>
    <ref id="B112">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wu</surname><given-names>Z.</given-names></name><name><surname>Johnston</surname><given-names>K. E.</given-names></name><name><surname>Arnold</surname><given-names>F. H.</given-names></name><name><surname>Yang</surname><given-names>K. K.</given-names></name></person-group> (<year>2021</year>). <article-title>Protein sequence design with deep generative models</article-title>. <source>Curr. Opin. Chem. Biol.</source>
<volume>65</volume>, <fpage>18</fpage>–<lpage>27</lpage>. <pub-id pub-id-type="doi">10.1016/j.cbpa.2021.04.004</pub-id>
<pub-id pub-id-type="pmid">34051682</pub-id></mixed-citation>
    </ref>
    <ref id="B113">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yang</surname><given-names>Z. R.</given-names></name><name><surname>Thomson</surname><given-names>R.</given-names></name><name><surname>Mcneil</surname><given-names>P.</given-names></name><name><surname>Esnouf</surname><given-names>R. M.</given-names></name></person-group> (<year>2005</year>). <article-title>Ronn: The bio-basis function neural network technique applied to the detection of natively disordered regions in proteins</article-title>. <source>Bioinformatics</source>
<volume>21</volume>, <fpage>3369</fpage>–<lpage>3376</lpage>. <pub-id pub-id-type="doi">10.1093/bioinformatics/bti534</pub-id>
<pub-id pub-id-type="pmid">15947016</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
