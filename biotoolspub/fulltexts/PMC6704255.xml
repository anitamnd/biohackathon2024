<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Sci Rep</journal-id>
    <journal-id journal-id-type="iso-abbrev">Sci Rep</journal-id>
    <journal-title-group>
      <journal-title>Scientific Reports</journal-title>
    </journal-title-group>
    <issn pub-type="epub">2045-2322</issn>
    <publisher>
      <publisher-name>Nature Publishing Group UK</publisher-name>
      <publisher-loc>London</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">6704255</article-id>
    <article-id pub-id-type="publisher-id">48489</article-id>
    <article-id pub-id-type="doi">10.1038/s41598-019-48489-3</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Article</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>atlasBREX: Automated template-derived brain extraction in animal MRI</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-8927-2453</contrib-id>
        <name>
          <surname>Lohmeier</surname>
          <given-names>Johannes</given-names>
        </name>
        <address>
          <email>johannes.lohmeier@charite.de</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Kaneko</surname>
          <given-names>Takaaki</given-names>
        </name>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Hamm</surname>
          <given-names>Bernd</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Makowski</surname>
          <given-names>Marcus R.</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Okano</surname>
          <given-names>Hideyuki</given-names>
        </name>
        <address>
          <email>hidokano@a2.keio.jp</email>
        </address>
        <xref ref-type="aff" rid="Aff2">2</xref>
        <xref ref-type="aff" rid="Aff3">3</xref>
      </contrib>
      <aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0001 2218 4662</institution-id><institution-id institution-id-type="GRID">grid.6363.0</institution-id><institution>Charité Universitätsmedizin Berlin, </institution></institution-wrap>Radiology, Berlin Germany </aff>
      <aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ISNI">0000000094465255</institution-id><institution-id institution-id-type="GRID">grid.7597.c</institution-id><institution>Center for Brain Science Institute, </institution><institution>RIKEN, Marmoset Neural Architecture, </institution></institution-wrap>Wako-shi, Saitama Japan </aff>
      <aff id="Aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0004 1936 9959</institution-id><institution-id institution-id-type="GRID">grid.26091.3c</institution-id><institution>Department of Physiology, </institution><institution>Keio University School of Medicine, </institution></institution-wrap>Tokyo, Japan </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>21</day>
      <month>8</month>
      <year>2019</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>21</day>
      <month>8</month>
      <year>2019</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2019</year>
    </pub-date>
    <volume>9</volume>
    <elocation-id>12219</elocation-id>
    <history>
      <date date-type="received">
        <day>12</day>
        <month>2</month>
        <year>2019</year>
      </date>
      <date date-type="accepted">
        <day>3</day>
        <month>6</month>
        <year>2019</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2019</copyright-statement>
      <license license-type="OpenAccess">
        <license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. The images or other third party material in this article are included in the article’s Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this license, visit <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>.</license-p>
      </license>
    </permissions>
    <abstract id="Abs1">
      <p id="Par1">We proposed a generic template-derived approach for (semi-) automated brain extraction in animal MRI studies and evaluated our implementation with different animal models (macaque, marmoset, rodent) and MRI protocols (T1, T2). While conventional MR-neuroimaging studies perform brain extraction as an initial step priming subsequent image-registration from subject to template, our proposed approach propagates an anatomical template to (whole-head) individual subjects in reverse order, which is challenging due to the surrounding extracranial tissue, greater differences in contrast pattern and larger areas with field inhomogeneity. As a novel approach, the herein introduced brain extraction algorithm derives whole-brain segmentation using rigid and non-rigid deformation based on unbiased anatomical atlas building with a priori estimates from study-cohort and an initial approximate brain extraction. We evaluated our proposed method in comparison to several other technical approaches including “Marker based watershed scalper”, “Brain-Extraction-Tool”, “3dSkullStrip”, “Primatologist-Toolbox”, “Rapid Automatic Tissue Segmentation” and “Robust automatic rodent brain extraction using 3D pulse-coupled neural networks” with manual skull-stripping as reference standard. ABX demonstrated best performance with accurate (≥92%) and consistent results throughout datasets and across species, age and MRI protocols. ABX was made available to the public with documentation, templates and sample material (<ext-link ext-link-type="uri" xlink:href="https://www.github.com/jlohmeier/atlasBREX">https://www.github.com/jlohmeier/atlasBREX</ext-link>).</p>
    </abstract>
    <kwd-group kwd-group-type="npg-subject">
      <title>Subject terms</title>
      <kwd>Image processing</kwd>
      <kwd>Computational neuroscience</kwd>
      <kwd>Magnetic resonance imaging</kwd>
    </kwd-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">https://doi.org/10.13039/100009619</institution-id>
            <institution>Japan Agency for Medical Research and Development (AMED)</institution>
          </institution-wrap>
        </funding-source>
        <award-id>15653395</award-id>
        <award-id>15653395</award-id>
        <award-id>15653395</award-id>
        <principal-award-recipient>
          <name>
            <surname>Lohmeier</surname>
            <given-names>Johannes</given-names>
          </name>
          <name>
            <surname>Kaneko</surname>
            <given-names>Takaaki</given-names>
          </name>
          <name>
            <surname>Okano</surname>
            <given-names>Hideyuki</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
    </funding-group>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>© The Author(s) 2019</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="Sec1" sec-type="introduction">
    <title>Introduction</title>
    <p id="Par2">Brain extraction, also referred as skull-stripping or whole-brain segmentation, describes the process of extracting the brain from the surrounding extracranial tissue. In MRI studies, it is common that this procedure is implemented at an early stage, as it plays an important role for further processing, such as spatial normalisation, surface reconstruction and structural analysis<sup><xref ref-type="bibr" rid="CR1">1</xref></sup>. Manual delineation is considered technical standard, but it demands high time investment, experience and neuroanatomical knowledge. Hence, there is need for automated technical alternatives, which are less operator-dependent. Several (semi-) automated (hybrid) approaches were developed for human neuroimaging thus far<sup><xref ref-type="bibr" rid="CR1">1</xref></sup>, but present a high degree of specialisation due to a priori estimates. Therefore, established technical approaches for human neuroimaging are often not compatible with animal MRI and the adaption can be demanding due to interspecies differences in brain size, shape and tissue contrast as well as differences in MRI scanners, magnetic field strengths, radiofrequency coils and MRI protocols. A common challenge in skull-stripping animal MR-neuroimaging is the presence of more severe field inhomogeneity, which is attributable to non-uniformity in radiofrequency coils. As illustrated in Fig. <xref rid="Fig1" ref-type="fig">1</xref>, both pattern of occurrence (see heterogeneous gradient) as well as the severity of distortion are subject to variation, which affects the performance of processing algorithms that infer information from image intensity. Further challenges arise from low-resolution images (see Fig. <xref rid="Fig1" ref-type="fig">1a,c</xref>), such as in functional and diffusion MRI studies.<fig id="Fig1"><label>Figure 1</label><caption><p>Challenges in skull-stripping animal MR-neuroimaging. Illustration of common difficulties when skull-stripping animal MRI (top-left: marmoset [9.4 T Biospec, Bruker, Germany]; top-right: rat [9.4 T Biospec, Bruker, Germany]; bottom-left: rhesus macaque [3 T Prisma, Siemens, Germany]; bottom-right: marmoset [3 T Prisma, Siemens, Germany]), such as low image resolution (<bold>a</bold>,<bold>c</bold>), strong field inhomogeneity (<bold>a</bold>–<bold>d</bold>) or greater field-of-view (<bold>b,d</bold>) with larger areas of non-brain tissue.</p></caption><graphic xlink:href="41598_2019_48489_Fig1_HTML" id="d29e321"/></fig></p>
    <p id="Par3">In recent years, neuroimaging studies with animal models, such as macaque<sup><xref ref-type="bibr" rid="CR2">2</xref></sup>, marmoset<sup><xref ref-type="bibr" rid="CR3">3</xref>,<xref ref-type="bibr" rid="CR4">4</xref></sup> and rodent<sup><xref ref-type="bibr" rid="CR5">5</xref></sup>, gained in significance due to their contributions to understanding the central nervous system<sup><xref ref-type="bibr" rid="CR6">6</xref>,<xref ref-type="bibr" rid="CR7">7</xref></sup>. To date, however, there are only few technical approaches available that can be applied to animal MRI, such as Marker based watershed scalper (MBWSS)<sup><xref ref-type="bibr" rid="CR8">8</xref></sup>, Brain-Extraction-Tool (BET)<sup><xref ref-type="bibr" rid="CR9">9</xref></sup>, 3dSkullStrip (3DSS) as part of the Analysis of Functional NeuroImages (AFNI) package<sup><xref ref-type="bibr" rid="CR10">10</xref></sup>, Primatologist-Toolbox (PRIMA)<sup><xref ref-type="bibr" rid="CR11">11</xref></sup>, Rapid Automatic Tissue Segmentation (RATS)<sup><xref ref-type="bibr" rid="CR12">12</xref></sup> and Robust automatic rodent brain extraction using 3D pulse-coupled neural networks (PCNN3D)<sup><xref ref-type="bibr" rid="CR13">13</xref></sup>. However, it is common that results are below standard and require further manual intervention. Hence, there is demand for more robust brain extraction algorithms in animal MRI.</p>
    <p id="Par4">Therefore, we proposed a generic template-derived approach for animal neuroimaging: We present atlasBREX (ABX), a semi-automated processing pipeline that propagates skull-stripping of an anatomical template built from the study-cohort after rigid and non-rigid deformation to each individual subject (see Fig. <xref rid="Fig2" ref-type="fig">2</xref>). First, in a practical and unbiased manner, an anatomical study-specific template is computed from all individual subjects (see Fig. <xref rid="Fig2" ref-type="fig">2</xref>, step 1) using an iterative hierarchical group-wise registration framework, Atlas Building by Self-Organized Registration and Bundling (ABSORB)<sup><xref ref-type="bibr" rid="CR14">14</xref></sup>. Next, the study-specific anatomical template is subject to manual (hybrid) skull-stripping (see Fig. <xref rid="Fig2" ref-type="fig">2</xref>, step 2). In the following steps, rigid and non-rigid deformation fields are computed from template- to target-space (see Fig. <xref rid="Fig2" ref-type="fig">2</xref>, step 5 and 7), which are applied to the template mask in order to compute a subject-specific brain mask (see Fig. <xref rid="Fig2" ref-type="fig">2</xref>, step 6 and 8).<fig id="Fig2"><label>Figure 2</label><caption><p>Workflow of atlasBREX for (semi-) automated brain extraction. In a first step (1), an unbiased anatomical template is constructed from the respective study-cohort using ABSORB, which is then subject to manual (hybrid) skull-stripping (2). Upon preprocessing in order to optimize the following image registration and initial approximate brain extraction (3), rigid and non-rigid deformation (5 and 7) fields are computed from template- to target-space, which are applied to the template mask in order to compute a subject-specific brain mask (6 and 8). Optional multi-step deformation to other target volumes, such as structural low-resolution (γ) and functional scans (δ), can be performed. Panels on the top-right demonstrate results from an adult marmoset upon rigid (α) and non-rigid (β) deformation as well as the results from the corresponding structural low-resolution (γ) and functional scans (δ).</p></caption><graphic xlink:href="41598_2019_48489_Fig2_HTML" id="d29e404"/></fig></p>
    <p id="Par5">While spatial transformation is conventionally performed after image preprocessing (including brain extraction) with the objective to align images within or across individuals, our proposed approach is based on the backpropagation of an anatomical template to the (whole-head) individual subject, which is challenging due to the surrounding extracranial tissue, greater differences in contrast pattern and larger areas with strong field inhomogeneity (see Fig. <xref rid="Fig1" ref-type="fig">1</xref>).</p>
    <p id="Par6">Therefore, as a novel approach, the herein introduced brain extraction algorithm derives whole-brain segmentation using rigid and non-rigid deformation based on unbiased anatomical atlas building with a priori estimates from the study-cohort and an initial approximate brain extraction. Thereby, our proposed approach achieves accurate and consistent results for an entire study population using only a single template, which exhibits high anatomical conformance and similarity in contrast. On the contrary, available templates, which were not built from the respective study population, can negatively impact the performance of registration algorithms due to greater divergence in brain morphology and differences in contrast pattern, originating from MRI scanner, radiofrequency coil or imaging protocol. In order to address some of the challenges described above, preprocessing operations, such as voxel-scaling, bias-field correction and intensity normalisation, were additionally implemented into the processing stream.</p>
    <p id="Par7">We evaluated ABX across different MRI protocols (T1, T2) with macaques, marmosets and rodents and compared its performance to several other technical methods.</p>
  </sec>
  <sec id="Sec2">
    <title>Method</title>
    <sec id="Sec3">
      <title>Datasets and MR-imaging protocols</title>
      <p id="Par8">Rhesus macaque (n = 32, age 0.5–36 months) datasets from the open, longitudinal UNC-Wisconsin Neurodevelopment Rhesus (UNCW-NRh) database<sup><xref ref-type="bibr" rid="CR15">15</xref></sup> were obtained featuring preprocessed (AutoSeg2, N4BiasFieldCorrection and BRAINSfit3 registration to Emory-UNC atlas) T1-/T2-weighted scans (Waisman Lab, University of Wisconsin Madison, 3 T MRI, GE Medical, Milwaukee WI; T1W/GE-BRAVO, TR/TE = 8.684/3.652 ms, FOV = 140 × 140 mm, matrix = 256 × 256, thickness = 0.8 mm, resolution = 0.55 × 0.55 × 0.8 mm; T2W/3D-FSECUBE, TR/TE = 2500/87 ms, FOV = 154 × 154 mm, matrix = 256 × 256, thickness = 0.6 mm, resolution = 0.6 × 0.6 × 0.6 mm) including results from manual hybrid brain extraction using Atlas-Based-Classification and manual intervention, which were used as reference standard.</p>
      <p id="Par9">All procedures were approved by Wako Animal Experiment Committee (Animal Care and Use Committee), RIKEN, and all experiments were performed in accordance with the approved guidelines and regulations. The following datasets were obtained:</p>
      <p id="Par10">Adult marmoset acquired at RIKEN Brain Science Institute (9.4 T MRI, Bruker, Germany; T2W/RARE, TR/TE = 8000/32 ms, FOV = 48 × 38.5 mm, matrix = 320 × 256, thickness = 0.3 mm, slices = 97, resolution = 0.15 × 0.15 × 0.3 mm, RARE-factor = 8; T2*W/Gradient-EPI, TR/TE = 2000/16 ms, FOV = 42 × 22 mm, matrix = 84 × 44, thickness = 1 mm, slices = 35, resolution = 0.5 × 0.5 × 1 mm). At Central Institute for Experimental Animals (CIEA) juvenile (n = 6, age 6–12 months) marmoset (7 T MRI, Bruker, Germany; T1W/MPRAGE, TR/TE = 14/45 ms, FOV = 50 × 50 mm, matrix = 192 × 192, thickness = 0.27 mm, slice = 120, resolution = 0.26 × 0.26 × 0.27 mm), adult (n = 5) marmoset (3 T MRI, Siemens, Germany; T2W, TR/TE = 3200/562 ms, FOV = 128 × 128 mm, matrix = 256 × 256, thickness = 0.5 mm, slice = 224, resolution = 0.5 × 0.5 × 0.5 mm; one sample excluded for quality reasons) and adult (n = 6) mouse (7 T MRI, Bruker, Germany; T2W/RARE, TR/TE = 6100/48 ms, FOV = 1.92 × 1.92 mm, matrix = 256 × 256, thickness = 0.3 mm, slice = 52, resolution = 0.075 × 0.075 × 0.3 mm, RARE-factor = 8) were obtained. Reference images were skull-stripped using a manual hybrid approach with BrainSuite (v16a1)<sup><xref ref-type="bibr" rid="CR16">16</xref></sup>.</p>
    </sec>
    <sec id="Sec4">
      <title>Building templates from the study-cohort using ABSORB</title>
      <p id="Par11">A hierarchical group-wise registration framework, Atlas Building by Self-Organized Registration and Bundling (ABSORB)<sup><xref ref-type="bibr" rid="CR14">14</xref></sup>, was used for unbiased template building (with histogram-matching and affine-registration; neighbourhood-size: 3; smoothing-kernel: 3,2,1; maximum-levels: 5; registration-to-mean: 3) built from the respective study-cohort (with whole-head images). Datasets were bias-field corrected (N4BiasFieldCorrection, ANTs) and aligned (3dAllineate, AFNI), where the built-in registration algorithm led to insufficient results. Gaussian convolution (3dmerge, AFNI) (smoothing-kernel: 0.3–0.5) was applied to templates after manual (hybrid) skull-stripping with BrainSuite (v16a1).</p>
    </sec>
    <sec id="Sec5">
      <title>atlasBREX with unbiased anatomical templates</title>
      <p id="Par12">atlasBREX (ABX) is a semi-automated processing pipeline that propagates skull-stripping of an anatomical template built from the study-cohort upon rigid and non-rigid deformation to each individual subject. It requires functional set-up of FMRIB’s Software Library (FSL, v5.0). Several optional features are available making use of Analysis of Functional NeuroImages (AFNI, v17.1.01) and Advanced Normalization Tools (ANTs, v2.1.0)<sup><xref ref-type="bibr" rid="CR17">17</xref></sup>.</p>
      <p id="Par13">At first, a template mask is aligned to a subject using linear registration (FLIRT, FSL) between the template brain and an initial approximate brain extraction from Brain-Extraction-Tool v2 (BET, FSL), as shown in Fig. <xref rid="Fig2" ref-type="fig">2</xref>. Prior to the provisional brain extraction, voxel dimensions are adjusted to resemble the human brain and (optional) preprocessing can be applied, such as intensity normalisation (3dUnifize, AFNI), recommended for T1-weighted images, and bias-field correction (N4BiasFieldCorrection, ANTs), which compensates for field inhomogeneity. Changes during preprocessing are implemented on intermediates and, therefore, are not present in final results.</p>
      <p id="Par14">In the following steps, a subject-specific brain mask is computed from the non-rigid deformation field based on non-linear registration (FNIRT, FSL), which relies on the affine transformation matrix from the previous linear registration and a (dilated) reference mask based on the result from rigid deformation, which prevents adverse impact of surrounding extracranial tissue at full resolution during registration. Where additional scans from the same subject are available, such as low-resolution structural or functional scans, rigid and non-rigid transformation matrices can be applied upon an additional transformation step.</p>
      <p id="Par15">Prior to automated processing of an entire dataset, a brief interactive user-guided pilot run needs to be performed to determine a suitable intensity threshold (0.3, 0.5 or 0.8) for the initial approximate brain extraction.</p>
    </sec>
    <sec id="Sec6">
      <title>Evaluation of atlasBREX</title>
      <p id="Par16">For quantitative evaluation, image datasets from infant (n = 8, 0.5–1 months, T1/T2) and juvenile (n = 8, 24–36 months, T1/T2) rhesus macaques, juvenile marmosets (n = 6, 6–12 months, T1), adult marmosets (n = 5, T2) and adult mice (n = 6, T2) were used. ABX was utilized on each dataset (with a single set of parameters upon a brief pilot run to determine an intensity threshold) with an anatomical template built from the respective study-cohort. In addition to Brain-Extraction-Tool v2 (BET), several dedicated technical methods (3dSkullStrip (3DSS), Primatologist-Toolbox (PRIMA) and Marker based watershed scalper (MBWSS) dedicated to non-human primates; Robust automatic rodent brain extraction using 3-D pulse-coupled neural networks (PCNN3D), Rapid Automatic Tissue Segmentation (RATS) and 3dSkullStrip (3DSS) dedicated to rodents) were applied to each dataset. Brain-Extraction-Tool v2 (BET) was assessed with different fractional intensity thresholds (5 variants, thresholds from 0.1–0.9). 3dSkullStrip (3DSS) was evaluated with dedicated presets (“monkey”, “rat” and “marmoset”). Marker based watershed scalper (MBWSS) features an optimized version for macaques, which was evaluated with different parameters (one variant with default parameters with (built-in) bias-field correction; 2 variants with settings recommended by the author: bias-field correction, increased smoothing, mask refinement, increased radius of opening). Primatologist-Toolbox (PRIMA) was assessed using respective options for T1- and T2-weighting and presets for “macaque” and “mouse”. For MBWSS and BET, where more than one variant was available, the best result was chosen according to the highest Jaccard-Index. All datasets were analysed on the same multi-core hardware platform (32 × 2.70 Ghz Intel-CPU, 260 GB RAM) running Linux 3.10 Centos 64-bit with FMRIB’s Software Library (FSL v5.0.10), Analysis of Functional NeuroImages (AFNI v17.2.09) and Advanced Normalization Tools (ANTs v2.1.0). ABX typically required few hours for computation.</p>
    </sec>
    <sec id="Sec7">
      <title>Statistical analysis</title>
      <p id="Par17">After visual inspection, quantitative evaluation was performed with manual (hybrid) skull-stripping as reference standard and Jaccard-Index (1) as similarity metric (metrics reported show Jaccard-Index). Quantitative parameters from the respective groups were analysed for statistically significant difference compared to ABX (each group tested against the results from ABX) using Friedman test followed by Dunn’s post-hoc test. Adjusted p-value &lt; 0.05 was considered statistically significant.<disp-formula id="Equ1"><label>1</label><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$J({\rm{A}},\,{\rm{B}})=\frac{|A{\cap }^{}B|}{|A{\cup }^{}B|}$$\end{document}</tex-math><mml:math id="M2" display="block"><mml:mi>J</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">A</mml:mi><mml:mo>,</mml:mo><mml:mspace width=".25em"/><mml:mi mathvariant="normal">B</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mi>A</mml:mi><mml:msup><mml:mo>∩</mml:mo><mml:mspace width="-.25em"/></mml:msup><mml:mi>B</mml:mi><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mi>A</mml:mi><mml:msup><mml:mo>∪</mml:mo><mml:mspace width="-.25em"/></mml:msup><mml:mi>B</mml:mi><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mfrac></mml:math><graphic xlink:href="41598_2019_48489_Article_Equ1.gif" position="anchor"/></alternatives></disp-formula></p>
    </sec>
  </sec>
  <sec id="Sec8" sec-type="results">
    <title>Results</title>
    <sec id="Sec9">
      <title>Evaluation with infant and juvenile rhesus macaques</title>
      <p id="Par18">We evaluated our approach with infant and juvenile non-human primates, which  can be considered challenging due to differences in brain volume and shape with regard to fixed a priori estimates in most brain extraction algorithms. In an overall view, ABX (Mdn[IQR] = 0.95[0.03]) demonstrated best performance regardless of image contrast (T1 vs. T2) and developmental stage (infant vs. juvenile) outperforming BET (Mdn[IQR] = 0.87[0.06], p &lt; 0.001), 3DSS (Mdn[IQR] = 0.86[0.24], p = 0.001), MBWSS (Mdn[IQR] = 0.72[0.18], p &lt; 0.001) and PRIMA (Mdn[IQR] = 0.65[0.36], p &lt; 0.001), as shown in Table <xref rid="Tab1" ref-type="table">1</xref>.<table-wrap id="Tab1"><label>Table 1</label><caption><p>Results from comparative analysis.</p></caption><table frame="hsides" rules="groups"><thead><tr><th/><th>Friedman test</th><th>Dunn’s test</th><th>Mean-rank difference</th><th>Adjusted p-value</th></tr></thead><tbody><tr><td rowspan="4"><p>Infant rhesus macaque</p><p>T1-weighted, n = 8</p></td><td rowspan="4"><p>F = 16.60</p><p>p = 0.002</p></td><td>BET</td><td>18.00</td><td>p = 0.02 (*)</td></tr><tr><td>3DSS</td><td>9.00</td><td>p = 0.62</td></tr><tr><td>PRIMA</td><td>24.00</td><td>p &lt; 0.001 (***)</td></tr><tr><td>MBWSS</td><td>14.00</td><td>p = 0.11</td></tr><tr><td rowspan="4"><p>Infant rhesus macaque</p><p>T2-weighted, n = 8</p></td><td rowspan="4"><p>F = 30.50</p><p>p &lt; 0.001</p></td><td>BET</td><td>21.00</td><td>p = 0.004 (**)</td></tr><tr><td>3DSS</td><td>2.00</td><td>p &gt; 0.99</td></tr><tr><td>PRIMA</td><td>13.00</td><td>p = 0.16</td></tr><tr><td>MBWSS</td><td>29.00</td><td>p &lt; 0.001 (***)</td></tr><tr><td rowspan="4"><p>Juvenile rhesus macaque</p><p>T1-weighted, n = 8</p></td><td rowspan="4"><p>F = 25.90</p><p>p &lt; 0.001</p></td><td>BET</td><td>18.00</td><td>p = 0.02 (*)</td></tr><tr><td>3DSS</td><td>15.00</td><td>p = 0.07</td></tr><tr><td>PRIMA</td><td>32.00</td><td>p &lt; 0.001 (***)</td></tr><tr><td>MBWSS</td><td>15.00</td><td>p = 0.07</td></tr><tr><td rowspan="4"><p>Juvenile rhesus macaque</p><p>T2-weighted, n = 8</p></td><td rowspan="4"><p>F = 22.10</p><p>p &lt; 0.001</p></td><td>BET</td><td>10.00</td><td>p = 0.46</td></tr><tr><td>3DSS</td><td>20.00</td><td>p = 0.006 (**)</td></tr><tr><td>PRIMA</td><td>−1.00</td><td>p &gt; 0.99</td></tr><tr><td>MBWSS</td><td>21.00</td><td>p = 0.004 (**)</td></tr><tr><td rowspan="4"><p>Infant and juvenile rhesus macaque</p><p>T1-/T2-weighted, n = 32</p></td><td rowspan="4"><p>F = 49.38</p><p>p &lt; 0.001</p></td><td>BET</td><td>67.00</td><td>p &lt; 0.001 (***)</td></tr><tr><td>3DSS</td><td>46.00</td><td>p = 0.001 (**)</td></tr><tr><td>PRIMA</td><td>68.00</td><td>p &lt; 0.001 (***)</td></tr><tr><td>MBWSS</td><td>79.00</td><td>p &lt; 0.001 (***)</td></tr><tr><td rowspan="4"><p>Juvenile marmoset</p><p>T1-weighted, n = 6</p></td><td rowspan="4"><p>F = 17.73</p><p>p = 0.001</p></td><td>BET</td><td>16.00</td><td>p = 0.01 (*)</td></tr><tr><td>3DSS</td><td>8.00</td><td>p = 0.58</td></tr><tr><td>PRIMA</td><td>15.00</td><td>p = 0.02 (*)</td></tr><tr><td>MBWSS</td><td>21.00</td><td>p &lt; 0.001 (***)</td></tr><tr><td rowspan="4"><p>Adult marmoset</p><p>T2-weighted, n = 5</p></td><td rowspan="4"><p>F = 15.52</p><p>p = 0.004</p></td><td>BET</td><td>15.00</td><td>p = 0.01 (*)</td></tr><tr><td>3DSS</td><td>9.00</td><td>p = 0.29</td></tr><tr><td>PRIMA</td><td>8.00</td><td>p = 0.44</td></tr><tr><td>MBWSS</td><td>18.00</td><td>p = 0.001 (**)</td></tr><tr><td rowspan="4"><p>Juvenile and adult marmoset</p><p>T1-/T2-weighted, n = 11</p></td><td rowspan="4"><p>F = 32.00</p><p>p &lt; 0.001</p></td><td>BET</td><td>31.00</td><td>p &lt; 0.001 (***)</td></tr><tr><td>3DSS</td><td>17.00</td><td>p = 0.09</td></tr><tr><td>PRIMA</td><td>23.00</td><td>p = 0.008 (**)</td></tr><tr><td>MBWSS</td><td>39.00</td><td>p &lt; 0.001 (***)</td></tr><tr><td rowspan="4"><p>Adult mouse</p><p>T2-weighted, n = 6</p></td><td rowspan="4"><p>F = 21.73</p><p>p &lt; 0.001</p></td><td>BET</td><td>19.00</td><td>p = 0.002 (**)</td></tr><tr><td>3DSS</td><td>10.00</td><td>p = 0.27</td></tr><tr><td>PCNN3D</td><td>2.00</td><td>p &gt; 0.99</td></tr><tr><td>RATS</td><td>19.00</td><td>p = 0.002 (**)</td></tr></tbody></table><table-wrap-foot><p>Comparative analysis between atlasBREX (ABX) and alternate technical methods (each group tested against the results from ABX) was performed using Jaccard-Index and Friedman test with Dunn’s post-hoc test. (*) p-value &lt; 0.05, (**) p-value &lt; 0.01, (***) p-value &lt; 0.001.</p></table-wrap-foot></table-wrap></p>
      <p id="Par19">For infant macaque datasets, as shown in Fig. <xref rid="Fig3" ref-type="fig">3a,b</xref>, 3DSS (T1, T2) and PRIMA (T2) achieved decent accuracy, however, visual inspection revealed that laborious manual intervention was inevitable for results from 3DSS (T1), while minor adjustments were needed for results from PRIMA (T2). Regarding juvenile macaque datasets (see Fig. <xref rid="Fig3" ref-type="fig">3c,d</xref>), PRIMA (T2) showed reliable performance. Although no statistically significant differences were apparent for MBWSS (T1), 3DSS (T1) and BET (T2), visual inspection showed that extensive manual corrections were still required. PRIMA presented better performance with T2-weighted datasets, while MBWSS showed higher accuracy for datasets with T1-weighting. Contrarily, ABX demonstrated robust and consistent brain extraction throughout datasets. Inaccurate delineation from ABX was apparent in a single case (Jaccard-Index = 0.76), which would have required parameter optimisation.<fig id="Fig3"><label>Figure 3</label><caption><p>Evaluation with infant and juvenile rhesus macaques. Bar graph diagrams (<bold>a</bold>–<bold>d</bold>) demonstrating results from atlasBREX (ABX), Brain-Extraction-Tool v2 (BET), 3dSkullStrip (3DSS), Primatologist-Toolbox (PRIMA) and Marker based watershed scalper (MBWSS) for each dataset (4 groups, each n = 8). Results from alternate technical methods were compared to ABX using Friedman test followed by Dunn’s post-hoc test. (*) p-value &lt; 0.05, (**) p-value &lt; 0.01, (***) p-value &lt; 0.001, (ns) non-significant. Mdn, IQR.</p></caption><graphic xlink:href="41598_2019_48489_Fig3_HTML" id="d29e1053"/></fig></p>
      <p id="Par20">Manual definition of the segmentation boundary is tedious and highly operator-dependent, which makes it prone to human error, e.g. unintentional erosion of brain voxels (see Fig. <xref rid="Fig4" ref-type="fig">4a</xref>), remaining non-brain tissue (see Fig. <xref rid="Fig4" ref-type="fig">4e</xref>) or insufficient masking with jagged edges (see Fig. <xref rid="Fig4" ref-type="fig">4c</xref>). In contrast, as shown in Fig. <xref rid="Fig4" ref-type="fig">4b,d,f</xref>, results from ABX presented consistent and accurate brain extraction with a high degree of standardisation through automated processing using a single set of parameters.<fig id="Fig4"><label>Figure 4</label><caption><p>Comparison between atlasBREX (ABX) and manual delineation from UNC-Wisconsin Rhesus Macaque Neurodevelopment Database. Representative cases from juvenile rhesus macaque (n = 8, T2) presenting common disadvantages of manual (hybrid) brain extraction (α), which is operator-dependent and time-consuming, compared to (semi-) automated skull-stripping (β) using ABX. First two panels (<bold>a</bold>,<bold>b</bold>) show common erosion of the olfactory bulb. Jagged edges with marginal erosion of brain tissue are depicted in the following two panels (<bold>c</bold>,<bold>d</bold>). Last panels (<bold>e</bold>,<bold>f</bold>) demonstrate inaccurate delineation. White arrow indicates the magnified region-of-interest.</p></caption><graphic xlink:href="41598_2019_48489_Fig4_HTML" id="d29e1097"/></fig></p>
    </sec>
    <sec id="Sec10">
      <title>Evaluation with juvenile and adult marmosets</title>
      <p id="Par21">We evaluated ABX with datasets from juvenile and adult marmosets obtained with different magnetic field strengths (3 T vs. 7 T) and MRI protocols (T1 vs. T2). In particular, the 3 T (adult) marmoset dataset, acquired on a device originally designed for human imaging, is technically demanding due to a greater field-of-view with larger differences in contrast pattern. ABX (Mdn[IQR] = 0.95[0.02]) presented consistent and highest accuracy across datasets (see Table <xref rid="Tab1" ref-type="table">1</xref>), which was followed by 3DSS (Mdn[IQR] = 0.85[0.08], p = 0.09), PRIMA (Mdn[IQR] = 0.82[0.18], p = 0.008), BET (Mdn[IQR] = 0.77[0.08], p &lt; 0.001) and MBWSS (Mdn[IQR] = 0.34[0.40], p &lt; 0.001).</p>
      <p id="Par22">Although there were no statistically significant differences for 3DSS (for both datasets) and PRIMA (for the adult marmoset dataset), visual inspection showed that (extensive) manual intervention was still required (see Fig. <xref rid="Fig5" ref-type="fig">5b,d</xref>). Brain voxel erosion (see red colour), notably affected the rostral/anterior and caudal/posterior brain regions (see Fig. <xref rid="Fig5" ref-type="fig">5,d</xref>, panel δ (3DSS) and ε (PRIMA)). Moreover, large areas with non-brain tissue (see green colour) remained, demonstrated in Fig. <xref rid="Fig5" ref-type="fig">5b,d</xref>, respectively panel ε (PRIMA). In contrast, ABX presented accurate segmentation of the marmoset brain, illustrated with brain models in Fig. <xref rid="Fig5" ref-type="fig">5b,d</xref>, respectively panel α, particularly with regard to the olfactory bulb.<fig id="Fig5"><label>Figure 5</label><caption><p>Evaluation with juvenile (n = 6, T1) and adult (n = 5, T2) marmosets. Bar graph diagrams (<bold>a</bold>,<bold>c</bold>) showing results from atlasBREX (ABX), Brain-Extraction-Tool v2 (BET), 3dSkullStrip (3DSS), Primatologist-Toolbox (PRIMA) and Marker based watershed scalper (MBWSS). Results from alternate technical methods were compared to ABX using Friedman test followed by Dunn’s post-hoc test. (*) p-value &lt; 0.05, (**) p-value &lt; 0.01, (***) p-value &lt; 0.001, (ns) non-significant. Mdn, IQR. For juvenile (<bold>b</bold>) and adult (<bold>d</bold>) marmoset, results from each method are demonstrated for a representative subject in coronal plane. First image (α) shows a 3D surface model computed from the result of ABX. The following images (β, γ, δ, ε, ζ) demonstrate the same slice using a three-coloured overlay (yellow colour indicates voxel match, while red (brain tissue erosion) or green (residual non-brain tissue) colour show mismatch) between reference and the respective result from ABX (β), BET (γ), 3DSS (δ), PRIMA (ε) and MBWSS (ζ).</p></caption><graphic xlink:href="41598_2019_48489_Fig5_HTML" id="d29e1143"/></fig></p>
    </sec>
    <sec id="Sec11">
      <title>Evaluation with adult mice</title>
      <p id="Par23">Moreover, we evaluated ABX with a rodent dataset, which is challenging to most brain extraction algorithms considering the vastly different brain morphology and difference in contrast between brain and scalp when compared to the primate brain. As shown in Fig. <xref rid="Fig6" ref-type="fig">6</xref>, ABX (Mdn[IQR] = 0.93[0.01]) demonstrated accurate results similar to its performance shown with non-human primates. While PCNN3D (Mdn[IQR] = 0.93[0.02], p &gt; 0.99) and 3DSS (Mdn[IQR] = 0.86[0.02], p = 0.27) achieved similar performance (see Fig. <xref rid="Fig6" ref-type="fig">6a</xref>), visual inspection suggested (minor) manual corrections in individual cases. Both RATS (Mdn[IQR] = 0.68[0.16], p = 0.002) and BET (Mdn[IQR] = 0.64[0.02], p = 0.002) provided insufficient results, as demonstrated in Fig. <xref rid="Fig6" ref-type="fig">6b</xref>, panel γ (BET) and ζ (RATS).<fig id="Fig6"><label>Figure 6</label><caption><p>Evaluation with adult (n = 6, T2) mice. First panel (a) presents a bar graph diagram from results of atlasBREX (ABX), Brain-Extraction-Tool v2 (BET), 3dSkullStrip (3DSS), Robust automatic rodent brain extraction using 3-D pulse-coupled neural networks (PCNN3D) and Rapid Automatic Tissue Segmentation (RATS). Results from alternate technical approaches were compared to ABX using Friedman test followed by Dunn’s post-hoc test. (**) p-value &lt; 0.01, (ns) non-significant. Mdn, IQR. Second panel (b) demonstrates results from each method for a representative subject in coronal plane. First image (α) shows a 3D surface model computed from the result of ABX. The following images (β, γ, δ, ε, ζ) demonstrate the same coronal slice using a three-coloured overlay (yellow colour indicates voxel match, while red (brain tissue erosion) or green (residual non-brain tissue) colour show mismatch) between reference and the respective result from ABX (β), BET (γ), 3DSS (δ), PCNN3D (ε) and RATS (ζ).</p></caption><graphic xlink:href="41598_2019_48489_Fig6_HTML" id="d29e1168"/></fig></p>
    </sec>
  </sec>
  <sec id="Sec12" sec-type="discussion">
    <title>Discussion</title>
    <p id="Par24">We introduced atlasBREX (ABX), a generic automated template-derived approach for brain extraction, and evaluated it with different animal models (macaque, marmoset and rodent) and MRI protocols (T1, T2). ABX demonstrated best performance and presented accurate and consistent results throughout datasets. We showed that (semi-) automated brain extraction using ABX can achieve results similar to manual (hybrid) skull-stripping, which is highly operator-dependent as a function of time-expenditure, neuroanatomical knowledge and experience with subsequent intra-/inter-individual variability. Provided that these premises are not given or present a limiting factor, standardised (semi-) automated skull-stripping using ABX can present a beneficial alternative. While our proposed approach is not entirely operator-independent, the results are substantially less subject to intra-/inter-rater variability compared to manual skull-stripping (as shown in Fig. <xref rid="Fig4" ref-type="fig">4</xref>).</p>
    <p id="Par25">We evaluated our proposed method in comparison to several other technical approaches including Marker based watershed scalper (MBWSS), Brain-Extraction-Tool v2 (BET), 3dSkullStrip (3DSS), Primatologist-Toolbox (PRIMA), Rapid Automatic Tissue Segmentation (RATS) and Robust automatic rodent brain extraction using 3D pulse-coupled neural networks (PCNN3D). In certain datasets, some of the alternative technical methods were able to provide accurate results, however, failed in other conditions, which is, inter alia, attributable to variable field inhomogeneity and differences in contrast pattern<sup><xref ref-type="bibr" rid="CR1">1</xref></sup>. Unlike other technical implementations using convoluted inferences derived from intensity, morphology or surface, template-based methods like ABX present a generic approach with greater versatility regarding interspecies differences in brain size, shape and tissue contrast. The current study demonstrated that our proposed approach shows robust performance regardless of difference in the degree of sulcus folding (macaque vs. marmoset), brain size (marmoset vs. rodent), developmental time course (juvenile vs. adult marmosets) and contrast pattern (T1/T2 or 3 T/7 T/9.4 T). Moreover, template-based approaches allow for simple implementation of specific segmentation protocols with in- or exclusion of distinct brain regions, such as the brain stem, optic chiasm or cerebellum.</p>
    <p id="Par26">But these benefits come at the cost of high computational demand (typically a few hours) and the time investment of a single manual operation, which is still considerably less manual effort than manual (hybrid) skull-stripping of an entire dataset. In contrast, computational workload and computation time was for the herein tested alternatives much lower (a few minutes). Although, this downside becomes debatable with regard to the likelihood for laborious manual intervention, the growing availability of advanced computing systems in research environments and faster non-linear registration algorithms using multithreading and GPU computing. With regard to the importance of skull-stripping for further processing and data analysis, it is common that reasonable amount of effort is dedicated towards achieving accurate results. However, where dedicated technical approaches, such as PCNN3D for rodents, achieve accurate and robust results within a fraction of computation time, suchlike methods should be considered. In the near future an emerging number of methods will leverage the potential of artificial intelligence (AI), e.g. using machine learning (ML) algorithms and convolutional neural networks (CNN), however, it remains controversial whether these methods will be able to provide versatile performance across MRI protocols, species and populations.</p>
    <p id="Par27">Study-specific templates provide the advantage of accounting for inter-subject variation and providing favourable contrast pattern, which can improve rigid and non-rigid deformation. A hierarchical group-wise registration framework, Atlas Building by Self-Organized Registration and Bundling (ABSORB)<sup><xref ref-type="bibr" rid="CR14">14</xref></sup>, was utilised for unbiased anatomical template building: ABSORB provides accurate templates with sharp structural boundaries using an iterative hierarchical group-wise registration approach, where images are warped towards a set of eligible neighbours and representative images from clusters advance to higher levels. In opposition to other template-based methods, which require either multiple atlases or laborious preparation of probabilistic maps, ABX achieves simple and straightforward skull-stripping with unbiased anatomical atlas building from the study-cohort.</p>
    <p id="Par28">In conclusion, we showed that ABX facilitates robust skull-stripping across T1-/T2-weighted datasets from different species (macaques, marmosets and rodents) at different developmental stages. Due to its generic nature, our proposed approach should be foremost considered for animal MRI studies, where no superior or equivalent dedicated technical method is available. Moreover, it is suitable for neurodevelopmental studies considering the vast morphological changes throughout brain development<sup><xref ref-type="bibr" rid="CR18">18</xref>,<xref ref-type="bibr" rid="CR19">19</xref></sup>, which can be challenging for brain extraction algorithms. Due to implementation as a scriptable (semi-) automated processing pipeline, large-scale, high-throughput application in functional and structural MRI studies is feasible. While ABX makes use of existing neuroimaging frameworks, the provided solution is not implemented in the respective applications and is novel among the technical methods applied. In addition, implementation using popular neuroimaging frameworks may benefit from their ongoing development, such as improvements regarding registration algorithms or parallel computing. Limitations of the current study are (to some extent) small sample size and evaluation restricted to non-human primates and rodents. Future studies should include larger sample size, in particular from open animal neuroimaging databases, which only started gaining in popularity in recent years<sup><xref ref-type="bibr" rid="CR15">15</xref>,<xref ref-type="bibr" rid="CR20">20</xref></sup>.</p>
  </sec>
</body>
<back>
  <fn-group>
    <fn>
      <p><bold>Publisher’s note:</bold> Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
    </fn>
  </fn-group>
  <ack>
    <title>Acknowledgements</title>
    <p>We would like to thank Drs Yuji Komako and Fumiko Seki (Central Institute for Experimental Animals), Dr. Takuya Hayashi (RIKEN Center for Life Science Technologies) for their respective datasets. Moreover, sincere gratitude goes to the German Academic Scholar Foundation (Studienstiftung des deutschen Volkes) and Japan Agency for Medical Research and Development (A-MED). This research project was supported by Brain/MINDS from A-MED (JP19dm0207001).</p>
  </ack>
  <notes notes-type="author-contribution">
    <title>Author Contributions</title>
    <p>J.L.: Study design, data collection, data analysis, interpretation of data, writing of manuscript drafts, revising and approving final content of manuscript. T.K.: Study design, data collection, data analysis, revising and approving final content of manuscript. B.H.: Study design, revising and approving final content of manuscript. M.M.: Study design, revising and approving final content of manuscript. H.O.: Study design, supervision, revising and approving final content of manuscript. All authors critically revised the manuscript.</p>
  </notes>
  <notes notes-type="data-availability">
    <title>Data Availability</title>
    <p>Authors confirm that all relevant data are included in the article.</p>
  </notes>
  <notes notes-type="COI-statement">
    <title>Competing Interests</title>
    <p id="Par29">The authors declare no competing interests.</p>
  </notes>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <label>1.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kalavathi</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Prasath</surname>
            <given-names>VB</given-names>
          </name>
        </person-group>
        <article-title>Methods on skull stripping of MRI head scan images-a review</article-title>
        <source>J Digit Imaging</source>
        <year>2016</year>
        <volume>29</volume>
        <fpage>365</fpage>
        <lpage>379</lpage>
        <pub-id pub-id-type="doi">10.1007/s10278-015-9847-8</pub-id>
        <pub-id pub-id-type="pmid">26628083</pub-id>
      </element-citation>
    </ref>
    <ref id="CR2">
      <label>2.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Russ</surname>
            <given-names>BE</given-names>
          </name>
          <name>
            <surname>Kaneko</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Saleem</surname>
            <given-names>KS</given-names>
          </name>
          <name>
            <surname>Berman</surname>
            <given-names>RA</given-names>
          </name>
          <name>
            <surname>Leopold</surname>
            <given-names>DA</given-names>
          </name>
        </person-group>
        <article-title>Distinct fMRI responses to self-induced versus stimulus motion during free viewing in the macaque</article-title>
        <source>J Neurosci</source>
        <year>2016</year>
        <volume>36</volume>
        <fpage>9580</fpage>
        <lpage>9589</lpage>
        <pub-id pub-id-type="doi">10.1523/JNEUROSCI.1152-16.2016</pub-id>
        <pub-id pub-id-type="pmid">27629710</pub-id>
      </element-citation>
    </ref>
    <ref id="CR3">
      <label>3.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kishi</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Sato</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Sasaki</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Okano</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <article-title>Common marmoset as a new model animal for neuroscience research and genome editing technology</article-title>
        <source>Dev Growth Differ</source>
        <year>2014</year>
        <volume>56</volume>
        <fpage>53</fpage>
        <lpage>62</lpage>
        <pub-id pub-id-type="doi">10.1111/dgd.12109</pub-id>
        <pub-id pub-id-type="pmid">24387631</pub-id>
      </element-citation>
    </ref>
    <ref id="CR4">
      <label>4.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Okano</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Mitra</surname>
            <given-names>P</given-names>
          </name>
        </person-group>
        <article-title>Brain-mapping projects using the common marmoset</article-title>
        <source>Neurosci Res</source>
        <year>2015</year>
        <volume>93</volume>
        <fpage>3</fpage>
        <lpage>7</lpage>
        <pub-id pub-id-type="doi">10.1016/j.neures.2014.08.014</pub-id>
        <pub-id pub-id-type="pmid">25264372</pub-id>
      </element-citation>
    </ref>
    <ref id="CR5">
      <label>5.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Komaki</surname>
            <given-names>Y</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Functional brain mapping using specific sensory-circuit stimulation and a theoretical graph network analysis in mice with neuropathic allodynia</article-title>
        <source>Sci Rep</source>
        <year>2016</year>
        <volume>6</volume>
        <fpage>37802</fpage>
        <pub-id pub-id-type="doi">10.1038/srep37802</pub-id>
        <?supplied-pmid 27898057?>
        <pub-id pub-id-type="pmid">27898057</pub-id>
      </element-citation>
    </ref>
    <ref id="CR6">
      <label>6.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Okano</surname>
            <given-names>H</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Brain/MINDS: A japanese national brain project for marmoset neuroscience</article-title>
        <source>Neuron</source>
        <year>2016</year>
        <volume>92</volume>
        <fpage>582</fpage>
        <lpage>590</lpage>
        <pub-id pub-id-type="doi">10.1016/j.neuron.2016.10.018</pub-id>
        <pub-id pub-id-type="pmid">27809998</pub-id>
      </element-citation>
    </ref>
    <ref id="CR7">
      <label>7.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lythgoe</surname>
            <given-names>MF</given-names>
          </name>
          <name>
            <surname>Sibson</surname>
            <given-names>NR</given-names>
          </name>
          <name>
            <surname>Harris</surname>
            <given-names>NG</given-names>
          </name>
        </person-group>
        <article-title>Neuroimaging of animal models of brain disease</article-title>
        <source>Br Med Bull</source>
        <year>2003</year>
        <volume>65</volume>
        <fpage>235</fpage>
        <lpage>257</lpage>
        <pub-id pub-id-type="doi">10.1093/bmb/65.1.235</pub-id>
        <pub-id pub-id-type="pmid">12697629</pub-id>
      </element-citation>
    </ref>
    <ref id="CR8">
      <label>8.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Beare</surname>
            <given-names>R</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Brain extraction using the watershed transform from markers</article-title>
        <source>Front Neuroinform</source>
        <year>2013</year>
        <volume>7</volume>
        <fpage>32</fpage>
        <pub-id pub-id-type="doi">10.3389/fninf.2013.00032</pub-id>
        <?supplied-pmid 24367327?>
        <pub-id pub-id-type="pmid">24367327</pub-id>
      </element-citation>
    </ref>
    <ref id="CR9">
      <label>9.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Smith</surname>
            <given-names>SM</given-names>
          </name>
        </person-group>
        <article-title>Fast robust automated brain extraction</article-title>
        <source>Hum Brain Mapp</source>
        <year>2002</year>
        <volume>17</volume>
        <fpage>143</fpage>
        <lpage>155</lpage>
        <pub-id pub-id-type="doi">10.1002/hbm.10062</pub-id>
        <pub-id pub-id-type="pmid">12391568</pub-id>
      </element-citation>
    </ref>
    <ref id="CR10">
      <label>10.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Cox</surname>
            <given-names>RW</given-names>
          </name>
        </person-group>
        <article-title>AFNI: Software for analysis and visualization of functional magnetic resonance neuroimages</article-title>
        <source>Comput Biomed Res</source>
        <year>1996</year>
        <volume>29</volume>
        <fpage>162</fpage>
        <lpage>173</lpage>
        <pub-id pub-id-type="doi">10.1006/cbmr.1996.0014</pub-id>
        <pub-id pub-id-type="pmid">8812068</pub-id>
      </element-citation>
    </ref>
    <ref id="CR11">
      <label>11.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Balbastre</surname>
            <given-names>Y</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Primatologist: A modular segmentation pipeline for macaque brain morphometry</article-title>
        <source>Neuroimage</source>
        <year>2017</year>
        <volume>162</volume>
        <fpage>306</fpage>
        <lpage>321</lpage>
        <pub-id pub-id-type="doi">10.1016/j.neuroimage.2017.09.007</pub-id>
        <pub-id pub-id-type="pmid">28899745</pub-id>
      </element-citation>
    </ref>
    <ref id="CR12">
      <label>12.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Oguz</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Rumple</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Sonka</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>RATS: Rapid automatic tissue segmentation in rodent brain MRI</article-title>
        <source>J Neurosci Methods</source>
        <year>2014</year>
        <volume>221</volume>
        <fpage>175</fpage>
        <lpage>182</lpage>
        <pub-id pub-id-type="doi">10.1016/j.jneumeth.2013.09.021</pub-id>
        <pub-id pub-id-type="pmid">24140478</pub-id>
      </element-citation>
    </ref>
    <ref id="CR13">
      <label>13.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chou</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Wu</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Bai Bingren</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Qiu</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Chuang</surname>
            <given-names>KH</given-names>
          </name>
        </person-group>
        <article-title>Robust automatic rodent brain extraction using 3-D pulse-coupled neural networks (PCNN)</article-title>
        <source>IEEE Trans Image Process</source>
        <year>2011</year>
        <volume>20</volume>
        <fpage>2554</fpage>
        <lpage>2564</lpage>
        <pub-id pub-id-type="doi">10.1109/TIP.2011.2126587</pub-id>
        <pub-id pub-id-type="pmid">21411404</pub-id>
      </element-citation>
    </ref>
    <ref id="CR14">
      <label>14.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Jia</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Wu</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>Q</given-names>
          </name>
          <name>
            <surname>Shen</surname>
            <given-names>D</given-names>
          </name>
        </person-group>
        <article-title>ABSORB: Atlas building by self-organized registration and bundling</article-title>
        <source>Neuroimage</source>
        <year>2010</year>
        <volume>51</volume>
        <fpage>1057</fpage>
        <lpage>1070</lpage>
        <pub-id pub-id-type="doi">10.1016/j.neuroimage.2010.03.010</pub-id>
        <pub-id pub-id-type="pmid">20226255</pub-id>
      </element-citation>
    </ref>
    <ref id="CR15">
      <label>15.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Young</surname>
            <given-names>JT</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>The UNC-Wisconsin rhesus macaque neurodevelopment database: A structural MRI and DTI database of early postnatal development</article-title>
        <source>Front Neurosci</source>
        <year>2017</year>
        <volume>11</volume>
        <fpage>29</fpage>
        <pub-id pub-id-type="doi">10.3389/fnins.2017.00029</pub-id>
        <?supplied-pmid 28210206?>
        <pub-id pub-id-type="pmid">28210206</pub-id>
      </element-citation>
    </ref>
    <ref id="CR16">
      <label>16.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Shattuck</surname>
            <given-names>DW</given-names>
          </name>
          <name>
            <surname>Leahy</surname>
            <given-names>RM</given-names>
          </name>
        </person-group>
        <article-title>BrainSuite: An automated cortical surface identification tool</article-title>
        <source>Med Image Anal</source>
        <year>2002</year>
        <volume>6</volume>
        <fpage>129</fpage>
        <lpage>142</lpage>
        <pub-id pub-id-type="doi">10.1016/S1361-8415(02)00054-3</pub-id>
        <pub-id pub-id-type="pmid">12045000</pub-id>
      </element-citation>
    </ref>
    <ref id="CR17">
      <label>17.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Avants</surname>
            <given-names>BB</given-names>
          </name>
          <name>
            <surname>Epstein</surname>
            <given-names>CL</given-names>
          </name>
          <name>
            <surname>Grossman</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Gee</surname>
            <given-names>JC</given-names>
          </name>
        </person-group>
        <article-title>Symmetric diffeomorphic image registration with cross-correlation: Evaluating automated labeling of elderly and neurodegenerative brain</article-title>
        <source>Med Image Anal</source>
        <year>2008</year>
        <volume>12</volume>
        <fpage>26</fpage>
        <lpage>41</lpage>
        <pub-id pub-id-type="doi">10.1016/j.media.2007.06.004</pub-id>
        <pub-id pub-id-type="pmid">17659998</pub-id>
      </element-citation>
    </ref>
    <ref id="CR18">
      <label>18.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Sanchez</surname>
            <given-names>CE</given-names>
          </name>
          <name>
            <surname>Richards</surname>
            <given-names>JE</given-names>
          </name>
          <name>
            <surname>Almli</surname>
            <given-names>CR</given-names>
          </name>
        </person-group>
        <article-title>Age-specific MRI templates for pediatric neuroimaging</article-title>
        <source>Dev Neuropsychol</source>
        <year>2012</year>
        <volume>37</volume>
        <fpage>379</fpage>
        <lpage>399</lpage>
        <pub-id pub-id-type="doi">10.1080/87565641.2012.688900</pub-id>
        <pub-id pub-id-type="pmid">22799759</pub-id>
      </element-citation>
    </ref>
    <ref id="CR19">
      <label>19.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lenroot</surname>
            <given-names>RK</given-names>
          </name>
          <name>
            <surname>Giedd</surname>
            <given-names>JN</given-names>
          </name>
        </person-group>
        <article-title>Brain development in children and adolescents: Insights from anatomical magnetic resonance imaging</article-title>
        <source>Neurosci Biobehav Rev</source>
        <year>2006</year>
        <volume>30</volume>
        <fpage>718</fpage>
        <lpage>729</lpage>
        <pub-id pub-id-type="doi">10.1016/j.neubiorev.2006.06.001</pub-id>
        <pub-id pub-id-type="pmid">16887188</pub-id>
      </element-citation>
    </ref>
    <ref id="CR20">
      <label>20.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Sakai</surname>
            <given-names>T</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>The japan monkey centre primates brain imaging repository for comparative neuroscience: An archive of digital records including records for endangered species</article-title>
        <source>Primates</source>
        <year>2018</year>
        <volume>59</volume>
        <fpage>553</fpage>
        <lpage>570</lpage>
        <pub-id pub-id-type="doi">10.1007/s10329-018-0694-3</pub-id>
        <pub-id pub-id-type="pmid">30357587</pub-id>
      </element-citation>
    </ref>
  </ref-list>
</back>
