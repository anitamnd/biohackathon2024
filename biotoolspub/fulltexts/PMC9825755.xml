<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id>
    <journal-id journal-id-type="publisher-id">bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1367-4803</issn>
    <issn pub-type="epub">1367-4811</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">9825755</article-id>
    <article-id pub-id-type="pmid">36495196</article-id>
    <article-id pub-id-type="doi">10.1093/bioinformatics/btac773</article-id>
    <article-id pub-id-type="publisher-id">btac773</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Applications Note</subject>
        <subj-group subj-group-type="category-toc-heading">
          <subject>Structural Bioinformatics</subject>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI01060</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>ManyFold: an efficient and flexible library for training and validating protein folding models</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-3286-049X</contrib-id>
        <name>
          <surname>Villegas-Morcillo</surname>
          <given-names>Amelia</given-names>
        </name>
        <aff><institution>InstaDeep</institution>, London W2 1AY, <country country="GB">UK</country></aff>
        <aff><institution>Department of Signal Theory, Telematics and Communications, University of Granada</institution>, Granada 18071, <country country="ES">Spain</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Robinson</surname>
          <given-names>Louis</given-names>
        </name>
        <aff><institution>InstaDeep</institution>, London W2 1AY, <country country="GB">UK</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Flajolet</surname>
          <given-names>Arthur</given-names>
        </name>
        <aff><institution>InstaDeep</institution>, London W2 1AY, <country country="GB">UK</country></aff>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Barrett</surname>
          <given-names>Thomas D</given-names>
        </name>
        <aff><institution>InstaDeep</institution>, London W2 1AY, <country country="GB">UK</country></aff>
        <xref rid="btac773-cor1" ref-type="corresp"/>
        <!--t.barrett@instadeep.com-->
      </contrib>
    </contrib-group>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Martelli</surname>
          <given-names>Pier Luigi</given-names>
        </name>
        <role>Associate Editor</role>
      </contrib>
    </contrib-group>
    <author-notes>
      <corresp id="btac773-cor1">To whom correspondence should be addressed. <email>t.barrett@instadeep.com</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <month>1</month>
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2022-12-10">
      <day>10</day>
      <month>12</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>10</day>
      <month>12</month>
      <year>2022</year>
    </pub-date>
    <volume>39</volume>
    <issue>1</issue>
    <elocation-id>btac773</elocation-id>
    <history>
      <date date-type="received">
        <day>02</day>
        <month>9</month>
        <year>2022</year>
      </date>
      <date date-type="rev-recd">
        <day>07</day>
        <month>11</month>
        <year>2022</year>
      </date>
      <date date-type="editorial-decision">
        <day>25</day>
        <month>11</month>
        <year>2022</year>
      </date>
      <date date-type="corrected-typeset">
        <day>13</day>
        <month>12</month>
        <year>2022</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2022. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2022</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="btac773.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Summary</title>
        <p>ManyFold is a flexible library for protein structure prediction with deep learning that (i) supports models that use both multiple sequence alignments (MSAs) and protein language model (pLM) embedding as inputs, (ii) allows inference of existing models (AlphaFold and OpenFold), (iii) is fully trainable, allowing for both fine-tuning and the training of new models from scratch and (iv) is written in Jax to support efficient batched operation in distributed settings. A proof-of-concept pLM-based model, pLMFold, is trained from scratch to obtain reasonable results with reduced computational overheads in comparison to AlphaFold.</p>
      </sec>
      <sec id="s2">
        <title>Availability and implementation</title>
        <p>The source code for ManyFold, the validation dataset and a small sample of training data are available at <ext-link xlink:href="https://github.com/instadeepai/manyfold" ext-link-type="uri">https://github.com/instadeepai/manyfold</ext-link>.</p>
      </sec>
      <sec id="s4">
        <title>Supplementary information</title>
        <p><xref rid="sup1" ref-type="supplementary-material">Supplementary data</xref> are available at <italic toggle="yes">Bioinformatics</italic> online.</p>
      </sec>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>TPUs from Google’s TPU Research Cloud</institution>
          </institution-wrap>
        </funding-source>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="3"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 Introduction</title>
    <p>The prediction of 3D protein structure from amino acid sequence is a challenging problem due to complex interactions between residues occurring in the space. Due to the close relationship between protein structure and biological function, methods that attempt to predict structures using only the amino acid sequence hold significant value, whilst still representing a significant practical challenge. In recent years, deep learning has emerged as the <italic toggle="yes">de facto</italic> paradigm of choice for so-called <italic toggle="yes">ab initio</italic> protein structure prediction, rapidly become the state-of-art approach.</p>
    <p>In particular, AlphaFold v2 (<xref rid="btac773-B4" ref-type="bibr">Jumper <italic toggle="yes">et al.</italic>, 2021</xref>)—the most successful folding model to date—is able to generate plausible protein structures as a result of massive computation on large multiple sequence alignments (MSAs) and, optionally, templates of similar sequences with known structure. However, these inputs can be computationally expensive to generate, rely on searching large databases and can be of low quality for many rare proteins that lack known homologs.</p>
    <p>An alternative is to take advantage of the vast amount of protein sequences contained in public databases to train protein language models (pLMs) (<xref rid="btac773-B2" ref-type="bibr">Elnaggar <italic toggle="yes">et al.</italic>, 2021</xref>; <xref rid="btac773-B7" ref-type="bibr">Rives <italic toggle="yes">et al.</italic>, 2021</xref>). Since the self-supervisory signal is the amino acid sequence itself, no structure information is needed to train pLMs. Moreover, the internal representations (or embeddings) learned by pLMs have proven successful in predicting the structural attributes of the protein. This is inspiring a new generation of folding models that replace the input MSAs with pre-trained pLM embeddings (<xref rid="btac773-B3" ref-type="bibr">Fang <italic toggle="yes">et al.</italic>, 2022</xref>; <xref rid="btac773-B5" ref-type="bibr">Lin <italic toggle="yes">et al.</italic>, 2022</xref>; <xref rid="btac773-B8" ref-type="bibr">Wu <italic toggle="yes">et al.</italic>, 2022</xref>).</p>
    <p>The development of the next generation of protein folding models has been aided by the open-sourcing of AlphaFold (inference only), and, re-implementations such as OpenFold (inference and training code in PyTorch) (<xref rid="btac773-B1" ref-type="bibr">Ahdritz <italic toggle="yes">et al.</italic>, 2022</xref>). However, the immense complexity and computational cost associated with developing such models still present a significant bottleneck and challenge to the wider community. To support these efforts, in this work, we introduce ManyFold—a flexible protein folding library that can implement multiple models (both MSA-based and pLM-based), is fully trainable and highly efficient, supporting batched operations and distributed compute across platforms. As well as demonstrating our pipeline on existing AlphaFold and OpenFold models, we also train from scratch a proof-of-concept pLM-based model, pLMFold. Using ESM-1b (<xref rid="btac773-B7" ref-type="bibr">Rives <italic toggle="yes">et al.</italic>, 2021</xref>) embeddings and attention maps as input to a lightweight AlphaFold-inspired network, pLMFold obtains reasonable results while significantly reducing inference time.</p>
  </sec>
  <sec>
    <title>2 Approach</title>
    <p>ManyFold is implemented in Python and Jax (<ext-link xlink:href="http://github.com/google/jax" ext-link-type="uri">http://github.com/google/jax</ext-link>). It allows for distributed training and efficient batched validation on a variety of platforms, including graphical processing units (GPUs) and tensor processing units (TPUs). The library contains all necessary scripts for training full AlphaFold models from either randomly initialized parameters and optimizer state, a previously stored checkpoint or pre-trained model parameters (for model fine-tuning). In addition, it can perform batched inference on validation sets to obtain the predicted structures and confidence metrics. Similarly, validation and fine-tuning of OpenFold models are also allowed (see <ext-link xlink:href="https://github.com/aqlaboratory/openfold" ext-link-type="uri">https://github.com/aqlaboratory/openfold</ext-link> on how to convert the model parameters into Jax).</p>
    <p>Additionally, ManyFold includes a new model called pLMFold, which we introduce here (<xref rid="btac773-F1" ref-type="fig">Fig. 1A</xref>). Unlike AlphaFold, which takes MSAs as inputs, the pLMFold model works on single protein sequences represented by pLM embeddings. While pLMFold can operate on any type of pLM embeddings, we use the ESM-1 family of models (<xref rid="btac773-B7" ref-type="bibr">Rives <italic toggle="yes">et al.</italic>, 2021</xref>) for this proof-of-concept (Jax implementations and weights are also provided). To process single sequences, we developed a more efficient version of the Evoformer, the pLMformer. Its inputs are (i) a single representation, which is a weighted average of the pLM embeddings over the different layers of the pLM and (ii) a pair representation that can be initialized to either the outer sum of the single representations or the averaged attention heads of the input pLM transformer. Then, the pLMformer applies multi-head attention over the single representation alone and reduces the model complexity by removing the triangle self-attention of AlphaFold which has computational cost scaling cubically with sequence length. This is in contrast to previous pLM-based prediction models [ESMFold (<xref rid="btac773-B5" ref-type="bibr">Lin <italic toggle="yes">et al.</italic>, 2022</xref>), OmegaFold (<xref rid="btac773-B8" ref-type="bibr">Wu <italic toggle="yes">et al.</italic>, 2022</xref>) and HelixFold-Single (<xref rid="btac773-B3" ref-type="bibr">Fang <italic toggle="yes">et al.</italic>, 2022</xref>)], where these computationally intensive operations are retained.</p>
    <fig position="float" id="btac773-F1">
      <label>Fig. 1.</label>
      <caption>
        <p>(<bold>A</bold>) The pLMFold model: a pre-trained pLM model first converts the input amino acid sequence into single and pair representations that are processed in the pLMformer module. The output is then fed into the structure module to generate the predicted protein structure. (<bold>B</bold>) Validation results measured as lDDT scores for our pLMFold model compared to other pLM-based models and AlphaFold (using either MSAs or single sequences as inputs). ‘Full’ refers to <monospace>model_1_ptm</monospace> and ‘No templates’ to <monospace>model_5_ptm</monospace>. (<bold>C</bold>) Inference times computed for pLMFold and AlphaFold over input sequences with different lengths. Inference times are averaged over five batches, each containing a single validation sample</p>
      </caption>
      <graphic xlink:href="btac773f1" position="float"/>
    </fig>
    <p>To validate ManyFold, we trained the pLMFold from scratch (using ESM-1b as pre-trained model and the original AlphaFold training data) on Google TPUs v2-128 (training details can be found in <xref rid="sup1" ref-type="supplementary-material">Supplementary material S1</xref>). Although pLMFold was trained using a subset of losses (structure loss, distogram loss and pLDDT loss), the tool supports training/fine-tuning on all losses defined for AlphaFold. The learning curves of pLMFold are provided in <xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S1</xref>. We then validated this model along with pre-trained AlphaFold, OpenFold, ESMFold, OmegaFold and HelixFold-Single models using an NVIDIA A100 GPU. Note that, unlike these methods, our pLMFold model was not fine-tuned on larger crops and did not use predicted structures as distillation targets during training.</p>
  </sec>
  <sec>
    <title>3 Results</title>
    <p>The performance of our folding models is validated on CAMEO targets from March to May 2022 with less than 700 residues, and domains from CASP14 (see <xref rid="sup1" ref-type="supplementary-material">Supplementary material S2</xref> for the full list of target ids). <xref rid="btac773-F1" ref-type="fig">Figure 1B</xref> shows the lDDT scores (<xref rid="btac773-B6" ref-type="bibr">Mariani <italic toggle="yes">et al.</italic>, 2013</xref>) given by pLMFold and two AlphaFold models using MSAs or just the target sequence as input (labeled as ‘No MSA’). Extended results for both datasets—including other widely used metrics such as TM-score and GDT-TS—are provided in <xref rid="sup1" ref-type="supplementary-material">Supplementary Tables S1 and S2</xref>. Ultimately, the performance of AlphaFold drops significantly when only the target sequence is provided as input (similar results are obtained with the OpenFold parameters as detailed in <xref rid="sup1" ref-type="supplementary-material">Supplementary material S2</xref>). By contrast, the pLMFold achieves considerably better results with the same limited input information (recovering 81.4% of the performance on CAMEO of the full AlphaFold model using MSA and templates). Moreover, pLMFold outperforms the full AlphaFold model for ∼5% of the evaluated targets. We also note that pLMFold does not use the additional fine-tuning or self-distillation phases of the full AlphaFold pipeline.</p>
    <p><xref rid="btac773-F1" ref-type="fig">Figure 1C</xref> plots the batched inference time as a function of sequence length, where the almost exponential scaling of AlphaFold inference time can be contrasted to the more linear scaling of pLMFold—culminating in a 6× speed for the longest targets. Indeed, this is a conservative estimate of the speed-up as the additional overheads of generating MSA and template features are not included for AlphaFold, whereas the calculation of ESM-1b embeddings is included for pLMFold.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material id="sup1" position="float" content-type="local-data">
      <label>btac773_Supplementary_Data</label>
      <media xlink:href="btac773_supplementary_data.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <sec>
    <title>Funding</title>
    <p>This work was supported with TPUs from Google’s TPU Research Cloud (TRC).</p>
    <p><italic toggle="yes">Conflict of Interest</italic>: none declared.</p>
  </sec>
  <sec sec-type="data-availability">
    <title>Data availability</title>
    <p>The data underlying this article are available at <ext-link xlink:href="https://github.com/instadeepai/manyfold" ext-link-type="uri">https://github.com/instadeepai/manyfold</ext-link>.</p>
  </sec>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="btac773-B1">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Ahdritz</surname><given-names>G.</given-names></string-name></person-group><etal>et al</etal> (<year>2022</year>) OpenFold: retraining AlphaFold2 yields new insights into its learning mechanisms and capacity for generalization. <italic toggle="yes">bioRxiv</italic>, 517210. <pub-id pub-id-type="doi">10.1101/2022.11.20</pub-id>.</mixed-citation>
    </ref>
    <ref id="btac773-B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Elnaggar</surname><given-names>A.</given-names></string-name></person-group><etal>et al</etal> (<year>2021</year>) <article-title>ProtTrans: towards cracking the language of life’s code through self-supervised deep learning and high performance computing</article-title>. <source>IEEE Trans. Pattern Anal. Mach. Intell</source>., <bold>44</bold>, <fpage>7112</fpage>–<lpage>7127</lpage>.</mixed-citation>
    </ref>
    <ref id="btac773-B3">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Fang</surname><given-names>X.</given-names></string-name></person-group><etal>et al</etal> (<year>2022</year>) HelixFold-Single: MSA-free protein structure prediction by using protein language model as an alternative. <italic toggle="yes">arXiv</italic>, <pub-id pub-id-type="doi">10.48550/ARXIV.2207.13921</pub-id>.</mixed-citation>
    </ref>
    <ref id="btac773-B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jumper</surname><given-names>J.</given-names></string-name></person-group><etal>et al</etal> (<year>2021</year>) <article-title>Highly accurate protein structure prediction with AlphaFold</article-title>. <source>Nature</source>, <volume>596</volume>, <fpage>583</fpage>–<lpage>589</lpage>.<pub-id pub-id-type="pmid">34265844</pub-id></mixed-citation>
    </ref>
    <ref id="btac773-B5">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Lin</surname><given-names>Z.</given-names></string-name></person-group><etal>et al</etal> (<year>2022</year>) Language models of protein sequences at the scale of evolution enable accurate structure prediction. <italic toggle="yes">bioRxiv</italic>, <pub-id pub-id-type="doi">10.1101/2022.07.20.500902</pub-id>.</mixed-citation>
    </ref>
    <ref id="btac773-B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mariani</surname><given-names>V.</given-names></string-name></person-group><etal>et al</etal> (<year>2013</year>) <article-title>lDDT: a local superposition-free score for comparing protein structures and models using distance difference tests</article-title>. <source>Bioinformatics</source>, <volume>29</volume>, <fpage>2722</fpage>–<lpage>2728</lpage>.<pub-id pub-id-type="pmid">23986568</pub-id></mixed-citation>
    </ref>
    <ref id="btac773-B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rives</surname><given-names>A.</given-names></string-name></person-group><etal>et al</etal> (<year>2021</year>) <article-title>Biological structure and function emerge from scaling unsupervised learning to 250 million protein sequences</article-title>. <source>Proc. Natl. Acad. Sci. USA</source>, <volume>118</volume>, <fpage>e2016239118</fpage>.<pub-id pub-id-type="pmid">33876751</pub-id></mixed-citation>
    </ref>
    <ref id="btac773-B8">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Wu</surname><given-names>R.</given-names></string-name></person-group><etal>et al</etal> (<year>2022</year>) High-resolution de novo structure prediction from primary sequence. <italic toggle="yes">bioRxiv</italic>, <pub-id pub-id-type="doi">10.1101/2022.07.21.500999</pub-id>.</mixed-citation>
    </ref>
  </ref-list>
</back>
