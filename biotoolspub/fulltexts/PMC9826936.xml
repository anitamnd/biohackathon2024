<?DTDIdentifier.IdentifierValue -//ES//DTD journal article DTD version 5.6.0//EN//XML?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName art560.dtd?>
<?SourceDTD.Version 5.6.0?>
<?ConverterInfo.XSLTName elsevier2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<?origin publisher?>
<?FILEmeta_CSBJ1954 xml ?>
<?FILEmain xml ?>
<?FILEmain pdf ?>
<?FILEgr1 jpg ?>
<?FILEgr2 jpg ?>
<?FILEgr3 jpg ?>
<?FILEgr4 jpg ?>
<?FILEgr5 jpg ?>
<?FILEgr6 jpg ?>
<?FILEgr7 jpg ?>
<?FILEgr8 jpg ?>
<?FILEgr9 jpg ?>
<?FILEga1 jpg ?>
<?FILEmmc1 docx ?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Comput Struct Biotechnol J</journal-id>
    <journal-id journal-id-type="iso-abbrev">Comput Struct Biotechnol J</journal-id>
    <journal-title-group>
      <journal-title>Computational and Structural Biotechnology Journal</journal-title>
    </journal-title-group>
    <issn pub-type="epub">2001-0370</issn>
    <publisher>
      <publisher-name>Research Network of Computational and Structural Biotechnology</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">9826936</article-id>
    <article-id pub-id-type="pii">S2001-0370(22)00601-8</article-id>
    <article-id pub-id-type="doi">10.1016/j.csbj.2022.12.043</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Research Article</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>CNN6mA: Interpretable neural network model based on position-specific CNN and cross-interactive network for 6mA site prediction</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" id="au0005">
        <name>
          <surname>Tsukiyama</surname>
          <given-names>Sho</given-names>
        </name>
        <xref rid="aff0005" ref-type="aff">a</xref>
      </contrib>
      <contrib contrib-type="author" id="au0010">
        <name>
          <surname>Hasan</surname>
          <given-names>Md Mehedi</given-names>
        </name>
        <xref rid="aff0010" ref-type="aff">b</xref>
      </contrib>
      <contrib contrib-type="author" id="au0015">
        <name>
          <surname>Kurata</surname>
          <given-names>Hiroyuki</given-names>
        </name>
        <email>kurata@bio.kyutech.ac.jp</email>
        <xref rid="aff0005" ref-type="aff">a</xref>
        <xref rid="cor1" ref-type="corresp">⁎</xref>
      </contrib>
      <aff id="aff0005"><label>a</label>Department of Bioscience and Bioinformatics, Kyushu Institute of Technology, 680–4 Kawazu, Iizuka, Fukuoka 820-8502, Japan</aff>
      <aff id="aff0010"><label>b</label>Tulane Center for Aging and Department of Medicine, Tulane University Health Sciences Center, New Orleans, LA 70112, USA</aff>
    </contrib-group>
    <author-notes>
      <corresp id="cor1"><label>⁎</label>Corresponding author. <email>kurata@bio.kyutech.ac.jp</email></corresp>
    </author-notes>
    <pub-date pub-type="pmc-release">
      <day>28</day>
      <month>12</month>
      <year>2022</year>
    </pub-date>
    <!-- PMC Release delay is 0 months and 0 days and was based on <pub-date
						pub-type="epub">.-->
    <pub-date pub-type="collection">
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="epub">
      <day>28</day>
      <month>12</month>
      <year>2022</year>
    </pub-date>
    <volume>21</volume>
    <fpage>644</fpage>
    <lpage>654</lpage>
    <history>
      <date date-type="received">
        <day>7</day>
        <month>10</month>
        <year>2022</year>
      </date>
      <date date-type="rev-recd">
        <day>26</day>
        <month>12</month>
        <year>2022</year>
      </date>
      <date date-type="accepted">
        <day>27</day>
        <month>12</month>
        <year>2022</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© 2022 The Author(s)</copyright-statement>
      <copyright-year>2022</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).</license-p>
      </license>
    </permissions>
    <abstract id="ab0010">
      <p>N6-methyladenine (6mA) plays a critical role in various epigenetic processing including DNA replication, DNA repair, silencing, transcription, and diseases such as cancer. To understand such epigenetic mechanisms, 6 mA has been detected by high-throughput technologies on a genome-wide scale at single-base resolution, together with conventional methods such as immunoprecipitation, mass spectrometry and capillary electrophoresis, but these experimental approaches are time-consuming and laborious. To complement these problems, we have developed a CNN-based 6 mA site predictor, named CNN6mA, which proposed two new architectures: a position-specific 1-D convolutional layer and a cross-interactive network. In the position-specific 1-D convolutional layer, position-specific filters with different window sizes were applied to an inquiry sequence instead of sharing the same filters over all positions in order to extract the position-specific features at different levels. The cross-interactive network explored the relationships between all the nucleotide patterns within the inquiry sequence. Consequently, CNN6mA outperformed the existing state-of-the-art models in many species and created the contribution score vector that intelligibly interpret the prediction mechanism. The source codes and web application in CNN6mA are freely accessible at <ext-link ext-link-type="uri" xlink:href="https://github.com/kuratahiroyuki/CNN6mA.git" id="ir0005">https://github.com/kuratahiroyuki/CNN6mA.git</ext-link> and <ext-link ext-link-type="uri" xlink:href="http://kurata35.bio.kyutech.ac.jp/CNN6mA/" id="ir0010">http://kurata35.bio.kyutech.ac.jp/CNN6mA/</ext-link>, respectively.</p>
    </abstract>
    <abstract abstract-type="graphical" id="ab0015">
      <title>Graphical Abstract</title>
      <p>
        <fig id="fig0050" position="anchor">
          <alt-text id="at0050">ga1</alt-text>
          <graphic xlink:href="ga1"/>
        </fig>
      </p>
    </abstract>
    <kwd-group id="keys0005">
      <title>Keywords</title>
      <kwd>N6-methyladenine</kwd>
      <kwd>DNA modification</kwd>
      <kwd>Deep learning</kwd>
      <kwd>Machine learning</kwd>
      <kwd>CNN</kwd>
      <kwd>Interpretable prediction</kwd>
    </kwd-group>
    <kwd-group id="keys0010">
      <title>Abbreviations</title>
      <kwd>6mA, N6-methyladenine</kwd>
      <kwd>SMRT, Single-molecule real-time</kwd>
      <kwd>RF, Random forest</kwd>
      <kwd>CNN, Convolutional neural network</kwd>
      <kwd>LSTM, Long short-term memory</kwd>
      <kwd>BERT, Bidirectional Encoder Representations from Transformers</kwd>
      <kwd>AUCs, Area under the curves</kwd>
      <kwd>SN, Sensitivity</kwd>
      <kwd>SP, Specificity</kwd>
      <kwd>MCC, Matthews correlation coefficient</kwd>
      <kwd>t-SNE, t-distributed stochastic neighbor embedding</kwd>
      <kwd>UMAP, Uniform manifold approximation and projection</kwd>
    </kwd-group>
  </article-meta>
</front>
<body>
  <sec id="sec0005">
    <label>1</label>
    <title>Introduction</title>
    <p id="p0005">N6-methyladenine (6 mA) is one of the epigenetic modifications which regulate genetic activities without any change of DNA sequences <xref rid="bib1" ref-type="bibr">[1]</xref>. Recent studies present that N6-methyladenine (6 mA) plays vital roles in a variety of epigenetic processing including DNA replication <xref rid="bib2" ref-type="bibr">[2]</xref>, DNA repair <xref rid="bib3" ref-type="bibr">[3]</xref>, <xref rid="bib4" ref-type="bibr">[4]</xref>, silencing <xref rid="bib5" ref-type="bibr">[5]</xref>, transcription <xref rid="bib6" ref-type="bibr">[6]</xref>, and gene expression <xref rid="bib7" ref-type="bibr">[7]</xref>, <xref rid="bib8" ref-type="bibr">[8]</xref>, and enhances its significance in biological functions and diseases such as cancer <xref rid="bib9" ref-type="bibr">[9]</xref>. To understand such epigenetic mechanisms, 6 mA has been detected by several experimental methods. Especially, high-throughput technologies including single-molecule real-time (SMRT) sequencing have been used for identification of 6 mA sites on a genome-wide scale at single-base resolution <xref rid="bib10" ref-type="bibr">[10]</xref>, <xref rid="bib11" ref-type="bibr">[11]</xref>, <xref rid="bib12" ref-type="bibr">[12]</xref>, together with conventional methods such as liquid chromatography-tandem mass spectrometry <xref rid="bib13" ref-type="bibr">[13]</xref> and capillary electrophoresis with laser-induced fluorescence <xref rid="bib14" ref-type="bibr">[14]</xref>. The validation with different experimental methods enables the identification of DNA modifications with high sensitivity and specificity, while these experimental approaches are time-consuming and laborious. Furthermore, some approaches are poor in the quality of sequencing and signal-to-noise ratios <xref rid="bib15" ref-type="bibr">[15]</xref>. To complement the experimental methods and accelerate an understanding of 6 mA regulation mechanisms, <italic>in silico</italic> approaches of machine learning and deep learning have been developed.</p>
    <p id="p0010">Lv et al. proposed a random forest (RF) model called iDNA-MS <xref rid="bib16" ref-type="bibr">[16]</xref> to predict 6 mA sites with the benchmark datasets of 11 species. This method showed high performances with learning small datasets, while there is room for improvement in the learning abilities with large datasets. To overcome this issue, convolutional neural network (CNN) and recurrent neural network including SICD6mA <xref rid="bib17" ref-type="bibr">[17]</xref> and SNNRice6mA <xref rid="bib18" ref-type="bibr">[18]</xref> have been developed, which predicted 6 mA sites with an accuracy (ACC) of more than 0.9 by capturing context information. Li et al. developed the Deep6mA <xref rid="bib19" ref-type="bibr">[19]</xref> that combines CNN with Long Short-Term Memory (LSTM), which presented higher performances than SNNRice6mA <xref rid="bib18" ref-type="bibr">[18]</xref> and MM-6mAPred <xref rid="bib20" ref-type="bibr">[20]</xref>. The Deep6mA used CNN and LSTM to extract nucleotide patterns and to capture their context relationships, respectively, outperforming the CNN stand-alone model.</p>
    <p id="p0015">In addition to CNN and LSTM, an attention mechanism, which is incorporated in recent powerful neural network models such as Transformer <xref rid="bib21" ref-type="bibr">[21]</xref> and Bidirectional Encoder Representations from Transformers (BERT) <xref rid="bib22" ref-type="bibr">[22]</xref>, has achieved remarkable improvements in the development of neural networks. Huang et al. combined LSTM with attention mechanisms and presented comparable performances to SICD6mA in 6 mA site prediction <xref rid="bib23" ref-type="bibr">[23]</xref>. Yu et al. constructed the BERT-based neural network model, named iDNA-ABT <xref rid="bib24" ref-type="bibr">[24]</xref>, and compared it with the previous models including iDNA-MS and SNNRice6mA on the benchmark datasets constructed by Lv et al. (iDNA-MS). The BERT-based neural network generated the feature vectors, depending on the context information to extract different information exhaustively. iDNA-ABT presented higher ACCs and area under the curves (AUCs) in some species than the previous modification sites prediction models including iDNA-MS, DeepTorrent <xref rid="bib25" ref-type="bibr">[25]</xref>, and SNNRice6mA.</p>
    <p id="p0020">The aforementioned approaches accurately predicted 6 mA sites by using machine learning and deep learning, while they did not intensively address their prediction mechanism. In 2022, we have proposed BERT6mA <xref rid="bib26" ref-type="bibr">[26]</xref> which combined BERT with word2vec-based encoding methods. BERT6mA presented the state-of-the-art performance by capturing the relationship between nucleotides at different positions and generated the attention weights to extract the features responsible for identifying 6 mA-associated nucleotide distributions. On the other hand, BERT6mA ignored the positional information of each nucleotide, while some studies regarding DNA and RNA modification prediction suggested the importance of position-specific features <xref rid="bib27" ref-type="bibr">[27]</xref>, <xref rid="bib28" ref-type="bibr">[28]</xref>.</p>
    <p id="p0025">In this study, we have developed a CNN-based 6 mA site predictor, called CNN6mA. which proposed two new architectures: a position-specific 1-D convolutional layer and a cross-interactive network (<xref rid="fig0005" ref-type="fig">Fig. 1</xref>). In the position-specific 1-D convolutional layer, position-specific filters with different window sizes were applied to an inquiry sequence instead of sharing the same filters over all positions in order to extract the position-specific features at different levels. The cross-interactive network explored the relationships between all the nucleotide patterns within the inquiry sequence. Consequently, CNN6mA outperformed the existing state-of-the-art models in many species and created the contribution score vector that intelligibly interpret the prediction mechanism.<fig id="fig0005"><label>Fig. 1</label><caption><p>Network structure of CNN6mA. The CNN6mA is composed of four sub-networks. In the first sub-network (embedding layer), each nucleotide in the sequences is transformed to feature vectors. Then, the position-specific nucleotide patterns and their relationships are captured by the position-specific 1-D convolutional layers in the second sub-network and the cross-interactive network in the third sub-network, respectively. In the position-specific 1-D convolutional layers, “PAD” indicates zero-padding vectors to make the shapes of the output and input matrices the same. The position-specific 1-D convolutional layers use multi-scale filters with window sizes of 3, 5, and 7. In the final sub-network, the resulting feature tensor is transformed into the contribution score vectors by using the three fully connected layers to calculate the final score.</p></caption><alt-text id="at0005">Fig. 1</alt-text><graphic xlink:href="gr1"/></fig></p>
  </sec>
  <sec id="sec0010">
    <label>2</label>
    <title>Materials and methods</title>
    <sec id="sec0015">
      <label>2.1</label>
      <title>Dataset</title>
      <p id="p0030">To compare CNN6mA with existing state-of-the-art methods, we used a variety of the datasets that were retrieved from Lv et al.’s web application. <xref rid="bib16" ref-type="bibr">[16]</xref>, as shown in <xref rid="sec0085" ref-type="sec">Table S1</xref>. The datasets were composed of 6 mA and non-6 mA sequences in 11 species including <italic>A. thaliana</italic>, <italic>C. elegans</italic>, <italic>C. equisetifpolia</italic>, <italic>D. melanogaster</italic>, <italic>F. vesca</italic>, <italic>H. sapiens</italic>, <italic>R. chinensis</italic>, <italic>S. cerevisiae</italic>, <italic>T. thermophile</italic>, <italic>Ts. SUP5–1</italic>, and <italic>Xoc. BLS256</italic>. We used the 41-bp DNA sequences with 6 mA and non-6 mA at the center as the positive and negative samples, respectively, and then removed the central adenine in both the samples, where the numbers of the two types of samples were the same in each dataset. The datasets were divided into the training and test data at a ratio of one to one.</p>
    </sec>
    <sec id="sec0020">
      <label>2.2</label>
      <title>Deep learning model</title>
      <p id="p0035">As shown in <xref rid="fig0005" ref-type="fig">Fig. 1</xref>, our proposed deep learning model is composed of four sub-networks: the embedding layer, position-specific 1-D convolutional layer, cross-interactive network, and output layer. We proposed the two, novel networks of the position-specific 1-D convolutional layer and cross-interactive network. The position-specific 1-D convolutional layer uses different filters at each position to extract position-specific nucleotide information. In other words, the weights of the position-specific filters at each position are allowed to be changed or optimized in backpropagation. It differs from the normal 1-D convolutional layer that shares the same filters at all the positions. The cross-interactive network considers relationships between pairwise nucleotide patterns within an inquiry sequence.</p>
      <p id="p0040">In the embedding layer, nucleotides A, T, G, and C of the DNA sequence with a length of <italic>N</italic> are converted into indexes 1, 2, 3, and 4, respectively, and then each index is represented as an <italic>M</italic>-dimensional feature vector by nn.Embedding (PyTorch), where <italic>M</italic> set to 64. The resulting <inline-formula><mml:math id="M1" altimg="si0001.svg"><mml:mrow><mml:mi>N</mml:mi><mml:mo>×</mml:mo><mml:mi>M</mml:mi></mml:mrow></mml:math></inline-formula>feature matrix <inline-formula><mml:math id="M2" altimg="si0002.svg"><mml:mrow><mml:mi>X</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></inline-formula> (<inline-formula><mml:math id="M3" altimg="si0003.svg"><mml:mrow><mml:mn>1</mml:mn><mml:mo>≤</mml:mo><mml:mi>i</mml:mi><mml:mo>≤</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="M4" altimg="si0004.svg"><mml:mrow><mml:mn>1</mml:mn><mml:mo>≤</mml:mo><mml:mi>j</mml:mi><mml:mo>≤</mml:mo><mml:mi>M</mml:mi></mml:mrow></mml:math></inline-formula>) is inputted into the position-specific 1-D convolutional layer. We create <italic>F</italic> filters with window size <italic>W</italic> at each sequence position <italic>i</italic>, <inline-formula><mml:math id="M5" altimg="si0005.svg"><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>W</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></inline-formula> (<inline-formula><mml:math id="M6" altimg="si0006.svg"><mml:mrow><mml:mn>1</mml:mn><mml:mo>≤</mml:mo><mml:mi>k</mml:mi><mml:mo>≤</mml:mo><mml:mi>F</mml:mi></mml:mrow></mml:math></inline-formula>), and apply them to <inline-formula><mml:math id="M7" altimg="si0007.svg"><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></inline-formula> generate output matrix <inline-formula><mml:math id="M8" altimg="si0008.svg"><mml:mrow><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>W</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></inline-formula>, given by:<disp-formula id="eqn0005"><label>(1)</label><mml:math id="M9" altimg="si0009.svg"><mml:mrow><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>W</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>W</mml:mi></mml:munderover><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>M</mml:mi></mml:munderover><mml:mrow><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>W</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mstyle displaystyle="true"><mml:mo>⊗</mml:mo></mml:mstyle><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>−</mml:mo><mml:mi>W</mml:mi><mml:mo>/</mml:mo><mml:mn>2</mml:mn><mml:mo>+</mml:mo><mml:mi>l</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where <italic>F</italic> is the number of filters and set to 128. For the convenience of explanation, the bias term is not displayed. During the training process, the weights of position-specific filters are optimized to capture position-specific sequence patterns. Zero-padding is applied to the resulting matrixes so that the shape of the input and output matrixes are the same. The output matrix is fed to the ReLU function and dropped out with a ratio of 0.2 to obtain the following matrix.<disp-formula id="eqn0010"><label>(2)</label><mml:math id="M10" altimg="si0010.svg"><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>W</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>D</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>u</mml:mi><mml:mi>t</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>L</mml:mi><mml:mi>U</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>W</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p>
      <p id="p0045">To capture feature patterns at different levels, we employ <italic>F</italic> filters with a different window size of <inline-formula><mml:math id="M11" altimg="si0011.svg"><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mn>.</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>S</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:math></inline-formula> and concatenate <inline-formula><mml:math id="M12" altimg="si0012.svg"><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="M13" altimg="si0013.svg"><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>,., <inline-formula><mml:math id="M14" altimg="si0014.svg"><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>S</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> at each position to obtain feature matrix <inline-formula><mml:math id="M15" altimg="si0015.svg"><mml:mi>B</mml:mi></mml:math></inline-formula> as follows:<disp-formula id="eqn0015"><label>(3)</label><mml:math id="M16" altimg="si0016.svg"><mml:mrow><mml:mi>B</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">]</mml:mo><mml:mo>=</mml:mo><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mn>.</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>S</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where <italic>S</italic> is the number of window sizes. The concatenated matrix is inputted into the cross-interactive network to generate feature tensor <inline-formula><mml:math id="M17" altimg="si0017.svg"><mml:mi>H</mml:mi></mml:math></inline-formula> that considers relationships between pairwise nucleotide patterns within an inquiry sequence. In the cross interactive network, matrix <inline-formula><mml:math id="M18" altimg="si0015.svg"><mml:mi>B</mml:mi></mml:math></inline-formula> is broadcasted in the two different axes. First, one dimension is added as the first dimension of <inline-formula><mml:math id="M19" altimg="si0015.svg"><mml:mi>B</mml:mi></mml:math></inline-formula>, and <inline-formula><mml:math id="M20" altimg="si0015.svg"><mml:mi>B</mml:mi></mml:math></inline-formula> is copied <italic>N</italic> times and expanded in the added axis, resulting in a tensor with a shape of <inline-formula><mml:math id="M21" altimg="si0018.svg"><mml:mrow><mml:mi>N</mml:mi><mml:mo>*</mml:mo><mml:mo>×</mml:mo><mml:mi>N</mml:mi><mml:mo>×</mml:mo><mml:mi>F</mml:mi></mml:mrow></mml:math></inline-formula>, where * indicates the added dimension. Second, the other dimension is inserted at the second dimension of <inline-formula><mml:math id="M22" altimg="si0015.svg"><mml:mi>B</mml:mi></mml:math></inline-formula>, and <inline-formula><mml:math id="M23" altimg="si0019.svg"><mml:mi>B</mml:mi></mml:math></inline-formula> is copied <italic>N</italic> times and expanded in the added axis, resulting in a tensor with a shape of <inline-formula><mml:math id="M24" altimg="si0020.svg"><mml:mrow><mml:mi>N</mml:mi><mml:mo>×</mml:mo><mml:mi>N</mml:mi><mml:mo>*</mml:mo><mml:mo>×</mml:mo><mml:mi>F</mml:mi></mml:mrow></mml:math></inline-formula>. The two resulting tensors are summed to obtain <inline-formula><mml:math id="M25" altimg="si0021.svg"><mml:mi>H</mml:mi></mml:math></inline-formula>, given by:<disp-formula id="eqn0020"><label>(4)</label><mml:math id="M26" altimg="si0022.svg"><mml:mrow><mml:mi>H</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">]</mml:mo><mml:mn>1</mml:mn><mml:mo>≤</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo>≤</mml:mo><mml:mi>N</mml:mi><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>≤</mml:mo><mml:mi>k</mml:mi><mml:mo>≤</mml:mo><mml:mi>F</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p>
      <p id="p0050">After reducing the feature size of <inline-formula><mml:math id="M27" altimg="si0021.svg"><mml:mi>H</mml:mi></mml:math></inline-formula> by a fully connected layer to <inline-formula><mml:math id="M28" altimg="si0023.svg"><mml:mrow><mml:mi>F</mml:mi><mml:mo accent="false">′</mml:mo></mml:mrow></mml:math></inline-formula>, we obtain feature matrix Q, given by:<disp-formula id="eqn0025"><label>(5)</label><mml:math id="M29" altimg="si0024.svg"><mml:mrow><mml:mi>Q</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">]</mml:mo><mml:mo>=</mml:mo><mml:munder><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>≤</mml:mo><mml:mi>p</mml:mi><mml:mo>≤</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:munder><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">]</mml:mo><mml:mn>1</mml:mn><mml:mo>≤</mml:mo><mml:mi>k</mml:mi><mml:mo>≤</mml:mo><mml:mi>F</mml:mi><mml:mo accent="false">′</mml:mo></mml:mrow></mml:math></disp-formula>,where <inline-formula><mml:math id="M30" altimg="si0023.svg"><mml:mrow><mml:mi>F</mml:mi><mml:mo accent="false">′</mml:mo></mml:mrow></mml:math></inline-formula> set to 256. Then, Q is sent to the output layer composed of three fully connected layers, where the output feature size of the first, second, and third fully connected layers are set to 128, 32, and 1, respectively. Q is fed to the first and second fully connected layers with the ReLU function and dropout layer (with a ratio of 0.2), and then fed to the third fully connected layer with the sigmoid function to produce the final output vector whose elements are values in a range of 0–1. The final output vector is defined as the contribution score vector that provides interpretability of the prediction. The final score is obtained by sampling a max value element from the final output vector.</p>
      <p id="p0055">Applying the global max-pooling layer to the last layer provided the contribution vector elements corresponding to the 6 mA-related nucleotide positions with a value close to 1. For example, if nucleotide patterns co-occurring with 6 mA exist, the global max-pooling layer outputs a higher value at those positions. It is because the neural networks are optimized so that the global max-pooling layer can give a value close to 1 to the positive samples. In other words, the mechanism for identifying the positions significantly responsible for positive samples is incorporated. CNN6mA presents the nucleotide positions that contributed to the 6 mA prediction through this contribution score vector to explain the prediction. The construction of the deep learning model is executed by PyTorch of the Python package <xref rid="bib29" ref-type="bibr">[29]</xref>.</p>
    </sec>
    <sec id="sec0025">
      <label>2.3</label>
      <title>Training and evaluation</title>
      <p id="p0060">We trained and validated the neural network model via 5-fold cross-validation with training data. Mini-batch learning was applied for the training with a batch size of 64. The optimization was executed by the Adam optimizer with a learning rate of <inline-formula><mml:math id="M31" altimg="si0025.svg"><mml:mrow><mml:mn>1.0</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> and was stopped when the maximum value of AUC in the validation data was not updated for consecutive 30 epochs.</p>
      <p id="p0065">The trained models were evaluated by the independent test with test data. For the evaluation, 5 statistical measures were adopted: sensitivity (SN; recall), specificity (SP), accuracy (ACC), and Matthews correlation coefficient (MCC) provided by:<disp-formula id="eqn0030"><label>(6)</label><mml:math id="M32" altimg="si0026.svg"><mml:mtable><mml:mtr><mml:mtd><mml:mi mathvariant="italic">SN</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">TP</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">TP</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="italic">FN</mml:mi></mml:mrow></mml:mfrac></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula><disp-formula id="eqn0035"><label>(7)</label><mml:math id="M33" altimg="si0027.svg"><mml:mtable><mml:mtr><mml:mtd><mml:mi mathvariant="italic">SP</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">TN</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">TN</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="italic">FP</mml:mi></mml:mrow></mml:mfrac></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula><disp-formula id="eqn0040"><label>(8)</label><mml:math id="M34" altimg="si0028.svg"><mml:mtable><mml:mtr><mml:mtd><mml:mi mathvariant="italic">ACC</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">TP</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="italic">TN</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">TP</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="italic">TN</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="italic">FP</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="italic">FN</mml:mi></mml:mrow></mml:mfrac></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula><disp-formula id="eqn0045"><label>(9)</label><mml:math id="M35" altimg="si0029.svg"><mml:mtable><mml:mtr><mml:mtd><mml:mi mathvariant="italic">MCC</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">TP</mml:mi><mml:mo>×</mml:mo><mml:mi mathvariant="italic">TN</mml:mi><mml:mo>−</mml:mo><mml:mi mathvariant="italic">FP</mml:mi><mml:mo>×</mml:mo><mml:mi mathvariant="italic">FN</mml:mi></mml:mrow><mml:mrow><mml:msqrt><mml:mrow><mml:mrow><mml:mfenced open="(" close=")"><mml:mrow><mml:mi mathvariant="italic">TN</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="italic">FN</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mo>×</mml:mo><mml:mrow><mml:mfenced open="(" close=")"><mml:mrow><mml:mi mathvariant="italic">TP</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="italic">FP</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mo>×</mml:mo><mml:mrow><mml:mfenced open="(" close=")"><mml:mrow><mml:mi mathvariant="italic">TN</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="italic">FP</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mo>×</mml:mo><mml:mrow><mml:mfenced open="(" close=")"><mml:mrow><mml:mi mathvariant="italic">TP</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="italic">FN</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:msqrt></mml:mrow></mml:mfrac></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>where <italic>TP</italic>, <italic>FP</italic>, <italic>TN</italic>, and <italic>FN</italic> indicate the numbers of true-positive, false-positive, true-negative, and false-negative samples, respectively. AUC is the area under the receiver operating characteristic curve given by plotting the <italic>SN</italic> with respect (1-<italic>SP</italic>) at various threshold settings. The threshold for separating positive samples from negative samples was set to 0.5. The statistical measures of 5 models were averaged. The calculation of the measurements was executed by scikit-learn <xref rid="bib30" ref-type="bibr">[30]</xref> of the Python package.</p>
    </sec>
    <sec id="sec0030">
      <label>2.4</label>
      <title>Analysis of contribution score vectors</title>
      <p id="p0070">Before analysis, the contribution score vectors were smoothed by averaging <inline-formula><mml:math id="M36" altimg="si0030.svg"><mml:mi>n</mml:mi></mml:math></inline-formula> consecutive score elements. Three smoothed contribution scores in <inline-formula><mml:math id="M37" altimg="si0030.svg"><mml:mi>n</mml:mi></mml:math></inline-formula> of 3, 5, and 7 were generated and averaged at each position. To observe the differences between contribution score vectors in positive and negative samples, we visualized the contribution score vectors by two methods for dimensional reduction: t-distributed stochastic neighbor embedding (t-SNE) <xref rid="bib31" ref-type="bibr">[31]</xref> and uniform manifold approximation and projection (UMAP) <xref rid="bib32" ref-type="bibr">[32]</xref>. In the t-SNE, the low dimensional data was generated by bringing the distribution of distances between the actual data points closer to that in low dimensional space. Perplexity which determines the variance in the distribution was set to 50. On the other hand, in the UMAP, data points in low dimensional space are determined by working repulsion and attraction between data points in a k-nearest neighbor graph. The number of neighbors in the k-neighbor graph and minimum distances between points were set to 30 and 0.15, respectively.</p>
      <p id="p0075">Furthermore, we explored the nucleotide patterns which present a higher value at a specific position in the contribution score vector. Concretely, we extracted the samples whose contribution scores satisfy the two following conditions at the target position:<disp-formula id="eqn0050"><label>(10)</label><mml:math id="M38" altimg="si0031.svg"><mml:mrow><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">target</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">&gt;</mml:mo><mml:mi>μ</mml:mi><mml:mo>+</mml:mo><mml:mi>k</mml:mi><mml:mi>σ</mml:mi></mml:mrow></mml:math></disp-formula><disp-formula id="eqn0055"><label>(11)</label><mml:math id="M39" altimg="si0032.svg"><mml:mrow><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">target</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">&gt;</mml:mo><mml:mn>0.5</mml:mn><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="M40" altimg="si0033.svg"><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">target</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, <inline-formula><mml:math id="M41" altimg="si0034.svg"><mml:mi>μ</mml:mi></mml:math></inline-formula>, <inline-formula><mml:math id="M42" altimg="si0035.svg"><mml:mi>σ</mml:mi></mml:math></inline-formula>, and <inline-formula><mml:math id="M43" altimg="si0036.svg"><mml:mi>k</mml:mi></mml:math></inline-formula> indicate the contribution score at the target position, the mean and standard deviation of the contribution score over all positions, and a constant. <inline-formula><mml:math id="M44" altimg="si0036.svg"><mml:mi>k</mml:mi></mml:math></inline-formula> was set to 2. We focused on the positions at which the number of the samples satisfying the conditions was more than 50.</p>
    </sec>
  </sec>
  <sec id="sec0035">
    <label>3</label>
    <title>Results and discussion</title>
    <sec id="sec0040">
      <label>3.1</label>
      <title>Optimization of CNN6mA</title>
      <p id="p0080">To extract position-specific nucleotide patterns, the position-specific filters were created in the 1-D convolutional layers of CNN6mA. In addition to the position-specific feature extraction, to further capture various nucleotide patterns, the multi-scale feature extraction was conducted by using filters with different window sizes of 3, 5, 7, and 9. In previous studies in DNA-protein binding site prediction, the use of multi-scale filters improved the performances <xref rid="bib33" ref-type="bibr">[33]</xref>, <xref rid="bib34" ref-type="bibr">[34]</xref>. We investigated the optimal combinations of multi-scale filters in position-specific feature extraction. Concretely, we constructed a filter with a window size of 3, two filters with window sizes of 3 and 5, three filters with window sizes of 3, 5, and 7, and four filters with window sizes of 3, 5, 7, and 9. We trained the CNN6mA model via 5-fold cross-validation with the respective training dataset of 11 species, where the statistical measures of the resulting 5 models in all species were averaged. As shown in <xref rid="fig0010" ref-type="fig">Fig. 2</xref>, the combination of three filters with window sizes of 3, 5, and 7 achieved the highest SN, ACC, MCC, and AUC, indicating that the combination of multi-scale filters is effective in enhanced prediction. Theoretically, a long-size filter extracts information of long sequence patterns; a short-size filter is not able to capture the information of such a long motif all at once. A window size of 9 might be too long to capture nucleotide patterns. Finally, we implemented three position-specific filters with window sizes of 3, 5, and 7 in the 1-D convolutional layers of CNN6mA.<fig id="fig0010"><label>Fig. 2</label><caption><p>Effect of the combination of multi-scale filters on the performance of CNN6mA in 5-fold cross-validation. The 1-D convolutional layer employs a filter with a window size of 3, two filters with window sizes of 3 and 5, three filters with window sizes of 3, 5, and 7, and four filters with window sizes of 3, 5, 7, and 9.</p></caption><alt-text id="at0010">Fig. 2</alt-text><graphic xlink:href="gr2"/></fig></p>
    </sec>
    <sec id="sec0045">
      <label>3.2</label>
      <title>Comparison of CNN6mA with existing state-of-the-art methods</title>
      <p id="p0085">We compared the performances of CNN6mA with those of existing state-of-the-art models including iDNA-MS, iDNA-ABT, SNNRice6mA, DeepTorrent, Deep6mA, and BERT6mA. The performances of iDNA-MS, iDNA-ABT, SNNRice6mA, DeepTorrent, and BERT6mA were evaluated in our previous paper <xref rid="bib26" ref-type="bibr">[26]</xref>. We trained Deep6mA via 5-fold cross-validation with the training data and evaluated them with the independent test data. As shown in <xref rid="fig0015" ref-type="fig">Fig. 3</xref> and <xref rid="sec0085" ref-type="sec">Table S2</xref>, CNN6mA presented the highest ACCs and AUCs in 6 and 8 species out of the 11 species, respectively, suggesting that CNN6mA has a high learning ability and generalizability. We consider that the high learning ability of CNN6mA is attributed to the position-specific filters of the 1-D convolutional layers and the cross-interactive network, which capture the position-associated information and the relationships between local nucleotide patterns, respectively. The usefulness of those two architectures will be demonstrated later.<fig id="fig0015"><label>Fig. 3</label><caption><p>Performance comparison of CNN6mA with the state-of-the-art methods in the independent tests for 11 species. The performances of iDNA-MS, iDNA-ABT, SNNRice6mA, DeepTorrent, and BERT6mA are given from <xref rid="sec0085" ref-type="sec">Table S3</xref> in Lv et al.’s paper (iDNA-MS), <xref rid="sec0085" ref-type="sec">Table S2</xref> in Yu et al.’s paper (iDNA-ABT), and <xref rid="sec0085" ref-type="sec">Tables S2-S12</xref> in our previous paper (BERT6mA). AUCs in Deep6mA are given from <xref rid="fig0020" ref-type="fig">Fig. 4</xref> in our previous paper (BERT6mA) and ACCs are calculated with the BERT6mA-trained models.</p></caption><alt-text id="at0015">Fig. 3</alt-text><graphic xlink:href="gr3"/></fig></p>
      <p id="p0090">The iDNA-MS presented high performances on the small datasets of <italic>F. vesca</italic> and <italic>R. chinensis</italic>, showing the effectiveness of machine learning on small datasets, respectively. CNN6mA presented high performances on small datasets, but the other deep learning-based models did not, suggesting the learning potential of CNN6mA on various data sizes. The BERT6mA, iDNA-ABT, and Deep6mA presented comparable performances to the CNN6mA in many species. The first two models could extract the context information based on the BERT-based neural networks; the Deep6mA model could capture some nucleotide patterns based on LSTM and CNN-based neural networks.</p>
    </sec>
    <sec id="sec0050">
      <label>3.3</label>
      <title>Effectiveness of position-specific 1-D convolutional layer</title>
      <p id="p0095">To investigate the effectiveness of the position-specific filters in the 1-D convolutional layer, we compared the performances of the multi-scale, position-specific 1-D convolutional layer that use the position-specific filters with those of the normal multi-scale 1-D convolutional layer that shares the same filters at all positions. We used the two different encoding methods: the index embedding method (see Materials and methods) and one-hot encoding. The one-hot encoding converts A, T, G, and C into <inline-formula><mml:math id="M45" altimg="si0037.svg"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="M46" altimg="si0038.svg"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>
<inline-formula><mml:math id="M47" altimg="si0039.svg"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, and <inline-formula><mml:math id="M48" altimg="si0040.svg"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, respectively. As shown in <xref rid="fig0020" ref-type="fig">Fig. 4</xref> and S1, and <xref rid="sec0085" ref-type="sec">Tables S3-S6</xref>, use of the position-specific 1-D convolutional layer presented significantly higher ACCs and AUCs than use of the normal 1-D convolutional layer in almost all species in both the encoding methods (one-sided paired-sample t-test), suggesting that use of the position-specific filters is effective in enhanced prediction. This explicitly indicates the usefulness of the position-specific information for 6 mA prediction.<fig id="fig0020"><label>Fig. 4</label><caption><p>Performance comparison of CNN6mA with the position-specific 1-D convolutional layer with that with the normal 1-D convolutional layer. The index-embedding method is used. One-sided paired-sample t-test is used.</p></caption><alt-text id="at0020">Fig. 4</alt-text><graphic xlink:href="gr4"/></fig></p>
    </sec>
    <sec id="sec0055">
      <label>3.4</label>
      <title>Effect of cross-interactive network</title>
      <p id="p0100">While the proposed position-specific 1-D convolutional layer captures nucleotide patterns at specific positions, it is not able to extract the relationships between those patterns at a distance. To complement this issue and represent the relationships between nucleotide patterns within an inquiry sequence, we created the cross-interactive network. This network superimposes the features between all the nucleotide pairs in the inquiry sequence to explore some relationships between them. To validate the usefulness of the cross-interactive network-based feature extraction, we compared the CNN6mA including the cross-interactive network with the CNN6mA without it (<xref rid="sec0085" ref-type="sec">Fig. S2</xref>). Notably, the performance increased while keeping the numbers of parameters in the two types of models the same. As shown in <xref rid="fig0025" ref-type="fig">Fig. 5</xref> and <xref rid="sec0085" ref-type="sec">Tables S3 and S7</xref>, use of the cross-interactive network significantly increased the prediction performance (one-sided paired-sample t-test), demonstrating that the cross-interactive network is useful for the prediction of 6 mA sites.<fig id="fig0025"><label>Fig. 5</label><caption><p>Effect of the cross-interactive network on the prediction performance of CNN6mA in independent tests.</p></caption><alt-text id="at0025">Fig. 5</alt-text><graphic xlink:href="gr5"/></fig></p>
    </sec>
    <sec id="sec0060">
      <label>3.5</label>
      <title>Interpretation of prediction mechanism</title>
      <p id="p0105">CNN6mA proposed the contribution score vector for the interpretation of prediction mechanisms. To exemplify the contribution score vectors, we visualized them in the independent test in <italic>H. sapiens</italic> by t-SNE and UMAP. The averaged contribution score vectors of the positive and negative samples were separated clearly (<xref rid="fig0030" ref-type="fig">Fig. 6</xref>), indicating that they are critically responsible for classification. Those in the positive samples have higher values than those in negative samples (<xref rid="fig0035" ref-type="fig">Fig. 7</xref>). In the positive samples, we observed that the positions with a high score agreed to those at which the preferred nucleotides appeared on the sequence logos, resulted from the information content Logo <xref rid="bib35" ref-type="bibr">[35]</xref>, pLogo <xref rid="bib36" ref-type="bibr">[36]</xref>, and <italic>k</italic>pLogo <xref rid="bib35" ref-type="bibr">[35]</xref> (<xref rid="fig0035" ref-type="fig">Fig. 7</xref>). Specifically, the high-value elements in the vector and the preferred nucleotides on the sequence logos were observed at middle positions from 18 to 28.<fig id="fig0030"><label>Fig. 6</label><caption><p>Visualization of the contribution score vectors for the negative and positive samples by UMAP (left) and (t-SNE).</p></caption><alt-text id="at0030">Fig. 6</alt-text><graphic xlink:href="gr6"/></fig><fig id="fig0035"><label>Fig. 7</label><caption><p>Heat map of the contribution score vector. In the positive (top) and negative samples (bottom), the contribution score vectors generated by the independent test of <italic>H. sapiens</italic> are averaged (Upper panel). Nucleotide preference profiles in the test data of <italic>H. sapiens</italic>. They are visualized by three tools of the information content Logo (top), pLogo (middle), and <italic>k</italic>pLogo (bottom) (Lower panel).</p></caption><alt-text id="at0035">Fig. 7</alt-text><graphic xlink:href="gr7"/></fig></p>
      <p id="p0110">To investigate the interpretability of the contribution score vectors, we collected the samples with a high score in the contribution vector and visualized those samples by the sequence logo (see Materials and methods). We focused on the positions where the number of samples with a high score is more than 50 and averaged those score vectors. As shown in <xref rid="fig0040" ref-type="fig">Fig. 8</xref>, <xref rid="fig0045" ref-type="fig">Fig. 9</xref>, the preferred nucleotide patterns appeared around the position with a high score in the contribution score vectors. For example, the sequences with a high score at position 20 contained a GAGG motif which was involved in actively transcribed genes in previous study <xref rid="bib9" ref-type="bibr">[9]</xref>. In addition, the sequences with high scores at positions 17 and 24 included the AAAA motif and CG motif, in the same manner as the sequence logs. These results suggest that the contribution score vectors reflect the positions of preferred nucleotides in the 6 mA samples.<fig id="fig0040"><label>Fig. 8</label><caption><p>Contribution score vectors and nucleotide patterns with a high score at the upstream positions of 6 mA. At positions of 6, 17, 18, 19, and 20, many samples have a high score at specific positions. The preferred nucleotides are visualized by three tools of the information content Logo, pLogo, and <italic>k</italic>pLogo.</p></caption><alt-text id="at0040">Fig. 8</alt-text><graphic xlink:href="gr8"/></fig><fig id="fig0045"><label>Fig. 9</label><caption><p>Contribution score vectors and nucleotide patterns with a high score at the upstream positions of 6 mA. At positions of 22, 23, 24, 25, 26, and 27, many samples have a high score at specific positions. The preferred nucleotides are visualized by three tools of the information content Logo, pLogo, and <italic>k</italic>pLogo.</p></caption><alt-text id="at0045">Fig. 9</alt-text><graphic xlink:href="gr9"/></fig></p>
      <p id="p0115">DNA motifs are generally related to DNA binding proteins and non-coding RNAs during DNA methylation processes. Previous studies investigated the relationship between the motifs and DNA methylation/demethylation and emphasized the importance of the motifs for establishing and maintaining the methylation <xref rid="bib37" ref-type="bibr">[37]</xref>, <xref rid="bib38" ref-type="bibr">[38]</xref>, <xref rid="bib39" ref-type="bibr">[39]</xref>, <xref rid="bib40" ref-type="bibr">[40]</xref> in addition to the locus-specificity of methylation <xref rid="bib37" ref-type="bibr">[37]</xref>. CNN6mA created the contribution score vectors that reflect the 6 mA-associated nucleotide patterns and can be useful for finding motifs. While motif exploration tools such as sequence Logo provide the comprehensive result over a sufficient number of samples, the contribution score vectors explicitly tell the critical positions and 6 mA-associated nucleotide patterns for each sample sequence. For example, as shown in <xref rid="fig0035" ref-type="fig">Fig. 7</xref>, the pLogo could not identify any preferential nucleotides in the upstream positions from 1 to 10 for all samples, while it could find adenine at position 6 only for the samples with a high contribution score. This is a great advantage of the contribution vector over the motif exploration tools.</p>
      <p id="p0120">BERT6mA <xref rid="bib26" ref-type="bibr">[26]</xref> interpreted the prediction mechanism through attention weights that indicate the relationships between <italic>k</italic>-mer sequences. Since the attention weight was generated for each <italic>k</italic>-mer, not for each nucleotide, it was difficult to specify the 6 mA-related nucleotides. Compared to such attention weights, the CNN6mA-generated contribution score vectors, which are calculated based on the information of specific 6 mA-related nucleotides and their relationships, explicitly evaluate a contribution degree at each nucleotide. This would make it more intuitive to find 6 mA-related patterns than the attention weight.</p>
    </sec>
    <sec id="sec0065">
      <label>3.6</label>
      <title>Web server implementation</title>
      <p id="p0125">To promote research in the field of epigenetics and genome analysis, a web server application of CNN6mA was constructed and can be freely accessed from <ext-link ext-link-type="uri" xlink:href="http://kurata35.bio.kyutech.ac.jp/CNN6mA/" id="ir0020">http://kurata35.bio.kyutech.ac.jp/CNN6mA/</ext-link>. Flask (1.1.2) in a python package (3.8.0) and apache (2.4.18) were used for implementation. The application requires DNA sequences with a length of 41 bp and an adenine positioned at the center in the FASTA format and outputs predictive scores and the contribution score vectors. The details of the application are provided on the help page of the site.</p>
    </sec>
  </sec>
  <sec id="sec0070">
    <label>4</label>
    <title>Conclusion</title>
    <p id="p0130">We constructed an interpretable CNN-based model for DNA 6 mA site prediction, named CNN6mA. In the present study, we suggest three novel neural network architectures: position-specific 1D convolutional layer, a cross-interactive network, and a global max-pooling layer-based network to generate the contribution score vectors. We showed that the first two architectures improved the prediction performances. Based on those architectures, in the benchmark, CNN6mA outperformed the state-of-the-art methods in many species. The third architecture generates the contribution score vectors that exhibit the neural network-focused positions. The contribution score vectors could be useful for finding 6 mA-associated motifs with a small number of samples. In the near future, we will find the species-common and species-specific motif patterns by using the contribution scores and examine their motif patterns and biological meanings to understand new epigenetic mechanisms.</p>
  </sec>
  <sec id="sec0075">
    <title>CRediT authorship contribution statement</title>
    <p id="p0135"><bold>Sho Tsukiyama</bold>: Conceptualization, Methodology, Software, Formal analysis, Writing – original draft, and Writing – review &amp; editing. <bold>Md Mehedi Hasan</bold>: Writing – original draft, Writing – review &amp; editing. <bold>Hiroyuki Kurata</bold>: Conceptualization, Methodology, Writing – original draft, and Writing – review &amp; editing.</p>
  </sec>
  <sec sec-type="COI-statement">
    <title>Declaration of Competing Interest</title>
    <p id="p0140">All authors declare that they have no conflicts of interest.</p>
  </sec>
</body>
<back>
  <ref-list id="bibliog0005">
    <title>References</title>
    <ref id="bib1">
      <label>1</label>
      <element-citation publication-type="journal" id="sbref1">
        <person-group person-group-type="author">
          <name>
            <surname>Chachar</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>P.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Harnessing current knowledge of DNA N6-methyladenosine from model plants for non-model crops</article-title>
        <source>Front Genet</source>
        <volume>12</volume>
        <year>2021</year>
        <object-id pub-id-type="publisher-id">668317</object-id>
      </element-citation>
    </ref>
    <ref id="bib2">
      <label>2</label>
      <element-citation publication-type="journal" id="sbref2">
        <person-group person-group-type="author">
          <name>
            <surname>Campbell</surname>
            <given-names>J.L.</given-names>
          </name>
          <name>
            <surname>Kleckner</surname>
            <given-names>N.</given-names>
          </name>
        </person-group>
        <article-title>E. coli oriC and the dnaA gene promoter are sequestered from dam methyltransferase following the passage of the chromosomal replication fork</article-title>
        <source>Cell</source>
        <volume>62</volume>
        <year>1990</year>
        <fpage>967</fpage>
        <lpage>979</lpage>
        <pub-id pub-id-type="pmid">1697508</pub-id>
      </element-citation>
    </ref>
    <ref id="bib3">
      <label>3</label>
      <element-citation publication-type="journal" id="sbref3">
        <person-group person-group-type="author">
          <name>
            <surname>Au</surname>
            <given-names>K.G.</given-names>
          </name>
          <name>
            <surname>Welsh</surname>
            <given-names>K.</given-names>
          </name>
          <name>
            <surname>Modrich</surname>
            <given-names>P.</given-names>
          </name>
        </person-group>
        <article-title>Initiation of methyl-directed mismatch repair</article-title>
        <source>J Biol Chem</source>
        <volume>267</volume>
        <year>1992</year>
        <fpage>12142</fpage>
        <lpage>12148</lpage>
        <pub-id pub-id-type="pmid">1601880</pub-id>
      </element-citation>
    </ref>
    <ref id="bib4">
      <label>4</label>
      <element-citation publication-type="journal" id="sbref4">
        <person-group person-group-type="author">
          <name>
            <surname>Pukkila</surname>
            <given-names>P.J.</given-names>
          </name>
          <name>
            <surname>Peterson</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Herman</surname>
            <given-names>G.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Effects of high levels of DNA adenine methylation on methyl-directed mismatch repair in Escherichia coli</article-title>
        <source>Genetics</source>
        <volume>104</volume>
        <year>1983</year>
        <fpage>571</fpage>
        <lpage>582</lpage>
        <pub-id pub-id-type="pmid">6225697</pub-id>
      </element-citation>
    </ref>
    <ref id="bib5">
      <label>5</label>
      <element-citation publication-type="journal" id="sbref5">
        <person-group person-group-type="author">
          <name>
            <surname>Li</surname>
            <given-names>Z.</given-names>
          </name>
          <name>
            <surname>Zhao</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Nelakanti</surname>
            <given-names>R.V.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>N6-methyladenine in DNA antagonizes SATB1 in early development</article-title>
        <source>Nature</source>
        <volume>583</volume>
        <year>2020</year>
        <fpage>625</fpage>
        <lpage>630</lpage>
        <pub-id pub-id-type="pmid">32669713</pub-id>
      </element-citation>
    </ref>
    <ref id="bib6">
      <label>6</label>
      <element-citation publication-type="journal" id="sbref6">
        <person-group person-group-type="author">
          <name>
            <surname>Robbins-Manke</surname>
            <given-names>J.L.</given-names>
          </name>
          <name>
            <surname>Zdraveski</surname>
            <given-names>Z.Z.</given-names>
          </name>
          <name>
            <surname>Marinus</surname>
            <given-names>M.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Analysis of global gene expression and double-strand-break formation in DNA adenine methyltransferase- and mismatch repair-deficient Escherichia coli</article-title>
        <source>J Bacteriol</source>
        <volume>187</volume>
        <year>2005</year>
        <fpage>7027</fpage>
        <lpage>7037</lpage>
        <pub-id pub-id-type="pmid">16199573</pub-id>
      </element-citation>
    </ref>
    <ref id="bib7">
      <label>7</label>
      <element-citation publication-type="journal" id="sbref7">
        <person-group person-group-type="author">
          <name>
            <surname>Heard</surname>
            <given-names>E.</given-names>
          </name>
          <name>
            <surname>Martienssen</surname>
            <given-names>R.A.</given-names>
          </name>
        </person-group>
        <article-title>Transgenerational epigenetic inheritance: myths and mechanisms</article-title>
        <source>Cell</source>
        <volume>157</volume>
        <year>2014</year>
        <fpage>95</fpage>
        <lpage>109</lpage>
        <pub-id pub-id-type="pmid">24679529</pub-id>
      </element-citation>
    </ref>
    <ref id="bib8">
      <label>8</label>
      <element-citation publication-type="journal" id="sbref8">
        <person-group person-group-type="author">
          <name>
            <surname>Low</surname>
            <given-names>D.A.</given-names>
          </name>
          <name>
            <surname>Weyand</surname>
            <given-names>N.J.</given-names>
          </name>
          <name>
            <surname>Mahan</surname>
            <given-names>M.J.</given-names>
          </name>
        </person-group>
        <article-title>Roles of DNA adenine methylation in regulating bacterial gene expression and virulence</article-title>
        <source>Infect Immun</source>
        <volume>69</volume>
        <year>2001</year>
        <fpage>7197</fpage>
        <lpage>7204</lpage>
        <pub-id pub-id-type="pmid">11705888</pub-id>
      </element-citation>
    </ref>
    <ref id="bib9">
      <label>9</label>
      <element-citation publication-type="journal" id="sbref9">
        <person-group person-group-type="author">
          <name>
            <surname>Xiao</surname>
            <given-names>C.-L.</given-names>
          </name>
          <name>
            <surname>Zhu</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>He</surname>
            <given-names>M.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>N6-methyladenine DNA modification in the human genome</article-title>
        <source>Mol Cell</source>
        <volume>71</volume>
        <year>2018</year>
        <fpage>306</fpage>
        <lpage>318.e307</lpage>
        <pub-id pub-id-type="pmid">30017583</pub-id>
      </element-citation>
    </ref>
    <ref id="bib10">
      <label>10</label>
      <element-citation publication-type="journal" id="sbref10">
        <person-group person-group-type="author">
          <name>
            <surname>Flusberg</surname>
            <given-names>B.A.</given-names>
          </name>
          <name>
            <surname>Webster</surname>
            <given-names>D.R.</given-names>
          </name>
          <name>
            <surname>Lee</surname>
            <given-names>J.H.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Direct detection of DNA methylation during single-molecule, real-time sequencing</article-title>
        <source>Nat Methods</source>
        <volume>7</volume>
        <year>2010</year>
        <fpage>461</fpage>
        <lpage>465</lpage>
        <pub-id pub-id-type="pmid">20453866</pub-id>
      </element-citation>
    </ref>
    <ref id="bib11">
      <label>11</label>
      <element-citation publication-type="journal" id="sbref11">
        <person-group person-group-type="author">
          <name>
            <surname>Bowden</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Davies</surname>
            <given-names>R.W.</given-names>
          </name>
          <name>
            <surname>Heger</surname>
            <given-names>A.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Sequencing of human genomes with nanopore technology</article-title>
        <source>Nat Commun</source>
        <volume>10</volume>
        <year>2019</year>
        <fpage>1869</fpage>
        <pub-id pub-id-type="pmid">31015479</pub-id>
      </element-citation>
    </ref>
    <ref id="bib12">
      <label>12</label>
      <element-citation publication-type="journal" id="sbref12">
        <person-group person-group-type="author">
          <name>
            <surname>Cloney</surname>
            <given-names>R.A.</given-names>
          </name>
        </person-group>
        <article-title>SMRT analysis of prokaryotic epigenomes</article-title>
        <source>Nat Rev Genet</source>
        <volume>17</volume>
        <year>2016</year>
      </element-citation>
    </ref>
    <ref id="bib13">
      <label>13</label>
      <element-citation publication-type="journal" id="sbref13">
        <person-group person-group-type="author">
          <name>
            <surname>Song</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>James</surname>
            <given-names>S.R.</given-names>
          </name>
          <name>
            <surname>Kazim</surname>
            <given-names>L.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Specific method for the determination of genomic DNA methylation by liquid chromatography-electrospray ionization tandem mass spectrometry</article-title>
        <source>Anal Chem</source>
        <volume>77</volume>
        <year>2005</year>
        <fpage>504</fpage>
        <lpage>510</lpage>
        <pub-id pub-id-type="pmid">15649046</pub-id>
      </element-citation>
    </ref>
    <ref id="bib14">
      <label>14</label>
      <element-citation publication-type="journal" id="sbref14">
        <person-group person-group-type="author">
          <name>
            <surname>Krais</surname>
            <given-names>A.M.</given-names>
          </name>
          <name>
            <surname>Cornelius</surname>
            <given-names>M.G.</given-names>
          </name>
          <name>
            <surname>Schmeiser</surname>
            <given-names>H.H.</given-names>
          </name>
        </person-group>
        <article-title>Genomic N(6)-methyladenine determination by MEKC with LIF</article-title>
        <source>Electrophoresis</source>
        <volume>31</volume>
        <year>2010</year>
        <fpage>3548</fpage>
        <lpage>3551</lpage>
        <pub-id pub-id-type="pmid">20925053</pub-id>
      </element-citation>
    </ref>
    <ref id="bib15">
      <label>15</label>
      <element-citation publication-type="journal" id="sbref15">
        <person-group person-group-type="author">
          <name>
            <surname>Liu</surname>
            <given-names>Q.</given-names>
          </name>
          <name>
            <surname>Fang</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Yu</surname>
            <given-names>G.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Detection of DNA base modifications by deep recurrent neural network on Oxford Nanopore sequencing data</article-title>
        <source>Nat Commun</source>
        <volume>10</volume>
        <year>2019</year>
        <fpage>2449</fpage>
        <pub-id pub-id-type="pmid">31164644</pub-id>
      </element-citation>
    </ref>
    <ref id="bib16">
      <label>16</label>
      <element-citation publication-type="journal" id="sbref16">
        <person-group person-group-type="author">
          <name>
            <surname>Lv</surname>
            <given-names>H.</given-names>
          </name>
          <name>
            <surname>Dao</surname>
            <given-names>F.Y.</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>D.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>iDNA-MS: an integrated computational tool for detecting DNA modification sites in multiple genomes</article-title>
        <source>iScience</source>
        <volume>23</volume>
        <year>2020</year>
        <object-id pub-id-type="publisher-id">100991</object-id>
      </element-citation>
    </ref>
    <ref id="bib17">
      <label>17</label>
      <mixed-citation publication-type="other" id="othref0005">Liu W., Li H. SICD6mA: Identifying 6mA Sites using Deep Memory Network, bioRxiv 2020:2020.2002.2002.930776.</mixed-citation>
    </ref>
    <ref id="bib18">
      <label>18</label>
      <element-citation publication-type="journal" id="sbref17">
        <person-group person-group-type="author">
          <name>
            <surname>Yu</surname>
            <given-names>H.</given-names>
          </name>
          <name>
            <surname>Dai</surname>
            <given-names>Z.</given-names>
          </name>
        </person-group>
        <article-title>SNNRice6mA: a deep learning method for predicting DNA N6-methyladenine sites in rice genome</article-title>
        <source>Front Genet</source>
        <volume>10</volume>
        <year>2019</year>
      </element-citation>
    </ref>
    <ref id="bib19">
      <label>19</label>
      <element-citation publication-type="journal" id="sbref18">
        <person-group person-group-type="author">
          <name>
            <surname>Li</surname>
            <given-names>Z.</given-names>
          </name>
          <name>
            <surname>Jiang</surname>
            <given-names>H.</given-names>
          </name>
          <name>
            <surname>Kong</surname>
            <given-names>L.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Deep6mA: A deep learning framework for exploring similar patterns in DNA N6-methyladenine sites across different species</article-title>
        <source>PLOS Comput Biol</source>
        <volume>17</volume>
        <year>2021</year>
        <object-id pub-id-type="publisher-id">e1008767</object-id>
      </element-citation>
    </ref>
    <ref id="bib20">
      <label>20</label>
      <element-citation publication-type="journal" id="sbref19">
        <person-group person-group-type="author">
          <name>
            <surname>Pian</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>G.</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>F.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>MM-6mAPred: identifying DNA N6-methyladenine sites based on Markov model</article-title>
        <source>Bioinformatics</source>
        <volume>36</volume>
        <year>2019</year>
        <fpage>388</fpage>
        <lpage>392</lpage>
      </element-citation>
    </ref>
    <ref id="bib21">
      <label>21</label>
      <mixed-citation publication-type="other" id="othref0010">Vaswani A., Shazeer N., Parmar N. et al. Attention Is All You Need. 2017, arXiv:1706.03762.</mixed-citation>
    </ref>
    <ref id="bib22">
      <label>22</label>
      <mixed-citation publication-type="other" id="othref0015">Devlin J., Chang M.-W., Lee K. et al. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. 2018, arXiv:1810.04805.</mixed-citation>
    </ref>
    <ref id="bib23">
      <label>23</label>
      <element-citation publication-type="journal" id="sbref20">
        <person-group person-group-type="author">
          <name>
            <surname>Huang</surname>
            <given-names>Q.</given-names>
          </name>
          <name>
            <surname>Zhou</surname>
            <given-names>W.</given-names>
          </name>
          <name>
            <surname>Guo</surname>
            <given-names>F.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>6mA-Pred: identifying DNA N6-methyladenine sites based on deep learning</article-title>
        <source>PeerJ</source>
        <volume>9</volume>
        <year>2021</year>
      </element-citation>
    </ref>
    <ref id="bib24">
      <label>24</label>
      <element-citation publication-type="journal" id="sbref21">
        <person-group person-group-type="author">
          <name>
            <surname>Yu</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>He</surname>
            <given-names>W.</given-names>
          </name>
          <name>
            <surname>Jin</surname>
            <given-names>J.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>iDNA-ABT: advanced deep learning model for detecting DNA methylation with adaptive features and transductive information maximization</article-title>
        <source>Bioinformatics</source>
        <volume>37</volume>
        <year>2021</year>
        <fpage>4603</fpage>
        <lpage>4610</lpage>
      </element-citation>
    </ref>
    <ref id="bib25">
      <label>25</label>
      <element-citation publication-type="journal" id="sbref22">
        <person-group person-group-type="author">
          <name>
            <surname>Liu</surname>
            <given-names>Q.</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>Y.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>DeepTorrent: a deep learning-based approach for predicting DNA N4-methylcytosine sites</article-title>
        <source>Brief Bioinform</source>
        <volume>22</volume>
        <year>2021</year>
        <object-id pub-id-type="publisher-id">bbaa124</object-id>
      </element-citation>
    </ref>
    <ref id="bib26">
      <label>26</label>
      <element-citation publication-type="journal" id="sbref23">
        <person-group person-group-type="author">
          <name>
            <surname>Tsukiyama</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Hasan</surname>
            <given-names>M.M.</given-names>
          </name>
          <name>
            <surname>Deng</surname>
            <given-names>H.-W.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>BERT6mA: prediction of DNA N6-methyladenine site using deep learning-based approaches</article-title>
        <source>Brief Bioinform</source>
        <volume>23</volume>
        <year>2022</year>
        <object-id pub-id-type="publisher-id">bbac053</object-id>
      </element-citation>
    </ref>
    <ref id="bib27">
      <label>27</label>
      <element-citation publication-type="journal" id="sbref24">
        <person-group person-group-type="author">
          <name>
            <surname>He</surname>
            <given-names>Z.</given-names>
          </name>
          <name>
            <surname>Xu</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Shi</surname>
            <given-names>H.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>m5CRegpred: epitranscriptome target prediction of 5-methylcytosine (m5C) regulators based on sequencing features</article-title>
        <source>Genes</source>
        <volume>13</volume>
        <year>2022</year>
        <fpage>677</fpage>
        <pub-id pub-id-type="pmid">35456483</pub-id>
      </element-citation>
    </ref>
    <ref id="bib28">
      <label>28</label>
      <element-citation publication-type="journal" id="sbref25">
        <person-group person-group-type="author">
          <name>
            <surname>Ahmed</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Hossain</surname>
            <given-names>Z.</given-names>
          </name>
          <name>
            <surname>Uddin</surname>
            <given-names>M.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Accurate prediction of RNA 5-hydroxymethylcytosine modification by utilizing novel position-specific gapped k-mer descriptors</article-title>
        <source>Comput Struct Biotechnol J</source>
        <volume>18</volume>
        <year>2020</year>
        <fpage>3528</fpage>
        <lpage>3538</lpage>
        <pub-id pub-id-type="pmid">33304452</pub-id>
      </element-citation>
    </ref>
    <ref id="bib29">
      <label>29</label>
      <element-citation publication-type="book" id="sbref26">
        <person-group person-group-type="author">
          <name>
            <surname>Paszke</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Gross</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Chintala</surname>
            <given-names>S.</given-names>
          </name>
          <etal/>
        </person-group>
        <part-title>Automatic Differentiation in PyTorch. NIPS 2017 Workshop on Autodiff</part-title>
        <year>2017</year>
        <publisher-name>Long Beach,</publisher-name>
        <publisher-loc>California, USA</publisher-loc>
      </element-citation>
    </ref>
    <ref id="bib30">
      <label>30</label>
      <mixed-citation publication-type="other" id="othref0020">Pedregosa F., Varoquaux G., Gramfort A. et al. Scikit-learn: Machine Learning in Python. 2012, arXiv:1201.0490.</mixed-citation>
    </ref>
    <ref id="bib31">
      <label>31</label>
      <element-citation publication-type="journal" id="sbref27">
        <person-group person-group-type="author">
          <name>
            <surname>Zhou</surname>
            <given-names>H.</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>F.</given-names>
          </name>
          <name>
            <surname>Tao</surname>
            <given-names>P.</given-names>
          </name>
        </person-group>
        <article-title>t-distributed stochastic neighbor embedding method with the least information loss for macromolecular simulations</article-title>
        <source>J Chem Theory Comput</source>
        <volume>14</volume>
        <year>2018</year>
        <fpage>5499</fpage>
        <lpage>5510</lpage>
        <pub-id pub-id-type="pmid">30252473</pub-id>
      </element-citation>
    </ref>
    <ref id="bib32">
      <label>32</label>
      <mixed-citation publication-type="other" id="othref0025">McInnes L., Healy J., Melville J. UMAP: Uniform Manifold Approximation and Projection for Dimension Reduction. 2018, arXiv:1802.03426.</mixed-citation>
    </ref>
    <ref id="bib33">
      <label>33</label>
      <element-citation publication-type="journal" id="sbref28">
        <person-group person-group-type="author">
          <name>
            <surname>Zhang</surname>
            <given-names>Q.</given-names>
          </name>
          <name>
            <surname>Yu</surname>
            <given-names>W.</given-names>
          </name>
          <name>
            <surname>Han</surname>
            <given-names>K.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Multi-scale capsule network for predicting DNA-protein binding sites</article-title>
        <source>IEEE/ACM Trans Comput Biol Bioinform</source>
        <volume>18</volume>
        <year>2021</year>
        <fpage>1793</fpage>
        <lpage>1800</lpage>
        <pub-id pub-id-type="pmid">32960766</pub-id>
      </element-citation>
    </ref>
    <ref id="bib34">
      <label>34</label>
      <element-citation publication-type="journal" id="sbref29">
        <person-group person-group-type="author">
          <name>
            <surname>Zhang</surname>
            <given-names>Q.</given-names>
          </name>
          <name>
            <surname>Zhu</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Huang</surname>
            <given-names>D.S.</given-names>
          </name>
        </person-group>
        <article-title>High-order convolutional neural network architecture for predicting DNA-protein binding sites</article-title>
        <source>IEEE/ACM Trans Comput Biol Bioinform</source>
        <volume>16</volume>
        <year>2019</year>
        <fpage>1184</fpage>
        <lpage>1192</lpage>
        <pub-id pub-id-type="pmid">29993783</pub-id>
      </element-citation>
    </ref>
    <ref id="bib35">
      <label>35</label>
      <element-citation publication-type="journal" id="sbref30">
        <person-group person-group-type="author">
          <name>
            <surname>Wu</surname>
            <given-names>X.</given-names>
          </name>
          <name>
            <surname>Bartel</surname>
            <given-names>D.P.</given-names>
          </name>
        </person-group>
        <article-title>kpLogo: positional k-mer analysis reveals hidden specificity in biological sequences</article-title>
        <source>Nucleic Acids Res</source>
        <volume>45</volume>
        <year>2017</year>
        <fpage>W534</fpage>
        <lpage>W538</lpage>
        <pub-id pub-id-type="pmid">28460012</pub-id>
      </element-citation>
    </ref>
    <ref id="bib36">
      <label>36</label>
      <element-citation publication-type="journal" id="sbref31">
        <person-group person-group-type="author">
          <name>
            <surname>O'Shea</surname>
            <given-names>J.P.</given-names>
          </name>
          <name>
            <surname>Chou</surname>
            <given-names>M.F.</given-names>
          </name>
          <name>
            <surname>Quader</surname>
            <given-names>S.A.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>pLogo: a probabilistic approach to visualizing sequence motifs</article-title>
        <source>Nat Methods</source>
        <volume>10</volume>
        <year>2013</year>
        <fpage>1211</fpage>
        <lpage>1212</lpage>
        <pub-id pub-id-type="pmid">24097270</pub-id>
      </element-citation>
    </ref>
    <ref id="bib37">
      <label>37</label>
      <element-citation publication-type="journal" id="sbref32">
        <person-group person-group-type="author">
          <name>
            <surname>Wang</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>K.</given-names>
          </name>
          <name>
            <surname>Ngo</surname>
            <given-names>V.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Identification of DNA motifs that regulate DNA methylation</article-title>
        <source>Nucleic Acids Res</source>
        <volume>47</volume>
        <year>2019</year>
        <fpage>6753</fpage>
        <lpage>6768</lpage>
        <pub-id pub-id-type="pmid">31334813</pub-id>
      </element-citation>
    </ref>
    <ref id="bib38">
      <label>38</label>
      <element-citation publication-type="journal" id="sbref33">
        <person-group person-group-type="author">
          <name>
            <surname>Lienert</surname>
            <given-names>F.</given-names>
          </name>
          <name>
            <surname>Wirbelauer</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Som</surname>
            <given-names>I.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Identification of genetic elements that autonomously determine DNA methylation states</article-title>
        <source>Nat Genet</source>
        <volume>43</volume>
        <year>2011</year>
        <fpage>1091</fpage>
        <lpage>1097</lpage>
        <pub-id pub-id-type="pmid">21964573</pub-id>
      </element-citation>
    </ref>
    <ref id="bib39">
      <label>39</label>
      <element-citation publication-type="journal" id="sbref34">
        <person-group person-group-type="author">
          <name>
            <surname>Stadler</surname>
            <given-names>M.B.</given-names>
          </name>
          <name>
            <surname>Murr</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Burger</surname>
            <given-names>L.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>DNA-binding factors shape the mouse methylome at distal regulatory regions</article-title>
        <source>Nature</source>
        <volume>480</volume>
        <year>2011</year>
        <fpage>490</fpage>
        <lpage>495</lpage>
        <pub-id pub-id-type="pmid">22170606</pub-id>
      </element-citation>
    </ref>
    <ref id="bib40">
      <label>40</label>
      <element-citation publication-type="journal" id="sbref35">
        <person-group person-group-type="author">
          <name>
            <surname>Ngo</surname>
            <given-names>V.</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>W.</given-names>
          </name>
        </person-group>
        <article-title>Finding de novo methylated DNA motifs</article-title>
        <source>Bioinformatics</source>
        <volume>35</volume>
        <year>2019</year>
        <fpage>3287</fpage>
        <lpage>3293</lpage>
        <pub-id pub-id-type="pmid">30726880</pub-id>
      </element-citation>
    </ref>
  </ref-list>
  <sec id="sec0085" sec-type="supplementary-material">
    <label>Appendix A</label>
    <title>Supplementary material</title>
    <p id="p0155"><supplementary-material content-type="local-data" id="ec0005"><caption><p>Supplementary material</p></caption><media xlink:href="mmc1.docx"/></supplementary-material>.</p>
  </sec>
  <sec sec-type="data-availability" id="da0005">
    <title>Data availability</title>
    <p id="p0026">The source codes of CNN6mA are freely accessible at <ext-link ext-link-type="uri" xlink:href="https://github.com/kuratahiroyuki/CNN6mA.git" id="ir0015">https://github.com/kuratahiroyuki/CNN6mA.git</ext-link>, respectively.</p>
  </sec>
  <ack id="ack0005">
    <title>Acknowledgment</title>
    <p id="p0145">This work was supported by a <funding-source id="gs1">Grant-in-Aid for Scientific Research</funding-source> (B) (22H03688) and partially supported by a <funding-source id="gs2">Grant-in-Aid for JSPS Research Fellows</funding-source> (22J22706) from the Japan Society for the Promotion of Science (<funding-source id="gs3"><institution-wrap><institution-id institution-id-type="doi">10.13039/501100001691</institution-id><institution>JSPS</institution></institution-wrap></funding-source>).</p>
  </ack>
  <fn-group>
    <fn id="sec0080" fn-type="supplementary-material">
      <label>Appendix A</label>
      <p id="p0150">Supplementary data associated with this article can be found in the online version at <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.csbj.2022.12.043" id="ir0025">doi:10.1016/j.csbj.2022.12.043</ext-link>.</p>
    </fn>
  </fn-group>
</back>
