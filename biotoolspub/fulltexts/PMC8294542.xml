<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1d3 20150301//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 39.96?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?subarticle pone.0254062.r001?>
<?properties open_access?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">PLoS One</journal-id>
    <journal-id journal-id-type="iso-abbrev">PLoS One</journal-id>
    <journal-id journal-id-type="publisher-id">plos</journal-id>
    <journal-title-group>
      <journal-title>PLoS ONE</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1932-6203</issn>
    <publisher>
      <publisher-name>Public Library of Science</publisher-name>
      <publisher-loc>San Francisco, CA USA</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">8294542</article-id>
    <article-id pub-id-type="publisher-id">PONE-D-21-10500</article-id>
    <article-id pub-id-type="doi">10.1371/journal.pone.0254062</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Research Article</subject>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Physical Sciences</subject>
        <subj-group>
          <subject>Mathematics</subject>
          <subj-group>
            <subject>Applied Mathematics</subject>
            <subj-group>
              <subject>Algorithms</subject>
              <subj-group>
                <subject>Machine Learning Algorithms</subject>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Research and Analysis Methods</subject>
        <subj-group>
          <subject>Simulation and Modeling</subject>
          <subj-group>
            <subject>Algorithms</subject>
            <subj-group>
              <subject>Machine Learning Algorithms</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Computer and Information Sciences</subject>
        <subj-group>
          <subject>Artificial Intelligence</subject>
          <subj-group>
            <subject>Machine Learning</subject>
            <subj-group>
              <subject>Machine Learning Algorithms</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Research and Analysis Methods</subject>
        <subj-group>
          <subject>Computational Techniques</subject>
          <subj-group>
            <subject>Computational Pipelines</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Physical Sciences</subject>
        <subj-group>
          <subject>Mathematics</subject>
          <subj-group>
            <subject>Optimization</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Computer and Information Sciences</subject>
        <subj-group>
          <subject>Artificial Intelligence</subject>
          <subj-group>
            <subject>Machine Learning</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Physical Sciences</subject>
        <subj-group>
          <subject>Mathematics</subject>
          <subj-group>
            <subject>Applied Mathematics</subject>
            <subj-group>
              <subject>Algorithms</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Research and Analysis Methods</subject>
        <subj-group>
          <subject>Simulation and Modeling</subject>
          <subj-group>
            <subject>Algorithms</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Medicine and Health Sciences</subject>
        <subj-group>
          <subject>Cardiology</subject>
          <subj-group>
            <subject>Heart Failure</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Computer and Information Sciences</subject>
        <subj-group>
          <subject>Artificial Intelligence</subject>
          <subj-group>
            <subject>Machine Learning</subject>
            <subj-group>
              <subject>Support Vector Machines</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Computer and Information Sciences</subject>
        <subj-group>
          <subject>Data Management</subject>
          <subj-group>
            <subject>Data Processing</subject>
          </subj-group>
        </subj-group>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>PHOTONAI—A Python API for rapid machine learning model development</article-title>
      <alt-title alt-title-type="running-head">PHOTONAI—A Python API for rapid machine learning model development</alt-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" equal-contrib="yes">
        <contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-9137-7510</contrib-id>
        <name>
          <surname>Leenings</surname>
          <given-names>Ramona</given-names>
        </name>
        <role content-type="https://casrai.org/credit/">Conceptualization</role>
        <role content-type="https://casrai.org/credit/">Formal analysis</role>
        <role content-type="https://casrai.org/credit/">Project administration</role>
        <role content-type="https://casrai.org/credit/">Software</role>
        <role content-type="https://casrai.org/credit/">Writing – original draft</role>
        <role content-type="https://casrai.org/credit/">Writing – review &amp; editing</role>
        <xref rid="aff001" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="aff002" ref-type="aff">
          <sup>2</sup>
        </xref>
        <xref rid="cor001" ref-type="corresp">*</xref>
      </contrib>
      <contrib contrib-type="author" equal-contrib="yes">
        <name>
          <surname>Winter</surname>
          <given-names>Nils Ralf</given-names>
        </name>
        <role content-type="https://casrai.org/credit/">Conceptualization</role>
        <role content-type="https://casrai.org/credit/">Project administration</role>
        <role content-type="https://casrai.org/credit/">Software</role>
        <role content-type="https://casrai.org/credit/">Writing – original draft</role>
        <role content-type="https://casrai.org/credit/">Writing – review &amp; editing</role>
        <xref rid="aff001" ref-type="aff">
          <sup>1</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Plagwitz</surname>
          <given-names>Lucas</given-names>
        </name>
        <role content-type="https://casrai.org/credit/">Software</role>
        <xref rid="aff001" ref-type="aff">
          <sup>1</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Holstein</surname>
          <given-names>Vincent</given-names>
        </name>
        <role content-type="https://casrai.org/credit/">Software</role>
        <role content-type="https://casrai.org/credit/">Writing – review &amp; editing</role>
        <xref rid="aff001" ref-type="aff">
          <sup>1</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-4649-2111</contrib-id>
        <name>
          <surname>Ernsting</surname>
          <given-names>Jan</given-names>
        </name>
        <role content-type="https://casrai.org/credit/">Software</role>
        <xref rid="aff001" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="aff002" ref-type="aff">
          <sup>2</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-4840-5619</contrib-id>
        <name>
          <surname>Sarink</surname>
          <given-names>Kelvin</given-names>
        </name>
        <role content-type="https://casrai.org/credit/">Software</role>
        <xref rid="aff001" ref-type="aff">
          <sup>1</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Fisch</surname>
          <given-names>Lukas</given-names>
        </name>
        <role content-type="https://casrai.org/credit/">Software</role>
        <xref rid="aff001" ref-type="aff">
          <sup>1</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Steenweg</surname>
          <given-names>Jakob</given-names>
        </name>
        <role content-type="https://casrai.org/credit/">Software</role>
        <xref rid="aff001" ref-type="aff">
          <sup>1</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Kleine-Vennekate</surname>
          <given-names>Leon</given-names>
        </name>
        <role content-type="https://casrai.org/credit/">Software</role>
        <xref rid="aff001" ref-type="aff">
          <sup>1</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Gebker</surname>
          <given-names>Julian</given-names>
        </name>
        <role content-type="https://casrai.org/credit/">Software</role>
        <xref rid="aff001" ref-type="aff">
          <sup>1</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Emden</surname>
          <given-names>Daniel</given-names>
        </name>
        <role content-type="https://casrai.org/credit/">Software</role>
        <xref rid="aff001" ref-type="aff">
          <sup>1</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Grotegerd</surname>
          <given-names>Dominik</given-names>
        </name>
        <role content-type="https://casrai.org/credit/">Software</role>
        <role content-type="https://casrai.org/credit/">Writing – review &amp; editing</role>
        <xref rid="aff001" ref-type="aff">
          <sup>1</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Opel</surname>
          <given-names>Nils</given-names>
        </name>
        <role content-type="https://casrai.org/credit/">Writing – review &amp; editing</role>
        <xref rid="aff001" ref-type="aff">
          <sup>1</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Risse</surname>
          <given-names>Benjamin</given-names>
        </name>
        <role content-type="https://casrai.org/credit/">Formal analysis</role>
        <role content-type="https://casrai.org/credit/">Writing – review &amp; editing</role>
        <xref rid="aff002" ref-type="aff">
          <sup>2</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Jiang</surname>
          <given-names>Xiaoyi</given-names>
        </name>
        <role content-type="https://casrai.org/credit/">Formal analysis</role>
        <role content-type="https://casrai.org/credit/">Writing – review &amp; editing</role>
        <xref rid="aff002" ref-type="aff">
          <sup>2</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Dannlowski</surname>
          <given-names>Udo</given-names>
        </name>
        <role content-type="https://casrai.org/credit/">Funding acquisition</role>
        <role content-type="https://casrai.org/credit/">Writing – review &amp; editing</role>
        <xref rid="aff001" ref-type="aff">
          <sup>1</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Hahn</surname>
          <given-names>Tim</given-names>
        </name>
        <role content-type="https://casrai.org/credit/">Conceptualization</role>
        <role content-type="https://casrai.org/credit/">Formal analysis</role>
        <role content-type="https://casrai.org/credit/">Funding acquisition</role>
        <role content-type="https://casrai.org/credit/">Software</role>
        <role content-type="https://casrai.org/credit/">Supervision</role>
        <role content-type="https://casrai.org/credit/">Writing – original draft</role>
        <role content-type="https://casrai.org/credit/">Writing – review &amp; editing</role>
        <xref rid="aff001" ref-type="aff">
          <sup>1</sup>
        </xref>
      </contrib>
    </contrib-group>
    <aff id="aff001">
      <label>1</label>
      <addr-line>Institute for Translational Psychiatry, University of Münster, Münster, Germany</addr-line>
    </aff>
    <aff id="aff002">
      <label>2</label>
      <addr-line>Faculty of Mathematics and Computer Science, University of Münster, Münster, Germany</addr-line>
    </aff>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Gadekallu</surname>
          <given-names>Thippa Reddy</given-names>
        </name>
        <role>Editor</role>
        <xref rid="edit1" ref-type="aff"/>
      </contrib>
    </contrib-group>
    <aff id="edit1">
      <addr-line>Vellore Institute of Technology: VIT University, INDIA</addr-line>
    </aff>
    <author-notes>
      <fn fn-type="COI-statement" id="coi001">
        <p><bold>Competing Interests: </bold>The authors have declared that no competing interests exist.</p>
      </fn>
      <corresp id="cor001">* E-mail: <email>leenings@uni-muenster.de</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <year>2021</year>
    </pub-date>
    <pub-date pub-type="epub">
      <day>21</day>
      <month>7</month>
      <year>2021</year>
    </pub-date>
    <volume>16</volume>
    <issue>7</issue>
    <elocation-id>e0254062</elocation-id>
    <history>
      <date date-type="received">
        <day>30</day>
        <month>3</month>
        <year>2021</year>
      </date>
      <date date-type="accepted">
        <day>20</day>
        <month>6</month>
        <year>2021</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© 2021 Leenings et al</copyright-statement>
      <copyright-year>2021</copyright-year>
      <copyright-holder>Leenings et al</copyright-holder>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an open access article distributed under the terms of the <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
      </license>
    </permissions>
    <self-uri xmlns:xlink="http://www.w3.org/1999/xlink" content-type="pdf" xlink:href="pone.0254062.pdf"/>
    <abstract>
      <p>PHOTONAI is a high-level Python API designed to simplify and accelerate machine learning model development. It functions as a unifying framework allowing the user to easily access and combine algorithms from different toolboxes into custom algorithm sequences. It is especially designed to support the iterative model development process and automates the repetitive training, hyperparameter optimization and evaluation tasks. Importantly, the workflow ensures unbiased performance estimates while still allowing the user to fully customize the machine learning analysis. PHOTONAI extends existing solutions with a novel pipeline implementation supporting more complex data streams, feature combinations, and algorithm selection. Metrics and results can be conveniently visualized using the PHOTONAI Explorer and predictive models are shareable in a standardized format for further external validation or application. A growing add-on ecosystem allows researchers to offer data modality specific algorithms to the community and enhance machine learning in the areas of the life sciences. Its practical utility is demonstrated on an exemplary medical machine learning problem, achieving a state-of-the-art solution in few lines of code. Source code is publicly available on Github, while examples and documentation can be found at <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="http://www.photon-ai.com" ext-link-type="uri">www.photon-ai.com</ext-link>.</p>
    </abstract>
    <funding-group>
      <award-group id="award001">
        <funding-source>
          <institution>Interdisziplinäres Zentrum für Klinische Forschung, Universitätsklinikum Münster</institution>
        </funding-source>
        <award-id>MzH 3/020/20</award-id>
        <principal-award-recipient>
          <name>
            <surname>Hahn</surname>
            <given-names>Tim</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
      <award-group id="award002">
        <funding-source>
          <institution>Interdisziplinäres Zentrum für Klinische Forschung, Universitätsklinikum Münster</institution>
        </funding-source>
        <award-id>Dan3/012/17</award-id>
        <principal-award-recipient>
          <name>
            <surname>Dannlowski</surname>
            <given-names>Udo</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
      <award-group id="award003">
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/501100001659</institution-id>
            <institution>Deutsche Forschungsgemeinschaft</institution>
          </institution-wrap>
        </funding-source>
        <award-id>HA7070/2-2, HA7070/3, HA7070/4</award-id>
        <principal-award-recipient>
          <name>
            <surname>Hahn</surname>
            <given-names>Tim</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
      <funding-statement>This work was supported by grants from the Interdisciplinary Center for Clinical Research (IZKF, <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://www.medizin.uni-muenster.de/izkf.html" ext-link-type="uri">https://www.medizin.uni-muenster.de/izkf.html</ext-link>) of the medical faculty of Münster (grant MzH 3/020/20 to TH and grant Dan3/012/17 to UD) and the German Research Foundation (DFG, <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://www.dfg.de/" ext-link-type="uri">https://www.dfg.de/</ext-link>, grants HA7070/2-2, HA7070/3, HA7070/4 to TH). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
    </funding-group>
    <counts>
      <fig-count count="4"/>
      <table-count count="3"/>
      <page-count count="19"/>
    </counts>
    <custom-meta-group>
      <custom-meta id="data-availability">
        <meta-name>Data Availability</meta-name>
        <meta-value><ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://doi.org/10.1186/s12911-020-1023-5" ext-link-type="uri">https://doi.org/10.1186/s12911-020-1023-5</ext-link> Davide Chicco, Giuseppe Jurman: Machine learning can predict survival of patients with heart failure from serum creatinine and ejection fraction alone. BMC Medical Informatics and Decision Making 20, 16 (2020) <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://www.kaggle.com/andrewmvd/heart-failure-clinical-data" ext-link-type="uri">https://www.kaggle.com/andrewmvd/heart-failure-clinical-data</ext-link>.</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
  <notes>
    <title>Data Availability</title>
    <p><ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://doi.org/10.1186/s12911-020-1023-5" ext-link-type="uri">https://doi.org/10.1186/s12911-020-1023-5</ext-link> Davide Chicco, Giuseppe Jurman: Machine learning can predict survival of patients with heart failure from serum creatinine and ejection fraction alone. BMC Medical Informatics and Decision Making 20, 16 (2020) <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://www.kaggle.com/andrewmvd/heart-failure-clinical-data" ext-link-type="uri">https://www.kaggle.com/andrewmvd/heart-failure-clinical-data</ext-link>.</p>
  </notes>
</front>
<body>
  <sec sec-type="intro" id="sec001">
    <title>Introduction</title>
    <p>In recent years, the interest in machine learning for medical, biological, and life science research has significantly increased. Technological advances develop with breathtaking speed. The basic workflow to construct, optimize and evaluate a machine learning model, however, has remained virtually unchanged. In essence, it can be framed as the (systematic) search for the best combination of data processing steps, learning algorithms, and hyperparameter values under the premise of unbiased performance estimation.</p>
    <p>Subject to the iteratively optimized workflow is a machine learning pipeline, which in this context is defined as the sequence of algorithms subsequently applied to the data. To begin with, the data is commonly prepared by successively applying several processing steps such as normalization, imputation, feature selection, dimensionality reduction, data augmentation, and others. The altered data is then forwarded to one or more learning algorithms which internally derive the best fit for the learning task and finally yield predictions.</p>
    <p>In practice, researchers select suitable preprocessing and learning algorithms from different toolboxes, learn toolbox-specific syntaxes, decide for a training and testing scheme, manage the data flow and, over time, iteratively optimize their choices. Importantly, all of this is done while preventing data leakage, calculating performance metrics, adhering to (nested) cross-validation best practices, and searching for the optimal (hyperparameter-) configuration.</p>
    <p>A multitude of high-quality and well-maintained open-source toolboxes offer specialized solutions, each for a particular subdomain of machine learning-related (optimization) problems.</p>
    <sec id="sec002">
      <title>Existing solutions: Specialized open-source toolboxes</title>
      <p>In the field of (deep) neural networks, libraries such as <italic toggle="yes">Tensorflow</italic>, <italic toggle="yes">Theano</italic>, <italic toggle="yes">Caffe</italic> and <italic toggle="yes">PyTorch</italic> [<xref rid="pone.0254062.ref001" ref-type="bibr">1</xref>–<xref rid="pone.0254062.ref004" ref-type="bibr">4</xref>] offer domain-specific implementations for nodes, layers, optimizers, as well as evaluation and utility functions. On top of that, higher level Application Programming Interfaces (APIs) such as <italic toggle="yes">Keras</italic> and <italic toggle="yes">fastai</italic> [<xref rid="pone.0254062.ref005" ref-type="bibr">5</xref>, <xref rid="pone.0254062.ref006" ref-type="bibr">6</xref>] offer expressive syntaxes for accelerated and enhanced development of deep neural network architectures.</p>
      <p>In the same manner, the <italic toggle="yes">scikit-learn</italic> [<xref rid="pone.0254062.ref007" ref-type="bibr">7</xref>] toolbox, has evolved as one of the major resources of the field, covering a very broad range of regression, classification, clustering, and preprocessing algorithms. It has established the de-facto standard interface for data processing and learning algorithms, and, in addition, offers a wide range of utility functions, such as cross-validation schemes and model evaluation metrics.</p>
      <p>Next to these general frameworks, other libraries in the software landscape offer functionalities to address more specialized problems. Prominent examples are the <italic toggle="yes">imbalanced-learn</italic> toolbox [<xref rid="pone.0254062.ref008" ref-type="bibr">8</xref>], which provides numerous over- or under-sampling methods, or modality-specific libraries such as <italic toggle="yes">nilearn</italic> and <italic toggle="yes">nibabel</italic> [<xref rid="pone.0254062.ref009" ref-type="bibr">9</xref>, <xref rid="pone.0254062.ref010" ref-type="bibr">10</xref>] which offer utility functions for accessing and preparing neuroimaging data.</p>
      <p>On top of that, the software landscape is complemented by several hyperparameter optimization packages, each implementing a different strategy to find the most effective hyperparameter combination. Next to Bayesian approaches, such as <italic toggle="yes">Scikit-optimize</italic> or <italic toggle="yes">SMAC</italic> [<xref rid="pone.0254062.ref011" ref-type="bibr">11</xref>, <xref rid="pone.0254062.ref012" ref-type="bibr">12</xref>], there are packages implementing evolutionary strategies [<xref rid="pone.0254062.ref013" ref-type="bibr">13</xref>] or packages approximating gradient descent within the hyperparameter space [<xref rid="pone.0254062.ref014" ref-type="bibr">14</xref>, <xref rid="pone.0254062.ref015" ref-type="bibr">15</xref>]. Each package requires specific syntax and unique hyperparameter space definitions.</p>
      <p>Finally, there are approaches uniting all these components into algorithms that automatically derive the best model architecture and hyperparameter settings for a given dataset. Libraries such as <italic toggle="yes">auto-sklearn</italic>, <italic toggle="yes">TPOT</italic>, <italic toggle="yes">AutoWeka</italic>, <italic toggle="yes">Auto-keras</italic>, <italic toggle="yes">AutoML</italic>, <italic toggle="yes">Auto-Gluon</italic> and others optimize a specific set of data-processing methods, learning algorithms and their respective hyperparameters [<xref rid="pone.0254062.ref016" ref-type="bibr">16</xref>–<xref rid="pone.0254062.ref022" ref-type="bibr">22</xref>]. While very intriguing, these libraries aim at full automation—neglecting the need for customization and foregoing the opportunity to incorporate high-level domain knowledge in the model architecture search. Especially the complex and often high-dimensional data structure native to medical and biological research requires the integration and application of modality-specific processing and often entails the development of novel algorithms.</p>
    </sec>
    <sec id="sec003">
      <title>Current shortcoming: Manual integration of cross-toolbox algorithm sequences</title>
      <p>Currently, iterative model development approaches across different toolboxes as well as design and optimization of custom algorithm sequences are barely supported. For a start, <italic toggle="yes">scikit-learn</italic> has introduced the concept of pipelines, which successively apply a list of processing methods (referred to as transformers) and a final learning algorithm (called estimator) to the data. The pipeline directs the data from one algorithm to another and can be trained and evaluated in (simple) cross-validation schemes, thereby significantly reducing programmatic overhead. Scikit-learn’s consistent usage of standard interfaces enables the pipeline to be subject to scikit-learn’s inherent hyperparameter optimization strategies based on random- and grid-search. While being a simple and effective tool, several limitations still remain. For one, hyperparameter optimization requires a nested cross-validation scheme, which is not inherently enforced. Second, a standardized solution for easy integration of custom or third-party algorithms is not considered. In addition, several repetitive tasks, such as metric calculations, logging, and visualization lack automation and still need to be handled manually. Finally, the pipeline can not handle adjustments to the target vector, thereby excluding algorithms for e.g. data augmentation or handling class imbalance.</p>
    </sec>
    <sec id="sec004">
      <title>Major contributions of PHOTONAI: Supporting a convenient development workflow</title>
      <p>To address these issues, we propose <italic toggle="yes">PHOTONAI</italic> as a high-level Python API that acts as a mediator between different toolboxes. Established solutions are conveniently accessible or can be easily added. It combines an automated supervised machine learning workflow with the concept of custom machine learning pipelines. Thereby it is able to considerably accelerate design iterations and simplify the evaluation of novel analysis pipelines. In essence, <italic toggle="yes">PHOTONAI</italic>’s major contributions are:</p>
      <sec id="sec005">
        <title>Increased accessibility</title>
        <p>By pre-registering data processing methods, learning algorithms, hyperparameter optimization strategies, performance metrics, and other functionalities, the user can effortlessly access established machine learning implementations via simple keywords. In addition, by relying on the established scikit-learn object API [<xref rid="pone.0254062.ref023" ref-type="bibr">23</xref>], users can easily integrate any third-party or custom algorithm implementation.</p>
      </sec>
      <sec id="sec006">
        <title>Extended pipeline functionality</title>
        <p>A simple to use class structure allows the user to arrange selected algorithms into single or parallel pipeline sequences. Extending the pipeline concept of scikit-learn [<xref rid="pone.0254062.ref007" ref-type="bibr">7</xref>], we add novel functionality such as flexible positioning of learning algorithms, target vector manipulations, callback functions, specialized caching, parallel data-streams, Or-Operations, and other features as described below.</p>
      </sec>
      <sec id="sec007">
        <title>Automation</title>
        <p>PHOTONAI can automatically train, (hyperparameter-) optimize and evaluate any custom pipeline. Importantly, the user designs the training and testing procedure by selecting (nested) cross-validation schemes, hyperparameter optimization strategies, and performance metrics from a range of pre-integrated or custom-built options. Thereby, development time is significantly decreased and conceptual errors such as information leakage between training, validation, and test set are avoided. Training information, baseline performances, hyperparameter optimization progress, and test performance evaluations are persisted and can be visualized via an interactive, browser-based graphical interface (PHOTONAI Explorer) to facilitate model insight.</p>
      </sec>
      <sec id="sec008">
        <title>Model sharing</title>
        <p>A standardized format for saving, loading, and distributing optimized and trained pipeline architectures enables model sharing and external model validation even for non-expert users.</p>
      </sec>
    </sec>
  </sec>
  <sec sec-type="materials|methods" id="sec009">
    <title>Materials and methods</title>
    <p>In the following, we will describe the automated supervised machine learning workflow implemented in PHOTONAI. Subsequently, we will outline the class structure, which is the core of its expressive syntax. At the same time, we will highlight its current functionalities, and finally, provide a hands-on example to introduce PHOTONAI’s usage. Lastly, we close with discussing current challenges and future developments.</p>
    <sec id="sec010">
      <title>Software architecture and workflow</title>
      <p>PHOTONAI automatizes the supervised machine learning workflow according to user-defined parameters (see pseudocode in Listing 1). In a nutshell, cross-validation folds are derived to iteratively train and evaluate a machine learning pipeline following the hyperparameter optimization strategy’s current parameter value suggestions. Performance metrics are calculated, the progress is logged and finally, the best hyperparameter configuration is selected to train a final model. The training, testing, and optimization workflow is automated, however, it is important to note that it is parameterized by user choices and therefore fully customized.</p>
      <p>In order to achieve an efficient and expressive customization syntax, PHOTONAI’s class architecture captures all workflow- and pipeline-related parameters into distinct and combinable components (see <xref rid="pone.0254062.g001" ref-type="fig">Fig 1</xref>). A central management class called <italic toggle="yes">Hyperpipe</italic>—short for hyperparameter optimization pipeline—handles the setup of the pipeline and executes the training and test procedure according to user choices. Basis to the data flow is a custom <italic toggle="yes">Pipeline</italic> implementation, which streams data through a sequence of <italic toggle="yes">PipelineElement</italic> objects, the latter of which represent either established or custom algorithm implementations. In addition, clear interfaces and several utility classes allow the integration of custom solutions, adjust the training and test procedure and build parallel data streams. In the following, PHOTONAI’s core classes and their respective features will be further detailed.</p>
      <fig position="float" id="pone.0254062.g001">
        <object-id pub-id-type="doi">10.1371/journal.pone.0254062.g001</object-id>
        <label>Fig 1</label>
        <caption>
          <title>Class architecture.</title>
          <p>The PHOTONAI framework is built to accelerate and simplify the design of machine learning models. It adds an abstraction layer to existing solutions and is thereby able to simplify, structure, and automate the training, optimization, and testing workflow. Importantly, the pipeline and the workflow are subject to user choices as the user selects a sequence of processing and learning algorithms and parameterizes the optimization and validation workflow. The here depicted class diagram shows PHOTONAI’s core structure. The central element is the <italic toggle="yes">Hyperpipe</italic> class, short for hyperparameter optimization pipeline, which manages a pipeline and the associated training, optimization, and testing workflow. The <italic toggle="yes">Pipeline</italic> streams data through a sequence of <italic toggle="yes">n</italic>
<italic toggle="yes">PipelineElements</italic>. PHOTONAI relies on the established scikit-learn [<xref rid="pone.0254062.ref007" ref-type="bibr">7</xref>] object API, to integrate established or custom algorithms (<italic toggle="yes">BaseElements</italic>) into the workflow. <italic toggle="yes">PipelineElements</italic> can have <italic toggle="yes">n</italic> hyperparameters which are subject to optimization by a hyperparameter optimization strategy.</p>
        </caption>
        <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="pone.0254062.g001" position="float"/>
      </fig>
      <sec id="sec011">
        <title>Core framework—The hyperpipe class</title>
        <p>PHOTONAI’s core functionality is encapsulated in a class called <italic toggle="yes">Hyperpipe</italic>, which controls all workflow and pipeline-related parameters and manages the cross-validated training and testing procedure (see Listing 1). In particular, it partitions the data according to the cross-validation splits, requests hyperparameter configurations, trains and evaluates the pipeline with the given configuration, calculates performance metrics, and coordinates the logging of all results and metadata such as e.g. computation time. In addition, the <italic toggle="yes">Hyperpipe</italic> ranks all tested hyperparameter configurations based on a user-selected performance metric and yields a final (optimal) model trained with the best performing hyperparameter configuration. Further, a baseline performance is established by applying a simple heuristic [<xref rid="pone.0254062.ref024" ref-type="bibr">24</xref>]. This aids in assessing model performance and facilitates interpretation of the results.</p>
        <p><bold>Algorithm 1</bold> Pseudocode for PHOTONAI’s training, hyperparameter optimization and testing workflow as implements in the Hyperpipe class</p>
        <p specific-use="line"> <bold>Input</bold>:</p>
        <p specific-use="line"> (1) Pipeline, sequence of algorithms, <italic toggle="yes">pipeline</italic></p>
        <p specific-use="line"> (2) Performance metrics, <italic toggle="yes">metrics</italic></p>
        <p specific-use="line"> (3) Hyperparameter Optimization Strategy, <italic toggle="yes">hpo</italic></p>
        <p specific-use="line"> (4) Outer Cross-Validation Strategy, <italic toggle="yes">ocv</italic></p>
        <p specific-use="line"> (5) Inner Cross-Validation Strategy, <italic toggle="yes">icv</italic></p>
        <p specific-use="line"> (6) Features X and Targets y, <italic toggle="yes">data</italic></p>
        <p specific-use="line"> (7) Performance Expectations, <italic toggle="yes">performance_constraints</italic></p>
        <p specific-use="line">1 <bold>for</bold>
<italic toggle="yes">outer_fold</italic> = 1, 2, … <italic toggle="yes">T</italic> ∈ <italic toggle="yes">ocv.split</italic>(<italic toggle="yes">data</italic>) <bold>do</bold></p>
        <p specific-use="line">2  outer_fold_data = data[outer_fold<sub>T</sub>]</p>
        <p specific-use="line">3  dummy_performance = apply_dummy_heuristic(outer_fold_data)</p>
        <p specific-use="line">4</p>
        <p specific-use="line">5  hpo.initialize_hyperparameter_space(pipeline)</p>
        <p specific-use="line">6  <bold>for</bold> hp_config in hpo.ask() <bold>do</bold></p>
        <p specific-use="line">7   <bold>for</bold>
<italic toggle="yes">inner_fold</italic> = 1, 2, ..<italic toggle="yes">V</italic> ∈ <italic toggle="yes">icv.split</italic>(<italic toggle="yes">outer_fold_data</italic>) <bold>do</bold></p>
        <p specific-use="line">8    inner_data = outer_fold_data[inner_fold<sub>V</sub>]</p>
        <p specific-use="line">9    hp_performance = train_and_test(pipeline, hp_config,</p>
        <p specific-use="line">10                 metrics, inner_data)</p>
        <p specific-use="line">11    hpo.tell(hp_performance)</p>
        <p specific-use="line">12    <bold>if</bold> performance_constraints <bold>then</bold></p>
        <p specific-use="line">13     <bold>if</bold> hp_performance &lt; performance_constraints <bold>then</bold></p>
        <p specific-use="line">14      break</p>
        <p specific-use="line">15     <bold>end if</bold></p>
        <p specific-use="line">16    <bold>end if</bold></p>
        <p specific-use="line">17   <bold>end for</bold></p>
        <p specific-use="line">18   val_performance = mean([hp_performance<sub>1</sub>, …, hp_performance<sub>V</sub>])</p>
        <p specific-use="line">19   <bold>if</bold> hp_config_performance &lt; best_performance <bold>then</bold></p>
        <p specific-use="line">20    best_outer_fold_configT = hp_config</p>
        <p specific-use="line">21   <bold>end if</bold></p>
        <p specific-use="line">22  <bold>end for</bold></p>
        <p specific-use="line">23  test_performance = train_and_test(pipeline, best_outer_fold_config,</p>
        <p specific-use="line">24                metrics, outer_fold_data)</p>
        <p specific-use="line">25 <bold>end for</bold></p>
        <p specific-use="line">26 overall_best_performance = argmax([test_performance<sub>1</sub>, …, test_performance<sub>T</sub>])</p>
        <p specific-use="line">27 overall_best_config = [best_outer_configs1, …,</p>
        <p specific-use="line">28          best_outer_configT][overall_best_performance]</p>
        <p specific-use="line">29 pipeline.set_params(overall_best_config)</p>
        <p specific-use="line">30 pipeline.fit(X, y)</p>
        <p specific-use="line">31 pipeline.save()</p>
        <p><bold>Listing 1</bold>. Setting the parameters to control the training, hyperparameter optimization and testing workflow using the <italic toggle="yes">Hyperpipe</italic> class.</p>
        <p specific-use="line">1 pipe = Hyperpipe(‘example_project’,</p>
        <p specific-use="line">2        optimizer=‘sk_opt’,</p>
        <p specific-use="line">3        optimizer_params={‘n_configurations’: 25},</p>
        <p specific-use="line">4        metrics=[‘accuracy’, ‘precision’, ‘recall’],</p>
        <p specific-use="line">5        best_config_metric=‘accuracy’,</p>
        <p specific-use="line">6        outer_cv=KFold(n_splits=3),</p>
        <p specific-use="line">7        inner_cv=KFold(n_splits=3))</p>
      </sec>
      <sec id="sec012">
        <title>The PHOTONAI pipeline—Extended pipeline features</title>
        <p>The <italic toggle="yes">Hyperpipe</italic> relies on a custom pipeline implementation that is conceptually related to the scikit-learn pipeline [<xref rid="pone.0254062.ref025" ref-type="bibr">25</xref>] but extends it with four core features. First, it enables the positioning of learning algorithms at an arbitrary position within the pipeline. In case a <italic toggle="yes">PipelineElement</italic> is identified that a) provides no <italic toggle="yes">transform</italic> method and b) yet is followed by one or more other <italic toggle="yes">PipelineElements</italic>, it automatically calls <italic toggle="yes">predict</italic> and delivers the output to the subsequent pipeline elements. Thereby, learning algorithms can be joined to ensembles, used within sub pipelines, or be part of other custom pipeline architectures without interrupting the data stream.</p>
        <p>Second, it allows for a dynamic transformation of the target vector anywhere within the data stream. Common use-cases for this scenario include data augmentation approaches—in which the number of training samples is increased by applying transformations (e.g. rotations to an image)—or strategies for an imbalanced dataset, in which the number of samples per class is equalized via e.g. under- or oversampling.</p>
        <p>Third, numerous use-cases rely on data not contained in the feature matrix at runtime, e.g. when aiming to control for the effect of covariates. In PHOTONAI, additional data can be streamed through the pipeline and is accessible for all pipeline steps while—importantly—being matched to the (nested) cross-validation splits.</p>
        <p>Finally, PHOTONAI implements pipeline callbacks which allow for live inspection of the data flowing through the pipeline at runtime. <italic toggle="yes">Callbacks</italic> act as pipeline elements and can be inserted at any point within the pipeline. They must define a function delegate which is called with the same data that the next pipeline step will receive. Thereby, a developer may inspect e.g. the shape and values of the feature matrix after a sequence of transformations has been applied. Return values from the delegate functions are ignored so that after returning from the delegate call, the original data is directly passed to the next processing step.</p>
        <p><bold>Listing 2</bold>. Algorithms can be accessed via keywords and are represented together with all potential hyperparameter values.</p>
        <p specific-use="line">1 # add two preprocessing algorithms to the data stream</p>
        <p specific-use="line">2 pipe += PipelineElement(‘PCA’,</p>
        <p specific-use="line">3            hyperparameters={‘n_components’:</p>
        <p specific-use="line">4                    FloatRange(0.5, 0.8, step = 0.1)},</p>
        <p specific-use="line">5            test_disabled = True)</p>
        <p specific-use="line">6</p>
        <p specific-use="line">7 pipe += PipelineElement(‘ImbalancedDataTransformer’,</p>
        <p specific-use="line">8            hyperparameters={‘method_name’:</p>
        <p specific-use="line">9                    [‘RandomUnderSampler’,‘SMOTE’]},</p>
        <p specific-use="line">10            test_disabled = True)</p>
      </sec>
      <sec id="sec013">
        <title>The pipeline element—Conveniently access cross-toolbox algorithms</title>
        <p>In order to integrate a particular algorithm into the pipeline’s data stream, PHOTONAI implements the <italic toggle="yes">PipelineElement</italic> class. This can either be a data processing algorithm, in reference to the <italic toggle="yes">scikit-learn</italic> interface also called transformer, or a learning algorithm, also referred to as estimator. By selecting and arranging <italic toggle="yes">PipelineElements</italic>, the user designs the ML pipeline. To facilitate this process, it enables convenient access to various established implementations from state-of-the-art machine learning toolboxes: With an internal registration system that instantiates class objects from a keyword, import, access, and setup of different algorithms is significantly simplified (see Listing 2). Relying on the established scikit-learn object API [<xref rid="pone.0254062.ref023" ref-type="bibr">23</xref>], users can integrate any third-party or custom algorithm implementation. Once registered, custom code fully integrates with all PHOTONAI functionalities thus being compatible with all other algorithms, hyperparameter optimization strategies, PHOTONAI’s pipeline functionality, nested cross-validation, and model persistence.</p>
      </sec>
    </sec>
    <sec id="sec014">
      <title>Hyperparameter optimization strategies</title>
      <p>Hyperparameters directly control the behavior of algorithms and may have a substantial impact on model performance. Therefore, unlike classic hyperparameter optimization, PHOTONAI’s hyperparameter optimization encompasses the hyperparameters of the entire pipeline—not only the learning algorithm’s hyperparameters as is usually done. The <italic toggle="yes">PipelineElement</italic> provides an expressive syntax for the specification of hyperparameters and their respective value ranges (see Listing 2). In addition, PHOTONAI conceptually extends the hyperparameter search by adding an on and off switch (a parameter called <italic toggle="yes">test_disabled</italic>) to each <italic toggle="yes">PipelineElement</italic>, allowing the hyperparameter optimization strategy to check if skipping an algorithm improves model performance. Representing algorithms together with their hyperparameter settings enables seamless switching between different hyperparameter optimization strategies, ranging from (random) grid search to more advanced approaches such as Bayesian or evolutionary optimization [<xref rid="pone.0254062.ref011" ref-type="bibr">11</xref>–<xref rid="pone.0254062.ref013" ref-type="bibr">13</xref>] Custom hyperparameter optimization strategies can be integrated via an extended an ask- and tell-interface or by accepting an objective function defined by PHOTONAI.</p>
    </sec>
    <sec id="sec015">
      <title>Parallel data streaming</title>
      <sec id="sec016">
        <title>The <italic toggle="yes">Switch</italic> element—Optimizing algorithm selection</title>
        <p>Building ML pipelines involves comparing different pipelines with each other. While in most state-of-the-art ML toolboxes the user has to define and benchmark each pipeline manually, in PHOTONAI it is possible to evaluate several possibilities at once. Specifically, the <italic toggle="yes">Switch</italic> object is interchanging several algorithms at the same pipeline position, representing an OR-Operation (see <xref rid="pone.0254062.g002" ref-type="fig">Fig 2</xref>). With data processing steps, learning algorithms and their hyperparameters intimately entangled, this enables algorithm selection to be part of the hyperparameter optimization process. For an example usage of the <italic toggle="yes">Switch</italic> element see <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://github.com/wwu-mmll/photonai/blob/master/examples/basic/switch.py" ext-link-type="uri">example code on github</ext-link>.</p>
        <fig position="float" id="pone.0254062.g002">
          <object-id pub-id-type="doi">10.1371/journal.pone.0254062.g002</object-id>
          <label>Fig 2</label>
          <caption>
            <title>Parallel pipeline elements.</title>
            <p><bold>A</bold>: The <italic toggle="yes">Switch</italic> class represents an OR-Operation and can be placed anywhere in the sequence to interchange and compare different algorithms at the same pipeline position. <bold>B</bold>: The <italic toggle="yes">Stack</italic> represents an AND-Operation and contains several algorithms to share a particular pipeline position. It streams the data to each element and horizontally concatenates the respective outputs (see Listing 3). Next to generating new feature matrices through several processing steps at runtime or building classifier ensembles, it can, in addition, be used in combination with the branch element.</p>
          </caption>
          <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="pone.0254062.g002" position="float"/>
        </fig>
      </sec>
      <sec id="sec017">
        <title>The <italic toggle="yes">Stack</italic> element—Combining data streams</title>
        <p>The <italic toggle="yes">Stack</italic> object acts as an AND-Operation. It allows several algorithms to share a particular pipeline position, streams the data to each element and horizontally concatenates the respective outputs (see <xref rid="pone.0254062.g002" ref-type="fig">Fig 2</xref> and Listing 3 or <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://github.com/wwu-mmll/photonai/blob/master/examples/basic/stack.py" ext-link-type="uri">demo code on github</ext-link>). Thus, new feature matrices can be created by processing the input in different ways and likewise, ensembles can be built by training several learning algorithms in parallel.</p>
        <p><bold>Listing 3</bold>. Using the <italic toggle="yes">Stack</italic> object, two learning algorithms can be trained in parallel resulting in various predictions that can e.g. to be fed into a subsequent meta-learner to create an ensemble.</p>
        <p specific-use="line">1</p>
        <p specific-use="line">2 # set up two learning algorithms in an ensemble</p>
        <p specific-use="line">3 ensemble = Stack(‘estimators’, use_probabilities = True)</p>
        <p specific-use="line">4 ensemble += PipelineElement(‘DecisionTreeClassifier’,</p>
        <p specific-use="line">5              criterion=‘gini’,</p>
        <p specific-use="line">6              hyperparameters={‘min_samples_split’:</p>
        <p specific-use="line">7                      IntegerRange(2, 4)})</p>
        <p specific-use="line">8 ensemble += PipelineElement(‘LinearSVC’,</p>
        <p specific-use="line">9              hyperparameters={‘C’: FloatRange(0.5, 25)})</p>
        <p specific-use="line">10</p>
        <p specific-use="line">11 pipe += ensemble</p>
      </sec>
      <sec id="sec018">
        <title>The <italic toggle="yes">Branch</italic> element—Building nested pipelines</title>
        <p>Finally, the <italic toggle="yes">Branch</italic> class constitutes a parallel sub-pipeline containing a distinct sequence of PipelineElements. It can be used in combination with the <italic toggle="yes">Switch</italic> and <italic toggle="yes">Stack</italic> elements enabling the creation of complex pipeline architectures integrating parallel sub-pipelines in the data flow (see <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://github.com/wwu-mmll/photonai/blob/master/examples/basic/data_integration.py" ext-link-type="uri">usage example on github</ext-link>). This could be particularly useful when deriving distinct predictions from several data subdomains, such as different brain regions, and further apply a voting strategy to the respective outputs.</p>
      </sec>
    </sec>
    <sec id="sec019">
      <title>Increasing workflow efficiency</title>
      <sec id="sec020">
        <title>Accelerated computation</title>
        <p>Several computational shortcuts are implemented in order to most efficiently use available resources. PHOTONAI allows specifying lower or upper bounds which the performance of a hyperparameter configuration has to exceed. Only then, the configuration is further evaluated in the remaining cross-validation folds, thereby accelerating hyperparameter search [<xref rid="pone.0254062.ref016" ref-type="bibr">16</xref>]. In addition, PHOTONAI can compute outer cross-validation folds in parallel relying on the python library <italic toggle="yes">dask</italic> [<xref rid="pone.0254062.ref026" ref-type="bibr">26</xref>]. It is compatible with any custom parallelized model implementation, e.g. for training a multi GPU model. Finally, PHOTONAI is able to reuse data already calculated: It implements a caching strategy that is specifically adapted to handle the varying datasets evolving from the nested cross-validation data splits as well as partially overlapping hyperparameter configurations.</p>
      </sec>
      <sec id="sec021">
        <title>Model distribution</title>
        <p>After identifying the optimal hyperparameter configuration, the <italic toggle="yes">Hyperpipe</italic> trains the pipeline with the best configuration on all available data. The resulting model including all transformers and estimators is persisted as a single file in a standardized format, suffixed with ‘.<italic toggle="yes">photon</italic>’. It can be reloaded to make predictions on new, unseen data. The .photon format facilitates model distribution, which is crucial for external model validation and thus at the heart of ML best practice, we also created a dedicated <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://www.photon-ai.com/repo" ext-link-type="uri">online model repository</ext-link> to which users can upload their models to make them publicly available. If the model is persisted in the .photon-format, others can download the file and make predictions without extensive system setups or the need to share data.</p>
      </sec>
      <sec id="sec022">
        <title>Logging and visualization</title>
        <p>PHOTONAI provides extensive result logging including both performances and metadata generated through the hyperparameter optimization process. Each hyperparameter configuration tested is archived including all performance metrics and complementary information such as computation time and the training, validation, and test indices.</p>
        <p>Finally, all results can be visualized by uploading the JSON output file to a JavaScript web application called <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://explorer.photon-ai.com" ext-link-type="uri">Explorer</ext-link>. It provides a visualization of the pipeline architecture, analysis design, and performance metrics. Confusion matrices (for classification problems) and scatter plots (for regression analyses) with interactive per-fold visualization of true and predicted values are shown. All evaluated hyperparameter configurations can be sorted and are searchable. In addition, the course of the hyperparameter optimization strategy over time is visualized (see <xref rid="pone.0254062.g003" ref-type="fig">Fig 3</xref>).</p>
        <fig position="float" id="pone.0254062.g003">
          <object-id pub-id-type="doi">10.1371/journal.pone.0254062.g003</object-id>
          <label>Fig 3</label>
          <caption>
            <title>PHOTONAI explorer.</title>
            <p>Example plots of PHOTONAI’s result visualization tool called <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://explorer.photon-ai.com" ext-link-type="uri">Explorer</ext-link>. <bold>A</bold>: User-defined performance metrics, here accuracy, precision and recall, for both training (blue) and test (dark) set. The horizontal line indicates a baseline performance stemming from a simple heuristic. <bold>B</bold>: For regression problems, true and predicted values are visualized in a scatter plot on both train (left) and test (right) set. The values are generated by the best model found in each outer folds, respectively. <bold>C</bold>: Hyperparameter optimization progress is depicted over time for each outer fold. <bold>D</bold>: Pipeline elements and their arrangement is visualized including the best hyperparameter value of each item.</p>
          </caption>
          <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="pone.0254062.g003" position="float"/>
        </fig>
      </sec>
    </sec>
  </sec>
  <sec id="sec023">
    <title>Example usage</title>
    <p>In the following, we will provide a hands-on example for using PHOTONAI to predict heart failure from medical data. To run the example, download the data available on kaggle [<xref rid="pone.0254062.ref027" ref-type="bibr">27</xref>] and install PHOTONAI either by cloning it from <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://github.com/wwu-mmll/photonai" ext-link-type="uri">Github</ext-link> or installing it via pip using:</p>
    <p specific-use="line">1 pip install photonai</p>
    <p>The complete example code can be downloaded from Github using this <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://github.com/wwu-mmll/photonai/blob/master/examples/heart_failure/heart_failure_final.py" ext-link-type="uri">link</ext-link>.</p>
    <sec id="sec024">
      <title>Heart failure data</title>
      <p>In the following, we will develop a model to predict mortality in the context of heart failure based on medical records [<xref rid="pone.0254062.ref027" ref-type="bibr">27</xref>, <xref rid="pone.0254062.ref028" ref-type="bibr">28</xref>]. The dataset consists of data from 299 patients (105 female, 194 male) in the age between 40 and 95. It provides 13 features per subject: age and gender, several clinical blood markers, information about body functions as well as the presence of comorbidities (anemia, diabetes), and lifestyle impacts (smoking). Finally, a boolean value indicates whether a subject died during the follow-up period, which spans 4 to 285 days. In approximately 68 percent of cases the patients survived while approximately 32 percent of the patients die due to heart failure.</p>
    </sec>
    <sec id="sec025">
      <title>Hyperpipe setup</title>
      <p>First, we will define the training, optimization, and evaluation workflow in an initial call to the <italic toggle="yes">Hyperpipe</italic> class. The python code in Listing 4 shows the PHOTONAI code defining both the data flow and the training and test procedure. After importing the relevant packages and loading the data, we instantiate a <italic toggle="yes">Hyperpipe</italic> and choose the workflow parameters as follows:</p>
      <list list-type="bullet">
        <list-item>
          <p>For the outer cross-validation loop, we specify 100 shuffled iterations each holding out a test set of 20 percent. For the inner cross-validation loop, we select a ten-fold cross-validation. (lines 13-14).</p>
        </list-item>
        <list-item>
          <p>To measure model performance, we specify that f1 score, Matthews correlation coefficient, balanced accuracy, as well as sensitivity and specificity are to be calculated (lines 16-17).</p>
        </list-item>
        <list-item>
          <p>We optimize the pipeline for f1 score, as it maximizes both sensitive and specific predictions, which is particularly important in medical contexts. (line 18).</p>
        </list-item>
        <list-item>
          <p>To save computational resources and time, we enable caching by specifying a cache folder (line 22). This is particularly useful in examples where there are a lot of partially overlapping hyperparameters to be tested.</p>
        </list-item>
        <list-item>
          <p>Finally, we specify a folder to which the output is written (line 21) and set the verbosity of the console log to 1. At this verbosity level, information on every tested hyperparameter configuration and its respective performance estimate is printed to the console.</p>
        </list-item>
      </list>
      <p>After the hyperpipe has been defined, we can design the flow of the data by adding algorithms and respective hyperparameters to the pipeline.</p>
      <list list-type="bullet">
        <list-item>
          <p>First, data is normalized using scikit-learn’s StandardScaler which both centers the data and scales it to unit variance (line 26).</p>
        </list-item>
        <list-item>
          <p>Second, we impute missing values with the mean values per feature of the training set by calling scikit-learn’s SimpleImputer (line 27).</p>
        </list-item>
      </list>
      <p>Of note, we consider use cases 1 to 3 (see below) to be exploratory analyses. We believe this simulates a naturalistic workflow of machine learning projects where different algorithms, feature preprocessing and hyperparameters are tested in a manual fashion. However, if done incorrectly, this inevitably leads to a manual over-fitting to the data at hand, which is especially troublesome in high-stake medical problems with small datasets. In this context, manual over-fitting happens implicitly when data scientists optimize algorithms and hyperparameters by repeatedly looking at cross-validated test performance. In PHOTONAI, this problem can easily be avoided by setting the <italic toggle="yes">Hyperpipe</italic> parameter <italic toggle="yes">use_test_set</italic> to <italic toggle="yes">False</italic>. This way, PHOTONAI will still apply nested cv but will only report validation performances from the inner cv loop, not the outer cv test data. In the final use case 4, <italic toggle="yes">use_test_set</italic> is set to <italic toggle="yes">True</italic> to estimate final model performance and generalizability on the actual test sets.</p>
    </sec>
    <sec id="sec026">
      <title>Use case 1—Estimator selection</title>
      <p>Although some rules of thumb for selecting the correct algorithm do exist, knowing the optimal learning algorithm for a specific task a priori is impossible (no free lunch theorems [<xref rid="pone.0254062.ref029" ref-type="bibr">29</xref>]). Therefore, the possibility to automatically evaluate multiple algorithms within nested cross-validation is crucial to efficient and unbiased machine learning analyses. In this example, we first train a machine learning pipeline and consider three different learning algorithms that we find appropriate for this learning problem. These algorithms are added to the PHOTONAI <italic toggle="yes">Hyperpipe</italic> in addition to the scaling and imputing preprocessing steps defined above.</p>
      <sec id="sec027">
        <title>Setup</title>
        <list list-type="bullet">
          <list-item>
            <p>To compare different learning algorithms, an Or-Element called Switch is added to the pipeline that toggles between several learning algorithms (see Listing 5). Here, we compare a random forest (RF), gradient boosting (GB), and a support vector machine (SVM) against each other. Again, all algorithms are imported from scikit-learn, and for every element we specify algorithm-specific hyperparameters that are automatically optimized.</p>
          </list-item>
          <list-item>
            <p>To efficiently optimize hyperparameters of different learning algorithms, the switch optimizer in PHOTONAI can be used which optimizes each learning algorithm in an individual hyperparameter space (line 19 in Listing 4). We apply Bayesian optimization to each space respectively and limit the number of tested configurations to 10 (line 20 in Listing 4).</p>
          </list-item>
        </list>
        <p>Finally, we can start the training, optimization, and test procedure by calling <italic toggle="yes">Hyperpipe.fit()</italic>. After the pipeline optimization has finished, we extract not only the overall best hyperparameter configuration and its respective performance, but also the best configuration performance per learning algorithm (RF, GB, SVM, see line 21 in Listing 5).</p>
        <p><bold>Listing 4</bold>. PHOTONAI code to define an initial training, optimization and test proecdure for the heart failure dataset. The pipeline normalizes the data and imputes missing values.</p>
        <p specific-use="line">1 import pandas as pd</p>
        <p specific-use="line">2 from sklearn.model_selection import KFold, ShuffleSplit</p>
        <p specific-use="line">3 from photonai.base import Hyperpipe, PipelineElement, Switch</p>
        <p specific-use="line">4 from photonai.optimization import FloatRange, IntegerRange, MinimumPerformanceConstraint</p>
        <p specific-use="line">5</p>
        <p specific-use="line">6 # load data</p>
        <p specific-use="line">7 df = pd.read_csv(‘./heart_failure_clinical_records_dataset.csv’)</p>
        <p specific-use="line">8 X = df.iloc[:, 0:12]</p>
        <p specific-use="line">9 y = df.iloc[:, 12]</p>
        <p specific-use="line">10</p>
        <p specific-use="line">11 # setup training and test workflow</p>
        <p specific-use="line">12 pipe = Hyperpipe(‘heart_failure’,</p>
        <p specific-use="line">13         outer_cv = ShuffleSplit(n_splits = 100, test_size = 0.2),</p>
        <p specific-use="line">14         inner_cv = KFold(n_splits = 10, shuffle = True),</p>
        <p specific-use="line">15         use_test_set = False,</p>
        <p specific-use="line">16         metrics=[‘balanced_accuracy’, ‘f1_score’, ‘matthews_corrcoef’,</p>
        <p specific-use="line">17            ‘sensitivity’, ‘specificity’],</p>
        <p specific-use="line">18         best_config_metric=‘f1_score’,</p>
        <p specific-use="line">19         optimizer=‘switch’,</p>
        <p specific-use="line">20         optimizer_params={‘name’: ‘sk_opt’, ‘n_configurations’: 10},</p>
        <p specific-use="line">21         project_folder=‘./tmp’,</p>
        <p specific-use="line">22         cache_folder=‘./cache’,</p>
        <p specific-use="line">23         verbosity = 1)</p>
        <p specific-use="line">24</p>
        <p specific-use="line">25 # arrange a sequence of algorithms subsequently applied</p>
        <p specific-use="line">26 pipe += PipelineElement(‘StandardScaler’)</p>
        <p specific-use="line">27 pipe += PipelineElement(‘SimpleImputer’)</p>
        <p specific-use="line">28</p>
        <p specific-use="line">29 # learning algorithm’s will be added here</p>
        <p specific-use="line">30 …</p>
        <p specific-use="line">31 #</p>
        <p specific-use="line">32</p>
        <p specific-use="line">33 # start the training, optimization and test procedure</p>
        <p specific-use="line">34 pipe.fit(X, y)</p>
        <p><bold>Listing 5</bold>. PHOTONAI code to define three learning algorithms that are tested by PHOTONAI automatically through an OR-element, the PHOTONAI Switch.</p>
        <p specific-use="line">1 # compare different learning algorithms in an OR_Element</p>
        <p specific-use="line">2 estimators = Switch(‘estimator_selection’)</p>
        <p specific-use="line">3</p>
        <p specific-use="line">4 estimators += PipelineElement(‘RandomForestClassifier’,</p>
        <p specific-use="line">5              criterion=‘gini’,</p>
        <p specific-use="line">6              bootstrap = True,</p>
        <p specific-use="line">7              hyperparameters={‘min_samples_split’: IntegerRange(2, 30),</p>
        <p specific-use="line">8                      ‘max_features’: [‘auto’, ‘sqrt’, ‘log2’]})</p>
        <p specific-use="line">9</p>
        <p specific-use="line">10 estimators += PipelineElement(‘GradientBoostingClassifier’,</p>
        <p specific-use="line">11              hyperparameters={‘loss’: [‘deviance’, ‘exponential’],</p>
        <p specific-use="line">12                      ‘learning_rate’: FloatRange(0.001, 1,</p>
        <p specific-use="line">13                                  “logspace”)})</p>
        <p specific-use="line">14 estimators += PipelineElement(‘SVC’,</p>
        <p specific-use="line">15              hyperparameters={‘C’: FloatRange(0.5, 25),</p>
        <p specific-use="line">16                      ‘kernel’: [‘linear’, ‘rbf’]})</p>
        <p specific-use="line">17 pipe += estimators</p>
        <p specific-use="line">18</p>
        <p specific-use="line">19 pipe.fit(X, y)</p>
        <p specific-use="line">20</p>
        <p specific-use="line">21 pipe.results_handler.get_mean_of_best_validation_configs_per_estimator()</p>
      </sec>
      <sec id="sec028">
        <title>Results</title>
        <p>The results of the initial estimator selection analysis are given in the first line of <xref rid="pone.0254062.t001" ref-type="table">Table 1</xref>. We observe an f1 score of 75% and a Matthews correlation coefficient of 65%. The best config found by the hyperparameter optimization strategy applied the Random Forest classifier, which thus in this case outperforms gradient boosting and the Support Vector Machine.</p>
        <table-wrap position="float" id="pone.0254062.t001">
          <object-id pub-id-type="doi">10.1371/journal.pone.0254062.t001</object-id>
          <label>Table 1</label>
          <caption>
            <title>Validation performance metrics for three different pipeline setups.</title>
          </caption>
          <alternatives>
            <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="pone.0254062.t001" id="pone.0254062.t001g" position="float"/>
            <table frame="box" rules="all" border="0">
              <colgroup span="1">
                <col align="left" valign="middle" span="1"/>
                <col align="left" valign="middle" span="1"/>
                <col align="left" valign="middle" span="1"/>
                <col align="left" valign="middle" span="1"/>
                <col align="left" valign="middle" span="1"/>
                <col align="left" valign="middle" span="1"/>
              </colgroup>
              <thead>
                <tr>
                  <th align="left" rowspan="1" colspan="1">
                    <italic toggle="yes">Pipeline</italic>
                  </th>
                  <th align="center" rowspan="1" colspan="1">
                    <italic toggle="yes">f1</italic>
                  </th>
                  <th align="center" rowspan="1" colspan="1">
                    <italic toggle="yes">matthews corr</italic>
                  </th>
                  <th align="center" rowspan="1" colspan="1">
                    <italic toggle="yes">BACC</italic>
                  </th>
                  <th align="center" rowspan="1" colspan="1">
                    <italic toggle="yes">sens</italic>
                  </th>
                  <th align="center" rowspan="1" colspan="1">
                    <italic toggle="yes">spec</italic>
                  </th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td align="left" rowspan="1" colspan="1">Estimator selection pipeline</td>
                  <td align="char" char="." rowspan="1" colspan="1">0.7504</td>
                  <td align="char" char="." rowspan="1" colspan="1">0.6583</td>
                  <td align="char" char="." rowspan="1" colspan="1">0.8217</td>
                  <td align="char" char="." rowspan="1" colspan="1">0.9144</td>
                  <td align="char" char="." rowspan="1" colspan="1">0.7289</td>
                </tr>
                <tr>
                  <td align="left" rowspan="1" colspan="1"> + Lasso feature selection</td>
                  <td align="char" char="." rowspan="1" colspan="1">0.7496</td>
                  <td align="char" char="." rowspan="1" colspan="1">0.6570</td>
                  <td align="char" char="." rowspan="1" colspan="1">0.8211</td>
                  <td align="char" char="." rowspan="1" colspan="1">0.7300</td>
                  <td align="char" char="." rowspan="1" colspan="1">0.9123</td>
                </tr>
                <tr>
                  <td align="left" rowspan="1" colspan="1"> + class balancing</td>
                  <td align="char" char="." rowspan="1" colspan="1">0.7644</td>
                  <td align="char" char="." rowspan="1" colspan="1">0.6619</td>
                  <td align="char" char="." rowspan="1" colspan="1">0.8384</td>
                  <td align="char" char="." rowspan="1" colspan="1">0.8210</td>
                  <td align="char" char="." rowspan="1" colspan="1">0.8557</td>
                </tr>
              </tbody>
            </table>
          </alternatives>
          <table-wrap-foot>
            <fn id="t001fn001">
              <p><italic toggle="yes">Notes</italic>: matthews corr = Matthews correlation coefficient, BACC = balanced accuracy, sens = sensitivity, spec = specificity</p>
            </fn>
          </table-wrap-foot>
        </table-wrap>
        <p><bold>Listing 6</bold>. Code for adding a feature selection pipeline element that uses Lasso coefficients to rank and remove features.</p>
        <p specific-use="line">1 pipe += PipelineElement(‘LassoFeatureSelection’,</p>
        <p specific-use="line">2            hyperparameters={‘percentile’: FloatRange(0.1, 0.5),</p>
        <p specific-use="line">3                    ‘alpha’: FloatRange(0.5, 5,</p>
        <p specific-use="line">4                     range_type=“logspace”)})</p>
      </sec>
    </sec>
    <sec id="sec029">
      <title>Use case 2—Feature selection</title>
      <p>Next, we will evaluate the effect of an additional feature selection step. This can be done, e.g., by analyzing a linear model’s normalization coefficients. While low coefficient features are interpreted detrimental to the learning process since they might induce error variance into the data, high coefficient features are interpreted as important information to solve learning problem. A frequently used feature selection approach is based on the Lasso algorithm, as the Lasso implements an L1 regularization norm that penalizes non-sparsity of the model and thus pushes unnecessary model weights to zero. The Lasso coefficients can then be used to select the most important features.</p>
      <sec id="sec030">
        <title>Setup</title>
        <p>The Lasso implementation is imported from scikit-learn, and in order to prepare it as a feature selection tool, accessed via a simple wrapper class provided in PHOTONAI. The wrapper sorts the fitted model’s coefficients and only features falling in the top k percentile are kept. Both the Lasso’s alpha parameter as well as the percentile of features to keep can be optimized. We add the pipeline element <italic toggle="yes">LassoFeatureSelection</italic> as given in Listing 6 between the <italic toggle="yes">SimpleImputer</italic> pipeline element and the estimator switch. Again, we run the analysis and evaluate only the validation set (<italic toggle="yes">Hyperpipe</italic> parameter <italic toggle="yes">use_test_set</italic> is set to <italic toggle="yes">False</italic>).</p>
      </sec>
      <sec id="sec031">
        <title>Results</title>
        <p>The performance metrics for the pipeline with Lasso Feature Selection are given in <xref rid="pone.0254062.t001" ref-type="table">Table 1</xref>. We see a minor performance decrease of approximately 1%. Apparently, linear feature selection is unhelpful indicating that the learning problem is rather under- than over-described by the features given. Interestingly, while 90% of the subjects are correctly identified as survivors (specificity of 91%), a notable amount of actual deaths are missed (sensitivity of 73%). The lower sensitivity in relation to a high specificity might be due to the class imbalance present in the data with more subjects surviving than dying (68%), which we will now investigate in use case 3.</p>
        <p><bold>Listing 7</bold>. Code for adding class balancing algorithms to the pipeline and optimizing the concrete class balancing strategy.</p>
        <p specific-use="line">1 pipe += PipelineElement(‘ImbalancedDataTransformer‘,</p>
        <p specific-use="line">2            hyperparameters={‘method_name‘: [‘RandomUnderSampler‘,</p>
        <p specific-use="line">3                           ‘RandomOverSampler‘,</p>
        <p specific-use="line">4                           ‘SMOTE‘]})</p>
      </sec>
    </sec>
    <sec id="sec032">
      <title>Use case 3—Handling class imbalance</title>
      <p>As a next step, we will try to enhance predictive accuracy and balance the trade-off between specificity and sensitivity by decreasing class imbalance.</p>
      <sec id="sec033">
        <title>Setup</title>
        <p>In order to conveniently access class balancing algorithms, PHOTONAI offers a wrapper calling over- and under-sampling (or a combination of both) techniques implemented in the imbalanced-learn package. We remove the <italic toggle="yes">LassoFeatureSelection</italic> pipeline element and substitute it with an <italic toggle="yes">ImbalancedDataTransformer</italic> pipeline element as shown in Listing 7. As a hyperparameter, we optimize the specific class balancing method itself by evaluating random undersampling, random oversampling, and a combination of both called SMOTE.</p>
      </sec>
      <sec id="sec034">
        <title>Results</title>
        <p>Rerunning the analysis with a class balancing algorithm yields a slightly better performance (f1 score = 0.76, Matthews correlation coefficient = 0.66, see line 3 in <xref rid="pone.0254062.t001" ref-type="table">Table 1</xref>). The optimal class balancing method was found to be SMOTE, a combination of under- and over-sampling. More importantly, a greater balance between sensitivity (82%) and specificity (86%) was reached which also resulted in a higher balanced accuracy compared to the two previous pipelines (BACC = 84%).</p>
      </sec>
    </sec>
    <sec id="sec035">
      <title>Use case 4—Estimating final model performance</title>
      <p>From the results of use cases 2 and 3, we can see that only class balancing but not feature selection slightly increased the classification performance in this specific dataset. Additionally, when we examine the results of the three learning algorithms of the class balancing pipeline, we can further see that the Random Forest (f1 = 0.76) is still outperforming gradient boosting and the Support Vector Machine (see <xref rid="pone.0254062.t002" ref-type="table">Table 2</xref>). Therefore, we restrict our final machine learning pipeline to a class balancing element and a Random Forest classifier.</p>
      <table-wrap position="float" id="pone.0254062.t002">
        <object-id pub-id-type="doi">10.1371/journal.pone.0254062.t002</object-id>
        <label>Table 2</label>
        <caption>
          <title>Different estimator’s average best validation performance for the class balancing pipeline.</title>
        </caption>
        <alternatives>
          <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="pone.0254062.t002" id="pone.0254062.t002g" position="float"/>
          <table frame="box" rules="all" border="0">
            <colgroup span="1">
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th align="left" rowspan="1" colspan="1">
                  <italic toggle="yes">Estimator</italic>
                </th>
                <th align="center" rowspan="1" colspan="1">
                  <italic toggle="yes">f1</italic>
                </th>
                <th align="center" rowspan="1" colspan="1">
                  <italic toggle="yes">matthews corr</italic>
                </th>
                <th align="center" rowspan="1" colspan="1">
                  <italic toggle="yes">BACC</italic>
                </th>
                <th align="center" rowspan="1" colspan="1">
                  <italic toggle="yes">sens</italic>
                </th>
                <th align="center" rowspan="1" colspan="1">
                  <italic toggle="yes">spec</italic>
                </th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="left" rowspan="1" colspan="1">Random Forest</td>
                <td align="char" char="." rowspan="1" colspan="1">0.7623</td>
                <td align="char" char="." rowspan="1" colspan="1">0.6602</td>
                <td align="char" char="." rowspan="1" colspan="1">0.8368</td>
                <td align="char" char="." rowspan="1" colspan="1">0.8161</td>
                <td align="char" char="." rowspan="1" colspan="1">0.8575</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Gradient Boosting</td>
                <td align="char" char="." rowspan="1" colspan="1">0.7393</td>
                <td align="char" char="." rowspan="1" colspan="1">0.6233</td>
                <td align="char" char="." rowspan="1" colspan="1">0.8192</td>
                <td align="char" char="." rowspan="1" colspan="1">0.7949</td>
                <td align="char" char="." rowspan="1" colspan="1">0.8435</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">SVM</td>
                <td align="char" char="." rowspan="1" colspan="1">0.7017</td>
                <td align="char" char="." rowspan="1" colspan="1">0.5717</td>
                <td align="char" char="." rowspan="1" colspan="1">0.7895</td>
                <td align="char" char="." rowspan="1" colspan="1">0.7445</td>
                <td align="char" char="." rowspan="1" colspan="1">0.8344</td>
              </tr>
            </tbody>
          </table>
        </alternatives>
        <table-wrap-foot>
          <fn id="t002fn001">
            <p><italic toggle="yes">Notes</italic>: matthews corr = Matthews correlation coefficient, BACC = balanced accuracy, sens = sensitivity, spec = specificity</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p><bold>Listing 8</bold>. Changes made to the PHOTONAI script to generate the final model</p>
      <p specific-use="line">1 pipe = Hyperpipe(…</p>
      <p specific-use="line">2         use_test_set = True,</p>
      <p specific-use="line">3         optimizer=‘grid_search’,</p>
      <p specific-use="line">4         optimizer_params = {},</p>
      <p specific-use="line">5         performance_constraints = MinimumPerformanceConstraint(‘f1_score’,</p>
      <p specific-use="line">6                                   threshold = 0.7,</p>
      <p specific-use="line">7                                   strategy=“mean”)</p>
      <p specific-use="line">8         …)</p>
      <p specific-use="line">9 …</p>
      <p specific-use="line">10 pipe += PipelineElement(‘RandomForestClassifier’,</p>
      <p specific-use="line">11            criterion=‘gini’,</p>
      <p specific-use="line">12            bootstrap = True,</p>
      <p specific-use="line">13            hyperparameters={‘min_samples_split’: IntegerRange(2, 30),</p>
      <p specific-use="line">14                   ‘max_features’: [‘auto’, ‘sqrt’, ‘log2’]})</p>
      <p specific-use="line">15 …</p>
      <p specific-use="line">16 pipe.fit(X,y)</p>
      <sec id="sec036">
        <title>Setup</title>
        <p>In this last step, we finish model development and estimate the final model performance. We remove the estimator switch from the pipeline and substitute it by a single Random Forest pipeline element. In addition, we decide to thoroughly investigate the hyperparameter space and therefore change the hyperparameter optimizer to grid search (see line 3-4 in Listing 8). In addition, we use the previously calculated validation metrics as a rough guide to specify a lower performance bound that promising hyperparameter configurations must outperform. Specifically, we apply a <italic toggle="yes">MinimumPerformanceConstraint</italic> on f1 score, meaning that inner fold calculations are aborted when the mean performance is below 0.7 (see line 5-7 in Listing 8). Thereby, less promising configurations are dismissed early and computational resources are saved. Importantly, we will now set <italic toggle="yes">use_test_set</italic> to <italic toggle="yes">True</italic> to make sure that PHOTONAI will evaluate the best hyperparameter configurations on the outer cv test set.</p>
      </sec>
      <sec id="sec037">
        <title>Results</title>
        <p>The final model performance on the test set is given in <xref rid="pone.0254062.t003" ref-type="table">Table 3</xref>. All metrics remained stable when being evaluated on the previously unused test set. As a comparison, Chicco et al. (2020) [<xref rid="pone.0254062.ref030" ref-type="bibr">30</xref>] trained several learning algorithms to the heart failure dataset used in this example (see row 2 of table 11 in Chicco et al. [<xref rid="pone.0254062.ref030" ref-type="bibr">30</xref>]). PHOTONAI is able to outperform the best model of Chicco et al. which was trained on all available features in a similar fashion (see <xref rid="pone.0254062.t003" ref-type="table">Table 3</xref>). For the f1 score, the PHOTONAI pipeline reaches 0.746. Also, sensitivity and specificity appears to be more balanced in comparison to Chicco et al.</p>
        <table-wrap position="float" id="pone.0254062.t003">
          <object-id pub-id-type="doi">10.1371/journal.pone.0254062.t003</object-id>
          <label>Table 3</label>
          <caption>
            <title>Test performance metrics for the final model.</title>
          </caption>
          <alternatives>
            <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="pone.0254062.t003" id="pone.0254062.t003g" position="float"/>
            <table frame="box" rules="all" border="0">
              <colgroup span="1">
                <col align="left" valign="middle" span="1"/>
                <col align="left" valign="middle" span="1"/>
                <col align="left" valign="middle" span="1"/>
                <col align="left" valign="middle" span="1"/>
                <col align="left" valign="middle" span="1"/>
                <col align="left" valign="middle" span="1"/>
              </colgroup>
              <thead>
                <tr>
                  <th align="left" rowspan="1" colspan="1"/>
                  <th align="center" rowspan="1" colspan="1">
                    <italic toggle="yes">f1</italic>
                  </th>
                  <th align="center" rowspan="1" colspan="1">
                    <italic toggle="yes">matthews corr</italic>
                  </th>
                  <th align="center" rowspan="1" colspan="1">
                    <italic toggle="yes">BACC</italic>
                  </th>
                  <th align="center" rowspan="1" colspan="1">
                    <italic toggle="yes">sens</italic>
                  </th>
                  <th align="center" rowspan="1" colspan="1">
                    <italic toggle="yes">spec</italic>
                  </th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td align="left" rowspan="1" colspan="1">Chicco et al.</td>
                  <td align="char" char="." rowspan="1" colspan="1">0.714</td>
                  <td align="char" char="." rowspan="1" colspan="1">0.607</td>
                  <td align="char" char="." rowspan="1" colspan="1">0.818</td>
                  <td align="char" char="." rowspan="1" colspan="1">0.780</td>
                  <td align="char" char="." rowspan="1" colspan="1">0.856</td>
                </tr>
                <tr>
                  <td align="left" rowspan="1" colspan="1">Final PHOTONAI model</td>
                  <td align="char" char="." rowspan="1" colspan="1">0.746</td>
                  <td align="char" char="." rowspan="1" colspan="1">0.619</td>
                  <td align="char" char="." rowspan="1" colspan="1">0.818</td>
                  <td align="char" char="." rowspan="1" colspan="1">0.813</td>
                  <td align="char" char="." rowspan="1" colspan="1">0.823</td>
                </tr>
              </tbody>
            </table>
          </alternatives>
          <table-wrap-foot>
            <fn id="t003fn001">
              <p><italic toggle="yes">Notes</italic>: matthews corr = Matthews correlation coefficient, BACC = balanced accuracy, sens = sensitivity, spec = specificity</p>
            </fn>
          </table-wrap-foot>
        </table-wrap>
        <p><xref rid="pone.0254062.g004" ref-type="fig">Fig 4</xref> shows a parallel plot of the hyperparameter space PHOTONAI has explored in this final analysis. Since we have used a grid search optimizer, all possible hyperparameter combinations have been evaluated. Interestingly, when looking at <xref rid="pone.0254062.g004" ref-type="fig">Fig 4</xref>, a clear disadvantage becomes evident when no class balancing algorithm is used, random under-sampling appears to provide generally better model performance.</p>
        <fig position="float" id="pone.0254062.g004">
          <object-id pub-id-type="doi">10.1371/journal.pone.0254062.g004</object-id>
          <label>Fig 4</label>
          <caption>
            <title>Parallel plot showing hyperparameter exploration.</title>
            <p>All three hyperparameters used in the final model are shown on the x-axis. They include the class balancing algorithm and two hyperparameters of the Random Forest classifier (maximum number of features and minimum samples per split). Each line represents a specific combination of all hyperparameters. The line color reflects the corresponding model performance based on the f1 score. Higher model performance is shown in dark red while lower model performance is shown in blue. Random under-sampling appears to increase model performance slightly while using no class balancing algorithm decreases overall model performance. CB = class balancing, RUS = random under-sampling, ROS = random over-sampling, SMOTE = synthetic minority oversampling technique, RF = Random Forest.</p>
          </caption>
          <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="pone.0254062.g004" position="float"/>
        </fig>
      </sec>
    </sec>
  </sec>
  <sec sec-type="conclusions" id="sec038">
    <title>Discussion</title>
    <p>We introduced PHOTONAI, a high-level Python API for rapid machine learning model development. As demonstrated in the example above, both the pipeline and the training and test procedure, as well the integration of hyperparameter optimization can be implemented in a few lines of code. In addition, experimenting with different algorithm sequences, hyperparameter optimization strategies, and other workflow-related parameters was realized by adding single lines of code or changing a few keywords. Through the automation of the training, validation and test procedure, data transformation and feature selection steps are restricted to the validation set only, thus strictly avoiding data leakage even when used by non-experts. Interestingly, this fundamentally important separation between training and test data was apparently not implemented for the feature selection analyses in Chicco et al., as they seem to have selected the most important features on the whole dataset which has most likely inflated their final model performance. Examples like this again highlight the importance of easy-to-use nested cross-validation frameworks that guarantee an unbiased estimate of the predictive performance and generalization error, which is key to, e.g., the development of reliable machine learning applications in the medical domain. Finally, the toolbox automatically identified the best hyperparameter configurations, yielded in-depth information about both validation and test set performance, and offered convenient estimator comparison tools.</p>
    <p>PHOTONAI is developed with common scientific use cases in mind, for which it can significantly decrease programmatic overhead and support rapid model prototyping. However, use cases that substantially differ in the amount of available data or in the computational resources required to train the model, might require a different model development workflow. For example, while all kinds of neural networks can be integrated in PHOTONAI, developing and optimizing extremely complex and specialized deep neural networks with specialized architecture optimization protocols might be cumbersome within the PHOTONAI framework. In addition, unbiased performance evaluation in massive amounts of data might significantly relax the need for strict cross-validation schemes.</p>
    <p>In addition, cross-toolbox access to algorithms comes at the cost of manually pre-registrating the algorithms with the PHOTONAI Registry system. In addition, if the algorithm does not inherently adheres to the scikit-learn object API, the user needs to manually write a wrapper class calling the algorithm according to the fit-predict-transform interface. However, this process is only required once and can afterwards be shared with the community, thereby enabling convenient access for other researchers without further effort. Furthermore, once registered, all integrated algorithms are instantaneously compatible with all other functionalities of the PHOTONAI framework, for example, can they be optimized with any hyperparameter optimization algorithm of choice.</p>
    <p>In the future, we intend to extend both functionality and usability. First, we will incorporate additional hyperparameter optimization strategies. While this area has seen tremendous progress in recent years, these algorithms are often not readily available to data scientists, and studies systematically comparing them are extremely scarce. Second, we seek to extend automatic ensemble generation to fully exploit the various models trained during the hyperparameter optimization process. Generally, we strive to pre-register more of the arising ML utility packages, so that accessibility is facilitated and functionality can be used within PHOTONAI as a unified framework. Finally, we would like to improve our convenience functions for model performance assessment and visualization.</p>
    <p>In addition to these core functionalities, we aim to establish an ecosystem of add-on modules simplifying ML analyses for different data types and modalities. For example, we will add a neuroimaging module as a means to directly use multimodal Magnetic Resonance Imaging (MRI) data in ML analyses. In addition, a graph module will integrate existing graph analysis functions and provide specialized ML approaches for graph data. Likewise, modules integrating additional data modalities such as omics data would be of great value. More generally, PHOTONAI would benefit from modules making novel approaches to model interpretation (i.e. Explainability) available.</p>
  </sec>
  <sec sec-type="conclusions" id="sec039">
    <title>Conclusion</title>
    <p>In summary, PHOTONAI is especially well-suited in contexts requiring rapid and iterative evaluation of novel approaches such as applied ML research in medicine and the Life Sciences. In the future, we hope to attract more developers and users to establish a thriving, open-source community.</p>
  </sec>
</body>
<back>
  <ref-list>
    <title>References</title>
    <ref id="pone.0254062.ref001">
      <label>1</label>
      <mixed-citation publication-type="journal"><name><surname>Abadi</surname><given-names>M</given-names></name>, <name><surname>Agarwal</surname><given-names>A</given-names></name>, <name><surname>Barham</surname><given-names>P</given-names></name>, <name><surname>Brevdo</surname><given-names>E</given-names></name>, <name><surname>Chen</surname><given-names>Z</given-names></name>, <name><surname>Citro</surname><given-names>C</given-names></name>, <etal>et al</etal>. <source>{TensorFlow}: Large-Scale Machine Learning on Heterogeneous Systems</source>; <year>2015</year>. Available from: <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://www.tensorflow.org/" ext-link-type="uri">https://www.tensorflow.org/</ext-link>.</mixed-citation>
    </ref>
    <ref id="pone.0254062.ref002">
      <label>2</label>
      <mixed-citation publication-type="other">Team TTD, Al-Rfou R, Alain G, Almahairi A, Angermueller C, Bahdanau D, et al. Theano: A Python Framework for Fast Computation of Mathematical Expressions. arXiv preprint arXiv:160502688. 2016;.</mixed-citation>
    </ref>
    <ref id="pone.0254062.ref003">
      <label>3</label>
      <mixed-citation publication-type="other">Jia Y, Shelhamer E, Donahue J, Karayev S, Long J, Girshick R, et al. Caffe: Convolutional Architecture For Fast Feature Embedding. In: Proceedings of the 22nd ACM international conference on Multimedia; 2014. p. 675–678.</mixed-citation>
    </ref>
    <ref id="pone.0254062.ref004">
      <label>4</label>
      <mixed-citation publication-type="book"><name><surname>Paszke</surname><given-names>A</given-names></name>, <name><surname>Gross</surname><given-names>S</given-names></name>, <name><surname>Massa</surname><given-names>F</given-names></name>, <name><surname>Lerer</surname><given-names>A</given-names></name>, <name><surname>Bradbury</surname><given-names>J</given-names></name>, <name><surname>Chanan</surname><given-names>G</given-names></name>, <etal>et al</etal>. <chapter-title>PyTorch: An Imperative Style, High-Performance Deep Learning Library</chapter-title>. In: <source>Advances in Neural Information Processing Systems</source>; <year>2019</year>. p. <fpage>8024</fpage>–<lpage>8035</lpage>.</mixed-citation>
    </ref>
    <ref id="pone.0254062.ref005">
      <label>5</label>
      <mixed-citation publication-type="other">Chollet F, Others. Keras; 2015. Available from: <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://keras.io" ext-link-type="uri">https://keras.io</ext-link>.</mixed-citation>
    </ref>
    <ref id="pone.0254062.ref006">
      <label>6</label>
      <mixed-citation publication-type="other">Howard J, Others. fastai; 2018. \url{<ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://github.com/fastai/fastai" ext-link-type="uri">https://github.com/fastai/fastai</ext-link>}.</mixed-citation>
    </ref>
    <ref id="pone.0254062.ref007">
      <label>7</label>
      <mixed-citation publication-type="journal"><name><surname>Pedregosa</surname><given-names>F</given-names></name>, <name><surname>Weiss</surname><given-names>R</given-names></name>, <name><surname>Brucher</surname><given-names>M</given-names></name>, <name><surname>Varoquaux</surname><given-names>G</given-names></name>, <name><surname>Gramfort</surname><given-names>A</given-names></name>, <name><surname>Michel</surname><given-names>V</given-names></name>, <etal>et al</etal>. <article-title>Scikit-learn: Machine Learning in Python</article-title>. <source>Journal of Machine Learning Research</source>. <year>2011</year>;<volume>12</volume>(<issue>Oct</issue>):<fpage>2825</fpage>–<lpage>2830</lpage>.</mixed-citation>
    </ref>
    <ref id="pone.0254062.ref008">
      <label>8</label>
      <mixed-citation publication-type="journal"><name><surname>Lemaitre</surname><given-names>G</given-names></name>, <name><surname>Nogueira</surname><given-names>F</given-names></name>, <name><surname>Aridas</surname><given-names>CK</given-names></name>. <article-title>Imbalanced-learn: A Python Toolbox to Tackle the Curse of Imbalanced Datasets in Machine Learning</article-title>. <source>Journal of Machine Learning Research</source>. <year>2017</year>;<volume>18</volume>(<issue>17</issue>):<fpage>1</fpage>–<lpage>5</lpage>.</mixed-citation>
    </ref>
    <ref id="pone.0254062.ref009">
      <label>9</label>
      <mixed-citation publication-type="journal"><name><surname>Abraham</surname><given-names>A</given-names></name>, <name><surname>Pedregosa</surname><given-names>F</given-names></name>, <name><surname>Eickenberg</surname><given-names>M</given-names></name>, <name><surname>Gervais</surname><given-names>P</given-names></name>, <name><surname>Mueller</surname><given-names>A</given-names></name>, <name><surname>Kossaifi</surname><given-names>J</given-names></name>, <etal>et al</etal>. <article-title>Machine learning for neuroimaging with scikit-learn</article-title>. <source>Frontiers in Neuroinformatics</source>. <year>2014</year>;<volume>8</volume>. <comment>doi: </comment><pub-id pub-id-type="doi">10.3389/fninf.2014.00014</pub-id><?supplied-pmid 24600388?><pub-id pub-id-type="pmid">24600388</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0254062.ref010">
      <label>10</label>
      <mixed-citation publication-type="other">Brett M, Markiewicz CJ, Hanke M, Côté MA, Cipollini B, McCarthy P, et al. nibabel; 2020. Available from: <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://zenodo.org/record/4295521" ext-link-type="uri">https://zenodo.org/record/4295521</ext-link>.</mixed-citation>
    </ref>
    <ref id="pone.0254062.ref011">
      <label>11</label>
      <mixed-citation publication-type="other">Head T, MechCoder, Louppe G, Shcherbatyi I, Fcharras, Vinícius Z, et al. Scikit-optimize; 2018. Available from: <pub-id pub-id-type="doi">10.5281/zenodo.1207017</pub-id>.</mixed-citation>
    </ref>
    <ref id="pone.0254062.ref012">
      <label>12</label>
      <mixed-citation publication-type="other">Hutter F, Hoos HH, Leyton-Brown K. Sequential Model-Based Optimization for General Algorithm Configuration. In: International Conference on Learning and Intelligent Optimization. Springer; 2011. p. 507–523.</mixed-citation>
    </ref>
    <ref id="pone.0254062.ref013">
      <label>13</label>
      <mixed-citation publication-type="other">Rapin J, Teytaud O. Nevergrad—A gradient-free optimization platform; 2018. \url{<ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://GitHub.com/FacebookResearch/Nevergrad" ext-link-type="uri">https://GitHub.com/FacebookResearch/Nevergrad</ext-link>}.</mixed-citation>
    </ref>
    <ref id="pone.0254062.ref014">
      <label>14</label>
      <mixed-citation publication-type="book"><name><surname>Pedregosa</surname><given-names>F</given-names></name>. <source>Hyperparameter Optimization with Approximate Gradient</source>. <publisher-name>Département Informatique de l’École Normale Supérieure</publisher-name>, <publisher-loc>Paris</publisher-loc>; <year>2016</year>.</mixed-citation>
    </ref>
    <ref id="pone.0254062.ref015">
      <label>15</label>
      <mixed-citation publication-type="other">Kartik Chandra Erik Meijer SAEAFIDJGMGBHSSATSY. Gradient Descent: The Ultimate Optimizer. Stanford University, Palo Alto, California—USA Facebook, Menlo Park, California, USA; 2019.</mixed-citation>
    </ref>
    <ref id="pone.0254062.ref016">
      <label>16</label>
      <mixed-citation publication-type="journal"><name><surname>Feurer</surname><given-names>M</given-names></name>, <name><surname>Klein</surname><given-names>A</given-names></name>, <name><surname>Eggensperger</surname><given-names>K</given-names></name>, <name><surname>Springenberg</surname><given-names>JT</given-names></name>, <name><surname>Blum</surname><given-names>M</given-names></name>, <name><surname>Hutter</surname><given-names>F</given-names></name>. <source>Auto-sklearn: Efficient and Robust Automated Machine Learning</source>; <year>2019</year>. p. <fpage>113</fpage>–<lpage>134</lpage>. Available from: <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="http://link.springer.com/10.1007/978-3-030-05318-5_6" ext-link-type="uri">http://link.springer.com/10.1007/978-3-030-05318-5_6</ext-link>.</mixed-citation>
    </ref>
    <ref id="pone.0254062.ref017">
      <label>17</label>
      <mixed-citation publication-type="journal"><name><surname>Olson</surname><given-names>RS</given-names></name>, <name><surname>Moore</surname><given-names>JH</given-names></name>. <source>TPOT: A Tree-Based Pipeline Optimization Tool for Automating Machine Learning</source>; <year>2019</year>. p. <fpage>151</fpage>–<lpage>160</lpage>. Available from: <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="http://link.springer.com/10.1007/978-3-030-05318-5_8" ext-link-type="uri">http://link.springer.com/10.1007/978-3-030-05318-5_8</ext-link>.</mixed-citation>
    </ref>
    <ref id="pone.0254062.ref018">
      <label>18</label>
      <mixed-citation publication-type="journal"><name><surname>Kotthoff</surname><given-names>L</given-names></name>, <name><surname>Thornton</surname><given-names>C</given-names></name>, <name><surname>Hoos</surname><given-names>HH</given-names></name>, <name><surname>Hutter</surname><given-names>F</given-names></name>, <name><surname>Leyton-Brown</surname><given-names>K</given-names></name>. <article-title>Auto-WEKA 2.0: Automatic Model Selection and Hyperparameter Optimization in WEKA</article-title>. <source>Journal of Machine Learning Research</source>. <year>2017</year>;<volume>18</volume>(<issue>1</issue>):<fpage>826</fpage>–<lpage>830</lpage>.</mixed-citation>
    </ref>
    <ref id="pone.0254062.ref019">
      <label>19</label>
      <mixed-citation publication-type="other">Jin H, Song Q, Hu X. Auto-Keras: An Efficient Neural Architecture Search System. In: Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining—KDD’19. New York, New York, USA: ACM Press; 2019. p. 1946–1956. Available from: <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="http://dl.acm.org/citation.cfm?doid=3292500.3330648" ext-link-type="uri">http://dl.acm.org/citation.cfm?doid=3292500.3330648</ext-link>.</mixed-citation>
    </ref>
    <ref id="pone.0254062.ref020">
      <label>20</label>
      <mixed-citation publication-type="journal"><name><surname>Zoph</surname><given-names>B</given-names></name>, <name><surname>Le</surname><given-names>QV</given-names></name>. <source>Neural Architecture Search with Reinforcement Learning</source>. <year>2016</year>;.</mixed-citation>
    </ref>
    <ref id="pone.0254062.ref021">
      <label>21</label>
      <mixed-citation publication-type="journal"><name><surname>Pham</surname><given-names>H</given-names></name>, <name><surname>Guan</surname><given-names>MY</given-names></name>, <name><surname>Zoph</surname><given-names>B</given-names></name>, <name><surname>Le</surname><given-names>QV</given-names></name>, <name><surname>Dean</surname><given-names>J</given-names></name>. <source>Efficient Neural Architecture Search via Parameter Sharing</source>. <year>2018</year>;.</mixed-citation>
    </ref>
    <ref id="pone.0254062.ref022">
      <label>22</label>
      <mixed-citation publication-type="journal"><name><surname>Erickson</surname><given-names>N</given-names></name>, <name><surname>Mueller</surname><given-names>J</given-names></name>, <name><surname>Shirkov</surname><given-names>A</given-names></name>, <name><surname>Zhang</surname><given-names>H</given-names></name>, <name><surname>Larroy</surname><given-names>P</given-names></name>, <name><surname>Li</surname><given-names>M</given-names></name>, <etal>et al</etal>. <source>AutoGluon-Tabular: Robust and Accurate AutoML for Structured Data</source>. <year>2020</year>;.</mixed-citation>
    </ref>
    <ref id="pone.0254062.ref023">
      <label>23</label>
      <mixed-citation publication-type="journal"><name><surname>Buitinck</surname><given-names>L</given-names></name>, <name><surname>Louppe</surname><given-names>G</given-names></name>, <name><surname>Blondel</surname><given-names>M</given-names></name>, <name><surname>Pedregosa</surname><given-names>F</given-names></name>, <name><surname>Mueller</surname><given-names>A</given-names></name>, <name><surname>Grisel</surname><given-names>O</given-names></name>, <etal>et al</etal>. <source>API Design For Machine Learning Software: Experiences From the scikit-learn Project</source>. <year>2013</year>;.</mixed-citation>
    </ref>
    <ref id="pone.0254062.ref024">
      <label>24</label>
      <mixed-citation publication-type="other">Pedregosa F, Weiss R, Brucher M, Varoquaux G, Gramfort A, Michel V, et al. DummyClassifier; 2020. Available from: <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html" ext-link-type="uri">https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html</ext-link>.</mixed-citation>
    </ref>
    <ref id="pone.0254062.ref025">
      <label>25</label>
      <mixed-citation publication-type="other">Pedregosa F, Weiss R, Brucher M, Varoquaux G, Gramfort A, Michel V, et al. Pipeline; 2020. Available from: <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html" ext-link-type="uri">https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html</ext-link>.</mixed-citation>
    </ref>
    <ref id="pone.0254062.ref026">
      <label>26</label>
      <mixed-citation publication-type="other">Rocklin M. Dask: Parallel computation with blocked algorithms and task scheduling. In: Proceedings of the 14th python in science conference. 130-136. Citeseer; 2015.</mixed-citation>
    </ref>
    <ref id="pone.0254062.ref027">
      <label>27</label>
      <mixed-citation publication-type="other">Ahmad T. Heart Failure Prediction; 2020. Available from: <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://www.kaggle.com/andrewmvd/heart-failure-clinical-data" ext-link-type="uri">https://www.kaggle.com/andrewmvd/heart-failure-clinical-data</ext-link></mixed-citation>
    </ref>
    <ref id="pone.0254062.ref028">
      <label>28</label>
      <mixed-citation publication-type="journal"><name><surname>Ahmad</surname><given-names>T</given-names></name>, <name><surname>Munir</surname><given-names>A</given-names></name>, <name><surname>Bhatti</surname><given-names>SH</given-names></name>, <name><surname>Aftab</surname><given-names>M</given-names></name>, <name><surname>Raza</surname><given-names>MA</given-names></name>. <article-title>Survival analysis of heart failure patients: A case study</article-title>. <source>PLOS ONE</source>. <year>2017</year>;<volume>12</volume>(<issue>7</issue>):<fpage>e0181001</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1371/journal.pone.0181001</pub-id><pub-id pub-id-type="pmid">28727739</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0254062.ref029">
      <label>29</label>
      <mixed-citation publication-type="journal"><name><surname>Lockett</surname><given-names>AJ</given-names></name>. <article-title>No free lunch theorems</article-title>. <source>Natural Computing Series</source>. <year>2020</year>;<volume>1</volume>(<issue>1</issue>):<fpage>287</fpage>–<lpage>322</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1007/978-3-662-62007-6_12</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0254062.ref030">
      <label>30</label>
      <mixed-citation publication-type="journal"><name><surname>Chicco</surname><given-names>D</given-names></name>, <name><surname>Jurman</surname><given-names>G</given-names></name>. <article-title>Machine learning can predict survival of patients with heart failure from serum creatinine and ejection fraction alone</article-title>. <source>BMC Medical Informatics and Decision Making</source>. <year>2020</year>;<volume>20</volume>(<issue>1</issue>):<fpage>16</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1186/s12911-020-1023-5</pub-id><pub-id pub-id-type="pmid">32013925</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
<sub-article article-type="aggregated-review-documents" id="pone.0254062.r001" specific-use="decision-letter">
  <front-stub>
    <article-id pub-id-type="doi">10.1371/journal.pone.0254062.r001</article-id>
    <title-group>
      <article-title>Decision Letter 0</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Gadekallu</surname>
          <given-names>Thippa Reddy</given-names>
        </name>
        <role>Academic Editor</role>
      </contrib>
    </contrib-group>
    <permissions>
      <copyright-statement>© 2021 Thippa Reddy Gadekallu</copyright-statement>
      <copyright-year>2021</copyright-year>
      <copyright-holder>Thippa Reddy Gadekallu</copyright-holder>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an open access article distributed under the terms of the <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
      </license>
    </permissions>
    <related-article xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="doi" xlink:href="10.1371/journal.pone.0254062" id="rel-obj001" related-article-type="reviewed-article"/>
    <custom-meta-group>
      <custom-meta>
        <meta-name>Submission Version</meta-name>
        <meta-value>0</meta-value>
      </custom-meta>
    </custom-meta-group>
  </front-stub>
  <body>
    <p>
      <named-content content-type="letter-date">19 Apr 2021</named-content>
    </p>
    <p>PONE-D-21-10500</p>
    <p>PHOTONAI - A Python API for rapid machine learning model development</p>
    <p>PLOS ONE</p>
    <p>Dear Dr. Leenings,</p>
    <p>Thank you for submitting your manuscript to PLOS ONE. After careful consideration, we feel that it has merit but does not fully meet PLOS ONE’s publication criteria as it currently stands. Therefore, we invite you to submit a revised version of the manuscript that addresses the points raised during the review process.</p>
    <p>Based on the comments received form the reviewers and my own observation, I recommend major revisions for the paper.</p>
    <p>Please submit your revised manuscript by Jun 03 2021 11:59PM. If you will need more time than this to complete your revisions, please reply to this message or contact the journal office at <email>plosone@plos.org</email>. When you're ready to submit your revision, log on to <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://www.editorialmanager.com/pone/" ext-link-type="uri">https://www.editorialmanager.com/pone/</ext-link> and select the 'Submissions Needing Revision' folder to locate your manuscript file.</p>
    <p>Please include the following items when submitting your revised manuscript:</p>
    <p>
      <list list-type="bullet">
        <list-item>
          <p>A rebuttal letter that responds to each point raised by the academic editor and reviewer(s). You should upload this letter as a separate file labeled 'Response to Reviewers'.</p>
        </list-item>
        <list-item>
          <p>A marked-up copy of your manuscript that highlights changes made to the original version. You should upload this as a separate file labeled 'Revised Manuscript with Track Changes'.</p>
        </list-item>
        <list-item>
          <p>An unmarked version of your revised paper without tracked changes. You should upload this as a separate file labeled 'Manuscript'.</p>
        </list-item>
      </list>
    </p>
    <p>If you would like to make changes to your financial disclosure, please include your updated statement in your cover letter. Guidelines for resubmitting your figure files are available below the reviewer comments at the end of this letter.</p>
    <p>If applicable, we recommend that you deposit your laboratory protocols in protocols.io to enhance the reproducibility of your results. Protocols.io assigns your protocol its own identifier (DOI) so that it can be cited independently in the future. For instructions see: <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="http://journals.plos.org/plosone/s/submission-guidelines#loc-laboratory-protocols" ext-link-type="uri">http://journals.plos.org/plosone/s/submission-guidelines#loc-laboratory-protocols</ext-link>. Additionally, PLOS ONE offers an option for publishing peer-reviewed Lab Protocol articles, which describe protocols hosted on protocols.io. Read more information on sharing protocols at <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://plos.org/protocols?utm_medium=editorial-email&amp;utm_source=authorletters&amp;utm_campaign=protocols" ext-link-type="uri">https://plos.org/protocols?utm_medium=editorial-email&amp;utm_source=authorletters&amp;utm_campaign=protocols</ext-link>.</p>
    <p>We look forward to receiving your revised manuscript.</p>
    <p>Kind regards,</p>
    <p>Thippa Reddy Gadekallu</p>
    <p>Academic Editor</p>
    <p>PLOS ONE</p>
    <p>Journal Requirements:</p>
    <p>When submitting your revision, we need you to address these additional requirements.</p>
    <p>
      <list list-type="order">
        <list-item>
          <p>Please ensure that your manuscript meets PLOS ONE's style requirements, including those for file naming. The PLOS ONE style templates can be found at</p>
        </list-item>
      </list>
    </p>
    <p><ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://journals.plos.org/plosone/s/file?id=wjVg/PLOSOne_formatting_sample_main_body.pdf" ext-link-type="uri">https://journals.plos.org/plosone/s/file?id=wjVg/PLOSOne_formatting_sample_main_body.pdf</ext-link> and</p>
    <p>
      <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://journals.plos.org/plosone/s/file?id=ba62/PLOSOne_formatting_sample_title_authors_affiliations.pdf" ext-link-type="uri">https://journals.plos.org/plosone/s/file?id=ba62/PLOSOne_formatting_sample_title_authors_affiliations.pdf</ext-link>
    </p>
    <p>[Note: HTML markup is below. Please do not edit.]</p>
    <p>Reviewers' comments:</p>
    <p>Reviewer's Responses to Questions</p>
    <p>
      <bold>Comments to the Author</bold>
    </p>
    <p>1. Is the manuscript technically sound, and do the data support the conclusions?</p>
    <p>The manuscript must describe a technically sound piece of scientific research with data that supports the conclusions. Experiments must have been conducted rigorously, with appropriate controls, replication, and sample sizes. The conclusions must be drawn appropriately based on the data presented. </p>
    <p>Reviewer #1: Yes</p>
    <p>Reviewer #2: Yes</p>
    <p>Reviewer #3: Yes</p>
    <p>**********</p>
    <p>2. Has the statistical analysis been performed appropriately and rigorously? </p>
    <p>Reviewer #1: N/A</p>
    <p>Reviewer #2: Yes</p>
    <p>Reviewer #3: Yes</p>
    <p>**********</p>
    <p>3. Have the authors made all data underlying the findings in their manuscript fully available?</p>
    <p>The <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="http://www.plosone.org/static/policies.action#sharing" ext-link-type="uri">PLOS Data policy</ext-link> requires authors to make all data underlying the findings described in their manuscript fully available without restriction, with rare exception (please refer to the Data Availability Statement in the manuscript PDF file). The data should be provided as part of the manuscript or its supporting information, or deposited to a public repository. For example, in addition to summary statistics, the data points behind means, medians and variance measures should be available. If there are restrictions on publicly sharing data—e.g. participant privacy or use of data from a third party—those must be specified.</p>
    <p>Reviewer #1: Yes</p>
    <p>Reviewer #2: Yes</p>
    <p>Reviewer #3: Yes</p>
    <p>**********</p>
    <p>4. Is the manuscript presented in an intelligible fashion and written in standard English?</p>
    <p>PLOS ONE does not copyedit accepted manuscripts, so the language in submitted articles must be clear, correct, and unambiguous. Any typographical or grammatical errors should be corrected at revision, so please note any specific errors here.</p>
    <p>Reviewer #1: Yes</p>
    <p>Reviewer #2: Yes</p>
    <p>Reviewer #3: Yes</p>
    <p>**********</p>
    <p>5. Review Comments to the Author</p>
    <p>Please use the space provided to explain your answers to the questions above. You may also include additional comments for the author, including concerns about dual publication, research ethics, or publication ethics. (Please upload your review as an attachment if it exceeds 20,000 characters)</p>
    <p>Reviewer #1: Authors have developed a high-level Python API to simplify and accelerate machine learning model development.</p>
    <p>Abstract looks promising, but can be improved to summarize the work in a more detailed way.</p>
    <p>The developed software is well-suited for different research applications because project specific custom code can be integrated easily within the machine learning pipeline.</p>
    <p>Introduction should be revised: (1) Introduce the problem (2)discuss about some of the existing solutions (3)identify the gap or scope of improvement (4) discuss in order to address the identified gaps what is the methodology used (5) list out the contributions.</p>
    <p>Related work in the same field should be written in detail along with the limitations.</p>
    <p>Authors may refer to the following articles:</p>
    <p>Towards Secure Data Fusion in Industrial IoT using Transfer Learning</p>
    <p>Applications in Security and Evasions in Machine Learning: A Survey</p>
    <p>Long-term Wind Power Forecasting using Tree-based Learning Algorithms</p>
    <p>Algorithm and Framework can be explained in a detailed and organized way.</p>
    <p>Some paragraphs in the paper lack connectivity.</p>
    <p>Future work should be mentioned after mentioning limitations of PHOTONAI.</p>
    <p>There are many grammatical errors along with typo.</p>
    <p>Reviewer #2: Authors of this paper presents a high-level abstract of newly developed Python API named PHOTONAI which simplify and accelerate the machine learning model development. Very interesting and high level technical paper. The novelty was clearly specified and explained. Very good use of language and very well written. The demonstration is a key for this paper. A high level of demonstration with case scenarios would have added more value to the paper. Literature review of the paper can be extended. Overall, a very good paper.</p>
    <p>Reviewer #3: Some of the comments to improve the quality.</p>
    <p>1. Abstract add the results achieved</p>
    <p>2. In introduction add the contributions</p>
    <p>3. Add the latest references</p>
    <p>4. In results make more tables and figures to justify your work.</p>
    <p>5. The authors can cite the following references</p>
    <p>(An AI-based intelligent system for healthcare analysis using Ridge-Adaline Stochastic Gradient Descent Classifier,</p>
    <p>Genetically Optimized Prediction of Remaining Useful Life)</p>
    <p>**********</p>
    <p>6. PLOS authors have the option to publish the peer review history of their article (<ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://journals.plos.org/plosone/s/editorial-and-peer-review-process#loc-peer-review-history" ext-link-type="uri">what does this mean?</ext-link>). If published, this will include your full peer review and any attached files.</p>
    <p>If you choose “no”, your identity will remain anonymous but your review may still be made public.</p>
    <p><bold>Do you want your identity to be public for this peer review?</bold> For information about this choice, including consent withdrawal, please see our <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://www.plos.org/privacy-policy" ext-link-type="uri">Privacy Policy</ext-link>.</p>
    <p>Reviewer #1: <bold>Yes: </bold>Rutvij H Jhaveri</p>
    <p>Reviewer #2: No</p>
    <p>Reviewer #3: <bold>Yes: </bold>Praveen Kumar Reddy Maddikunta</p>
    <p>[NOTE: If reviewer comments were submitted as an attachment file, they will be attached to this email and accessible via the submission site. Please log into your account, locate the manuscript record, and check for the action link "View Attachments". If this link does not appear, there are no attachment files.]</p>
    <p>While revising your submission, please upload your figure files to the Preflight Analysis and Conversion Engine (PACE) digital diagnostic tool, <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://pacev2.apexcovantage.com/" ext-link-type="uri">https://pacev2.apexcovantage.com/</ext-link>. PACE helps ensure that figures meet PLOS requirements. To use PACE, you must first register as a user. Registration is free. Then, login and navigate to the UPLOAD tab, where you will find detailed instructions on how to use the tool. If you encounter any issues or have any questions when using PACE, please email PLOS at <email>figures@plos.org</email>. Please note that Supporting Information files do not need this step.</p>
  </body>
</sub-article>
<sub-article article-type="author-comment" id="pone.0254062.r002">
  <front-stub>
    <article-id pub-id-type="doi">10.1371/journal.pone.0254062.r002</article-id>
    <title-group>
      <article-title>Author response to Decision Letter 0</article-title>
    </title-group>
    <related-article xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="doi" xlink:href="10.1371/journal.pone.0254062" id="rel-obj002" related-article-type="editor-report"/>
    <custom-meta-group>
      <custom-meta>
        <meta-name>Submission Version</meta-name>
        <meta-value>1</meta-value>
      </custom-meta>
    </custom-meta-group>
  </front-stub>
  <body>
    <p>
      <named-content content-type="author-response-date">7 Jun 2021</named-content>
    </p>
    <p>REVIEWER #1 </p>
    <p>Authors have developed a high-level Python API to simplify and accelerate machine learning model development.</p>
    <p>Abstract looks promising, but can be improved to summarize the work in a more detailed way.</p>
    <p>We thank Reviewer 1 for this helpful suggestion and have added further details to the abstract</p>
    <p>p. 1: “[...] It functions as a unifying framework allowing the user to easily access and combine algorithms from different toolboxes into custom algorithm sequences. It is especially designed to support the iterative model development process and automates the repetitive training, hyperparameter optimization and evaluation tasks. Importantly, the workflow ensures unbiased performance estimates while still allowing the user to fully customize the machine learning analysis. [...] Its practical utility is demonstrated on an exemplary medical machine learning problem, achieving a state-of-the-art solution in few lines of code. [...]”</p>
    <p>The developed software is well-suited for different research applications because project specific custom code can be integrated easily within the machine learning pipeline.</p>
    <p>Introduction should be revised: (1) Introduce the problem (2)discuss about some of the existing solutions (3)identify the gap or scope of improvement (4) discuss in order to address the identified gaps what is the methodology used (5) list out the contributions.</p>
    <p>Related work in the same field should be written in detail along with the limitations.</p>
    <p>Authors may refer to the following articles:</p>
    <p>Towards Secure Data Fusion in Industrial IoT using Transfer Learning</p>
    <p>Applications in Security and Evasions in Machine Learning: A Survey</p>
    <p>Long-term Wind Power Forecasting using Tree-based Learning Algorithms</p>
    <p>We thank Reviewer 1 for this concrete feedback and have restructured the introduction to improve the line of reasoning and integrate the suggested structure. Specifically, in the second section of the introduction (now called ‘Existing solutions’), we have revised the description of existing software packages and have added more detail on the distinction between these packages and the proposed PHOTONAI software. We have also added additional headings to make the separation between these paragraphs clearer, which should make it easier for the reader to follow the argument. Additionally, we have added a completely new section on current shortcomings of existing solutions to further emphasize the contributions we aim to provide with PHOTONAI.</p>
    <p>p. 2: (1) Introduce the problem:</p>
    <p>“In recent years, the interest in machine learning for medical, biological, and life science research has significantly increased. Technological advances develop with breathtaking speed. The basic workflow to construct, optimize and evaluate a machine learning model, however, has remained virtually unchanged. In essence, it can be framed as the (systematic) search for the best combination of data processing steps, learning algorithms, and hyperparameter values under the premise of unbiased performance estimation.</p>
    <p>Subject to the iteratively optimized workflow is a machine learning pipeline, which in this context is defined as the sequence of algorithms subsequently applied to the data. To begin with, the data is commonly prepared by successively applying several processing steps such as normalization, imputation, feature selection, dimensionality reduction, data augmentation, and others. The altered data is then forwarded to one or more learning algorithms which internally derive the best fit for the learning task and finally yield predictions.</p>
    <p>In practice, researchers select suitable preprocessing and learning algorithms from different toolboxes, learn toolbox-specific syntaxes, decide for a training and testing scheme, manage the data flow and, over time, iteratively optimize their choices. Importantly, all of this is done while preventing data leakage, calculating performance metrics, adhering to (nested) cross-validation best practices, and searching for the optimal (hyperparameter-) configuration.</p>
    <p>A multitude of high-quality and well-maintained open-source toolboxes offer specialized solutions, each for a particular subdomain of machine learning-related (optimization) problems.”</p>
    <p>p. 3-4: (2) Discuss existing solutions. </p>
    <p>“In the field of (deep) neural networks for example, libraries such as Tensorflow, Theano, Caffe and PyTorch offer domain-specific implementations for nodes, layers, optimizers, as well as evaluation and utility functions. On top of that, higher level Application Programming Interfaces (APIs) such as Keras and fastai, offer expressive syntaxes for accelerated and enhanced development of deep neural network architectures. </p>
    <p>In the same manner, the scikit-learn toolbox has evolved as one of the major resources of the field, covering a very broad range of regression-, classification-, clustering- and preprocessing algorithm implementations. It has established the de-facto standard interface for data-processing and learning algorithms, and, in addition, offers a wide range of utility functions, such as cross-validation schemes and model evaluation metrics.</p>
    <p>Next to these general frameworks, other libraries in the software landscape offer functionalities to address more specialized problems. Prominent examples are the imbalanced-learn toolbox, which provides numerous over- or under- sampling methods, or modality-specific libraries such as nilearn and nibabel which offer utility functions for accessing and preparing neuroimaging data.</p>
    <p>On top of that, the software landscape is complemented by several hyperparameter optimization packages, each implementing a different strategy to find the most effective hyperparameter combination. Next to Bayesian approaches, such as Scikit-optimize or SMAC, there are packages implementing evolutionary strategies or packages approximating gradient descent within the hyperparameter space. Each package requires specific syntax and unique hyperparameter space definitions.</p>
    <p>Finally, there are approaches uniting all these components into algorithms that automatically derive the best model architecture and hyperparameter settings for a given dataset. Libraries such as auto-sklearn, TPOT, AutoWeka, Auto-keras, AutoML, Auto-Gluon and others optimize a specific set of data-processing methods, learning algorithms and their respective hyperparameters. While very intriguing, these libraries aim at full automation - neglecting the need for customization and foregoing the opportunity to incorporate high-level domain knowledge in the model architecture search. Especially the complex and often high-dimensional data structure native to medical and biological research requires the integration and application of modality-specific processing and often entails the development of novel algorithms.”</p>
    <p>p.5: (3) Identify the gap or scope of improvement</p>
    <p>“Currently, iterative model development approaches across different toolboxes as well as design and optimization of custom algorithm sequences are barely supported. For a start, scikit-learn has introduced the concept of pipelines, which successively apply a list of processing methods (referred to as transformers) and a final learning algorithm (called estimator) to the data. The pipeline directs the data from one algorithm to another and can be trained and evaluated in (simple) cross-validation schemes, thereby significantly reducing programmatic overhead. Scikit-learn's consistent usage of standard interfaces enables the pipeline to be subject to scikit-learn's inherent hyperparameter optimization strategies based on random- and grid-search. While being a simple and effective tool, there still are several limitations. For one, hyperparameter optimization requires a nested cross-validation scheme, which is not inherently enforced. Second, a standardized solution for easy integration of custom or third-party algorithms is not considered. In addition, several repetitive tasks, such as metric calculations, logging, and visualization lack automation and still need to be handled manually. Finally, the pipeline can not handle adjustments to the target vector, thereby excluding algorithms for e.g. data augmentation or handling class imbalance.”</p>
    <p>p. 5: (4) Discuss methodology to address identified issues</p>
    <p>“To address these issues, we propose PHOTONAI as a high-level Python API that acts as a mediator between different toolboxes. Established solutions are conveniently accessible or can be easily added. It combines an automated supervised machine learning workflow with the concept of custom machine learning pipelines. Thereby it is able to considerably accelerate design iterations and simplify the evaluation of novel analysis pipelines.”</p>
    <p>p. 5-6: (5) List out contributions</p>
    <p>Increased Accessibility. By pre-registering data processing methods, learning algorithms, hyperparameter optimization strategies, performance metrics, and other functionalities, the user can effortlessly access established machine learning implementations via simple keywords. In addition, by relying on the established scikit-learn object API, users can easily integrate any third-party or custom algorithm implementation.</p>
    <p>Extended Pipeline Functionality. A simple to use class structure allows the user to arrange selected algorithms into single or parallel pipeline sequences. Extending the pipeline concept of scikit-learn, we add novel functionality such as flexible positioning of learning algorithms, target vector manipulations, callback functions, specialized caching, parallel data-streams, Or-Operations, and other features as described below.</p>
    <p>Automation. PHOTONAI can automatically train, (hyperparameter-) optimize and evaluate any custom pipeline. Importantly, the user designs the training and testing procedure by selecting (nested) cross-validation schemes, hyperparameter optimization strategies, and performance metrics from a range of pre-integrated or custom-built options. Thereby, development time is significantly decreased and conceptual errors such as information leakage between training, validation, and test set are minimized. Training information, baseline performances, hyperparameter optimization progress, and test performance evaluations are persisted and can be visualized via an interactive, browser-based graphical interface (PHOTONAI Explorer) to facilitate model improvement.</p>
    <p>Model Sharing. A standardized format for saving, loading, and distributing optimized and trained pipeline architectures enables model sharing and external model validation even for non-expert users.”</p>
    <p>Algorithm and Framework can be explained in a detailed and organized way.</p>
    <p>Some paragraphs in the paper lack connectivity.</p>
    <p>We thank reviewer #1 for outlining this shortcoming and have updated the section introducing the algorithm and the framework, as well as the description of the software’s features. To further improve the readability of these sections, we have added additional headings to the respective paragraphs.</p>
    <p>p. 6-7: “In the following, we will describe the automated supervised machine learning workflow implemented in PHOTONAI. Subsequently, we will outline the class structure, which is the core of its expressive syntax. At the same time, we will highlight its current functionalities, and finally, provide a hands-on example to introduce PHOTONAI's usage.</p>
    <p>PHOTONAI automatizes the supervised machine learning workflow according to user-defined parameters (see pseudocode in Listing~1). In a nutshell, cross-validation folds are derived to iteratively train and evaluate a machine learning pipeline following the hyperparameter optimization strategy's current parameter value suggestions. Performance metrics are calculated, the progress is logged and finally, the best hyperparameter configuration is selected to train a final model. The training, testing, and optimization workflow is automated, however, it is important to note that it is parameterized by user choices and therefore fully customized.”</p>
    <p>p. 7: “In order to achieve an efficient and expressive customization syntax, PHOTONAI's class architecture captures all workflow- and pipeline-related parameters into distinct and combinable components (see Fig~1). A central management class called Hyperpipe - short for hyperparameter optimization pipeline - handles the setup of the pipeline and executes the training and test procedure according to user choices. Basis to the data flow is a custom Pipeline implementation, which streams data through a sequence of PipelineElement objects, the latter of which represent either established or custom algorithm implementations. In addition, clear interfaces and several utility classes allow the integration of custom solutions, adjust the training and test procedure and build parallel data streams. In the following, PHOTONAI's core classes and their respective features will be further detailed. </p>
    <p>PHOTONAI's core functionality is encapsulated in a class called Hyperpipe, which controls all workflow and pipeline-related parameters and manages the cross-validated training and testing procedure. [...]”</p>
    <p>p.9: “The Hyperpipe relies on a custom pipeline implementation that is conceptually related to the scikit-learn pipeline but extends it with four core features. [...]”</p>
    <p>p.10: “In order to integrate a particular algorithm into the pipeline's data stream, PHOTONAI implements the PipelineElement class. [...]”</p>
    <p>Future work should be mentioned after mentioning limitations of PHOTONAI.</p>
    <p>We agree with reviewer #1 and have introduced a discussion of limitations before mentioning future work. </p>
    <p>p. 23: “We introduced PHOTONAI, a high-level Python API for rapid machine learning model development. As demonstrated in the example above, both the pipeline and the training and test procedure, as well the integration of hyperparameter optimization can be implemented in a few lines of code. In addition, experimenting with different algorithm sequences, hyperparameter optimization strategies, and other workflow-related parameters was realized by adding single lines of code or changing a few keywords. Through the automation of the training, validation and test procedure, data transformation and feature selection steps are restricted to the validation set only, thus strictly avoiding data leakage even when used by non-experts. Interestingly, this fundamentally important separation between training and test data was apparently not implemented for the feature selection analyses in Chicco et al., as they seem to have selected the most important features on the whole dataset which has most likely inflated their final model performance. Examples like this again highlight the importance of easy-to-use nested cross-validation frameworks that guarantee an unbiased estimate of the predictive performance and generalization error, which is key to, e.g., the development of reliable machine learning applications in the medical domain. Finally, the toolbox automatically identified the best hyperparameter configurations, yielded in-depth information about both validation and test set performance, and offered convenient estimator comparison tools.</p>
    <p>PHOTONAI is developed with common scientific use cases in mind, for which it can significantly decrease programmatic overhead and support rapid model prototyping. However, use cases that substantially differ in the amount of available data or in the computational resources required to train the model, might require a different model development workflow. For example, while all kinds of neural networks can be integrated in PHOTONAI, developing and optimizing extremely complex and specialized deep neural networks with specialized architecture optimization protocols might be cumbersome within the PHOTONAI framework. In addition, unbiased performance evaluation in massive amounts of data might significantly relax the need for strict cross-validation schemes.</p>
    <p>In addition, cross-toolbox access to algorithms comes at the cost of manually pre-registrating the algorithms with the PHOTONAI Registry system. In addition, if the algorithm does not inherently adheres to the scikit-learn object API, the user needs to manually write a wrapper class calling the algorithm according to the fit-predict-transform interface. However, this process is only required once and can afterwards be shared with the community, thereby enabling convenient access for other researchers without further effort. Furthermore, once registered, all integrated algorithms are instantaneously compatible with all other functionalities of the PHOTONAI framework, for example, can they be optimized with any hyperparameter optimization algorithm of choice. </p>
    <p>In the future, we intend to extend both functionality and usability. [...]“</p>
    <p>There are many grammatical errors along with typo.</p>
    <p>We apologize for this shortcoming and have double-checked typos and grammatical errors in the entire manuscript. </p>
    <p>REVIEWER #2</p>
    <p>Authors of this paper presents a high-level abstract of newly developed Python API named PHOTONAI which simplify and accelerate the machine learning model development. Very interesting and high level technical paper. The novelty was clearly specified and explained. Very good use of language and very well written. The demonstration is a key for this paper. [...] Overall, a very good paper.</p>
    <p>We thank reviewer#2 for his expertise and the overall good evaluation of the paper.</p>
    <p>A high level of demonstration with case scenarios would have added more value to the paper. </p>
    <p>We agree with reviewer#2 and have divided the example section into four separate use cases that highlight different aspects of the toolbox’s functionalities. We have also adjusted the syntax highlighting and formatting of the example Python code to make it easier to read and follow along.</p>
    <p>p. 14-22: </p>
    <p>Hyperpipe Setup</p>
    <p>First, we will define the training, optimization, and evaluation workflow in an initial call to the Hyperpipe class. The python code in Listing 4 shows the PHOTONAI code defining both the data flow and the training and test procedure. After importing the relevant packages and loading the data, we instantiate a Hyperpipe and choose the workflow parameters as follows:</p>
    <p>For the outer cross-validation loop, we specify 100 shuffled iterations each holding out a test set of 20 percent. For the inner cross-validation loop, we select a ten-fold cross-validation. (lines 13-14).</p>
    <p>To measure model performance, we specify that f1 score, Matthews correlation coefficient, balanced accuracy, as well as sensitivity and specificity are to be calculated (lines 16-17).</p>
    <p>We optimize the pipeline for f1 score, as it maximizes both sensitive and specific predictions, which is particularly important in medical contexts. (line 18).</p>
    <p>To save computational resources and time, we enable caching by specifying a cache folder (line 22). This is particularly useful in examples where there are a lot of partially overlapping hyperparameters to be tested.</p>
    <p>Finally, we specify a folder to which the output is written (line 21) and set the verbosity of the console log to 1. At this verbosity level, information on every tested hyperparameter configuration and its respective performance estimate is printed to the console.</p>
    <p>After the hyperpipe has been defined, we can design the flow of the data by adding algorithms and respective hyperparameters to the pipeline.</p>
    <p>First, data is normalized using scikit-learn's StandardScaler which both centers the data and scales it to unit variance (line 26).</p>
    <p>Second, we impute missing values with the mean values per feature of the training set by calling scikit-learn's SimpleImputer (line 27). </p>
    <p>Of note, we consider use cases 1 to 3 (see below) to be exploratory analyses. We believe this simulates a naturalistic workflow of machine learning projects where different algorithms, feature preprocessing and hyperparameters are tested in a manual fashion. However, if done incorrectly, this inevitably leads to a manual over-fitting to the data at hand, which is especially troublesome in high-stake medical problems with small datasets. In this context, manual over-fitting happens implicitly when data scientists optimize algorithms and hyperparameters by repeatedly looking at cross-validated test performance. In PHOTONAI, this problem can easily be avoided by setting the Hyperpipe parameter use_test_set to False. This way, PHOTONAI will still apply nested cv but will only report validation performances from the inner cv loop, not the outer cv test data. In the final use case 4, use_test_set is set to True to estimate final model performance and generalizability on the actual test sets.</p>
    <p>Use case 1 - Estimator selection</p>
    <p>Although some rules of thumb for selecting the correct algorithm do exist, knowing the optimal learning algorithm for a specific task a priori is impossible (no free lunch theorems). Therefore, the possibility to automatically evaluate multiple algorithms within nested cross-validation is crucial to efficient and unbiased machine learning analyses. In this example, we first train a machine learning pipeline and consider three different learning algorithms that we find appropriate for this learning problem. These algorithms are added to the PHOTONAI Hyperpipe in addition to the scaling and imputing preprocessing steps defined above.</p>
    <p>Setup</p>
    <p>To compare different learning algorithms, an Or-Element called Switch is added to the pipeline that toggles between several learning algorithms (see Listing 5). Here, we compare a random forest (RF), gradient boosting (GB), and a support vector machine (SVM) against each other. Again, all algorithms are imported from scikit-learn, and for every element we specify algorithm-specific hyperparameters that are automatically optimized.</p>
    <p>To efficiently optimize hyperparameters of different learning algorithms, the switch optimizer in PHOTONAI can be used which optimizes each learning algorithm in an individual hyperparameter space (line 19 in Listing). We apply Bayesian optimization to each space respectively and limit the number of tested configurations to 10 (line 20 in Listing 4).</p>
    <p>Finally, we can start the training, optimization, and test procedure by calling Hyperpipe.fit(). After the pipeline optimization has finished, we extract not only the overall best hyperparameter configuration and its respective performance, but also the best configuration performance per learning algorithm (RF, GB, SVM, see line 21 in Listing).</p>
    <p>Results</p>
    <p>The results of the initial estimator selection analysis are given in the first line of Table 1. We observe an f1 score of 75% and a Matthews correlation coefficient of 65%. The best config found by the hyperparameter optimization strategy applied the Random Forest classifier, which thus in this case outperforms gradient boosting and the Support Vector Machine.</p>
    <p>Use case 2 - Feature selection</p>
    <p>Next, we will evaluate the effect of an additional feature selection step. This can be done, e.g., by analyzing a linear model's normalization coefficients. While low coefficient features are interpreted detrimental to the learning process since they might induce error variance into the data, high coefficient features are interpreted as important information to solve learning problem. A frequently used feature selection approach is based on the Lasso algorithm, as the Lasso implements an L1 regularization norm that penalizes non-sparsity of the model and thus pushes unnecessary model weights to zero. The Lasso coefficients can then be used to select the most important features.</p>
    <p>Setup</p>
    <p>The Lasso implementation is imported from scikit-learn, and in order to prepare it as a feature selection tool, accessed via a simple wrapper class provided in PHOTONAI. The wrapper sorts the fitted model's coefficients and only features falling in the top k percentile are kept. Both the Lasso's alpha parameter as well as the percentile of features to keep can be optimized. We add the pipeline element LassoFeatureSelection as given in Listing 6 between the SimpleImputer pipeline element and the estimator switch. Again, we run the analysis and evaluate only the validation set (Hyperpipe parameter use_test_set is set to False).</p>
    <p>Results</p>
    <p>The performance metrics for the pipeline with Lasso Feature Selection are given in Table 1. We see a minor performance decrease of approximately 1%. Apparently, linear feature selection is unhelpful indicating that the learning problem is rather under- than over-described by the features given. Interestingly, while 90% of the subjects are correctly identified as survivors (specificity of 91%), a notable amount of actual deaths are missed (sensitivity of 73%). The lower sensitivity in relation to a high specificity might be due to the class imbalance present in the data with more subjects surviving than dying (68%), which we will now investigate in use case 3.</p>
    <p>Use case 3 - Handling class imbalance</p>
    <p>As a next step, we will try to enhance predictive accuracy and balance the trade-off between specificity and sensitivity by decreasing class imbalance.</p>
    <p>Setup</p>
    <p>In order to conveniently access class balancing algorithms, PHOTONAI offers a wrapper calling over- and under-sampling (or a combination of both) techniques implemented in the imbalanced-learn package. We remove the LassoFeatureSelection pipeline element and substitute it with an ImbalancedDataTransformer pipeline element as shown in Listing 7. As a hyperparameter, we optimize the specific class balancing method itself by evaluating random undersampling, random oversampling, and a combination of both called SMOTE.</p>
    <p>Results</p>
    <p>Rerunning the analysis with a class balancing algorithm yields a slightly better performance (f1 score = 0.76, Matthews correlation coefficient = 0.66, see line 3 in Table 1). The optimal class balancing method was found to be SMOTE, a combination of under- and over-sampling. More importantly, a greater balance between sensitivity (82%) and specificity (86%) was reached which also resulted in a higher balanced accuracy compared to the two previous pipelines (BACC = 84%).</p>
    <p>Use case 4 - Estimating final model performance</p>
    <p>From the results of use cases 2 and 3, we can see that only class balancing but not feature selection slightly increased the classification performance in this specific dataset. Additionally, when we examine the results of the three learning algorithms of the class balancing pipeline, we can further see that the Random Forest (f1 = 0.76) is still outperforming gradient boosting and the Support Vector Machine (see Table 2). Therefore, we restrict our final machine learning pipeline to a class balancing element and a Random Forest classifier.</p>
    <p>Setup</p>
    <p>In this last step, we finish model development and estimate the final model performance. We remove the estimator switch from the pipeline and substitute it by a single Random Forest pipeline element. In addition, we decide to thoroughly investigate the hyperparameter space and therefore change the hyperparameter optimizer to grid search (see line 3-4 in Listing 8). In addition, we use the previously calculated validation metrics as a rough guide to specify a lower performance bound that promising hyperparameter configurations must outperform. Specifically, we apply a MinimumPerformanceConstraint on f1 score, meaning that inner fold calculations are aborted when the mean performance is below 0.7 (see line 5-7 in Listing 8). Thereby, less promising configurations are dismissed early and computational resources are saved. Importantly, we will now set use_test_set to True to make sure that PHOTONAI will evaluate the best hyperparameter configurations on the outer cv test set.</p>
    <p>Results</p>
    <p>The final model performance on the test set is given in Table 3. All metrics remained stable when being evaluated on the previously unused test set. As a comparison, Chicco et al. (2020) trained several learning algorithms to the heart failure dataset used in this example (see row 2 of Table 11 in Chicco et al.). PHOTONAI is able to outperform the best model of Chicco et al. which was trained on all available features in a similar fashion (see Table 3). For the f1 score, the PHOTONAI pipeline reaches 0.746. Also, sensitivity and specificity appears to be more balanced in comparison to Chicco et al. </p>
    <p>Fig 4 shows a parallel plot of the hyperparameter space PHOTONAI has explored in this final analysis. Since we have used a grid search optimizer, all possible hyperparameter combinations have been evaluated. Interestingly, when looking at Figure 4, a clear disadvantage becomes evident when no class balancing algorithm is used, random under-sampling appears to provide generally better model performance. </p>
    <p>Literature review of the paper can be extended. </p>
    <p>We thank reviewer #2 for this useful comment and have updated the related section.</p>
    <p>p. 3: “A multitude of high-quality and well-maintained open-source toolboxes offer specialized solutions, each for a particular subdomain of machine learning-related (optimization) problems.</p>
    <p>In the field of (deep) neural networks for example, libraries such as Tensorflow, Theano, Caffe and PyTorch offer domain-specific implementations for nodes, layers, optimizers, as well as evaluation and utility functions. On top of that, higher level Application Programming Interfaces (APIs) such as Keras and fastai, offer expressive syntaxes for accelerated and enhanced development of deep neural network architectures. </p>
    <p>In the same manner, the scikit-learn toolbox has evolved as one of the major resources of the field, covering a very broad range of regression-, classification-, clustering- and preprocessing algorithm implementations. It has established the de-facto standard interface for data-processing and learning algorithms, and, in addition, offers a wide range of utility functions, such as cross-validation schemes and model evaluation metrics.</p>
    <p>Next to these general frameworks, other libraries in the software landscape offer functionalities to address more specialized problems. Prominent examples are the imbalanced-learn toolbox,which provides numerous over- or under- sampling methods, or modality-specific libraries such as nilearn and nibabel which offer utility functions for accessing and preparing neuroimaging data.</p>
    <p>On top of that, the software landscape is complemented by several hyperparameter optimization packages, each implementing a different strategy to find the most effective hyperparameter combination. Next to Bayesian approaches, such as Scikit-optimize or SMAC, there are packages implementing evolutionary strategies or packages approximating gradient descent within the hyperparameter space. Each package requires specific syntax and unique hyperparameter space definitions.</p>
    <p>Finally, there are approaches uniting all these components into algorithms that automatically derive the best model architecture and hyperparameter settings for a given dataset. Libraries such as auto-sklearn, TPOT, AutoWeka, Auto-keras, AutoML, Auto-Gluon and others optimize a specific set of data-processing methods, learning algorithms and their respective hyperparameters. While very intriguing, these libraries aim at full automation - neglecting the need for customization and foregoing the opportunity to incorporate high-level domain knowledge in the model architecture search. Especially the complex and often high-dimensional data structure native to medical and biological research requires the integration and application of modality-specific processing and often entails the development of novel algorithms.</p>
    <p>Currently, iterative model development approaches across different toolboxes as well as design and optimization of custom algorithm sequences are barely supported. For a start, scikit-learn has introduced the concept of pipelines, which successively apply a list of processing methods (referred to as transformers) and a final learning algorithm (called estimator) to the data. The pipeline directs the data from one algorithm to another and can be trained and evaluated in (simple) cross-validation schemes, thereby significantly reducing programmatic overhead. Scikit-learn's consistent usage of standard interfaces enables the pipeline to be subject to scikit-learn's inherent hyperparameter optimization strategies based on random- and grid-search. While being a simple and effective tool, there still are several limitations. For one, hyperparameter optimization requires a nested cross-validation scheme, which is not inherently enforced. Second, a standardized solution for easy integration of custom or third-party algorithms is not considered. In addition, several repetitive tasks, such as metric calculations, logging, and visualization lack automation and still need to be handled manually. Finally, the pipeline can not handle adjustments to the target vector, thereby excluding algorithms for e.g. data augmentation or handling class imbalance.”</p>
    <p>REVIEWER #3 </p>
    <p>Some of the comments to improve the quality.</p>
    <p>1. Abstract add the results achieved</p>
    <p>We thank reviewer #3 for this helpful suggestion and have added the results to the abstract. </p>
    <p>p. 1: “Its practical utility is demonstrated on an exemplary medical machine learning problem for which we reach state-of-the-art performance in a few lines of code.”</p>
    <p>2. In introduction add the contributions</p>
    <p>We thank reviewer #3 for outlining this shortcoming and have edited the introduction to clarify the contributions. </p>
    <p>p. 3-4: “To address these issues, we propose PHOTONAI as a high-level Python API that acts as a mediator between different toolboxes. Established solutions are conveniently accessible or can be easily added. It combines an automated supervised machine learning workflow with the concept of custom machine learning pipelines. Thereby it is able to considerably accelerate design iterations and simplify the evaluation of novel analysis pipelines.</p>
    <p>Increased Accessibility. By pre-registering data processing methods, learning algorithms, hyperparameter optimization strategies, performance metrics, and other functionalities, the user can effortlessly access established machine learning implementations via simple keywords. In addition, by relying on the established scikit-learn object API, users can easily integrate any third-party or custom algorithm implementation.</p>
    <p>Extended Pipeline Functionality. A simple to use class structure allows the user to arrange selected algorithms into single or parallel pipeline sequences. Extending the pipeline concept of scikit-learn, we add novel functionality such as flexible positioning of learning algorithms, target vector manipulations, callback functions, specialized caching, parallel data-streams, Or-Operations, and other features as described below.</p>
    <p>Automation. PHOTONAI can automatically train, (hyperparameter-) optimize and evaluate any custom pipeline. Importantly, the user designs the training and testing procedure by selecting (nested) cross-validation schemes, hyperparameter optimization strategies, and performance metrics from a range of pre-integrated or custom-built options. Thereby, development time is significantly decreased and conceptual errors such as information leakage between training, validation, and test set are minimized. Training information, baseline performances, hyperparameter optimization progress, and test performance evaluations are persisted and can be visualized via an interactive, browser-based graphical interface (PHOTONAI Explorer) to facilitate model improvement.</p>
    <p>Model Sharing. A standardized format for saving, loading, and distributing optimized and trained pipeline architectures enables model sharing and external model validation even for non-expert users.”</p>
    <p>3. Add the latest references</p>
    <p>We agreed with reviewer #3 and have updated the paper, see comment 2 of Reviewer #2 </p>
    <p>4. In results make more tables and figures to justify your work.</p>
    <p>We thank reviewer #1 for outlining this shortcoming and have revised the complete example and result section. We have added an individual result paragraph for every use case scenario and have added the benchmark results to the final model performance table. We have also increased the readability and design of all tables. Additionally, we have added a parallel plot to visualize the explored hyperparameter space of the final analysis. </p>
    <p>p. 14-22: For the corresponding changes of the example and results section, please see our response to reviewer #3 (“high-level of demonstration with case scenarios”).</p>
    <p>p.22:</p>
    <p>Fig 4. Parallel plot showing hyperparameter exploration. All three hyperparameters used in the final model are shown on the x-axis. They include the class balancing algorithm and two hyperparameters of the Random Forest classifier (maximum number of features and minimum samples per split). Each line represents a specific combination of all hyperparameters. The line color reflects the corresponding model performance based on the f1 score. Higher model performance is shown in dark red while lower model performance is shown in blue. Random under-sampling appears to increase model performance slightly while using no class balancing algorithm decreases overall model performance. CB = class balancing, RUS = random under-sampling, ROS = random over-sampling, SMOTE = synthetic minority oversampling technique, RF = Random Forest.</p>
    <p>5. The authors can cite the following references</p>
    <p>(An AI-based intelligent system for healthcare analysis using Ridge-Adaline Stochastic Gradient Descent Classifier, Genetically Optimized Prediction of Remaining Useful Life)</p>
    <p>We are happy to include the two references suggested by reviewer#3. However, due to the specificity of both papers we were unable to relate the topic and context to the current, rather general work focused on software engineering. We kindly ask the reviewer to specify where and in which context the papers could be cited in our work.</p>
    <supplementary-material id="pone.0254062.s001" position="float" content-type="local-data">
      <label>Attachment</label>
      <caption>
        <p>Submitted filename: <named-content content-type="submitted-filename">plosOne Reponse.pdf</named-content></p>
      </caption>
      <media xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="pone.0254062.s001.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </body>
</sub-article>
<sub-article article-type="aggregated-review-documents" id="pone.0254062.r003" specific-use="decision-letter">
  <front-stub>
    <article-id pub-id-type="doi">10.1371/journal.pone.0254062.r003</article-id>
    <title-group>
      <article-title>Decision Letter 1</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Gadekallu</surname>
          <given-names>Thippa Reddy</given-names>
        </name>
        <role>Academic Editor</role>
      </contrib>
    </contrib-group>
    <permissions>
      <copyright-statement>© 2021 Thippa Reddy Gadekallu</copyright-statement>
      <copyright-year>2021</copyright-year>
      <copyright-holder>Thippa Reddy Gadekallu</copyright-holder>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an open access article distributed under the terms of the <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
      </license>
    </permissions>
    <related-article xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="doi" xlink:href="10.1371/journal.pone.0254062" id="rel-obj003" related-article-type="reviewed-article"/>
    <custom-meta-group>
      <custom-meta>
        <meta-name>Submission Version</meta-name>
        <meta-value>1</meta-value>
      </custom-meta>
    </custom-meta-group>
  </front-stub>
  <body>
    <p>
      <named-content content-type="letter-date">21 Jun 2021</named-content>
    </p>
    <p>PHOTONAI - A Python API for rapid machine learning model development</p>
    <p>PONE-D-21-10500R1</p>
    <p>Dear Dr. Leenings,</p>
    <p>We’re pleased to inform you that your manuscript has been judged scientifically suitable for publication and will be formally accepted for publication once it meets all outstanding technical requirements.</p>
    <p>Within one week, you’ll receive an e-mail detailing the required amendments. When these have been addressed, you’ll receive a formal acceptance letter and your manuscript will be scheduled for publication.</p>
    <p>An invoice for payment will follow shortly after the formal acceptance. To ensure an efficient process, please log into Editorial Manager at <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="http://www.editorialmanager.com/pone/" ext-link-type="uri">http://www.editorialmanager.com/pone/</ext-link>, click the 'Update My Information' link at the top of the page, and double check that your user information is up-to-date. If you have any billing related questions, please contact our Author Billing department directly at <email>authorbilling@plos.org</email>.</p>
    <p>If your institution or institutions have a press office, please notify them about your upcoming paper to help maximize its impact. If they’ll be preparing press materials, please inform our press team as soon as possible -- no later than 48 hours after receiving the formal acceptance. Your manuscript will remain under strict press embargo until 2 pm Eastern Time on the date of publication. For more information, please contact <email>onepress@plos.org</email>.</p>
    <p>Kind regards,</p>
    <p>Thippa Reddy Gadekallu</p>
    <p>Academic Editor</p>
    <p>PLOS ONE</p>
    <p>Additional Editor Comments (optional):</p>
    <p>Reviewers' comments:</p>
    <p>Reviewer's Responses to Questions</p>
    <p>
      <bold>Comments to the Author</bold>
    </p>
    <p>1. If the authors have adequately addressed your comments raised in a previous round of review and you feel that this manuscript is now acceptable for publication, you may indicate that here to bypass the “Comments to the Author” section, enter your conflict of interest statement in the “Confidential to Editor” section, and submit your "Accept" recommendation.</p>
    <p>Reviewer #2: All comments have been addressed</p>
    <p>Reviewer #3: All comments have been addressed</p>
    <p>**********</p>
    <p>2. Is the manuscript technically sound, and do the data support the conclusions?</p>
    <p>The manuscript must describe a technically sound piece of scientific research with data that supports the conclusions. Experiments must have been conducted rigorously, with appropriate controls, replication, and sample sizes. The conclusions must be drawn appropriately based on the data presented. </p>
    <p>Reviewer #2: Yes</p>
    <p>Reviewer #3: Yes</p>
    <p>**********</p>
    <p>3. Has the statistical analysis been performed appropriately and rigorously? </p>
    <p>Reviewer #2: Yes</p>
    <p>Reviewer #3: Yes</p>
    <p>**********</p>
    <p>4. Have the authors made all data underlying the findings in their manuscript fully available?</p>
    <p>The <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="http://www.plosone.org/static/policies.action#sharing" ext-link-type="uri">PLOS Data policy</ext-link> requires authors to make all data underlying the findings described in their manuscript fully available without restriction, with rare exception (please refer to the Data Availability Statement in the manuscript PDF file). The data should be provided as part of the manuscript or its supporting information, or deposited to a public repository. For example, in addition to summary statistics, the data points behind means, medians and variance measures should be available. If there are restrictions on publicly sharing data—e.g. participant privacy or use of data from a third party—those must be specified.</p>
    <p>Reviewer #2: Yes</p>
    <p>Reviewer #3: Yes</p>
    <p>**********</p>
    <p>5. Is the manuscript presented in an intelligible fashion and written in standard English?</p>
    <p>PLOS ONE does not copyedit accepted manuscripts, so the language in submitted articles must be clear, correct, and unambiguous. Any typographical or grammatical errors should be corrected at revision, so please note any specific errors here.</p>
    <p>Reviewer #2: Yes</p>
    <p>Reviewer #3: Yes</p>
    <p>**********</p>
    <p>6. Review Comments to the Author</p>
    <p>Please use the space provided to explain your answers to the questions above. You may also include additional comments for the author, including concerns about dual publication, research ethics, or publication ethics. (Please upload your review as an attachment if it exceeds 20,000 characters)</p>
    <p>Reviewer #2: Authors of this manuscript did a great job on addressing the comments from the reviewers. Outstanding effort!</p>
    <p>Reviewer #3: The authors have addressed all of my comments. The paper can can be accepted in the current format. Thank you</p>
    <p>**********</p>
    <p>7. PLOS authors have the option to publish the peer review history of their article (<ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://journals.plos.org/plosone/s/editorial-and-peer-review-process#loc-peer-review-history" ext-link-type="uri">what does this mean?</ext-link>). If published, this will include your full peer review and any attached files.</p>
    <p>If you choose “no”, your identity will remain anonymous but your review may still be made public.</p>
    <p><bold>Do you want your identity to be public for this peer review?</bold> For information about this choice, including consent withdrawal, please see our <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://www.plos.org/privacy-policy" ext-link-type="uri">Privacy Policy</ext-link>.</p>
    <p>Reviewer #2: No</p>
    <p>Reviewer #3: No</p>
  </body>
</sub-article>
<sub-article article-type="editor-report" id="pone.0254062.r004" specific-use="acceptance-letter">
  <front-stub>
    <article-id pub-id-type="doi">10.1371/journal.pone.0254062.r004</article-id>
    <title-group>
      <article-title>Acceptance letter</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Gadekallu</surname>
          <given-names>Thippa Reddy</given-names>
        </name>
        <role>Academic Editor</role>
      </contrib>
    </contrib-group>
    <permissions>
      <copyright-statement>© 2021 Thippa Reddy Gadekallu</copyright-statement>
      <copyright-year>2021</copyright-year>
      <copyright-holder>Thippa Reddy Gadekallu</copyright-holder>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an open access article distributed under the terms of the <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
      </license>
    </permissions>
    <related-article xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="doi" xlink:href="10.1371/journal.pone.0254062" id="rel-obj004" related-article-type="reviewed-article"/>
  </front-stub>
  <body>
    <p>
      <named-content content-type="letter-date">12 Jul 2021</named-content>
    </p>
    <p>PONE-D-21-10500R1 </p>
    <p>PHOTONAI - A Python API for rapid machine learning model development </p>
    <p>Dear Dr. Leenings:</p>
    <p>I'm pleased to inform you that your manuscript has been deemed suitable for publication in PLOS ONE. Congratulations! Your manuscript is now with our production department. </p>
    <p>If your institution or institutions have a press office, please let them know about your upcoming paper now to help maximize its impact. If they'll be preparing press materials, please inform our press team within the next 48 hours. Your manuscript will remain under strict press embargo until 2 pm Eastern Time on the date of publication. For more information please contact <email>onepress@plos.org</email>.</p>
    <p>If we can help with anything else, please email us at <email>plosone@plos.org</email>. </p>
    <p>Thank you for submitting your work to PLOS ONE and supporting open access. </p>
    <p>Kind regards, </p>
    <p>PLOS ONE Editorial Office Staff</p>
    <p>on behalf of</p>
    <p>Dr. Thippa Reddy Gadekallu </p>
    <p>Academic Editor</p>
    <p>PLOS ONE</p>
  </body>
</sub-article>
