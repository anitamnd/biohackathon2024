<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1 20151215//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.1?>
<?ConverterInfo.XSLTName jp2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id>
    <journal-id journal-id-type="publisher-id">bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1367-4803</issn>
    <issn pub-type="epub">1367-4811</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">6612825</article-id>
    <article-id pub-id-type="doi">10.1093/bioinformatics/btz336</article-id>
    <article-id pub-id-type="publisher-id">btz336</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Ismb/Eccb 2019 Conference Proceedings</subject>
        <subj-group subj-group-type="category-toc-heading">
          <subject>Macromolecular Sequence, Structure, and Function</subject>
        </subj-group>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Precise modelling and interpretation of bioactivities of ligands targeting G protein-coupled receptors</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Wu</surname>
          <given-names>Jiansheng</given-names>
        </name>
        <xref ref-type="aff" rid="btz336-aff1">1</xref>
        <xref ref-type="aff" rid="btz336-aff2">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Liu</surname>
          <given-names>Ben</given-names>
        </name>
        <xref ref-type="aff" rid="btz336-aff3">3</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Chan</surname>
          <given-names>Wallace K B</given-names>
        </name>
        <xref ref-type="aff" rid="btz336-aff4">4</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Wu</surname>
          <given-names>Weijian</given-names>
        </name>
        <xref ref-type="aff" rid="btz336-aff5">5</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Pang</surname>
          <given-names>Tao</given-names>
        </name>
        <xref ref-type="aff" rid="btz336-aff6">6</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Hu</surname>
          <given-names>Haifeng</given-names>
        </name>
        <xref ref-type="aff" rid="btz336-aff3">3</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Yan</surname>
          <given-names>Shancheng</given-names>
        </name>
        <xref ref-type="aff" rid="btz336-aff1">1</xref>
        <xref ref-type="aff" rid="btz336-aff2">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Ke</surname>
          <given-names>Xiaoyan</given-names>
        </name>
        <xref ref-type="aff" rid="btz336-aff7">7</xref>
        <xref ref-type="corresp" rid="btz336-cor1"/>
        <!--<email>kexiaoyan@njmu.edu.cn</email>-->
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Zhang</surname>
          <given-names>Yang</given-names>
        </name>
        <xref ref-type="aff" rid="btz336-aff8">8</xref>
        <xref ref-type="aff" rid="btz336-aff9">9</xref>
        <xref ref-type="corresp" rid="btz336-cor1"/>
        <!--<email>zhng@umich.edu</email>-->
      </contrib>
    </contrib-group>
    <aff id="btz336-aff1"><label>1</label>School of Geographic and Biological Information, Nanjing University of Posts and Telecommunications, Nanjing, China</aff>
    <aff id="btz336-aff2"><label>2</label>Smart Health Big Data Analysis and Location Services Engineering Lab of Jiangsu Province, Nanjing University of Posts and Telecommunications, Nanjing, China</aff>
    <aff id="btz336-aff3"><label>3</label>School of Telecommunication and Information Engineering, Nanjing University of Posts and Telecommunications, Nanjing, China</aff>
    <aff id="btz336-aff4"><label>4</label>Department of Pharmacology, University of Michigan, Ann Arbor, MI, USA</aff>
    <aff id="btz336-aff5"><label>5</label>College of Computer and Information, Hohai University, Nanjing, China</aff>
    <aff id="btz336-aff6"><label>6</label>Jiangsu Key Laboratory of Drug Screening, China Pharmaceutical University, Nanjing, China</aff>
    <aff id="btz336-aff7"><label>7</label>Child Mental Health Research Center, Nanjing Brain Hospital, Nanjing Medical University, Nanjing, China</aff>
    <aff id="btz336-aff8"><label>8</label>Department of Computational Medicine and Bioinformatics, University of Michigan, Ann Arbor, MI, USA</aff>
    <aff id="btz336-aff9"><label>9</label>Department of Biological Chemistry, University of Michigan, Ann Arbor, MI, USA</aff>
    <author-notes>
      <corresp id="btz336-cor1">To whom correspondence should be addressed. <email>kexiaoyan@njmu.edu.cn</email> or <email>zhng@umich.edu</email></corresp>
    </author-notes>
    <pub-date pub-type="ppub">
      <month>7</month>
      <year>2019</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2019-07-05">
      <day>05</day>
      <month>7</month>
      <year>2019</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>05</day>
      <month>7</month>
      <year>2019</year>
    </pub-date>
    <!-- PMC Release delay is 0 months and 0 days and was based on the <pub-date pub-type="epub"/>. -->
    <volume>35</volume>
    <issue>14</issue>
    <fpage>i324</fpage>
    <lpage>i332</lpage>
    <permissions>
      <copyright-statement>© The Author(s) 2019. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2019</copyright-year>
      <license license-type="cc-by-nc" xlink:href="http://creativecommons.org/licenses/by-nc/4.0/">
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by-nc/4.0/">http://creativecommons.org/licenses/by-nc/4.0/</ext-link>), which permits non-commercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited. For commercial re-use, please contact journals.permissions@oup.com</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="btz336.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Motivation</title>
        <p>Accurate prediction and interpretation of ligand bioactivities are essential for virtual screening and drug discovery. Unfortunately, many important drug targets lack experimental data about the ligand bioactivities; this is particularly true for G protein-coupled receptors (GPCRs), which account for the targets of about a third of drugs currently on the market. Computational approaches with the potential of precise assessment of ligand bioactivities and determination of key substructural features which determine ligand bioactivities are needed to address this issue.</p>
      </sec>
      <sec id="s2">
        <title>Results</title>
        <p>A new method, SED, was proposed to predict ligand bioactivities and to recognize key substructures associated with GPCRs through the coupling of <bold>s</bold>creening for Lasso of long <bold>e</bold>xtended-connectivity fingerprints (ECFPs) with deep neural network training. The SED pipeline contains three successive steps: (i) representation of long ECFPs for ligand molecules, (ii) feature selection by screening for Lasso of ECFPs and (iii) bioactivity prediction through a deep neural network regression model. The method was examined on a set of 16 representative GPCRs that cover most subfamilies of human GPCRs, where each has 300–5000 ligand associations. The results show that SED achieves excellent performance in modelling ligand bioactivities, especially for those in the GPCR datasets without sufficient ligand associations, where SED improved the baseline predictors by 12% in correlation coefficient (<italic>r<sup>2</sup></italic>) and 19% in root mean square error. Detail data analyses suggest that the major advantage of SED lies on its ability to detect substructures from long ECFPs which significantly improves the predictive performance.</p>
      </sec>
      <sec id="s3">
        <title>Availability and implementation</title>
        <p>The source code and datasets of SED are freely available at <ext-link ext-link-type="uri" xlink:href="https://zhanglab.ccmb.med.umich.edu/SED/">https://zhanglab.ccmb.med.umich.edu/SED/</ext-link>.</p>
      </sec>
      <sec id="s4">
        <title>Supplementary information</title>
        <p><xref ref-type="supplementary-material" rid="sup1">Supplementary data</xref> are available at <italic>Bioinformatics</italic> online.</p>
      </sec>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <named-content content-type="funder-name">National Science Foundation of China</named-content>
          <named-content content-type="funder-identifier">10.13039/501100001809</named-content>
        </funding-source>
        <award-id>61872198</award-id>
        <award-id>81771478</award-id>
        <award-id>61571233</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <named-content content-type="funder-name">Natural Science Foundation of the Higher Education Institutions of Jiangsu Province</named-content>
        </funding-source>
        <award-id>18KJB416005</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <named-content content-type="funder-name">key University Science Research Project of Jiangsu Province</named-content>
        </funding-source>
        <award-id>17KJA510003</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <named-content content-type="funder-name">Natural Science Foundation of Nanjing University of Posts and Telecommunications</named-content>
        </funding-source>
        <award-id>NY218092</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <named-content content-type="funder-name">National Science Foundation</named-content>
          <named-content content-type="funder-identifier">10.13039/100000001</named-content>
        </funding-source>
        <award-id>DBI1564756</award-id>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="9"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 Introduction</title>
    <p>Drug discovery often begins with the screening of a high number of chemical compounds against a therapeutic protein target via biological high-throughput assays <italic>in vitro</italic>. Subsequently, leading hits are selected based on their bioactivities and optimized to make them stronger binders or more target selective (<xref rid="btz336-B20" ref-type="bibr">Unterthiner <italic>et al.</italic>, 2014</xref>). However, biological high-throughput assays and bioactivity determinations are usually time and labor intensive. Currently, only a small part of ‘available compounds’ can be synthesizable or available for drug design studies. Thus, it is not possible to employ experimental high-throughput screening assays to determine the bioactivities for all the compounds (<xref rid="btz336-B2" ref-type="bibr">Blum and Reymond, 2009</xref>), where computer-based virtual screening becomes an important complement to the experimental efforts.</p>
    <p>Virtual screening can be classified into receptor-based and ligand-based approaches (<xref rid="btz336-B5" ref-type="bibr">Cherkasov <italic>et al.</italic>, 2014</xref>). The receptor-based approaches screen compounds via simulating physical interactions between a drug target protein and known compounds, but they are only valid when the 3D structure of the biomolecular target is available (<xref rid="btz336-B3" ref-type="bibr">Ceretomassagué <italic>et al.</italic>, 2015</xref>). Ligand-based techniques learn the bioactivity of a compound acting with a target protein using known experimental data; of these, machine learning-based methods have been the most popular and widely applied in drug design (<xref rid="btz336-B3" ref-type="bibr">Ceretomassagué <italic>et al.</italic>, 2015</xref>). A common approach to the machine learning-based virtual screening is to build predictive models through the training on the fixed-length hand-crafted features. Recently, deep learning-based methods have witnessed impressive success in ligand-based virtual screening (<xref rid="btz336-B16" ref-type="bibr">Ramsundar <italic>et al.</italic>, 2017</xref>; <xref rid="btz336-B20" ref-type="bibr">Unterthiner <italic>et al.</italic>, 2014</xref>; <xref rid="btz336-B22" ref-type="bibr">Wallach <italic>et al.</italic>, 2015</xref>; <xref rid="btz336-B24" ref-type="bibr">Winkler and Le, 2017</xref>; <xref rid="btz336-B26" ref-type="bibr">Xu <italic>et al.</italic>, 2017</xref>). For instance, in 2012, Merck organized a challenge for the design of machine learning methods to model the bioactivities of ligands acting with target proteins, and methods using deep learning achieved the best performance. Later, <xref rid="btz336-B14" ref-type="bibr">Ma <italic>et al.</italic> (2015)</xref> proposed a deep neural net model for determining quantitative structure–activity relationships (QSARs), which demonstrated better performance than random forest models for most of the data they studied (<xref rid="btz336-B14" ref-type="bibr">Ma <italic>et al.</italic>, 2015</xref>). Most recently, we proposed a weighted deep learning algorithm that takes arbitrarily sized inputs and generates bioactivity predictions which are significantly more accurate than the control predictors with different molecular fingerprints and descriptors (<xref rid="btz336-B25" ref-type="bibr">Wu <italic>et al.</italic>, 2018</xref>).</p>
    <p>In addition to the accurate prediction of ligand bioactivities, comprehensive interpretation of predictors by precise identification of key substructures that control ligand bioactivities is equally important to the virtual screening and drug discovery studies. In this regard, the utilization of the extended-connectivity fingerprints (ECFPs), which are circular fingerprints whose features denote the presence or absence of particular substructures, have been shown beneficial to an accurate interpretation of ligand bioactivities (<xref rid="btz336-B17" ref-type="bibr">Rogers and Hahn, 2010</xref>). In addition, ECFPs have several useful features: (i) they do not need to be predefined and can code an infinite number of different molecular features, which is critical to the improvement of virtual screening performance; (ii) they can be rapidly calculated; and (iii) the ECFP algorithm can be tailored to produce different kinds of circular fingerprints, optimized for different usages.</p>
    <p>In order to precisely predict ligand bioactivities, long ECFPs are required for obtaining optimal performance. For instance, after removing rarely occurring features, Unterthiner <italic>et al.</italic> created a 43 000-dimensional ECFP vector, where the ECFP12 fingerprints (chemical substructures) with long dimensions were found ideal for representing compound properties in QSARs (<xref rid="btz336-B20" ref-type="bibr">Unterthiner <italic>et al.</italic>, 2014</xref>). More importantly, the use of long ECFPs can reduce the occurrence of bit collision, which helps determine more accurate substructures of each bit of the input compound molecule in feature retrieval (<xref rid="btz336-B17" ref-type="bibr">Rogers and Hahn, 2010</xref>). A drawback to the use of long ECFPs is, however, the requirement of greater computational and storage costs. Furthermore, the use of long fingerprints for compounds usually results in extremely sparse data, which may lead to the ‘Curse of Dimensionality’ (i.e. the drastic decrease in prediction performance) in many real-world ligand-based virtual screening campaigns, especially for drug targets without sufficient data. To the best of our knowledge, there have been no previous studies on the efficient utilization of long ECFPs in ligand-based virtual screening with the aim of improving the predictive performance of models and increasing the interpretability of experimental results.</p>
    <p>It is generally assumed that ligand bioactivity is determined by some local regions and is usually closely related to a small number of chemical substructures (<xref rid="btz336-B7" ref-type="bibr">Crisman <italic>et al.</italic>, 2008</xref>). Currently, one of the most popular methods to find the important and explainable substructures is through the least absolute shrinkage and selection operator (Lasso), which is a widely used regression technique for identifying sparse representations (<xref rid="btz336-B18" ref-type="bibr">Tibshirani, 1996</xref>). However, with high-dimensional ECFPs, the identification of relevant features by solving the Lasso problem remains challenging because it is computationally expensive and may not be possible to load the feature matrix into the main memory (<xref rid="btz336-B23" ref-type="bibr">Wang <italic>et al.</italic>, 2013</xref>). Fortunately, screening for Lasso helps quickly recognize irrelevant features that have zero components in the solution, and then ignores these in the optimization. Therefore, we can work on a reduced-feature matrix when dealing with the Lasso problem, which would result in substantial savings in computational cost and memory usage, as well as alleviating the ‘Curse of Dimensionality’. Moreover, the irrelevant features removed by screening for Lasso are guaranteed to have zero coefficients in the solution stage, so there is no loss of accuracy or optimality (<xref rid="btz336-B23" ref-type="bibr">Wang <italic>et al.</italic>, 2013</xref>).</p>
    <p>In this work, we describe a novel method that employs screening for Lasso of ECFPs and deep neural nets (SED) for predicting the bioactivities. Our focus will be on the ligands associated with G protein-coupled receptors (GPCRs), mainly because of their significant importance in drug discovery studies, where currently drugs targeting GPCRs account for ∼27% of the global therapeutic drugs market (<xref rid="btz336-B10" ref-type="bibr">Hauser <italic>et al.</italic>, 2017</xref>). For this purpose, we collect ligands from 16 human GPCR datasets that cover most families of human GPCRs. The testing results show that SED can achieve exceptional performance in terms of predicting ligand bioactivities. In particular, on datasets without sufficient ligand samples, the model performance exhibits a significant improvement just by adopting relevant ECFP features selected by screening for Lasso. If long ECFPs are used, further improvements can be observed. Moreover, in order to precisely interpret bioactivities of ligands interacting with the GPCRs, a case study was performed to examine key substructures which determine ligand bioactivities.</p>
    <p>There has been an unfortunate lack of open-source code for virtual screening tools, as most have been designed for commercial usage. In this work, a demonstration program including the source code and data was produced and released on our webserver for the benefit of academic usage. As a general Lasso screening method for long ECFPs and a deep neural network (DNN) model were adopted by our approach for predicting the bioactivities of ligand molecules, it is straightforward for users to design virtual screening models for their targets of interest. All SED code and data are freely available at <ext-link ext-link-type="uri" xlink:href="https://zhanglab.ccmb.med.umich.edu/SED/">https://zhanglab.ccmb.med.umich.edu/SED/</ext-link>.</p>
  </sec>
  <sec>
    <title>2 Datasets and methods</title>
    <sec>
      <title>2.1 Datasets</title>
      <p>We first downloaded the ‘all interaction data’ file from GLASS database (<ext-link ext-link-type="uri" xlink:href="http://zhanglab.ccmb.med.umich.edu/GLASS/">http://zhanglab.ccmb.med.umich.edu/GLASS/</ext-link>), which contains 533 470 unique GPCR–ligand interaction entries (<xref rid="btz336-B4" ref-type="bibr">Chan <italic>et al.</italic>, 2015</xref>). Entries with the match ‘Standard units=nM’ were retained, and GPCR–ligand pairs with multiple bioactivity values were replaced with their median value to reduce the influence of outliers. For each GPCR, an experimental dataset was built with active ligands, which contain the canonical SMILES strings and target-associated bioactivities of these ligands.</p>
      <p>For GPCR data, we downloaded the ‘7tmrlist’ file, which includes 3093 GPCRs, from the UniProt database (<ext-link ext-link-type="uri" xlink:href="http://www.uniprot.org/docs/7tmrlist">http://www.uniprot.org/docs/7tmrlist</ext-link>) (<xref rid="btz336-B19" ref-type="bibr">The UnitProt Consortium, 2008</xref>). After parsing this file, a total of 825 human GPCR proteins were found, of which only 55 had 3D structures available in the PDB (<xref rid="btz336-B1" ref-type="bibr">Berman <italic>et al.</italic>, 2000</xref>; <xref rid="btz336-B27" ref-type="bibr">Zhang <italic>et al.</italic>, 2015</xref>) (see also <ext-link ext-link-type="uri" xlink:href="https://zhanglab.ccmb.med.umich.edu/GPCR-EXP/">https://zhanglab.ccmb.med.umich.edu/GPCR-EXP/</ext-link>). Sixteen representative GPCRs without a solved structure, having at least 300 ligands, were selected as the experimental targets. These GPCRs are not homologous with each other with the maximum pair-wise sequence identity of 50% (for P0DMS8 and Q99835) and about 80% of pair-wise sequence identity is less than 30%. They cover four GPCR classes (A, B, C and F) and 13 subfamilies (see <xref ref-type="supplementary-material" rid="sup1">Supplementary Table S1</xref>). Other subfamilies with no or few experimental ligand associations were not considered because the lack of sufficient samples would preclude the construction of reliable models; these include, for instance, the subfamily ‘Sensory receptors’ in Class A, ‘Adhesion receptors’ in Class B, ‘Sensory receptors’ and ‘Orphan receptors’ in Class C, among others (<xref rid="btz336-B4" ref-type="bibr">Chan <italic>et al.</italic>, 2015</xref>; <xref rid="btz336-B12" ref-type="bibr">Isberg <italic>et al.</italic>, 2014</xref>). Such diversity of dataset selections is important for examining the generality of the models and to avoid cross-learning from homologous targets during the training process. As the raw bioactivity values of ligands span a large range, we adopted the p-bioactivity metric throughout this work. This is defined as <inline-formula id="IE1"><mml:math id="IM1"><mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mo> </mml:mo><mml:mtext>log</mml:mtext><mml:mo> </mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mn>10</mml:mn></mml:mrow></mml:msub><mml:mi>v</mml:mi></mml:mrow></mml:math></inline-formula>, where <inline-formula id="IE2"><mml:math id="IM2"><mml:mi>v</mml:mi></mml:math></inline-formula> is the raw bioactivity that can be evaluated using IC<sub>50</sub>, EC<sub>50</sub>, K<sub>i</sub>, K<sub>d</sub> and so on (<xref rid="btz336-B6" ref-type="bibr">Cortes-Ciriano, 2016</xref>). In our experimental datasets, the p-bioactivity ranges from −11 to 2.523, where smaller values indicate lower ligand activity.</p>
      <p>Some control ligands were added into each GPCR dataset to ensure more robust feature selection and regression models for ligand-based virtual screening. The control ligands, without association with the target GPCR, were randomly selected from the remaining subfamily irrelevant GPCR datasets, representing approximately 20% of the original ligands. As for the control ligands, the p-bioactivity was fixed to −11, which is the upper bound of all GPCR–ligand interaction entries in GLASS database. <xref ref-type="supplementary-material" rid="sup1">Supplementary Table S1</xref> presents a detailed description of the 16 GPCR datasets used in this work.</p>
    </sec>
    <sec>
      <title>2.2 Methods</title>
      <p>We propose a three-stage method to effectively screen key substructures from long ECFPs and then predict the bioactivities of ligands acting with GPCR targets. The proposed SED approach involves three steps: (i) ECFP generation, (ii) key substructure selection and (iii) bioactivity prediction using a DNN regression model (<xref ref-type="fig" rid="btz336-F1">Fig. 1</xref>).
</p>
      <fig id="btz336-F1" orientation="portrait" position="float">
        <label>Fig. 1.</label>
        <caption>
          <p>Schematic of SED. The approach is composed of three stages: long extended-connectivity fingerprint (ECFP) representation for ligand molecules, feature selection by screening for Lasso and construction of deep neural network regression prediction models</p>
        </caption>
        <graphic xlink:href="btz336f1"/>
      </fig>
      <sec>
        <title>2.2.1 Generation of extended-connectivity fingerprints</title>
        <p>ECFPs are among the most popular molecular fingerprints. Based on the Morgan algorithm (<xref rid="btz336-B15" ref-type="bibr">Morgan, 1965</xref>), they are highly suitable for the identification of the presence or absence of particular substructures and are often used for QSAR model building in the lead optimization process (<xref rid="btz336-B17" ref-type="bibr">Rogers and Hahn, 2010</xref>).</p>
        <p>The ECFP generation contains three steps: (i) initial assignment of atom identifiers, (ii) iterative update of identifiers and (iii) duplication removal (<xref rid="btz336-B17" ref-type="bibr">Rogers and Hahn, 2010</xref>) (also see <ext-link ext-link-type="uri" xlink:href="https://docs.chemaxon.com/">https://docs.chemaxon.com/</ext-link>). ECFP generation starts with the assignment of an initial integer identifier to every nonhydrogen atom of the input ligand molecule. This integer identifier catches some local information on the corresponding atom such that various properties (e.g. atomic number, connection count) are wrapped into a single identifier by a hash function. Several iterations are then implemented to merge the initial atom identifiers with those of neighbor atoms until a predefined diameter is reached. Each iteration captures a greater circular neighborhood around each atom and packs this into a single integer identifier through the appropriate hashing methods. The final stage of the generation process is to remove multiple identifier representations for identical atom neighborhoods. Here, two neighborhoods are treated as identical if they occupy the same set of chemical bonds or if their hashed integer identifiers are the same.</p>
        <p>In this study, ECFPs were generated using three key parameters: diameter, length and count (<xref rid="btz336-B17" ref-type="bibr">Rogers and Hahn, 2010</xref>) (also see <ext-link ext-link-type="uri" xlink:href="https://docs.chemaxon.com/">https://docs.chemaxon.com/</ext-link>). The diameter determines the maximum diameter of the circular neighborhoods employed for each atom. This is the main ECFP parameter, regulating the number and maximum size of the atom neighborhoods, and thus determines the length of the identifier list representation and the size of ‘1’ bits in the fixed-length string representation. The parameter ‘length’ defines the length of the bit string representation, whereas the parameter ‘count’ controls whether identical integer identifiers are saved with occurrence counts or kept only once. To decrease the likelihood of bit collision and information loss, the diameter was fixed to 12 in this study; the count was set to the default ‘No’ option, meaning that each identifier was stored only once. The ECFPs were generated by the program GenerateMD, which was authorized by the ChemAxon Ltd. with the free license for academic research.</p>
      </sec>
      <sec>
        <title>2.2.2 Feature selection</title>
        <p>Consider the ligand sample dataset <inline-formula id="IE3"><mml:math id="IM3"><mml:mrow><mml:mi>D</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, where <inline-formula id="IE4"><mml:math id="IM4"><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> represents the <italic>i</italic>th ligand molecule that takes the encoding ECFP of each molecule as input and <inline-formula id="IE5"><mml:math id="IM5"><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> denotes its p-bioactivity value.</p>
        <p>Lasso (<xref rid="btz336-B18" ref-type="bibr">Tibshirani, 1996</xref>) is widely used to obtain sparse data representations or predictive models. Standard Lasso takes the form
<disp-formula id="E1"><label>(1)</label><mml:math id="M1"><mml:mrow><mml:msup><mml:mrow><mml:mo>β</mml:mo></mml:mrow><mml:mo>*</mml:mo></mml:msup><mml:mo>=</mml:mo><mml:munder><mml:mrow><mml:mi>arg</mml:mi><mml:mi>min</mml:mi></mml:mrow><mml:mrow><mml:mo>β</mml:mo><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mi>p</mml:mi></mml:msup></mml:mrow></mml:munder><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac><mml:msubsup><mml:mrow><mml:mrow><mml:mrow><mml:mo>‖</mml:mo><mml:mrow><mml:mi>y</mml:mi><mml:mo>−</mml:mo><mml:mi>X</mml:mi><mml:mo>β</mml:mo></mml:mrow><mml:mo>‖</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mo>+</mml:mo><mml:mo>λ</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mrow><mml:mo>‖</mml:mo><mml:mo>β</mml:mo><mml:mo>‖</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></disp-formula>
where <inline-formula id="IE6"><mml:math id="IM6"><mml:mrow><mml:mi>X</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>⋅</mml:mo><mml:mo>⋅</mml:mo><mml:mo>⋅</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></inline-formula> is the <inline-formula id="IE7"><mml:math id="IM7"><mml:mrow><mml:mi>n</mml:mi><mml:mo>×</mml:mo><mml:mi>p</mml:mi></mml:mrow></mml:math></inline-formula> ECFP feature matrix, <inline-formula id="IE8"><mml:math id="IM8"><mml:mrow><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>⋅</mml:mo><mml:mo>⋅</mml:mo><mml:mo>⋅</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></inline-formula> is the p-bioactivity response vector, <inline-formula id="IE9"><mml:math id="IM9"><mml:mrow><mml:msup><mml:mrow><mml:mo>β</mml:mo></mml:mrow><mml:mo>*</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula> is the optimal sparse representation and <inline-formula id="IE10"><mml:math id="IM10"><mml:mrow><mml:mo>λ</mml:mo><mml:mo>≥</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> is the regularization parameter.</p>
        <p>When the dimension of the ECFP feature space is long, solving the Lasso problem may be challenging because we might not be able to read the data matrix into main memory. To solve large-scale Lasso problems efficiently, the standard Lasso can be written in its dual form (<xref rid="btz336-B23" ref-type="bibr">Wang <italic>et al.</italic>, 2013</xref>)
<disp-formula id="E2"><label>(2)</label><mml:math id="M2"><mml:mrow><mml:munder><mml:mrow><mml:mi>sup</mml:mi></mml:mrow><mml:mo>θ</mml:mo></mml:munder><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac><mml:msubsup><mml:mrow><mml:mrow><mml:mrow><mml:mo>‖</mml:mo><mml:mi>y</mml:mi><mml:mo>‖</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mn>2</mml:mn></mml:mfrac><mml:msubsup><mml:mrow><mml:mrow><mml:mrow><mml:mo>‖</mml:mo><mml:mrow><mml:mo>θ</mml:mo><mml:mo>−</mml:mo><mml:mfrac><mml:mi>y</mml:mi><mml:mo>λ</mml:mo></mml:mfrac></mml:mrow><mml:mo>‖</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mo>:</mml:mo><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mi>X</mml:mi><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mi>j</mml:mi><mml:mi>T</mml:mi></mml:msubsup><mml:mo>θ</mml:mo></mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mo>≤</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>p</mml:mi></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>
where <inline-formula id="IE11"><mml:math id="IM11"><mml:mo>θ</mml:mo></mml:math></inline-formula> denotes the dual variable and <inline-formula id="IE12"><mml:math id="IM12"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mi>X</mml:mi><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is the <italic>j</italic>th column of <italic>X</italic>. Let <inline-formula id="IE13"><mml:math id="IM13"><mml:mrow><mml:msubsup><mml:mrow><mml:mo>θ</mml:mo></mml:mrow><mml:mo>λ</mml:mo><mml:mo>*</mml:mo></mml:msubsup></mml:mrow></mml:math></inline-formula> be the optimal solution of (2) and <inline-formula id="IE14"><mml:math id="IM14"><mml:mrow><mml:msubsup><mml:mrow><mml:mo>β</mml:mo></mml:mrow><mml:mo>λ</mml:mo><mml:mo>*</mml:mo></mml:msubsup></mml:mrow></mml:math></inline-formula> be the optimal solution of (1). The Karush–Kuhn–Tucker (KKT) conditions are implemented by
<disp-formula id="E3"><label>(3)</label><mml:math id="M3"><mml:mrow><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mi>X</mml:mi><mml:msubsup><mml:mrow><mml:mo>β</mml:mo></mml:mrow><mml:mo>λ</mml:mo><mml:mo>*</mml:mo></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mo>λ</mml:mo><mml:mo>θ</mml:mo></mml:mrow></mml:mrow><mml:mo>λ</mml:mo><mml:mo>*</mml:mo></mml:msubsup></mml:mrow></mml:math></disp-formula><disp-formula id="E4"><label>(4)</label><mml:math id="M4"><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mo>θ</mml:mo></mml:mrow><mml:mo>λ</mml:mo><mml:mo>*</mml:mo></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:mrow><mml:mo stretchy="true">{</mml:mo><mml:mrow><mml:mtable><mml:mtr columnalign="left"><mml:mtd><mml:mrow><mml:mtext>sign</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msubsup><mml:mrow><mml:mo>β</mml:mo></mml:mrow><mml:mo>λ</mml:mo><mml:mo>*</mml:mo></mml:msubsup><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo> </mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mtext>if</mml:mtext><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msubsup><mml:mrow><mml:mo>β</mml:mo></mml:mrow><mml:mo>λ</mml:mo><mml:mo>*</mml:mo></mml:msubsup><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>≠</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">]</mml:mo><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mtext>if</mml:mtext><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msubsup><mml:mrow><mml:mo>β</mml:mo></mml:mrow><mml:mo>λ</mml:mo><mml:mo>*</mml:mo></mml:msubsup><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo> </mml:mo><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula>
where <inline-formula id="IE15"><mml:math id="IM15"><mml:mrow><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msubsup><mml:mrow><mml:mo>β</mml:mo></mml:mrow><mml:mo>λ</mml:mo><mml:mo>*</mml:mo></mml:msubsup><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> denotes the <italic>i</italic>th component of <inline-formula id="IE16"><mml:math id="IM16"><mml:mrow><mml:mo> </mml:mo><mml:msubsup><mml:mrow><mml:mo>β</mml:mo></mml:mrow><mml:mo>λ</mml:mo><mml:mo>*</mml:mo></mml:msubsup></mml:mrow></mml:math></inline-formula>. Considering the KKT condition in (4), the following rule holds: <inline-formula id="IE17"><mml:math id="IM17"><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mo>θ</mml:mo></mml:mrow><mml:mo>λ</mml:mo><mml:mo>*</mml:mo></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mo>&lt;</mml:mo><mml:mn>1</mml:mn><mml:mo>⇒</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mo>β</mml:mo></mml:mrow><mml:mo>λ</mml:mo><mml:mo>*</mml:mo></mml:msubsup></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>⇒</mml:mo><mml:msub><mml:mrow><mml:mo>β</mml:mo></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> denotes an inactive feature.</p>
        <p>The inactive features occupy the zero components in the optimal solution, <inline-formula id="IE18"><mml:math id="IM18"><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">β</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">λ</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">*</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula>, and can be discarded from the optimization without any sacrifice of the performance of the optimal value in the objective function (1). We refer to this approach as the Safe Screening Rules. SAFE (<xref rid="btz336-B9" ref-type="bibr">Ghaoui <italic>et al.</italic>, 2010</xref>) is an efficient safe screening method. In SAFE, the <italic>i</italic>th entry of <inline-formula id="IE19"><mml:math id="IM19"><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">β</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">λ</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">*</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula> is removed when
<disp-formula id="E5"><label>(5)</label><mml:math id="M5"><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mi>i</mml:mi><mml:mi>T</mml:mi></mml:msubsup><mml:mi>y</mml:mi></mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mo>&lt;</mml:mo><mml:mo>λ</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mrow><mml:mo>‖</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>‖</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:msub><mml:mrow><mml:mrow><mml:mrow><mml:mo>‖</mml:mo><mml:mi>y</mml:mi><mml:mo>‖</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mrow><mml:mi>max</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mo>λ</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mrow><mml:mi>max</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula>
where <inline-formula id="IE20"><mml:math id="IM20"><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mrow><mml:mi>max</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mtext>max</mml:mtext></mml:mrow></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo> </mml:mo><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mi>i</mml:mi><mml:mi>T</mml:mi></mml:msubsup><mml:mi>y</mml:mi></mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the maximal parameter value such that the solution is non-trivial. To fine tune the value of <inline-formula id="IE21"><mml:math id="IM21"><mml:mo>λ</mml:mo></mml:math></inline-formula>, methods such as cross-validation can be applied to the Lasso problem along with a sequence of parameters <inline-formula id="IE22"><mml:math id="IM22"><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>0</mml:mn></mml:msub><mml:mo> </mml:mo><mml:mo>&gt;</mml:mo><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo> </mml:mo></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:mo>…</mml:mo><mml:mo>&gt;</mml:mo><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mo>κ</mml:mo></mml:msub><mml:mo> </mml:mo></mml:mrow></mml:math></inline-formula>. However, this may be very time-consuming. Enhanced Dual Polytope Projection (EDPP) is a much more efficient form of safe screening rules (<xref rid="btz336-B23" ref-type="bibr">Wang <italic>et al.</italic>, 2013</xref>). An implementation of EDPP is available on GitHub: <ext-link ext-link-type="uri" xlink:href="http://dpc-screening.github.io/lasso.html">http://dpc-screening.github.io/lasso.html</ext-link>.</p>
        <p>Consequently, the reduced data matrix <inline-formula id="IE23"><mml:math id="IM23"><mml:mrow><mml:mover accent="true"><mml:mi>X</mml:mi><mml:mo>˜</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> can be optimized and the original problem (1) can be transformed into
<disp-formula id="E6"><label>(6)</label><mml:math id="M6"><mml:mrow><mml:msup><mml:mrow><mml:mover accent="true"><mml:mi>β</mml:mi><mml:mo>˜</mml:mo></mml:mover></mml:mrow><mml:mtext>*</mml:mtext></mml:msup><mml:mtext>=</mml:mtext><mml:munder><mml:mrow><mml:mi>arg</mml:mi><mml:mi>min</mml:mi></mml:mrow><mml:mover accent="true"><mml:mi>β</mml:mi><mml:mo>˜</mml:mo></mml:mover></mml:munder><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mn>2</mml:mn></mml:mfrac><mml:msubsup><mml:mrow><mml:mrow><mml:mrow><mml:mo>‖</mml:mo><mml:mrow><mml:mi>y</mml:mi><mml:mo>−</mml:mo><mml:mover accent="true"><mml:mi>X</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mover accent="true"><mml:mi>β</mml:mi><mml:mo>˜</mml:mo></mml:mover></mml:mrow><mml:mo>‖</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mo>+</mml:mo><mml:mtext>λ</mml:mtext><mml:msub><mml:mrow><mml:mrow><mml:mrow><mml:mo>‖</mml:mo><mml:mover accent="true"><mml:mi>β</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mo>‖</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></disp-formula>
where <inline-formula id="IE24"><mml:math id="IM24"><mml:mrow><mml:mover accent="true"><mml:mi>β</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mtext> </mml:mtext><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>, <inline-formula id="IE25"><mml:math id="IM25"><mml:mrow><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> is the number of zero components in <inline-formula id="IE26"><mml:math id="IM26"><mml:mrow><mml:msup><mml:mrow><mml:mo>β</mml:mo></mml:mrow><mml:mo>*</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula>, <inline-formula id="IE27"><mml:math id="IM27"><mml:mrow><mml:mover accent="true"><mml:mi>X</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo> </mml:mo><mml:mo>×</mml:mo><mml:mo> </mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>p</mml:mi><mml:mo> </mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mn>0</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>, <inline-formula id="IE28"><mml:math id="IM28"><mml:mrow><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></inline-formula> denotes the p-bioactivity responses, <inline-formula id="IE29"><mml:math id="IM29"><mml:mrow><mml:msup><mml:mrow><mml:mover accent="true"><mml:mi>β</mml:mi><mml:mo>˜</mml:mo></mml:mover></mml:mrow><mml:mtext>*</mml:mtext></mml:msup></mml:mrow></mml:math></inline-formula> is the optimal sparse representation, and <inline-formula id="IE30"><mml:math id="IM30"><mml:mrow><mml:mo>λ</mml:mo><mml:mo>≥</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> is the regularization parameter. Applying the Lasso solver from the SLEP package (<xref rid="btz336-B13" ref-type="bibr">Liu <italic>et al.</italic>, 2009</xref>) (<ext-link ext-link-type="uri" xlink:href="http://www.yelab.net/software/SLEP/">http://www.yelab.net/software/SLEP/</ext-link><underline>)</underline>, only a small subset of the original features are selected for use in the final model. This improves the prediction performance and interpretability of regression models.</p>
      </sec>
      <sec>
        <title>2.2.3 Deep neural network training</title>
        <p>A neural network model is a hierarchical network composed of multiple layers. The lowest layer takes the molecular descriptors as the model input, whereas the uppermost layer outputs the predicted activities. Between the two are one or more hidden layers, which form a very complicated nonlinear transformation from the input descriptors to the output variables. A DNN holds more than one hidden layer and can model complex relationships among the input descriptors.</p>
        <p>A standard DNN model is specified by three basic components (<xref rid="btz336-B11" ref-type="bibr">Haykin, 1994</xref>; <xref rid="btz336-B26" ref-type="bibr">Xu <italic>et al.</italic>, 2017</xref>). The first is the interconnections between layer nodes. These interconnections are weighted according to the strength of the relationship between nodes, and the input value for a node is a weighted sum of the output values of nodes in the previous layer. The second component is the activation function, which performs the nonlinear transfer of the weighted sum of input values to the output at each node. The final component of a neural network is the optimization scheme, which tunes the weights to best match the activities.</p>
        <p>The stage for updating the weight parameters is known as training and proceeds in an iterative fashion. During the optimization process, the weights are tuned to decrease the divergence between the prediction and the real bioactivity. For regression problems, the standard cost function for optimization is the mean square error (MSE). Because of the hierarchical structure of DNNs, the training process for reducing errors is usually called backpropagation. Because DNNs have many hyperparameters, it is time and labor intensive to implement the whole set of grid search. Since most previous studies on applying DNNs for ligand-based virtual screening optimized the adjustable weights in the neural network model, here we adopted the set of hyperparameter values that work well in similar tasks (<xref rid="btz336-B14" ref-type="bibr">Ma <italic>et al.</italic>, 2015</xref>). The settings are as follows: (i) the DNN has four hidden layers containing 4000, 2000, 1000 and 1000 nodes, respectively; (ii) the dropout rates in the DNN are 0% in the input layer, 25% in the first 3 hidden layers, and 10% in the last hidden layer; (iii) the activation function is the rectified linear unit (ReLU); (iv) no unsupervised pretraining is conducted, and the network weights were initialized as random small values; (v) the size of each mini-batch is 20 and the number of epochs is 200; and (vi) the parameters for the optimization step are fixed to their default values, i.e. the learning rate is 0.05, the momentum strength is 0.9 and the weight cost strength is 0.0001. The DNN model runs in Python, and the code is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/Merck/DeepNeuralNet-QSAR">https://github.com/Merck/ DeepNeuralNet-QSAR</ext-link>.</p>
      </sec>
    </sec>
    <sec>
      <title>2.3 Evaluation criterion</title>
      <p>In the Kaggle challenge organized by Merck in 2012, the correlation coefficient (<italic>r</italic><sup>2</sup>) was used to assess the performance of drug activity predictions. This metric is calculated as
<disp-formula id="E7"><label>(7)</label><mml:math id="M7"><mml:mrow><mml:msup><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="true">[</mml:mo><mml:mrow><mml:mstyle displaystyle="true"><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mover accent="true"><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo>¯</mml:mo></mml:mover><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:mrow><mml:mo stretchy="true">]</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mrow><mml:mstyle displaystyle="true"><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mstyle displaystyle="true"><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mover accent="true"><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo>¯</mml:mo></mml:mover><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula>
where <inline-formula id="IE31"><mml:math id="IM31"><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is the true activity, <inline-formula id="IE32"><mml:math id="IM32"><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> is the mean of the true activity, <inline-formula id="IE33"><mml:math id="IM33"><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is the predicted activity, <inline-formula id="IE34"><mml:math id="IM34"><mml:mover accent="true"><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo>¯</mml:mo></mml:mover></mml:math></inline-formula> is the mean of the predicted activity and <italic>n</italic> is the number of ligand molecules in the dataset. The larger the value of <italic>r</italic><sup>2</sup>, the better the prediction performance.</p>
      <p>A common metric for evaluating regression models is the root mean square error (RMSE), given by
<disp-formula id="E8"><label>(8)</label><mml:math id="M8"><mml:mrow><mml:mtext>RMSE</mml:mtext><mml:mo>=</mml:mo><mml:msqrt><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>n</mml:mi></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mrow></mml:msqrt></mml:mrow></mml:math></disp-formula>
where <inline-formula id="IE35"><mml:math id="IM35"><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE36"><mml:math id="IM36"><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> are the true and predicted activity values, respectively, and <italic>n</italic> is the number of ligand molecules. The smaller the RMSE value, the better the prediction performance.</p>
      <p>To remove the influence of random selection, three sets of control ligands were collected for each GPCR dataset, and the regression model for predicting the ligand bioactivities was trained separately. The mean criterion value of the three models was designated as the final result. Moreover, the Wilcoxon signed-rank test was performed to verify the statistical significance between the performance of the compared methods.</p>
    </sec>
  </sec>
  <sec>
    <title>3 Results and discussion</title>
    <sec>
      <title>3.1 Performance of top features selected from various ECFPs</title>
      <p>We compared the ligand bioactivity prediction performance after feature selection from various sizes of ECFPs. Full-length ECFPs with 1024 bits were used to build the baseline prediction model. All regression models were implemented by DNN. For different sizes of ECFPs, the top 300 dimensions, ranked by the Lasso weight values, were used to construct DNN regression models. The GPCR datasets were divided into two groups according to their number of ligand samples. Datasets with sufficient samples (more than 600) formed Group I, whereas those with insufficient samples (≤600) formed Group II (details are given in the ‘# of ligands’ column in <xref ref-type="supplementary-material" rid="sup1">Supplementary Table S1</xref>).</p>
      <p>The results show that, when the number of ligand samples is sufficient (Group I), baseline methods perform well on all GPCR datasets (<italic>r</italic><sup>2</sup>: 0.9224 ± 0.0181; RMSE: 1.1693 ± 0.1351). Indeed, after feature selection, there is no significant difference between the performance of models based on the top 300 features (<italic>r</italic><sup>2</sup>: 0.9186 ± 0.0189; RMSE: 1.2812 ± 0.2455) and the baseline methods (Wilcoxon signed-rank test, two-tailed <italic>P</italic>-value = 0.0663) (<xref rid="btz336-T1" ref-type="table">Table 1</xref>). With long ECFPs, the performance of the regression models improved on most GPCR data after feature selection. For example, with 10 240 bits, the Group I GPCR datasets give <italic>r</italic><sup>2</sup> = 0.9267 ± 0.0273 and RMSE = 1.099 ± 0.1834. When there are insufficient ligand samples in a GPCR dataset (Group II), the performance of the baseline method is often poor (<italic>r</italic><sup>2</sup>: 0.7943 ± 0.1020; RMSE: 1.5655 ± 0.2868). In this case, after feature selection, the performance of models based on the top 300 features exhibits significant improvements (<italic>r</italic><sup>2</sup>: 0.8358 ± 0.0807; RMSE: 1.4110 ± 0.2444). Using long ECFPs, the models achieve further improvements in performance when using the top 300 features, with the average improvement on <italic>r<sup>2</sup></italic> of 12% and RMSE of 19% against the baseline predictors. In addition, we further consider the effect of the size of ligand samples in the GPCR datasets on model performance. The results show that, after feature selection for the baseline methods, the improvement in <italic>r</italic><sup>2</sup> on the GPCR datasets of Group II is significantly better than that of Group I (Group I: −0.0026 ± 0.0073; Group II: 0.0572 ± 0.0556) (<xref ref-type="supplementary-material" rid="sup1">Supplementary Fig. S1A</xref>). Using long ECFPs (based on the best results, highlighted in boldface in <xref rid="btz336-T1" ref-type="table">Table 1</xref>), the improvement in <italic>r</italic><sup>2</sup> on the GPCR datasets of Group II was again significantly better that of Group I after feature selection (Group I: 0.0093 ± 0.0084; Group II: 0.0554 ± 0.0653) (<xref ref-type="supplementary-material" rid="sup1">Supplementary Fig. S1B</xref>). These results show that our SED method can improve performance on datasets without sufficient ligand samples.</p>
      <table-wrap id="btz336-T1" orientation="portrait" position="float">
        <label>Table 1.</label>
        <caption>
          <p>Performance of deep neural networks with top features selected from various sizes of long ECFPs</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="2" colspan="1">Group<xref ref-type="table-fn" rid="tblfn1"><sup>a</sup></xref></th>
              <th rowspan="2" colspan="1">GPCRs</th>
              <th rowspan="2" colspan="1">EC<xref ref-type="table-fn" rid="tblfn2"><sup>b</sup></xref></th>
              <th rowspan="1" colspan="1">Baseline<xref ref-type="table-fn" rid="tblfn3"><sup>c</sup></xref><hr/></th>
              <th colspan="5" rowspan="1">Top 300 features selected from various sizes<hr/></th>
            </tr>
            <tr>
              <th rowspan="1" colspan="1">1024</th>
              <th rowspan="1" colspan="1">1024</th>
              <th rowspan="1" colspan="1">5120</th>
              <th rowspan="1" colspan="1">10 240</th>
              <th rowspan="1" colspan="1">51 200</th>
              <th rowspan="1" colspan="1">102 400</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="18" colspan="1">I</td>
              <td rowspan="2" colspan="1">P08908</td>
              <td rowspan="1" colspan="1"><italic>r</italic><sup>2</sup> (↑)</td>
              <td rowspan="1" colspan="1">0.9268</td>
              <td rowspan="1" colspan="1">0.9249</td>
              <td rowspan="1" colspan="1">0.9310</td>
              <td rowspan="1" colspan="1">
                <bold>0.9314</bold>
              </td>
              <td rowspan="1" colspan="1">0.9227</td>
              <td rowspan="1" colspan="1">0.9127</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">RMSE(↓)</td>
              <td rowspan="1" colspan="1">1.0483</td>
              <td rowspan="1" colspan="1">1.0878</td>
              <td rowspan="1" colspan="1">0.9968</td>
              <td rowspan="1" colspan="1">
                <bold>0.9879</bold>
              </td>
              <td rowspan="1" colspan="1">1.0636</td>
              <td rowspan="1" colspan="1">1.0982</td>
            </tr>
            <tr>
              <td rowspan="2" colspan="1">Q9Y5N1</td>
              <td rowspan="1" colspan="1"><italic>r</italic><sup>2</sup> (↑)</td>
              <td rowspan="1" colspan="1">0.9513</td>
              <td rowspan="1" colspan="1">0.9464</td>
              <td rowspan="1" colspan="1">0.9468</td>
              <td rowspan="1" colspan="1">
                <bold>0.9598</bold>
              </td>
              <td rowspan="1" colspan="1">0.9272</td>
              <td rowspan="1" colspan="1">0.921</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">RMSE(↓)</td>
              <td rowspan="1" colspan="1">1.0218</td>
              <td rowspan="1" colspan="1">0.9627</td>
              <td rowspan="1" colspan="1">0.9748</td>
              <td rowspan="1" colspan="1">
                <bold>0.9486</bold>
                <xref ref-type="table-fn" rid="tblfn4">
                  <sup>d</sup>
                </xref>
              </td>
              <td rowspan="1" colspan="1">1.0827</td>
              <td rowspan="1" colspan="1">1.0889</td>
            </tr>
            <tr>
              <td rowspan="2" colspan="1">P28335</td>
              <td rowspan="1" colspan="1"><italic>r</italic><sup>2</sup> (↑)</td>
              <td rowspan="1" colspan="1">0.9096</td>
              <td rowspan="1" colspan="1">0.9066</td>
              <td rowspan="1" colspan="1">0.8989</td>
              <td rowspan="1" colspan="1">
                <bold>0.9095</bold>
              </td>
              <td rowspan="1" colspan="1">0.8983</td>
              <td rowspan="1" colspan="1">0.8903</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">RMSE(↓)</td>
              <td rowspan="1" colspan="1">1.1475</td>
              <td rowspan="1" colspan="1">1.1335</td>
              <td rowspan="1" colspan="1">1.1533</td>
              <td rowspan="1" colspan="1">
                <bold>1.1184</bold>
              </td>
              <td rowspan="1" colspan="1">1.1549</td>
              <td rowspan="1" colspan="1">1.1723</td>
            </tr>
            <tr>
              <td rowspan="2" colspan="1">P35372</td>
              <td rowspan="1" colspan="1"><italic>r</italic><sup>2</sup> (↑)</td>
              <td rowspan="1" colspan="1">0.9034</td>
              <td rowspan="1" colspan="1">0.8968</td>
              <td rowspan="1" colspan="1">0.8966</td>
              <td rowspan="1" colspan="1">0.8954</td>
              <td rowspan="1" colspan="1">0.8796</td>
              <td rowspan="1" colspan="1">0.8814</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">RMSE(↓)</td>
              <td rowspan="1" colspan="1">1.2931</td>
              <td rowspan="1" colspan="1">1.3478</td>
              <td rowspan="1" colspan="1">1.1616</td>
              <td rowspan="1" colspan="1">
                <bold>1.1547</bold>
              </td>
              <td rowspan="1" colspan="1">1.2367</td>
              <td rowspan="1" colspan="1">1.2384</td>
            </tr>
            <tr>
              <td rowspan="2" colspan="1">Q99705</td>
              <td rowspan="1" colspan="1"><italic>r</italic><sup>2</sup> (↑)</td>
              <td rowspan="1" colspan="1">0.9389</td>
              <td rowspan="1" colspan="1">0.931</td>
              <td rowspan="1" colspan="1">0.9393</td>
              <td rowspan="1" colspan="1">
                <bold>0.9436</bold>
              </td>
              <td rowspan="1" colspan="1">0.9295</td>
              <td rowspan="1" colspan="1">0.9327</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">RMSE(↓)</td>
              <td rowspan="1" colspan="1">1.1132</td>
              <td rowspan="1" colspan="1">1.2236</td>
              <td rowspan="1" colspan="1">0.9649</td>
              <td rowspan="1" colspan="1">
                <bold>0.8928</bold>
                <xref ref-type="table-fn" rid="tblfn4">
                  <sup>d</sup>
                </xref>
              </td>
              <td rowspan="1" colspan="1">0.9464<xref ref-type="table-fn" rid="tblfn4"><sup>d</sup></xref></td>
              <td rowspan="1" colspan="1">0.9351<xref ref-type="table-fn" rid="tblfn4"><sup>d</sup></xref></td>
            </tr>
            <tr>
              <td rowspan="2" colspan="1">P0DMS8</td>
              <td rowspan="1" colspan="1"><italic>r</italic><sup>2</sup> (↑)</td>
              <td rowspan="1" colspan="1">0.8937</td>
              <td rowspan="1" colspan="1">0.8859</td>
              <td rowspan="1" colspan="1">0.8864</td>
              <td rowspan="1" colspan="1">
                <bold>0.8938</bold>
              </td>
              <td rowspan="1" colspan="1">0.8781</td>
              <td rowspan="1" colspan="1">0.8555</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">RMSE(↓)</td>
              <td rowspan="1" colspan="1">1.1979</td>
              <td rowspan="1" colspan="1">1.2348</td>
              <td rowspan="1" colspan="1">1.1987</td>
              <td rowspan="1" colspan="1">
                <bold>1.1907</bold>
              </td>
              <td rowspan="1" colspan="1">1.2572</td>
              <td rowspan="1" colspan="1">1.3375</td>
            </tr>
            <tr>
              <td rowspan="2" colspan="1">Q16602</td>
              <td rowspan="1" colspan="1"><italic>r</italic><sup>2</sup> (↑)</td>
              <td rowspan="1" colspan="1">0.9268</td>
              <td rowspan="1" colspan="1">0.9326</td>
              <td rowspan="1" colspan="1">0.9514<xref ref-type="table-fn" rid="tblfn4"><sup>d</sup></xref></td>
              <td rowspan="1" colspan="1">
                <bold>0.9533</bold>
                <xref ref-type="table-fn" rid="tblfn4">
                  <sup>d</sup>
                </xref>
              </td>
              <td rowspan="1" colspan="1">0.9516<xref ref-type="table-fn" rid="tblfn4"><sup>d</sup></xref></td>
              <td rowspan="1" colspan="1">0.9527<xref ref-type="table-fn" rid="tblfn4"><sup>d</sup></xref></td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">RMSE(↓)</td>
              <td rowspan="1" colspan="1">1.2783</td>
              <td rowspan="1" colspan="1">1.8135</td>
              <td rowspan="1" colspan="1">1.6057</td>
              <td rowspan="1" colspan="1">1.4746</td>
              <td rowspan="1" colspan="1">1.4675</td>
              <td rowspan="1" colspan="1">1.3730</td>
            </tr>
            <tr>
              <td rowspan="2" colspan="1">P51677</td>
              <td rowspan="1" colspan="1"><italic>r</italic><sup>2</sup> (↑)</td>
              <td rowspan="1" colspan="1">0.9329</td>
              <td rowspan="1" colspan="1">0.9216</td>
              <td rowspan="1" colspan="1">0.9338</td>
              <td rowspan="1" colspan="1">
                <bold>0.9405 </bold>
              </td>
              <td rowspan="1" colspan="1">0.9211</td>
              <td rowspan="1" colspan="1">0.9161</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">RMSE(↓)</td>
              <td rowspan="1" colspan="1">1.0194</td>
              <td rowspan="1" colspan="1">1.2781</td>
              <td rowspan="1" colspan="1">1.0674</td>
              <td rowspan="1" colspan="1">1.0280</td>
              <td rowspan="1" colspan="1">1.0048</td>
              <td rowspan="1" colspan="1">1.0989</td>
            </tr>
            <tr>
              <td rowspan="2" colspan="1">P48039</td>
              <td rowspan="1" colspan="1"><italic>r</italic><sup>2</sup> (↑)</td>
              <td rowspan="1" colspan="1">0.9180</td>
              <td rowspan="1" colspan="1">0.9209</td>
              <td rowspan="1" colspan="1">0.9108</td>
              <td rowspan="1" colspan="1">0.9147</td>
              <td rowspan="1" colspan="1">0.9126</td>
              <td rowspan="1" colspan="1">0.908</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">RMSE(↓)</td>
              <td rowspan="1" colspan="1">1.4047</td>
              <td rowspan="1" colspan="1">1.4495</td>
              <td rowspan="1" colspan="1">1.4607</td>
              <td rowspan="1" colspan="1">
                <bold>1.3635</bold>
              </td>
              <td rowspan="1" colspan="1">1.3699</td>
              <td rowspan="1" colspan="1">1.3831</td>
            </tr>
            <tr>
              <td rowspan="14" colspan="1">II</td>
              <td rowspan="2" colspan="1">Q9H228</td>
              <td rowspan="1" colspan="1"><italic>r</italic><sup>2</sup> (↑)</td>
              <td rowspan="1" colspan="1">0.8152</td>
              <td rowspan="1" colspan="1">0.8636<xref ref-type="table-fn" rid="tblfn4"><sup>d</sup></xref></td>
              <td rowspan="1" colspan="1">0.8789<xref ref-type="table-fn" rid="tblfn4"><sup>d</sup></xref></td>
              <td rowspan="1" colspan="1">0.8870<xref ref-type="table-fn" rid="tblfn4"><sup>d</sup></xref></td>
              <td rowspan="1" colspan="1">
                <bold>0.9100</bold>
                <xref ref-type="table-fn" rid="tblfn4">
                  <sup>d</sup>
                </xref>
              </td>
              <td rowspan="1" colspan="1">0.8942<xref ref-type="table-fn" rid="tblfn4"><sup>d</sup></xref></td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">RMSE(↓)</td>
              <td rowspan="1" colspan="1">1.6521</td>
              <td rowspan="1" colspan="1">1.3965<xref ref-type="table-fn" rid="tblfn4"><sup>d</sup></xref></td>
              <td rowspan="1" colspan="1">1.5009</td>
              <td rowspan="1" colspan="1">1.372<xref ref-type="table-fn" rid="tblfn4"><sup>d</sup></xref></td>
              <td rowspan="1" colspan="1">
                <bold>1.3231</bold>
                <xref ref-type="table-fn" rid="tblfn4">
                  <sup>d</sup>
                </xref>
              </td>
              <td rowspan="1" colspan="1">1.3239<xref ref-type="table-fn" rid="tblfn4"><sup>d</sup></xref></td>
            </tr>
            <tr>
              <td rowspan="2" colspan="1">Q8TDU6</td>
              <td rowspan="1" colspan="1"><italic>r</italic><sup>2</sup> (↑)</td>
              <td rowspan="1" colspan="1">0.8830</td>
              <td rowspan="1" colspan="1">0.9124</td>
              <td rowspan="1" colspan="1">
                <bold>0.9329</bold>
                <xref ref-type="table-fn" rid="tblfn4">
                  <sup>d</sup>
                </xref>
              </td>
              <td rowspan="1" colspan="1">0.9206<xref ref-type="table-fn" rid="tblfn4"><sup>d</sup></xref></td>
              <td rowspan="1" colspan="1">0.9165<xref ref-type="table-fn" rid="tblfn4"><sup>d</sup></xref></td>
              <td rowspan="1" colspan="1">0.9077</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">RMSE(↓)</td>
              <td rowspan="1" colspan="1">1.3289</td>
              <td rowspan="1" colspan="1">1.1804</td>
              <td rowspan="1" colspan="1">
                <bold>1.0253</bold>
                <xref ref-type="table-fn" rid="tblfn4">
                  <sup>d</sup>
                </xref>
              </td>
              <td rowspan="1" colspan="1">1.0906<xref ref-type="table-fn" rid="tblfn4"><sup>d</sup></xref></td>
              <td rowspan="1" colspan="1">1.1056<xref ref-type="table-fn" rid="tblfn4"><sup>d</sup></xref></td>
              <td rowspan="1" colspan="1">1.1713</td>
            </tr>
            <tr>
              <td rowspan="2" colspan="1">Q8TDS4</td>
              <td rowspan="1" colspan="1"><italic>r</italic><sup>2</sup> (↑)</td>
              <td rowspan="1" colspan="1">0.9154</td>
              <td rowspan="1" colspan="1">0.9262</td>
              <td rowspan="1" colspan="1">0.929</td>
              <td rowspan="1" colspan="1">0.9222</td>
              <td rowspan="1" colspan="1">
                <bold>0.9378</bold>
                <xref ref-type="table-fn" rid="tblfn4">
                  <sup>d</sup>
                </xref>
              </td>
              <td rowspan="1" colspan="1">0.9348<xref ref-type="table-fn" rid="tblfn4"><sup>d</sup></xref></td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">RMSE(↓)</td>
              <td rowspan="1" colspan="1">1.0707</td>
              <td rowspan="1" colspan="1">1.0445</td>
              <td rowspan="1" colspan="1">1.1328</td>
              <td rowspan="1" colspan="1">1.1051</td>
              <td rowspan="1" colspan="1">
                <bold>0.9567</bold>
                <xref ref-type="table-fn" rid="tblfn4">
                  <sup>d</sup>
                </xref>
              </td>
              <td rowspan="1" colspan="1">0.9906</td>
            </tr>
            <tr>
              <td rowspan="2" colspan="1">Q9HC97</td>
              <td rowspan="1" colspan="1"><italic>r</italic><sup>2</sup> (↑)</td>
              <td rowspan="1" colspan="1">0.6047</td>
              <td rowspan="1" colspan="1">0.7097<xref ref-type="table-fn" rid="tblfn4"><sup>d</sup></xref></td>
              <td rowspan="1" colspan="1">0.7649<xref ref-type="table-fn" rid="tblfn4"><sup>d</sup></xref></td>
              <td rowspan="1" colspan="1">
                <bold>0.8508</bold>
                <xref ref-type="table-fn" rid="tblfn4">
                  <sup>d</sup>
                </xref>
              </td>
              <td rowspan="1" colspan="1">0.8264<xref ref-type="table-fn" rid="tblfn4"><sup>d</sup></xref></td>
              <td rowspan="1" colspan="1">0.7801<xref ref-type="table-fn" rid="tblfn4"><sup>d</sup></xref></td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">RMSE(↓)</td>
              <td rowspan="1" colspan="1">1.7889</td>
              <td rowspan="1" colspan="1">1.5855<xref ref-type="table-fn" rid="tblfn4"><sup>d</sup></xref></td>
              <td rowspan="1" colspan="1">1.6228<xref ref-type="table-fn" rid="tblfn4"><sup>d</sup></xref></td>
              <td rowspan="1" colspan="1">1.3631<xref ref-type="table-fn" rid="tblfn4"><sup>d</sup></xref></td>
              <td rowspan="1" colspan="1">1.3282<xref ref-type="table-fn" rid="tblfn4"><sup>d</sup></xref></td>
              <td rowspan="1" colspan="1">1.4242<xref ref-type="table-fn" rid="tblfn4"><sup>d</sup></xref></td>
            </tr>
            <tr>
              <td rowspan="2" colspan="1">P41180</td>
              <td rowspan="1" colspan="1"><italic>r</italic><sup>2</sup> (↑)</td>
              <td rowspan="1" colspan="1">0.7784</td>
              <td rowspan="1" colspan="1">0.7916</td>
              <td rowspan="1" colspan="1">0.8253<xref ref-type="table-fn" rid="tblfn4"><sup>d</sup></xref></td>
              <td rowspan="1" colspan="1">
                <bold>0.8435</bold>
                <xref ref-type="table-fn" rid="tblfn4">
                  <sup>d</sup>
                </xref>
              </td>
              <td rowspan="1" colspan="1">0.8029</td>
              <td rowspan="1" colspan="1">0.8217<xref ref-type="table-fn" rid="tblfn4"><sup>d</sup></xref></td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">RMSE(↓)</td>
              <td rowspan="1" colspan="1">1.9226</td>
              <td rowspan="1" colspan="1">1.7581</td>
              <td rowspan="1" colspan="1">1.7082</td>
              <td rowspan="1" colspan="1">
                <bold>1.5410</bold>
                <xref ref-type="table-fn" rid="tblfn4">
                  <sup>d</sup>
                </xref>
              </td>
              <td rowspan="1" colspan="1">1.5869<xref ref-type="table-fn" rid="tblfn4"><sup>d</sup></xref></td>
              <td rowspan="1" colspan="1">1.5510<xref ref-type="table-fn" rid="tblfn4"><sup>d</sup></xref></td>
            </tr>
            <tr>
              <td rowspan="2" colspan="1">Q14833</td>
              <td rowspan="1" colspan="1"><italic>r</italic><sup>2</sup> (↑)</td>
              <td rowspan="1" colspan="1">0.7429</td>
              <td rowspan="1" colspan="1">0.7682</td>
              <td rowspan="1" colspan="1">
                <bold>0.7947</bold>
                <xref ref-type="table-fn" rid="tblfn4">
                  <sup>d</sup>
                </xref>
              </td>
              <td rowspan="1" colspan="1">0.7743<xref ref-type="table-fn" rid="tblfn4"><sup>d</sup></xref></td>
              <td rowspan="1" colspan="1">0.7424</td>
              <td rowspan="1" colspan="1">0.7302</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">RMSE(↓)</td>
              <td rowspan="1" colspan="1">1.6512</td>
              <td rowspan="1" colspan="1">1.5453</td>
              <td rowspan="1" colspan="1">
                <bold>1.4635</bold>
                <xref ref-type="table-fn" rid="tblfn4">
                  <sup>d</sup>
                </xref>
              </td>
              <td rowspan="1" colspan="1">1.4754<xref ref-type="table-fn" rid="tblfn4"><sup>d</sup></xref></td>
              <td rowspan="1" colspan="1">1.6216</td>
              <td rowspan="1" colspan="1">1.6719</td>
            </tr>
            <tr>
              <td rowspan="2" colspan="1">Q99835</td>
              <td rowspan="1" colspan="1"><italic>r</italic><sup>2</sup> (↑)</td>
              <td rowspan="1" colspan="1">0.8203</td>
              <td rowspan="1" colspan="1">0.8790<xref ref-type="table-fn" rid="tblfn4"><sup>d</sup></xref></td>
              <td rowspan="1" colspan="1">0.892<xref ref-type="table-fn" rid="tblfn4"><sup>d</sup></xref></td>
              <td rowspan="1" colspan="1">0.8933<xref ref-type="table-fn" rid="tblfn4"><sup>d</sup></xref></td>
              <td rowspan="1" colspan="1">0.8999<xref ref-type="table-fn" rid="tblfn4"><sup>d</sup></xref></td>
              <td rowspan="1" colspan="1">
                <bold>0.9028</bold>
                <xref ref-type="table-fn" rid="tblfn4">
                  <sup>d</sup>
                </xref>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">RMSE(↓)</td>
              <td rowspan="1" colspan="1">1.5439</td>
              <td rowspan="1" colspan="1">1.3669</td>
              <td rowspan="1" colspan="1">1.1953<xref ref-type="table-fn" rid="tblfn4"><sup>d</sup></xref></td>
              <td rowspan="1" colspan="1">1.1924<xref ref-type="table-fn" rid="tblfn4"><sup>d</sup></xref></td>
              <td rowspan="1" colspan="1">1.155<xref ref-type="table-fn" rid="tblfn4"><sup>d</sup></xref></td>
              <td rowspan="1" colspan="1">
                <bold>1.1239</bold>
                <xref ref-type="table-fn" rid="tblfn4">
                  <sup>d</sup>
                </xref>
              </td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn1">
            <label>a</label>
            <p>Group I: original number of ligands &gt;600; II: original number of ligands ≤600.</p>
          </fn>
          <fn id="tblfn2">
            <label>b</label>
            <p>Evaluation Criterion: ↑ (↓) indicates that larger (smaller) values are better; the best results for each evaluation criterion are highlighted in boldface.</p>
          </fn>
          <fn id="tblfn3">
            <label>c</label>
            <p>Baseline: full-length ECFPs with 1024 bits.</p>
          </fn>
          <fn id="tblfn4">
            <label>d</label>
            <p>Indicates that the performance of the method using the top 300 ECFP features selected from various ECFPs is significantly better than that of the baseline methods based on Wilcoxon signed-rank test.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p>When the number of ligand samples in a GPCR dataset is sufficient, the baseline method usually performs well, and it is difficult to obtain further improvement. This is because the dimension of the ECFPs used in the baseline methods is only 1024, too small for any obvious ‘Curse of Dimensionality’ problems, and therefore the performance will not be significantly improved after feature selection. When long ECFPs are used, the model performance can be improved because more comprehensive information is captured by including more substructures. When the number of ligand samples is insufficient, the baseline methods perform poorly on most GPCR datasets. This is because the ‘Curse of Dimensionality’ probably exists in the baseline methods when 1024-bit ECFPs are used, as this is greater than the number of ligand samples in each dataset. When the most irrelevant features are removed via feature selection, the prediction performance improved significantly, which suggests that the bioactivity of a ligand is related to relatively few substructures. Moreover, when using long ECFPs, the model performance would be further improved by feature selection because more comprehensive information can be captured by the inclusion of larger and more substructures.</p>
    </sec>
    <sec>
      <title>3.2 Influence of regression models</title>
      <p>We investigated the dependence of SED on the regression model and applied Gradient Boosting Decision Tree (GBDT), Support Vector Regression (SVR), Random Forest (RF) and DNN to the GPCR datasets. The input of each regression model was the top 300 features selected from the optimal bits of the ECFPs. For each GPCR dataset, the optimal bit is the ECFP length corresponding to the optimal result (highlighted in boldface in <xref rid="btz336-T1" ref-type="table">Table 1</xref>). The optimal parameters of the RF, GBDT and SVR models were obtained through three-fold cross-validation with a standard grid search method, and the optimal model was evaluated by addressing the mean of <italic>r<sup>2</sup></italic> value of three-fold cross-validation. Specifically, for RF, the number of trees in the forest is set to 1000, and the number of features to consider at each split is set to ‘sqrt’. For GBDT, the learning rate is set to 0.1, and the number of boosting stages to perform is set to 1000. For SVR, the ‘rbf’ kernel type is used, and the gamma is set to 0.2.</p>
      <p><xref ref-type="fig" rid="btz336-F2">Figure 2</xref> shows a head-to-head comparison of SED implementations with different regression models, where the same training and validation datasets in the cross validation have been used. Here, a lower RMSE or higher <italic>r<sup>2</sup></italic> value indicates better model performance. The results show that the DNN regression models achieve an optimal performance with all GPCR datasets and evaluations, with a mean <italic>r<sup>2</sup></italic> value of 0.8913 which is 0.047, 0.1147 and 0.0597 higher than that of RF, GBDT and SVR, and a mean RMSE value of 1.1847 which is of 0.0425, 0.1510 and 0.0919 lower than that of RF, GBDT and SVR, respectively (see <xref ref-type="fig" rid="btz336-F2">Fig. 2</xref> and <xref ref-type="supplementary-material" rid="sup1">Supplementary Table S2</xref>). In addition, the <italic>r<sup>2</sup></italic> value of DNN statistically significantly better than that of the runner-up method RF (with the two-tailed <italic>P</italic>-value = 0.0004 in the Wilcoxon signed-rank test). Thus, the DNNregression model was employed in SED because of its robust performance.
</p>
      <fig id="btz336-F2" orientation="portrait" position="float">
        <label>Fig. 2.</label>
        <caption>
          <p>Effect of regression model on performance. GBDT, Gradient Boosting Decision Tree; SVR, Support Vector Regression; RF, Random Forest; DNN, deep neural network. (<bold>A</bold>): P08908; (<bold>B</bold>): Q9Y5N1; (<bold>C</bold>): P28335; (<bold>D</bold>): P35372; (<bold>E</bold>): Q99705; (<bold>F</bold>): P0DMS8; (<bold>G</bold>): Q16602; (<bold>H</bold>): P51677; (<bold>I</bold>): P48039; (<bold>J</bold>): Q9H228; (<bold>K</bold>): Q8TDU6; (<bold>L</bold>): Q8TDS4; (<bold>M</bold>): Q9HC97; (<bold>N</bold>): P41180; (<bold>O</bold>): Q14833; (<bold>P</bold>): Q99835</p>
        </caption>
        <graphic xlink:href="btz336f2"/>
      </fig>
      <p>In <xref ref-type="supplementary-material" rid="sup1">Supplementary Table S3</xref>, we present a comparison of SED with WDL-RF, which was previously developed for modeling ligand bioactivities by combining weighted network learning and random forest regression (<xref rid="btz336-B25" ref-type="bibr">Wu <italic>et al.</italic>, 2018</xref>). Here, the input to WDL-RF is in the format of canonical SMILES and the bioactivity values of compounds, where the default parameters of the WDL-RF program are adopted, that is the number of module units (<italic>L</italic>) is set to 4, and <inline-formula id="IE37"><mml:math id="IM37"><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">estimates</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo></mml:math></inline-formula>100 and <inline-formula id="IE38"><mml:math id="IM38"><mml:mi mathvariant="normal">ma</mml:mi><mml:msub><mml:mrow><mml:mi mathvariant="normal">x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">features</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi mathvariant="normal">'</mml:mi><mml:mi mathvariant="normal">sqrt</mml:mi><mml:mi mathvariant="normal">'</mml:mi></mml:math></inline-formula> in the random forest regression. The results show that the SED models achieve a better performance with all GPCR datasets and evaluations: the mean <italic>r<sup>2</sup></italic> value is 0.907 which is 0.243 higher than that by WDL-RF, and the mean RMSE value is 1.185 which is of 0.239 lower than that of WDL-RF (see <xref ref-type="supplementary-material" rid="sup1">Supplementary Table S3</xref>). The main reason for the better performance of SED over WDL-RF is that SED adopts long molecular fingerprints, with the maximum of 102 400 bits, whereas WDL-RF employs short molecular fingerprints, with only 50 bits.</p>
    </sec>
    <sec>
      <title>3.3 Effect of number of selected features</title>
      <p>We now examine how the prediction of ligand bioactivities is affected by the number of features selected (<italic>K</italic>), where the features are ranked in order of weight values returned by Lasso. In this paper, we compare the predicted ligand bioactivities given by <italic>K</italic> = 50, 100, 300, and 600. For each GPCR dataset, the optimal bit is the ECFP length corresponding to the optimal result (highlighted in boldface in <xref rid="btz336-T1" ref-type="table">Table 1</xref>).</p>
      <p>The results show that the model performance based on the top 300 features is better than that based on both the top 50 features and top 100 features on all GPCR datasets (<xref ref-type="fig" rid="btz336-F3">Fig. 3</xref>). Moreover, the <italic>r<sup>2</sup></italic> values given by using the top 300 features significantly better than those based on the top 50 features (Wilcoxon signed-rank test, two-tailed <italic>P</italic>-value &lt; 0.05) on the vast majority of GPCR datasets (14/16), and also obviously superior to those based on the top 100 features (Wilcoxon signed-rank test, two-tailed <italic>P</italic>-value &lt; 0.05) on most GPCR datasets (9/16) (<xref ref-type="fig" rid="btz336-F3">Fig. 3</xref>). Moreover, the <italic>r<sup>2</sup></italic> values based on the top 300 features are better than those based on the top 600 features on the majority of GPCR datasets (9/16) (<xref ref-type="fig" rid="btz336-F3">Fig. 3</xref>). Thus, the default value of <italic>K</italic> was set to 300 in this study.
</p>
      <fig id="btz336-F3" orientation="portrait" position="float">
        <label>Fig. 3.</label>
        <caption>
          <p>Dependence of SED performance on the number of selected features. (<bold>A</bold>): P08908; (<bold>B</bold>): Q9Y5N1; (<bold>C</bold>): P28335; (<bold>D</bold>): P35372; (<bold>E</bold>): Q99705; (<bold>F</bold>): P0DMS8; (<bold>G</bold>): Q16602; (<bold>H</bold>): P51677; (<bold>I</bold>): P48039; (<bold>J</bold>): Q9H228; (<bold>K</bold>): Q8TDU6; (<bold>L</bold>): Q8TDS4; (<bold>M</bold>): Q9HC97; (<bold>N</bold>): P41180; (<bold>O</bold>): Q14833; (<bold>P</bold>): Q99835</p>
        </caption>
        <graphic xlink:href="btz336f3"/>
      </fig>
    </sec>
    <sec>
      <title>3.4 Correlation analysis of selected features</title>
      <p>To further verify the effect of feature selection, we performed correlation analysis. For each selected feature, we calculated the Pearson correlation coefficient (PCC) between their values and the ligand bioactivities. A positive value indicates a positive correlation, and vice versa. The greater the absolute value, the stronger the correlation. Here, we focused on the absolute values of the PCCs and considered the top 300 features identified by sparse screening and Lasso (marked as ‘T300’ in <xref ref-type="fig" rid="btz336-F4">Fig. 4</xref>). For comparison, another group of 300 features were randomly selected from all dimensions of the ECFPs (marked as ‘R300’ in <xref ref-type="fig" rid="btz336-F4">Fig. 4</xref>). The boxes in <xref ref-type="fig" rid="btz336-F4">Figure 4</xref> indicate the distribution of PCCs of the top 300 and random 300 features on each GPCR dataset. The results show that the absolute values of PCCs for the top 300 features are significantly different from those for the random 300 features (Wilcoxon signed-rank test, two-tailed <italic>P</italic>-value &lt; 0.01). On all GPCR datasets, the mean absolute value of the PCCs for the top 300 features was 0.1537, much higher than that of the random 300 features (0.0333). As a comparison, we also display the data based on the top 100 and 50 features (marked as ‘T100’ and ‘T50’ in <xref ref-type="fig" rid="btz336-F4">Fig. 4</xref>). The result shows that the average PCCs for top 100 (0.2074) and top 50 (0.2530) features are slightly higher than that of top 300, but they generally have a larger fluctuation (indicating a lower reliability) than the top 300 ones. Overall, PCCs by all top 300, 100 and 50 features are significantly higher (with <italic>P</italic>-value &lt; 0.01) than the randomly selected top 300 features, suggesting that our selected features by sparse screening and Lasso are effective and feasible.
</p>
      <fig id="btz336-F4" orientation="portrait" position="float">
        <label>Fig. 4.</label>
        <caption>
          <p>Pearson correlation analysis of selected features. T300, T100 and T50: The top 300, 100 and 50 features identified by screening for Lasso. R300: the 300 features randomly selected from all dimensions of the ECFPs. (<bold>A</bold>): P08908; (<bold>B</bold>): Q9Y5N1; (<bold>C</bold>): P28335; (<bold>D</bold>): P35372; (<bold>E</bold>): Q99705; (<bold>F</bold>): P0DMS8; (<bold>G</bold>): Q16602; (<bold>H</bold>): P51677; (<bold>I</bold>): P48039; (<bold>J</bold>): Q9H228; (<bold>K</bold>): Q8TDU6; (<bold>L</bold>): Q8TDS4; (<bold>M</bold>): Q9HC97; (<bold>N</bold>): P41180; (<bold>O</bold>): Q14833; (<bold>P</bold>): Q99835</p>
        </caption>
        <graphic xlink:href="btz336f4"/>
      </fig>
    </sec>
    <sec>
      <title>3.5 Case study</title>
      <p>Sphingosine 1-phosphate receptor 5 (S1PR5) is a GPCR which binds the lipid-signaling molecule sphingosine 1-phosphate. Its agonists have been proposed as an innovative mechanism for the treatment of neurodegenerative disorders (such as Alzheimer’s disease) and lysosomal storage disorders (such as Niemann–Pick disease) (<xref rid="btz336-B21" ref-type="bibr">van der Kam <italic>et al.</italic>, 2014</xref>). As shown in <xref ref-type="supplementary-material" rid="sup1">Supplementary Table S1</xref>, the S1PR5 dataset contains 320 original and 60 control ligand samples. As indicated in <xref rid="btz336-T2" ref-type="table">Table 2</xref>, the regression performance based on the top 300 features is improved significantly when feature selection was applied to the baseline method, which is then improved further when long ECFPs were used. Using 51 200 bits, the model achieved improvements on 12% in <italic>r<sup>2</sup></italic> and 20% in RMSE compared with the baseline method.</p>
      <table-wrap id="btz336-T2" orientation="portrait" position="float">
        <label>Table 2.</label>
        <caption>
          <p>Top 50 substructures identified by SED along with the associated Pearson correlation coefficients</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
          </colgroup>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">
                <inline-graphic xlink:href="btz336ilf1.jpg"/>
              </td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
      <p>Screening for Lasso issued by SED is to identify the key substructures of ECFPs that affect ligand bioactivities. Visualization and correlation analysis of the key substructures which determine ligand bioactivities is important for understanding GPCR–ligand interactions and designing new drugs. The JChem Suite of ChemAxon (<xref rid="btz336-B8" ref-type="bibr">Csizmadia, 2000</xref>) provides a lookup service for the substructures encoded in ECFP fingerprints. Its ‘ECFPFeatureLookup’ class retrieves substructures corresponding to a given integer identifier or bit position. The program MarvinView was used to visualize substructures. The top 50 substructures identified by SED are presented in <xref rid="btz336-T2" ref-type="table">Table 2</xref>, and the top 51–300 substructures are presented in <xref ref-type="supplementary-material" rid="sup1">Supplementary Table S4</xref>, along with the associated PCCs between the attribute values of each dimension and ligand bioactivities. The top substructures have the potential of guiding further optimization of lead compounds by constructing new and better ligand molecules.</p>
    </sec>
  </sec>
  <sec>
    <title>4 Conclusions</title>
    <p>We have developed a novel method, SED, which combines the screening for Lasso of ECFPs with DNNs to predict the bioactivities of GPCR-associated ligand molecules. The method is comprised of three consecutive steps: (i) generation of long ECFPs for ligand samples, (ii) feature selection by screening for Lasso of ECFPs and (iii) bioactivity prediction using a DNN regression model. Large-scale benchmark tests show that SED can generate excellent bioactivity predictions from various datasets. Using GPCR datasets without sufficient ligand samples, the regression model performance exhibits significant improvements by simply adopting the relevant ECFP features selected by screening for Lasso; if long ECFPs are used, the performance can be further improved. The results indicate that the SED method can quickly remove irrelevant features, resulting in a reduced feature matrix for the Lasso problem. This may lead to substantial reductions in computational cost and memory usage, as well as greatly alleviate the potential for the ‘Curse of Dimensionality’. In addition, a visualized study was examined to clearly explore key substructures which determine bioactivities of ligand molecular acting with GPCRs for accurate understanding the experimental results.</p>
    <p>At present, the relationship between ligand binding and biology remains unclear. In this regard, the SED method can help to quickly screen key substructures that determine ligand bioactivities. Current results have showed that further improvement can be achieved by models based on the top identified substructures, especially for GPCRs datasets without sufficient ligand samples. Moreover, PCCs between their values and the ligand bioactivities were calculated for each selected feature, where the top substructures tend to have a higher correlation with bioactivity values. These analyses can help provide a better understanding of the success of the SED method, and the top substructures are likely to be new and correct in the context of the machine learning experiment. Ideally, the best and reliable choice for the model controls is to validate the method through biomedical experiments, where the next important work is to apply the SED model to virtual screening for specific drug targets. The work along this line is currently in progress.</p>
    <p>The SED source code and datasets are freely available at <ext-link ext-link-type="uri" xlink:href="https://zhanglab.ccmb.med.umich.edu/SED/">https://zhanglab.ccmb.med.umich.edu/SED/</ext-link>, with the code usage provided in <xref ref-type="supplementary-material" rid="sup1">Supplementary Text S1</xref>.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material content-type="local-data" id="sup1">
      <label>btz336_Supplementary_Data</label>
      <media xlink:href="btz336_supplementary_data.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ack id="ack1">
    <title>Acknowledgement</title>
    <p>We thank the ChemAxon Ltd. to provide the free license of the ChemAxon softwares for academic research.</p>
    <sec>
      <title>Funding</title>
      <p>This work was supported, in part, by the National Science Foundation of China [61872198, 81771478 and 61571233]; the Natural Science Foundation of the Higher Education Institutions of Jiangsu Province [18KJB416005]; the key University Science Research Project of Jiangsu Province [17KJA510003]; the Natural Science Foundation of Nanjing University of Posts and Telecommunications [NY218092]; and the National Science Foundation [DBI1564756].</p>
      <p><italic>Conflict of Interest</italic>: none declared.</p>
    </sec>
  </ack>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="btz336-B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Berman</surname><given-names>H.M.</given-names></name></person-group><etal>et al</etal> (<year>2000</year>) 
<article-title>The Protein Data Bank</article-title>. <source>Nucleic Acids Res</source>., <volume>28</volume>, <fpage>235</fpage>–<lpage>242</lpage>.<pub-id pub-id-type="pmid">10592235</pub-id></mixed-citation>
    </ref>
    <ref id="btz336-B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Blum</surname><given-names>L.C.</given-names></name>, <name name-style="western"><surname>Reymond</surname><given-names>J.L.</given-names></name></person-group> (<year>2009</year>) 
<article-title>970 million druglike small molecules for virtual screening in the chemical universe database GDB-13</article-title>. <source>J. Am. Chem. Soc</source>., <volume>131</volume>, <fpage>8732.</fpage><pub-id pub-id-type="pmid">19505099</pub-id></mixed-citation>
    </ref>
    <ref id="btz336-B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Ceretomassagué</surname><given-names>A.</given-names></name></person-group><etal>et al</etal> (<year>2015</year>) 
<article-title>Molecular fingerprint similarity search in virtual screening</article-title>. <source>Methods</source>, <volume>71</volume>, <fpage>58</fpage>–<lpage>63</lpage>.<pub-id pub-id-type="pmid">25132639</pub-id></mixed-citation>
    </ref>
    <ref id="btz336-B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Chan</surname><given-names>W.K.</given-names></name></person-group><etal>et al</etal> (<year>2015</year>) 
<article-title>GLASS: a comprehensive database for experimentally validated GPCR–ligand associations</article-title>. <source>Bioinformatics</source>, <volume>31</volume>, <fpage>3035</fpage>–<lpage>3042</lpage>.<pub-id pub-id-type="pmid">25971743</pub-id></mixed-citation>
    </ref>
    <ref id="btz336-B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Cherkasov</surname><given-names>A.</given-names></name></person-group><etal>et al</etal> (<year>2014</year>) 
<article-title>QSAR modeling: where have you been? Where are you going to?</article-title><source>J. Med. Chem</source>., <volume>57</volume>, <fpage>4977.</fpage><pub-id pub-id-type="pmid">24351051</pub-id></mixed-citation>
    </ref>
    <ref id="btz336-B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Cortes-Ciriano</surname><given-names>I.</given-names></name></person-group> (<year>2016</year>) 
<article-title>Benchmarking the predictive power of ligand efficiency indices in QSAR</article-title>. <source>J. Chem. Inform. Model</source>., <volume>56</volume>, <fpage>1576.</fpage></mixed-citation>
    </ref>
    <ref id="btz336-B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Crisman</surname><given-names>T.J.</given-names></name></person-group><etal>et al</etal> (<year>2008</year>) 
<article-title>Ligand-target interaction-based weighting of substructures for virtual screening</article-title>. <source>J. Chem. Inform. Model</source>., <volume>48</volume>, <fpage>1955</fpage>–<lpage>1964</lpage>.</mixed-citation>
    </ref>
    <ref id="btz336-B8">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Csizmadia</surname><given-names>F.</given-names></name></person-group> (<year>2000</year>) 
<article-title>JChem: Java applets and modules supporting chemical database handling from web browsers</article-title>. <source>J. Chem. Inform. Comput. Sci</source>., <volume>40</volume>, <fpage>323</fpage>–<lpage>324</lpage>.</mixed-citation>
    </ref>
    <ref id="btz336-B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Ghaoui</surname><given-names>E.</given-names></name></person-group><etal>et al</etal> (<year>2010</year>) 
<article-title>Safe feature elimination in sparse supervised learning</article-title>. <source>Pacific J. Optim</source>., <volume>8</volume>, <fpage>667</fpage>–<lpage>698</lpage>.</mixed-citation>
    </ref>
    <ref id="btz336-B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Hauser</surname><given-names>A.S.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) 
<article-title>Trends in GPCR drug discovery: new agents, targets and indications</article-title>. <source>Nat. Rev. Drug Discov</source>., <volume>16</volume>, <fpage>829</fpage>–<lpage>842</lpage>.<pub-id pub-id-type="pmid">29075003</pub-id></mixed-citation>
    </ref>
    <ref id="btz336-B11">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Haykin</surname><given-names>S.</given-names></name></person-group> (<year>1994</year>) <source>Neural Networks: A Comprehensive Foundation</source>. 
<publisher-name>Prentice Hall PTR</publisher-name>, 
<publisher-loc>Upper Saddle River, New Jersey</publisher-loc>, pp. <fpage>71</fpage>–<lpage>80</lpage>.</mixed-citation>
    </ref>
    <ref id="btz336-B12">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Isberg</surname><given-names>V.</given-names></name></person-group><etal>et al</etal> (<year>2014</year>) 
<article-title>GPCRDB: an information system for G protein-coupled receptors</article-title>. <source>Nucleic Acids Res</source>., <volume>42</volume>, <fpage>D422.</fpage><pub-id pub-id-type="pmid">24304901</pub-id></mixed-citation>
    </ref>
    <ref id="btz336-B13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Liu</surname><given-names>J.</given-names></name></person-group><etal>et al</etal> (<year>2009</year>) <source>SLEP: Sparse Learning with Efficient Projections</source>. Arizona State Univ., Tempe, AZ, USA.</mixed-citation>
    </ref>
    <ref id="btz336-B14">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Ma</surname><given-names>J.</given-names></name></person-group><etal>et al</etal> (<year>2015</year>) 
<article-title>Deep neural nets as a method for quantitative structure–activity relationships</article-title>. <source>J. Chem. Inform. Model</source>., <volume>55</volume>, <fpage>263</fpage>–<lpage>274</lpage>.</mixed-citation>
    </ref>
    <ref id="btz336-B15">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Morgan</surname><given-names>H.L.</given-names></name></person-group> (<year>1965</year>) 
<article-title>The generation of a unique machine description for chemical structures - a technique developed at Chemical Abstracts Service</article-title>. <source>J. Chem. Document</source>., <volume>5</volume>, <fpage>107</fpage>–<lpage>113</lpage>.</mixed-citation>
    </ref>
    <ref id="btz336-B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Ramsundar</surname><given-names>B.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) 
<article-title>Is multitask deep learning practical for pharma?</article-title><source>J. Chem. Inform. Model</source>., <volume>57</volume>, <fpage>2068</fpage>–<lpage>2076</lpage>.</mixed-citation>
    </ref>
    <ref id="btz336-B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Rogers</surname><given-names>D.</given-names></name>, <name name-style="western"><surname>Hahn</surname><given-names>M.</given-names></name></person-group> (<year>2010</year>) 
<article-title>Extended-connectivity fingerprints</article-title>. <source>J. Chem. Inform. Model</source>., <volume>50</volume>, <fpage>742</fpage>–<lpage>754</lpage>.</mixed-citation>
    </ref>
    <ref id="btz336-B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Tibshirani</surname><given-names>R.</given-names></name></person-group> (<year>1996</year>) 
<article-title>Regression shrinkage and selection via the lasso</article-title>. <source>J. R. Statist. Soc. Ser. B Methodol</source>., <volume>58</volume>, <fpage>267</fpage>–<lpage>288</lpage>.</mixed-citation>
    </ref>
    <ref id="btz336-B19">
      <mixed-citation publication-type="journal">The UnitProt Consortium (<year>2008</year>) 
<article-title>The Universal Protein Resource</article-title>. <source>Nucleic Acids Res</source>., <volume>35</volume>, <fpage>193</fpage>–<lpage>197</lpage>.</mixed-citation>
    </ref>
    <ref id="btz336-B20">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Unterthiner</surname><given-names>T.</given-names></name></person-group><etal>et al</etal> (<year>2014</year>) 
<article-title>Deep learning as an opportunity in virtual screening</article-title>. In: <source>Proceedings of the Deep Learning Workshop at NIPS, Montreal, Canada</source>, pp. <fpage>1</fpage>–<lpage>9</lpage>.</mixed-citation>
    </ref>
    <ref id="btz336-B21">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Van der Kam</surname><given-names>E.</given-names></name></person-group><etal>et al</etal> (<year>2014</year>) 
<article-title>The use of selective sphingosine-1-phosphate receptor 5 agonists for the treatment of neurodegenerative disorders such as Alzheimer's disease and lysosomal storage diseases such as Niemann-Pick c disease</article-title>. <source>Alzheimer’s Dement. J. Alzheimer’s Assoc</source>., <volume>10</volume>, <fpage>P281.</fpage></mixed-citation>
    </ref>
    <ref id="btz336-B22">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Wallach</surname><given-names>I.</given-names></name></person-group><etal>et al</etal> (<year>2015</year>) 
<article-title>AtomNet: a deep convolutional neural network for bioactivity prediction in structure-based drug discovery</article-title>. <source>Mathemat. Z</source>., <volume>47</volume>, <fpage>34</fpage>–<lpage>46</lpage>.</mixed-citation>
    </ref>
    <ref id="btz336-B23">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Wang</surname><given-names>J.</given-names></name></person-group><etal>et al</etal> (<year>2013</year>) 
<article-title>Lasso screening rules via dual polytope projection</article-title>. <source>Adv. Neural Inform. Process. Syst</source>., <fpage>1070</fpage>–<lpage>1078</lpage>.</mixed-citation>
    </ref>
    <ref id="btz336-B24">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Winkler</surname><given-names>D.A.</given-names></name>, <name name-style="western"><surname>Le</surname><given-names>T.C.</given-names></name></person-group> (<year>2017</year>) 
<article-title>Performance of deep and shallow neural networks, the universal approximation theorem, activity cliffs, and QSAR</article-title>. <source>Mol. Inform</source>., <volume>36</volume>, <fpage>1</fpage>–<lpage>2</lpage>.</mixed-citation>
    </ref>
    <ref id="btz336-B25">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Wu</surname><given-names>J.</given-names></name></person-group><etal>et al</etal> (<year>2018</year>) 
<article-title>WDL-RF: predicting bioactivities of ligand molecules acting with G protein-coupled receptors by combining weighted deep learning and random forest</article-title>. <source>Bioinformatics</source>, <volume>34</volume>, <fpage>2271</fpage>–<lpage>2282</lpage>.<pub-id pub-id-type="pmid">29432522</pub-id></mixed-citation>
    </ref>
    <ref id="btz336-B26">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Xu</surname><given-names>Y.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) 
<article-title>Demystifying multitask deep neural networks for quantitative structure–activity relationships</article-title>. <source>J. Chem. Inform. Model</source>., <volume>57</volume>, <fpage>2490</fpage>–<lpage>2504</lpage>.</mixed-citation>
    </ref>
    <ref id="btz336-B27">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Zhang</surname><given-names>J.</given-names></name></person-group><etal>et al</etal> (<year>2015</year>) 
<article-title>GPCR-I-TASSER: a Hybrid approach to G protein-coupled receptor structure modeling and the application to the human genome</article-title>. <source>Structure</source>, <volume>23</volume>, <fpage>1538</fpage>–<lpage>1549</lpage>.<pub-id pub-id-type="pmid">26190572</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
