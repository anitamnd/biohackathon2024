<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-archivearticle1.dtd?>
<?SourceDTD.Version 1.1?>
<?ConverterInfo.XSLTName jp2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">PLoS One</journal-id>
    <journal-id journal-id-type="iso-abbrev">PLoS ONE</journal-id>
    <journal-id journal-id-type="publisher-id">plos</journal-id>
    <journal-id journal-id-type="pmc">plosone</journal-id>
    <journal-title-group>
      <journal-title>PLoS ONE</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1932-6203</issn>
    <publisher>
      <publisher-name>Public Library of Science</publisher-name>
      <publisher-loc>San Francisco, CA USA</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">4504710</article-id>
    <article-id pub-id-type="publisher-id">PONE-D-15-14166</article-id>
    <article-id pub-id-type="doi">10.1371/journal.pone.0132868</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Research Article</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>elPrep: High-Performance Preparation of Sequence Alignment/Map Files for Variant Calling</article-title>
      <alt-title alt-title-type="running-head">elPrep: High-Performance Preparation of Sequence Alignment/Map Files</alt-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" equal-contrib="yes">
        <name>
          <surname>Herzeel</surname>
          <given-names>Charlotte</given-names>
        </name>
        <xref ref-type="aff" rid="aff001">
          <sup>1</sup>
        </xref>
        <xref ref-type="aff" rid="aff005">
          <sup>5</sup>
        </xref>
        <xref ref-type="corresp" rid="cor001">*</xref>
      </contrib>
      <contrib contrib-type="author" equal-contrib="yes">
        <name>
          <surname>Costanza</surname>
          <given-names>Pascal</given-names>
        </name>
        <xref ref-type="aff" rid="aff002">
          <sup>2</sup>
        </xref>
        <xref ref-type="aff" rid="aff005">
          <sup>5</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Decap</surname>
          <given-names>Dries</given-names>
        </name>
        <xref ref-type="aff" rid="aff003">
          <sup>3</sup>
        </xref>
        <xref ref-type="aff" rid="aff005">
          <sup>5</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Fostier</surname>
          <given-names>Jan</given-names>
        </name>
        <xref ref-type="aff" rid="aff003">
          <sup>3</sup>
        </xref>
        <xref ref-type="aff" rid="aff005">
          <sup>5</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Reumers</surname>
          <given-names>Joke</given-names>
        </name>
        <xref ref-type="aff" rid="aff004">
          <sup>4</sup>
        </xref>
        <xref ref-type="aff" rid="aff005">
          <sup>5</sup>
        </xref>
      </contrib>
    </contrib-group>
    <aff id="aff001">
      <label>1</label>
      <addr-line>Imec, Leuven, Belgium</addr-line>
    </aff>
    <aff id="aff002">
      <label>2</label>
      <addr-line>Intel Corporation, Leuven, Belgium</addr-line>
    </aff>
    <aff id="aff003">
      <label>3</label>
      <addr-line>Department of Information Technology, Ghent University—iMinds, Ghent, Belgium</addr-line>
    </aff>
    <aff id="aff004">
      <label>4</label>
      <addr-line>Janssen Research &amp; Development, a division of Janssen Pharmaceutica NV, Beerse, Belgium</addr-line>
    </aff>
    <aff id="aff005">
      <label>5</label>
      <addr-line>ExaScience Life Lab, Leuven, Belgium</addr-line>
    </aff>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Antoniewski</surname>
          <given-names>Christophe</given-names>
        </name>
        <role>Editor</role>
        <xref ref-type="aff" rid="edit1"/>
      </contrib>
    </contrib-group>
    <aff id="edit1">
      <addr-line>CNRS UMR7622 &amp; University Paris 6 Pierre-et-Marie-Curie, FRANCE</addr-line>
    </aff>
    <author-notes>
      <fn fn-type="COI-statement" id="coi001">
        <p><bold>Competing Interests: </bold>The authors have the following interests: This work is funded in part by Intel and Janssen Pharmaceutica. Charlotte Herzeel is an employee of IMEC vzw, Belgium; Pascal Costanza is an employee of Intel Corporation NV/SA, Belgium; Dries Decap and Jan Fostier are employees of iMinds vzw, Ghent, Belgium; Joke Reumers is an employee of Janssen Pharmaceutica NV/SA, Belgium. All authors are also affiliated with ExaScience Life Lab which is a consortium of companies and universities. There are no patents, products in development or marketed products to declare. This does not alter the authors’ adherence to all the PLOS ONE policies on sharing data and materials.</p>
      </fn>
      <fn fn-type="con" id="contrib001">
        <p>Conceived and designed the experiments: CH PC JR. Performed the experiments: CH PC. Analyzed the data: CH PC DD JF JR. Contributed reagents/materials/analysis tools: JR PC. Wrote the paper: CH PC DD JF JR. Designed and implemented the tool presented in the paper: CH PC.</p>
      </fn>
      <corresp id="cor001">* E-mail: <email>Charlotte.Herzeel@imec.be</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <year>2015</year>
    </pub-date>
    <pub-date pub-type="epub">
      <day>16</day>
      <month>7</month>
      <year>2015</year>
    </pub-date>
    <volume>10</volume>
    <issue>7</issue>
    <elocation-id>e0132868</elocation-id>
    <history>
      <date date-type="received">
        <day>1</day>
        <month>4</month>
        <year>2015</year>
      </date>
      <date date-type="accepted">
        <day>18</day>
        <month>6</month>
        <year>2015</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© 2015 Herzeel et al</copyright-statement>
      <copyright-year>2015</copyright-year>
      <copyright-holder>Herzeel et al</copyright-holder>
      <license xlink:href="http://creativecommons.org/licenses/by/4.0/">
        <license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are properly credited.</license-p>
      </license>
    </permissions>
    <self-uri content-type="pdf" xlink:type="simple" xlink:href="pone.0132868.pdf"/>
    <abstract>
      <p>elPrep is a high-performance tool for preparing sequence alignment/map files for variant calling in sequencing pipelines. It can be used as a replacement for SAMtools and Picard for preparation steps such as filtering, sorting, marking duplicates, reordering contigs, and so on, while producing identical results. What sets elPrep apart is its software architecture that allows executing preparation pipelines by making only a single pass through the data, no matter how many preparation steps are used in the pipeline. elPrep is designed as a multithreaded application that runs entirely in memory, avoids repeated file I/O, and merges the computation of several preparation steps to significantly speed up the execution time. For example, for a preparation pipeline of five steps on a whole-exome BAM file (NA12878), we reduce the execution time from about 1:40 hours, when using a combination of SAMtools and Picard, to about 15 minutes when using elPrep, while utilising the same server resources, here 48 threads and 23GB of RAM. For the same pipeline on whole-genome data (NA12878), elPrep reduces the runtime from 24 hours to less than 5 hours. As a typical clinical study may contain sequencing data for hundreds of patients, elPrep can remove several hundreds of hours of computing time, and thus substantially reduce analysis time and cost.</p>
    </abstract>
    <funding-group>
      <funding-statement>This work is funded by Intel, Janssen Pharmaceutica, and by the Institute for the Promotion of Innovation through Science and Technology in Flanders (IWT): IWT O&amp;O Project 130406. Charlotte Herzeel is an employee of IMEC vzw, Belgium; Pascal Costanza is an employee of Intel Corporation NV/SA, Belgium; Dries Decap and Jan Fostier are employees of iMinds vzw, Ghent, Belgium; Joke Reumers is an employee of Janssen Pharmaceutica NV/SA, Belgium. All authors are also affiliated with ExaScience Life Lab which is a consortium of companies and universities. These companies provided support in the form of salaries for these authors but did not have any additional role in the study design, data collection and analysis, decision to publish, or preparation of the manuscript. The specific role of each author is articulated in the “author contributions” section.</funding-statement>
    </funding-group>
    <counts>
      <fig-count count="3"/>
      <table-count count="10"/>
      <page-count count="16"/>
    </counts>
    <custom-meta-group>
      <custom-meta id="data-availability">
        <meta-name>Data Availability</meta-name>
        <meta-value>All relevant data are within the paper and its Supporting Information files.</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
  <notes>
    <title>Data Availability</title>
    <p>All relevant data are within the paper and its Supporting Information files.</p>
  </notes>
</front>
<body>
  <sec sec-type="intro" id="sec001">
    <title>Introduction</title>
    <p>DNA sequence analysis generally consists of a mapping phase followed by an analysis phase (<xref ref-type="fig" rid="pone.0132868.g001">Fig 1</xref>). In the mapping phase, the reads sequenced in the wet lab are mapped to a known reference genome via an alignment tool, such as BWA [<xref rid="pone.0132868.ref001" ref-type="bibr">1</xref>]. Afterwards, the mapped reads are processed by an analysis tool, for example for variant detection, such as GATK [<xref rid="pone.0132868.ref002" ref-type="bibr">2</xref>]. A large variety of alignment and analysis tools exist, each with their specific use cases.</p>
    <fig id="pone.0132868.g001" orientation="portrait" position="float">
      <object-id pub-id-type="doi">10.1371/journal.pone.0132868.g001</object-id>
      <label>Fig 1</label>
      <caption>
        <title>The computational phases of DNA sequencing.</title>
        <p>First, the reads produced by the wet lab (in FastQ format) are aligned against a reference genome, producing a sequence alignment map file (SAM). Then this SAM file is processed so that it can be used by an analysis tool to produce a VCF file.</p>
      </caption>
      <graphic xlink:href="pone.0132868.g001"/>
    </fig>
    <p>Alignment and analysis tools communicate via sequence alignment/map (SAM) files, a standardised file format for storing mapped reads [<xref rid="pone.0132868.ref003" ref-type="bibr">3</xref>], or the compressed variants thereof (BAM/CRAM) [<xref rid="pone.0132868.ref004" ref-type="bibr">4</xref>, <xref rid="pone.0132868.ref005" ref-type="bibr">5</xref>]. A SAM file is a tab-separated file that stores information about the reads generated by the sequencer, such as their query template names and their segment sequences, as well as information generated by the alignment tool, for example the positions where the reads map to the reference genome, and the CIGAR strings that describe how well the reads map to these positions [<xref rid="pone.0132868.ref006" ref-type="bibr">6</xref>]. The SAM format is a very flexible semi-structured format that allows storing optional and tool-specific information.</p>
    <p>In practice, different alignment tools produce slightly different outputs, and different analysis tools depend on slightly different SAM structures to work properly. For example, some analysis tools require optional information to be present, or require the reads to be filtered, for example to remove unmapped reads, or only work if the reads are stored in a particular order, and so on. This is why in practice, there are typically a number of steps in between the alignment and analysis tools to rewrite the SAM file into a form that is accepted by the analysis tool (<xref ref-type="fig" rid="pone.0132868.g002">Fig 2</xref>). For example, the GATK Best Practices [<xref rid="pone.0132868.ref007" ref-type="bibr">7</xref>] and the bcbio-nextgen project [<xref rid="pone.0132868.ref008" ref-type="bibr">8</xref>] give recommendations on which SAM manipulation tools need to be called to successfully combine different alignment and analysis tools.</p>
    <fig id="pone.0132868.g002" orientation="portrait" position="float">
      <object-id pub-id-type="doi">10.1371/journal.pone.0132868.g002</object-id>
      <label>Fig 2</label>
      <caption>
        <title>BAM processing: standard practice (top) versus elPrep (bottom).</title>
        <p>The standard practice is calling a (different) preparation tool for each step, which leads to repeated file I/O, as well as repeated traversal of the same SAM file. To use elPrep, one instead issues a single command that lists the preparation steps to be applied to a SAM file. elPrep internally combines the execution of the different preparation steps, resulting in a single pass over the SAM file, and avoiding repetitive file I/O.</p>
      </caption>
      <graphic xlink:href="pone.0132868.g002"/>
    </fig>
    <p>SAMtools [<xref rid="pone.0132868.ref003" ref-type="bibr">3</xref>] and Picard (<ext-link ext-link-type="uri" xlink:href="http://picard.sourceforge.net/">http://picard.sourceforge.net/</ext-link>) are arguably the most widely used tools for manipulating SAM files. They are command-line tools with commands for sorting and filtering reads, for adding optional information, for marking polymerase chain reaction (PCR) duplicates based on mapping positions, and so on. A pipeline script calls several of these commands one after the other, each call creating an intermediate SAM file, to eventually end up with a SAM file that is passed as input to the analysis tool.</p>
    <p>The computation time spent on preparation steps is not negligible. For example, running a five-step preparation pipeline used at Janssen Pharmaceutica on a whole-exome BAM file takes about 1:40 hours on a standard 24-core server. Since a typical clinical experiment easily consists of several hundreds of BAM files to process, the compute time spent on preparation steps easily adds up to a couple of hundred hours, which incurs a significant waiting time and/or a significant cost, for example for renting the necessary compute nodes in the cloud. The computational challenge for whole-genome data is even more pressing, as BAM files are ten to twenty times larger than exome files. We show that there are opportunities to redesign the software to drastically reduce this runtime and the associated costs.</p>
    <sec id="sec002">
      <title>Problem statement</title>
      <p>The standard practice of creating preparation pipelines by calling multiple command line tools one after the other, has the following drawbacks from a performance perspective (<xref ref-type="fig" rid="pone.0132868.g002">Fig 2</xref>):
<list list-type="order"><list-item><p>There is repeated file I/O between the steps, including BAM/CRAM compression/decompression, as each command line invocation generates a new SAM file.</p></list-item><list-item><p>There are multiple traversals of the same incrementally modified data, as each preparation tool iterates over entire SAM files representing that data to perform its particular computation.</p></list-item><list-item><p>Parallelisation opportunities are limited as each tool invocation introduces a synchronisation point.</p></list-item></list>
</p>
      <p>We propose a software architecture where the execution of a preparation pipeline, independent of which preparation steps are used, requires only a single pass through the SAM file. We have implemented this architecture in the form of a concrete tool called <italic>elPrep</italic>. With elPrep, a user issues only a single command that lists all preparation steps to be applied. The software internally takes care of merging and parallelising the execution of the different steps. This eliminates the end user’s need for naming and organising the storage for intermediate files, for understanding advanced concepts like Unix pipes and when they are applicable or not, and ultimately reduces the runtime and the associated costs.</p>
    </sec>
  </sec>
  <sec id="sec003">
    <title>Implementation</title>
    <p>elPrep is developed and maintained at the ExaScience Life Lab (<ext-link ext-link-type="uri" xlink:href="http://www.exascience.com">http://www.exascience.com</ext-link>) for the Linux operating system. End users either use elPrep directly as a command line tool, or can use Python for scripting. All relevant configuration options are documented and their uses are illustrated with example Python scripts. The core elPrep execution engine is implemented in Common Lisp, and can be compiled either with the commercial LispWorks compiler, or the open-source SBCL compiler, both widely used and actively maintained implementations of Common Lisp. A precompiled binary can be downloaded, along with documentation and source code from the elPrep github repository at <ext-link ext-link-type="uri" xlink:href="http://github.com/ExaScience/elprep">http://github.com/ExaScience/elprep</ext-link>, released under a BSD-style open source license, and therefore free for both non-commercial and commercial uses. For developers who wish to extend elPrep, extensive API documentation is also available at <ext-link ext-link-type="uri" xlink:href="http://exascience.github.io/elprep/elprep-package/index.html">http://exascience.github.io/elprep/elprep-package/index.html</ext-link>—however, such detailed information is not needed for regular uses of elPrep.</p>
  </sec>
  <sec sec-type="materials|methods" id="sec004">
    <title>Methods</title>
    <p>elPrep is designed as a high-performance alternative to existing tools for manipulating SAM, BAM, and CRAM files. The software is designed to run in memory, avoiding repeated file I/O between the preparation steps and merging their computations to execute more efficiently. Additionally, elPrep is designed as a multithreaded program from the ground up, so that <italic>all</italic> preparation steps can be executed in parallel, without any unnecessary barriers in between steps.</p>
    <sec id="sec005">
      <title>A single-pass, filtering architecture</title>
      <p>A key idea behind elPrep is to distinguish between SAM manipulation tools that can be expressed as operations or <italic>filters</italic> that work on individual reads, and operations that affect the whole set of reads such as sorting. A pipeline of SAM manipulation tools that are expressed as filters can be executed using a single loop over the SAM file, as illustrated by the pseudo code in <xref rid="pone.0132868.t001" ref-type="table">Listing 1</xref>. The idea is that the loop makes a single pass over the reads in the SAM file and executes the different filters one after the other on each read it encounters this way. Filters may have side effects, for updating the information stored for the read, and return a Boolean value for checking whether the read is to be included in the output file.</p>
      <table-wrap id="pone.0132868.t001" orientation="portrait" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pone.0132868.t001</object-id>
        <label>Listing 1</label>
        <caption>
          <title>Execution of the preparation pipeline as a single loop over the input file.</title>
        </caption>
        <alternatives>
          <graphic id="pone.0132868.t001g" xlink:href="pone.0132868.t001"/>
          <table frame="box" rules="all" border="0">
            <colgroup span="1">
              <col align="left" valign="top" span="1"/>
            </colgroup>
            <tbody>
              <tr>
                <td align="left" rowspan="1" colspan="1">
                  <monospace>filters = [remove_unmapped, mark_duplicates, …]</monospace>
                </td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">
                  <monospace>loop <bold>for</bold> read <bold>in</bold> input_file:</monospace>
                </td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1"> 
<monospace>flag = true</monospace>
</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1"> 
<monospace>loop <bold>for</bold> function <bold>in</bold> filters:</monospace>
</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">  
<monospace>flag = flag <bold>and apply</bold>(function, read)</monospace>
</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1"> 
<monospace><bold>if</bold> flag:</monospace>
</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">  
<monospace>write read to output_file</monospace>
</td>
              </tr>
            </tbody>
          </table>
        </alternatives>
      </table-wrap>
      <p>From a top-level perspective, elPrep can be viewed as a loop that parses the reads from file into memory, applies the filters on the individual reads, passes the filtered reads to the operations that work on the whole set of reads, and finally writes the reads one by one to the output file. In contrast, the execution of preparation pipelines created by calling multiple command-line tools one after the other, results in a separate loop for each filter operation. Computationally, all these loops are <italic>O</italic>(<italic>n</italic>) operations, so the overall execution differs only by a constant factor. However, since SAM/BAM files are large, this constant has a big impact on the actual runtime. Because elPrep only makes a single pass through the data, this also avoids the repeated file I/O that occurs when combining multiple calls to different tools.</p>
    </sec>
    <sec id="sec006">
      <title>A parallel architecture</title>
      <p>elPrep is designed to take advantage of multithreading for parallel processing. To this end, elPrep defines an <italic>input</italic> thread, <italic>worker</italic> threads, and an <italic>output</italic> thread. The input thread streams the data from the input file into memory, while distributing the reads among the available worker threads. The worker threads execute the preparation steps in parallel that are formulated as filters on the incoming reads, modifying their state. Once all data is streamed into memory and filters are applied, the operations that work on the whole data set, such as sorting, are executed. elPrep implements this phase using fork-join patterns, which are executed on a work-stealing scheduler for load balancing [<xref rid="pone.0132868.ref009" ref-type="bibr">9</xref>]. After the processing phase, the worker threads transform the data back into SAM file entries in parallel, while possibly applying additional filters, to finally send the result to the output thread which writes it to the output file.</p>
      <p>In practice, only some commands in existing tools for manipulating SAM files make use of multithreading. One strategy could be to parallelise the codes that implement the different commands. However, the execution strategy in elPrep has the advantage that there is no synchronisation between preparation steps.</p>
    </sec>
    <sec id="sec007">
      <title>A modular plug-in architecture</title>
      <p>To facilitate a modular plug-in architecture, the elPrep execution engine is designed as a collection of <italic>higher-order functions</italic>, and filters are implemented as <italic>lambda expressions</italic>. Lambda expressions are a language feature for implementing anonymous <italic>first-class functions</italic>, functions that can be treated as values, for example by passing them as input parameters, or using them as return values.</p>
      <p>Lambda expressions are typically known from <italic>pure</italic> functional programming languages that do not allow for side effects such as assigning new values to object fields. However, lambda expressions are useful also outside of pure functional programming, and have for example been introduced more recently in C++11 (2011) and Java 8 (2014). elPrep ensures through its design that modifications to the header and read objects passed to filters are safe.</p>
      <p>Concretely, filters in elPrep are modelled by layering three levels of filtering functions (<xref rid="pone.0132868.t002" ref-type="table">Listing 2</xref>). A filter is implemented as a function that implements or returns a <italic>header filter</italic>. A header filter is a function that receives as input the SAM header it can modify, and possibly returns a <italic>thread-local</italic> filter. The header filter is a global filter that is executed once for processing the SAM file. The variables declared in the header filter are visible by all worker threads. The thread-local filter returned by the header filter is a function that receives no arguments and returns a <italic>read filter</italic>. The body of a thread-local filter can be used to set up thread-local variables that are shared by the invocations of the read filter within a worker thread. The read filter itself is a function that receives a read object it can modify, and returns a Boolean value, indicating whether the read is to be included in the output or not.</p>
      <table-wrap id="pone.0132868.t002" orientation="portrait" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pone.0132868.t002</object-id>
        <label>Listing 2</label>
        <caption>
          <title>Skeleton structure of a filter definition in elPrep.</title>
        </caption>
        <alternatives>
          <graphic id="pone.0132868.t002g" xlink:href="pone.0132868.t002"/>
          <table frame="box" rules="all" border="0">
            <colgroup span="1">
              <col align="left" valign="top" span="1"/>
            </colgroup>
            <tbody>
              <tr>
                <td align="left" rowspan="1" colspan="1">
                  <monospace><bold>filter</bold> = <bold>lambda</bold> header:</monospace>
                </td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">     … <monospace><italic># modify header</italic></monospace>
</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">     
<monospace><bold>lambda</bold>:</monospace>
</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">      … <monospace><italic># thread–local variables</italic></monospace>
</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">      
<monospace><bold>lambda</bold> read:</monospace>
</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">       … <monospace><italic># modify read alignment</italic></monospace>
</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">       
<monospace><bold>return</bold> true <bold>or</bold> false</monospace>
</td>
              </tr>
            </tbody>
          </table>
        </alternatives>
      </table-wrap>
      <p>The pseudo code in <xref rid="pone.0132868.t003" ref-type="table">Listing 3</xref> illustrates the implementation of a filter for removing unmapped reads. According to the SAM specification [<xref rid="pone.0132868.ref003" ref-type="bibr">3</xref>], a read is unmapped when the third bit of the flag entry of the read is zero. This is checked by the read filter, implemented by the third lambda expression. Since the filter for removing unmapped reads does not modify the header of the SAM file, the body of the header filter is empty (first lambda expression). The filter does not require any thread-local variables, hence the body of the thread-local filter is also empty (second lambda expression).</p>
      <table-wrap id="pone.0132868.t003" orientation="portrait" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pone.0132868.t003</object-id>
        <label>Listing 3</label>
        <caption>
          <title>Removing unmapped reads as a filter in elPrep.</title>
        </caption>
        <alternatives>
          <graphic id="pone.0132868.t003g" xlink:href="pone.0132868.t003"/>
          <table frame="box" rules="all" border="0">
            <colgroup span="1">
              <col align="left" valign="top" span="1"/>
            </colgroup>
            <tbody>
              <tr>
                <td align="left" rowspan="1" colspan="1">
                  <monospace>filter_unmapped = <bold>lambda</bold> header:</monospace>
                </td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">        
<monospace><bold>lambda</bold>:</monospace>
</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">         
<monospace><bold>lambda</bold> read:</monospace>
</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">          
<monospace><bold>return</bold> (read . flag &amp; #<italic>x4) == 0</italic></monospace>
</td>
              </tr>
            </tbody>
          </table>
        </alternatives>
      </table-wrap>
      <p>The advantage of using lambda expressions for implementing filters is that they allow for treating filters in elPrep as modular plug-ins: New filters can be easily added or removed without the need to know about the internal implementation details of the elPrep execution engine or the other filters.</p>
    </sec>
    <sec id="sec008">
      <title>Expressing duplicate marking in elPrep</title>
      <p>Most preparation tools, such as replacing the header, replacing the sequence dictionary, filtering unmapped reads, or replacing read groups, are trivial to express within the elPrep framework. However, some preparation tools require algorithmic reformulations. A non-trivial example is duplicate marking, which is used for identifying PCR duplicates. PCR duplicates occur when the same DNA molecule is read multiple times during the sequencing process in the wet lab. They are hard to identify because PCR duplicates do not necessarily produce the exact same segment sequences. A common approach is to identify PCR duplicates in software after the mapping phase by comparing the reads that map to the same position in the reference genome, and marking the reads with the lowest quality scores as duplicates. It is a computationally intensive process as each read needs to be compared to each other read, which, in general, is an <italic>O</italic>(<italic>n</italic>
<sup>2</sup>) process.</p>
      <sec id="sec009">
        <title>Picard algorithm</title>
        <p>One of the most widely used duplicate marking algorithms is implemented by the Picard program (<ext-link ext-link-type="uri" xlink:href="http://picard.sourceforge.net/">http://picard.sourceforge.net/</ext-link>). This tool is recommended when targeting the GATK variant caller [<xref rid="pone.0132868.ref007" ref-type="bibr">7</xref>]. In elPrep, we implement the same algorithm used in Picard in the sense that the output produced by the elPrep algorithm is equivalent to the output produced by the Picard algorithm, yet the structure of the algorithm is different.</p>
        <p>The Picard algorithm for duplicate marking is a multi-pass algorithm that reads the input file multiple times. Structurally, there are three phases in the Picard algorithm (pseudo code can be found in our technical presentation at <ext-link ext-link-type="uri" xlink:href="http://www.exascience.com/public-files/elprep">http://www.exascience.com/public-files/elprep</ext-link>). In the first phase, the reads are sorted according to mapping coordinates, while keeping track of the original positions of the reads as they occur in the input file. In a second phase, the algorithm identifies the groups of potential duplicates within the sorted list by grouping together all reads that map to the same position. For each of those groups of reads, the algorithm identifies the read with the highest quality score, while keeping track of the file positions of all other reads in that group. Finally, in the third phase, a new output file is written by copying the reads from the original file, using the file positions identified in the second phase to identify which reads are marked as duplicate.</p>
      </sec>
      <sec id="sec010">
        <title>Expressing duplicate marking as a filter</title>
        <p>We need to reformulate the multi-pass Picard algorithm as a filter operation to make it fit with the single-pass framework of elPrep. The basic idea is to define a memoization table to keep track of the read with the best quality score for each read position seen so far as the execution progresses (<xref rid="pone.0132868.t004" ref-type="table">Listing 4</xref>). Each time it processes a new read, the algorithm checks the memoization table if a read was already encountered that has the same mapping position, in which case the algorithm marks the read with the worse quality score as a duplicate, and puts the read with the better quality score in the memoization table. Since the memoization table must be shared between worker threads, we use a concurrent hash table implementation to avoid unnecessary contention (not shown in <xref rid="pone.0132868.t004" ref-type="table">Listing 4</xref>).</p>
        <table-wrap id="pone.0132868.t004" orientation="portrait" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pone.0132868.t004</object-id>
          <label>Listing 4</label>
          <caption>
            <title>Duplicate marking as a filter in elPrep (simplified).</title>
          </caption>
          <alternatives>
            <graphic id="pone.0132868.t004g" xlink:href="pone.0132868.t004"/>
            <table frame="box" rules="all" border="0">
              <colgroup span="1">
                <col align="left" valign="top" span="1"/>
              </colgroup>
              <tbody>
                <tr>
                  <td align="left" rowspan="1" colspan="1">
                    <monospace>filter_duplicate = <bold>lambda</bold> header:</monospace>
                  </td>
                </tr>
                <tr>
                  <td align="left" rowspan="1" colspan="1">        
<monospace>cache = []</monospace>
</td>
                </tr>
                <tr>
                  <td align="left" rowspan="1" colspan="1">        
<monospace><bold>lambda</bold>:</monospace>
</td>
                </tr>
                <tr>
                  <td align="left" rowspan="1" colspan="1">         
<monospace><bold>lambda</bold> read:</monospace>
</td>
                </tr>
                <tr>
                  <td align="left" rowspan="1" colspan="1">          
<monospace>cached_read = cache . <bold>hash</bold>(read . pos)</monospace>
</td>
                </tr>
                <tr>
                  <td align="left" rowspan="1" colspan="1">          
<monospace><bold>if</bold> read . score &gt; cached_read . score</monospace>
</td>
                </tr>
                <tr>
                  <td align="left" rowspan="1" colspan="1">           
<monospace>cached_read . mark()</monospace>
</td>
                </tr>
                <tr>
                  <td align="left" rowspan="1" colspan="1">           
<monospace>cache . remove(cached_read)</monospace>
</td>
                </tr>
                <tr>
                  <td align="left" rowspan="1" colspan="1">           
<monospace>cache . add(read, read . pos)</monospace>
</td>
                </tr>
                <tr>
                  <td align="left" rowspan="1" colspan="1">          
<monospace><bold>else</bold>:</monospace>
</td>
                </tr>
                <tr>
                  <td align="left" rowspan="1" colspan="1">           
<monospace>read . mark()</monospace>
</td>
                </tr>
              </tbody>
            </table>
          </alternatives>
        </table-wrap>
      </sec>
      <sec id="sec011">
        <title>Splitting execution in genomic regions</title>
        <p>elPrep provides the option to process preparation pipelines per genomic region, a practice for splitting up sequencing workloads. However, it is not trivial to apply this technique to the Picard algorithm.</p>
        <p>Picard considers two reads potential duplicates if they both map to the same genomic region <italic>and</italic> the same position within that region. Paired-end reads are compared by comparing the reads that make up the pairs. One difficulty is that Picard guarantees duplicate marking of <italic>fragments</italic>, reads that are part of a pair where the mate is missing from the SAM file. The algorithm cannot simply look at a read and conclude that its mate is missing. Instead, it has to go through all of the reads in the file to determine which pairs are complete before comparing the fragments among each other. Another reason why processing per genomic region in Picard is hard, is that reads of a pair may not map to a single genomic region, and Picard guarantees the correct duplicate marking of such read pairs.</p>
        <p>Since the Picard algorithm is designed to process the SAM file as a whole, simply splitting up the workload to run the Picard algorithm per chromosome or genomic region, changes the outcome, and the Picard program provides no options to run it as such. elPrep allows duplicate marking of SAM files per genomic region without changing the outcome compared to running Picard on the whole file.</p>
        <p>To achieve this, the elPrep algorithm looks at the sequence dictionary in the header of the SAM file to identify the genomic regions, and splits up the SAM file into multiple smaller files, one for each genomic region. Normally, the elPrep splitter simply assigns a read to the file that matches the genomic region to which the read maps. Reads that are part of a pair where the reads map to different genomic regions, are collected in a separate split file. This ensures that such read pairs are complete in that file. The reads where the mate maps to a different genomic region are also duplicated in the file that matches the genomic region where the read maps (<xref ref-type="fig" rid="pone.0132868.g003">Fig 3</xref>).</p>
        <fig id="pone.0132868.g003" orientation="portrait" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pone.0132868.g003</object-id>
          <label>Fig 3</label>
          <caption>
            <title>Distribution of read pairs and fragments among split files.</title>
            <p>elPrep allows splitting SAM files into smaller files which can be processed in parallel, without information loss. The figure shows the mapping of the reads to the reference (top) and shows that elPrep generates a file per genomic region (bottom). Pairs (see chr1) and fragments (see chrY) that map to a single genomic region are put in the files that match those regions. Pairs where reads map to different genomic regions (see reads mapping to chr2 and chr3) are put in a separate split file (far right). The individual reads of those pairs are also duplicated in the files that match the genomic regions where the reads map. This strategy guarantees that all split files contain all information for duplicate marking.</p>
          </caption>
          <graphic xlink:href="pone.0132868.g003"/>
        </fig>
        <p>The elPrep splitting strategy guarantees that all split files have all information for correct duplicate marking. The reads of a pair always end up in the same split file, so duplicate marking of pairs can be done separately per split file. As for fragment reads, the fragments that map to the same position, end up in the same split file, so duplicate marking can also be done per split file. The case where Picard marks fragments as duplicates when a read pair exists where one read maps to the same position, is also covered. If the full pair maps to the same genomic region as the fragment, it is just present in the same split file. If the fragment matches a read that is part of a pair that spans different genomic regions, that read was duplicated in the same file by the splitter.</p>
        <p>elPrep of course also provides a command for merging the results of processing multiple split files after marking duplicates.</p>
      </sec>
    </sec>
  </sec>
  <sec sec-type="results" id="sec012">
    <title>Results</title>
    <p>We claim that elPrep is more efficient than the standard practice of calling multiple command-line tools one after the other. We shows this is mainly because our software architecture requires making only a single pass through a SAM file to execute a preparation pipeline.</p>
    <sec id="sec013">
      <title>Benchmarks</title>
      <p>To prove our claims we set up benchmark experiments for three pipelines for preparing BAM files for variant calling with GATK. The GATK Best Practices recommendations [<xref rid="pone.0132868.ref007" ref-type="bibr">7</xref>] provide guidelines for two preparation pipelines. The first preparation pipeline is part of <italic>Base protocol 1</italic>, a protocol that describes the best practice to go from unaligned FASTQ files to a BAM file that can be used by GATK. This protocol explains how to do alignment with BWA and then discusses two preparation steps:
<list list-type="order"><list-item><p>Sorting the BAM file for coordinate order using Picard;</p></list-item><list-item><p>Marking the duplicate reads with Picard.</p></list-item></list>
The pseudo code in [<xref rid="pone.0132868.ref007" ref-type="bibr">7</xref>] suggests that both steps can be performed by a single Picard command, but Picard actually requires issuing separate commands for sorting and duplicate marking.</p>
      <p>A second preparation pipeline is discussed in [<xref rid="pone.0132868.ref007" ref-type="bibr">7</xref>] (<italic>Support protocol 3</italic>), which is recommended for preparing BAM files that one downloads from online data repositories or receives from colleagues, and may not be properly formatted for GATK. This preparation pipeline consists of:
<list list-type="order"><list-item><p>Sorting the BAM for coordinate order with Picard;</p></list-item><list-item><p>Marking duplicate reads with Picard;</p></list-item><list-item><p>Adding or replacing read groups with Picard.</p></list-item></list>
</p>
      <p>In practice, it may be necessary to perform additional formatting steps, which is documented in the online documentation of GATK [<xref rid="pone.0132868.ref010" ref-type="bibr">10</xref>], or the domain expert may decide to perform additional filtering steps on the reads before doing the variant calling.</p>
      <p>The third preparation pipeline we discuss as a benchmark is the one that is used at Janssen Pharmaceutica (<italic>JP protocol</italic>). Their pipeline to prepare BAM files for variant calling consists of five steps:
<list list-type="order"><list-item><p>Sorting the BAM for coordinate order with Picard;</p></list-item><list-item><p>Removing unmapped reads and reads with erroneous mapping scores/flags with SAMtools;</p></list-item><list-item><p>Marking duplicate reads with Picard;</p></list-item><list-item><p>Replacing read groups with Picard;</p></list-item><list-item><p>Reordering and filtering the sequence dictionary with Picard.</p></list-item></list>
</p>
      <sec id="sec014">
        <title>Software and data sets</title>
        <p>We execute the three pipelines with both elPrep and Picard/SAMtools. Our goal is to show that, in contrast to existing tools, the execution time with elPrep is largely independent of how many preparation steps need to be executed. We use the latest release of all tools at the time of writing, namely elprep-2.3, samtools-1.2, and picard-tools-1.129. We chose to execute the pipelines with both an exome workload (Illumina high-coverage whole-exome NA12878, human genome [<xref rid="pone.0132868.ref011" ref-type="bibr">11</xref>]) and a whole-genome workload (Illumina Platinum genomes, NA12878, 100bp, 50-fold coverage, human genome [<xref rid="pone.0132868.ref012" ref-type="bibr">12</xref>]).</p>
      </sec>
      <sec id="sec015">
        <title>Hardware</title>
        <p>All our benchmarks were run on a 24-core server, consisting of two 12-core Intel Xeon E5-2690 processors clocked at 2.6 Ghz, allowing the simultaneous execution of up to 48 hyper-threads. The server is equipped with 256GB RAM and a 2TB Intel P3700 SSD hard disk for storing intermediate files. The machine runs CentOS 7.0 with Linux kernel 3.19.0.</p>
      </sec>
      <sec id="sec016">
        <title>Validation</title>
        <p>elPrep produces BAM files that are equivalent to those produced by Picard and SAMtools for overlapping functionality. We have verified the equivalence by performing a textual comparison of the BAM files uncompressed to SAM format (essentially using the Unix <italic>diff</italic> command, see <xref ref-type="supplementary-material" rid="pone.0132868.s002">S2 Appendix</xref> for a detailed discussion).</p>
      </sec>
    </sec>
    <sec id="sec017">
      <title>Whole-exome benchmark (NA12878)</title>
      <p>The Picard versions of the three pipelines consist of scripts that call the individual Picard commands one after the other. There is no composition mechanism in Picard to combine the execution of the different pipeline steps. There is also no support in Picard for using streaming with Unix pipes. Hence the execution times of the full pipelines are equal to the sum of the execution times for the individual steps.</p>
      <p>While in elPrep it is possible to build pipelines using separate elPrep commands connected via Unix pipes, we claim it is much more efficient to formulate the pipeline using a single elPrep command that lists all the pipeline steps. We formulated the pipelines using both approaches in elPrep to do the comparison (Tables <xref rid="pone.0132868.t005" ref-type="table">1</xref>–<xref rid="pone.0132868.t007" ref-type="table">3</xref>). elPrep is flexible in terms of how much RAM it uses via its split/merge tools. We executed elPrep once with giving it access to an amount of RAM that is similar to what Picard uses by splitting the input file per chromosomal regions as they occur in the header of the BAM (third column), and we also did a run with giving elPrep access to all available RAM on the benchmark server (fourth column). All of the benchmark runs we show for elPrep were executed with 48 threads, as were the SAMtools calls. There is no option to configure the number of threads used by Picard.</p>
      <table-wrap id="pone.0132868.t005" orientation="portrait" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pone.0132868.t005</object-id>
        <label>Table 1</label>
        <caption>
          <title>Benchmarks of the 2-step pipeline on NA12878 exome (Basic protocol 1).</title>
        </caption>
        <alternatives>
          <graphic id="pone.0132868.t005g" xlink:href="pone.0132868.t005"/>
          <table frame="box" rules="all" border="0">
            <colgroup span="1">
              <col align="left" valign="top" span="1"/>
              <col align="left" valign="top" span="1"/>
              <col align="left" valign="top" span="1"/>
              <col align="left" valign="top" span="1"/>
              <col align="left" valign="top" span="1"/>
              <col align="left" valign="top" span="1"/>
              <col align="left" valign="top" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th align="left" rowspan="1" colspan="1"/>
                <th colspan="2" align="center" rowspan="1">Picard</th>
                <th colspan="2" align="center" rowspan="1">elPrep</th>
                <th colspan="2" align="center" rowspan="1">elPrep (max RAM)</th>
              </tr>
              <tr>
                <th align="left" rowspan="1" colspan="1"/>
                <th align="left" rowspan="1" colspan="1">Time</th>
                <th align="left" rowspan="1" colspan="1">RAM</th>
                <th align="left" rowspan="1" colspan="1">Time</th>
                <th align="left" rowspan="1" colspan="1">RAM</th>
                <th align="left" rowspan="1" colspan="1">Time</th>
                <th align="left" rowspan="1" colspan="1">RAM</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="left" rowspan="1" colspan="1">Sort by coordinates</td>
                <td align="left" rowspan="1" colspan="1">22m 36s</td>
                <td align="left" rowspan="1" colspan="1">12GB</td>
                <td align="left" rowspan="1" colspan="1">15m 33s</td>
                <td align="left" rowspan="1" colspan="1">19GB</td>
                <td align="left" rowspan="1" colspan="1">10m 5s</td>
                <td align="left" rowspan="1" colspan="1">180GB</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Mark duplicates</td>
                <td align="left" rowspan="1" colspan="1">31m 19s</td>
                <td align="left" rowspan="1" colspan="1">23GB</td>
                <td align="left" rowspan="1" colspan="1">14m 23s</td>
                <td align="left" rowspan="1" colspan="1">22GB</td>
                <td align="left" rowspan="1" colspan="1">8m 58s</td>
                <td align="left" rowspan="1" colspan="1">216GB</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Separately executed steps (total)</td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>53m 55s</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">23GB</td>
                <td align="left" rowspan="1" colspan="1">29m 57s</td>
                <td align="left" rowspan="1" colspan="1">22GB</td>
                <td align="left" rowspan="1" colspan="1">19m 3s</td>
                <td align="left" rowspan="1" colspan="1">216GB</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Combined execution steps</td>
                <td align="left" rowspan="1" colspan="1">na</td>
                <td align="left" rowspan="1" colspan="1">na</td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>15m 20s</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">22GB</td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>10m 58s</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">216GB</td>
              </tr>
            </tbody>
          </table>
        </alternatives>
        <table-wrap-foot>
          <fn id="t005fn001">
            <p>In elPrep, the combined execution of both preparation steps is faster than running the steps one after the other. When elPrep gets to use a similar amount of RAM as Picard uses, it executes the pipeline three times faster than Picard (third column). When elPrep is given access to all available RAM, it executes the pipeline five times faster than Picard (fourth column).</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <table-wrap id="pone.0132868.t006" orientation="portrait" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pone.0132868.t006</object-id>
        <label>Table 2</label>
        <caption>
          <title>Benchmarks of the 3-step pipeline on NA12878 exome (Support protocol 3).</title>
        </caption>
        <alternatives>
          <graphic id="pone.0132868.t006g" xlink:href="pone.0132868.t006"/>
          <table frame="box" rules="all" border="0">
            <colgroup span="1">
              <col align="left" valign="top" span="1"/>
              <col align="left" valign="top" span="1"/>
              <col align="left" valign="top" span="1"/>
              <col align="left" valign="top" span="1"/>
              <col align="left" valign="top" span="1"/>
              <col align="left" valign="top" span="1"/>
              <col align="left" valign="top" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th align="left" rowspan="1" colspan="1"/>
                <th colspan="2" align="center" rowspan="1">Picard</th>
                <th colspan="2" align="center" rowspan="1">elPrep</th>
                <th colspan="2" align="center" rowspan="1">elPrep (max RAM)</th>
              </tr>
              <tr>
                <th align="left" rowspan="1" colspan="1"/>
                <th align="left" rowspan="1" colspan="1">Time</th>
                <th align="left" rowspan="1" colspan="1">RAM</th>
                <th align="left" rowspan="1" colspan="1">Time</th>
                <th align="left" rowspan="1" colspan="1">RAM</th>
                <th align="left" rowspan="1" colspan="1">Time</th>
                <th align="left" rowspan="1" colspan="1">RAM</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="left" rowspan="1" colspan="1">Sort by coordinates</td>
                <td align="left" rowspan="1" colspan="1">22m 36s</td>
                <td align="left" rowspan="1" colspan="1">12GB</td>
                <td align="left" rowspan="1" colspan="1">15m 33s</td>
                <td align="left" rowspan="1" colspan="1">19GB</td>
                <td align="left" rowspan="1" colspan="1">10m 5s</td>
                <td align="left" rowspan="1" colspan="1">180GB</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Mark duplicates</td>
                <td align="left" rowspan="1" colspan="1">31m 19s</td>
                <td align="left" rowspan="1" colspan="1">23GB</td>
                <td align="left" rowspan="1" colspan="1">14m 23s</td>
                <td align="left" rowspan="1" colspan="1">22GB</td>
                <td align="left" rowspan="1" colspan="1">8m 58s</td>
                <td align="left" rowspan="1" colspan="1">216GB</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Add read groups</td>
                <td align="left" rowspan="1" colspan="1">22m 55s</td>
                <td align="left" rowspan="1" colspan="1">0.6GB</td>
                <td align="left" rowspan="1" colspan="1">15m 23s</td>
                <td align="left" rowspan="1" colspan="1">1.7GB</td>
                <td align="left" rowspan="1" colspan="1">6m 20s</td>
                <td align="left" rowspan="1" colspan="1">2.7GB</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Separately executed steps (total)</td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>76m 50s</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">23GB</td>
                <td align="left" rowspan="1" colspan="1">45m 20s</td>
                <td align="left" rowspan="1" colspan="1">22GB</td>
                <td align="left" rowspan="1" colspan="1">25m 23s</td>
                <td align="left" rowspan="1" colspan="1">216GB</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Combined execution steps</td>
                <td align="left" rowspan="1" colspan="1">na</td>
                <td align="left" rowspan="1" colspan="1">na</td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>15m 47s</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">23GB</td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>10m 34s</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">219GB</td>
              </tr>
            </tbody>
          </table>
        </alternatives>
        <table-wrap-foot>
          <fn id="t006fn001">
            <p>In elPrep, the combined execution of all three preparation steps is faster than running the steps one after the other. Compared to Basic protocol 1 (<xref rid="pone.0132868.t005" ref-type="table">Table 1</xref>), the extra step in this pipeline does not add an additional runtime cost when combining the execution of the steps with elPrep. elPrep executes the full pipeline five to seven times faster than using Picard, depending on how much RAM elPrep can use, namely the same amount as Picard (third column) or all available RAM (fourth column).</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <table-wrap id="pone.0132868.t007" orientation="portrait" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pone.0132868.t007</object-id>
        <label>Table 3</label>
        <caption>
          <title>Benchmarks of the 5-step pipeline on NA12878 exome (JP protocol).</title>
        </caption>
        <alternatives>
          <graphic id="pone.0132868.t007g" xlink:href="pone.0132868.t007"/>
          <table frame="box" rules="all" border="0">
            <colgroup span="1">
              <col align="left" valign="top" span="1"/>
              <col align="left" valign="top" span="1"/>
              <col align="left" valign="top" span="1"/>
              <col align="left" valign="top" span="1"/>
              <col align="left" valign="top" span="1"/>
              <col align="left" valign="top" span="1"/>
              <col align="left" valign="top" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th align="left" rowspan="1" colspan="1"/>
                <th colspan="2" align="center" rowspan="1">Picard*/SAMtools<sup>+</sup>
</th>
                <th colspan="2" align="center" rowspan="1">elPrep</th>
                <th colspan="2" align="center" rowspan="1">elPrep (max RAM)</th>
              </tr>
              <tr>
                <th align="left" rowspan="1" colspan="1"/>
                <th align="left" rowspan="1" colspan="1">Time</th>
                <th align="left" rowspan="1" colspan="1">RAM</th>
                <th align="left" rowspan="1" colspan="1">Time</th>
                <th align="left" rowspan="1" colspan="1">RAM</th>
                <th align="left" rowspan="1" colspan="1">Time</th>
                <th align="left" rowspan="1" colspan="1">RAM</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="left" rowspan="1" colspan="1">Sort by coordinates</td>
                <td align="left" rowspan="1" colspan="1">22m 36s*</td>
                <td align="left" rowspan="1" colspan="1">12GB</td>
                <td align="left" rowspan="1" colspan="1">16m 4s</td>
                <td align="left" rowspan="1" colspan="1">19GB</td>
                <td align="left" rowspan="1" colspan="1">10m 19s</td>
                <td align="left" rowspan="1" colspan="1">180GB</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Filter unmapped reads</td>
                <td align="left" rowspan="1" colspan="1">3m 16s<sup>+</sup>
</td>
                <td align="left" rowspan="1" colspan="1">0.8GB</td>
                <td align="left" rowspan="1" colspan="1">14m 58s</td>
                <td align="left" rowspan="1" colspan="1">1.5GB</td>
                <td align="left" rowspan="1" colspan="1">6m 12s</td>
                <td align="left" rowspan="1" colspan="1">2.8GB</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Mark duplicates</td>
                <td align="left" rowspan="1" colspan="1">30m 47s*</td>
                <td align="left" rowspan="1" colspan="1">23GB</td>
                <td align="left" rowspan="1" colspan="1">14m 18s</td>
                <td align="left" rowspan="1" colspan="1">22GB</td>
                <td align="left" rowspan="1" colspan="1">8m 48s</td>
                <td align="left" rowspan="1" colspan="1">216GB</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Add read groups</td>
                <td align="left" rowspan="1" colspan="1">22m 39s*</td>
                <td align="left" rowspan="1" colspan="1">0.7GB</td>
                <td align="left" rowspan="1" colspan="1">14m 49s</td>
                <td align="left" rowspan="1" colspan="1">1.7GB</td>
                <td align="left" rowspan="1" colspan="1">6m 42s</td>
                <td align="left" rowspan="1" colspan="1">2.5GB</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Filter sequence dictionary</td>
                <td align="left" rowspan="1" colspan="1">20m 39s*</td>
                <td align="left" rowspan="1" colspan="1">11.8GB</td>
                <td align="left" rowspan="1" colspan="1">14m 48s</td>
                <td align="left" rowspan="1" colspan="1">19GB</td>
                <td align="left" rowspan="1" colspan="1">9m 35s</td>
                <td align="left" rowspan="1" colspan="1">189GB</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Separately executed steps (total)</td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>99m 58s</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">23GB</td>
                <td align="left" rowspan="1" colspan="1">74m 56s</td>
                <td align="left" rowspan="1" colspan="1">22GB</td>
                <td align="left" rowspan="1" colspan="1">41m 37s</td>
                <td align="left" rowspan="1" colspan="1">216GB</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Combined execution steps</td>
                <td align="left" rowspan="1" colspan="1">na</td>
                <td align="left" rowspan="1" colspan="1">na</td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>15m 31s</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">23GB</td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>10m 23s</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">219GB</td>
              </tr>
            </tbody>
          </table>
        </alternatives>
        <table-wrap-foot>
          <fn id="t007fn001">
            <p>In elPrep, the combined execution of all preparation steps is faster than running the steps one after the other. The execution of the five-step pipeline in elPrep does not take significantly longer than the execution of the two-step and three-step pipelines (Tables <xref rid="pone.0132868.t006" ref-type="table">2</xref> and <xref rid="pone.0132868.t007" ref-type="table">3</xref>). elPrep executes the full pipeline between six times faster when using a similar amount of RAM as Picard (third column) and ten times faster when given access to all available RAM (fourth column).</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p>For the two-step pipeline (<xref rid="pone.0132868.t005" ref-type="table">Table 1</xref>), the combined execution of the steps with a single elPrep invocation is almost two times faster than executing the steps as separate elPrep commands. In case of the three-step (<xref rid="pone.0132868.t006" ref-type="table">Table 2</xref>) and five-step (<xref rid="pone.0132868.t007" ref-type="table">Table 3</xref>) pipelines, the combined execution in elPrep is respectively three and five times faster. In terms of total runtime, there is not much difference between executing the two-step, three-step or five-step pipeline in elPrep. In contrast, there is a significant difference between the runtimes for the Picard versions of the pipelines. The three-step pipeline is 1.5 slower than the two-step pipeline, and the five-step pipeline is almost two times slower.</p>
      <p>For a direct comparison between elPrep and Picard, we also need to compare the execution times of the individual steps. We see that the elPrep versions are typically between a factor 1.5 and 2 faster than the equivalent Picard versions. However, the main performance advantage of elPrep comes from its ability to merge the execution of multiple commands. Using this functionality improves the performance for the execution of the full pipeline by another factor two, three, and five for respectively the two-step, three-step, and five-step pipelines. Overall, elPrep executes the two-step pipeline three to five times faster, the three-step pipeline five to seven times faster, and the five-step pipeline six to ten times faster than Picard.</p>
      <p>In practice, a clinical experiment consists of 300 or more samples to process, and using elPrep thusly saves several hundred hours of computing time, namely 200+ hours for the two-step pipeline, 300+ hours for the three-step pipeline, and more than 450 hours for the five-step pipeline.</p>
    </sec>
    <sec id="sec018">
      <title>Whole-genome benchmark (NA12878)</title>
      <p>We executed the same three preparation protocols on the whole-genome data set for NA12878 (Tables <xref rid="pone.0132868.t008" ref-type="table">4</xref>–<xref rid="pone.0132868.t010" ref-type="table">6</xref>). Similar to what we see for the exome benchmarks, the combined execution of the different preparation steps in elPrep is more efficient than executing the steps one after the other.</p>
      <table-wrap id="pone.0132868.t008" orientation="portrait" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pone.0132868.t008</object-id>
        <label>Table 4</label>
        <caption>
          <title>Benchmarks of the 2-step pipeline on NA12878 whole genome (Basic protocol 1).</title>
        </caption>
        <alternatives>
          <graphic id="pone.0132868.t008g" xlink:href="pone.0132868.t008"/>
          <table frame="box" rules="all" border="0">
            <colgroup span="1">
              <col align="left" valign="top" span="1"/>
              <col align="left" valign="top" span="1"/>
              <col align="left" valign="top" span="1"/>
              <col align="left" valign="top" span="1"/>
              <col align="left" valign="top" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th align="left" rowspan="1" colspan="1"/>
                <th colspan="2" align="center" rowspan="1">Picard</th>
                <th colspan="2" align="center" rowspan="1">elPrep</th>
              </tr>
              <tr>
                <th align="left" rowspan="1" colspan="1"/>
                <th align="left" rowspan="1" colspan="1">Time</th>
                <th align="left" rowspan="1" colspan="1">RAM</th>
                <th align="left" rowspan="1" colspan="1">Time</th>
                <th align="left" rowspan="1" colspan="1">RAM</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="left" rowspan="1" colspan="1">Sort by coordinates</td>
                <td align="left" rowspan="1" colspan="1">5h 14m</td>
                <td align="left" rowspan="1" colspan="1">12GB</td>
                <td align="left" rowspan="1" colspan="1">5h 2m</td>
                <td align="left" rowspan="1" colspan="1">203GB</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Mark duplicates</td>
                <td align="left" rowspan="1" colspan="1">7h 45m</td>
                <td align="left" rowspan="1" colspan="1">28GB</td>
                <td align="left" rowspan="1" colspan="1">5h 16m</td>
                <td align="left" rowspan="1" colspan="1">234GB</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Separately executed steps (total)</td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>12h 59m</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">28GB</td>
                <td align="left" rowspan="1" colspan="1">10h 18m</td>
                <td align="left" rowspan="1" colspan="1">234GB</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Combined execution steps</td>
                <td align="left" rowspan="1" colspan="1">na</td>
                <td align="left" rowspan="1" colspan="1">na</td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>5h 9m</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">239GB</td>
              </tr>
            </tbody>
          </table>
        </alternatives>
        <table-wrap-foot>
          <fn id="t008fn001">
            <p>Similar as with exome data, the combined execution of the preparation pipeline in elPrep is much faster than executing the individual steps one by one, which is the only option with Picard. elPrep executes Basic protocol 1 about 2.5 times faster than Picard.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <table-wrap id="pone.0132868.t009" orientation="portrait" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pone.0132868.t009</object-id>
        <label>Table 5</label>
        <caption>
          <title>Benchmarks of the 3-step pipeline on NA12878 whole genome (Support protocol 3).</title>
        </caption>
        <alternatives>
          <graphic id="pone.0132868.t009g" xlink:href="pone.0132868.t009"/>
          <table frame="box" rules="all" border="0">
            <colgroup span="1">
              <col align="left" valign="top" span="1"/>
              <col align="left" valign="top" span="1"/>
              <col align="left" valign="top" span="1"/>
              <col align="left" valign="top" span="1"/>
              <col align="left" valign="top" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th align="left" rowspan="1" colspan="1"/>
                <th colspan="2" align="center" rowspan="1">Picard</th>
                <th colspan="2" align="center" rowspan="1">elPrep</th>
              </tr>
              <tr>
                <th align="left" rowspan="1" colspan="1"/>
                <th align="left" rowspan="1" colspan="1">Time</th>
                <th align="left" rowspan="1" colspan="1">RAM</th>
                <th align="left" rowspan="1" colspan="1">Time</th>
                <th align="left" rowspan="1" colspan="1">RAM</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="left" rowspan="1" colspan="1">Sort by coordinates</td>
                <td align="left" rowspan="1" colspan="1">5h 14m</td>
                <td align="left" rowspan="1" colspan="1">12GB</td>
                <td align="left" rowspan="1" colspan="1">5h 2m</td>
                <td align="left" rowspan="1" colspan="1">203GB</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Mark duplicates</td>
                <td align="left" rowspan="1" colspan="1">7h 45m</td>
                <td align="left" rowspan="1" colspan="1">28GB</td>
                <td align="left" rowspan="1" colspan="1">5h 16m</td>
                <td align="left" rowspan="1" colspan="1">234GB</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Add read groups</td>
                <td align="left" rowspan="1" colspan="1">6h 51m</td>
                <td align="left" rowspan="1" colspan="1">0.7GB</td>
                <td align="left" rowspan="1" colspan="1">1h 26m</td>
                <td align="left" rowspan="1" colspan="1">20GB</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Separately executed steps (total)</td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>19h 51m</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">28GB</td>
                <td align="left" rowspan="1" colspan="1">11h 44m</td>
                <td align="left" rowspan="1" colspan="1">234GB</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Combined execution steps</td>
                <td align="left" rowspan="1" colspan="1">na</td>
                <td align="left" rowspan="1" colspan="1">na</td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>5h 11m</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">239GB</td>
              </tr>
            </tbody>
          </table>
        </alternatives>
        <table-wrap-foot>
          <fn id="t009fn001">
            <p>The execution time with elPrep remains stable compared to Basic protocol 1 (<xref rid="pone.0132868.t008" ref-type="table">Table 4</xref>). elPrep executes this preparation pipeline almost four times faster than Picard.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <table-wrap id="pone.0132868.t010" orientation="portrait" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pone.0132868.t010</object-id>
        <label>Table 6</label>
        <caption>
          <title>Benchmarks of the 5-step pipeline on NA12878 whole genome (JP protocol).</title>
        </caption>
        <alternatives>
          <graphic id="pone.0132868.t010g" xlink:href="pone.0132868.t010"/>
          <table frame="box" rules="all" border="0">
            <colgroup span="1">
              <col align="left" valign="top" span="1"/>
              <col align="left" valign="top" span="1"/>
              <col align="left" valign="top" span="1"/>
              <col align="left" valign="top" span="1"/>
              <col align="left" valign="top" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th align="left" rowspan="1" colspan="1"/>
                <th colspan="2" align="center" rowspan="1">Picard*/SAMtools<sup>+</sup>
</th>
                <th colspan="2" align="center" rowspan="1">elPrep</th>
              </tr>
              <tr>
                <th align="left" rowspan="1" colspan="1"/>
                <th align="left" rowspan="1" colspan="1">Time</th>
                <th align="left" rowspan="1" colspan="1">RAM</th>
                <th align="left" rowspan="1" colspan="1">Time</th>
                <th align="left" rowspan="1" colspan="1">RAM</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="left" rowspan="1" colspan="1">Sort by coordinates</td>
                <td align="left" rowspan="1" colspan="1">5h 14m*</td>
                <td align="left" rowspan="1" colspan="1">12GB</td>
                <td align="left" rowspan="1" colspan="1">5h 2m</td>
                <td align="left" rowspan="1" colspan="1">203GB</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Filter unmapped reads</td>
                <td align="left" rowspan="1" colspan="1">42m 16s<sup>+</sup>
</td>
                <td align="left" rowspan="1" colspan="1">0.8GB</td>
                <td align="left" rowspan="1" colspan="1">1h 26m</td>
                <td align="left" rowspan="1" colspan="1">2.5GB</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Mark duplicates</td>
                <td align="left" rowspan="1" colspan="1">7h 4m*</td>
                <td align="left" rowspan="1" colspan="1">29GB</td>
                <td align="left" rowspan="1" colspan="1">5h 1m</td>
                <td align="left" rowspan="1" colspan="1">233GB</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Add read groups</td>
                <td align="left" rowspan="1" colspan="1">5h 18m*</td>
                <td align="left" rowspan="1" colspan="1">0.8GB</td>
                <td align="left" rowspan="1" colspan="1">1h 18m</td>
                <td align="left" rowspan="1" colspan="1">2.8GB</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Filter sequence dictionary</td>
                <td align="left" rowspan="1" colspan="1">5h 6m*</td>
                <td align="left" rowspan="1" colspan="1">12GB</td>
                <td align="left" rowspan="1" colspan="1">4h 54m</td>
                <td align="left" rowspan="1" colspan="1">196GB</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Separately executed steps (total)</td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>23h 25m</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">29GB</td>
                <td align="left" rowspan="1" colspan="1">17h 42m</td>
                <td align="left" rowspan="1" colspan="1">233GB</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Combined execution steps</td>
                <td align="left" rowspan="1" colspan="1">na</td>
                <td align="left" rowspan="1" colspan="1">na</td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>4h 47m</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">239GB</td>
              </tr>
            </tbody>
          </table>
        </alternatives>
        <table-wrap-foot>
          <fn id="t010fn001">
            <p>Again, combined execution in elPrep is faster than executing the steps one by one. elPrep executes the five-step pipeline faster than the three-step pipeline (<xref rid="pone.0132868.t009" ref-type="table">Table 5</xref>), even though it has two more steps. This is because the second step here removes unmapped and erroneously tagged reads. This reduces the number of reads that are processed by the subsequent steps. This can be seen by looking at the timings of the individual steps, both for elPrep and Picard, as well. Overall, elPrep executes the five-step pipeline almost five times faster.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p>We executed the benchmarks by having elPrep split up the input file by chromosomal regions as they occur in the header of the BAM file. elPrep uses an amount of RAM that is proportional to the input size of the split files, which, in the case of the whole-genome benchmarks, means that elPrep uses 8.5× more RAM than Picard/SAMtools (see the RAM entries in Tables <xref rid="pone.0132868.t008" ref-type="table">4</xref>–<xref rid="pone.0132868.t010" ref-type="table">6</xref>).</p>
      <p>A solution to use less RAM would be to use a more fine-grained splitting strategy than splitting by chromosomal regions, but elPrep currently does not support this. If machines with sufficient RAM are not available to the user, we recommend other tools that are optimised for low-memory footprints (discussed in detail in <xref ref-type="supplementary-material" rid="pone.0132868.s001">S1 Appendix</xref>) or switching to a cloud-based solution. For example, when using Amazon Web Services, the cost of renting a memory-optimised server that runs elPrep is in the same range as renting a server with less RAM that runs Picard/SAMtools (<ext-link ext-link-type="uri" xlink:href="https://aws.amazon.com/ec2/pricing/">https://aws.amazon.com/ec2/pricing/</ext-link> as of May 19, 2015). Based on the resource requirements in Tables <xref rid="pone.0132868.t008" ref-type="table">4</xref>–<xref rid="pone.0132868.t010" ref-type="table">6</xref>), we need to run elPrep on an r3.8xlarge (memory optimised) instance with 32 virtual CPU cores, 244GB RAM, and 2× 320 GB SSD drives, which costs $2.800/hour. For running the Picard/SAMtools pipelines, a i2.xlarge (storage optimised) instance with 4 virtual CPU cores, 30.5GB RAM, and 1× 800 GB SSD drive would suffice, which costs $0.853/hour. Hence the instance for running the pipelines with elPrep costs roughly 3.3× more than the instance for using Picard/SAMtools. However, since elPrep executes the pipelines between 2.5 to 5× faster than Picard/SAMtools (see Tables <xref rid="pone.0132868.t008" ref-type="table">4</xref>–<xref rid="pone.0132868.t010" ref-type="table">6</xref>), the server cost of using elPrep is in the same range for Basic protocol 1, and cheaper for Support Protocol 3 and the JP Protocol, than using Picard/SAMtools, with the added benefit of a substantially reduced waiting time for the elPrep user.</p>
    </sec>
  </sec>
  <sec id="sec019">
    <title>Related Work</title>
    <p>There is a large body of related work that focuses on optimising individual SAM manipulation tools (see <xref ref-type="supplementary-material" rid="pone.0132868.s001">S1 Appendix</xref> for a detailed overview). For example, many tools focus on optimising memory use of duplicate marking, for example by defining data structures that overflow to disk when a certain threshold is reached (bamUtil [<xref rid="pone.0132868.ref013" ref-type="bibr">13</xref>], biobambam [<xref rid="pone.0132868.ref014" ref-type="bibr">14</xref>], Sambamba [<xref rid="pone.0132868.ref015" ref-type="bibr">15</xref>]) or define an alternative duplicate marking strategy that does not require comparing all alignments (SAMBLASTER [<xref rid="pone.0132868.ref016" ref-type="bibr">16</xref>]). Some of these tools are faster for executing the individual tools they implement, or use substantially less RAM than elPrep. However, none of the tools offer a way of combining the execution of multiple tools like elPrep does. Whereas we focus on tackling the drawbacks of composing pipelines as separate command invocations, the related work focuses on optimising individual tools, such as duplicate marking and sorting for coordinate order. These results are orthogonal, and it should be possible to add the optimisations to elPrep, or to redesign the other tools to use a software architecture similar to that of elPrep. Since lambda expressions have recently been added to languages such as C++11 and Java 8, such a redesign should be viable for at least some of the related work.</p>
    <p>Other related work focuses on integrating complete pipelines into single applications with a focus on taking advantage of computational resources, like BALSA [<xref rid="pone.0132868.ref017" ref-type="bibr">17</xref>], optimised for GPUs, and ISAAC [<xref rid="pone.0132868.ref018" ref-type="bibr">18</xref>], optimised for servers with high amounts of RAM. Since these tools have full control over the pipeline, they have more opportunities for optimisations, such as defining their own alignment format instead of using the generic SAM format (BALSA), or partially combining secondary analysis steps such as filtering with the alignment phase (ISAAC). However, an advantage of using de-facto, community-driven standard file formats like SAM/BAM/CRAM is that they provide scientists the freedom to freely choose different tools from different tool authors for different phases of the pipeline. This is also partially acknowledged by the integrated pipeline solutions, in that they are also split into subtools: ISAAC comes with a separate aligner and variant caller and is open source, so that modifications to these tools are in principle possible; BALSA, while closed source, provides <italic>snapshot files</italic>, its own format for representing alignments, which can be used to implement one’s own secondary analysis and variant caller tools. Unlike these other integrated tools, elPrep focuses on modifying SAM/BAM/CRAM files to ease the combined use of different aligners and variant callers.</p>
  </sec>
  <sec id="sec020">
    <title>Conclusions and Future Work</title>
    <p>The main contribution of this paper is a software architecture for SAM/BAM manipulation tools that only requires a single pass through a SAM file to execute a sequencing pipeline, independent of which and how many tools need to be applied. The idea is to define the execution engine in terms of higher-order functions and define the manipulation tools as lambda expressions, allowing for a modular design where individual tools are implemented without a need to know how the other tools are implemented or how they are executed (in parallel) by the execution engine.</p>
    <p>We have implemented this architecture as a tool called elPrep. With elPrep, a user speficies a sequencing pipeline as a single command, and elPrep takes care of merging and parallelising the execution of the different steps within the pipeline. Our benchmarks show this is much faster than executing the steps one after the other by using separate command invocations, which is the standard practice for defining sequencing pipelines today. elPrep avoids the repeated file I/O that occurs between seperate command invocations, as well as the repeated traversals of the same SAM files, and the explicit synchronisation that limits parallelism with separate command invocations.</p>
    <p>Concretely, elPrep executes a five-step pipeline used at Janssen Pharmaceutica between six to ten times faster—depending on how much memory elPrep is allowed to use—than using a combination of SAMtools and Picard invocations. Similarly, elPrep executes a two-step and three-step pipeline from the GATK Best Practices recommendations between respectively three to five times and five to seven times faster than Picard. For exome workloads this means elPrep reduces the runtime from about 1:40 hours to about 10 to 15 minutes, saving hundreds of hours of computation time in a typical clinical experiment. The benefit would be even larger for whole-genome data, where SAM files are ten to twenty times larger.</p>
    <p>A possible drawback of elPrep is that it is currently under development, and more mature tools such as SAMtools and Picard are more feature complete.</p>
    <p>elPrep focuses on preparation tools for SAM/BAM/CRAM files. We think it should be possible to further optimise the whole sequencing pipeline to take advantage of the single-pass execution strategy of elPrep. For example, elPrep relies on a splitting phase that takes the BAM file and splits it up according to genomic regions for parallel processing. However, we could adapt the aligner tool to directly output multiple split files instead of writing a single BAM file. While this is a minor modification to the aligner, we would avoid the cost of splitting up the BAM file in elPrep. We have not yet explored this in detail.</p>
    <p>Another feature of our architecture that we did not discuss in this paper, is that our architecture is agnostic with regard to where input, intermediate, and output data are stored. The framework is designed in such a way that data can reside in files on disk, in memory, or even in a database. For example, preliminary support for MongoDB is provided as a separate extension library for elPrep. Such a feature is interesting for connecting interactive applications to sequencing pipelines, but we need to further explore the impact on performance of our approach.</p>
    <p>elPrep can be used as a plugin for the Halvade MapReduce framework for executing sequencing pipelines in parallel on a cluster [<xref rid="pone.0132868.ref019" ref-type="bibr">19</xref>]. This is particularly interesting for further parallelising the execution of whole-genome data.</p>
  </sec>
  <sec sec-type="supplementary-material" id="sec021">
    <title>Supporting Information</title>
    <supplementary-material content-type="local-data" id="pone.0132868.s001">
      <label>S1 Appendix</label>
      <caption>
        <title>Detailed overview of related work.</title>
        <p>Benchmarks and discussion of bamUtil, biobambam, Sambamba, SAMBLASTER, and SAMtools, compared to elPrep.</p>
        <p>(PDF)</p>
      </caption>
      <media xlink:href="pone.0132868.s001.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material content-type="local-data" id="pone.0132868.s002">
      <label>S2 Appendix</label>
      <caption>
        <title>Validation of elPrep output compared to Picard/SAMtools output.</title>
        <p>Detailed comparison of elPrep and Picard/SAMtools output using textual comparison (<italic>diff</italic>).</p>
        <p>(PDF)</p>
      </caption>
      <media xlink:href="pone.0132868.s002.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ack>
    <p>We thank Gert Pauwels from Intel for providing support and access to benchmark servers.</p>
  </ack>
  <ref-list>
    <title>References</title>
    <ref id="pone.0132868.ref001">
      <label>1</label>
      <mixed-citation publication-type="journal"><name><surname>Li</surname><given-names>H</given-names></name>, <name><surname>Durbin</surname><given-names>R</given-names></name>. <article-title>Fast and accurate short read alignment with Burrows-Wheeler Transform</article-title>. <source>Bioinformatics</source>. <year>2009</year><month>7</month><day>15</day>;<volume>25</volume>(<issue>14</issue>):<fpage>1754</fpage>–<lpage>60</lpage>. <pub-id pub-id-type="doi">10.1093/bioinformatics/btp324</pub-id><?supplied-pmid 19451168?><pub-id pub-id-type="pmid">19451168</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0132868.ref002">
      <label>2</label>
      <mixed-citation publication-type="journal"><name><surname>DePristo</surname><given-names>M</given-names></name>, <name><surname>Banks</surname><given-names>E</given-names></name>, <name><surname>Poplin</surname><given-names>R</given-names></name>, <name><surname>Garimella</surname><given-names>K</given-names></name>, <name><surname>Maguire</surname><given-names>J</given-names></name>, <name><surname>Hartl</surname><given-names>C</given-names></name>, <etal>et al</etal><article-title>A framework for variation discovery and genotyping using next-generation DNA sequencing data</article-title>. <source>Nature Genetics</source>. <year>2011</year><month>4</month><day>10</day>;<volume>43</volume>,<fpage>491</fpage>–<lpage>498</lpage>. <pub-id pub-id-type="doi">10.1038/ng.806</pub-id><?supplied-pmid 21478889?><pub-id pub-id-type="pmid">21478889</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0132868.ref003">
      <label>3</label>
      <mixed-citation publication-type="journal"><name><surname>Li</surname><given-names>H</given-names></name>, <name><surname>Hansaker</surname><given-names>B</given-names></name>, <name><surname>Wysoker</surname><given-names>A</given-names></name>, <name><surname>Fennell</surname><given-names>T</given-names></name>, <name><surname>Ruan</surname><given-names>J</given-names></name>, <name><surname>Homer</surname><given-names>N</given-names></name>, <etal>et al</etal><article-title>The Sequence Alignment/Map format and SAMtools</article-title>. <source>Bioinformatics</source>. <year>2009</year><month>8</month><day>15</day>;<volume>25</volume>(<issue>16</issue>):<fpage>2078</fpage>–<lpage>9</lpage>. <pub-id pub-id-type="doi">10.1093/bioinformatics/btp352</pub-id><?supplied-pmid 19505943?><pub-id pub-id-type="pmid">19505943</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0132868.ref004">
      <label>4</label>
      <mixed-citation publication-type="journal"><name><surname>Fritz</surname><given-names>M</given-names></name>, <name><surname>Leinonen</surname><given-names>R</given-names></name>, <name><surname>Cochrane</surname><given-names>G</given-names></name>, <name><surname>Birney</surname><given-names>E</given-names></name>. <article-title>Efficient storage of high throughput DNA sequencing data using reference-based compression</article-title>. <source>Genome Res</source>. <year>2011</year><month>1</month><day>18</day>;<volume>21</volume>:<fpage>734</fpage>–<lpage>740</lpage>.<pub-id pub-id-type="pmid">21245279</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0132868.ref005">
      <label>5</label>
      <mixed-citation publication-type="journal"><name><surname>Cochrane</surname><given-names>G</given-names></name>, <name><surname>Cook</surname><given-names>C</given-names></name>, <name><surname>Birney</surname><given-names>E</given-names></name>. <article-title>The future of DNA sequencing archiving</article-title>. <source>GigaScience</source>. <year>2012</year><month>7</month><day>12</day>;<volume>1</volume>:<fpage>2</fpage><pub-id pub-id-type="doi">10.1186/2047-217X-1-2</pub-id><?supplied-pmid 23587147?><pub-id pub-id-type="pmid">23587147</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0132868.ref006">
      <label>6</label>
      <mixed-citation publication-type="other">The SAM/BAM Format Specification Working Group. Sequence Alignment/Map Format Specification. 2015 March 3 [cited 24 March 2015]. Available: <ext-link ext-link-type="uri" xlink:href="http://github.com/samtools/sam-spec">http://github.com/samtools/sam-spec</ext-link>.</mixed-citation>
    </ref>
    <ref id="pone.0132868.ref007">
      <label>7</label>
      <mixed-citation publication-type="journal"><name><surname>Van der Auwera</surname><given-names>G</given-names></name>, <name><surname>Carneiro</surname><given-names>M</given-names></name>, <name><surname>Hartl</surname><given-names>C</given-names></name>, <name><surname>Poplin</surname><given-names>R</given-names></name>, <name><surname>del Angel</surname><given-names>G</given-names></name>, <name><surname>Levy-Moonshine</surname><given-names>A</given-names></name>, <etal>et al</etal><article-title>From FastQ Data to High-Confidence Variant Calls: The Genome Analysis Toolkit Best Practices Pipeline</article-title>. <source>Curr Protoc Bioinformatics</source>. <year>2013</year><month>10</month><day>15</day>;<volume>43</volume>:<fpage>11.10.1</fpage>–<lpage>11.10.33</lpage>.<pub-id pub-id-type="pmid">25431634</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0132868.ref008">
      <label>8</label>
      <mixed-citation publication-type="journal"><name><surname>Guimera</surname><given-names>R</given-names></name>, <name><surname>Chapman</surname><given-names>B</given-names></name>. <article-title>bcbio-nextgen: Automated, distributed, next-gen sequencing pipeline</article-title>. <source>EMBnet.journal</source>. <year>2012</year>; <volume>7.B</volume>:p.<fpage>30</fpage><pub-id pub-id-type="doi">10.14806/ej.17.B.286</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0132868.ref009">
      <label>9</label>
      <mixed-citation publication-type="journal"><name><surname>Blumofe</surname><given-names>R</given-names></name>, <name><surname>Leiserson</surname><given-names>C</given-names></name>. <article-title>Scheduling Multithreaded Computations by Work Stealing</article-title>. <source>Journal of the ACM</source>. <year>1999</year><month>9</month>;<volume>46</volume>,<issue>5</issue>, <fpage>720</fpage>–<lpage>748</lpage>. <pub-id pub-id-type="doi">10.1145/324133.324234</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0132868.ref010">
      <label>10</label>
      <mixed-citation publication-type="other">Van der Auwera G. Collected FAQs about BAM files. 2013 March [cited 24 March 2015]. Available: <ext-link ext-link-type="uri" xlink:href="http://gatkforums.broadinstitute.org/discussion/1317/collected-faqs-about-bam-files">http://gatkforums.broadinstitute.org/discussion/1317/collected-faqs-about-bam-files</ext-link>
</mixed-citation>
    </ref>
    <ref id="pone.0132868.ref011">
      <label>11</label>
      <mixed-citation publication-type="other">National Center for Biotechnology Information. 2014 Oct 12 [cited 24 March 2015]. Available: <ext-link ext-link-type="uri" xlink:href="http://www.ncbi.nlm.nih.gov/sra/SRX731649">http://www.ncbi.nlm.nih.gov/sra/SRX731649</ext-link>
</mixed-citation>
    </ref>
    <ref id="pone.0132868.ref012">
      <label>12</label>
      <mixed-citation publication-type="other">European Nucleotide Archive. 2012 Nov 12 [cited 24 March 2015]. Available: <ext-link ext-link-type="uri" xlink:href="http://www.ebi.ac.uk/ena/data/view/ERP001960">http://www.ebi.ac.uk/ena/data/view/ERP001960</ext-link>
</mixed-citation>
    </ref>
    <ref id="pone.0132868.ref013">
      <label>13</label>
      <mixed-citation publication-type="other">Wing MK. bamUtil Overview. 2010 Apr 6 [cited 19 May 2015]. Available: <ext-link ext-link-type="uri" xlink:href="http://genome.sph.umich.edu/wiki/BamUtil">http://genome.sph.umich.edu/wiki/BamUtil</ext-link>
</mixed-citation>
    </ref>
    <ref id="pone.0132868.ref014">
      <label>14</label>
      <mixed-citation publication-type="journal"><name><surname>Tischler</surname><given-names>G</given-names></name>, <name><surname>Leonard</surname><given-names>S</given-names></name>. <article-title>biobambam: tools for read pair collation based algorithms on BAM files</article-title>. <source>Source Code Biol Med</source>. <year>2014</year><month>6</month><day>20</day>;<volume>9</volume>:<fpage>13</fpage><pub-id pub-id-type="doi">10.1186/1751-0473-9-13</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0132868.ref015">
      <label>15</label>
      <mixed-citation publication-type="other">Tarasov A. Sambamba. 2012 Apr 28 [cited 19 May 2015]. Available: <ext-link ext-link-type="uri" xlink:href="https://github.com/lomereiter/sambamba">https://github.com/lomereiter/sambamba</ext-link>
</mixed-citation>
    </ref>
    <ref id="pone.0132868.ref016">
      <label>16</label>
      <mixed-citation publication-type="journal"><name><surname>Faust</surname><given-names>G</given-names></name>, <name><surname>Hall</surname><given-names>I</given-names></name>. <article-title>SAMBLASTER: fast duplicate marking and structural variant read extraction</article-title>. <source>Bioinformatics</source>. <year>2014</year><month>9</month><day>1</day>;<volume>30</volume>(<issue>17</issue>):<fpage>2503</fpage>–<lpage>5</lpage>. <pub-id pub-id-type="doi">10.1093/bioinformatics/btu314</pub-id><?supplied-pmid 24812344?><pub-id pub-id-type="pmid">24812344</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0132868.ref017">
      <label>17</label>
      <mixed-citation publication-type="journal"><name><surname>Luo</surname><given-names>R</given-names></name>, <name><surname>Wong</surname><given-names>Y</given-names></name>, <name><surname>Law</surname><given-names>W</given-names></name>, <name><surname>Lee</surname><given-names>L</given-names></name>, <name><surname>Cheung</surname><given-names>J</given-names></name>, <name><surname>Liu</surname><given-names>C</given-names></name>, <etal>et al</etal><article-title>BALSA: integrated secondary analysis for whole-genome and whole-exome sequencing, accelerated by GPU</article-title>. <source>PeerJ</source>. <year>2014</year><month>6</month><day>3</day>;<volume>2</volume>:<fpage>e421</fpage><pub-id pub-id-type="doi">10.7717/peerj.421</pub-id><?supplied-pmid 24949238?><pub-id pub-id-type="pmid">24949238</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0132868.ref018">
      <label>18</label>
      <mixed-citation publication-type="journal"><name><surname>Raczy</surname><given-names>C</given-names></name>, <name><surname>Petrovski</surname><given-names>R</given-names></name>, <name><surname>Saunders</surname><given-names>CT</given-names></name>, <name><surname>Chorny</surname><given-names>I</given-names></name>, <name><surname>Kruglyak</surname><given-names>S</given-names></name>, <name><surname>Margulies</surname><given-names>EH</given-names></name>, <etal>et al</etal><article-title>Isaac: ultra-fast whole-genome secondary analysis on Illumina sequencing platforms</article-title>. <source>Bioinformatics</source>. <year>2013</year><month>8</month><day>15</day>;<volume>29</volume>(<issue>16</issue>):<fpage>2041</fpage>–<lpage>3</lpage>. <pub-id pub-id-type="doi">10.1093/bioinformatics/btt314</pub-id><?supplied-pmid 23736529?><pub-id pub-id-type="pmid">23736529</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0132868.ref019">
      <label>19</label>
      <mixed-citation publication-type="journal"><name><surname>Decap</surname><given-names>D</given-names></name>, <name><surname>Reumers</surname><given-names>J</given-names></name>, <name><surname>Herzeel</surname><given-names>C</given-names></name>, <name><surname>Costanza</surname><given-names>P</given-names></name>, <name><surname>Fostier</surname><given-names>J</given-names></name>. <article-title>Halvade: scalable sequence analysis with MapReduce</article-title>. <source>Bioinformatics</source>. <year>2015</year><month>3</month><day>26</day> In press. <pub-id pub-id-type="doi">10.1093/bioinformatics/btv179</pub-id>
<?supplied-pmid 25819078?><pub-id pub-id-type="pmid">25819078</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
