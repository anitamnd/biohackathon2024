<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinform Adv</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinform Adv</journal-id>
    <journal-id journal-id-type="publisher-id">bioadv</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics Advances</journal-title>
    </journal-title-group>
    <issn pub-type="epub">2635-0041</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">9710621</article-id>
    <article-id pub-id-type="doi">10.1093/bioadv/vbac053</article-id>
    <article-id pub-id-type="publisher-id">vbac053</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Application Note</subject>
        <subj-group subj-group-type="category-toc-heading">
          <subject>Bioimage Informatics</subject>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI01060</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>CellSium: versatile cell simulator for microcolony ground truth generation</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Sachs</surname>
          <given-names>Christian Carsten</given-names>
        </name>
        <aff><institution>Institute of Bio- and Geosciences, IBG-1: Biotechnology, Forschungszentrum Jülich GmbH</institution>, 52425 Jülich, <country country="DE">Germany</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Ruzaeva</surname>
          <given-names>Karina</given-names>
        </name>
        <aff><institution>Institute of Bio- and Geosciences, IBG-1: Biotechnology, Forschungszentrum Jülich GmbH</institution>, 52425 Jülich, <country country="DE">Germany</country></aff>
        <aff><institution>Aachen Institute for Advanced Study in Computational Engineering Science (AICES), RWTH Aachen University</institution>, 52062 Aachen, <country country="DE">Germany</country></aff>
        <xref rid="vbac053-FM1" ref-type="author-notes"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Seiffarth</surname>
          <given-names>Johannes</given-names>
        </name>
        <aff><institution>Institute of Bio- and Geosciences, IBG-1: Biotechnology, Forschungszentrum Jülich GmbH</institution>, 52425 Jülich, <country country="DE">Germany</country></aff>
        <aff><institution>Computational Systems Biotechnology (AVT.CSB), RWTH Aachen University</institution>, 52074 Aachen, <country country="DE">Germany</country></aff>
        <xref rid="vbac053-FM1" ref-type="author-notes"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Wiechert</surname>
          <given-names>Wolfgang</given-names>
        </name>
        <aff><institution>Institute of Bio- and Geosciences, IBG-1: Biotechnology, Forschungszentrum Jülich GmbH</institution>, 52425 Jülich, <country country="DE">Germany</country></aff>
        <aff><institution>Computational Systems Biotechnology (AVT.CSB), RWTH Aachen University</institution>, 52074 Aachen, <country country="DE">Germany</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Berkels</surname>
          <given-names>Benjamin</given-names>
        </name>
        <aff><institution>Aachen Institute for Advanced Study in Computational Engineering Science (AICES), RWTH Aachen University</institution>, 52062 Aachen, <country country="DE">Germany</country></aff>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-5407-2275</contrib-id>
        <name>
          <surname>Nöh</surname>
          <given-names>Katharina</given-names>
        </name>
        <aff><institution>Institute of Bio- and Geosciences, IBG-1: Biotechnology, Forschungszentrum Jülich GmbH</institution>, 52425 Jülich, <country country="DE">Germany</country></aff>
        <xref rid="vbac053-cor1" ref-type="corresp"/>
        <!--k.noeh@fz-juelich.de-->
      </contrib>
    </contrib-group>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Bateman</surname>
          <given-names>Alex</given-names>
        </name>
        <role>Associate Editor</role>
      </contrib>
    </contrib-group>
    <author-notes>
      <fn id="vbac053-FM1">
        <p>Karina Ruzaeva and Johannes Seiffarth wish it to be known that these authors contributed equally.</p>
      </fn>
      <corresp id="vbac053-cor1">To whom correspondence should be addressed. <email>k.noeh@fz-juelich.de</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2022-08-03">
      <day>03</day>
      <month>8</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>03</day>
      <month>8</month>
      <year>2022</year>
    </pub-date>
    <volume>2</volume>
    <issue>1</issue>
    <elocation-id>vbac053</elocation-id>
    <history>
      <date date-type="received">
        <day>06</day>
        <month>5</month>
        <year>2022</year>
      </date>
      <date date-type="rev-recd">
        <day>25</day>
        <month>7</month>
        <year>2022</year>
      </date>
      <date date-type="editorial-decision">
        <day>26</day>
        <month>7</month>
        <year>2022</year>
      </date>
      <date date-type="accepted">
        <day>28</day>
        <month>7</month>
        <year>2022</year>
      </date>
      <date date-type="corrected-typeset">
        <day>12</day>
        <month>8</month>
        <year>2022</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2022. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2022</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="vbac053.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Summary</title>
        <p>To train deep learning-based segmentation models, large ground truth datasets are needed. To address this need in microfluidic live-cell imaging, we present <italic toggle="yes">CellSium</italic>, a flexibly configurable cell simulator built to synthesize realistic image sequences of bacterial microcolonies growing in monolayers. We illustrate that the simulated images are suitable for training neural networks. Synthetic time-lapse videos with and without fluorescence, using programmable cell growth models, and simulation-ready 3D colony geometries for computational fluid dynamics are also supported.</p>
      </sec>
      <sec id="s2">
        <title>Availability and implementation</title>
        <p><italic toggle="yes">CellSium</italic> is free and open source software under the BSD license, implemented in Python, available at <ext-link xlink:href="https://github.com/modsim/cellsium" ext-link-type="uri">github.com/modsim/cellsium</ext-link> (DOI: 10.5281/zenodo.6193033), along with documentation, usage examples and Docker images.</p>
      </sec>
      <sec id="s4">
        <title>Supplementary information</title>
        <p><xref rid="sup1" ref-type="supplementary-material">Supplementary data</xref> are available at <italic toggle="yes">Bioinformatics Advances</italic> online.</p>
      </sec>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Deutsche Forschungsgemeinschaft</institution>
            <institution-id institution-id-type="DOI">10.13039/501100001659</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>WI 1705/16-2</award-id>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="3"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 Introduction</title>
    <p>Deep learning (DL)-based segmentation methods have become the standard for bioimage analysis, largely surpassing traditional approaches (<xref rid="vbac053-B5" ref-type="bibr">Jeckel and Drescher, 2021</xref>). A bottleneck in the application of DL techniques is the need for comprehensive ground truth (GT) data for training and validation. For the task of cell segmentation, for example, pixel-perfect masks discerning individual cells from the background are crucial. Such data are, however, problem-specific and laborious to produce (<xref rid="vbac053-B5" ref-type="bibr">Jeckel and Drescher, 2021</xref>). Synthesizing data along with its GT is a tried and tested way to alleviate this bottleneck. Cell simulators have been built to form a better understanding of biological growth phenomena, by modeling molecular aspects, rather than aiming at generating photorealistic images (e.g. <xref rid="vbac053-B3" ref-type="bibr">Gutiérrez <italic toggle="yes">et al.</italic>, 2017</xref>). For eukaryotic cells, data augmentation using (fluorescence) image generators is well established (e.g. <xref rid="vbac053-B8" ref-type="bibr">Lehmussola <italic toggle="yes">et al.</italic>, 2007</xref>; <xref rid="vbac053-B9" ref-type="bibr">Svoboda and Ulman, 2017</xref>). However, apart from an example for brightfield yeast image generation (<xref rid="vbac053-B7" ref-type="bibr">Kruitbosch <italic toggle="yes">et al.</italic>, 2022</xref>), the benefits of synthetic imagine generation have not been exploited for microbial image analysis, in particular in the field of phase contrast microscopy.</p>
    <p>To serve the needs of training data hungry DL approaches to analyze phase contrast image stacks, we have developed the highly configurable bacterial microcolony simulator <italic toggle="yes">CellSium</italic>. We demonstrate its applicability for object detection (YOLOv5) as well as semantic segmentation (Mask R-CNN) using synthetic data and verify the resulting neural networks with real image data. Further usage scenarios of <italic toggle="yes">CellSium</italic> beyond image synthetization are also showcased.</p>
  </sec>
  <sec>
    <title>2 Approach</title>
    <p><italic toggle="yes">CellSium</italic> is an agent-based simulator. Internally, each cell is represented as a Python object, with individual properties, such as shape or growth behavior, implemented as mixins following object-oriented programming paradigms. Cell geometries are modeled via closed polygonal chains, allowing for arbitrary shapes (<xref rid="sup1" ref-type="supplementary-material">Supplementary Section</xref><xref rid="sup1" ref-type="supplementary-material"> S.1</xref>). Various common ready-to-use unicellular geometries are implemented, such as straight and bent rods, simple coccoid (circular) and ellipsoid shapes (<xref rid="sup1" ref-type="supplementary-material">Supplementary </xref><xref rid="sup1" ref-type="supplementary-material">Fig. S.2</xref>). Colony growth behavior is implemented in the <monospace>grow()</monospace> function. Here, phenomenological cell size homeostasis models, such as ‘timer’ or ‘sizer’ can be realized (<xref rid="sup1" ref-type="supplementary-material">Supplementary </xref><xref rid="sup1" ref-type="supplementary-material">Section S.2</xref>) (<xref rid="vbac053-B10" ref-type="bibr">Taheri-Araghi <italic toggle="yes">et al.</italic>, 2015</xref>). The <monospace>grow()</monospace> method is then called for each simulated time step and cell geometries are used with a physics engine to calculate feasible cell placements. Various output routines exist, such as realistic phase contrast images, time-lapse videos, TrackMate XML (<xref rid="vbac053-B11" ref-type="bibr">Tinevez <italic toggle="yes">et al.</italic>, 2017</xref>) or simulation-ready input geometries for computational fluid dynamics (CFD) simulations (<xref rid="sup1" ref-type="supplementary-material">Supplementary </xref><xref rid="sup1" ref-type="supplementary-material">Section S.3</xref>).</p>
    <p>The image generation process is shown in <xref rid="vbac053-F1" ref-type="fig">Figure 1A</xref>: A ‘perfect’ (noiseless) image is generated (A1–A5), which is deteriorated by adding different kinds of noise. The typical phase contrast ‘halo’ around the cells is generated by Gaussian blurring of the image (A2–A4), which is combined to mimic a phase contrast image (A5). Next, uneven illumination is added (A6), along with additive/multiplicative noise (A7, A9), yielding a realistic phase contrast bacterial cell image (A10). All noise models are flexibly configurable. This allows, for instance, simulating deteriorated image quality (<xref rid="sup1" ref-type="supplementary-material">Supplementary </xref><xref rid="sup1" ref-type="supplementary-material">Section S.4</xref>), and makes <italic toggle="yes">CellSium</italic> readily transferable to other imaging modalities. Optionally, fluorescence can be generated using a Gaussian point spread function (<xref rid="sup1" ref-type="supplementary-material">Supplementary </xref><xref rid="sup1" ref-type="supplementary-material">Section S.5</xref>).</p>
    <fig position="float" id="vbac053-F1">
      <label>Fig. 1.</label>
      <caption>
        <p>(<bold>A</bold>) Highly configurable image generation flow to produce realistic phase contrast images. (<bold>B</bold>–<bold>E</bold>) Prediction results of neural networks trained with data simulated using <italic toggle="yes">CellSium</italic> and evaluated with real data. (<bold>B</bold>) Input image, a <italic toggle="yes">Corynebacterium glutamicum</italic> microcolony; (<bold>C</bold>) manually corrected GT; (<bold>D</bold>) YOLOv5 object detector result; and (<bold>E</bold>) Mask R-CNN segmentation network result</p>
      </caption>
      <graphic xlink:href="vbac053f1" position="float"/>
    </fig>
  </sec>
  <sec>
    <title>3 Methods</title>
    <p><italic toggle="yes">CellSium</italic> is implemented in the Python programming language, using NumPy and SciPy libraries (<ext-link xlink:href="http://github.com/numpy" ext-link-type="uri">http://github.com/numpy</ext-link>, <ext-link xlink:href="http://github.com/scipy/scipy" ext-link-type="uri">http://github.com/scipy/scipy</ext-link>), as well as matplotlib (<ext-link xlink:href="http://github.com/matplotlib" ext-link-type="uri">http://github.com/matplotlib</ext-link>) and OpenCV (<ext-link xlink:href="http://github.com/opencv" ext-link-type="uri">http://github.com/opencv</ext-link>) for image generation. Physical placement simulation is performed using the off-the-shelve 2D physics library PyMunk (<ext-link xlink:href="http://github.com/viblo/pymunk" ext-link-type="uri">http://github.com/viblo/pymunk</ext-link>). Source code, PyPI/Anaconda packages and a Docker image are available, enabling platform-independent usage. The documentation includes application programming interface (API) documentation, as well as usage examples for configuring time-lapse simulations, 3D cell geometries and parametrizable cell models (<xref rid="sup1" ref-type="supplementary-material">Supplementary Section S.1–S.3</xref>).</p>
  </sec>
  <sec>
    <title>4 Use case: <italic toggle="yes">CellSium</italic> as GT generator</title>
    <p>To assess the applicability of <italic toggle="yes">CellSium</italic> as a GT generator, a dataset was generated using the <italic toggle="yes">YOLOOutput</italic> and <italic toggle="yes">COCOOutput</italic> modules (128 images, 512 × 512, 0.09 µm/pixel, 0–512 cells per frame). Synthesized images are verified to have a similar intensity distribution compared to real images with the similar cell/background ratio (<xref rid="sup1" ref-type="supplementary-material">Supplementary Section S.6</xref>). The synthesized outputs were then used to train the object detector/segmentation frameworks YOLOv5 (<xref rid="vbac053-B6" ref-type="bibr">Jocher <italic toggle="yes">et al.</italic>, 2020</xref>) and the Mask R-CNN (<xref rid="vbac053-B4" ref-type="bibr">He <italic toggle="yes">et al.</italic>, 2017</xref>) module of MMDetection (<xref rid="vbac053-B2" ref-type="bibr">Chen <italic toggle="yes">et al.</italic>, 2019</xref>). As test data, a microcolony image of <italic toggle="yes">Corynebacterium glutamicum</italic> was used (<xref rid="vbac053-F1" ref-type="fig">Fig. 1B</xref>), which was interactively segmented using the Trainable Weka Segmentation (<xref rid="vbac053-B1" ref-type="bibr">Arganda-Carreras <italic toggle="yes">et al.</italic>, 2017</xref>) and then hand-corrected (<xref rid="vbac053-F1" ref-type="fig">Fig. 1C</xref>).</p>
    <p>The YOLOv5 (You Only Look Once v5, <italic toggle="yes">ultralytics/yolov5</italic> v4.0) net was trained in <italic toggle="yes">yolo5l</italic> mode for 300 epochs, and the test data were predicted with an intersection over union threshold for non-maximum suppression of 0.6 and a confidence threshold of 0.001. A Mask R-CNN (Region-Convolutional Neural Network) was trained using the MMDetection framework (<italic toggle="yes">open-mmlab/mmdetection</italic> v2.17.0) for 13 epochs, and the test data were predicted with proposal counts raised to accommodate for the cell count (nms_pre/rpn.max_per_img/rccn.max_per_img 12000/4000/3000 and a score threshold of 0.5).</p>
    <p>The mean average precision (mAP) results are given in <xref rid="vbac053-T1" ref-type="table">Table 1</xref>. The YOLO net yielded a mAP<sub>50</sub> of 0.994, while the Mask R-CNN yielded a mAP<sub>50</sub> of 0.987 for both bounding boxes segmentations. All files to reproduce the evaluation are available in the GitHub repository <ext-link xlink:href="http://github.com/modsim/cellsium" ext-link-type="uri">http://github.com/modsim/cellsium</ext-link>.</p>
    <table-wrap position="float" id="vbac053-T1">
      <label>Table 1</label>
      <caption>
        <p>Mean average precision (mAP) results for trained YOLOv5 and Mask R-CNN networks</p>
      </caption>
      <table frame="hsides" rules="groups">
        <colgroup span="1">
          <col valign="top" align="left" span="1"/>
          <col valign="top" align="char" char="." span="1"/>
          <col valign="top" align="char" char="." span="1"/>
          <col valign="top" align="center" span="1"/>
          <col valign="top" align="center" span="1"/>
        </colgroup>
        <thead>
          <tr>
            <th rowspan="1" colspan="1"/>
            <th colspan="2" align="center" rowspan="1">Bounding box<hr/></th>
            <th colspan="2" rowspan="1">Segmentation<hr/></th>
          </tr>
          <tr>
            <th rowspan="1" colspan="1">Network</th>
            <th rowspan="1" colspan="1">mAP<sub>0.5:0.95</sub></th>
            <th rowspan="1" colspan="1">mAP<sub>0.5</sub></th>
            <th rowspan="1" colspan="1">mAP<sub>0.5:0.95</sub></th>
            <th rowspan="1" colspan="1">mAP<sub>0.5</sub></th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td rowspan="1" colspan="1">YOLOv5</td>
            <td rowspan="1" colspan="1">0.667</td>
            <td rowspan="1" colspan="1">0.994</td>
            <td rowspan="1" colspan="1">–</td>
            <td rowspan="1" colspan="1">–</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">Mask R-CNN</td>
            <td rowspan="1" colspan="1">0.465</td>
            <td rowspan="1" colspan="1">0.987</td>
            <td rowspan="1" colspan="1">0.470</td>
            <td rowspan="1" colspan="1">0.987</td>
          </tr>
        </tbody>
      </table>
      <table-wrap-foot>
        <fn id="tblfn1">
          <p>Tests were performed on an Intel Core i7 4790 (3.6 GHz, 8 threads), 32 GB, GeForce GTX 1080 Ti Linux workstation.</p>
        </fn>
      </table-wrap-foot>
    </table-wrap>
  </sec>
  <sec>
    <title>5 Conclusion</title>
    <p><italic toggle="yes">CellSium</italic> is a microcolony simulator primarily aimed at bacterial image dataset GT generation. Simulated training data showed high-intensity histogram correlation with real data and were proven useful for state-of-the-art object detector/segmentation frameworks (YOLOv5, Mask R-CNN), yielding networks capable of producing competitive results with real time-lapse microscopy images. Compared to the laborious manual annotation of image sequences, taking an <italic toggle="yes">in silico</italic> approach allows generating labeled data with desired characteristics at any amounts, which benefits training and method verification. Likewise, <italic toggle="yes">CellSium</italic> is an effective education tool that allows users, in a well-defined environment, to train method usage or to test phenomenological cell growth models and their impact on the growth characteristics of microcolonies. Finally, developers of bioimage analysis algorithms can benchmark and validate their segmentation and tracking methods with the simulator in flexibly configurable settings.</p>
    <p><italic toggle="yes">CellSium</italic> can be easily used as-is, or, due to its pluggable architecture, serve as a base for implementing other cell types, developing custom cell behavior within growing microcolonies, or embedding the image generation, for example directly in a DL training loop for continuous procedural training data generation. <italic toggle="yes">CellSium’</italic>s current image generation capabilities are well-suited for training networks tailored to one imaging modality. A future step, owing to its highly flexible noise model, is to implement generative adversarial networks to achieve a high level of realism, independent of the modality.</p>
  </sec>
  <sec>
    <title>Funding</title>
    <p>This work was supported by the Deutsche Forschungsgemeinschaft [WI 1705/16-2], the President’s Initiative and Networking Funds of the Helmholtz Association of German Research Centres [SATOMI ZT-I-PF-04-011] and was performed as part of the Helmholtz School for Data Science in Life, Earth and Energy (HDS-LEE) and received funding from the Helmholtz Association of German Research Centres. Open Access publication funded by the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) [491111487].</p>
    <p><italic toggle="yes">Conflict of Interest</italic>: none declared.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material id="sup1" position="float" content-type="local-data">
      <label>vbac053_Supplementary_Data</label>
      <media xlink:href="vbac053_supplementary_data.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="vbac053-B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Arganda-Carreras</surname><given-names>I.</given-names></string-name></person-group><etal>et al</etal> (<year>2017</year>) <article-title>Trainable Weka segmentation: a machine learning tool for microscopy pixel classification</article-title>. <source>Bioinformatics</source>, <volume>33</volume>, <fpage>2424</fpage>–<lpage>2426</lpage>.<pub-id pub-id-type="pmid">28369169</pub-id></mixed-citation>
    </ref>
    <ref id="vbac053-B2">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Chen</surname><given-names>K.</given-names></string-name></person-group><etal>et al</etal> (<year>2019</year>) MMDetection: Open MMLab detection toolbox and benchmark. <italic toggle="yes">arXiv:1906.07155</italic>.</mixed-citation>
    </ref>
    <ref id="vbac053-B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gutiérrez</surname><given-names>M.</given-names></string-name></person-group><etal>et al</etal> (<year>2017</year>) <article-title>A new improved and extended version of the multicell bacterial simulator gro</article-title>. <source>ACS Synth. Biol</source>., <volume>6</volume>, <fpage>1496</fpage>–<lpage>1508</lpage>.<pub-id pub-id-type="pmid">28438021</pub-id></mixed-citation>
    </ref>
    <ref id="vbac053-B4">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>He</surname><given-names>K.</given-names></string-name></person-group> et al (2020) Mask R-CNN. IEEE Trans. Pattern Anal. Mach. Intell., 42, 386–397.</mixed-citation>
    </ref>
    <ref id="vbac053-B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jeckel</surname><given-names>H.</given-names></string-name>, <string-name><surname>Drescher</surname><given-names>K.</given-names></string-name></person-group> (<year>2021</year>) <article-title>Advances and opportunities in image analysis of bacterial cells and communities</article-title>. <source>FEMS Microbiol. Rev</source>., <volume>45</volume>, <fpage>1</fpage>–<lpage>14</lpage>.</mixed-citation>
    </ref>
    <ref id="vbac053-B6">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Jocher</surname><given-names>G.</given-names></string-name></person-group><etal>et al</etal> (<year>2020</year>) ultralytics/yolov5: v3.1—Bug fixes and performance improvements. <italic toggle="yes">zenodo</italic>. doi:<pub-id pub-id-type="doi">10.5281/zenodo.4154370</pub-id>.</mixed-citation>
    </ref>
    <ref id="vbac053-B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kruitbosch</surname><given-names>H.T.</given-names></string-name></person-group><etal>et al</etal> (<year>2022</year>) <article-title>A convolutional neural network for segmentation of yeast cells without manual training annotations</article-title>. <source>Bioinformatics</source>, <volume>38</volume>, <fpage>1427</fpage>–<lpage>1433</lpage>.</mixed-citation>
    </ref>
    <ref id="vbac053-B8">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lehmussola</surname><given-names>A.</given-names></string-name></person-group><etal>et al</etal> (<year>2007</year>) <article-title>Computational framework for simulating fluorescence microscope images with cell populations</article-title>. <source>IEEE Trans. Med. Imaging</source>, <volume>26</volume>, <fpage>1010</fpage>–<lpage>1016</lpage>.<pub-id pub-id-type="pmid">17649914</pub-id></mixed-citation>
    </ref>
    <ref id="vbac053-B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Svoboda</surname><given-names>D.</given-names></string-name>, <string-name><surname>Ulman</surname><given-names>V.</given-names></string-name></person-group> (<year>2017</year>) <article-title>Mitogen: a framework for generating 3D synthetic time-lapse sequences of cell populations in fluorescence microscopy</article-title>. <source>IEEE Trans. Med. Imaging</source>, <volume>36</volume>, <fpage>310</fpage>–<lpage>321</lpage>.<pub-id pub-id-type="pmid">27623575</pub-id></mixed-citation>
    </ref>
    <ref id="vbac053-B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Taheri-Araghi</surname><given-names>S.</given-names></string-name></person-group><etal>et al</etal> (<year>2015</year>) <article-title>Cell-size control and homeostasis in bacteria</article-title>. <source>Curr. Biol</source>., <volume>25</volume>, <fpage>385</fpage>–<lpage>391</lpage>.<pub-id pub-id-type="pmid">25544609</pub-id></mixed-citation>
    </ref>
    <ref id="vbac053-B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tinevez</surname><given-names>J.-Y.</given-names></string-name></person-group><etal>et al</etal> (<year>2017</year>) <article-title>Trackmate: an open and extensible platform for single-particle tracking</article-title>. <source>Methods</source>, <volume>115</volume>, <fpage>80</fpage>–<lpage>90</lpage>.<pub-id pub-id-type="pmid">27713081</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
