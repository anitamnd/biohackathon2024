<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1d3 20150301//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 39.96?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?covid-19-tdm?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">PLoS One</journal-id>
    <journal-id journal-id-type="iso-abbrev">PLoS One</journal-id>
    <journal-id journal-id-type="publisher-id">plos</journal-id>
    <journal-title-group>
      <journal-title>PLOS ONE</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1932-6203</issn>
    <publisher>
      <publisher-name>Public Library of Science</publisher-name>
      <publisher-loc>San Francisco, CA USA</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">9891495</article-id>
    <article-id pub-id-type="publisher-id">PONE-D-22-07646</article-id>
    <article-id pub-id-type="doi">10.1371/journal.pone.0281147</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Research Article</subject>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Medicine and Health Sciences</subject>
        <subj-group>
          <subject>Medical Conditions</subject>
          <subj-group>
            <subject>Infectious Diseases</subject>
            <subj-group>
              <subject>Viral Diseases</subject>
              <subj-group>
                <subject>Covid 19</subject>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Medicine and Health Sciences</subject>
        <subj-group>
          <subject>Epidemiology</subject>
          <subj-group>
            <subject>Pandemics</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Computer and Information Sciences</subject>
        <subj-group>
          <subject>Information Technology</subject>
          <subj-group>
            <subject>Natural Language Processing</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Medicine and Health Sciences</subject>
        <subj-group>
          <subject>Medical Conditions</subject>
          <subj-group>
            <subject>Infectious Diseases</subject>
            <subj-group>
              <subject>Viral Diseases</subject>
              <subj-group>
                <subject>SARS</subject>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Medicine and Health Sciences</subject>
        <subj-group>
          <subject>Public and Occupational Health</subject>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Medicine and Health Sciences</subject>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Social Sciences</subject>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and life sciences</subject>
        <subj-group>
          <subject>Organisms</subject>
          <subj-group>
            <subject>Viruses</subject>
            <subj-group>
              <subject>RNA viruses</subject>
              <subj-group>
                <subject>Coronaviruses</subject>
                <subj-group>
                  <subject>SARS coronavirus</subject>
                </subj-group>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and life sciences</subject>
        <subj-group>
          <subject>Microbiology</subject>
          <subj-group>
            <subject>Medical microbiology</subject>
            <subj-group>
              <subject>Microbial pathogens</subject>
              <subj-group>
                <subject>Viral pathogens</subject>
                <subj-group>
                  <subject>Coronaviruses</subject>
                  <subj-group>
                    <subject>SARS coronavirus</subject>
                  </subj-group>
                </subj-group>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Medicine and health sciences</subject>
        <subj-group>
          <subject>Pathology and laboratory medicine</subject>
          <subj-group>
            <subject>Pathogens</subject>
            <subj-group>
              <subject>Microbial pathogens</subject>
              <subj-group>
                <subject>Viral pathogens</subject>
                <subj-group>
                  <subject>Coronaviruses</subject>
                  <subj-group>
                    <subject>SARS coronavirus</subject>
                  </subj-group>
                </subj-group>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and life sciences</subject>
        <subj-group>
          <subject>Organisms</subject>
          <subj-group>
            <subject>Viruses</subject>
            <subj-group>
              <subject>Viral pathogens</subject>
              <subj-group>
                <subject>Coronaviruses</subject>
                <subj-group>
                  <subject>SARS coronavirus</subject>
                </subj-group>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>COVIDScholar: An automated COVID-19 research aggregation and analysis platform</article-title>
      <alt-title alt-title-type="running-head">COVIDScholar: An automated COVID-19 research aggregation and analysis platform</alt-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" corresp="yes" equal-contrib="yes">
        <contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-2181-4815</contrib-id>
        <name>
          <surname>Dagdelen</surname>
          <given-names>John</given-names>
        </name>
        <role content-type="http://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role>
        <role content-type="http://credit.niso.org/contributor-roles/data-curation/">Data curation</role>
        <role content-type="http://credit.niso.org/contributor-roles/formal-analysis/">Formal analysis</role>
        <role content-type="http://credit.niso.org/contributor-roles/funding-acquisition/">Funding acquisition</role>
        <role content-type="http://credit.niso.org/contributor-roles/investigation/">Investigation</role>
        <role content-type="http://credit.niso.org/contributor-roles/methodology/">Methodology</role>
        <role content-type="http://credit.niso.org/contributor-roles/project-administration/">Project administration</role>
        <role content-type="http://credit.niso.org/contributor-roles/software/">Software</role>
        <role content-type="http://credit.niso.org/contributor-roles/validation/">Validation</role>
        <role content-type="http://credit.niso.org/contributor-roles/visualization/">Visualization</role>
        <role content-type="http://credit.niso.org/contributor-roles/writing-original-draft/">Writing – original draft</role>
        <role content-type="http://credit.niso.org/contributor-roles/writing-review-editing/">Writing – review &amp; editing</role>
        <xref rid="aff001" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="aff002" ref-type="aff">
          <sup>2</sup>
        </xref>
        <xref rid="cor001" ref-type="corresp">*</xref>
      </contrib>
      <contrib contrib-type="author" equal-contrib="yes">
        <name>
          <surname>Trewartha</surname>
          <given-names>Amalie</given-names>
        </name>
        <role content-type="http://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role>
        <role content-type="http://credit.niso.org/contributor-roles/data-curation/">Data curation</role>
        <role content-type="http://credit.niso.org/contributor-roles/formal-analysis/">Formal analysis</role>
        <role content-type="http://credit.niso.org/contributor-roles/funding-acquisition/">Funding acquisition</role>
        <role content-type="http://credit.niso.org/contributor-roles/investigation/">Investigation</role>
        <role content-type="http://credit.niso.org/contributor-roles/methodology/">Methodology</role>
        <role content-type="http://credit.niso.org/contributor-roles/resources/">Resources</role>
        <role content-type="http://credit.niso.org/contributor-roles/software/">Software</role>
        <role content-type="http://credit.niso.org/contributor-roles/validation/">Validation</role>
        <role content-type="http://credit.niso.org/contributor-roles/visualization/">Visualization</role>
        <role content-type="http://credit.niso.org/contributor-roles/writing-original-draft/">Writing – original draft</role>
        <role content-type="http://credit.niso.org/contributor-roles/writing-review-editing/">Writing – review &amp; editing</role>
        <xref rid="aff001" ref-type="aff">
          <sup>1</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Huo</surname>
          <given-names>Haoyan</given-names>
        </name>
        <role content-type="http://credit.niso.org/contributor-roles/data-curation/">Data curation</role>
        <role content-type="http://credit.niso.org/contributor-roles/formal-analysis/">Formal analysis</role>
        <role content-type="http://credit.niso.org/contributor-roles/investigation/">Investigation</role>
        <role content-type="http://credit.niso.org/contributor-roles/software/">Software</role>
        <role content-type="http://credit.niso.org/contributor-roles/validation/">Validation</role>
        <role content-type="http://credit.niso.org/contributor-roles/visualization/">Visualization</role>
        <xref rid="aff001" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="aff002" ref-type="aff">
          <sup>2</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Fei</surname>
          <given-names>Yuxing</given-names>
        </name>
        <role content-type="http://credit.niso.org/contributor-roles/data-curation/">Data curation</role>
        <role content-type="http://credit.niso.org/contributor-roles/investigation/">Investigation</role>
        <role content-type="http://credit.niso.org/contributor-roles/software/">Software</role>
        <role content-type="http://credit.niso.org/contributor-roles/visualization/">Visualization</role>
        <xref rid="aff004" ref-type="aff">
          <sup>4</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>He</surname>
          <given-names>Tanjin</given-names>
        </name>
        <role content-type="http://credit.niso.org/contributor-roles/data-curation/">Data curation</role>
        <role content-type="http://credit.niso.org/contributor-roles/investigation/">Investigation</role>
        <role content-type="http://credit.niso.org/contributor-roles/software/">Software</role>
        <role content-type="http://credit.niso.org/contributor-roles/validation/">Validation</role>
        <role content-type="http://credit.niso.org/contributor-roles/visualization/">Visualization</role>
        <xref rid="aff001" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="aff002" ref-type="aff">
          <sup>2</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Cruse</surname>
          <given-names>Kevin</given-names>
        </name>
        <role content-type="http://credit.niso.org/contributor-roles/data-curation/">Data curation</role>
        <role content-type="http://credit.niso.org/contributor-roles/investigation/">Investigation</role>
        <role content-type="http://credit.niso.org/contributor-roles/software/">Software</role>
        <role content-type="http://credit.niso.org/contributor-roles/validation/">Validation</role>
        <role content-type="http://credit.niso.org/contributor-roles/visualization/">Visualization</role>
        <xref rid="aff001" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="aff002" ref-type="aff">
          <sup>2</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Wang</surname>
          <given-names>Zheren</given-names>
        </name>
        <role content-type="http://credit.niso.org/contributor-roles/data-curation/">Data curation</role>
        <role content-type="http://credit.niso.org/contributor-roles/investigation/">Investigation</role>
        <role content-type="http://credit.niso.org/contributor-roles/software/">Software</role>
        <role content-type="http://credit.niso.org/contributor-roles/validation/">Validation</role>
        <role content-type="http://credit.niso.org/contributor-roles/visualization/">Visualization</role>
        <xref rid="aff001" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="aff002" ref-type="aff">
          <sup>2</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Subramanian</surname>
          <given-names>Akshay</given-names>
        </name>
        <role content-type="http://credit.niso.org/contributor-roles/data-curation/">Data curation</role>
        <role content-type="http://credit.niso.org/contributor-roles/investigation/">Investigation</role>
        <role content-type="http://credit.niso.org/contributor-roles/software/">Software</role>
        <role content-type="http://credit.niso.org/contributor-roles/validation/">Validation</role>
        <role content-type="http://credit.niso.org/contributor-roles/visualization/">Visualization</role>
        <xref rid="aff003" ref-type="aff">
          <sup>3</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Justus</surname>
          <given-names>Benjamin</given-names>
        </name>
        <role content-type="http://credit.niso.org/contributor-roles/data-curation/">Data curation</role>
        <role content-type="http://credit.niso.org/contributor-roles/software/">Software</role>
        <role content-type="http://credit.niso.org/contributor-roles/visualization/">Visualization</role>
        <xref rid="aff002" ref-type="aff">
          <sup>2</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Ceder</surname>
          <given-names>Gerbrand</given-names>
        </name>
        <role content-type="http://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role>
        <role content-type="http://credit.niso.org/contributor-roles/funding-acquisition/">Funding acquisition</role>
        <role content-type="http://credit.niso.org/contributor-roles/supervision/">Supervision</role>
        <role content-type="http://credit.niso.org/contributor-roles/writing-review-editing/">Writing – review &amp; editing</role>
        <xref rid="aff001" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="aff002" ref-type="aff">
          <sup>2</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-2495-5509</contrib-id>
        <name>
          <surname>Persson</surname>
          <given-names>Kristin A.</given-names>
        </name>
        <role content-type="http://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role>
        <role content-type="http://credit.niso.org/contributor-roles/funding-acquisition/">Funding acquisition</role>
        <role content-type="http://credit.niso.org/contributor-roles/project-administration/">Project administration</role>
        <role content-type="http://credit.niso.org/contributor-roles/supervision/">Supervision</role>
        <role content-type="http://credit.niso.org/contributor-roles/writing-review-editing/">Writing – review &amp; editing</role>
        <xref rid="aff002" ref-type="aff">
          <sup>2</sup>
        </xref>
        <xref rid="aff005" ref-type="aff">
          <sup>5</sup>
        </xref>
        <xref rid="cor001" ref-type="corresp">*</xref>
      </contrib>
    </contrib-group>
    <aff id="aff001">
      <label>1</label>
      <addr-line>Materials Sciences Division, Lawrence Berkeley National Laboratory, Berkeley, CA, United States of America</addr-line>
    </aff>
    <aff id="aff002">
      <label>2</label>
      <addr-line>Department of Materials Science &amp; Engineering, University of California, Berkeley, Berkeley, CA, United States of America</addr-line>
    </aff>
    <aff id="aff003">
      <label>3</label>
      <addr-line>Indian Institute of Technology Roorkee, Roorkee, Uttarakhand, India</addr-line>
    </aff>
    <aff id="aff004">
      <label>4</label>
      <addr-line>Wuhan University, Wuhan, Hubei, China</addr-line>
    </aff>
    <aff id="aff005">
      <label>5</label>
      <addr-line>Molecular Foundry Division, Lawrence Berkeley National Laboratory, Berkeley, CA, United States of America</addr-line>
    </aff>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Speier</surname>
          <given-names>William</given-names>
        </name>
        <role>Editor</role>
        <xref rid="edit1" ref-type="aff"/>
      </contrib>
    </contrib-group>
    <aff id="edit1">
      <addr-line>UCLA Medical School: University of California Los Angeles David Geffen School of Medicine, UNITED STATES</addr-line>
    </aff>
    <author-notes>
      <fn fn-type="COI-statement" id="coi001">
        <p><bold>Competing Interests: </bold>The authors have declared that no competing interests exist.</p>
      </fn>
      <corresp id="cor001">* E-mail: <email>jdagdelen@berkeley.edu</email> (JD); <email>kristinpersson@berkeley.edu</email> (KAP)</corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="epub">
      <day>1</day>
      <month>2</month>
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>1</day>
      <month>2</month>
      <year>2023</year>
    </pub-date>
    <!--PMC Release delay is 0 months and 0 days and was based on the <pub-date pub-type="epub"/>.-->
    <volume>18</volume>
    <issue>2</issue>
    <elocation-id>e0281147</elocation-id>
    <history>
      <date date-type="received">
        <day>14</day>
        <month>3</month>
        <year>2022</year>
      </date>
      <date date-type="accepted">
        <day>16</day>
        <month>1</month>
        <year>2023</year>
      </date>
    </history>
    <permissions>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="cc0license">https://creativecommons.org/publicdomain/zero/1.0/</ali:license_ref>
        <license-p>This is an open access article, free of all copyright, and may be freely reproduced, distributed, transmitted, modified, built upon, or otherwise used by anyone for any lawful purpose. The work is made available under the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/publicdomain/zero/1.0/">Creative Commons CC0</ext-link> public domain dedication.</license-p>
      </license>
    </permissions>
    <self-uri content-type="pdf" xlink:href="pone.0281147.pdf"/>
    <abstract>
      <p>The ongoing COVID-19 pandemic produced far-reaching effects throughout society, and science is no exception. The scale, speed, and breadth of the scientific community’s COVID-19 response lead to the emergence of new research at the remarkable rate of more than 250 papers published per day. This posed a challenge for the scientific community as traditional methods of engagement with the literature were strained by the volume of new research being produced. Meanwhile, the urgency of response lead to an increasingly prominent role for preprint servers and a diffusion of relevant research through many channels simultaneously. These factors created a need for new tools to change the way scientific literature is organized and found by researchers. With this challenge in mind, we present an overview of COVIDScholar <ext-link xlink:href="https://covidscholar.org" ext-link-type="uri">https://covidscholar.org</ext-link>, an automated knowledge portal which utilizes natural language processing (NLP) that was built to meet these urgent needs. The search interface for this corpus of more than 260,000 research articles, patents, and clinical trials served more than 33,000 users at an average of 2,000 monthly active users and a peak of more than 8,600 weekly active users in the summer of 2020. Additionally, we include an analysis of trends in COVID-19 research over the course of the pandemic with a particular focus on the first 10 months, which represents a unique period of rapid worldwide shift in scientific attention.</p>
    </abstract>
    <funding-group>
      <award-group id="award001">
        <funding-source>
          <institution>C3.ai Digital Transformation Institute</institution>
        </funding-source>
      </award-group>
      <award-group id="award002">
        <funding-source>
          <institution>Laboratory Directed Research and Development Program of Lawrence Berkeley National Laboratory</institution>
        </funding-source>
        <award-id>DE-AC02-05CH11231</award-id>
      </award-group>
      <award-group id="award003">
        <funding-source>
          <institution>Office of Science of the U.S. Department of Energy</institution>
        </funding-source>
        <award-id>NERSC DDR-ERCAP0021505</award-id>
      </award-group>
      <award-group id="award004">
        <funding-source>
          <institution>National Virtual Biotechnology Laboratory</institution>
        </funding-source>
      </award-group>
      <funding-statement>Funding for this work was awarded to G.C. and K.P. Portions of this work were supported by the C3.ai Digital Transformation Institute (<ext-link xlink:href="https://c3dti.ai" ext-link-type="uri">https://c3dti.ai</ext-link>) and the Laboratory Directed Research and Development Program of Lawrence Berkeley National Laboratory (<ext-link xlink:href="https://www.lbl.gov" ext-link-type="uri">https://www.lbl.gov</ext-link>) under U.S. Department of Energy Contract No. DE-AC02-05CH11231. This research used resources of the National Energy Research Scientific Computing Center, a DOE Office of Science User Facility supported by the Office of Science of the U.S. Department of Energy under Contract No. DE-AC02-05CH11231 using NERSC award NERSC DDR-ERCAP0021505. The text corpus analysis and development of machine learning algorithms were supported by the DOE Office of Science through the National Virtual Biotechnology Laboratory (<ext-link xlink:href="https://science.osti.gov/nvbl" ext-link-type="uri">https://science.osti.gov/nvbl</ext-link>), a consortium of DOE national laboratories focused on response to COVID-19, with funding provided by the Coronavirus CARES Act. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript. There was no additional external funding received for this study.</funding-statement>
    </funding-group>
    <counts>
      <fig-count count="9"/>
      <table-count count="3"/>
      <page-count count="16"/>
    </counts>
    <custom-meta-group>
      <custom-meta id="data-availability">
        <meta-name>Data Availability</meta-name>
        <meta-value>All data other than the abstracts and full text of the research paper corpus are available at <ext-link xlink:href="https://www.gitHub.com/COVID-19-Text-Mining/COVIDScholar-data" ext-link-type="uri">https://www.gitHub.com/COVID-19-Text-Mining/COVIDScholar-data</ext-link>. Due to copyright reasons we cannot share the database of research papers, but they can be searched via our literature search tool at <ext-link xlink:href="https://www.covidscholar.org" ext-link-type="uri">https://www.covidscholar.org</ext-link>.</meta-value>
      </custom-meta>
      <custom-meta id="outbreaks">
        <meta-name>Outbreaks</meta-name>
        <meta-value>COVID-19</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
  <notes>
    <title>Data Availability</title>
    <p>All data other than the abstracts and full text of the research paper corpus are available at <ext-link xlink:href="https://www.gitHub.com/COVID-19-Text-Mining/COVIDScholar-data" ext-link-type="uri">https://www.gitHub.com/COVID-19-Text-Mining/COVIDScholar-data</ext-link>. Due to copyright reasons we cannot share the database of research papers, but they can be searched via our literature search tool at <ext-link xlink:href="https://www.covidscholar.org" ext-link-type="uri">https://www.covidscholar.org</ext-link>.</p>
  </notes>
</front>
<body>
  <sec sec-type="intro" id="sec001">
    <title>Introduction</title>
    <p>The scientific community responded to the COVID-19 pandemic with unprecedented speed. As a result, an enormous amount of research literature rapidly emerged, at a rate of over 250 papers a day [<xref rid="pone.0281147.ref001" ref-type="bibr">1</xref>]. The urgency and volume of emerging research has caused preprints to take a prominent role in lieu of traditional journals, leading to widespread usage of preprint servers for the first time in many fields, most prominently biomedical sciences [<xref rid="pone.0281147.ref002" ref-type="bibr">2</xref>, <xref rid="pone.0281147.ref003" ref-type="bibr">3</xref>]. While this allows new research to be disseminated to the community sooner, this also circumvents the role of journals in filtering papers with flawed methodologies or unsupported conclusions and highlighting especially timely or impactful research results [<xref rid="pone.0281147.ref004" ref-type="bibr">4</xref>]. Additionally, the highly multi-disciplinary nature of the scientific community’s response to the pandemic lead to pertinent research being dispersed across many different preprint services and open-access journals. There was no single comprehensive repository of COVID-19 literature.</p>
    <p>These challenges revealed the need and opportunity for new tools and methods that rethink the way in which researchers engage with the wealth of available scientific literature on rapidly evolving subjects, in particular those associated with an urgent societal need.</p>
    <p>COVIDScholar embodies such an effort to address these issues by using natural language processing (NLP) techniques to aggregate, analyze, and search the COVID-19 research literature. We developed an automated, scalable infrastructure for scraping and integrating new research as it appears, and used it to construct a targeted corpus of over 260,000 scientific papers and documents from a broad range of disciplines. Of these, 180,000 directly concern COVID-19 and the remainder of the corpus–some 70,000 papers and research items–contains other information that may be useful to COVID-19 researchers like studies on SARS or other respiratory diseases. To make this corpus accessible and useful to the scientific community, we developed a unique literature search interface for this corpus, <ext-link xlink:href="https://covidscholar.org" ext-link-type="uri">https://covidscholar.org</ext-link>, which has served over 33,000 users at an average of 2,000 monthly active users during the pandemic.</p>
    <p>While a variety of other COVID-19 literature aggregation efforts started in response to the pandemic [<xref rid="pone.0281147.ref005" ref-type="bibr">5</xref>–<xref rid="pone.0281147.ref007" ref-type="bibr">7</xref>], COVIDScholar differs in the breadth of literature collected. In addition to the biological and medical research collected by other large-scale aggregation efforts such as CORD-19 [<xref rid="pone.0281147.ref006" ref-type="bibr">6</xref>] and LitCOVID [<xref rid="pone.0281147.ref007" ref-type="bibr">7</xref>], COVIDScholar’s collection targets the full breadth of COVID-19 research, including public health, behavioral science, physical sciences, economics, psychology, and humanities.</p>
    <p>In this paper, we present a description of the COVIDScholar data intake pipeline, back-end infrastructure, and the NLP models used to power directed searches on the frontend search portal, which can serve as a model for future literature management efforts in new emergent situations with widespread, distributed research activities. We also present an analysis of the COVIDScholar corpus and discuss trends we observe in the dynamics of research output during the pandemic.</p>
  </sec>
  <sec id="sec002">
    <title>Data pipeline &amp; infrastructure</title>
    <sec id="sec003">
      <title>Data collection</title>
      <p>At the heart of COVIDScholar is the automated data intake and processing pipeline, depicted in <xref rid="pone.0281147.g001" ref-type="fig">Fig 1</xref>. Data sources are continually checked for new or updated papers, patents, and clinical trials. Documents are then parsed, cleaned, analyzed with NLP models to produce document embeddings, COVID-19 relevance scores, inter-document similarity metrics, keywords, and subject-area tags. The processed entries and NLP-derived metadata are then made searchable for end-users on the frontend website, <ext-link xlink:href="https://covidscholar.org" ext-link-type="uri">https://covidscholar.org</ext-link>. The complete codebase for the data pipeline is available at <ext-link xlink:href="https://github.com/COVID-19-Text-Mining" ext-link-type="uri">https://github.com/COVID-19-Text-Mining</ext-link>.</p>
      <fig position="float" id="pone.0281147.g001">
        <object-id pub-id-type="doi">10.1371/journal.pone.0281147.g001</object-id>
        <label>Fig 1</label>
        <caption>
          <title>The data pipeline used to construct the COVIDScholar research corpus.</title>
        </caption>
        <graphic xlink:href="pone.0281147.g001" position="float"/>
      </fig>
      <p>The COVIDScholar research corpus consists of research literature from 14 different open-access sources and preprint services, shown in <xref rid="pone.0281147.g002" ref-type="fig">Fig 2</xref>. For each of these, a web scraper regularly checks for new documents and new versions of existing documents. Missing metadata is then collected from Crossref and citation data is collected from OpenCitations [<xref rid="pone.0281147.ref008" ref-type="bibr">8</xref>]. During the early phase of the pandemic, when very little was known and response time was of the essence, the database was updated daily. Later on in the pandemic it was updated 2–3 times per week.</p>
      <fig position="float" id="pone.0281147.g002">
        <object-id pub-id-type="doi">10.1371/journal.pone.0281147.g002</object-id>
        <label>Fig 2</label>
        <caption>
          <title>Publication counts by source.</title>
          <p>The source of papers, patents, and clinical trials in the COVIDScholar collection, with the count of COVID-19 related publications from each source. Papers are sourced from [<xref rid="pone.0281147.ref006" ref-type="bibr">6</xref>, <xref rid="pone.0281147.ref007" ref-type="bibr">7</xref>, <xref rid="pone.0281147.ref009" ref-type="bibr">9</xref>–<xref rid="pone.0281147.ref019" ref-type="bibr">19</xref>]. Note: many papers in our database are available from multiple sources. The total number of unique documents is approximately 260,000.</p>
        </caption>
        <graphic xlink:href="pone.0281147.g002" position="float"/>
      </fig>
    </sec>
    <sec id="sec004">
      <title>Data cleaning and pre-processing</title>
      <p>After collection, these publications are then parsed into a unified format, cleaned, and resolved to remove duplicates. Publications are identified as duplicates when they share any of doi (up to version number), pubmed id, or uncased title. For clinical trials without valid document identifiers, a shared title is used to identify duplicates. In cases where there are multiple versions of a single paper (most commonly, a preprint and a published version), a combined single document is produced, whose contents are selected on a field-by-field basis using a priority system. Published versions and higher version numbers (based on doi) are given higher priority, and sources are otherwise prioritized based on the quality of their text.</p>
      <p>In cases where full-text PDFs are available, text is parsed from the document using pdfminer (for PDFs with embedded text [<xref rid="pone.0281147.ref020" ref-type="bibr">20</xref>]) or optical character recognition (OCR). However, it is our experience that text extracted in this manner is usually not of sufficient quality for to be used by the classification and relevance NLP models, and at this time is used solely for text searches.</p>
    </sec>
    <sec id="sec005">
      <title>Overview of analysis, keyword extraction, and search index construction</title>
      <p>We use NLP models to classify documents based on their relevance to COVID-19, topic, discipline, and field. The topic labels used are derived from the LitCovid project (<ext-link xlink:href="https://www.ncbi.nlm.nih.gov/research/coronavirus/" ext-link-type="uri">https://www.ncbi.nlm.nih.gov/research/coronavirus/</ext-link>)—“treatment”, “prevention”, “mechanism”, “diagnosis”, “transmission”, “epidemic forecasting”, and “case report”. Documents can belong to multiple categories and publications for which an abstract cannot be found are not classified.</p>
      <p>Keywords are also extracted from titles and abstracts using an unsupervised approach. We also apply subject/discipline labels jointly developed with the Rapid Reviews: COVID-19 editorial team for use in their back-end preprint review system—“biological &amp; chemical sciences”, “medical sciences”, “public health”, “physical sciences and engineering”, and “humanities &amp; social sciences”.</p>
      <p>Our web portal, COVIDScholar.org (<xref rid="pone.0281147.g003" ref-type="fig">Fig 3</xref>), provides an accessible user interface to a variety of literature search tools and information retrieval algorithms tuned specifically for the needs of COVID-19 researchers. To do this, we have utilized new machine learning and natural language processing techniques together with proven information retrieval approaches to create the search algorithms and indices behind COVIDScholar, which we describe in the remainder of this section.</p>
      <fig position="float" id="pone.0281147.g003">
        <object-id pub-id-type="doi">10.1371/journal.pone.0281147.g003</object-id>
        <label>Fig 3</label>
        <caption>
          <title>COVIDScholar literature search portal.</title>
          <p>Screenshot of COVIDScholar.org, which includes text-search with COVID-19 relevance boosting, category labels, extracted keywords, and other features designed to aid COVID-19 researchers in finding relevant information quickly and staying on top of a rapidly evolving research landscape.</p>
        </caption>
        <graphic xlink:href="pone.0281147.g003" position="float"/>
      </fig>
    </sec>
    <sec id="sec006">
      <title>COVID-19 relevance scoring</title>
      <p>The goal of any relevance scoring system is to give a higher rank to documents that are most likely to contain relevant information or answers to a user’s query. Our approach to relevance ranking in literature search and discovery for COVID-19 related research is intended to help researchers find the most relevant documents to their queries in a way that not only matches keywords in the query but also takes a document’s overall relevance to SARS-CoV2 and COVID-19 into consideration.</p>
      <p>Machine learning algorithms can be used to identify emerging trends in the literature and correlate them with similar patterns from pre-existing research. This was especially useful in the early stages of the pandemic where little existing literature on COVID-19 had been published and researchers wanted to leverage existing research on related viruses (SARS, MERS), epidemiology, epidemiological modeling, and other respiratory diseases. For this reason, we chose to base our search backend on the Vespa engine [<xref rid="pone.0281147.ref021" ref-type="bibr">21</xref>], which provides a high level of performance, wide scalability, and easy integration with dense vector search and custom machine learning models. The default search result ranking profile on COVIDScholar.org combines BM25 relevance [<xref rid="pone.0281147.ref022" ref-type="bibr">22</xref>] (a robust keyword-based document relevance ranking algorithm) with a “COVID-19 relevance” score calculated by a classification model trained to predict whether a paper is relevant to the SARS-CoV-2 virus or COVID-19.</p>
      <p>Ranking schemes that also promote results with information on certain viruses/diseases that are similar to SARS-CoV2 but predate the COVID-19 pandemic can be useful to COVID-19 researchers during the information discovery phase, especially for papers on the original SARS and other respiratory diseases. SARS-CoV-2 shares 79% of its genome sequence identity with the SARS-CoV virus [<xref rid="pone.0281147.ref023" ref-type="bibr">23</xref>], and there are many similarities between how the two viruses enter cells, replicate, and transmit between hosts [<xref rid="pone.0281147.ref024" ref-type="bibr">24</xref>]. Because the COVID-19 relevance classification model gives a higher score to studies on these similar diseases, we can use this score to help boost the ranking of search results that are likely to contain relevant information, even if it is not directly focused on COVID-19. A specific example of this is the transmembrane protease TMPRSS2, which plays an important role in viral entry and spread for both SARS-CoV and SARS-CoV-2. Inhibition of TMPRSS2 is a promising avenue for treating COVID-19 [<xref rid="pone.0281147.ref025" ref-type="bibr">25</xref>, <xref rid="pone.0281147.ref026" ref-type="bibr">26</xref>]. A wealth of information on strategies to inhibit TMPRSS2 activity and their efficacy in blocking SARS-CoV from entering host cells was available in the early days of the COVID-19 pandemic and these specific studies were boosted in search results because our model assigned them high relevance scores, thereby bringing potentially useful information to the attention of researchers more directly. In comparison, results of a Google Scholar search for “TMPRSS2” (with results containing “COVID-19” and “SARS-CoV-2” filtered out) are dominated by studies on the protease’s role in various cancers rather than SARS-CoV.</p>
      <p>COVIDScholar also provides tools that utilizes unsupervised document embeddings so that searches can be performed within “related documents” to automatically link research papers together by topics, methods, drugs, and other key pieces of information. Documents are sorted by similarity via the cosine distances between unsupervised document embeddings [<xref rid="pone.0281147.ref027" ref-type="bibr">27</xref>], which is then combined with the result-ranking score mentioned above. This allows users to focus their results into a more specific domain without having to repeatedly pick and choose new search terms to add to their queries. Users can also filter all of the documents in the database by broader subjects relevant to COVID-19 (treatment, transmission, case reports, etc), which are all determined though the application of machine learning models trained on a smaller number of hand-labeled examples. All combined, these approaches have allowed us to create more targeted tools for COVID-19 literature search and knowledge discovery.</p>
    </sec>
  </sec>
  <sec id="sec007">
    <title>NLP models for text analysis</title>
    <sec id="sec008">
      <title>Rapid reviews: COVID-19 subject model</title>
      <p>As part of a collaboration between COVIDScholar and Rapid Reviews: COVID-19, an overlay journal that rapidly peer-reviews COVID-19 preprints, we developed a pipeline that categorized preprints into feeds from various subject areas so that editors could follow their respective areas of expertise. To do this, we trained a subject classification model on approximately 3,300 documents (title + abstract) hand-labeled with subject area tags selected by the Rapid Reviews: COVID-19 editorial team (“Biological &amp; Chemical Sciences”, “Medical Sciences”, “Public Health”, “Physical Sciences, Engineering &amp; Computational Studies”, and “Humanities &amp; Social Sciences”.) A paper may belong to any number of disciplines and each discipline is composed of 12–15 sub-fields, which are listed in the <xref rid="pone.0281147.s001" ref-type="supplementary-material">S1 Table</xref>.</p>
      <p>For this task we used a fine-tuned SciBERT [<xref rid="pone.0281147.ref028" ref-type="bibr">28</xref>] model trained on this datasets. While other BERT models pre-trained on scientific text exist (e.g. [<xref rid="pone.0281147.ref029" ref-type="bibr">29</xref>–<xref rid="pone.0281147.ref031" ref-type="bibr">31</xref>]), we selected SciBERT due to its broad, multidisciplinary training corpus, which we expect to more closely resemble the COVIDScholar corpus than those pre-trained on a single discipline. At the time of our model’s development, SciBERT had state-of-the-art performance on the task of paper domain classification [<xref rid="pone.0281147.ref032" ref-type="bibr">32</xref>], as well as a number of biomedical domain benchmarks [<xref rid="pone.0281147.ref033" ref-type="bibr">33</xref>–<xref rid="pone.0281147.ref035" ref-type="bibr">35</xref>]—the most common discipline in the COVIDScholar corpus. The input to the model is the title and abstract of the document appended together and a single fully-connected layer with sigmoid activation is used as a classification head. The model is fine-tuned for 6 epochs using roughly 3,300 human-annotated abstracts that were labeled by members of the Rapid Reviews: COVID-19 [<xref rid="pone.0281147.ref036" ref-type="bibr">36</xref>] editorial team. We compare this model to a baseline random forest model using TF-IDF features and two transformer text classifiers based on more recent models (distilBERT [<xref rid="pone.0281147.ref037" ref-type="bibr">37</xref>] and Specter [<xref rid="pone.0281147.ref038" ref-type="bibr">38</xref>]) trained on the same sample dataset.</p>
    </sec>
  </sec>
  <sec id="sec009">
    <title>Benchmark results</title>
    <p>ROC curves for the COVIDScholar classifier’s performance for each top-level Rapid Reviews discipline using 10-fold cross-validation are shown in <xref rid="pone.0281147.g004" ref-type="fig">Fig 4</xref>. The classifier performs well, with average F1 scores above 0.80 for all disciplines.</p>
    <fig position="float" id="pone.0281147.g004">
      <object-id pub-id-type="doi">10.1371/journal.pone.0281147.g004</object-id>
      <label>Fig 4</label>
      <caption>
        <title>Classifier performance.</title>
        <p>ROC curves for discipline classification models of paper abstracts using a fine-tuned SciBERT [<xref rid="pone.0281147.ref028" ref-type="bibr">28</xref>] model adapted for classification. Training is performed using a set of roughly 3,300 human-annotated abstracts, and results shown are generated with 10-fold cross validation.</p>
      </caption>
      <graphic xlink:href="pone.0281147.g004" position="float"/>
    </fig>
    <p><xref rid="pone.0281147.t001" ref-type="table">Table 1</xref> contains F1, precision, and recall scores for the Rapid Reviews category classification task for the models uses in COVIDScholar and three baseline models: a random forest model using TF-IDF features, a fine-tuned distilBERT model, and a fine-tuned Specter model. Each model was evaluated using 10-fold cross-validation over a dataset of 3,307 hand-labeled abstracts.</p>
    <table-wrap position="float" id="pone.0281147.t001">
      <object-id pub-id-type="doi">10.1371/journal.pone.0281147.t001</object-id>
      <label>Table 1</label>
      <caption>
        <title>Scoring metrics of SciBERT [<xref rid="pone.0281147.ref028" ref-type="bibr">28</xref>] and baseline classification models (random forest, distilBERT, and Specter).</title>
      </caption>
      <alternatives>
        <graphic xlink:href="pone.0281147.t001" id="pone.0281147.t001g" position="float"/>
        <table frame="box" rules="all" border="0">
          <colgroup span="1">
            <col align="left" valign="middle" span="1"/>
            <col align="left" valign="middle" span="1"/>
            <col align="left" valign="middle" span="1"/>
            <col align="left" valign="middle" span="1"/>
            <col align="left" valign="middle" span="1"/>
            <col align="left" valign="middle" span="1"/>
            <col align="left" valign="middle" span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th align="center" style="border-bottom-width:thick" rowspan="1" colspan="1"/>
              <th align="center" style="border-bottom-width:thick" rowspan="1" colspan="1"/>
              <th align="center" style="border-bottom-width:thick" rowspan="1" colspan="1">Biological &amp; Chem. Sciences</th>
              <th align="center" style="border-bottom-width:thick" rowspan="1" colspan="1">Medical Sciences</th>
              <th align="center" style="border-bottom-width:thick" rowspan="1" colspan="1">Public Health</th>
              <th align="center" style="border-bottom-width:thick" rowspan="1" colspan="1">Phys. Sci, Eng. and Comp. Studies</th>
              <th align="center" style="border-bottom-width:thick" rowspan="1" colspan="1">Humanities &amp; Social Sciences</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td align="left" rowspan="3" colspan="1">SciBERT</td>
              <td align="center" rowspan="1" colspan="1">F1</td>
              <td align="char" char="." rowspan="1" colspan="1">0.91</td>
              <td align="char" char="." rowspan="1" colspan="1">0.87</td>
              <td align="char" char="." rowspan="1" colspan="1">0.87</td>
              <td align="char" char="." rowspan="1" colspan="1">0.80</td>
              <td align="char" char="." rowspan="1" colspan="1">0.88</td>
            </tr>
            <tr>
              <td align="center" rowspan="1" colspan="1">Precision</td>
              <td align="char" char="." rowspan="1" colspan="1">0.88</td>
              <td align="char" char="." rowspan="1" colspan="1">0.86</td>
              <td align="char" char="." rowspan="1" colspan="1">0.86</td>
              <td align="char" char="." rowspan="1" colspan="1">0.80</td>
              <td align="char" char="." rowspan="1" colspan="1">0.88</td>
            </tr>
            <tr>
              <td align="center" rowspan="1" colspan="1">Recall</td>
              <td align="char" char="." rowspan="1" colspan="1">0.93</td>
              <td align="char" char="." rowspan="1" colspan="1">0.88</td>
              <td align="char" char="." rowspan="1" colspan="1">0.88</td>
              <td align="char" char="." rowspan="1" colspan="1">0.81</td>
              <td align="char" char="." rowspan="1" colspan="1">0.89</td>
            </tr>
            <tr>
              <td align="left" rowspan="3" colspan="1">Random Forest</td>
              <td align="center" rowspan="1" colspan="1">F1</td>
              <td align="char" char="." rowspan="1" colspan="1">0.79</td>
              <td align="char" char="." rowspan="1" colspan="1">0.51</td>
              <td align="char" char="." rowspan="1" colspan="1">0.68</td>
              <td align="char" char="." rowspan="1" colspan="1">0.26</td>
              <td align="char" char="." rowspan="1" colspan="1">0.46</td>
            </tr>
            <tr>
              <td align="center" rowspan="1" colspan="1">Precision</td>
              <td align="char" char="." rowspan="1" colspan="1">0.84</td>
              <td align="char" char="." rowspan="1" colspan="1">0.76</td>
              <td align="char" char="." rowspan="1" colspan="1">0.72</td>
              <td align="char" char="." rowspan="1" colspan="1">0.74</td>
              <td align="char" char="." rowspan="1" colspan="1">0.83</td>
            </tr>
            <tr>
              <td align="center" rowspan="1" colspan="1">Recall</td>
              <td align="char" char="." rowspan="1" colspan="1">0.76</td>
              <td align="char" char="." rowspan="1" colspan="1">0.40</td>
              <td align="char" char="." rowspan="1" colspan="1">0.67</td>
              <td align="char" char="." rowspan="1" colspan="1">0.16</td>
              <td align="char" char="." rowspan="1" colspan="1">0.33</td>
            </tr>
            <tr>
              <td align="left" rowspan="3" colspan="1">distilBERT</td>
              <td align="center" rowspan="1" colspan="1">F1</td>
              <td align="char" char="." rowspan="1" colspan="1">0.91</td>
              <td align="char" char="." rowspan="1" colspan="1">0.87</td>
              <td align="char" char="." rowspan="1" colspan="1">0.87</td>
              <td align="char" char="." rowspan="1" colspan="1">0.80</td>
              <td align="char" char="." rowspan="1" colspan="1">0.87</td>
            </tr>
            <tr>
              <td align="center" rowspan="1" colspan="1">Precision</td>
              <td align="char" char="." rowspan="1" colspan="1">0.84</td>
              <td align="char" char="." rowspan="1" colspan="1">0.86</td>
              <td align="char" char="." rowspan="1" colspan="1">0.84</td>
              <td align="char" char="." rowspan="1" colspan="1">0.79</td>
              <td align="char" char="." rowspan="1" colspan="1">0.88</td>
            </tr>
            <tr>
              <td align="center" rowspan="1" colspan="1">Recall</td>
              <td align="char" char="." rowspan="1" colspan="1">0.92</td>
              <td align="char" char="." rowspan="1" colspan="1">0.88</td>
              <td align="char" char="." rowspan="1" colspan="1">0.89</td>
              <td align="char" char="." rowspan="1" colspan="1">0.82</td>
              <td align="char" char="." rowspan="1" colspan="1">0.87</td>
            </tr>
            <tr>
              <td align="left" rowspan="3" colspan="1">Specter</td>
              <td align="center" rowspan="1" colspan="1">F1</td>
              <td align="char" char="." rowspan="1" colspan="1">0.90</td>
              <td align="char" char="." rowspan="1" colspan="1">0.87</td>
              <td align="char" char="." rowspan="1" colspan="1">0.86</td>
              <td align="char" char="." rowspan="1" colspan="1">0.81</td>
              <td align="char" char="." rowspan="1" colspan="1">0.87</td>
            </tr>
            <tr>
              <td align="center" rowspan="1" colspan="1">Precision</td>
              <td align="char" char="." rowspan="1" colspan="1">0.89</td>
              <td align="char" char="." rowspan="1" colspan="1">0.88</td>
              <td align="char" char="." rowspan="1" colspan="1">0.84</td>
              <td align="char" char="." rowspan="1" colspan="1">0.80</td>
              <td align="char" char="." rowspan="1" colspan="1">0.86</td>
            </tr>
            <tr>
              <td align="center" rowspan="1" colspan="1">Recall</td>
              <td align="char" char="." rowspan="1" colspan="1">0.91</td>
              <td align="char" char="." rowspan="1" colspan="1">0.88</td>
              <td align="char" char="." rowspan="1" colspan="1">0.88</td>
              <td align="char" char="." rowspan="1" colspan="1">0.82</td>
              <td align="char" char="." rowspan="1" colspan="1">0.88</td>
            </tr>
          </tbody>
        </table>
      </alternatives>
    </table-wrap>
    <p>The SciBERT model significantly outperforms the random forest baseline model on all categories and performs very similarly to distilBERT and Specter baseline models. It is also of note in each case that while precision is similar between the the models, the random forest baseline model exhibits significantly lower recall. This may be due to unbalanced training data—no single discipline accounts for more than 33% of the total corpus. For search applications, often a relatively small number of documents is relevant to each query. In this case, a high recall is more desirable than a high precision.</p>
  </sec>
  <sec id="sec010">
    <title>COVID-19 relevance classification</title>
    <p>On the task of binary classification as related to COVID-19, our current models perform similarly well, achieving an F1 score of 0.98. While the binary classification task is significantly simpler from an NLP perspective—the majority of related papers contain “COVID-19” or some synonym—this still represents a significant performance improvement over the random forest baseline model, which achieves an F1-score of 0.90. Given the relative simplicity of this task, in cases where an abstract is absent we classify it as related to COVID-19 based on the title.</p>
  </sec>
  <sec id="sec011">
    <title>Keywords</title>
    <p>Keywords extracted from titles and abstracts are useful for quickly summarizing search results. For the task of unsupervised keyword extraction, 63 abstracts were annotated by humans and four keyword-extraction methods were tested. Two of the methods are statistical, TextRank [<xref rid="pone.0281147.ref039" ref-type="bibr">39</xref>] and TF-IDF [<xref rid="pone.0281147.ref040" ref-type="bibr">40</xref>], and two are graph-based models, RaKUn [<xref rid="pone.0281147.ref041" ref-type="bibr">41</xref>] and Yake [<xref rid="pone.0281147.ref042" ref-type="bibr">42</xref>]. The models were evaluated for overlap between human-annotated keywords and extracted keywords, and results are shown in <xref rid="pone.0281147.t002" ref-type="table">Table 2</xref>. Note that due to the inherent subjectivity of the keyword extraction task scores are relatively low—the best performing model, RaKUn has an F1 score of only 0.2 for recapturing the keywords chosen by the human annotator. However, the quality of extracted keywords from this model was deemed reasonable for display on the search portal after manual review.</p>
    <table-wrap position="float" id="pone.0281147.t002">
      <object-id pub-id-type="doi">10.1371/journal.pone.0281147.t002</object-id>
      <label>Table 2</label>
      <caption>
        <title>Precision, recall, and F1 scores for 4 unsupervised keywords extractors, RaKUn [<xref rid="pone.0281147.ref041" ref-type="bibr">41</xref>], Yake [<xref rid="pone.0281147.ref042" ref-type="bibr">42</xref>], TextRank [<xref rid="pone.0281147.ref039" ref-type="bibr">39</xref>], and TF-IDF [<xref rid="pone.0281147.ref040" ref-type="bibr">40</xref>].</title>
        <p>Output from keyword extractors was compared to 63 abstracts with human-annotated keywords.</p>
      </caption>
      <alternatives>
        <graphic xlink:href="pone.0281147.t002" id="pone.0281147.t002g" position="float"/>
        <table frame="box" rules="all" border="0">
          <colgroup span="1">
            <col align="left" valign="middle" span="1"/>
            <col align="left" valign="middle" span="1"/>
            <col align="left" valign="middle" span="1"/>
            <col align="left" valign="middle" span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th align="center" style="border-bottom-width:thick" rowspan="1" colspan="1">Model</th>
              <th align="center" style="border-bottom-width:thick" rowspan="1" colspan="1">Precision</th>
              <th align="center" style="border-bottom-width:thick" rowspan="1" colspan="1">Recall</th>
              <th align="center" style="border-bottom-width:thick" rowspan="1" colspan="1">F1</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td align="center" rowspan="1" colspan="1">RaKUn</td>
              <td align="char" char="." rowspan="1" colspan="1">0.17</td>
              <td align="char" char="." rowspan="1" colspan="1">0.33</td>
              <td align="char" char="." rowspan="1" colspan="1">0.2</td>
            </tr>
            <tr>
              <td align="center" rowspan="1" colspan="1">Yake</td>
              <td align="char" char="." rowspan="1" colspan="1">0.11</td>
              <td align="char" char="." rowspan="1" colspan="1">0.45</td>
              <td align="char" char="." rowspan="1" colspan="1">0.15</td>
            </tr>
            <tr>
              <td align="center" rowspan="1" colspan="1">TextRank</td>
              <td align="char" char="." rowspan="1" colspan="1">0.06</td>
              <td align="char" char="." rowspan="1" colspan="1">0.36</td>
              <td align="char" char="." rowspan="1" colspan="1">0.09</td>
            </tr>
            <tr>
              <td align="center" rowspan="1" colspan="1">TF-IDF</td>
              <td align="char" char="." rowspan="1" colspan="1">0.10</td>
              <td align="char" char="." rowspan="1" colspan="1">0.09</td>
              <td align="char" char="." rowspan="1" colspan="1">0.08</td>
            </tr>
          </tbody>
        </table>
      </alternatives>
    </table-wrap>
  </sec>
  <sec id="sec012">
    <title>Word and phrase embeddings</title>
    <p>To better visualize the embedding of COVID-19-related phrases and find latent relationship between biomedical terms, we built a tool based on the work of Ref. [<xref rid="pone.0281147.ref043" ref-type="bibr">43</xref>] via a modified version of the open source tensorboard embedding projector visualization tool. A screenshot of the tool is shown in <xref rid="pone.0281147.g005" ref-type="fig">Fig 5</xref>. We utilize FastText [<xref rid="pone.0281147.ref044" ref-type="bibr">44</xref>] embeddings for the embedding projector, with an embedding dimension of 100. Embeddings are trained on the abstracts of all papers from the October 2020 COVIDScholar corpus which have been classified as relevant to COVID-19.</p>
    <fig position="float" id="pone.0281147.g005">
      <object-id pub-id-type="doi">10.1371/journal.pone.0281147.g005</object-id>
      <label>Fig 5</label>
      <caption>
        <title>Embedding visualization.</title>
        <p>A screenshot of the embedding projector visualizing tokens similar to “spike protein”, using FastText [<xref rid="pone.0281147.ref044" ref-type="bibr">44</xref>] embeddings trained on the COVIDScholar corpus.</p>
      </caption>
      <graphic xlink:href="pone.0281147.g005" position="float"/>
    </fig>
    <p>For the purpose of visualization, embeddings must be projected to a lower dimensional space (2D or 3D). The dimensionality reduction technique used here includes principal component analysis (PCA), uniform manifold approximation and projection (UMAP) [<xref rid="pone.0281147.ref045" ref-type="bibr">45</xref>] and t-distributed stochastic neighbor embedding (t-SNE) [<xref rid="pone.0281147.ref046" ref-type="bibr">46</xref>]. Users can set various parameters and run the dimensionality reduction algorithms in-browser, and can also load and visualize the cached result on the server with default parameters. Cosine distance is used to measure the similarity between phrases. If the cosine distance between two phrases is quite small, they are likely to have similar meaning;
<disp-formula id="pone.0281147.e001"><alternatives><graphic xlink:href="pone.0281147.e001.jpg" id="pone.0281147.e001g" position="anchor"/><mml:math id="M1" display="block" overflow="scroll"><mml:mrow><mml:mtext>Cosine</mml:mtext><mml:mspace width="4pt"/><mml:mtext>Distance</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:mtext mathvariant="bold-italic">Emb</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>·</mml:mo><mml:mtext mathvariant="bold-italic">Emb</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mo>∥</mml:mo><mml:mtext mathvariant="bold-italic">Emb</mml:mtext><mml:mo>(</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>)</mml:mo><mml:mo>∥</mml:mo></mml:mrow><mml:mspace width="2pt"/><mml:mrow><mml:mo>∥</mml:mo><mml:mtext mathvariant="bold-italic">Emb</mml:mtext><mml:mo>(</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>)</mml:mo><mml:mo>∥</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:math></alternatives></disp-formula>
where <italic toggle="yes">p</italic><sub>1</sub>, <italic toggle="yes">p</italic><sub>2</sub> represent two phrases, <bold><italic toggle="yes">Emb</italic></bold> maps phrases to their embedded representation in the learned semantic space.</p>
  </sec>
  <sec id="sec013">
    <title>COVIDScholar corpus analysis</title>
    <sec id="sec014">
      <title>Corpus breakdown</title>
      <p>As of January 2022, the COVIDScholar corpus consists of over 260,000 total documents, of which 252,000 are papers. The remainder is composed of 3,303 patents, 1,712 clinical trials, 1,194 book chapters, and 1,196 datasets. Of the papers, approximately 180,000 are classified as directly related to COVID-19. Papers marked not relevant to COVID-19 are a combination of papers on related diseases, such as SARS and MERS, or other relevant topics. In October 2020, the total number of papers was approximately equally split between preprints and published peer-reviewed papers (44% vs 56% respectively) while today the split stands at 20% preprints and 80% peer-reviewed, reflecting the evolution of the literature from a high-pace, preprint-driven modality to a more conventional mix.</p>
      <p>To explore the subject distribution of the corpus we trained a Latent Dirichlet Allocation model on 10,000 documents (titles and abstracts) randomly selected from papers in our corpus published between Jan 2020 and Jan 2022. LDA is a probabilistic model that assumes that each document in a collection is a mixture of a fixed number of topics, and topic is a mixture of words. LDA estimates the distribution of topics in each document and the distribution of words within each topic, using a generative process [<xref rid="pone.0281147.ref047" ref-type="bibr">47</xref>]. We used the LDA model to assign every paper published during that time to one of 10 topics. Top keywords for each topic were used to assign a human-readable topic name, but we note that these names may not fully describe the documents belonging to each LDA topic. A table with the full lists of topic keywords is available in the <xref rid="pone.0281147.s002" ref-type="supplementary-material">S2 Table</xref>, and we also provide an interactive explorer for the LDA topic model that can be opened in a web browser at <ext-link xlink:href="http://www.covidscholar.org/topics" ext-link-type="uri">www.covidscholar.org/topics</ext-link>. Many of the keywords identified by our topic model were also identified by Bose et al in their analysis of COVID-19 research papers published during the pandemic [<xref rid="pone.0281147.ref048" ref-type="bibr">48</xref>].</p>
      <p><xref rid="pone.0281147.g006" ref-type="fig">Fig 6</xref> shows the fraction of the papers published each month that belong to each topic over the course of the pandemic through then end of 2021 smoothed with a 2-month moving average. We observe that while most of the topics make up approximately the same fraction of papers published over the time period, the “case numbers and pandemic growth” topic shrinks significantly from approximately 18 percent of papers published per month to less than 7.5 percent while the “virology and mechanism” and “testing” topics grow from 1–2 percent to more than 5 percent. It’s interesting to note that the number of papers belonging to the testing and virology and mechanism topics make up only 10 percent of papers published in January 2022. We believe this is likely because these areas are more specialized than the other topic areas, so relatively fewer papers were published on those subjects each month.</p>
      <fig position="float" id="pone.0281147.g006">
        <object-id pub-id-type="doi">10.1371/journal.pone.0281147.g006</object-id>
        <label>Fig 6</label>
        <caption>
          <title>LDA topic distribution by month.</title>
          <p>Fraction of papers published each month belonging to each of the 10 LDA topics over the course of the pandemic. Lines are smoothed using the 2-month moving average.</p>
        </caption>
        <graphic xlink:href="pone.0281147.g006" position="float"/>
      </fig>
      <p>A breakdown by discipline of the COVID-19 relevant papers sampled in October 2020 is shown in <xref rid="pone.0281147.t003" ref-type="table">Table 3</xref>. We present cumulative counts from our database in this period as a snapshot of the research landscape as it stood in the middle of the pandemic. Approximately 85% of papers were assigned at least one category label by our model. As may be expected, “medical sciences” and “biological &amp; chemical sciences” were the most represented disciplines, with respectively 34% and 27% of the COVIDScholar corpus at the time tagged as members of these two research areas. Overlap between these two disciplines was relatively small. Only 9,858 papers were classified as belonging to both “medical sciences” and “biological &amp; chemical sciences” while 63,927 papers belong to only one of the two.</p>
      <table-wrap position="float" id="pone.0281147.t003">
        <object-id pub-id-type="doi">10.1371/journal.pone.0281147.t003</object-id>
        <label>Table 3</label>
        <caption>
          <title>The number of papers and fraction of total COVID-19 related papers in the COVIDScholar corpus for each discipline in October 2020, which is a good sample of the research landscape in the middle of the pandemic.</title>
          <p>Only papers with abstracts are classified and included in final count. A given paper may have any number of discipline labels or no label.</p>
        </caption>
        <alternatives>
          <graphic xlink:href="pone.0281147.t003" id="pone.0281147.t003g" position="float"/>
          <table frame="box" rules="all" border="0">
            <colgroup span="1">
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th align="center" style="border-bottom-width:thick" rowspan="1" colspan="1">Discipline</th>
                <th align="center" style="border-bottom-width:thick" rowspan="1" colspan="1">Paper Count</th>
                <th align="center" style="border-bottom-width:thick" rowspan="1" colspan="1">Fraction of Total</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="center" rowspan="1" colspan="1">Biological and Chemical Sciences</td>
                <td align="center" rowspan="1" colspan="1">32,722</td>
                <td align="char" char="." rowspan="1" colspan="1">0.27</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">Humanities and Social Sciences</td>
                <td align="center" rowspan="1" colspan="1">21,022</td>
                <td align="char" char="." rowspan="1" colspan="1">0.17</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">Medical Sciences</td>
                <td align="center" rowspan="1" colspan="1">41,063</td>
                <td align="char" char="." rowspan="1" colspan="1">0.34</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">Physical Sciences, Engineering, and Computational Studies</td>
                <td align="center" rowspan="1" colspan="1">17,413</td>
                <td align="char" char="." rowspan="1" colspan="1">0.14</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">Public Health</td>
                <td align="center" rowspan="1" colspan="1">27,304</td>
                <td align="char" char="." rowspan="1" colspan="1">0.23</td>
              </tr>
            </tbody>
          </table>
        </alternatives>
      </table-wrap>
    </sec>
    <sec id="sec015">
      <title>Evolution of corpus size and makeup</title>
      <p>A cumulative monthly count of COVID-19 papers in the COVIDScholar collection over the pandemic is shown in <xref rid="pone.0281147.g007" ref-type="fig">Fig 7</xref>. Papers are categorized by the fine-tuned SciBERT model described later in “NLP models for text analysis.” In cases where a paper falls into multiple disciplines, we add it fractionally to both categories with equal weight (e.g. a paper with two categories adds 1/2 of a paper to each.) The total number of reported US COVID-19 cases is also plotted. Data on cases is from US Center for Disease Control, based on reports from state and local health agencies (<ext-link xlink:href="https://covid.cdc.gov/covid-data-tracker/#trends_dailycases" ext-link-type="uri">https://covid.cdc.gov/covid-data-tracker/#trends_dailycases</ext-link>).</p>
      <fig position="float" id="pone.0281147.g007">
        <object-id pub-id-type="doi">10.1371/journal.pone.0281147.g007</object-id>
        <label>Fig 7</label>
        <caption>
          <title>Overview of COVID-19 papers in corpus by discipline.</title>
          <p>Cumulative count by primary discipline of COVID-19 papers in the COVIDScholar database and total number of reported US COVID-19 cases from January 2020 to January 2022 (Right) and focused view of January-October 2020 (Left). Papers are categorized by the classification model described in Sec. 1. Case data from the United States Center for Disease Control. Note that only those papers with abstracts available are classified and papers can be classified with none of the labels, so the publication count is somewhat lower than the total number of documents in the database.</p>
        </caption>
        <graphic xlink:href="pone.0281147.g007" position="float"/>
      </fig>
      <p>The rate at which publications emerged in all disciplines shows a steep increase through the early months of 2020. Between the declaration of a Public Health Emergency of International Concern [<xref rid="pone.0281147.ref049" ref-type="bibr">49</xref>] by the World Health Organization in January 2020 and April 2020, the rate of new publications approximately tripled every month, from just 91 papers published in January to 7,135 papers published in April. After May 2020 the rate stabilized at approximately 8,000 papers per month.</p>
      <p>Given the lag between research activity and publication, it therefore seems that by April 2020 the COVID-19 research effort had already reached full capacity. This is before the US case count began to dramatically rise in the summer of 2020. The US government also passed two stimulus bills, each with over $1 billion in funding allocated for coronavirus research on March 5th, 2020 [<xref rid="pone.0281147.ref050" ref-type="bibr">50</xref>] and March 27th, 2020 [<xref rid="pone.0281147.ref051" ref-type="bibr">51</xref>]. Our data suggests that any increase in rate of research associated with these had already fully manifested itself within 2 months of their passing, demonstrating the rapidity of the scientific community’s COVID-19 response. Other notable events within this time frame include the declaration of global pandemic by the WHO on March 11, 2020 [<xref rid="pone.0281147.ref052" ref-type="bibr">52</xref>].</p>
      <p>A breakdown of research in the COVIDScholar corpus by discipline is shown in <xref rid="pone.0281147.g008" ref-type="fig">Fig 8</xref>, which depicts the fraction of monthly COVID-19 publications primarily associated with each discipline. In this case, rather than assigning fractional papers for cases where multiple labels are assigned, we assign papers to the disciplines with the predicted label assigned the highest likelihood. There is a overall trend of an increasing fraction of research in the “humanities/social sciences” category and a decreasing fraction of research in the “medical sciences” category. The periods of February-April 2020 and June-July 2020 had more papers published in the “biological and chemical sciences” category than at other times over the pandemic, which correspond to periods where a large amount of research into the mechanism of infection and possible routes for vaccines and therapeutics was being conducted.</p>
      <fig position="float" id="pone.0281147.g008">
        <object-id pub-id-type="doi">10.1371/journal.pone.0281147.g008</object-id>
        <label>Fig 8</label>
        <caption>
          <title>Fraction of total COVID-19 papers in corpus by primary discipline.</title>
          <p>Fractions are calculated based on total over calendar month. Papers are categorized by a fine-tuned SciBERT classification model (see “NLP models for text analysis”), and assigned to the discipline with highest predicted likelihood for this breakdown.</p>
        </caption>
        <graphic xlink:href="pone.0281147.g008" position="float"/>
      </fig>
      <p>There is a clear increase in research related to psychological impacts of lockdown and social distancing. Between March and April 2020, many countries and territories instituted lockdown orders, and by April, over half of the world’s population was under either compulsory or recommended shelter-in-place orders [<xref rid="pone.0281147.ref053" ref-type="bibr">53</xref>]. The corresponding emergence of a robust literature on psychological impacts associated with this is the major driving force behind the increase in COVID-19 literature from “humanities &amp; social sciences” in our corpus. This topic grew significantly during the first 10 months of the pandemic. We visualize this increase in <xref rid="pone.0281147.g009" ref-type="fig">Fig 9</xref>, where we have plotted the fraction of total monthly papers on selected topics related to mental health and lockdown.</p>
      <fig position="float" id="pone.0281147.g009">
        <object-id pub-id-type="doi">10.1371/journal.pone.0281147.g009</object-id>
        <label>Fig 9</label>
        <caption>
          <title>Fraction of COVID-19 literature on mental health- and lockdown-related topics on a monthly basis.</title>
        </caption>
        <graphic xlink:href="pone.0281147.g009" position="float"/>
      </fig>
    </sec>
  </sec>
  <sec id="sec016">
    <title>Summary</title>
    <p>We developed and implemented a scalable research aggregation, analysis, and dissemination infrastructure, and created a targeted corpus of over 260,000 COVID-19 related research documents. At the height of the early pandemic, the associated search portal, <ext-link xlink:href="https://covidscholar.org" ext-link-type="uri">https://covidscholar.org</ext-link>, served over 8,600 weekly scientific users at its peak and has served a total of more than 33,000 users since its release in 2020. The large amount of open data and enormous scientific interest in COVID-19 during the pandemic have made it an ideal use-case for large-scale AI-driven scientific literature aggregation efforts, but the infrastructure we have described is domain-agnostic and presents a blueprint for future situations where there is rapid production and dissemination of new research. We hope that this work and its accompanying software packages can provide useful guidance in those circumstances.</p>
  </sec>
  <sec id="sec017" sec-type="supplementary-material">
    <title>Supporting information</title>
    <supplementary-material id="pone.0281147.s001" position="float" content-type="local-data">
      <label>S1 Table</label>
      <caption>
        <title>The 5 top-level disciplines (boldface) and corresponding composite fields into which COVIDScholar’s text corpus is classified.</title>
        <p>(PDF)</p>
      </caption>
      <media xlink:href="pone.0281147.s001.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material id="pone.0281147.s002" position="float" content-type="local-data">
      <label>S2 Table</label>
      <caption>
        <title>LDA topics and keywords.</title>
        <p>(PDF)</p>
      </caption>
      <media xlink:href="pone.0281147.s002.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ack>
    <p>We are thankful to the editorial team of Rapid Reviews: COVID-19 for their assistance in annotating text and helping us establish the research domain category labels.</p>
  </ack>
  <ref-list>
    <title>References</title>
    <ref id="pone.0281147.ref001">
      <label>1</label>
      <mixed-citation publication-type="other">COVIDScholar; 2020. Available from: <ext-link xlink:href="https://covidscholar.org/stats" ext-link-type="uri">https://covidscholar.org/stats</ext-link>.</mixed-citation>
    </ref>
    <ref id="pone.0281147.ref002">
      <label>2</label>
      <mixed-citation publication-type="journal"><name><surname>Johansson</surname><given-names>MA</given-names></name>, <name><surname>Reich</surname><given-names>NG</given-names></name>, <name><surname>Meyers</surname><given-names>LA</given-names></name>, <name><surname>Lipsitch</surname><given-names>M</given-names></name>. <article-title>Preprints: An underutilized mechanism to accelerate outbreak science</article-title>. <source>PLOS Medicine</source>. <year>2018</year>;<volume>15</volume>(<issue>4</issue>):<fpage>1</fpage>–<lpage>5</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1371/journal.pmed.1002549</pub-id><?supplied-pmid 29614073?><pub-id pub-id-type="pmid">29614073</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0281147.ref003">
      <label>3</label>
      <mixed-citation publication-type="journal"><name><surname>Fraser</surname><given-names>N</given-names></name>, <name><surname>Brierley</surname><given-names>L</given-names></name>, <name><surname>Dey</surname><given-names>G</given-names></name>, <name><surname>Polka</surname><given-names>JK</given-names></name>, <name><surname>Pálfy</surname><given-names>M</given-names></name>, <name><surname>Nanni</surname><given-names>F</given-names></name>, <etal>et al</etal>. <article-title>Preprinting the COVID-19 pandemic</article-title>. <source>bioRxiv</source>. <year>2020</year>;. <comment>doi: </comment><pub-id pub-id-type="doi">10.1101/2020.05.22.111294</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0281147.ref004">
      <label>4</label>
      <mixed-citation publication-type="journal"><name><surname>Mian</surname><given-names>A</given-names></name>, <name><surname>Khan</surname><given-names>S</given-names></name>. <article-title>Coronavirus: The spread of misinformation</article-title>. <source>BMC Medicine</source>. <year>2020</year>;<volume>18</volume>(<issue>1</issue>). <comment>doi: </comment><pub-id pub-id-type="doi">10.1186/s12916-020-01556-3</pub-id><?supplied-pmid 32188445?><pub-id pub-id-type="pmid">32188445</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0281147.ref005">
      <label>5</label>
      <mixed-citation publication-type="other">WHO COVID-19 Database; 2020. Available from: <ext-link xlink:href="https://search.bvsalud.org/global-literature-on-novel-coronavirus-2019-ncov/" ext-link-type="uri">https://search.bvsalud.org/global-literature-on-novel-coronavirus-2019-ncov/</ext-link>.</mixed-citation>
    </ref>
    <ref id="pone.0281147.ref006">
      <label>6</label>
      <mixed-citation publication-type="other">Wang LL, Lo K, Chandrasekhar Y, Reas R, Yang J, Burdick D, et al. CORD-19: The COVID-19 Open Research Dataset; 2020.</mixed-citation>
    </ref>
    <ref id="pone.0281147.ref007">
      <label>7</label>
      <mixed-citation publication-type="journal"><name><surname>Chen</surname><given-names>Q</given-names></name>, <name><surname>Allot</surname><given-names>A</given-names></name>, <name><surname>Lu</surname><given-names>Z</given-names></name>. <article-title>Keep up with the latest coronavirus research</article-title>. <source>Nature</source>. <year>2020</year>;<volume>579</volume>(<issue>7798</issue>):<fpage>193</fpage>–<lpage>193</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/d41586-020-00694-1</pub-id><?supplied-pmid 32157233?><pub-id pub-id-type="pmid">32157233</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0281147.ref008">
      <label>8</label>
      <mixed-citation publication-type="journal"><name><surname>Peroni</surname><given-names>S</given-names></name>, <name><surname>Shotton</surname><given-names>D</given-names></name>. <article-title>OpenCitations, an infrastructure organization for open scholarship</article-title>. <source>Quantitative Science Studies</source>. <year>2019</year>;<volume>1</volume>:<fpage>428</fpage>–<lpage>444</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1162/qss_a_00023</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0281147.ref009">
      <label>9</label>
      <mixed-citation publication-type="other">The Multidisciplinary Preprint Platform; 2020. Available from: <ext-link xlink:href="https://www.preprints.org/" ext-link-type="uri">https://www.preprints.org/</ext-link>.</mixed-citation>
    </ref>
    <ref id="pone.0281147.ref010">
      <label>10</label>
      <mixed-citation publication-type="other">OSF; 2020. Available from: <ext-link xlink:href="https://osf.io/" ext-link-type="uri">https://osf.io/</ext-link>.</mixed-citation>
    </ref>
    <ref id="pone.0281147.ref011">
      <label>11</label>
      <mixed-citation publication-type="other">The Lens COVID-19 Data Initiative; 2020. Available from: <ext-link xlink:href="https://about.lens.org/covid-19/" ext-link-type="uri">https://about.lens.org/covid-19/</ext-link>.</mixed-citation>
    </ref>
    <ref id="pone.0281147.ref012">
      <label>12</label>
      <mixed-citation publication-type="other">Social Science Research Network; 2020. Available from: <ext-link xlink:href="https://www.ssrn.com/index.cfm/en/" ext-link-type="uri">https://www.ssrn.com/index.cfm/en/</ext-link>.</mixed-citation>
    </ref>
    <ref id="pone.0281147.ref013">
      <label>13</label>
      <mixed-citation publication-type="other">Rife S. Introducing PsyArXiv: a preprint service for psychological science; 2016. Available from: <ext-link xlink:href="http://blog.psyarxiv.com/2016/09/19/introducing-psyarxiv/" ext-link-type="uri">http://blog.psyarxiv.com/2016/09/19/introducing-psyarxiv/</ext-link>.</mixed-citation>
    </ref>
    <ref id="pone.0281147.ref014">
      <label>14</label>
      <mixed-citation publication-type="other">Dimensions COVID-19 Dataset; 2020. Available from: <ext-link xlink:href="https://www.dimensions.ai/covid19/" ext-link-type="uri">https://www.dimensions.ai/covid19/</ext-link>.</mixed-citation>
    </ref>
    <ref id="pone.0281147.ref015">
      <label>15</label>
      <mixed-citation publication-type="other">Elsevier Novel Coronavirus Information Center; 2020. Available from: <ext-link xlink:href="https://www.elsevier.com/connect/coronavirus-information-center" ext-link-type="uri">https://www.elsevier.com/connect/coronavirus-information-center</ext-link>.</mixed-citation>
    </ref>
    <ref id="pone.0281147.ref016">
      <label>16</label>
      <mixed-citation publication-type="other">Chemrxiv; 2020. Available from: <ext-link xlink:href="https://chemrxiv.org/" ext-link-type="uri">https://chemrxiv.org/</ext-link>.</mixed-citation>
    </ref>
    <ref id="pone.0281147.ref017">
      <label>17</label>
      <mixed-citation publication-type="other">Kaiser J, Hicks L, Service RF. New Preprint Server Aims to Be Biologists’ Answer to Physicists’ arXiv; 2017. Available from: <ext-link xlink:href="https://www.sciencemag.org/news/2013/11/new-preprint-server-aims-be-biologists-answer-physicists-arxiv" ext-link-type="uri">https://www.sciencemag.org/news/2013/11/new-preprint-server-aims-be-biologists-answer-physicists-arxiv</ext-link>.</mixed-citation>
    </ref>
    <ref id="pone.0281147.ref018">
      <label>18</label>
      <mixed-citation publication-type="other">Rawlinson C, Bloom T. New preprint server for medical research; 2019.</mixed-citation>
    </ref>
    <ref id="pone.0281147.ref019">
      <label>19</label>
      <mixed-citation publication-type="other">NBER Working Papers; 2020. Available from: <ext-link xlink:href="https://www.nber.org/papers" ext-link-type="uri">https://www.nber.org/papers</ext-link>.</mixed-citation>
    </ref>
    <ref id="pone.0281147.ref020">
      <label>20</label>
      <mixed-citation publication-type="other">PDFMiner; 2020. Available from: <ext-link xlink:href="https://github.com/pdfminer/pdfminer.six" ext-link-type="uri">https://github.com/pdfminer/pdfminer.six</ext-link>.</mixed-citation>
    </ref>
    <ref id="pone.0281147.ref021">
      <label>21</label>
      <mixed-citation publication-type="other">Vespa Engine;. Available from: <ext-link xlink:href="https://vespa.ai/" ext-link-type="uri">https://vespa.ai/</ext-link>.</mixed-citation>
    </ref>
    <ref id="pone.0281147.ref022">
      <label>22</label>
      <mixed-citation publication-type="book"><name><surname>Jones</surname><given-names>KS</given-names></name>, <name><surname>Walker</surname><given-names>S</given-names></name>, <name><surname>Robertson</surname><given-names>SE</given-names></name>. <part-title>A probabilistic model of information retrieval: development and comparative experiments</part-title>. In: <source>Information Processing and Management</source>; <year>2000</year>. p. <fpage>779</fpage>–<lpage>840</lpage>.</mixed-citation>
    </ref>
    <ref id="pone.0281147.ref023">
      <label>23</label>
      <mixed-citation publication-type="journal"><name><surname>Lu</surname><given-names>R</given-names></name>, <name><surname>Zhao</surname><given-names>X</given-names></name>, <name><surname>Li</surname><given-names>J</given-names></name>, <name><surname>Niu</surname><given-names>P</given-names></name>, <name><surname>Yang</surname><given-names>B</given-names></name>, <name><surname>Wu</surname><given-names>H</given-names></name>, <etal>et al</etal>. <article-title>Genomic characterisation and epidemiology of 2019 novel coronavirus: implications for virus origins and receptor binding</article-title>. <source>The Lancet</source>. <year>2020</year>;<volume>395</volume>(<issue>10224</issue>):<fpage>565</fpage>–<lpage>574</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/S0140-6736(20)30251-8</pub-id><?supplied-pmid 32007145?><pub-id pub-id-type="pmid">32007145</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0281147.ref024">
      <label>24</label>
      <mixed-citation publication-type="journal"><name><surname>Rabaan</surname><given-names>AA</given-names></name>, <name><surname>Al-Ahmed</surname><given-names>SH</given-names></name>, <name><surname>Haque</surname><given-names>S</given-names></name>, <name><surname>Sah</surname><given-names>R</given-names></name>, <name><surname>Tiwari</surname><given-names>R</given-names></name>, <name><surname>Malik</surname><given-names>YS</given-names></name>, <etal>et al</etal>. <article-title>SARS-CoV-2, SARS-CoV, and MERS-CoV: A comparative overview</article-title>. <source>Infezioni in Medicina</source>. <year>2020</year>;<volume>28</volume>(<issue>2</issue>):<fpage>174</fpage>–<lpage>184</lpage>. <?supplied-pmid 32275259?><pub-id pub-id-type="pmid">32275259</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0281147.ref025">
      <label>25</label>
      <mixed-citation publication-type="journal"><name><surname>Mollica</surname><given-names>V</given-names></name>, <name><surname>Rizzo</surname><given-names>A</given-names></name>, <name><surname>Massari</surname><given-names>F</given-names></name>. <article-title>The pivotal role of TMPRSS2 in coronavirus disease 2019 and prostate cancer</article-title>. <source>Future Oncology</source>. <year>2020</year>;<volume>16</volume>(<issue>27</issue>):<fpage>2029</fpage>–<lpage>2033</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.2217/fon-2020-0571</pub-id><?supplied-pmid 32658591?><pub-id pub-id-type="pmid">32658591</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0281147.ref026">
      <label>26</label>
      <mixed-citation publication-type="journal"><name><surname>Stopsack</surname><given-names>KH</given-names></name>, <name><surname>Mucci</surname><given-names>LA</given-names></name>, <name><surname>Antonarakis</surname><given-names>ES</given-names></name>, <name><surname>Nelson</surname><given-names>PS</given-names></name>, <name><surname>Kantoff</surname><given-names>PW</given-names></name>. <article-title>TMPRSS2 and COVID-19: Serendipity or Opportunity for Intervention?</article-title><source>Cancer discovery</source>. <year>2020</year>;<volume>10</volume>(<issue>6</issue>):<fpage>779</fpage>–<lpage>782</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1158/2159-8290.CD-20-0451</pub-id><?supplied-pmid 32276929?><pub-id pub-id-type="pmid">32276929</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0281147.ref027">
      <label>27</label>
      <mixed-citation publication-type="other">Le Q, Mikolov T. Distributed Representations of Sentences and Documents. In: Proceedings of the 31st International Conference on International Conference on Machine Learning—Volume 32. ICML’14. JMLR.org; 2014. p. II–1188–II–1196.</mixed-citation>
    </ref>
    <ref id="pone.0281147.ref028">
      <label>28</label>
      <mixed-citation publication-type="other">Beltagy I, Lo K, Cohan A. SciBERT: Pretrained Language Model for Scientific Text. In: EMNLP; 2019.</mixed-citation>
    </ref>
    <ref id="pone.0281147.ref029">
      <label>29</label>
      <mixed-citation publication-type="journal"><name><surname>Lee</surname><given-names>J</given-names></name>, <name><surname>Yoon</surname><given-names>W</given-names></name>, <name><surname>Kim</surname><given-names>S</given-names></name>, <name><surname>Kim</surname><given-names>D</given-names></name>, <name><surname>Kim</surname><given-names>S</given-names></name>, <name><surname>So</surname><given-names>CH</given-names></name>, <etal>et al</etal>. <article-title>BioBERT: a pre-trained biomedical language representation model for biomedical text mining</article-title>. <source>Bioinformatics</source>. <year>2019</year>;. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/bioinformatics/btz682</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0281147.ref030">
      <label>30</label>
      <mixed-citation publication-type="other">Rasmy L, Xiang Y, Xie Z, Tao C, Zhi D. Med-BERT: pre-trained contextualized embeddings on large-scale structured electronic health records for disease prediction; 2020.</mixed-citation>
    </ref>
    <ref id="pone.0281147.ref031">
      <label>31</label>
      <mixed-citation publication-type="other">Alsentzer E, Murphy J, Boag W, Weng WH, Jin D, Naumann T, et al. Publicly Available Clinical BERT Embeddings. In: Proceedings of the 2nd Clinical Natural Language Processing Workshop. Minneapolis, Minnesota, USA: Association for Computational Linguistics; 2019. p. 72–78. Available from: <ext-link xlink:href="https://www.aclweb.org/anthology/W19-1909" ext-link-type="uri">https://www.aclweb.org/anthology/W19-1909</ext-link>.</mixed-citation>
    </ref>
    <ref id="pone.0281147.ref032">
      <label>32</label>
      <mixed-citation publication-type="other">Sinha A, Shen Z, Song Y, Ma H, Eide D, Wang K. An Overview of Microsoft Academic Service (MAS) and Applications. In: WWW—World Wide Web Consortium (W3C); 2015.Available from: <ext-link xlink:href="https://www.microsoft.com/en-us/research/publication/an-overview-of-microsoft-academic-service-mas-and-applications-2/" ext-link-type="uri">https://www.microsoft.com/en-us/research/publication/an-overview-of-microsoft-academic-service-mas-and-applications-2/</ext-link>.</mixed-citation>
    </ref>
    <ref id="pone.0281147.ref033">
      <label>33</label>
      <mixed-citation publication-type="journal"><name><surname>Yoon</surname><given-names>W</given-names></name>, <name><surname>So</surname><given-names>CH</given-names></name>, <name><surname>Lee</surname><given-names>J</given-names></name>, <name><surname>Kang</surname><given-names>J</given-names></name>. <article-title>CollaboNet: collaboration of deep neural networks for biomedical named entity recognition</article-title>. <source>BMC Bioinformatics</source>. <year>2019</year>;<volume>20</volume>(<issue>S10</issue>). <comment>doi: </comment><pub-id pub-id-type="doi">10.1186/s12859-019-2813-6</pub-id><?supplied-pmid 31138109?><pub-id pub-id-type="pmid">31138109</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0281147.ref034">
      <label>34</label>
      <mixed-citation publication-type="other">Nye B, Li JJ, Patel R, Yang Y, Marshall I, Nenkova A, et al. A Corpus with Multi-Level Annotations of Patients, Interventions and Outcomes to Support Language Processing for Medical Literature. In: Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). Melbourne, Australia: Association for Computational Linguistics; 2018. p. 197–207. Available from: <ext-link xlink:href="https://www.aclweb.org/anthology/P18-1019" ext-link-type="uri">https://www.aclweb.org/anthology/P18-1019</ext-link>.</mixed-citation>
    </ref>
    <ref id="pone.0281147.ref035">
      <label>35</label>
      <mixed-citation publication-type="journal"><name><surname>Lim</surname><given-names>S</given-names></name>, <name><surname>Kang</surname><given-names>J</given-names></name>. <article-title>Chemical–gene relation extraction using recursive neural network</article-title>. <source>Database</source>. <year>2018</year>;<volume>2018</volume>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/database/bay060</pub-id><?supplied-pmid 29961818?><pub-id pub-id-type="pmid">29961818</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0281147.ref036">
      <label>36</label>
      <mixed-citation publication-type="other">Rapid Reviews: COVID-19, publishes reviews of COVID-19 preprints. Rapid Reviews COVID-19. 2020;.</mixed-citation>
    </ref>
    <ref id="pone.0281147.ref037">
      <label>37</label>
      <mixed-citation publication-type="other">Sanh V, Debut L, Chaumond J, Wolf T. DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter. ArXiv. 2019;.</mixed-citation>
    </ref>
    <ref id="pone.0281147.ref038">
      <label>38</label>
      <mixed-citation publication-type="other">Cohan A, Feldman S, Beltagy I, Downey D, Weld DS. SPECTER: Document-level Representation Learning using Citation-informed Transformers. ArXiv. 2020;.</mixed-citation>
    </ref>
    <ref id="pone.0281147.ref039">
      <label>39</label>
      <mixed-citation publication-type="other">Mihalcea R, Tarau P. TextRank: Bringing Order into Text. In: Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing. Barcelona, Spain: Association for Computational Linguistics; 2004. p. 404–411. Available from: <ext-link xlink:href="https://www.aclweb.org/anthology/W04-3252" ext-link-type="uri">https://www.aclweb.org/anthology/W04-3252</ext-link>.</mixed-citation>
    </ref>
    <ref id="pone.0281147.ref040">
      <label>40</label>
      <mixed-citation publication-type="journal"><name><surname>Salton</surname><given-names>G</given-names></name>, <name><surname>Buckley</surname><given-names>C</given-names></name>. <article-title>Term-weighting approaches in automatic text retrieval</article-title>. <source>Information Processing &amp; Management</source>. <year>1988</year>;<volume>24</volume>(<issue>5</issue>):<fpage>513</fpage>–<lpage>523</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/0306-4573(88)90021-0</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0281147.ref041">
      <label>41</label>
      <mixed-citation publication-type="other">Skrlj B, Repar A, Pollak S. RaKUn: Rank-based Keyword extraction via Unsupervised learning and Meta vertex aggregation. ArXiv. 2019;abs/1907.06458.</mixed-citation>
    </ref>
    <ref id="pone.0281147.ref042">
      <label>42</label>
      <mixed-citation publication-type="other">Campos R, Mangaravite V, Pasquali A, Jorge A, Nunes C, Jatowt A. YAKE! Collection-Independent Automatic Keyword Extractor; 2018.</mixed-citation>
    </ref>
    <ref id="pone.0281147.ref043">
      <label>43</label>
      <mixed-citation publication-type="other">Smilkov D, Thorat N, Nicholson C, Reif E, Viégas FB, Wattenberg M. Embedding projector: Interactive visualization and interpretation of embeddings. arXiv preprint arXiv:161105469. 2016;.</mixed-citation>
    </ref>
    <ref id="pone.0281147.ref044">
      <label>44</label>
      <mixed-citation publication-type="other">Bojanowski P, Grave E, Joulin A, Mikolov T. Enriching Word Vectors with Subword Information. arXiv preprint arXiv:160704606. 2016;.</mixed-citation>
    </ref>
    <ref id="pone.0281147.ref045">
      <label>45</label>
      <mixed-citation publication-type="other">McInnes L, Healy J, Melville J. UMAP: Uniform Manifold Approximation and Projection for Dimension Reduction; 2018. Available from: <ext-link xlink:href="http://arxiv.org/abs/1802.03426" ext-link-type="uri">http://arxiv.org/abs/1802.03426</ext-link>.</mixed-citation>
    </ref>
    <ref id="pone.0281147.ref046">
      <label>46</label>
      <mixed-citation publication-type="journal"><name><surname>van der Maaten</surname><given-names>L</given-names></name>, <name><surname>Hinton</surname><given-names>G</given-names></name>. <article-title>Visualizing Data using t-SNE</article-title>. <source>Journal of Machine Learning Research</source>. <year>2008</year>;<volume>9</volume>:<fpage>2579</fpage>–<lpage>2605</lpage>.</mixed-citation>
    </ref>
    <ref id="pone.0281147.ref047">
      <label>47</label>
      <mixed-citation publication-type="other">Blei DM, Ng AY, Edu JB. Latent Dirichlet Allocation Michael I. Jordan; 2003.</mixed-citation>
    </ref>
    <ref id="pone.0281147.ref048">
      <label>48</label>
      <mixed-citation publication-type="journal"><name><surname>Bose</surname><given-names>P</given-names></name>, <name><surname>Roy</surname><given-names>S</given-names></name>, <name><surname>Ghosh</surname><given-names>P</given-names></name>. <article-title>A Comparative NLP-Based Study on theCurrent Trends and Future Directions in COVID-19 Research</article-title>. <source>IEEE Access</source>. <year>2021</year>;<volume>9</volume>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1109/ACCESS.2021.3082108</pub-id><?supplied-pmid 34786315?><pub-id pub-id-type="pmid">34786315</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0281147.ref049">
      <label>49</label>
      <mixed-citation publication-type="other">WHO. Statement on the second meeting of the International Health Regulations (2005) Emergency Committee regarding the outbreak of novel coronavirus (2019-nCoV); 2020. Available from: <ext-link xlink:href="http://bit.ly/3J7QbNI" ext-link-type="uri">http://bit.ly/3J7QbNI</ext-link>.</mixed-citation>
    </ref>
    <ref id="pone.0281147.ref050">
      <label>50</label>
      <mixed-citation publication-type="other">116th Congress (2019-2020). H.R.6074—Coronavirus Preparedness and Response Supplemental Appropriations Act, 2020; 2020. Available from: <ext-link xlink:href="https://www.congress.gov/bill/116th-congress/house-bill/6074/text" ext-link-type="uri">https://www.congress.gov/bill/116th-congress/house-bill/6074/text</ext-link>.</mixed-citation>
    </ref>
    <ref id="pone.0281147.ref051">
      <label>51</label>
      <mixed-citation publication-type="other">116th Congress (2019-2020). H.R. 748—Coronavirus Aid, Relief, 3 and Economic Security Act; 2020. Available from: <ext-link xlink:href="https://www.congress.gov/116/bills/hr748/BILLS-116hr748eas.pdf" ext-link-type="uri">https://www.congress.gov/116/bills/hr748/BILLS-116hr748eas.pdf</ext-link>.</mixed-citation>
    </ref>
    <ref id="pone.0281147.ref052">
      <label>52</label>
      <mixed-citation publication-type="other">WHO. WHO Director-General’s opening remarks at the media briefing on COVID-19; 2020. Available from: <ext-link xlink:href="http://bit.ly/3kxGDRX" ext-link-type="uri">http://bit.ly/3kxGDRX</ext-link>.</mixed-citation>
    </ref>
    <ref id="pone.0281147.ref053">
      <label>53</label>
      <mixed-citation publication-type="other">Sandford A. Coronavirus: Half of humanity now on lockdown as 90 countries call for confinement; 2020. Available from: <ext-link xlink:href="http://bit.ly/404odZo" ext-link-type="uri">http://bit.ly/404odZo</ext-link>.</mixed-citation>
    </ref>
  </ref-list>
</back>
