<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 2?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">J Cheminform</journal-id>
    <journal-id journal-id-type="iso-abbrev">J Cheminform</journal-id>
    <journal-title-group>
      <journal-title>Journal of Cheminformatics</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1758-2946</issn>
    <publisher>
      <publisher-name>Springer International Publishing</publisher-name>
      <publisher-loc>Cham</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">4570700</article-id>
    <article-id pub-id-type="pmid">26379782</article-id>
    <article-id pub-id-type="publisher-id">94</article-id>
    <article-id pub-id-type="doi">10.1186/s13321-015-0094-2</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Research Article</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>RRegrs: an R package for computer-aided model selection with multiple regression models</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" corresp="yes" equal-contrib="yes">
        <name>
          <surname>Tsiliki</surname>
          <given-names>Georgia</given-names>
        </name>
        <address>
          <email>gtsiliki@central.ntua.gr</email>
        </address>
        <xref ref-type="aff" rid="Aff1"/>
      </contrib>
      <contrib contrib-type="author" equal-contrib="yes">
        <name>
          <surname>Munteanu</surname>
          <given-names>Cristian R.</given-names>
        </name>
        <address>
          <email>crm.publish@gmail.com</email>
        </address>
        <xref ref-type="aff" rid="Aff2"/>
        <xref ref-type="aff" rid="Aff3"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Seoane</surname>
          <given-names>Jose A.</given-names>
        </name>
        <address>
          <email>seoane@stanford.edu</email>
        </address>
        <xref ref-type="aff" rid="Aff4"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Fernandez-Lozano</surname>
          <given-names>Carlos</given-names>
        </name>
        <address>
          <email>carlos.fernandez@udc.es</email>
        </address>
        <xref ref-type="aff" rid="Aff2"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Sarimveis</surname>
          <given-names>Haralambos</given-names>
        </name>
        <address>
          <email>hsarimv@central.ntua.gr</email>
        </address>
        <xref ref-type="aff" rid="Aff1"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Willighagen</surname>
          <given-names>Egon L.</given-names>
        </name>
        <address>
          <email>egon.willighagen@maastrichtuniversity.nl</email>
        </address>
        <xref ref-type="aff" rid="Aff3"/>
      </contrib>
      <aff id="Aff1"><label/>School of Chemical Engineering, National Technical University of Athens, 9 Heroon Polytechneiou Street, Zografou Campus, 15780 Athens, Greece </aff>
      <aff id="Aff2"><label/>Computer Science Faculty, University of A Coruna, Campus Elviña, s/n, 15071 A Coruña, Spain </aff>
      <aff id="Aff3"><label/>Department of Bioinformatics-BiGCaT, NUTRIM, Maastricht University, P.O. Box 616, UNS50 Box 19, 6200 MD Maastricht, The Netherlands </aff>
      <aff id="Aff4"><label/>Stanford Cancer Institute, Stanford University, C.J.Huang Building, 780 Welch Road, Palo Alto, CA 94304 USA </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>15</day>
      <month>9</month>
      <year>2015</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>15</day>
      <month>9</month>
      <year>2015</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2015</year>
    </pub-date>
    <volume>7</volume>
    <elocation-id>46</elocation-id>
    <history>
      <date date-type="received">
        <day>7</day>
        <month>4</month>
        <year>2015</year>
      </date>
      <date date-type="accepted">
        <day>24</day>
        <month>8</month>
        <year>2015</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© Tsiliki et al. 2015</copyright-statement>
      <license license-type="OpenAccess">
        <license-p><bold>Open Access</bold>This article is distributed under the terms of the Creative Commons Attribution 4.0 International License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted use, distribution, and reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/publicdomain/zero/1.0/">http://creativecommons.org/publicdomain/zero/1.0/</ext-link>) applies to the data made available in this article, unless otherwise stated.</license-p>
      </license>
    </permissions>
    <abstract id="Abs1">
      <sec>
        <title>Background</title>
        <p>Predictive regression models can 
be created with many different modelling approaches. Choices need to be made for data set splitting, cross-validation methods, specific regression parameters and best model criteria, as they all affect the accuracy and efficiency of the produced predictive models, and therefore, raising model reproducibility and comparison issues. Cheminformatics and bioinformatics are extensively using predictive modelling and exhibit a need for standardization of these methodologies in order to assist model selection and speed up the process of predictive model development. A tool accessible to all users, irrespectively of their statistical knowledge, would be valuable if it tests several simple and complex regression models and validation schemes, produce unified reports, and offer the option to be integrated into more extensive studies. Additionally, such methodology should be implemented as a free programming package, in order to be continuously adapted and redistributed by others.</p>
      </sec>
      <sec>
        <title>Results</title>
        <p>We propose an integrated framework for creating multiple regression models, called RRegrs. The tool offers the option of ten simple and complex regression methods combined with repeated 10-fold and leave-one-out cross-validation. Methods include Multiple Linear regression, Generalized Linear Model with Stepwise Feature Selection, Partial Least Squares regression, Lasso regression, and Support Vector Machines Recursive Feature Elimination. The new framework is an automated fully validated procedure which produces standardized reports to quickly oversee the impact of choices in modelling algorithms and assess the model and cross-validation results. The methodology was implemented as an open source R package, available at <ext-link ext-link-type="uri" xlink:href="https://www.github.com/enanomapper/RRegrs">https://www.github.com/enanomapper/RRegrs</ext-link>, by reusing and extending on the caret package.</p>
      </sec>
      <sec>
        <title>Conclusion</title>
        <p>The universality of the new methodology is demonstrated using five standard data sets from different scientific fields. Its efficiency in cheminformatics and QSAR modelling is shown with three use cases: proteomics data for surface-modified gold nanoparticles, nano-metal oxides descriptor data, and molecular descriptors for acute aquatic toxicity data. The results show that for all data sets RRegrs reports models with equal or better performance for both training and test sets than those reported in the original publications. Its good performance as well as its adaptability in terms of parameter optimization could make RRegrs a popular framework to assist the initial exploration of predictive models, and with that, the design of more comprehensive in silico screening applications.<fig position="anchor" id="Figa"><label>Graphical abstract</label><caption><p>RRegrs is a computer-aided model selection framework for R multiple regression models; this is a fully validated procedure with application to QSAR modelling</p></caption><graphic position="anchor" xlink:href="13321_2015_94_Figa_HTML" id="MO1000"/></fig></p>
      </sec>
    </abstract>
    <kwd-group xml:lang="en">
      <title>Keywords</title>
      <kwd>Multiple regression</kwd>
      <kwd>QSAR</kwd>
      <kwd>R package</kwd>
      <kwd>Caret-based tool</kwd>
    </kwd-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution>eNanoMapper (FP7-NMP-2013-SMALL-7)</institution>
        </funding-source>
        <award-id>604134</award-id>
      </award-group>
    </funding-group>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>© The Author(s) 2015</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="Sec1">
    <title>Background</title>
    <p>Many open-source statistical, data-mining, and machine learning software projects give access to a wide range of data processing and modelling algorithms often providing graphical user interfaces. Among them are Weka (Waikato Environment for Knowledge Analysis) [<xref ref-type="bibr" rid="CR1">1</xref>], RapidMiner [<xref ref-type="bibr" rid="CR2">2</xref>], Keel (Knowledge Extraction based on Evolutionary Learning) [<xref ref-type="bibr" rid="CR3">3</xref>], Orange [<xref ref-type="bibr" rid="CR4">4</xref>], Scikit-learn [<xref ref-type="bibr" rid="CR5">5</xref>], C1C2 [<xref ref-type="bibr" rid="CR6">6</xref>] and KNIME (Konstanz Information Miner) [<xref ref-type="bibr" rid="CR7">7</xref>], effectively, providing full predictive modelling frameworks.</p>
    <p>Additionally, web-based platforms such as OpenTox [<xref ref-type="bibr" rid="CR8">8</xref>] and Online Chemical Modelling Environment (OCHEM) [<xref ref-type="bibr" rid="CR9">9</xref>] focus on the development of quantitative structure-activity relationship (QSAR) models, i.e. regression or classification models that are used for the in silica assessment of physicochemical properties and biological activities of chemical compounds such as toxicity, biological potency and side effects [<xref ref-type="bibr" rid="CR10">10</xref>–<xref ref-type="bibr" rid="CR12">12</xref>]. Such platforms typically consist of two major subsystems: the database of experimental measurements and the modelling framework. They allow users to create their own QSAR models, predict results for new chemicals, and share them. OpenTox in particular is a platform-independent collection of components which communicate through web services, so that the user can combine data, models and validation results from multiple sources in a dependable and time-effective way. Several other tools offer virtual evaluation of chemical properties and toxicity using implemented QSAR models; for instance, Vega [<xref ref-type="bibr" rid="CR13">13</xref>], EPI Suite [<xref ref-type="bibr" rid="CR14">14</xref>], Toxicity Estimation Software Tool (TEST) [<xref ref-type="bibr" rid="CR15">15</xref>], QSAR4u [<xref ref-type="bibr" rid="CR16">16</xref>], BuildQSAR [<xref ref-type="bibr" rid="CR17">17</xref>], OECD QSAR Toolbox [<xref ref-type="bibr" rid="CR18">18</xref>], AZOrange [<xref ref-type="bibr" rid="CR19">19</xref>] or Bioclipse-R [<xref ref-type="bibr" rid="CR20">20</xref>]. However, these tools are limited to supported data sets, QSAR models or specific regressions methods.</p>
    <p>On the other hand, the R statistical language environment [<xref ref-type="bibr" rid="CR21">21</xref>] offers many solutions for regression modelling and also some packages providing simultaneous access to multiple methods. For example, the glmulti package conducts automated model selection and model-averaging based on the Akaike Information Criterion (AIC) or the Bayesian Information Criterion (BIC) [<xref ref-type="bibr" rid="CR22">22</xref>], the kernlab package applies Kernel-based machine learning methods for classification, regression, clustering, novelty detection, quantile regression and dimensionality reduction, and the e1071 package includes functions for latent class analysis, short time Fourier transform, fuzzy clustering, and support vector machines. Other R packages are specializing on particular set of algorithms, for instance the R package tree focuses on producing classification and regression trees.</p>
    <p>Of particular interest is the R package for predictive modelling called caret (Classification and Regression Training) which gathers and simplifies numerous R algorithms for the development of a wide variety of predictive models by calling and integrating more than 25 other packages [<xref ref-type="bibr" rid="CR23">23</xref>]. Unique features of caret include data splitting, pre-processing, characterizing performance and variable importance, and parallel processing tools.</p>
    <p>Although this package is providing useful methods for the syntactical unification of regression and classification prediction modelling approaches, the various models have different inputs and the outcomes different formats, typically depending on their parameters. This makes it hard to run all the available methods for multiple data sets, compare all the outputs, and produce a standardized results summary.</p>
    <p>Furthermore, the complexity of the workflows complicates the reproduction of the same regression results and it may affect decisions on issues, such as how to split the original data set, how often to split the data set, which cross-validation method is to be use, which data filtering to apply before regression (correlated features removal, “not available” (NA) values elimination, etc.), which data scaling is applied (normalization, standardization, etc.), which regression methods to test, which regression parameters and seeds to use, how to summarize and compare the results for several regression models, and which criteria to use in order to choose the best regression model.</p>
    <p>To address these limitations, the current manuscript describes a standardized framework that automates the development of a reliable and well-validated QSAR model, or set of models. The so-called RRegrs tool (R Regressions) is based on the R caret package and is focusing on regression modelling. RRegrs workflow offers a fully validated procedure capturing any variability or inconsistency in the data. A single RRegrs function call is needed to run the entire workflow and obtain the produced validated QSAR model(s) in a reproducible format in contrast to the standard, inefficient and time-consuming QSAR modelling workflow, where the modeller tries many different algorithms and even needs to further search the parameter space of each algorithm. This is a considerable advantage for users with perhaps limited statistical knowledge or limited R experience. Also reproducibility is a comparative advantage since often the same procedure needs to be applied for different data sets. RRegrs implements an easy way to explore the models’ search space of linear and non-linear models with special parameters specifications and cross validation schemes. Furthermore, model outputs are easily accessible and readable, organized by methods, centralized and averaged by multiple reproducible data set splits. Summary files are also produced helping the user to easily access all methodologies results, which can then be prioritized based on various statistics. The current implementation of the RRegrs package contains ten different regression algorithms and supports parallel processing, if prompted. RRegrs function calls can be integrated into complex desktop and web tools for QSAR. RRegrs package is available as an open repository at <ext-link ext-link-type="uri" xlink:href="https://www.github.com/enanomapper/RRegrs">https://www.github.com/enanomapper/RRegrs</ext-link>. The current release is available from ZENODO with the doi:10.5281/zenodo.21946.</p>
  </sec>
  <sec id="Sec2">
    <title>Results and discussion</title>
    <p>RRegrs is an R package for computer-aided model selection, designed and implemented as a collection of regression tools available from the caret package. RRegrs uses the R package testthat for testing [<xref ref-type="bibr" rid="CR24">24</xref>]. It does not apply full unit testing, but several RRegrs parameter combinations are tested, which are run during the build process. RRegrs can be used to find the best regression model for any numerical data set using some or all of ten linear and non-linear regression models: Multiple Linear regression (LM), Generalized Linear Model with Stepwise Feature Selection (GLM) [<xref ref-type="bibr" rid="CR25">25</xref>], Partial Least Squares Regression (PLS) [<xref ref-type="bibr" rid="CR26">26</xref>], Lasso regression (LASSO) [<xref ref-type="bibr" rid="CR27">27</xref>], Elastic Net regression (ENET) [<xref ref-type="bibr" rid="CR28">28</xref>], Support vector machine using radial functions (SVRM) [<xref ref-type="bibr" rid="CR29">29</xref>], Neural Networks regression (NN) [<xref ref-type="bibr" rid="CR30">30</xref>], Random Forest (RF) [<xref ref-type="bibr" rid="CR31">31</xref>], Random Forest Recursive Feature Elimination (RF-RFE) [<xref ref-type="bibr" rid="CR32">32</xref>] and Support Vector Machines Recursive Feature Elimination (SVM-RFE) [<xref ref-type="bibr" rid="CR33">33</xref>]. Using the above methods, we explore the model space and compare outputs to decide on the optimal model, given the data. We are setting the regression method parameters with grid functions which have been carefully chosen to optimize different models, and particularly this is done for PLS, SVRM, SVM-RFE, NN, RF, RF-RFE, ENET. Specifically for SVRM, SVM-RFE the user could also specify custom parameters.</p>
    <p>The main scope of the presented tool is to be able to run a large number of regression methods from the caret package using only one function call, to use standardized cross-validation (CV) scheme for all the methods, to obtain standardized outputs, to generate result summary tables and comparison plots for the regression methods and to store for each method detailed statistics and fitting plots. RRegrs integrates results of individual models and decides on the best model given the data set and the user specified parameters, unlike caret. Therefore, RRegrs permits users, irrespective of their programming or statistics experience, to predict any type of numerical output using multiple regression methods. In addition, advanced users could integrate RRegrs in other applications or software packages. For example, in cheminformatics RRegrs can be used to generate predictive models using molecular descriptors calculated with the rcdk package, using functions offered by the Chemistry Development Kit [<xref ref-type="bibr" rid="CR34">34</xref>].</p>
    <p>RRegrs function wraps up all the above mentioned procedures within just one call. The following steps are included (see Fig. <xref rid="Fig1" ref-type="fig">1</xref>): load parameters and data set, remove the NA values, remove near zero variance features, scale the data set, remove correlated features, split data set into training and test sets, run the selected regression methods using the selected cross-validation method(s), summarize the statistics for all methods and splittings, average for each method and cross-validation type for all splittings, apply the best model of each method and split on the test sets, apply Y-randomization on the best model, and assess the Applicability Domain. For each model, a CV scheme is introduced with two options: 10-fold repeated CV and Leave-One-Out (LOO) CV. The more time-consuming regression methods (RF, SVM-RFE, RF-RFE) are using only repeated cross-validation (other validation methods could be very slow for these complex functions), whereas for computationally demanding methods RRegrs offers parallel processing for a defined number of CPU cores. Detailed output files for all regression methods are produced, plots for individual model statistics, as well as summary statistics and comparison plots between methods, resulting in a significant number of CSV, PDF, PNG outputs files. Additionally, several summary files are created. A CSV output file is created with all the basic statistics (17 values) for each method, data splitting and CV type. Based on the above, averaged statistics are calculated for each regression method and across all data splits, which are the values needed to decide on the final best model performance. The best model is further validated with Y-randomization runs (100 by default).<fig id="Fig1"><label>Fig. 1</label><caption><p>RRegrs methodology flowchart. Outline of the steps performed by the RRegrs function</p></caption><graphic xlink:href="13321_2015_94_Fig1_HTML" id="MO1"/></fig></p>
    <p>For each regression method, caret package utilities are employed. For example, RRegrs uses the trainControl and train functions to set the training conditions (10 repetitions; RMSE used as metrics to choose the model) and train the model, respectively. For each method, RRegrs is generating the same list of 17 statistics values: regression name, split number, cross-validation type, number of model features, names of model features, training adjusted R-squared (adj.R<sup>2</sup>), training root mean squared error (RMSE<sub>CV/LOO</sub>), training <inline-formula id="IEq1"><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text{R}}_{{{\text{CV}}/{\text{LOO}}}}^{2}$$\end{document}</tex-math><mml:math id="M2"><mml:msubsup><mml:mtext>R</mml:mtext><mml:mrow><mml:mrow><mml:mtext>CV</mml:mtext><mml:mo stretchy="false">/</mml:mo><mml:mtext>LOO</mml:mtext></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:math><inline-graphic xlink:href="13321_2015_94_Article_IEq1.gif"/></alternatives></inline-formula>, training standardized RMSE, test adjusted R<sup>2</sup>, test RMSE (RMSE<sub>test</sub>), test R<sup>2</sup> (<inline-formula id="IEq2"><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text{R}}_{\text{test}}^{2}$$\end{document}</tex-math><mml:math id="M4"><mml:msubsup><mml:mtext>R</mml:mtext><mml:mrow><mml:mtext>test</mml:mtext></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:math><inline-graphic xlink:href="13321_2015_94_Article_IEq2.gif"/></alternatives></inline-formula>), test correlation, and corresponding values for both sets. If the user requests detailed output (the default flag is set to True), several files are generated such as a CSV file with statistics about each regression model listing the following information: regression method, splitting number, cross-validation type, training set summary, test set summary, fitting summary, list of predictors, training/test predictors, a full list of statistics as defined above, feature importance, residuals of the fitted model, assessment of applicability domain/leverage analysis such as mean of hat values, hat values with warnings, leverage threshold, list of points with leverage greater than threshold, Cook’s distances, Cook’s distance cutoff, points influence. Particularly, for each data splitting and CV method, the following plots are produced: observed versus predicted values for training/test sets, feature importance, fitted versus residuals for the fitted model, leverage statistics for fitted model, Cook’s distance for fitted model, and six standard fitting plots including Cook’s distance cutoff.</p>
    <p>Moreover, RRegrs offers an exhaustive validation framework by introducing multiple random data splittings. For each algorithm and data split, the model is produced based on training and validation sets. We are reporting both CV and external validation statistics, however, the test set is used to select the final best model, i.e. the best performing amongst the optimal models produced by different algorithms (both linear and non-linear). Decision is made on the averaged statistics across data splits to remove any bias towards the structure of the test set. The best regression model is selected based on the following criterion: from the best averaged <inline-formula id="IEq3"><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text{R}}_{\text{test}}^{2}$$\end{document}</tex-math><mml:math id="M6"><mml:msubsup><mml:mtext>R</mml:mtext><mml:mrow><mml:mtext>test</mml:mtext></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:math><inline-graphic xlink:href="13321_2015_94_Article_IEq3.gif"/></alternatives></inline-formula> (+/−0.05), the model with minimum RMSE<sub>test</sub> is the final one. Alternatively, the test adjusted R<sup>2</sup> can be used to select the best model. For the best model, an additional CSV file is generated providing detailed statistics as well as PDF plots for important statistics.</p>
    <p>As mentioned above, parallel processing is employed during training steps by enabling caret’s parallel design, and it is activated by either using caret’s TrainControl “allowParallel” option, or in the case of RFE methods also within the model selection (iterating with a parallel foreach through the cross validation model selection for each feature size) using RFEControl “allowParallel” option. Libraries doMC (Linux/Mac) and doSNOW (Windows) provide foreach parallel adaptor.</p>
    <p>The uses of RRegrs reported here are aimed at finding QSAR models for cheminformatics and nanotoxicology for the eNanoMapper European FP7 project. RRegrs was first tested with five standard data sets from UC Irvine Machine Learning Repository [<xref ref-type="bibr" rid="CR35">35</xref>], followed by a demonstration the efficiency of RRegrs in cheminformatics and bioinformatics areas, using three publicly available data sets, as presented in the following sections.</p>
    <sec id="Sec3">
      <title>RRegrs models for standard data sets</title>
      <p>To benchmark RRegrs we first used five standard regression data sets from the UC Irvine machine learning repository [<xref ref-type="bibr" rid="CR35">35</xref>]: the housing [<xref ref-type="bibr" rid="CR36">36</xref>], computer hardware, wine quality [<xref ref-type="bibr" rid="CR37">37</xref>], automobile [<xref ref-type="bibr" rid="CR38">38</xref>], and Parkinsons telemonitoring [<xref ref-type="bibr" rid="CR39">39</xref>] data sets. Based on these data sets we demonstrate the RRegrs methodology capabilities in different scientific fields. The number of cases and features of these data sets are described in the Methods section.</p>
      <p>The housing data set is the most used standard data set for complex regression methods: combination of regression estimators as genetic algorithm-based selective neural network ensemble [<xref ref-type="bibr" rid="CR40">40</xref>], distributed multivariate regression using wavelet-based collective data mining [<xref ref-type="bibr" rid="CR41">41</xref>], application of the Bayesian evidence framework to support vector regression (SVR) [<xref ref-type="bibr" rid="CR42">42</xref>], Principal Components approach that combines regression estimates [<xref ref-type="bibr" rid="CR43">43</xref>], regression on feature projections (RFP) method [<xref ref-type="bibr" rid="CR44">44</xref>], subset-based least squares subspace regression in reproducing Kernel Hilbert space (RKHS) [<xref ref-type="bibr" rid="CR45">45</xref>], Smola and Scholkopf’s sequential minimal optimization (SMO) algorithm for SVM regression [<xref ref-type="bibr" rid="CR46">46</xref>], etc.</p>
      <p>Tables <xref rid="Tab1" ref-type="table">1</xref> and <xref rid="Tab2" ref-type="table">2</xref> present two statistic values for these standard data sets: <inline-formula id="IEq4"><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text{R}}_{\text{test}}^{2}$$\end{document}</tex-math><mml:math id="M8"><mml:msubsup><mml:mtext>R</mml:mtext><mml:mrow><mml:mtext>test</mml:mtext></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:math><inline-graphic xlink:href="13321_2015_94_Article_IEq4.gif"/></alternatives></inline-formula> and RMSE<sub>test</sub> values, averaged by 10 different data set splits, using 10-fold repeated CV and 10 Y-randomization. The results show that advanced methods such as RF-RFE and RF give the highest R<sup>2</sup> values. In the case of the Housing data set, PLS provides a very low <inline-formula id="IEq5"><alternatives><tex-math id="M9">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text{R}}_{\text{test}}^{2}$$\end{document}</tex-math><mml:math id="M10"><mml:msubsup><mml:mtext>R</mml:mtext><mml:mrow><mml:mtext>test</mml:mtext></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:math><inline-graphic xlink:href="13321_2015_94_Article_IEq5.gif"/></alternatives></inline-formula> of 0.266 compared with the RF-RFE/RF that shows 0.875/0.874 (<inline-formula id="IEq6"><alternatives><tex-math id="M11">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text{R}}_{\text{test}}^{2}$$\end{document}</tex-math><mml:math id="M12"><mml:msubsup><mml:mtext>R</mml:mtext><mml:mrow><mml:mtext>test</mml:mtext></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:math><inline-graphic xlink:href="13321_2015_94_Article_IEq6.gif"/></alternatives></inline-formula> for LM is 0.707). Because of its slightly lower RMSE<sub>test</sub> value compared to RF-RFE (less than 0.001), RRegrs suggests RF as the best model. Figure <xref rid="Fig2" ref-type="fig">2</xref> shows the differences for <inline-formula id="IEq7"><alternatives><tex-math id="M13">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text{R}}_{\text{test}}^{2}$$\end{document}</tex-math><mml:math id="M14"><mml:msubsup><mml:mtext>R</mml:mtext><mml:mrow><mml:mtext>test</mml:mtext></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:math><inline-graphic xlink:href="13321_2015_94_Article_IEq7.gif"/></alternatives></inline-formula> and RMSE<sub>CV</sub> on the training set (data split 1) and Fig. <xref rid="Fig3" ref-type="fig">3</xref> presents the comparison for resampling on the training set (data split 1). In order to observe the quality of the regression models, Fig. <xref rid="Fig4" ref-type="fig">4</xref> presents the observed versus predicted values in the test set for the best models for five data sets (10-fold repeated CV). The applicability domain section of RRegrs plotted the leverage for the Housing best fitted model (RF) as in Fig. <xref rid="Fig5" ref-type="fig">5</xref>.<table-wrap id="Tab1"><label>Table 1</label><caption><p>Test averaged R<sup>2</sup> values for five standard data sets</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">RRegrs method</th><th align="left">Housing</th><th align="left">Computer hardware</th><th align="left">Red wine quality</th><th align="left">Automobile</th><th align="left">Parkinson telemonitoring</th></tr></thead><tbody><tr><td align="left">LM</td><td char="." align="char">0.707</td><td char="." align="char">0.822</td><td char="." align="char">0.355</td><td char="." align="char">0.824</td><td char="." align="char">0.154</td></tr><tr><td align="left">GLM</td><td char="." align="char">0.709</td><td char="." align="char">0.825</td><td char="." align="char">0.353</td><td char="." align="char">0.824</td><td char="." align="char">0.153</td></tr><tr><td align="left">PLS</td><td char="." align="char">0.266</td><td char="." align="char">0.740</td><td char="." align="char">0.066</td><td char="." align="char">0.757</td><td char="." align="char">0.091</td></tr><tr><td align="left">LASSO</td><td char="." align="char">0.704</td><td char="." align="char">0.828</td><td char="." align="char">0.354</td><td char="." align="char">0.831</td><td char="." align="char">0.154</td></tr><tr><td align="left">ENET</td><td char="." align="char">0.705</td><td char="." align="char">0.826</td><td char="." align="char">0.354</td><td char="." align="char">0.830</td><td char="." align="char">0.154</td></tr><tr><td align="left">SVRM</td><td char="." align="char">0.845</td><td char="." align="char">0.765</td><td char="." align="char">0.396</td><td char="." align="char">0.853</td><td char="." align="char">0.637</td></tr><tr><td align="left">NN</td><td char="." align="char">0.688</td><td char="." align="char">0.824</td><td char="." align="char">0.352</td><td char="." align="char">0.829</td><td char="." align="char">0.142</td></tr><tr><td align="left">RF</td><td char="." align="char">0.874</td><td char="." align="char">0.907</td><td char="." align="char">0.500</td><td char="." align="char">0.915</td><td char="." align="char">0.972</td></tr><tr><td align="left">RF-RFE</td><td char="." align="char">0.875</td><td char="." align="char">0.903</td><td char="." align="char">0.501</td><td char="." align="char">0.914</td><td char="." align="char">0.900</td></tr><tr><td align="left">SVM-RFE</td><td char="." align="char">0.717</td><td char="." align="char">0.742</td><td char="." align="char">0.383</td><td char="." align="char">0.714</td><td char="." align="char">0.479</td></tr></tbody></table></table-wrap><table-wrap id="Tab2"><label>Table 2</label><caption><p>Test averaged RMSE values for five standard data sets</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">RRegrs method</th><th align="left">Housing</th><th align="left">Computer hardware</th><th align="left">Red wine quality</th><th align="left">Automobile</th><th align="left">Parkinson telemonitoring</th></tr></thead><tbody><tr><td align="left">LM</td><td char="." align="char">0.007</td><td char="." align="char">0.001</td><td char="." align="char">0.002</td><td char="." align="char">0.076</td><td char="." align="char">0.034</td></tr><tr><td align="left">GLM</td><td char="." align="char">0.007</td><td char="." align="char">0.001</td><td char="." align="char">0.002</td><td char="." align="char">0.076</td><td char="." align="char">0.034</td></tr><tr><td align="left">PLS</td><td char="." align="char">0.011</td><td char="." align="char">0.001</td><td char="." align="char">0.003</td><td char="." align="char">0.094</td><td char="." align="char">0.035</td></tr><tr><td align="left">LASSO</td><td char="." align="char">0.007</td><td char="." align="char">0.001</td><td char="." align="char">0.002</td><td char="." align="char">0.074</td><td char="." align="char">0.034</td></tr><tr><td align="left">ENET</td><td char="." align="char">0.007</td><td char="." align="char">0.001</td><td char="." align="char">0.002</td><td char="." align="char">0.075</td><td char="." align="char">0.034</td></tr><tr><td align="left">SVRM</td><td char="." align="char">0.005</td><td char="." align="char">0.001</td><td char="." align="char">0.002</td><td char="." align="char">0.067</td><td char="." align="char">0.022</td></tr><tr><td align="left">NN</td><td char="." align="char">0.007</td><td char="." align="char">0.001</td><td char="." align="char">0.002</td><td char="." align="char">0.075</td><td char="." align="char">0.034</td></tr><tr><td align="left">RF</td><td char="." align="char">0.005</td><td char="." align="char">0.001</td><td char="." align="char">0.002</td><td char="." align="char">0.052</td><td char="." align="char">0.006</td></tr><tr><td align="left">RF-RFE</td><td char="." align="char">0.005</td><td char="." align="char">0.001</td><td char="." align="char">0.002</td><td char="." align="char">0.052</td><td char="." align="char">0.013</td></tr><tr><td align="left">SVM-RFE</td><td char="." align="char">0.008</td><td char="." align="char">0.002</td><td char="." align="char">0.002</td><td char="." align="char">0.113</td><td char="." align="char">0.027</td></tr></tbody></table></table-wrap><fig id="Fig2"><label>Fig. 2</label><caption><p>Models’ differences on the Housing training set (data split 1). We show the average performance value (<italic>dot</italic>) with two-sided confidence limits as computed by Student <italic>t</italic> test with Bonferroni multiplicity correction. Results are shown for RMSE and R<sup>2</sup> statistics and all pairwise model comparisons</p></caption><graphic xlink:href="13321_2015_94_Fig2_HTML" id="MO2"/></fig><fig id="Fig3"><label>Fig. 3</label><caption><p>Models’ comparison of resampling results for Housing training set (data split 1). Univariate visualization of the resampling distributions of RMSE and R<sup>2</sup> statistics, for the various RRegrs models</p></caption><graphic xlink:href="13321_2015_94_Fig3_HTML" id="MO3"/></fig><fig id="Fig4"><label>Fig. 4</label><caption><p>Test Yobs—Ypred for the five standard data sets best models (10-fold cross-validation). Plots for the observed versus the predicted values and the best model found for each of the five data sets</p></caption><graphic xlink:href="13321_2015_94_Fig4_HTML" id="MO4"/></fig><fig id="Fig5"><label>Fig. 5</label><caption><p>Leverage for Housing best fitted model. Histogram showing the Hat values for the RF fitted model. The<italic> red dashed line</italic> indicates the leverage threshold value (<inline-formula id="IEq44"><alternatives><tex-math id="M15">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\frac{{3{\text{m}}}}{\text{n}}$$\end{document}</tex-math><mml:math id="M16"><mml:mfrac><mml:mrow><mml:mn>3</mml:mn><mml:mtext>m</mml:mtext></mml:mrow><mml:mtext>n</mml:mtext></mml:mfrac></mml:math><inline-graphic xlink:href="13321_2015_94_Article_IEq44.gif"/></alternatives></inline-formula>, where m are the number of model parameters and n the number of observations)</p></caption><graphic xlink:href="13321_2015_94_Fig5_HTML" id="MO5"/></fig></p>
      <p>The best model for the Computer Hardware data set was obtained with the RF method (<inline-formula id="IEq8"><alternatives><tex-math id="M17">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text{R}}_{\text{test}}^{2}$$\end{document}</tex-math><mml:math id="M18"><mml:msubsup><mml:mtext>R</mml:mtext><mml:mrow><mml:mtext>test</mml:mtext></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:math><inline-graphic xlink:href="13321_2015_94_Article_IEq8.gif"/></alternatives></inline-formula> of 0.907) and the worst one using PLS (<inline-formula id="IEq9"><alternatives><tex-math id="M19">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text{R}}_{\text{test}}^{2}$$\end{document}</tex-math><mml:math id="M20"><mml:msubsup><mml:mtext>R</mml:mtext><mml:mrow><mml:mtext>test</mml:mtext></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:math><inline-graphic xlink:href="13321_2015_94_Article_IEq9.gif"/></alternatives></inline-formula> of 0.740). The LM method has <inline-formula id="IEq10"><alternatives><tex-math id="M21">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text{R}}_{\text{test}}^{2}$$\end{document}</tex-math><mml:math id="M22"><mml:msubsup><mml:mtext>R</mml:mtext><mml:mrow><mml:mtext>test</mml:mtext></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:math><inline-graphic xlink:href="13321_2015_94_Article_IEq10.gif"/></alternatives></inline-formula> of 0.822. Models for the Red Wine data set do not produce good values for <inline-formula id="IEq11"><alternatives><tex-math id="M23">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text{R}}_{\text{test}}^{2}$$\end{document}</tex-math><mml:math id="M24"><mml:msubsup><mml:mtext>R</mml:mtext><mml:mrow><mml:mtext>test</mml:mtext></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:math><inline-graphic xlink:href="13321_2015_94_Article_IEq11.gif"/></alternatives></inline-formula> (&gt;0.501) due to the non-continuous values of the output variable. When RRegrs is applied to the Automobile data set, <inline-formula id="IEq12"><alternatives><tex-math id="M25">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text{R}}_{\text{test}}^{2}$$\end{document}</tex-math><mml:math id="M26"><mml:msubsup><mml:mtext>R</mml:mtext><mml:mrow><mml:mtext>test</mml:mtext></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:math><inline-graphic xlink:href="13321_2015_94_Article_IEq12.gif"/></alternatives></inline-formula> values vary from about 0.915 for RF/RF-RFE to 0.714 for SVM-RFE (<inline-formula id="IEq13"><alternatives><tex-math id="M27">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text{R}}_{\text{test}}^{2}$$\end{document}</tex-math><mml:math id="M28"><mml:msubsup><mml:mtext>R</mml:mtext><mml:mrow><mml:mtext>test</mml:mtext></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:math><inline-graphic xlink:href="13321_2015_94_Article_IEq13.gif"/></alternatives></inline-formula> for LM is 0.824).</p>
      <p>If the RRegrs call uses all available CPU cores for the complex methods, one dataset split, one Y-randomizations, and all the regression methods, the following execution times (in seconds) are obtained for the Boston standard dataset (see Table <xref rid="Tab3" ref-type="table">3</xref>). The computer was an Windows 8.1 64bit with i7-4790 CPU (3.60 GHz, 4 cores, 8 logical cores), 16G RAM. The total execution time was 5.43 min (325.64 s).<table-wrap id="Tab3"><label>Table 3</label><caption><p>RRegrs execution time (in seconds) for one split of Boston House dataset</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Method</th><th align="left">Repeated CV</th><th align="left">LOOCV</th></tr></thead><tbody><tr><td align="left">LM</td><td char="." align="char">11.97</td><td align="left">1.78</td></tr><tr><td align="left">GLM</td><td char="." align="char">2.14</td><td align="left">5.48</td></tr><tr><td align="left">PLS</td><td char="." align="char">0.99</td><td align="left">1.40</td></tr><tr><td align="left">Lasso</td><td char="." align="char">1.32</td><td align="left">–</td></tr><tr><td align="left">ENET</td><td char="." align="char">12.70</td><td align="left">45.30</td></tr><tr><td align="left">SVM radial</td><td char="." align="char">4.62</td><td align="left">13.77</td></tr><tr><td align="left">NN</td><td char="." align="char">12.53</td><td align="left">49.97</td></tr><tr><td align="left">RF</td><td char="." align="char">88.89</td><td align="left">–</td></tr><tr><td align="left">RF-RFE</td><td char="." align="char">3.89</td><td align="left">–</td></tr><tr><td align="left">SVM-RFE</td><td char="." align="char">46.36</td><td align="left">–</td></tr></tbody></table></table-wrap></p>
    </sec>
    <sec id="Sec4">
      <title>Use case 1: RRegrs application on protein corona data</title>
      <p>Recent studies have shown that the presence of serum proteins in vitro cell culture systems form a protein adsorption layer (a.k.a. the ‘protein corona’) on the surface of nanoparticles (NPs). This corona is reported to affect the nanoparticle-cell interactions as well as change the cell response [<xref ref-type="bibr" rid="CR47">47</xref>, <xref ref-type="bibr" rid="CR48">48</xref>], and defines the NP’s ‘biological identity’ [<xref ref-type="bibr" rid="CR49">49</xref>]. It thus encodes information about the interface formed between the NP core and the cell surface within a physiological environment.</p>
      <p>This section presents results for proteomics data recently published that characterizes the serum protein corona ‘fingerprint’ formed around a library of 105 distinct surface-modified gold NPs [<xref ref-type="bibr" rid="CR49">49</xref>]. The authors used LC–MS/MS to identify 129 serum proteins which were considered suitable for relative quantification. The relative abundances for each of these proteins on the corona of a nanoparticle formulation defines the serum protein ‘fingerprint’ for that formulation. The authors presented a multivariate regression model that uses the protein corona fingerprint to predict cell association for the gold NPs and found a model predicted cell association with a <inline-formula id="IEq14"><alternatives><tex-math id="M29">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text{R}}_{\text{LOO}}^{2}$$\end{document}</tex-math><mml:math id="M30"><mml:msubsup><mml:mtext>R</mml:mtext><mml:mrow><mml:mtext>LOO</mml:mtext></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:math><inline-graphic xlink:href="13321_2015_94_Article_IEq14.gif"/></alternatives></inline-formula> of 0.81. Specifically, they applied a PLS regression model along with an internal iterative filtering procedure using the Variable Importance to the Projection (VIP) score and jackknife resampling.</p>
      <p>Here we present results on the initial set of 129 × 84 proteins to gold NPs data (21 neutral NPs were excluded from analysis as in Walkey et al. [<xref ref-type="bibr" rid="CR49">49</xref>]), and also on a set of 76 × 84 proteins to gold NPs data. These 76 proteins are selected in [<xref ref-type="bibr" rid="CR49">49</xref>] with VIP ≥ 0.6 threshold. RRegrs was applied with 10 random splits of the data (75 % train and 25 % test) along with 10 Y-randomization runs for the best model. Table <xref rid="Tab4" ref-type="table">4</xref> shows the best model selected by RRegrs, its number of features, the adj.R<sup>2</sup> and the R<sup>2</sup> and RMSE values for the train and test sets, averaged over 10 random splits of the data. Table <xref rid="Tab5" ref-type="table">5</xref> shows the best model found in all data splits, i.e. we compare all methodologies and data splits to find the best R<sub arrange="stack">test</sub><sup arrange="stack">2</sup>. Data are normalized and filtered using the RRegrs near zero variance and correlation filters, for that reason the 129 proteins are filtered to be 99 and the 76 proteins data set are reduced to 60 features.<table-wrap id="Tab4"><label>Table 4</label><caption><p>RRegrs averaged statistics reported for the three use cases, under the 10-fold repeated CVscheme</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Use case</th><th align="left">Best model</th><th align="left">Features no.</th><th align="left">adj.R<sup>2</sup>
</th><th align="left"><inline-formula id="IEq45"><alternatives><tex-math id="M31">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text{R}}_{\text{CV}}^{ 2}$$\end{document}</tex-math><mml:math id="M32"><mml:msubsup><mml:mtext>R</mml:mtext><mml:mrow><mml:mtext>CV</mml:mtext></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:math><inline-graphic xlink:href="13321_2015_94_Article_IEq45.gif"/></alternatives></inline-formula></th><th align="left"><inline-formula id="IEq46"><alternatives><tex-math id="M33">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text{R}}^{ 2}_{\text{test}}$$\end{document}</tex-math><mml:math id="M34"><mml:msubsup><mml:mrow><mml:mtext>R</mml:mtext></mml:mrow><mml:mtext>test</mml:mtext><mml:mn>2</mml:mn></mml:msubsup></mml:math><inline-graphic xlink:href="13321_2015_94_Article_IEq46.gif"/></alternatives></inline-formula></th><th align="left">RMSE<sub>CV</sub>
</th><th align="left">RMSE<sub>test</sub>
</th></tr></thead><tbody><tr><td align="left" colspan="8">UC1: protein corona</td></tr><tr><td align="left"> 129 proteins</td><td align="left">SVRM</td><td char="." align="char">99</td><td char="." align="char">1.02</td><td char="." align="char">0.687</td><td char="." align="char">0.631</td><td char="." align="char">0.558</td><td char="." align="char">0.612</td></tr><tr><td align="left"> 76 proteins</td><td align="left">SVRM</td><td char="." align="char">60</td><td char="." align="char">0.582</td><td char="." align="char">0.777</td><td char="." align="char">0.728</td><td char="." align="char">0.477</td><td char="." align="char">0.538</td></tr><tr><td align="left"> UC2: metal oxides</td><td align="left">ENET</td><td char="." align="char">8.8</td><td char="." align="char">1</td><td char="." align="char">0.933</td><td char="." align="char">0.746</td><td char="." align="char">0.639</td><td char="." align="char">0.639</td></tr><tr><td align="left"> UC3: toxicity data</td><td align="left">SVRM</td><td char="." align="char">8</td><td char="." align="char">0.7</td><td char="." align="char">0.556</td><td char="." align="char">0.537</td><td char="." align="char">0.68</td><td char="." align="char">0.67</td></tr></tbody></table><table-wrap-foot><p>Averaged values are reported across the ten different data splits</p></table-wrap-foot></table-wrap><table-wrap id="Tab5"><label>Table 5</label><caption><p>RRegrs best model statistics reported for the three use cases. Both LOO and CV values are considered</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Use case</th><th align="left">Best model</th><th align="left">Data split</th><th align="left">Features no.</th><th align="left">Validation type</th><th align="left">adj.R<sup>2</sup>
</th><th align="left"><inline-formula id="IEq47"><alternatives><tex-math id="M35">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text{R}}_{\text{CV/LOO}}^{ 2}$$\end{document}</tex-math><mml:math id="M36"><mml:msubsup><mml:mtext>R</mml:mtext><mml:mrow><mml:mtext>CV/LOO</mml:mtext></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:math><inline-graphic xlink:href="13321_2015_94_Article_IEq47.gif"/></alternatives></inline-formula></th><th align="left"><inline-formula id="IEq48"><alternatives><tex-math id="M37">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text{R}}_{\text{test}}^{ 2}$$\end{document}</tex-math><mml:math id="M38"><mml:msubsup><mml:mtext>R</mml:mtext><mml:mrow><mml:mtext>test</mml:mtext></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:math><inline-graphic xlink:href="13321_2015_94_Article_IEq48.gif"/></alternatives></inline-formula></th><th align="left">RMSE<sub>CV/LOO</sub>
</th><th align="left">RMSE<sub>test</sub>
</th></tr></thead><tbody><tr><td align="left" colspan="10">UC1: protein corona</td></tr><tr><td align="left"> 129 proteins</td><td align="left">SVRM</td><td char="." align="char">5</td><td char="." align="char">99</td><td align="left">LOO, CV</td><td char="." align="char">1.03</td><td align="left">0.644/0.61</td><td char="." align="char">0.844</td><td align="left">0.618/0.643</td><td char="." align="char">0.357</td></tr><tr><td align="left"> 76 proteins</td><td align="left">SVRM</td><td char="." align="char">5</td><td char="." align="char">60</td><td align="left">LOO, CV</td><td char="." align="char">0.407</td><td align="left">0.767/0.741</td><td char="." align="char">0.89</td><td align="left">0.525/0.527</td><td char="." align="char">0.296</td></tr><tr><td align="left">UC2: metal oxides</td><td align="left">ENET</td><td char="." align="char">8</td><td char="." align="char">8</td><td align="left">LOO</td><td char="." align="char">0.808</td><td align="left">0.7</td><td char="." align="char">0.998</td><td align="left">0.588</td><td char="." align="char">0.246</td></tr><tr><td align="left">UC3: toxicity data</td><td align="left">SVRM</td><td char="." align="char">2</td><td char="." align="char">8</td><td align="left">LOO</td><td char="." align="char">0.685</td><td align="left">0.506</td><td char="." align="char">0.657</td><td align="left">0.705</td><td char="." align="char">0.609</td></tr></tbody></table></table-wrap></p>
      <p>For the data set with 129 proteins, the best model is an SVRM model with <inline-formula id="IEq15"><alternatives><tex-math id="M39">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text{R}}_{\text{test}}^{2}$$\end{document}</tex-math><mml:math id="M40"><mml:msubsup><mml:mtext>R</mml:mtext><mml:mrow><mml:mtext>test</mml:mtext></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:math><inline-graphic xlink:href="13321_2015_94_Article_IEq15.gif"/></alternatives></inline-formula> = 0.631. CV results on the training set can be seen in Fig. <xref rid="Fig6" ref-type="fig">6</xref>, where we can observe that the LM and GLM models are not suitable for the protein corona data, whereas the remaining methodologies perform similarly. It can be observed in Table <xref rid="Tab5" ref-type="table">5</xref> that the highest value reported was <inline-formula id="IEq16"><alternatives><tex-math id="M41">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text{R}}_{\text{test}}^{2}$$\end{document}</tex-math><mml:math id="M42"><mml:msubsup><mml:mtext>R</mml:mtext><mml:mrow><mml:mtext>test</mml:mtext></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:math><inline-graphic xlink:href="13321_2015_94_Article_IEq16.gif"/></alternatives></inline-formula> = 0.844 for individual split nine of the data set.<fig id="Fig6"><label>Fig. 6</label><caption><p>Models’ differences for protein corona training set (data split 5). Differences for R<sup>2</sup> and RMSE values among the applied models are presented. The average performance with two-sided confidence limits are plotted as derived by the Student t-test with Bonferroni multiplicity correction. We can observe that LM and GLM models are not fitting the data very well (large RMSE values)</p></caption><graphic xlink:href="13321_2015_94_Fig6_HTML" id="MO6"/></fig></p>
      <p>When we study the set with 76 proteins, we find that the best model is an SVRM model with averaged <inline-formula id="IEq17"><alternatives><tex-math id="M43">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text{R}}_{\text{test}}^{2}$$\end{document}</tex-math><mml:math id="M44"><mml:msubsup><mml:mtext>R</mml:mtext><mml:mrow><mml:mtext>test</mml:mtext></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:math><inline-graphic xlink:href="13321_2015_94_Article_IEq17.gif"/></alternatives></inline-formula> = 0.728, whereas the best individual split value is <inline-formula id="IEq18"><alternatives><tex-math id="M45">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text{R}}_{\text{test}}^{2}$$\end{document}</tex-math><mml:math id="M46"><mml:msubsup><mml:mtext>R</mml:mtext><mml:mrow><mml:mtext>test</mml:mtext></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:math><inline-graphic xlink:href="13321_2015_94_Article_IEq18.gif"/></alternatives></inline-formula> = 0.89. CV results on the training set are shown in Fig. <xref rid="Fig7" ref-type="fig">7</xref>. The corresponding RRegrs results for the PLS model are <inline-formula id="IEq19"><alternatives><tex-math id="M47">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text{R}}_{\text{test}}^{2}$$\end{document}</tex-math><mml:math id="M48"><mml:msubsup><mml:mtext>R</mml:mtext><mml:mrow><mml:mtext>test</mml:mtext></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:math><inline-graphic xlink:href="13321_2015_94_Article_IEq19.gif"/></alternatives></inline-formula> = 0.7 (averaged over 10 data splits), whereas the highest values are reported for individual split five <inline-formula id="IEq20"><alternatives><tex-math id="M49">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text{R}}_{\text{test}}^{2}$$\end{document}</tex-math><mml:math id="M50"><mml:msubsup><mml:mtext>R</mml:mtext><mml:mrow><mml:mtext>test</mml:mtext></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:math><inline-graphic xlink:href="13321_2015_94_Article_IEq20.gif"/></alternatives></inline-formula> = 0.885 (for repeated CV) and <inline-formula id="IEq21"><alternatives><tex-math id="M51">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text{R}}_{\text{test}}^{2}$$\end{document}</tex-math><mml:math id="M52"><mml:msubsup><mml:mtext>R</mml:mtext><mml:mrow><mml:mtext>test</mml:mtext></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:math><inline-graphic xlink:href="13321_2015_94_Article_IEq21.gif"/></alternatives></inline-formula> = 0.873 (for LOO). Although the last number cannot be directly compared to <inline-formula id="IEq22"><alternatives><tex-math id="M53">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text{R}}_{\text{LOO}}^{2}$$\end{document}</tex-math><mml:math id="M54"><mml:msubsup><mml:mtext>R</mml:mtext><mml:mrow><mml:mtext>LOO</mml:mtext></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:math><inline-graphic xlink:href="13321_2015_94_Article_IEq22.gif"/></alternatives></inline-formula> = 0.81 reported by the authors, it gives an indication of how our PLS implementation performs for the specific data set.<fig id="Fig7"><label>Fig. 7</label><caption><p>Models’ differences for protein corona optimal training set (data split 5). Differences for R<sup>2</sup> and RMSE values among the applied models are presented for the trimmed corona data set (76 proteins). The average performance with two-sided confidence limits are plotted as derived by the Student t-test with Bonferroni multiplicity correction</p></caption><graphic xlink:href="13321_2015_94_Fig7_HTML" id="MO7"/></fig></p>
    </sec>
    <sec id="Sec5">
      <title>Use case 2: RRegrs application on metal oxides data set</title>
      <p>The authors of [<xref ref-type="bibr" rid="CR50">50</xref>] combined experimental and theoretical measurements to develop a nano-QSAR model that describes the toxicity of eighteen nano-metal oxides (MeOx) to the human keratinocyte (HaCaT) cell line, which is a common in vitro model for keratinocyte response during toxic dermal exposure. The study was aimed at exposing and explaining the differences in modes of toxic action of metal oxide nanoparticles between the eukaryotic system and the prokaryotic system (<italic>E. coli</italic>).</p>
      <p>They calculated 32 parameters that quantitatively describe the variability of the nanoparticles’ structure, called nano-descriptors, which included quantum-mechanical descriptors derived from quantum-chemical calculations, and image descriptors derived from transmission electron microscopy (TEM) images. Some of the descriptors included are: particle size and size distribution, agglomeration state, particle shape, crystal structure, chemical composition, surface area, surface chemistry, surface charge, electronic properties (reactivity, conductivity, interaction energies, etc.), and porosity. Additionally, the LC<sub>50</sub> was calculated from experimental data for all MeOx NPs. This is the concentration that caused a 50 % reduction of the cells after 24 h exposure, whereas the −log(LC<sub>50</sub>) values were used in modelling, as the dependent variable t be predicted.</p>
      <p>The authors applied a Genetic Algorithm (GA) to independently select the most efficient combination of the molecular descriptors which were then analyzed using multiple linear regression. They found that two descriptors were sufficient to predict NPs toxicity with high statistical significance, namely <inline-formula id="IEq23"><alternatives><tex-math id="M55">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\Delta {\text{H}}_{\text{c}}^{\text{f}}$$\end{document}</tex-math><mml:math id="M56"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:msubsup><mml:mtext>H</mml:mtext><mml:mrow><mml:mtext>c</mml:mtext></mml:mrow><mml:mtext>f</mml:mtext></mml:msubsup></mml:mrow></mml:math><inline-graphic xlink:href="13321_2015_94_Article_IEq23.gif"/></alternatives></inline-formula> descriptor, which is the enthalpy of formation of metal oxide nanocluster representing a fragment of the surface and, χ<sup>c</sup> descriptor, which is the Mulliken’s electronegativity of the cluster. The reported values are: R<sup>2</sup> = 0.93 (RMSE = 0.12), <inline-formula id="IEq24"><alternatives><tex-math id="M57">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text{R}}_{\text{LOO}}^{2}$$\end{document}</tex-math><mml:math id="M58"><mml:msubsup><mml:mtext>R</mml:mtext><mml:mrow><mml:mtext>LOO</mml:mtext></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:math><inline-graphic xlink:href="13321_2015_94_Article_IEq24.gif"/></alternatives></inline-formula> = 0.86 (RMSE<sub>LOO</sub> = 0.16), <inline-formula id="IEq25"><alternatives><tex-math id="M59">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text{R}}_{\text{test}}^{2}$$\end{document}</tex-math><mml:math id="M60"><mml:msubsup><mml:mtext>R</mml:mtext><mml:mrow><mml:mtext>test</mml:mtext></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:math><inline-graphic xlink:href="13321_2015_94_Article_IEq25.gif"/></alternatives></inline-formula> = 0.83 (RMSE<sub>test</sub> = 0.13). Note that R<sup>2,</sup> here and in other cases, refers to the coefficient of determination for fitting the model to the training data.</p>
      <p>Ten random splits of the data were performed (75 % train and 25 % test) along with ten Y-randomization runs for the best model. Tables <xref rid="Tab4" ref-type="table">4</xref> and <xref rid="Tab5" ref-type="table">5</xref> show RRegrs results for the initial set of 32 parameters to the eighteen MeOx’s, averaged or non-averaged values across the ten data splits, respectively. Because of the restricted number of samples and descriptors RRegrs was applied without filtering options, whereas data were normalized, as in [<xref ref-type="bibr" rid="CR50">50</xref>]. The best model was selected between those that perform feature selection, i.e. GLM, LASSO, SVM-RFE, RF-RFE, ENET. As can be seen from the tables, the best performance model and the best averaged model is ENET in this case, keeping on average 8.8 variables from the data including the two important variables (∆H<sup>c</sup>, χ<sup>c</sup>) selected in the original publication. The ENET averaged statistics for 10 splits of the data are <inline-formula id="IEq26"><alternatives><tex-math id="M61">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text{R}}_{\text{test}}^{2}$$\end{document}</tex-math><mml:math id="M62"><mml:msubsup><mml:mtext>R</mml:mtext><mml:mrow><mml:mtext>test</mml:mtext></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:math><inline-graphic xlink:href="13321_2015_94_Article_IEq26.gif"/></alternatives></inline-formula> = 0.746, <inline-formula id="IEq27"><alternatives><tex-math id="M63">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text{R}}_{\text{CV}}^{2}$$\end{document}</tex-math><mml:math id="M64"><mml:msubsup><mml:mtext>R</mml:mtext><mml:mrow><mml:mtext>CV</mml:mtext></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:math><inline-graphic xlink:href="13321_2015_94_Article_IEq27.gif"/></alternatives></inline-formula> = 0.933, which are very similar to the values reported by the authors. The best individual split value is equal to <inline-formula id="IEq28"><alternatives><tex-math id="M65">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text{R}}_{\text{test}}^{2}$$\end{document}</tex-math><mml:math id="M66"><mml:msubsup><mml:mtext>R</mml:mtext><mml:mrow><mml:mtext>test</mml:mtext></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:math><inline-graphic xlink:href="13321_2015_94_Article_IEq28.gif"/></alternatives></inline-formula> = 0.998 for ENET model with eight variables including the final two suggested by the authors (LOO at the eighth split of the data). The boxplots in Fig. <xref rid="Fig8" ref-type="fig">8</xref> show the resampling values of RMSE<sub>CV</sub> and <inline-formula id="IEq29"><alternatives><tex-math id="M67">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text{R}}_{\text{CV}}^{2}$$\end{document}</tex-math><mml:math id="M68"><mml:msubsup><mml:mtext>R</mml:mtext><mml:mrow><mml:mtext>CV</mml:mtext></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:math><inline-graphic xlink:href="13321_2015_94_Article_IEq29.gif"/></alternatives></inline-formula> values in the training set for split eight, where only methodologies with the same resampling scheme are included in the graph. Figure <xref rid="Fig8" ref-type="fig">8</xref> also includes the fit of the selected model ENET for the same data split.<fig id="Fig8"><label>Fig. 8</label><caption><p>Results on MeOx data set (data split 8). For the three selected methodologies we show the resampling distributions for the RMSE and R<sup>2</sup> statistics. On the right hand-side, we show the observed versus the predicted values for the ENET model in the training set</p></caption><graphic xlink:href="13321_2015_94_Fig8_HTML" id="MO8"/></fig></p>
    </sec>
    <sec id="Sec6">
      <title>Use case 3: RRegrs application on aquatic toxicity data set</title>
      <p>The authors of [<xref ref-type="bibr" rid="CR51">51</xref>] developed a QSAR model based on 546 organic molecules, to predict acute aquatic toxicity towards Daphnia magna, which is the organism preferred for short-term aquatic toxicity testing according to REACH [<xref ref-type="bibr" rid="CR52">52</xref>]. Ad hoc-designed workflows were used for data curation and filtering, as well as for the extraction of LC<sub>50</sub> data, which in this case is defined to be the concentration that causes death in 50 % of test Daphnia magna over a test duration of 48 h. For modelling purposes the −log(LC<sub>50</sub>) values were considered as the dependent variable to be predicted. Other experimental data on aquatic toxicity were retrieved from three databases and available scientific publications, as well as one-dimensional (1-D) and2-D molecular descriptors implemented with DRAGON software [<xref ref-type="bibr" rid="CR51">51</xref>], resulting in a total of 2, 187 molecular descriptors.</p>
      <p>A modified k-Nearest Neighbour (kNN) strategy coupled with GA algorithms was used to select the relevant molecular descriptors. The final data set comprised of 546 organic molecules and a set of 201 descriptors. The GA-kNN strategy was implemented with a threshold on the average Mahalanobis distance from the k nearest neighbours, so that only molecules satisfying the threshold criterion were predicted. Particularly, predictions for molecules with an average distance greater than 1.26 from their three neighbours, were considered to be outside of the applicability domain. The training molecules exceeding the threshold did not contribute to the model’s statistics, but were not removed from the data set. The final model showed good performance when the average distance threshold was applied, namely <inline-formula id="IEq30"><alternatives><tex-math id="M69">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text{R}}_{\text{CV}}^{2}$$\end{document}</tex-math><mml:math id="M70"><mml:msubsup><mml:mtext>R</mml:mtext><mml:mrow><mml:mtext>CV</mml:mtext></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:math><inline-graphic xlink:href="13321_2015_94_Article_IEq30.gif"/></alternatives></inline-formula> = <inline-formula id="IEq31"><alternatives><tex-math id="M71">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text{R}}_{\text{test}}^{2}$$\end{document}</tex-math><mml:math id="M72"><mml:msubsup><mml:mtext>R</mml:mtext><mml:mrow><mml:mtext>test</mml:mtext></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:math><inline-graphic xlink:href="13321_2015_94_Article_IEq31.gif"/></alternatives></inline-formula> = 0.78 (5-fold CV), R<sup>2</sup> = 0.72. The model selected eight molecular descriptors that encoded information about lipophilicity, the formation of H-bonds, polar surface area, polarisability, nucleophilicity and electrophilicity. When no distance threshold is applied, the corresponding values are: R<sup>2</sup> = 0.60, <inline-formula id="IEq32"><alternatives><tex-math id="M73">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text{R}}_{\text{CV}}^{2}$$\end{document}</tex-math><mml:math id="M74"><mml:msubsup><mml:mtext>R</mml:mtext><mml:mrow><mml:mtext>CV</mml:mtext></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:math><inline-graphic xlink:href="13321_2015_94_Article_IEq32.gif"/></alternatives></inline-formula> = 0.61, <inline-formula id="IEq33"><alternatives><tex-math id="M75">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text{R}}_{\text{test}}^{2}$$\end{document}</tex-math><mml:math id="M76"><mml:msubsup><mml:mtext>R</mml:mtext><mml:mrow><mml:mtext>test</mml:mtext></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:math><inline-graphic xlink:href="13321_2015_94_Article_IEq33.gif"/></alternatives></inline-formula> = 0.43.</p>
      <p>Tables <xref rid="Tab4" ref-type="table">4</xref> and <xref rid="Tab5" ref-type="table">5</xref> show the results for the final set of eight descriptors for 546 organic molecules: the averaged values across data splits and the best model statistics for all data splits are presented. RRegrs is applied using normalization and filtering options. Ten random splits of the data were performed (75 % train and 25 % test) along with ten Y-randomization runs for the best model. As can be seen from the tables the best performance model and the best averaged model is SVRM in this case, keeping all 8 descriptors in the data. The SVRM averaged statistics for ten splits of the data are <inline-formula id="IEq34"><alternatives><tex-math id="M77">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text{R}}_{\text{CV}}^{2}$$\end{document}</tex-math><mml:math id="M78"><mml:msubsup><mml:mtext>R</mml:mtext><mml:mrow><mml:mtext>CV</mml:mtext></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:math><inline-graphic xlink:href="13321_2015_94_Article_IEq34.gif"/></alternatives></inline-formula> = 0.556 (10-fold CV), <inline-formula id="IEq35"><alternatives><tex-math id="M79">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text{R}}_{\text{test}}^{2}$$\end{document}</tex-math><mml:math id="M80"><mml:msubsup><mml:mtext>R</mml:mtext><mml:mrow><mml:mtext>test</mml:mtext></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:math><inline-graphic xlink:href="13321_2015_94_Article_IEq35.gif"/></alternatives></inline-formula> = 0.537, which are close to the ones reported by the authors when the distance threshold is not applied. The adjusted R<sup>2</sup> = 0.7, exceeding the 0.6 value reported without the distance threshold application, and still approaching the 0.78 value when the distance threshold was applied. The best individual split value is reported to be <inline-formula id="IEq36"><alternatives><tex-math id="M81">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text{R}}_{\text{test}}^{2}$$\end{document}</tex-math><mml:math id="M82"><mml:msubsup><mml:mtext>R</mml:mtext><mml:mrow><mml:mtext>test</mml:mtext></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:math><inline-graphic xlink:href="13321_2015_94_Article_IEq36.gif"/></alternatives></inline-formula> = 0.657 for SVRM model with eight variables (LOO at the second split of the data). Figure <xref rid="Fig9" ref-type="fig">9</xref> shows the differences between the various models in terms of <inline-formula id="IEq37"><alternatives><tex-math id="M83">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text{R}}_{\text{CV}}^{2}$$\end{document}</tex-math><mml:math id="M84"><mml:msubsup><mml:mtext>R</mml:mtext><mml:mrow><mml:mtext>CV</mml:mtext></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:math><inline-graphic xlink:href="13321_2015_94_Article_IEq37.gif"/></alternatives></inline-formula> and RMSE<sub>CV</sub> values in the training set of the second data split, i.e. the train data where the highest <inline-formula id="IEq38"><alternatives><tex-math id="M85">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text{R}}_{\text{test}}^{2}$$\end{document}</tex-math><mml:math id="M86"><mml:msubsup><mml:mtext>R</mml:mtext><mml:mrow><mml:mtext>test</mml:mtext></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:math><inline-graphic xlink:href="13321_2015_94_Article_IEq38.gif"/></alternatives></inline-formula> was observed. We can observe that the PLS model differs from all others, having the worst performance, whilst LM, GLM, LASSO, and ENET models have very similar performances.<fig id="Fig9"><label>Fig. 9</label><caption><p>Models’ differences for toxicity training set (data split 2). Differences for R<sup>2</sup> and RMSE values among the applied models are presented. The average performance with two-sided confidence limits are plotted as derived by the Student t-test with Bonferroni multiplicity correction. We can observe small differences for LM, LASSO, ENET models, whereas the performance of the best model, SVRM, appears to be close to that of RF and NN models</p></caption><graphic xlink:href="13321_2015_94_Fig9_HTML" id="MO9"/></fig></p>
    </sec>
  </sec>
  <sec id="Sec7" sec-type="conclusion">
    <title>Conclusions</title>
    <p>This paper introduces RRegrs as a new computer-aided model selection framework using a single R function call. The aim of RRegrs is to automatically obtain the best regression model given the data set, and the set of all ten regression models available, after an extensive search of the model space. A fully validated procedure is suggested where data are split in training and test sets, ten times by default, capturing any variability or inconsistency in the data. The best model is then found across different data splits and cross-validation schemes, based on the averaged data splits statistics. RRegrs produces easily accessible summary files that provide an overview of model details and allows methodology comparisons using the same statistics, enabling QSAR model selection. These direct comparisons are built on top of the caret package, and in that respect provide a useful flexibility for all users. However, use of this package does not require advanced knowledge of R, while, on the other hand, experienced R users can easily modify and extend the package with additional algorithms of choice. The single function call makes it easy to integrate into larger QSAR and in silico molecular screening studies. The new tool was tested with five standard data sets from several domains and three use cases originating from cheminformatics and nanotoxicity, showing good performance in all cases. RRegrs is open source and available from <ext-link ext-link-type="uri" xlink:href="https://www.github.com/enanomapper/RRegrs">https://www.github.com/enanomapper/RRegrs</ext-link> (doi:10.5281/zenodo.21946).</p>
  </sec>
  <sec id="Sec8" sec-type="materials|methods">
    <title>Methods</title>
    <sec id="Sec9">
      <title>Regression methods in RRegrs</title>
      <p>The RRegrs tool is using ten different linear and non-linear regression models briefly described in this section, to explore the model space. The most basic model in this package is the LM model [<xref ref-type="bibr" rid="CR33">33</xref>]. Variable selection could improve the result of prediction in regression models. For that reason we have included a generalized linear model, denoted by GLM, which selects variables that minimize the AIC score. LASSO and ENET are also penalizing the number of variables via an embedded minimization process [<xref ref-type="bibr" rid="CR27">27</xref>, <xref ref-type="bibr" rid="CR28">28</xref>].</p>
      <p>Apart from the standard regression methodologies included in RRegrs, other methods that focus on specific characteristics of the data are included. PLS uses linear projections of input and output sets, which is a useful strategy when many of the inputs are correlated. PLS coefficient optimization algorithm improves previous regression coefficient algorithms because the search path is directed to high variance and high correlations paths [<xref ref-type="bibr" rid="CR26">26</xref>]. The SVMR algorithm attempts to find the hyperplane that separates the positive and negative samples, practically allowing a non-linear solution to a regression problem by transforming the data to a hyperdimensional feature space using the kernel functions [<xref ref-type="bibr" rid="CR53">53</xref>, <xref ref-type="bibr" rid="CR54">54</xref>]. SVMR in RRegrs uses the radial function or Gaussian function. RRegrs package also allows the use of a support vector regression model where the w<sup>2</sup> (the square of SVM hyperplane weight vector) measures the importance of each feature [<xref ref-type="bibr" rid="CR29">29</xref>].</p>
      <p>RRegrs includes two additional learning algorithms, namely NN and ensemble RF. NN is usually defined as a network of a large number of connected neurons (simple processors), which produce good results with imprecise and complicated data [<xref ref-type="bibr" rid="CR30">30</xref>]. RF is a bagging method constructing decision trees based on the random subspace method [<xref ref-type="bibr" rid="CR31">31</xref>].</p>
      <p>Finally, we have included two of the best performing methodologies with extra feature selection characteristics. Particularly, because the SVM and RF methods can be time-consuming, we have considered their implementation with random feature elimination (RFE), a feature selection method also introduced in caret where less important features are sequentially removed from the model until optimal performance is reached [<xref ref-type="bibr" rid="CR32">32</xref>]. The two methods are here labeled as RF-RFE and SVM-RFE. Further details for the functions’ main parameters are available in the online tutorial of the RRegrs package.</p>
    </sec>
    <sec id="Sec10">
      <title>Model optimization</title>
      <p>Two CV schemes are employed within RRegrs, namely 10-fold repeated CV and LOO CV. In the case of repeated CV, we run ten repeats of 10-fold CV for all models except SVM-RFE (3-folds, one repeat) and RF-RFE (5-folds, one repeat), which are particularly time-consuming methods. The procedure followed by caret and also introduced in RRegrs tool, randomly splits the data in K distinct blocks of roughly equal size (K = 10, 3, 5 depending on the method). Each block of data is left out sequentially, and a model is fit to the remaining of the data; this model is used to predict the held out block. The process is repeated where for each repetition a random proportion of the data are used to train the model (default value is 0.75) while the remainder is used for testing the models. Average performance across the number of repeats are reported: <inline-formula id="IEq39"><alternatives><tex-math id="M87">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text{R}}_{\text{test}}^{2}$$\end{document}</tex-math><mml:math id="M88"><mml:msubsup><mml:mtext>R</mml:mtext><mml:mrow><mml:mtext>test</mml:mtext></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:math><inline-graphic xlink:href="13321_2015_94_Article_IEq39.gif"/></alternatives></inline-formula>, RMSE<sub>test,</sub>, <inline-formula id="IEq40"><alternatives><tex-math id="M89">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text{R}}_{\text{CV}}^{2}$$\end{document}</tex-math><mml:math id="M90"><mml:msubsup><mml:mtext>R</mml:mtext><mml:mrow><mml:mtext>CV</mml:mtext></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:math><inline-graphic xlink:href="13321_2015_94_Article_IEq40.gif"/></alternatives></inline-formula>, <inline-formula id="IEq41"><alternatives><tex-math id="M91">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text{R}}_{\text{LOO}}^{2}$$\end{document}</tex-math><mml:math id="M92"><mml:msubsup><mml:mtext>R</mml:mtext><mml:mrow><mml:mtext>LOO</mml:mtext></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:math><inline-graphic xlink:href="13321_2015_94_Article_IEq41.gif"/></alternatives></inline-formula>, RM SE<sub>C V</sub>, RM SE<sub>LOO</sub>. The best model is selected based on the averaged R<sub arrange="stack">test</sub><sup arrange="stack">2</sup> value; if multiple models only differ by ≤0.005 from the best <inline-formula id="IEq42"><alternatives><tex-math id="M93">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text{R}}_{\text{test}}^{2}$$\end{document}</tex-math><mml:math id="M94"><mml:msubsup><mml:mtext>R</mml:mtext><mml:mrow><mml:mtext>test</mml:mtext></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:math><inline-graphic xlink:href="13321_2015_94_Article_IEq42.gif"/></alternatives></inline-formula>value, the model with the lowest RMSE<sub>test</sub> statistic is selected.</p>
      <p>In order to further validate RRegrs test results, Y-randomization is applied to the best model found. For the last data split and the best model found, RRegrs performs Y-randomization for the 10-fold repeated CV scheme, and compares <inline-formula id="IEq43"><alternatives><tex-math id="M95">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text{R}}_{\text{test}}^{2}$$\end{document}</tex-math><mml:math id="M96"><mml:msubsup><mml:mtext>R</mml:mtext><mml:mrow><mml:mtext>test</mml:mtext></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:math><inline-graphic xlink:href="13321_2015_94_Article_IEq43.gif"/></alternatives></inline-formula> values to the best model corresponding value.</p>
    </sec>
    <sec id="Sec11">
      <title>RRegrs tested data sets</title>
      <p>RRegrs has been used to find the best regression models for eight data sets: three from nano- and cheminformatics (use cases), and five standard data sets from different fields. The standard data sets have been downloaded from UC Irvine machine learning repository [<xref ref-type="bibr" rid="CR35">35</xref>]: housing [<xref ref-type="bibr" rid="CR36">36</xref>], computer hardware, wine quality [<xref ref-type="bibr" rid="CR37">37</xref>], automobile [<xref ref-type="bibr" rid="CR38">38</xref>] and Parkinsons telemonitoring [<xref ref-type="bibr" rid="CR39">39</xref>] data sets. The non-numeric columns have been eliminated, whereas the first column is the dependent variable (output of the model). The number of initial features/cases are the following: 13/506 for Housing data set, 6/209 for Computer Hardware data set, 11/1, 599 for Red Wine Quality data set, 14/195 for Automobile data set, and 19/5, 875 for Parkinson telemonitoring data set. The use case data sets were derived from their original publications; the initial number of features and cases are the following: the protein corona data set [<xref ref-type="bibr" rid="CR49">49</xref>] has 129 features and 84 cases, the metal oxide data set [<xref ref-type="bibr" rid="CR50">50</xref>] has 32 features and 18 cases and the toxicity data set [<xref ref-type="bibr" rid="CR51">51</xref>] contains 8 features, and 546 cases.</p>
    </sec>
    <sec id="Sec12">
      <title>RRegrs call in R</title>
      <p>The main function of RRegrs (also called RRegrs) permits the call of the entire RRegrs methodology in a single line. All details about functions’ main parameters are given in the R package documentation. All these parameters have default values. The default values imply a default location for the output files, execution of all modelling steps (removal of NA, and near zero variance features, and of correlated features), normalization of the data set, ten splits, ten Y-randomization steps, and running of all ten regression methods. The user can alter any step or parameter of the RRegrs methodology.</p>
      <p>The following examples show simple calls of the RRegrs() function using a specific dataset file entitled ”MyDataSet.csv” that it should be provided by the user:</p>
      <p>
        <graphic xlink:href="13321_2015_94_Figb_HTML.gif" id="MO101"/>
      </p>
      <p>The output variable RRegrsResults is a complex object which contains the object of the fitted models and the main statistics for each regression model. Details about each function are presented into the tutorial of the RRegrs package.</p>
      <p>The following example could be used to test the RRegrs package using a dataset file from RRegrs GitHub URL:</p>
      <p>
        <graphic xlink:href="13321_2015_94_Figc_HTML.gif" id="MO102"/>
      </p>
    </sec>
    <sec id="Sec13">
      <title>Availability and requirements</title>
      <p>
        <list list-type="bullet">
          <list-item>
            <p>Project name: RRegrs</p>
          </list-item>
          <list-item>
            <p>Project home page: RRegrs</p>
          </list-item>
          <list-item>
            <p>Operating system(s): Platform-independent</p>
          </list-item>
          <list-item>
            <p>Programming language: R programming language</p>
          </list-item>
          <list-item>
            <p>Other requirements: R 3.1.0 or higher</p>
          </list-item>
          <list-item>
            <p>License: NewBSD or MIT</p>
          </list-item>
          <list-item>
            <p>Any restrictions to use by non-academics: none other than those defined by the license</p>
          </list-item>
        </list>
      </p>
    </sec>
  </sec>
</body>
<back>
  <glossary>
    <title>Abbreviations</title>
    <def-list>
      <def-item>
        <term>RRegrs</term>
        <def>
          <p>R regressions (package)</p>
        </def>
      </def-item>
      <def-item>
        <term>QSAR</term>
        <def>
          <p>quantitative structure-activity relationship</p>
        </def>
      </def-item>
      <def-item>
        <term>R<sup>2</sup></term>
        <def>
          <p>R-squared</p>
        </def>
      </def-item>
      <def-item>
        <term>RMSE</term>
        <def>
          <p>root-mean-square error</p>
        </def>
      </def-item>
      <def-item>
        <term>AIC</term>
        <def>
          <p>akaike information criterion</p>
        </def>
      </def-item>
      <def-item>
        <term>LM</term>
        <def>
          <p>linear multi-regression</p>
        </def>
      </def-item>
      <def-item>
        <term>GLM</term>
        <def>
          <p>generalized linear model with stepwise feature selection</p>
        </def>
      </def-item>
      <def-item>
        <term>PLS</term>
        <def>
          <p>partial least squares regression</p>
        </def>
      </def-item>
      <def-item>
        <term>LASSO</term>
        <def>
          <p>Lasso regression</p>
        </def>
      </def-item>
      <def-item>
        <term>ENET</term>
        <def>
          <p>elastic net regression</p>
        </def>
      </def-item>
      <def-item>
        <term>SVRM</term>
        <def>
          <p>support vector machine using radial functions</p>
        </def>
      </def-item>
      <def-item>
        <term>NN</term>
        <def>
          <p>neural networks regression</p>
        </def>
      </def-item>
      <def-item>
        <term>RF</term>
        <def>
          <p>random forest</p>
        </def>
      </def-item>
      <def-item>
        <term>RF-RFE</term>
        <def>
          <p>random forest recursive feature elimination</p>
        </def>
      </def-item>
      <def-item>
        <term>SVM-RFE</term>
        <def>
          <p>support vector machines recursive feature elimination</p>
        </def>
      </def-item>
      <def-item>
        <term>CSV</term>
        <def>
          <p>comma-separated values file format</p>
        </def>
      </def-item>
      <def-item>
        <term>PDF</term>
        <def>
          <p>portable document format of files</p>
        </def>
      </def-item>
      <def-item>
        <term>PNG</term>
        <def>
          <p>portable network graphics file format</p>
        </def>
      </def-item>
      <def-item>
        <term>NP</term>
        <def>
          <p>nanoparticle</p>
        </def>
      </def-item>
    </def-list>
  </glossary>
  <fn-group>
    <fn>
      <p>Georgia Tsiliki and Cristian R. Munteanu contributed equally to this work</p>
    </fn>
  </fn-group>
  <ack>
    <title>Authors’ contributions</title>
    <p>GT and CRM equally contributed in the conceptual framework, implementation of the framework and writing the paper, supplementary information, and R manual files. JAS and CFL contributed in implementing ENET, RF, SVMRFE, RFRFE methods, writing the corresponding supporting information, and R manual files. HS and ELW contributed in the conceptual framework and writing of the paper. ELW built and maintains the RRegrs R package. All authors read and approved the final manuscript.</p>
    <sec id="d30e2842">
      <title>Acknowledgements</title>
      <p>The eNanoMapper project is funded by the European Union’s Seventh Framework Programme for research, technological development and demonstration (FP7-NMP-2013-SMALL-7) under grant agreement no 604134. The authors acknowledge the support by the Galician Network of Drugs R+D REGID (Xunta de Galicia R2014/025) and by “Collaborative Project on Medical Informatics (CIMED)” P I 13/00280 funded by the Carlos III Health Institute from the Spanish National plan for Scientific and Technical Research and Innovation 2013–2016 and the European Regional Development Funds (FEDER).</p>
    </sec>
    <sec id="d30e2847">
      <title>Compliance with ethical guidelines</title>
      <p><bold>Competing interests</bold> The authors declare that they have no competing interests.</p>
    </sec>
  </ack>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <label>1.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hall</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Frank</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Holmes</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Pfahringer</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Reutemann</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Witten</surname>
            <given-names>IH</given-names>
          </name>
        </person-group>
        <article-title>The WEKA data mining software: an update. SIGKDD Explor</article-title>
        <source>Newsl</source>
        <year>2009</year>
        <volume>11</volume>
        <issue>1</issue>
        <fpage>10</fpage>
        <lpage>18</lpage>
      </element-citation>
    </ref>
    <ref id="CR2">
      <label>2.</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Hofmann</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Klinkenberg</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <source>RapidMiner: Data mining use cases and business analytics applications</source>
        <year>2013</year>
        <publisher-loc>Boca Raton</publisher-loc>
        <publisher-name>Chapman and Hall, CRC Press</publisher-name>
      </element-citation>
    </ref>
    <ref id="CR3">
      <label>3.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Alcal´a-Fdez</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>S´anchez</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Garc´ıa</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>del Jesu´s</surname>
            <given-names>MJ</given-names>
          </name>
          <name>
            <surname>Ventura</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Garrell</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Otero</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Romero</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Bacardit</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Rivas</surname>
            <given-names>VM</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>KEEL: a software tool to assess evolutionary algorithms for data mining problems</article-title>
        <source>Soft Comput</source>
        <year>2009</year>
        <volume>13</volume>
        <issue>3</issue>
        <fpage>307</fpage>
        <lpage>318</lpage>
        <pub-id pub-id-type="doi">10.1007/s00500-008-0323-y</pub-id>
      </element-citation>
    </ref>
    <ref id="CR4">
      <label>4.</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Demšar</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Zupan</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Leban</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Curk</surname>
            <given-names>T</given-names>
          </name>
        </person-group>
        <source>Orange: From experimental machine learning to interactive data mining</source>
        <year>2004</year>
        <publisher-loc>Berlin Heidelberg</publisher-loc>
        <publisher-name>Springer</publisher-name>
      </element-citation>
    </ref>
    <ref id="CR5">
      <label>5.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Pedregosa</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Varoquaux</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Gramfort</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Michel</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Thirion</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Grisel</surname>
            <given-names>O</given-names>
          </name>
          <name>
            <surname>Blondel</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Prettenhofer</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Weiss</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Dubourg</surname>
            <given-names>V</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Scikit-learn: machine learning in python</article-title>
        <source>J Mach Learn Res</source>
        <year>2011</year>
        <volume>12</volume>
        <fpage>2825</fpage>
        <lpage>2830</lpage>
      </element-citation>
    </ref>
    <ref id="CR6">
      <label>6.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Eklund</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Spjuth</surname>
            <given-names>O</given-names>
          </name>
          <name>
            <surname>Wikberg</surname>
            <given-names>JE</given-names>
          </name>
        </person-group>
        <article-title>The c1c2: a framework for simultaneous model selection and assessment</article-title>
        <source>BMC Bioinform</source>
        <year>2008</year>
        <volume>9</volume>
        <issue>1</issue>
        <fpage>360</fpage>
        <pub-id pub-id-type="doi">10.1186/1471-2105-9-360</pub-id>
      </element-citation>
    </ref>
    <ref id="CR7">
      <label>7.</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Berthold</surname>
            <given-names>MR</given-names>
          </name>
          <name>
            <surname>Cebron</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Dill</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Gabriel</surname>
            <given-names>TR</given-names>
          </name>
          <name>
            <surname>Kotter</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Meinl</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Ohl</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Sieb</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Thiel</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Wiswedel</surname>
            <given-names>B</given-names>
          </name>
        </person-group>
        <source>KNIME: the Konstanz information miner</source>
        <year>2008</year>
        <publisher-loc>Berlin, Heidelberg</publisher-loc>
        <publisher-name>Springer</publisher-name>
      </element-citation>
    </ref>
    <ref id="CR8">
      <label>8.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hardy</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Douglas</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Helma</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Rautenberg</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Jeliazkova</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Jeliazkov</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Nikolova</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Benigni</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Tcheremenskaia</surname>
            <given-names>O</given-names>
          </name>
          <name>
            <surname>Kramer</surname>
            <given-names>S</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Collaborative development of predictive toxicology applications</article-title>
        <source>J Cheminform</source>
        <year>2010</year>
        <volume>2</volume>
        <issue>1</issue>
        <fpage>1</fpage>
        <lpage>29</lpage>
        <pub-id pub-id-type="doi">10.1186/1758-2946-2-7</pub-id>
        <pub-id pub-id-type="pmid">20298528</pub-id>
      </element-citation>
    </ref>
    <ref id="CR9">
      <label>9.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Sushko</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Novotarskyi</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Körner</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Pandey</surname>
            <given-names>AK</given-names>
          </name>
          <name>
            <surname>Rupp</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Teetz</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Brandmaier</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Abdelaziz</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Prokopenko</surname>
            <given-names>VV</given-names>
          </name>
          <name>
            <surname>Tanchuk</surname>
            <given-names>VY</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Online chemical modeling environment (OCHEM): web platform for data storage, model development and publishing of chemical information</article-title>
        <source>J Comp Aided Mol Design</source>
        <year>2011</year>
        <volume>25</volume>
        <issue>6</issue>
        <fpage>533</fpage>
        <lpage>554</lpage>
        <pub-id pub-id-type="doi">10.1007/s10822-011-9440-2</pub-id>
      </element-citation>
    </ref>
    <ref id="CR10">
      <label>10.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Cases</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Briggs</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Steger-Hartmann</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Pognan</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Marc</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Kleinöder</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Schwab</surname>
            <given-names>CH</given-names>
          </name>
          <name>
            <surname>Pastor</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Wichard</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Sanz</surname>
            <given-names>F</given-names>
          </name>
        </person-group>
        <article-title>The eTOX data-sharing project to advance in silico drug-induced toxicity prediction</article-title>
        <source>Int J Mol Sci</source>
        <year>2014</year>
        <volume>15</volume>
        <issue>11</issue>
        <fpage>21136</fpage>
        <lpage>21154</lpage>
        <pub-id pub-id-type="doi">10.3390/ijms151121136</pub-id>
        <pub-id pub-id-type="pmid">25405742</pub-id>
      </element-citation>
    </ref>
    <ref id="CR11">
      <label>11.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ekins</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>Progress in computational toxicology</article-title>
        <source>J Pharmacol Toxicol Methods</source>
        <year>2014</year>
        <volume>69</volume>
        <issue>2</issue>
        <fpage>115</fpage>
        <lpage>140</lpage>
        <pub-id pub-id-type="doi">10.1016/j.vascn.2013.12.003</pub-id>
        <pub-id pub-id-type="pmid">24361690</pub-id>
      </element-citation>
    </ref>
    <ref id="CR12">
      <label>12.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Cherkasov</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Muratov</surname>
            <given-names>EN</given-names>
          </name>
          <name>
            <surname>Fourches</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Varnek</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Baskin</surname>
            <given-names>II</given-names>
          </name>
          <name>
            <surname>Cronin</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Dearden</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Gramatica</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Martin</surname>
            <given-names>YC</given-names>
          </name>
          <name>
            <surname>Todeschini</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Consonni</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Kuzmin</surname>
            <given-names>VE</given-names>
          </name>
          <name>
            <surname>Cramer</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Benigni</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Rathman</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Terfloth</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Gasteiger</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Richard</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Tropsha</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>QSAR modeling: where have you been? where are you going to?</article-title>
        <source>J Med Chem</source>
        <year>2014</year>
        <volume>57</volume>
        <issue>12</issue>
        <fpage>4977</fpage>
        <lpage>5010</lpage>
        <pub-id pub-id-type="doi">10.1021/jm4004285</pub-id>
        <pub-id pub-id-type="pmid">24351051</pub-id>
      </element-citation>
    </ref>
    <ref id="CR13">
      <label>13.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Fjodorova</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Vracko</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Novic</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Roncaglioni</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Benfenati</surname>
            <given-names>E</given-names>
          </name>
        </person-group>
        <article-title>New public QSAR model for carcinogenicity</article-title>
        <source>Chem Cent J</source>
        <year>2010</year>
        <volume>4</volume>
        <issue>Suppl 1</issue>
        <fpage>3</fpage>
        <pub-id pub-id-type="doi">10.1186/1752-153X-4-S1-S3</pub-id>
        <pub-id pub-id-type="pmid">20181222</pub-id>
      </element-citation>
    </ref>
    <ref id="CR14">
      <label>14.</label>
      <mixed-citation publication-type="other">US Environmental Protection Agency (2012) EPI Suite software. <ext-link ext-link-type="uri" xlink:href="http://www.epa.gov/oppt/exposure/pubs/episuitedl.htm">http://www.epa.gov/oppt/exposure/pubs/episuitedl.htm</ext-link></mixed-citation>
    </ref>
    <ref id="CR15">
      <label>15.</label>
      <mixed-citation publication-type="other">US Environmental Protection Agency (2012) Toxicity estimation software tool (TEST). <ext-link ext-link-type="uri" xlink:href="http://www.epa.gov/nrmrl/std/qsar/qsar.html%23TEST">http://www.epa.gov/nrmrl/std/qsar/qsar.html#TEST</ext-link></mixed-citation>
    </ref>
    <ref id="CR16">
      <label>16.</label>
      <mixed-citation publication-type="other">National Academy of Sciences of Ukraine (2012) QSAR4u. <ext-link ext-link-type="uri" xlink:href="http://www.qsar4u.com/">http://www.qsar4u.com/</ext-link></mixed-citation>
    </ref>
    <ref id="CR17">
      <label>17.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>de Oliveira</surname>
            <given-names>DB</given-names>
          </name>
          <name>
            <surname>Gaudio</surname>
            <given-names>AC</given-names>
          </name>
        </person-group>
        <article-title>Buildqsar: A new computer program for qsar analysis</article-title>
        <source>Quant Struct Act Relat</source>
        <year>2000</year>
        <volume>19</volume>
        <issue>6</issue>
        <fpage>599</fpage>
        <lpage>601</lpage>
        <pub-id pub-id-type="doi">10.1002/1521-3838(200012)19:6&lt;599::AID-QSAR599&gt;3.0.CO;2-B</pub-id>
      </element-citation>
    </ref>
    <ref id="CR18">
      <label>18.</label>
      <mixed-citation publication-type="other">OECD (2011) OECD QSAR Toolbox. <ext-link ext-link-type="uri" xlink:href="http://www.oecd.org/chemicalsafety/risk-assessment/theoecdqsartoolbox.htm">http://www.oecd.org/chemicalsafety/risk-assessment/theoecdqsartoolbox.htm</ext-link></mixed-citation>
    </ref>
    <ref id="CR19">
      <label>19.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Stålring</surname>
            <given-names>JC</given-names>
          </name>
          <name>
            <surname>Carlsson</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Almeida</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Boyer</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>AZOrange-High performance open source machine learning for QSAR modeling in a graphical programming environment</article-title>
        <source>J Cheminform</source>
        <year>2011</year>
        <volume>3</volume>
        <fpage>28</fpage>
        <pub-id pub-id-type="doi">10.1186/1758-2946-3-28</pub-id>
        <pub-id pub-id-type="pmid">21798025</pub-id>
      </element-citation>
    </ref>
    <ref id="CR20">
      <label>20.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Spjuth</surname>
            <given-names>O</given-names>
          </name>
          <name>
            <surname>Georgiev</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Carlsson</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Alvarsson</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Berg</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Willighagen</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Wikberg</surname>
            <given-names>JES</given-names>
          </name>
          <name>
            <surname>Eklund</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>Bioclipse-R: Integrating management and visualization of life science data with statistical analysis</article-title>
        <source>Bioinformatics</source>
        <year>2013</year>
        <volume>29</volume>
        <issue>2</issue>
        <fpage>286</fpage>
        <lpage>9</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/bts681</pub-id>
        <pub-id pub-id-type="pmid">23178637</pub-id>
      </element-citation>
    </ref>
    <ref id="CR21">
      <label>21.</label>
      <mixed-citation publication-type="other">Team RC et al (2011) R: A language and environment for statistical computing. The R Foundation for Statistical Computing, Vienna, Austria. ISBN 3-900051-07-0. <ext-link ext-link-type="uri" xlink:href="http://www.R-project.org/">http://www.R-project.org/</ext-link></mixed-citation>
    </ref>
    <ref id="CR22">
      <label>22.</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Venables</surname>
            <given-names>WN</given-names>
          </name>
          <name>
            <surname>Ripley</surname>
            <given-names>BD</given-names>
          </name>
        </person-group>
        <source>Modern Applied Statistics with S</source>
        <year>2002</year>
        <edition>4</edition>
        <publisher-loc>New York</publisher-loc>
        <publisher-name>Springer</publisher-name>
      </element-citation>
    </ref>
    <ref id="CR23">
      <label>23.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kuhn</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>Building predictive models in R using the caret package</article-title>
        <source>J Stat Softw</source>
        <year>2008</year>
        <volume>28</volume>
        <issue>5</issue>
        <fpage>1</fpage>
        <lpage>26</lpage>
      </element-citation>
    </ref>
    <ref id="CR24">
      <label>24.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wickham</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <article-title>testthat: get started with testing</article-title>
        <source>R J</source>
        <year>2011</year>
        <volume>3</volume>
        <fpage>5</fpage>
        <lpage>10</lpage>
      </element-citation>
    </ref>
    <ref id="CR25">
      <label>25.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hocking</surname>
            <given-names>RR</given-names>
          </name>
        </person-group>
        <article-title>The Analysis And Selection Of Variables In Linear Regression</article-title>
        <source>Biometrics</source>
        <year>1976</year>
        <volume>32</volume>
        <issue>1</issue>
        <fpage>1</fpage>
        <lpage>49</lpage>
        <pub-id pub-id-type="doi">10.2307/2529336</pub-id>
      </element-citation>
    </ref>
    <ref id="CR26">
      <label>26.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wold</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Ruhe</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Wold</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Dunn</surname>
            <given-names>W</given-names>
            <suffix>III</suffix>
          </name>
        </person-group>
        <article-title>The collinearity problem in linear regression. The partial least squares (PLS) approach to generalized inverses</article-title>
        <source>SIAM J Sci Stat Comput</source>
        <year>1984</year>
        <volume>5</volume>
        <issue>3</issue>
        <fpage>735</fpage>
        <lpage>743</lpage>
        <pub-id pub-id-type="doi">10.1137/0905052</pub-id>
      </element-citation>
    </ref>
    <ref id="CR27">
      <label>27.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Tibshirani</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>Regression selection and shrinkage via the lasso</article-title>
        <source>J R Stat Soc Ser B Stat Methodol</source>
        <year>1994</year>
        <volume>58</volume>
        <fpage>267</fpage>
        <lpage>288</lpage>
      </element-citation>
    </ref>
    <ref id="CR28">
      <label>28.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zou</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Hastie</surname>
            <given-names>T</given-names>
          </name>
        </person-group>
        <article-title>Regularization and variable selection via the elastic net</article-title>
        <source>J R Stat Soc Ser B Stat Methodol</source>
        <year>2005</year>
        <volume>67</volume>
        <fpage>301</fpage>
        <lpage>320</lpage>
        <pub-id pub-id-type="doi">10.1111/j.1467-9868.2005.00503.x</pub-id>
      </element-citation>
    </ref>
    <ref id="CR29">
      <label>29.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Guyon</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Weston</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Barnhill</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Vapnik</surname>
            <given-names>V</given-names>
          </name>
        </person-group>
        <article-title>Gene selection for cancer classification using support vector machines</article-title>
        <source>Mach Learn</source>
        <year>2002</year>
        <volume>46</volume>
        <issue>1–3</issue>
        <fpage>389</fpage>
        <lpage>422</lpage>
        <pub-id pub-id-type="doi">10.1023/A:1012487302797</pub-id>
      </element-citation>
    </ref>
    <ref id="CR30">
      <label>30.</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Bishop</surname>
            <given-names>CM</given-names>
          </name>
        </person-group>
        <source>Neural networks for pattern recognition</source>
        <year>1995</year>
        <publisher-loc>New York</publisher-loc>
        <publisher-name>Oxford University Press Inc</publisher-name>
      </element-citation>
    </ref>
    <ref id="CR31">
      <label>31.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Breiman</surname>
            <given-names>L</given-names>
          </name>
        </person-group>
        <article-title>Random forests</article-title>
        <source>Mach Learn</source>
        <year>2001</year>
        <volume>45</volume>
        <issue>1</issue>
        <fpage>5</fpage>
        <lpage>32</lpage>
        <pub-id pub-id-type="doi">10.1023/A:1010933404324</pub-id>
      </element-citation>
    </ref>
    <ref id="CR32">
      <label>32.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Saeys</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Inza</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Larrñaaga</surname>
            <given-names>P</given-names>
          </name>
        </person-group>
        <article-title>A review of feature selection techniques in bioinformatics</article-title>
        <source>Bioinformatics</source>
        <year>2007</year>
        <volume>23</volume>
        <issue>19</issue>
        <fpage>2507</fpage>
        <lpage>2517</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btm344</pub-id>
        <pub-id pub-id-type="pmid">17720704</pub-id>
      </element-citation>
    </ref>
    <ref id="CR33">
      <label>33.</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Dobson</surname>
            <given-names>AJ</given-names>
          </name>
          <name>
            <surname>Barnett</surname>
            <given-names>AG</given-names>
          </name>
        </person-group>
        <source>An introduction to generalized linear models</source>
        <year>2008</year>
        <publisher-loc>Boca Raton</publisher-loc>
        <publisher-name>Chapman and Hall, CRC Press</publisher-name>
      </element-citation>
    </ref>
    <ref id="CR34">
      <label>34.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Guha</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>Chemical informatics functionality in R</article-title>
        <source>J Stat Softw</source>
        <year>2007</year>
        <volume>18</volume>
        <issue>5</issue>
        <fpage>1</fpage>
        <lpage>16</lpage>
      </element-citation>
    </ref>
    <ref id="CR35">
      <label>35.</label>
      <mixed-citation publication-type="other">Bache K, Lichman M (2013) UCI machine learning repository. <ext-link ext-link-type="uri" xlink:href="http://www.archive.ics.uci.edu/ml">http://www.archive.ics.uci.edu/ml</ext-link></mixed-citation>
    </ref>
    <ref id="CR36">
      <label>36.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Harrison</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Rubinfeld</surname>
            <given-names>DL</given-names>
          </name>
        </person-group>
        <article-title>Hedonic housing prices and the demand for clean air</article-title>
        <source>J Environ Econ Manage</source>
        <year>1978</year>
        <volume>5</volume>
        <issue>1</issue>
        <fpage>81</fpage>
        <lpage>102</lpage>
        <pub-id pub-id-type="doi">10.1016/0095-0696(78)90006-2</pub-id>
      </element-citation>
    </ref>
    <ref id="CR37">
      <label>37.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Cortez</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Cerdeira</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Almeida</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Matos</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Reis</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Modeling wine preferences by data mining from physicochemical properties</article-title>
        <source>Decis Support Syst</source>
        <year>2009</year>
        <volume>47</volume>
        <issue>4</issue>
        <fpage>547</fpage>
        <lpage>553</lpage>
        <pub-id pub-id-type="doi">10.1016/j.dss.2009.05.016</pub-id>
      </element-citation>
    </ref>
    <ref id="CR38">
      <label>38.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kibler</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Aha</surname>
            <given-names>DW</given-names>
          </name>
          <name>
            <surname>Albert</surname>
            <given-names>MK</given-names>
          </name>
        </person-group>
        <article-title>Instance-based prediction of real-valued attributes</article-title>
        <source>Comput Intell</source>
        <year>1989</year>
        <volume>5</volume>
        <issue>2</issue>
        <fpage>51</fpage>
        <lpage>57</lpage>
        <pub-id pub-id-type="doi">10.1111/j.1467-8640.1989.tb00315.x</pub-id>
      </element-citation>
    </ref>
    <ref id="CR39">
      <label>39.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Tsanas</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Little</surname>
            <given-names>MA</given-names>
          </name>
          <name>
            <surname>McSharry</surname>
            <given-names>PE</given-names>
          </name>
          <name>
            <surname>Ramig</surname>
            <given-names>LO</given-names>
          </name>
        </person-group>
        <article-title>Accurate telemonitoring of parkinsons disease progression by noninvasive speech tests</article-title>
        <source>Biomed Eng IEEE Trans</source>
        <year>2010</year>
        <volume>57</volume>
        <issue>4</issue>
        <fpage>884</fpage>
        <lpage>893</lpage>
        <pub-id pub-id-type="doi">10.1109/TBME.2009.2036000</pub-id>
      </element-citation>
    </ref>
    <ref id="CR40">
      <label>40.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhou</surname>
            <given-names>Z-H</given-names>
          </name>
          <name>
            <surname>Wu</surname>
            <given-names>J-X</given-names>
          </name>
          <name>
            <surname>Tang</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>Z</given-names>
          </name>
        </person-group>
        <article-title>Combining regression estimators: GA-based selective neural network ensemble</article-title>
        <source>Int J Comput Intell Appl</source>
        <year>2001</year>
        <volume>1</volume>
        <fpage>341</fpage>
        <pub-id pub-id-type="doi">10.1142/S1469026801000287</pub-id>
      </element-citation>
    </ref>
    <ref id="CR41">
      <label>41.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hershberger</surname>
            <given-names>DE</given-names>
          </name>
          <name>
            <surname>Kargupta</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <article-title>Distributed multivariate regression using wavelet-based collective data mining</article-title>
        <source>J Parallel Distrib Comput</source>
        <year>2001</year>
        <volume>61</volume>
        <fpage>372</fpage>
        <pub-id pub-id-type="doi">10.1006/jpdc.2000.1694</pub-id>
      </element-citation>
    </ref>
    <ref id="CR42">
      <label>42.</label>
      <mixed-citation publication-type="other">Law MHC, Kwok JT (2001) Applying the bayesian evidence framework to υ-support vector regression. In: ECML, pp 312</mixed-citation>
    </ref>
    <ref id="CR43">
      <label>43.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Merz</surname>
            <given-names>CJ</given-names>
          </name>
          <name>
            <surname>Pazzani</surname>
            <given-names>MJ</given-names>
          </name>
        </person-group>
        <article-title>A principal components approach to combining regression estimates</article-title>
        <source>Mach Learn</source>
        <year>1999</year>
        <volume>36</volume>
        <fpage>9</fpage>
        <pub-id pub-id-type="doi">10.1023/A:1007507221352</pub-id>
      </element-citation>
    </ref>
    <ref id="CR44">
      <label>44.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Guvenir</surname>
            <given-names>HA</given-names>
          </name>
          <name>
            <surname>Uysal</surname>
            <given-names>I</given-names>
          </name>
        </person-group>
        <article-title>Regression on feature projections</article-title>
        <source>Knowl Based Syst</source>
        <year>2000</year>
        <volume>13</volume>
        <issue>4</issue>
        <fpage>207</fpage>
        <lpage>214</lpage>
        <pub-id pub-id-type="doi">10.1016/S0950-7051(00)00060-5</pub-id>
      </element-citation>
    </ref>
    <ref id="CR45">
      <label>45.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hoegaerts</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Suykens</surname>
            <given-names>JAK</given-names>
          </name>
          <name>
            <surname>Vandewalle</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>De Moor</surname>
            <given-names>B</given-names>
          </name>
        </person-group>
        <article-title>Subset based least squares subspace regression in RKHS</article-title>
        <source>Neurocomputing</source>
        <year>2005</year>
        <volume>63</volume>
        <fpage>293</fpage>
        <lpage>323</lpage>
        <pub-id pub-id-type="doi">10.1016/j.neucom.2004.04.013</pub-id>
      </element-citation>
    </ref>
    <ref id="CR46">
      <label>46.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Shevade</surname>
            <given-names>SK</given-names>
          </name>
          <name>
            <surname>Keerthi</surname>
            <given-names>SS</given-names>
          </name>
          <name>
            <surname>Bhattacharyya</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Murthy</surname>
            <given-names>KRK</given-names>
          </name>
        </person-group>
        <article-title>Improvements to the smo algorithm for svm regression</article-title>
        <source>Neural Netw IEEE Trans</source>
        <year>2000</year>
        <volume>11</volume>
        <issue>5</issue>
        <fpage>1188</fpage>
        <lpage>1193</lpage>
        <pub-id pub-id-type="doi">10.1109/72.870050</pub-id>
      </element-citation>
    </ref>
    <ref id="CR47">
      <label>47.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ge</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Du</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Zhao</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Zhou</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Zhao</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Chai</surname>
            <given-names>Z</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Binding of blood proteins to carbon nanotubes reduces cytotoxicity</article-title>
        <source>Proc Natl Acad Sci</source>
        <year>2011</year>
        <volume>108</volume>
        <issue>41</issue>
        <fpage>16968</fpage>
        <lpage>16973</lpage>
        <pub-id pub-id-type="doi">10.1073/pnas.1105270108</pub-id>
        <pub-id pub-id-type="pmid">21969544</pub-id>
      </element-citation>
    </ref>
    <ref id="CR48">
      <label>48.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lesniak</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Fenaroli</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Monopoli</surname>
            <given-names>MP</given-names>
          </name>
          <name>
            <surname>Aberg</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Dawson</surname>
            <given-names>KA</given-names>
          </name>
          <name>
            <surname>Salvati</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Effects of the presence or absence of a protein corona on silica nanoparticle uptake and impact on cells</article-title>
        <source>ACS Nano</source>
        <year>2012</year>
        <volume>6</volume>
        <issue>7</issue>
        <fpage>5845</fpage>
        <lpage>5857</lpage>
        <pub-id pub-id-type="doi">10.1021/nn300223w</pub-id>
        <pub-id pub-id-type="pmid">22721453</pub-id>
      </element-citation>
    </ref>
    <ref id="CR49">
      <label>49.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Walkey</surname>
            <given-names>CD</given-names>
          </name>
          <name>
            <surname>Olsen</surname>
            <given-names>JB</given-names>
          </name>
          <name>
            <surname>Song</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Guo</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Olsen</surname>
            <given-names>DWH</given-names>
          </name>
          <name>
            <surname>Cohen</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Emili</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Chan</surname>
            <given-names>WCW</given-names>
          </name>
        </person-group>
        <article-title>Protein corona fingerprinting predicts the cellular interaction of gold and silver nanoparticles</article-title>
        <source>ACS Nano</source>
        <year>2014</year>
        <volume>8</volume>
        <issue>3</issue>
        <fpage>2439</fpage>
        <lpage>2455</lpage>
        <pub-id pub-id-type="doi">10.1021/nn406018q</pub-id>
        <pub-id pub-id-type="pmid">24517450</pub-id>
      </element-citation>
    </ref>
    <ref id="CR50">
      <label>50.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Gajewicz</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Schaeublin</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Rasulev</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Hussain</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Leszczynska</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Puzyn</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Leszczynski</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Towards understanding mechanisms governing cytotoxicity of metal oxides nanoparticles: Hints from nano-QSAR studies</article-title>
        <source>Nanotoxicology</source>
        <year>2015</year>
        <volume>9</volume>
        <issue>3</issue>
        <fpage>313</fpage>
        <lpage>325</lpage>
        <pub-id pub-id-type="doi">10.3109/17435390.2014.930195</pub-id>
        <pub-id pub-id-type="pmid">24983896</pub-id>
      </element-citation>
    </ref>
    <ref id="CR51">
      <label>51.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Cassotti</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Ballabio</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Consonni</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Mauri</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Tetko</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Todeschini</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>Prediction of acute aquatic toxicity toward daphnia magna by using the ga-knn method</article-title>
        <source>Altern Lab Anim ATLA</source>
        <year>2014</year>
        <volume>42</volume>
        <issue>1</issue>
        <fpage>31</fpage>
        <lpage>41</lpage>
        <pub-id pub-id-type="pmid">24773486</pub-id>
      </element-citation>
    </ref>
    <ref id="CR52">
      <label>52.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lahl</surname>
            <given-names>U</given-names>
          </name>
          <name>
            <surname>Gundert-Remy</surname>
            <given-names>U</given-names>
          </name>
        </person-group>
        <article-title>The use of (Q)SAR methods in the context of REACH</article-title>
        <source>Toxicol Mech Methods</source>
        <year>2008</year>
        <volume>18</volume>
        <issue>2–3</issue>
        <fpage>149</fpage>
        <lpage>158</lpage>
        <pub-id pub-id-type="doi">10.1080/15376510701857288</pub-id>
        <pub-id pub-id-type="pmid">20020911</pub-id>
      </element-citation>
    </ref>
    <ref id="CR53">
      <label>53.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Brereton</surname>
            <given-names>RG</given-names>
          </name>
          <name>
            <surname>Lloyd</surname>
            <given-names>GR</given-names>
          </name>
        </person-group>
        <article-title>Support vector machines for classification and regression</article-title>
        <source>Analyst</source>
        <year>2010</year>
        <volume>135</volume>
        <issue>2</issue>
        <fpage>230</fpage>
        <lpage>267</lpage>
        <pub-id pub-id-type="doi">10.1039/B918972F</pub-id>
        <pub-id pub-id-type="pmid">20098757</pub-id>
      </element-citation>
    </ref>
    <ref id="CR54">
      <label>54.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Smola</surname>
            <given-names>AJ</given-names>
          </name>
          <name>
            <surname>Schölkopf</surname>
            <given-names>B</given-names>
          </name>
        </person-group>
        <article-title>A tutorial on support vector regression</article-title>
        <source>Stat Comput</source>
        <year>2004</year>
        <volume>14</volume>
        <issue>3</issue>
        <fpage>199</fpage>
        <lpage>222</lpage>
        <pub-id pub-id-type="doi">10.1023/B:STCO.0000035301.49549.88</pub-id>
      </element-citation>
    </ref>
  </ref-list>
</back>
