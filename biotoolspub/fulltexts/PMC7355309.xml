<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1 20151215//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.1?>
<?ConverterInfo.XSLTName jp2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id>
    <journal-id journal-id-type="publisher-id">bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1367-4803</issn>
    <issn pub-type="epub">1367-4811</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">7355309</article-id>
    <article-id pub-id-type="doi">10.1093/bioinformatics/btaa461</article-id>
    <article-id pub-id-type="publisher-id">btaa461</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>General Computational Biology</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Interactive visualization and analysis of morphological skeletons of brain vasculature networks with VessMorphoVis</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Abdellah</surname>
          <given-names>Marwan</given-names>
        </name>
        <xref ref-type="corresp" rid="btaa461-cor1"/>
        <xref ref-type="aff" rid="btaa461-aff1"/>
        <!--<email>marwan.abdellah@epfl.ch</email>-->
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Guerrero</surname>
          <given-names>Nadir Román</given-names>
        </name>
        <xref ref-type="aff" rid="btaa461-aff1"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Lapere</surname>
          <given-names>Samuel</given-names>
        </name>
        <xref ref-type="aff" rid="btaa461-aff1"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Coggan</surname>
          <given-names>Jay S</given-names>
        </name>
        <xref ref-type="aff" rid="btaa461-aff1"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Keller</surname>
          <given-names>Daniel</given-names>
        </name>
        <xref ref-type="aff" rid="btaa461-aff1"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Coste</surname>
          <given-names>Benoit</given-names>
        </name>
        <xref ref-type="aff" rid="btaa461-aff1"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Dagar</surname>
          <given-names>Snigdha</given-names>
        </name>
        <xref ref-type="aff" rid="btaa461-aff1"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Courcol</surname>
          <given-names>Jean-Denis</given-names>
        </name>
        <xref ref-type="aff" rid="btaa461-aff1"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Markram</surname>
          <given-names>Henry</given-names>
        </name>
        <xref ref-type="aff" rid="btaa461-aff1"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Schürmann</surname>
          <given-names>Felix</given-names>
        </name>
        <xref ref-type="corresp" rid="btaa461-cor1"/>
        <xref ref-type="aff" rid="btaa461-aff1"/>
        <!--<email>felix.schuermann@epfl.ch</email>-->
      </contrib>
    </contrib-group>
    <aff id="btaa461-aff1"><institution>Blue Brain Project (BBP), École Polytechnique Fédérale de Lausanne (EPFL)</institution>, Campus Biotech, 1202 Geneva, <country country="CH">Switzerland</country></aff>
    <author-notes>
      <corresp id="btaa461-cor1">To whom correspondence should be addressed. E-mail: <email>marwan.abdellah@epfl.ch</email> or <email>felix.schuermann@epfl.ch</email></corresp>
    </author-notes>
    <pub-date pub-type="ppub">
      <month>7</month>
      <year>2020</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2020-07-13">
      <day>13</day>
      <month>7</month>
      <year>2020</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>13</day>
      <month>7</month>
      <year>2020</year>
    </pub-date>
    <!-- PMC Release delay is 0 months and 0 days and was based on the <pub-date pub-type="epub"/>. -->
    <volume>36</volume>
    <issue>Suppl 1</issue>
    <issue-title>ISMB 2020 Proceedings</issue-title>
    <fpage>i534</fpage>
    <lpage>i541</lpage>
    <permissions>
      <copyright-statement>© The Author(s) 2020. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2020</copyright-year>
      <license license-type="cc-by-nc" xlink:href="http://creativecommons.org/licenses/by-nc/4.0/">
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by-nc/4.0/">http://creativecommons.org/licenses/by-nc/4.0/</ext-link>), which permits non-commercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited. For commercial re-use, please contact journals.permissions@oup.com</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="btaa461.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Motivation</title>
        <p>Accurate morphological models of brain vasculature are key to modeling and simulating cerebral blood flow in realistic vascular networks. This <italic>in silico</italic> approach is fundamental to revealing the principles of neurovascular coupling. Validating those vascular morphologies entails performing certain visual analysis tasks that cannot be accomplished with generic visualization frameworks. This limitation has a substantial impact on the accuracy of the vascular models employed in the simulation.</p>
      </sec>
      <sec id="s2">
        <title>Results</title>
        <p>We present VessMorphoVis, an integrated suite of toolboxes for interactive visualization and analysis of vast brain vascular networks represented by morphological graphs segmented originally from imaging or microscopy stacks. Our workflow leverages the outstanding potentials of Blender, aiming to establish an integrated, extensible and domain-specific framework capable of interactive visualization, analysis, repair, high-fidelity meshing and high-quality rendering of vascular morphologies. Based on the initial feedback of the users, we anticipate that our framework will be an essential component in vascular modeling and simulation in the future, filling a gap that is at present largely unfulfilled.</p>
      </sec>
      <sec id="s3">
        <title>Availability and implementation</title>
        <p>VessMorphoVis is freely available under the GNU public license on Github at <ext-link ext-link-type="uri" xlink:href="https://github.com/BlueBrain/VessMorphoVis">https://github.com/BlueBrain/VessMorphoVis</ext-link>. The morphology analysis, visualization, meshing and rendering modules are implemented as an add-on for Blender 2.8 based on its Python API (application programming interface). The add-on functionality is made available to users through an intuitive graphical user interface, as well as through exhaustive configuration files calling the API via a feature-rich command line interface running Blender in background mode.</p>
      </sec>
      <sec id="s5">
        <title>Supplementary information</title>
        <p><xref ref-type="supplementary-material" rid="sup1">Supplementary data</xref> are available at <italic>Bioinformatics</italic> online.</p>
      </sec>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Blue Brain Project</institution>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Polytechnique Fédérale de Lausanne</institution>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Swiss Government’s ETH Board</institution>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Swiss Federal Institutes of Technology</institution>
          </institution-wrap>
        </funding-source>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="8"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <label>1</label>
    <title>Introduction</title>
    <p>The brain requires an adequate supply of energy to drive billions of neurons to fire properly. To ensure its normal functioning, essential energy substrates including oxygen, glucose and lactate are provided, on-demand, through a vast network of cerebral blood vessels via neurovascular coupling (NVC; <xref rid="btaa461-B18" ref-type="bibr">Iadecola, 2017</xref>). The length of this network in human brains is estimated to be ∼700 km and the failure to deliver the proper amount of blood at the right time and location will be accompanied by catastrophic neurodegenerative disorders (<xref rid="btaa461-B40" ref-type="bibr">Sweeney <italic>et al.</italic>, 2018</xref>). While most of the focus in neuroscience research covers the structural and functional aspects of brain cells such as neurons (<xref rid="btaa461-B29" ref-type="bibr">Markram <italic>et al.</italic>, 2015</xref>) and glia (<xref rid="btaa461-B42" ref-type="bibr">von Bartheld <italic>et al.</italic>, 2016</xref>), the dense network of vascular channels that course through our brains has received comparatively less attention. This oversight is unfortunate considering the disproportionately high metabolic demands of neural tissues, the function of which must surely be tied to the availability of energy and other nutrients. There is a large body of work on gross-scale hemodynamics with the use of brain imaging technologies such as functional magnetic resonance (MR) imaging, with which the blood-oxygen level-dependent activity is measured (<xref rid="btaa461-B26" ref-type="bibr">Logothetis <italic>et al.</italic>, 2001</xref>; <xref rid="btaa461-B33" ref-type="bibr">Raichle and Mintun, 2006</xref>). But this and other imaging methods do not resolve the functions of fine-scale structures that form the points of contact between the microvasculature and glial cells or within the effective range of individual neurons. Not only does an understanding of normal brain function require improving our concept of neurovascular structure, but there are numerous disease states associated with blood vessel damage that are broadly referred to as vascular cognitive impairments or <italic>dementias</italic>. Although all are generally due to cerebral hemodynamic insufficiencies of one sort or another, there is still little etiological or diagnostic agreement about causes or precise definitions, let alone treatments (<xref rid="btaa461-B15" ref-type="bibr">Frantellizzi <italic>et al.</italic>, 2020</xref>). The neuro-glia-vasculature (NGV) ensemble is often considered as a functional unit for the study of interactions among these critical components of brain energy metabolism at an oligocellular scale (<xref rid="btaa461-B9" ref-type="bibr">Coggan <italic>et al.</italic>, 2018b</xref>; <xref rid="btaa461-B21" ref-type="bibr">Jolivet <italic>et al.</italic>, 2015</xref>). Within this unit, detailed vascular maps revealing fine anatomical features of vessels and their interaction with neurons and glia are therefore critical to understanding overall brain function (<xref rid="btaa461-B6" ref-type="bibr">Calcinaghi <italic>et al.</italic>, 2013</xref>; <xref rid="btaa461-B7" ref-type="bibr">Calì <italic>et al.</italic>, 2019</xref>; <xref rid="btaa461-B8" ref-type="bibr">Coggan <italic>et al.</italic>, 2018a</xref>; <xref rid="btaa461-B28" ref-type="bibr">Marín-Padilla, 2012</xref>; <xref rid="btaa461-B37" ref-type="bibr">Schmid <italic>et al.</italic>, 2019</xref>). These maps are essential for developing blood flow models to simulate cerebral blood flow (CBF) in realistic vascular networks (<xref rid="btaa461-B11" ref-type="bibr">Damseh <italic>et al.</italic>, 2019</xref>; <xref rid="btaa461-B34" ref-type="bibr">Reichold <italic>et al.</italic>, 2009</xref>), analyzing the proximity of cell bodies to vasculature elements (<xref rid="btaa461-B4" ref-type="bibr">Blinder <italic>et al.</italic>, 2013</xref>) and also for classifying vascular components into different types of segments (<xref rid="btaa461-B45" ref-type="bibr">Zeng <italic>et al.</italic>, 2017</xref>). Accurate digital reconstructions of vascular ultrastructure down to capillary level (<xref rid="btaa461-B12" ref-type="bibr">Di Giovanna <italic>et al.</italic>, 2018</xref>) are central to this goal, which requires innovative and rapid software visualization tools to investigate the topology of the vascular network and to model its behavior (<xref rid="btaa461-B39" ref-type="bibr">Smith <italic>et al.</italic>, 2019</xref>). Unfortunately, the existence of convenient domain-specific software frameworks capable of visualizing those vascular models in real time is currently lacking. We therefore remedy this limitation and present an integrated tool to address this problem. This tool is primarily devoted to neuroscience researchers studying NVC using computational modeling and simulation.</p>
    <sec>
      <label>1.1</label>
      <title>Relevant work</title>
      <p>Vasculature datasets are originally obtained on multiple scales from two principal sources: imaging scanners such as computed tomography or MR (<xref rid="btaa461-B32" ref-type="bibr">Preim and Oeltze, 2008</xref>; <xref rid="btaa461-B43" ref-type="bibr">Wright <italic>et al.</italic>, 2013</xref>) and microscopy, mainly from optical (<xref rid="btaa461-B27" ref-type="bibr">Lugo-Hernandez <italic>et al.</italic>, 2017</xref>) and electron microscopes (<xref rid="btaa461-B20" ref-type="bibr">Januszewski <italic>et al.</italic>, 2018</xref>). Certain optical techniques have bridged the gap between macroscopic and microscopic imaging, such as ultramicroscopy which can reconstruct cm-sized vascular networks with micrometer resolution (<xref rid="btaa461-B19" ref-type="bibr">Jährling <italic>et al.</italic>, 2009</xref>). A recent study proposed an advanced approach improving vascular demarcation, making it possible to reconstruct a whole brain vasculature with extremely high resolution that can capture the details of a single capillary (<xref rid="btaa461-B12" ref-type="bibr">Di Giovanna <italic>et al.</italic>, 2018</xref>). Nevertheless, exploring those vascular reconstructions and analyzing their fine structures with which we can test our scientific hypotheses, mainly in computational modeling, remains challenging.</p>
      <p>A large variety of rendering techniques has been developed to visualize different structural aspects of vasculature networks (<xref rid="btaa461-B32" ref-type="bibr">Preim and Oeltze, 2008</xref>). Complex networks can be visualized relying on direct volume rendering methods, such as slice-based viewing or ray-marching, employing original angiography stacks prior to their segmentation (<xref rid="btaa461-B24" ref-type="bibr">Kubisch <italic>et al.</italic>, 2012</xref>). This approach is substantial to classify and reveal vessel abnormalities more faithfully using multi-dimensional transfer functions, allowing diagnosis of vascular diseases, such as atherosclerosis or stenosis. Visualization of large-scale volumes is not as trivial however. It requires scalable volume rendering workflows that either use out-of-core algorithms, distributed solutions with sort-last rendering or combine the two approaches to load terabyte-sized datasets (<xref rid="btaa461-B14" ref-type="bibr">Eilemann <italic>et al.</italic>, 2012</xref>). These workflows remain unavailable to the public, which drives scientists to use standard visualization packages such as Paraview (<xref rid="btaa461-B16" ref-type="bibr">Henderson <italic>et al.</italic>, 2004</xref>), or even build their custom workflows based on visualization toolkit (VTK; <xref rid="btaa461-B38" ref-type="bibr">Schroeder <italic>et al.</italic>, 2004</xref>; <xref rid="btaa461-B41" ref-type="bibr">Taka and Srinivasan, 2011</xref>). The vascular modeling toolkit is a prominent example, designed based on VTK and insight toolkit specifically to visualize and model vascular data (<xref rid="btaa461-B3" ref-type="bibr">Antiga and Steinman, 2006</xref>). It has several components for (i) segmenting vessels from imaging stacks, (ii) reconstructing surface meshes, (iii) computing centerlines of vascular segments from polygonal surfaces and (iv) creating tetrahedral meshes. Nevertheless, its capability to perform these tasks for complex or large networks is doubtful. Obviously, volume rendering can be useful for segmentation and quantification purposes (<xref rid="btaa461-B5" ref-type="bibr">Bühler <italic>et al.</italic>, 2004</xref>), but it cannot reveal spatial relationships between different structures in the volume. Several limitations of volume rendering can be addressed by relying on polygonal surface meshes instead. Visualization of vascular meshes reconstructed from those stacks can be accomplished with either model-free or model-based techniques (<xref rid="btaa461-B23" ref-type="bibr">Kretschmer <italic>et al.</italic>, 2013</xref>). Conventional surface rendering applications use marching cubes algorithms to visualize a polygonal surface reconstructed during the rendering stage based on an appropriate iso-value. Although the quality of this category of algorithms is relatively poor, it could be enhanced if the surface is explicitly segmented <italic>a priori</italic>, but it might be subject to other inaccuracies due to user interaction. Unfortunately, even for relatively small-scale networks, the size of corresponding vascular meshes might be large for interactive visualization and analysis.</p>
      <p>Skeletal representation of vascular networks has been proposed fundamentally for morphometric analysis purposes (<xref rid="btaa461-B43" ref-type="bibr">Wright <italic>et al.</italic>, 2013</xref>), but it has resolved implicitly the size limitation issue. Storing a complex graph of a vascular network is comparatively more efficient than a corresponding mesh. Although skeletons must be reconstructed either from volumes or meshes, there are advanced skeletonization methods that can perform this task efficiently (<xref rid="btaa461-B36" ref-type="bibr">Saha <italic>et al.</italic>, 2016</xref>). Nevertheless, visualizing those skeletons was not similarly investigated, in particular for brain vasculature. We only found a few studies that have used input vascular trees for visualization or analysis purposes based on convolution surfaces (<xref rid="btaa461-B30" ref-type="bibr">Oeltze and Preim, 2004</xref>), abstract—yet spatially contextualized—approaches (<xref rid="btaa461-B31" ref-type="bibr">Pandey <italic>et al.</italic>, 2020</xref>), illustrative rendering approaches (<xref rid="btaa461-B35" ref-type="bibr">Ritter <italic>et al.</italic>, 2006</xref>) and signed distance fields (<xref rid="btaa461-B25" ref-type="bibr">Lichtenberg <italic>et al.</italic>, 2019</xref>). Nevertheless, these research trials were not accompanied with open source implementations that can be adapted. The presence of a software package that is mainly domain-specific, extensible, cross-platform and more significantly free, capable of interactive visualization and analysis of large-scale morphologies of vascular networks integrated in a single package is still largely missing.</p>
    </sec>
    <sec>
      <label>1.2</label>
      <title>Contribution</title>
      <p>We present <italic>VessMorphoVis</italic>, a multi-functional, domain-specific and user-friendly add-on leveraging the core functionality provided by Blender. This add-on is primarily developed for visual analysis of large-scale morphological skeletons of vascular networks, allowing to build accurate vasculature structures for modeling and simulating CBF to understand the mechanisms of NVC. The add-on comes with the following features:
</p>
      <list list-type="order">
        <list-item>
          <p>Interactive visualization, analysis and automated repair of large-scale vasculature morphology skeletons.</p>
        </list-item>
        <list-item>
          <p>Creation of high-fidelity polygonal mesh models of vascular structures from their morphology skeletons using metaballs.</p>
        </list-item>
        <list-item>
          <p>Automated creation of high-quality multimedia content using artistic shader nodes for debugging, discovery and dissemination.</p>
        </list-item>
        <list-item>
          <p>Extensible python-based application programming interface (API) for analysis and visualization. This API can be called from the user interface of Blender or invoked via feature-rich command line interface (CLI) that runs Blender in background mode.</p>
        </list-item>
      </list>
    </sec>
  </sec>
  <sec>
    <title>2 System architecture and results</title>
    <p><italic>VessMorphoVis</italic> is composed of five modules: (i) data handling, (ii) vascular network analysis and repair, (iii) morphology building for interactive visualization, (iv) polygonal mesh reconstruction and (v) high-quality rendering. In the following part, we present the functionality of each module and then demonstrate the features of the add-on with multiple datasets of varying structure and complexity. A high-level overview of the framework is illustrated in <xref ref-type="supplementary-material" rid="sup1">Supplementary Figure S1</xref>. The integration of the add-on in the graphical user interface (GUI) of Blender is shown in <xref ref-type="supplementary-material" rid="sup1">Supplementary Figures S2 and S3</xref>. The corresponding panels of each module as seen in the GUI are shown in <xref ref-type="supplementary-material" rid="sup1">Supplementary Material</xref> (Section 4).</p>
    <sec>
      <title>2.1 Vasculature morphology structure</title>
      <p>A vascular morphology skeleton, or a vascular graph (VC), consists of a set of ordered samples or points, where each sample is specified by an index, a three-dimensional Cartesian position vector and a diameter reflecting the cross-sectional extent of the skeleton at this point. Each two consecutive samples account for a segment, where a list of connected segments between two branching points represents a section. The segments are implicitly connected based on the order of their constituent samples in the section. A loop is composed of two independent sections having the same parents and children. For efficient data storage and convenient representation, the sections are logically connected at their respective branching points, i.e. any two connected sections have, at least, a shared terminal sample with the exact same Cartesian position, but with different indices and possibly varying radii for each respective section. In certain cases, the connectivity information is not explicitly encoded in the morphology tree, and therefore, it will be computed on-the-fly if needed. <xref ref-type="fig" rid="btaa461-F1">Figure 1</xref> illustrates a schematic view of a small chunk of vasculature morphology skeleton extracted from a larger vascular network.
</p>
      <fig id="btaa461-F1" orientation="portrait" position="float">
        <label>Fig. 1.</label>
        <caption>
          <p>A schematic view of a vascular morphology network</p>
        </caption>
        <graphic xlink:href="btaa461f1"/>
      </fig>
    </sec>
    <sec>
      <title>2.2 Data format</title>
      <p><italic>VessMorphoVis</italic> supports two unique data formats: an internal binary file format based on the HDF5 library (with extension.<italic>h5</italic>) that targets efficient storage of data to guarantee scalability, and another ASCII format (with extension.<italic>vmv</italic>) that is mainly provided to external collaborators and the neuroscientific community. The ASCII format is designed to be extensible, allowing users to add further optional parameters that serve their needs. The structure of the file formats is detailed in <xref ref-type="supplementary-material" rid="sup1">Supplementary Material</xref> (Section 1).</p>
    </sec>
    <sec>
      <title>2.3 Skeleton analysis and repair</title>
      <p>To complement the subjective visual analysis of the skeleton, it was crucial to integrate another module for automated morphological analysis as well. This module applies a list of predefined kernels on the input network and produces a set of measurements and statistical distributions. This analysis is essential to detect and reveal any structural artifacts in the skeleton. Users can then apply another set of kernels to repair any artifact that might affect the visual quality of the reconstructed morphology, e.g. having a sample with zero diameter. Afterwards, a fact sheet containing the computed measures of the VC is displayed in the analysis panel, allowing users to link those values to the morphology skeleton appearing on the rendering widget. The measurements include the total number of samples, segments and sections in the morphology before and after resampling the skeleton, statistical distributions of the lengths of sections and their corresponding segments and the entire network in addition to the total number of fragmented components and loops. <xref ref-type="supplementary-material" rid="sup1">Supplementary Figure S4</xref> shows a screenshot demonstrating a large vascular network loaded in the viewport and its analysis results.</p>
    </sec>
    <sec>
      <title>2.4 Interactive skeleton visualization</title>
      <p>Visualizing complex networks of brain vasculature is relatively challenging with respect to other NGV structures (<xref rid="btaa461-B9" ref-type="bibr">Coggan <italic>et al.</italic>, 2018b</xref>), such as neurons or glial cells. Neuronal and glial morphologies are represented by directed acyclic graphs, which makes storing and traversing them simpler than vasculature which are represented by cyclic ones. In terms of data complexity, neuronal morphologies have—on average—fewer numbers of samples than a small piece of vasculature network. They range from several hundred for simple morphologies and up to a few thousand for a neuron with highly complex arborizations in its dendritic or axonal trees. Subsequently, building interactive visualizers to render individual neuronal graphs in real time relying on Blender (<xref rid="btaa461-B1" ref-type="bibr">Abdellah <italic>et al.</italic>, 2018</xref>) is comparatively trivial. Blender is a powerful application; it comes with a rich high-level API and an intuitive GUI that can be exploited jointly for sketching, animation, mesh reconstruction and even progressive rendering using third party plug-ins such as Cycles. However, it is limited in terms of the number of objects that can be drawn in the scene. For instance, spheres can only be visualized based on explicit geometry (polygonal meshes) using UV spheres or icospheres; they cannot be represented by implicit geometry like signed distance functions (<xref rid="btaa461-B22" ref-type="bibr">Karlsson <italic>et al.</italic>, 2019</xref>; <xref rid="btaa461-B25" ref-type="bibr">Lichtenberg <italic>et al.</italic>, 2019</xref>). This representation impacts the total number of independent sphere objects that can be drawn in the scene.</p>
      <p>The fundamental objective of <italic>VessMorphoVis</italic> is to allow neuroscientists and modelers to load, optimize and interactively visualize large-scale vascular networks that can have several millions of traced samples. Visualizing the connectivity of these networks using the most straightforward approach requires drawing each element in the morphology (segment or section) using a unique polyline object. This object can be referenced later to assign a different property to it, e.g. a color code, that maps its radius or any other vascular property given by the user. This entails creating a geometric primitive per element and then linking it to the scene. This approach is not scalable; it can only be used to draw hundreds of polylines at most. Trying to go beyond this limit results in a non-responsive application which ultimately reduces its usability. The vascular network graph is highly interconnected and can contain up to tens of millions of samples if reconstructed at single capillary level (<xref rid="btaa461-B12" ref-type="bibr">Di Giovanna <italic>et al.</italic>, 2018</xref>). Therefore, we had to investigate a radically different approach capable of reconstructing the same polyline geometry and drawing millions of samples in few seconds. We then developed several skeleton builders to visualize vasculature morphologies in various styles, making it possible to visually analyze their structure (e.g. how each section is sampled and whether there is an overlapping between or within the sections or not) and the connectivity between its different components (segments or sections—refer to <xref ref-type="fig" rid="btaa461-F1">Fig. 1</xref>). <xref ref-type="fig" rid="btaa461-F2">Figure 2</xref> shows an exemplar vascular morphology visualized with the different builders.
</p>
      <fig id="btaa461-F2" orientation="portrait" position="float">
        <label>Fig. 2.</label>
        <caption>
          <p><italic>VessMorphoVis</italic> implements different algorithms for visualizing vascular networks. The outline of the morphology is sketched in (<bold>A</bold>) using thin polylines and tiny spheres to represent the sections and samples of the morphology, respectively. In (<bold>B</bold>), the morphology is illustrated by a list of points showing only the individual samples without any connectivity. The morphology is visualized as a disconnected set of segments and sections using the same color in (<bold>C</bold>) and (<bold>F</bold>), with alternating colors in (<bold>D</bold>) and (<bold>G</bold>) and also using transparent shaders in (<bold>E</bold>) and (<bold>H</bold>), respectively</p>
        </caption>
        <graphic xlink:href="btaa461f2"/>
      </fig>
      <sec>
        <title>2.4.1 Disconnected sections builder</title>
        <p>This builder converts each section in the morphology into a virtual polyline structure whose segments correspond to those composed by the section itself. The final morphology is constructed by creating all the polylines and combining them into a single object with which it gets linked to the scene to be drawn in the viewport only once. This approach allows to efficiently pack a giant number of polylines into a single object, which in turn makes it possible to visualize large and dense vascular networks as shown in <xref ref-type="supplementary-material" rid="sup1">Supplementary Figures S3 and S4</xref>. This builder does not require any section-to-section connectivity information; the segment-to-segment connectivity is sufficient, which is already granted by having ordered set of samples per section in the loaded skeleton.</p>
      </sec>
      <sec>
        <title>2.4.2 Disconnected segments builder</title>
        <p>This builder converts each segment in the morphology into a line. To build up on the implementation of the previous builder, this line is merely a polyline composed of two points. This builder is used to visualize how the segments are distributed along every section in the morphology. It is mainly exploited to debug morphologies containing oversampled sections where we can clearly remove unnecessary samples and preserve the spatial topology of the morphology.</p>
      </sec>
      <sec>
        <title>2.4.3 Connected sections builder</title>
        <p>In some cases, connected sections might have certain configurations leading to reconstructed objects with artifacts such as having clear gaps between its different polylines at their branching points. These issues are not <italic>visually</italic> pleasant when users are interested in creating closeup images of their skeletons. Consequently, we have extended the disconnected sections builder to resolve this issue and create morphologies with connected sections that exhibit natural branching. Nevertheless, this extension entails the presence of valid connectivity list between the different sections in the morphology. As explained, this list might be missing in some morphology files as it requires an extra step after segmenting the skeleton from its microscopy stack to be built. However, it could be easily constructed on-the-fly before building the polylines. If the branching samples have the same indices in the different sections they belong to, this connectivity list can be built by comparing the indices of the terminal samples on a per-section-basis. Otherwise, connectivity can be obtained by evaluating the Euclidean distance between the terminal samples. Once this connectivity list is computed, a long polyline is constructed per section starting from a parent section, passing through the section itself and ending at a child. Therefore, this building strategy will create multiple polylines for every section within the network. If a section is connected between two parent and two child sections, four polylines will be created. <xref ref-type="fig" rid="btaa461-F3">Figure 3</xref> shows the same morphology reconstructed with the disconnected and connected builders and how the central gap between two sections at the branching point is filled using the connected sections builder.
</p>
        <fig id="btaa461-F3" orientation="portrait" position="float">
          <label>Fig. 3.</label>
          <caption>
            <p>A close up showing how the connected sections builder is applied to visualize the morphology skeleton (right) to resolve any visual artifacts (gaps between sections) revealed by the disconnected sections builder (left)</p>
          </caption>
          <graphic xlink:href="btaa461f3"/>
        </fig>
      </sec>
      <sec>
        <title>2.4.4 Samples builder</title>
        <p>We also implemented another builder to construct the skeleton directly from its raw samples as a group of spheres, each of them has a center and radius matching a corresponding sample in the morphology. Blender has no implicit sphere representation; therefore, we based our implementation on an isotropic simplicial polyhedron approximating a sphere called icosphere. To maximally reduce the number of vertices, a subdivision of two is used to construct the icosphere. To accelerate building the entire skeleton, each icosphere is created relying on an internal mesh editing library in Blender called <italic>bmesh</italic>, i.e. all the icospheres are created and joined together into a single object before being linked to the scene (<xref rid="btaa461-B10" ref-type="bibr">Conlan, 2017</xref>). This visualization mode is selected to visualize the distribution of samples along each section in the morphology. Nevertheless, it is not advised to visualize dense skeletons as it becomes less efficient and cluttered as shown in <xref ref-type="supplementary-material" rid="sup1">Supplementary Figure S5</xref>.</p>
      </sec>
      <sec>
        <title>2.4.5 General features</title>
        <p>The morphology visualization module was integrated with a set of features that are generic and transparent to all the builders. These features include resampling the morphology skeleton, changing the tubular quality of the polylines or using spline interpolations to plot the polylines and several other features that are detailed in the documentation. Skeleton resampling is encouraged for two reasons. First of all, it removes any visual artifacts introduced from overlapping segments having different radii. Moreover, it eliminates all unnecessary samples along every section in the morphology, and therefore, optimizes the building process and makes the visualization further interactive. <xref ref-type="fig" rid="btaa461-F4">Figure 4</xref> shows the substantial differences between an original highly oversampled vascular morphology and an optimized one after the resampling process. A combined rendering of a small morphology before and after resampling is shown in <xref ref-type="supplementary-material" rid="sup1">Supplementary Figure S6</xref> to demonstrate how the resampling process affects the morphology.
</p>
        <fig id="btaa461-F4" orientation="portrait" position="float">
          <label>Fig. 4.</label>
          <caption>
            <p>(<bold>A</bold>) A highly oversampled (∼1.5 million samples) vascular network extracted from the cortex. Removing the unnecessary samples (<bold>B</bold> and <bold>C</bold>) without changing the connectivity of the morphology evidently improves the visual quality of the reconstructed morphology (<bold>D</bold> and <bold>E</bold>) and increases the rendering interactivity</p>
          </caption>
          <graphic xlink:href="btaa461f4"/>
        </fig>
        <p>The tubular surface of the polylines is reconstructed from interpolating a bevel object whose sides determine its cross-sectional shape and quality. We added an external parameter that allows users to control the number of sides of this bevel object, with minimum of 4 and maximum of 32 sides. Increasing the number of sides increases the geometry of the reconstructed polygons and, in turn, reduces the rendering performance. By default, we set this parameter to eight to balance between quality and interactivity, but we also expose this parameter to be controlled by users. This allows to load extremely large networks, where they can use 4 sides for interactive rendering and 16 sides for creating high-quality images. For the same reason, we added an option allowing the users to use spline interpolation to improve the visual quality of the reconstructed polylines. These features are illustrated on the exemplar morphology in <xref ref-type="fig" rid="btaa461-F5">Figure 5</xref>. In summary, <xref ref-type="supplementary-material" rid="sup1">Supplementary Videos S1–S3</xref> demonstrate how to use the morphology visualization module interactively.
</p>
        <fig id="btaa461-F5" orientation="portrait" position="float">
          <label>Fig. 5.</label>
          <caption>
            <p>Users can control the visual quality of the skeleton, choosing between highly optimized geometry (<bold>A</bold> and <bold>C</bold>) for global far views or high-quality reconstructions (<bold>B</bold> and <bold>D</bold>) for close up views. Morphology polylines are rendered using bevel objects with 4 and 16 sides in A and B, respectively. The piecewise segments of the polylines (C) might limit the visual quality in case of close ups; therefore, we added another parameter to use spline interpolation to smooth their curvature (D)</p>
          </caption>
          <graphic xlink:href="btaa461f5"/>
        </fig>
        <p>Certain CBF modeling experiments mandate visualizing some vascular properties per segment such as its length, diameter, pressure or flow (<xref rid="btaa461-B34" ref-type="bibr">Reichold <italic>et al.</italic>, 2009</xref>; <xref rid="btaa461-B39" ref-type="bibr">Smith <italic>et al.</italic>, 2019</xref>). Therefore, it was essential to implement different coloring schemes allowing the users to select between using a single color to visualize the entire morphology, or using alternating colors to see some structural aspects of the morphology—<xref ref-type="fig" rid="btaa461-F4">Figure 4C and E</xref>, or even use a high dynamic range colormap to reveal other functional aspects. We added another option that allows users to color every segment or section in the morphology according to a specific property defined by the user. This feature is demonstrated in <xref ref-type="fig" rid="btaa461-F6">Figure 6</xref>.
</p>
        <fig id="btaa461-F6" orientation="portrait" position="float">
          <label>Fig. 6.</label>
          <caption>
            <p>Users can assign a color map to reveal the spatial distribution of the radii of all the segments in the morphology</p>
          </caption>
          <graphic xlink:href="btaa461f6"/>
        </fig>
      </sec>
    </sec>
    <sec>
      <label>2.5</label>
      <title>Polygonal mesh reconstruction</title>
      <p>Packing the vascular morphology as a list of polylines into a single object was essential for interactive visual analysis of dense vascular networks. Nevertheless, this polyline-based structure is limited in two aspects. First of all, it is merely convenient for visualization and structural validation purposes; it cannot be used to perform or even visualize stochastic reaction-diffusion simulations that entail highly accurate and optimized polygonal meshes associated with a color mapping scheme on a per-vertex basis. Furthermore, it can be only loaded in Blender which ultimately limits the usability of datasets beyond their visualization or analysis. Therefore, it was significant to integrate a mesh reconstruction module in <italic>VessMorphoVis</italic>, making it possible to build vascular surface meshes from their morphological skeletons, with which they can be used by other applications. In general, mesh generation of graph-based structures is known to be an offline process that might even take several hours based on the graph complexity, so the performance of this module was not a concern.</p>
      <p>We propose an offline, but highly accurate mesh generator based on implicit structures called metaobjects (<xref rid="btaa461-B30" ref-type="bibr">Oeltze and Preim, 2004</xref>; <xref rid="btaa461-B46" ref-type="bibr">Zoppè <italic>et al.</italic>, 2008</xref>) allowing to create high-fidelity vascular meshes from raw morphologies even without the necessity to have any section connectivity information in the morphology. Metaobjects are implicit surfaces defined procedurally. Unlike meshes that are composed of vertices or surfaces that are defined by control points, these objects are merely represented by mathematical functions that are computed on-the-fly. The fundamental feature that makes metaobjects significant is their ability to blend, i.e. when two independent metaobjects are getting closer to each other, they start to interact and blend together into a single object. We, based on metaobjects and in particular metaballs, propose an algorithm to reconstruct vasculature meshes—refer to <xref ref-type="supplementary-material" rid="sup1">Supplementary Figure S7</xref>. This algorithm is capable of handling highly complex branching scenarios avoiding to create intersecting geometry that is common in other meshing algorithms, e.g. skin modifiers (<xref rid="btaa461-B2" ref-type="bibr">Abdellah <italic>et al.</italic>, 2019</xref>).</p>
      <p>Generating a vasculature mesh from its morphological skeleton using metaballs requires three principal stages: (i) initializing the metaobject, (ii) building the metaobject structure on a per-section-basis and (iii) converting the metaobject into a target surface mesh. During the initialization stage, an empty metaobject of type bpy.data.metaball is created and linked to the scene. The initial resolution of this object is set to 1; however, this resolution will be modified in the finalization stage based on the radius of the smallest sample along the morphology skeleton to avoid reconstructing a fragmented mesh as shown in <xref ref-type="fig" rid="btaa461-F7">Figure 7</xref> and <xref ref-type="supplementary-material" rid="sup1">Supplementary Video S4</xref>.
</p>
      <fig id="btaa461-F7" orientation="portrait" position="float">
        <label>Fig. 7.</label>
        <caption>
          <p>A vasculature mesh created with the proposed metaballs implementation. The resolution of the metaobject is automatically set to 0.5 to create a highly tessellated mesh in (<bold>A</bold>). The meshes in (<bold>B</bold>), (<bold>C</bold>) and (<bold>D</bold>) are created with metaobject resolutions of 1.0, 2.0 and 4.0, respectively. These meshes have much fewer polygons than the original mesh in A, but their quality is degrading correspondingly. The small vessels and loops are not reconstructed in C and the large vessels are completely fragmented in D</p>
        </caption>
        <graphic xlink:href="btaa461f7"/>
      </fig>
      <p>Afterwards, the metaobject body is constructed on a per-section-basis, where each step converts a raw list of ordered samples that belong to the section to what is called a meta-section. During this step, each pair of connected samples along the section is used to create a meta-segment and append it to the metaobject using sphere marching. The segment length and direction are initially computed and then the spatial extent of the segment is filled with multiple interpolated points based on the radii and position vectors of the two samples of the segment until the traveled distance along the ray exceeds the segment length. The radius of the smallest sample in the morphology skeleton is computed during the building of each meta-section. At the finalization stage, this radius is used to set the actual resolution of the metaobject and then the metaobject is converted to a manifold surface mesh. The reconstructed mesh is tessellated or decimated to result in a smooth and non-bumpy surface and then linked to the rendering widget.</p>
      <p>It has to be noted that our implementation does not require the connectivity information between the sections. However, it assumes that the corresponding branching points of the connected sections are logically located at the same Cartesian positions even if they have different radii. The segment connectivity information per section is mandatory to be able to construct correct structures. <xref ref-type="supplementary-material" rid="sup1">Supplementary Figure S8</xref> shows a combined rendering of a reconstructed vascular mesh and its corresponding morphology for qualitative validation.</p>
      <p>The mesh generation time depends mainly on the size of the vascular morphology and the metaballs resolution used to build the mesh. Building meshes for morphologies with less than few thousands of samples at full resolution takes several hundreds of milliseconds to a few seconds. For a relatively larger dataset with 55 807 samples, we performed the meshing at three different resolutions. The mesh reconstruction process took 107.45, 6.37 and 2.49 s corresponding to metaball resolutions of 1, 2 and 3, respectively.</p>
    </sec>
    <sec>
      <label>2.6</label>
      <title>Mesh optimization</title>
      <p>The tessellation of the reconstructed meshes from the metaballs implementation is primarily based on the radius of the smallest sample along the skeleton. Consequently, the presence of relatively small samples would significantly impact the geometry of the mesh by creating very small polygons that are not necessarily essential to preserve the structure of the vascular network. By default, the resolution of the metaobject is obtained during the metaobject building process, and set at the finalization stage before converting the metaobject into a mesh. But, for convenience, we added another option that allows users to manually set the metaobject resolution. Although very useful for testing, inappropriate values of this parameter can result in highly fragmented mesh as obvious in <xref ref-type="fig" rid="btaa461-F7">Figure 7</xref>.</p>
      <p>To overcome this issue, we added another option to decimate the geometry allowing to create optimized meshes which could be used for several applications, e.g. real-time rendering or stochastic simulations. To avoid destructing the mesh, the decimation range exposed to the user is limited between 0.99 and 0.125. This range has been set based on trial-and-error. This allows users to create a mesh with decent size without sacrificing its quality by reducing the metaobject resolution. <xref ref-type="fig" rid="btaa461-F8">Figure 8</xref> demonstrates how a highly tessellated mesh with ∼68 000 polygons can be optimized to ∼17 000 polygons without any loss in visual quality. We can also notice that decimation factors beyond the 0.125 can introduce visual artifacts due to loss of topological detail.
</p>
      <fig id="btaa461-F8" orientation="portrait" position="float">
        <label>Fig. 8.</label>
        <caption>
          <p>Decimation is essential to reduce the tessellation of meshes with large polygon counts. At certain point, it can reduce the visual quality of the reconstructed mesh, but it does not fragment the mesh into several pieces. The mesh complexity (number of polygons) has been reduced 40 times and the branching is still preserved</p>
        </caption>
        <graphic xlink:href="btaa461f8"/>
      </fig>
      <p>There are different metrics that define mesh quality including its minimum and maximum dihedral angles, edge and radius ratios (<xref rid="btaa461-B17" ref-type="bibr">Hu <italic>et al.</italic>, 2018</xref>). Due to the nature of the metaobject algorithm itself, the topology of the resulting meshes is not optimized according to these metrics. We therefore have added another utility (implemented in the C code of Blender) to optimize any generated mesh according to these metrics based on an open source mesh optimization library (<xref rid="btaa461-B44" ref-type="bibr">Yu <italic>et al.</italic>, 2008</xref>). The resulting meshes from this optimization process are shown in <xref ref-type="fig" rid="btaa461-F9">Figure 9</xref>.
</p>
      <fig id="btaa461-F9" orientation="portrait" position="float">
        <label>Fig. 9.</label>
        <caption>
          <p>Mesh optimization. A mesh reconstructed from the metaballs implementation in (<bold>A</bold>) is optimized with two different decimation factors in (<bold>B</bold>) and (<bold>C</bold>)</p>
        </caption>
        <graphic xlink:href="btaa461f9"/>
      </fig>
    </sec>
    <sec>
      <label>2.7</label>
      <title>High-quality rendering and multimedia generation</title>
      <p>High-quality scientific illustrations are essential in any research process, but creating these illustrations requires a substantial amount of time and effort, deep knowledge of media design applications in addition to having individual artistic skills to a certain degree. Therefore, we have integrated an extra module in <italic>VessMorphoVis</italic> specifically designed to seamlessly create high-quality multimedia content that reveals the beauty of vascular networks. The rendering module is transparently connected to the morphology and meshing modules. It consists of a list of artistic shader nodes and light setups that are automatically configured to render scientific illustrations for vascular morphologies and their corresponding surface meshes including high-resolution static images and 360 sequences. These renderings are also helpful to debug the connectivity of the skeletons. <xref ref-type="supplementary-material" rid="sup1">Supplementary Videos S5 and S6</xref> show 360 sequences for two meshes of different network complexities. The rendering components including camera, lighting setup and the selection of the rendering engine itself are automatically added to the scene based on three items: (i) the rendering resolution (or scale), (ii) the selected shader (or material) and (iii) the type of the geometry that exists in the scene. The frustum of the camera is defined based on its projection type (whether orthographic or perspective) and the bounding box of the geometry that exist in the scene. Users can create two sets of images, either for debugging and analysis or for scientific articles media. The first set uses glossy shaders with the Workbench renderer, making it possible to create very high-resolution images in only few seconds. The other set uses physically based shaders with Cycles to create cinematic renderings (<xref rid="btaa461-B13" ref-type="bibr">Eid <italic>et al.</italic>, 2017</xref>) even for highly dense vascular networks. <xref ref-type="fig" rid="btaa461-F10">Figure 10</xref> shows a vascular mesh rendered with different types of shaders and rendering engines. <xref ref-type="supplementary-material" rid="sup1">Supplementary Figure S9</xref> shows other shading styles using a radius-based colormap.
</p>
      <fig id="btaa461-F10" orientation="portrait" position="float">
        <label>Fig. 10.</label>
        <caption>
          <p>The same mesh reconstructed with metaballs algorithm is rendered with four different shaders: <italic>glossy</italic>, <italic>flat</italic>, <italic>artistic bumby</italic> and <italic>artistic glossy</italic> in A, B, C and D, respectively, using the Workbench and Cycles renderes in Blender</p>
        </caption>
        <graphic xlink:href="btaa461f10"/>
      </fig>
    </sec>
  </sec>
  <sec>
    <label>3</label>
    <title>Discussion and experts feedback</title>
    <p><italic>VessMorphoVis</italic> is designed to be an open source and domain-specific software solution. It serves diverse categories of users, primarily neuroscience modeling researchers in addition to visualization specialists and scientific multimedia designers. For this reason, we based our implementation on Blender, exploiting its user-friendly GUI, well-documented Python API to accomplish multiple design goals. Starting from an input vascular morphology, users can analyze its graph using automated kernels and interactive visual inspection, allowing them to repair the morphology and then create an implicit representation that is converted into a surface mesh. This polygonal mesh is further optimized and can be used to reconstruct a tetrahedral mesh for simulating the CBF. Moreover, scientists can seamlessly create visualizations to debug the vascular network and render high-quality multimedia using ray tracing for scientific articles. <xref ref-type="fig" rid="btaa461-F11">Figure 11</xref> shows a high-quality rendering of a large mesh reconstructed from a very dense skeleton. The API was also designed taking into consideration extensibility, allowing researchers who have basic Python programming knowledge to implement certain custom features needed for their research purposes with minimal efforts.
</p>
    <fig id="btaa461-F11" orientation="portrait" position="float">
      <label>Fig. 11.</label>
      <caption>
        <p>A high-quality rendering of a large vasculature mesh reconstructed from a vascular graph having ∼2.1 million samples based on our metaballs implementation. The mesh is rendered using the artistic glossy shader with Cycles</p>
      </caption>
      <graphic xlink:href="btaa461f11"/>
    </fig>
    <p>To assess the overall performance, usability and impact of the add-on, we prepared a collection of vascular morphologies with varying size and complexity. Then, we presented the features of the tool to a group of domain experts. This group included neuroscientists working on computational modeling of brain vasculature, visualization researchers and also multimedia specialists whose mission is creating scientific illustrations of neuroscientific content with Blender. The users were asked to report their feedback indicating (i) points of strength and (ii) current limitations that can be improved, and (iii) other features that can be implemented to be helpful for their specific needs.</p>
    <p>The experimental feedback was largely positive and satisfactory. The scientists provided the following comments. The morphology builders are extremely insightful to verify several structural aspects of the vascular morphology and reveal certain inaccuracies of its graph including false loops, disconnected fragments, misaligned sections, incorrect branching and overlapping components. The automated analysis module is very helpful and efficient. A single user click creates an inclusive fact sheet summarizing different analysis results of the whole network. Further kernels can be effortlessly implemented to enhance the results. To them, resampling the skeleton without altering its spatial structure was substantial; several datasets are excessively oversampled and using those datasets without resampling in computational modeling increases the simulation time significantly. The design of the add-on is intuitive and even with no previous Blender experience, it can be used seamlessly. Every item on the interface comes with a clear tooltip documentation displayed upon mouse hover over the element. Moreover, designing a rich CLI to the add-on was as crucial as its GUI to allow its integration into other software pipelines, which would potentially magnify the impact of <italic>VessMorphoVis</italic>. The visualization and media specialists have mainly liked the integrity of the tool. The meshing and rendering modules were of significant value to them. It would be very helpful to create Blender scenes where they can apply further shading nodes to create outstanding multimedia.</p>
    <p>We then received several feature requests to further enhance the add-on functionality including (i) adding other coloring schemes to visualize more vascular properties, (ii) visualizing dynamic graphs to reveal changing structures over time to help <italic>in silico</italic> experimentalists to explore the impact of varying modeling parameters on the network, (iii) integrating another module allowing scientists to manually reconnect disconnected or fragmented pieces that were poorly segmented, (iv) adding support to visualize a region of interest selected from the GUI to focus on specific parts of the morphology and (v) finally, making the API callable from a web interface. Surprisingly, we were excited to see that other collaborators are willing and deeply interested to implement some of these requests by themselves to get to know more about the API.</p>
  </sec>
  <sec>
    <label>4</label>
    <title>Conclusion</title>
    <p>Vascular modeling efforts in the neuroscientific community are lacking domain-specific frameworks enabling interactive visual analysis of vast morphological networks of brain vasculature. <italic>VessMorphoVis</italic> is presented to fill this gap. Integrated in a single open source toolbox, this Blender add-on is capable of interactive visual analysis of vascular networks, synthesizing high-fidelity polygonal meshes from their morphologies and also creating high-quality scientific illustrations and sequences of these networks. The capabilities of the add-on were demonstrated on several vascular morphologies with varying sizes and complexity. We performed a set of user experiments to evaluate different aspects of the add-on including its performance, functionality and interface intuitiveness. We concluded from their feedback that our tool will be an essential component in vascular modeling and simulation in the future.</p>
  </sec>
  <sec>
    <title>Add-on Requirements</title>
    <p>VessMorphoVis is designed as a python add-on for Blender 2.80. The add-on depends only on the following software components: Blender and the python bindings of HDF5 and MorphIO.</p>
  </sec>
  <sec>
    <title>Data sources</title>
    <p>The vascular morphologies used in this paper are kindly provided by Bruno Weber, Institute of Pharmacologyand Toxicology –Experimental Imaging and Neuroenergetics, University of Zürich (UZH), Switzerland, Pablo Blinder, Department of Neurobiology, George S. Wise Faculty of Life Sciences, Tel Aviv University (TAU), Israel and David Kleinfeld, University of California at San Diego (UCSD), USA.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material content-type="local-data" id="sup1">
      <label>btaa461_Supplementary_Data</label>
      <media xlink:href="btaa461_supplementary_data.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ack id="ack1">
    <title>Acknowledgements</title>
    <p>We thank Stéphanie Battini, Alexis Arnaudon, Eleftherios Zisis and Pablo Blinder for their user feedback. We also thank Karin Holm, Alessandro Foni and Judit Planas for their valuable comments and suggestions.</p>
    <sec>
      <title>Funding</title>
      <p>This study was supported by funding to the Blue Brain Project, a research center of the École Polytechnique Fédérale de Lausanne (EPFL), from the Swiss Government’s ETH Board of the Swiss Federal Institutes of Technology.</p>
      <p><italic>Conflict of Interest</italic>: none declared.</p>
    </sec>
  </ack>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="btaa461-B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Abdellah</surname><given-names>M.</given-names></name></person-group><etal>et al</etal> (<year>2018</year>) 
<article-title>Neuromorphovis: a collaborative framework for analysis and visualization of neuronal morphology skeletons reconstructed from microscopy stacks</article-title>. <source>Bioinformatics</source>, <volume>34</volume>, <fpage>i574</fpage>–<lpage>i582</lpage>.<pub-id pub-id-type="pmid">29949998</pub-id></mixed-citation>
    </ref>
    <ref id="btaa461-B2">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Abdellah</surname><given-names>M.</given-names></name></person-group><etal>et al</etal> (<year>2019</year>) 
<article-title>Generating high fidelity surface meshes of neocortical neurons using skin modifiers. In: Vidal,F.P. <italic>et al</italic>. (eds), Computer Graphics and Visual Computing (CGVC), The Eurographics Association</article-title>.</mixed-citation>
    </ref>
    <ref id="btaa461-B3">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Antiga</surname><given-names>L.</given-names></name>, <name name-style="western"><surname>Steinman</surname><given-names>D.A.</given-names></name></person-group> (<year>2006</year>) <source>VMTK: Vascular Modeling Toolkit</source>. 
<publisher-name>VMTK</publisher-name>, 
<publisher-loc>San Francisco, CA, USA</publisher-loc>.</mixed-citation>
    </ref>
    <ref id="btaa461-B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Blinder</surname><given-names>P.</given-names></name></person-group><etal>et al</etal> (<year>2013</year>) 
<article-title>The cortical angiome: an interconnected vascular network with noncolumnar patterns of blood flow</article-title>. <source>Nat. Neurosci</source>., <volume>16</volume>, <fpage>889</fpage>–<lpage>897</lpage>.<pub-id pub-id-type="pmid">23749145</pub-id></mixed-citation>
    </ref>
    <ref id="btaa461-B5">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Bühler</surname><given-names>K.</given-names></name></person-group><etal>et al</etal> (<year>2004</year>) <chapter-title>Geometric methods for vessel visualization and quantification—a survey</chapter-title> In <source>Geometric Modeling for Scientific Visualization</source><publisher-name>, </publisher-name>pp. <fpage>399</fpage>–<lpage>419</lpage>. Springer, Berlin, Heidelberg.</mixed-citation>
    </ref>
    <ref id="btaa461-B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Calcinaghi</surname><given-names>N.</given-names></name></person-group><etal>et al</etal> (<year>2013</year>) 
<article-title>Multimodal imaging in rats reveals impaired neurovascular coupling in sustained hypertension</article-title>. <source>Stroke</source>, <volume>44</volume>, <fpage>1957</fpage>–<lpage>1964</lpage>.<pub-id pub-id-type="pmid">23735955</pub-id></mixed-citation>
    </ref>
    <ref id="btaa461-B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Calì</surname><given-names>C.</given-names></name></person-group><etal>et al</etal> (<year>2019</year>) 
<article-title>Sparse reconstruction of neurons and glial cells of layer vi somatosensory cortex of a juvenile rat</article-title>. <source>IBRO Rep</source>., <volume>6</volume>, <fpage>S383</fpage>–<lpage>S384</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa461-B8">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Coggan</surname><given-names>J.S.</given-names></name></person-group><etal>et al</etal> (<year>2018</year>a) 
<article-title>Norepinephrine stimulates glycogenolysis in astrocytes to fuel neurons with lactate</article-title>. <source>PLoS Comput. Biol</source>., <volume>14</volume>, <fpage>e1006392</fpage>.<pub-id pub-id-type="pmid">30161133</pub-id></mixed-citation>
    </ref>
    <ref id="btaa461-B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Coggan</surname><given-names>J.S.</given-names></name></person-group><etal>et al</etal> (<year>2018</year>b) 
<article-title>A process for digitizing and simulating biologically realistic oligocellular networks demonstrated for the neuro-glio-vascular ensemble</article-title>. <source>Front. Neurosci</source>., <volume>12</volume>, <fpage>664</fpage>.<pub-id pub-id-type="pmid">30319342</pub-id></mixed-citation>
    </ref>
    <ref id="btaa461-B10">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Conlan</surname><given-names>C.</given-names></name></person-group> (<year>2017</year>) <chapter-title>The bmesh module</chapter-title> In <source>The Blender Python API</source>, pp. <fpage>27</fpage>–<lpage>42</lpage>. Apress, Berkeley, CA.</mixed-citation>
    </ref>
    <ref id="btaa461-B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Damseh</surname><given-names>R.</given-names></name></person-group><etal>et al</etal> (<year>2019</year>) 
<article-title>Automatic graph-based modeling of brain microvessels captured with two-photon microscopy</article-title>. <source>IEEE J. Biomed. Health Inf</source>., <volume>23</volume>, <fpage>2551</fpage>–<lpage>2562</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa461-B12">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Di Giovanna</surname><given-names>A.P.</given-names></name></person-group><etal>et al</etal> (<year>2018</year>) 
<article-title>Whole-brain vasculature reconstruction at the single capillary level</article-title>. <source>Sci. Rep</source>., <volume>8</volume>, <fpage>12573</fpage>.<pub-id pub-id-type="pmid">30135559</pub-id></mixed-citation>
    </ref>
    <ref id="btaa461-B13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Eid</surname><given-names>M.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) 
<article-title>Cinematic rendering in CT: a novel, lifelike 3d visualization technique</article-title>. <source>Am. J. Roentgenol</source>., <volume>209</volume>, <fpage>370</fpage>–<lpage>379</lpage>.<pub-id pub-id-type="pmid">28504564</pub-id></mixed-citation>
    </ref>
    <ref id="btaa461-B14">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Eilemann</surname><given-names>S.</given-names></name></person-group><etal>et al</etal> (<year>2012</year>) Parallel rendering on hybrid multi-GPU clusters. In <italic>Eurographics Symposium on Parallel Graphics and Visualization</italic>, <italic>Number EPFL-CONF-216016</italic>, pp. <fpage>109</fpage>–<lpage>117</lpage>. The Eurographics Association, Cagliari, Italy.</mixed-citation>
    </ref>
    <ref id="btaa461-B15">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Frantellizzi</surname><given-names>V.</given-names></name></person-group><etal>et al</etal> (<year>2020</year>) 
<article-title>Neuroimaging in vascular cognitive impairment and dementia: a systematic review</article-title>. <source>J. Alzheimers Dis</source>., <volume>73</volume>, <fpage>1279</fpage>–<lpage>1294</lpage>.<pub-id pub-id-type="pmid">31929166</pub-id></mixed-citation>
    </ref>
    <ref id="btaa461-B16">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Henderson</surname><given-names>A.</given-names></name></person-group><etal>et al</etal> (<year>2004</year>) <source>The ParaView Guide</source>. 
<publisher-name>Kitware</publisher-name>, 
<publisher-loc>Clifton Park, NY, USA</publisher-loc>.</mixed-citation>
    </ref>
    <ref id="btaa461-B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Hu</surname><given-names>Y.</given-names></name></person-group><etal>et al</etal> (<year>2018</year>) 
<article-title>Tetrahedral meshing in the wild</article-title>. <source>ACM Trans. Graph</source>., <volume>37</volume>, <fpage>60</fpage>.</mixed-citation>
    </ref>
    <ref id="btaa461-B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Iadecola</surname><given-names>C.</given-names></name></person-group> (<year>2017</year>) 
<article-title>The neurovascular unit coming of age: a journey through neurovascular coupling in health and disease</article-title>. <source>Neuron</source>, <volume>96</volume>, <fpage>17</fpage>–<lpage>42</lpage>.<pub-id pub-id-type="pmid">28957666</pub-id></mixed-citation>
    </ref>
    <ref id="btaa461-B19">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Jährling</surname><given-names>N.</given-names></name></person-group><etal>et al</etal> (<year>2009</year>) 
<article-title>3D-reconstruction of blood vessels by ultramicroscopy</article-title>. <source>Organogenesis</source>, <volume>5</volume>, <fpage>227</fpage>–<lpage>230</lpage>.<pub-id pub-id-type="pmid">20539742</pub-id></mixed-citation>
    </ref>
    <ref id="btaa461-B20">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Januszewski</surname><given-names>M.</given-names></name></person-group><etal>et al</etal> (<year>2018</year>) 
<article-title>High-precision automated reconstruction of neurons with flood-filling networks</article-title>. <source>Nat. Methods</source>, <volume>15</volume>, <fpage>605</fpage>–<lpage>610</lpage>.<pub-id pub-id-type="pmid">30013046</pub-id></mixed-citation>
    </ref>
    <ref id="btaa461-B21">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Jolivet</surname><given-names>R.</given-names></name></person-group><etal>et al</etal> (<year>2015</year>) 
<article-title>Multi-timescale modeling of activity-dependent metabolic coupling in the neuron-glia-vasculature ensemble</article-title>. <source>PLoS Comput. Biol</source>., <volume>11</volume>, <fpage>e1004036</fpage>.<pub-id pub-id-type="pmid">25719367</pub-id></mixed-citation>
    </ref>
    <ref id="btaa461-B22">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Karlsson</surname><given-names>J.</given-names></name></person-group><etal>et al</etal> (<year>2019</year>) High fidelity visualization of large scale digitally reconstructed brain circuitry with signed distance functions. In: <italic>2019 IEEE Visualization Conference (VIS)</italic>, pp. <fpage>176</fpage>–<lpage>180</lpage>. IEEE, Vancouver, Canada.</mixed-citation>
    </ref>
    <ref id="btaa461-B23">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Kretschmer</surname><given-names>J.</given-names></name></person-group><etal>et al</etal> (<year>2013</year>) 
<article-title>Interactive patient-specific vascular modeling with sweep surfaces</article-title>. <source>IEEE Trans. Vis. Comput. Graph</source>., <volume>19</volume>, <fpage>2828</fpage>–<lpage>2837</lpage>.<pub-id pub-id-type="pmid">24051850</pub-id></mixed-citation>
    </ref>
    <ref id="btaa461-B24">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Kubisch</surname><given-names>C.</given-names></name></person-group><etal>et al</etal> (<year>2012</year>) <chapter-title>Vessel visualization with volume rendering</chapter-title> In <source>Visualization in Medicine and Life Sciences II</source>, pp. <fpage>109</fpage>–<lpage>132</lpage>. Springer, Berlin, Heidelberg.</mixed-citation>
    </ref>
    <ref id="btaa461-B25">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Lichtenberg</surname><given-names>N.</given-names></name></person-group><etal>et al</etal> (<year>2019</year>) 
<article-title>Distance field visualization and 2d abstraction of vessel tree structures with on-the-fly parameterization</article-title>.</mixed-citation>
    </ref>
    <ref id="btaa461-B26">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Logothetis</surname><given-names>N.K.</given-names></name></person-group><etal>et al</etal> (<year>2001</year>) 
<article-title>Neurophysiological investigation of the basis of the fMRI signal</article-title>. <source>Nature</source>, <volume>412</volume>, <fpage>150</fpage>–<lpage>157</lpage>.<pub-id pub-id-type="pmid">11449264</pub-id></mixed-citation>
    </ref>
    <ref id="btaa461-B27">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Lugo-Hernandez</surname><given-names>E.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) 
<article-title>3D visualization and quantification of microvessels in the whole ischemic mouse brain using solvent-based clearing and light sheet microscopy</article-title>. <source>J. Cereb. Blood Flow Metab</source>., <volume>37</volume>, <fpage>3355</fpage>–<lpage>3367</lpage>.<pub-id pub-id-type="pmid">28350253</pub-id></mixed-citation>
    </ref>
    <ref id="btaa461-B28">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Marín-Padilla</surname><given-names>M.</given-names></name></person-group> (<year>2012</year>) 
<article-title>The human brain intracerebral microvascular system: development and structure</article-title>. <source>Front. Neuroanat</source>., <volume>6</volume>, <fpage>38</fpage>.<pub-id pub-id-type="pmid">22993505</pub-id></mixed-citation>
    </ref>
    <ref id="btaa461-B29">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Markram</surname><given-names>H.</given-names></name></person-group><etal>et al</etal> (<year>2015</year>) 
<article-title>Reconstruction and simulation of neocortical microcircuitry</article-title>. <source>Cell</source>, <volume>163</volume>, <fpage>456</fpage>–<lpage>492</lpage>.<pub-id pub-id-type="pmid">26451489</pub-id></mixed-citation>
    </ref>
    <ref id="btaa461-B30">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Oeltze</surname><given-names>S.</given-names></name>, <name name-style="western"><surname>Preim</surname><given-names>B.</given-names></name></person-group> (<year>2004</year>) Visualization of anatomic tree structures with convolution surfaces. In: <italic>Joint EUROGRAPHICS - IEEE TCVG Symposium on Visualization (2004)</italic>, Eurographics. pp. <fpage>311</fpage>–<lpage>320</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa461-B31">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Pandey</surname><given-names>A.</given-names></name></person-group><etal>et al</etal> (<year>2020</year>) 
<article-title>Cerebrovis: designing an abstract yet spatially contextualized cerebral artery network visualization</article-title>. <source>IEEE Trans. Vis. Comput. Graph</source>., <volume>26</volume>, <fpage>938</fpage>–<lpage>948</lpage>.<pub-id pub-id-type="pmid">31545730</pub-id></mixed-citation>
    </ref>
    <ref id="btaa461-B32">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Preim</surname><given-names>B.</given-names></name>, <name name-style="western"><surname>Oeltze</surname><given-names>S.</given-names></name></person-group> (<year>2008</year>) <chapter-title>3D visualization of vasculature: an overview</chapter-title> In <source>Visualization in Medicine and Life Sciences</source>, pp. <fpage>39</fpage>–<lpage>59</lpage>. Springer, Berlin, Heidelberg.</mixed-citation>
    </ref>
    <ref id="btaa461-B33">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Raichle</surname><given-names>M.E.</given-names></name>, <name name-style="western"><surname>Mintun</surname><given-names>M.A.</given-names></name></person-group> (<year>2006</year>) 
<article-title>Brain work and brain imaging</article-title>. <source>Annu. Rev. Neurosci</source>., <volume>29</volume>, <fpage>449</fpage>–<lpage>476</lpage>.<pub-id pub-id-type="pmid">16776593</pub-id></mixed-citation>
    </ref>
    <ref id="btaa461-B34">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Reichold</surname><given-names>J.</given-names></name></person-group><etal>et al</etal> (<year>2009</year>) 
<article-title>Vascular graph model to simulate the cerebral blood flow in realistic vascular networks</article-title>. <source>J. Cereb. Blood Flow Metab</source>., <volume>29</volume>, <fpage>1429</fpage>–<lpage>1443</lpage>.<pub-id pub-id-type="pmid">19436317</pub-id></mixed-citation>
    </ref>
    <ref id="btaa461-B35">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Ritter</surname><given-names>F.</given-names></name></person-group><etal>et al</etal> (<year>2006</year>) 
<article-title>Real-time illustration of vascular structures</article-title>. <source>IEEE Trans. Vis. Comput. Graph</source>., <volume>12</volume>, <fpage>877</fpage>–<lpage>884</lpage>.<pub-id pub-id-type="pmid">17080812</pub-id></mixed-citation>
    </ref>
    <ref id="btaa461-B36">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Saha</surname><given-names>P.K.</given-names></name></person-group><etal>et al</etal> (<year>2016</year>) 
<article-title>A survey on skeletonization algorithms and their applications</article-title>. <source>Pattern Recognit. Lett</source>., <volume>76</volume>, <fpage>3</fpage>–<lpage>12</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa461-B37">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Schmid</surname><given-names>F.</given-names></name></person-group><etal>et al</etal> (<year>2019</year>) 
<article-title>Vascular density and distribution in neocortex</article-title>. <source>Neuroimage</source>, <volume>197</volume>, <fpage>792</fpage>–<lpage>805</lpage>.<pub-id pub-id-type="pmid">28669910</pub-id></mixed-citation>
    </ref>
    <ref id="btaa461-B38">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Schroeder</surname><given-names>W.J.</given-names></name></person-group><etal>et al</etal> (<year>2004</year>) <source>The Visualization Toolkit: An Object-Oriented Approach to 3D Graphics</source>. 
<publisher-name>Kitware</publisher-name>, 
<publisher-loc>Clifton Park, NY, USA</publisher-loc>.</mixed-citation>
    </ref>
    <ref id="btaa461-B39">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Smith</surname><given-names>A.F.</given-names></name></person-group><etal>et al</etal> (<year>2019</year>) 
<article-title>Brain capillary networks across species: a few simple organizational requirements are sufficient to reproduce both structure and function</article-title>. <source>Front. Physiol</source>., <volume>10</volume>, <fpage>233</fpage>.<pub-id pub-id-type="pmid">30971935</pub-id></mixed-citation>
    </ref>
    <ref id="btaa461-B40">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Sweeney</surname><given-names>M.D.</given-names></name></person-group><etal>et al</etal> (<year>2018</year>) 
<article-title>The role of brain vasculature in neurodegenerative disorders</article-title>. <source>Nat. Neurosci</source>., <volume>21</volume>, <fpage>1318</fpage>–<lpage>1331</lpage>.<pub-id pub-id-type="pmid">30250261</pub-id></mixed-citation>
    </ref>
    <ref id="btaa461-B41">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Taka</surname><given-names>S.J.</given-names></name>, <name name-style="western"><surname>Srinivasan</surname><given-names>S.</given-names></name></person-group> (<year>2011</year>) 
<article-title>Nirviz: 3D visualization software for multimodality optical imaging using visualization toolkit (VTK) and insight segmentation toolkit (ITK)</article-title>. <source>J. Digit. Imaging</source>, <volume>24</volume>, <fpage>1103</fpage>–<lpage>1111</lpage>.<pub-id pub-id-type="pmid">21274590</pub-id></mixed-citation>
    </ref>
    <ref id="btaa461-B42">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>von Bartheld</surname><given-names>C.S.</given-names></name></person-group><etal>et al</etal> (<year>2016</year>) 
<article-title>The search for true numbers of neurons and glial cells in the human brain: a review of 150 years of cell counting</article-title>. <source>J. Comp. Neurol</source>., <volume>524</volume>, <fpage>3865</fpage>–<lpage>3895</lpage>.<pub-id pub-id-type="pmid">27187682</pub-id></mixed-citation>
    </ref>
    <ref id="btaa461-B43">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Wright</surname><given-names>S.N.</given-names></name></person-group><etal>et al</etal> (<year>2013</year>) 
<article-title>Digital reconstruction and morphometric analysis of human brain arterial vasculature from magnetic resonance angiography</article-title>. <source>Neuroimage</source>, <volume>82</volume>, <fpage>170</fpage>–<lpage>181</lpage>.<pub-id pub-id-type="pmid">23727319</pub-id></mixed-citation>
    </ref>
    <ref id="btaa461-B44">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Yu</surname><given-names>Z.</given-names></name></person-group><etal>et al</etal> (<year>2008</year>) 
<article-title>Feature-preserving adaptive mesh generation for molecular shape modeling and simulation</article-title>. <source>J. Mol. Graph. Model</source>., <volume>26</volume>, <fpage>1370</fpage>–<lpage>1380</lpage>.<pub-id pub-id-type="pmid">18337134</pub-id></mixed-citation>
    </ref>
    <ref id="btaa461-B45">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Zeng</surname><given-names>Y-z.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) 
<article-title>Liver vessel segmentation and identification based on oriented flux symmetry and graph cuts</article-title>. <source>Comput. Methods Prog. Biomed</source>., <volume>150</volume>, <fpage>31</fpage>–<lpage>39</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa461-B46">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Zoppè</surname><given-names>M.</given-names></name></person-group><etal>et al</etal> (<year>2008</year>) Using blender for molecular animation and scientific representation. In Blender Conference. Amsterdam.</mixed-citation>
    </ref>
  </ref-list>
</back>
