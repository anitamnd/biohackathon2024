<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id>
    <journal-id journal-id-type="publisher-id">bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1367-4803</issn>
    <issn pub-type="epub">1367-4811</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">8756175</article-id>
    <article-id pub-id-type="pmid">34694333</article-id>
    <article-id pub-id-type="doi">10.1093/bioinformatics/btab737</article-id>
    <article-id pub-id-type="publisher-id">btab737</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Original Papers</subject>
        <subj-group subj-group-type="category-toc-heading">
          <subject>Structural Bioinformatics</subject>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI01060</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>DeepTrio: a ternary prediction system for protein–protein interaction using mask multiple parallel convolutional neural networks</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Hu</surname>
          <given-names>Xiaotian</given-names>
        </name>
        <aff><institution>Department of Bioinformatics, College of Life Sciences, Zhejiang University</institution>, Hangzhou 310058, <country country="CN">China</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Feng</surname>
          <given-names>Cong</given-names>
        </name>
        <aff><institution>Department of Bioinformatics, College of Life Sciences, Zhejiang University</institution>, Hangzhou 310058, <country country="CN">China</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Zhou</surname>
          <given-names>Yincong</given-names>
        </name>
        <aff><institution>Department of Bioinformatics, College of Life Sciences, Zhejiang University</institution>, Hangzhou 310058, <country country="CN">China</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Harrison</surname>
          <given-names>Andrew</given-names>
        </name>
        <aff><institution>Department of Mathematical Sciences, University of Essex</institution>, Colchester CO4 3SQ, <country country="GB">UK</country></aff>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-9677-1699</contrib-id>
        <name>
          <surname>Chen</surname>
          <given-names>Ming</given-names>
        </name>
        <xref rid="btab737-cor1" ref-type="corresp"/>
        <aff><institution>Department of Bioinformatics, College of Life Sciences, Zhejiang University</institution>, Hangzhou 310058, <country country="CN">China</country></aff>
        <aff><institution>Biomedical Big Data Center, the First Affiliated Hospital, Zhejiang University School of Medicine; Institute of Hematology, Zhejiang University</institution>, Hangzhou 310058, <country country="CN">China</country></aff>
        <!--mchen@zju.edu.cn-->
      </contrib>
    </contrib-group>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Martelli</surname>
          <given-names>Pier Luigi</given-names>
        </name>
        <role>Associate Editor</role>
      </contrib>
    </contrib-group>
    <author-notes>
      <corresp id="btab737-cor1">To whom correspondence should be addressed. <email>mchen@zju.edu.cn</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <day>01</day>
      <month>2</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2021-10-25">
      <day>25</day>
      <month>10</month>
      <year>2021</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>25</day>
      <month>10</month>
      <year>2021</year>
    </pub-date>
    <volume>38</volume>
    <issue>3</issue>
    <fpage>694</fpage>
    <lpage>702</lpage>
    <history>
      <date date-type="received">
        <day>09</day>
        <month>4</month>
        <year>2021</year>
      </date>
      <date date-type="rev-recd">
        <day>05</day>
        <month>10</month>
        <year>2021</year>
      </date>
      <date date-type="editorial-decision">
        <day>06</day>
        <month>10</month>
        <year>2021</year>
      </date>
      <date date-type="accepted">
        <day>20</day>
        <month>10</month>
        <year>2021</year>
      </date>
      <date date-type="corrected-typeset">
        <day>05</day>
        <month>11</month>
        <year>2021</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2021. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2021</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="btab737.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Motivation</title>
        <p>Protein–protein interaction (PPI), as a relative property, is determined by two binding proteins, which brings a great challenge to design an expert model with an unbiased learning architecture and a superior generalization performance. Additionally, few efforts have been made to allow PPI predictors to discriminate between relative properties and intrinsic properties.</p>
      </sec>
      <sec id="s2">
        <title>Results</title>
        <p>We present a sequence-based approach, DeepTrio, for PPI prediction using mask multiple parallel convolutional neural networks. Experimental evaluations show that DeepTrio achieves a better performance over several state-of-the-art methods in terms of various quality metrics. Besides, DeepTrio is extended to provide additional insights into the contribution of each input neuron to the prediction results.</p>
      </sec>
      <sec id="s3">
        <title>Availability and implementation</title>
        <p>We provide an online application at <ext-link xlink:href="http://bis.zju.edu.cn/deeptrio" ext-link-type="uri">http://bis.zju.edu.cn/deeptrio</ext-link>. The DeepTrio models and training data are deposited at <ext-link xlink:href="https://github.com/huxiaoti/deeptrio.git" ext-link-type="uri">https://github.com/huxiaoti/deeptrio.git</ext-link>.</p>
      </sec>
      <sec id="s5">
        <title>Supplementary information</title>
        <p><xref rid="sup1" ref-type="supplementary-material">Supplementary data</xref> are available at <italic toggle="yes">Bioinformatics</italic> online.</p>
      </sec>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>National Key Research and Development Program of China</institution>
            <institution-id institution-id-type="DOI">10.13039/501100012166</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>2016YFA0501704</award-id>
        <award-id>2018YFC0310602</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>National Natural Sciences Foundation of China</institution>
          </institution-wrap>
        </funding-source>
        <award-id>31771477</award-id>
        <award-id>32070677</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>151 Talent Project of Zhejiang Province</institution>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Jiangsu Collaborative Innovation Center for Modern Crop Production and Collaborative Innovation Center for Modern Crop Production cosponsored by province and ministry</institution>
          </institution-wrap>
        </funding-source>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="9"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 Introduction</title>
    <p>Various kinds of biological macromolecule interactions, especially protein–protein interactions (PPIs) (<xref rid="btab737-B13" ref-type="bibr">Jones and Thornton, 1996</xref>), play a fundamental role in biological information exchange, energy production and material transportation. A number of high-throughput and low-throughput experimental approaches, like yeast-two-hybrid purification followed by mass spectrometry (<xref rid="btab737-B19" ref-type="bibr">Lage, 2014</xref>), affinity capture-western, cocrystal structure analysis, bimolecular fluorescence complementation and biochemical modification analysis (<xref rid="btab737-B26" ref-type="bibr">Oughtred <italic toggle="yes">et al.</italic>, 2019</xref>), have been leveraged to identify PPIs. Thus, a tremendous number of PPIs have been identified and used to construct PPI databases, such as DIP (<xref rid="btab737-B31" ref-type="bibr">Salwinski <italic toggle="yes">et al.</italic>, 2004</xref>; <xref rid="btab737-B44" ref-type="bibr">Xenarios <italic toggle="yes">et al.</italic>, 2002</xref>), BioGRID (<xref rid="btab737-B26" ref-type="bibr">Oughtred <italic toggle="yes">et al.</italic>, 2019</xref>; <xref rid="btab737-B36" ref-type="bibr">Stark <italic toggle="yes">et al.</italic>, 2006</xref>) and STRING (<xref rid="btab737-B37" ref-type="bibr">Szklarczyk <italic toggle="yes">et al.</italic>, 2019</xref>), which makes it possible to identify PPIs in silico instead of the time-consuming and labor-intensive experimental methods.</p>
    <p>Traditionally, protein 3D structure has been regarded as an essential profile for PPI prediction. However, with the discovery of intrinsically disordered proteins whose spatial structures interconvert on a series of timescales (<xref rid="btab737-B40" ref-type="bibr">Uversky <italic toggle="yes">et al.</italic>, 2008</xref>), the protein 3D structure is no longer regarded as the only determinant of PPIs, and that the protein primary structure may offer more clues for PPI prediction. Since the protein sequence can be easily obtained by many inexpensive and time-saving experimental technologies or directly inferred from gene sequences, it has become the most accessible type of protein profiles. Currently, a variety of protein properties can be predicted using the protein sequences. Some of them only depend on the protein itself like solubility (intrinsic property), while others require the information from another object like PPI (relative property). However, there are few existing prediction methods consider PPI as a relative property.</p>
    <p>Many sequence-based machine learning methods have been developed for PPI prediction, such as Guo’s work (<xref rid="btab737-B10" ref-type="bibr">Guo <italic toggle="yes">et al.,</italic> 2008</xref>), Wang’s work (<xref rid="btab737-B43" ref-type="bibr">Wang <italic toggle="yes">et al.</italic>, 2018</xref>), DPPI (<xref rid="btab737-B11" ref-type="bibr">Hashemifar <italic toggle="yes">et al.</italic>, 2018</xref>), DNN-PPI (<xref rid="btab737-B21" ref-type="bibr">Li <italic toggle="yes">et al.</italic>, 2018</xref>), DeepFE-PPI (<xref rid="btab737-B46" ref-type="bibr">Yao <italic toggle="yes">et al.</italic>, 2019</xref>) and Protein–Protein Interaction Prediction Based on Siamese Residual RCNN (PIPR) (<xref rid="btab737-B4" ref-type="bibr">Chen <italic toggle="yes">et al.</italic>, 2019</xref>). Guo’s work (<xref rid="btab737-B10" ref-type="bibr">Guo <italic toggle="yes">et al.</italic>, 2008</xref>) curates seven physicochemical properties of amino acids (such as hydrophobicity, polarity and volumes of side chains) as protein feature descriptors. Each protein sequence is represented as seven vectors according to these descriptors. For a given protein sequence, auto covariance (AC) variables are used to describe the average interactions between residues throughout the whole sequence, and in downstream analysis, a support vector machine (SVM) (<xref rid="btab737-B5" ref-type="bibr">Cortes and Vapnik, 1995</xref>) is leveraged to determine whether the given proteins interact. DPPI (<xref rid="btab737-B11" ref-type="bibr">Hashemifar <italic toggle="yes">et al.</italic>, 2018</xref>) utilizes PSI-BLAST (<xref rid="btab737-B3" ref-type="bibr">Altschul <italic toggle="yes">et al.</italic>, 1997</xref>) to construct a comprehensive protein representation. DPPI incorporates a random projection module into the convolutional neural network (CNN) architecture, which projects the protein representations learned by the convolutional layers to two different vector spaces. The random projection module can help the model learn about the interaction potential of two input proteins. Finally, a linear transformation unit computes a probability value indicating whether two proteins interact in the prediction module. DeepFE-PPI (<xref rid="btab737-B46" ref-type="bibr">Yao <italic toggle="yes">et al.</italic>, 2019</xref>) exploits a novel residue representation method, Res2vec, to embed protein sequences, which may describe more precisely residue–residue interactions and supply more effective information for the downstream model. DeepFE-PPI employs the deep neural networks (DNN) as the learning architecture, and uses both a batch normalization module and a dropout module to prevent over-fitting. PIPR (<xref rid="btab737-B4" ref-type="bibr">Chen <italic toggle="yes">et al.</italic>, 2019</xref>) uses a pretrained semilatent vector to represent amino acids for capturing their contextual similarity and physicochemical properties. PIPR employs a residual recurrent convolutional neural network (RCNN) as the model architecture, and achieves the state-of-the-art performance for PPI prediction. In addition, PIPR is extended to contain three independent models for different application scenarios involving PPI prediction, interaction type prediction and binding affinity estimation.</p>
    <p>Although a growing number of PPI predictors have been proposed in recent years, there remains some room for improvement: (i) it can be beneficial for prediction if a model can consider PPI as a relative property rather than an intrinsic property; (ii) few efforts have been made to provide an intuitive description of the inner mechanism of pairwise-input neural networks and illustrate the effect of each amino acid residue on PPI.</p>
    <p>In this paper, we propose DeepTrio, a deep-learning framework based on a mask multiscale CNN architecture, in which multiple parallel filters provide valuable insights for PPI prediction by apprehending the multiscale contextual information of protein sequences. In comparison to existing tools, the main contributions of our work are: (i) an additional class, single-protein class, is introduced to our model, which allows DeepTrio to discriminate between the relative property and intrinsic property; (ii) due to the application of the single-protein class and masking operation, DeepTrio requires only one training set to build a model that can not only identify PPIs, but also further investigate the effect of each protein residue on PPI without any additional specific training; (iii) DeepTrio is also available as an online tool for inexperienced users in order to address the cross-platform usage and dependency related issues.</p>
  </sec>
  <sec>
    <title>2 Materials and methods</title>
    <p>Since PPI prediction is a binary classification task, most of the existing models are trained to classify the input data into two classes: interacting or noninteracting. However, we have designed DeepTrio for ternary prediction that takes as input a pair of protein sequences, and generates a three-dimensional vector output indicating the probability of interaction, noninteraction and single-protein. The overall framework of DeepTrio is illustrated in <xref rid="btab737-F1" ref-type="fig">Figure  1a</xref>. DeepTrio also employs a Siamese architecture, which involves two identical subnetworks sharing the same configuration and weights, to ensure that two input sequences are represented and analyzed equally. In addition, DeepTrio can calculate the importance score for each residue by using the masking method.</p>
    <fig position="float" id="btab737-F1">
      <label>Fig. 1.</label>
      <caption>
        <p>Details of the DeepTrio framework. (<bold>a</bold>) The development flowchart of DeepTrio. (<bold>b</bold>) Masking operation for three different purposes: generating single-protein cases, calculating the effect of each residue on PPI and padding the short sequences. (<bold>c</bold>) The strategy for constructing BioGRID negative datasets. Given an interacting protein pair <inline-formula id="IE1"><mml:math id="IM1" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">A</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula id="IE2"><mml:math id="IM2" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">B</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, we randomly choose one protein (e.g. <inline-formula id="IE3"><mml:math id="IM3" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">B</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>) from them, and then shuffle its sequence with 2-let counts (excluding the first residue) to get a novel protein <inline-formula id="IE4"><mml:math id="IM4" display="inline" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">B</mml:mi></mml:mrow><mml:mrow><mml:mi>′</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula>. A negative sample is generated by pairing <inline-formula id="IE5"><mml:math id="IM5" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">A</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula id="IE6"><mml:math id="IM6" display="inline" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">B</mml:mi></mml:mrow><mml:mrow><mml:mi>′</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula></p>
      </caption>
      <graphic xlink:href="btab737f1" position="float"/>
    </fig>
    <sec>
      <title>2.1 Data collection</title>
      <p>There are four datasets used for training and testing the models in this study. Two datasets are derived from the Biological General Repository for Interaction Datasets (BioGRID) (<xref rid="btab737-B26" ref-type="bibr">Oughtred <italic toggle="yes">et al.</italic>, 2019</xref>), and the other two datasets are derived from the database of interacting proteins (DIP) (<xref rid="btab737-B31" ref-type="bibr">Salwinski <italic toggle="yes">et al.</italic>, 2004</xref>; <xref rid="btab737-B44" ref-type="bibr">Xenarios <italic toggle="yes">et al.</italic>, 2002</xref>).</p>
      <sec>
        <title>2.1.1 BioGRID multivalidated physical interaction data</title>
        <p>The BioGRID database (<xref rid="btab737-B26" ref-type="bibr">Oughtred <italic toggle="yes">et al.</italic>, 2019</xref>) is a comprehensive, specialized database for PPIs derived from multiple major species, whose multivalidated physical interaction subsets curate PPIs according to the criteria by which the interacting pairs must be validated in at least two different experimental systems or two different publication sources. Since the <italic toggle="yes">Saccharomyces cerevisiae</italic> (yeast) and <italic toggle="yes">Homo sapiens</italic> (human) data are widely used to evaluate the performance of PPI predictors (<xref rid="btab737-B4" ref-type="bibr">Chen <italic toggle="yes">et al.</italic>, 2019</xref>; <xref rid="btab737-B10" ref-type="bibr">Guo <italic toggle="yes">et al.</italic>, 2008</xref>; <xref rid="btab737-B11" ref-type="bibr">Hashemifar <italic toggle="yes">et al.</italic>, 2018</xref>; <xref rid="btab737-B46" ref-type="bibr">Yao <italic toggle="yes">et al.</italic>, 2019</xref>), we use the human and yeast multivalidated physical interaction datasets in BioGRID as the benchmarks for training and evaluating. The protein sequences are retrieved from the UniProt (<xref rid="btab737-B39" ref-type="bibr">UniProt Consortium, 2019</xref>) and restricted in length to a minimum of 150 and a maximum of 1500 residues. The human dataset involves 7705 proteins forming 31 164 positive cases and the yeast dataset contains 3553 proteins forming 13 462 positive cases. Following the same strategy as PIPR, we use CD-HIT (<xref rid="btab737-B8" ref-type="bibr">Fu <italic toggle="yes">et al.</italic>, 2012</xref>; <xref rid="btab737-B22" ref-type="bibr">Li and Godzik, 2006</xref>) to decrease sequence redundancy of the datasets, in which two PPIs are considered similar if they share a sequence identity greater than 40%.</p>
        <p>The negative samples in these two benchmarks are generated by shuffling one sequence of a positive case with 2-let counts (excluding the first residue of the protein) (<xref rid="btab737-F1" ref-type="fig">Fig.  1c</xref>). It has been demonstrated that the possibility of interaction can be deemed negligible if a sequence of one interacting pair is shuffled (<xref rid="btab737-B15" ref-type="bibr">Kandel <italic toggle="yes">et al.</italic>, 1996</xref>). Additionally, the shuffled sequence retains the same amino acid composition and approximately the same di-peptide frequencies as the original sequence.</p>
      </sec>
      <sec>
        <title>2.1.2 <italic toggle="yes">Saccharomyces cerevisiae</italic> core data</title>
        <p>The <italic toggle="yes">S.cerevisiae</italic> core dataset, as a widely used benchmark, is composed of 11 188 PPI cases including 5594 positive cases proposed by <xref rid="btab737-B10" ref-type="bibr">Guo <italic toggle="yes">et al.</italic> (2008)</xref> and a heterogeneous set of 5594 negative cases according to different papers. The positive cases are selected from the DIP database (<xref rid="btab737-B31" ref-type="bibr">Salwinski <italic toggle="yes">et al.</italic>, 2004</xref>; <xref rid="btab737-B44" ref-type="bibr">Xenarios <italic toggle="yes">et al.</italic>, 2002</xref>), where proteins shorter than 50 amino acids and sharing ≥40% sequence identity are removed. The negative cases in these datasets are generated by randomly pairing the proteins without obvious evidence of interaction. However, there are some differences between the <italic toggle="yes">S.cerevisiae</italic> positive sets from DeepFE-PPI and PIPR, so we use both of the <italic toggle="yes">S.cerevisiae</italic> datasets to train and test DeepTrio and other baseline approaches.</p>
      </sec>
      <sec>
        <title>2.1.3 Single-protein data</title>
        <p>The single-protein case consists of two components: a normal protein sequence and a masked sequence whose all residues are masked by blank bits (<xref rid="btab737-F1" ref-type="fig">Fig.  1b</xref>). Each unique sequence in the positive and negative datasets corresponds to one case in the single-protein set. This set is designed for relieving the obscure influence caused by the relative property and preventing the potential weight polarization in the intermediary layers. The way we train single-protein data are the same as the positive and negative cases. Note that this set is only used for training DeepTrio, and does not participate in the evaluation for DeepTrio.</p>
      </sec>
    </sec>
    <sec>
      <title>2.2 Protein feature encoder</title>
      <p>DeepTrio employs a Siamese architecture with the multiple parallel convolution (multiscale convolution) module to capture various protein features in multiscale windows. It takes as input a protein pair (<inline-formula id="IE7"><mml:math id="IM7" display="inline" overflow="scroll"><mml:mi mathvariant="bold">X</mml:mi></mml:math></inline-formula>, <inline-formula id="IE8"><mml:math id="IM8" display="inline" overflow="scroll"><mml:msup><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">′</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula><bold>)</bold>, and yields two protein representations (<inline-formula id="IE9"><mml:math id="IM9" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi mathvariant="bold">H</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">conc</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi> </mml:mi><mml:msub><mml:mrow><mml:mi mathvariant="bold">H</mml:mi><mml:mi mathvariant="bold">'</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">conc</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:msub></mml:math></inline-formula>) for downstream analysis (<xref rid="btab737-F2" ref-type="fig">Fig.  2</xref>).</p>
      <fig position="float" id="btab737-F2">
        <label>Fig. 2.</label>
        <caption>
          <p>DeepTrio overall architecture. The protein sequences are converted into liquid-like tensors by a tunable embedding module. The container-like layers of different size constantly shape the flowing tensors, where <inline-formula id="IE10"><mml:math id="IM10" display="inline" overflow="scroll"><mml:mi>Z</mml:mi></mml:math></inline-formula> is the number of samples in a batch</p>
        </caption>
        <graphic xlink:href="btab737f2" position="float"/>
      </fig>
      <sec>
        <title>2.2.1 Single-protein data</title>
        <p>The input protein sequence is projected into a sparse orthonormal vector space by performing one-hot encoding transformation in the input module. For two input proteins <inline-formula id="IE11"><mml:math id="IM11" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">A</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula id="IE12"><mml:math id="IM12" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">B</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, each of them is transformed into a binary matrix <inline-formula id="IE13"><mml:math id="IM13" display="inline" overflow="scroll"><mml:mi mathvariant="bold">X</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mo>×</mml:mo><mml:mn>23</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> as follows:
<disp-formula id="E1"><mml:math id="M1" display="block" overflow="scroll"><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:maligngroup/><mml:mi>X</mml:mi><mml:mo>=</mml:mo><mml:mfenced open="[" close="]" separators="|"><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:maligngroup/><mml:msub><mml:mrow><mml:mi> </mml:mi><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:maligngroup/><mml:mo>⋮</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:maligngroup/><mml:msub><mml:mrow><mml:mi> </mml:mi><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:maligngroup/><mml:mo>⋮</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:maligngroup/><mml:msub><mml:mrow><mml:mi> </mml:mi><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mfenced><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>where <inline-formula id="IE14"><mml:math id="IM14" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>×</mml:mo><mml:mn>23</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> (<inline-formula id="IE15"><mml:math id="IM15" display="inline" overflow="scroll"><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi mathvariant="normal"> </mml:mi><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>L</mml:mi></mml:math></inline-formula>) is a binary vector of length 23 (22 for the proteinogenic amino acids and 1 for the mask bit) corresponding to the <inline-formula id="IE16"><mml:math id="IM16" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">th</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> amino acid residue in a sequence, and <inline-formula id="IE17"><mml:math id="IM17" display="inline" overflow="scroll"><mml:mi>L</mml:mi></mml:math></inline-formula> is fixed to 1500. A trainable embedding weight matrix <inline-formula id="IE18"><mml:math id="IM18" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi mathvariant="bold">W</mml:mi></mml:mrow><mml:mrow><mml:mi>e</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mn>23</mml:mn><mml:mo>×</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> (optimized by backpropagation) is used to map <inline-formula id="IE19"><mml:math id="IM19" display="inline" overflow="scroll"><mml:mi mathvariant="bold">X</mml:mi></mml:math></inline-formula> to a dense continuous vector space by the following equation:
<disp-formula id="E2"><mml:math id="M2" display="block" overflow="scroll"><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:maligngroup/><mml:mi>E</mml:mi><mml:mo>=</mml:mo><mml:mi>X</mml:mi><mml:msub><mml:mrow><mml:mi mathvariant="bold">W</mml:mi></mml:mrow><mml:mrow><mml:mi>e</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>where <inline-formula id="IE20"><mml:math id="IM20" display="inline" overflow="scroll"><mml:mi mathvariant="bold">E</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mo>×</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> is the embedded representation of one input protein and <inline-formula id="IE21"><mml:math id="IM21" display="inline" overflow="scroll"><mml:mi>d</mml:mi></mml:math></inline-formula> is the feature dimension of the amino acid symbol lexicon.</p>
      </sec>
      <sec>
        <title>2.2.2 Masking module</title>
        <p>A Boolean matrix, <inline-formula id="IE22"><mml:math id="IM22" display="inline" overflow="scroll"><mml:mi mathvariant="bold">B</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mo>×</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula>, will be attached to the embedded representation <inline-formula id="IE23"><mml:math id="IM23" display="inline" overflow="scroll"><mml:mi mathvariant="bold">E</mml:mi></mml:math></inline-formula> in this module, which eliminates the masked residues from the calculation in the downstream modules. This operation will be called in three scenarios (<xref rid="btab737-F1" ref-type="fig">Fig.  1b</xref>):
</p>
        <list list-type="roman-lower">
          <list-item>
            <p>The length of protein sequences is fixed to 1500. Thus, the shorter sequences will be padded with mask bits.</p>
          </list-item>
          <list-item>
            <p>In the single-protein case, the whole sequence of one of the proteins is masked by mask bits. Thus, there is only one protein participating in the calculation of the deep-learning model when the single-protein case is inputted.</p>
          </list-item>
          <list-item>
            <p>When DeepTrio investigates the effect of a particular residue <inline-formula id="IE24"><mml:math id="IM24" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> on PPI, a mask bit will be attached to this residue, which blocks the calculation of <inline-formula id="IE25"><mml:math id="IM25" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> in the downstream layers.</p>
          </list-item>
        </list>
      </sec>
      <sec>
        <title>2.2.3 Multiple parallel convolutional module with pooling</title>
        <p>The embedded representation <inline-formula id="IE26"><mml:math id="IM26" display="inline" overflow="scroll"><mml:mi mathvariant="bold">E</mml:mi></mml:math></inline-formula> is analyzed by <inline-formula id="IE27"><mml:math id="IM27" display="inline" overflow="scroll"><mml:mi>N</mml:mi></mml:math></inline-formula> parallel convolution filters with <inline-formula id="IE28"><mml:math id="IM28" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> (<inline-formula id="IE29"><mml:math id="IM29" display="inline" overflow="scroll"><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi mathvariant="normal"> </mml:mi><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>N</mml:mi></mml:math></inline-formula>) kernels (<xref rid="btab737-F2" ref-type="fig">Fig.  2</xref>). Each convolution filter extracts a certain specific aspect of protein profiles and outputs as follows:
<disp-formula id="E3"><mml:math id="M3" display="block" overflow="scroll"><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:maligngroup/><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">T</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:munderover><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munderover><mml:mrow><mml:mrow><mml:munderover><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>m</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup><mml:mo>×</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">E</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mfenced separators="|"><mml:mrow><mml:mi>k</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfenced><mml:mo>×</mml:mo><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>where <inline-formula id="IE30"><mml:math id="IM30" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula id="IE31"><mml:math id="IM31" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> denote the length of the convolution window and stride in the <inline-formula id="IE32"><mml:math id="IM32" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">th</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> convolution filter, respectively. The output <inline-formula id="IE33"><mml:math id="IM33" display="inline" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">T</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup></mml:math></inline-formula> (<inline-formula id="IE34"><mml:math id="IM34" display="inline" overflow="scroll"><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi mathvariant="normal"> </mml:mi><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mfrac><mml:mrow><mml:mi>L</mml:mi><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:math></inline-formula>) is the <inline-formula id="IE35"><mml:math id="IM35" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">th</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> interior element in the <inline-formula id="IE36"><mml:math id="IM36" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">th</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> row of the <inline-formula id="IE37"><mml:math id="IM37" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">th</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> convolution filter, <inline-formula id="IE38"><mml:math id="IM38" display="inline" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>m</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup></mml:math></inline-formula> is the <inline-formula id="IE39"><mml:math id="IM39" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">th</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> interior element in <inline-formula id="IE40"><mml:math id="IM40" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">th</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> row of the <inline-formula id="IE41"><mml:math id="IM41" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">th</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> kernel in the <inline-formula id="IE42"><mml:math id="IM42" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">th</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> convolution filter, and <inline-formula id="IE43"><mml:math id="IM43" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi mathvariant="bold">E</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is the <inline-formula id="IE44"><mml:math id="IM44" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">th</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> interior element in <inline-formula id="IE45"><mml:math id="IM45" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mi>k</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="normal">th</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> row of the embedded matrix <inline-formula id="IE46"><mml:math id="IM46" display="inline" overflow="scroll"><mml:mi mathvariant="bold">E</mml:mi></mml:math></inline-formula>. Note that the bias calculation is not applied to the convolution calculation.</p>
        <p>The filter outputs are activated by the rectified linear unit (ReLU) (<xref rid="btab737-B45" ref-type="bibr">Xu <italic toggle="yes">et al.</italic>, 2015</xref>) and yield a set of feature maps, <inline-formula id="IE47"><mml:math id="IM47" display="inline" overflow="scroll"><mml:mo>{</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">A</mml:mi></mml:mrow><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msup><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>L</mml:mi><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfenced><mml:mo>×</mml:mo><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi mathvariant="normal"> </mml:mi><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>N</mml:mi><mml:mo>}</mml:mo></mml:math></inline-formula>, which are calculated as follows:
<disp-formula id="E4"><mml:math id="M4" display="block" overflow="scroll"><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:maligngroup/><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">A</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mi>ReLU</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">T</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>where <inline-formula id="IE48"><mml:math id="IM48" display="inline" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">A</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup></mml:math></inline-formula> is the <inline-formula id="IE49"><mml:math id="IM49" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">th</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> interior element in the <inline-formula id="IE50"><mml:math id="IM50" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">th</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> row of <inline-formula id="IE51"><mml:math id="IM51" display="inline" overflow="scroll"><mml:msup><mml:mrow><mml:mi mathvariant="bold">A</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula>. After obtaining these feature maps, a global max-pooling operation is performed for reducing the dimension of feature maps and highlighting the most significant features. The max-pooling output <inline-formula id="IE52"><mml:math id="IM52" display="inline" overflow="scroll"><mml:msup><mml:mrow><mml:mi mathvariant="bold">H</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>×</mml:mo><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:math></inline-formula> (for the <inline-formula id="IE53"><mml:math id="IM53" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">th</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> convolution filter) is given by
<disp-formula id="E5"><mml:math id="M5" display="block" overflow="scroll"><mml:mtable><mml:mtr><mml:mtd><mml:msubsup><mml:mi mathvariant="bold-italic">h</mml:mi><mml:mi>m</mml:mi><mml:mfenced separators="|"><mml:mi>n</mml:mi></mml:mfenced></mml:msubsup><mml:mo>=</mml:mo><mml:mi>max</mml:mi><mml:mo>⁡</mml:mo><mml:mfenced separators="|"><mml:mrow><mml:msubsup><mml:mi mathvariant="bold">A</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>m</mml:mi></mml:mrow><mml:mfenced separators="|"><mml:mi>n</mml:mi></mml:mfenced></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi mathvariant="bold">A</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mi>m</mml:mi></mml:mrow><mml:mfenced separators="|"><mml:mi>n</mml:mi></mml:mfenced></mml:msubsup><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msubsup><mml:mi mathvariant="bold">A</mml:mi><mml:mrow><mml:mfrac><mml:mrow><mml:mi>L</mml:mi><mml:mo>-</mml:mo><mml:msub><mml:mi>l</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mfrac><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>m</mml:mi></mml:mrow><mml:mfenced separators="|"><mml:mi>n</mml:mi></mml:mfenced></mml:msubsup></mml:mrow></mml:mfenced><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>
 <disp-formula id="E6"><mml:math id="M6" display="block" overflow="scroll"><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:maligngroup/><mml:msup><mml:mrow><mml:mi mathvariant="bold">H</mml:mi></mml:mrow><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mfenced separators="|"><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">h</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">h</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">h</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">h</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>where <inline-formula id="IE54"><mml:math id="IM54" display="inline" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">h</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup></mml:math></inline-formula> is the <inline-formula id="IE55"><mml:math id="IM55" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">th</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> element of <inline-formula id="IE56"><mml:math id="IM56" display="inline" overflow="scroll"><mml:msup><mml:mrow><mml:mi mathvariant="bold">H</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula>. Next, we flatten and concatenate all the <inline-formula id="IE57"><mml:math id="IM57" display="inline" overflow="scroll"><mml:msup><mml:mrow><mml:mi mathvariant="bold">H</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> (<inline-formula id="IE58"><mml:math id="IM58" display="inline" overflow="scroll"><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mi>N</mml:mi></mml:math></inline-formula>) to get a new row vector <inline-formula id="IE59"><mml:math id="IM59" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi mathvariant="bold">H</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">conc</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>×</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula>:
<disp-formula id="E7"><mml:math id="M7" display="block" overflow="scroll"><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:maligngroup/><mml:msub><mml:mrow><mml:mi mathvariant="bold">H</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">conc</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfenced open="[" close="]" separators="|"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">H</mml:mi></mml:mrow><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:mfenced></mml:mrow></mml:msup><mml:mo>;</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">H</mml:mi></mml:mrow><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfenced></mml:mrow></mml:msup><mml:mo>;</mml:mo><mml:mo>…</mml:mo><mml:mo>;</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">H</mml:mi></mml:mrow><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msup></mml:mrow></mml:mfenced><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p>
      </sec>
    </sec>
    <sec>
      <title>2.3 Prediction and learning objectives</title>
      <p>Two max-pooling outputs generated by the aforementioned modules are first merged into one vector, and then passed into the dense layers to calculate the probability value for PPI. The learning architecture is trained to optimize the cross-entropy loss between predictions and targets by backpropagation with AMSGrad algorithm (<xref rid="btab737-B30" ref-type="bibr">Reddi <italic toggle="yes">et al</italic>., 2019</xref>).</p>
      <sec>
        <title>2.3.1 Prediction module</title>
        <p>Two max-pooling outputs, <inline-formula id="IE60"><mml:math id="IM60" display="inline" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">H</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">conc</mml:mi><mml:mo>.</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="normal">A</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula> and <inline-formula id="IE61"><mml:math id="IM61" display="inline" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">H</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">conc</mml:mi><mml:mo>.</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="normal">B</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula>, given by the two subnetworks (sharing the same configuration and weights), are combined via element-wise addition and transformed into a merged vector <inline-formula id="IE62"><mml:math id="IM62" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi mathvariant="bold">H</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">merged</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>×</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula>. Compared with the element-wise multiplication, the addition operation prevents <inline-formula id="IE63"><mml:math id="IM63" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi mathvariant="bold">H</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">merged</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> being a zero-vector when the single-protein case is inputted. The merged vector <inline-formula id="IE64"><mml:math id="IM64" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi mathvariant="bold">H</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">merged</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is first passed through two dense layers, and then normalized by the softmax function as follows:
<disp-formula id="E8"><mml:math id="M8" display="block" overflow="scroll"><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:maligngroup/><mml:mi>F</mml:mi><mml:mo>=</mml:mo><mml:mi>ReLU</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="normal">ReLU</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">H</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">merged</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="bold">W</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:msub><mml:mrow><mml:mi mathvariant="bold">W</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>
 <disp-formula id="E9"><mml:math id="M9" display="block" overflow="scroll"><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:maligngroup/><mml:msub><mml:mrow><mml:mi mathvariant="bold">c</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>σ</mml:mo><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">F</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">exp</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">F</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:munderover><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:munderover><mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">exp</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">F</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>where <inline-formula id="IE65"><mml:math id="IM65" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi mathvariant="bold">W</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mo>×</mml:mo><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:math></inline-formula>, <inline-formula id="IE66"><mml:math id="IM66" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi mathvariant="bold">W</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>×</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> are the weight matrices of the first and the second dense layers, respectively. The <inline-formula id="IE67"><mml:math id="IM67" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">th</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> dimension of <inline-formula id="IE68"><mml:math id="IM68" display="inline" overflow="scroll"><mml:mi mathvariant="bold">c</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>×</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> corresponds to the confidence score, <inline-formula id="IE69"><mml:math id="IM69" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi mathvariant="bold">c</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:mo>[</mml:mo><mml:mn>0,1</mml:mn><mml:mo>]</mml:mo></mml:math></inline-formula>, of the <inline-formula id="IE70"><mml:math id="IM70" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">th</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> class.</p>
      </sec>
      <sec>
        <title>2.3.2 Learning objective</title>
        <p>For a given protein pair <inline-formula id="IE71"><mml:math id="IM71" display="inline" overflow="scroll"><mml:mi>p</mml:mi></mml:math></inline-formula>, its class label <inline-formula id="IE72"><mml:math id="IM72" display="inline" overflow="scroll"><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> is defined as
<disp-formula id="E10"><mml:math id="M10" display="block" overflow="scroll"><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:maligngroup/><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mfenced open="{" close="" separators="|"><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mfenced separators="|"><mml:mrow><mml:mn>1,0</mml:mn><mml:mo>,</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mfenced><mml:mi mathvariant="normal"> </mml:mi><mml:mi mathvariant="normal">interacting</mml:mi><mml:mi mathvariant="normal"> </mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mfenced separators="|"><mml:mrow><mml:mn>0,1</mml:mn><mml:mo>,</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mfenced><mml:mi mathvariant="normal"> </mml:mi><mml:mi mathvariant="normal">negative</mml:mi><mml:mi mathvariant="normal"> </mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mfenced separators="|"><mml:mrow><mml:mn>0,0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfenced><mml:mi mathvariant="normal"> </mml:mi><mml:mi mathvariant="normal">single</mml:mi><mml:mi mathvariant="normal"> </mml:mi><mml:mi mathvariant="normal">protein</mml:mi></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mfenced><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p>
        <p>The learning model is trained to minimize the following cross-entropy loss and classify the inputs into their corresponding classes correctly
<disp-formula id="E11"><mml:math id="M11" display="block" overflow="scroll"><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:maligngroup/><mml:mi>L</mml:mi><mml:mi mathvariant="italic">oss</mml:mi><mml:mo>=</mml:mo><mml:mi>CEE</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">c</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>Z</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:munderover><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>z</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>Z</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:mrow><mml:munderover><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:munderover><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mrow><mml:mi mathvariant="normal">ln</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi>c </mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>where CEE is the cross-entropy error function, <inline-formula id="IE73"><mml:math id="IM73" display="inline" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">c</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula> and <inline-formula id="IE74"><mml:math id="IM74" display="inline" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">p</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula> represent the <inline-formula id="IE75"><mml:math id="IM75" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">th</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> scalar components of the model prediction <inline-formula id="IE76"><mml:math id="IM76" display="inline" overflow="scroll"><mml:msup><mml:mrow><mml:mi mathvariant="bold">c</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> and its corresponding class label <inline-formula id="IE77"><mml:math id="IM77" display="inline" overflow="scroll"><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula>, respectively, and <inline-formula id="IE78"><mml:math id="IM78" display="inline" overflow="scroll"><mml:mi>Z</mml:mi></mml:math></inline-formula> is the number of inputs in a batch.</p>
      </sec>
      <sec>
        <title>2.3.3 Optimization strategy</title>
        <p>We adopt AMSGrad (<xref rid="btab737-B30" ref-type="bibr">Reddi <italic toggle="yes">et al.</italic>, 2019</xref>), a variant of Adam optimizer (<xref rid="btab737-B17" ref-type="bibr">Kingma and Ba, 2014</xref>), to optimize the cross-entropy loss of our learning model. Following the same strategy as PIPR, the learning rate <inline-formula id="IE79"><mml:math id="IM79" display="inline" overflow="scroll"><mml:mo>α</mml:mo></mml:math></inline-formula> is set to 0.001, and the exponential decay rates <inline-formula id="IE80"><mml:math id="IM80" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mo>β</mml:mo></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula id="IE81"><mml:math id="IM81" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mo>β</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> are set to 0.9 and 0.999, respectively.</p>
      </sec>
      <sec>
        <title>2.3.4 Hyperparameter tuning</title>
        <p>The hyperparameter searching space of our model consists of 13 dimensions (including the hyperparameters for the embedding dimension, dropout rates, convolution kernel lengths, convolution strides and optimizers), which form about 140 000 combinations (<xref rid="sup1" ref-type="supplementary-material">Supplementary Table S1</xref>). It is too large for the grid search algorithm to find the optimal combination. Therefore, we leverage a Bayesian tuning tool GpyOpt (<xref rid="btab737-B38" ref-type="bibr">The GPyOpt Authors, 2016</xref>) to optimize the search process, which has been proved to be more efficient than the randomized grid search (<xref rid="btab737-B41" ref-type="bibr">Wang <italic toggle="yes">et al.</italic>, 2019</xref>). For the optimization program GpyOpt, we set the number of initial random searching points and the maximum number of iterations to 10 and 50, respectively. The performance of all candidate models and their corresponding hyperparameter settings are listed in <xref rid="sup1" ref-type="supplementary-material">Supplementary Table S2</xref>.</p>
      </sec>
      <sec>
        <title>2.3.5 Implementation details</title>
        <p>We randomly initialize the weights of the embedding, convolution and dense layers according to the Glorot uniform distribution (<xref rid="btab737-B9" ref-type="bibr">Glorot and Bengio, 2010</xref>), which is a common strategy used by deep-learning methods for model initialization (<xref rid="btab737-B18" ref-type="bibr">Kulmanov <italic toggle="yes">et al.</italic>, 2018</xref>; <xref rid="btab737-B34" ref-type="bibr">Seo <italic toggle="yes">et al.</italic>, 2018</xref>; <xref rid="btab737-B42" ref-type="bibr">Wang <italic toggle="yes">et al.</italic>, 2020</xref>). We design DeepTrio based on the open-source TensorFlow 2.0 library (<xref rid="btab737-B1" ref-type="bibr">Abadi <italic toggle="yes">et al.</italic>, 2016</xref>), and implement training and evaluation for all baseline models using a NVIDIA Tesla P100 GPU with 16 GB of memory.</p>
      </sec>
    </sec>
    <sec>
      <title>2.4 Calculating the effect of protein residues on prediction</title>
      <p>Suppose we have a pair of interacting proteins <inline-formula id="IE82"><mml:math id="IM82" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">A</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>(</mml:mo><mml:msubsup><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi mathvariant="normal">A</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mi mathvariant="normal">A</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">A</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">A</mml:mi></mml:mrow></mml:msubsup><mml:mo>)</mml:mo></mml:math></inline-formula> and <inline-formula id="IE83"><mml:math id="IM83" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">B</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>(</mml:mo><mml:msubsup><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi mathvariant="normal">B</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mi mathvariant="normal">B</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">B</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">B</mml:mi></mml:mrow></mml:msubsup><mml:mo>)</mml:mo></mml:math></inline-formula>, where <inline-formula id="IE84"><mml:math id="IM84" display="inline" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">A</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula> and <inline-formula id="IE85"><mml:math id="IM85" display="inline" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">B</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula> are the <inline-formula id="IE86"><mml:math id="IM86" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">th</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> residues of <inline-formula id="IE87"><mml:math id="IM87" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">A</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula id="IE88"><mml:math id="IM88" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">B</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, respectively. To calculate the effect of the residue <inline-formula id="IE89"><mml:math id="IM89" display="inline" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">A</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula> on prediction with respect to <inline-formula id="IE90"><mml:math id="IM90" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">B</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, we first calculate the probability that <inline-formula id="IE91"><mml:math id="IM91" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">A</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> does not interact with <inline-formula id="IE92"><mml:math id="IM92" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">B</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> [i.e. <inline-formula id="IE93"><mml:math id="IM93" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi mathvariant="normal">P</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">neg</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">A</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">B</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:math></inline-formula>]. Second, we attach a mask vector (with an inactive bit in the <inline-formula id="IE94"><mml:math id="IM94" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">th</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> component) to the embedded representation of <inline-formula id="IE95"><mml:math id="IM95" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">A</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> (generating a new sequence called <inline-formula id="IE96"><mml:math id="IM96" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi mathvariant="normal">A</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>) and recalculate the probability that <inline-formula id="IE97"><mml:math id="IM97" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi mathvariant="normal">A</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> does not interact with <inline-formula id="IE98"><mml:math id="IM98" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">B</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> [i.e. <inline-formula id="IE99"><mml:math id="IM99" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi mathvariant="normal">P</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">neg</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi mathvariant="normal">A</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">B</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:math></inline-formula>]. Finally, the effect of <inline-formula id="IE100"><mml:math id="IM100" display="inline" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">A</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula> on prediction with respect to <inline-formula id="IE101"><mml:math id="IM101" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">B</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is assigned to be
<disp-formula id="E12"><mml:math id="M12" display="block" overflow="scroll"><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:maligngroup/><mml:msub><mml:mrow><mml:mi mathvariant="normal">U</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">B</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">A</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">P</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">neg</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi mathvariant="normal">A</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">B</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">P</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">neg</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">A</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">B</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p>
    </sec>
  </sec>
  <sec>
    <title>3 Results</title>
    <p>We report the performance of DeepTrio and other approaches on four different PPI datasets. Further, we test the performance of DeepTrio on the multiple specie dataset where proteins are filtered based on different thresholds of sequence identity. In addition to the binary prediction of PPIs, DeepTrio can generate an intuitive protein portrait for the detection of potentially important residues for interaction. Lastly, a logically concise online application has been developed to help researchers make better use of DeepTrio.</p>
    <sec>
      <title>3.1 Performance comparison of DeepTrio with other approaches</title>
      <p>The main task of DeepTrio is to estimate the interaction probability of a given protein pair based on its sequences. We compare DeepTrio with several state-of-the-art PPI prediction methods including SVM-AC (<xref rid="btab737-B10" ref-type="bibr">Guo <italic toggle="yes">et al.</italic>, 2008</xref>), SVM-MCD (<xref rid="btab737-B48" ref-type="bibr">You <italic toggle="yes">et al.</italic>, 2014</xref>), DPPI (<xref rid="btab737-B11" ref-type="bibr">Hashemifar <italic toggle="yes">et al.</italic>, 2018</xref>), PIPR (<xref rid="btab737-B4" ref-type="bibr">Chen <italic toggle="yes">et al.</italic>, 2019</xref>) and DeepFE-PPI (<xref rid="btab737-B46" ref-type="bibr">Yao <italic toggle="yes">et al.</italic>, 2019</xref>) on a variety of benchmark datasets. Furthermore, we also report the performance of a simplified variant of DeepTrio (named as DeepDuo), which has the same learning architecture as DeepTrio but is not trained by the single-protein dataset. By setting the simplified control of DeepTrio, we can further investigate how the single-protein cases influence the prediction performance of our model.</p>
      <sec>
        <title>3.1.1 BioGRID multivalidated physical interaction data</title>
        <p>We perform 5-fold cross-validation on the BioGRID human and yeast datasets. Under this setting, the data are equally divided into five parts and each part has an equal chance to train and test the models. We aggregate eight quality metrics including accuracy, precision, sensitivity, specificity, F1 score, Matthews correlation coefficient (MCC) and average precision (AP) to assess the prediction performance of the models. Higher values in all these metrics indicate better performance.</p>
        <p>As shown in <xref rid="btab737-T1" ref-type="table">Tables  1</xref> and <xref rid="btab737-T2" ref-type="table">2</xref>, the RCNN architecture of PIPR promises a remarkable performance and gets the highest scores in sensitivity on both the human and yeast datasets. However, DeepTrio achieves the best performance in other metrics by leveraging a multiscale convolution architecture that can better learn the deep features from protein sequences. For example, DeepTrio outperforms PIPR by 0.52% and 1.79% in accuracy, and by 1.43% and 4.34% in precision on the human and yeast datasets, respectively.</p>
        <table-wrap position="float" id="btab737-T1">
          <label>Table 1.</label>
          <caption>
            <p>Evaluation of PPI prediction performance on the BioGRID <italic toggle="yes">S.cerevisiae</italic> dataset based on 5-fold cross-validation</p>
          </caption>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col valign="top" align="left" span="1"/>
              <col valign="top" align="center" span="1"/>
              <col valign="top" align="center" span="1"/>
              <col valign="top" align="center" span="1"/>
              <col valign="top" align="center" span="1"/>
              <col valign="top" align="center" span="1"/>
              <col valign="top" align="center" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th rowspan="1" colspan="1">Methods</th>
                <th rowspan="1" colspan="1">Accuracy (%)</th>
                <th rowspan="1" colspan="1">Precision (%)</th>
                <th rowspan="1" colspan="1">Sensitivity (%)</th>
                <th rowspan="1" colspan="1">Specificity (%)</th>
                <th rowspan="1" colspan="1">MCC (%)</th>
                <th rowspan="1" colspan="1">F1-score (%)</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td rowspan="1" colspan="1">DeepFE-PPI<xref rid="tblfn2" ref-type="table-fn"><sup>a</sup></xref> (<xref rid="btab737-B46" ref-type="bibr">Yao <italic toggle="yes">et al.</italic>, 2019</xref>)</td>
                <td rowspan="1" colspan="1">85.24 ± 0.52</td>
                <td rowspan="1" colspan="1">85.49 ± 1.41</td>
                <td rowspan="1" colspan="1">84.99 ± 2.77</td>
                <td rowspan="1" colspan="1">85.49 ± 2.11</td>
                <td rowspan="1" colspan="1">70.57 ± 1.06</td>
                <td rowspan="1" colspan="1">85.19 ± 0.79</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">PIPR<xref rid="tblfn2" ref-type="table-fn"><sup>a</sup></xref> (<xref rid="btab737-B4" ref-type="bibr">Chen <italic toggle="yes">et al.</italic>, 2019</xref>)</td>
                <td rowspan="1" colspan="1">95.76 ± 0.25</td>
                <td rowspan="1" colspan="1">94.61 ± 0.53</td>
                <td rowspan="1" colspan="1">97.06 ± 0.41</td>
                <td rowspan="1" colspan="1">94.47 ± 0.55</td>
                <td rowspan="1" colspan="1">91.56 ± 0.48</td>
                <td rowspan="1" colspan="1">95.82 ± 0.24</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">DeepDuo<xref rid="tblfn2" ref-type="table-fn"><sup>a</sup></xref></td>
                <td rowspan="1" colspan="1">97.06 ± 0.28</td>
                <td rowspan="1" colspan="1">98.06 ± 0.51</td>
                <td rowspan="1" colspan="1">96.02 ± 0.35</td>
                <td rowspan="1" colspan="1">98.10 ± 0.50</td>
                <td rowspan="1" colspan="1">94.14 ± 0.57</td>
                <td rowspan="1" colspan="1">97.02 ± 0.30</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">DeepTrio<xref rid="tblfn2" ref-type="table-fn"><sup>a</sup></xref></td>
                <td rowspan="1" colspan="1">97.55 ± 0.38</td>
                <td rowspan="1" colspan="1">98.95 ± 0.20</td>
                <td rowspan="1" colspan="1">96.12 ± 0.74</td>
                <td rowspan="1" colspan="1">98.98 ± 0.21</td>
                <td rowspan="1" colspan="1">95.15 ± 0.74</td>
                <td rowspan="1" colspan="1">97.52 ± 0.40</td>
              </tr>
            </tbody>
          </table>
          <table-wrap-foot>
            <fn id="tblfn1">
              <p><italic toggle="yes">Note</italic>: We report the mean values and standard deviations for the test sets.</p>
            </fn>
            <fn id="tblfn2">
              <label>a</label>
              <p>Those models are retrained using the same data.</p>
            </fn>
          </table-wrap-foot>
        </table-wrap>
        <table-wrap position="float" id="btab737-T2">
          <label>Table 2.</label>
          <caption>
            <p>Evaluation of PPI prediction performance on the BioGRID <italic toggle="yes">H.sapiens</italic> dataset based on 5-fold cross-validation</p>
          </caption>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col valign="top" align="left" span="1"/>
              <col valign="top" align="center" span="1"/>
              <col valign="top" align="center" span="1"/>
              <col valign="top" align="center" span="1"/>
              <col valign="top" align="center" span="1"/>
              <col valign="top" align="center" span="1"/>
              <col valign="top" align="center" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th rowspan="1" colspan="1">Methods</th>
                <th rowspan="1" colspan="1">Accuracy (%)</th>
                <th rowspan="1" colspan="1">Precision (%)</th>
                <th rowspan="1" colspan="1">Sensitivity (%)</th>
                <th rowspan="1" colspan="1">Specificity (%)</th>
                <th rowspan="1" colspan="1">MCC (%)</th>
                <th rowspan="1" colspan="1">F1-score (%)</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td rowspan="1" colspan="1">DeepFE-PPI<xref rid="tblfn4" ref-type="table-fn"><sup>a</sup></xref> (<xref rid="btab737-B46" ref-type="bibr">Yao <italic toggle="yes">et al.</italic>, 2019</xref>)</td>
                <td rowspan="1" colspan="1">87.66 ± 0.57</td>
                <td rowspan="1" colspan="1">89.42 ± 1.05</td>
                <td rowspan="1" colspan="1">85.47 ± 2.27</td>
                <td rowspan="1" colspan="1">89.85 ± 1.40</td>
                <td rowspan="1" colspan="1">75.44 ± 1.09</td>
                <td rowspan="1" colspan="1">87.37 ± 0.78</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">PIPR<xref rid="tblfn4" ref-type="table-fn"><sup>a</sup></xref> (<xref rid="btab737-B4" ref-type="bibr">Chen <italic toggle="yes">et al.</italic>, 2019</xref>)</td>
                <td rowspan="1" colspan="1">97.60 ± 0.08</td>
                <td rowspan="1" colspan="1">97.57 ± 0.35</td>
                <td rowspan="1" colspan="1">97.63 ± 0.44</td>
                <td rowspan="1" colspan="1">97.56 ± 0.36</td>
                <td rowspan="1" colspan="1">95.20 ± 0.15</td>
                <td rowspan="1" colspan="1">97.60 ± 0.10</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">DeepDuo<xref rid="tblfn4" ref-type="table-fn"><sup>a</sup></xref></td>
                <td rowspan="1" colspan="1">98.04 ± 0.05</td>
                <td rowspan="1" colspan="1">98.83 ± 0.28</td>
                <td rowspan="1" colspan="1">97.23 ± 0.28</td>
                <td rowspan="1" colspan="1">98.85 ± 0.27</td>
                <td rowspan="1" colspan="1">96.09 ± 0.10</td>
                <td rowspan="1" colspan="1">98.02 ± 0.05</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">DeepTrio<xref rid="tblfn4" ref-type="table-fn"><sup>a</sup></xref></td>
                <td rowspan="1" colspan="1">98.12 ± 0.12</td>
                <td rowspan="1" colspan="1">99.00 ± 0.17</td>
                <td rowspan="1" colspan="1">97.23 ± 0.28</td>
                <td rowspan="1" colspan="1">99.01 ± 0.17</td>
                <td rowspan="1" colspan="1">96.26 ± 0.23</td>
                <td rowspan="1" colspan="1">98.11 ± 0.13</td>
              </tr>
            </tbody>
          </table>
          <table-wrap-foot>
            <fn id="tblfn3">
              <p><italic toggle="yes">Note</italic>: We report the mean values and standard deviations for the test sets.</p>
            </fn>
            <fn id="tblfn4">
              <label>a</label>
              <p>Those models are retrained using the same data.</p>
            </fn>
          </table-wrap-foot>
        </table-wrap>
        <p>In addition, we report the comparison between DeepDuo and DeepTrio on the BioGRID benchmarks, which provides insights into the role of single-protein training in PPI prediction. It is observed that DeepTrio perform consistently better than DeepDuo in all of the evaluation metrics (<xref rid="btab737-T1" ref-type="table">Tables  1</xref> and <xref rid="btab737-T2" ref-type="table">2</xref>). For example, DeepTrio attains an accuracy value of 97.55% (which is 0.49% higher than DeepDuo), and an MCC value of 95.15% (which is 1.01% higher than DeepDuo) in the yeast dataset. These results suggest that the single-protein training process can improve our model performance on the BioGRID datasets.</p>
      </sec>
      <sec>
        <title>3.1.2 <italic toggle="yes">Saccharomyces cerevisiae</italic> core data</title>
        <p>We first use DeepFE-PPI’s <italic toggle="yes">S.cerevisiae</italic> dataset to evaluate the performance of DeepTrio. The positive set from DeepFE-PPI is identical with that from <xref rid="btab737-B49" ref-type="bibr">You <italic toggle="yes">et al.</italic> (2015)</xref>. To make the data suitable for the model input, we remove 255 cases that contains proteins longer than 1500 amino acids, and use the truncated data to retrain and evaluate DeepTrio and PIPR. The evaluation shows that, under the highest scores attained by DeepFE-PPI on its own data, DeepTrio achieves better performance than PIPR with respect to five evaluation metrics (<xref rid="btab737-T3" ref-type="table">Table  3</xref>). Second, we test the performance of DeepTrio and DeepFE-PPI on PIPR’s dataset, where we remove 231 cases containing proteins longer than 2000 amino acids. The results in <xref rid="btab737-T4" ref-type="table">Table  4</xref> show that DeepTrio attains better performance than DeepFE-PPI (such as 3.74% higher in accuracy, 8.04% higher in precision and 7.44% higher in MCC) on PIPR’s dataset. However, PIPR achieves the state-of-the-art performance on its own dataset, but exhibits worse performance than DeepTrio in precision and specificity. In addition, DeepTrio also outperforms DeepDuo on both of the <italic toggle="yes">S.cerevisiae</italic> datasets in most metrics (<xref rid="btab737-T3" ref-type="table">Tables  3</xref> and <xref rid="btab737-T4" ref-type="table">4</xref>). Detailed performance of DeepTrio, PIPR and DeepFE-PPI on two <italic toggle="yes">S</italic> <italic toggle="yes">cerevisiae</italic> datasets is provided in the <xref rid="sup1" ref-type="supplementary-material">Supplementary Material</xref>.</p>
        <table-wrap position="float" id="btab737-T3">
          <label>Table 3.</label>
          <caption>
            <p>Evaluation of PPI prediction performance on the <italic toggle="yes">S.cerevisiae</italic> core dataset from DeepFE-PPI based on 5-fold cross-validation</p>
          </caption>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col valign="top" align="left" span="1"/>
              <col valign="top" align="center" span="1"/>
              <col valign="top" align="center" span="1"/>
              <col valign="top" align="center" span="1"/>
              <col valign="top" align="center" span="1"/>
              <col valign="top" align="center" span="1"/>
              <col valign="top" align="center" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th rowspan="1" colspan="1">Methods</th>
                <th rowspan="1" colspan="1">Accuracy (%)</th>
                <th rowspan="1" colspan="1">Precision (%)</th>
                <th rowspan="1" colspan="1">Sensitivity (%)</th>
                <th rowspan="1" colspan="1">Specificity (%)</th>
                <th rowspan="1" colspan="1">MCC (%)</th>
                <th rowspan="1" colspan="1">F1-score (%)</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td rowspan="1" colspan="1">SVM-AC (<xref rid="btab737-B10" ref-type="bibr">Guo <italic toggle="yes">et al.</italic>, 2008</xref>)</td>
                <td rowspan="1" colspan="1">87.35 ± 1.38</td>
                <td rowspan="1" colspan="1">87.82 ± 4.84</td>
                <td rowspan="1" colspan="1">87.30 ± 5.23</td>
                <td rowspan="1" colspan="1">87.41 ± 6.33</td>
                <td rowspan="1" colspan="1">87.34 ± 1.33</td>
                <td rowspan="1" colspan="1">75.09 ± 2.51</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">SVM-MCD (<xref rid="btab737-B48" ref-type="bibr">You <italic toggle="yes">et al.</italic>, 2014</xref>)</td>
                <td rowspan="1" colspan="1">91.36 ± 0.4</td>
                <td rowspan="1" colspan="1">91.94 ± 0.69</td>
                <td rowspan="1" colspan="1">90.67 ± 0.77</td>
                <td rowspan="1" colspan="1">NA</td>
                <td rowspan="1" colspan="1">91.3 ± 0.73</td>
                <td rowspan="1" colspan="1">84.21 ± 0.59</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">DeepFE-PPI (<xref rid="btab737-B46" ref-type="bibr">Yao <italic toggle="yes">et al.</italic>, 2019</xref>)</td>
                <td rowspan="1" colspan="1">94.78 ± 0.61</td>
                <td rowspan="1" colspan="1">96.45 ± 0.87</td>
                <td rowspan="1" colspan="1">92.99 ± 0.66</td>
                <td rowspan="1" colspan="1">NA</td>
                <td rowspan="1" colspan="1">NA</td>
                <td rowspan="1" colspan="1">89.62 ± 1.23</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">DeepDuo<xref rid="tblfn6" ref-type="table-fn"><sup>a</sup></xref></td>
                <td rowspan="1" colspan="1">92.16 ± 0.55</td>
                <td rowspan="1" colspan="1">96.57 ± 1.22</td>
                <td rowspan="1" colspan="1">87.46 ± 1.46</td>
                <td rowspan="1" colspan="1">96.83 ± 1.27</td>
                <td rowspan="1" colspan="1">91.78 ± 0.59</td>
                <td rowspan="1" colspan="1">84.71 ± 1.10</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">PIPR<xref rid="tblfn6" ref-type="table-fn"><sup>a</sup></xref> (<xref rid="btab737-B4" ref-type="bibr">Chen <italic toggle="yes">et al.</italic>, 2019</xref>)</td>
                <td rowspan="1" colspan="1">92.26 ± 0.44</td>
                <td rowspan="1" colspan="1">94.17 ± 0.65</td>
                <td rowspan="1" colspan="1">90.11 ± 0.56</td>
                <td rowspan="1" colspan="1">94.42 ± 0.56</td>
                <td rowspan="1" colspan="1">92.09 ± 0.53</td>
                <td rowspan="1" colspan="1">84.60 ± 0.89</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">DeepTrio<xref rid="tblfn6" ref-type="table-fn"><sup>a</sup></xref></td>
                <td rowspan="1" colspan="1">92.57 ± 0.63</td>
                <td rowspan="1" colspan="1">96.33 ± 0.88</td>
                <td rowspan="1" colspan="1">88.53 ± 1.19</td>
                <td rowspan="1" colspan="1">96.62 ± 0.83</td>
                <td rowspan="1" colspan="1">92.26 ± 0.65</td>
                <td rowspan="1" colspan="1">85.43 ± 1.22</td>
              </tr>
            </tbody>
          </table>
          <table-wrap-foot>
            <fn id="tblfn5">
              <p><italic toggle="yes">Note</italic>: Performance values for majority of baseline approaches are obtained from <xref rid="btab737-B46" ref-type="bibr">Yao <italic toggle="yes">et al.</italic> (2019)</xref>, and NA denotes unavailability of the values from the original papers. We report the mean values and standard deviations for the test sets.</p>
            </fn>
            <fn id="tblfn6">
              <label>a</label>
              <p>Those models are retrained using the same data.</p>
            </fn>
          </table-wrap-foot>
        </table-wrap>
        <table-wrap position="float" id="btab737-T4">
          <label>Table 4.</label>
          <caption>
            <p>Evaluation of PPI prediction performance on the <italic toggle="yes">S.cerevisiae</italic> core dataset from PIPR based on 5-fold cross-validation</p>
          </caption>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col valign="top" align="left" span="1"/>
              <col valign="top" align="center" span="1"/>
              <col valign="top" align="center" span="1"/>
              <col valign="top" align="center" span="1"/>
              <col valign="top" align="center" span="1"/>
              <col valign="top" align="center" span="1"/>
              <col valign="top" align="center" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th rowspan="1" colspan="1">Methods</th>
                <th rowspan="1" colspan="1">Accuracy (%)</th>
                <th rowspan="1" colspan="1">Precision (%)</th>
                <th rowspan="1" colspan="1">Sensitivity (%)</th>
                <th rowspan="1" colspan="1">Specificity (%)</th>
                <th rowspan="1" colspan="1">MCC (%)</th>
                <th rowspan="1" colspan="1">F1-score (%)</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td rowspan="1" colspan="1">DPPI (<xref rid="btab737-B11" ref-type="bibr">Hashemifar <italic toggle="yes">et al.</italic>, 2018</xref>)</td>
                <td rowspan="1" colspan="1">94.55</td>
                <td rowspan="1" colspan="1">96.68</td>
                <td rowspan="1" colspan="1">92.24</td>
                <td rowspan="1" colspan="1">NA</td>
                <td rowspan="1" colspan="1">94.41</td>
                <td rowspan="1" colspan="1">NA</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">PIPR (<xref rid="btab737-B4" ref-type="bibr">Chen <italic toggle="yes">et al.</italic>, 2019</xref>)</td>
                <td rowspan="1" colspan="1">97.09 ± 0.24</td>
                <td rowspan="1" colspan="1">97.00 ± 0.65</td>
                <td rowspan="1" colspan="1">97.17 ± 0.44</td>
                <td rowspan="1" colspan="1">97.00 ± 0.67</td>
                <td rowspan="1" colspan="1">97.09 ± 0.23</td>
                <td rowspan="1" colspan="1">94.17 ± 0.48</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">DeepDuo<xref rid="tblfn8" ref-type="table-fn"><sup>a</sup></xref></td>
                <td rowspan="1" colspan="1">94.14 ± 0.30</td>
                <td rowspan="1" colspan="1">96.37 ± 1.43</td>
                <td rowspan="1" colspan="1">91.74 ± 1.26</td>
                <td rowspan="1" colspan="1">96.51 ± 1.41</td>
                <td rowspan="1" colspan="1">93.98 ± 0.27</td>
                <td rowspan="1" colspan="1">88.40 ± 0.67</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">DeepFE-PPI<xref rid="tblfn8" ref-type="table-fn"><sup>a</sup></xref> (<xref rid="btab737-B46" ref-type="bibr">Yao <italic toggle="yes">et al.</italic>, 2019</xref>)</td>
                <td rowspan="1" colspan="1">91.04 ± 0.45</td>
                <td rowspan="1" colspan="1">89.14 ± 1.58</td>
                <td rowspan="1" colspan="1">93.52 ± 1.67</td>
                <td rowspan="1" colspan="1">88.55 ± 2.01</td>
                <td rowspan="1" colspan="1">91.25 ± 0.4</td>
                <td rowspan="1" colspan="1">82.23 ± 0.86</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">DeepTrio<xref rid="tblfn8" ref-type="table-fn"><sup>a</sup></xref></td>
                <td rowspan="1" colspan="1">94.78 ± 0.28</td>
                <td rowspan="1" colspan="1">97.18 ± 0.28</td>
                <td rowspan="1" colspan="1">92.20 ± 0.49</td>
                <td rowspan="1" colspan="1">97.33 ± 0.30</td>
                <td rowspan="1" colspan="1">94.63 ± 0.29</td>
                <td rowspan="1" colspan="1">89.67 ± 0.55</td>
              </tr>
            </tbody>
          </table>
          <table-wrap-foot>
            <fn id="tblfn7">
              <p><italic toggle="yes">Note</italic>: Performance values for majority of baseline approaches are obtained from <xref rid="btab737-B46" ref-type="bibr">Yao <italic toggle="yes">et al.</italic> (2019)</xref>, and NA denotes unavailability of the values from the original papers. We report the mean values and standard deviations for the test sets.</p>
            </fn>
            <fn id="tblfn8">
              <label>a</label>
              <p>Those models are retrained using the same data.</p>
            </fn>
          </table-wrap-foot>
        </table-wrap>
      </sec>
      <sec>
        <title>3.1.3 Comprehensive comparison between DeepTrio and PIPR</title>
        <p>Based on the four datasets mentioned above, we count how many times DeepTrio or PIPR attains higher scores with respect to six metrics. <xref rid="btab737-T5" ref-type="table">Table  5</xref> shows that DeepTrio offers robust performance over the four datasets and outperforms PIPR in many evaluation metrics, especially in precision and specificity.</p>
        <table-wrap position="float" id="btab737-T5">
          <label>Table 5.</label>
          <caption>
            <p>Statistics for the better performance achieved by DeepTrio and PIPR on four datasets with respect to six evaluation metrics</p>
          </caption>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col valign="top" align="left" span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th rowspan="1" colspan="1">Methods</th>
                <th rowspan="1" colspan="1">Accuracy</th>
                <th rowspan="1" colspan="1">Precision</th>
                <th rowspan="1" colspan="1">Sensitivity</th>
                <th rowspan="1" colspan="1">Specificity</th>
                <th rowspan="1" colspan="1">F1-score</th>
                <th rowspan="1" colspan="1">MCC</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td rowspan="1" colspan="1">PIPR</td>
                <td rowspan="1" colspan="1">1</td>
                <td rowspan="1" colspan="1">0</td>
                <td rowspan="1" colspan="1">4</td>
                <td rowspan="1" colspan="1">0</td>
                <td rowspan="1" colspan="1">1</td>
                <td rowspan="1" colspan="1">1</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">DeepTrio</td>
                <td rowspan="1" colspan="1">3</td>
                <td rowspan="1" colspan="1">4</td>
                <td rowspan="1" colspan="1">0</td>
                <td rowspan="1" colspan="1">4</td>
                <td rowspan="1" colspan="1">3</td>
                <td rowspan="1" colspan="1">3</td>
              </tr>
            </tbody>
          </table>
        </table-wrap>
      </sec>
    </sec>
    <sec>
      <title>3.2 PPI prediction on multispecies dataset</title>
      <p>Following the same strategy as PIPR (<xref rid="btab737-B4" ref-type="bibr">Chen <italic toggle="yes">et al.</italic>, 2019</xref>), we perform 5-fold cross-validation of DeepTrio on the multispecies dataset (<italic toggle="yes">Caenorhabditis elegans</italic>, <italic toggle="yes">Escherichia coli</italic> and <italic toggle="yes">Drosophila melanogaster</italic>), where proteins are filtered based on different thresholds of sequence identity (40%, 25%, 10% and 1%). To make the data suitable for the model input, we also remove the cases containing proteins longer than 1500 amino acids. The results in <xref rid="btab737-T6" ref-type="table">Table  6</xref> show that DeepTrio performs consistently well on a series of datasets with different sequence identities.</p>
      <table-wrap position="float" id="btab737-T6">
        <label>Table 6.</label>
        <caption>
          <p>Evaluation of PPI prediction performance on the multispecies (<italic toggle="yes">C.elegans</italic>, <italic toggle="yes">D.melanogaster</italic> and <italic toggle="yes">E.coli</italic>) dataset</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1">Sequence identity</th>
              <th rowspan="1" colspan="1">Protein number</th>
              <th rowspan="1" colspan="1">Positive pairs</th>
              <th rowspan="1" colspan="1">Negative pairs</th>
              <th rowspan="1" colspan="1">Accuracy (%)</th>
              <th rowspan="1" colspan="1">Precision (%)</th>
              <th rowspan="1" colspan="1">Sensitivity (%)</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">Any</td>
              <td rowspan="1" colspan="1">11 108</td>
              <td rowspan="1" colspan="1">31 227</td>
              <td rowspan="1" colspan="1">30 368</td>
              <td rowspan="1" colspan="1">98.20</td>
              <td rowspan="1" colspan="1">99.51</td>
              <td rowspan="1" colspan="1">96.92</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">≤40%</td>
              <td rowspan="1" colspan="1">9354</td>
              <td rowspan="1" colspan="1">24 406</td>
              <td rowspan="1" colspan="1">20 461</td>
              <td rowspan="1" colspan="1">97.83</td>
              <td rowspan="1" colspan="1">99.23</td>
              <td rowspan="1" colspan="1">96.77</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">≤25%</td>
              <td rowspan="1" colspan="1">7454</td>
              <td rowspan="1" colspan="1">18 193</td>
              <td rowspan="1" colspan="1">14 485</td>
              <td rowspan="1" colspan="1">97.52</td>
              <td rowspan="1" colspan="1">98.78</td>
              <td rowspan="1" colspan="1">96.74</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">≤10%</td>
              <td rowspan="1" colspan="1">5478</td>
              <td rowspan="1" colspan="1">11 777</td>
              <td rowspan="1" colspan="1">8839</td>
              <td rowspan="1" colspan="1">97.32</td>
              <td rowspan="1" colspan="1">98.87</td>
              <td rowspan="1" colspan="1">96.42</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">≤1%</td>
              <td rowspan="1" colspan="1">4932</td>
              <td rowspan="1" colspan="1">10 110</td>
              <td rowspan="1" colspan="1">7284</td>
              <td rowspan="1" colspan="1">97.11</td>
              <td rowspan="1" colspan="1">98.89</td>
              <td rowspan="1" colspan="1">96.10</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
    </sec>
    <sec>
      <title>3.3 PPI prediction on independent test set</title>
      <p>Here, we use the virus–human interaction dataset in <xref rid="btab737-B23" ref-type="bibr">Liu-Wei <italic toggle="yes">et al.</italic> (2021)</xref> as an independent test set to assess the performance of DeepTrio and other approaches (trained by the BioGRID human–human interaction dataset). Following the preprocessing methods in the previous studies (<xref rid="btab737-B11" ref-type="bibr">Hashemifar <italic toggle="yes">et al.</italic>, 2018</xref>; <xref rid="btab737-B16" ref-type="bibr">Khurana <italic toggle="yes">et al.</italic>, 2018</xref>; <xref rid="btab737-B29" ref-type="bibr">Rawi <italic toggle="yes">et al.</italic>, 2018</xref>), we first decrease sequence redundancy in the virus protein data with a maximum sequence identity of 10%. Second, we exclude all the virus sequences in the independent test set with a sequence identity of ≥25% to any sequence in the human–human interaction training set. The negative independent test data are generated by randomly shuffling the protein sequences in the virus–human interaction dataset (this method is elaborated in Section 2.1.1). The final independent test set is composed of 8929 interacting and 8929 noninteracting protein pairs. The results in <xref rid="btab737-F3" ref-type="fig">Figure  3</xref> show that DeepTrio exhibits competitive performance on the independent test set in comparison to PIPR.</p>
      <fig position="float" id="btab737-F3">
        <label>Fig. 3.</label>
        <caption>
          <p>Performance comparison of DeepTrio with PIPR and DeepFE-PPI on independent test set. (<bold>a</bold>) Comparison of area under receiver operating curve (AUC). (<bold>b</bold>) Comparison of AP with respect to the interacting class. (<bold>c</bold>) Comparison of AP with respect to the noninteracting class</p>
        </caption>
        <graphic xlink:href="btab737f3" position="float"/>
      </fig>
    </sec>
    <sec>
      <title>3.4 Detecting and visualizing potentially important residues for interaction</title>
      <p>Since experiment-based methods require meticulous operations and lots of time to identify the important sites for interaction, it is crucial to conduct a prior assessment of experimental protocols and prereject initial targets with the lowest interaction probability. Thus, we extend DeepTrio to an additional scenario that helps detect the potentially important sites for interaction (which are not limited to the residues in core binding regions, but also include some other crucial residues that shape the external and internal structures, provide skeleton support through long aliphatic side chains or create the hydrophobic environment). The main goal of this extension is to find out which residues take the main responsibility for the prediction results and visualize the importance score for each residue in a sequence.</p>
      <p>Recently, a handful of previous works have already applied several visualization techniques to provide interpretable explanations for deep-learning models. DeepBind (<xref rid="btab737-B2" ref-type="bibr">Alipanahi <italic toggle="yes">et al.</italic>, 2015</xref>) uses ‘<italic toggle="yes">mutation maps</italic>’ to illustrate the effect that each possible point mutation may have on binding affinity between DNA and proteins. DeepChrome (<xref rid="btab737-B35" ref-type="bibr">Singh <italic toggle="yes">et al.</italic>, 2016</xref>) utilizes a network-centric approach (<xref rid="btab737-B47" ref-type="bibr">Yosinski <italic toggle="yes">et al.</italic>, 2015</xref>) to extract the class-specific feature patterns that are highly influential in gene expression predictions. DeepSig (<xref rid="btab737-B32" ref-type="bibr">Savojardo <italic toggle="yes">et al.</italic>, 2018</xref>) employs the deep Taylor decomposition approach (<xref rid="btab737-B24" ref-type="bibr">Montavon <italic toggle="yes">et al.</italic>, 2017</xref>) to determine a relevance score measuring the contribution of each input neuron toward the prediction. In this work, owing to the integration of the single-protein training strategy and masking operation, it is possible to allow DeepTrio to visualize the contribution of each input neuron toward the prediction (which is elaborated in Section 2.4).</p>
      <p>We validate the visualization results given by DeepTrio (the model is trained using the BioGRID human multivalidated physical interaction data) with the recent experimental evidence in biochemical studies. Note that all the PPIs mentioned below, along with their mutants, are not included in the training data of DeepTrio. <xref rid="btab737-F4" ref-type="fig">Figure  4a</xref> shows the <italic toggle="yes">importance map</italic> of the mutant human calreticulin (CALR) (that loses most of the C-terminal acidic residues and gains a novel common C-terminus with 36 amino acids rich in positively electrostatic charges caused by a heterogeneous set of +1 bp frameshift mutations in exon 9) (<xref rid="btab737-B25" ref-type="bibr">Nangalia <italic toggle="yes">et al.</italic>, 2013</xref>). These positively charged residues in the novel C-terminus are reported essential for mediating the erroneous activation of MPL signaling and the physical interaction between mutant CALR and the thrombopoietin receptor MPL, which can lead to myeloproliferative disorders (<xref rid="btab737-B6" ref-type="bibr">Elf <italic toggle="yes">et al.</italic>, 2016</xref>, <xref rid="btab737-B7" ref-type="bibr">2018</xref>). We use the ‘<italic toggle="yes">importance map</italic>’ to illustrate the importance score of each residue in the mutant CALR (p.L367fs*46) (<xref rid="btab737-F4" ref-type="fig">Fig.  4a</xref>). The ‘<italic toggle="yes">importance map</italic>’ is rendered as a heat map with <italic toggle="yes">l</italic> squares (where <italic toggle="yes">l</italic> is the length of the given protein), and each line in the heat map is set to 20 squares. It can be observed in <xref rid="btab737-F4" ref-type="fig">Figure  4a</xref> that most of the residues with crimson backgrounds are enriched in the C-terminus, where the positively charged residues (like arginine and lysine) exhibit a strong trend of higher importance scores. These results are basically consistent with the previous findings in experimental studies (<xref rid="btab737-B6" ref-type="bibr">Elf <italic toggle="yes">et al.</italic>, 2016</xref>, <xref rid="btab737-B7" ref-type="bibr">2018</xref>). <xref rid="btab737-F4" ref-type="fig">Figure  4b</xref> depicts the <italic toggle="yes">importance map</italic> of Choline kinase alpha (ChoKα). ChoKα catalyzes the phosphorylation of choline to phosphocholine, and its high expression has proven to be associated with cancer malignancy and poor patient prognosis (<xref rid="btab737-B27" ref-type="bibr">Ramírez De Molina <italic toggle="yes">et al.</italic>, 2002</xref>, <xref rid="btab737-B28" ref-type="bibr">2005</xref>). Recent biophysical and biochemical studies (<xref rid="btab737-B14" ref-type="bibr">Kall <italic toggle="yes">et al.</italic>, 2019</xref>) have demonstrated that the ChoKα poly-proline region in residues 49–79 (especially prolines 61 and 62) mediates the physical interaction between ChoKα and the SH3 domain of c-Src tyrosine kinases. It can be seen in the ChoKα <italic toggle="yes">importance map</italic> (<xref rid="btab737-F4" ref-type="fig">Fig.  4b</xref>) that the highly scored residues are enriched in the N-terminal poly-proline region, which is consistent with the findings in the aforementioned experimental studies.</p>
      <fig position="float" id="btab737-F4">
        <label>Fig. 4.</label>
        <caption>
          <p>An ‘<italic toggle="yes">importance map</italic>’ are employed to visualize the effect of each amino acid residue on interaction, where residues in red colors exert positive effects and those in blue colors exert negative effects on prediction. (<bold>a</bold>) Analysis of the potential importance of each residue in CALR p. L367fs*46 for interaction with MPL. The positively charged residues in the last 36 amino acids exhibit a strong trend of higher importance scores, which have been proved essential for the physical interaction between CALR p. L367fs*46 and MPL. (<bold>b</bold>) Analysis of the potential importance of each residue in ChoKα for interaction with the SH3 domain of c-Src. The poly-proline region in ChoKα residues 53–78 harbors relatively higher scores in the <italic toggle="yes">importance map</italic>, which are reported crucial for the interaction with the SH3 domain of c-Src (<xref rid="btab737-B14" ref-type="bibr">Kall <italic toggle="yes">et al.</italic>, 2019</xref>)</p>
        </caption>
        <graphic xlink:href="btab737f4" position="float"/>
      </fig>
      <p>In practice, the <italic toggle="yes">importance map</italic> shows a preference for finding the key residues that share similar properties in the adjacent regions and a sensitivity decrease for large protein assessment. Another noteworthy observation in both <xref rid="btab737-F4" ref-type="fig">Figures  4a and 4b</xref> is that the vast majority of the negative-effect residues harbor the pale-blue backgrounds, which can be explained by the hypothesis that most of point mutations will reduce the interaction between two proteins that have already reached the optimal conformation for binding.</p>
    </sec>
    <sec>
      <title>3.5 Online server</title>
      <p>To provide an accessible interface in a logically concise manner, we develop an online application based on the DeepTrio model. The PPI prediction results and <italic toggle="yes">importance maps</italic> can be easily obtained by submitting two protein sequences to the web server. Moreover, the results from multiple submissions will be recorded on the web page, and they can be conveniently filtered and downloaded from the website. This online application is available at <ext-link xlink:href="http://bis.zju.edu.cn/deeptrio" ext-link-type="uri">http://bis.zju.edu.cn/deeptrio</ext-link>.</p>
    </sec>
  </sec>
  <sec>
    <title>4 Conclusion</title>
    <p>With the development of deep-learning algorithms such as CNN (<xref rid="btab737-B20" ref-type="bibr">LeCun and Bengio, 1995</xref>), recurrent neural networks (<xref rid="btab737-B12" ref-type="bibr">Hochreiter and Schmidhuber, 1997</xref>) and graph neural networks (<xref rid="btab737-B33" ref-type="bibr">Scarselli <italic toggle="yes">et al.</italic>, 2009</xref>), an increasing number of sequence-based deep-learning methods have been developed for PPI prediction. A state-of-the-art approach, PIPR, adopts an RCNN architecture to capture the local features and contextualized information and has achieved remarkable performance, whereas it does not provide a convenient implementation for inexperienced users and a visualization method to make the model interpretable. However, DeepTrio provides a superior prediction for PPI and an intuitive visualization for the importance of each protein residue in both online and offline implements. Besides, a variety of experimental evaluations show that the additional single-protein training indeed improves the performance of PPI prediction by inherently preventing weight polarization. For future work, a possible direction is to incorporate molecular docking calculation into DeepTrio for more accurate prediction of key regions for PPI. We also explore the possibilities of using dynamic visualization techniques to interpret our model better.</p>
    <p>In summary, we propose a deep-learning-based model, DeepTrio, to predict PPIs using raw protein sequences. By adopting the multiple parallel convolution filter architecture that allows DeepTrio to capture the deep features from the protein profiles, our model achieves encouraging performance on the benchmark datasets in terms of various evaluation metrics. We also integrate the single-protein training strategy and masking operation to prevent weight polarization in the intermediary layers and enable DeepTrio to visualize the contribution of each protein residue to the prediction results. Furthermore, we also provide an online application for PPI prediction and important residue detection.</p>
  </sec>
  <sec>
    <title>Funding</title>
    <p>This work was supported by the National Key Research and Development Program of China [2016YFA0501704, 2018YFC0310602]; the National Natural Sciences Foundation of China [31771477, 32070677]; the 151 Talent Project of Zhejiang Province (first level); Jiangsu Collaborative Innovation Center for Modern Crop Production and Collaborative Innovation Center for Modern Crop Production cosponsored by province and ministry.</p>
    <p><italic toggle="yes">Conflict of Interest</italic>: none declared. </p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material id="sup1" position="float" content-type="local-data">
      <label>btab737_Supplementary_Data</label>
      <media xlink:href="btab737_supplementary_data.docx">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="btab737-B1">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Abadi</surname><given-names>M.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2016</year>) Tensorflow: a system for large-scale machine learning. In: <italic toggle="yes"><italic toggle="yes">Proceedings of the 12th USENIX Conference on Operating Systems Design and Implementation</italic>,</italic><italic toggle="yes">OSDI’16</italic>, pp. 265–283. USENIX Association, Berkeley, CA, USA.</mixed-citation>
    </ref>
    <ref id="btab737-B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Alipanahi</surname><given-names>B.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2015</year>) <article-title>Predicting the sequence specificities of DNA- and RNA-binding proteins by deep learning</article-title>. <source>Nat. Biotechnol</source>., <volume>33</volume>, <fpage>831</fpage>–<lpage>838</lpage>.<pub-id pub-id-type="pmid">26213851</pub-id></mixed-citation>
    </ref>
    <ref id="btab737-B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Altschul</surname><given-names>S.F.</given-names></string-name></person-group>  <etal>et al</etal> (<year>1997</year>) <article-title>Gapped BLAST and PSI-BLAST: a new generation of protein database search programs</article-title>. <source>Nucleic Acids Res</source>., <volume>25</volume>, <fpage>3389</fpage>–<lpage>3402</lpage>.<pub-id pub-id-type="pmid">9254694</pub-id></mixed-citation>
    </ref>
    <ref id="btab737-B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chen</surname><given-names>M.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2019</year>) <article-title>Multifaceted protein–protein interaction prediction based on Siamese residual RCNN</article-title>. <source>Bioinformatics</source>, <volume>35</volume>, <fpage>i305</fpage>–<lpage>i314</lpage>.<pub-id pub-id-type="pmid">31510705</pub-id></mixed-citation>
    </ref>
    <ref id="btab737-B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cortes</surname><given-names>C.</given-names></string-name>, <string-name><surname>Vapnik</surname><given-names>V.</given-names></string-name></person-group> (<year>1995</year>) <article-title>Support-vector networks</article-title>. <source>Mach. Learn</source>., <volume>20</volume>, <fpage>273</fpage>–<lpage>297</lpage>.</mixed-citation>
    </ref>
    <ref id="btab737-B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Elf</surname><given-names>S.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2016</year>) <article-title>Mutant calreticulin requires both its mutant C-terminus and the thrombopoietin receptor for oncogenic transformation</article-title>. <source>Cancer Discov</source>., <volume>6</volume>, <fpage>368</fpage>–<lpage>381</lpage>.<pub-id pub-id-type="pmid">26951227</pub-id></mixed-citation>
    </ref>
    <ref id="btab737-B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Elf</surname><given-names>S.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2018</year>) <article-title>Defining the requirements for the pathogenic interaction between mutant calreticulin and MPL in MPN</article-title>. <source>Blood</source>, <volume>131</volume>, <fpage>782</fpage>–<lpage>786</lpage>.<pub-id pub-id-type="pmid">29288169</pub-id></mixed-citation>
    </ref>
    <ref id="btab737-B8">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fu</surname><given-names>L.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2012</year>) <article-title>CD-HIT: accelerated for clustering the next-generation sequencing data</article-title>. <source>Bioinformatics</source>, <volume>28</volume>, <fpage>3150</fpage>–<lpage>3152</lpage>.<pub-id pub-id-type="pmid">23060610</pub-id></mixed-citation>
    </ref>
    <ref id="btab737-B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Glorot</surname><given-names>X.</given-names></string-name>, <string-name><surname>Bengio</surname><given-names>Y.</given-names></string-name></person-group> (<year>2010</year>) Understanding the difficulty of training deep feedforward neural networks. In: <italic toggle="yes">Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics (AISTATS 2010)</italic>, Sardinia, Italy, Vol. <volume>9</volume>, pp. <fpage>249</fpage>–<lpage>256</lpage>.</mixed-citation>
    </ref>
    <ref id="btab737-B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Guo</surname><given-names>Y.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2008</year>) <article-title>Using support vector machine combined with auto covariance to predict protein–protein interactions from protein sequences</article-title>. <source>Nucleic Acids Res</source>., <volume>36</volume>, <fpage>3025</fpage>–<lpage>3030</lpage>.<pub-id pub-id-type="pmid">18390576</pub-id></mixed-citation>
    </ref>
    <ref id="btab737-B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hashemifar</surname><given-names>S.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2018</year>) <article-title>Predicting protein–protein interactions through sequence-based deep learning</article-title>. <source>Bioinformatics</source>, <volume>34</volume>, <fpage>i802</fpage>–<lpage>i810</lpage>.<pub-id pub-id-type="pmid">30423091</pub-id></mixed-citation>
    </ref>
    <ref id="btab737-B12">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hochreiter</surname><given-names>S.</given-names></string-name>, <string-name><surname>Schmidhuber</surname><given-names>J.</given-names></string-name></person-group> (<year>1997</year>) <article-title>Long short-term memory</article-title>. <source>Neural Comput</source>., <volume>9</volume>, <fpage>1735</fpage>–<lpage>1780</lpage>.<pub-id pub-id-type="pmid">9377276</pub-id></mixed-citation>
    </ref>
    <ref id="btab737-B13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jones</surname><given-names>S.</given-names></string-name>, <string-name><surname>Thornton</surname><given-names>J.M.</given-names></string-name></person-group> (<year>1996</year>) <article-title>Principles of protein-protein interactions</article-title>. <source>Proc. Natl. Acad. Sci. USA</source>, <volume>93</volume>, <fpage>13</fpage>–<lpage>20</lpage>.<pub-id pub-id-type="pmid">8552589</pub-id></mixed-citation>
    </ref>
    <ref id="btab737-B14">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kall</surname><given-names>S.L.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2019</year>) <article-title>Molecular basis for the interaction between human choline kinase alpha and the SH3 domain of the c-Src tyrosine kinase</article-title>. <source>Sci. Rep</source>., <volume>9</volume>, <fpage>1</fpage>–<lpage>13</lpage>.<pub-id pub-id-type="pmid">30626917</pub-id></mixed-citation>
    </ref>
    <ref id="btab737-B15">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kandel</surname><given-names>D.</given-names></string-name></person-group>  <etal>et al</etal> (<year>1996</year>) <article-title>Shuffling biological sequences</article-title>. <source>Discret. Appl. Math</source>., <volume>71</volume>, <fpage>171</fpage>–<lpage>185</lpage>.</mixed-citation>
    </ref>
    <ref id="btab737-B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Khurana</surname><given-names>S.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2018</year>) <article-title>DeepSol: a deep learning framework for sequence-based protein solubility prediction</article-title>. <source>Bioinformatics</source>, <volume>34</volume>, <fpage>2605</fpage>–<lpage>2613</lpage>.<pub-id pub-id-type="pmid">29554211</pub-id></mixed-citation>
    </ref>
    <ref id="btab737-B17">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Kingma</surname><given-names>D.</given-names></string-name>, <string-name><surname>Ba</surname><given-names>J.</given-names></string-name></person-group> (<year>2014</year>) Adam: a method for stochastic optimization. <italic toggle="yes">arXiv</italic> preprint. <italic toggle="yes">arXiv</italic>:1412.6980.</mixed-citation>
    </ref>
    <ref id="btab737-B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kulmanov</surname><given-names>M.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2018</year>) <article-title>DeepGO: predicting protein functions from sequence and interactions using a deep ontology-aware classifier</article-title>. <source>Bioinformatics</source>, <volume>34</volume>, <fpage>660</fpage>–<lpage>668</lpage>.<pub-id pub-id-type="pmid">29028931</pub-id></mixed-citation>
    </ref>
    <ref id="btab737-B19">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lage</surname><given-names>K.</given-names></string-name></person-group> (<year>2014</year>) <article-title>Protein–protein interactions and genetic diseases: the interactome</article-title>. <source>Biochim. Biophys. Acta</source>, <volume>1842</volume>, <fpage>1971</fpage>–<lpage>1980</lpage>.<pub-id pub-id-type="pmid">24892209</pub-id></mixed-citation>
    </ref>
    <ref id="btab737-B20">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>LeCun</surname><given-names>Y.</given-names></string-name>, <string-name><surname>Bengio</surname><given-names>Y.</given-names></string-name></person-group> (<year>1995</year>) <article-title>Convolutional networks for images, speech, and time series</article-title>. In: Arbib,M.A. (ed.) <source>The Handbook of Brain Theory and Neural Networks</source>, Vol. <volume>3361</volume>. MIT Press, Boston, MA.</mixed-citation>
    </ref>
    <ref id="btab737-B21">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Li</surname><given-names>H.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2018</year>) <article-title>Deep neural network based predictions of protein interactions using primary sequences</article-title>. <source>Molecules</source>, <volume>23</volume>, <fpage>1923</fpage>.<pub-id pub-id-type="pmid">30071670</pub-id></mixed-citation>
    </ref>
    <ref id="btab737-B22">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Li</surname><given-names>W.</given-names></string-name>, <string-name><surname>Godzik</surname><given-names>A.</given-names></string-name></person-group> (<year>2006</year>) <article-title>CD-HIT: a fast program for clustering and comparing large sets of protein or nucleotide sequences</article-title>. <source>Bioinformatics</source>, <volume>22</volume>, <fpage>1658</fpage>–<lpage>1659</lpage>.<pub-id pub-id-type="pmid">16731699</pub-id></mixed-citation>
    </ref>
    <ref id="btab737-B23">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Liu-Wei</surname><given-names>W.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2021</year>) <article-title>DeepViral: prediction of novel virus-host interactions from protein sequences and infectious disease phenotypes</article-title>. <source>Bioinformatics</source>, <volume>37</volume>, <fpage>2722</fpage>–<lpage>2729</lpage>.<pub-id pub-id-type="pmid">33682875</pub-id></mixed-citation>
    </ref>
    <ref id="btab737-B24">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Montavon</surname><given-names>G.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2017</year>) <article-title>Explaining nonlinear classification decisions with deep Taylor decomposition</article-title>. <source>Pattern Recognit</source>., <volume>65</volume>, <fpage>211</fpage>–<lpage>222</lpage>.</mixed-citation>
    </ref>
    <ref id="btab737-B25">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nangalia</surname><given-names>J.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2013</year>) <article-title>Somatic CALR mutations in myeloproliferative neoplasms with nonmutated JAK2</article-title>. <source>N. Engl. J. Med</source>., <volume>369</volume>, <fpage>2391</fpage>–<lpage>2405</lpage>.<pub-id pub-id-type="pmid">24325359</pub-id></mixed-citation>
    </ref>
    <ref id="btab737-B26">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Oughtred</surname><given-names>R.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2019</year>) <article-title>The BioGRID interaction database: 2019 update</article-title>. <source>Nucleic Acids Res</source>., <volume>47</volume>, <fpage>D529</fpage>–<lpage>D541</lpage>.<pub-id pub-id-type="pmid">30476227</pub-id></mixed-citation>
    </ref>
    <ref id="btab737-B27">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ramírez De Molina</surname><given-names>A.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2002</year>) <article-title>Increased choline kinase activity in human breast carcinomas: clinical evidence for a potential novel antitumor strategy</article-title>. <source>Oncogene</source>, <volume>21</volume>, <fpage>4317</fpage>–<lpage>4322</lpage>.<pub-id pub-id-type="pmid">12082619</pub-id></mixed-citation>
    </ref>
    <ref id="btab737-B28">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ramírez De Molina</surname><given-names>A.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2005</year>) <article-title>Choline kinase is a novel oncogene that potentiates RhoA-induced carcinogenesis</article-title>. <source>Cancer Res</source>., <volume>65</volume>, <fpage>5647</fpage>–<lpage>5653</lpage>.<pub-id pub-id-type="pmid">15994937</pub-id></mixed-citation>
    </ref>
    <ref id="btab737-B29">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rawi</surname><given-names>R.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2018</year>) <article-title>PaRSnIP: sequence-based protein solubility prediction using gradient boosting machine</article-title>. <source>Bioinformatics</source>, <volume>34</volume>, <fpage>1092</fpage>–<lpage>1098</lpage>.<pub-id pub-id-type="pmid">29069295</pub-id></mixed-citation>
    </ref>
    <ref id="btab737-B30">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Reddi</surname><given-names>S.J.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2019</year>) On the convergence of Adam and beyond. <italic toggle="yes">arXiv</italic> preprint. <italic toggle="yes">arXiv</italic>:1904.09237.</mixed-citation>
    </ref>
    <ref id="btab737-B31">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Salwinski</surname><given-names>L.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2004</year>) <article-title>The database of interacting proteins: 2004 update</article-title>. <source>Nucleic Acids Res</source>., <volume>32</volume>, <fpage>D449</fpage>–<lpage>D451</lpage>.<pub-id pub-id-type="pmid">14681454</pub-id></mixed-citation>
    </ref>
    <ref id="btab737-B32">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Savojardo</surname><given-names>C.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2018</year>) <article-title>DeepSig: deep learning improves signal peptide detection in proteins</article-title>. <source>Bioinformatics</source>, <volume>34</volume>, <fpage>1690</fpage>–<lpage>1696</lpage>.<pub-id pub-id-type="pmid">29280997</pub-id></mixed-citation>
    </ref>
    <ref id="btab737-B33">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Scarselli</surname><given-names>F.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2009</year>) <article-title>The graph neural network model</article-title>. <source>IEEE Trans. Neural Netw</source>., <volume>20</volume>, <fpage>61</fpage>–<lpage>80</lpage>.<pub-id pub-id-type="pmid">19068426</pub-id></mixed-citation>
    </ref>
    <ref id="btab737-B34">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Seo</surname><given-names>S.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2018</year>) <article-title>DeepFam: deep learning based alignment-free method for protein family modeling and prediction</article-title>. <source>Bioinformatics</source>, <volume>34</volume>, <fpage>i254</fpage>–<lpage>i262</lpage>.<pub-id pub-id-type="pmid">29949966</pub-id></mixed-citation>
    </ref>
    <ref id="btab737-B35">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Singh</surname><given-names>R.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2016</year>) <article-title>DeepChrome: deep-learning for predicting gene expression from histone modifications</article-title>. <source>Bioinformatics</source>, <volume>32</volume>, <fpage>i639</fpage>–<lpage>i648</lpage>.<pub-id pub-id-type="pmid">27587684</pub-id></mixed-citation>
    </ref>
    <ref id="btab737-B36">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Stark</surname><given-names>C.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2006</year>) <article-title>BioGRID: a general repository for interaction datasets</article-title>. <source>Nucleic Acids Res</source>., <volume>34</volume>, <fpage>D535</fpage>–<lpage>D539</lpage>.<pub-id pub-id-type="pmid">16381927</pub-id></mixed-citation>
    </ref>
    <ref id="btab737-B37">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>ΘΡSzklarczyk</surname><given-names>D.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2019</year>) <article-title>STRING v11: protein–protein association networks with increased coverage, supporting functional discovery in genome-wide experimental datasets</article-title>. <source>Nucleic Acids Res</source>., <volume>47</volume>, <fpage>D607</fpage>–<lpage>D613</lpage>.<pub-id pub-id-type="pmid">30476243</pub-id></mixed-citation>
    </ref>
    <ref id="btab737-B38">
      <mixed-citation publication-type="other">The GPyOpt Authors. (<year>2016</year>) <article-title>GPyOpt: Bayesian optimization framework in Python</article-title>. <ext-link xlink:href="http://github.com/SheffieldML/GPyOpt" ext-link-type="uri">http://github.com/SheffieldML/GPyOpt (10 January 2021, date last accessed)</ext-link>.</mixed-citation>
    </ref>
    <ref id="btab737-B39">
      <mixed-citation publication-type="journal">UniProt Consortium. (<year>2019</year>) <article-title>UniProt: a worldwide hub of protein knowledge</article-title>. <source>Nucleic Acids Res</source>., <volume>47</volume>, <fpage>D506</fpage>–<lpage>D515</lpage>.<pub-id pub-id-type="pmid">30395287</pub-id></mixed-citation>
    </ref>
    <ref id="btab737-B40">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Uversky</surname><given-names>V.N.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2008</year>) <article-title>Intrinsically disordered proteins in human diseases: introducing the D2 concept</article-title>. <source>Annu. Rev. Biophys</source>., <volume>37</volume>, <fpage>215</fpage>–<lpage>246</lpage>.<pub-id pub-id-type="pmid">18573080</pub-id></mixed-citation>
    </ref>
    <ref id="btab737-B41">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname><given-names>D.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2019</year>) <article-title>Optimized CRISPR guide RNA design for two high-fidelity Cas9 variants by deep learning</article-title>. <source>Nat. Commun</source>., <volume>10</volume>, <fpage>1</fpage>–<lpage>14</lpage>.<pub-id pub-id-type="pmid">30602773</pub-id></mixed-citation>
    </ref>
    <ref id="btab737-B42">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname><given-names>X.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2020</year>) <article-title>Protein docking model evaluation by 3D deep convolutional neural networks</article-title>. <source>Bioinformatics</source>, <volume>36</volume>, <fpage>2113</fpage>–<lpage>2118</lpage>.<pub-id pub-id-type="pmid">31746961</pub-id></mixed-citation>
    </ref>
    <ref id="btab737-B43">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname><given-names>Y.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2018</year>) <article-title>Predicting protein interactions using a deep learning method-stacked sparse autoencoder combined with a probabilistic classification vector machine</article-title>. <source>Complexity</source>, <volume>2018</volume>, <fpage>1</fpage>–<lpage>12</lpage>.</mixed-citation>
    </ref>
    <ref id="btab737-B44">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Xenarios</surname><given-names>I.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2002</year>) <article-title>DIP, the database of interacting proteins: a research tool for studying cellular networks of protein interactions</article-title>. <source>Nucleic Acids Res</source>., <volume>30</volume>, <fpage>303</fpage>–<lpage>305</lpage>.<pub-id pub-id-type="pmid">11752321</pub-id></mixed-citation>
    </ref>
    <ref id="btab737-B45">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Xu</surname><given-names>B.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2015</year>) Empirical evaluation of rectified activations in convolutional network. <italic toggle="yes">arXiv</italic> preprint. <italic toggle="yes">arXiv</italic>:1505.00853.</mixed-citation>
    </ref>
    <ref id="btab737-B46">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yao</surname><given-names>Y.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2019</year>) <article-title>An integration of deep learning with feature embedding for protein–protein interaction prediction</article-title>. <source>PeerJ</source>, <volume>7</volume>, <fpage>e7126</fpage>.<pub-id pub-id-type="pmid">31245182</pub-id></mixed-citation>
    </ref>
    <ref id="btab737-B47">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Yosinski</surname><given-names>J.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2015</year>) Understanding neural networks through deep visualization. <italic toggle="yes">arXiv</italic> preprint. <italic toggle="yes">arXiv</italic>:1506.06579.</mixed-citation>
    </ref>
    <ref id="btab737-B48">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>You</surname><given-names>Z.-H.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2014</year>) <article-title>Prediction of protein–protein interactions from amino acid sequences using a novel multi-scale continuous and discontinuous feature set</article-title>. <source>BMC Bioinformatics</source>, <volume>15</volume>, <fpage>S9</fpage>.</mixed-citation>
    </ref>
    <ref id="btab737-B49">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>You</surname><given-names>Z.-H.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2015</year>) <article-title>Predicting protein-protein interactions from primary protein sequences using a novel multi-scale local feature representation scheme and the random forest</article-title>. <source>PLoS One</source>, <volume>10</volume>, <fpage>e0125811</fpage>.<pub-id pub-id-type="pmid">25946106</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
