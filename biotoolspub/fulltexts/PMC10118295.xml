<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Database (Oxford)</journal-id>
    <journal-id journal-id-type="iso-abbrev">Database (Oxford)</journal-id>
    <journal-id journal-id-type="publisher-id">databa</journal-id>
    <journal-title-group>
      <journal-title>Database: The Journal of Biological Databases and Curation</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1758-0463</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
      <publisher-loc>UK</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">10118295</article-id>
    <article-id pub-id-type="pmid">37079891</article-id>
    <article-id pub-id-type="doi">10.1093/database/baad023</article-id>
    <article-id pub-id-type="publisher-id">baad023</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Original Article</subject>
      </subj-group>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI00960</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>CARD*Shark: automated prioritization of literature curation for the Comprehensive Antibiotic Resistance Database</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Edalatmand</surname>
          <given-names>Arman</given-names>
        </name>
        <aff><institution content-type="department">David Braley Centre for Antibiotic Discovery, McMaster University</institution>, 1280 Main Street West, Hamilton, ON L8S 4L8, <country country="CA">Canada</country></aff>
        <aff><institution content-type="department">Michael G. DeGroote Institute for Infectious Disease Research, McMaster University</institution>, 1280 Main Street West, Hamilton, ON L8S 4L8, <country country="CA">Canada</country></aff>
        <aff><institution content-type="department">Department of Biochemistry and Biomedical Sciences, McMaster University</institution>, 1280 Main Street West, Hamilton, ON L8S 4L8, <country country="CA">Canada</country></aff>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-1142-3063</contrib-id>
        <name>
          <surname>McArthur</surname>
          <given-names>Andrew G</given-names>
        </name>
        <!--mcarthua@mcmaster.ca-->
        <xref rid="COR0001" ref-type="corresp"/>
        <aff><institution content-type="department">David Braley Centre for Antibiotic Discovery, McMaster University</institution>, 1280 Main Street West, Hamilton, ON L8S 4L8, <country country="CA">Canada</country></aff>
        <aff><institution content-type="department">Michael G. DeGroote Institute for Infectious Disease Research, McMaster University</institution>, 1280 Main Street West, Hamilton, ON L8S 4L8, <country country="CA">Canada</country></aff>
        <aff><institution content-type="department">Department of Biochemistry and Biomedical Sciences, McMaster University</institution>, 1280 Main Street West, Hamilton, ON L8S 4L8, <country country="CA">Canada</country></aff>
      </contrib>
    </contrib-group>
    <author-notes>
      <corresp id="COR0001">*Corresponding author: Tel: 1-905-525-9140 x 21663; Email: <email xlink:href="mcarthua@mcmaster.ca">mcarthua@mcmaster.ca</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2023-04-20">
      <day>20</day>
      <month>4</month>
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>20</day>
      <month>4</month>
      <year>2023</year>
    </pub-date>
    <volume>2023</volume>
    <elocation-id>baad023</elocation-id>
    <history>
      <date date-type="received">
        <day>22</day>
        <month>11</month>
        <year>2022</year>
      </date>
      <date date-type="rev-recd">
        <day>01</day>
        <month>3</month>
        <year>2023</year>
      </date>
      <date date-type="accepted">
        <day>27</day>
        <month>3</month>
        <year>2023</year>
      </date>
      <date date-type="editorial-decision">
        <day>20</day>
        <month>3</month>
        <year>2023</year>
      </date>
      <date date-type="corrected-typeset">
        <day>20</day>
        <month>4</month>
        <year>2023</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2023. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2023</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="baad023.pdf"/>
    <abstract>
      <title>Abstract</title>
      <p>Scientific literature is published at a rate that makes manual data extraction a highly time-consuming task. The Comprehensive Antibiotic Resistance Database (CARD) utilizes literature to curate information on antimicrobial resistance genes and to enable time-efficient triage of publications we have developed a classification algorithm for identifying publications describing first reports of new resistance genes. Trained on publications contained in the CARD, CARD*Shark downloads, processes and identifies publications recently added to PubMed that should be reviewed by biocurators. With CARD*Shark, we can minimize the monthly scope of articles a biocurator reviews from hundreds of articles to a few dozen, drastically improving the speed of curation while ensuring no relevant publications are overlooked.</p>
      <p><bold>Database URL</bold>
 <ext-link xlink:href="http://card.mcmaster.ca" ext-link-type="uri">http://card.mcmaster.ca</ext-link></p>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Canadian Institutes of Health Research</institution>
            <institution-id institution-id-type="DOI">10.13039/501100000024</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>PJT-156214</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Canada Foundation for Innovation</institution>
            <institution-id institution-id-type="DOI">10.13039/501100000196</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>34531</award-id>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="6"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec id="s2">
    <title>Introduction</title>
    <p>Antimicrobial resistance (AMR) is a health-care crisis estimated to cause the death of 10 million individuals and cost $100 trillion worldwide by 2050 (<xref rid="R1" ref-type="bibr">1</xref>). Antimicrobial misuse in both clinical and agricultural settings has undermined the effectiveness of molecules responsible for an otherwise miracle of modern medicine (<xref rid="R2" ref-type="bibr">2</xref>), i.e. our ability to control infection by bacterial pathogens since the early 20th century. Yet even as bacteria evolve mechanisms to resist current antimicrobials, the discovery pipeline for new candidate molecules has become moribund (<xref rid="R3" ref-type="bibr">3</xref>, <xref rid="R4" ref-type="bibr">4</xref>). With this dire background, phenotypic and genotypic surveillance of AMR is increasingly important at regional, national and international levels to assess risk and inform policy, while new machine learning approaches hold promise for personalized medicine based on pathogen genome sequencing to guide treatment of individuals while favoring stewardship of antimicrobials for the broader community (<xref rid="R5" ref-type="bibr">5–8</xref>).</p>
    <p>Understanding the mechanisms underlying AMR is of great importance for the targeted treatment of bacterial infections and for community risk assessment. With an understanding of the suite of AMR genes (ARGs) found in a pathogen together with the antibiotics they confer resistance toward, we come closer to predicting the phenotypic antibiogram of a pathogen (<xref rid="R9" ref-type="bibr">9</xref>). As such, sequencing of pathogen genomes from individual infections, among communities, and in different environments is in increasing use in research, public health and industry. With this increased effort in sequencing of bacterial pathogens comes the need for accurate annotation of ARGs within these genome sequences and an increasing number of tools and databases exist for this annotation effort. While many are specialized to specific pathogens, drug classes or mechanisms of resistance, several databases and associated tools attempt to annotate the entire catalog of known ARGs for genome assemblies or metagenomic reads, foremost among these being the Comprehensive Antibiotic Resistance Database (CARD) (<xref rid="R10" ref-type="bibr">10</xref>), ResFinder (<xref rid="R11" ref-type="bibr">11</xref>) and the National Center for Biotechnology Information Pathogen Detection Reference Gene Catalog (<xref rid="R12" ref-type="bibr">12</xref>). Yet, AMR is a unique curation challenge as the antimicrobial resistome spans numerous environments, and the misuse of antimicrobials can create selective pressure upon new targets, leading to new resistance ARGs and mechanisms. Furthermore, ARGs are often associated with mobile genetic elements such as plasmids, allowing ARGs emerging in environmental settings to move into agricultural settings and follow the farm-to-fork route to clinical settings. Novel ARGs are quickly being discovered with the expansion of next-generation sequencing efforts, and it has become difficult for teams of biocurators to efficiently identify the subset of literature discussing novel ARGs or mutations within the corpus of the AMR literature (∼8000 new publications per year).</p>
    <p>CARD is an ontological-driven database of ARGs and individual mutations conferring resistance in a broad range of bacterial species, including those found in clinical, agricultural and environmental settings (<xref rid="R10" ref-type="bibr">10</xref>). Powered by the Antibiotic Resistance Ontology (ARO), CARD seeks to catalog all known ARGs, their products and associated phenotypes within both an ontological context (i.e. connecting ARGs to antibiotics, AMR mechanisms, and evolution from drug targets) and bioinformatic context (i.e. collating reference sequences and mapped mutations in the context of bioinformatic parameters for their accurate prediction in new genomic data). Upon this knowledge base, CARD layers software tools for genome or metagenome annotation, design of bait capture platforms, and annotation of &gt;100 000 genomes, plasmids or shotgun assemblies to provide comprehensive resistome, variants, and prevalence information. Yet, at its base CARD relies heavily on manual, expert curation of ARGs (<xref rid="R10" ref-type="bibr">10</xref>, <xref rid="R13" ref-type="bibr">13</xref>). In particular, curators seek to ensure CARD and the ARO have information on all ARGs upon their first description and that ‘to be included in CARD an AMR determinant must be described in a peer-reviewed scientific publication, with its DNA sequence available in GenBank, including clear experimental evidence of elevated minimum inhibitory concentration (MIC) over controls’ (<xref rid="R10" ref-type="bibr">10</xref>). Given the high pace of the discovery of new ARGs, manual triage of the scientific literature proved inefficient, and the CARD team developed word-association scoring matrices to prioritize publications in PubMed for manual investigation by curators (<xref rid="R10" ref-type="bibr">10</xref>, <xref rid="R13" ref-type="bibr">13</xref>). However, this method proved to have several limitations, outlined below, and here we report the development of supervised learning methods for the identification and prioritization of scientific publications containing newly described ARGs for curation into CARD. This work is informative for the development of automated or algorithm-assisted curation of the scientific literature and provides details on CARD’s approach for ensuring comprehensive curation of ARGs for annotation of newly sequenced genomes or metagenomes.</p>
  </sec>
  <sec id="s3">
    <title>Materials and methods</title>
    <sec id="s3-s1">
      <title>Prioritization via word-association scoring matrices (CARD*Shark 2)</title>
      <p>The CARD team initially attempted the use of word-association scoring matrices to prioritize papers in PubMed. After two rounds of development, the Python-based CARD*Shark 2 algorithm guided curators to relevant papers using an algorithm that scored papers based on their abstract similarity to papers previously curated in CARD for ARGs. For example, for macrolide antibiotics, using the relative frequencies of each word in the abstracts of all papers associated with macrolides in CARD, CARD*Shark 2 calculates a score for each macrolide-associated paper by taking the sum of relative frequencies of all abstract words. Based on the score, it assigned new papers in PubMed to a low- or high-level group that dictates the papers’ relevance to curators if the score falls below or above a cut-off, respectively. For our analysis, papers assigned to the high-level group are considered positive predictions, and low-level papers are considered negative predictions. Although the algorithm provided curators with a reasonable set of papers to triage, there were a few key limitations. First, CARD*Shark 2 pulled papers from PubMed on a monthly basis using only drug class terms found in CARD’s ARO as query terms, ignoring words for individual antibiotics or ARGs and thus potentially missing important papers when an abstract does not discuss a drug class directly. In addition, papers in PubMed can include multiple drug class terms and are thus scored differently by each drug class–specific scoring matrix. Such papers could be reported under multiple drug class search results, creating redundancy and inefficiency for curators, but also inconsistency as papers could appear low level in one drug class group but high level in another. Finally, every paper CARD*Shark 2 examined was considered a positive result even if the initial PubMed query result included non-AMR papers, yet the scoring was often not discriminatory and forced a manual review of all papers by curators. With these flaws in mind, we were interested in implementing a machine learning version of CARD*Shark that reviewed all recently added PubMed articles monthly and identified all relevant publications with high recall, while not overburdening the curator with too many false positives, i.e. low precision.</p>
    </sec>
    <sec id="s3-s2">
      <title>Paper retrieval, preprocessing and feature extraction for supervised learning</title>
      <p>The type of problem CARD*Shark 2 aims to solve is one of binary classification: given an input of publications newly added to PubMed, we wish to assign a pass/fail on whether they contain valuable new information for curation into CARD. Many machine learning algorithms can solve binary classification problems and we examined these as possible improvements upon CARD*Shark 2. Machine learning classification algorithms fall into two broad categories: supervised learning and unsupervised learning (<xref rid="R14" ref-type="bibr">14</xref>). Unsupervised learning methods use clustering methods on unlabeled data to identify unknown groups of data (<xref rid="R14" ref-type="bibr">14</xref>), while supervised algorithms require two steps: a training step and a prediction or testing step. For supervised algorithms, the training step involves using a processed, pre-labeled set of data that can be fed to the algorithm to generate a model. This model is then used to predict results for performance analysis and subsequent real-world application.</p>
      <p>For the classification of the scientific literature, we examined supervised classification algorithms including logistic regression, naive Bayes, random forest, extreme gradient boosting and support vector machines to determine the best-performing approach to guide the curation of papers into CARD. To create prediction models for classification tasks, we used PubMed’s Entrez application programming interface (API) to retrieve abstracts and metadata from PubMed’s database (<xref rid="R15" ref-type="bibr">15</xref>) as a step toward creating a set of features for training models. The retrieved papers were then preprocessed using the Natural Language Toolkit (NLTK) and the regular expression package in python (<xref rid="R16" ref-type="bibr">16</xref>) to help normalize and reduce redundancy within the text (<xref rid="R17" ref-type="bibr">17</xref>). Preprocessing is an important step to help improve model performance by removing any non-essential terms from the text, removing punctuation, converting terms to their base form and removing digits (<xref rid="R17" ref-type="bibr">17</xref>). Using regular expressions, we first removed punctuation from abstracts. Then, after splitting abstracts into individual words, stopwords provided by the NLTK package were removed along with digits. A Porter stemmer then converted each remaining word to its base form (<xref rid="R18" ref-type="bibr">18</xref>), and collectively these preprocessing steps resulted in abstracts containing a series of normalized words.</p>
      <p>Once preprocessed, the procedure of converting data into usable vectors for machine learning is called feature extraction and aims to reduce the dimensionality of data for algorithmic use. The two major types of dimensionality reduction that can be applied to text include bag-of-words (BOW) and term frequency–inverse document frequency (TF–IDF) (<xref rid="R19" ref-type="bibr">19</xref>, <xref rid="R20" ref-type="bibr">20</xref>). BOW, like its name suggests, involves counting the number of occurrences of a word in a document. TF–IDF can be considered a more sophisticated version of BOW as it takes the frequency of words appearing in a text and multiplies it by the logarithm of the inverse fraction of documents containing the word (<xref rid="R19" ref-type="bibr">19</xref>). TF–IDF helps classifiers ignore words that appear too commonly, giving more weight to other words more relevant to the information extraction task at hand. To assess the relative strengths of each approach, the normalized abstracts were converted into usable vectors following three approaches using scikit-learn (<xref rid="R21" ref-type="bibr">21</xref>): TF–IDF on bigrams and trigrams, BOW, and TF–IDF on individual words. Each method was applied separately to produce three separate training/testing sets for evaluation by each of the different supervised learning approaches.</p>
    </sec>
    <sec id="s3-s3">
      <title>Model training and cross-validation</title>
      <p>To determine the best classifier and using scikit-learn (<xref rid="R21" ref-type="bibr">21</xref>), we trained and tested logistic regression, naive Bayes, random forest, extreme gradient boosting and support vector machines through 5-fold stratified cross-validation for each set of normalized abstracts. We trained/tested models on a set of 9710 papers, of which 1886 papers were previously curated into CARD within ‘AMR Gene Family’ tagged ontology terms as our positive set. The remaining 7824 papers acted as our negative set, i.e. low-scoring predictions obtained from CARD*Shark 2 but not added to CARD by human curators. Of the total set of papers, 75% was used for initial model training and testing through cross-validation, with the remaining 25% of papers used for a final holdout evaluation. After 5-fold cross-validation, we calculated precision (i.e. the proportion of papers classified as curation-worthy that were in the 1886 paper positive set), recall (i.e. the proportion of the 1886 paper positive set classified as curation-worthy) and the <italic toggle="yes">F</italic><sub>1</sub> statistic (i.e. the harmonic mean of precision and recall). For comparison, we also scored the 9710 papers using CARD*Shark 2 with 5-fold stratified cross-validation.</p>
    </sec>
    <sec id="s3-s4">
      <title>Human validation</title>
      <p>Papers for September and November 2019 were obtained from PubMed using the MeSH ‘[Date—Create]’ query via the Entrez API (i.e. ‘start date’ [Date - Create]: ‘end date’ [Date - Create]). We processed these papers, as outlined earlier, and classified them using the models generated from cross-validation. For independent human validation of the classifiers, 100 papers were randomly selected from the September logistic regression predictions, with an even 50/50 split between classification results (i.e. 50% predicted positive and 50% predicted negative), while for the November set, a total of 330 papers were selected for validation (half provided by selecting an even split of predictions from naive Bayes and the other half from an even split of predictions from random forest). Subsequently, a group of 11 experienced CARD curators reviewed each paper by answering a series of three questions to generate binary labels for each paper, with two individuals reviewing each paper. The subset of algorithms examined during human validation was based on the best-performing approaches during initial investigations, instead of all possible algorithms, to reduce the overall effort required by our human curators. The three questions asked of the human curators were the following: ‘Is there an AMR gene described in the abstract’, ‘Is there an elevated MIC anywhere in the paper’ and ‘Would you curate the gene into CARD based solely on the abstract?’ If conflicting labels arose, the paper was not included in the final validation results; otherwise, the human curator results were compared to the supervised model predictions as an independent assessment of performance.</p>
    </sec>
  </sec>
  <sec id="s4">
    <title>Results and discussion</title>
    <p>With the overwhelming number of papers added every month to PubMed, it is difficult for curators to triage the whole scope of domain-specific literature. CARD had previously developed CARD*Shark 2 to address the issue of reducing the number of papers individual curators needed to review to identify novel ARGs. However, there were limitations with this word-association scoring algorithm in both the scope of papers it scored and the grouping of papers. To improve upon CARD*Shark 2 while expanding the scope of papers examined, we created and tested a set of supervised learning models that would predict whether a paper contained information appropriate for curation into CARD. To identify the best-performing model, we evaluated five supervised learning methods through cross-validation. All the supervised learning models achieved receiver operating characteristic (ROC) area under the curves of &gt;0.94, while CARD*Shark 2 obtained an area under the curve of 0.88 (<xref rid="F1" ref-type="fig">Figure 1</xref>). Similarly, the precision and <italic toggle="yes">F</italic><sub>1</sub> results of CARD*Shark 2 underperformed in comparison to most supervised learning models (<xref rid="T1" ref-type="table">Table 1</xref>), although not surprisingly CARD*Shark 2 was able to recall 97% of papers already curated into CARD while suffering from low precision (i.e. also predicting many unworthy papers as curation-worthy). Overall, results from cross-validation of the supervised learning models showed that these methods can achieve a better performance compared to the current CARD*Shark 2 algorithm. However, solely based on cross-validation, it was difficult to discern the best-performing supervised learning model.</p>
    <fig position="float" id="F1" fig-type="figure">
      <label>Figure 1.</label>
      <caption>
        <p>CARD*Shark 2 and supervised learning cross-validation ROC curves. Results from 5-fold cross-validation of several supervised learning models using three feature extraction methods, plus CARD*Shark 2. Results from all five cross-validation tests were averaged to produce a single curve. Shadows around each line are ±1SD from the mean. For CARD*Shark 2, high-level predictions are considered positive predictions, and low-level predictions are considered negative predictions.</p>
      </caption>
      <graphic xlink:href="baad023f1" position="float"/>
    </fig>
    <table-wrap position="float" id="T1">
      <label>Table 1.</label>
      <caption>
        <p>CARD*Shark 2 and supervised learning cross-validation precision-recall statistics</p>
      </caption>
      <table frame="hsides" rules="groups">
        <colgroup span="1">
          <col align="left" span="1"/>
          <col align="left" span="1"/>
          <col align="left" span="1"/>
          <col align="left" span="1"/>
          <col align="left" span="1"/>
        </colgroup>
        <thead>
          <tr>
            <th valign="bottom" align="left" rowspan="1" colspan="1">Model name</th>
            <th valign="bottom" align="left" rowspan="1" colspan="1">Feature extraction method</th>
            <th valign="bottom" align="left" rowspan="1" colspan="1">Precision</th>
            <th valign="bottom" align="left" rowspan="1" colspan="1">Recall</th>
            <th valign="bottom" align="left" rowspan="1" colspan="1">
              <italic toggle="yes">F</italic>
              <sub>1</sub>
            </th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td rowspan="3" align="left" colspan="1">Logistic regression</td>
            <td align="left" rowspan="1" colspan="1">TF–IDF bi/trigram</td>
            <td align="left" rowspan="1" colspan="1">0.96</td>
            <td align="left" rowspan="1" colspan="1">0.41</td>
            <td align="left" rowspan="1" colspan="1">0.58</td>
          </tr>
          <tr>
            <td align="left" rowspan="1" colspan="1">TF–IDF word</td>
            <td align="left" rowspan="1" colspan="1">0.92</td>
            <td align="left" rowspan="1" colspan="1">0.81</td>
            <td align="left" rowspan="1" colspan="1">0.86</td>
          </tr>
          <tr>
            <td align="left" rowspan="1" colspan="1">BOW</td>
            <td align="left" rowspan="1" colspan="1">0.89</td>
            <td align="left" rowspan="1" colspan="1">0.88</td>
            <td align="left" rowspan="1" colspan="1">
              <underline>0.89</underline>
            </td>
          </tr>
          <tr>
            <td rowspan="3" align="left" colspan="1">Naive Bayes</td>
            <td align="left" rowspan="1" colspan="1">TF–IDF bi/trigram</td>
            <td align="left" rowspan="1" colspan="1">
              <underline>1.00</underline>
            </td>
            <td align="left" rowspan="1" colspan="1">0.26</td>
            <td align="left" rowspan="1" colspan="1">0.41</td>
          </tr>
          <tr>
            <td align="left" rowspan="1" colspan="1">TF–IDF word</td>
            <td align="left" rowspan="1" colspan="1">0.99</td>
            <td align="left" rowspan="1" colspan="1">0.36</td>
            <td align="left" rowspan="1" colspan="1">0.52</td>
          </tr>
          <tr>
            <td align="left" rowspan="1" colspan="1">BOW</td>
            <td align="left" rowspan="1" colspan="1">0.74</td>
            <td align="left" rowspan="1" colspan="1">
              <underline>0.96</underline>
            </td>
            <td align="left" rowspan="1" colspan="1">0.83</td>
          </tr>
          <tr>
            <td rowspan="3" align="left" colspan="1">Random forest</td>
            <td align="left" rowspan="1" colspan="1">TF–IDF bi/trigram</td>
            <td align="left" rowspan="1" colspan="1">0.83</td>
            <td align="left" rowspan="1" colspan="1">0.60</td>
            <td align="left" rowspan="1" colspan="1">0.70</td>
          </tr>
          <tr>
            <td align="left" rowspan="1" colspan="1">TF–IDF word</td>
            <td align="left" rowspan="1" colspan="1">0.89</td>
            <td align="left" rowspan="1" colspan="1">0.66</td>
            <td align="left" rowspan="1" colspan="1">0.76</td>
          </tr>
          <tr>
            <td align="left" rowspan="1" colspan="1">BOW</td>
            <td align="left" rowspan="1" colspan="1">0.90</td>
            <td align="left" rowspan="1" colspan="1">0.66</td>
            <td align="left" rowspan="1" colspan="1">0.76</td>
          </tr>
          <tr>
            <td rowspan="3" align="left" colspan="1">Extreme gradient boosting</td>
            <td align="left" rowspan="1" colspan="1">TF–IDF bi/trigram</td>
            <td align="left" rowspan="1" colspan="1">0.84</td>
            <td align="left" rowspan="1" colspan="1">0.65</td>
            <td align="left" rowspan="1" colspan="1">0.74</td>
          </tr>
          <tr>
            <td align="left" rowspan="1" colspan="1">TF–IDF word</td>
            <td align="left" rowspan="1" colspan="1">0.89</td>
            <td align="left" rowspan="1" colspan="1">0.81</td>
            <td align="left" rowspan="1" colspan="1">0.85</td>
          </tr>
          <tr>
            <td align="left" rowspan="1" colspan="1">BOW</td>
            <td align="left" rowspan="1" colspan="1">0.89</td>
            <td align="left" rowspan="1" colspan="1">0.81</td>
            <td align="left" rowspan="1" colspan="1">0.85</td>
          </tr>
          <tr>
            <td rowspan="3" align="left" colspan="1">Support vector machine</td>
            <td align="left" rowspan="1" colspan="1">TF–IDF bi/trigram</td>
            <td align="left" rowspan="1" colspan="1">-</td>
            <td align="left" rowspan="1" colspan="1">0.00</td>
            <td align="left" rowspan="1" colspan="1">0.00</td>
          </tr>
          <tr>
            <td align="left" rowspan="1" colspan="1">TF–IDF word</td>
            <td align="left" rowspan="1" colspan="1">-</td>
            <td align="left" rowspan="1" colspan="1">0.00</td>
            <td align="left" rowspan="1" colspan="1">0.00</td>
          </tr>
          <tr>
            <td align="left" rowspan="1" colspan="1">BOW</td>
            <td align="left" rowspan="1" colspan="1">0.96</td>
            <td align="left" rowspan="1" colspan="1">0.15</td>
            <td align="left" rowspan="1" colspan="1">0.26</td>
          </tr>
          <tr>
            <td colspan="2" align="left" rowspan="1">CARD*Shark 2</td>
            <td align="left" rowspan="1" colspan="1">0.38</td>
            <td align="left" rowspan="1" colspan="1">0.97</td>
            <td align="left" rowspan="1" colspan="1">0.54</td>
          </tr>
        </tbody>
      </table>
      <table-wrap-foot>
        <fn id="T0001-fn1">
          <p>Results from 5-fold cross-validation of several supervised learning models using three feature extraction methods, plus CARD*Shark 2. Underlined numbers represent the best-performing method for each category. For CARD*Shark 2, high-level predictions are considered positive predictions, and low-level predictions are considered negative predictions.</p>
        </fn>
      </table-wrap-foot>
    </table-wrap>
    <table-wrap position="float" id="T2" orientation="landscape">
      <label>Table 2.</label>
      <caption>
        <p>Model validation results and predictions for November and September 2019 papers</p>
      </caption>
      <table frame="hsides" rules="groups">
        <colgroup span="1">
          <col align="left" span="1"/>
          <col align="left" span="1"/>
          <col align="left" span="1"/>
          <col align="left" span="1"/>
          <col align="left" span="1"/>
          <col align="left" span="1"/>
          <col align="left" span="1"/>
          <col align="left" span="1"/>
          <col align="left" span="1"/>
          <col align="left" span="1"/>
          <col align="left" span="1"/>
        </colgroup>
        <thead>
          <tr>
            <th valign="bottom" align="left" rowspan="1" colspan="1">Model name</th>
            <th valign="bottom" align="left" rowspan="1" colspan="1">Feature extraction method</th>
            <th valign="bottom" align="left" rowspan="1" colspan="1">FN</th>
            <th valign="bottom" align="left" rowspan="1" colspan="1">FP</th>
            <th valign="bottom" align="left" rowspan="1" colspan="1">TN</th>
            <th valign="bottom" align="left" rowspan="1" colspan="1">TP</th>
            <th valign="bottom" align="left" rowspan="1" colspan="1">Precision</th>
            <th valign="bottom" align="left" rowspan="1" colspan="1">Recall</th>
            <th valign="bottom" align="left" rowspan="1" colspan="1">
              <italic toggle="yes">F</italic>
              <sub>1</sub>
            </th>
            <th valign="bottom" align="left" rowspan="1" colspan="1">Negative predictions</th>
            <th valign="bottom" align="left" rowspan="1" colspan="1">Positive predictions</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td rowspan="3" align="left" colspan="1">Logistic regression</td>
            <td align="left" rowspan="1" colspan="1">TF–IDF bi/trigram</td>
            <td align="left" rowspan="1" colspan="1">7</td>
            <td align="left" rowspan="1" colspan="1">6</td>
            <td align="left" rowspan="1" colspan="1">397</td>
            <td align="left" rowspan="1" colspan="1">1</td>
            <td align="left" rowspan="1" colspan="1">0.14</td>
            <td align="left" rowspan="1" colspan="1">0.13</td>
            <td align="left" rowspan="1" colspan="1">0.13</td>
            <td align="left" rowspan="1" colspan="1">241 618</td>
            <td align="left" rowspan="1" colspan="1">187</td>
          </tr>
          <tr>
            <td align="left" rowspan="1" colspan="1">TF–IDF word</td>
            <td align="left" rowspan="1" colspan="1">4</td>
            <td align="left" rowspan="1" colspan="1">42</td>
            <td align="left" rowspan="1" colspan="1">361</td>
            <td align="left" rowspan="1" colspan="1">4</td>
            <td align="left" rowspan="1" colspan="1">0.09</td>
            <td align="left" rowspan="1" colspan="1">0.50</td>
            <td align="left" rowspan="1" colspan="1">0.15</td>
            <td align="left" rowspan="1" colspan="1">240 773</td>
            <td align="left" rowspan="1" colspan="1">1032</td>
          </tr>
          <tr>
            <td align="left" rowspan="1" colspan="1">BOW</td>
            <td align="left" rowspan="1" colspan="1">4</td>
            <td align="left" rowspan="1" colspan="1">96</td>
            <td align="left" rowspan="1" colspan="1">307</td>
            <td align="left" rowspan="1" colspan="1">4</td>
            <td align="left" rowspan="1" colspan="1">0.04</td>
            <td align="left" rowspan="1" colspan="1">0.50</td>
            <td align="left" rowspan="1" colspan="1">0.07</td>
            <td align="left" rowspan="1" colspan="1">237 149</td>
            <td align="left" rowspan="1" colspan="1">4.656</td>
          </tr>
          <tr>
            <td rowspan="3" align="left" colspan="1">Naive Bayes</td>
            <td align="left" rowspan="1" colspan="1">TF–IDF bi/trigram</td>
            <td align="left" rowspan="1" colspan="1">8</td>
            <td align="left" rowspan="1" colspan="1">0</td>
            <td align="left" rowspan="1" colspan="1">403</td>
            <td align="left" rowspan="1" colspan="1">0</td>
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1">0.00</td>
            <td align="left" rowspan="1" colspan="1">0.00</td>
            <td align="left" rowspan="1" colspan="1">241 796</td>
            <td align="left" rowspan="1" colspan="1">9</td>
          </tr>
          <tr>
            <td align="left" rowspan="1" colspan="1">TF–IDF word</td>
            <td align="left" rowspan="1" colspan="1">8</td>
            <td align="left" rowspan="1" colspan="1">0</td>
            <td align="left" rowspan="1" colspan="1">403</td>
            <td align="left" rowspan="1" colspan="1">0</td>
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1">0.00</td>
            <td align="left" rowspan="1" colspan="1">0.00</td>
            <td align="left" rowspan="1" colspan="1">241 788</td>
            <td align="left" rowspan="1" colspan="1">17</td>
          </tr>
          <tr>
            <td align="left" rowspan="1" colspan="1">BOW</td>
            <td align="left" rowspan="1" colspan="1">1</td>
            <td align="left" rowspan="1" colspan="1">92</td>
            <td align="left" rowspan="1" colspan="1">311</td>
            <td align="left" rowspan="1" colspan="1">7</td>
            <td align="left" rowspan="1" colspan="1">0.07</td>
            <td align="left" rowspan="1" colspan="1">
              <underline>0.88</underline>
            </td>
            <td align="left" rowspan="1" colspan="1">0.13</td>
            <td align="left" rowspan="1" colspan="1">237 126</td>
            <td align="left" rowspan="1" colspan="1">4679</td>
          </tr>
          <tr>
            <td rowspan="3" align="left" colspan="1">Random forest</td>
            <td align="left" rowspan="1" colspan="1">TF–IDF bi/trigram</td>
            <td align="left" rowspan="1" colspan="1">3</td>
            <td align="left" rowspan="1" colspan="1">33</td>
            <td align="left" rowspan="1" colspan="1">370</td>
            <td align="left" rowspan="1" colspan="1">5</td>
            <td align="left" rowspan="1" colspan="1">0.13</td>
            <td align="left" rowspan="1" colspan="1">0.63</td>
            <td align="left" rowspan="1" colspan="1">
              <underline>0.22</underline>
            </td>
            <td align="left" rowspan="1" colspan="1">240 570</td>
            <td align="left" rowspan="1" colspan="1">1235</td>
          </tr>
          <tr>
            <td align="left" rowspan="1" colspan="1">TF–IDF Word</td>
            <td align="left" rowspan="1" colspan="1">7</td>
            <td align="left" rowspan="1" colspan="1">30</td>
            <td align="left" rowspan="1" colspan="1">373</td>
            <td align="left" rowspan="1" colspan="1">1</td>
            <td align="left" rowspan="1" colspan="1">0.03</td>
            <td align="left" rowspan="1" colspan="1">0.13</td>
            <td align="left" rowspan="1" colspan="1">0.05</td>
            <td align="left" rowspan="1" colspan="1">240 163</td>
            <td align="left" rowspan="1" colspan="1">1642</td>
          </tr>
          <tr>
            <td align="left" rowspan="1" colspan="1">BOW</td>
            <td align="left" rowspan="1" colspan="1">5</td>
            <td align="left" rowspan="1" colspan="1">38</td>
            <td align="left" rowspan="1" colspan="1">365</td>
            <td align="left" rowspan="1" colspan="1">3</td>
            <td align="left" rowspan="1" colspan="1">0.07</td>
            <td align="left" rowspan="1" colspan="1">0.38</td>
            <td align="left" rowspan="1" colspan="1">0.12</td>
            <td align="left" rowspan="1" colspan="1">240 023</td>
            <td align="left" rowspan="1" colspan="1">1782</td>
          </tr>
          <tr>
            <td rowspan="3" align="left" colspan="1">Extreme gradient boosting</td>
            <td align="left" rowspan="1" colspan="1">TF–IDF bi/trigram</td>
            <td align="left" rowspan="1" colspan="1">5</td>
            <td align="left" rowspan="1" colspan="1">28</td>
            <td align="left" rowspan="1" colspan="1">375</td>
            <td align="left" rowspan="1" colspan="1">3</td>
            <td align="left" rowspan="1" colspan="1">0.10</td>
            <td align="left" rowspan="1" colspan="1">0.38</td>
            <td align="left" rowspan="1" colspan="1">0.15</td>
            <td align="left" rowspan="1" colspan="1">240 882</td>
            <td align="left" rowspan="1" colspan="1">923</td>
          </tr>
          <tr>
            <td align="left" rowspan="1" colspan="1">TF–IDF word</td>
            <td align="left" rowspan="1" colspan="1">4</td>
            <td align="left" rowspan="1" colspan="1">31</td>
            <td align="left" rowspan="1" colspan="1">372</td>
            <td align="left" rowspan="1" colspan="1">4</td>
            <td align="left" rowspan="1" colspan="1">0.11</td>
            <td align="left" rowspan="1" colspan="1">0.50</td>
            <td align="left" rowspan="1" colspan="1">0.19</td>
            <td align="left" rowspan="1" colspan="1">240 165</td>
            <td align="left" rowspan="1" colspan="1">1640</td>
          </tr>
          <tr>
            <td align="left" rowspan="1" colspan="1">BOW</td>
            <td align="left" rowspan="1" colspan="1">6</td>
            <td align="left" rowspan="1" colspan="1">27</td>
            <td align="left" rowspan="1" colspan="1">376</td>
            <td align="left" rowspan="1" colspan="1">2</td>
            <td align="left" rowspan="1" colspan="1">0.07</td>
            <td align="left" rowspan="1" colspan="1">0.25</td>
            <td align="left" rowspan="1" colspan="1">0.11</td>
            <td align="left" rowspan="1" colspan="1">240 290</td>
            <td align="left" rowspan="1" colspan="1">1515</td>
          </tr>
          <tr>
            <td rowspan="3" align="left" colspan="1">Support vector machine</td>
            <td align="left" rowspan="1" colspan="1">TF–IDF bi/trigram</td>
            <td align="left" rowspan="1" colspan="1">8</td>
            <td align="left" rowspan="1" colspan="1">0</td>
            <td align="left" rowspan="1" colspan="1">403</td>
            <td align="left" rowspan="1" colspan="1">0</td>
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1">0.00</td>
            <td align="left" rowspan="1" colspan="1">0.00</td>
            <td align="left" rowspan="1" colspan="1">241 805</td>
            <td align="left" rowspan="1" colspan="1">0</td>
          </tr>
          <tr>
            <td align="left" rowspan="1" colspan="1">TF–IDF word</td>
            <td align="left" rowspan="1" colspan="1">8</td>
            <td align="left" rowspan="1" colspan="1">0</td>
            <td align="left" rowspan="1" colspan="1">403</td>
            <td align="left" rowspan="1" colspan="1">0</td>
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1">0.00</td>
            <td align="left" rowspan="1" colspan="1">0.00</td>
            <td align="left" rowspan="1" colspan="1">241 805</td>
            <td align="left" rowspan="1" colspan="1">0</td>
          </tr>
          <tr>
            <td align="left" rowspan="1" colspan="1">BOW</td>
            <td align="left" rowspan="1" colspan="1">7</td>
            <td align="left" rowspan="1" colspan="1">2</td>
            <td align="left" rowspan="1" colspan="1">401</td>
            <td align="left" rowspan="1" colspan="1">1</td>
            <td align="left" rowspan="1" colspan="1">
              <underline>0.33</underline>
            </td>
            <td align="left" rowspan="1" colspan="1">0.13</td>
            <td align="left" rowspan="1" colspan="1">0.18</td>
            <td align="left" rowspan="1" colspan="1">241 742</td>
            <td align="left" rowspan="1" colspan="1">63</td>
          </tr>
          <tr>
            <td align="left" rowspan="1" colspan="1">CARD*Shark 2</td>
            <td align="left" rowspan="1" colspan="1"/>
            <td align="left" rowspan="1" colspan="1">0</td>
            <td align="left" rowspan="1" colspan="1">165</td>
            <td align="left" rowspan="1" colspan="1">238</td>
            <td align="left" rowspan="1" colspan="1">8</td>
            <td align="left" rowspan="1" colspan="1">0.05</td>
            <td align="left" rowspan="1" colspan="1">
              <underline>1</underline>
            </td>
            <td align="left" rowspan="1" colspan="1">0.09</td>
            <td align="left" rowspan="1" colspan="1">200 906</td>
            <td align="left" rowspan="1" colspan="1">40 899</td>
          </tr>
        </tbody>
      </table>
      <table-wrap-foot>
        <fn id="T0002-fn1">
          <p>TP, TN, FP, FN, precision, recall and <italic toggle="yes">F</italic><sub>1</sub> values represent validation of a random subset of papers by human curators, with underlined numbers representing the best-performing method for precision, recall and <italic toggle="yes">F</italic><sub>1</sub>. Negative predictions represent the number of papers that CARD curators would ignore, while positive predictions are the number of papers requiring review by CARD curators for possible new additions to CARD. For CARD*Shark 2, high-level predictions are considered positive predictions, and low-level predictions are considered negative predictions. TP, true positive; TN, true negative; FP, false positive; FN, false negative.</p>
        </fn>
      </table-wrap-foot>
    </table-wrap>
    <p>To gain a better understanding of each model’s performance in a real-world application, each model made predictions on all papers for September and November 2019 (<xref rid="T2" ref-type="table">Table 2</xref>). A random subset of these papers was used for independent human validation. The main goal of these models was to achieve a high recall value as missing a novel ARG because of a poorly performing model is detrimental to CARD’s overall objectives. The secondary objective of these models was a high precision to reduce the number of papers curators must review. Based on human validation, all the supervised learning models resulted in low precision values of &lt;34%, while naive Bayes obtained the highest recall of 88% (<xref rid="T2" ref-type="table">Table 2</xref>). Despite high recall by naive Bayes, low precision is undesirable as it would result in too many papers for manual review. If we instead focus on models with a good balance between precision and recall via <italic toggle="yes">F</italic><sub>1</sub> values, we find logistic regression, naive Bayes, random forest and extreme gradient boosting each have one model that performs with the highest <italic toggle="yes">F</italic><sub>1</sub> score, with random forest on TF–IDF on bi/trigrams having the best overall performance (<xref rid="T1" ref-type="table">Table 1</xref>). CARD*Shark 2 performs with the best recall (100%) at the cost of having the third lowest precision. The impact of CARD*Shark 2’s low precision can be seen in the 40 899 papers it flags for curator review, more than an order of magnitude higher than any of the supervised learning methods. Future improvements to precision and recall may require the use of an ensemble of the best-performing models. Notably, only 430 papers were selected for human validation out of a set of &gt;200 000 papers, and as such, we cannot definitively conclude that one model is better than another until more papers are evaluated. A more significant issue faced by both CARD*Shark 2 and the supervised learning models is that we do not know the extent of relevant papers being ignored as CARD does not keep a record of negative curations. Moving forward, it would be advisable to mix a subsample of negative predictions into the curation set to evaluate ignored essential papers.</p>
    <p>Continued evaluation of logistic regression, random forest and naive Bayes is being performed through monthly paper predictions that are assessed by CARD’s team of curators. Additionally, a retrospective analysis of each of the models was conducted by predicting papers for the majority of months CARD*Shark 2 has been running (1 July 2017–1 November 2020). During this time, CARD*Shark 2 flagged 22 196 unique papers, 66 of which were added to CARD by the curators (<xref rid="T3" ref-type="table">Table 3</xref>). The benefit of the expanded scope of the supervised learning models can be seen in <xref rid="F2" ref-type="fig">Figure 2</xref>, where 44 papers were successfully identified by the models but never flagged by CARD*Shark 2. At the same time, CARD*Shark 2 was able to identify 16 papers the supervised learning models missed (<xref rid="F2" ref-type="fig">Figure 2</xref>). These results indicate that a combination of CARD*Shark 2 and the supervised learning models may be necessary to identify papers for curation into CARD.</p>
    <table-wrap position="float" id="T3">
      <label>Table 3.</label>
      <caption>
        <p>Retrospective predictions against papers added to PubMed between July 2017 and December 2020</p>
      </caption>
      <table frame="hsides" rules="groups">
        <colgroup span="1">
          <col align="left" span="1"/>
          <col align="left" span="1"/>
          <col align="left" span="1"/>
          <col align="left" span="1"/>
        </colgroup>
        <thead>
          <tr>
            <th valign="bottom" align="left" rowspan="1" colspan="1">Model name</th>
            <th valign="bottom" align="left" rowspan="1" colspan="1">Papers examined</th>
            <th valign="bottom" align="left" rowspan="1" colspan="1">Positive predictions</th>
            <th valign="bottom" align="left" rowspan="1" colspan="1">Added to CARD</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td align="left" rowspan="1" colspan="1">Logistic regression</td>
            <td rowspan="3" align="left" colspan="1">3 955 928</td>
            <td align="left" rowspan="1" colspan="1">30 049</td>
            <td align="left" rowspan="1" colspan="1">75</td>
          </tr>
          <tr>
            <td align="left" rowspan="1" colspan="1">Naive Bayes</td>
            <td align="left" rowspan="1" colspan="1">75 843</td>
            <td align="left" rowspan="1" colspan="1">93</td>
          </tr>
          <tr>
            <td align="left" rowspan="1" colspan="1">Random forest</td>
            <td align="left" rowspan="1" colspan="1">17 318</td>
            <td align="left" rowspan="1" colspan="1">69</td>
          </tr>
          <tr>
            <td align="left" rowspan="1" colspan="1">CARD*Shark 2</td>
            <td align="left" rowspan="1" colspan="1">22 196</td>
            <td align="left" rowspan="1" colspan="1">H: 10 676;L: 11 520</td>
            <td align="left" rowspan="1" colspan="1">H: 58; L: 8</td>
          </tr>
        </tbody>
      </table>
      <table-wrap-foot>
        <fn id="T0003-fn1">
          <p>CARD*Shark 2 categorizes its predictions into an L or H level. L, low; H, high.</p>
        </fn>
      </table-wrap-foot>
    </table-wrap>
    <fig position="float" id="F2" fig-type="figure">
      <label>Figure 2.</label>
      <caption>
        <p>A Venn diagram illustrating the overlap of each model’s positive paper predictions that were ultimately curated into CARD. The plot based on data from <xref rid="T3" ref-type="table">Table 3</xref>. For CARD*Shark 2, both high- and low-level predictions are included.</p>
      </caption>
      <graphic xlink:href="baad023f2" position="float"/>
    </fig>
  </sec>
  <sec id="s5">
    <title>Conclusion</title>
    <p>Overall, we have found that supervised learning applications to rapidly triage thousands of publications can viably reduce the burden associated with curating data. However, due to the limited scope associated with CARD’s curation goal (i.e. identifying new ARGs only), models perform with poor precision but high recall. To compensate for this precision, a combination of CARD*Shark 2 and the supervised learning models will be incorporated into CARD by ranking publications based on model agreement to maintain high recall while prioritizing high-value publications (i.e. publications with the highest model agreement are reviewed first). As such, a computer-guided curation paradigm that centers ultimately on expert, human biocuration allows CARD to provide comprehensive, high-value, trustworthy data for genomic surveillance of AMR.</p>
  </sec>
</body>
<back>
  <ack id="ack1">
    <title>Acknowledgements</title>
    <p>We thank Brian P. Alcock and Amogelang R. Raphenya of the CARD for assistance with all aspects of this research. We would like to thank Brian P. Alcock, Amogelang R. Raphenya, Kara Tsang, Jalees Nasir, Martins Oloni, William Huynh, Sohaib Syed, Rachel Tran and Marcel Jansen for participation in the validation of CARD*Shark predictions. Lastly, we thank Sachin Doshi and Arjun Sharma for pioneering literature triage methods for CARD.</p>
  </ack>
  <sec sec-type="data-availability" id="s6">
    <title>Data availability</title>
    <p>Software for CARD*Shark is available at <ext-link xlink:href="https://github.com/edalatma/card_shark_3" ext-link-type="uri">https://github.com/edalatma/card_shark_3</ext-link>.</p>
  </sec>
  <sec id="s7">
    <title>Funding</title>
    <p>Canadian Institutes of Health Research (PJT-156214 to A.G.M.); Cisco Systems Canada, Inc. (a Cisco Research Chair in Bioinformatics to A.G.M.); an Ontario Graduate Scholarship and a McMaster University Ashbaugh Graduate Scholarship (to A.E.). Computer resources were supplied by the McMaster Service Lab and Repository computing cluster, funded in part by grants from the Canada Foundation for Innovation (34531 to A.G.M.).</p>
  </sec>
  <sec sec-type="COI-statement" id="s8">
    <title>Conflict of interest statement</title>
    <p>The authors declare no competing interests.</p>
  </sec>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="R1">
      <label>1.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><collab>Centers for Disease Control and Prevention (U.S.)</collab></person-group>. (<year>2019</year>) <article-title>Antibiotic Resistance Threats in the United States, 2019</article-title>. <publisher-name>Centers for Disease Control and Prevention</publisher-name>.</mixed-citation>
    </ref>
    <ref id="R2">
      <label>2.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Holmes</surname><given-names>A.H.</given-names></string-name>, <string-name><surname>Moore</surname><given-names>L.S.P.</given-names></string-name>, <string-name><surname>Sundsfjord</surname><given-names>A.</given-names></string-name></person-group>  <etal>et al.</etal> (<year>2016</year>) <article-title>Understanding the mechanisms and drivers of antimicrobial resistance</article-title>. <source><italic toggle="yes">Lancet</italic></source>, <volume>387</volume>, <fpage>176</fpage>–<lpage>187</lpage>.<pub-id pub-id-type="pmid">26603922</pub-id></mixed-citation>
    </ref>
    <ref id="R3">
      <label>3.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Brown</surname><given-names>E.D.</given-names></string-name> and <string-name><surname>Wright</surname><given-names>G.D.</given-names></string-name></person-group> (<year>2016</year>) <article-title>Antibacterial drug discovery in the resistance era</article-title>. <source><italic toggle="yes">Nature</italic></source>, <volume>529</volume>, <fpage>336</fpage>–<lpage>343</lpage>.<pub-id pub-id-type="pmid">26791724</pub-id></mixed-citation>
    </ref>
    <ref id="R4">
      <label>4.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Privalsky</surname><given-names>T.M.</given-names></string-name>, <string-name><surname>Soohoo</surname><given-names>A.M.</given-names></string-name>, <string-name><surname>Wang</surname><given-names>J.</given-names></string-name></person-group>  <etal>et al.</etal> (<year>2021</year>) <article-title>Prospects for antibacterial discovery and development</article-title>. <source><italic toggle="yes">J. Am. Chem. Soc.</italic></source>, <volume>143</volume>, <fpage>21127</fpage>–<lpage>21142</lpage>.<pub-id pub-id-type="pmid">34860516</pub-id></mixed-citation>
    </ref>
    <ref id="R5">
      <label>5.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tamma</surname><given-names>P.D.</given-names></string-name>, <string-name><surname>Fan</surname><given-names>Y.</given-names></string-name>, <string-name><surname>Bergman</surname><given-names>Y.</given-names></string-name></person-group>  <etal>et al.</etal> (<year>2019</year>) <article-title>Applying rapid whole-genome sequencing to predict phenotypic antimicrobial susceptibility testing results among carbapenem-resistant <italic toggle="yes">Klebsiella pneumoniae</italic> clinical isolates</article-title>. <source><italic toggle="yes">Antimicrob. Agents Chemother.</italic></source>, <volume>63</volume>, <fpage>e01923</fpage>–<lpage>18</lpage>.<pub-id pub-id-type="pmid">30373801</pub-id></mixed-citation>
    </ref>
    <ref id="R6">
      <label>6.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tsang</surname><given-names>K.K.</given-names></string-name>, <string-name><surname>Maguire</surname><given-names>F.</given-names></string-name>, <string-name><surname>Zubyk</surname><given-names>H.L.</given-names></string-name></person-group>  <etal>et al.</etal> (<year>2021</year>) <article-title>Identifying novel β-lactamase substrate activity through <italic toggle="yes">in silico</italic> prediction of antimicrobial resistance</article-title>. <source><italic toggle="yes">Microb. Genom.</italic></source>, <volume>7</volume>, <page-range>mgen.0.000500</page-range>.</mixed-citation>
    </ref>
    <ref id="R7">
      <label>7.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname><given-names>S.</given-names></string-name>, <string-name><surname>Zhao</surname><given-names>C.</given-names></string-name>, <string-name><surname>Yin</surname><given-names>Y.</given-names></string-name></person-group>  <etal>et al.</etal> (<year>2022</year>) <article-title>A practical approach for predicting antimicrobial phenotype resistance in <italic toggle="yes">Staphylococcus aureus</italic> through machine learning analysis of genome data</article-title>. <source><italic toggle="yes">Front. Microbiol.</italic></source>, <volume>13</volume>, <page-range>841289</page-range>.</mixed-citation>
    </ref>
    <ref id="R8">
      <label>8.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kuang</surname><given-names>X.</given-names></string-name>, <string-name><surname>Wang</surname><given-names>F.</given-names></string-name>, <string-name><surname>Hernandez</surname><given-names>K.M.</given-names></string-name></person-group>  <etal>et al.</etal> (<year>2022</year>) <article-title>Accurate and rapid prediction of tuberculosis drug resistance from genome sequence data using traditional machine learning algorithms and CNN</article-title>. <source><italic toggle="yes">Sci. Rep.</italic></source>, <volume>12</volume>, <page-range>2427</page-range>.</mixed-citation>
    </ref>
    <ref id="R9">
      <label>9.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ellington</surname><given-names>M.J.</given-names></string-name>, <string-name><surname>Ekelund</surname><given-names>O.</given-names></string-name>, <string-name><surname>Aarestrup</surname><given-names>F.M.</given-names></string-name></person-group>  <etal>et al.</etal> (<year>2017</year>) <article-title>The role of whole genome sequencing in antimicrobial susceptibility testing of bacteria: report from the EUCAST Subcommittee</article-title>. <source><italic toggle="yes">Clin. Microbiol. Infect.</italic></source>, <volume>23</volume>, <fpage>2</fpage>–<lpage>22</lpage>.<pub-id pub-id-type="pmid">27890457</pub-id></mixed-citation>
    </ref>
    <ref id="R10">
      <label>10.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Alcock</surname><given-names>B.P.</given-names></string-name>, <string-name><surname>Raphenya</surname><given-names>A.R.</given-names></string-name>, <string-name><surname>Lau</surname><given-names>T.T.Y.</given-names></string-name></person-group>  <etal>et al.</etal> (<year>2020</year>) <article-title>CARD 2020: antibiotic resistome surveillance with the Comprehensive Antibiotic Resistance Database</article-title>. <source><italic toggle="yes">Nucleic Acids Res.</italic></source>, <volume>48</volume>, <fpage>D517</fpage>–<lpage>D525</lpage>.<pub-id pub-id-type="pmid">31665441</pub-id></mixed-citation>
    </ref>
    <ref id="R11">
      <label>11.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Florensa</surname><given-names>A.F.</given-names></string-name>, <string-name><surname>Kaas</surname><given-names>R.S.</given-names></string-name>, <string-name><surname>Clausen</surname><given-names>P.T.L.C.</given-names></string-name></person-group>  <etal>et al.</etal> (<year>2022</year>) <article-title>ResFinder—an open online resource for identification of antimicrobial resistance genes in next-generation sequencing data and prediction of phenotypes from genotypes</article-title>. <source><italic toggle="yes">Microb. Genom.</italic></source>, <volume>8</volume>, <page-range>000748</page-range>.</mixed-citation>
    </ref>
    <ref id="R12">
      <label>12.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Feldgarden</surname><given-names>M.</given-names></string-name>, <string-name><surname>Brover</surname><given-names>V.</given-names></string-name>, <string-name><surname>Gonzalez-Escalona</surname><given-names>N.</given-names></string-name></person-group>  <etal>et al.</etal> (<year>2021</year>) <article-title>AMRFinderPlus and the Reference Gene Catalog facilitate examination of the genomic links among antimicrobial resistance, stress response, and virulence</article-title>. <source><italic toggle="yes">Sci. Rep.</italic></source>, <volume>11</volume>, <page-range>12728</page-range>.</mixed-citation>
    </ref>
    <ref id="R13">
      <label>13.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jia</surname><given-names>B.</given-names></string-name>, <string-name><surname>Raphenya</surname><given-names>A.R.</given-names></string-name>, <string-name><surname>Alcock</surname><given-names>B.</given-names></string-name></person-group>  <etal>et al.</etal> (<year>2017</year>) <article-title>CARD 2017: expansion and model-centric curation of the Comprehensive Antibiotic Resistance Database</article-title>. <source><italic toggle="yes">Nucleic Acids Res.</italic></source>, <volume>45</volume>, <fpage>D566</fpage>–<lpage>D573</lpage>.<pub-id pub-id-type="pmid">27789705</pub-id></mixed-citation>
    </ref>
    <ref id="R14">
      <label>14.</label>
      <mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><surname>Kotsiantis</surname><given-names>S.B.</given-names></string-name></person-group> (<year>2007</year>) <article-title>Supervised machine learning: a review of classification techniques</article-title>. In: <conf-name>Proceedings of the 2007 Conference on Emerging Artificial Intelligence Applications in Computer Engineering: Real Word AI Systems with Applications in eHealth, HCI, Information Retrieval and Pervasive Technologies</conf-name>, <publisher-name>IOS Press</publisher-name>, <conf-loc>Amsterdam, The Netherlands</conf-loc>, pp. <fpage>3</fpage>–<lpage>24</lpage>.</mixed-citation>
    </ref>
    <ref id="R15">
      <label>15.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Sayers</surname><given-names>E.</given-names></string-name></person-group> (<year>2010</year>) <article-title>A General Introduction to the E-utilities</article-title>. <publisher-name>National Center for Biotechnology Information</publisher-name>. <ext-link xlink:href="https://www.ncbi.nlm.nih.gov/books/NBK25497/" ext-link-type="uri">https://www.ncbi.nlm.nih.gov/books/NBK25497/</ext-link> (7 April 2020, date last accessed).</mixed-citation>
    </ref>
    <ref id="R16">
      <label>16.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Bird</surname><given-names>S.</given-names></string-name>, <string-name><surname>Loper</surname><given-names>E.</given-names></string-name> and <string-name><surname>Klein</surname>  <given-names>E.</given-names></string-name></person-group> (<year>2009</year>) <source><italic toggle="yes">Natural Language Processing with Python</italic></source>. <publisher-loc>Sebastopol, CA</publisher-loc>, <publisher-name>O’Reilly Media</publisher-name>.</mixed-citation>
    </ref>
    <ref id="R17">
      <label>17.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Uysal</surname><given-names>A.K.</given-names></string-name> and <string-name><surname>Gunal</surname><given-names>S.</given-names></string-name></person-group> (<year>2014</year>) <article-title>The impact of preprocessing on text classification</article-title>. <source><italic toggle="yes">Inf. Process. Manag.</italic></source>, <volume>50</volume>, <fpage>104</fpage>–<lpage>112</lpage>.</mixed-citation>
    </ref>
    <ref id="R18">
      <label>18.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Porter</surname><given-names>M.F.</given-names></string-name></person-group> (<year>1980</year>) <article-title>An algorithm for suffix stripping</article-title>. <source><italic toggle="yes">Program</italic></source>, <volume>14</volume>, <fpage>130</fpage>–<lpage>137</lpage>.</mixed-citation>
    </ref>
    <ref id="R19">
      <label>19.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Saxena</surname><given-names>D.</given-names></string-name>, <string-name><surname>Saritha</surname><given-names>S.K.</given-names></string-name> and <string-name><surname>Prasad</surname><given-names>K.N.S.S.V.</given-names></string-name></person-group> (<year>2017</year>) <article-title>Survey paper on feature extraction methods in text categorization</article-title>. <source><italic toggle="yes">Int. J. Comput. Appl.</italic></source>, <volume>166</volume>, <fpage>11</fpage>–<lpage>17</lpage>.</mixed-citation>
    </ref>
    <ref id="R20">
      <label>20.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Beel</surname><given-names>J.</given-names></string-name>, <string-name><surname>Gipp</surname><given-names>B.</given-names></string-name>, <string-name><surname>Langer</surname><given-names>S.</given-names></string-name></person-group>  <etal>et al.</etal> (<year>2016</year>) <article-title>Research-paper recommender systems: a literature survey</article-title>. <source><italic toggle="yes">Int. J. Digit. Libr.</italic></source>, <volume>17</volume>, <fpage>305</fpage>–<lpage>338</lpage>.</mixed-citation>
    </ref>
    <ref id="R21">
      <label>21.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pedregosa</surname><given-names>F.</given-names></string-name>, <string-name><surname>Varoquaux</surname><given-names>G.</given-names></string-name>, <string-name><surname>Gramfort</surname><given-names>A.</given-names></string-name></person-group>  <etal>et al.</etal> (<year>2011</year>) <article-title>Scikit-learn: machine learning in Python</article-title>. <source><italic toggle="yes">J. Mach. Learn. Res.</italic></source>, <volume>12</volume>, <fpage>2825</fpage>–<lpage>2830</lpage>.</mixed-citation>
    </ref>
  </ref-list>
</back>
