<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-archivearticle1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Research (Wash D C)</journal-id>
    <journal-id journal-id-type="iso-abbrev">Research (Wash D C)</journal-id>
    <journal-id journal-id-type="publisher-id">RESEARCH</journal-id>
    <journal-title-group>
      <journal-title>Research</journal-title>
    </journal-title-group>
    <issn pub-type="epub">2639-5274</issn>
    <publisher>
      <publisher-name>AAAS</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">10528219</article-id>
    <article-id pub-id-type="doi">10.34133/research.0240</article-id>
    <article-id pub-id-type="publisher-id">0240</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Research Article</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>A Transformer-Based Ensemble Framework for the Prediction of Protein–Protein Interaction Sites</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0001-7619-2975</contrib-id>
        <name>
          <surname>Mou</surname>
          <given-names>Minjie</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="afn1" ref-type="author-notes">
          <sup>†</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-3883-4161</contrib-id>
        <name>
          <surname>Pan</surname>
          <given-names>Ziqi</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="afn1" ref-type="author-notes">
          <sup>†</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0009-0007-7980-7577</contrib-id>
        <name>
          <surname>Zhou</surname>
          <given-names>Zhimeng</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0001-7533-2649</contrib-id>
        <name>
          <surname>Zheng</surname>
          <given-names>Lingyan</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-4728-7702</contrib-id>
        <name>
          <surname>Zhang</surname>
          <given-names>Hanyu</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0009-0007-9638-5089</contrib-id>
        <name>
          <surname>Shi</surname>
          <given-names>Shuiyang</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-1846-639X</contrib-id>
        <name>
          <surname>Li</surname>
          <given-names>Fengcheng</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0001-7991-5825</contrib-id>
        <name>
          <surname>Sun</surname>
          <given-names>Xiuna</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0001-8069-0053</contrib-id>
        <name>
          <surname>Zhu</surname>
          <given-names>Feng</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="aff2" ref-type="aff">
          <sup>2</sup>
        </xref>
        <xref rid="corr1" ref-type="corresp">
          <sup>*</sup>
        </xref>
      </contrib>
    </contrib-group>
    <aff id="aff1"><label><sup>1</sup></label><addr-line>College of Pharmaceutical Sciences, The Second Affiliated Hospital</addr-line>, 
<institution>Zhejiang University</institution><addr-line>School of Medicine, National Key Laboratory of Advanced Drug Delivery and Release Systems, Zhejiang University</addr-line>, Hangzhou 310058, <country>China</country>.</aff>
    <aff id="aff2"><label><sup>2</sup></label><institution>Innovation Institute for Artificial Intelligence in Medicine of Zhejiang University</institution>, <addr-line>Alibaba-Zhejiang University Joint Research Center of Future Digital Healthcare</addr-line>, Hangzhou 330110, <country>China</country>.</aff>
    <author-notes>
      <corresp id="corr1"><label>*</label>Address correspondence to: <email xlink:href="mailto:zhufeng@zju.edu.cn">zhufeng@zju.edu.cn</email></corresp>
      <fn id="afn1" fn-type="equal">
        <label>†</label>
        <p>These authors contributed equally to this work.</p>
      </fn>
    </author-notes>
    <pub-date publication-format="electronic" date-type="pub">
      <day>27</day>
      <month>9</month>
      <year>2023</year>
    </pub-date>
    <pub-date publication-format="electronic" date-type="collection">
      <year>2023</year>
    </pub-date>
    <volume>6</volume>
    <elocation-id>0240</elocation-id>
    <history>
      <date date-type="received">
        <day>02</day>
        <month>8</month>
        <year>2023</year>
      </date>
      <date date-type="accepted">
        <day>08</day>
        <month>9</month>
        <year>2023</year>
      </date>
      <date date-type="pub">
        <day>27</day>
        <month>9</month>
        <year>2023</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>Copyright © 2023 Minjie Mou et al.</copyright-statement>
      <copyright-year>2023</copyright-year>
      <copyright-holder>Minjie Mou et al.</copyright-holder>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>Exclusive licensee Science and Technology Review Publishing House. No claim to original U.S. Government Works. Distributed under a <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License 4.0 (CC BY 4.0)</ext-link>.</license-p>
      </license>
    </permissions>
    <self-uri content-type="pdf" xlink:href="research.0240.pdf"/>
    <abstract>
      <p>The identification of protein–protein interaction (PPI) sites is essential in the research of protein function and the discovery of new drugs. So far, a variety of computational tools based on machine learning have been developed to accelerate the identification of PPI sites. However, existing methods suffer from the low predictive accuracy or the limited scope of application. Specifically, some methods learned only global or local sequential features, leading to low predictive accuracy, while others achieved improved performance by extracting residue interactions from structures but were limited in their application scope for the serious dependence on precise structure information. There is an urgent need to develop a method that integrates comprehensive information to realize proteome-wide accurate profiling of PPI sites. Herein, a novel ensemble framework for PPI sites prediction, EnsemPPIS, was therefore proposed based on transformer and gated convolutional networks. EnsemPPIS can effectively capture not only global and local patterns but also residue interactions. Specifically, EnsemPPIS was unique in (a) extracting residue interactions from protein sequences with transformer and (b) further integrating global and local sequential features with the ensemble learning strategy. Compared with various existing methods, EnsemPPIS exhibited either superior performance or broader applicability on multiple PPI sites prediction tasks. Moreover, pattern analysis based on the interpretability of EnsemPPIS demonstrated that EnsemPPIS was fully capable of learning residue interactions within the local structure of PPI sites using only sequence information. The web server of EnsemPPIS is freely available at <ext-link xlink:href="http://idrblab.org/ensemppis" ext-link-type="uri">http://idrblab.org/ensemppis</ext-link>.</p>
    </abstract>
    <counts>
      <fig-count count="7"/>
      <table-count count="2"/>
      <ref-count count="100"/>
      <page-count count="0"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec id="sec1">
    <title>Introduction</title>
    <p>Protein–protein interaction (PPI) plays a fundamental role in numerous cellular functional progresses [<xref rid="B1" ref-type="bibr">1</xref>–<xref rid="B5" ref-type="bibr">5</xref>]. PPI sites refer to the interfacial residues of proteins that are involved in these interactions, and the identification of PPI sites is of utmost importance for unraveling the mysteries of cell processes and promoting the development of new drugs [<xref rid="B6" ref-type="bibr">6</xref>–<xref rid="B8" ref-type="bibr">8</xref>]. Experimental approaches for identifying PPI sites, including affinity purification coupled to mass spectrometry [<xref rid="B9" ref-type="bibr">9</xref>,<xref rid="B10" ref-type="bibr">10</xref>], coimmunoprecipitation [<xref rid="B11" ref-type="bibr">11</xref>,<xref rid="B12" ref-type="bibr">12</xref>] and 2-hybrid screening [<xref rid="B13" ref-type="bibr">13</xref>,<xref rid="B14" ref-type="bibr">14</xref>], face challenges due to their intricate and time-consuming procedures [<xref rid="B15" ref-type="bibr">15</xref>–<xref rid="B18" ref-type="bibr">18</xref>]. Therefore, the development of efficient computational methods to accelerate the identification of PPI sites is of vital importance [<xref rid="B19" ref-type="bibr">19</xref>–<xref rid="B22" ref-type="bibr">22</xref>].</p>
    <p>So far, various computational methods have been developed for predicting PPI sites, which can be categorized into 2 mainstream strategies [<xref rid="B23" ref-type="bibr">23</xref>]. The first strategy involves docking methods that predict pairwise interaction sites and rely on the structural information of both interacting proteins [<xref rid="B24" ref-type="bibr">24</xref>,<xref rid="B25" ref-type="bibr">25</xref>]. In contrast, the second strategy focuses on predicting putative interaction sites within individual isolated proteins, without requiring any knowledge of the partner proteins [<xref rid="B26" ref-type="bibr">26</xref>]. The latter strategy holds great research importance since the structure of protein complex or the information on partner protein may not be available, and therefore has spawned a series of machine learning-based tools to perform partner-independent prediction of PPI sites in a more general paradigm [<xref rid="B17" ref-type="bibr">17</xref>]. These tools were built to learn and extract information that determines PPI, and were broadly categorized into sequence-based and structure-based according to the type of input data [<xref rid="B27" ref-type="bibr">27</xref>–<xref rid="B29" ref-type="bibr">29</xref>]. Some tools encode residues from the primary sequence and output the probability of being PPI sites [<xref rid="B30" ref-type="bibr">30</xref>], such as SPRINGS [<xref rid="B31" ref-type="bibr">31</xref>], SCRIBER [<xref rid="B32" ref-type="bibr">32</xref>], ProNA2020 [<xref rid="B33" ref-type="bibr">33</xref>], and DELPHI [<xref rid="B34" ref-type="bibr">34</xref>]. Others leverage structural information to identify PPI sites, such as secondary structure and residue contact map. Prominent examples in this category include SPPIDER [<xref rid="B28" ref-type="bibr">28</xref>], DeepPPISP [<xref rid="B22" ref-type="bibr">22</xref>], EGRET [<xref rid="B23" ref-type="bibr">23</xref>], and GraphPPIS [<xref rid="B35" ref-type="bibr">35</xref>]. Recently, several methods utilized geometric deep learning to capture structural surface features for PPI sites prediction, including PInet [<xref rid="B36" ref-type="bibr">36</xref>], MaSIF-site [<xref rid="B37" ref-type="bibr">37</xref>], ScanNet [<xref rid="B38" ref-type="bibr">38</xref>], and PeSTo [<xref rid="B39" ref-type="bibr">39</xref>].</p>
    <p>However, these methods suffer from the low predictive accuracy or the limited scope of application. Specifically, some methods had a main disadvantage of relatively low prediction accuracy because they only excelled at learning global or local contextual features from primary sequences [<xref rid="B22" ref-type="bibr">22</xref>,<xref rid="B23" ref-type="bibr">23</xref>,<xref rid="B40" ref-type="bibr">40</xref>,<xref rid="B41" ref-type="bibr">41</xref>], but failed to leverage local structural features whose information proves to be inextricably linked to PPI sites [<xref rid="B23" ref-type="bibr">23</xref>,<xref rid="B35" ref-type="bibr">35</xref>,<xref rid="B42" ref-type="bibr">42</xref>]. Others achieved improved performance by extracting residue interactions from protein structures, particularly the long-range interactions within local structures, but their application scope and generalization ability were extremely limited for their acute dependence on precise structure information, severe sensitivity to structural errors, and inappropriate use of protein conformation for model training [<xref rid="B35" ref-type="bibr">35</xref>,<xref rid="B43" ref-type="bibr">43</xref>,<xref rid="B44" ref-type="bibr">44</xref>]. Therefore, there is an urgent need to develop a method that integrates comprehensive information to enable accurate identification of PPI sites in the largest scope of whole proteome [<xref rid="B45" ref-type="bibr">45</xref>–<xref rid="B47" ref-type="bibr">47</xref>].</p>
    <p>Herein, a novel transformer-based ensemble method for PPI sites prediction, EnsemPPIS, was therefore proposed, which can capture not only global and local patterns but also residue interactions. EnsemPPIS consists of 2 base models, namely, TransformerPPIS and GatCNNPPIS. The transformer framework in TransformerPPIS is equipped with the ability to learn global features and calculate attention weights between residues, making it possible to capture residue dependencies within local structures, while GatCNNPPIS is capable of learning local contextual features using the gated convolutional networks. EnsemPPIS was thoroughly evaluated on multiple PPI sites prediction tasks and exhibited either superior performance or broader applicability compared with various existing methods. Moreover, pattern analysis based on the interpretability of EnsemPPIS demonstrated that EnsemPPIS was fully capable of learning residue interactions using only primary sequences, thereby improving the performance of PPI sites prediction. A web server of EnsemPPIS was further established, which is freely available at <ext-link xlink:href="http://idrblab.org/ensemppis" ext-link-type="uri">http://idrblab.org/ensemppis</ext-link>. EnsemPPIS is applicable for proteome-wide profiling of PPI sites and expected to provide more insights into protein function research and drug discovery.</p>
  </sec>
  <sec id="sec2">
    <title>Results and Discussion</title>
    <sec id="sec3">
      <title>The ensemble framework of EnsemPPIS for predicting PPI sites</title>
      <p>EnsemPPIS functions through 3 steps, including ProtBERT embedding, feature learning, and prediction, as illustrated in Fig. <xref rid="F1" ref-type="fig">1</xref>. Specifically, proteins are input into ProtBERT, a pretrained protein language model, to obtain the embeddings for residues [<xref rid="B48" ref-type="bibr">48</xref>]. Following the embedding, an ensemble learning framework is employed to effectively learn the underlying features, which consists of 2 deep learning base models, namely, TransformerPPIS and GatCNNPPIS. These models leverage the embeddings obtained from ProtBERT for further analysis and prediction of PPI sites. TransformerPPIS can extract residue interaction information and global features of proteins. To extract global features, the protein embeddings are fed into the encoder module. Simultaneously, each residue embedding undergoes a fully connected layer (FC) before being input into the decoder module alongside the global features. Within the decoder, the pairwise residue interactions are extracted using the self-attention mechanism of the transformer algorithm. The concrete architecture of TransformerPPIS is illustrated in Fig. <xref rid="F2" ref-type="fig">2</xref>, with a more detailed description presented in Materials and Methods. GatCNNPPIS can extract local features from protein embeddings. Specifically, GatCNNPPIS employs gated convolutional networks with residual connections to capture sequential motifs. In this approach, each residue is represented by its local contextual environment, which encompasses a total of 7 residues. Finally, the latent representations generated by TransformerPPIS and GatCNNPPIS are separately fed into the classifier, which consists of several FCs. The classifier utilizes these representations to output the probability score. The average probability score serves as the final probability of each residue being a potential PPI site. In summary, the major characteristic of EnsemPPIS is its ability to extract local and global features, as well as residue interaction information from ProtBERT-embedded proteins based on the ensemble learning framework.</p>
      <fig position="float" id="F1">
        <label>Fig. 1.</label>
        <caption>
          <p>The ensemble learning framework of EnsemPPIS for predicting PPI sites. EnsemPPIS consists of 2 base models (TransformerPPIS and GatCNNPPIS) and functions through 3 steps, including ProtBERT embedding, feature learning and prediction. The average of probability scores output by the 2 base models is considered as the final probability of each residue as a potential PPI site. GLU, gated linear unit; RC, residual connection; FC, fully connected layer.</p>
        </caption>
        <graphic xlink:href="research.0240.fig.001" position="float"/>
      </fig>
      <fig position="float" id="F2">
        <label>Fig. 2.</label>
        <caption>
          <p>The deep learning architecture of the base model TransformerPPIS in EnsemPPIS. TransformerPPIS is mainly composed of 3 modules: the encoder, the decoder, and the classifier module. The sequence embedding obtained by ProtBERT is first input into the encoder module to extract global feature. Then, the global feature of the protein and the original embedding feature of a specific residue are both input into decoder module. The output of decoder is further passed into the classifier module to generate the probability score of a residue being a potential PPI site. GLU, gated linear unit; RC, residual connection; LN, layer normalization; FC, fully connected layer.</p>
        </caption>
        <graphic xlink:href="research.0240.fig.002" position="float"/>
      </fig>
    </sec>
    <sec id="sec4">
      <title>Leading performance of EnsemPPIS in residue-level prediction</title>
      <p>Previous studies have generated multiple datasets preserving experimentally validated PPI sites data, which have been widely utilized in developing computational tools, as displayed in Table <xref rid="supplementary-material-1" ref-type="sec">S1</xref>. We took advantage of these valuable benchmark datasets to train and evaluate EnsemPPIS and made comprehensive comparisons with various existing methods. As a result, EnsemPPIS achieved leading performance in residue-level prediction on <italic toggle="yes">DeepPPISP task</italic> and <italic toggle="yes">DELPHI task</italic>.</p>
      <p>(a) <italic toggle="yes">Performance evaluation on DeepPPISP task</italic></p>
      <p>EnsemPPIS, along with 12 other competing methods, was first evaluated and compared on the <italic toggle="yes">DeepPPISP task</italic>, as shown in Table <xref rid="T1" ref-type="table">1</xref>. Some of the results were obtained by reproducing the provided source code or utilizing the web server. Meanwhile, for certain methods that employed the same training and test data as the previous work DeepPPISP [<xref rid="B22" ref-type="bibr">22</xref>], the results were directly collected from that study to ensure consistency and comparability.</p>
      <table-wrap position="float" id="T1">
        <label>Table 1.</label>
        <caption>
          <p>Comparison of the predictive performance of our proposed methods and other state-of-the-art methods on <italic toggle="yes">DeepPPISP task</italic>. DeepPPISP, EGRET, IntPred, and SPPIDER use protein structural information. DELPHI, DLPred, ISIS, ProNA2020, PSIVER, RF_PPI, SCRIBER, and SPRINGS use protein sequences. TransformerPPIS, GatCNNPPIS, and EnsemPPIS are proposed in this study. All comparison methods are sorted alphabetically. The best results are shown in bold.</p>
        </caption>
        <table frame="hsides" rules="groups">
          <thead>
            <tr>
              <th align="left" rowspan="1" colspan="1">Method</th>
              <th align="center" rowspan="1" colspan="1">ACC</th>
              <th align="center" rowspan="1" colspan="1">PRE</th>
              <th align="center" rowspan="1" colspan="1">REC</th>
              <th align="center" rowspan="1" colspan="1">F1</th>
              <th align="center" rowspan="1" colspan="1">AUROC</th>
              <th align="center" rowspan="1" colspan="1">AUPRC</th>
              <th align="center" rowspan="1" colspan="1">MCC</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td align="left" rowspan="1" colspan="1">DeepPPISP <sup>a</sup></td>
              <td align="center" rowspan="1" colspan="1">0.655</td>
              <td align="center" rowspan="1" colspan="1">0.303</td>
              <td align="center" rowspan="1" colspan="1">0.577</td>
              <td align="center" rowspan="1" colspan="1">0.397</td>
              <td align="center" rowspan="1" colspan="1">0.671</td>
              <td align="center" rowspan="1" colspan="1">0.320</td>
              <td align="center" rowspan="1" colspan="1">0.206</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">DELPHI <sup>b</sup></td>
              <td align="center" rowspan="1" colspan="1">0.667</td>
              <td align="center" rowspan="1" colspan="1">0.319</td>
              <td align="center" rowspan="1" colspan="1">0.604</td>
              <td align="center" rowspan="1" colspan="1">0.418</td>
              <td align="center" rowspan="1" colspan="1">0.690</td>
              <td align="center" rowspan="1" colspan="1">0.360</td>
              <td align="center" rowspan="1" colspan="1">0.236</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">DLPred <sup>c</sup></td>
              <td align="center" rowspan="1" colspan="1">0.680</td>
              <td align="center" rowspan="1" colspan="1">0.325</td>
              <td align="center" rowspan="1" colspan="1">0.577</td>
              <td align="center" rowspan="1" colspan="1">0.416</td>
              <td align="center" rowspan="1" colspan="1">0.697</td>
              <td align="center" rowspan="1" colspan="1">0.380</td>
              <td align="center" rowspan="1" colspan="1">0.235</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">EGRET <sup>b</sup></td>
              <td align="center" rowspan="1" colspan="1">0.715</td>
              <td align="center" rowspan="1" colspan="1">0.358</td>
              <td align="center" rowspan="1" colspan="1">0.561</td>
              <td align="center" rowspan="1" colspan="1">0.438</td>
              <td align="center" rowspan="1" colspan="1">0.719</td>
              <td align="center" rowspan="1" colspan="1">0.405</td>
              <td align="center" rowspan="1" colspan="1">0.270</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">IntPred <sup>a</sup></td>
              <td align="center" rowspan="1" colspan="1">0.672</td>
              <td align="center" rowspan="1" colspan="1">0.247</td>
              <td align="center" rowspan="1" colspan="1">0.508</td>
              <td align="center" rowspan="1" colspan="1">0.332</td>
              <td align="center" rowspan="1" colspan="1">-</td>
              <td align="center" rowspan="1" colspan="1">-</td>
              <td align="center" rowspan="1" colspan="1">0.165</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">ISIS <sup>a</sup></td>
              <td align="center" rowspan="1" colspan="1">0.622</td>
              <td align="center" rowspan="1" colspan="1">0.211</td>
              <td align="center" rowspan="1" colspan="1">0.362</td>
              <td align="center" rowspan="1" colspan="1">0.267</td>
              <td align="center" rowspan="1" colspan="1">-</td>
              <td align="center" rowspan="1" colspan="1">0.240</td>
              <td align="center" rowspan="1" colspan="1">0.097</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">ProNA2020 <sup>c</sup></td>
              <td align="center" rowspan="1" colspan="1">
                <bold>0.741</bold>
              </td>
              <td align="center" rowspan="1" colspan="1">0.297</td>
              <td align="center" rowspan="1" colspan="1">0.229</td>
              <td align="center" rowspan="1" colspan="1">0.258</td>
              <td align="center" rowspan="1" colspan="1">-</td>
              <td align="center" rowspan="1" colspan="1">-</td>
              <td align="center" rowspan="1" colspan="1">0.106</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">PSIVER <sup>a</sup></td>
              <td align="center" rowspan="1" colspan="1">0.653</td>
              <td align="center" rowspan="1" colspan="1">0.253</td>
              <td align="center" rowspan="1" colspan="1">0.468</td>
              <td align="center" rowspan="1" colspan="1">0.328</td>
              <td align="center" rowspan="1" colspan="1">-</td>
              <td align="center" rowspan="1" colspan="1">0.250</td>
              <td align="center" rowspan="1" colspan="1">0.138</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">RF_PPI <sup>a</sup></td>
              <td align="center" rowspan="1" colspan="1">0.598</td>
              <td align="center" rowspan="1" colspan="1">0.173</td>
              <td align="center" rowspan="1" colspan="1">0.512</td>
              <td align="center" rowspan="1" colspan="1">0.258</td>
              <td align="center" rowspan="1" colspan="1">-</td>
              <td align="center" rowspan="1" colspan="1">0.210</td>
              <td align="center" rowspan="1" colspan="1">0.118</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">SCRIBER <sup>c</sup></td>
              <td align="center" rowspan="1" colspan="1">0.616</td>
              <td align="center" rowspan="1" colspan="1">0.274</td>
              <td align="center" rowspan="1" colspan="1">0.569</td>
              <td align="center" rowspan="1" colspan="1">0.370</td>
              <td align="center" rowspan="1" colspan="1">0.635</td>
              <td align="center" rowspan="1" colspan="1">0.307</td>
              <td align="center" rowspan="1" colspan="1">0.159</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">SPPIDER <sup>c</sup></td>
              <td align="center" rowspan="1" colspan="1">0.667</td>
              <td align="center" rowspan="1" colspan="1">0.240</td>
              <td align="center" rowspan="1" colspan="1">0.315</td>
              <td align="center" rowspan="1" colspan="1">0.273</td>
              <td align="center" rowspan="1" colspan="1">0.518</td>
              <td align="center" rowspan="1" colspan="1">0.235</td>
              <td align="center" rowspan="1" colspan="1">0.063</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">SPRINGS <sup>a</sup></td>
              <td align="center" rowspan="1" colspan="1">0.631</td>
              <td align="center" rowspan="1" colspan="1">0.248</td>
              <td align="center" rowspan="1" colspan="1">0.598</td>
              <td align="center" rowspan="1" colspan="1">0.35</td>
              <td align="center" rowspan="1" colspan="1">-</td>
              <td align="center" rowspan="1" colspan="1">0.280</td>
              <td align="center" rowspan="1" colspan="1">0.181</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">TransformerPPIS</td>
              <td align="center" rowspan="1" colspan="1">0.681</td>
              <td align="center" rowspan="1" colspan="1">0.332</td>
              <td align="center" rowspan="1" colspan="1">0.604</td>
              <td align="center" rowspan="1" colspan="1">0.429</td>
              <td align="center" rowspan="1" colspan="1">0.711</td>
              <td align="center" rowspan="1" colspan="1">0.389</td>
              <td align="center" rowspan="1" colspan="1">0.253</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">GatCNNPPIS</td>
              <td align="center" rowspan="1" colspan="1">0.633</td>
              <td align="center" rowspan="1" colspan="1">0.306</td>
              <td align="center" rowspan="1" colspan="1">
                <bold>0.698</bold>
              </td>
              <td align="center" rowspan="1" colspan="1">0.421</td>
              <td align="center" rowspan="1" colspan="1">0.698</td>
              <td align="center" rowspan="1" colspan="1">0.369</td>
              <td align="center" rowspan="1" colspan="1">0.239</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">EnsemPPIS</td>
              <td align="center" rowspan="1" colspan="1">0.732</td>
              <td align="center" rowspan="1" colspan="1">
                <bold>0.375</bold>
              </td>
              <td align="center" rowspan="1" colspan="1">0.532</td>
              <td align="center" rowspan="1" colspan="1">
                <bold>0.440</bold>
              </td>
              <td align="center" rowspan="1" colspan="1">
                <bold>0.719</bold>
              </td>
              <td align="center" rowspan="1" colspan="1">
                <bold>0.405</bold>
              </td>
              <td align="center" rowspan="1" colspan="1">
                <bold>0.277</bold>
              </td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn>
            <p><sup>a</sup> Results reported by DeepPPISP. </p>
            <p><sup>b</sup> Results obtained by reproducing the source code. ProNA2020 only makes binary predictions, and its AUROC and AUPRC are not calculated. </p>
            <p><sup>c</sup> Results obtained by utilizing the web server.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p>As a result, EnsemPPIS achieved the highest performance among all evaluated methods, achieving the MCC value of 0.277, AUPRC of 0.405, and F1 of 0.405. These 3 evaluation metrics are the most important ones in the imbalanced task of PPI sites prediction [<xref rid="B22" ref-type="bibr">22</xref>]. Specifically, when compared to the state-of-the-art (SOTA) sequence-based method DELPHI, EnsemPPIS achieved a 5.3% improvement in F1, a 12.5% improvement in AUPRC, and a remarkable 17.4% improvement in MCC. Moreover, EnsemPPIS, using only sequence information, exhibited competitive performance even when compared to structure-based methods. In fact, EnsemPPIS slightly outperformed the most recent method, EGRET, in terms of F1 and MCC. The performance of the 2 base models, TransformerPPIS and GatCNNPPIS, was also evaluated. TransformerPPIS exhibited superior performance compared to most of the existing methods, showcasing its effectiveness in leveraging global features and residue interactions from the protein embeddings. On the other hand, GatCNNPPIS achieved strong performance, highlighting its ability to capture local contextual information. Both models demonstrated their efficacy and contributed to the overall success of the EnsemPPIS framework. In general, EnsemPPIS achieved the highest performance, indicating the effectiveness of ensemble learning. Importantly, the PRE value of EnsemPPIS demonstrated an increase compared to that of the base models. This indicated that ensemble learning effectively contributed to controlling the false-positive rate to a certain extent.</p>
      <p>EnsemPPIS achieves accurate prediction of PPI sites by integrating 2 separately trained base models. To demonstrate the effectiveness of ensemble learning, 2 variants of EnsemPPIS were constructed by combining the 2 base models into a single model for concurrent training, namely, EnsemPPIS-Va and EnsemPPIS-Vb, as shown in Fig. <xref rid="F3" ref-type="fig">3</xref>A and B. The detailed description of these 2 variants was provided in Materials and Methods. Both variants were also evaluated on the <italic toggle="yes">DeepPPISP task</italic>. Figure <xref rid="F3" ref-type="fig">3</xref>C depicts the performance comparison between EnsemPPIS and its 2 variants. Obviously, EnsemPPIS demonstrated superior performance compared to EnsemPPIS-Va and EnsemPPIS-Vb across all metrics, particularly in terms of MCC and AUPRC. This suggested that the ensemble of the 2 separately trained base models was more effective compared to the approach of initially integrating the 2 base models and training them simultaneously.</p>
      <fig position="float" id="F3">
        <label>Fig. 3.</label>
        <caption>
          <p>Performance evaluation of EnsemPPIS, its variants, and the base model on the <italic toggle="yes">DeepPPISP task</italic>. (A) Architecture of variant EnsemPPIS-Va. The output of TransformerPPIS’s decoder and the output of GatCNNPPIS’s encoder were concatenated. The concatenated vector was then fed into multiple fully connected layers (FCs). (B) Architecture of variant EnsemPPIS-Vb. The output of TransformerPPIS’s decoder and the output of GatCNNPPIS’s encoder were separately passed through FCs. The resulting 2-dimensional vectors were concatenated and further processed through an FC. (C) Performance comparison of EnsemPPIS, EnsemPPIS-Va, and EnsemPPIS-Vb on various metrics. (D) Matthews correlation coefficient (MCC) of TransformerPPIS using different types of feature. (E) Area under the receiver operator characteristic curve (AUROC) of TransformerPPIS using different types of feature. The orange bars represent the performance without ProtBERT feature, and the yellow bars represent the performance with inclusion of ProtBERT feature.</p>
        </caption>
        <graphic xlink:href="research.0240.fig.003" position="float"/>
      </fig>
      <p>Furthermore, we additionally assessed the performance of TransformerPPIS using different types of features or feature combinations, namely, ProtBERT, PSSM [<xref rid="B49" ref-type="bibr">49</xref>], DSSP [<xref rid="B50" ref-type="bibr">50</xref>], and One-hot [<xref rid="B22" ref-type="bibr">22</xref>], and the results were depicted in Fig. <xref rid="F3" ref-type="fig">3</xref>D and E. Consequently, BERT-based feature outperformed the traditional handcrafted features on MCC and AUROC, and the inclusion of ProtBERT feature significantly enhanced the predictive performance.</p>
      <p>(b) <italic toggle="yes">Performance evaluation on DELPHI task</italic></p>
      <p>EnsemPPIS was further assessed on <italic toggle="yes">DELPHI task</italic>, as shown in Table <xref rid="T2" ref-type="table">2</xref>. Due to the unavailability of structural information in the training data, the evaluation and comparison of methods in this task focused solely on those utilizing protein sequences. This allowed for a fair and direct assessment of the performance of sequence-based methods in predicting PPI sites. All results were calculated by using the source code or web server. As a result, EnsemPPIS proved to be the best method. Specifically, considerable improvements in F1, AUPRC, and MCC were achieved by 5.8%, 8.8%, and 4.7%, respectively, compared with the SOTA method DELPHI.</p>
      <table-wrap position="float" id="T2">
        <label>Table 2.</label>
        <caption>
          <p>Comparison of the predictive performance of EnsemPPIS and other state-of-the-art methods on <italic toggle="yes">DELPHI task</italic>. All comparison methods use only protein sequences and are sorted alphabetically. The best results are shown in bold.</p>
        </caption>
        <table frame="hsides" rules="groups">
          <thead>
            <tr>
              <th align="left" rowspan="1" colspan="1">Method</th>
              <th align="center" rowspan="1" colspan="1">ACC</th>
              <th align="center" rowspan="1" colspan="1">F1</th>
              <th align="center" rowspan="1" colspan="1">AUROC</th>
              <th align="center" rowspan="1" colspan="1">AUPRC</th>
              <th align="center" rowspan="1" colspan="1">MCC</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td align="left" rowspan="1" colspan="1">DELPHI <sup>a</sup></td>
              <td align="center" rowspan="1" colspan="1">
                <bold>0.848</bold>
              </td>
              <td align="center" rowspan="1" colspan="1">0.364</td>
              <td align="center" rowspan="1" colspan="1">0.746</td>
              <td align="center" rowspan="1" colspan="1">0.326</td>
              <td align="center" rowspan="1" colspan="1">0.278</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">DLPred <sup>b</sup></td>
              <td align="center" rowspan="1" colspan="1">0.835</td>
              <td align="center" rowspan="1" colspan="1">0.308</td>
              <td align="center" rowspan="1" colspan="1">0.724</td>
              <td align="center" rowspan="1" colspan="1">0.272</td>
              <td align="center" rowspan="1" colspan="1">0.214</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">SCRIBER <sup>b</sup></td>
              <td align="center" rowspan="1" colspan="1">0.838</td>
              <td align="center" rowspan="1" colspan="1">0.322</td>
              <td align="center" rowspan="1" colspan="1">0.719</td>
              <td align="center" rowspan="1" colspan="1">0.275</td>
              <td align="center" rowspan="1" colspan="1">0.230</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">SPRINGS <sup>a</sup></td>
              <td align="center" rowspan="1" colspan="1">0.811</td>
              <td align="center" rowspan="1" colspan="1">0.211</td>
              <td align="center" rowspan="1" colspan="1">0.608</td>
              <td align="center" rowspan="1" colspan="1">0.178</td>
              <td align="center" rowspan="1" colspan="1">0.103</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">EnsemPPIS</td>
              <td align="center" rowspan="1" colspan="1">0.821</td>
              <td align="center" rowspan="1" colspan="1">
                <bold>0.385</bold>
              </td>
              <td align="center" rowspan="1" colspan="1">
                <bold>0.770</bold>
              </td>
              <td align="center" rowspan="1" colspan="1">
                <bold>0.354</bold>
              </td>
              <td align="center" rowspan="1" colspan="1">
                <bold>0.291</bold>
              </td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn>
            <p><sup>a</sup> Results obtained by reproducing the source code. </p>
            <p><sup>b</sup> Results obtained by utilizing the web server.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p>In summary, EnsemPPIS achieved remarkable improvements in residue-level prediction of PPI sites using only protein sequences, outperforming all existing sequence-based methods and comparable to even the most advanced structure-based methods. In this study, protein sequences were input into the pretrained language model ProtBERT to obtain the protein embeddings. Currently, there are some large protein language models that are able to generate informative latent vectors for residues [<xref rid="B51" ref-type="bibr">51</xref>], such as ESM-2 [<xref rid="B52" ref-type="bibr">52</xref>] and AminoBERT [<xref rid="B53" ref-type="bibr">53</xref>]. These models utilize advanced deep learning techniques and large-scale training data to capture intricate features and patterns within protein sequences. By comprehensively leveraging these large language models, it is indeed possible to further enhance the performance of EnsemPPIS.</p>
    </sec>
    <sec id="sec5">
      <title>Broader applicability of EnsemPPIS using only primary sequences</title>
      <p>EnsemPPIS was also evaluated and compared on the <italic toggle="yes">GraphPPIS task</italic>, and the results can be found in Table <xref rid="supplementary-material-1" ref-type="sec">S2</xref>. Two additional methods using protein structures, namely, RGN and GraphPPIS, were reproduced and evaluated in this task. All results were calculated using the source code or web server. Several methods compared on <italic toggle="yes">DeepPPISP task</italic> were not included in the <italic toggle="yes">GraphPPIS task</italic> for comparison, such as EGRET, because they were not provided with the training source code, thus preventing their retraining. As a result, EnsemPPIS once again outperformed all sequence-based methods and even achieved better performance than some structure-based approaches. Specifically, considerable improvements in F1, AUPRC, and MCC were achieved by 7.5%, 10.3%, and 17.2%, respectively, compared with the best existing method using protein sequences. In addition, EnsemPPIS also surpassed 2 of the structure-based methods (SPPIDER and DeepPPISP) on F1, AUPRC, and MCC, but slightly lagged behind RGN and GraphPPIS.</p>
      <p>Although EnsemPPIS is inferior to RGN and GraphPPIS in the <italic toggle="yes">GraphPPIS task</italic> and only comparable to EGRET in the <italic toggle="yes">DeepPPISP task</italic>, it promises to be an indispensable tool and is applicable for the whole proteome, because it is free from the inherent limitations of structure-based methods, namely, the acute dependence on precise protein structures and the improper use of protein conformation for model training.</p>
      <p>The first limitation of structure-based methods is that the lack of experimentally validated protein structures severely limits their scope of application [<xref rid="B43" ref-type="bibr">43</xref>,<xref rid="B54" ref-type="bibr">54</xref>]. This limitation can be partially alleviated through the use of advanced protein structure prediction tools such as AlphaFold2 [<xref rid="B55" ref-type="bibr">55</xref>,<xref rid="B56" ref-type="bibr">56</xref>], RoseTTAFold [<xref rid="B57" ref-type="bibr">57</xref>], ESMFold [<xref rid="B52" ref-type="bibr">52</xref>], and RGN2 [<xref rid="B53" ref-type="bibr">53</xref>]. To investigate the impact of predicted protein structures on the performance of structure-based methods, we tested the performance of EGRET on Test70 dataset using the structures predicted by AlphaFold2. The results showed that the predictive accuracy on many proteins decreased to varying degrees while using predicted structures in place of real structures. As shown in Fig. <xref rid="F4" ref-type="fig">4</xref>A and B, the AlphaFold2 predictions were colored in orange and overlaid on the ground truth (green). AlphaFold2 made accurate predictions for 2 proteins from RCSB Protein Data Bank (PDB) (PDB: 1svdM and PDB: 2f91A), with root mean square deviation (RMSD) of 0.446 and 0.380 Å, respectively [<xref rid="B58" ref-type="bibr">58</xref>]. Unfortunately, even with predicted structures of such high accuracy (RMSD value lower than 1.0 Å [<xref rid="B55" ref-type="bibr">55</xref>]), EGRET’s predictive performance for both proteins declined significantly. As illustrated in Fig. <xref rid="F4" ref-type="fig">4</xref>C, the MCC of two proteins achieved by EGRET decreased by 0.033 and 0.044, respectively, when the predicted structures were used as input, indicating that structure-based methods are highly sensitive to slight structural errors. Notably, due to the identical protein sequence between real structure and predicted structure, EnsemPPIS was not affected by any structural errors in predicting PPI sites and outperformed EGRET on both proteins in terms of MCC (the red dashed line in Fig. <xref rid="F4" ref-type="fig">4</xref>C). Moreover, currently available protein structure prediction methods have some significant limitations, particularly regarding the prediction of structures for proteins with low homology or missense mutations [<xref rid="B59" ref-type="bibr">59</xref>–<xref rid="B64" ref-type="bibr">64</xref>]. These inaccurate protein structure predictions will seriously mislead the results of structure-based PPI sites prediction approaches.</p>
      <fig position="float" id="F4">
        <label>Fig. 4.</label>
        <caption>
          <p>The impact of predicted structures and conformational changes on the performance of structure-based methods. (A) Real structure of the protein (PDB: 1svdM) and structure predicted by AlphaFold2. (B) Real structure of the protein (PDB: 2f91A) and structure predicted by AlphaFold2. The AlphaFold2 predictions are colored in orange and overlaid on the ground truth (green). (C) Performance of EnsemPPIS and EGRET on 1svdM and 2f91A using real structures and predicted structures. Green bars represent the MCC values of EGRET using the real structures, and orange bars represent the MCC values of EGRET using the predicted structures. The red dashed lines denote the MCC values of EnsemPPIS using only primary sequences. (D) Bound (PDB: 1qa9B) and unbound conformations (PDB: 1ci5A) of the same protein (UniProt: P19256). The bound conformation is colored in green and overlaid on the unbound conformation (orange). (E) Performance of EnsemPPIS, GraphPPIS, and RGN using the bound and unbound conformations. Green bars represent the MCC values of GraphPPIS and RGN using the bound conformation, and orange bars represent the MCC values using the unbound conformation. The red dashed line denotes the MCC value of EnsemPPIS using only primary sequence.</p>
        </caption>
        <graphic xlink:href="research.0240.fig.004" position="float"/>
      </fig>
      <p>Protein conformation undergoes changes when binding with a partner [<xref rid="B44" ref-type="bibr">44</xref>,<xref rid="B65" ref-type="bibr">65</xref>,<xref rid="B66" ref-type="bibr">66</xref>], and currently available structure-based PPI sites prediction tools were typically trained using protein complex structures, which limits their accuracy and generalization ability when predicting PPI sites on unbound-form proteins [<xref rid="B35" ref-type="bibr">35</xref>]. To elaborate the second limitation of structure-based methods, we compared the predictive performance of RGN and GraphPPIS on the same protein with different conformations (i.e., bound and unbound conformations). The human lymphocyte function-associated antigen 3 (UniProt: P19256) in Test60 dataset was randomly selected as a case to conduct this analysis. As shown in Fig. <xref rid="F4" ref-type="fig">4</xref>D, the RMSD value between bound conformation (PDB: 1qa9B) and unbound conformation (PDB: 1ci5A) was 1.161 Å, and the position of α-helix (or β-sheet) in the 2 conformations was different, indicating that conformational changes indeed occurred during the binding process. As expected, both RGN and GraphPPIS presented an obvious decrease in MCC when predicting PPI sites on unbound conformation, as displayed in Fig. <xref rid="F4" ref-type="fig">4</xref>E. This suggested that models trained with complex structure information are limited in their robustness and generalization ability when making predictions on monomeric protein structures. PPI sites prediction methods that solely rely on protein sequences are not subject to the limitation of conformational changes because protein sequences remain consistent across different conformations. This offers an advantage in scenarios where accurate structural information is not readily available or when dealing with proteins with dynamic conformations. Specifically, EnsemPPIS exhibited noteworthy performance on both bound and unbound conformations, achieving the MCC value of 0.547 in both scenarios (as shown by the red dashed line in Fig. <xref rid="F4" ref-type="fig">4</xref>E). Importantly, this performance surpassed that of RGN and GraphPPIS specifically on the unbound conformation. In summary, our proposed EnsemPPIS overcomes the limitations associated with structure-based methods by solely relying on the information derived from primary protein sequences, and holds great advantages of broader applicability and stronger generalization ability.</p>
    </sec>
    <sec id="sec6">
      <title>Superior performance of EnsemPPIS in protein-level prediction</title>
      <p>(a) <italic toggle="yes">EnsemPPIS outperforms SOTA ensemble learning method</italic></p>
      <p>EnsemPPIS consistently demonstrated superior performance in predicting PPI sites at the residue level. However, it is worth noting that similar predictive methods are commonly employed for individual protein predictions in downstream research. Therefore, we further assessed the performance of EnsemPPIS in protein-level prediction on the <italic toggle="yes">DeepPPISP task</italic>. We conducted a comparative analysis between our method and the SOTA ensemble learning method DELPHI to evaluate their performance in predicting individual protein sequences from the Test70 dataset. The results of this comparison were depicted in Fig. <xref rid="F5" ref-type="fig">5</xref>. Specifically, DELPHI only learned local and global sequential features based on convolutional neural network (CNN) and recurrent neural network (RNN), respectively. As a result, EnsemPPIS achieved protein predictions with AUROC values exceeding 0.60, 0.70, and 0.80 at rates of 75.71%, 47.14%, and 15.71%, respectively (as shown in Fig. <xref rid="F5" ref-type="fig">5</xref>A), and it predicted proteins with PRE values exceeding 0.30, 0.40, and 0.50 at rates of 64.29%, 35.71%, and 22.86%, respectively (as shown in Fig. <xref rid="F5" ref-type="fig">5</xref>B). EnsemPPIS outperformed DELPHI in terms of predicting a greater number of proteins with superior AUROC or PRE values across various intervals.</p>
      <fig position="float" id="F5">
        <label>Fig. 5.</label>
        <caption>
          <p>The comparison of EnsemPPIS and DELPHI in protein-level prediction on the Test70 dataset. (A) AUROC comparison between EnsemPPIS and DELPHI. (B) PRE comparison between EnsemPPIS and DELPHI. DELPHI is the current state-of-the-art ensemble method for the prediction of PPI sites using protein sequences. The scatter plot shows the performance comparison between EnsemPPIS and DELPHI, where each scatter represents a protein sequence in the Test70 dataset. The proportions of proteins across different intervals of AUROC and PRE are noted in the table. (C) Visualization of the prediction results achieved by TransformerPPIS, EnsemPPIS, and DELPHI for a specific protein (PDB: 1jtdB). PPI sites are shown in purple, and non-PPI sites are shown in gray.</p>
        </caption>
        <graphic xlink:href="research.0240.fig.005" position="float"/>
      </fig>
      <p>To elucidate the advantage of EnsemPPIS in predicting individual proteins, 2 specific proteins (PDB: 1jtdB and PDB: 1b6cA) were randomly selected as cases to visualize the prediction results of TransformerPPIS, EnsemPPIS, and DELPHI. As shown in Fig. <xref rid="F5" ref-type="fig">5</xref>C, the PPI sites on protein 1jtdB predicted by DELPHI exhibited a relatively dispersed pattern, whereas the PPI sites predicted by TransformerPPIS were more spatially concentrated, predominantly distributed on the same surface of the protein. This indicated that TransformerPPIS might learn the local structure of protein based on its sequence and capture the information about residues close in space. Furthermore, by rotating the protein conformation, as shown at the bottom of Fig. <xref rid="F5" ref-type="fig">5</xref>C, it was obvious that EnsemPPIS further reduced the false-positive rate, thereby enhancing the predictive performance (MCC = 0.760). The visualization of the prediction results for the protein 1b6cA was depicted in Fig. <xref rid="supplementary-material-1" ref-type="sec">S1</xref>. Similar observations can be made, suggesting that EnsemPPIS attained the highest level of MCC (MCC = 0.542) while effectively managing the false-positive rate. This was attributed to the integration of GatCNNPPIS base model, which was capable of learning local sequential features.</p>
      <p>(b) <italic toggle="yes">EnsemPPIS is robust on sequences of different lengths</italic></p>
      <p>Existing sequence-based methods predominantly focused on local sequential features of residues, largely neglecting the sequence interdependency [<xref rid="B22" ref-type="bibr">22</xref>]. This oversight tended to compromise the performance of these methods when predicting long sequences due to the critical role of long-range residue interactions in the formation of PPI [<xref rid="B23" ref-type="bibr">23</xref>,<xref rid="B35" ref-type="bibr">35</xref>]. As reported by DeepPPISP, the protein length greatly impacted the predictive performance and its performance significantly deteriorated when predicting longer sequences [<xref rid="B22" ref-type="bibr">22</xref>].</p>
      <p>Therefore, we also evaluated the predictive performance of EnsemPPIS on sequences of varying lengths in the Test70 dataset. All the 70 sequences were grouped into 3 categories, namely, short length (less than 100 residues), medium length (100 to 200 residues), and long length (more than 200 residues). The number of sequences of short length, medium length, and long length was 18, 32, and 20, respectively. We evaluated EnsemPPIS on different lengths in both residue-level and protein-level prediction tasks. As illustrated in Fig. <xref rid="F6" ref-type="fig">6</xref>A, at the residue level, EnsemPPIS exhibited similar AUROCs in predicting PPI sites from sequences of varying lengths. In addition, Fig. <xref rid="F6" ref-type="fig">6</xref>B displays the distributions of each sequence AUROCs achieved by EnsemPPIS in predicting proteins from different length categories at the protein level. EnsemPPIS maintained consistent predictive performance across proteins of varying lengths (<italic toggle="yes">P</italic> &gt; 0.05) according to the Mann–Whitney <italic toggle="yes">U</italic> test [<xref rid="B67" ref-type="bibr">67</xref>]. The results indicated the robustness of EnsemPPIS in predicting proteins of different lengths, which might be attributed to the ability of TransformerPPIS in capturing long-range residue interactions from sequences.</p>
      <fig position="float" id="F6">
        <label>Fig. 6.</label>
        <caption>
          <p>Performance evaluation of EnsemPPIS on different sequence lengths in both residue-level and protein-level prediction tasks on the Test70 dataset. (A) Receiver operator characteristic curve (ROC) and AUROC of EnsemPPIS at the residue level for different sequence lengths. The yellow, green, and blue curves represent the ROC of sequences with short length (1 to 100 residues), medium length (100 to 200 residues), and long length (&gt;200 residues), respectively. (B) Distributions of each sequence AUROC achieved by EnsemPPIS at the protein level under different length categories. The box bounds the interquartile range divided by the median, with whiskers extending to 1.5 times the interquartile range. Each red star represents the mean. Each violin plot illustrates the kernel probability density, where the shaded area represents the proportion of the samples located there. The Mann–Whitney <italic toggle="yes">U</italic> test is used to perform the statistical analysis and calculate <italic toggle="yes">P</italic> values, and all <italic toggle="yes">P</italic> values are 2-sided.</p>
        </caption>
        <graphic xlink:href="research.0240.fig.006" position="float"/>
      </fig>
    </sec>
    <sec id="sec7">
      <title>Pattern analysis based on the interpretability of EnsemPPIS</title>
      <p>The black box nature of deep learning methods calls for careful investigation of interpretability [<xref rid="B68" ref-type="bibr">68</xref>–<xref rid="B70" ref-type="bibr">70</xref>]. Owing to the implementation of the self-attention mechanism, the TransformerPPIS base model of EnsemPPIS exhibited commendable interpretability. Inspired by EGRET [<xref rid="B23" ref-type="bibr">23</xref>], the residue PHE-74 on the PDB protein 1jtdB was selected for the in-depth pattern analysis based on the interpretability of TransformerPPIS. We used the Spearman rank-order correlation [<xref rid="B23" ref-type="bibr">23</xref>] to calculate the correlation coefficient between the attention scores and predicted labels of residues within different distance ranges. As shown in Table <xref rid="supplementary-material-1" ref-type="sec">S3</xref>, within the range of 5, 6, and 8 Å, the attention scores assigned to residues consistently exhibited a significant positive correlation with the predicted labels (all <italic toggle="yes">P</italic> &lt; 0.05). In the case of the 8-Å range, the correlation coefficient (<italic toggle="yes">r</italic>) was calculated to be 0.697, with a corresponding <italic toggle="yes">P</italic> value of 2.71 × 10<sup>−5</sup>. To gain further insights, we divided the residues within this range into 2 groups based on either the median of the attention scores or the predicted labels. This division allowed us to visualize the distribution of residues and examine their characteristics. As depicted in Fig. <xref rid="F7" ref-type="fig">7</xref>A and B, within the range of 8 Å, residues predicted as PPI sites (purple residues in Fig. <xref rid="F7" ref-type="fig">7</xref>A) significantly overlapped with those with higher attention scores (green residues in Fig. <xref rid="F7" ref-type="fig">7</xref>B). Figure <xref rid="F7" ref-type="fig">7</xref>C reveals that residues predicted as PPI sites had notably higher attention scores than those predicted as non-PPI sites (<italic toggle="yes">P</italic> = 1.25 × 10<sup>−4</sup>) according to the Mann–Whitney <italic toggle="yes">U</italic> test.</p>
      <fig position="float" id="F7">
        <label>Fig. 7.</label>
        <caption>
          <p>Attention analysis of residues within the 8 Å of the PPI site PHE-74 on a specific protein (PDB: 1jtdB) based on the predicted labels and the spatial distances to PHE-74. (A) Visualization of residue distribution based on their predicted labels. The predicted PPI sites are denoted in purple, and the predicted non-PPI sites are denoted in blue. (B) Visualization of residue distribution based on their attention scores. All the residues are divided into 2 groups according to the median of the attention scores. Residues with higher attention scores are shown in green, while those with lower attention scores are shown in blue. (C) Boxplot of attention scores for residues predicted as PPI sites and non-PPI sites. (D) Boxplot of attention scores for close residues and distant resides. Residues with distance less than or equal to the median value are labeled as “Close Residues,” and the remaining residues are labeled as “Distant Residues.” (E) Boxplot of residue distances for residues with high attention score and with low attention scores. Residues with attention score higher than or equal to the median value are categorized into “High Attention Score,” and the remaining residues are categorized into “Low Attention Score.” The box bounds the interquartile range divided by the median, with whiskers extending to 1.5 times the interquartile range. Each red star represents the mean value. The Mann–Whitney <italic toggle="yes">U</italic> test is used to perform the statistical analysis and calculate the <italic toggle="yes">P</italic> value.</p>
        </caption>
        <graphic xlink:href="research.0240.fig.007" position="float"/>
      </fig>
      <p>PPI sites are relatively aggregated in protein structures, and local structural features play a crucial role in the formation of PPI. This implies that the interactions among residues within local structures play a crucial role in predicting PPI sites, and therefore, structure-based methods conduct the prediction by learning the features from spatially proximate amino acids [<xref rid="B35" ref-type="bibr">35</xref>]. However, spatially close residues may be distant in sequence. This poses a challenge for existing sequence-based methods, as they primarily emphasize the local sequential features of PPI sites. Consequently, capturing long-range residue interactions becomes difficult within the framework of these methods. In this study, the TransformerPPIS module was able to extract residue interactions including long-range interactions based on primary sequences. Again, take the residue PHE-74 as an example, its surrounding residues within the 8-Å range can be divided into 2 groups according to their distances to PHE-74 or attention scores. Specifically, we first defined the residue distance based on the average distance of all atoms between 2 residues. A total of 15 residues with distance less than or equal to the median value were grouped into “Close Residues,” while the remaining 14 residues were grouped into “Distant Residues.” The Mann–Whitney <italic toggle="yes">U</italic> test was then employed to examine the significant difference of the attention scores between these 2 groups. As illustrated in Fig. <xref rid="F7" ref-type="fig">7</xref>D, the <italic toggle="yes">P</italic> value was 0.0386, indicating that the attention scores of “Close Residues” were significantly higher than those of “Distant Residues.” Similarly, these residues were classified into another 2 groups, namely, “High Attention Score” and “Low Attention Score,” based on the median of their attention scores. As shown in Fig. <xref rid="F7" ref-type="fig">7</xref>E, the <italic toggle="yes">P</italic> value was 0.0351, which implied that residues with higher attention scores were spatially closer in local structure, but might be far apart in sequence. This pattern analysis suggested that residues closer in local space contributed more to the formation of PPI sites, which corroborated the fact that residues closer in space interact more significantly [<xref rid="B71" ref-type="bibr">71</xref>].</p>
      <p>In summary, these findings highlighted that the TransformerPPIS base model within EnsemPPIS is fully capable of learning residue interactions, particularly the long-range interactions within the local structure of PPI sites using only primary sequences. This capability allows the model to extract meaningful connections between protein sequences and structures, ultimately leading to improved performance in predicting PPI sites.</p>
    </sec>
    <sec id="sec8">
      <title>Availability of EnsemPPIS web server</title>
      <p>A web server that implements EnsemPPIS was constructed in this study, which is convenient for researchers to apply our proposed PPI sites prediction method. The EnsemPPIS server was deployed on a Linux server of an Intel Xeon Gold 6149 3.10GHz CPU with 8 cores and 64 GB of memory based on the Python web framework of Django. As an open online platform, all users could freely access it through popular web browsers, including Google Chrome, Mozilla Firefox, Safari, and Internet Explorer 10 (or later).</p>
      <p>EnsemPPIS requires only the FASTA-formatted protein sequences as input, and users should set a project name to associate their PPI sites prediction task. After successful submission, the information necessary to schedule the task would be placed into a MySQL database. Users could find their submitted project displayed on the “Queue” page of the web server. Clicking on the corresponding task information bar will redirect users to the program processing page, which offers 2 key functions: (a) encoding the input protein sequences using the pretrained ProtBERT and providing a downloadable <italic toggle="yes">pickle</italic> file containing the embedding vectors; (b) identifying potential PPI sites on all protein sequences and making a downloadable text file containing the prediction results. EnsemPPIS is freely available at <ext-link xlink:href="http://idrblab.org/ensemppis" ext-link-type="uri">http://idrblab.org/ensemppis</ext-link>.</p>
    </sec>
  </sec>
  <sec id="sec9">
    <title>Conclusion</title>
    <p>In this study, to improve the accuracy of PPI sites prediction and expand the application scope, a novel transformer-based ensemble learning method for PPI sites prediction, EnsemPPIS, was proposed, which incorporated 2 base models, namely, TransformerPPIS and GatCNNPPIS. EnsemPPIS was designed to extract residue interactions by leveraging the transformer and integrate global and local sequential features through ensemble learning. EnsemPPIS exhibited leading performance across multiple tasks, surpassing all existing sequence-based prediction methods and demonstrating its broader applicability in comparison to structure-based methods. Additionally, EnsemPPIS exhibited superior and robust performance in both residue-level and protein-level prediction tasks. Moreover, pattern analysis based on the interpretability of EnsemPPIS revealed its ability to learn residue interactions directly from protein sequences. EnsemPPIS is expected to facilitate in-depth understanding of molecular biology and advance research of drug discovery.</p>
  </sec>
  <sec id="sec10">
    <title>Materials and Methods</title>
    <sec id="sec11">
      <title>Benchmark datasets and evaluation metrics</title>
      <p>In this study, the performance of our proposed EnsemPPIS was comprehensively assessed on 3 PPI sites prediction tasks, including <italic toggle="yes">DeepPPISP task</italic> [<xref rid="B22" ref-type="bibr">22</xref>], <italic toggle="yes">GraphPPIS task</italic> [<xref rid="B35" ref-type="bibr">35</xref>], and <italic toggle="yes">DELPHI task</italic> [<xref rid="B34" ref-type="bibr">34</xref>]. The basic information about the datasets used in the 3 tasks is described below, and Table <xref rid="supplementary-material-1" ref-type="sec">S1</xref> provides the statistics of these datasets.</p>
      <sec id="sec12">
        <title>(a) <italic toggle="yes">DeepPPISP task</italic></title>
        <p>The Train352 and Test70 datasets used in the <italic toggle="yes">DeepPPISP task</italic> were obtained from DeepPPISP [<xref rid="B22" ref-type="bibr">22</xref>]. The DeepPPISP dataset was generated by combining 3 widely used benchmark datasets, namely, Dset_186 [<xref rid="B72" ref-type="bibr">72</xref>], Dset_72 [<xref rid="B72" ref-type="bibr">72</xref>], and PDBset_164 [<xref rid="B22" ref-type="bibr">22</xref>], each collected from the PDB database [<xref rid="B73" ref-type="bibr">73</xref>] and built through a data filtering process involving 6 steps [<xref rid="B72" ref-type="bibr">72</xref>]. In total, there were 422 protein sequences in the DeepPPISP dataset, each with the resolution less than 3.0 Å and sequence homology lower than 25%. A surface amino acid was defined as a PPI site if its absolute solvent accessibility decreases by at least 1.0 Å<sup>2</sup> upon protein binding [<xref rid="B74" ref-type="bibr">74</xref>]. For a fair comparison, we used the same data splitting scheme as DeepPPISP [<xref rid="B22" ref-type="bibr">22</xref>]. Thus, the training dataset Train352 contained 352 protein sequences and the independent test dataset Test70 was composed of 70 protein sequences. A subset of Train352 with 50 hold-out proteins is further randomly selected to form the validation dataset. As a result, there were 302 proteins in the training dataset, 50 proteins in the validation dataset, and 70 proteins in the test dataset.</p>
      </sec>
      <sec id="sec13">
        <title>(b) <italic toggle="yes">GraphPPIS task</italic></title>
        <p>The Train335 and Test60 datasets used in the <italic toggle="yes">GraphPPIS task</italic> were originally constructed by GraphPPIS and were also obtained by integrating the 3 datasets mentioned above (Dset_186, Dset_72, and PDBset_164) [<xref rid="B35" ref-type="bibr">35</xref>]. After the fusion of 3 benchmark datasets, BLASTClust [<xref rid="B75" ref-type="bibr">75</xref>] was further applied to remove protein sequences with similarities over 25%, leaving 395 nonredundant proteins. Subsequently, 335 proteins were randomly picked as the training data (Train335), and the remaining 60 proteins were used as the independent test data (Test60). To ensure a fair comparison, the Train335 and Test60 datasets used in this study were consistent with those used by GraphPPIS.</p>
      </sec>
      <sec id="sec14">
        <title>(c) <italic toggle="yes">DELPHI task</italic></title>
        <p>The Train9982 and Test355 datasets in <italic toggle="yes">DELPHI task</italic> were collected by DELPHI, a recent research of PPI sites prediction using sequences [<xref rid="B34" ref-type="bibr">34</xref>]. The Test355 dataset was a subset of Dset_448 dataset [<xref rid="B32" ref-type="bibr">32</xref>], which was built based on the BioLip database [<xref rid="B76" ref-type="bibr">76</xref>] and consisted of 448 nonredundant proteins with pairwise similarities lower than 25%. In the Dset_448 dataset, the interaction sites in a protein complex were defined as the residues to which 2 atoms belonged, based on a distance criterion. Specifically, if the distance between 2 atoms from different chains was found to be less than 0.5 Å plus the sum of their Van der Waals radii, these residues were identified as interacting sites. To ensure the comparability with another competing method named DLPred [<xref rid="B77" ref-type="bibr">77</xref>], the developers of DELPHI removed 93 proteins sharing similarities above 40% with any sequences in DLPred’s training dataset, and then constructed the Test355 dataset. To obtain the Train9982 dataset, the developers collected a large dataset from a previous study [<xref rid="B78" ref-type="bibr">78</xref>] and used PSI-CD-HIT [<xref rid="B79" ref-type="bibr">79</xref>] to remove sequences sharing similarities over 25% with any sequences in the Test355, followed by the removal of sequences with similarities above 25% among the remaining proteins. Among 9,982 sequences in the Train9982 dataset, 1,110 sequences were randomly selected to compose the validation dataset and the remaining sequences were utilized to train the model. It is important to note that the Train9982 dataset cannot be applied directly to train structure-based PPI sites prediction methods for the lack of structural information. Therefore, several methods using only sequences were evaluated in this task.</p>
        <p>The prediction of PPI sites is essentially a binary classification task. In this study, the interaction sites were taken as positive samples and non-interaction sites as negative samples. To fully evaluate the performance of EnsemPPIS and other competing methods, 7 widely used evaluation metrics were adopted in this study, including accuracy (ACC), precision (PRE), recall (REC), F1-score (F1), Matthews correlation coefficient (MCC), area under the receiver operator characteristic curve (AUROC), and area under the precision–recall curve (AUPRC). All metrics were calculated using the Scikit-learn package [<xref rid="B80" ref-type="bibr">80</xref>], and the formulas for computing these metrics were provided in Supplementary Methods. Serious data imbalance is reported to be a significant characteristic of PPI sites datasets, making MCC, F1, and AUPRC the most important and comprehensive indicators as they can emphasize more on the minority class [<xref rid="B22" ref-type="bibr">22</xref>,<xref rid="B81" ref-type="bibr">81</xref>,<xref rid="B82" ref-type="bibr">82</xref>].</p>
      </sec>
    </sec>
    <sec id="sec15">
      <title>Deep learning architecture of EnsemPPIS</title>
      <p>To convert protein sequences into embeddings, the pretrained protein language model, ProtBERT, was used to generate an <italic toggle="yes">L</italic> × 1,024 matrix for each protein sequence, where <italic toggle="yes">L</italic> is the sequence length and each amino acid is represented by a 1,024 embedding vector. ProtBERT is a BERT model pretrained on UniRef100 through self-supervised learning, which can capture biophysical features of protein sequences [<xref rid="B48" ref-type="bibr">48</xref>,<xref rid="B82" ref-type="bibr">82</xref>,<xref rid="B83" ref-type="bibr">83</xref>]. The embeddings of proteins were further passed to the 2 base models of EnsemPPIS, namely, TransformerPPIS and GatCNNPPIS. Inspired by the great ability of transformer in extracting sequence features, the novel TransformerPPIS was proposed for predicting PPI sites using the modified transformer. The architecture of TransformerPPIS, as shown in Fig. <xref rid="F2" ref-type="fig">2</xref>, consists of 3 modules: the encoder, the decoder, and the classifier module.</p>
      <sec id="sec16">
        <title>(a) <italic toggle="yes">Encoder module</italic></title>
        <p>In contrast to the original transformer framework, the encoder of TransformerPPIS uses a gated convolutional network with Conv1D and gated linear unit in place of the self-attention layers [<xref rid="B84" ref-type="bibr">84</xref>]. Conv1D mainly captures the contextual representation of residues with local biases and learns the global protein features by assembling local features of all residues. The gated linear unit can enhance the network's capacity to process nonlinear information and extract more informative representations from proteins. The sequence embedding of a protein is first converted into an <italic toggle="yes">L</italic> × 64 matrix using the FC and then fed into the gated convolutional network. The hidden layers <italic toggle="yes">h</italic><sub>0</sub>, …, <italic toggle="yes">h<sub>l</sub></italic> in the gated convolutional network are computed as <xref rid="EQ1" ref-type="disp-formula">Eq. 1</xref>:<disp-formula id="EQ1"><mml:math id="M1" display="block" overflow="scroll"><mml:msub><mml:mi>h</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:mfenced open="(" close=")"><mml:mi mathvariant="bold-italic">X</mml:mi></mml:mfenced><mml:mo>=</mml:mo><mml:mfenced open="(" close=")"><mml:mrow><mml:mi mathvariant="bold-italic">X</mml:mi><mml:mo>∗</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">b</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mfenced><mml:mo>⊗</mml:mo><mml:mi>σ</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:mi mathvariant="bold-italic">X</mml:mi><mml:mo>∗</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">b</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mfenced></mml:math><label>(1)</label></disp-formula></p>
        <p>where <bold><italic toggle="yes">X</italic></bold> ∈ <italic toggle="yes">ℝ</italic><sup><italic toggle="yes">n</italic>×<italic toggle="yes">m</italic><sub>1</sub></sup> is the input of layer <italic toggle="yes">h<sub>l</sub></italic>; <bold><italic toggle="yes">W</italic></bold><sub>1</sub> ∈ <italic toggle="yes">ℝ</italic><sup><italic toggle="yes">k</italic>×<italic toggle="yes">m</italic><sub>1</sub>×<italic toggle="yes">m</italic><sub>2</sub></sup>, <bold><italic toggle="yes">W</italic></bold><sub>2</sub> ∈ <italic toggle="yes">ℝ</italic><sup><italic toggle="yes">k</italic>×<italic toggle="yes">m</italic><sub>1</sub>×<italic toggle="yes">m</italic><sub>2</sub></sup>, <italic toggle="yes">b</italic><sub>1</sub> ∈ <italic toggle="yes">ℝ</italic><sup><italic toggle="yes">m</italic><sub>2</sub></sup>, and <italic toggle="yes">b</italic><sub>2</sub> ∈ <italic toggle="yes">ℝ</italic><sup><italic toggle="yes">m</italic><sub>2</sub></sup> are trainable parameters; <italic toggle="yes">l</italic> is the number of encoder layers; <italic toggle="yes">n</italic> is the length of the sequence; <italic toggle="yes">m</italic><sub>1</sub> and <italic toggle="yes">m</italic><sub>2</sub> are the dimension of input and hidden features of the gated convolutional network, respectively; <italic toggle="yes">k</italic> is the kernel size of Conv1D; <italic toggle="yes">σ</italic> is the sigmoid function; and ⨂ represents the element-wise product between matrices [<xref rid="B84" ref-type="bibr">84</xref>]. In this study, <italic toggle="yes">l</italic> is 3, <italic toggle="yes">m</italic><sub>1</sub> is 64, <italic toggle="yes">m</italic><sub>2</sub> is 128, and <italic toggle="yes">k</italic> is 7. The encoder module adopts residual connection and layer normalization to solve the oversmoothing problem [<xref rid="B85" ref-type="bibr">85</xref>]. The output of encoder, an <italic toggle="yes">L</italic> × 64 matrix, is the final representation of a protein.</p>
      </sec>
      <sec id="sec17">
        <title>(b) <italic toggle="yes">Decoder module</italic></title>
        <p>The decoder module of TransformerPPIS is specifically designed to learn and capture residue interactions within protein sequences. The input of decoder module contains 2 parts: the global feature of the protein output by the encoder module and the original embedding of a specific residue obtained by ProtBERT. The decoder module mainly consists of multi-head self-attention layers and feedforward layers. The multi-head self-attention layer extracts the interactions between the specific residue and other residues, which takes 3 inputs: the queries, <bold><italic toggle="yes">Q</italic></bold>; the keys, <bold><italic toggle="yes">K</italic></bold>; and the values, <bold><italic toggle="yes">V</italic></bold> [<xref rid="B86" ref-type="bibr">86</xref>,<xref rid="B87" ref-type="bibr">87</xref>]. TransformerPPIS regards the residue embedding as <bold><italic toggle="yes">Q</italic></bold> and the global protein feature as <bold><italic toggle="yes">K</italic></bold> and <bold><italic toggle="yes">V</italic></bold>, and calculates the attention weight using <bold><italic toggle="yes">Q</italic></bold> and <bold><italic toggle="yes">K</italic></bold>. The calculation formula is as follows:<disp-formula id="EQ2"><mml:math id="M2" display="block" overflow="scroll"><mml:mtext>attention</mml:mtext><mml:mfenced open="(" close=")"><mml:mrow><mml:mi mathvariant="bold-italic">Q</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">K</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">V</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mtext>softmax</mml:mtext><mml:mfenced open="(" close=")"><mml:mrow><mml:mfrac><mml:mrow><mml:mi mathvariant="bold-italic">Q</mml:mi><mml:msup><mml:mi mathvariant="bold-italic">K</mml:mi><mml:mi mathvariant="normal">T</mml:mi></mml:msup></mml:mrow><mml:msqrt><mml:msub><mml:mi>d</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:msqrt></mml:mfrac></mml:mrow></mml:mfenced><mml:mi mathvariant="bold-italic">V</mml:mi></mml:math><label>(2)</label></disp-formula></p>
        <p>where <italic toggle="yes">d<sub>k</sub></italic> is a scaling factor depending on the dimension of the hidden layer. The mask operation in the original transformer framework is modified in the decoder module to ensure that the complete sequence information is accessible. Accurately identifying PPI sites necessitates careful attention to the features of the local structure surrounding these sites [<xref rid="B40" ref-type="bibr">40</xref>]. However, residues that are spatially close may be far apart in sequence due to the intricate folding patterns and 3-dimensional arrangement of protein structures. The self-attention mechanism employed in TransformerPPIS empowers the model to effectively capture the interactions between remote residues in a protein sequence. Another major component of decoder module is the feedforward layer, which improves the expressiveness of features by nonlinear transformation [<xref rid="B88" ref-type="bibr">88</xref>]. After each self-attention layer and feedforward layer, the residual connection and layer normalization are used.</p>
      </sec>
      <sec id="sec18">
        <title>(c) <italic toggle="yes">Classifier module</italic></title>
        <p>The output of decoder module is the interaction feature between the specific residue and the global protein sequence. The interaction feature vector is further fed to the classifier module, which is composed of 3 FCs and the ReLU activation function [<xref rid="B89" ref-type="bibr">89</xref>]. Finally, the probability of a residue being a PPI site is calculated by the softmax function.</p>
        <p>The GatCNNPPIS base model presented here can be viewed as a simplified version of TransformerPPIS, consisting solely of the encoder and the classifier modules. In the output of the encoder module (the <italic toggle="yes">L</italic> × 64 matrix), each vector represents the local contextual feature of a particular residue. GatCNNPPIS takes this vector as input and directly feeds it into the classifier module, which outputs the probability of the corresponding residue being an interaction site.</p>
      </sec>
    </sec>
    <sec id="sec19">
      <title>Model training and hyperparameter tuning</title>
      <p>The classification of PPI sites poses a challenge due to the inherent imbalance in the dataset. After the softmax function normalized the output of the network into the probability over the 2 classes (interaction site and non-interaction site), the weighted cross-entropy loss function was adopted to compute the loss values of samples, which were subsequently used to calculate the gradient of parameter update in the backward propagation process [<xref rid="B90" ref-type="bibr">90</xref>]. The weighted cross-entropy loss function assigned different class weights to positive and negative samples, allowing the model to prioritize the minority class and allocate more attention to its predictions. During model training, the ratio between the weights of positive and negative samples was determined based on the model’s performance on the validation dataset. Specifically, in the <italic toggle="yes">DeepPPISP task</italic> and <italic toggle="yes">GraphPPIS task</italic>, the weight ratio was set to 5:1, while in the <italic toggle="yes">DELPHI task</italic>, it was set to 3:1. The LookAhead optimizer and RAdam optimizer were used during the training process [<xref rid="B91" ref-type="bibr">91</xref>]. In each PPI sites prediction task, the EnsemPPIS used the same training scheme as that of the competing method [<xref rid="B22" ref-type="bibr">22</xref>,<xref rid="B34" ref-type="bibr">34</xref>,<xref rid="B35" ref-type="bibr">35</xref>]. Specifically, in the <italic toggle="yes">DeepPPISP task</italic> and <italic toggle="yes">DELPHI task</italic>, the training dataset was used to train EnsemPPIS, and the validation dataset was used to evaluate the predictive performance and optimize the hyperparameters, followed by the assessment and report of the performance of the best model on the independent test dataset. In the <italic toggle="yes">GraphPPIS task</italic>, the 5-fold cross-validation was performed on the training dataset to avoid the influence of random errors, that is, all proteins in the Train335 dataset were randomly divided into 5 folds. Among these 5 folds, 4 folds were utilized to train EnsemPPIS and the remaining fold served as the validation dataset to evaluate the model. This procedure was repeated 5 times, with each fold serving as the validation dataset. The average of the 5 evaluation results was then calculated to obtain the overall evaluation result. Based on this result, the best hyperparameters were selected. When the hyperparameters were determined, the final model was trained using all training data and evaluated on the independent test dataset. The early stopping strategy was applied to reduce overfitting and training cost [<xref rid="B92" ref-type="bibr">92</xref>–<xref rid="B94" ref-type="bibr">94</xref>]. In order to facilitate the convergence of training and improve the capacity of generalization, regularization methods including dropout and weight decay were used during training EnsemPPIS [<xref rid="B95" ref-type="bibr">95</xref>–<xref rid="B97" ref-type="bibr">97</xref>].</p>
      <p>As an ensemble learning framework, the 2 base models of EnsemPPIS (TransformerPPIS and GatCNNPPIS) were separately trained using the same training procedure. To optimize EnsemPPIS, we selected the optimal combinations of base models [<xref rid="B98" ref-type="bibr">98</xref>]. After the completion of model training, the 2 saved models were loaded for individual prediction of PPI sites. In addition, we constructed 2 variants of EnsemPPIS to evaluate the outcomes achieved by combining the 2 base models into a single model for concurrent training. The architectures of the 2 variants were depicted in Fig. <xref rid="F3" ref-type="fig">3</xref>A and B. Specifically, in the first variant of EnsemPPIS (EnsemPPIS-Va), the output of TransformerPPIS’s decoder and the output of GatCNNPPIS’s encoder were concatenated. The concatenated vector was then fed into multiple FCs to obtain the probability of being PPI site. In the second variant (EnsemPPIS-Vb), the output of TransformerPPIS’s decoder and the output of GatCNNPPIS’s encoder were separately passed through 3 FCs. The resulting 2-dimensional vectors were then concatenated, and the concatenated 4-dimensional vector was further processed through an FC to obtain the predicted probability. The output of each variant was utilized to calculate the loss for jointly updating the parameters of the 2 base models.</p>
      <p>Three most influential hyperparameters (batch size, learning rate, and dropout rate) were tuned according to the predictive performance on the validation dataset. As a result, the optimal combination of the above 3 hyperparameters was decided (batch size = 128, learning rate = 0.0005, dropout rate = 0.1). All the hyperparameter settings of EnsemPPIS were summarized in Table <xref rid="supplementary-material-1" ref-type="sec">S4</xref>. EnsemPPIS was implemented with Pytorch 1.2.0 (<ext-link xlink:href="http://pytorch.org/" ext-link-type="uri">http://pytorch.org/</ext-link>) and supported distributed training [<xref rid="B99" ref-type="bibr">99</xref>]. All scripts were written by Python 3.7.11, and all models were developed on the computer with Intel Xeon Gold 6132 CPU @ 2.60GHz, NVIDIA Tesla P100 16GB GPU and 263GB RAM on CentOS Linux release 7.9.2009 (Core).</p>
    </sec>
    <sec id="sec20">
      <title>A variety of methods compared with EnsemPPIS</title>
      <p>A comprehensive review on the previously published tools for PPI sites prediction was conducted in this study, which were systematically compared with our proposed EnsemPPIS, as shown in Table <xref rid="supplementary-material-1" ref-type="sec">S5</xref>. These methods can be grouped into sequence-based and structure-based depending on whether the protein structural information is used. Sequence-based methods include ISIS [<xref rid="B100" ref-type="bibr">100</xref>], PSIVER [<xref rid="B72" ref-type="bibr">72</xref>], SPRINGS [<xref rid="B31" ref-type="bibr">31</xref>], RF_PPI [<xref rid="B27" ref-type="bibr">27</xref>], SCRIBER [<xref rid="B32" ref-type="bibr">32</xref>], DELPHI [<xref rid="B34" ref-type="bibr">34</xref>], ProNA2020 [<xref rid="B33" ref-type="bibr">33</xref>], and DLPred [<xref rid="B77" ref-type="bibr">77</xref>]. SCRIBER used a 2-layer architecture to perform partner type-specific prediction of protein-binding residues [<xref rid="B32" ref-type="bibr">32</xref>]. ProNA2020 utilized the combination of homology-based inference and machine learning methods to predict protein-macromolecular binding residues using only protein sequences [<xref rid="B33" ref-type="bibr">33</xref>]. DELPHI was the SOTA sequence-based method that used 12 feature groups to encode proteins, and incorporated CNN and RNN with the ensemble learning strategy to enhance its predictive performance [<xref rid="B34" ref-type="bibr">34</xref>]. Structure-based methods include SPPIDER [<xref rid="B28" ref-type="bibr">28</xref>], IntPred [<xref rid="B21" ref-type="bibr">21</xref>], DeepPPISP [<xref rid="B22" ref-type="bibr">22</xref>], EGRET [<xref rid="B23" ref-type="bibr">23</xref>], GraphPPIS [<xref rid="B35" ref-type="bibr">35</xref>], and RGN [<xref rid="B40" ref-type="bibr">40</xref>]. DeepPPISP proposed an end to end deep learning model, which used CNN to combine local contextual and global features for PPI sites prediction [<xref rid="B22" ref-type="bibr">22</xref>]. EGRET constructed an edge aggregated graph attention network to effectively leverage protein structural information [<xref rid="B23" ref-type="bibr">23</xref>]. GraphPPIS employed evolutionary information and structural properties of amino acids to train the deep convolutional network for the prediction of PPI sites [<xref rid="B35" ref-type="bibr">35</xref>]. RGN applied PSSM, hidden Markov model, hydrogen bond estimation algorithm, and ProtBERT for node representation and constructed a residue-based graph attention and convolutional network [<xref rid="B40" ref-type="bibr">40</xref>].</p>
    </sec>
  </sec>
</body>
<back>
  <ack>
    <title>Acknowledgments</title>
    <p><bold>Funding:</bold> This work was supported by the National Natural Science Foundation of China (82373790, U1909208, 22220102001, and 81872798), Natural Science Foundation of Zhejiang Province (LR21H300001), Leading Talent of the “Ten Thousand Plan”—National High-Level Talents Special Supports Plan of China, National Key R&amp;D Program of China (2022YFC3400501), Key R&amp;D Program of Zhejiang Province (2020C03010), “Double Top-Class” Universities Projects (181201*194232101), Fundamental Research Funds for Central University (2018QNA7023), Alibaba-Zhejiang University Joint Research Center Future Digital Healthcare, Westlake Laboratory (Westlake Laboratory of Life Science &amp; Biomedicine), Alibaba Cloud, and Information Technology Center of Zhejiang University. Funds for the open access charge: Natural Science Foundation of Zhejiang Province (LR21H300001). <bold>Author contributions:</bold> M.M., Z.P., and F.Z. conceptualized ideas, proposed methods, and wrote the manuscript. M.M. investigated and implemented the deep learning programs. Z.Z. and F.L. constructed the web server. L.Z., H.Z., S.S., and X.S. completed the data collection. All authors have read and approved the final manuscript. <bold>Competing interests:</bold> The authors declare that they have no competing interests.</p>
  </ack>
  <sec sec-type="data-availability">
    <title>Data Availability</title>
    <p>The EnsemPPIS web server is freely available at <ext-link xlink:href="http://idrblab.org/ensemppis" ext-link-type="uri">http://idrblab.org/ensemppis</ext-link>, with all source codes and benchmark datasets in this study. The trained models and the EnsemPPIS standalone source code can be found at <ext-link xlink:href="https://github.com/idrblab/EnsemPPIS" ext-link-type="uri">https://github.com/idrblab/EnsemPPIS</ext-link>.</p>
  </sec>
  <sec sec-type="supplementary-material" id="supplementary-material-1">
    <title>Supplementary Materials</title>
    <supplementary-material id="supp-1" position="float" content-type="local-data">
      <label>Supplementary 1</label>
      <caption>
        <p>Methods</p>
        <p>Tables S1 to S5</p>
        <p>Fig. S1</p>
        <p>References</p>
      </caption>
      <media xlink:href="research.0240.f1.docx">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
  <ref-list>
    <title>References</title>
    <ref id="B1">
      <label>1.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kim</surname><given-names>M</given-names></string-name>, <string-name><surname>Park</surname><given-names>J</given-names></string-name>, <string-name><surname>Bouhaddou</surname><given-names>M</given-names></string-name>, <string-name><surname>Kim</surname><given-names>K</given-names></string-name>, <string-name><surname>Rojc</surname><given-names>A</given-names></string-name>, <string-name><surname>Modak</surname><given-names>M</given-names></string-name>, <string-name><surname>Soucheray</surname><given-names>M</given-names></string-name>, <string-name><surname>McGregor</surname><given-names>MJ</given-names></string-name>, <string-name><surname>O'Leary</surname><given-names>P</given-names></string-name>, <string-name><surname>Wolf</surname><given-names>D</given-names></string-name>, <etal>et al.</etal></person-group><article-title>A protein interaction landscape of breast cancer</article-title>. <source><italic toggle="yes">Science</italic></source>. <year>2021</year>;<volume>374</volume>(<issue>6563</issue>):<fpage>eabf3066</fpage>.<pub-id pub-id-type="pmid">34591612</pub-id></mixed-citation>
    </ref>
    <ref id="B2">
      <label>2.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fessenden</surname><given-names>M</given-names></string-name></person-group>. 
<article-title>Protein maps chart the causes of disease</article-title>. <source><italic toggle="yes">Nature</italic></source>. <year>2017</year>;<volume>549</volume>(<issue>7671</issue>):<fpage>293</fpage>–<lpage>295</lpage>.<pub-id pub-id-type="pmid">28905898</pub-id></mixed-citation>
    </ref>
    <ref id="B3">
      <label>3.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Batra</surname><given-names>J</given-names></string-name>, <string-name><surname>Hultquist</surname><given-names>JF</given-names></string-name>, <string-name><surname>Liu</surname><given-names>D</given-names></string-name>, <string-name><surname>Shtanko</surname><given-names>O</given-names></string-name>, <string-name><surname>Von Dollen</surname><given-names>J</given-names></string-name>, <string-name><surname>Satkamp</surname><given-names>L</given-names></string-name>, <string-name><surname>Jang</surname><given-names>GM</given-names></string-name>, <string-name><surname>Luthra</surname><given-names>P</given-names></string-name>, <string-name><surname>Schwarz</surname><given-names>TM</given-names></string-name>, <string-name><surname>Small</surname><given-names>GI</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Protein interaction mapping identifies RBBP6 as a negative regulator of Ebola virus replication</article-title>. <source><italic toggle="yes">Cell</italic></source>. <year>2018</year>;<volume>175</volume>(<issue>7</issue>):<fpage>1917</fpage>–<lpage>1930 e1913</lpage>.<pub-id pub-id-type="pmid">30550789</pub-id></mixed-citation>
    </ref>
    <ref id="B4">
      <label>4.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wojtowicz</surname><given-names>WM</given-names></string-name>, <string-name><surname>Vielmetter</surname><given-names>J</given-names></string-name>, <string-name><surname>Fernandes</surname><given-names>RA</given-names></string-name>, <string-name><surname>Siepe</surname><given-names>DH</given-names></string-name>, <string-name><surname>Eastman</surname><given-names>CL</given-names></string-name>, <string-name><surname>Chisholm</surname><given-names>GB</given-names></string-name>, <string-name><surname>Cox</surname><given-names>S</given-names></string-name>, <string-name><surname>Klock</surname><given-names>H</given-names></string-name>, <string-name><surname>Anderson</surname><given-names>PW</given-names></string-name>, <string-name><surname>Rue</surname><given-names>SM</given-names></string-name>, <etal>et al.</etal></person-group><article-title>A human IgSF cell-surface Interactome reveals a complex network of protein-protein interactions</article-title>. <source><italic toggle="yes">Cell</italic></source>. <year>2020</year>;<volume>182</volume>(<issue>4</issue>):<fpage>1027</fpage>–<lpage>1043</lpage>.<pub-id pub-id-type="pmid">32822567</pub-id></mixed-citation>
    </ref>
    <ref id="B5">
      <label>5.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Stelzl</surname><given-names>U</given-names></string-name>, <string-name><surname>Worm</surname><given-names>U</given-names></string-name>, <string-name><surname>Lalowski</surname><given-names>M</given-names></string-name>, <string-name><surname>Haenig</surname><given-names>C</given-names></string-name>, <string-name><surname>Brembeck</surname><given-names>FH</given-names></string-name>, <string-name><surname>Goehler</surname><given-names>H</given-names></string-name>, <string-name><surname>Stroedicke</surname><given-names>M</given-names></string-name>, <string-name><surname>Zenkner</surname><given-names>M</given-names></string-name>, <string-name><surname>Schoenherr</surname><given-names>A</given-names></string-name>, <string-name><surname>Koeppen</surname><given-names>S</given-names></string-name>, <etal>et al.</etal></person-group><article-title>A human protein-protein interaction network: A resource for annotating the proteome</article-title>. <source><italic toggle="yes">Cell</italic></source>. <year>2005</year>;<volume>122</volume>(<issue>6</issue>):<fpage>957</fpage>–<lpage>968</lpage>.<pub-id pub-id-type="pmid">16169070</pub-id></mixed-citation>
    </ref>
    <ref id="B6">
      <label>6.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hamdi</surname><given-names>A</given-names></string-name>, <string-name><surname>Colas</surname><given-names>P</given-names></string-name></person-group>. 
<article-title>Yeast two-hybrid methods and their applications in drug discovery</article-title>. <source><italic toggle="yes">Trends Pharmacol Sci</italic></source>. <year>2012</year>;<volume>33</volume>(<issue>2</issue>):<fpage>109</fpage>–<lpage>118</lpage>.<pub-id pub-id-type="pmid">22130009</pub-id></mixed-citation>
    </ref>
    <ref id="B7">
      <label>7.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname><given-names>J</given-names></string-name>, <string-name><surname>Lisanza</surname><given-names>S</given-names></string-name>, <string-name><surname>Juergens</surname><given-names>D</given-names></string-name>, <string-name><surname>Tischer</surname><given-names>D</given-names></string-name>, <string-name><surname>Watson</surname><given-names>JL</given-names></string-name>, <string-name><surname>Castro</surname><given-names>KM</given-names></string-name>, <string-name><surname>Ragotte</surname><given-names>R</given-names></string-name>, <string-name><surname>Saragovi</surname><given-names>A</given-names></string-name>, <string-name><surname>Milles</surname><given-names>LF</given-names></string-name>, <string-name><surname>Baek</surname><given-names>M</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Scaffolding protein functional sites using deep learning</article-title>. <source><italic toggle="yes">Science</italic></source>. <year>2022</year>;<volume>377</volume>(<issue>6604</issue>):<fpage>387</fpage>–<lpage>394</lpage>.<pub-id pub-id-type="pmid">35862514</pub-id></mixed-citation>
    </ref>
    <ref id="B8">
      <label>8.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Qi</surname><given-names>R</given-names></string-name>, <string-name><surname>Zou</surname><given-names>Q</given-names></string-name></person-group>. 
<article-title>Trends and potential of machine learning and deep learning in drug study at single-cell level</article-title>. <source><italic toggle="yes">Research (Wash D C)</italic></source>. <year>2023</year>;<volume>6</volume>:<fpage>0050</fpage>.<pub-id pub-id-type="pmid">36930772</pub-id></mixed-citation>
    </ref>
    <ref id="B9">
      <label>9.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Liu</surname><given-names>X</given-names></string-name>, <string-name><surname>Salokas</surname><given-names>K</given-names></string-name>, <string-name><surname>Weldatsadik</surname><given-names>RG</given-names></string-name>, <string-name><surname>Gawriyski</surname><given-names>L</given-names></string-name>, <string-name><surname>Varjosalo</surname><given-names>M</given-names></string-name></person-group>. 
<article-title>Combined proximity labeling and affinity purification-mass spectrometry workflow for mapping and visualizing protein interaction networks</article-title>. <source><italic toggle="yes">Nat Protoc</italic></source>. <year>2020</year>;<volume>15</volume>(<issue>10</issue>):<fpage>3182</fpage>–<lpage>3211</lpage>.<pub-id pub-id-type="pmid">32778839</pub-id></mixed-citation>
    </ref>
    <ref id="B10">
      <label>10.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mou</surname><given-names>M</given-names></string-name>, <string-name><surname>Pan</surname><given-names>Z</given-names></string-name>, <string-name><surname>Lu</surname><given-names>M</given-names></string-name>, <string-name><surname>Sun</surname><given-names>H</given-names></string-name>, <string-name><surname>Wang</surname><given-names>Y</given-names></string-name>, <string-name><surname>Luo</surname><given-names>Y</given-names></string-name>, <string-name><surname>Zhu</surname><given-names>F</given-names></string-name></person-group>. 
<article-title>Application of machine learning in spatial proteomics</article-title>. <source><italic toggle="yes">J Chem Inf Model</italic></source>. <year>2022</year>;<volume>62</volume>(<issue>23</issue>):<fpage>5875</fpage>–<lpage>5895</lpage>.<pub-id pub-id-type="pmid">36378082</pub-id></mixed-citation>
    </ref>
    <ref id="B11">
      <label>11.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kong</surname><given-names>L</given-names></string-name>, <string-name><surname>Chen</surname><given-names>J</given-names></string-name>, <string-name><surname>Ji</surname><given-names>X</given-names></string-name>, <string-name><surname>Qin</surname><given-names>Q</given-names></string-name>, <string-name><surname>Yang</surname><given-names>H</given-names></string-name>, <string-name><surname>Liu</surname><given-names>D</given-names></string-name>, <string-name><surname>Li</surname><given-names>D</given-names></string-name>, <string-name><surname>Sun</surname><given-names>M</given-names></string-name></person-group>. 
<article-title>Alcoholic fatty liver disease inhibited the co-expression of Fmo5 and PPARalpha to activate the NF-kappaB signaling pathway, thereby reducing liver injury via inducing gut microbiota disturbance</article-title>. <source><italic toggle="yes">J Exp Clin Cancer Res</italic></source>. <year>2021</year>;<volume>40</volume>(<issue>1</issue>):<fpage>18</fpage>.<pub-id pub-id-type="pmid">33413501</pub-id></mixed-citation>
    </ref>
    <ref id="B12">
      <label>12.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sung</surname><given-names>MS</given-names></string-name>, <string-name><surname>Jung</surname><given-names>JH</given-names></string-name>, <string-name><surname>Jeong</surname><given-names>C</given-names></string-name>, <string-name><surname>Yoon</surname><given-names>TY</given-names></string-name>, <string-name><surname>Park</surname><given-names>JH</given-names></string-name></person-group>. 
<article-title>Single-molecule co-immunoprecipitation reveals functional inheritance of EGFRs in extracellular vesicles</article-title>. <source><italic toggle="yes">Small</italic></source>. <year>2018</year>;<volume>14</volume>(<issue>42</issue>):
<elocation-id>e1802358</elocation-id>.<pub-id pub-id-type="pmid">30239124</pub-id></mixed-citation>
    </ref>
    <ref id="B13">
      <label>13.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tang</surname><given-names>HW</given-names></string-name>, <string-name><surname>Spirohn</surname><given-names>K</given-names></string-name>, <string-name><surname>Hu</surname><given-names>Y</given-names></string-name>, <string-name><surname>Hao</surname><given-names>T</given-names></string-name>, <string-name><surname>Kovacs</surname><given-names>IA</given-names></string-name>, <string-name><surname>Gao</surname><given-names>Y</given-names></string-name>, <string-name><surname>Binari</surname><given-names>R</given-names></string-name>, <string-name><surname>Yang-Zhou</surname><given-names>D</given-names></string-name>, <string-name><surname>Wan</surname><given-names>KH</given-names></string-name>, <string-name><surname>Bader</surname><given-names>JS</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Next-generation large-scale binary protein interaction network for Drosophila melanogaster</article-title>. <source><italic toggle="yes">Nat Commun</italic></source>. <year>2023</year>;<volume>14</volume>(<issue>1</issue>):<fpage>2162</fpage>.<pub-id pub-id-type="pmid">37061542</pub-id></mixed-citation>
    </ref>
    <ref id="B14">
      <label>14.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Giot</surname><given-names>L</given-names></string-name>, <string-name><surname>Bader</surname><given-names>JS</given-names></string-name>, <string-name><surname>Brouwer</surname><given-names>C</given-names></string-name>, <string-name><surname>Chaudhuri</surname><given-names>A</given-names></string-name>, <string-name><surname>Kuang</surname><given-names>B</given-names></string-name>, <string-name><surname>Li</surname><given-names>Y</given-names></string-name>, <string-name><surname>Hao</surname><given-names>YL</given-names></string-name>, <string-name><surname>Ooi</surname><given-names>CE</given-names></string-name>, <string-name><surname>Godwin</surname><given-names>B</given-names></string-name>, <string-name><surname>Vitols</surname><given-names>E</given-names></string-name>, <etal>et al.</etal></person-group><article-title>A protein interaction map of Drosophila melanogaster</article-title>. <source><italic toggle="yes">Science</italic></source>. <year>2003</year>;<volume>302</volume>(<issue>5651</issue>):<fpage>1727</fpage>–<lpage>1736</lpage>.<pub-id pub-id-type="pmid">14605208</pub-id></mixed-citation>
    </ref>
    <ref id="B15">
      <label>15.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kataria</surname><given-names>R</given-names></string-name>, <string-name><surname>Kaundal</surname><given-names>R</given-names></string-name></person-group>. 
<article-title>WeCoNET: A host-pathogen interactome database for deciphering crucial molecular networks of wheat-common bunt cross-talk mechanisms</article-title>. <source><italic toggle="yes">Plant Methods</italic></source>. <year>2022</year>;<volume>18</volume>(<issue>1</issue>):<fpage>73</fpage>.<pub-id pub-id-type="pmid">35658913</pub-id></mixed-citation>
    </ref>
    <ref id="B16">
      <label>16.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Shu</surname><given-names>Y</given-names></string-name>, <string-name><surname>Hai</surname><given-names>Y</given-names></string-name>, <string-name><surname>Cao</surname><given-names>L</given-names></string-name>, <string-name><surname>Wu</surname><given-names>J</given-names></string-name></person-group>. 
<article-title>Deep-learning based approach to identify substrates of human E3 ubiquitin ligases and deubiquitinases</article-title>. <source><italic toggle="yes">Comput Struct Biotechnol J</italic></source>. <year>2023</year>;<volume>21</volume>:<fpage>1014</fpage>–<lpage>1021</lpage>.<pub-id pub-id-type="pmid">36733699</pub-id></mixed-citation>
    </ref>
    <ref id="B17">
      <label>17.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wu</surname><given-names>F</given-names></string-name>, <string-name><surname>Wang</surname><given-names>S</given-names></string-name>, <string-name><surname>Zeng</surname><given-names>Q</given-names></string-name>, <string-name><surname>Liu</surname><given-names>J</given-names></string-name>, <string-name><surname>Yang</surname><given-names>J</given-names></string-name>, <string-name><surname>Mu</surname><given-names>J</given-names></string-name>, <string-name><surname>Xu</surname><given-names>H</given-names></string-name>, <string-name><surname>Wu</surname><given-names>L</given-names></string-name>, <string-name><surname>Gao</surname><given-names>Q</given-names></string-name>, <string-name><surname>He</surname><given-names>X</given-names></string-name>, <etal>et al.</etal></person-group><article-title>TGF-betaRII regulates glucose metabolism in oral cancer-associated fibroblasts via promoting PKM2 nuclear translocation</article-title>. <source><italic toggle="yes">Cell Death Discov</italic></source>. <year>2022</year>;<volume>8</volume>(<issue>1</issue>):<fpage>3</fpage>.<pub-id pub-id-type="pmid">35013150</pub-id></mixed-citation>
    </ref>
    <ref id="B18">
      <label>18.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zheng</surname><given-names>M</given-names></string-name>, <string-name><surname>Liu</surname><given-names>X</given-names></string-name>, <string-name><surname>Xu</surname><given-names>Y</given-names></string-name>, <string-name><surname>Li</surname><given-names>H</given-names></string-name>, <string-name><surname>Luo</surname><given-names>C</given-names></string-name>, <string-name><surname>Jiang</surname><given-names>H</given-names></string-name></person-group>. 
<article-title>Computational methods for drug design and discovery: Focus on China</article-title>. <source><italic toggle="yes">Trends Pharmacol Sci</italic></source>. <year>2013</year>;<volume>34</volume>(<issue>10</issue>):<fpage>549</fpage>–<lpage>559</lpage>.<pub-id pub-id-type="pmid">24035675</pub-id></mixed-citation>
    </ref>
    <ref id="B19">
      <label>19.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Esmaielbeiki</surname><given-names>R</given-names></string-name>, <string-name><surname>Krawczyk</surname><given-names>K</given-names></string-name>, <string-name><surname>Knapp</surname><given-names>B</given-names></string-name>, <string-name><surname>Nebel</surname><given-names>JC</given-names></string-name>, <string-name><surname>Deane</surname><given-names>CM</given-names></string-name></person-group>. 
<article-title>Progress and challenges in predicting protein interfaces</article-title>. <source><italic toggle="yes">Brief Bioinform</italic></source>. <year>2016</year>;<volume>17</volume>(<issue>1</issue>):<fpage>117</fpage>–<lpage>131</lpage>.<pub-id pub-id-type="pmid">25971595</pub-id></mixed-citation>
    </ref>
    <ref id="B20">
      <label>20.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ezkurdia</surname><given-names>I</given-names></string-name>, <string-name><surname>Bartoli</surname><given-names>L</given-names></string-name>, <string-name><surname>Fariselli</surname><given-names>P</given-names></string-name>, <string-name><surname>Casadio</surname><given-names>R</given-names></string-name>, <string-name><surname>Valencia</surname><given-names>A</given-names></string-name>, <string-name><surname>Tress</surname><given-names>ML</given-names></string-name></person-group>. 
<article-title>Progress and challenges in predicting protein-protein interaction sites</article-title>. <source><italic toggle="yes">Brief Bioinform</italic></source>. <year>2009</year>;<volume>10</volume>(<issue>3</issue>):<fpage>233</fpage>–<lpage>246</lpage>.<pub-id pub-id-type="pmid">19346321</pub-id></mixed-citation>
    </ref>
    <ref id="B21">
      <label>21.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Northey</surname><given-names>TC</given-names></string-name>, <string-name><surname>Baresic</surname><given-names>A</given-names></string-name>, <string-name><surname>Martin</surname><given-names>ACR</given-names></string-name></person-group>. 
<article-title>IntPred: A structure-based predictor of protein-protein interaction sites</article-title>. <source><italic toggle="yes">Bioinformatics</italic></source>. <year>2018</year>;<volume>34</volume>(<issue>2</issue>):<fpage>223</fpage>–<lpage>229</lpage>.<pub-id pub-id-type="pmid">28968673</pub-id></mixed-citation>
    </ref>
    <ref id="B22">
      <label>22.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zeng</surname><given-names>M</given-names></string-name>, <string-name><surname>Zhang</surname><given-names>F</given-names></string-name>, <string-name><surname>Wu</surname><given-names>FX</given-names></string-name>, <string-name><surname>Li</surname><given-names>Y</given-names></string-name>, <string-name><surname>Wang</surname><given-names>J</given-names></string-name>, <string-name><surname>Li</surname><given-names>M</given-names></string-name></person-group>. 
<article-title>Protein-protein interaction site prediction through combining local and global features with deep neural networks</article-title>. <source><italic toggle="yes">Bioinformatics</italic></source>. <year>2020</year>;<volume>36</volume>(<issue>4</issue>):<fpage>1114</fpage>–<lpage>1120</lpage>.<pub-id pub-id-type="pmid">31593229</pub-id></mixed-citation>
    </ref>
    <ref id="B23">
      <label>23.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mahbub</surname><given-names>S</given-names></string-name>, <string-name><surname>Bayzid</surname><given-names>MS</given-names></string-name></person-group>. 
<article-title>EGRET: Edge aggregated graph attention networks and transfer learning improve protein-protein interaction site prediction</article-title>. <source><italic toggle="yes">Brief Bioinform</italic></source>. <year>2022</year>;<volume>23</volume>(<issue>2</issue>):<fpage>bbab578</fpage>.<pub-id pub-id-type="pmid">35106547</pub-id></mixed-citation>
    </ref>
    <ref id="B24">
      <label>24.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname><given-names>Q</given-names></string-name>, <string-name><surname>Feng</surname><given-names>T</given-names></string-name>, <string-name><surname>Xu</surname><given-names>L</given-names></string-name>, <string-name><surname>Sun</surname><given-names>H</given-names></string-name>, <string-name><surname>Pan</surname><given-names>P</given-names></string-name>, <string-name><surname>Li</surname><given-names>Y</given-names></string-name>, <string-name><surname>Li</surname><given-names>D</given-names></string-name>, <string-name><surname>Hou</surname><given-names>T</given-names></string-name></person-group>. 
<article-title>Recent advances in protein-protein docking</article-title>. <source><italic toggle="yes">Curr Drug Targets</italic></source>. <year>2016</year>;<volume>17</volume>(<issue>14</issue>):<fpage>1586</fpage>–<lpage>1594</lpage>.<pub-id pub-id-type="pmid">26758670</pub-id></mixed-citation>
    </ref>
    <ref id="B25">
      <label>25.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rodrigues</surname><given-names>JP</given-names></string-name>, <string-name><surname>Karaca</surname><given-names>E</given-names></string-name>, <string-name><surname>Bonvin</surname><given-names>AM</given-names></string-name></person-group>. 
<article-title>Information-driven structural modelling of protein-protein interactions</article-title>. <source><italic toggle="yes">Methods Mol Biol</italic></source>. <year>2015</year>;<volume>1215</volume>:<fpage>399</fpage>–<lpage>424</lpage>.<pub-id pub-id-type="pmid">25330973</pub-id></mixed-citation>
    </ref>
    <ref id="B26">
      <label>26.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sanchez-Garcia</surname><given-names>R</given-names></string-name>, <string-name><surname>Sorzano</surname><given-names>COS</given-names></string-name>, <string-name><surname>Carazo</surname><given-names>JM</given-names></string-name>, <string-name><surname>Segura</surname><given-names>J</given-names></string-name></person-group>. 
<article-title>BIPSPI: A method for the prediction of partner-specific protein-protein interfaces</article-title>. <source><italic toggle="yes">Bioinformatics</italic></source>. <year>2019</year>;<volume>35</volume>(<issue>3</issue>):<fpage>470</fpage>–<lpage>477</lpage>.<pub-id pub-id-type="pmid">30020406</pub-id></mixed-citation>
    </ref>
    <ref id="B27">
      <label>27.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hou</surname><given-names>Q</given-names></string-name>, <string-name><surname>De Geest</surname><given-names>PFG</given-names></string-name>, <string-name><surname>Vranken</surname><given-names>WF</given-names></string-name>, <string-name><surname>Heringa</surname><given-names>J</given-names></string-name>, <string-name><surname>Feenstra</surname><given-names>KA</given-names></string-name></person-group>. 
<article-title>Seeing the trees through the forest: Sequence-based homo- and heteromeric protein-protein interaction sites prediction using random forest</article-title>. <source><italic toggle="yes">Bioinformatics</italic></source>. <year>2017</year>;<volume>33</volume>(<issue>10</issue>):<fpage>1479</fpage>–<lpage>1487</lpage>.<pub-id pub-id-type="pmid">28073761</pub-id></mixed-citation>
    </ref>
    <ref id="B28">
      <label>28.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Porollo</surname><given-names>A</given-names></string-name>, <string-name><surname>Meller</surname><given-names>J</given-names></string-name></person-group>. 
<article-title>Prediction-based fingerprints of protein-protein interactions</article-title>. <source><italic toggle="yes">Proteins</italic></source>. <year>2007</year>;<volume>66</volume>(<issue>3</issue>):<fpage>630</fpage>–<lpage>645</lpage>.<pub-id pub-id-type="pmid">17152079</pub-id></mixed-citation>
    </ref>
    <ref id="B29">
      <label>29.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Li</surname><given-names>S</given-names></string-name>, <string-name><surname>Wu</surname><given-names>S</given-names></string-name>, <string-name><surname>Wang</surname><given-names>L</given-names></string-name>, <string-name><surname>Li</surname><given-names>F</given-names></string-name>, <string-name><surname>Jiang</surname><given-names>H</given-names></string-name>, <string-name><surname>Bai</surname><given-names>F</given-names></string-name></person-group>. 
<article-title>Recent advances in predicting protein-protein interactions with the aid of artificial intelligence algorithms</article-title>. <source><italic toggle="yes">Curr Opin Struct Biol</italic></source>. <year>2022</year>;<volume>73</volume>:
<elocation-id>102344</elocation-id>.<pub-id pub-id-type="pmid">35219216</pub-id></mixed-citation>
    </ref>
    <ref id="B30">
      <label>30.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname><given-names>J</given-names></string-name>, <string-name><surname>Kurgan</surname><given-names>L</given-names></string-name></person-group>. 
<article-title>Review and comparative assessment of sequence-based predictors of protein-binding residues</article-title>. <source><italic toggle="yes">Brief Bioinform</italic></source>. <year>2018</year>;<volume>19</volume>(<issue>5</issue>):<fpage>821</fpage>–<lpage>837</lpage>.<pub-id pub-id-type="pmid">28334258</pub-id></mixed-citation>
    </ref>
    <ref id="B31">
      <label>31.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Singh</surname><given-names>G</given-names></string-name>, <string-name><surname>Dhole</surname><given-names>KD</given-names></string-name>, <string-name><surname>Pai</surname><given-names>P</given-names></string-name>, <string-name><surname>Mondal</surname><given-names>SK</given-names></string-name></person-group>. 
<article-title>SPRINGS: Prediction of protein- protein interaction sites using artificial neural networks</article-title>. <source><italic toggle="yes">J Proteom Comput Biol</italic></source>. <year>2014</year>;<volume>1</volume>(<issue>1</issue>):<fpage>7</fpage>.</mixed-citation>
    </ref>
    <ref id="B32">
      <label>32.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname><given-names>J</given-names></string-name>, <string-name><surname>Kurgan</surname><given-names>L</given-names></string-name></person-group>. 
<article-title>SCRIBER: Accurate and partner type-specific prediction of protein-binding residues from proteins sequences</article-title>. <source><italic toggle="yes">Bioinformatics</italic></source>. <year>2019</year>;<volume>35</volume>(<issue>14</issue>):<fpage>i343</fpage>–<lpage>i353</lpage>.<pub-id pub-id-type="pmid">31510679</pub-id></mixed-citation>
    </ref>
    <ref id="B33">
      <label>33.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Qiu</surname><given-names>J</given-names></string-name>, <string-name><surname>Bernhofer</surname><given-names>M</given-names></string-name>, <string-name><surname>Heinzinger</surname><given-names>M</given-names></string-name>, <string-name><surname>Kemper</surname><given-names>S</given-names></string-name>, <string-name><surname>Norambuena</surname><given-names>T</given-names></string-name>, <string-name><surname>Melo</surname><given-names>F</given-names></string-name>, <string-name><surname>Rost</surname><given-names>B</given-names></string-name></person-group>. 
<article-title>ProNA2020 predicts protein-DNA, protein-RNA, and protein-protein binding proteins and residues from sequence</article-title>. <source><italic toggle="yes">J Mol Biol</italic></source>. <year>2020</year>;<volume>432</volume>(<issue>7</issue>):<fpage>2428</fpage>–<lpage>2443</lpage>.<pub-id pub-id-type="pmid">32142788</pub-id></mixed-citation>
    </ref>
    <ref id="B34">
      <label>34.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Li</surname><given-names>Y</given-names></string-name>, <string-name><surname>Golding</surname><given-names>GB</given-names></string-name>, <string-name><surname>Ilie</surname><given-names>L</given-names></string-name></person-group>. 
<article-title>DELPHI: Accurate deep ensemble model for protein interaction sites prediction</article-title>. <source><italic toggle="yes">Bioinformatics</italic></source>. <year>2021</year>;<volume>37</volume>(<issue>7</issue>):<fpage>896</fpage>–<lpage>904</lpage>.<pub-id pub-id-type="pmid">32840562</pub-id></mixed-citation>
    </ref>
    <ref id="B35">
      <label>35.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yuan</surname><given-names>Q</given-names></string-name>, <string-name><surname>Chen</surname><given-names>J</given-names></string-name>, <string-name><surname>Zhao</surname><given-names>H</given-names></string-name>, <string-name><surname>Zhou</surname><given-names>Y</given-names></string-name>, <string-name><surname>Yang</surname><given-names>Y</given-names></string-name></person-group>. 
<article-title>Structure-aware protein-protein interaction site prediction using deep graph convolutional network</article-title>. <source><italic toggle="yes">Bioinformatics</italic></source>. <year>2021</year>;<volume>38</volume>(<issue>1</issue>):<fpage>125</fpage>–<lpage>132</lpage>.<pub-id pub-id-type="pmid">34498061</pub-id></mixed-citation>
    </ref>
    <ref id="B36">
      <label>36.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dai</surname><given-names>B</given-names></string-name>, <string-name><surname>Bailey-Kellogg</surname><given-names>C</given-names></string-name></person-group>. 
<article-title>Protein interaction interface region prediction by geometric deep learning</article-title>. <source><italic toggle="yes">Bioinformatics</italic></source>. <year>2021</year>;<volume>37</volume>(<issue>17</issue>):<fpage>2580</fpage>–<lpage>2588</lpage>.<pub-id pub-id-type="pmid">33693581</pub-id></mixed-citation>
    </ref>
    <ref id="B37">
      <label>37.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gainza</surname><given-names>P</given-names></string-name>, <string-name><surname>Sverrisson</surname><given-names>F</given-names></string-name>, <string-name><surname>Monti</surname><given-names>F</given-names></string-name>, <string-name><surname>Rodola</surname><given-names>E</given-names></string-name>, <string-name><surname>Boscaini</surname><given-names>D</given-names></string-name>, <string-name><surname>Bronstein</surname><given-names>MM</given-names></string-name>, <string-name><surname>Correia</surname><given-names>BE</given-names></string-name></person-group>. 
<article-title>Deciphering interaction fingerprints from protein molecular surfaces using geometric deep learning</article-title>. <source><italic toggle="yes">Nat Methods</italic></source>. <year>2020</year>;<volume>17</volume>(<issue>2</issue>):<fpage>184</fpage>–<lpage>192</lpage>.<pub-id pub-id-type="pmid">31819266</pub-id></mixed-citation>
    </ref>
    <ref id="B38">
      <label>38.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tubiana</surname><given-names>J</given-names></string-name>, <string-name><surname>Schneidman-Duhovny</surname><given-names>D</given-names></string-name>, <string-name><surname>Wolfson</surname><given-names>HJ</given-names></string-name></person-group>. 
<article-title>ScanNet: An interpretable geometric deep learning model for structure-based protein binding site prediction</article-title>. <source><italic toggle="yes">Nat Methods</italic></source>. <year>2022</year>;<volume>19</volume>(<issue>6</issue>):<fpage>730</fpage>–<lpage>739</lpage>.<pub-id pub-id-type="pmid">35637310</pub-id></mixed-citation>
    </ref>
    <ref id="B39">
      <label>39.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Krapp</surname><given-names>LF</given-names></string-name>, <string-name><surname>Abriata</surname><given-names>LA</given-names></string-name>, <string-name><surname>Cortes Rodriguez</surname><given-names>F</given-names></string-name>, <string-name><surname>Dal Peraro</surname><given-names>M</given-names></string-name></person-group>. 
<article-title>PeSTo: Parameter-free geometric deep learning for accurate prediction of protein binding interfaces</article-title>. <source><italic toggle="yes">Nat Commun</italic></source>. <year>2023</year>;<volume>14</volume>(<issue>1</issue>):<fpage>2175</fpage>.<pub-id pub-id-type="pmid">37072397</pub-id></mixed-citation>
    </ref>
    <ref id="B40">
      <label>40.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname><given-names>S</given-names></string-name>, <string-name><surname>Chen</surname><given-names>W</given-names></string-name>, <string-name><surname>Han</surname><given-names>P</given-names></string-name>, <string-name><surname>Li</surname><given-names>X</given-names></string-name>, <string-name><surname>Song</surname><given-names>T</given-names></string-name></person-group>. 
<article-title>RGN: Residue-based graph attention and convolutional network for protein-protein interaction site prediction</article-title>. <source><italic toggle="yes">J Chem Inf Model</italic></source>. <year>2022</year>;<volume>62</volume>(<issue>23</issue>):<fpage>5961</fpage>–<lpage>5974</lpage>.<pub-id pub-id-type="pmid">36398714</pub-id></mixed-citation>
    </ref>
    <ref id="B41">
      <label>41.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yang</surname><given-names>Y</given-names></string-name>, <string-name><surname>Hou</surname><given-names>Z</given-names></string-name>, <string-name><surname>Ma</surname><given-names>Z</given-names></string-name>, <string-name><surname>Li</surname><given-names>X</given-names></string-name>, <string-name><surname>Wong</surname><given-names>KC</given-names></string-name></person-group>. 
<article-title>iCircRBP-DHN: Identification of circRNA-RBP interaction sites using deep hierarchical network</article-title>. <source><italic toggle="yes">Brief Bioinform</italic></source>. <year>2021</year>;<volume>22</volume>(<issue>4</issue>).</mixed-citation>
    </ref>
    <ref id="B42">
      <label>42.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hou</surname><given-names>Z</given-names></string-name>, <string-name><surname>Yang</surname><given-names>Y</given-names></string-name>, <string-name><surname>Ma</surname><given-names>Z</given-names></string-name>, <string-name><surname>Wong</surname><given-names>KC</given-names></string-name>, <string-name><surname>Li</surname><given-names>X</given-names></string-name></person-group>. 
<article-title>Learning the protein language of proteome-wide protein-protein binding sites via explainable ensemble deep learning</article-title>. <source><italic toggle="yes">Commun Biol</italic></source>. <year>2023</year>;<volume>6</volume>(<issue>1</issue>):<fpage>73</fpage>.<pub-id pub-id-type="pmid">36653447</pub-id></mixed-citation>
    </ref>
    <ref id="B43">
      <label>43.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Senior</surname><given-names>AW</given-names></string-name>, <string-name><surname>Evans</surname><given-names>R</given-names></string-name>, <string-name><surname>Jumper</surname><given-names>J</given-names></string-name>, <string-name><surname>Kirkpatrick</surname><given-names>J</given-names></string-name>, <string-name><surname>Sifre</surname><given-names>L</given-names></string-name>, <string-name><surname>Green</surname><given-names>T</given-names></string-name>, <string-name><surname>Qin</surname><given-names>C</given-names></string-name>, <string-name><surname>Zidek</surname><given-names>A</given-names></string-name>, <string-name><surname>Nelson</surname><given-names>AWR</given-names></string-name>, <string-name><surname>Bridgland</surname><given-names>A</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Improved protein structure prediction using potentials from deep learning</article-title>. <source><italic toggle="yes">Nature</italic></source>. <year>2020</year>;<volume>577</volume>(<issue>7792</issue>):<fpage>706</fpage>–<lpage>710</lpage>.<pub-id pub-id-type="pmid">31942072</pub-id></mixed-citation>
    </ref>
    <ref id="B44">
      <label>44.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hammes</surname><given-names>GG</given-names></string-name>, <string-name><surname>Chang</surname><given-names>YC</given-names></string-name>, <string-name><surname>Oas</surname><given-names>TG</given-names></string-name></person-group>. 
<article-title>Conformational selection or induced fit: A flux description of reaction mechanism</article-title>. <source><italic toggle="yes">Proc Natl Acad Sci U S A</italic></source>. <year>2009</year>;<volume>106</volume>(<issue>33</issue>):<fpage>13737</fpage>–<lpage>13741</lpage>.<pub-id pub-id-type="pmid">19666553</pub-id></mixed-citation>
    </ref>
    <ref id="B45">
      <label>45.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yang</surname><given-names>H</given-names></string-name>, <string-name><surname>Wang</surname><given-names>M</given-names></string-name>, <string-name><surname>Liu</surname><given-names>X</given-names></string-name>, <string-name><surname>Zhao</surname><given-names>XM</given-names></string-name>, <string-name><surname>Li</surname><given-names>A</given-names></string-name></person-group>. 
<article-title>PhosIDN: An integrated deep neural network for improving protein phosphorylation site prediction by combining sequence and protein-protein interaction information</article-title>. <source><italic toggle="yes">Bioinformatics</italic></source>. <year>2021</year>;<volume>37</volume>(<issue>24</issue>):<fpage>4668</fpage>–<lpage>4676</lpage>.<pub-id pub-id-type="pmid">34320631</pub-id></mixed-citation>
    </ref>
    <ref id="B46">
      <label>46.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Du</surname><given-names>H</given-names></string-name>, <string-name><surname>Jiang</surname><given-names>D</given-names></string-name>, <string-name><surname>Gao</surname><given-names>J</given-names></string-name>, <string-name><surname>Zhang</surname><given-names>X</given-names></string-name>, <string-name><surname>Jiang</surname><given-names>L</given-names></string-name>, <string-name><surname>Zeng</surname><given-names>Y</given-names></string-name>, <string-name><surname>Wu</surname><given-names>Z</given-names></string-name>, <string-name><surname>Shen</surname><given-names>C</given-names></string-name>, <string-name><surname>Xu</surname><given-names>L</given-names></string-name>, <string-name><surname>Cao</surname><given-names>D</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Proteome-wide profiling of the covalent-Druggable cysteines with a structure-based deep graph learning network</article-title>. <source><italic toggle="yes">Research (Wash D C)</italic></source>. <year>2022</year>;<volume>2022</volume>:
<elocation-id>9873564</elocation-id>.<pub-id pub-id-type="pmid">35958111</pub-id></mixed-citation>
    </ref>
    <ref id="B47">
      <label>47.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname><given-names>Y</given-names></string-name>, <string-name><surname>Yang</surname><given-names>Y</given-names></string-name>, <string-name><surname>Ma</surname><given-names>Z</given-names></string-name>, <string-name><surname>Wong</surname><given-names>KC</given-names></string-name>, <string-name><surname>Li</surname><given-names>X</given-names></string-name></person-group>. 
<article-title>EDCNN: Identification of genome-wide RNA-binding proteins using evolutionary deep convolutional neural network</article-title>. <source><italic toggle="yes">Bioinformatics</italic></source>. <year>2022</year>;<volume>38</volume>(<issue>3</issue>):<fpage>678</fpage>–<lpage>686</lpage>.<pub-id pub-id-type="pmid">34694393</pub-id></mixed-citation>
    </ref>
    <ref id="B48">
      <label>48.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Elnaggar</surname><given-names>A</given-names></string-name>, <string-name><surname>Heinzinger</surname><given-names>M</given-names></string-name>, <string-name><surname>Dallago</surname><given-names>C</given-names></string-name>, <string-name><surname>Rehawi</surname><given-names>G</given-names></string-name>, <string-name><surname>Wang</surname><given-names>Y</given-names></string-name>, <string-name><surname>Jones</surname><given-names>L</given-names></string-name>, <string-name><surname>Gibbs</surname><given-names>T</given-names></string-name>, <string-name><surname>Feher</surname><given-names>T</given-names></string-name>, <string-name><surname>Angerer</surname><given-names>C</given-names></string-name>, <string-name><surname>Steinegger</surname><given-names>M</given-names></string-name>, <etal>et al.</etal></person-group><article-title>ProtTrans: Toward understanding the language of life through self-supervised learning</article-title>. <source><italic toggle="yes">IEEE Trans Pattern Anal Mach Intell</italic></source>. <year>2022</year>;<volume>44</volume>(<issue>10</issue>):<fpage>7112</fpage>–<lpage>7127</lpage>.<pub-id pub-id-type="pmid">34232869</pub-id></mixed-citation>
    </ref>
    <ref id="B49">
      <label>49.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Altschul</surname><given-names>SF</given-names></string-name>, <string-name><surname>Madden</surname><given-names>TL</given-names></string-name>, <string-name><surname>Schaffer</surname><given-names>AA</given-names></string-name>, <string-name><surname>Zhang</surname><given-names>J</given-names></string-name>, <string-name><surname>Zhang</surname><given-names>Z</given-names></string-name>, <string-name><surname>Miller</surname><given-names>W</given-names></string-name>, <string-name><surname>Lipman</surname><given-names>DJ</given-names></string-name></person-group>. 
<article-title>Gapped BLAST and PSI-BLAST: A new generation of protein database search programs</article-title>. <source><italic toggle="yes">Nucleic Acids Res</italic></source>. <year>1997</year>;<volume>25</volume>(<issue>17</issue>):<fpage>3389</fpage>–<lpage>3402</lpage>.<pub-id pub-id-type="pmid">9254694</pub-id></mixed-citation>
    </ref>
    <ref id="B50">
      <label>50.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zacharias</surname><given-names>J</given-names></string-name>, <string-name><surname>Knapp</surname><given-names>EW</given-names></string-name></person-group>. 
<article-title>Protein secondary structure classification revisited: Processing DSSP information with PSSC</article-title>. <source><italic toggle="yes">J Chem Inf Model</italic></source>. <year>2014</year>;<volume>54</volume>(<issue>7</issue>):<fpage>2166</fpage>–<lpage>2179</lpage>.<pub-id pub-id-type="pmid">24866861</pub-id></mixed-citation>
    </ref>
    <ref id="B51">
      <label>51.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Shi</surname><given-names>Z</given-names></string-name>, <string-name><surname>Deng</surname><given-names>R</given-names></string-name>, <string-name><surname>Yuan</surname><given-names>Q</given-names></string-name>, <string-name><surname>Mao</surname><given-names>Z</given-names></string-name>, <string-name><surname>Wang</surname><given-names>R</given-names></string-name>, <string-name><surname>Li</surname><given-names>H</given-names></string-name>, <string-name><surname>Liao</surname><given-names>X</given-names></string-name>, <string-name><surname>Ma</surname><given-names>H</given-names></string-name></person-group>. 
<article-title>Enzyme commission number prediction and benchmarking with hierarchical dual-core multitask learning framework</article-title>. <source><italic toggle="yes">Research (Wash D C)</italic></source>. <year>2023</year>;<volume>6</volume>:<fpage>0153</fpage>.<pub-id pub-id-type="pmid">37275124</pub-id></mixed-citation>
    </ref>
    <ref id="B52">
      <label>52.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lin</surname><given-names>Z</given-names></string-name>, <string-name><surname>Akin</surname><given-names>H</given-names></string-name>, <string-name><surname>Rao</surname><given-names>R</given-names></string-name>, <string-name><surname>Hie</surname><given-names>B</given-names></string-name>, <string-name><surname>Zhu</surname><given-names>Z</given-names></string-name>, <string-name><surname>Lu</surname><given-names>W</given-names></string-name>, <string-name><surname>Smetanin</surname><given-names>N</given-names></string-name>, <string-name><surname>Verkuil</surname><given-names>R</given-names></string-name>, <string-name><surname>Kabeli</surname><given-names>O</given-names></string-name>, <string-name><surname>Shmueli</surname><given-names>Y</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Evolutionary-scale prediction of atomic-level protein structure with a language model</article-title>. <source><italic toggle="yes">Science</italic></source>. <year>2023</year>;<volume>379</volume>(<issue>6637</issue>):<fpage>1123</fpage>–<lpage>1130</lpage>.<pub-id pub-id-type="pmid">36927031</pub-id></mixed-citation>
    </ref>
    <ref id="B53">
      <label>53.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chowdhury</surname><given-names>R</given-names></string-name>, <string-name><surname>Bouatta</surname><given-names>N</given-names></string-name>, <string-name><surname>Biswas</surname><given-names>S</given-names></string-name>, <string-name><surname>Floristean</surname><given-names>C</given-names></string-name>, <string-name><surname>Kharkar</surname><given-names>A</given-names></string-name>, <string-name><surname>Roy</surname><given-names>K</given-names></string-name>, <string-name><surname>Rochereau</surname><given-names>C</given-names></string-name>, <string-name><surname>Ahdritz</surname><given-names>G</given-names></string-name>, <string-name><surname>Zhang</surname><given-names>J</given-names></string-name>, <string-name><surname>Church</surname><given-names>GM</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Single-sequence protein structure prediction using a language model and deep learning</article-title>. <source><italic toggle="yes">Nat Biotechnol</italic></source>. <year>2022</year>;<volume>40</volume>(<issue>11</issue>):<fpage>1617</fpage>–<lpage>1623</lpage>.<pub-id pub-id-type="pmid">36192636</pub-id></mixed-citation>
    </ref>
    <ref id="B54">
      <label>54.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yang</surname><given-names>Q</given-names></string-name>, <string-name><surname>Syed</surname><given-names>AAS</given-names></string-name>, <string-name><surname>Fahira</surname><given-names>A</given-names></string-name>, <string-name><surname>Shi</surname><given-names>Y</given-names></string-name></person-group>. 
<article-title>Structural analysis of the SARS-CoV-2 omicron variant proteins</article-title>. <source><italic toggle="yes">Research (Wash D C)</italic></source>. <year>2021</year>;<volume>2021</volume>:
<elocation-id>9769586</elocation-id>.<pub-id pub-id-type="pmid">35088054</pub-id></mixed-citation>
    </ref>
    <ref id="B55">
      <label>55.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jumper</surname><given-names>J</given-names></string-name>, <string-name><surname>Evans</surname><given-names>R</given-names></string-name>, <string-name><surname>Pritzel</surname><given-names>A</given-names></string-name>, <string-name><surname>Green</surname><given-names>T</given-names></string-name>, <string-name><surname>Figurnov</surname><given-names>M</given-names></string-name>, <string-name><surname>Ronneberger</surname><given-names>O</given-names></string-name>, <string-name><surname>Tunyasuvunakool</surname><given-names>K</given-names></string-name>, <string-name><surname>Bates</surname><given-names>R</given-names></string-name>, <string-name><surname>Zidek</surname><given-names>A</given-names></string-name>, <string-name><surname>Potapenko</surname><given-names>A</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Highly accurate protein structure prediction with AlphaFold</article-title>. <source><italic toggle="yes">Nature</italic></source>. <year>2021</year>;<volume>596</volume>(<issue>7873</issue>):<fpage>583</fpage>–<lpage>589</lpage>.<pub-id pub-id-type="pmid">34265844</pub-id></mixed-citation>
    </ref>
    <ref id="B56">
      <label>56.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tunyasuvunakool</surname><given-names>K</given-names></string-name>, <string-name><surname>Adler</surname><given-names>J</given-names></string-name>, <string-name><surname>Wu</surname><given-names>Z</given-names></string-name>, <string-name><surname>Green</surname><given-names>T</given-names></string-name>, <string-name><surname>Zielinski</surname><given-names>M</given-names></string-name>, <string-name><surname>Zidek</surname><given-names>A</given-names></string-name>, <string-name><surname>Bridgland</surname><given-names>A</given-names></string-name>, <string-name><surname>Cowie</surname><given-names>A</given-names></string-name>, <string-name><surname>Meyer</surname><given-names>C</given-names></string-name>, <string-name><surname>Laydon</surname><given-names>A</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Highly accurate protein structure prediction for the human proteome</article-title>. <source><italic toggle="yes">Nature</italic></source>. <year>2021</year>;<volume>596</volume>(<issue>7873</issue>):<fpage>590</fpage>–<lpage>596</lpage>.<pub-id pub-id-type="pmid">34293799</pub-id></mixed-citation>
    </ref>
    <ref id="B57">
      <label>57.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Baek</surname><given-names>M</given-names></string-name>, <string-name><surname>DiMaio</surname><given-names>F</given-names></string-name>, <string-name><surname>Anishchenko</surname><given-names>I</given-names></string-name>, <string-name><surname>Dauparas</surname><given-names>J</given-names></string-name>, <string-name><surname>Ovchinnikov</surname><given-names>S</given-names></string-name>, <string-name><surname>Lee</surname><given-names>GR</given-names></string-name>, <string-name><surname>Wang</surname><given-names>J</given-names></string-name>, <string-name><surname>Cong</surname><given-names>Q</given-names></string-name>, <string-name><surname>Kinch</surname><given-names>LN</given-names></string-name>, <string-name><surname>Schaeffer</surname><given-names>RD</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Accurate prediction of protein structures and interactions using a three-track neural network</article-title>. <source><italic toggle="yes">Science</italic></source>. <year>2021</year>;<volume>373</volume>(<issue>6557</issue>):<fpage>871</fpage>–<lpage>876</lpage>.<pub-id pub-id-type="pmid">34282049</pub-id></mixed-citation>
    </ref>
    <ref id="B58">
      <label>58.</label>
      <mixed-citation publication-type="journal"><article-title>RCSB Protein Data Bank (RCSB.org): Delivery of experimentally-determined PDB structures alongside one million computed structure models of proteins from artificial intelligence/machine learning</article-title>. <source><italic toggle="yes">Nucleic Acids Res</italic></source>. <year>2023</year>;<volume>51</volume>(<issue>D1</issue>):<fpage>D488</fpage>–<lpage>D508</lpage>.<pub-id pub-id-type="pmid">36420884</pub-id></mixed-citation>
    </ref>
    <ref id="B59">
      <label>59.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Buel</surname><given-names>GR</given-names></string-name>, <string-name><surname>Walters</surname><given-names>KJ</given-names></string-name></person-group>. 
<article-title>Can AlphaFold2 predict the impact of missense mutations on structure?</article-title><source><italic toggle="yes">Nat Struct Mol Biol</italic></source>. <year>2022</year>;<volume>29</volume>(<issue>1</issue>):<fpage>1</fpage>–<lpage>2</lpage>.<pub-id pub-id-type="pmid">35046575</pub-id></mixed-citation>
    </ref>
    <ref id="B60">
      <label>60.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yang</surname><given-names>Z</given-names></string-name>, <string-name><surname>Zeng</surname><given-names>X</given-names></string-name>, <string-name><surname>Zhao</surname><given-names>Y</given-names></string-name>, <string-name><surname>Chen</surname><given-names>R</given-names></string-name></person-group>. 
<article-title>AlphaFold2 and its applications in the fields of biology and medicine</article-title>. <source><italic toggle="yes">Signal Transduct Target Ther</italic></source>. <year>2023</year>;<volume>8</volume>(<issue>1</issue>):<fpage>115</fpage>.<pub-id pub-id-type="pmid">36918529</pub-id></mixed-citation>
    </ref>
    <ref id="B61">
      <label>61.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yang</surname><given-names>Q</given-names></string-name>, <string-name><surname>Jian</surname><given-names>X</given-names></string-name>, <string-name><surname>Syed</surname><given-names>AAS</given-names></string-name>, <string-name><surname>Fahira</surname><given-names>A</given-names></string-name>, <string-name><surname>Zheng</surname><given-names>C</given-names></string-name>, <string-name><surname>Zhu</surname><given-names>Z</given-names></string-name>, <string-name><surname>Wang</surname><given-names>K</given-names></string-name>, <string-name><surname>Zhang</surname><given-names>J</given-names></string-name>, <string-name><surname>Wen</surname><given-names>Y</given-names></string-name>, <string-name><surname>Li</surname><given-names>Z</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Structural comparison and drug screening of spike proteins of ten SARS-CoV-2 variants</article-title>. <source><italic toggle="yes">Research (Wash D C)</italic></source>. <year>2022</year>;<volume>2022</volume>:
<elocation-id>9781758</elocation-id>.<pub-id pub-id-type="pmid">35198984</pub-id></mixed-citation>
    </ref>
    <ref id="B62">
      <label>62.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fu</surname><given-names>T</given-names></string-name>, <string-name><surname>Li</surname><given-names>F</given-names></string-name>, <string-name><surname>Zhang</surname><given-names>Y</given-names></string-name>, <string-name><surname>Yin</surname><given-names>J</given-names></string-name>, <string-name><surname>Qiu</surname><given-names>W</given-names></string-name>, <string-name><surname>Li</surname><given-names>X</given-names></string-name>, <string-name><surname>Liu</surname><given-names>X</given-names></string-name>, <string-name><surname>Xin</surname><given-names>W</given-names></string-name>, <string-name><surname>Wang</surname><given-names>C</given-names></string-name>, <string-name><surname>Yu</surname><given-names>L</given-names></string-name>, <etal>et al.</etal></person-group><article-title>VARIDT 2.0: Structural variability of drug transporter</article-title>. <source><italic toggle="yes">Nucleic Acids Res</italic></source>. <year>2022</year>;<volume>50</volume>(<issue>D1</issue>):<fpage>D1417</fpage>–<lpage>D1431</lpage>.<pub-id pub-id-type="pmid">34747471</pub-id></mixed-citation>
    </ref>
    <ref id="B63">
      <label>63.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Iqbal</surname><given-names>S</given-names></string-name>, <string-name><surname>Ge</surname><given-names>F</given-names></string-name>, <string-name><surname>Li</surname><given-names>F</given-names></string-name>, <string-name><surname>Akutsu</surname><given-names>T</given-names></string-name>, <string-name><surname>Zheng</surname><given-names>Y</given-names></string-name>, <string-name><surname>Gasser</surname><given-names>RB</given-names></string-name>, <string-name><surname>Yu</surname><given-names>DJ</given-names></string-name>, <string-name><surname>Webb</surname><given-names>GI</given-names></string-name>, <string-name><surname>Song</surname><given-names>J</given-names></string-name></person-group>. 
<article-title>PROST: AlphaFold2-aware sequence-based predictor to estimate protein stability changes upon missense mutations</article-title>. <source><italic toggle="yes">J Chem Inf Model</italic></source>. <year>2022</year>;<volume>62</volume>(<issue>17</issue>):<fpage>4270</fpage>–<lpage>4282</lpage>.<pub-id pub-id-type="pmid">35973091</pub-id></mixed-citation>
    </ref>
    <ref id="B64">
      <label>64.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lin</surname><given-names>B</given-names></string-name>, <string-name><surname>Zhang</surname><given-names>H</given-names></string-name>, <string-name><surname>Zheng</surname><given-names>Q</given-names></string-name></person-group>. 
<article-title>How do mutations affect the structural characteristics and substrate binding of CYP21A2? An investigation by molecular dynamics simulations</article-title>. <source><italic toggle="yes">Phys Chem Chem Phys</italic></source>. <year>2020</year>;<volume>22</volume>(<issue>16</issue>):<fpage>8870</fpage>–<lpage>8877</lpage>.<pub-id pub-id-type="pmid">32286592</pub-id></mixed-citation>
    </ref>
    <ref id="B65">
      <label>65.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Liang</surname><given-names>B</given-names></string-name>, <string-name><surname>Zhu</surname><given-names>Y</given-names></string-name>, <string-name><surname>Shi</surname><given-names>W</given-names></string-name>, <string-name><surname>Ni</surname><given-names>C</given-names></string-name>, <string-name><surname>Tan</surname><given-names>B</given-names></string-name>, <string-name><surname>Tang</surname><given-names>S</given-names></string-name></person-group>. 
<article-title>SARS-CoV-2 spike protein post-translational modification landscape and its impact on protein structure and function via computational prediction</article-title>. <source><italic toggle="yes">Research (Wash D C)</italic></source>. <year>2023</year>;<volume>6</volume>:<fpage>0078</fpage>.<pub-id pub-id-type="pmid">36930770</pub-id></mixed-citation>
    </ref>
    <ref id="B66">
      <label>66.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname><given-names>X</given-names></string-name>, <string-name><surname>Zheng</surname><given-names>Q</given-names></string-name></person-group>. 
<article-title>How DNA affects the hyperthermophilic protein Ape10b2 for oligomerization: An investigation using multiple short molecular dynamics simulations</article-title>. <source><italic toggle="yes">Phys Chem Chem Phys</italic></source>. <year>2021</year>;<volume>23</volume>(<issue>45</issue>):<fpage>25841</fpage>–<lpage>25849</lpage>.<pub-id pub-id-type="pmid">34763347</pub-id></mixed-citation>
    </ref>
    <ref id="B67">
      <label>67.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tai</surname><given-names>KY</given-names></string-name>, <string-name><surname>Dhaliwal</surname><given-names>J</given-names></string-name>, <string-name><surname>Balasubramaniam</surname><given-names>V</given-names></string-name></person-group>. 
<article-title>Leveraging Mann-Whitney U test on large-scale genetic variation data for analysing malaria genetic markers</article-title>. <source><italic toggle="yes">Malar J</italic></source>. <year>2022</year>;<volume>21</volume>(<issue>1</issue>):<fpage>79</fpage>.<pub-id pub-id-type="pmid">35264165</pub-id></mixed-citation>
    </ref>
    <ref id="B68">
      <label>68.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Xu</surname><given-names>J</given-names></string-name>, <string-name><surname>Li</surname><given-names>F</given-names></string-name>, <string-name><surname>Li</surname><given-names>C</given-names></string-name>, <string-name><surname>Guo</surname><given-names>X</given-names></string-name>, <string-name><surname>Landersdorfer</surname><given-names>C</given-names></string-name>, <string-name><surname>Shen</surname><given-names>HH</given-names></string-name>, <string-name><surname>Peleg</surname><given-names>AY</given-names></string-name>, <string-name><surname>Li</surname><given-names>J</given-names></string-name>, <string-name><surname>Imoto</surname><given-names>S</given-names></string-name>, <string-name><surname>Yao</surname><given-names>J</given-names></string-name>, <etal>et al.</etal></person-group><article-title>iAMPCN: A deep-learning approach for identifying antimicrobial peptides and their functional activities</article-title>. <source><italic toggle="yes">Brief Bioinform</italic></source>. <year>2023</year>;<volume>24</volume>(<issue>4</issue>):<fpage>bbad240</fpage>.<pub-id pub-id-type="pmid">37369638</pub-id></mixed-citation>
    </ref>
    <ref id="B69">
      <label>69.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname><given-names>R</given-names></string-name>, <string-name><surname>Jiang</surname><given-names>Y</given-names></string-name>, <string-name><surname>Jin</surname><given-names>J</given-names></string-name>, <string-name><surname>Yin</surname><given-names>C</given-names></string-name>, <string-name><surname>Yu</surname><given-names>H</given-names></string-name>, <string-name><surname>Wang</surname><given-names>F</given-names></string-name>, <string-name><surname>Feng</surname><given-names>J</given-names></string-name>, <string-name><surname>Su</surname><given-names>R</given-names></string-name>, <string-name><surname>Nakai</surname><given-names>K</given-names></string-name>, <string-name><surname>Zou</surname><given-names>Q</given-names></string-name>, <etal>et al.</etal></person-group><article-title>DeepBIO: An automated and interpretable deep-learning platform for high-throughput biological sequence prediction, functional annotation and visualization analysis</article-title>. <source><italic toggle="yes">Nucleic Acids Res</italic></source>. <year>2023</year>;<volume>51</volume>(<issue>7</issue>):<fpage>3017</fpage>–<lpage>3029</lpage>.<pub-id pub-id-type="pmid">36796796</pub-id></mixed-citation>
    </ref>
    <ref id="B70">
      <label>70.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname><given-names>C</given-names></string-name>, <string-name><surname>Zou</surname><given-names>Q</given-names></string-name></person-group>. 
<article-title>Prediction of protein solubility based on sequence physicochemical patterns and distributed representation information with DeepSoluE</article-title>. <source><italic toggle="yes">BMC Biol</italic></source>. <year>2023</year>;<volume>21</volume>(<issue>1</issue>):<fpage>12</fpage>.<pub-id pub-id-type="pmid">36694239</pub-id></mixed-citation>
    </ref>
    <ref id="B71">
      <label>71.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jain</surname><given-names>S</given-names></string-name>, <string-name><surname>Jou</surname><given-names>JD</given-names></string-name>, <string-name><surname>Georgiev</surname><given-names>IS</given-names></string-name>, <string-name><surname>Donald</surname><given-names>BR</given-names></string-name></person-group>. 
<article-title>A critical analysis of computational protein design with sparse residue interaction graphs</article-title>. <source><italic toggle="yes">PLoS Comput Biol</italic></source>. <year>2017</year>;<volume>13</volume>(<issue>3</issue>):
<elocation-id>e1005346</elocation-id>.<pub-id pub-id-type="pmid">28358804</pub-id></mixed-citation>
    </ref>
    <ref id="B72">
      <label>72.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Murakami</surname><given-names>Y</given-names></string-name>, <string-name><surname>Mizuguchi</surname><given-names>K</given-names></string-name></person-group>. 
<article-title>Applying the naive Bayes classifier with kernel density estimation to the prediction of protein-protein interaction sites</article-title>. <source><italic toggle="yes">Bioinformatics</italic></source>. <year>2010</year>;<volume>26</volume>(<issue>15</issue>):<fpage>1841</fpage>–<lpage>1848</lpage>.<pub-id pub-id-type="pmid">20529890</pub-id></mixed-citation>
    </ref>
    <ref id="B73">
      <label>73.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Burley</surname><given-names>SK</given-names></string-name>, <string-name><surname>Bhikadiya</surname><given-names>C</given-names></string-name>, <string-name><surname>Bi</surname><given-names>C</given-names></string-name>, <string-name><surname>Bittrich</surname><given-names>S</given-names></string-name>, <string-name><surname>Chao</surname><given-names>H</given-names></string-name>, <string-name><surname>Chen</surname><given-names>L</given-names></string-name>, <string-name><surname>Craig</surname><given-names>PA</given-names></string-name>, <string-name><surname>Crichlow</surname><given-names>GV</given-names></string-name>, <string-name><surname>Dalenberg</surname><given-names>K</given-names></string-name>, <string-name><surname>Duarte</surname><given-names>JM</given-names></string-name>, <etal>et al.</etal></person-group><article-title>RCSB protein data Bank (<ext-link xlink:href="http://RCSB.org" ext-link-type="uri">RCSB.org</ext-link>): Delivery of experimentally-determined PDB structures alongside one million computed structure models of proteins from artificial intelligence/machine learning</article-title>. <source><italic toggle="yes">Nucleic Acids Res</italic></source>. <year>2023</year>;<volume>51</volume>(<issue>D1</issue>):<fpage>D488</fpage>–<lpage>D508</lpage>.<pub-id pub-id-type="pmid">36420884</pub-id></mixed-citation>
    </ref>
    <ref id="B74">
      <label>74.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jones</surname><given-names>S</given-names></string-name>, <string-name><surname>Thornton</surname><given-names>JM</given-names></string-name></person-group>. 
<article-title>Analysis of protein-protein interaction sites using surface patches</article-title>. <source><italic toggle="yes">J Mol Biol</italic></source>. <year>1997</year>;<volume>272</volume>(<issue>1</issue>):<fpage>121</fpage>–<lpage>132</lpage>.<pub-id pub-id-type="pmid">9299342</pub-id></mixed-citation>
    </ref>
    <ref id="B75">
      <label>75.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Altschul</surname><given-names>SF</given-names></string-name>, <string-name><surname>Gish</surname><given-names>W</given-names></string-name>, <string-name><surname>Miller</surname><given-names>W</given-names></string-name>, <string-name><surname>Myers</surname><given-names>EW</given-names></string-name>, <string-name><surname>Lipman</surname><given-names>DJ</given-names></string-name></person-group>. 
<article-title>Basic local alignment search tool</article-title>. <source><italic toggle="yes">J Mol Biol</italic></source>. <year>1990</year>;<volume>215</volume>(<issue>3</issue>):<fpage>403</fpage>–<lpage>410</lpage>.<pub-id pub-id-type="pmid">2231712</pub-id></mixed-citation>
    </ref>
    <ref id="B76">
      <label>76.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yang</surname><given-names>J</given-names></string-name>, <string-name><surname>Roy</surname><given-names>A</given-names></string-name>, <string-name><surname>Zhang</surname><given-names>Y</given-names></string-name></person-group>. 
<article-title>BioLiP: A semi-manually curated database for biologically relevant ligand-protein interactions</article-title>. <source><italic toggle="yes">Nucleic Acids Res</italic></source>. <year>2013</year>;<volume>41</volume>(<issue>D</issue>):<fpage>D1096</fpage>–<lpage>D1103</lpage>.<pub-id pub-id-type="pmid">23087378</pub-id></mixed-citation>
    </ref>
    <ref id="B77">
      <label>77.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname><given-names>BZ</given-names></string-name>, <string-name><surname>Li</surname><given-names>JY</given-names></string-name>, <string-name><surname>Quan</surname><given-names>LJ</given-names></string-name>, <string-name><surname>Chen</surname><given-names>Y</given-names></string-name>, <string-name><surname>Lu</surname><given-names>Q</given-names></string-name></person-group>. 
<article-title>Sequence-based prediction of protein-protein interaction sites by simplified long short-term memory network</article-title>. <source><italic toggle="yes">Neurocomputing</italic></source>. <year>2019</year>;<volume>357</volume>:<fpage>86</fpage>–<lpage>100</lpage>.</mixed-citation>
    </ref>
    <ref id="B78">
      <label>78.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname><given-names>J</given-names></string-name>, <string-name><surname>Ma</surname><given-names>Z</given-names></string-name>, <string-name><surname>Kurgan</surname><given-names>L</given-names></string-name></person-group>. 
<article-title>Comprehensive review and empirical analysis of hallmarks of DNA-, RNA- and protein-binding residues in protein chains</article-title>. <source><italic toggle="yes">Brief Bioinform</italic></source>. <year>2019</year>;<volume>20</volume>(<issue>4</issue>):<fpage>1250</fpage>–<lpage>1268</lpage>.<pub-id pub-id-type="pmid">29253082</pub-id></mixed-citation>
    </ref>
    <ref id="B79">
      <label>79.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fu</surname><given-names>L</given-names></string-name>, <string-name><surname>Niu</surname><given-names>B</given-names></string-name>, <string-name><surname>Zhu</surname><given-names>Z</given-names></string-name>, <string-name><surname>Wu</surname><given-names>S</given-names></string-name>, <string-name><surname>Li</surname><given-names>W</given-names></string-name></person-group>. 
<article-title>CD-HIT: Accelerated for clustering the next-generation sequencing data</article-title>. <source><italic toggle="yes">Bioinformatics</italic></source>. <year>2012</year>;<volume>28</volume>(<issue>23</issue>):<fpage>3150</fpage>–<lpage>3152</lpage>.<pub-id pub-id-type="pmid">23060610</pub-id></mixed-citation>
    </ref>
    <ref id="B80">
      <label>80.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pedregosa</surname><given-names>F</given-names></string-name>, <string-name><surname>Varoquaux</surname><given-names>G</given-names></string-name>, <string-name><surname>Gramfort</surname><given-names>A</given-names></string-name>, <string-name><surname>Michel</surname><given-names>V</given-names></string-name>, <string-name><surname>Thirion</surname><given-names>B</given-names></string-name>, <string-name><surname>Grisel</surname><given-names>O</given-names></string-name>, <string-name><surname>Blondel</surname><given-names>M</given-names></string-name>, <string-name><surname>Prettenhofer</surname><given-names>P</given-names></string-name>, <string-name><surname>Weiss</surname><given-names>R</given-names></string-name>, <string-name><surname>Dubourg</surname><given-names>V</given-names></string-name></person-group>. 
<article-title>Scikit-learn: Machine learning in python</article-title>. <source><italic toggle="yes">J Mach Learn Res</italic></source>. <year>2011</year>;<volume>12</volume>:<fpage>2825</fpage>–<lpage>2830</lpage>.</mixed-citation>
    </ref>
    <ref id="B81">
      <label>81.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Luo</surname><given-names>Y</given-names></string-name>, <string-name><surname>Wang</surname><given-names>P</given-names></string-name>, <string-name><surname>Mou</surname><given-names>M</given-names></string-name>, <string-name><surname>Zheng</surname><given-names>H</given-names></string-name>, <string-name><surname>Hong</surname><given-names>J</given-names></string-name>, <string-name><surname>Tao</surname><given-names>L</given-names></string-name>, <string-name><surname>Zhu</surname><given-names>F</given-names></string-name></person-group>. 
<article-title>A novel strategy for designing the magic shotguns for distantly related target pairs</article-title>. <source><italic toggle="yes">Brief Bioinform</italic></source>. <year>2023</year>;<volume>24</volume>(<issue>1</issue>):<fpage>bbac621</fpage>.<pub-id pub-id-type="pmid">36631399</pub-id></mixed-citation>
    </ref>
    <ref id="B82">
      <label>82.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname><given-names>Y</given-names></string-name>, <string-name><surname>Luo</surname><given-names>X</given-names></string-name>, <string-name><surname>Zou</surname><given-names>Q</given-names></string-name></person-group>. 
<article-title>Effector-GAN: Prediction of fungal effector proteins based on pretrained deep representation learning methods and generative adversarial networks</article-title>. <source><italic toggle="yes">Bioinformatics</italic></source>. <year>2022</year>;<volume>38</volume>(<issue>14</issue>):<fpage>3541</fpage>–<lpage>3548</lpage>.<pub-id pub-id-type="pmid">35640972</pub-id></mixed-citation>
    </ref>
    <ref id="B83">
      <label>83.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Suzek</surname><given-names>BE</given-names></string-name>, <string-name><surname>Wang</surname><given-names>Y</given-names></string-name>, <string-name><surname>Huang</surname><given-names>H</given-names></string-name>, <string-name><surname>McGarvey</surname><given-names>PB</given-names></string-name>, <string-name><surname>Wu</surname><given-names>CH</given-names></string-name>, <string-name><surname>UniProt</surname><given-names>C</given-names></string-name></person-group>. 
<article-title>UniRef clusters: A comprehensive and scalable alternative for improving sequence similarity searches</article-title>. <source><italic toggle="yes">Bioinformatics</italic></source>. <year>2015</year>;<volume>31</volume>(<issue>6</issue>):<fpage>926</fpage>–<lpage>932</lpage>.<pub-id pub-id-type="pmid">25398609</pub-id></mixed-citation>
    </ref>
    <ref id="B84">
      <label>84.</label>
      <mixed-citation publication-type="other">Dauphin YN, Fan A, Auli M, Grangier D. Language modeling with gated convolutional networks. Paper presented at: Proceedings of the 34th International Conference on Machine Learning; 2017; Sydney, Australia.</mixed-citation>
    </ref>
    <ref id="B85">
      <label>85.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rassil</surname><given-names>A</given-names></string-name>, <string-name><surname>Chougrad</surname><given-names>H</given-names></string-name>, <string-name><surname>Zouaki</surname><given-names>H</given-names></string-name></person-group>. 
<article-title>Augmented graph neural network with hierarchical global-based residual connections</article-title>. <source><italic toggle="yes">Neural Netw</italic></source>. <year>2022</year>;<volume>150</volume>:<fpage>149</fpage>–<lpage>166</lpage>.<pub-id pub-id-type="pmid">35313247</pub-id></mixed-citation>
    </ref>
    <ref id="B86">
      <label>86.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hou</surname><given-names>Z</given-names></string-name>, <string-name><surname>Yang</surname><given-names>Y</given-names></string-name>, <string-name><surname>Li</surname><given-names>H</given-names></string-name>, <string-name><surname>Wong</surname><given-names>KC</given-names></string-name>, <string-name><surname>Li</surname><given-names>X</given-names></string-name></person-group>. 
<article-title>iDeepSubMito: Identification of protein submitochondrial localization with deep learning</article-title>. <source><italic toggle="yes">Brief Bioinform</italic></source>. <year>2021</year>;<volume>22</volume>(<issue>6</issue>):<fpage>bbab288</fpage>.<pub-id pub-id-type="pmid">34337657</pub-id></mixed-citation>
    </ref>
    <ref id="B87">
      <label>87.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yang</surname><given-names>Y</given-names></string-name>, <string-name><surname>Hou</surname><given-names>Z</given-names></string-name>, <string-name><surname>Wang</surname><given-names>Y</given-names></string-name>, <string-name><surname>Ma</surname><given-names>H</given-names></string-name>, <string-name><surname>Sun</surname><given-names>P</given-names></string-name>, <string-name><surname>Ma</surname><given-names>Z</given-names></string-name>, <string-name><surname>Wong</surname><given-names>KC</given-names></string-name>, <string-name><surname>Li</surname><given-names>X</given-names></string-name></person-group>. 
<article-title>HCRNet: High-throughput circRNA-binding event identification from CLIP-seq data using deep temporal convolutional network</article-title>. <source><italic toggle="yes">Brief Bioinform</italic></source>. <year>2022</year>;<volume>23</volume>(<issue>2</issue>):<fpage>bbac027</fpage>.<pub-id pub-id-type="pmid">35189638</pub-id></mixed-citation>
    </ref>
    <ref id="B88">
      <label>88.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Luo</surname><given-names>G</given-names></string-name>, <string-name><surname>Zhou</surname><given-names>Y</given-names></string-name>, <string-name><surname>Sun</surname><given-names>X</given-names></string-name>, <string-name><surname>Wang</surname><given-names>Y</given-names></string-name>, <string-name><surname>Cao</surname><given-names>L</given-names></string-name>, <string-name><surname>Wu</surname><given-names>Y</given-names></string-name>, <string-name><surname>Huang</surname><given-names>F</given-names></string-name>, <string-name><surname>Ji</surname><given-names>R</given-names></string-name></person-group>. 
<article-title>Towards lightweight transformer via group-wise transformation for vision-and-language tasks</article-title>. <source><italic toggle="yes">IEEE Trans Image Process</italic></source>. <year>2022</year>;<volume>31</volume>:<fpage>3386</fpage>–<lpage>3398</lpage>.<pub-id pub-id-type="pmid">35471883</pub-id></mixed-citation>
    </ref>
    <ref id="B89">
      <label>89.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Eckle</surname><given-names>K</given-names></string-name>, <string-name><surname>Schmidt-Hieber</surname><given-names>J</given-names></string-name></person-group>. 
<article-title>A comparison of deep networks with ReLU activation function and linear spline-type methods</article-title>. <source><italic toggle="yes">Neural Netw</italic></source>. <year>2019</year>;<volume>110</volume>:<fpage>232</fpage>–<lpage>242</lpage>.<pub-id pub-id-type="pmid">30616095</pub-id></mixed-citation>
    </ref>
    <ref id="B90">
      <label>90.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Shen</surname><given-names>WX</given-names></string-name>, <string-name><surname>Zeng</surname><given-names>X</given-names></string-name>, <string-name><surname>Zhu</surname><given-names>F</given-names></string-name>, <string-name><surname>Wang</surname><given-names>YL</given-names></string-name>, <string-name><surname>Qin</surname><given-names>C</given-names></string-name>, <string-name><surname>Tan</surname><given-names>Y</given-names></string-name>, <string-name><surname>Jiang</surname><given-names>YY</given-names></string-name>, <string-name><surname>Chen</surname><given-names>YZ</given-names></string-name></person-group>. 
<article-title>Out-of-the-box deep learning prediction of pharmaceutical properties by broadly learned knowledge-based molecular representations</article-title>. <source><italic toggle="yes">Nat Mach Intelli</italic></source>. <year>2021</year>;<volume>3</volume>(<issue>4</issue>):<fpage>334</fpage>–<lpage>343</lpage>.</mixed-citation>
    </ref>
    <ref id="B91">
      <label>91.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chen</surname><given-names>L</given-names></string-name>, <string-name><surname>Tan</surname><given-names>X</given-names></string-name>, <string-name><surname>Wang</surname><given-names>D</given-names></string-name>, <string-name><surname>Zhong</surname><given-names>F</given-names></string-name>, <string-name><surname>Liu</surname><given-names>X</given-names></string-name>, <string-name><surname>Yang</surname><given-names>T</given-names></string-name>, <string-name><surname>Luo</surname><given-names>X</given-names></string-name>, <string-name><surname>Chen</surname><given-names>K</given-names></string-name>, <string-name><surname>Jiang</surname><given-names>H</given-names></string-name>, <string-name><surname>Zheng</surname><given-names>M</given-names></string-name></person-group>. 
<article-title>TransformerCPI: Improving compound-protein interaction prediction by sequence-based deep learning with self-attention mechanism and label reversal experiments</article-title>. <source><italic toggle="yes">Bioinformatics</italic></source>. <year>2020</year>;<volume>36</volume>(<issue>16</issue>):<fpage>4406</fpage>–<lpage>4414</lpage>.<pub-id pub-id-type="pmid">32428219</pub-id></mixed-citation>
    </ref>
    <ref id="B92">
      <label>92.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wenzel</surname><given-names>J</given-names></string-name>, <string-name><surname>Matter</surname><given-names>H</given-names></string-name>, <string-name><surname>Schmidt</surname><given-names>F</given-names></string-name></person-group>. 
<article-title>Predictive multitask deep neural network models for ADME-Tox properties: Learning from large data sets</article-title>. <source><italic toggle="yes">J Chem Inf Model</italic></source>. <year>2019</year>;<volume>59</volume>(<issue>3</issue>):<fpage>1253</fpage>–<lpage>1268</lpage>.<pub-id pub-id-type="pmid">30615828</pub-id></mixed-citation>
    </ref>
    <ref id="B93">
      <label>93.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname><given-names>C</given-names></string-name>, <string-name><surname>Mou</surname><given-names>M</given-names></string-name>, <string-name><surname>Zhou</surname><given-names>Y</given-names></string-name>, <string-name><surname>Zhang</surname><given-names>W</given-names></string-name>, <string-name><surname>Lian</surname><given-names>X</given-names></string-name>, <string-name><surname>Shi</surname><given-names>S</given-names></string-name>, <string-name><surname>Lu</surname><given-names>M</given-names></string-name>, <string-name><surname>Sun</surname><given-names>H</given-names></string-name>, <string-name><surname>Li</surname><given-names>F</given-names></string-name>, <string-name><surname>Wang</surname><given-names>Y</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Biological activities of drug inactive ingredients</article-title>. <source><italic toggle="yes">Brief Bioinform</italic></source>. <year>2022</year>;<volume>23</volume>(<issue>5</issue>):<fpage>bbac160</fpage>.<pub-id pub-id-type="pmid">35524477</pub-id></mixed-citation>
    </ref>
    <ref id="B94">
      <label>94.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Xia</surname><given-names>W</given-names></string-name>, <string-name><surname>Zheng</surname><given-names>L</given-names></string-name>, <string-name><surname>Fang</surname><given-names>J</given-names></string-name>, <string-name><surname>Li</surname><given-names>F</given-names></string-name>, <string-name><surname>Zhou</surname><given-names>Y</given-names></string-name>, <string-name><surname>Zeng</surname><given-names>Z</given-names></string-name>, <string-name><surname>Zhang</surname><given-names>B</given-names></string-name>, <string-name><surname>Li</surname><given-names>Z</given-names></string-name>, <string-name><surname>Li</surname><given-names>H</given-names></string-name>, <string-name><surname>Zhu</surname><given-names>F</given-names></string-name></person-group>. 
<article-title>PFmulDL: A novel strategy enabling multi-class and multi-label protein function annotation by integrating diverse deep learning methods</article-title>. <source><italic toggle="yes">Comput Biol Med</italic></source>. <year>2022</year>;<volume>145</volume>:
<elocation-id>105465</elocation-id>.<pub-id pub-id-type="pmid">35366467</pub-id></mixed-citation>
    </ref>
    <ref id="B95">
      <label>95.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hong</surname><given-names>J</given-names></string-name>, <string-name><surname>Luo</surname><given-names>Y</given-names></string-name>, <string-name><surname>Mou</surname><given-names>M</given-names></string-name>, <string-name><surname>Fu</surname><given-names>J</given-names></string-name>, <string-name><surname>Zhang</surname><given-names>Y</given-names></string-name>, <string-name><surname>Xue</surname><given-names>W</given-names></string-name>, <string-name><surname>Xie</surname><given-names>T</given-names></string-name>, <string-name><surname>Tao</surname><given-names>L</given-names></string-name>, <string-name><surname>Lou</surname><given-names>Y</given-names></string-name>, <string-name><surname>Zhu</surname><given-names>F</given-names></string-name></person-group>. 
<article-title>Convolutional neural network-based annotation of bacterial type IV secretion system effectors with enhanced accuracy and reduced false discovery</article-title>. <source><italic toggle="yes">Brief Bioinform</italic></source>. <year>2020</year>;<volume>21</volume>(<issue>5</issue>):<fpage>1825</fpage>–<lpage>1836</lpage>.<pub-id pub-id-type="pmid">31860715</pub-id></mixed-citation>
    </ref>
    <ref id="B96">
      <label>96.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname><given-names>H</given-names></string-name>, <string-name><surname>Wang</surname><given-names>Y</given-names></string-name>, <string-name><surname>Pan</surname><given-names>Z</given-names></string-name>, <string-name><surname>Sun</surname><given-names>X</given-names></string-name>, <string-name><surname>Mou</surname><given-names>M</given-names></string-name>, <string-name><surname>Zhang</surname><given-names>B</given-names></string-name>, <string-name><surname>Li</surname><given-names>Z</given-names></string-name>, <string-name><surname>Li</surname><given-names>H</given-names></string-name>, <string-name><surname>Zhu</surname><given-names>F</given-names></string-name></person-group>. 
<article-title>ncRNAInter: A novel strategy based on graph neural network to discover interactions between lncRNA and miRNA</article-title>. <source><italic toggle="yes">Brief Bioinform</italic></source>. <year>2022</year>;<volume>23</volume>(<issue>6</issue>):<fpage>bbac411</fpage>.<pub-id pub-id-type="pmid">36198065</pub-id></mixed-citation>
    </ref>
    <ref id="B97">
      <label>97.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mummadi</surname><given-names>SR</given-names></string-name>, <string-name><surname>Al-Zubaidi</surname><given-names>A</given-names></string-name>, <string-name><surname>Hahn</surname><given-names>PY</given-names></string-name></person-group>. 
<article-title>Overfitting and use of mismatched cohorts in deep learning models: Preventable design limitations</article-title>. <source><italic toggle="yes">Am J Respir Crit Care Med</italic></source>. <year>2018</year>;<volume>198</volume>(<issue>4</issue>):<fpage>544</fpage>–<lpage>545</lpage>.<pub-id pub-id-type="pmid">29641217</pub-id></mixed-citation>
    </ref>
    <ref id="B98">
      <label>98.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bu</surname><given-names>Y</given-names></string-name>, <string-name><surname>Jia</surname><given-names>C</given-names></string-name>, <string-name><surname>Guo</surname><given-names>X</given-names></string-name>, <string-name><surname>Li</surname><given-names>F</given-names></string-name>, <string-name><surname>Song</surname><given-names>J</given-names></string-name></person-group>. 
<article-title>COPPER: An ensemble deep-learning approach for identifying exclusive virus-derived small interfering RNAs in plants</article-title>. <source><italic toggle="yes">Brief Funct Genomics</italic></source>. <year>2023</year>;<volume>22</volume>(<issue>3</issue>):<fpage>274</fpage>–<lpage>280</lpage>.<pub-id pub-id-type="pmid">36528813</pub-id></mixed-citation>
    </ref>
    <ref id="B99">
      <label>99.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Abrahamyan</surname><given-names>L</given-names></string-name>, <string-name><surname>Chen</surname><given-names>Y</given-names></string-name>, <string-name><surname>Bekoulis</surname><given-names>G</given-names></string-name>, <string-name><surname>Deligiannis</surname><given-names>N</given-names></string-name></person-group>. 
<article-title>Learned gradient compression for distributed deep learning</article-title>. <source><italic toggle="yes">IEEE Trans Neural Netw Learn Syst</italic></source>. <year>2022</year>;<volume>33</volume>(<issue>12</issue>):<fpage>7330</fpage>–<lpage>7344</lpage>.<pub-id pub-id-type="pmid">34111008</pub-id></mixed-citation>
    </ref>
    <ref id="B100">
      <label>100.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ofran</surname><given-names>Y</given-names></string-name>, <string-name><surname>Rost</surname><given-names>B</given-names></string-name></person-group>. 
<article-title>ISIS: Interaction sites identified from sequence</article-title>. <source><italic toggle="yes">Bioinformatics</italic></source>. <year>2007</year>;<volume>23</volume>(<issue>2</issue>):<fpage>e13</fpage>–<lpage>e16</lpage>.<pub-id pub-id-type="pmid">17237081</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-archivearticle1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Research (Wash D C)</journal-id>
    <journal-id journal-id-type="iso-abbrev">Research (Wash D C)</journal-id>
    <journal-id journal-id-type="publisher-id">RESEARCH</journal-id>
    <journal-title-group>
      <journal-title>Research</journal-title>
    </journal-title-group>
    <issn pub-type="epub">2639-5274</issn>
    <publisher>
      <publisher-name>AAAS</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">10528219</article-id>
    <article-id pub-id-type="doi">10.34133/research.0240</article-id>
    <article-id pub-id-type="publisher-id">0240</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Research Article</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>A Transformer-Based Ensemble Framework for the Prediction of Protein–Protein Interaction Sites</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0001-7619-2975</contrib-id>
        <name>
          <surname>Mou</surname>
          <given-names>Minjie</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="afn1" ref-type="author-notes">
          <sup>†</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-3883-4161</contrib-id>
        <name>
          <surname>Pan</surname>
          <given-names>Ziqi</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="afn1" ref-type="author-notes">
          <sup>†</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0009-0007-7980-7577</contrib-id>
        <name>
          <surname>Zhou</surname>
          <given-names>Zhimeng</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0001-7533-2649</contrib-id>
        <name>
          <surname>Zheng</surname>
          <given-names>Lingyan</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-4728-7702</contrib-id>
        <name>
          <surname>Zhang</surname>
          <given-names>Hanyu</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0009-0007-9638-5089</contrib-id>
        <name>
          <surname>Shi</surname>
          <given-names>Shuiyang</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-1846-639X</contrib-id>
        <name>
          <surname>Li</surname>
          <given-names>Fengcheng</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0001-7991-5825</contrib-id>
        <name>
          <surname>Sun</surname>
          <given-names>Xiuna</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0001-8069-0053</contrib-id>
        <name>
          <surname>Zhu</surname>
          <given-names>Feng</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="aff2" ref-type="aff">
          <sup>2</sup>
        </xref>
        <xref rid="corr1" ref-type="corresp">
          <sup>*</sup>
        </xref>
      </contrib>
    </contrib-group>
    <aff id="aff1"><label><sup>1</sup></label><addr-line>College of Pharmaceutical Sciences, The Second Affiliated Hospital</addr-line>, 
<institution>Zhejiang University</institution><addr-line>School of Medicine, National Key Laboratory of Advanced Drug Delivery and Release Systems, Zhejiang University</addr-line>, Hangzhou 310058, <country>China</country>.</aff>
    <aff id="aff2"><label><sup>2</sup></label><institution>Innovation Institute for Artificial Intelligence in Medicine of Zhejiang University</institution>, <addr-line>Alibaba-Zhejiang University Joint Research Center of Future Digital Healthcare</addr-line>, Hangzhou 330110, <country>China</country>.</aff>
    <author-notes>
      <corresp id="corr1"><label>*</label>Address correspondence to: <email xlink:href="mailto:zhufeng@zju.edu.cn">zhufeng@zju.edu.cn</email></corresp>
      <fn id="afn1" fn-type="equal">
        <label>†</label>
        <p>These authors contributed equally to this work.</p>
      </fn>
    </author-notes>
    <pub-date publication-format="electronic" date-type="pub">
      <day>27</day>
      <month>9</month>
      <year>2023</year>
    </pub-date>
    <pub-date publication-format="electronic" date-type="collection">
      <year>2023</year>
    </pub-date>
    <volume>6</volume>
    <elocation-id>0240</elocation-id>
    <history>
      <date date-type="received">
        <day>02</day>
        <month>8</month>
        <year>2023</year>
      </date>
      <date date-type="accepted">
        <day>08</day>
        <month>9</month>
        <year>2023</year>
      </date>
      <date date-type="pub">
        <day>27</day>
        <month>9</month>
        <year>2023</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>Copyright © 2023 Minjie Mou et al.</copyright-statement>
      <copyright-year>2023</copyright-year>
      <copyright-holder>Minjie Mou et al.</copyright-holder>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>Exclusive licensee Science and Technology Review Publishing House. No claim to original U.S. Government Works. Distributed under a <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License 4.0 (CC BY 4.0)</ext-link>.</license-p>
      </license>
    </permissions>
    <self-uri content-type="pdf" xlink:href="research.0240.pdf"/>
    <abstract>
      <p>The identification of protein–protein interaction (PPI) sites is essential in the research of protein function and the discovery of new drugs. So far, a variety of computational tools based on machine learning have been developed to accelerate the identification of PPI sites. However, existing methods suffer from the low predictive accuracy or the limited scope of application. Specifically, some methods learned only global or local sequential features, leading to low predictive accuracy, while others achieved improved performance by extracting residue interactions from structures but were limited in their application scope for the serious dependence on precise structure information. There is an urgent need to develop a method that integrates comprehensive information to realize proteome-wide accurate profiling of PPI sites. Herein, a novel ensemble framework for PPI sites prediction, EnsemPPIS, was therefore proposed based on transformer and gated convolutional networks. EnsemPPIS can effectively capture not only global and local patterns but also residue interactions. Specifically, EnsemPPIS was unique in (a) extracting residue interactions from protein sequences with transformer and (b) further integrating global and local sequential features with the ensemble learning strategy. Compared with various existing methods, EnsemPPIS exhibited either superior performance or broader applicability on multiple PPI sites prediction tasks. Moreover, pattern analysis based on the interpretability of EnsemPPIS demonstrated that EnsemPPIS was fully capable of learning residue interactions within the local structure of PPI sites using only sequence information. The web server of EnsemPPIS is freely available at <ext-link xlink:href="http://idrblab.org/ensemppis" ext-link-type="uri">http://idrblab.org/ensemppis</ext-link>.</p>
    </abstract>
    <counts>
      <fig-count count="7"/>
      <table-count count="2"/>
      <ref-count count="100"/>
      <page-count count="0"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec id="sec1">
    <title>Introduction</title>
    <p>Protein–protein interaction (PPI) plays a fundamental role in numerous cellular functional progresses [<xref rid="B1" ref-type="bibr">1</xref>–<xref rid="B5" ref-type="bibr">5</xref>]. PPI sites refer to the interfacial residues of proteins that are involved in these interactions, and the identification of PPI sites is of utmost importance for unraveling the mysteries of cell processes and promoting the development of new drugs [<xref rid="B6" ref-type="bibr">6</xref>–<xref rid="B8" ref-type="bibr">8</xref>]. Experimental approaches for identifying PPI sites, including affinity purification coupled to mass spectrometry [<xref rid="B9" ref-type="bibr">9</xref>,<xref rid="B10" ref-type="bibr">10</xref>], coimmunoprecipitation [<xref rid="B11" ref-type="bibr">11</xref>,<xref rid="B12" ref-type="bibr">12</xref>] and 2-hybrid screening [<xref rid="B13" ref-type="bibr">13</xref>,<xref rid="B14" ref-type="bibr">14</xref>], face challenges due to their intricate and time-consuming procedures [<xref rid="B15" ref-type="bibr">15</xref>–<xref rid="B18" ref-type="bibr">18</xref>]. Therefore, the development of efficient computational methods to accelerate the identification of PPI sites is of vital importance [<xref rid="B19" ref-type="bibr">19</xref>–<xref rid="B22" ref-type="bibr">22</xref>].</p>
    <p>So far, various computational methods have been developed for predicting PPI sites, which can be categorized into 2 mainstream strategies [<xref rid="B23" ref-type="bibr">23</xref>]. The first strategy involves docking methods that predict pairwise interaction sites and rely on the structural information of both interacting proteins [<xref rid="B24" ref-type="bibr">24</xref>,<xref rid="B25" ref-type="bibr">25</xref>]. In contrast, the second strategy focuses on predicting putative interaction sites within individual isolated proteins, without requiring any knowledge of the partner proteins [<xref rid="B26" ref-type="bibr">26</xref>]. The latter strategy holds great research importance since the structure of protein complex or the information on partner protein may not be available, and therefore has spawned a series of machine learning-based tools to perform partner-independent prediction of PPI sites in a more general paradigm [<xref rid="B17" ref-type="bibr">17</xref>]. These tools were built to learn and extract information that determines PPI, and were broadly categorized into sequence-based and structure-based according to the type of input data [<xref rid="B27" ref-type="bibr">27</xref>–<xref rid="B29" ref-type="bibr">29</xref>]. Some tools encode residues from the primary sequence and output the probability of being PPI sites [<xref rid="B30" ref-type="bibr">30</xref>], such as SPRINGS [<xref rid="B31" ref-type="bibr">31</xref>], SCRIBER [<xref rid="B32" ref-type="bibr">32</xref>], ProNA2020 [<xref rid="B33" ref-type="bibr">33</xref>], and DELPHI [<xref rid="B34" ref-type="bibr">34</xref>]. Others leverage structural information to identify PPI sites, such as secondary structure and residue contact map. Prominent examples in this category include SPPIDER [<xref rid="B28" ref-type="bibr">28</xref>], DeepPPISP [<xref rid="B22" ref-type="bibr">22</xref>], EGRET [<xref rid="B23" ref-type="bibr">23</xref>], and GraphPPIS [<xref rid="B35" ref-type="bibr">35</xref>]. Recently, several methods utilized geometric deep learning to capture structural surface features for PPI sites prediction, including PInet [<xref rid="B36" ref-type="bibr">36</xref>], MaSIF-site [<xref rid="B37" ref-type="bibr">37</xref>], ScanNet [<xref rid="B38" ref-type="bibr">38</xref>], and PeSTo [<xref rid="B39" ref-type="bibr">39</xref>].</p>
    <p>However, these methods suffer from the low predictive accuracy or the limited scope of application. Specifically, some methods had a main disadvantage of relatively low prediction accuracy because they only excelled at learning global or local contextual features from primary sequences [<xref rid="B22" ref-type="bibr">22</xref>,<xref rid="B23" ref-type="bibr">23</xref>,<xref rid="B40" ref-type="bibr">40</xref>,<xref rid="B41" ref-type="bibr">41</xref>], but failed to leverage local structural features whose information proves to be inextricably linked to PPI sites [<xref rid="B23" ref-type="bibr">23</xref>,<xref rid="B35" ref-type="bibr">35</xref>,<xref rid="B42" ref-type="bibr">42</xref>]. Others achieved improved performance by extracting residue interactions from protein structures, particularly the long-range interactions within local structures, but their application scope and generalization ability were extremely limited for their acute dependence on precise structure information, severe sensitivity to structural errors, and inappropriate use of protein conformation for model training [<xref rid="B35" ref-type="bibr">35</xref>,<xref rid="B43" ref-type="bibr">43</xref>,<xref rid="B44" ref-type="bibr">44</xref>]. Therefore, there is an urgent need to develop a method that integrates comprehensive information to enable accurate identification of PPI sites in the largest scope of whole proteome [<xref rid="B45" ref-type="bibr">45</xref>–<xref rid="B47" ref-type="bibr">47</xref>].</p>
    <p>Herein, a novel transformer-based ensemble method for PPI sites prediction, EnsemPPIS, was therefore proposed, which can capture not only global and local patterns but also residue interactions. EnsemPPIS consists of 2 base models, namely, TransformerPPIS and GatCNNPPIS. The transformer framework in TransformerPPIS is equipped with the ability to learn global features and calculate attention weights between residues, making it possible to capture residue dependencies within local structures, while GatCNNPPIS is capable of learning local contextual features using the gated convolutional networks. EnsemPPIS was thoroughly evaluated on multiple PPI sites prediction tasks and exhibited either superior performance or broader applicability compared with various existing methods. Moreover, pattern analysis based on the interpretability of EnsemPPIS demonstrated that EnsemPPIS was fully capable of learning residue interactions using only primary sequences, thereby improving the performance of PPI sites prediction. A web server of EnsemPPIS was further established, which is freely available at <ext-link xlink:href="http://idrblab.org/ensemppis" ext-link-type="uri">http://idrblab.org/ensemppis</ext-link>. EnsemPPIS is applicable for proteome-wide profiling of PPI sites and expected to provide more insights into protein function research and drug discovery.</p>
  </sec>
  <sec id="sec2">
    <title>Results and Discussion</title>
    <sec id="sec3">
      <title>The ensemble framework of EnsemPPIS for predicting PPI sites</title>
      <p>EnsemPPIS functions through 3 steps, including ProtBERT embedding, feature learning, and prediction, as illustrated in Fig. <xref rid="F1" ref-type="fig">1</xref>. Specifically, proteins are input into ProtBERT, a pretrained protein language model, to obtain the embeddings for residues [<xref rid="B48" ref-type="bibr">48</xref>]. Following the embedding, an ensemble learning framework is employed to effectively learn the underlying features, which consists of 2 deep learning base models, namely, TransformerPPIS and GatCNNPPIS. These models leverage the embeddings obtained from ProtBERT for further analysis and prediction of PPI sites. TransformerPPIS can extract residue interaction information and global features of proteins. To extract global features, the protein embeddings are fed into the encoder module. Simultaneously, each residue embedding undergoes a fully connected layer (FC) before being input into the decoder module alongside the global features. Within the decoder, the pairwise residue interactions are extracted using the self-attention mechanism of the transformer algorithm. The concrete architecture of TransformerPPIS is illustrated in Fig. <xref rid="F2" ref-type="fig">2</xref>, with a more detailed description presented in Materials and Methods. GatCNNPPIS can extract local features from protein embeddings. Specifically, GatCNNPPIS employs gated convolutional networks with residual connections to capture sequential motifs. In this approach, each residue is represented by its local contextual environment, which encompasses a total of 7 residues. Finally, the latent representations generated by TransformerPPIS and GatCNNPPIS are separately fed into the classifier, which consists of several FCs. The classifier utilizes these representations to output the probability score. The average probability score serves as the final probability of each residue being a potential PPI site. In summary, the major characteristic of EnsemPPIS is its ability to extract local and global features, as well as residue interaction information from ProtBERT-embedded proteins based on the ensemble learning framework.</p>
      <fig position="float" id="F1">
        <label>Fig. 1.</label>
        <caption>
          <p>The ensemble learning framework of EnsemPPIS for predicting PPI sites. EnsemPPIS consists of 2 base models (TransformerPPIS and GatCNNPPIS) and functions through 3 steps, including ProtBERT embedding, feature learning and prediction. The average of probability scores output by the 2 base models is considered as the final probability of each residue as a potential PPI site. GLU, gated linear unit; RC, residual connection; FC, fully connected layer.</p>
        </caption>
        <graphic xlink:href="research.0240.fig.001" position="float"/>
      </fig>
      <fig position="float" id="F2">
        <label>Fig. 2.</label>
        <caption>
          <p>The deep learning architecture of the base model TransformerPPIS in EnsemPPIS. TransformerPPIS is mainly composed of 3 modules: the encoder, the decoder, and the classifier module. The sequence embedding obtained by ProtBERT is first input into the encoder module to extract global feature. Then, the global feature of the protein and the original embedding feature of a specific residue are both input into decoder module. The output of decoder is further passed into the classifier module to generate the probability score of a residue being a potential PPI site. GLU, gated linear unit; RC, residual connection; LN, layer normalization; FC, fully connected layer.</p>
        </caption>
        <graphic xlink:href="research.0240.fig.002" position="float"/>
      </fig>
    </sec>
    <sec id="sec4">
      <title>Leading performance of EnsemPPIS in residue-level prediction</title>
      <p>Previous studies have generated multiple datasets preserving experimentally validated PPI sites data, which have been widely utilized in developing computational tools, as displayed in Table <xref rid="supplementary-material-1" ref-type="sec">S1</xref>. We took advantage of these valuable benchmark datasets to train and evaluate EnsemPPIS and made comprehensive comparisons with various existing methods. As a result, EnsemPPIS achieved leading performance in residue-level prediction on <italic toggle="yes">DeepPPISP task</italic> and <italic toggle="yes">DELPHI task</italic>.</p>
      <p>(a) <italic toggle="yes">Performance evaluation on DeepPPISP task</italic></p>
      <p>EnsemPPIS, along with 12 other competing methods, was first evaluated and compared on the <italic toggle="yes">DeepPPISP task</italic>, as shown in Table <xref rid="T1" ref-type="table">1</xref>. Some of the results were obtained by reproducing the provided source code or utilizing the web server. Meanwhile, for certain methods that employed the same training and test data as the previous work DeepPPISP [<xref rid="B22" ref-type="bibr">22</xref>], the results were directly collected from that study to ensure consistency and comparability.</p>
      <table-wrap position="float" id="T1">
        <label>Table 1.</label>
        <caption>
          <p>Comparison of the predictive performance of our proposed methods and other state-of-the-art methods on <italic toggle="yes">DeepPPISP task</italic>. DeepPPISP, EGRET, IntPred, and SPPIDER use protein structural information. DELPHI, DLPred, ISIS, ProNA2020, PSIVER, RF_PPI, SCRIBER, and SPRINGS use protein sequences. TransformerPPIS, GatCNNPPIS, and EnsemPPIS are proposed in this study. All comparison methods are sorted alphabetically. The best results are shown in bold.</p>
        </caption>
        <table frame="hsides" rules="groups">
          <thead>
            <tr>
              <th align="left" rowspan="1" colspan="1">Method</th>
              <th align="center" rowspan="1" colspan="1">ACC</th>
              <th align="center" rowspan="1" colspan="1">PRE</th>
              <th align="center" rowspan="1" colspan="1">REC</th>
              <th align="center" rowspan="1" colspan="1">F1</th>
              <th align="center" rowspan="1" colspan="1">AUROC</th>
              <th align="center" rowspan="1" colspan="1">AUPRC</th>
              <th align="center" rowspan="1" colspan="1">MCC</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td align="left" rowspan="1" colspan="1">DeepPPISP <sup>a</sup></td>
              <td align="center" rowspan="1" colspan="1">0.655</td>
              <td align="center" rowspan="1" colspan="1">0.303</td>
              <td align="center" rowspan="1" colspan="1">0.577</td>
              <td align="center" rowspan="1" colspan="1">0.397</td>
              <td align="center" rowspan="1" colspan="1">0.671</td>
              <td align="center" rowspan="1" colspan="1">0.320</td>
              <td align="center" rowspan="1" colspan="1">0.206</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">DELPHI <sup>b</sup></td>
              <td align="center" rowspan="1" colspan="1">0.667</td>
              <td align="center" rowspan="1" colspan="1">0.319</td>
              <td align="center" rowspan="1" colspan="1">0.604</td>
              <td align="center" rowspan="1" colspan="1">0.418</td>
              <td align="center" rowspan="1" colspan="1">0.690</td>
              <td align="center" rowspan="1" colspan="1">0.360</td>
              <td align="center" rowspan="1" colspan="1">0.236</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">DLPred <sup>c</sup></td>
              <td align="center" rowspan="1" colspan="1">0.680</td>
              <td align="center" rowspan="1" colspan="1">0.325</td>
              <td align="center" rowspan="1" colspan="1">0.577</td>
              <td align="center" rowspan="1" colspan="1">0.416</td>
              <td align="center" rowspan="1" colspan="1">0.697</td>
              <td align="center" rowspan="1" colspan="1">0.380</td>
              <td align="center" rowspan="1" colspan="1">0.235</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">EGRET <sup>b</sup></td>
              <td align="center" rowspan="1" colspan="1">0.715</td>
              <td align="center" rowspan="1" colspan="1">0.358</td>
              <td align="center" rowspan="1" colspan="1">0.561</td>
              <td align="center" rowspan="1" colspan="1">0.438</td>
              <td align="center" rowspan="1" colspan="1">0.719</td>
              <td align="center" rowspan="1" colspan="1">0.405</td>
              <td align="center" rowspan="1" colspan="1">0.270</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">IntPred <sup>a</sup></td>
              <td align="center" rowspan="1" colspan="1">0.672</td>
              <td align="center" rowspan="1" colspan="1">0.247</td>
              <td align="center" rowspan="1" colspan="1">0.508</td>
              <td align="center" rowspan="1" colspan="1">0.332</td>
              <td align="center" rowspan="1" colspan="1">-</td>
              <td align="center" rowspan="1" colspan="1">-</td>
              <td align="center" rowspan="1" colspan="1">0.165</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">ISIS <sup>a</sup></td>
              <td align="center" rowspan="1" colspan="1">0.622</td>
              <td align="center" rowspan="1" colspan="1">0.211</td>
              <td align="center" rowspan="1" colspan="1">0.362</td>
              <td align="center" rowspan="1" colspan="1">0.267</td>
              <td align="center" rowspan="1" colspan="1">-</td>
              <td align="center" rowspan="1" colspan="1">0.240</td>
              <td align="center" rowspan="1" colspan="1">0.097</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">ProNA2020 <sup>c</sup></td>
              <td align="center" rowspan="1" colspan="1">
                <bold>0.741</bold>
              </td>
              <td align="center" rowspan="1" colspan="1">0.297</td>
              <td align="center" rowspan="1" colspan="1">0.229</td>
              <td align="center" rowspan="1" colspan="1">0.258</td>
              <td align="center" rowspan="1" colspan="1">-</td>
              <td align="center" rowspan="1" colspan="1">-</td>
              <td align="center" rowspan="1" colspan="1">0.106</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">PSIVER <sup>a</sup></td>
              <td align="center" rowspan="1" colspan="1">0.653</td>
              <td align="center" rowspan="1" colspan="1">0.253</td>
              <td align="center" rowspan="1" colspan="1">0.468</td>
              <td align="center" rowspan="1" colspan="1">0.328</td>
              <td align="center" rowspan="1" colspan="1">-</td>
              <td align="center" rowspan="1" colspan="1">0.250</td>
              <td align="center" rowspan="1" colspan="1">0.138</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">RF_PPI <sup>a</sup></td>
              <td align="center" rowspan="1" colspan="1">0.598</td>
              <td align="center" rowspan="1" colspan="1">0.173</td>
              <td align="center" rowspan="1" colspan="1">0.512</td>
              <td align="center" rowspan="1" colspan="1">0.258</td>
              <td align="center" rowspan="1" colspan="1">-</td>
              <td align="center" rowspan="1" colspan="1">0.210</td>
              <td align="center" rowspan="1" colspan="1">0.118</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">SCRIBER <sup>c</sup></td>
              <td align="center" rowspan="1" colspan="1">0.616</td>
              <td align="center" rowspan="1" colspan="1">0.274</td>
              <td align="center" rowspan="1" colspan="1">0.569</td>
              <td align="center" rowspan="1" colspan="1">0.370</td>
              <td align="center" rowspan="1" colspan="1">0.635</td>
              <td align="center" rowspan="1" colspan="1">0.307</td>
              <td align="center" rowspan="1" colspan="1">0.159</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">SPPIDER <sup>c</sup></td>
              <td align="center" rowspan="1" colspan="1">0.667</td>
              <td align="center" rowspan="1" colspan="1">0.240</td>
              <td align="center" rowspan="1" colspan="1">0.315</td>
              <td align="center" rowspan="1" colspan="1">0.273</td>
              <td align="center" rowspan="1" colspan="1">0.518</td>
              <td align="center" rowspan="1" colspan="1">0.235</td>
              <td align="center" rowspan="1" colspan="1">0.063</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">SPRINGS <sup>a</sup></td>
              <td align="center" rowspan="1" colspan="1">0.631</td>
              <td align="center" rowspan="1" colspan="1">0.248</td>
              <td align="center" rowspan="1" colspan="1">0.598</td>
              <td align="center" rowspan="1" colspan="1">0.35</td>
              <td align="center" rowspan="1" colspan="1">-</td>
              <td align="center" rowspan="1" colspan="1">0.280</td>
              <td align="center" rowspan="1" colspan="1">0.181</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">TransformerPPIS</td>
              <td align="center" rowspan="1" colspan="1">0.681</td>
              <td align="center" rowspan="1" colspan="1">0.332</td>
              <td align="center" rowspan="1" colspan="1">0.604</td>
              <td align="center" rowspan="1" colspan="1">0.429</td>
              <td align="center" rowspan="1" colspan="1">0.711</td>
              <td align="center" rowspan="1" colspan="1">0.389</td>
              <td align="center" rowspan="1" colspan="1">0.253</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">GatCNNPPIS</td>
              <td align="center" rowspan="1" colspan="1">0.633</td>
              <td align="center" rowspan="1" colspan="1">0.306</td>
              <td align="center" rowspan="1" colspan="1">
                <bold>0.698</bold>
              </td>
              <td align="center" rowspan="1" colspan="1">0.421</td>
              <td align="center" rowspan="1" colspan="1">0.698</td>
              <td align="center" rowspan="1" colspan="1">0.369</td>
              <td align="center" rowspan="1" colspan="1">0.239</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">EnsemPPIS</td>
              <td align="center" rowspan="1" colspan="1">0.732</td>
              <td align="center" rowspan="1" colspan="1">
                <bold>0.375</bold>
              </td>
              <td align="center" rowspan="1" colspan="1">0.532</td>
              <td align="center" rowspan="1" colspan="1">
                <bold>0.440</bold>
              </td>
              <td align="center" rowspan="1" colspan="1">
                <bold>0.719</bold>
              </td>
              <td align="center" rowspan="1" colspan="1">
                <bold>0.405</bold>
              </td>
              <td align="center" rowspan="1" colspan="1">
                <bold>0.277</bold>
              </td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn>
            <p><sup>a</sup> Results reported by DeepPPISP. </p>
            <p><sup>b</sup> Results obtained by reproducing the source code. ProNA2020 only makes binary predictions, and its AUROC and AUPRC are not calculated. </p>
            <p><sup>c</sup> Results obtained by utilizing the web server.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p>As a result, EnsemPPIS achieved the highest performance among all evaluated methods, achieving the MCC value of 0.277, AUPRC of 0.405, and F1 of 0.405. These 3 evaluation metrics are the most important ones in the imbalanced task of PPI sites prediction [<xref rid="B22" ref-type="bibr">22</xref>]. Specifically, when compared to the state-of-the-art (SOTA) sequence-based method DELPHI, EnsemPPIS achieved a 5.3% improvement in F1, a 12.5% improvement in AUPRC, and a remarkable 17.4% improvement in MCC. Moreover, EnsemPPIS, using only sequence information, exhibited competitive performance even when compared to structure-based methods. In fact, EnsemPPIS slightly outperformed the most recent method, EGRET, in terms of F1 and MCC. The performance of the 2 base models, TransformerPPIS and GatCNNPPIS, was also evaluated. TransformerPPIS exhibited superior performance compared to most of the existing methods, showcasing its effectiveness in leveraging global features and residue interactions from the protein embeddings. On the other hand, GatCNNPPIS achieved strong performance, highlighting its ability to capture local contextual information. Both models demonstrated their efficacy and contributed to the overall success of the EnsemPPIS framework. In general, EnsemPPIS achieved the highest performance, indicating the effectiveness of ensemble learning. Importantly, the PRE value of EnsemPPIS demonstrated an increase compared to that of the base models. This indicated that ensemble learning effectively contributed to controlling the false-positive rate to a certain extent.</p>
      <p>EnsemPPIS achieves accurate prediction of PPI sites by integrating 2 separately trained base models. To demonstrate the effectiveness of ensemble learning, 2 variants of EnsemPPIS were constructed by combining the 2 base models into a single model for concurrent training, namely, EnsemPPIS-Va and EnsemPPIS-Vb, as shown in Fig. <xref rid="F3" ref-type="fig">3</xref>A and B. The detailed description of these 2 variants was provided in Materials and Methods. Both variants were also evaluated on the <italic toggle="yes">DeepPPISP task</italic>. Figure <xref rid="F3" ref-type="fig">3</xref>C depicts the performance comparison between EnsemPPIS and its 2 variants. Obviously, EnsemPPIS demonstrated superior performance compared to EnsemPPIS-Va and EnsemPPIS-Vb across all metrics, particularly in terms of MCC and AUPRC. This suggested that the ensemble of the 2 separately trained base models was more effective compared to the approach of initially integrating the 2 base models and training them simultaneously.</p>
      <fig position="float" id="F3">
        <label>Fig. 3.</label>
        <caption>
          <p>Performance evaluation of EnsemPPIS, its variants, and the base model on the <italic toggle="yes">DeepPPISP task</italic>. (A) Architecture of variant EnsemPPIS-Va. The output of TransformerPPIS’s decoder and the output of GatCNNPPIS’s encoder were concatenated. The concatenated vector was then fed into multiple fully connected layers (FCs). (B) Architecture of variant EnsemPPIS-Vb. The output of TransformerPPIS’s decoder and the output of GatCNNPPIS’s encoder were separately passed through FCs. The resulting 2-dimensional vectors were concatenated and further processed through an FC. (C) Performance comparison of EnsemPPIS, EnsemPPIS-Va, and EnsemPPIS-Vb on various metrics. (D) Matthews correlation coefficient (MCC) of TransformerPPIS using different types of feature. (E) Area under the receiver operator characteristic curve (AUROC) of TransformerPPIS using different types of feature. The orange bars represent the performance without ProtBERT feature, and the yellow bars represent the performance with inclusion of ProtBERT feature.</p>
        </caption>
        <graphic xlink:href="research.0240.fig.003" position="float"/>
      </fig>
      <p>Furthermore, we additionally assessed the performance of TransformerPPIS using different types of features or feature combinations, namely, ProtBERT, PSSM [<xref rid="B49" ref-type="bibr">49</xref>], DSSP [<xref rid="B50" ref-type="bibr">50</xref>], and One-hot [<xref rid="B22" ref-type="bibr">22</xref>], and the results were depicted in Fig. <xref rid="F3" ref-type="fig">3</xref>D and E. Consequently, BERT-based feature outperformed the traditional handcrafted features on MCC and AUROC, and the inclusion of ProtBERT feature significantly enhanced the predictive performance.</p>
      <p>(b) <italic toggle="yes">Performance evaluation on DELPHI task</italic></p>
      <p>EnsemPPIS was further assessed on <italic toggle="yes">DELPHI task</italic>, as shown in Table <xref rid="T2" ref-type="table">2</xref>. Due to the unavailability of structural information in the training data, the evaluation and comparison of methods in this task focused solely on those utilizing protein sequences. This allowed for a fair and direct assessment of the performance of sequence-based methods in predicting PPI sites. All results were calculated by using the source code or web server. As a result, EnsemPPIS proved to be the best method. Specifically, considerable improvements in F1, AUPRC, and MCC were achieved by 5.8%, 8.8%, and 4.7%, respectively, compared with the SOTA method DELPHI.</p>
      <table-wrap position="float" id="T2">
        <label>Table 2.</label>
        <caption>
          <p>Comparison of the predictive performance of EnsemPPIS and other state-of-the-art methods on <italic toggle="yes">DELPHI task</italic>. All comparison methods use only protein sequences and are sorted alphabetically. The best results are shown in bold.</p>
        </caption>
        <table frame="hsides" rules="groups">
          <thead>
            <tr>
              <th align="left" rowspan="1" colspan="1">Method</th>
              <th align="center" rowspan="1" colspan="1">ACC</th>
              <th align="center" rowspan="1" colspan="1">F1</th>
              <th align="center" rowspan="1" colspan="1">AUROC</th>
              <th align="center" rowspan="1" colspan="1">AUPRC</th>
              <th align="center" rowspan="1" colspan="1">MCC</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td align="left" rowspan="1" colspan="1">DELPHI <sup>a</sup></td>
              <td align="center" rowspan="1" colspan="1">
                <bold>0.848</bold>
              </td>
              <td align="center" rowspan="1" colspan="1">0.364</td>
              <td align="center" rowspan="1" colspan="1">0.746</td>
              <td align="center" rowspan="1" colspan="1">0.326</td>
              <td align="center" rowspan="1" colspan="1">0.278</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">DLPred <sup>b</sup></td>
              <td align="center" rowspan="1" colspan="1">0.835</td>
              <td align="center" rowspan="1" colspan="1">0.308</td>
              <td align="center" rowspan="1" colspan="1">0.724</td>
              <td align="center" rowspan="1" colspan="1">0.272</td>
              <td align="center" rowspan="1" colspan="1">0.214</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">SCRIBER <sup>b</sup></td>
              <td align="center" rowspan="1" colspan="1">0.838</td>
              <td align="center" rowspan="1" colspan="1">0.322</td>
              <td align="center" rowspan="1" colspan="1">0.719</td>
              <td align="center" rowspan="1" colspan="1">0.275</td>
              <td align="center" rowspan="1" colspan="1">0.230</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">SPRINGS <sup>a</sup></td>
              <td align="center" rowspan="1" colspan="1">0.811</td>
              <td align="center" rowspan="1" colspan="1">0.211</td>
              <td align="center" rowspan="1" colspan="1">0.608</td>
              <td align="center" rowspan="1" colspan="1">0.178</td>
              <td align="center" rowspan="1" colspan="1">0.103</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">EnsemPPIS</td>
              <td align="center" rowspan="1" colspan="1">0.821</td>
              <td align="center" rowspan="1" colspan="1">
                <bold>0.385</bold>
              </td>
              <td align="center" rowspan="1" colspan="1">
                <bold>0.770</bold>
              </td>
              <td align="center" rowspan="1" colspan="1">
                <bold>0.354</bold>
              </td>
              <td align="center" rowspan="1" colspan="1">
                <bold>0.291</bold>
              </td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn>
            <p><sup>a</sup> Results obtained by reproducing the source code. </p>
            <p><sup>b</sup> Results obtained by utilizing the web server.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p>In summary, EnsemPPIS achieved remarkable improvements in residue-level prediction of PPI sites using only protein sequences, outperforming all existing sequence-based methods and comparable to even the most advanced structure-based methods. In this study, protein sequences were input into the pretrained language model ProtBERT to obtain the protein embeddings. Currently, there are some large protein language models that are able to generate informative latent vectors for residues [<xref rid="B51" ref-type="bibr">51</xref>], such as ESM-2 [<xref rid="B52" ref-type="bibr">52</xref>] and AminoBERT [<xref rid="B53" ref-type="bibr">53</xref>]. These models utilize advanced deep learning techniques and large-scale training data to capture intricate features and patterns within protein sequences. By comprehensively leveraging these large language models, it is indeed possible to further enhance the performance of EnsemPPIS.</p>
    </sec>
    <sec id="sec5">
      <title>Broader applicability of EnsemPPIS using only primary sequences</title>
      <p>EnsemPPIS was also evaluated and compared on the <italic toggle="yes">GraphPPIS task</italic>, and the results can be found in Table <xref rid="supplementary-material-1" ref-type="sec">S2</xref>. Two additional methods using protein structures, namely, RGN and GraphPPIS, were reproduced and evaluated in this task. All results were calculated using the source code or web server. Several methods compared on <italic toggle="yes">DeepPPISP task</italic> were not included in the <italic toggle="yes">GraphPPIS task</italic> for comparison, such as EGRET, because they were not provided with the training source code, thus preventing their retraining. As a result, EnsemPPIS once again outperformed all sequence-based methods and even achieved better performance than some structure-based approaches. Specifically, considerable improvements in F1, AUPRC, and MCC were achieved by 7.5%, 10.3%, and 17.2%, respectively, compared with the best existing method using protein sequences. In addition, EnsemPPIS also surpassed 2 of the structure-based methods (SPPIDER and DeepPPISP) on F1, AUPRC, and MCC, but slightly lagged behind RGN and GraphPPIS.</p>
      <p>Although EnsemPPIS is inferior to RGN and GraphPPIS in the <italic toggle="yes">GraphPPIS task</italic> and only comparable to EGRET in the <italic toggle="yes">DeepPPISP task</italic>, it promises to be an indispensable tool and is applicable for the whole proteome, because it is free from the inherent limitations of structure-based methods, namely, the acute dependence on precise protein structures and the improper use of protein conformation for model training.</p>
      <p>The first limitation of structure-based methods is that the lack of experimentally validated protein structures severely limits their scope of application [<xref rid="B43" ref-type="bibr">43</xref>,<xref rid="B54" ref-type="bibr">54</xref>]. This limitation can be partially alleviated through the use of advanced protein structure prediction tools such as AlphaFold2 [<xref rid="B55" ref-type="bibr">55</xref>,<xref rid="B56" ref-type="bibr">56</xref>], RoseTTAFold [<xref rid="B57" ref-type="bibr">57</xref>], ESMFold [<xref rid="B52" ref-type="bibr">52</xref>], and RGN2 [<xref rid="B53" ref-type="bibr">53</xref>]. To investigate the impact of predicted protein structures on the performance of structure-based methods, we tested the performance of EGRET on Test70 dataset using the structures predicted by AlphaFold2. The results showed that the predictive accuracy on many proteins decreased to varying degrees while using predicted structures in place of real structures. As shown in Fig. <xref rid="F4" ref-type="fig">4</xref>A and B, the AlphaFold2 predictions were colored in orange and overlaid on the ground truth (green). AlphaFold2 made accurate predictions for 2 proteins from RCSB Protein Data Bank (PDB) (PDB: 1svdM and PDB: 2f91A), with root mean square deviation (RMSD) of 0.446 and 0.380 Å, respectively [<xref rid="B58" ref-type="bibr">58</xref>]. Unfortunately, even with predicted structures of such high accuracy (RMSD value lower than 1.0 Å [<xref rid="B55" ref-type="bibr">55</xref>]), EGRET’s predictive performance for both proteins declined significantly. As illustrated in Fig. <xref rid="F4" ref-type="fig">4</xref>C, the MCC of two proteins achieved by EGRET decreased by 0.033 and 0.044, respectively, when the predicted structures were used as input, indicating that structure-based methods are highly sensitive to slight structural errors. Notably, due to the identical protein sequence between real structure and predicted structure, EnsemPPIS was not affected by any structural errors in predicting PPI sites and outperformed EGRET on both proteins in terms of MCC (the red dashed line in Fig. <xref rid="F4" ref-type="fig">4</xref>C). Moreover, currently available protein structure prediction methods have some significant limitations, particularly regarding the prediction of structures for proteins with low homology or missense mutations [<xref rid="B59" ref-type="bibr">59</xref>–<xref rid="B64" ref-type="bibr">64</xref>]. These inaccurate protein structure predictions will seriously mislead the results of structure-based PPI sites prediction approaches.</p>
      <fig position="float" id="F4">
        <label>Fig. 4.</label>
        <caption>
          <p>The impact of predicted structures and conformational changes on the performance of structure-based methods. (A) Real structure of the protein (PDB: 1svdM) and structure predicted by AlphaFold2. (B) Real structure of the protein (PDB: 2f91A) and structure predicted by AlphaFold2. The AlphaFold2 predictions are colored in orange and overlaid on the ground truth (green). (C) Performance of EnsemPPIS and EGRET on 1svdM and 2f91A using real structures and predicted structures. Green bars represent the MCC values of EGRET using the real structures, and orange bars represent the MCC values of EGRET using the predicted structures. The red dashed lines denote the MCC values of EnsemPPIS using only primary sequences. (D) Bound (PDB: 1qa9B) and unbound conformations (PDB: 1ci5A) of the same protein (UniProt: P19256). The bound conformation is colored in green and overlaid on the unbound conformation (orange). (E) Performance of EnsemPPIS, GraphPPIS, and RGN using the bound and unbound conformations. Green bars represent the MCC values of GraphPPIS and RGN using the bound conformation, and orange bars represent the MCC values using the unbound conformation. The red dashed line denotes the MCC value of EnsemPPIS using only primary sequence.</p>
        </caption>
        <graphic xlink:href="research.0240.fig.004" position="float"/>
      </fig>
      <p>Protein conformation undergoes changes when binding with a partner [<xref rid="B44" ref-type="bibr">44</xref>,<xref rid="B65" ref-type="bibr">65</xref>,<xref rid="B66" ref-type="bibr">66</xref>], and currently available structure-based PPI sites prediction tools were typically trained using protein complex structures, which limits their accuracy and generalization ability when predicting PPI sites on unbound-form proteins [<xref rid="B35" ref-type="bibr">35</xref>]. To elaborate the second limitation of structure-based methods, we compared the predictive performance of RGN and GraphPPIS on the same protein with different conformations (i.e., bound and unbound conformations). The human lymphocyte function-associated antigen 3 (UniProt: P19256) in Test60 dataset was randomly selected as a case to conduct this analysis. As shown in Fig. <xref rid="F4" ref-type="fig">4</xref>D, the RMSD value between bound conformation (PDB: 1qa9B) and unbound conformation (PDB: 1ci5A) was 1.161 Å, and the position of α-helix (or β-sheet) in the 2 conformations was different, indicating that conformational changes indeed occurred during the binding process. As expected, both RGN and GraphPPIS presented an obvious decrease in MCC when predicting PPI sites on unbound conformation, as displayed in Fig. <xref rid="F4" ref-type="fig">4</xref>E. This suggested that models trained with complex structure information are limited in their robustness and generalization ability when making predictions on monomeric protein structures. PPI sites prediction methods that solely rely on protein sequences are not subject to the limitation of conformational changes because protein sequences remain consistent across different conformations. This offers an advantage in scenarios where accurate structural information is not readily available or when dealing with proteins with dynamic conformations. Specifically, EnsemPPIS exhibited noteworthy performance on both bound and unbound conformations, achieving the MCC value of 0.547 in both scenarios (as shown by the red dashed line in Fig. <xref rid="F4" ref-type="fig">4</xref>E). Importantly, this performance surpassed that of RGN and GraphPPIS specifically on the unbound conformation. In summary, our proposed EnsemPPIS overcomes the limitations associated with structure-based methods by solely relying on the information derived from primary protein sequences, and holds great advantages of broader applicability and stronger generalization ability.</p>
    </sec>
    <sec id="sec6">
      <title>Superior performance of EnsemPPIS in protein-level prediction</title>
      <p>(a) <italic toggle="yes">EnsemPPIS outperforms SOTA ensemble learning method</italic></p>
      <p>EnsemPPIS consistently demonstrated superior performance in predicting PPI sites at the residue level. However, it is worth noting that similar predictive methods are commonly employed for individual protein predictions in downstream research. Therefore, we further assessed the performance of EnsemPPIS in protein-level prediction on the <italic toggle="yes">DeepPPISP task</italic>. We conducted a comparative analysis between our method and the SOTA ensemble learning method DELPHI to evaluate their performance in predicting individual protein sequences from the Test70 dataset. The results of this comparison were depicted in Fig. <xref rid="F5" ref-type="fig">5</xref>. Specifically, DELPHI only learned local and global sequential features based on convolutional neural network (CNN) and recurrent neural network (RNN), respectively. As a result, EnsemPPIS achieved protein predictions with AUROC values exceeding 0.60, 0.70, and 0.80 at rates of 75.71%, 47.14%, and 15.71%, respectively (as shown in Fig. <xref rid="F5" ref-type="fig">5</xref>A), and it predicted proteins with PRE values exceeding 0.30, 0.40, and 0.50 at rates of 64.29%, 35.71%, and 22.86%, respectively (as shown in Fig. <xref rid="F5" ref-type="fig">5</xref>B). EnsemPPIS outperformed DELPHI in terms of predicting a greater number of proteins with superior AUROC or PRE values across various intervals.</p>
      <fig position="float" id="F5">
        <label>Fig. 5.</label>
        <caption>
          <p>The comparison of EnsemPPIS and DELPHI in protein-level prediction on the Test70 dataset. (A) AUROC comparison between EnsemPPIS and DELPHI. (B) PRE comparison between EnsemPPIS and DELPHI. DELPHI is the current state-of-the-art ensemble method for the prediction of PPI sites using protein sequences. The scatter plot shows the performance comparison between EnsemPPIS and DELPHI, where each scatter represents a protein sequence in the Test70 dataset. The proportions of proteins across different intervals of AUROC and PRE are noted in the table. (C) Visualization of the prediction results achieved by TransformerPPIS, EnsemPPIS, and DELPHI for a specific protein (PDB: 1jtdB). PPI sites are shown in purple, and non-PPI sites are shown in gray.</p>
        </caption>
        <graphic xlink:href="research.0240.fig.005" position="float"/>
      </fig>
      <p>To elucidate the advantage of EnsemPPIS in predicting individual proteins, 2 specific proteins (PDB: 1jtdB and PDB: 1b6cA) were randomly selected as cases to visualize the prediction results of TransformerPPIS, EnsemPPIS, and DELPHI. As shown in Fig. <xref rid="F5" ref-type="fig">5</xref>C, the PPI sites on protein 1jtdB predicted by DELPHI exhibited a relatively dispersed pattern, whereas the PPI sites predicted by TransformerPPIS were more spatially concentrated, predominantly distributed on the same surface of the protein. This indicated that TransformerPPIS might learn the local structure of protein based on its sequence and capture the information about residues close in space. Furthermore, by rotating the protein conformation, as shown at the bottom of Fig. <xref rid="F5" ref-type="fig">5</xref>C, it was obvious that EnsemPPIS further reduced the false-positive rate, thereby enhancing the predictive performance (MCC = 0.760). The visualization of the prediction results for the protein 1b6cA was depicted in Fig. <xref rid="supplementary-material-1" ref-type="sec">S1</xref>. Similar observations can be made, suggesting that EnsemPPIS attained the highest level of MCC (MCC = 0.542) while effectively managing the false-positive rate. This was attributed to the integration of GatCNNPPIS base model, which was capable of learning local sequential features.</p>
      <p>(b) <italic toggle="yes">EnsemPPIS is robust on sequences of different lengths</italic></p>
      <p>Existing sequence-based methods predominantly focused on local sequential features of residues, largely neglecting the sequence interdependency [<xref rid="B22" ref-type="bibr">22</xref>]. This oversight tended to compromise the performance of these methods when predicting long sequences due to the critical role of long-range residue interactions in the formation of PPI [<xref rid="B23" ref-type="bibr">23</xref>,<xref rid="B35" ref-type="bibr">35</xref>]. As reported by DeepPPISP, the protein length greatly impacted the predictive performance and its performance significantly deteriorated when predicting longer sequences [<xref rid="B22" ref-type="bibr">22</xref>].</p>
      <p>Therefore, we also evaluated the predictive performance of EnsemPPIS on sequences of varying lengths in the Test70 dataset. All the 70 sequences were grouped into 3 categories, namely, short length (less than 100 residues), medium length (100 to 200 residues), and long length (more than 200 residues). The number of sequences of short length, medium length, and long length was 18, 32, and 20, respectively. We evaluated EnsemPPIS on different lengths in both residue-level and protein-level prediction tasks. As illustrated in Fig. <xref rid="F6" ref-type="fig">6</xref>A, at the residue level, EnsemPPIS exhibited similar AUROCs in predicting PPI sites from sequences of varying lengths. In addition, Fig. <xref rid="F6" ref-type="fig">6</xref>B displays the distributions of each sequence AUROCs achieved by EnsemPPIS in predicting proteins from different length categories at the protein level. EnsemPPIS maintained consistent predictive performance across proteins of varying lengths (<italic toggle="yes">P</italic> &gt; 0.05) according to the Mann–Whitney <italic toggle="yes">U</italic> test [<xref rid="B67" ref-type="bibr">67</xref>]. The results indicated the robustness of EnsemPPIS in predicting proteins of different lengths, which might be attributed to the ability of TransformerPPIS in capturing long-range residue interactions from sequences.</p>
      <fig position="float" id="F6">
        <label>Fig. 6.</label>
        <caption>
          <p>Performance evaluation of EnsemPPIS on different sequence lengths in both residue-level and protein-level prediction tasks on the Test70 dataset. (A) Receiver operator characteristic curve (ROC) and AUROC of EnsemPPIS at the residue level for different sequence lengths. The yellow, green, and blue curves represent the ROC of sequences with short length (1 to 100 residues), medium length (100 to 200 residues), and long length (&gt;200 residues), respectively. (B) Distributions of each sequence AUROC achieved by EnsemPPIS at the protein level under different length categories. The box bounds the interquartile range divided by the median, with whiskers extending to 1.5 times the interquartile range. Each red star represents the mean. Each violin plot illustrates the kernel probability density, where the shaded area represents the proportion of the samples located there. The Mann–Whitney <italic toggle="yes">U</italic> test is used to perform the statistical analysis and calculate <italic toggle="yes">P</italic> values, and all <italic toggle="yes">P</italic> values are 2-sided.</p>
        </caption>
        <graphic xlink:href="research.0240.fig.006" position="float"/>
      </fig>
    </sec>
    <sec id="sec7">
      <title>Pattern analysis based on the interpretability of EnsemPPIS</title>
      <p>The black box nature of deep learning methods calls for careful investigation of interpretability [<xref rid="B68" ref-type="bibr">68</xref>–<xref rid="B70" ref-type="bibr">70</xref>]. Owing to the implementation of the self-attention mechanism, the TransformerPPIS base model of EnsemPPIS exhibited commendable interpretability. Inspired by EGRET [<xref rid="B23" ref-type="bibr">23</xref>], the residue PHE-74 on the PDB protein 1jtdB was selected for the in-depth pattern analysis based on the interpretability of TransformerPPIS. We used the Spearman rank-order correlation [<xref rid="B23" ref-type="bibr">23</xref>] to calculate the correlation coefficient between the attention scores and predicted labels of residues within different distance ranges. As shown in Table <xref rid="supplementary-material-1" ref-type="sec">S3</xref>, within the range of 5, 6, and 8 Å, the attention scores assigned to residues consistently exhibited a significant positive correlation with the predicted labels (all <italic toggle="yes">P</italic> &lt; 0.05). In the case of the 8-Å range, the correlation coefficient (<italic toggle="yes">r</italic>) was calculated to be 0.697, with a corresponding <italic toggle="yes">P</italic> value of 2.71 × 10<sup>−5</sup>. To gain further insights, we divided the residues within this range into 2 groups based on either the median of the attention scores or the predicted labels. This division allowed us to visualize the distribution of residues and examine their characteristics. As depicted in Fig. <xref rid="F7" ref-type="fig">7</xref>A and B, within the range of 8 Å, residues predicted as PPI sites (purple residues in Fig. <xref rid="F7" ref-type="fig">7</xref>A) significantly overlapped with those with higher attention scores (green residues in Fig. <xref rid="F7" ref-type="fig">7</xref>B). Figure <xref rid="F7" ref-type="fig">7</xref>C reveals that residues predicted as PPI sites had notably higher attention scores than those predicted as non-PPI sites (<italic toggle="yes">P</italic> = 1.25 × 10<sup>−4</sup>) according to the Mann–Whitney <italic toggle="yes">U</italic> test.</p>
      <fig position="float" id="F7">
        <label>Fig. 7.</label>
        <caption>
          <p>Attention analysis of residues within the 8 Å of the PPI site PHE-74 on a specific protein (PDB: 1jtdB) based on the predicted labels and the spatial distances to PHE-74. (A) Visualization of residue distribution based on their predicted labels. The predicted PPI sites are denoted in purple, and the predicted non-PPI sites are denoted in blue. (B) Visualization of residue distribution based on their attention scores. All the residues are divided into 2 groups according to the median of the attention scores. Residues with higher attention scores are shown in green, while those with lower attention scores are shown in blue. (C) Boxplot of attention scores for residues predicted as PPI sites and non-PPI sites. (D) Boxplot of attention scores for close residues and distant resides. Residues with distance less than or equal to the median value are labeled as “Close Residues,” and the remaining residues are labeled as “Distant Residues.” (E) Boxplot of residue distances for residues with high attention score and with low attention scores. Residues with attention score higher than or equal to the median value are categorized into “High Attention Score,” and the remaining residues are categorized into “Low Attention Score.” The box bounds the interquartile range divided by the median, with whiskers extending to 1.5 times the interquartile range. Each red star represents the mean value. The Mann–Whitney <italic toggle="yes">U</italic> test is used to perform the statistical analysis and calculate the <italic toggle="yes">P</italic> value.</p>
        </caption>
        <graphic xlink:href="research.0240.fig.007" position="float"/>
      </fig>
      <p>PPI sites are relatively aggregated in protein structures, and local structural features play a crucial role in the formation of PPI. This implies that the interactions among residues within local structures play a crucial role in predicting PPI sites, and therefore, structure-based methods conduct the prediction by learning the features from spatially proximate amino acids [<xref rid="B35" ref-type="bibr">35</xref>]. However, spatially close residues may be distant in sequence. This poses a challenge for existing sequence-based methods, as they primarily emphasize the local sequential features of PPI sites. Consequently, capturing long-range residue interactions becomes difficult within the framework of these methods. In this study, the TransformerPPIS module was able to extract residue interactions including long-range interactions based on primary sequences. Again, take the residue PHE-74 as an example, its surrounding residues within the 8-Å range can be divided into 2 groups according to their distances to PHE-74 or attention scores. Specifically, we first defined the residue distance based on the average distance of all atoms between 2 residues. A total of 15 residues with distance less than or equal to the median value were grouped into “Close Residues,” while the remaining 14 residues were grouped into “Distant Residues.” The Mann–Whitney <italic toggle="yes">U</italic> test was then employed to examine the significant difference of the attention scores between these 2 groups. As illustrated in Fig. <xref rid="F7" ref-type="fig">7</xref>D, the <italic toggle="yes">P</italic> value was 0.0386, indicating that the attention scores of “Close Residues” were significantly higher than those of “Distant Residues.” Similarly, these residues were classified into another 2 groups, namely, “High Attention Score” and “Low Attention Score,” based on the median of their attention scores. As shown in Fig. <xref rid="F7" ref-type="fig">7</xref>E, the <italic toggle="yes">P</italic> value was 0.0351, which implied that residues with higher attention scores were spatially closer in local structure, but might be far apart in sequence. This pattern analysis suggested that residues closer in local space contributed more to the formation of PPI sites, which corroborated the fact that residues closer in space interact more significantly [<xref rid="B71" ref-type="bibr">71</xref>].</p>
      <p>In summary, these findings highlighted that the TransformerPPIS base model within EnsemPPIS is fully capable of learning residue interactions, particularly the long-range interactions within the local structure of PPI sites using only primary sequences. This capability allows the model to extract meaningful connections between protein sequences and structures, ultimately leading to improved performance in predicting PPI sites.</p>
    </sec>
    <sec id="sec8">
      <title>Availability of EnsemPPIS web server</title>
      <p>A web server that implements EnsemPPIS was constructed in this study, which is convenient for researchers to apply our proposed PPI sites prediction method. The EnsemPPIS server was deployed on a Linux server of an Intel Xeon Gold 6149 3.10GHz CPU with 8 cores and 64 GB of memory based on the Python web framework of Django. As an open online platform, all users could freely access it through popular web browsers, including Google Chrome, Mozilla Firefox, Safari, and Internet Explorer 10 (or later).</p>
      <p>EnsemPPIS requires only the FASTA-formatted protein sequences as input, and users should set a project name to associate their PPI sites prediction task. After successful submission, the information necessary to schedule the task would be placed into a MySQL database. Users could find their submitted project displayed on the “Queue” page of the web server. Clicking on the corresponding task information bar will redirect users to the program processing page, which offers 2 key functions: (a) encoding the input protein sequences using the pretrained ProtBERT and providing a downloadable <italic toggle="yes">pickle</italic> file containing the embedding vectors; (b) identifying potential PPI sites on all protein sequences and making a downloadable text file containing the prediction results. EnsemPPIS is freely available at <ext-link xlink:href="http://idrblab.org/ensemppis" ext-link-type="uri">http://idrblab.org/ensemppis</ext-link>.</p>
    </sec>
  </sec>
  <sec id="sec9">
    <title>Conclusion</title>
    <p>In this study, to improve the accuracy of PPI sites prediction and expand the application scope, a novel transformer-based ensemble learning method for PPI sites prediction, EnsemPPIS, was proposed, which incorporated 2 base models, namely, TransformerPPIS and GatCNNPPIS. EnsemPPIS was designed to extract residue interactions by leveraging the transformer and integrate global and local sequential features through ensemble learning. EnsemPPIS exhibited leading performance across multiple tasks, surpassing all existing sequence-based prediction methods and demonstrating its broader applicability in comparison to structure-based methods. Additionally, EnsemPPIS exhibited superior and robust performance in both residue-level and protein-level prediction tasks. Moreover, pattern analysis based on the interpretability of EnsemPPIS revealed its ability to learn residue interactions directly from protein sequences. EnsemPPIS is expected to facilitate in-depth understanding of molecular biology and advance research of drug discovery.</p>
  </sec>
  <sec id="sec10">
    <title>Materials and Methods</title>
    <sec id="sec11">
      <title>Benchmark datasets and evaluation metrics</title>
      <p>In this study, the performance of our proposed EnsemPPIS was comprehensively assessed on 3 PPI sites prediction tasks, including <italic toggle="yes">DeepPPISP task</italic> [<xref rid="B22" ref-type="bibr">22</xref>], <italic toggle="yes">GraphPPIS task</italic> [<xref rid="B35" ref-type="bibr">35</xref>], and <italic toggle="yes">DELPHI task</italic> [<xref rid="B34" ref-type="bibr">34</xref>]. The basic information about the datasets used in the 3 tasks is described below, and Table <xref rid="supplementary-material-1" ref-type="sec">S1</xref> provides the statistics of these datasets.</p>
      <sec id="sec12">
        <title>(a) <italic toggle="yes">DeepPPISP task</italic></title>
        <p>The Train352 and Test70 datasets used in the <italic toggle="yes">DeepPPISP task</italic> were obtained from DeepPPISP [<xref rid="B22" ref-type="bibr">22</xref>]. The DeepPPISP dataset was generated by combining 3 widely used benchmark datasets, namely, Dset_186 [<xref rid="B72" ref-type="bibr">72</xref>], Dset_72 [<xref rid="B72" ref-type="bibr">72</xref>], and PDBset_164 [<xref rid="B22" ref-type="bibr">22</xref>], each collected from the PDB database [<xref rid="B73" ref-type="bibr">73</xref>] and built through a data filtering process involving 6 steps [<xref rid="B72" ref-type="bibr">72</xref>]. In total, there were 422 protein sequences in the DeepPPISP dataset, each with the resolution less than 3.0 Å and sequence homology lower than 25%. A surface amino acid was defined as a PPI site if its absolute solvent accessibility decreases by at least 1.0 Å<sup>2</sup> upon protein binding [<xref rid="B74" ref-type="bibr">74</xref>]. For a fair comparison, we used the same data splitting scheme as DeepPPISP [<xref rid="B22" ref-type="bibr">22</xref>]. Thus, the training dataset Train352 contained 352 protein sequences and the independent test dataset Test70 was composed of 70 protein sequences. A subset of Train352 with 50 hold-out proteins is further randomly selected to form the validation dataset. As a result, there were 302 proteins in the training dataset, 50 proteins in the validation dataset, and 70 proteins in the test dataset.</p>
      </sec>
      <sec id="sec13">
        <title>(b) <italic toggle="yes">GraphPPIS task</italic></title>
        <p>The Train335 and Test60 datasets used in the <italic toggle="yes">GraphPPIS task</italic> were originally constructed by GraphPPIS and were also obtained by integrating the 3 datasets mentioned above (Dset_186, Dset_72, and PDBset_164) [<xref rid="B35" ref-type="bibr">35</xref>]. After the fusion of 3 benchmark datasets, BLASTClust [<xref rid="B75" ref-type="bibr">75</xref>] was further applied to remove protein sequences with similarities over 25%, leaving 395 nonredundant proteins. Subsequently, 335 proteins were randomly picked as the training data (Train335), and the remaining 60 proteins were used as the independent test data (Test60). To ensure a fair comparison, the Train335 and Test60 datasets used in this study were consistent with those used by GraphPPIS.</p>
      </sec>
      <sec id="sec14">
        <title>(c) <italic toggle="yes">DELPHI task</italic></title>
        <p>The Train9982 and Test355 datasets in <italic toggle="yes">DELPHI task</italic> were collected by DELPHI, a recent research of PPI sites prediction using sequences [<xref rid="B34" ref-type="bibr">34</xref>]. The Test355 dataset was a subset of Dset_448 dataset [<xref rid="B32" ref-type="bibr">32</xref>], which was built based on the BioLip database [<xref rid="B76" ref-type="bibr">76</xref>] and consisted of 448 nonredundant proteins with pairwise similarities lower than 25%. In the Dset_448 dataset, the interaction sites in a protein complex were defined as the residues to which 2 atoms belonged, based on a distance criterion. Specifically, if the distance between 2 atoms from different chains was found to be less than 0.5 Å plus the sum of their Van der Waals radii, these residues were identified as interacting sites. To ensure the comparability with another competing method named DLPred [<xref rid="B77" ref-type="bibr">77</xref>], the developers of DELPHI removed 93 proteins sharing similarities above 40% with any sequences in DLPred’s training dataset, and then constructed the Test355 dataset. To obtain the Train9982 dataset, the developers collected a large dataset from a previous study [<xref rid="B78" ref-type="bibr">78</xref>] and used PSI-CD-HIT [<xref rid="B79" ref-type="bibr">79</xref>] to remove sequences sharing similarities over 25% with any sequences in the Test355, followed by the removal of sequences with similarities above 25% among the remaining proteins. Among 9,982 sequences in the Train9982 dataset, 1,110 sequences were randomly selected to compose the validation dataset and the remaining sequences were utilized to train the model. It is important to note that the Train9982 dataset cannot be applied directly to train structure-based PPI sites prediction methods for the lack of structural information. Therefore, several methods using only sequences were evaluated in this task.</p>
        <p>The prediction of PPI sites is essentially a binary classification task. In this study, the interaction sites were taken as positive samples and non-interaction sites as negative samples. To fully evaluate the performance of EnsemPPIS and other competing methods, 7 widely used evaluation metrics were adopted in this study, including accuracy (ACC), precision (PRE), recall (REC), F1-score (F1), Matthews correlation coefficient (MCC), area under the receiver operator characteristic curve (AUROC), and area under the precision–recall curve (AUPRC). All metrics were calculated using the Scikit-learn package [<xref rid="B80" ref-type="bibr">80</xref>], and the formulas for computing these metrics were provided in Supplementary Methods. Serious data imbalance is reported to be a significant characteristic of PPI sites datasets, making MCC, F1, and AUPRC the most important and comprehensive indicators as they can emphasize more on the minority class [<xref rid="B22" ref-type="bibr">22</xref>,<xref rid="B81" ref-type="bibr">81</xref>,<xref rid="B82" ref-type="bibr">82</xref>].</p>
      </sec>
    </sec>
    <sec id="sec15">
      <title>Deep learning architecture of EnsemPPIS</title>
      <p>To convert protein sequences into embeddings, the pretrained protein language model, ProtBERT, was used to generate an <italic toggle="yes">L</italic> × 1,024 matrix for each protein sequence, where <italic toggle="yes">L</italic> is the sequence length and each amino acid is represented by a 1,024 embedding vector. ProtBERT is a BERT model pretrained on UniRef100 through self-supervised learning, which can capture biophysical features of protein sequences [<xref rid="B48" ref-type="bibr">48</xref>,<xref rid="B82" ref-type="bibr">82</xref>,<xref rid="B83" ref-type="bibr">83</xref>]. The embeddings of proteins were further passed to the 2 base models of EnsemPPIS, namely, TransformerPPIS and GatCNNPPIS. Inspired by the great ability of transformer in extracting sequence features, the novel TransformerPPIS was proposed for predicting PPI sites using the modified transformer. The architecture of TransformerPPIS, as shown in Fig. <xref rid="F2" ref-type="fig">2</xref>, consists of 3 modules: the encoder, the decoder, and the classifier module.</p>
      <sec id="sec16">
        <title>(a) <italic toggle="yes">Encoder module</italic></title>
        <p>In contrast to the original transformer framework, the encoder of TransformerPPIS uses a gated convolutional network with Conv1D and gated linear unit in place of the self-attention layers [<xref rid="B84" ref-type="bibr">84</xref>]. Conv1D mainly captures the contextual representation of residues with local biases and learns the global protein features by assembling local features of all residues. The gated linear unit can enhance the network's capacity to process nonlinear information and extract more informative representations from proteins. The sequence embedding of a protein is first converted into an <italic toggle="yes">L</italic> × 64 matrix using the FC and then fed into the gated convolutional network. The hidden layers <italic toggle="yes">h</italic><sub>0</sub>, …, <italic toggle="yes">h<sub>l</sub></italic> in the gated convolutional network are computed as <xref rid="EQ1" ref-type="disp-formula">Eq. 1</xref>:<disp-formula id="EQ1"><mml:math id="M1" display="block" overflow="scroll"><mml:msub><mml:mi>h</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:mfenced open="(" close=")"><mml:mi mathvariant="bold-italic">X</mml:mi></mml:mfenced><mml:mo>=</mml:mo><mml:mfenced open="(" close=")"><mml:mrow><mml:mi mathvariant="bold-italic">X</mml:mi><mml:mo>∗</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">b</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mfenced><mml:mo>⊗</mml:mo><mml:mi>σ</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:mi mathvariant="bold-italic">X</mml:mi><mml:mo>∗</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">b</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mfenced></mml:math><label>(1)</label></disp-formula></p>
        <p>where <bold><italic toggle="yes">X</italic></bold> ∈ <italic toggle="yes">ℝ</italic><sup><italic toggle="yes">n</italic>×<italic toggle="yes">m</italic><sub>1</sub></sup> is the input of layer <italic toggle="yes">h<sub>l</sub></italic>; <bold><italic toggle="yes">W</italic></bold><sub>1</sub> ∈ <italic toggle="yes">ℝ</italic><sup><italic toggle="yes">k</italic>×<italic toggle="yes">m</italic><sub>1</sub>×<italic toggle="yes">m</italic><sub>2</sub></sup>, <bold><italic toggle="yes">W</italic></bold><sub>2</sub> ∈ <italic toggle="yes">ℝ</italic><sup><italic toggle="yes">k</italic>×<italic toggle="yes">m</italic><sub>1</sub>×<italic toggle="yes">m</italic><sub>2</sub></sup>, <italic toggle="yes">b</italic><sub>1</sub> ∈ <italic toggle="yes">ℝ</italic><sup><italic toggle="yes">m</italic><sub>2</sub></sup>, and <italic toggle="yes">b</italic><sub>2</sub> ∈ <italic toggle="yes">ℝ</italic><sup><italic toggle="yes">m</italic><sub>2</sub></sup> are trainable parameters; <italic toggle="yes">l</italic> is the number of encoder layers; <italic toggle="yes">n</italic> is the length of the sequence; <italic toggle="yes">m</italic><sub>1</sub> and <italic toggle="yes">m</italic><sub>2</sub> are the dimension of input and hidden features of the gated convolutional network, respectively; <italic toggle="yes">k</italic> is the kernel size of Conv1D; <italic toggle="yes">σ</italic> is the sigmoid function; and ⨂ represents the element-wise product between matrices [<xref rid="B84" ref-type="bibr">84</xref>]. In this study, <italic toggle="yes">l</italic> is 3, <italic toggle="yes">m</italic><sub>1</sub> is 64, <italic toggle="yes">m</italic><sub>2</sub> is 128, and <italic toggle="yes">k</italic> is 7. The encoder module adopts residual connection and layer normalization to solve the oversmoothing problem [<xref rid="B85" ref-type="bibr">85</xref>]. The output of encoder, an <italic toggle="yes">L</italic> × 64 matrix, is the final representation of a protein.</p>
      </sec>
      <sec id="sec17">
        <title>(b) <italic toggle="yes">Decoder module</italic></title>
        <p>The decoder module of TransformerPPIS is specifically designed to learn and capture residue interactions within protein sequences. The input of decoder module contains 2 parts: the global feature of the protein output by the encoder module and the original embedding of a specific residue obtained by ProtBERT. The decoder module mainly consists of multi-head self-attention layers and feedforward layers. The multi-head self-attention layer extracts the interactions between the specific residue and other residues, which takes 3 inputs: the queries, <bold><italic toggle="yes">Q</italic></bold>; the keys, <bold><italic toggle="yes">K</italic></bold>; and the values, <bold><italic toggle="yes">V</italic></bold> [<xref rid="B86" ref-type="bibr">86</xref>,<xref rid="B87" ref-type="bibr">87</xref>]. TransformerPPIS regards the residue embedding as <bold><italic toggle="yes">Q</italic></bold> and the global protein feature as <bold><italic toggle="yes">K</italic></bold> and <bold><italic toggle="yes">V</italic></bold>, and calculates the attention weight using <bold><italic toggle="yes">Q</italic></bold> and <bold><italic toggle="yes">K</italic></bold>. The calculation formula is as follows:<disp-formula id="EQ2"><mml:math id="M2" display="block" overflow="scroll"><mml:mtext>attention</mml:mtext><mml:mfenced open="(" close=")"><mml:mrow><mml:mi mathvariant="bold-italic">Q</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">K</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">V</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mtext>softmax</mml:mtext><mml:mfenced open="(" close=")"><mml:mrow><mml:mfrac><mml:mrow><mml:mi mathvariant="bold-italic">Q</mml:mi><mml:msup><mml:mi mathvariant="bold-italic">K</mml:mi><mml:mi mathvariant="normal">T</mml:mi></mml:msup></mml:mrow><mml:msqrt><mml:msub><mml:mi>d</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:msqrt></mml:mfrac></mml:mrow></mml:mfenced><mml:mi mathvariant="bold-italic">V</mml:mi></mml:math><label>(2)</label></disp-formula></p>
        <p>where <italic toggle="yes">d<sub>k</sub></italic> is a scaling factor depending on the dimension of the hidden layer. The mask operation in the original transformer framework is modified in the decoder module to ensure that the complete sequence information is accessible. Accurately identifying PPI sites necessitates careful attention to the features of the local structure surrounding these sites [<xref rid="B40" ref-type="bibr">40</xref>]. However, residues that are spatially close may be far apart in sequence due to the intricate folding patterns and 3-dimensional arrangement of protein structures. The self-attention mechanism employed in TransformerPPIS empowers the model to effectively capture the interactions between remote residues in a protein sequence. Another major component of decoder module is the feedforward layer, which improves the expressiveness of features by nonlinear transformation [<xref rid="B88" ref-type="bibr">88</xref>]. After each self-attention layer and feedforward layer, the residual connection and layer normalization are used.</p>
      </sec>
      <sec id="sec18">
        <title>(c) <italic toggle="yes">Classifier module</italic></title>
        <p>The output of decoder module is the interaction feature between the specific residue and the global protein sequence. The interaction feature vector is further fed to the classifier module, which is composed of 3 FCs and the ReLU activation function [<xref rid="B89" ref-type="bibr">89</xref>]. Finally, the probability of a residue being a PPI site is calculated by the softmax function.</p>
        <p>The GatCNNPPIS base model presented here can be viewed as a simplified version of TransformerPPIS, consisting solely of the encoder and the classifier modules. In the output of the encoder module (the <italic toggle="yes">L</italic> × 64 matrix), each vector represents the local contextual feature of a particular residue. GatCNNPPIS takes this vector as input and directly feeds it into the classifier module, which outputs the probability of the corresponding residue being an interaction site.</p>
      </sec>
    </sec>
    <sec id="sec19">
      <title>Model training and hyperparameter tuning</title>
      <p>The classification of PPI sites poses a challenge due to the inherent imbalance in the dataset. After the softmax function normalized the output of the network into the probability over the 2 classes (interaction site and non-interaction site), the weighted cross-entropy loss function was adopted to compute the loss values of samples, which were subsequently used to calculate the gradient of parameter update in the backward propagation process [<xref rid="B90" ref-type="bibr">90</xref>]. The weighted cross-entropy loss function assigned different class weights to positive and negative samples, allowing the model to prioritize the minority class and allocate more attention to its predictions. During model training, the ratio between the weights of positive and negative samples was determined based on the model’s performance on the validation dataset. Specifically, in the <italic toggle="yes">DeepPPISP task</italic> and <italic toggle="yes">GraphPPIS task</italic>, the weight ratio was set to 5:1, while in the <italic toggle="yes">DELPHI task</italic>, it was set to 3:1. The LookAhead optimizer and RAdam optimizer were used during the training process [<xref rid="B91" ref-type="bibr">91</xref>]. In each PPI sites prediction task, the EnsemPPIS used the same training scheme as that of the competing method [<xref rid="B22" ref-type="bibr">22</xref>,<xref rid="B34" ref-type="bibr">34</xref>,<xref rid="B35" ref-type="bibr">35</xref>]. Specifically, in the <italic toggle="yes">DeepPPISP task</italic> and <italic toggle="yes">DELPHI task</italic>, the training dataset was used to train EnsemPPIS, and the validation dataset was used to evaluate the predictive performance and optimize the hyperparameters, followed by the assessment and report of the performance of the best model on the independent test dataset. In the <italic toggle="yes">GraphPPIS task</italic>, the 5-fold cross-validation was performed on the training dataset to avoid the influence of random errors, that is, all proteins in the Train335 dataset were randomly divided into 5 folds. Among these 5 folds, 4 folds were utilized to train EnsemPPIS and the remaining fold served as the validation dataset to evaluate the model. This procedure was repeated 5 times, with each fold serving as the validation dataset. The average of the 5 evaluation results was then calculated to obtain the overall evaluation result. Based on this result, the best hyperparameters were selected. When the hyperparameters were determined, the final model was trained using all training data and evaluated on the independent test dataset. The early stopping strategy was applied to reduce overfitting and training cost [<xref rid="B92" ref-type="bibr">92</xref>–<xref rid="B94" ref-type="bibr">94</xref>]. In order to facilitate the convergence of training and improve the capacity of generalization, regularization methods including dropout and weight decay were used during training EnsemPPIS [<xref rid="B95" ref-type="bibr">95</xref>–<xref rid="B97" ref-type="bibr">97</xref>].</p>
      <p>As an ensemble learning framework, the 2 base models of EnsemPPIS (TransformerPPIS and GatCNNPPIS) were separately trained using the same training procedure. To optimize EnsemPPIS, we selected the optimal combinations of base models [<xref rid="B98" ref-type="bibr">98</xref>]. After the completion of model training, the 2 saved models were loaded for individual prediction of PPI sites. In addition, we constructed 2 variants of EnsemPPIS to evaluate the outcomes achieved by combining the 2 base models into a single model for concurrent training. The architectures of the 2 variants were depicted in Fig. <xref rid="F3" ref-type="fig">3</xref>A and B. Specifically, in the first variant of EnsemPPIS (EnsemPPIS-Va), the output of TransformerPPIS’s decoder and the output of GatCNNPPIS’s encoder were concatenated. The concatenated vector was then fed into multiple FCs to obtain the probability of being PPI site. In the second variant (EnsemPPIS-Vb), the output of TransformerPPIS’s decoder and the output of GatCNNPPIS’s encoder were separately passed through 3 FCs. The resulting 2-dimensional vectors were then concatenated, and the concatenated 4-dimensional vector was further processed through an FC to obtain the predicted probability. The output of each variant was utilized to calculate the loss for jointly updating the parameters of the 2 base models.</p>
      <p>Three most influential hyperparameters (batch size, learning rate, and dropout rate) were tuned according to the predictive performance on the validation dataset. As a result, the optimal combination of the above 3 hyperparameters was decided (batch size = 128, learning rate = 0.0005, dropout rate = 0.1). All the hyperparameter settings of EnsemPPIS were summarized in Table <xref rid="supplementary-material-1" ref-type="sec">S4</xref>. EnsemPPIS was implemented with Pytorch 1.2.0 (<ext-link xlink:href="http://pytorch.org/" ext-link-type="uri">http://pytorch.org/</ext-link>) and supported distributed training [<xref rid="B99" ref-type="bibr">99</xref>]. All scripts were written by Python 3.7.11, and all models were developed on the computer with Intel Xeon Gold 6132 CPU @ 2.60GHz, NVIDIA Tesla P100 16GB GPU and 263GB RAM on CentOS Linux release 7.9.2009 (Core).</p>
    </sec>
    <sec id="sec20">
      <title>A variety of methods compared with EnsemPPIS</title>
      <p>A comprehensive review on the previously published tools for PPI sites prediction was conducted in this study, which were systematically compared with our proposed EnsemPPIS, as shown in Table <xref rid="supplementary-material-1" ref-type="sec">S5</xref>. These methods can be grouped into sequence-based and structure-based depending on whether the protein structural information is used. Sequence-based methods include ISIS [<xref rid="B100" ref-type="bibr">100</xref>], PSIVER [<xref rid="B72" ref-type="bibr">72</xref>], SPRINGS [<xref rid="B31" ref-type="bibr">31</xref>], RF_PPI [<xref rid="B27" ref-type="bibr">27</xref>], SCRIBER [<xref rid="B32" ref-type="bibr">32</xref>], DELPHI [<xref rid="B34" ref-type="bibr">34</xref>], ProNA2020 [<xref rid="B33" ref-type="bibr">33</xref>], and DLPred [<xref rid="B77" ref-type="bibr">77</xref>]. SCRIBER used a 2-layer architecture to perform partner type-specific prediction of protein-binding residues [<xref rid="B32" ref-type="bibr">32</xref>]. ProNA2020 utilized the combination of homology-based inference and machine learning methods to predict protein-macromolecular binding residues using only protein sequences [<xref rid="B33" ref-type="bibr">33</xref>]. DELPHI was the SOTA sequence-based method that used 12 feature groups to encode proteins, and incorporated CNN and RNN with the ensemble learning strategy to enhance its predictive performance [<xref rid="B34" ref-type="bibr">34</xref>]. Structure-based methods include SPPIDER [<xref rid="B28" ref-type="bibr">28</xref>], IntPred [<xref rid="B21" ref-type="bibr">21</xref>], DeepPPISP [<xref rid="B22" ref-type="bibr">22</xref>], EGRET [<xref rid="B23" ref-type="bibr">23</xref>], GraphPPIS [<xref rid="B35" ref-type="bibr">35</xref>], and RGN [<xref rid="B40" ref-type="bibr">40</xref>]. DeepPPISP proposed an end to end deep learning model, which used CNN to combine local contextual and global features for PPI sites prediction [<xref rid="B22" ref-type="bibr">22</xref>]. EGRET constructed an edge aggregated graph attention network to effectively leverage protein structural information [<xref rid="B23" ref-type="bibr">23</xref>]. GraphPPIS employed evolutionary information and structural properties of amino acids to train the deep convolutional network for the prediction of PPI sites [<xref rid="B35" ref-type="bibr">35</xref>]. RGN applied PSSM, hidden Markov model, hydrogen bond estimation algorithm, and ProtBERT for node representation and constructed a residue-based graph attention and convolutional network [<xref rid="B40" ref-type="bibr">40</xref>].</p>
    </sec>
  </sec>
</body>
<back>
  <ack>
    <title>Acknowledgments</title>
    <p><bold>Funding:</bold> This work was supported by the National Natural Science Foundation of China (82373790, U1909208, 22220102001, and 81872798), Natural Science Foundation of Zhejiang Province (LR21H300001), Leading Talent of the “Ten Thousand Plan”—National High-Level Talents Special Supports Plan of China, National Key R&amp;D Program of China (2022YFC3400501), Key R&amp;D Program of Zhejiang Province (2020C03010), “Double Top-Class” Universities Projects (181201*194232101), Fundamental Research Funds for Central University (2018QNA7023), Alibaba-Zhejiang University Joint Research Center Future Digital Healthcare, Westlake Laboratory (Westlake Laboratory of Life Science &amp; Biomedicine), Alibaba Cloud, and Information Technology Center of Zhejiang University. Funds for the open access charge: Natural Science Foundation of Zhejiang Province (LR21H300001). <bold>Author contributions:</bold> M.M., Z.P., and F.Z. conceptualized ideas, proposed methods, and wrote the manuscript. M.M. investigated and implemented the deep learning programs. Z.Z. and F.L. constructed the web server. L.Z., H.Z., S.S., and X.S. completed the data collection. All authors have read and approved the final manuscript. <bold>Competing interests:</bold> The authors declare that they have no competing interests.</p>
  </ack>
  <sec sec-type="data-availability">
    <title>Data Availability</title>
    <p>The EnsemPPIS web server is freely available at <ext-link xlink:href="http://idrblab.org/ensemppis" ext-link-type="uri">http://idrblab.org/ensemppis</ext-link>, with all source codes and benchmark datasets in this study. The trained models and the EnsemPPIS standalone source code can be found at <ext-link xlink:href="https://github.com/idrblab/EnsemPPIS" ext-link-type="uri">https://github.com/idrblab/EnsemPPIS</ext-link>.</p>
  </sec>
  <sec sec-type="supplementary-material" id="supplementary-material-1">
    <title>Supplementary Materials</title>
    <supplementary-material id="supp-1" position="float" content-type="local-data">
      <label>Supplementary 1</label>
      <caption>
        <p>Methods</p>
        <p>Tables S1 to S5</p>
        <p>Fig. S1</p>
        <p>References</p>
      </caption>
      <media xlink:href="research.0240.f1.docx">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
  <ref-list>
    <title>References</title>
    <ref id="B1">
      <label>1.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kim</surname><given-names>M</given-names></string-name>, <string-name><surname>Park</surname><given-names>J</given-names></string-name>, <string-name><surname>Bouhaddou</surname><given-names>M</given-names></string-name>, <string-name><surname>Kim</surname><given-names>K</given-names></string-name>, <string-name><surname>Rojc</surname><given-names>A</given-names></string-name>, <string-name><surname>Modak</surname><given-names>M</given-names></string-name>, <string-name><surname>Soucheray</surname><given-names>M</given-names></string-name>, <string-name><surname>McGregor</surname><given-names>MJ</given-names></string-name>, <string-name><surname>O'Leary</surname><given-names>P</given-names></string-name>, <string-name><surname>Wolf</surname><given-names>D</given-names></string-name>, <etal>et al.</etal></person-group><article-title>A protein interaction landscape of breast cancer</article-title>. <source><italic toggle="yes">Science</italic></source>. <year>2021</year>;<volume>374</volume>(<issue>6563</issue>):<fpage>eabf3066</fpage>.<pub-id pub-id-type="pmid">34591612</pub-id></mixed-citation>
    </ref>
    <ref id="B2">
      <label>2.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fessenden</surname><given-names>M</given-names></string-name></person-group>. 
<article-title>Protein maps chart the causes of disease</article-title>. <source><italic toggle="yes">Nature</italic></source>. <year>2017</year>;<volume>549</volume>(<issue>7671</issue>):<fpage>293</fpage>–<lpage>295</lpage>.<pub-id pub-id-type="pmid">28905898</pub-id></mixed-citation>
    </ref>
    <ref id="B3">
      <label>3.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Batra</surname><given-names>J</given-names></string-name>, <string-name><surname>Hultquist</surname><given-names>JF</given-names></string-name>, <string-name><surname>Liu</surname><given-names>D</given-names></string-name>, <string-name><surname>Shtanko</surname><given-names>O</given-names></string-name>, <string-name><surname>Von Dollen</surname><given-names>J</given-names></string-name>, <string-name><surname>Satkamp</surname><given-names>L</given-names></string-name>, <string-name><surname>Jang</surname><given-names>GM</given-names></string-name>, <string-name><surname>Luthra</surname><given-names>P</given-names></string-name>, <string-name><surname>Schwarz</surname><given-names>TM</given-names></string-name>, <string-name><surname>Small</surname><given-names>GI</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Protein interaction mapping identifies RBBP6 as a negative regulator of Ebola virus replication</article-title>. <source><italic toggle="yes">Cell</italic></source>. <year>2018</year>;<volume>175</volume>(<issue>7</issue>):<fpage>1917</fpage>–<lpage>1930 e1913</lpage>.<pub-id pub-id-type="pmid">30550789</pub-id></mixed-citation>
    </ref>
    <ref id="B4">
      <label>4.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wojtowicz</surname><given-names>WM</given-names></string-name>, <string-name><surname>Vielmetter</surname><given-names>J</given-names></string-name>, <string-name><surname>Fernandes</surname><given-names>RA</given-names></string-name>, <string-name><surname>Siepe</surname><given-names>DH</given-names></string-name>, <string-name><surname>Eastman</surname><given-names>CL</given-names></string-name>, <string-name><surname>Chisholm</surname><given-names>GB</given-names></string-name>, <string-name><surname>Cox</surname><given-names>S</given-names></string-name>, <string-name><surname>Klock</surname><given-names>H</given-names></string-name>, <string-name><surname>Anderson</surname><given-names>PW</given-names></string-name>, <string-name><surname>Rue</surname><given-names>SM</given-names></string-name>, <etal>et al.</etal></person-group><article-title>A human IgSF cell-surface Interactome reveals a complex network of protein-protein interactions</article-title>. <source><italic toggle="yes">Cell</italic></source>. <year>2020</year>;<volume>182</volume>(<issue>4</issue>):<fpage>1027</fpage>–<lpage>1043</lpage>.<pub-id pub-id-type="pmid">32822567</pub-id></mixed-citation>
    </ref>
    <ref id="B5">
      <label>5.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Stelzl</surname><given-names>U</given-names></string-name>, <string-name><surname>Worm</surname><given-names>U</given-names></string-name>, <string-name><surname>Lalowski</surname><given-names>M</given-names></string-name>, <string-name><surname>Haenig</surname><given-names>C</given-names></string-name>, <string-name><surname>Brembeck</surname><given-names>FH</given-names></string-name>, <string-name><surname>Goehler</surname><given-names>H</given-names></string-name>, <string-name><surname>Stroedicke</surname><given-names>M</given-names></string-name>, <string-name><surname>Zenkner</surname><given-names>M</given-names></string-name>, <string-name><surname>Schoenherr</surname><given-names>A</given-names></string-name>, <string-name><surname>Koeppen</surname><given-names>S</given-names></string-name>, <etal>et al.</etal></person-group><article-title>A human protein-protein interaction network: A resource for annotating the proteome</article-title>. <source><italic toggle="yes">Cell</italic></source>. <year>2005</year>;<volume>122</volume>(<issue>6</issue>):<fpage>957</fpage>–<lpage>968</lpage>.<pub-id pub-id-type="pmid">16169070</pub-id></mixed-citation>
    </ref>
    <ref id="B6">
      <label>6.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hamdi</surname><given-names>A</given-names></string-name>, <string-name><surname>Colas</surname><given-names>P</given-names></string-name></person-group>. 
<article-title>Yeast two-hybrid methods and their applications in drug discovery</article-title>. <source><italic toggle="yes">Trends Pharmacol Sci</italic></source>. <year>2012</year>;<volume>33</volume>(<issue>2</issue>):<fpage>109</fpage>–<lpage>118</lpage>.<pub-id pub-id-type="pmid">22130009</pub-id></mixed-citation>
    </ref>
    <ref id="B7">
      <label>7.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname><given-names>J</given-names></string-name>, <string-name><surname>Lisanza</surname><given-names>S</given-names></string-name>, <string-name><surname>Juergens</surname><given-names>D</given-names></string-name>, <string-name><surname>Tischer</surname><given-names>D</given-names></string-name>, <string-name><surname>Watson</surname><given-names>JL</given-names></string-name>, <string-name><surname>Castro</surname><given-names>KM</given-names></string-name>, <string-name><surname>Ragotte</surname><given-names>R</given-names></string-name>, <string-name><surname>Saragovi</surname><given-names>A</given-names></string-name>, <string-name><surname>Milles</surname><given-names>LF</given-names></string-name>, <string-name><surname>Baek</surname><given-names>M</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Scaffolding protein functional sites using deep learning</article-title>. <source><italic toggle="yes">Science</italic></source>. <year>2022</year>;<volume>377</volume>(<issue>6604</issue>):<fpage>387</fpage>–<lpage>394</lpage>.<pub-id pub-id-type="pmid">35862514</pub-id></mixed-citation>
    </ref>
    <ref id="B8">
      <label>8.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Qi</surname><given-names>R</given-names></string-name>, <string-name><surname>Zou</surname><given-names>Q</given-names></string-name></person-group>. 
<article-title>Trends and potential of machine learning and deep learning in drug study at single-cell level</article-title>. <source><italic toggle="yes">Research (Wash D C)</italic></source>. <year>2023</year>;<volume>6</volume>:<fpage>0050</fpage>.<pub-id pub-id-type="pmid">36930772</pub-id></mixed-citation>
    </ref>
    <ref id="B9">
      <label>9.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Liu</surname><given-names>X</given-names></string-name>, <string-name><surname>Salokas</surname><given-names>K</given-names></string-name>, <string-name><surname>Weldatsadik</surname><given-names>RG</given-names></string-name>, <string-name><surname>Gawriyski</surname><given-names>L</given-names></string-name>, <string-name><surname>Varjosalo</surname><given-names>M</given-names></string-name></person-group>. 
<article-title>Combined proximity labeling and affinity purification-mass spectrometry workflow for mapping and visualizing protein interaction networks</article-title>. <source><italic toggle="yes">Nat Protoc</italic></source>. <year>2020</year>;<volume>15</volume>(<issue>10</issue>):<fpage>3182</fpage>–<lpage>3211</lpage>.<pub-id pub-id-type="pmid">32778839</pub-id></mixed-citation>
    </ref>
    <ref id="B10">
      <label>10.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mou</surname><given-names>M</given-names></string-name>, <string-name><surname>Pan</surname><given-names>Z</given-names></string-name>, <string-name><surname>Lu</surname><given-names>M</given-names></string-name>, <string-name><surname>Sun</surname><given-names>H</given-names></string-name>, <string-name><surname>Wang</surname><given-names>Y</given-names></string-name>, <string-name><surname>Luo</surname><given-names>Y</given-names></string-name>, <string-name><surname>Zhu</surname><given-names>F</given-names></string-name></person-group>. 
<article-title>Application of machine learning in spatial proteomics</article-title>. <source><italic toggle="yes">J Chem Inf Model</italic></source>. <year>2022</year>;<volume>62</volume>(<issue>23</issue>):<fpage>5875</fpage>–<lpage>5895</lpage>.<pub-id pub-id-type="pmid">36378082</pub-id></mixed-citation>
    </ref>
    <ref id="B11">
      <label>11.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kong</surname><given-names>L</given-names></string-name>, <string-name><surname>Chen</surname><given-names>J</given-names></string-name>, <string-name><surname>Ji</surname><given-names>X</given-names></string-name>, <string-name><surname>Qin</surname><given-names>Q</given-names></string-name>, <string-name><surname>Yang</surname><given-names>H</given-names></string-name>, <string-name><surname>Liu</surname><given-names>D</given-names></string-name>, <string-name><surname>Li</surname><given-names>D</given-names></string-name>, <string-name><surname>Sun</surname><given-names>M</given-names></string-name></person-group>. 
<article-title>Alcoholic fatty liver disease inhibited the co-expression of Fmo5 and PPARalpha to activate the NF-kappaB signaling pathway, thereby reducing liver injury via inducing gut microbiota disturbance</article-title>. <source><italic toggle="yes">J Exp Clin Cancer Res</italic></source>. <year>2021</year>;<volume>40</volume>(<issue>1</issue>):<fpage>18</fpage>.<pub-id pub-id-type="pmid">33413501</pub-id></mixed-citation>
    </ref>
    <ref id="B12">
      <label>12.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sung</surname><given-names>MS</given-names></string-name>, <string-name><surname>Jung</surname><given-names>JH</given-names></string-name>, <string-name><surname>Jeong</surname><given-names>C</given-names></string-name>, <string-name><surname>Yoon</surname><given-names>TY</given-names></string-name>, <string-name><surname>Park</surname><given-names>JH</given-names></string-name></person-group>. 
<article-title>Single-molecule co-immunoprecipitation reveals functional inheritance of EGFRs in extracellular vesicles</article-title>. <source><italic toggle="yes">Small</italic></source>. <year>2018</year>;<volume>14</volume>(<issue>42</issue>):
<elocation-id>e1802358</elocation-id>.<pub-id pub-id-type="pmid">30239124</pub-id></mixed-citation>
    </ref>
    <ref id="B13">
      <label>13.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tang</surname><given-names>HW</given-names></string-name>, <string-name><surname>Spirohn</surname><given-names>K</given-names></string-name>, <string-name><surname>Hu</surname><given-names>Y</given-names></string-name>, <string-name><surname>Hao</surname><given-names>T</given-names></string-name>, <string-name><surname>Kovacs</surname><given-names>IA</given-names></string-name>, <string-name><surname>Gao</surname><given-names>Y</given-names></string-name>, <string-name><surname>Binari</surname><given-names>R</given-names></string-name>, <string-name><surname>Yang-Zhou</surname><given-names>D</given-names></string-name>, <string-name><surname>Wan</surname><given-names>KH</given-names></string-name>, <string-name><surname>Bader</surname><given-names>JS</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Next-generation large-scale binary protein interaction network for Drosophila melanogaster</article-title>. <source><italic toggle="yes">Nat Commun</italic></source>. <year>2023</year>;<volume>14</volume>(<issue>1</issue>):<fpage>2162</fpage>.<pub-id pub-id-type="pmid">37061542</pub-id></mixed-citation>
    </ref>
    <ref id="B14">
      <label>14.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Giot</surname><given-names>L</given-names></string-name>, <string-name><surname>Bader</surname><given-names>JS</given-names></string-name>, <string-name><surname>Brouwer</surname><given-names>C</given-names></string-name>, <string-name><surname>Chaudhuri</surname><given-names>A</given-names></string-name>, <string-name><surname>Kuang</surname><given-names>B</given-names></string-name>, <string-name><surname>Li</surname><given-names>Y</given-names></string-name>, <string-name><surname>Hao</surname><given-names>YL</given-names></string-name>, <string-name><surname>Ooi</surname><given-names>CE</given-names></string-name>, <string-name><surname>Godwin</surname><given-names>B</given-names></string-name>, <string-name><surname>Vitols</surname><given-names>E</given-names></string-name>, <etal>et al.</etal></person-group><article-title>A protein interaction map of Drosophila melanogaster</article-title>. <source><italic toggle="yes">Science</italic></source>. <year>2003</year>;<volume>302</volume>(<issue>5651</issue>):<fpage>1727</fpage>–<lpage>1736</lpage>.<pub-id pub-id-type="pmid">14605208</pub-id></mixed-citation>
    </ref>
    <ref id="B15">
      <label>15.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kataria</surname><given-names>R</given-names></string-name>, <string-name><surname>Kaundal</surname><given-names>R</given-names></string-name></person-group>. 
<article-title>WeCoNET: A host-pathogen interactome database for deciphering crucial molecular networks of wheat-common bunt cross-talk mechanisms</article-title>. <source><italic toggle="yes">Plant Methods</italic></source>. <year>2022</year>;<volume>18</volume>(<issue>1</issue>):<fpage>73</fpage>.<pub-id pub-id-type="pmid">35658913</pub-id></mixed-citation>
    </ref>
    <ref id="B16">
      <label>16.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Shu</surname><given-names>Y</given-names></string-name>, <string-name><surname>Hai</surname><given-names>Y</given-names></string-name>, <string-name><surname>Cao</surname><given-names>L</given-names></string-name>, <string-name><surname>Wu</surname><given-names>J</given-names></string-name></person-group>. 
<article-title>Deep-learning based approach to identify substrates of human E3 ubiquitin ligases and deubiquitinases</article-title>. <source><italic toggle="yes">Comput Struct Biotechnol J</italic></source>. <year>2023</year>;<volume>21</volume>:<fpage>1014</fpage>–<lpage>1021</lpage>.<pub-id pub-id-type="pmid">36733699</pub-id></mixed-citation>
    </ref>
    <ref id="B17">
      <label>17.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wu</surname><given-names>F</given-names></string-name>, <string-name><surname>Wang</surname><given-names>S</given-names></string-name>, <string-name><surname>Zeng</surname><given-names>Q</given-names></string-name>, <string-name><surname>Liu</surname><given-names>J</given-names></string-name>, <string-name><surname>Yang</surname><given-names>J</given-names></string-name>, <string-name><surname>Mu</surname><given-names>J</given-names></string-name>, <string-name><surname>Xu</surname><given-names>H</given-names></string-name>, <string-name><surname>Wu</surname><given-names>L</given-names></string-name>, <string-name><surname>Gao</surname><given-names>Q</given-names></string-name>, <string-name><surname>He</surname><given-names>X</given-names></string-name>, <etal>et al.</etal></person-group><article-title>TGF-betaRII regulates glucose metabolism in oral cancer-associated fibroblasts via promoting PKM2 nuclear translocation</article-title>. <source><italic toggle="yes">Cell Death Discov</italic></source>. <year>2022</year>;<volume>8</volume>(<issue>1</issue>):<fpage>3</fpage>.<pub-id pub-id-type="pmid">35013150</pub-id></mixed-citation>
    </ref>
    <ref id="B18">
      <label>18.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zheng</surname><given-names>M</given-names></string-name>, <string-name><surname>Liu</surname><given-names>X</given-names></string-name>, <string-name><surname>Xu</surname><given-names>Y</given-names></string-name>, <string-name><surname>Li</surname><given-names>H</given-names></string-name>, <string-name><surname>Luo</surname><given-names>C</given-names></string-name>, <string-name><surname>Jiang</surname><given-names>H</given-names></string-name></person-group>. 
<article-title>Computational methods for drug design and discovery: Focus on China</article-title>. <source><italic toggle="yes">Trends Pharmacol Sci</italic></source>. <year>2013</year>;<volume>34</volume>(<issue>10</issue>):<fpage>549</fpage>–<lpage>559</lpage>.<pub-id pub-id-type="pmid">24035675</pub-id></mixed-citation>
    </ref>
    <ref id="B19">
      <label>19.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Esmaielbeiki</surname><given-names>R</given-names></string-name>, <string-name><surname>Krawczyk</surname><given-names>K</given-names></string-name>, <string-name><surname>Knapp</surname><given-names>B</given-names></string-name>, <string-name><surname>Nebel</surname><given-names>JC</given-names></string-name>, <string-name><surname>Deane</surname><given-names>CM</given-names></string-name></person-group>. 
<article-title>Progress and challenges in predicting protein interfaces</article-title>. <source><italic toggle="yes">Brief Bioinform</italic></source>. <year>2016</year>;<volume>17</volume>(<issue>1</issue>):<fpage>117</fpage>–<lpage>131</lpage>.<pub-id pub-id-type="pmid">25971595</pub-id></mixed-citation>
    </ref>
    <ref id="B20">
      <label>20.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ezkurdia</surname><given-names>I</given-names></string-name>, <string-name><surname>Bartoli</surname><given-names>L</given-names></string-name>, <string-name><surname>Fariselli</surname><given-names>P</given-names></string-name>, <string-name><surname>Casadio</surname><given-names>R</given-names></string-name>, <string-name><surname>Valencia</surname><given-names>A</given-names></string-name>, <string-name><surname>Tress</surname><given-names>ML</given-names></string-name></person-group>. 
<article-title>Progress and challenges in predicting protein-protein interaction sites</article-title>. <source><italic toggle="yes">Brief Bioinform</italic></source>. <year>2009</year>;<volume>10</volume>(<issue>3</issue>):<fpage>233</fpage>–<lpage>246</lpage>.<pub-id pub-id-type="pmid">19346321</pub-id></mixed-citation>
    </ref>
    <ref id="B21">
      <label>21.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Northey</surname><given-names>TC</given-names></string-name>, <string-name><surname>Baresic</surname><given-names>A</given-names></string-name>, <string-name><surname>Martin</surname><given-names>ACR</given-names></string-name></person-group>. 
<article-title>IntPred: A structure-based predictor of protein-protein interaction sites</article-title>. <source><italic toggle="yes">Bioinformatics</italic></source>. <year>2018</year>;<volume>34</volume>(<issue>2</issue>):<fpage>223</fpage>–<lpage>229</lpage>.<pub-id pub-id-type="pmid">28968673</pub-id></mixed-citation>
    </ref>
    <ref id="B22">
      <label>22.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zeng</surname><given-names>M</given-names></string-name>, <string-name><surname>Zhang</surname><given-names>F</given-names></string-name>, <string-name><surname>Wu</surname><given-names>FX</given-names></string-name>, <string-name><surname>Li</surname><given-names>Y</given-names></string-name>, <string-name><surname>Wang</surname><given-names>J</given-names></string-name>, <string-name><surname>Li</surname><given-names>M</given-names></string-name></person-group>. 
<article-title>Protein-protein interaction site prediction through combining local and global features with deep neural networks</article-title>. <source><italic toggle="yes">Bioinformatics</italic></source>. <year>2020</year>;<volume>36</volume>(<issue>4</issue>):<fpage>1114</fpage>–<lpage>1120</lpage>.<pub-id pub-id-type="pmid">31593229</pub-id></mixed-citation>
    </ref>
    <ref id="B23">
      <label>23.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mahbub</surname><given-names>S</given-names></string-name>, <string-name><surname>Bayzid</surname><given-names>MS</given-names></string-name></person-group>. 
<article-title>EGRET: Edge aggregated graph attention networks and transfer learning improve protein-protein interaction site prediction</article-title>. <source><italic toggle="yes">Brief Bioinform</italic></source>. <year>2022</year>;<volume>23</volume>(<issue>2</issue>):<fpage>bbab578</fpage>.<pub-id pub-id-type="pmid">35106547</pub-id></mixed-citation>
    </ref>
    <ref id="B24">
      <label>24.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname><given-names>Q</given-names></string-name>, <string-name><surname>Feng</surname><given-names>T</given-names></string-name>, <string-name><surname>Xu</surname><given-names>L</given-names></string-name>, <string-name><surname>Sun</surname><given-names>H</given-names></string-name>, <string-name><surname>Pan</surname><given-names>P</given-names></string-name>, <string-name><surname>Li</surname><given-names>Y</given-names></string-name>, <string-name><surname>Li</surname><given-names>D</given-names></string-name>, <string-name><surname>Hou</surname><given-names>T</given-names></string-name></person-group>. 
<article-title>Recent advances in protein-protein docking</article-title>. <source><italic toggle="yes">Curr Drug Targets</italic></source>. <year>2016</year>;<volume>17</volume>(<issue>14</issue>):<fpage>1586</fpage>–<lpage>1594</lpage>.<pub-id pub-id-type="pmid">26758670</pub-id></mixed-citation>
    </ref>
    <ref id="B25">
      <label>25.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rodrigues</surname><given-names>JP</given-names></string-name>, <string-name><surname>Karaca</surname><given-names>E</given-names></string-name>, <string-name><surname>Bonvin</surname><given-names>AM</given-names></string-name></person-group>. 
<article-title>Information-driven structural modelling of protein-protein interactions</article-title>. <source><italic toggle="yes">Methods Mol Biol</italic></source>. <year>2015</year>;<volume>1215</volume>:<fpage>399</fpage>–<lpage>424</lpage>.<pub-id pub-id-type="pmid">25330973</pub-id></mixed-citation>
    </ref>
    <ref id="B26">
      <label>26.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sanchez-Garcia</surname><given-names>R</given-names></string-name>, <string-name><surname>Sorzano</surname><given-names>COS</given-names></string-name>, <string-name><surname>Carazo</surname><given-names>JM</given-names></string-name>, <string-name><surname>Segura</surname><given-names>J</given-names></string-name></person-group>. 
<article-title>BIPSPI: A method for the prediction of partner-specific protein-protein interfaces</article-title>. <source><italic toggle="yes">Bioinformatics</italic></source>. <year>2019</year>;<volume>35</volume>(<issue>3</issue>):<fpage>470</fpage>–<lpage>477</lpage>.<pub-id pub-id-type="pmid">30020406</pub-id></mixed-citation>
    </ref>
    <ref id="B27">
      <label>27.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hou</surname><given-names>Q</given-names></string-name>, <string-name><surname>De Geest</surname><given-names>PFG</given-names></string-name>, <string-name><surname>Vranken</surname><given-names>WF</given-names></string-name>, <string-name><surname>Heringa</surname><given-names>J</given-names></string-name>, <string-name><surname>Feenstra</surname><given-names>KA</given-names></string-name></person-group>. 
<article-title>Seeing the trees through the forest: Sequence-based homo- and heteromeric protein-protein interaction sites prediction using random forest</article-title>. <source><italic toggle="yes">Bioinformatics</italic></source>. <year>2017</year>;<volume>33</volume>(<issue>10</issue>):<fpage>1479</fpage>–<lpage>1487</lpage>.<pub-id pub-id-type="pmid">28073761</pub-id></mixed-citation>
    </ref>
    <ref id="B28">
      <label>28.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Porollo</surname><given-names>A</given-names></string-name>, <string-name><surname>Meller</surname><given-names>J</given-names></string-name></person-group>. 
<article-title>Prediction-based fingerprints of protein-protein interactions</article-title>. <source><italic toggle="yes">Proteins</italic></source>. <year>2007</year>;<volume>66</volume>(<issue>3</issue>):<fpage>630</fpage>–<lpage>645</lpage>.<pub-id pub-id-type="pmid">17152079</pub-id></mixed-citation>
    </ref>
    <ref id="B29">
      <label>29.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Li</surname><given-names>S</given-names></string-name>, <string-name><surname>Wu</surname><given-names>S</given-names></string-name>, <string-name><surname>Wang</surname><given-names>L</given-names></string-name>, <string-name><surname>Li</surname><given-names>F</given-names></string-name>, <string-name><surname>Jiang</surname><given-names>H</given-names></string-name>, <string-name><surname>Bai</surname><given-names>F</given-names></string-name></person-group>. 
<article-title>Recent advances in predicting protein-protein interactions with the aid of artificial intelligence algorithms</article-title>. <source><italic toggle="yes">Curr Opin Struct Biol</italic></source>. <year>2022</year>;<volume>73</volume>:
<elocation-id>102344</elocation-id>.<pub-id pub-id-type="pmid">35219216</pub-id></mixed-citation>
    </ref>
    <ref id="B30">
      <label>30.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname><given-names>J</given-names></string-name>, <string-name><surname>Kurgan</surname><given-names>L</given-names></string-name></person-group>. 
<article-title>Review and comparative assessment of sequence-based predictors of protein-binding residues</article-title>. <source><italic toggle="yes">Brief Bioinform</italic></source>. <year>2018</year>;<volume>19</volume>(<issue>5</issue>):<fpage>821</fpage>–<lpage>837</lpage>.<pub-id pub-id-type="pmid">28334258</pub-id></mixed-citation>
    </ref>
    <ref id="B31">
      <label>31.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Singh</surname><given-names>G</given-names></string-name>, <string-name><surname>Dhole</surname><given-names>KD</given-names></string-name>, <string-name><surname>Pai</surname><given-names>P</given-names></string-name>, <string-name><surname>Mondal</surname><given-names>SK</given-names></string-name></person-group>. 
<article-title>SPRINGS: Prediction of protein- protein interaction sites using artificial neural networks</article-title>. <source><italic toggle="yes">J Proteom Comput Biol</italic></source>. <year>2014</year>;<volume>1</volume>(<issue>1</issue>):<fpage>7</fpage>.</mixed-citation>
    </ref>
    <ref id="B32">
      <label>32.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname><given-names>J</given-names></string-name>, <string-name><surname>Kurgan</surname><given-names>L</given-names></string-name></person-group>. 
<article-title>SCRIBER: Accurate and partner type-specific prediction of protein-binding residues from proteins sequences</article-title>. <source><italic toggle="yes">Bioinformatics</italic></source>. <year>2019</year>;<volume>35</volume>(<issue>14</issue>):<fpage>i343</fpage>–<lpage>i353</lpage>.<pub-id pub-id-type="pmid">31510679</pub-id></mixed-citation>
    </ref>
    <ref id="B33">
      <label>33.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Qiu</surname><given-names>J</given-names></string-name>, <string-name><surname>Bernhofer</surname><given-names>M</given-names></string-name>, <string-name><surname>Heinzinger</surname><given-names>M</given-names></string-name>, <string-name><surname>Kemper</surname><given-names>S</given-names></string-name>, <string-name><surname>Norambuena</surname><given-names>T</given-names></string-name>, <string-name><surname>Melo</surname><given-names>F</given-names></string-name>, <string-name><surname>Rost</surname><given-names>B</given-names></string-name></person-group>. 
<article-title>ProNA2020 predicts protein-DNA, protein-RNA, and protein-protein binding proteins and residues from sequence</article-title>. <source><italic toggle="yes">J Mol Biol</italic></source>. <year>2020</year>;<volume>432</volume>(<issue>7</issue>):<fpage>2428</fpage>–<lpage>2443</lpage>.<pub-id pub-id-type="pmid">32142788</pub-id></mixed-citation>
    </ref>
    <ref id="B34">
      <label>34.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Li</surname><given-names>Y</given-names></string-name>, <string-name><surname>Golding</surname><given-names>GB</given-names></string-name>, <string-name><surname>Ilie</surname><given-names>L</given-names></string-name></person-group>. 
<article-title>DELPHI: Accurate deep ensemble model for protein interaction sites prediction</article-title>. <source><italic toggle="yes">Bioinformatics</italic></source>. <year>2021</year>;<volume>37</volume>(<issue>7</issue>):<fpage>896</fpage>–<lpage>904</lpage>.<pub-id pub-id-type="pmid">32840562</pub-id></mixed-citation>
    </ref>
    <ref id="B35">
      <label>35.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yuan</surname><given-names>Q</given-names></string-name>, <string-name><surname>Chen</surname><given-names>J</given-names></string-name>, <string-name><surname>Zhao</surname><given-names>H</given-names></string-name>, <string-name><surname>Zhou</surname><given-names>Y</given-names></string-name>, <string-name><surname>Yang</surname><given-names>Y</given-names></string-name></person-group>. 
<article-title>Structure-aware protein-protein interaction site prediction using deep graph convolutional network</article-title>. <source><italic toggle="yes">Bioinformatics</italic></source>. <year>2021</year>;<volume>38</volume>(<issue>1</issue>):<fpage>125</fpage>–<lpage>132</lpage>.<pub-id pub-id-type="pmid">34498061</pub-id></mixed-citation>
    </ref>
    <ref id="B36">
      <label>36.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dai</surname><given-names>B</given-names></string-name>, <string-name><surname>Bailey-Kellogg</surname><given-names>C</given-names></string-name></person-group>. 
<article-title>Protein interaction interface region prediction by geometric deep learning</article-title>. <source><italic toggle="yes">Bioinformatics</italic></source>. <year>2021</year>;<volume>37</volume>(<issue>17</issue>):<fpage>2580</fpage>–<lpage>2588</lpage>.<pub-id pub-id-type="pmid">33693581</pub-id></mixed-citation>
    </ref>
    <ref id="B37">
      <label>37.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gainza</surname><given-names>P</given-names></string-name>, <string-name><surname>Sverrisson</surname><given-names>F</given-names></string-name>, <string-name><surname>Monti</surname><given-names>F</given-names></string-name>, <string-name><surname>Rodola</surname><given-names>E</given-names></string-name>, <string-name><surname>Boscaini</surname><given-names>D</given-names></string-name>, <string-name><surname>Bronstein</surname><given-names>MM</given-names></string-name>, <string-name><surname>Correia</surname><given-names>BE</given-names></string-name></person-group>. 
<article-title>Deciphering interaction fingerprints from protein molecular surfaces using geometric deep learning</article-title>. <source><italic toggle="yes">Nat Methods</italic></source>. <year>2020</year>;<volume>17</volume>(<issue>2</issue>):<fpage>184</fpage>–<lpage>192</lpage>.<pub-id pub-id-type="pmid">31819266</pub-id></mixed-citation>
    </ref>
    <ref id="B38">
      <label>38.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tubiana</surname><given-names>J</given-names></string-name>, <string-name><surname>Schneidman-Duhovny</surname><given-names>D</given-names></string-name>, <string-name><surname>Wolfson</surname><given-names>HJ</given-names></string-name></person-group>. 
<article-title>ScanNet: An interpretable geometric deep learning model for structure-based protein binding site prediction</article-title>. <source><italic toggle="yes">Nat Methods</italic></source>. <year>2022</year>;<volume>19</volume>(<issue>6</issue>):<fpage>730</fpage>–<lpage>739</lpage>.<pub-id pub-id-type="pmid">35637310</pub-id></mixed-citation>
    </ref>
    <ref id="B39">
      <label>39.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Krapp</surname><given-names>LF</given-names></string-name>, <string-name><surname>Abriata</surname><given-names>LA</given-names></string-name>, <string-name><surname>Cortes Rodriguez</surname><given-names>F</given-names></string-name>, <string-name><surname>Dal Peraro</surname><given-names>M</given-names></string-name></person-group>. 
<article-title>PeSTo: Parameter-free geometric deep learning for accurate prediction of protein binding interfaces</article-title>. <source><italic toggle="yes">Nat Commun</italic></source>. <year>2023</year>;<volume>14</volume>(<issue>1</issue>):<fpage>2175</fpage>.<pub-id pub-id-type="pmid">37072397</pub-id></mixed-citation>
    </ref>
    <ref id="B40">
      <label>40.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname><given-names>S</given-names></string-name>, <string-name><surname>Chen</surname><given-names>W</given-names></string-name>, <string-name><surname>Han</surname><given-names>P</given-names></string-name>, <string-name><surname>Li</surname><given-names>X</given-names></string-name>, <string-name><surname>Song</surname><given-names>T</given-names></string-name></person-group>. 
<article-title>RGN: Residue-based graph attention and convolutional network for protein-protein interaction site prediction</article-title>. <source><italic toggle="yes">J Chem Inf Model</italic></source>. <year>2022</year>;<volume>62</volume>(<issue>23</issue>):<fpage>5961</fpage>–<lpage>5974</lpage>.<pub-id pub-id-type="pmid">36398714</pub-id></mixed-citation>
    </ref>
    <ref id="B41">
      <label>41.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yang</surname><given-names>Y</given-names></string-name>, <string-name><surname>Hou</surname><given-names>Z</given-names></string-name>, <string-name><surname>Ma</surname><given-names>Z</given-names></string-name>, <string-name><surname>Li</surname><given-names>X</given-names></string-name>, <string-name><surname>Wong</surname><given-names>KC</given-names></string-name></person-group>. 
<article-title>iCircRBP-DHN: Identification of circRNA-RBP interaction sites using deep hierarchical network</article-title>. <source><italic toggle="yes">Brief Bioinform</italic></source>. <year>2021</year>;<volume>22</volume>(<issue>4</issue>).</mixed-citation>
    </ref>
    <ref id="B42">
      <label>42.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hou</surname><given-names>Z</given-names></string-name>, <string-name><surname>Yang</surname><given-names>Y</given-names></string-name>, <string-name><surname>Ma</surname><given-names>Z</given-names></string-name>, <string-name><surname>Wong</surname><given-names>KC</given-names></string-name>, <string-name><surname>Li</surname><given-names>X</given-names></string-name></person-group>. 
<article-title>Learning the protein language of proteome-wide protein-protein binding sites via explainable ensemble deep learning</article-title>. <source><italic toggle="yes">Commun Biol</italic></source>. <year>2023</year>;<volume>6</volume>(<issue>1</issue>):<fpage>73</fpage>.<pub-id pub-id-type="pmid">36653447</pub-id></mixed-citation>
    </ref>
    <ref id="B43">
      <label>43.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Senior</surname><given-names>AW</given-names></string-name>, <string-name><surname>Evans</surname><given-names>R</given-names></string-name>, <string-name><surname>Jumper</surname><given-names>J</given-names></string-name>, <string-name><surname>Kirkpatrick</surname><given-names>J</given-names></string-name>, <string-name><surname>Sifre</surname><given-names>L</given-names></string-name>, <string-name><surname>Green</surname><given-names>T</given-names></string-name>, <string-name><surname>Qin</surname><given-names>C</given-names></string-name>, <string-name><surname>Zidek</surname><given-names>A</given-names></string-name>, <string-name><surname>Nelson</surname><given-names>AWR</given-names></string-name>, <string-name><surname>Bridgland</surname><given-names>A</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Improved protein structure prediction using potentials from deep learning</article-title>. <source><italic toggle="yes">Nature</italic></source>. <year>2020</year>;<volume>577</volume>(<issue>7792</issue>):<fpage>706</fpage>–<lpage>710</lpage>.<pub-id pub-id-type="pmid">31942072</pub-id></mixed-citation>
    </ref>
    <ref id="B44">
      <label>44.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hammes</surname><given-names>GG</given-names></string-name>, <string-name><surname>Chang</surname><given-names>YC</given-names></string-name>, <string-name><surname>Oas</surname><given-names>TG</given-names></string-name></person-group>. 
<article-title>Conformational selection or induced fit: A flux description of reaction mechanism</article-title>. <source><italic toggle="yes">Proc Natl Acad Sci U S A</italic></source>. <year>2009</year>;<volume>106</volume>(<issue>33</issue>):<fpage>13737</fpage>–<lpage>13741</lpage>.<pub-id pub-id-type="pmid">19666553</pub-id></mixed-citation>
    </ref>
    <ref id="B45">
      <label>45.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yang</surname><given-names>H</given-names></string-name>, <string-name><surname>Wang</surname><given-names>M</given-names></string-name>, <string-name><surname>Liu</surname><given-names>X</given-names></string-name>, <string-name><surname>Zhao</surname><given-names>XM</given-names></string-name>, <string-name><surname>Li</surname><given-names>A</given-names></string-name></person-group>. 
<article-title>PhosIDN: An integrated deep neural network for improving protein phosphorylation site prediction by combining sequence and protein-protein interaction information</article-title>. <source><italic toggle="yes">Bioinformatics</italic></source>. <year>2021</year>;<volume>37</volume>(<issue>24</issue>):<fpage>4668</fpage>–<lpage>4676</lpage>.<pub-id pub-id-type="pmid">34320631</pub-id></mixed-citation>
    </ref>
    <ref id="B46">
      <label>46.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Du</surname><given-names>H</given-names></string-name>, <string-name><surname>Jiang</surname><given-names>D</given-names></string-name>, <string-name><surname>Gao</surname><given-names>J</given-names></string-name>, <string-name><surname>Zhang</surname><given-names>X</given-names></string-name>, <string-name><surname>Jiang</surname><given-names>L</given-names></string-name>, <string-name><surname>Zeng</surname><given-names>Y</given-names></string-name>, <string-name><surname>Wu</surname><given-names>Z</given-names></string-name>, <string-name><surname>Shen</surname><given-names>C</given-names></string-name>, <string-name><surname>Xu</surname><given-names>L</given-names></string-name>, <string-name><surname>Cao</surname><given-names>D</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Proteome-wide profiling of the covalent-Druggable cysteines with a structure-based deep graph learning network</article-title>. <source><italic toggle="yes">Research (Wash D C)</italic></source>. <year>2022</year>;<volume>2022</volume>:
<elocation-id>9873564</elocation-id>.<pub-id pub-id-type="pmid">35958111</pub-id></mixed-citation>
    </ref>
    <ref id="B47">
      <label>47.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname><given-names>Y</given-names></string-name>, <string-name><surname>Yang</surname><given-names>Y</given-names></string-name>, <string-name><surname>Ma</surname><given-names>Z</given-names></string-name>, <string-name><surname>Wong</surname><given-names>KC</given-names></string-name>, <string-name><surname>Li</surname><given-names>X</given-names></string-name></person-group>. 
<article-title>EDCNN: Identification of genome-wide RNA-binding proteins using evolutionary deep convolutional neural network</article-title>. <source><italic toggle="yes">Bioinformatics</italic></source>. <year>2022</year>;<volume>38</volume>(<issue>3</issue>):<fpage>678</fpage>–<lpage>686</lpage>.<pub-id pub-id-type="pmid">34694393</pub-id></mixed-citation>
    </ref>
    <ref id="B48">
      <label>48.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Elnaggar</surname><given-names>A</given-names></string-name>, <string-name><surname>Heinzinger</surname><given-names>M</given-names></string-name>, <string-name><surname>Dallago</surname><given-names>C</given-names></string-name>, <string-name><surname>Rehawi</surname><given-names>G</given-names></string-name>, <string-name><surname>Wang</surname><given-names>Y</given-names></string-name>, <string-name><surname>Jones</surname><given-names>L</given-names></string-name>, <string-name><surname>Gibbs</surname><given-names>T</given-names></string-name>, <string-name><surname>Feher</surname><given-names>T</given-names></string-name>, <string-name><surname>Angerer</surname><given-names>C</given-names></string-name>, <string-name><surname>Steinegger</surname><given-names>M</given-names></string-name>, <etal>et al.</etal></person-group><article-title>ProtTrans: Toward understanding the language of life through self-supervised learning</article-title>. <source><italic toggle="yes">IEEE Trans Pattern Anal Mach Intell</italic></source>. <year>2022</year>;<volume>44</volume>(<issue>10</issue>):<fpage>7112</fpage>–<lpage>7127</lpage>.<pub-id pub-id-type="pmid">34232869</pub-id></mixed-citation>
    </ref>
    <ref id="B49">
      <label>49.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Altschul</surname><given-names>SF</given-names></string-name>, <string-name><surname>Madden</surname><given-names>TL</given-names></string-name>, <string-name><surname>Schaffer</surname><given-names>AA</given-names></string-name>, <string-name><surname>Zhang</surname><given-names>J</given-names></string-name>, <string-name><surname>Zhang</surname><given-names>Z</given-names></string-name>, <string-name><surname>Miller</surname><given-names>W</given-names></string-name>, <string-name><surname>Lipman</surname><given-names>DJ</given-names></string-name></person-group>. 
<article-title>Gapped BLAST and PSI-BLAST: A new generation of protein database search programs</article-title>. <source><italic toggle="yes">Nucleic Acids Res</italic></source>. <year>1997</year>;<volume>25</volume>(<issue>17</issue>):<fpage>3389</fpage>–<lpage>3402</lpage>.<pub-id pub-id-type="pmid">9254694</pub-id></mixed-citation>
    </ref>
    <ref id="B50">
      <label>50.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zacharias</surname><given-names>J</given-names></string-name>, <string-name><surname>Knapp</surname><given-names>EW</given-names></string-name></person-group>. 
<article-title>Protein secondary structure classification revisited: Processing DSSP information with PSSC</article-title>. <source><italic toggle="yes">J Chem Inf Model</italic></source>. <year>2014</year>;<volume>54</volume>(<issue>7</issue>):<fpage>2166</fpage>–<lpage>2179</lpage>.<pub-id pub-id-type="pmid">24866861</pub-id></mixed-citation>
    </ref>
    <ref id="B51">
      <label>51.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Shi</surname><given-names>Z</given-names></string-name>, <string-name><surname>Deng</surname><given-names>R</given-names></string-name>, <string-name><surname>Yuan</surname><given-names>Q</given-names></string-name>, <string-name><surname>Mao</surname><given-names>Z</given-names></string-name>, <string-name><surname>Wang</surname><given-names>R</given-names></string-name>, <string-name><surname>Li</surname><given-names>H</given-names></string-name>, <string-name><surname>Liao</surname><given-names>X</given-names></string-name>, <string-name><surname>Ma</surname><given-names>H</given-names></string-name></person-group>. 
<article-title>Enzyme commission number prediction and benchmarking with hierarchical dual-core multitask learning framework</article-title>. <source><italic toggle="yes">Research (Wash D C)</italic></source>. <year>2023</year>;<volume>6</volume>:<fpage>0153</fpage>.<pub-id pub-id-type="pmid">37275124</pub-id></mixed-citation>
    </ref>
    <ref id="B52">
      <label>52.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lin</surname><given-names>Z</given-names></string-name>, <string-name><surname>Akin</surname><given-names>H</given-names></string-name>, <string-name><surname>Rao</surname><given-names>R</given-names></string-name>, <string-name><surname>Hie</surname><given-names>B</given-names></string-name>, <string-name><surname>Zhu</surname><given-names>Z</given-names></string-name>, <string-name><surname>Lu</surname><given-names>W</given-names></string-name>, <string-name><surname>Smetanin</surname><given-names>N</given-names></string-name>, <string-name><surname>Verkuil</surname><given-names>R</given-names></string-name>, <string-name><surname>Kabeli</surname><given-names>O</given-names></string-name>, <string-name><surname>Shmueli</surname><given-names>Y</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Evolutionary-scale prediction of atomic-level protein structure with a language model</article-title>. <source><italic toggle="yes">Science</italic></source>. <year>2023</year>;<volume>379</volume>(<issue>6637</issue>):<fpage>1123</fpage>–<lpage>1130</lpage>.<pub-id pub-id-type="pmid">36927031</pub-id></mixed-citation>
    </ref>
    <ref id="B53">
      <label>53.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chowdhury</surname><given-names>R</given-names></string-name>, <string-name><surname>Bouatta</surname><given-names>N</given-names></string-name>, <string-name><surname>Biswas</surname><given-names>S</given-names></string-name>, <string-name><surname>Floristean</surname><given-names>C</given-names></string-name>, <string-name><surname>Kharkar</surname><given-names>A</given-names></string-name>, <string-name><surname>Roy</surname><given-names>K</given-names></string-name>, <string-name><surname>Rochereau</surname><given-names>C</given-names></string-name>, <string-name><surname>Ahdritz</surname><given-names>G</given-names></string-name>, <string-name><surname>Zhang</surname><given-names>J</given-names></string-name>, <string-name><surname>Church</surname><given-names>GM</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Single-sequence protein structure prediction using a language model and deep learning</article-title>. <source><italic toggle="yes">Nat Biotechnol</italic></source>. <year>2022</year>;<volume>40</volume>(<issue>11</issue>):<fpage>1617</fpage>–<lpage>1623</lpage>.<pub-id pub-id-type="pmid">36192636</pub-id></mixed-citation>
    </ref>
    <ref id="B54">
      <label>54.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yang</surname><given-names>Q</given-names></string-name>, <string-name><surname>Syed</surname><given-names>AAS</given-names></string-name>, <string-name><surname>Fahira</surname><given-names>A</given-names></string-name>, <string-name><surname>Shi</surname><given-names>Y</given-names></string-name></person-group>. 
<article-title>Structural analysis of the SARS-CoV-2 omicron variant proteins</article-title>. <source><italic toggle="yes">Research (Wash D C)</italic></source>. <year>2021</year>;<volume>2021</volume>:
<elocation-id>9769586</elocation-id>.<pub-id pub-id-type="pmid">35088054</pub-id></mixed-citation>
    </ref>
    <ref id="B55">
      <label>55.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jumper</surname><given-names>J</given-names></string-name>, <string-name><surname>Evans</surname><given-names>R</given-names></string-name>, <string-name><surname>Pritzel</surname><given-names>A</given-names></string-name>, <string-name><surname>Green</surname><given-names>T</given-names></string-name>, <string-name><surname>Figurnov</surname><given-names>M</given-names></string-name>, <string-name><surname>Ronneberger</surname><given-names>O</given-names></string-name>, <string-name><surname>Tunyasuvunakool</surname><given-names>K</given-names></string-name>, <string-name><surname>Bates</surname><given-names>R</given-names></string-name>, <string-name><surname>Zidek</surname><given-names>A</given-names></string-name>, <string-name><surname>Potapenko</surname><given-names>A</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Highly accurate protein structure prediction with AlphaFold</article-title>. <source><italic toggle="yes">Nature</italic></source>. <year>2021</year>;<volume>596</volume>(<issue>7873</issue>):<fpage>583</fpage>–<lpage>589</lpage>.<pub-id pub-id-type="pmid">34265844</pub-id></mixed-citation>
    </ref>
    <ref id="B56">
      <label>56.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tunyasuvunakool</surname><given-names>K</given-names></string-name>, <string-name><surname>Adler</surname><given-names>J</given-names></string-name>, <string-name><surname>Wu</surname><given-names>Z</given-names></string-name>, <string-name><surname>Green</surname><given-names>T</given-names></string-name>, <string-name><surname>Zielinski</surname><given-names>M</given-names></string-name>, <string-name><surname>Zidek</surname><given-names>A</given-names></string-name>, <string-name><surname>Bridgland</surname><given-names>A</given-names></string-name>, <string-name><surname>Cowie</surname><given-names>A</given-names></string-name>, <string-name><surname>Meyer</surname><given-names>C</given-names></string-name>, <string-name><surname>Laydon</surname><given-names>A</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Highly accurate protein structure prediction for the human proteome</article-title>. <source><italic toggle="yes">Nature</italic></source>. <year>2021</year>;<volume>596</volume>(<issue>7873</issue>):<fpage>590</fpage>–<lpage>596</lpage>.<pub-id pub-id-type="pmid">34293799</pub-id></mixed-citation>
    </ref>
    <ref id="B57">
      <label>57.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Baek</surname><given-names>M</given-names></string-name>, <string-name><surname>DiMaio</surname><given-names>F</given-names></string-name>, <string-name><surname>Anishchenko</surname><given-names>I</given-names></string-name>, <string-name><surname>Dauparas</surname><given-names>J</given-names></string-name>, <string-name><surname>Ovchinnikov</surname><given-names>S</given-names></string-name>, <string-name><surname>Lee</surname><given-names>GR</given-names></string-name>, <string-name><surname>Wang</surname><given-names>J</given-names></string-name>, <string-name><surname>Cong</surname><given-names>Q</given-names></string-name>, <string-name><surname>Kinch</surname><given-names>LN</given-names></string-name>, <string-name><surname>Schaeffer</surname><given-names>RD</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Accurate prediction of protein structures and interactions using a three-track neural network</article-title>. <source><italic toggle="yes">Science</italic></source>. <year>2021</year>;<volume>373</volume>(<issue>6557</issue>):<fpage>871</fpage>–<lpage>876</lpage>.<pub-id pub-id-type="pmid">34282049</pub-id></mixed-citation>
    </ref>
    <ref id="B58">
      <label>58.</label>
      <mixed-citation publication-type="journal"><article-title>RCSB Protein Data Bank (RCSB.org): Delivery of experimentally-determined PDB structures alongside one million computed structure models of proteins from artificial intelligence/machine learning</article-title>. <source><italic toggle="yes">Nucleic Acids Res</italic></source>. <year>2023</year>;<volume>51</volume>(<issue>D1</issue>):<fpage>D488</fpage>–<lpage>D508</lpage>.<pub-id pub-id-type="pmid">36420884</pub-id></mixed-citation>
    </ref>
    <ref id="B59">
      <label>59.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Buel</surname><given-names>GR</given-names></string-name>, <string-name><surname>Walters</surname><given-names>KJ</given-names></string-name></person-group>. 
<article-title>Can AlphaFold2 predict the impact of missense mutations on structure?</article-title><source><italic toggle="yes">Nat Struct Mol Biol</italic></source>. <year>2022</year>;<volume>29</volume>(<issue>1</issue>):<fpage>1</fpage>–<lpage>2</lpage>.<pub-id pub-id-type="pmid">35046575</pub-id></mixed-citation>
    </ref>
    <ref id="B60">
      <label>60.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yang</surname><given-names>Z</given-names></string-name>, <string-name><surname>Zeng</surname><given-names>X</given-names></string-name>, <string-name><surname>Zhao</surname><given-names>Y</given-names></string-name>, <string-name><surname>Chen</surname><given-names>R</given-names></string-name></person-group>. 
<article-title>AlphaFold2 and its applications in the fields of biology and medicine</article-title>. <source><italic toggle="yes">Signal Transduct Target Ther</italic></source>. <year>2023</year>;<volume>8</volume>(<issue>1</issue>):<fpage>115</fpage>.<pub-id pub-id-type="pmid">36918529</pub-id></mixed-citation>
    </ref>
    <ref id="B61">
      <label>61.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yang</surname><given-names>Q</given-names></string-name>, <string-name><surname>Jian</surname><given-names>X</given-names></string-name>, <string-name><surname>Syed</surname><given-names>AAS</given-names></string-name>, <string-name><surname>Fahira</surname><given-names>A</given-names></string-name>, <string-name><surname>Zheng</surname><given-names>C</given-names></string-name>, <string-name><surname>Zhu</surname><given-names>Z</given-names></string-name>, <string-name><surname>Wang</surname><given-names>K</given-names></string-name>, <string-name><surname>Zhang</surname><given-names>J</given-names></string-name>, <string-name><surname>Wen</surname><given-names>Y</given-names></string-name>, <string-name><surname>Li</surname><given-names>Z</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Structural comparison and drug screening of spike proteins of ten SARS-CoV-2 variants</article-title>. <source><italic toggle="yes">Research (Wash D C)</italic></source>. <year>2022</year>;<volume>2022</volume>:
<elocation-id>9781758</elocation-id>.<pub-id pub-id-type="pmid">35198984</pub-id></mixed-citation>
    </ref>
    <ref id="B62">
      <label>62.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fu</surname><given-names>T</given-names></string-name>, <string-name><surname>Li</surname><given-names>F</given-names></string-name>, <string-name><surname>Zhang</surname><given-names>Y</given-names></string-name>, <string-name><surname>Yin</surname><given-names>J</given-names></string-name>, <string-name><surname>Qiu</surname><given-names>W</given-names></string-name>, <string-name><surname>Li</surname><given-names>X</given-names></string-name>, <string-name><surname>Liu</surname><given-names>X</given-names></string-name>, <string-name><surname>Xin</surname><given-names>W</given-names></string-name>, <string-name><surname>Wang</surname><given-names>C</given-names></string-name>, <string-name><surname>Yu</surname><given-names>L</given-names></string-name>, <etal>et al.</etal></person-group><article-title>VARIDT 2.0: Structural variability of drug transporter</article-title>. <source><italic toggle="yes">Nucleic Acids Res</italic></source>. <year>2022</year>;<volume>50</volume>(<issue>D1</issue>):<fpage>D1417</fpage>–<lpage>D1431</lpage>.<pub-id pub-id-type="pmid">34747471</pub-id></mixed-citation>
    </ref>
    <ref id="B63">
      <label>63.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Iqbal</surname><given-names>S</given-names></string-name>, <string-name><surname>Ge</surname><given-names>F</given-names></string-name>, <string-name><surname>Li</surname><given-names>F</given-names></string-name>, <string-name><surname>Akutsu</surname><given-names>T</given-names></string-name>, <string-name><surname>Zheng</surname><given-names>Y</given-names></string-name>, <string-name><surname>Gasser</surname><given-names>RB</given-names></string-name>, <string-name><surname>Yu</surname><given-names>DJ</given-names></string-name>, <string-name><surname>Webb</surname><given-names>GI</given-names></string-name>, <string-name><surname>Song</surname><given-names>J</given-names></string-name></person-group>. 
<article-title>PROST: AlphaFold2-aware sequence-based predictor to estimate protein stability changes upon missense mutations</article-title>. <source><italic toggle="yes">J Chem Inf Model</italic></source>. <year>2022</year>;<volume>62</volume>(<issue>17</issue>):<fpage>4270</fpage>–<lpage>4282</lpage>.<pub-id pub-id-type="pmid">35973091</pub-id></mixed-citation>
    </ref>
    <ref id="B64">
      <label>64.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lin</surname><given-names>B</given-names></string-name>, <string-name><surname>Zhang</surname><given-names>H</given-names></string-name>, <string-name><surname>Zheng</surname><given-names>Q</given-names></string-name></person-group>. 
<article-title>How do mutations affect the structural characteristics and substrate binding of CYP21A2? An investigation by molecular dynamics simulations</article-title>. <source><italic toggle="yes">Phys Chem Chem Phys</italic></source>. <year>2020</year>;<volume>22</volume>(<issue>16</issue>):<fpage>8870</fpage>–<lpage>8877</lpage>.<pub-id pub-id-type="pmid">32286592</pub-id></mixed-citation>
    </ref>
    <ref id="B65">
      <label>65.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Liang</surname><given-names>B</given-names></string-name>, <string-name><surname>Zhu</surname><given-names>Y</given-names></string-name>, <string-name><surname>Shi</surname><given-names>W</given-names></string-name>, <string-name><surname>Ni</surname><given-names>C</given-names></string-name>, <string-name><surname>Tan</surname><given-names>B</given-names></string-name>, <string-name><surname>Tang</surname><given-names>S</given-names></string-name></person-group>. 
<article-title>SARS-CoV-2 spike protein post-translational modification landscape and its impact on protein structure and function via computational prediction</article-title>. <source><italic toggle="yes">Research (Wash D C)</italic></source>. <year>2023</year>;<volume>6</volume>:<fpage>0078</fpage>.<pub-id pub-id-type="pmid">36930770</pub-id></mixed-citation>
    </ref>
    <ref id="B66">
      <label>66.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname><given-names>X</given-names></string-name>, <string-name><surname>Zheng</surname><given-names>Q</given-names></string-name></person-group>. 
<article-title>How DNA affects the hyperthermophilic protein Ape10b2 for oligomerization: An investigation using multiple short molecular dynamics simulations</article-title>. <source><italic toggle="yes">Phys Chem Chem Phys</italic></source>. <year>2021</year>;<volume>23</volume>(<issue>45</issue>):<fpage>25841</fpage>–<lpage>25849</lpage>.<pub-id pub-id-type="pmid">34763347</pub-id></mixed-citation>
    </ref>
    <ref id="B67">
      <label>67.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tai</surname><given-names>KY</given-names></string-name>, <string-name><surname>Dhaliwal</surname><given-names>J</given-names></string-name>, <string-name><surname>Balasubramaniam</surname><given-names>V</given-names></string-name></person-group>. 
<article-title>Leveraging Mann-Whitney U test on large-scale genetic variation data for analysing malaria genetic markers</article-title>. <source><italic toggle="yes">Malar J</italic></source>. <year>2022</year>;<volume>21</volume>(<issue>1</issue>):<fpage>79</fpage>.<pub-id pub-id-type="pmid">35264165</pub-id></mixed-citation>
    </ref>
    <ref id="B68">
      <label>68.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Xu</surname><given-names>J</given-names></string-name>, <string-name><surname>Li</surname><given-names>F</given-names></string-name>, <string-name><surname>Li</surname><given-names>C</given-names></string-name>, <string-name><surname>Guo</surname><given-names>X</given-names></string-name>, <string-name><surname>Landersdorfer</surname><given-names>C</given-names></string-name>, <string-name><surname>Shen</surname><given-names>HH</given-names></string-name>, <string-name><surname>Peleg</surname><given-names>AY</given-names></string-name>, <string-name><surname>Li</surname><given-names>J</given-names></string-name>, <string-name><surname>Imoto</surname><given-names>S</given-names></string-name>, <string-name><surname>Yao</surname><given-names>J</given-names></string-name>, <etal>et al.</etal></person-group><article-title>iAMPCN: A deep-learning approach for identifying antimicrobial peptides and their functional activities</article-title>. <source><italic toggle="yes">Brief Bioinform</italic></source>. <year>2023</year>;<volume>24</volume>(<issue>4</issue>):<fpage>bbad240</fpage>.<pub-id pub-id-type="pmid">37369638</pub-id></mixed-citation>
    </ref>
    <ref id="B69">
      <label>69.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname><given-names>R</given-names></string-name>, <string-name><surname>Jiang</surname><given-names>Y</given-names></string-name>, <string-name><surname>Jin</surname><given-names>J</given-names></string-name>, <string-name><surname>Yin</surname><given-names>C</given-names></string-name>, <string-name><surname>Yu</surname><given-names>H</given-names></string-name>, <string-name><surname>Wang</surname><given-names>F</given-names></string-name>, <string-name><surname>Feng</surname><given-names>J</given-names></string-name>, <string-name><surname>Su</surname><given-names>R</given-names></string-name>, <string-name><surname>Nakai</surname><given-names>K</given-names></string-name>, <string-name><surname>Zou</surname><given-names>Q</given-names></string-name>, <etal>et al.</etal></person-group><article-title>DeepBIO: An automated and interpretable deep-learning platform for high-throughput biological sequence prediction, functional annotation and visualization analysis</article-title>. <source><italic toggle="yes">Nucleic Acids Res</italic></source>. <year>2023</year>;<volume>51</volume>(<issue>7</issue>):<fpage>3017</fpage>–<lpage>3029</lpage>.<pub-id pub-id-type="pmid">36796796</pub-id></mixed-citation>
    </ref>
    <ref id="B70">
      <label>70.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname><given-names>C</given-names></string-name>, <string-name><surname>Zou</surname><given-names>Q</given-names></string-name></person-group>. 
<article-title>Prediction of protein solubility based on sequence physicochemical patterns and distributed representation information with DeepSoluE</article-title>. <source><italic toggle="yes">BMC Biol</italic></source>. <year>2023</year>;<volume>21</volume>(<issue>1</issue>):<fpage>12</fpage>.<pub-id pub-id-type="pmid">36694239</pub-id></mixed-citation>
    </ref>
    <ref id="B71">
      <label>71.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jain</surname><given-names>S</given-names></string-name>, <string-name><surname>Jou</surname><given-names>JD</given-names></string-name>, <string-name><surname>Georgiev</surname><given-names>IS</given-names></string-name>, <string-name><surname>Donald</surname><given-names>BR</given-names></string-name></person-group>. 
<article-title>A critical analysis of computational protein design with sparse residue interaction graphs</article-title>. <source><italic toggle="yes">PLoS Comput Biol</italic></source>. <year>2017</year>;<volume>13</volume>(<issue>3</issue>):
<elocation-id>e1005346</elocation-id>.<pub-id pub-id-type="pmid">28358804</pub-id></mixed-citation>
    </ref>
    <ref id="B72">
      <label>72.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Murakami</surname><given-names>Y</given-names></string-name>, <string-name><surname>Mizuguchi</surname><given-names>K</given-names></string-name></person-group>. 
<article-title>Applying the naive Bayes classifier with kernel density estimation to the prediction of protein-protein interaction sites</article-title>. <source><italic toggle="yes">Bioinformatics</italic></source>. <year>2010</year>;<volume>26</volume>(<issue>15</issue>):<fpage>1841</fpage>–<lpage>1848</lpage>.<pub-id pub-id-type="pmid">20529890</pub-id></mixed-citation>
    </ref>
    <ref id="B73">
      <label>73.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Burley</surname><given-names>SK</given-names></string-name>, <string-name><surname>Bhikadiya</surname><given-names>C</given-names></string-name>, <string-name><surname>Bi</surname><given-names>C</given-names></string-name>, <string-name><surname>Bittrich</surname><given-names>S</given-names></string-name>, <string-name><surname>Chao</surname><given-names>H</given-names></string-name>, <string-name><surname>Chen</surname><given-names>L</given-names></string-name>, <string-name><surname>Craig</surname><given-names>PA</given-names></string-name>, <string-name><surname>Crichlow</surname><given-names>GV</given-names></string-name>, <string-name><surname>Dalenberg</surname><given-names>K</given-names></string-name>, <string-name><surname>Duarte</surname><given-names>JM</given-names></string-name>, <etal>et al.</etal></person-group><article-title>RCSB protein data Bank (<ext-link xlink:href="http://RCSB.org" ext-link-type="uri">RCSB.org</ext-link>): Delivery of experimentally-determined PDB structures alongside one million computed structure models of proteins from artificial intelligence/machine learning</article-title>. <source><italic toggle="yes">Nucleic Acids Res</italic></source>. <year>2023</year>;<volume>51</volume>(<issue>D1</issue>):<fpage>D488</fpage>–<lpage>D508</lpage>.<pub-id pub-id-type="pmid">36420884</pub-id></mixed-citation>
    </ref>
    <ref id="B74">
      <label>74.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jones</surname><given-names>S</given-names></string-name>, <string-name><surname>Thornton</surname><given-names>JM</given-names></string-name></person-group>. 
<article-title>Analysis of protein-protein interaction sites using surface patches</article-title>. <source><italic toggle="yes">J Mol Biol</italic></source>. <year>1997</year>;<volume>272</volume>(<issue>1</issue>):<fpage>121</fpage>–<lpage>132</lpage>.<pub-id pub-id-type="pmid">9299342</pub-id></mixed-citation>
    </ref>
    <ref id="B75">
      <label>75.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Altschul</surname><given-names>SF</given-names></string-name>, <string-name><surname>Gish</surname><given-names>W</given-names></string-name>, <string-name><surname>Miller</surname><given-names>W</given-names></string-name>, <string-name><surname>Myers</surname><given-names>EW</given-names></string-name>, <string-name><surname>Lipman</surname><given-names>DJ</given-names></string-name></person-group>. 
<article-title>Basic local alignment search tool</article-title>. <source><italic toggle="yes">J Mol Biol</italic></source>. <year>1990</year>;<volume>215</volume>(<issue>3</issue>):<fpage>403</fpage>–<lpage>410</lpage>.<pub-id pub-id-type="pmid">2231712</pub-id></mixed-citation>
    </ref>
    <ref id="B76">
      <label>76.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yang</surname><given-names>J</given-names></string-name>, <string-name><surname>Roy</surname><given-names>A</given-names></string-name>, <string-name><surname>Zhang</surname><given-names>Y</given-names></string-name></person-group>. 
<article-title>BioLiP: A semi-manually curated database for biologically relevant ligand-protein interactions</article-title>. <source><italic toggle="yes">Nucleic Acids Res</italic></source>. <year>2013</year>;<volume>41</volume>(<issue>D</issue>):<fpage>D1096</fpage>–<lpage>D1103</lpage>.<pub-id pub-id-type="pmid">23087378</pub-id></mixed-citation>
    </ref>
    <ref id="B77">
      <label>77.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname><given-names>BZ</given-names></string-name>, <string-name><surname>Li</surname><given-names>JY</given-names></string-name>, <string-name><surname>Quan</surname><given-names>LJ</given-names></string-name>, <string-name><surname>Chen</surname><given-names>Y</given-names></string-name>, <string-name><surname>Lu</surname><given-names>Q</given-names></string-name></person-group>. 
<article-title>Sequence-based prediction of protein-protein interaction sites by simplified long short-term memory network</article-title>. <source><italic toggle="yes">Neurocomputing</italic></source>. <year>2019</year>;<volume>357</volume>:<fpage>86</fpage>–<lpage>100</lpage>.</mixed-citation>
    </ref>
    <ref id="B78">
      <label>78.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname><given-names>J</given-names></string-name>, <string-name><surname>Ma</surname><given-names>Z</given-names></string-name>, <string-name><surname>Kurgan</surname><given-names>L</given-names></string-name></person-group>. 
<article-title>Comprehensive review and empirical analysis of hallmarks of DNA-, RNA- and protein-binding residues in protein chains</article-title>. <source><italic toggle="yes">Brief Bioinform</italic></source>. <year>2019</year>;<volume>20</volume>(<issue>4</issue>):<fpage>1250</fpage>–<lpage>1268</lpage>.<pub-id pub-id-type="pmid">29253082</pub-id></mixed-citation>
    </ref>
    <ref id="B79">
      <label>79.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fu</surname><given-names>L</given-names></string-name>, <string-name><surname>Niu</surname><given-names>B</given-names></string-name>, <string-name><surname>Zhu</surname><given-names>Z</given-names></string-name>, <string-name><surname>Wu</surname><given-names>S</given-names></string-name>, <string-name><surname>Li</surname><given-names>W</given-names></string-name></person-group>. 
<article-title>CD-HIT: Accelerated for clustering the next-generation sequencing data</article-title>. <source><italic toggle="yes">Bioinformatics</italic></source>. <year>2012</year>;<volume>28</volume>(<issue>23</issue>):<fpage>3150</fpage>–<lpage>3152</lpage>.<pub-id pub-id-type="pmid">23060610</pub-id></mixed-citation>
    </ref>
    <ref id="B80">
      <label>80.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pedregosa</surname><given-names>F</given-names></string-name>, <string-name><surname>Varoquaux</surname><given-names>G</given-names></string-name>, <string-name><surname>Gramfort</surname><given-names>A</given-names></string-name>, <string-name><surname>Michel</surname><given-names>V</given-names></string-name>, <string-name><surname>Thirion</surname><given-names>B</given-names></string-name>, <string-name><surname>Grisel</surname><given-names>O</given-names></string-name>, <string-name><surname>Blondel</surname><given-names>M</given-names></string-name>, <string-name><surname>Prettenhofer</surname><given-names>P</given-names></string-name>, <string-name><surname>Weiss</surname><given-names>R</given-names></string-name>, <string-name><surname>Dubourg</surname><given-names>V</given-names></string-name></person-group>. 
<article-title>Scikit-learn: Machine learning in python</article-title>. <source><italic toggle="yes">J Mach Learn Res</italic></source>. <year>2011</year>;<volume>12</volume>:<fpage>2825</fpage>–<lpage>2830</lpage>.</mixed-citation>
    </ref>
    <ref id="B81">
      <label>81.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Luo</surname><given-names>Y</given-names></string-name>, <string-name><surname>Wang</surname><given-names>P</given-names></string-name>, <string-name><surname>Mou</surname><given-names>M</given-names></string-name>, <string-name><surname>Zheng</surname><given-names>H</given-names></string-name>, <string-name><surname>Hong</surname><given-names>J</given-names></string-name>, <string-name><surname>Tao</surname><given-names>L</given-names></string-name>, <string-name><surname>Zhu</surname><given-names>F</given-names></string-name></person-group>. 
<article-title>A novel strategy for designing the magic shotguns for distantly related target pairs</article-title>. <source><italic toggle="yes">Brief Bioinform</italic></source>. <year>2023</year>;<volume>24</volume>(<issue>1</issue>):<fpage>bbac621</fpage>.<pub-id pub-id-type="pmid">36631399</pub-id></mixed-citation>
    </ref>
    <ref id="B82">
      <label>82.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname><given-names>Y</given-names></string-name>, <string-name><surname>Luo</surname><given-names>X</given-names></string-name>, <string-name><surname>Zou</surname><given-names>Q</given-names></string-name></person-group>. 
<article-title>Effector-GAN: Prediction of fungal effector proteins based on pretrained deep representation learning methods and generative adversarial networks</article-title>. <source><italic toggle="yes">Bioinformatics</italic></source>. <year>2022</year>;<volume>38</volume>(<issue>14</issue>):<fpage>3541</fpage>–<lpage>3548</lpage>.<pub-id pub-id-type="pmid">35640972</pub-id></mixed-citation>
    </ref>
    <ref id="B83">
      <label>83.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Suzek</surname><given-names>BE</given-names></string-name>, <string-name><surname>Wang</surname><given-names>Y</given-names></string-name>, <string-name><surname>Huang</surname><given-names>H</given-names></string-name>, <string-name><surname>McGarvey</surname><given-names>PB</given-names></string-name>, <string-name><surname>Wu</surname><given-names>CH</given-names></string-name>, <string-name><surname>UniProt</surname><given-names>C</given-names></string-name></person-group>. 
<article-title>UniRef clusters: A comprehensive and scalable alternative for improving sequence similarity searches</article-title>. <source><italic toggle="yes">Bioinformatics</italic></source>. <year>2015</year>;<volume>31</volume>(<issue>6</issue>):<fpage>926</fpage>–<lpage>932</lpage>.<pub-id pub-id-type="pmid">25398609</pub-id></mixed-citation>
    </ref>
    <ref id="B84">
      <label>84.</label>
      <mixed-citation publication-type="other">Dauphin YN, Fan A, Auli M, Grangier D. Language modeling with gated convolutional networks. Paper presented at: Proceedings of the 34th International Conference on Machine Learning; 2017; Sydney, Australia.</mixed-citation>
    </ref>
    <ref id="B85">
      <label>85.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rassil</surname><given-names>A</given-names></string-name>, <string-name><surname>Chougrad</surname><given-names>H</given-names></string-name>, <string-name><surname>Zouaki</surname><given-names>H</given-names></string-name></person-group>. 
<article-title>Augmented graph neural network with hierarchical global-based residual connections</article-title>. <source><italic toggle="yes">Neural Netw</italic></source>. <year>2022</year>;<volume>150</volume>:<fpage>149</fpage>–<lpage>166</lpage>.<pub-id pub-id-type="pmid">35313247</pub-id></mixed-citation>
    </ref>
    <ref id="B86">
      <label>86.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hou</surname><given-names>Z</given-names></string-name>, <string-name><surname>Yang</surname><given-names>Y</given-names></string-name>, <string-name><surname>Li</surname><given-names>H</given-names></string-name>, <string-name><surname>Wong</surname><given-names>KC</given-names></string-name>, <string-name><surname>Li</surname><given-names>X</given-names></string-name></person-group>. 
<article-title>iDeepSubMito: Identification of protein submitochondrial localization with deep learning</article-title>. <source><italic toggle="yes">Brief Bioinform</italic></source>. <year>2021</year>;<volume>22</volume>(<issue>6</issue>):<fpage>bbab288</fpage>.<pub-id pub-id-type="pmid">34337657</pub-id></mixed-citation>
    </ref>
    <ref id="B87">
      <label>87.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yang</surname><given-names>Y</given-names></string-name>, <string-name><surname>Hou</surname><given-names>Z</given-names></string-name>, <string-name><surname>Wang</surname><given-names>Y</given-names></string-name>, <string-name><surname>Ma</surname><given-names>H</given-names></string-name>, <string-name><surname>Sun</surname><given-names>P</given-names></string-name>, <string-name><surname>Ma</surname><given-names>Z</given-names></string-name>, <string-name><surname>Wong</surname><given-names>KC</given-names></string-name>, <string-name><surname>Li</surname><given-names>X</given-names></string-name></person-group>. 
<article-title>HCRNet: High-throughput circRNA-binding event identification from CLIP-seq data using deep temporal convolutional network</article-title>. <source><italic toggle="yes">Brief Bioinform</italic></source>. <year>2022</year>;<volume>23</volume>(<issue>2</issue>):<fpage>bbac027</fpage>.<pub-id pub-id-type="pmid">35189638</pub-id></mixed-citation>
    </ref>
    <ref id="B88">
      <label>88.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Luo</surname><given-names>G</given-names></string-name>, <string-name><surname>Zhou</surname><given-names>Y</given-names></string-name>, <string-name><surname>Sun</surname><given-names>X</given-names></string-name>, <string-name><surname>Wang</surname><given-names>Y</given-names></string-name>, <string-name><surname>Cao</surname><given-names>L</given-names></string-name>, <string-name><surname>Wu</surname><given-names>Y</given-names></string-name>, <string-name><surname>Huang</surname><given-names>F</given-names></string-name>, <string-name><surname>Ji</surname><given-names>R</given-names></string-name></person-group>. 
<article-title>Towards lightweight transformer via group-wise transformation for vision-and-language tasks</article-title>. <source><italic toggle="yes">IEEE Trans Image Process</italic></source>. <year>2022</year>;<volume>31</volume>:<fpage>3386</fpage>–<lpage>3398</lpage>.<pub-id pub-id-type="pmid">35471883</pub-id></mixed-citation>
    </ref>
    <ref id="B89">
      <label>89.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Eckle</surname><given-names>K</given-names></string-name>, <string-name><surname>Schmidt-Hieber</surname><given-names>J</given-names></string-name></person-group>. 
<article-title>A comparison of deep networks with ReLU activation function and linear spline-type methods</article-title>. <source><italic toggle="yes">Neural Netw</italic></source>. <year>2019</year>;<volume>110</volume>:<fpage>232</fpage>–<lpage>242</lpage>.<pub-id pub-id-type="pmid">30616095</pub-id></mixed-citation>
    </ref>
    <ref id="B90">
      <label>90.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Shen</surname><given-names>WX</given-names></string-name>, <string-name><surname>Zeng</surname><given-names>X</given-names></string-name>, <string-name><surname>Zhu</surname><given-names>F</given-names></string-name>, <string-name><surname>Wang</surname><given-names>YL</given-names></string-name>, <string-name><surname>Qin</surname><given-names>C</given-names></string-name>, <string-name><surname>Tan</surname><given-names>Y</given-names></string-name>, <string-name><surname>Jiang</surname><given-names>YY</given-names></string-name>, <string-name><surname>Chen</surname><given-names>YZ</given-names></string-name></person-group>. 
<article-title>Out-of-the-box deep learning prediction of pharmaceutical properties by broadly learned knowledge-based molecular representations</article-title>. <source><italic toggle="yes">Nat Mach Intelli</italic></source>. <year>2021</year>;<volume>3</volume>(<issue>4</issue>):<fpage>334</fpage>–<lpage>343</lpage>.</mixed-citation>
    </ref>
    <ref id="B91">
      <label>91.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chen</surname><given-names>L</given-names></string-name>, <string-name><surname>Tan</surname><given-names>X</given-names></string-name>, <string-name><surname>Wang</surname><given-names>D</given-names></string-name>, <string-name><surname>Zhong</surname><given-names>F</given-names></string-name>, <string-name><surname>Liu</surname><given-names>X</given-names></string-name>, <string-name><surname>Yang</surname><given-names>T</given-names></string-name>, <string-name><surname>Luo</surname><given-names>X</given-names></string-name>, <string-name><surname>Chen</surname><given-names>K</given-names></string-name>, <string-name><surname>Jiang</surname><given-names>H</given-names></string-name>, <string-name><surname>Zheng</surname><given-names>M</given-names></string-name></person-group>. 
<article-title>TransformerCPI: Improving compound-protein interaction prediction by sequence-based deep learning with self-attention mechanism and label reversal experiments</article-title>. <source><italic toggle="yes">Bioinformatics</italic></source>. <year>2020</year>;<volume>36</volume>(<issue>16</issue>):<fpage>4406</fpage>–<lpage>4414</lpage>.<pub-id pub-id-type="pmid">32428219</pub-id></mixed-citation>
    </ref>
    <ref id="B92">
      <label>92.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wenzel</surname><given-names>J</given-names></string-name>, <string-name><surname>Matter</surname><given-names>H</given-names></string-name>, <string-name><surname>Schmidt</surname><given-names>F</given-names></string-name></person-group>. 
<article-title>Predictive multitask deep neural network models for ADME-Tox properties: Learning from large data sets</article-title>. <source><italic toggle="yes">J Chem Inf Model</italic></source>. <year>2019</year>;<volume>59</volume>(<issue>3</issue>):<fpage>1253</fpage>–<lpage>1268</lpage>.<pub-id pub-id-type="pmid">30615828</pub-id></mixed-citation>
    </ref>
    <ref id="B93">
      <label>93.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname><given-names>C</given-names></string-name>, <string-name><surname>Mou</surname><given-names>M</given-names></string-name>, <string-name><surname>Zhou</surname><given-names>Y</given-names></string-name>, <string-name><surname>Zhang</surname><given-names>W</given-names></string-name>, <string-name><surname>Lian</surname><given-names>X</given-names></string-name>, <string-name><surname>Shi</surname><given-names>S</given-names></string-name>, <string-name><surname>Lu</surname><given-names>M</given-names></string-name>, <string-name><surname>Sun</surname><given-names>H</given-names></string-name>, <string-name><surname>Li</surname><given-names>F</given-names></string-name>, <string-name><surname>Wang</surname><given-names>Y</given-names></string-name>, <etal>et al.</etal></person-group><article-title>Biological activities of drug inactive ingredients</article-title>. <source><italic toggle="yes">Brief Bioinform</italic></source>. <year>2022</year>;<volume>23</volume>(<issue>5</issue>):<fpage>bbac160</fpage>.<pub-id pub-id-type="pmid">35524477</pub-id></mixed-citation>
    </ref>
    <ref id="B94">
      <label>94.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Xia</surname><given-names>W</given-names></string-name>, <string-name><surname>Zheng</surname><given-names>L</given-names></string-name>, <string-name><surname>Fang</surname><given-names>J</given-names></string-name>, <string-name><surname>Li</surname><given-names>F</given-names></string-name>, <string-name><surname>Zhou</surname><given-names>Y</given-names></string-name>, <string-name><surname>Zeng</surname><given-names>Z</given-names></string-name>, <string-name><surname>Zhang</surname><given-names>B</given-names></string-name>, <string-name><surname>Li</surname><given-names>Z</given-names></string-name>, <string-name><surname>Li</surname><given-names>H</given-names></string-name>, <string-name><surname>Zhu</surname><given-names>F</given-names></string-name></person-group>. 
<article-title>PFmulDL: A novel strategy enabling multi-class and multi-label protein function annotation by integrating diverse deep learning methods</article-title>. <source><italic toggle="yes">Comput Biol Med</italic></source>. <year>2022</year>;<volume>145</volume>:
<elocation-id>105465</elocation-id>.<pub-id pub-id-type="pmid">35366467</pub-id></mixed-citation>
    </ref>
    <ref id="B95">
      <label>95.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hong</surname><given-names>J</given-names></string-name>, <string-name><surname>Luo</surname><given-names>Y</given-names></string-name>, <string-name><surname>Mou</surname><given-names>M</given-names></string-name>, <string-name><surname>Fu</surname><given-names>J</given-names></string-name>, <string-name><surname>Zhang</surname><given-names>Y</given-names></string-name>, <string-name><surname>Xue</surname><given-names>W</given-names></string-name>, <string-name><surname>Xie</surname><given-names>T</given-names></string-name>, <string-name><surname>Tao</surname><given-names>L</given-names></string-name>, <string-name><surname>Lou</surname><given-names>Y</given-names></string-name>, <string-name><surname>Zhu</surname><given-names>F</given-names></string-name></person-group>. 
<article-title>Convolutional neural network-based annotation of bacterial type IV secretion system effectors with enhanced accuracy and reduced false discovery</article-title>. <source><italic toggle="yes">Brief Bioinform</italic></source>. <year>2020</year>;<volume>21</volume>(<issue>5</issue>):<fpage>1825</fpage>–<lpage>1836</lpage>.<pub-id pub-id-type="pmid">31860715</pub-id></mixed-citation>
    </ref>
    <ref id="B96">
      <label>96.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname><given-names>H</given-names></string-name>, <string-name><surname>Wang</surname><given-names>Y</given-names></string-name>, <string-name><surname>Pan</surname><given-names>Z</given-names></string-name>, <string-name><surname>Sun</surname><given-names>X</given-names></string-name>, <string-name><surname>Mou</surname><given-names>M</given-names></string-name>, <string-name><surname>Zhang</surname><given-names>B</given-names></string-name>, <string-name><surname>Li</surname><given-names>Z</given-names></string-name>, <string-name><surname>Li</surname><given-names>H</given-names></string-name>, <string-name><surname>Zhu</surname><given-names>F</given-names></string-name></person-group>. 
<article-title>ncRNAInter: A novel strategy based on graph neural network to discover interactions between lncRNA and miRNA</article-title>. <source><italic toggle="yes">Brief Bioinform</italic></source>. <year>2022</year>;<volume>23</volume>(<issue>6</issue>):<fpage>bbac411</fpage>.<pub-id pub-id-type="pmid">36198065</pub-id></mixed-citation>
    </ref>
    <ref id="B97">
      <label>97.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mummadi</surname><given-names>SR</given-names></string-name>, <string-name><surname>Al-Zubaidi</surname><given-names>A</given-names></string-name>, <string-name><surname>Hahn</surname><given-names>PY</given-names></string-name></person-group>. 
<article-title>Overfitting and use of mismatched cohorts in deep learning models: Preventable design limitations</article-title>. <source><italic toggle="yes">Am J Respir Crit Care Med</italic></source>. <year>2018</year>;<volume>198</volume>(<issue>4</issue>):<fpage>544</fpage>–<lpage>545</lpage>.<pub-id pub-id-type="pmid">29641217</pub-id></mixed-citation>
    </ref>
    <ref id="B98">
      <label>98.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bu</surname><given-names>Y</given-names></string-name>, <string-name><surname>Jia</surname><given-names>C</given-names></string-name>, <string-name><surname>Guo</surname><given-names>X</given-names></string-name>, <string-name><surname>Li</surname><given-names>F</given-names></string-name>, <string-name><surname>Song</surname><given-names>J</given-names></string-name></person-group>. 
<article-title>COPPER: An ensemble deep-learning approach for identifying exclusive virus-derived small interfering RNAs in plants</article-title>. <source><italic toggle="yes">Brief Funct Genomics</italic></source>. <year>2023</year>;<volume>22</volume>(<issue>3</issue>):<fpage>274</fpage>–<lpage>280</lpage>.<pub-id pub-id-type="pmid">36528813</pub-id></mixed-citation>
    </ref>
    <ref id="B99">
      <label>99.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Abrahamyan</surname><given-names>L</given-names></string-name>, <string-name><surname>Chen</surname><given-names>Y</given-names></string-name>, <string-name><surname>Bekoulis</surname><given-names>G</given-names></string-name>, <string-name><surname>Deligiannis</surname><given-names>N</given-names></string-name></person-group>. 
<article-title>Learned gradient compression for distributed deep learning</article-title>. <source><italic toggle="yes">IEEE Trans Neural Netw Learn Syst</italic></source>. <year>2022</year>;<volume>33</volume>(<issue>12</issue>):<fpage>7330</fpage>–<lpage>7344</lpage>.<pub-id pub-id-type="pmid">34111008</pub-id></mixed-citation>
    </ref>
    <ref id="B100">
      <label>100.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ofran</surname><given-names>Y</given-names></string-name>, <string-name><surname>Rost</surname><given-names>B</given-names></string-name></person-group>. 
<article-title>ISIS: Interaction sites identified from sequence</article-title>. <source><italic toggle="yes">Bioinformatics</italic></source>. <year>2007</year>;<volume>23</volume>(<issue>2</issue>):<fpage>e13</fpage>–<lpage>e16</lpage>.<pub-id pub-id-type="pmid">17237081</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
