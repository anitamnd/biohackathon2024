<?properties open_access?>
<?subarticle pcbi.1008697.r001?>
<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1d3 20150301//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 39.96?>
<?ConverterInfo.XSLTName jp2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
    <journal-id journal-id-type="iso-abbrev">PLoS Comput Biol</journal-id>
    <journal-id journal-id-type="publisher-id">plos</journal-id>
    <journal-id journal-id-type="pmc">ploscomp</journal-id>
    <journal-title-group>
      <journal-title>PLoS Computational Biology</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1553-734X</issn>
    <issn pub-type="epub">1553-7358</issn>
    <publisher>
      <publisher-name>Public Library of Science</publisher-name>
      <publisher-loc>San Francisco, CA USA</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">7904165</article-id>
    <article-id pub-id-type="pmid">33571205</article-id>
    <article-id pub-id-type="publisher-id">PCOMPBIOL-D-20-00512</article-id>
    <article-id pub-id-type="doi">10.1371/journal.pcbi.1008697</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Research Article</subject>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Computer and Information Sciences</subject>
        <subj-group>
          <subject>Software Engineering</subject>
          <subj-group>
            <subject>Computer Software</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Engineering and Technology</subject>
        <subj-group>
          <subject>Software Engineering</subject>
          <subj-group>
            <subject>Computer Software</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Physical Sciences</subject>
        <subj-group>
          <subject>Physics</subject>
          <subj-group>
            <subject>Classical Mechanics</subject>
            <subj-group>
              <subject>Kinematics</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Computer and Information Sciences</subject>
        <subj-group>
          <subject>Software Engineering</subject>
          <subj-group>
            <subject>Computer Software</subject>
            <subj-group>
              <subject>Open Source Software</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Engineering and Technology</subject>
        <subj-group>
          <subject>Software Engineering</subject>
          <subj-group>
            <subject>Computer Software</subject>
            <subj-group>
              <subject>Open Source Software</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Science Policy</subject>
        <subj-group>
          <subject>Open Science</subject>
          <subj-group>
            <subject>Open Source Software</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Engineering and Technology</subject>
        <subj-group>
          <subject>Signal Processing</subject>
          <subj-group>
            <subject>Image Processing</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Physical Sciences</subject>
        <subj-group>
          <subject>Mathematics</subject>
          <subj-group>
            <subject>Applied Mathematics</subject>
            <subj-group>
              <subject>Algorithms</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Research and Analysis Methods</subject>
        <subj-group>
          <subject>Simulation and Modeling</subject>
          <subj-group>
            <subject>Algorithms</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Research and Analysis Methods</subject>
        <subj-group>
          <subject>Imaging Techniques</subject>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Physical Sciences</subject>
        <subj-group>
          <subject>Mathematics</subject>
          <subj-group>
            <subject>Geometry</subject>
            <subj-group>
              <subject>Ellipses</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Physical Sciences</subject>
        <subj-group>
          <subject>Mathematics</subject>
          <subj-group>
            <subject>Optimization</subject>
          </subj-group>
        </subj-group>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>FastTrack: An open-source software for tracking varying numbers of deformable objects</article-title>
      <alt-title alt-title-type="running-head">FastTrack: An open-source software for tracking varying numbers of deformable objects</alt-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Gallois</surname>
          <given-names>Benjamin</given-names>
        </name>
        <role content-type="https://casrai.org/credit/">Data curation</role>
        <role content-type="https://casrai.org/credit/">Investigation</role>
        <role content-type="https://casrai.org/credit/">Software</role>
        <role content-type="https://casrai.org/credit/">Validation</role>
        <role content-type="https://casrai.org/credit/">Visualization</role>
        <role content-type="https://casrai.org/credit/">Writing – original draft</role>
        <role content-type="https://casrai.org/credit/">Writing – review &amp; editing</role>
        <xref ref-type="aff" rid="aff001"/>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-1523-6249</contrib-id>
        <name>
          <surname>Candelier</surname>
          <given-names>Raphaël</given-names>
        </name>
        <role content-type="https://casrai.org/credit/">Conceptualization</role>
        <role content-type="https://casrai.org/credit/">Data curation</role>
        <role content-type="https://casrai.org/credit/">Formal analysis</role>
        <role content-type="https://casrai.org/credit/">Funding acquisition</role>
        <role content-type="https://casrai.org/credit/">Investigation</role>
        <role content-type="https://casrai.org/credit/">Methodology</role>
        <role content-type="https://casrai.org/credit/">Project administration</role>
        <role content-type="https://casrai.org/credit/">Supervision</role>
        <role content-type="https://casrai.org/credit/">Validation</role>
        <role content-type="https://casrai.org/credit/">Writing – original draft</role>
        <role content-type="https://casrai.org/credit/">Writing – review &amp; editing</role>
        <xref ref-type="aff" rid="aff001"/>
        <xref ref-type="corresp" rid="cor001">*</xref>
      </contrib>
    </contrib-group>
    <aff id="aff001">
      <addr-line>Sorbonne Université, CNRS, Institut de Biologie Paris-Seine (IBPS), Laboratoire Jean Perrin (LJP), Paris, France</addr-line>
    </aff>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Marz</surname>
          <given-names>Manja</given-names>
        </name>
        <role>Editor</role>
        <xref ref-type="aff" rid="edit1"/>
      </contrib>
    </contrib-group>
    <aff id="edit1">
      <addr-line>bioinformatics, GERMANY</addr-line>
    </aff>
    <author-notes>
      <fn fn-type="COI-statement" id="coi001">
        <p>The authors have declared that no competing interests exist.</p>
      </fn>
      <corresp id="cor001">* E-mail: <email>raphael.candelier@sorbonne-universite.fr</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <month>2</month>
      <year>2021</year>
    </pub-date>
    <pub-date pub-type="epub">
      <day>11</day>
      <month>2</month>
      <year>2021</year>
    </pub-date>
    <volume>17</volume>
    <issue>2</issue>
    <elocation-id>e1008697</elocation-id>
    <history>
      <date date-type="received">
        <day>27</day>
        <month>3</month>
        <year>2020</year>
      </date>
      <date date-type="accepted">
        <day>10</day>
        <month>1</month>
        <year>2021</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© 2021 Gallois, Candelier</copyright-statement>
      <copyright-year>2021</copyright-year>
      <copyright-holder>Gallois, Candelier</copyright-holder>
      <license xlink:href="http://creativecommons.org/licenses/by/4.0/">
        <license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
      </license>
    </permissions>
    <self-uri content-type="pdf" xlink:href="pcbi.1008697.pdf"/>
    <abstract>
      <p>Analyzing the dynamical properties of mobile objects requires to extract trajectories from recordings, which is often done by tracking movies. We compiled a database of two-dimensional movies for very different biological and physical systems spanning a wide range of length scales and developed a general-purpose, optimized, open-source, cross-platform, easy to install and use, self-updating software called FastTrack. It can handle a changing number of deformable objects in a region of interest, and is particularly suitable for animal and cell tracking in two-dimensions. Furthermore, we introduce the probability of incursions as a new measure of a movie’s trackability that doesn’t require the knowledge of ground truth trajectories, since it is resilient to small amounts of errors and can be computed on the basis of an <italic>ad hoc</italic> tracking. We also leveraged the versatility and speed of FastTrack to implement an iterative algorithm determining a set of nearly-optimized tracking parameters—yet further reducing the amount of human intervention—and demonstrate that FastTrack can be used to explore the space of tracking parameters to optimize the number of swaps for a batch of similar movies. A benchmark shows that FastTrack is orders of magnitude faster than state-of-the-art tracking algorithms, with a comparable tracking accuracy. The source code is available under the GNU GPLv3 at <ext-link ext-link-type="uri" xlink:href="https://github.com/FastTrackOrg/FastTrack">https://github.com/FastTrackOrg/FastTrack</ext-link> and pre-compiled binaries for Windows, Mac and Linux are available at <ext-link ext-link-type="uri" xlink:href="http://www.fasttrack.sh">http://www.fasttrack.sh</ext-link>.</p>
    </abstract>
    <abstract abstract-type="summary">
      <title>Author summary</title>
      <p>Many researchers and engineers face the challenge of tracking objects from very different systems across several fields of research. We observed that despite this diversity the core of the tracking task is very general and can be formalized. We thus introduce the notion of <italic>incursions</italic>—<italic>i.e.</italic> to what extent an object can enter a neighbor’s space—which can be defined on a statistical basis and captures the interplay between the acquisition rate, the objects’ dynamics and the geometrical characteristics of the scene, including density. To validate this approach, we compiled a dataset from various fields of Physics, Biology and human activities to serve as a benchmark for general-purpose tracking softwares. This dataset is open and accepts new submissions. We also developped a software called <italic>FastTrack</italic> that is able to track most of the movies in the dataset by proposing standard image processing tools and state-of-the-art implementation of the matching algorithm, which is at the core of the tracking task. Besides, it is open-source, simple to install and use and has an ergonomic interface to obtain fast and reliable results. FastTrack is particularly convenient for small-scale research projects, typically when the development of a dedicated software is overkill.</p>
    </abstract>
    <funding-group>
      <award-group id="award001">
        <funding-source>
          <institution>ANR</institution>
        </funding-source>
        <award-id>ANR-16-CE16-0017</award-id>
        <principal-award-recipient>
          <contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-1523-6249</contrib-id>
          <name>
            <surname>Candelier</surname>
            <given-names>Raphaël</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
      <funding-statement>This work has been financed by an ANR JCJC grant (ANR-16-CE16-0017, <ext-link ext-link-type="uri" xlink:href="https://anr.fr/">https://anr.fr/</ext-link>) received by RC.</funding-statement>
    </funding-group>
    <counts>
      <fig-count count="5"/>
      <table-count count="0"/>
      <page-count count="19"/>
    </counts>
    <custom-meta-group>
      <custom-meta>
        <meta-name>PLOS Publication Stage</meta-name>
        <meta-value>vor-update-to-uncorrected-proof</meta-value>
      </custom-meta>
      <custom-meta>
        <meta-name>Publication Update</meta-name>
        <meta-value>2021-02-24</meta-value>
      </custom-meta>
      <custom-meta id="data-availability">
        <meta-name>Data Availability</meta-name>
        <meta-value>All data files are available from the TD2 database (<ext-link ext-link-type="uri" xlink:href="http://data.ljp.upmc.fr/datasets/TD2/">http://data.ljp.upmc.fr/datasets/TD2/</ext-link>).</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
  <notes>
    <title>Data Availability</title>
    <p>All data files are available from the TD2 database (<ext-link ext-link-type="uri" xlink:href="http://data.ljp.upmc.fr/datasets/TD2/">http://data.ljp.upmc.fr/datasets/TD2/</ext-link>).</p>
  </notes>
</front>
<body>
  <disp-quote>
    <p>This is a <italic>PLOS Computational Biology</italic> Software paper.</p>
  </disp-quote>
  <sec sec-type="intro" id="sec001">
    <title>Introduction</title>
    <p>Tracking objects moving in two dimensions is a demanded ability in computer vision, with applications in various fields of Biology ranging from the monitoring of cellular motion [<xref rid="pcbi.1008697.ref001" ref-type="bibr">1</xref>, <xref rid="pcbi.1008697.ref002" ref-type="bibr">2</xref>] to behavioral assays [<xref rid="pcbi.1008697.ref003" ref-type="bibr">3</xref>, <xref rid="pcbi.1008697.ref004" ref-type="bibr">4</xref>], but also in many other fields of Science—like microfluidics [<xref rid="pcbi.1008697.ref005" ref-type="bibr">5</xref>], active matter [<xref rid="pcbi.1008697.ref006" ref-type="bibr">6</xref>], social sciences [<xref rid="pcbi.1008697.ref007" ref-type="bibr">7</xref>] or robotics [<xref rid="pcbi.1008697.ref008" ref-type="bibr">8</xref>] to name a few—and in industrial processes [<xref rid="pcbi.1008697.ref009" ref-type="bibr">9</xref>]. There has been countless libraries and softwares designed for the purpose of tracking specific systems in specific conditions, but to date none has emerged as a general tool that could track virtually any type of object in a large panel of imaging conditions.</p>
    <p>This owes for a large part to the many issues arising during the detection phase, <italic>i.e.</italic> the definition of the objects that are present on each frame. In order to lower the error rate of the whole tracking process, many softwares focus on adaptating the details of object detection to the system of interest [<xref rid="pcbi.1008697.ref004" ref-type="bibr">4</xref>]. Yet, in various situations the objects are allowed to partly overlap (quasi two-dimensional systems), making proper detection extremely challenging. In particular, this is very common among biological systems since a strict planar confinment is often difficult to achieve and may bias the object’s dynamics [<xref rid="pcbi.1008697.ref010" ref-type="bibr">10</xref>–<xref rid="pcbi.1008697.ref012" ref-type="bibr">12</xref>]. A few algorithms have been developed to manage these situations by defining a unique identifier for each object that allows to recombine the trajectory fragments before and after occlusions [<xref rid="pcbi.1008697.ref013" ref-type="bibr">13</xref>, <xref rid="pcbi.1008697.ref014" ref-type="bibr">14</xref>]. This approach is however computationally heavy and limited to a small number of well-defined, non-saturated objects.</p>
    <p>Here we take a different approach and provide a software designed to be as general as possible. First, we created an open dataset comprising 41 movies of very different systems in order to test and benchmark general tracking softwares. Then, we created the FastTrack software that implements standard image processing techniques and a performant matching procedure. FastTrack can handle deformable objects as long as they keep a constant area and manages flawlessly a variable number of objects. For the end user, all these features allow to obtain excellent trackings in minutes for a very large panel of systems. To achieve perfect trackings, FastTrack also has a manual post-processing tool that displaces the workload from the fine-tuning of complex detection algorithms to the manual correction of a few remaining errors, if any. This strategy does not require programming skills and with an ergonomic interface it is time-saving for small size datasets or when there is a very low tolerance for errors.</p>
    <p>Furthermore, we propose a new quantifier called the probability of incursions, that can be computed based on a statistical analysis of the dynamical and geometric properties of each movie. We show that this probability displays a remarkable scaling with the logarithm of the sampling timescale, and that one can easily derive a robust and practical <italic>ad hoc</italic> characterization of virtually any movie. Finally, we implemented an algorithm to determine nearly-optimized tracking parameters automatically. FastTrack has already been used in a few publications [<xref rid="pcbi.1008697.ref015" ref-type="bibr">15</xref>, <xref rid="pcbi.1008697.ref016" ref-type="bibr">16</xref>] and is currently used for several research projects in Physics and Biology. The raw data for all plots can be found in <xref ref-type="supplementary-material" rid="pcbi.1008697.s012">S1 Data</xref>.</p>
  </sec>
  <sec id="sec002">
    <title>Dataset</title>
    <p>We compiled various video recordings to form a large dataset called the Two-Dimentional Tracking Dataset (TD<sup>2</sup>). It is open to new contributions and available for download at <ext-link ext-link-type="uri" xlink:href="http://data.ljp.upmc.fr/datasets/TD2/">http://data.ljp.upmc.fr/datasets/TD2/</ext-link>. All videos have been either previously published [<xref rid="pcbi.1008697.ref013" ref-type="bibr">13</xref>, <xref rid="pcbi.1008697.ref015" ref-type="bibr">15</xref>–<xref rid="pcbi.1008697.ref026" ref-type="bibr">26</xref>] or have been kindly provided by their authors and are licenced under the Non-Commercial, Share-Alike Creative Commons licence (CC BY-NC-SA). Each movie has an unique identifier composed of three letters and three digits (<italic>e.g.</italic>
<monospace>ACT_001</monospace>), that we use in the sequel anytime we need to refer to the data.</p>
    <p>The dataset comprises 41 sequences involving different types of objects at various scales: bacteria, paramecia, cells in a dense tissue, 7 animal species (including some whose behavior is commonly studied: fruit flies, medaka, zebrafish and mice), self-propelled particles, passive hard particles, droplets in microfluidic channels, centimetric robots, macroscopic objects on a conveyor belt, humans playing sports and traffic. A summary of the key features of each movie in the dataset is presented in <xref ref-type="supplementary-material" rid="pcbi.1008697.s001">S1 Table</xref>, thumbnails of the dataset are show in <xref ref-type="supplementary-material" rid="pcbi.1008697.s003">S1 Fig</xref> and <xref ref-type="supplementary-material" rid="pcbi.1008697.s008">S1 Video</xref> is a footage of the movies with the trajectories overlaid.</p>
    <p>The number of objects is constant in about half of the movies (22), while in the other half some objects appear or disappear at various locations in the field of view. Independantly, in about half the movies (20) the objects are moving in a strict two-dimensional space, while for the other half the objects evolve in a quasi-2D space and can at least partly overlap on some frames.</p>
  </sec>
  <sec id="sec003">
    <title>Software design and implementation</title>
    <p>FastTrack is written in C++ and respects the object-oriented programming paradigm. We use the OpenCV library for image processing and the Qt framework for the graphical user interface. The software wokflow is depicted in <xref ref-type="fig" rid="pcbi.1008697.g001">Fig 1</xref>, and can be broken down in three main phases: detection, matching and post-process.</p>
    <fig id="pcbi.1008697.g001" orientation="portrait" position="float">
      <object-id pub-id-type="doi">10.1371/journal.pcbi.1008697.g001</object-id>
      <label>Fig 1</label>
      <caption>
        <title>FastTrack flow chart.</title>
        <p>The workflow divides in three mains parts: detection, matching and post-process. The few steps that require user input are indicated by a <inline-formula id="pcbi.1008697.e026"><inline-graphic xlink:href="pcbi.1008697.e026.jpg" mimetype="image"/></inline-formula>. Sample dataset: <monospace>ZFJ_001</monospace>.</p>
      </caption>
      <graphic xlink:href="pcbi.1008697.g001"/>
    </fig>
    <p>As an entry point, the user defines data sources as video files (all formats supported by FFmpeg) or sequences of frames (<monospace>*.bmp</monospace>, <monospace>*.dib</monospace>, <monospace>*.jpeg</monospace>, <monospace>*.jpg</monospace>, <monospace>*.jpe</monospace>, <monospace>*.jp2</monospace>, <monospace>*.png</monospace>, <monospace>*.pbm</monospace>, <monospace>*.pgm</monospace>, <monospace>*.ppm</monospace>, <monospace>*.sr</monospace>, <monospace>*.ras</monospace>, <monospace>*.tiff</monospace> or <monospace>*.tif</monospace>) in a folder; in the latter case the images must have a naming convention with left-padded zeros to ensure a correct ordering of the frames (<italic>e.g.</italic>
<monospace>frame_000001.pgm</monospace>). The whole process described below can be applied on a movie-per-movie basis or for a batch of movies. In the latter case, the user can define different sets of parameters and background images, either manually or <italic>via</italic> a configuration file, and select subsets of movies for which the software will use those sets.</p>
    <sec id="sec004">
      <title>Detection</title>
      <p>This phase aims at extracting a collection of kinematic parameters (<italic>e.g.</italic> positions, direction, area) for each object in a frame. FastTrack includes a collection of standard image processing techniques to let the user adjust and perform object detection within the graphical interface for simple movies, without the need of an external pre-processing.</p>
      <sec id="sec005">
        <title>Image registration</title>
        <p>It is common to have translational and rotational drifts in movies, and several registration options are available to compensate for it [<xref rid="pcbi.1008697.ref027" ref-type="bibr">27</xref>]. FastTrack implements three different approaches: phase correlation, enhanced correlation coefficient and feature-based. All methods are implemented in a pyramidal way, <italic>i.e.</italic> registration is first performed on downsampled images to correct for large drifts and then minute corrections are computed from full resolution images.</p>
        <p>The phase correlation method detects translational drifts between two images by using the Fourier shift theorem in the frequency domain. This method is resilient to noise and artifacts but can misestimate large shifts. The enhanced correlation coefficient (ECC) registration method consists in maximizing the ECC function to find the best transformation between two images [<xref rid="pcbi.1008697.ref028" ref-type="bibr">28</xref>]. In FastTrack, the ECC registration is restraint to Euclidian motion (translation and rotation). This method has several assets, as it is invariant with respect to photometric distortion, performs well in noisy conditions and the solving time is linear, leading to an acceptable computation time with respect to other optimization algorithms [<xref rid="pcbi.1008697.ref028" ref-type="bibr">28</xref>] even though it is slower than the other two methods implemented here. Feature-based registration consists in finding key points and their descriptors in a pair of images and compute a homography. Then, the corresponding transformation is applied to all the pixels of one image to perform the registration. FastTrack uses the automatic ORB feature detector [<xref rid="pcbi.1008697.ref029" ref-type="bibr">29</xref>] to find approximately 500 key points in each image. The key points are matched pairwise between the two images using the Hamming distance. The homography is computed between the matching key points by using the Random Sample Consensus RANSAC [<xref rid="pcbi.1008697.ref030" ref-type="bibr">30</xref>] estimation method to minimize errors.</p>
        <p><xref ref-type="fig" rid="pcbi.1008697.g002">Fig 2</xref> provides a rough comparison of the performance of the three methods. Using two recordings of the dataset, we benchmarked both the accuracy—with the root mean squared difference (RMSD) of pixel intensities between the reference and the corrected image—and the relative computation time. Choosing the right method to obtain the best accuracy depends on each movie’s characteristics, but one can use the rule of thumb that if the objects to track occupy a large fraction of the total area then the best accuracy is more likely to be obtained by using ECC, and by using the features-based method otherwise. However, as shown in <xref ref-type="fig" rid="pcbi.1008697.g002">Fig 2C</xref> the ECC method is generally slower by an order of magnitude, so we recommend to use the features-based method in the general case, and <italic>a fortiori</italic> for long movies.</p>
        <fig id="pcbi.1008697.g002" orientation="portrait" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1008697.g002</object-id>
          <label>Fig 2</label>
          <caption>
            <title>Image registration.</title>
            <p>Two recordings with severe drift are used for benchmarking (top: <monospace>DRO_001</monospace>, bottom: <monospace>ULT_001</monospace>). (<bold>A</bold>) Comparison of a frame (magenta) with the first frame (green) and magnification of details in the scene. (<bold>B</bold>) Root mean square deviation (RMSD) of pixel intensities after registration onto the first image, averaged over all time frames and normalized by the RMSD without registration, for three registration methods. Error bars: standard deviation across time frames. (<bold>C</bold>) Relative average computation time of the three registration methods, normalized by the total number of pixels in the movie (arbitrary units). Error bars: standard deviation across time frames. Raw data are available in <xref ref-type="supplementary-material" rid="pcbi.1008697.s012">S1 Data</xref>.</p>
          </caption>
          <graphic xlink:href="pcbi.1008697.g002"/>
        </fig>
      </sec>
      <sec id="sec006">
        <title>Object detection</title>
        <p>Object detection is performed by binarizing the difference between the frames and a background, and filtering the result. At each step, the display is live-updated as the user changes the parameters to provide a direct visual feedback.</p>
        <p>In case the scene can be imaged without objects, or when specific computation are necessary, the background can be provided as a separate image file. Otherwise FastTrack can estimate the background by taking the minimum, maximum or average value of pixels on a subset of images taken at regular intervals. The user has then to specify the region of interest (ROI) in the images (default: full image), whether the background is lighter or darker than the objects to detect and provide a threshold to finalize the binarization.</p>
        <p>A collection of standard operations is implemented to filter the binary images: morphological operations (erosion, dilatation, closing, opening, gradient, top hat, black hat and hit miss) with rectangle, cross-shaped or elliptical kernels, and a filter based on the area of the remaining connex shapes can be used to remove both small artifacts (shapes below the minimal area threshold) and overlapping objects (shapes above the maximal area threshold). Finally, the objects’ contours are extracted from the remaining binary shapes by using the algorithm described in [<xref rid="pcbi.1008697.ref031" ref-type="bibr">31</xref>].</p>
      </sec>
      <sec id="sec007">
        <title>Kinematic parameters extraction</title>
        <p>Kinematic parameters are a collection of scalars that are extracted from the images in order to feed the matching algorithm. This step is at the core of any tracking procedure, and a large panel of parameters have been employed previously, ranging from basic measurements (<italic>e.g.</italic> position of the center of mass) to more complicated quantities aimed at identifying uniquely the object to track [<xref rid="pcbi.1008697.ref013" ref-type="bibr">13</xref>, <xref rid="pcbi.1008697.ref032" ref-type="bibr">32</xref>].</p>
        <p>Here, to improve speed the matching algorithm is based on quantities that are straightforward to obtain, namely the position of the center of mass, the angle of the binary object’s main axis, the area and the perimeter. To extract the position and angle, FastTrack computes the equivalent ellipse of each object by using the second order image moments as in [<xref rid="pcbi.1008697.ref033" ref-type="bibr">33</xref>], but for an even faster implementation we derived it from the contours using the Green’s formula [<xref rid="pcbi.1008697.ref034" ref-type="bibr">34</xref>]. The object’s orientation is given by the ellipse’s major axis and is only defined in the interval [0; <italic>π</italic>[. We determined the directions in the interval [0; 2<italic>π</italic>[ by projecting the pixels of each object on the major axis of the equivalent ellipse and calculating the skewness of the distribution of distances of these projected points to the center of mass. The sign of the skewness is a robust indicator of the asymmetry of the object along its principal axis.</p>
        <p>However, for non-rigid objects this direction can significantly deviate from the direction of motion. For instance, swimming fish bend their body and the instantaneous direction of motion is closer to the head’s direction than to the whole body’s (<italic>e.g.</italic>
<monospace>MED_001</monospace>, <monospace>ZFJ_001</monospace>, <monospace>ZFA_001</monospace>). We thus added as an option the method developed in [<xref rid="pcbi.1008697.ref035" ref-type="bibr">35</xref>–<xref rid="pcbi.1008697.ref037" ref-type="bibr">37</xref>] to decompose the objects in two ellipses—corresponding to the head and tail in the case of fish—and let the user determine which ellipse is more representative of the direction of motion (<xref ref-type="supplementary-material" rid="pcbi.1008697.s004">S2 Fig</xref>).</p>
      </sec>
    </sec>
    <sec id="sec008">
      <title>Matching</title>
      <p>In this step, objects on different frames are paired up based on the similarity of their kinematic parameters. FastTrack uses 4 kinematic parameters (position, direction, area and perimeter) in a method inspired by [<xref rid="pcbi.1008697.ref038" ref-type="bibr">38</xref>], which relies on the fact that objects usually change very little in position or direction between successive frames, as compared to their relative distances and angular difference.</p>
      <p>For each pair of objects (<italic>i</italic>, <italic>j</italic>) belonging to distinct time frames, and for each kinematic parameter, FastTrack computes a cost which is the product of a <italic>soft</italic> and a <italic>hard</italic> term (see <xref ref-type="supplementary-material" rid="pcbi.1008697.s005">S3 Fig</xref>). This terminology is brought from statistical physics, where particles can have soft, long-ranged interactions or hard, binary contacts. For instance, with position as kinematic parameter the hard term <inline-formula id="pcbi.1008697.e001"><alternatives><graphic xlink:href="pcbi.1008697.e001.jpg" id="pcbi.1008697.e001g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M1"><mml:msubsup><mml:mi>h</mml:mi><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> is set to 1 when the distance between <italic>i</italic> and <italic>j</italic> is smaller than a given threshold <italic>h</italic><sub><italic>r</italic></sub> and set to +∞ otherwise. The soft term <inline-formula id="pcbi.1008697.e002"><alternatives><graphic xlink:href="pcbi.1008697.e002.jpg" id="pcbi.1008697.e002g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M2"><mml:msubsup><mml:mi>s</mml:mi><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> is simply computed as the distance <italic>dr</italic><sub><italic>i</italic>,<italic>j</italic></sub> normalized by a factor <italic>s</italic><sub><italic>r</italic></sub>. Altogether, the complete cost function for a pair (<italic>i</italic>, <italic>j</italic>) writes:
<disp-formula id="pcbi.1008697.e003"><alternatives><graphic xlink:href="pcbi.1008697.e003.jpg" id="pcbi.1008697.e003g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M3"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mi>h</mml:mi><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msubsup><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>r</mml:mi></mml:msub></mml:mfrac><mml:mo>+</mml:mo><mml:msubsup><mml:mi>h</mml:mi><mml:mi>α</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msubsup><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>α</mml:mi></mml:msub></mml:mfrac><mml:mo>+</mml:mo><mml:msubsup><mml:mi>h</mml:mi><mml:mi>A</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msubsup><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>A</mml:mi></mml:msub></mml:mfrac><mml:mo>+</mml:mo><mml:msubsup><mml:mi>h</mml:mi><mml:mi>p</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msubsup><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>p</mml:mi></mml:msub></mml:mfrac></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(1)</label></disp-formula>
where <italic>dr</italic><sub><italic>i</italic>,<italic>j</italic></sub> is the distance between <italic>i</italic> and <italic>j</italic>, <italic>dα</italic><sub><italic>i</italic>,<italic>j</italic></sub> is the absolute angular difference between the directions of <italic>i</italic> and <italic>j</italic> defined in the interval [0; <italic>π</italic>] and <italic>dA</italic><sub><italic>i</italic>,<italic>j</italic></sub> and <italic>dp</italic><sub><italic>i</italic>,<italic>j</italic></sub> are the absolute difference of area and perimeter. If any of the hard thresholds is passed, then <italic>c</italic><sub><italic>i</italic>,<italic>j</italic></sub> = +∞ and the association is impossible. The soft factors <italic>s</italic><sub><italic>r</italic></sub>, <italic>s</italic><sub><italic>α</italic></sub>, <italic>s</italic><sub><italic>A</italic></sub> and <italic>s</italic><sub><italic>p</italic></sub> are normalization coefficients which represent the typical changes that an object undergoes between the two frames. In case one would like to discard a kinematic parameter from the computation, both the hard threshold and the soft factor have to be set to +∞.</p>
      <p>The cost matrix can be rectangular if the number of objects is not constant, typically when there are occlusions, object loss during the detection phase or entries and exits at the boundaries of the ROI. Finding the best matching amounts to define the set of pairs that minimizes the sum of costs for all retained pairs. This problem, sometimes called the <italic>rectangular assignment problem</italic>, falls into the category of linear assignment problems [<xref rid="pcbi.1008697.ref039" ref-type="bibr">39</xref>] and can be exactly solved using the Kuhn-Munkres algorithm [<xref rid="pcbi.1008697.ref040" ref-type="bibr">40</xref>], also called the <italic>Hungarian algorithm</italic>. FastTrack uses a fast C++ implementation [<xref rid="pcbi.1008697.ref041" ref-type="bibr">41</xref>] of this algorithm to perform the matching automatically.</p>
      <p>The Kuhn-Munkres algorithm operates only between two time frames, so in strict implementations when an object disappears the trajectory stops, and if it reappears later on a new trajectory is created. In order to deal with brief object disappearances we introduce a temporal hard parameter <italic>h</italic><sub><italic>t</italic></sub>, which is the maximal acceptable time during which an object can be lost. In practice, all the objects that have not been assigned in the few previous frames (below <italic>h</italic><sub><italic>t</italic></sub>) are also integrated in the cost matrix for the matching between <italic>t</italic> and <italic>t</italic> + 1. They are treated as pseudo-occurences at time <italic>t</italic>, though the resulting trajectories are generated such that they appear at the correct time frame, which is before <italic>t</italic>. This allows the algorithm to have a kind of “short-term memory” and manage short disappearances due to detection issues or occlusions for instance.</p>
      <p>In the graphical interface of FastTrack, the user can set up the tracking parameters and preview the tracked trajectories on a selected chunk of the image stack.</p>
    </sec>
    <sec id="sec009">
      <title>Post-processing</title>
      <sec id="sec010">
        <title>Output</title>
        <p>FastTrack delivers the tracking result in a single, large text file with one row per object per frame. This format is convenient since it can be parsed for subsequent analysis with many external tools. The array contains 23 columns corresponding to the features tracked; the main features are the position and direction of the object (<monospace>xBody</monospace>, <monospace>yBody</monospace>, <monospace>tBody</monospace>), the object’s id (<monospace>id</monospace>) and the frame index (<monospace>imageNumber</monospace>). The other features are self-explanatory and provided to the user for optional subsequent analysis.</p>
        <p>Additionnally, a movie with the tracking overlaid can be created from the <italic>Replay</italic> panel and saved in <monospace>AVI</monospace> format.</p>
      </sec>
      <sec id="sec011">
        <title>Manual post-processing</title>
        <p>The <italic>Replay</italic> panel can be used to manually correct for errors in the trajectories. The output text file can be loaded at any time and the display overlays tracking information like the objects’ indices or short-term anterior trajectories onto the original frames. Graphical controls as well as a set of keyboard shortcuts provide an efficient framework for spotting errors, remove fragments of trajectories and switch indices whenever necessary.</p>
      </sec>
    </sec>
  </sec>
  <sec sec-type="results" id="sec012">
    <title>Results</title>
    <sec id="sec013">
      <title>Processing of the dataset</title>
      <p>Being able to track objects in virtually any movie is an overwhelming challenge, and achieving this with one single software is, to date, utopic. This is primarily due to the versatility of the imaging conditions which multiply the number of approaches that are needed to correctly perform the detection phase. Two main pitfals can be discerned: the variations due to illumination (<italic>e.g.</italic> reflections as in <monospace>GRA_001</monospace>, shadows as in <monospace>SOC_001</monospace> and <monospace>TRA_001</monospace>) and the partial overlaps between objects (<italic>e.g.</italic>
<monospace>HXB_001</monospace>, <monospace>ZFA_001</monospace>).</p>
      <p>Still, many experimental setups in academia and production lines in industry are designed to mitigate these issues and it is common to have a uniform, diffuse and constant illumination, and either a compartimentation, strict two-dimensional confinment or low density of objects to avoid overlaps. In the TD<sup>2</sup> dataset, approximately half of the movies (23, see <xref ref-type="supplementary-material" rid="pcbi.1008697.s001">S1 Table</xref>) had sufficiently good illumination conditions to be tracked directly with FastTrack. The other movies required an additional pre-processing step, that was performed upstream with custom Matlab scripts. Severe and frequent overlaps impeded the processing of two movies (<monospace>HXB_001</monospace> and <monospace>ZFL_001</monospace>), that were discarded for the remaining of the analysis.</p>
      <p>Then, the workflow performed robustly and we could track the objects in the remaining 39 movies. The Kuhn-Munkres algorithm performs in <italic>O</italic>(<italic>n</italic><sup>3</sup>) polynomial time [<xref rid="pcbi.1008697.ref042" ref-type="bibr">42</xref>] so the matching phase is generally fast; on a modern workstation we observed processing peaks at 500 frames/s and it took at most a few minutes with up to more than 2,000 objects in the field of view over 1,000 frames (<monospace>GRA_001</monospace>). We then used the post-processing tools of FastTrack to manually correct for all remaining errors, and we could achieve a perfect tracking—within the margin of a few human errors that we may have missed—for all the dataset (<xref ref-type="supplementary-material" rid="pcbi.1008697.s008">S1 Video</xref>) in a reasonable time. In the following, we refer to these trajectories as the <italic>ground truth</italic> trajectories.</p>
    </sec>
    <sec id="sec014">
      <title>Classification of the dataset based on incursions</title>
      <p>To characterize and classify the different movies of the dataset, we introduce the notion of “incursions”. Incursions happen every time an object travels sufficiently between to time points to exit its own Voronoï cell, defined at the initial time, thus entering one of it’s neighbor’s cell. With this definition the Voronoï cells are static boundaries defined by the initial frame, and the likelyhood of an incursion highly depends on the timescale <italic>τ</italic> over which the displacement is observed (<xref ref-type="fig" rid="pcbi.1008697.g003">Fig 3A</xref>), with <italic>τ</italic> = 1 corresponding to the time between two successive frames. On a global scale, the amount of incursions depends on the distribution of displacements but also on the density <italic>d</italic> (defined as the number of objects per unit area), the complex statistical properties of the geometry of Voronoï cells and the degree of motion alignment.</p>
      <fig id="pcbi.1008697.g003" orientation="portrait" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1008697.g003</object-id>
        <label>Fig 3</label>
        <caption>
          <title>Characterization of the TD<sup>2</sup> dataset.</title>
          <p>(<bold>A</bold>) Illustration of the dynamics at various timescales in <monospace>ACT_002</monospace>. The Voronoï cells (dashed white) and the displacements of a particle at <italic>τ</italic> = 1, 10 and 100 are overlaid. (<bold>B</bold>) Geometric probability of incursion <italic>p</italic><sub><italic>inc</italic></sub> (red) and distribution of the reduced displacement <italic>ρ</italic> at three different timescales <italic>τ</italic> (black) in <monospace>ACT_002</monospace>. The probability of incursion <italic>P</italic><sub><italic>inc</italic></sub> is the intersection of the areas under the two curves. (<bold>C</bold>) <italic>P</italic><sub><italic>inc</italic></sub> as a function of <italic>τ</italic> for the whole dataset (symbols). The solid lines are fits with a logistic function (see text). (<bold>D</bold>) Scaling of the reduced quantities <italic>P</italic><sub><italic>inc</italic></sub>/<italic>L</italic> as a function of <inline-formula id="pcbi.1008697.e004"><alternatives><graphic id="pcbi.1008697.e004g" xlink:href="pcbi.1008697.e004"/><mml:math id="M4"><mml:mrow><mml:mi>k</mml:mi><mml:mo>.</mml:mo><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>g</mml:mi><mml:mo>(</mml:mo><mml:mfrac><mml:mi>τ</mml:mi><mml:msub><mml:mi>τ</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mfrac><mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> on the standard logistic sigmoid function (solid black). (<bold>E</bold>) Classification of the movies in the dataset by increasing values of <italic>τ</italic><sub>1</sub> as defined by <xref ref-type="disp-formula" rid="pcbi.1008697.e009">Eq (4)</xref>, with fitting parameters determined over a logarithmic scale for <italic>P</italic><sub><italic>inc</italic></sub>. Movies with <italic>τ</italic><sub>1</sub> &lt; 1 are undersampled while movies with <italic>τ</italic><sub>1</sub> &gt; 1 are oversampled. (<bold>F</bold>) Comparison of <italic>P</italic><sub><italic>inc</italic></sub>(<italic>τ</italic>) for different levels of degradation <italic>δ</italic> (symbols) and corresponding logistic fits (solid curves) in <monospace>ACT_002</monospace>. (<bold>G-I</bold>) Evolutions of the fitting parameters <italic>L</italic>, <italic>k</italic> and <italic>τ</italic><sub>0</sub> as a function of the degration <italic>δ</italic> in <monospace>ACT_002</monospace>.</p>
        </caption>
        <graphic xlink:href="pcbi.1008697.g003"/>
      </fig>
      <p>To account for the density, we use the dimensionless reduced displacement <inline-formula id="pcbi.1008697.e005"><alternatives><graphic xlink:href="pcbi.1008697.e005.jpg" id="pcbi.1008697.e005g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M5"><mml:mrow><mml:mi>ρ</mml:mi><mml:mo>=</mml:mo><mml:mi>r</mml:mi><mml:msqrt><mml:mi>d</mml:mi></mml:msqrt></mml:mrow></mml:math></alternatives></inline-formula>. A value of <italic>ρ</italic> = 1 represents the typical distance between two objects, while <italic>ρ</italic> = 1/2 is the typical distance for an object to travel before entering a neighbor’s Voronoï cell. Then, for a given displacement <italic>ρ</italic> we compute the <italic>geometric probability of incursion</italic>
<italic>p</italic><sub><italic>inc</italic></sub>(<italic>ρ</italic>) by determining the proportion of angles for which incursions occur, on average over a representatively large set of Voronoï cells. As illustrated in <xref ref-type="fig" rid="pcbi.1008697.g003">Fig 3B</xref>, <italic>p</italic><sub><italic>inc</italic></sub>(<italic>ρ</italic>) always has a sigmoid shape with an inflection point close to <italic>ρ</italic> = 1/2. The precise shape of this function is sensitive to the compacity of the objects in the scene: if they are sparsely distributed (<italic>e.g.</italic>
<monospace>PAR_001</monospace>, <monospace>ROT_001</monospace>) then the Voronoï cells are highly heteregeneous and <italic>p</italic><sub><italic>inc</italic></sub> growns slowly, while for dense packings forming an hexagonal pattern (<italic>e.g.</italic>
<monospace>ACT_002</monospace>, <monospace>DRP_001</monospace>) the cells are stereotyped and <italic>p</italic><sub><italic>inc</italic></sub> increases steeply. The asymptotic value of <italic>p</italic><sub><italic>inc</italic></sub> for <italic>ρ</italic> ≫ 1 may not be 1 for systems with reflective walls and a low number of objects, as show in <xref ref-type="supplementary-material" rid="pcbi.1008697.s006">S4 Fig</xref>.</p>
      <p>Assuming that the dynamics is uncorrelated with the geometric properties of the Voronoï cells, the probability of incursion writes:
<disp-formula id="pcbi.1008697.e006"><alternatives><graphic xlink:href="pcbi.1008697.e006.jpg" id="pcbi.1008697.e006g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M6"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mo>∫</mml:mo><mml:mn>0</mml:mn><mml:mi>∞</mml:mi></mml:msubsup><mml:mi>R</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>ρ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>ρ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mi>d</mml:mi><mml:mi>ρ</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(2)</label></disp-formula>
where <italic>R</italic>(<italic>ρ</italic>) is the distribution of <italic>ρ</italic> at the timescale <italic>τ</italic>. The distribution <italic>R</italic>(<italic>ρ</italic>) is shown in <xref ref-type="fig" rid="pcbi.1008697.g003">Fig 3B</xref> for three values of <italic>τ</italic>, and a graphical way of calculating <italic>P</italic><sub><italic>inc</italic></sub> is to take the intersection of the areas under <italic>R</italic>(<italic>ρ</italic>) and <italic>p</italic><sub><italic>inc</italic></sub>(<italic>ρ</italic>). In the regime where <italic>R</italic>(<italic>ρ</italic>) and <italic>p</italic><sub><italic>inc</italic></sub>(<italic>ρ</italic>) are well-separated, the resulting value of <italic>P</italic><sub><italic>inc</italic></sub> are low but also highly sensitive to the amount of swaps in the tracking; indeed, the swaps create a bump in <italic>R</italic> at values of <italic>ρ</italic> close to one that can artificially increase <italic>P</italic><sub><italic>inc</italic></sub> of orders of magnitude. So, unless the ground truth trajectories are accessible, in most cases the single value of <italic>P</italic><sub><italic>inc</italic></sub> at <italic>τ</italic> = 1 cannot be used as an <italic>ad hoc</italic> measure for the trackability of a movie.</p>
      <p>A timescale-varying analysis allowed us to extract more robust quantifiers. As <italic>p</italic><sub><italic>inc</italic></sub>(<italic>ρ</italic>) does not depend on <italic>τ</italic> and <italic>R</italic>(<italic>ρ</italic>) is shifted to the high values of <italic>ρ</italic> when <italic>τ</italic> increases, one can easily expect that <italic>P</italic><sub><italic>inc</italic></sub>(<italic>τ</italic>) has a sigmoid-like shape. We thus computed <italic>P</italic><sub><italic>inc</italic></sub> for various values of <italic>τ</italic>: for <italic>τ</italic> &gt; 1 we tooks integer values (<italic>i.e.</italic> keep one frame every <italic>τ</italic>) while for <italic>τ</italic> &lt; 1 we linearly interpolated the displacements (<italic>i.e.</italic> multiplied <italic>ρ</italic> by <italic>τ</italic>). We represented the results in <xref ref-type="fig" rid="pcbi.1008697.g003">Fig 3C</xref> for the 39 movies that could be tracked in the dataset. Strikingly, all <italic>P</italic><sub><italic>inc</italic></sub> followed a logistic curve when <italic>τ</italic> is log-scaled so we used fits of the form:
<disp-formula id="pcbi.1008697.e007"><alternatives><graphic xlink:href="pcbi.1008697.e007.jpg" id="pcbi.1008697.e007g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M7"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mi>L</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mi>k</mml:mi><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>τ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>-</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(3)</label></disp-formula>
and, noting <inline-formula id="pcbi.1008697.e008"><alternatives><graphic xlink:href="pcbi.1008697.e008.jpg" id="pcbi.1008697.e008g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M8"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:msup></mml:mrow></mml:math></alternatives></inline-formula>, the fitting function can be rewritten as:
<disp-formula id="pcbi.1008697.e009"><alternatives><graphic xlink:href="pcbi.1008697.e009.jpg" id="pcbi.1008697.e009g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M9"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mi>L</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:msub><mml:mi>τ</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mi>τ</mml:mi></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:mi>k</mml:mi></mml:msup></mml:mrow></mml:mfrac></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(4)</label></disp-formula></p>
      <p>The fits are shown in <xref ref-type="fig" rid="pcbi.1008697.g003">Fig 3C</xref>, and are valid for all the movies in the dataset. To make all data collapse on a single master curve, we show in <xref ref-type="fig" rid="pcbi.1008697.g003">Fig 3D</xref> that <italic>P</italic><sub><italic>inc</italic></sub>/<italic>L</italic> plotted as a function of <inline-formula id="pcbi.1008697.e010"><alternatives><graphic xlink:href="pcbi.1008697.e010.jpg" id="pcbi.1008697.e010g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M10"><mml:mrow><mml:mi>k</mml:mi><mml:mo>.</mml:mo><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>g</mml:mi><mml:mo>(</mml:mo><mml:mfrac><mml:mi>τ</mml:mi><mml:msub><mml:mi>τ</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mfrac><mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> follows the standard logistic sigmoid function <inline-formula id="pcbi.1008697.e011"><alternatives><graphic xlink:href="pcbi.1008697.e011.jpg" id="pcbi.1008697.e011g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M11"><mml:mrow><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:mrow></mml:math></alternatives></inline-formula>.</p>
      <p>An interesting outcome of this approach is the ability to determine the framerate at which experiments should be performed. It is indeed a recurent experimental question, as high temporal resolution is preferable to reduce the number of incursions and ease the tracking, but may not always be accessible (<italic>e.g.</italic> limited sensor rate, intense illumination required as the exposure time drops) and generates large amounts of images to store and process. We computed <italic>τ</italic><sub>1</sub>, the timescale at which <italic>P</italic><sub><italic>inc</italic></sub> reaches the inverse of the total number of objects on all frames <italic>N</italic><sub><italic>obj</italic></sub>, <italic>i.e.</italic> the probability of a single incursion in the whole movie. As <italic>τ</italic><sub>1</sub> defines the onset of incursions and the possibility of swaps in the tracking procedure, it can be used as an indicator of the sampling quality of each movie. Movies with <italic>τ</italic><sub>1</sub> &lt; 1 already have incursions at the current framerate and are thus <italic>undersampled</italic>, whereas for movies with <italic>τ</italic><sub>1</sub> &gt; 1 the current framerate can be degraded without triggering incursions, they are <italic>oversampled</italic>. In addition, <italic>τ</italic><sub>1</sub> is directly the resampling factor that one should use to have the minimal movie size without generating incursions. Using <xref ref-type="disp-formula" rid="pcbi.1008697.e009">Eq (4)</xref>, it reads:
<disp-formula id="pcbi.1008697.e012"><alternatives><graphic xlink:href="pcbi.1008697.e012.jpg" id="pcbi.1008697.e012g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M12"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>L</mml:mi><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>o</mml:mi><mml:mi>b</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>k</mml:mi></mml:mfrac></mml:mrow></mml:msup></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(5)</label></disp-formula></p>
      <p>We ordered the values of <italic>τ</italic><sub>1</sub> in <xref ref-type="fig" rid="pcbi.1008697.g003">Fig 3E</xref>, and it appears that three quarters (30) of the movies are oversampled; one should not expect any difficulty in the tracking of these movies with respect to incursions. On the other hand, the 9 undersampled recordings were already known to be difficult to track; three of them (<monospace>ACT_003</monospace>, <monospace>ACT_004</monospace> and <monospace>GRA_003</monospace>) have required specific algorithms for analysis [<xref rid="pcbi.1008697.ref019" ref-type="bibr">19</xref>, <xref rid="pcbi.1008697.ref020" ref-type="bibr">20</xref>, <xref rid="pcbi.1008697.ref024" ref-type="bibr">24</xref>] and two (<monospace>BAC_001</monospace>, <monospace>ZFA_001</monospace>) required dedicated softwares [<xref rid="pcbi.1008697.ref013" ref-type="bibr">13</xref>, <xref rid="pcbi.1008697.ref043" ref-type="bibr">43</xref>, <xref rid="pcbi.1008697.ref044" ref-type="bibr">44</xref>].</p>
      <p>Then, we tested to what extent this characterization is robust to swaps in the trajectories. Starting from the ground truth trajectories of <monospace>ACT_002</monospace>, we degraded the trajectories by introducing random swaps between neighboring objects. This process is controlled by a degradation rate <italic>δ</italic>, which is the number of artificial swaps divided by the total number of objects on all frames. Such a degradation affects the small timescales more severely, so the multi-scale approach takes on its full interest: as depicted in <xref ref-type="fig" rid="pcbi.1008697.g003">Fig 3F to 3I</xref>, the fits of <italic>P</italic><sub><italic>inc</italic></sub>(<italic>τ</italic>) are insensitive to degradation up to a remarkably high level of <italic>δ</italic> ≃ 10<sup>−3</sup>. This means that even a poor-quality tracking can be used as an input for this method: as long as the distribution of displacements is only marginally affected, the output remains unchanged.</p>
    </sec>
    <sec id="sec015">
      <title>Automatic tracking parameters</title>
      <p>In this section we detail the procedure used by FastTrack to determine automatically the soft normalization factors (<italic>s</italic><sub><italic>r</italic></sub>, <italic>s</italic><sub><italic>α</italic></sub>, <italic>s</italic><sub><italic>A</italic></sub> and <italic>s</italic><sub><italic>p</italic></sub>) which, according to <xref ref-type="disp-formula" rid="pcbi.1008697.e003">Eq (1)</xref>, allow to compare terms of very different nature and amplitude into a single cost function. It is therefore intuitive to use the standard deviation of the increments of each kinematic parameter. However, as one needs some trajectories in order to estimate the standard deviations, we set up an iterative, rapidly-converging algorithm.</p>
      <p>Let us use <monospace>ZFJ_001</monospace>, a movie that is slightly oversampled but with many occlusions and objects of different sizes to illustrate the details of the algorithm. For the sake of simplicity let us use here only the position, angle and area as kinematic parameters—it is straightforward to add the perimeter to the method but there is no gain to expect as the objects shapes are very similar. A snapshot of this movie is shown in <xref ref-type="fig" rid="pcbi.1008697.g004">Fig 4A</xref>.</p>
      <fig id="pcbi.1008697.g004" orientation="portrait" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1008697.g004</object-id>
        <label>Fig 4</label>
        <caption>
          <title>Automatic tracking parameters.</title>
          <p>(<bold>A</bold>) Snapshot and blow-up of <monospace>ZFJ_001</monospace>, with definition of <inline-formula id="pcbi.1008697.e013"><alternatives><graphic id="pcbi.1008697.e013g" xlink:href="pcbi.1008697.e013"/><mml:math id="M13"><mml:mover accent="true"><mml:mrow><mml:mi>d</mml:mi><mml:mi>r</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover></mml:math></alternatives></inline-formula> and <italic>dα</italic> (<bold>B</bold>) Scheme of the algorithm for determining the tracking parameters automatically. (<bold>C-E</bold>) Distribution of displacements <italic>dr</italic> (in pixels), angular differences <italic>dα</italic> (in radians) and area differences <italic>dA</italic> (in pixels) when the default parameters of the software are used on <monospace>ZFJ_001</monospace>, for <italic>τ</italic> = 1 (black). The corresponding <italic>χ</italic> and Gaussian fits are displayed in red. Orange bars: resulting soft parameters. (<bold>F</bold>) Evolution of <italic>s</italic><sub><italic>r</italic></sub>, <italic>s</italic><sub><italic>α</italic></sub> and <italic>s</italic><sub><italic>A</italic></sub> with algorithm iterations for <monospace>ZFJ_001</monospace>. Left: iterations 1 and 2; right: iterations 2 and 3. A hundred runs with random initial values are shown, the run with the software default parameters is highlighted in red. (<bold>G</bold>) Evolution of <italic>P</italic><sub><italic>swap</italic></sub> with algorithm iterations, same runs. (<bold>H-J</bold>) Evolution of the converged parameters <inline-formula id="pcbi.1008697.e014"><alternatives><graphic id="pcbi.1008697.e014g" xlink:href="pcbi.1008697.e014"/><mml:math id="M14"><mml:msub><mml:mover accent="true"><mml:mi>s</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>r</mml:mi></mml:msub></mml:math></alternatives></inline-formula>, <inline-formula id="pcbi.1008697.e015"><alternatives><graphic id="pcbi.1008697.e015g" xlink:href="pcbi.1008697.e015"/><mml:math id="M15"><mml:msub><mml:mover accent="true"><mml:mi>s</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>α</mml:mi></mml:msub></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1008697.e016"><alternatives><graphic id="pcbi.1008697.e016g" xlink:href="pcbi.1008697.e016"/><mml:math id="M16"><mml:msub><mml:mover accent="true"><mml:mi>s</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>A</mml:mi></mml:msub></mml:math></alternatives></inline-formula> as a function of the timescale <italic>τ</italic> for <monospace>ZFJ_001</monospace>. (<bold>K</bold>) Comparison between <italic>P</italic><sub><italic>swap</italic></sub> (blue crosses) obtained with the converged parameters and <italic>P</italic><sub><italic>inc</italic></sub> (red dots) for <monospace>ZFJ_001</monospace>. The solid black line is the logistic fit of <italic>P</italic><sub><italic>inc</italic></sub>.</p>
        </caption>
        <graphic xlink:href="pcbi.1008697.g004"/>
      </fig>
      <p>In order to evaluate the distributions of <italic>dr</italic>, <italic>dα</italic> and <italic>dA</italic>, we start by tracking the movie with the default parameters of the software. The resulting distributions are shown in <xref ref-type="fig" rid="pcbi.1008697.g004">Fig 4C to 4E</xref>. Then, for kinematic parameters whose differential values can be positive or negative the distribution is fitted by a Gaussian function and the soft parameter is set at the standard deviation. For instance with the angular difference <italic>dα</italic> the fit reads:
<disp-formula id="pcbi.1008697.e017"><alternatives><graphic xlink:href="pcbi.1008697.e017.jpg" id="pcbi.1008697.e017g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M17"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>d</mml:mi><mml:mi>α</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>α</mml:mi></mml:msub><mml:msqrt><mml:mrow><mml:mn>2</mml:mn><mml:mi>π</mml:mi></mml:mrow></mml:msqrt></mml:mrow></mml:mfrac><mml:mspace width="0.277778em"/><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msup><mml:mi>α</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:msubsup><mml:mi>s</mml:mi><mml:mi>α</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mfrac></mml:mrow></mml:msup></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(6)</label></disp-formula>
and <italic>s</italic><sub><italic>α</italic></sub> (orange bar in <xref ref-type="fig" rid="pcbi.1008697.g004">Fig 4D</xref>) is stored as the soft parameter to use during the next iteration. The computation of the soft parameter for displacement <italic>s</italic><sub><italic>r</italic></sub> is different since distances can only be positive. Assuming that the displacements along the <italic>x</italic> and <italic>y</italic> axes follow two independent Gaussian processes, the resulting displacement follows a <italic>χ</italic> distribution with 2 degrees of freedom and the fit reads:
<disp-formula id="pcbi.1008697.e018"><alternatives><graphic xlink:href="pcbi.1008697.e018.jpg" id="pcbi.1008697.e018g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M18"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>d</mml:mi><mml:mi>r</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mi>r</mml:mi></mml:mrow><mml:msubsup><mml:mi>s</mml:mi><mml:mi>r</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mfrac><mml:mspace width="0.277778em"/><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msup><mml:mi>r</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:msubsup><mml:mi>s</mml:mi><mml:mi>r</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mfrac></mml:mrow></mml:msup></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(7)</label></disp-formula>
where <italic>s</italic><sub><italic>r</italic></sub> (orange bar in <xref ref-type="fig" rid="pcbi.1008697.g004">Fig 4C</xref>) is stored as the soft parameter to use for the next iteration.</p>
      <p>Once all tracking parameters have been derived fom the distributions, the software recomputes new trajectories and updates the distributions. This iterative process, depicted in <xref ref-type="fig" rid="pcbi.1008697.g004">Fig 4B</xref>, is run until the tracking parameters converge. In practice, the convergence is very fast regardless of the initial position in the parameters space: we drawn 100 sets of seed parameters from uniform distributions spanning large intervals and convergence has been attained in a very few iterations for all parameters (<xref ref-type="fig" rid="pcbi.1008697.g004">Fig 4F</xref>). The convergence criterion implemented in the software is that all parameters should vary that less than 10<sup>−3</sup> of the corresponding soft parameter.</p>
      <p>We then characterized the resulting trackings by computing the amount of swaps with respect to the ground truth, captured by the probability of swaps:
<disp-formula id="pcbi.1008697.e019"><alternatives><graphic xlink:href="pcbi.1008697.e019.jpg" id="pcbi.1008697.e019g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M19"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>w</mml:mi><mml:mi>a</mml:mi><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>w</mml:mi><mml:mi>a</mml:mi><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>o</mml:mi><mml:mi>b</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mi>p</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(8)</label></disp-formula>
with <italic>N</italic><sub><italic>swap</italic></sub> being the total number of swaps, <italic>N</italic><sub><italic>obj</italic></sub> the total number of objects on all frames and <italic>n</italic><sub><italic>ap</italic></sub> the number of times a new object appears. If the number of objects is constant and noted <italic>n</italic>, then <italic>n</italic><sub><italic>ap</italic></sub> = <italic>n</italic> and <italic>N</italic><sub><italic>obj</italic></sub> = <italic>nT</italic>, with <italic>T</italic> the number of frames in the recording, such that <italic>P</italic><sub><italic>swap</italic></sub> simply reads:
<disp-formula id="pcbi.1008697.e020"><alternatives><graphic xlink:href="pcbi.1008697.e020.jpg" id="pcbi.1008697.e020g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M20"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>w</mml:mi><mml:mi>a</mml:mi><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>w</mml:mi><mml:mi>a</mml:mi><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mi>n</mml:mi><mml:mo>(</mml:mo><mml:mi>T</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(9)</label></disp-formula></p>
      <p><italic>P</italic><sub><italic>swap</italic></sub> also converges very fast, to a value that is nearly-optimal: for 77% of the parameter sets <italic>P</italic><sub><italic>swap</italic></sub> is decreased or remain equal, with an average drop of 0.0119 (155% of the converged value), while for 23% of the parameter sets <italic>P</italic><sub><italic>swap</italic></sub> is increased with an average rise of 0.0011 (14% of the converged value). The expected difference is thus −0.0090 (116% of the converged value) for this movie. The automatic parameters are therefore a very good starting point in the general case, over which the end user can fine-tune the weights given to the kinetic parameters to take into account the specificities of each movie.</p>
      <p>Then, we computed the converged soft parameters <inline-formula id="pcbi.1008697.e021"><alternatives><graphic xlink:href="pcbi.1008697.e021.jpg" id="pcbi.1008697.e021g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M21"><mml:msub><mml:mover accent="true"><mml:mi>s</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>r</mml:mi></mml:msub></mml:math></alternatives></inline-formula>, <inline-formula id="pcbi.1008697.e022"><alternatives><graphic xlink:href="pcbi.1008697.e022.jpg" id="pcbi.1008697.e022g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M22"><mml:msub><mml:mover accent="true"><mml:mi>s</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>α</mml:mi></mml:msub></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1008697.e023"><alternatives><graphic xlink:href="pcbi.1008697.e023.jpg" id="pcbi.1008697.e023g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M23"><mml:msub><mml:mover accent="true"><mml:mi>s</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>A</mml:mi></mml:msub></mml:math></alternatives></inline-formula> for several sampling rates of <italic>τ</italic> &gt; 1 (<xref ref-type="fig" rid="pcbi.1008697.g004">Fig 4H to 4J</xref>). We then used these parameters to track the <monospace>ZFJ_001</monospace> movie at different <italic>τ</italic> and compute <italic>P</italic><sub><italic>swap</italic></sub>. A comparison between <italic>P</italic><sub><italic>swap</italic></sub> and <italic>P</italic><sub><italic>inc</italic></sub> as a function of <italic>τ</italic> is shown in <xref ref-type="fig" rid="pcbi.1008697.g004">Fig 4K</xref>. This comparison illustrates that <italic>P</italic><sub><italic>swap</italic></sub> is a noisier measurement of a movie’s trackability than <italic>P</italic><sub><italic>inc</italic></sub> and confirms that the iterative algorithm produces trajectories with an amount of errors that is close to the statistical limit.</p>
    </sec>
    <sec id="sec016">
      <title>Parameter optimization</title>
      <p>One may also want to determine the tracking parameters that are really optimal with respect to <italic>P</italic><sub><italic>swap</italic></sub>. In this case, provided that the ground truth is known (<italic>e.g.</italic> by a careful manual post-processing) for at least one movie, it is possible to leverage the speed of FastTrack to explore the parameters space and minimize <italic>P</italic><sub><italic>swap</italic></sub>; then the optimized parameters can be used to track other similar movies with a minimal error rate. The workflow of the method is depicted in <xref ref-type="supplementary-material" rid="pcbi.1008697.s007">S5(A) Fig</xref>. As the exploration of the whole parameters space requires to perform at least thousands of trackings, such an approach is only made possible by the command-line interface (CLI, see <xref ref-type="supplementary-material" rid="pcbi.1008697.s002">S2 Table</xref>) and the speed of execution of FastTrack.</p>
      <p>Let us first apply this approach to gain insight into the influence of <italic>h</italic><sub><italic>r</italic></sub>, the maximal distance allowed for an object to travel before it is considered lost. <xref ref-type="supplementary-material" rid="pcbi.1008697.s007">S5(B) Fig</xref> displays how <italic>P</italic><sub><italic>swap</italic></sub> evolves as a function of <italic>h</italic><sub><italic>r</italic></sub> for three recordings in the dataset. For low values of <italic>h</italic><sub><italic>r</italic></sub>, <italic>P</italic><sub><italic>swap</italic></sub> is essentially imposed by the distribution of the objects’ displacements, since a high number of errors are generated when the objects are not allowed to move sufficiently. For higher values of <italic>h</italic><sub><italic>r</italic></sub>, the distribution of the distances to the neighbors—as defined by the Voronoï tesselation—starts to influence <italic>P</italic><sub><italic>swap</italic></sub> as the algorithm becomes sensitive to incursions. It can also be more easily fooled by entries and exits at the boundaries of the region of interest when the number of objects in the scene varies.</p>
      <p>In between, for most recordings there is a gap yielding the minimal probability of error; this is particularly true when the objects are densely packed, since the distribution of distances to neighbors is sharper, like for <monospace>DRP_001</monospace> where <italic>P</italic><sub><italic>swap</italic></sub> drops to zero on a range of <italic>h</italic><sub><italic>r</italic></sub>. The acquisition framerate also has an important role here: with highly-resolved movies the distribution of displacements is shifted to the left, leading to a clear separation and low values of <italic>P</italic><sub><italic>swap</italic></sub>, while for poorly-resolved movies like <monospace>ZFJ_001</monospace> the two distributions overlap and <italic>P</italic><sub><italic>swap</italic></sub> is always bound to high values.</p>
      <p>Similar analysis can be performed on the other tracking parameters. <xref ref-type="supplementary-material" rid="pcbi.1008697.s007">S5(C) Fig</xref> represents <italic>P</italic><sub><italic>swap</italic></sub> as a function of both hard parameters <italic>h</italic><sub><italic>r</italic></sub> and <italic>h</italic><sub><italic>t</italic></sub> for <monospace>PAR_001</monospace>, and a thin optimal segment appears. <xref ref-type="supplementary-material" rid="pcbi.1008697.s007">S5(D) Fig</xref> represents <italic>P</italic><sub><italic>swap</italic></sub> as a function of the two soft parameters <italic>s</italic><sub><italic>r</italic></sub> and <italic>s</italic><sub><italic>α</italic></sub>, and an optimal ratio lies at <inline-formula id="pcbi.1008697.e024"><alternatives><graphic xlink:href="pcbi.1008697.e024.jpg" id="pcbi.1008697.e024g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M24"><mml:mrow><mml:mfrac bevelled="true"><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>r</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>α</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo>≃</mml:mo><mml:mn>0.63</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>. Altogether, a set of optimal parameters can be derived and used for the processing of similar recordings.</p>
    </sec>
    <sec id="sec017">
      <title>Comparison with other softwares</title>
      <p>To assess the performance of FastTrack, we ran a benchmark with two state-of-the art tracking softwares that have been applied to various types of two-dimensional data: idtracker.ai [<xref rid="pcbi.1008697.ref045" ref-type="bibr">45</xref>] and ToxTrac [<xref rid="pcbi.1008697.ref046" ref-type="bibr">46</xref>]. First, it is worth mentionning that these softwares are much more difficult to install than FastTrack, and that they have strong intrinsic limitations as compared to FastTrack: both require a good framerate and image quality, with sufficient contrast and number of pixels per object, and a constant number of objects in the scene.</p>
      <p>The benchmark was thus performed on a dataset constituted of a selection of videos that were provided with each software and some movies of the TD<sup>2</sup> dataset that meet these requirements. <monospace>idtrackerai_video_example</monospace> and <monospace>100Zebra</monospace> (<xref ref-type="supplementary-material" rid="pcbi.1008697.s011">S4 Video</xref>) are available on the idtracker.ai website (<ext-link ext-link-type="uri" xlink:href="https://idtrackerai.readthedocs.io/en/latest/data.html">https://idtrackerai.readthedocs.io/en/latest/data.html</ext-link>). <monospace>Guppy2</monospace>, <monospace>Waterlouse5</monospace>, and <monospace>Wingedant</monospace> on the ToxTrac SourceForge (<ext-link ext-link-type="uri" xlink:href="https://sourceforge.net/projects/toxtrac/files/ScientificReports/">https://sourceforge.net/projects/toxtrac/files/ScientificReports/</ext-link>). Movies that were provided in image sequence format were converted losslessly to video format with FFmpeg since idtracker.ai and ToxTrac were not able to process directly image sequences. <monospace>DRO_002</monospace> and <monospace>ACT_002</monospace> were preprocessed with a custom Matlab script to detect the objects before using the softwares. In addition, only the first 100 images of <monospace>DRO_002</monospace> were used to reduce the computing time.</p>
      <p>The benchmark between idtracker.ai and FastTrack was performed on a workstation with an Intel i7-6900K (16 cores), 4.0 GHz CPU, an NVIDIA GeForce GTX 1060 with 6GB or RAM GPU, 32GB of RAM, and a NVMe SSD of 250GB running Arch Linux. The parameters were set by trials and errors inside the graphical user interface of the two softwares. The tracking duration was recorded using the command line interface available for the two software. The average tracking duration and the standard deviation were averaged over 5 runs except for <monospace>DRO_002</monospace> (2 runs) and <monospace>ACT_002</monospace> (1 run) due to the very long processing time. Idtracker.ai was evaluated with and without GPU capability except for <monospace>100Zebra</monospace>, <monospace>DRO_002</monospace>, and <monospace>ACT_002</monospace> due to the very long processing time.</p>
      <p>The benchmark between ToxTrac and FastTrack was performed on a computer with an Intel i7-8565U (4 Cores), 1.99 GHz CPU, 16 GB of RAM, and a NVMe SSD of 1 TB running Windows10. The parameters were set by trials and errors in the graphical user interface. The average tracking duration and the standard deviation were averaged over 5 runs using the built-in timer feature implemented in each software.</p>
      <p>The accuracy was evaluated manually using the built-in review feature implemented in each software. The number of swaps and the number of non-detected objects were counted in each movie. Occlusion events were ignored in this counting. The accuracy was computed as:
<disp-formula id="pcbi.1008697.e025"><alternatives><graphic xlink:href="pcbi.1008697.e025.jpg" id="pcbi.1008697.e025g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M25"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>A</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>o</mml:mi><mml:mi>b</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>*</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>m</mml:mi><mml:mi>g</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mn>2</mml:mn><mml:mo>*</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>w</mml:mi><mml:mi>a</mml:mi><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>u</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>o</mml:mi><mml:mi>b</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>*</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>m</mml:mi><mml:mi>g</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(10)</label></disp-formula>
with <italic>N</italic><sub><italic>swap</italic></sub> the number of swaps, <italic>N</italic><sub><italic>undetected</italic></sub> the number of non-detected objects, <italic>n</italic><sub><italic>obj</italic></sub> the number of objects and <italic>n</italic><sub><italic>img</italic></sub> the number of images. For <monospace>100Zebra</monospace>, the accuracy was computed only over the 200 first images.</p>
      <p>All the results are presented in <xref ref-type="fig" rid="pcbi.1008697.g005">Fig 5</xref>. In terms of speed FastTrack is orders of magnitude faster than idtracker.ai and significanly faster than ToxTrac on all tested videos. In terms of accuracy, all softwares performed extremely well, except idtracker.ai on <monospace>ZFJ_001</monospace>. FastTrack had a perfect accuracy on 8 movies out of 11 and always had an accuracy above 99%. In order to correct for the few errors, the ergonomic post-processing interface of FastTrack can be used to reach a perfect tracking within a few more minutes. Altogether, FastTrack offers many assets as compared to idtracker.ai and ToxTrac: it is more versatile and the total time spent to track a movie is globally lower—in some cases by orders of magnitude—without sacrificing the tracking accuracy.</p>
      <fig id="pcbi.1008697.g005" orientation="portrait" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1008697.g005</object-id>
        <label>Fig 5</label>
        <caption>
          <title>Benchmark of FastTrack, idtracker.ai and ToxTrac.</title>
          <p>(<bold>A-B</bold>) Comparison of the computation time for the tracking of various movies with the same workstation. Whenever possible, CPU and GPU variants of idtracker.ai have been run. Only the first 100 images of <monospace>DRO_002</monospace> have been used. (<bold>C-D</bold>) Accuracies of the resulting trackings. “perfect” means an accuracy of exactly 1. The trajectories computed by the CPU and GPU variants of idtracker.ai being rigourously similar, we only show the results for the GPU. For <monospace>100Zebra</monospace>, the accuracy was computed by taking into account only the first 200 images.</p>
        </caption>
        <graphic xlink:href="pcbi.1008697.g005"/>
      </fig>
    </sec>
  </sec>
  <sec id="sec018">
    <title>Availability and future directions</title>
    <p>The source code of FastTrack is licensed under the GNU GPLv3 and can be downloaded at the following Github repository: <ext-link ext-link-type="uri" xlink:href="https://github.com/FastTrackOrg/FastTrack">https://github.com/FastTrackOrg/FastTrack</ext-link>. Developers implementing algorithmic improvements or new features are encouraged to submit their code <italic>via</italic> Github’s pull request mechanism for inclusion in a forthcoming release.</p>
    <p>Pre-built binaries (AppImages) for Windows, Mac and all versions linux can be downloaded on the FastTrack website (<ext-link ext-link-type="uri" xlink:href="http://www.fasttrack.sh">http://www.fasttrack.sh</ext-link>). We also provide a PPA for Ubuntu 18.04 that ensure proper system integration. The Windows and PPA versions incorporate an automatic update manager such that users always stay up-to-date with the latest stable release. For the Mac and Linux AppImages, updates have to be performed manually by downloading the latest version.</p>
    <p>User’s and developer’s documentation are available on the FastTrack website. A video tutorial for beginners illustrating the complete workflow is available in <xref ref-type="supplementary-material" rid="pcbi.1008697.s009">S2 Video</xref>. We also provide an additional video presenting the post-processing panel in detail (<xref ref-type="supplementary-material" rid="pcbi.1008697.s010">S3 Video</xref>).</p>
    <p>The FastTrack algorithm only uses past and current information and is relatively fast, so it is in principle amenable to live tracking. Currenty the software doesn’t natively integrate a live tracking feature, but it can be integrated inside any C++ project with minimal programming skills as explained in the developer’s documentation (<ext-link ext-link-type="uri" xlink:href="http://www.fasttrack.sh/API/index.html">http://www.fasttrack.sh/API/index.html</ext-link>).</p>
    <p>In the future, we will continue the effort to make the TD<sup>2</sup> dataset grow, and greatly encourage new submissions from all fields of science. It is a useful basis for the development of general-purpose tracking softwares and a convenient material for benchmarking.</p>
    <p>Though the software has been designed to process a broad range of systems, there is still room for improvement both at the detection and matching levels to make it more universal. For the detection phase, the need for an upstream custom preprocessing step could be greatly reduced for many movies by the implementation of tools for shadow removal [<xref rid="pcbi.1008697.ref047" ref-type="bibr">47</xref>] and adaptative thresholds [<xref rid="pcbi.1008697.ref048" ref-type="bibr">48</xref>]. The separation of the RGB channels for colored images could also be useful in some cases. Then, for the matching phase we plan to allow for the integration of more kinematic parameters in the computation of the cost matrix. Among the possible improvements we can mention basic shape descriptors like eccentricity or the object’s velocity. In the latter case, it may be useful to modulate the hard threshold for displacements <italic>h</italic><sub><italic>r</italic></sub> by the previous values of speed. We also plan to integrate the average intensity level, which could be useful for tracking fluorescent objects with different levels of expression.</p>
    <p>Finally, in order to overcome the problem of losing the objects when they are clipped by a boundary or overlapping, we are currently working on an algorithm capable of resolving truncated and overlapping shapes based on a model learned in an unsupervised manner. Ultimately, this will make FastTrack a very complete tool for general tracking purpose.</p>
  </sec>
  <sec sec-type="supplementary-material" id="sec019">
    <title>Supporting information</title>
    <supplementary-material content-type="local-data" id="pcbi.1008697.s001">
      <label>S1 Table</label>
      <caption>
        <title>Two-dimensional tracking dataset.</title>
        <p>Description and credentials of the data that have been used for testing the FastTrack software. All movies in the dataset can be downloaded at <ext-link ext-link-type="uri" xlink:href="http://data.ljp.upmc.fr/datasets/TD2">http://data.ljp.upmc.fr/datasets/TD2</ext-link>.</p>
        <p>(PDF)</p>
      </caption>
      <media xlink:href="pcbi.1008697.s001.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material content-type="local-data" id="pcbi.1008697.s002">
      <label>S2 Table</label>
      <caption>
        <title>User-defined parameters.</title>
        <p>List of the parameters that can be set in FastTrack for image processing and automatic tracking, as of version 5.1.7.</p>
        <p>(PDF)</p>
      </caption>
      <media xlink:href="pcbi.1008697.s002.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material content-type="local-data" id="pcbi.1008697.s003">
      <label>S1 Fig</label>
      <caption>
        <title>Thumbnails of the TD<sup>2</sup> dataset.</title>
        <p>(TIF)</p>
      </caption>
      <media xlink:href="pcbi.1008697.s003.tif">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material content-type="local-data" id="pcbi.1008697.s004">
      <label>S2 Fig</label>
      <caption>
        <title>Definition of the kinematic parameters.</title>
        <p>The raw image is binarized and the binary shape is described by one or two ellipses. The position (center of mass) and direction (see text) of the chosen ellipse are used as an input for the matching phase.</p>
        <p>(TIF)</p>
      </caption>
      <media xlink:href="pcbi.1008697.s004.tif">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material content-type="local-data" id="pcbi.1008697.s005">
      <label>S3 Fig</label>
      <caption>
        <title>General workflow of cost-based tracking.</title>
        <p>Depending on the system and recording conditions, many kinematic parameters can be employed to define the cost matrix. For each parameter a soft (normalized) and a hard (binarized) terms can be combined and summed to form the General Cost Matrix. An assignment algorithm is then used to produce the trajectories.</p>
        <p>(TIF)</p>
      </caption>
      <media xlink:href="pcbi.1008697.s005.tif">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material content-type="local-data" id="pcbi.1008697.s006">
      <label>S4 Fig</label>
      <caption>
        <title>Effect of confinment on <italic>p</italic><sub><italic>inc</italic></sub>.</title>
        <p>The geometric probability of incursion <italic>p</italic><sub><italic>inc</italic></sub> is computed for a system composed of <italic>n</italic> punctual objects uniformly distributed at random in a square of size 1, as a function of the reduced displacement <italic>ρ</italic> for various values of <italic>n</italic> (plain). <italic>p</italic><sub><italic>inc</italic></sub>(<italic>ρ</italic>) is also shown for a system without walls (dashed); in this case the curve is independent of the density <italic>d</italic>.</p>
        <p>(TIF)</p>
      </caption>
      <media xlink:href="pcbi.1008697.s006.tif">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material content-type="local-data" id="pcbi.1008697.s007">
      <label>S5 Fig</label>
      <caption>
        <title>Optimization of tracking parameters based on <italic>P</italic><sub><italic>swap</italic></sub>.</title>
        <p>(<bold>A</bold>) Scheme of the optimization workflow: on top of the detection/matching/post-process flow chart, the ground truth is used to compute <italic>P</italic><sub><italic>swap</italic></sub> and create a feedback loop on the tracking parameters. (<bold>B</bold>) <italic>P</italic><sub><italic>swap</italic></sub> (black) as a function of the maximal distance parameter <italic>h</italic><sub><italic>r</italic></sub> (in pixels) for three typical recordings. Vertical lines for <monospace>DRP_001</monospace> indicate that <italic>P</italic><sub><italic>swap</italic></sub> drops to 0. The distributions of displacements between successive frames (blue) and of distances to the neighbors (orange) are also shown for comparison. (<bold>C</bold>) <italic>P</italic><sub><italic>swap</italic></sub> as a function of the maximal distance parameter <italic>h</italic><sub><italic>r</italic></sub> (in pixels) and the maximal disappearance time <italic>h</italic><sub><italic>t</italic></sub> (in frames) for <monospace>PAR_001</monospace>. Soft parameters are set to <italic>s</italic><sub><italic>r</italic></sub> = 95 and <italic>s</italic><sub><italic>α</italic></sub> = 60. (<bold>D</bold>) <italic>P</italic><sub><italic>swap</italic></sub> as a function of the normalization distance parameter <italic>s</italic><sub><italic>r</italic></sub> (in pixels) and the normalization angle <italic>s</italic><sub><italic>α</italic></sub> (in degrees) for <monospace>PAR_001</monospace>. Hard parameters are set to <italic>h</italic><sub><italic>r</italic></sub> = 210 and <italic>h</italic><sub><italic>t</italic></sub> = 90.</p>
        <p>(TIF)</p>
      </caption>
      <media xlink:href="pcbi.1008697.s007.tif">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material content-type="local-data" id="pcbi.1008697.s008">
      <label>S1 Video</label>
      <caption>
        <title>Result of the tracking with FastTrack.</title>
        <p>Compilation of short sequences extracted from the 39 recordings of the TD<sup>2</sup> dataset that could be tracked with FastTrack. The trajectories are overlaid over the original frames.</p>
        <p>(MP4)</p>
      </caption>
      <media xlink:href="pcbi.1008697.s008.mp4">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material content-type="local-data" id="pcbi.1008697.s009">
      <label>S2 Video</label>
      <caption>
        <title>General usage of the FastTrack software.</title>
        <p>(MP4)</p>
      </caption>
      <media xlink:href="pcbi.1008697.s009.mp4">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material content-type="local-data" id="pcbi.1008697.s010">
      <label>S3 Video</label>
      <caption>
        <title>Details of the post-processing panel.</title>
        <p>(MP4)</p>
      </caption>
      <media xlink:href="pcbi.1008697.s010.mp4">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material content-type="local-data" id="pcbi.1008697.s011">
      <label>S4 Video</label>
      <caption>
        <title>Tracking of the 100Zebra movie by FastTrack.</title>
        <p>(MP4)</p>
      </caption>
      <media xlink:href="pcbi.1008697.s011.mp4">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material content-type="local-data" id="pcbi.1008697.s012">
      <label>S1 Data</label>
      <caption>
        <title>Raw data.</title>
        <p>(XLSX)</p>
      </caption>
      <media xlink:href="pcbi.1008697.s012.xlsx">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ack>
    <p>We warmly thank all contributors to the TD<sup>2</sup> dataset. We thank Guillaume Le Goc, Julie Lafaye and Nicolas Escoubet for useful comments and feedback on the software.</p>
  </ack>
  <ref-list>
    <title>References</title>
    <ref id="pcbi.1008697.ref001">
      <label>1</label>
      <mixed-citation publication-type="other">Ray Juang R, Levchenko A, Burlina P. Tracking cell motion using GM-PHD. In: 2009 IEEE International Symposium on Biomedical Imaging: From Nano to Macro; 2009. p. 1154–1157.</mixed-citation>
    </ref>
    <ref id="pcbi.1008697.ref002">
      <label>2</label>
      <mixed-citation publication-type="journal"><name><surname>Dewan</surname><given-names>MAA</given-names></name>, <name><surname>Ahmad</surname><given-names>MO</given-names></name>, <name><surname>Swamy</surname><given-names>MNS</given-names></name>. <article-title>Tracking Biological Cells in Time-Lapse Microscopy: An Adaptive Technique Combining Motion and Topological Features</article-title>. <source>IEEE Transactions on Biomedical Engineering</source>. <year>2011</year>;<volume>58</volume>(<issue>6</issue>):<fpage>1637</fpage>–<lpage>1647</lpage>. <pub-id pub-id-type="doi">10.1109/TBME.2011.2109001</pub-id><pub-id pub-id-type="pmid">21278009</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1008697.ref003">
      <label>3</label>
      <mixed-citation publication-type="journal"><name><surname>Dell</surname><given-names>AI</given-names></name>, <name><surname>Bender</surname><given-names>JA</given-names></name>, <name><surname>Branson</surname><given-names>K</given-names></name>, <name><surname>Couzin</surname><given-names>ID</given-names></name>, <name><surname>de Polavieja</surname><given-names>GG</given-names></name>, <name><surname>Noldus</surname><given-names>LPJJ</given-names></name>, <etal>et al</etal><article-title>Automated image-based tracking and its application in ecology</article-title>. <source>Trends in Ecology &amp; Evolution</source>. <year>2014</year>;<volume>29</volume>(<issue>7</issue>):<fpage>417</fpage>–<lpage>428</lpage>. <pub-id pub-id-type="doi">10.1016/j.tree.2014.05.004</pub-id><?supplied-pmid 24908439?><pub-id pub-id-type="pmid">24908439</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1008697.ref004">
      <label>4</label>
      <mixed-citation publication-type="journal"><name><surname>Risse</surname><given-names>B</given-names></name>, <name><surname>Berh</surname><given-names>D</given-names></name>, <name><surname>Otto</surname><given-names>N</given-names></name>, <name><surname>Klämbt</surname><given-names>C</given-names></name>, <name><surname>Jiang</surname><given-names>X</given-names></name>. <article-title>FIMTrack: An open source tracking and locomotion analysis software for small animals</article-title>. <source>PLOS Computational Biology</source>. <year>2017</year>;<volume>13</volume>(<issue>5</issue>):<fpage>1</fpage>–<lpage>15</lpage>. <pub-id pub-id-type="doi">10.1371/journal.pcbi.1005530</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1008697.ref005">
      <label>5</label>
      <mixed-citation publication-type="journal"><name><surname>Jeong</surname><given-names>J</given-names></name>, <name><surname>Frohberg</surname><given-names>NJ</given-names></name>, <name><surname>Zhou</surname><given-names>E</given-names></name>, <name><surname>Sulchek</surname><given-names>T</given-names></name>, <name><surname>Qiu</surname><given-names>P</given-names></name>. <article-title>Accurately tracking single-cell movement trajectories in microfluidic cell sorting devices</article-title>. <source>PLOS ONE</source>. <year>2018</year>;<volume>13</volume>(<issue>2</issue>):<fpage>1</fpage>–<lpage>16</lpage>. <pub-id pub-id-type="doi">10.1371/journal.pone.0192463</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1008697.ref006">
      <label>6</label>
      <mixed-citation publication-type="journal"><name><surname>Bricard</surname><given-names>A</given-names></name>, <name><surname>Caussin</surname><given-names>JB</given-names></name>, <name><surname>Desreumaux</surname><given-names>N</given-names></name>, <name><surname>Dauchot</surname><given-names>O</given-names></name>, <name><surname>Bartolo</surname><given-names>D</given-names></name>. <article-title>Emergence of macroscopic directed motion in populations of motile colloids</article-title>. <source>Nature</source>. <year>2013</year>;<volume>503</volume>:<fpage>95</fpage>–<lpage>98</lpage>. <pub-id pub-id-type="doi">10.1038/nature12673</pub-id><pub-id pub-id-type="pmid">24201282</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1008697.ref007">
      <label>7</label>
      <mixed-citation publication-type="journal"><name><surname>Ali</surname><given-names>I</given-names></name>, <name><surname>Dailey</surname><given-names>MN</given-names></name>. <article-title>Multiple human tracking in high-density crowds</article-title>. <source>Image and Vision Computing</source>. <year>2012</year>;<volume>30</volume>(<issue>12</issue>):<fpage>966</fpage>–<lpage>977</lpage>. <pub-id pub-id-type="doi">10.1016/j.imavis.2012.08.013</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1008697.ref008">
      <label>8</label>
      <mixed-citation publication-type="journal"><name><surname>Treptow</surname><given-names>A</given-names></name>, <name><surname>Zell</surname><given-names>A</given-names></name>. <article-title>Real-time object tracking for soccer-robots without color information</article-title>. <source>Robotics and Autonomous Systems</source>. <year>2004</year>;<volume>48</volume>(<issue>1</issue>):<fpage>41</fpage>–<lpage>48</lpage>. <pub-id pub-id-type="doi">10.1016/j.robot.2004.05.005</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1008697.ref009">
      <label>9</label>
      <mixed-citation publication-type="other">Luo RC, Mullen RE, Wessell DE. An adaptive robotic tracking system using optical flow. In: Proceedings. 1988 IEEE International Conference on Robotics and Automation; 1988. p. 568–573 vol.1.</mixed-citation>
    </ref>
    <ref id="pcbi.1008697.ref010">
      <label>10</label>
      <mixed-citation publication-type="journal"><name><surname>Irimia</surname><given-names>D</given-names></name>, <name><surname>Toner</surname><given-names>M</given-names></name>. <article-title>Spontaneous migration of cancer cells under conditions of mechanical confinement</article-title>. <source>Integrative Biology</source>. <year>2009</year>;<volume>1</volume>(<issue>8-9</issue>):<fpage>506</fpage>–<lpage>512</lpage>. <pub-id pub-id-type="doi">10.1039/b908595e</pub-id><pub-id pub-id-type="pmid">20023765</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1008697.ref011">
      <label>11</label>
      <mixed-citation publication-type="journal"><name><surname>Balzer</surname><given-names>EM</given-names></name>, <name><surname>Tong</surname><given-names>Z</given-names></name>, <name><surname>Paul</surname><given-names>CD</given-names></name>, <name><surname>Hung</surname><given-names>WC</given-names></name>, <name><surname>Stroka</surname><given-names>KM</given-names></name>, <name><surname>Boggs</surname><given-names>AE</given-names></name>, <etal>et al</etal><article-title>Physical confinement alters tumor cell adhesion and migration phenotypes</article-title>. <source>The FASEB Journal</source>. <year>2012</year>;<volume>26</volume>(<issue>10</issue>):<fpage>4045</fpage>–<lpage>4056</lpage>. <pub-id pub-id-type="doi">10.1096/fj.12-211441</pub-id><?supplied-pmid 22707566?><pub-id pub-id-type="pmid">22707566</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1008697.ref012">
      <label>12</label>
      <mixed-citation publication-type="journal"><name><surname>Zöttl</surname><given-names>A</given-names></name>, <name><surname>Stark</surname><given-names>H</given-names></name>. <article-title>Hydrodynamics Determines Collective Motion and Phase Behavior of Active Colloids in Quasi-Two-Dimensional Confinement</article-title>. <source>Phys Rev Lett</source>. <year>2014</year>;<volume>112</volume>:<fpage>118101</fpage><pub-id pub-id-type="doi">10.1103/PhysRevLett.112.118101</pub-id><pub-id pub-id-type="pmid">24702421</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1008697.ref013">
      <label>13</label>
      <mixed-citation publication-type="journal"><name><surname>Pérez-Escudero</surname><given-names>A</given-names></name>, <name><surname>Vicente-Page</surname><given-names>J</given-names></name>, <name><surname>Hinz</surname><given-names>RC</given-names></name>, <name><surname>Arganda</surname><given-names>S</given-names></name>, <name><surname>De Polavieja</surname><given-names>GG</given-names></name>. <article-title>idTracker: tracking individuals in a group by automatic identification of unmarked animals</article-title>. <source>Nature methods</source>. <year>2014</year>;<volume>11</volume>(<issue>7</issue>):<fpage>743</fpage><pub-id pub-id-type="doi">10.1038/nmeth.2994</pub-id><pub-id pub-id-type="pmid">24880877</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1008697.ref014">
      <label>14</label>
      <mixed-citation publication-type="journal"><name><surname>Rodriguez</surname><given-names>A</given-names></name>, <name><surname>Zhang</surname><given-names>H</given-names></name>, <name><surname>Klaminder</surname><given-names>J</given-names></name>, <name><surname>Brodin</surname><given-names>T</given-names></name>, <name><surname>Andersson</surname><given-names>M</given-names></name>. <article-title>ToxId: an efficient algorithm to solve occlusions when tracking multiple animals</article-title>. <source>Scientific Reports</source>. <year>2017</year>;<volume>7</volume>(<issue>14774</issue>). <pub-id pub-id-type="doi">10.1038/s41598-017-15104-2</pub-id><?supplied-pmid 29116122?><pub-id pub-id-type="pmid">29116122</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1008697.ref015">
      <label>15</label>
      <mixed-citation publication-type="journal"><name><surname>Candelier</surname><given-names>R</given-names></name>, <name><surname>Bois</surname><given-names>A</given-names></name>, <name><surname>Tronche</surname><given-names>S</given-names></name>, <name><surname>Mahieu</surname><given-names>J</given-names></name>, <name><surname>Mannioui</surname><given-names>A</given-names></name>. <article-title>A Semi-Automatic Dispenser for Solid and Liquid Food in Aquatic Facilities</article-title>. <source>Zebrafish</source>. <year>2019</year>;<volume>17</volume>(<issue>33</issue>). <pub-id pub-id-type="doi">10.1089/zeb.2019.1733</pub-id><?supplied-pmid 31237527?><pub-id pub-id-type="pmid">31237527</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1008697.ref016">
      <label>16</label>
      <mixed-citation publication-type="journal"><name><surname>Golovkova</surname><given-names>I</given-names></name>, <name><surname>Montel</surname><given-names>L</given-names></name>, <name><surname>Wandersman</surname><given-names>E</given-names></name>, <name><surname>Bertrand</surname><given-names>T</given-names></name>, <name><surname>Prevost</surname><given-names>AM</given-names></name>, <name><surname>Pontani</surname><given-names>LL</given-names></name>. <article-title>Depletion attraction impairs the plasticity of emulsions flowing in a constriction</article-title>. <source>Soft Matter</source>. <year>2020</year>;<volume>16</volume>:<fpage>3294</fpage>–<lpage>3302</lpage>. <pub-id pub-id-type="doi">10.1039/C9SM02343G</pub-id><pub-id pub-id-type="pmid">32173724</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1008697.ref017">
      <label>17</label>
      <mixed-citation publication-type="journal"><name><surname>Briand</surname><given-names>G</given-names></name>, <name><surname>Dauchot</surname><given-names>O</given-names></name>. <article-title>Crystallization of Self-Propelled Hard Discs</article-title>. <source>Phys Rev Lett</source>. <year>2016</year>;<volume>117</volume>:<fpage>098004</fpage><pub-id pub-id-type="doi">10.1103/PhysRevLett.117.098004</pub-id><pub-id pub-id-type="pmid">27610889</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1008697.ref018">
      <label>18</label>
      <mixed-citation publication-type="journal"><name><surname>Briand</surname><given-names>G</given-names></name>, <name><surname>Schindler</surname><given-names>M</given-names></name>, <name><surname>Dauchot</surname><given-names>O</given-names></name>. <article-title>Spontaneously Flowing Crystal of Self-Propelled Particles</article-title>. <source>Phys Rev Lett</source>. <year>2018</year>;<volume>120</volume>:<fpage>208001</fpage><pub-id pub-id-type="doi">10.1103/PhysRevLett.120.208001</pub-id><pub-id pub-id-type="pmid">29864372</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1008697.ref019">
      <label>19</label>
      <mixed-citation publication-type="journal"><name><surname>Deseigne</surname><given-names>J</given-names></name>, <name><surname>Dauchot</surname><given-names>O</given-names></name>, <name><surname>Chaté</surname><given-names>H</given-names></name>. <article-title>Collective Motion of Vibrated Polar Disks</article-title>. <source>Phys Rev Lett</source>. <year>2010</year>;<volume>105</volume>:<fpage>098001</fpage><pub-id pub-id-type="doi">10.1103/PhysRevLett.105.098001</pub-id><pub-id pub-id-type="pmid">20868196</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1008697.ref020">
      <label>20</label>
      <mixed-citation publication-type="journal"><name><surname>Izri</surname><given-names>Z</given-names></name>, <name><surname>van der Linden</surname><given-names>MN</given-names></name>, <name><surname>Michelin</surname><given-names>S</given-names></name>, <name><surname>Dauchot</surname><given-names>O</given-names></name>. <article-title>Self-Propulsion of Pure Water Droplets by Spontaneous Marangoni-Stress-Driven Motion</article-title>. <source>Phys Rev Lett</source>. <year>2014</year>;<volume>113</volume>:<fpage>248302</fpage><pub-id pub-id-type="doi">10.1103/PhysRevLett.113.248302</pub-id><pub-id pub-id-type="pmid">25541808</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1008697.ref021">
      <label>21</label>
      <mixed-citation publication-type="journal"><name><surname>Buchanan</surname><given-names>SM</given-names></name>, <name><surname>Kain</surname><given-names>JS</given-names></name>, <name><surname>de Bivort</surname><given-names>BL</given-names></name>. <article-title>Neuronal control of locomotor handedness in Drosophila</article-title>. <source>Proceedings of the National Academy of Sciences</source>. <year>2015</year>;<volume>112</volume>(<issue>21</issue>):<fpage>6700</fpage>–<lpage>6705</lpage>. <pub-id pub-id-type="doi">10.1073/pnas.1500804112</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1008697.ref022">
      <label>22</label>
      <mixed-citation publication-type="journal"><name><surname>Honegger</surname><given-names>KS</given-names></name>, <name><surname>Smith</surname><given-names>MAY</given-names></name>, <name><surname>Churgin</surname><given-names>MA</given-names></name>, <name><surname>Turner</surname><given-names>GC</given-names></name>, <name><surname>de Bivort</surname><given-names>BL</given-names></name>. <article-title>Idiosyncratic neural coding and neuromodulation of olfactory individuality in Drosophila</article-title>. <source>Proceedings of the National Academy of Sciences</source>. <year>2019</year>.</mixed-citation>
    </ref>
    <ref id="pcbi.1008697.ref023">
      <label>23</label>
      <mixed-citation publication-type="journal"><name><surname>Jose</surname><given-names>BM</given-names></name>, <name><surname>Cubaud</surname><given-names>T</given-names></name>. <article-title>Droplet arrangement and coalescence in diverging/converging microchannels</article-title>. <source>Microfluidics and Nanofluidics</source>. <year>2012</year>;<volume>12</volume>(<issue>5</issue>):<fpage>687</fpage>–<lpage>696</lpage>. <pub-id pub-id-type="doi">10.1007/s10404-011-0909-z</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1008697.ref024">
      <label>24</label>
      <mixed-citation publication-type="journal"><name><surname>Candelier</surname><given-names>R</given-names></name>, <name><surname>Dauchot</surname><given-names>O</given-names></name>. <article-title>Creep Motion of an Intruder within a Granular Glass Close to Jamming</article-title>. <source>Phys Rev Lett</source>. <year>2009</year>;<volume>103</volume>:<fpage>128001</fpage><pub-id pub-id-type="doi">10.1103/PhysRevLett.103.128001</pub-id><pub-id pub-id-type="pmid">19792459</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1008697.ref025">
      <label>25</label>
      <mixed-citation publication-type="journal"><name><surname>Dauchot</surname><given-names>O</given-names></name>, <name><surname>Démery</surname><given-names>V</given-names></name>. <article-title>Dynamics of a Self-Propelled Particle in a Harmonic Trap</article-title>. <source>Phys Rev Lett</source>. <year>2019</year>;<volume>122</volume>:<fpage>068002</fpage><pub-id pub-id-type="doi">10.1103/PhysRevLett.122.068002</pub-id><pub-id pub-id-type="pmid">30822074</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1008697.ref026">
      <label>26</label>
      <mixed-citation publication-type="journal"><name><surname>Imada</surname><given-names>H</given-names></name>, <name><surname>Hoki</surname><given-names>M</given-names></name>, <name><surname>Suehiro</surname><given-names>Y</given-names></name>, <name><surname>Okuyama</surname><given-names>T</given-names></name>, <name><surname>Kurabayashi</surname><given-names>D</given-names></name>, <name><surname>Shimada</surname><given-names>A</given-names></name>, <etal>et al</etal><article-title>Coordinated and Cohesive Movement of Two Small Conspecific Fish Induced by Eliciting a Simultaneous Optomotor Response</article-title>. <source>PLOS ONE</source>. <year>2010</year>;<volume>5</volume>(<issue>6</issue>):<fpage>1</fpage>–<lpage>7</lpage>. <pub-id pub-id-type="doi">10.1371/journal.pone.0011248</pub-id><?supplied-pmid 20582314?><pub-id pub-id-type="pmid">20582314</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1008697.ref027">
      <label>27</label>
      <mixed-citation publication-type="book"><name><surname>Russ</surname><given-names>JC</given-names></name>, <name><surname>Neal</surname><given-names>FB</given-names></name>. <source>The Image Processing Handbook</source>. <edition designator="7">7th ed</edition><publisher-loc>USA</publisher-loc>: <publisher-name>CRC Press, Inc.</publisher-name>; <year>2015</year>.</mixed-citation>
    </ref>
    <ref id="pcbi.1008697.ref028">
      <label>28</label>
      <mixed-citation publication-type="journal"><name><surname>Evangelidis</surname><given-names>GD</given-names></name>, <name><surname>Psarakis</surname><given-names>EZ</given-names></name>. <article-title>Parametric image alignment using enhanced correlation coefficient maximization</article-title>. <source>IEEE Transactions on Pattern Analysis and Machine Intelligence</source>. <year>2008</year>;<volume>30</volume>(<issue>10</issue>):<fpage>1858</fpage>–<lpage>1865</lpage>. <pub-id pub-id-type="doi">10.1109/TPAMI.2008.113</pub-id><pub-id pub-id-type="pmid">18703836</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1008697.ref029">
      <label>29</label>
      <mixed-citation publication-type="other">Rublee E, Rabaud V, Konolige K, Bradski G. ORB: An efficient alternative to SIFT or SURF. In: 2011 International conference on computer vision. Ieee; 2011. p. 2564–2571.</mixed-citation>
    </ref>
    <ref id="pcbi.1008697.ref030">
      <label>30</label>
      <mixed-citation publication-type="journal"><name><surname>Bolles</surname><given-names>RC</given-names></name>, <name><surname>Fischler</surname><given-names>MA</given-names></name>. <article-title>A RANSAC-based approach to model fitting and its application to finding cylinders in range data</article-title>. In: <source>IJCAI</source>. <volume>vol. 1981</volume>; <year>1981</year> p. <fpage>637</fpage>–<lpage>643</lpage>.</mixed-citation>
    </ref>
    <ref id="pcbi.1008697.ref031">
      <label>31</label>
      <mixed-citation publication-type="journal"><name><surname>Suzuki</surname><given-names>S</given-names></name>, <name><surname>Be</surname><given-names>KA</given-names></name>. <article-title>Topological structural analysis of digitized binary images by border following</article-title>. <source>Computer Vision, Graphics, and Image Processing</source>. <year>1985</year>;<volume>30</volume>(<issue>1</issue>):<fpage>32</fpage>–<lpage>46</lpage>. <pub-id pub-id-type="doi">10.1016/0734-189X(85)90016-7</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1008697.ref032">
      <label>32</label>
      <mixed-citation publication-type="journal"><name><surname>Shuo</surname><given-names>H</given-names></name>, <name><surname>Na</surname><given-names>W</given-names></name>, <name><surname>Huajun</surname><given-names>S</given-names></name>. <article-title>Object Tracking Method Based on SURF</article-title>. <source>AASRI Conference on Modelling, Identification and Control</source>. <year>2012</year>;<volume>3</volume>:<fpage>351</fpage>–<lpage>356</lpage>.</mixed-citation>
    </ref>
    <ref id="pcbi.1008697.ref033">
      <label>33</label>
      <mixed-citation publication-type="journal"><name><surname>Chaumette</surname><given-names>F</given-names></name>. <article-title>Image moments: a general and useful set of features for visual servoing</article-title>. <source>IEEE Transactions on Robotics</source>. <year>2004</year>;<volume>20</volume>(<issue>4</issue>):<fpage>713</fpage>–<lpage>723</lpage>. <pub-id pub-id-type="doi">10.1109/TRO.2004.829463</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1008697.ref034">
      <label>34</label>
      <mixed-citation publication-type="other">Riemann B. Grundlagen für eine allgemeine Theorie der Functionen einer veränderlichen complexen Grösse. PhD. 1851;.</mixed-citation>
    </ref>
    <ref id="pcbi.1008697.ref035">
      <label>35</label>
      <mixed-citation publication-type="other">Rocha L, Velho L, Carvalho PCP. Image moments-based structuring and tracking of objects. In: Computer Graphics and Image Processing, 2002. Proceedings. XV Brazilian Symposium on. IEEE; 2002. p. 99–105.</mixed-citation>
    </ref>
    <ref id="pcbi.1008697.ref036">
      <label>36</label>
      <mixed-citation publication-type="journal"><name><surname>Olive</surname><given-names>R</given-names></name>, <name><surname>Wolf</surname><given-names>S</given-names></name>, <name><surname>Dubreuil</surname><given-names>A</given-names></name>, <name><surname>Bormuth</surname><given-names>V</given-names></name>, <name><surname>Debrégeas</surname><given-names>G</given-names></name>, <name><surname>Candelier</surname><given-names>R</given-names></name>. <article-title>Rheotaxis of Larval Zebrafish: Behavioral Study of a Multi-Sensory Process</article-title>. <source>Front Syst Neurosci</source>. <year>2016</year>;<volume>10</volume>:<fpage>14</fpage><pub-id pub-id-type="doi">10.3389/fnsys.2016.00014</pub-id><pub-id pub-id-type="pmid">26941620</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1008697.ref037">
      <label>37</label>
      <mixed-citation publication-type="journal"><name><surname>Jouary</surname><given-names>A</given-names></name>, <name><surname>Haudrechy</surname><given-names>M</given-names></name>, <name><surname>Candelier</surname><given-names>R</given-names></name>, <name><surname>Sumbre</surname><given-names>G</given-names></name>. <article-title>A 2D virtual reality system for visual goal-driven navigation in zebrafish larvae</article-title>. <source>Scientific Reports</source>. <year>2016</year>;<volume>6</volume>(<issue>34015</issue>). <pub-id pub-id-type="doi">10.1038/srep34015</pub-id><?supplied-pmid 27659496?><pub-id pub-id-type="pmid">27659496</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1008697.ref038">
      <label>38</label>
      <mixed-citation publication-type="journal"><name><surname>Qian</surname><given-names>ZM</given-names></name>, <name><surname>Wang</surname><given-names>SH</given-names></name>, <name><surname>Cheng</surname><given-names>XE</given-names></name>, <name><surname>Chen</surname><given-names>YQ</given-names></name>. <article-title>An effective and robust method for tracking multiple fish in video image based on fish head detection</article-title>. <source>BMC Bioinformatics</source>. <year>2016</year>;<volume>17</volume>(<issue>1</issue>):<fpage>251</fpage><pub-id pub-id-type="doi">10.1186/s12859-016-1138-y</pub-id><pub-id pub-id-type="pmid">27338122</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1008697.ref039">
      <label>39</label>
      <mixed-citation publication-type="other">Martello S, Toth P. Linear Assignment Problems. In: Martello S, Laporte G, Minoux M, Ribeiro C, editors. Surveys in Combinatorial Optimization. vol. 132 of North-Holland Mathematics Studies. North-Holland; 1987. p. 259–282. Available from: <ext-link ext-link-type="uri" xlink:href="http://www.sciencedirect.com/science/article/pii/S0304020808732389">http://www.sciencedirect.com/science/article/pii/S0304020808732389</ext-link>.</mixed-citation>
    </ref>
    <ref id="pcbi.1008697.ref040">
      <label>40</label>
      <mixed-citation publication-type="journal"><name><surname>Kuhn</surname><given-names>HW</given-names></name>. <article-title>The Hungarian method for the assignment problem</article-title>. <source>Naval research logistics quarterly</source>. <year>1955</year>;<volume>2</volume>(<issue>1-2</issue>):<fpage>83</fpage>–<lpage>97</lpage>. <pub-id pub-id-type="doi">10.1002/nav.3800020109</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1008697.ref041">
      <label>41</label>
      <mixed-citation publication-type="other">Buehren M. Functions for the rectangular assignment problem; 2005. Available from: <ext-link ext-link-type="uri" xlink:href="https://github.com/mcximing/hungarian-algorithm-cpp">https://github.com/mcximing/hungarian-algorithm-cpp</ext-link>.</mixed-citation>
    </ref>
    <ref id="pcbi.1008697.ref042">
      <label>42</label>
      <mixed-citation publication-type="book"><name><surname>Christos</surname><given-names>H</given-names></name><name><surname>Papadimitriou</surname><given-names>KS</given-names></name>. <chapter-title>Combinatorial Optimization: Algorithms and Complexity</chapter-title><source>vol. 1 of Mathematical optimization</source>. <edition designator="2">2nd ed</edition><publisher-name>Prentice Hall</publisher-name>; <year>1998</year>.</mixed-citation>
    </ref>
    <ref id="pcbi.1008697.ref043">
      <label>43</label>
      <mixed-citation publication-type="journal"><name><surname>Young</surname><given-names>JW</given-names></name>, <name><surname>Locke</surname><given-names>JCW</given-names></name>, <name><surname>Altinok</surname><given-names>A</given-names></name>, <name><surname>Rosenfeld</surname><given-names>N</given-names></name>, <name><surname>Bacarian</surname><given-names>T</given-names></name>, <name><surname>Swain</surname><given-names>PS</given-names></name>, <etal>et al</etal><article-title>Measuring single-cell gene expression dynamics in bacteria using fluorescence time-lapse microscopy</article-title>. <source>Nature Protocols</source>. <year>2012</year>;<volume>7</volume>(<issue>1</issue>). <pub-id pub-id-type="doi">10.1038/nprot.2012.113</pub-id><?supplied-pmid 23018195?><pub-id pub-id-type="pmid">23018195</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1008697.ref044">
      <label>44</label>
      <mixed-citation publication-type="journal"><name><surname>Sadanandan</surname><given-names>SK</given-names></name>, <name><surname>Baltekin</surname><given-names>Ö</given-names></name>, <name><surname>Magnusson</surname><given-names>KEG</given-names></name>, <name><surname>Boucharin</surname><given-names>A</given-names></name>, <name><surname>Ranefall</surname><given-names>P</given-names></name>, <name><surname>Jaldén</surname><given-names>J</given-names></name>, <etal>et al</etal><article-title>Segmentation and Track-Analysis in Time-Lapse Imaging of Bacteria</article-title>. <source>IEEE Journal of Selected Topics in Signal Processing</source>. <year>2016</year>;<volume>10</volume>(<issue>1</issue>):<fpage>174</fpage>–<lpage>184</lpage>. <pub-id pub-id-type="doi">10.1109/JSTSP.2015.2491304</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1008697.ref045">
      <label>45</label>
      <mixed-citation publication-type="journal"><name><surname>Romero-Ferrero</surname><given-names>F</given-names></name>, <name><surname>Bergomi</surname><given-names>MG</given-names></name>, <name><surname>Hinz</surname><given-names>RC</given-names></name>, <name><surname>Heras</surname><given-names>FJH</given-names></name>, <name><surname>de Polavieja</surname><given-names>GG</given-names></name>. <article-title>idtracker.ai: tracking all individuals in small or large collectives of unmarked animals</article-title>. <source>Nat Methods</source>. <year>2019</year>;<volume>16</volume>(<issue>2</issue>):<fpage>179</fpage>–<lpage>182</lpage>. <pub-id pub-id-type="doi">10.1038/s41592-018-0295-5</pub-id><pub-id pub-id-type="pmid">30643215</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1008697.ref046">
      <label>46</label>
      <mixed-citation publication-type="journal"><name><surname>Rodriguez</surname><given-names>A</given-names></name>, <name><surname>Zhang</surname><given-names>H</given-names></name>, <name><surname>Klaminder</surname><given-names>J</given-names></name>, <name><surname>Brodin</surname><given-names>T</given-names></name>, <name><surname>Andersson</surname><given-names>PL</given-names></name>, <name><surname>Andersson</surname><given-names>M</given-names></name>. <article-title>ToxTrac: A fast and robust software for tracking organisms</article-title>. <source>Methods in Ecology and Evolution</source>. <year>2018</year>;<volume>9</volume>(<issue>3</issue>):<fpage>460</fpage>–<lpage>464</lpage>. <pub-id pub-id-type="doi">10.1111/2041-210X.12874</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1008697.ref047">
      <label>47</label>
      <mixed-citation publication-type="journal"><name><surname>Shor</surname><given-names>Y</given-names></name>, <name><surname>Lischinski</surname><given-names>D</given-names></name>. <article-title>The Shadow Meets the Mask: Pyramid-Based Shadow Removal</article-title>. <source>Computer Graphics Forum</source>. <year>2008</year>;<volume>27</volume>(<issue>2</issue>):<fpage>577</fpage>–<lpage>586</lpage>. <pub-id pub-id-type="doi">10.1111/j.1467-8659.2008.01155.x</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1008697.ref048">
      <label>48</label>
      <mixed-citation publication-type="other">Dey N, Dutta S, Dey G, Chakraborty S, Ray R, Roy P. Adaptive thresholding: A comparative study; 2014.</mixed-citation>
    </ref>
  </ref-list>
</back>
<sub-article id="pcbi.1008697.r001" article-type="aggregated-review-documents">
  <front-stub>
    <article-id pub-id-type="doi">10.1371/journal.pcbi.1008697.r001</article-id>
    <title-group>
      <article-title>Decision Letter 0</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Marz</surname>
          <given-names>Manja</given-names>
        </name>
        <role>Software Editor</role>
      </contrib>
    </contrib-group>
    <permissions>
      <copyright-statement>© 2021 Manja Marz</copyright-statement>
      <copyright-year>2021</copyright-year>
      <copyright-holder>Manja Marz</copyright-holder>
      <license xlink:href="http://creativecommons.org/licenses/by/4.0/">
        <license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
      </license>
    </permissions>
    <related-article id="rel-obj001" ext-link-type="doi" xlink:href="10.1371/journal.pcbi.1008697" related-article-type="reviewed-article"/>
    <custom-meta-group>
      <custom-meta>
        <meta-name>Submission Version</meta-name>
        <meta-value>0</meta-value>
      </custom-meta>
    </custom-meta-group>
  </front-stub>
  <body>
    <p>
      <named-content content-type="letter-date">30 Jul 2020</named-content>
    </p>
    <p>Dear Dr Candelier,</p>
    <p>Thank you very much for submitting your manuscript "FastTrack: an open-source software for tracking varying numbers of deformable objects" for consideration at PLOS Computational Biology.</p>
    <p>As with all papers reviewed by the journal, your manuscript was reviewed by members of the editorial board and by several independent reviewers. In light of the reviews (below this email), we would like to invite the resubmission of a significantly-revised version that takes into account the reviewers' comments.</p>
    <p>We cannot make any decision about publication until we have seen the revised manuscript and your response to the reviewers' comments. Your revised manuscript is also likely to be sent to reviewers for further evaluation.</p>
    <p>When you are ready to resubmit, please upload the following:</p>
    <p>[1] A letter containing a detailed list of your responses to the review comments and a description of the changes you have made in the manuscript. Please note while forming your response, if your article is accepted, you may have the opportunity to make the peer review history publicly available. The record will include editor decision letters (with reviews) and your responses to reviewer comments. If eligible, we will contact you to opt in or out.</p>
    <p>[2] Two versions of the revised manuscript: one with either highlights or tracked changes denoting where the text has been changed; the other a clean version (uploaded as the manuscript file).</p>
    <p>Important additional instructions are given below your reviewer comments.</p>
    <p>Please prepare and submit your revised manuscript within 60 days. If you anticipate any delay, please let us know the expected resubmission date by replying to this email. Please note that revised manuscripts received after the 60-day due date may require evaluation and peer review similar to newly submitted manuscripts.</p>
    <p>Thank you again for your submission. We hope that our editorial process has been constructive so far, and we welcome your feedback at any time. Please don't hesitate to contact us if you have any questions or comments.</p>
    <p>Sincerely,</p>
    <p>Manja Marz</p>
    <p>Software Editor</p>
    <p>PLOS Computational Biology</p>
    <p>Manja Marz</p>
    <p>Software Editor</p>
    <p>PLOS Computational Biology</p>
    <p>***********************</p>
    <p>Reviewer's Responses to Questions</p>
    <p>
      <bold>Comments to the Authors:</bold>
    </p>
    <p>
      <bold>Please note here if the review is uploaded as an attachment.</bold>
    </p>
    <p>Reviewer #1: The review is uploaded as attachment.</p>
    <p>Reviewer #2: The authors present FastTrack as a general tool to track any kind of objects in 2D and in a large panel of imaging conditions. My impression is that FastTrack is a very powerful tool for objects detection, but the tracking approach is weak in automatically solving occlusions, which is the very core of all tracking algorithms. The authors also present a database of different data on which the algorithm is tested. The algorithm is heavily based on manual checks through post-processing procedure, which is another weakness of the algorithm strictly related to the matching method followed by the authors.</p>
    <p>My suggestion is to dampen the part of the manuscript in which the algorithm is defined as general and applicable to any type of data. My main concerns are indeed about the matching module of the algorithm and about the database.</p>
    <p>Matching.</p>
    <p>1- hard cost. the authors define h_ij as a hard cost, but in my opinion h_ij is instead a boolean variable associated to the pair i,j: h_ij=1 if r_ij &lt; h_d otherwise it is equal to 0, where r_ij is the distance between i and j, and h_d is a threshold value. Therefore h_ij is a sort of participation variable that defines which pairs have a finite cost.</p>
    <p>2- soft cost. It is not clear to me how s_d and s_a are chosen. The authors state that these 2 factors are the typical change in position and direction of motion respectively, but they do not give details on how these two factors are computed from the data, and my impression is that s_d and s_a are normalization factors that can be chosen from the users to increase the contribution of one term or the other in the soft cost definition.</p>
    <p>3- occlusion. The matching between detected objects is performed using an Hungarian method, which can only produce one-to-one matches, which is clearly not a way to solve occlusions, but even worse it may produce swapping of identities. Video 1 of Supplementary Information clearly shows what happens when an occlusion occurs, as it is evident in the part of the movie with the 2 mice, but also in other parts of the video. While two objects are occluded the detected occluded detected object is not included in any trajectory and the output of the algorithm consists of 4 short trajectories that are matched before and after the occlusion. I guess that the identities are matched via a manual intervention of the user or via the part of the software related to the objects disappearance.</p>
    <p>4- objects disappeareance. The authors should give more details on how the global cost matrix between not-matching objects is performed.</p>
    <p>Post-processing.</p>
    <p>The entire software is based on post-processing manual check of the algorithm output which is also used to train the matching procedure on data of the same type. My concern about this highly manual component of the algorithm is that this is applicable only on low density datasets of a small number of individuals.</p>
    <p>Data.</p>
    <p>1- public datasets. The authors state that the algorithm can be applied to a broad class of data. My question is then why they did not test the algorithm on already existing datasets, which is a common practise in the computer vision community.</p>
    <p>2- tracking data. Many of the data included in the database are interesting from the object detection point of view, but they do not present particular difficulties from the tracking point of view. This is the case of the Drosophila examples in Video1 of the Supplementary Information, where Drosophila move in Y cells that do not communicate, hence tracking is essentially a segmentation and linking of detected objects within a specific region. This is also the case of the industrial examples of the same Video, where still objects are transported by small platforms.</p>
    <p>Minor comments.</p>
    <p>1- Fig.2c: how is the computational time normalized?</p>
    <p>2- the authors should give the idea of the method chosen to extract the objects contours</p>
    <p>3- in Section “Parameters optimization” the authors use the term swap to indicate an error in the matching, but swapping is not the only cause for a tracking error. A second kind of error is a missing match, which happens every time that an object is not included in any match. This last situation is what happens when h_d is too small and there are not possible matching candidates for the objects or for a part of them.</p>
    <p>4- developped -&gt; developed</p>
    <p>Reviewer #3: The present paper introduces FastTrack, "an open-source software for tracking varying numbers of deformable objects". The authors</p>
    <p>describe the software and it's workflow (mainly detection, matching, post processing). They introduce a replay feature, a system</p>
    <p>to let users manually correct errors from automated tracking by swapping assigned identifiers. The authors provide a method to</p>
    <p>estimate the number of manual corrections needed in a specific tracking task. Based on manually extracted ground truth, they also</p>
    <p>introduce a method to optimize some of the parameters of the tracking algorithm.</p>
    <p>* General Comments:</p>
    <p>In general the paper is clear and well written, but it does not go deep into results, nor issues that can be encountered when</p>
    <p>doing a tracking task. The state of the art is superficial.</p>
    <p>It is very appreciated that the software is released under an open license, with documentation, and with datasets for testing it.</p>
    <p>The software is operational and provides a rather well thought interface, although there are specific details that could be improved.</p>
    <p>The probability of incursions P_inc may be one of the key contribution of the paper, unfortunately the authors did not connect</p>
    <p>this value with empirical measurements of P_swap to assess the usefulness of their approach.</p>
    <p>The authors show how P_swap can be used to optimize the tracking parameters. This approach is tedious and standard practice.</p>
    <p>It is interesting to report some methodology, but there is no novelty in this, as far as I can see.</p>
    <p>* Specific comments:</p>
    <p>- Probability of incursions:</p>
    <p>The approach is interesting, however explanations are scarce. In particular I could not fully understand Equation 3, with r left</p>
    <p>undefined. The general idea that I could grasp is that based on estimated motion (from tracking algorithm) and Voronoi cells, the</p>
    <p>authors estimate the probability of incursions which may lead to tracking issues (erroneous objects assignments). The authors</p>
    <p>provide calculations of P_inc they made on several test videos, but they provide no reference to understand how P_inc may be</p>
    <p>useful. A simple solution would be to manually extract P_swap value of all the videos and compare P_inc to P_swap. This would</p>
    <p>already help understanding if this estimator is relevant.</p>
    <p>- Computational efficiency of FastTrack</p>
    <p>The authors claim that their software is fast, with no data to support the claim. Please do a benchmark, with a well characterized</p>
    <p>hardware, compare to other softwares doing the exact same task.</p>
    <p>- Details of tracking algorithm</p>
    <p>While reading the paper, it was not clear to me how the software handles assignment of newly appeared objects, or how intermittently</p>
    <p>appearing objects are handled.</p>
    <p>- Ergonomics of the software</p>
    <p>As I tested FastTrack, I had difficulties zooming in particular areas of the image, the authors might want to improve this aspect.</p>
    <p>Also, the replay section could see some ergonomics improvements. Manual corrections are best carried out in non linear editing mode,</p>
    <p>with simple controls to go back and forth between frames. I found only one slider to move between frames, and keyboard shortcuts</p>
    <p>would alternate between translating the image and skipping frames. I also tried to do some manual corrections on a personal video</p>
    <p>of moving fish, but my attempt was rather unsuccessful. As an example, I faced the case of 3 fish getting close together and the</p>
    <p>overlay of ids and ellipses made it unclear where each fish was. Moreover, I don't see how to do manual corrections if some</p>
    <p>objects are not detected during several frames and assignments jump to distant locations (for instance when 3 fish overlap in the</p>
    <p>video during several frames). It may help to visualize past and future trajectories, and be able to select and drag a detected</p>
    <p>object to its "real" location, and optionally to recalculate the trajectories of nearby objects in case of a 2-objects</p>
    <p>swap. Finally, the software is extracting all the frames of analyzed videos in png format which might take a long time, or be</p>
    <p>impossible in case of high resolution or long movies (example: 4K 24h @ 1fps could easily yield 260GB of images)</p>
    <p>- Usefulness of the software</p>
    <p>There are no tangible results about the tracking performance of the software. I would expect some measurements of speed, of</p>
    <p>accuracy compared to ground truth, of ergonomics to manually post process results. This could be done using the data set</p>
    <p>provided. Also, the authors may compare their results to other existing software to better highlight their contribution.</p>
    <p>**********</p>
    <p>
      <bold>Have all data underlying the figures and results presented in the manuscript been provided?</bold>
    </p>
    <p>Large-scale datasets should be made available via a public repository as described in the <italic>PLOS Computational Biology</italic>
<ext-link ext-link-type="uri" xlink:href="http://journals.plos.org/ploscompbiol/s/data-availability">data availability policy</ext-link>, and numerical data that underlies graphs or summary statistics should be provided in spreadsheet form as supporting information.</p>
    <p>Reviewer #1: Yes</p>
    <p>Reviewer #2: Yes</p>
    <p>Reviewer #3: Yes</p>
    <p>**********</p>
    <p>PLOS authors have the option to publish the peer review history of their article (<ext-link ext-link-type="uri" xlink:href="https://journals.plos.org/ploscompbiol/s/editorial-and-peer-review-process#loc-peer-review-history">what does this mean?</ext-link>). If published, this will include your full peer review and any attached files.</p>
    <p>If you choose “no”, your identity will remain anonymous but your review may still be made public.</p>
    <p><bold>Do you want your identity to be public for this peer review?</bold> For information about this choice, including consent withdrawal, please see our <ext-link ext-link-type="uri" xlink:href="https://www.plos.org/privacy-policy">Privacy Policy</ext-link>.</p>
    <p>Reviewer #1: <bold>Yes: </bold>Hangjian Ling</p>
    <p>Reviewer #2: No</p>
    <p>Reviewer #3: <bold>Yes: </bold>Alexandre Campo</p>
    <p>
      <underline>Figure Files:</underline>
    </p>
    <p>While revising your submission, please upload your figure files to the Preflight Analysis and Conversion Engine (PACE) digital diagnostic tool, <underline><ext-link ext-link-type="uri" xlink:href="https://pacev2.apexcovantage.com/" xlink:type="simple">https://pacev2.apexcovantage.com</ext-link></underline>. PACE helps ensure that figures meet PLOS requirements. To use PACE, you must first register as a user. Then, login and navigate to the UPLOAD tab, where you will find detailed instructions on how to use the tool. If you encounter any issues or have any questions when using PACE, please email us at <underline><email xlink:type="simple">figures@plos.org</email></underline>.</p>
    <p>
      <underline>Data Requirements:</underline>
    </p>
    <p>Please note that, as a condition of publication, PLOS' data policy requires that you make available all data used to draw the conclusions outlined in your manuscript. Data must be deposited in an appropriate repository, included within the body of the manuscript, or uploaded as supporting information. This includes all numerical values that were used to generate graphs, histograms etc.. For an example in PLOS Biology see here: <ext-link ext-link-type="uri" xlink:href="http://www.plosbiology.org/article/info%3Adoi%2F10.1371%2Fjournal.pbio.1001908#s5">http://www.plosbiology.org/article/info%3Adoi%2F10.1371%2Fjournal.pbio.1001908#s5</ext-link>.</p>
    <p>
      <underline>Reproducibility:</underline>
    </p>
    <p>To enhance the reproducibility of your results, PLOS recommends that you deposit laboratory protocols in protocols.io, where a protocol can be assigned its own identifier (DOI) such that it can be cited independently in the future. For instructions, please see <underline><ext-link ext-link-type="uri" xlink:href="http://journals.plos.org/plospathogens/s/submission-guidelines" xlink:type="simple">http://journals.plos.org/compbiol/s/submission-guidelines#loc-materials-and-methods</ext-link></underline></p>
    <supplementary-material content-type="local-data" id="pcbi.1008697.s013">
      <label>Attachment</label>
      <caption>
        <p>Submitted filename: <named-content content-type="submitted-filename">PCOMPBIO_2020_06_25.docx</named-content></p>
      </caption>
      <media xlink:href="pcbi.1008697.s013.docx">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </body>
</sub-article>
<sub-article id="pcbi.1008697.r002" article-type="author-comment">
  <front-stub>
    <article-id pub-id-type="doi">10.1371/journal.pcbi.1008697.r002</article-id>
    <title-group>
      <article-title>Author response to Decision Letter 0</article-title>
    </title-group>
    <related-article id="rel-obj002" ext-link-type="doi" xlink:href="10.1371/journal.pcbi.1008697" related-article-type="editor-report"/>
    <custom-meta-group>
      <custom-meta>
        <meta-name>Submission Version</meta-name>
        <meta-value>1</meta-value>
      </custom-meta>
    </custom-meta-group>
  </front-stub>
  <body>
    <p>
      <named-content content-type="author-response-date">13 Nov 2020</named-content>
    </p>
    <supplementary-material content-type="local-data" id="pcbi.1008697.s014">
      <label>Attachment</label>
      <caption>
        <p>Submitted filename: <named-content content-type="submitted-filename">Response_reviewers.pdf</named-content></p>
      </caption>
      <media xlink:href="pcbi.1008697.s014.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </body>
</sub-article>
<sub-article id="pcbi.1008697.r003" article-type="aggregated-review-documents">
  <front-stub>
    <article-id pub-id-type="doi">10.1371/journal.pcbi.1008697.r003</article-id>
    <title-group>
      <article-title>Decision Letter 1</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Marz</surname>
          <given-names>Manja</given-names>
        </name>
        <role>Software Editor</role>
      </contrib>
    </contrib-group>
    <permissions>
      <copyright-statement>© 2021 Manja Marz</copyright-statement>
      <copyright-year>2021</copyright-year>
      <copyright-holder>Manja Marz</copyright-holder>
      <license xlink:href="http://creativecommons.org/licenses/by/4.0/">
        <license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
      </license>
    </permissions>
    <related-article id="rel-obj003" ext-link-type="doi" xlink:href="10.1371/journal.pcbi.1008697" related-article-type="reviewed-article"/>
    <custom-meta-group>
      <custom-meta>
        <meta-name>Submission Version</meta-name>
        <meta-value>1</meta-value>
      </custom-meta>
    </custom-meta-group>
  </front-stub>
  <body>
    <p>
      <named-content content-type="letter-date">10 Jan 2021</named-content>
    </p>
    <p>Dear Dr Candelier,</p>
    <p>We are pleased to inform you that your manuscript 'FastTrack: an open-source software for tracking varying numbers of deformable objects' has been provisionally accepted for publication in PLOS Computational Biology.</p>
    <p>Before your manuscript can be formally accepted you will need to complete some formatting changes, which you will receive in a follow up email. A member of our team will be in touch with a set of requests.</p>
    <p>Please note that your manuscript will not be scheduled for publication until you have made the required changes, so a swift response is appreciated.</p>
    <p>IMPORTANT: The editorial review process is now complete. PLOS will only permit corrections to spelling, formatting or significant scientific errors from this point onwards. Requests for major changes, or any which affect the scientific understanding of your work, will cause delays to the publication date of your manuscript.</p>
    <p>Should you, your institution's press office or the journal office choose to press release your paper, you will automatically be opted out of early publication. We ask that you notify us now if you or your institution is planning to press release the article. All press must be co-ordinated with PLOS.</p>
    <p>Thank you again for supporting Open Access publishing; we are looking forward to publishing your work in PLOS Computational Biology. </p>
    <p>Best regards,</p>
    <p>Manja Marz</p>
    <p>Software Editor</p>
    <p>PLOS Computational Biology</p>
    <p>Manja Marz</p>
    <p>Software Editor</p>
    <p>PLOS Computational Biology</p>
    <p>***********************************************************</p>
    <p>Reviewer's Responses to Questions</p>
    <p>
      <bold>Comments to the Authors:</bold>
    </p>
    <p>
      <bold>Please note here if the review is uploaded as an attachment.</bold>
    </p>
    <p>Reviewer #1: After reviewing the revised manuscript, I consider that all my questions have been fully addressed. I have no further comments, and recommend the manuscript to be published.</p>
    <p>Reviewer #3: The revised paper is now clearer, the authors responses to reviewers comments are detailed and very welcome.</p>
    <p>Also the improvements brought to the paper and the software for this second revision are great and required</p>
    <p>lots of efforts, this is very appreciated.</p>
    <p>The comparison with existing software helps understand the benefits brought by this software. Some results are</p>
    <p>not really surprising, as ID tracker is known to be slow (at least at some point in time); I would have been curious</p>
    <p>to see other softwares benchmarked but this choice makes sense since ID tracker is popular, and benchmarking</p>
    <p>is a tedious task. The shift of focus to P_inc is welcome, removing the requirement of ground truth is a step forward.</p>
    <p>Overall, the automation of parameterization, together with an interface to perform manual adjustments and corrections</p>
    <p>gives a very useful tool to the communities of scientists that need effective video tracking.</p>
    <p>**********</p>
    <p>
      <bold>Have all data underlying the figures and results presented in the manuscript been provided?</bold>
    </p>
    <p>Large-scale datasets should be made available via a public repository as described in the <italic>PLOS Computational Biology</italic>
<ext-link ext-link-type="uri" xlink:href="http://journals.plos.org/ploscompbiol/s/data-availability">data availability policy</ext-link>, and numerical data that underlies graphs or summary statistics should be provided in spreadsheet form as supporting information.</p>
    <p>Reviewer #1: Yes</p>
    <p>Reviewer #3: Yes</p>
    <p>**********</p>
    <p>PLOS authors have the option to publish the peer review history of their article (<ext-link ext-link-type="uri" xlink:href="https://journals.plos.org/ploscompbiol/s/editorial-and-peer-review-process#loc-peer-review-history">what does this mean?</ext-link>). If published, this will include your full peer review and any attached files.</p>
    <p>If you choose “no”, your identity will remain anonymous but your review may still be made public.</p>
    <p><bold>Do you want your identity to be public for this peer review?</bold> For information about this choice, including consent withdrawal, please see our <ext-link ext-link-type="uri" xlink:href="https://www.plos.org/privacy-policy">Privacy Policy</ext-link>.</p>
    <p>Reviewer #1: <bold>Yes: </bold>Hangjian Ling</p>
    <p>Reviewer #3: <bold>Yes: </bold>Alexandre Campo</p>
  </body>
</sub-article>
<sub-article id="pcbi.1008697.r004" article-type="editor-report">
  <front-stub>
    <article-id pub-id-type="doi">10.1371/journal.pcbi.1008697.r004</article-id>
    <title-group>
      <article-title>Acceptance letter</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Marz</surname>
          <given-names>Manja</given-names>
        </name>
        <role>Software Editor</role>
      </contrib>
    </contrib-group>
    <permissions>
      <copyright-statement>© 2021 Manja Marz</copyright-statement>
      <copyright-year>2021</copyright-year>
      <copyright-holder>Manja Marz</copyright-holder>
      <license xlink:href="http://creativecommons.org/licenses/by/4.0/">
        <license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
      </license>
    </permissions>
    <related-article id="rel-obj004" ext-link-type="doi" xlink:href="10.1371/journal.pcbi.1008697" related-article-type="reviewed-article"/>
  </front-stub>
  <body>
    <p>
      <named-content content-type="letter-date">4 Feb 2021</named-content>
    </p>
    <p>PCOMPBIOL-D-20-00512R1 </p>
    <p>FastTrack: an open-source software for tracking varying numbers of deformable objects</p>
    <p>Dear Dr Candelier,</p>
    <p>I am pleased to inform you that your manuscript has been formally accepted for publication in PLOS Computational Biology. Your manuscript is now with our production department and you will be notified of the publication date in due course.</p>
    <p>The corresponding author will soon be receiving a typeset proof for review, to ensure errors have not been introduced during production. Please review the PDF proof of your manuscript carefully, as this is the last chance to correct any errors. Please note that major changes, or those which affect the scientific understanding of the work, will likely cause delays to the publication date of your manuscript. </p>
    <p>Soon after your final files are uploaded, unless you have opted out, the early version of your manuscript will be published online. The date of the early version will be your article's publication date. The final article will be published to the same URL, and all versions of the paper will be accessible to readers.</p>
    <p>Thank you again for supporting PLOS Computational Biology and open-access publishing. We are looking forward to publishing your work! </p>
    <p>With kind regards,</p>
    <p>Alice Ellingham</p>
    <p>PLOS Computational Biology | Carlyle House, Carlyle Road, Cambridge CB4 3DN | United Kingdom <email>ploscompbiol@plos.org</email> | Phone +44 (0) 1223-442824 | <ext-link ext-link-type="uri" xlink:href="http://ploscompbiol.org">ploscompbiol.org</ext-link> | @PLOSCompBiol</p>
  </body>
</sub-article>
