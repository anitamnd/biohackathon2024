<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">BMC Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">BMC Bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>BMC Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1471-2105</issn>
    <publisher>
      <publisher-name>BioMed Central</publisher-name>
      <publisher-loc>London</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">6933662</article-id>
    <article-id pub-id-type="publisher-id">3291</article-id>
    <article-id pub-id-type="doi">10.1186/s12859-019-3291-6</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Methodology</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>DeepMF: deciphering the latent patterns in omics profiles with a deep learning method</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" equal-contrib="yes">
        <name>
          <surname>Chen</surname>
          <given-names>Lingxi</given-names>
        </name>
        <address>
          <email>chanlingxi@gmail.com</email>
        </address>
        <xref ref-type="aff" rid="Aff1"/>
      </contrib>
      <contrib contrib-type="author" equal-contrib="yes">
        <name>
          <surname>Xu</surname>
          <given-names>Jiao</given-names>
        </name>
        <address>
          <email>jiaox96@gmail.com</email>
        </address>
        <xref ref-type="aff" rid="Aff1"/>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Li</surname>
          <given-names>Shuai Cheng</given-names>
        </name>
        <address>
          <email>shuaicli@cityu.edu.hk</email>
        </address>
        <xref ref-type="aff" rid="Aff1"/>
      </contrib>
      <aff id="Aff1"><institution-wrap><institution-id institution-id-type="ISNI">0000 0004 1792 6846</institution-id><institution-id institution-id-type="GRID">grid.35030.35</institution-id><institution>City University of Hong Kong, </institution></institution-wrap>83 Tat Chee Ave, Kowloon Tong, Hong Kong, China </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>27</day>
      <month>12</month>
      <year>2019</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>27</day>
      <month>12</month>
      <year>2019</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2019</year>
    </pub-date>
    <volume>20</volume>
    <issue>Suppl 23</issue>
    <issue-sponsor>Publication of this supplement has not been supported by sponsorship. Information about the source of funding for publication charges can be found in the individual articles. The articles have undergone the journal's standard peer review process for supplements. Supplement Editors were not responsible for the review of papers they had authored. No other competing interests were declared.</issue-sponsor>
    <elocation-id>648</elocation-id>
    <permissions>
      <copyright-statement>© The Author(s) 2019</copyright-statement>
      <license license-type="OpenAccess">
        <license-p><bold>Open Access</bold> This article is distributed under the terms of the Creative Commons Attribution 4.0 International License(<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted use, distribution, and reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver(<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/publicdomain/zero/1.0/">http://creativecommons.org/publicdomain/zero/1.0/</ext-link>) applies to the data made available in this article, unless otherwise stated.</license-p>
      </license>
    </permissions>
    <abstract id="Abs1">
      <sec>
        <title>Background</title>
        <p id="Par1">With recent advances in high-throughput technologies, <italic>matrix factorization</italic> techniques are increasingly being utilized for mapping quantitative omics profiling matrix data into low-dimensional embedding space, in the hope of uncovering insights in the underlying biological processes. Nevertheless, current matrix factorization tools fall short in handling noisy data and missing entries, both deficiencies that are often found in real-life data.</p>
      </sec>
      <sec>
        <title>Results</title>
        <p id="Par2">Here, we propose DeepMF, a deep neural network-based factorization model. DeepMF disentangles the association between molecular feature-associated and sample-associated latent matrices, and is tolerant to noisy and missing values. It exhibited feasible cancer subtype discovery efficacy on mRNA, miRNA, and protein profiles of medulloblastoma cancer, leukemia cancer, breast cancer, and small-blue-round-cell cancer, achieving the highest clustering accuracy of 76%, 100%, 92%, and 100% respectively. When analyzing data sets with 70% missing entries, DeepMF gave the best recovery capacity with silhouette values of 0.47, 0.6, 0.28, and 0.44, outperforming other state-of-the-art MF tools on the cancer data sets Medulloblastoma, Leukemia, TCGA BRCA, and SRBCT. Its embedding strength as measured by clustering accuracy is 88%, 100%, 84%, and 96% on these data sets, which improves on the current best methods 76%, 100%, 78%, and 87%.</p>
      </sec>
      <sec>
        <title>Conclusion</title>
        <p id="Par3">DeepMF demonstrated robust denoising, imputation, and embedding ability. It offers insights to uncover the underlying biological processes such as cancer subtype discovery. Our implementation of DeepMF can be found at <ext-link ext-link-type="uri" xlink:href="https://github.com/paprikachan/DeepMF">https://github.com/paprikachan/DeepMF</ext-link>.</p>
      </sec>
    </abstract>
    <kwd-group xml:lang="en">
      <title>Keywords</title>
      <kwd>Matrix factorization</kwd>
      <kwd>Dimension reduction</kwd>
      <kwd>Deep learning</kwd>
      <kwd>Omics profile</kwd>
      <kwd>Cancer subtype</kwd>
    </kwd-group>
    <conference xlink:href="https://www.abacbs.org/conference2019/about">
      <conf-name>Joint 30th International Conference on Genome Informatics (GIW) &amp; Australian Bioinformatics and Computational Biology Society (ABACBS) Annual Conference</conf-name>
      <conf-loc>Sydney, Australia</conf-loc>
      <conf-date>9-11 December 2019</conf-date>
    </conference>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>© The Author(s) 2019</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="Sec1">
    <title>Background</title>
    <p>Recent advances in high-throughput technologies have eased the quantitative profiling of biological data [<xref ref-type="bibr" rid="CR1">1</xref>]. In many cases, the biological data are captured in a high-dimensional matrix with molecular features such as gene, mutation locus, or species as rows and samples/repetition as columns. Values in the matrices are typically measurements such as expression abundances, mutation levels, or species counts. Based on the assumption that samples with the similar phenotype (or molecular features) that participate in a similar biological process will share similar distribution of biological variation [<xref ref-type="bibr" rid="CR1">1</xref>], researchers leverage clustering methods like <italic>k</italic>-means and hierarchical clustering to identify similar patterns and discover molecular features or sample subgroups [<xref ref-type="bibr" rid="CR2">2</xref>, <xref ref-type="bibr" rid="CR3">3</xref>]. Nevertheless, these clustering methods might fail to capture the full scape of underlying structures, which may debilitate the accuracy of subgroup identification and introduce bias to the underlying biological process. Thus, in this field, researchers increasingly adopt dimension reduction techniques and utilize the inferred alternative low-dimensional structure as input for subgroups clustering [<xref ref-type="bibr" rid="CR1">1</xref>, <xref ref-type="bibr" rid="CR2">2</xref>].</p>
    <p>Matrix factorization (MF), as given by the formula <inline-formula id="IEq1"><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\boldsymbol {A} \in \mathbb {R}^{M \times N} \approx \boldsymbol {U} \in \mathbb {R}^{M \times K} \times \boldsymbol {V} \in \mathbb {R}^{K \times N}$\end{document}</tex-math><mml:math id="M2"><mml:mi mathvariant="bold-italic">A</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi>ℝ</mml:mi></mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mo>×</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:msup><mml:mo>≈</mml:mo><mml:mi mathvariant="bold-italic">U</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi>ℝ</mml:mi></mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mo>×</mml:mo><mml:mi>K</mml:mi></mml:mrow></mml:msup><mml:mo>×</mml:mo><mml:mi mathvariant="bold-italic">V</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi>ℝ</mml:mi></mml:mrow><mml:mrow><mml:mi>K</mml:mi><mml:mo>×</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="12859_2019_3291_Article_IEq1.gif"/></alternatives></inline-formula> in Fig. <xref rid="Fig1" ref-type="fig">1</xref>a, is a popular approach to infer low-dimensional pattern from high-dimensional omics data [<xref ref-type="bibr" rid="CR1">1</xref>]. MFs decipher two sets of <italic>K</italic>-dimensional hidden representations from high-dimensional data: one explaining molecular relationship <bold><italic>U</italic></bold> and another describing sample-level connection <bold><italic>V</italic></bold>. We refer <bold><italic>U</italic></bold> as the signatures or molecular feature latent matrix, since the values in each column of <bold><italic>U</italic></bold> are continuous weights illustrating the relative participation of a molecule in each inferred biology process signature. Leveraging the molecular feature latent matrices learned from gene expression profiles, the data-driven functional pathways can be identified [<xref ref-type="bibr" rid="CR4">4</xref>–<xref ref-type="bibr" rid="CR6">6</xref>]. MF has also been used to define COSMIC mutational signatures in pan-cancer studies with patients mutation profiles [<xref ref-type="bibr" rid="CR7">7</xref>–<xref ref-type="bibr" rid="CR9">9</xref>]. We call <bold><italic>V</italic></bold> the metagenes or sample latent matrix, as each column of <bold><italic>V</italic></bold> represents the genes in embedding space and each row of <bold><italic>V</italic></bold> depicts the fractions of samples in the matched biological process signature. Patient subgroups discovery is well enabled by analysis of the sample latent matrix. For instance, detecting leukemia cancer subtype based on expression profiles [<xref ref-type="bibr" rid="CR2">2</xref>], classifying HPV subtypes in head and neck tumors by integrating gene expression and DNA methylation data[<xref ref-type="bibr" rid="CR10">10</xref>], and The Cancer Genome Atlas (TCGA) pan-cancer patients subtyping from mutation profiles [<xref ref-type="bibr" rid="CR11">11</xref>].
<fig id="Fig1"><label>Fig. 1</label><caption><p>DeepMF structure overview. <bold>a</bold>-<bold>b</bold> Illustration of MF and DeepMF, respectively. <bold>c</bold> The training process of DeepMF. The triangles represent the <italic>K</italic> dimensional molecular feature latent factors <inline-formula id="IEq2"><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\boldsymbol {u}\in \mathbb {R}^{K}$\end{document}</tex-math><mml:math id="M4"><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi>ℝ</mml:mi></mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="12859_2019_3291_Article_IEq2.gif"/></alternatives></inline-formula> or sample latent factors <inline-formula id="IEq3"><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\boldsymbol {v}\in \mathbb {R}^{K}$\end{document}</tex-math><mml:math id="M6"><mml:mi mathvariant="bold-italic">v</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi>ℝ</mml:mi></mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="12859_2019_3291_Article_IEq3.gif"/></alternatives></inline-formula></p></caption><graphic xlink:href="12859_2019_3291_Fig1_HTML" id="MO1"/></fig></p>
    <p>In biological field, current widely applied MF methods are principal component analysis (PCA), independent component analysis (ICA), and non-negative matrix factorization (NMF). Intuitively, PCA finds governing variation in high-dimensional data, securing the most important biological process signatures that differentiate between samples [<xref ref-type="bibr" rid="CR12">12</xref>]. ICA separates mixed-signal matrix into statistically independent biological process signatures [<xref ref-type="bibr" rid="CR13">13</xref>]. NMF-based approaches extracted signatures and metagenes matrices with non-negative constraints [<xref ref-type="bibr" rid="CR14">14</xref>, <xref ref-type="bibr" rid="CR15">15</xref>]. Despite the effectiveness of MF in interpreting biological matrices, several limitations persist in practice. First, real-world data are often plagued with many types of noises, e.g., systematic noise, batch effect, and random noise [<xref ref-type="bibr" rid="CR16">16</xref>], which potentially mask signals in the downstream process. Second, high throughput omics data frequently suffer from missing values due to various experimental settings [<xref ref-type="bibr" rid="CR17">17</xref>], whereas the majority of MF tools have no support for input matrix with missing values. At present, the standard practice to deal with these two problems is to perform denoising and imputation prior to MF. In the meantime, deep learning based matrix factorization architectures are developed in the recommendation system field [<xref ref-type="bibr" rid="CR18">18</xref>, <xref ref-type="bibr" rid="CR19">19</xref>]. Those architectures employ two deep encoders to map column and row factors into low-dimensional embedding space, respectively, and apply cosine similarity or multiple layer perceptron as the decoder to refine the existing and predict the missing rating scores.</p>
    <p>In this study, we focus on the problem of the cancer subtyping, and propose a novel deep neural network-based matrix factorization framework, DeepMF (see Fig. <xref rid="Fig1" ref-type="fig">1</xref>b), which seperately maps molecular features and samples into low-dimensional latent space, tolerant with noisy and missing entries. First of all, we demonstrate DeepMF is robust in denoising, imputation, and embedding with in silico instances. Then, we collected four wet lab datasets, medulloblastoma cancer, leukemia cancer, breast cancer, and small-blue-round-cell cancer datasets, as benchmark sets to evaluate the tools. DeepMF outperformed the existing MF tools on cancer subtype discovery in omics profiles of the four benchmark datasets, with the highest clustering accuracy on all the four datasets. Furthermore, with 70% data randomly removed, DeepMF demonstrated the best recovery capacity with silhouette values 0.47, 0.6, 0.28, and 0.44. It also displayed the best embedding power on the four sparse benchmark sets, with clustering accuracy of respectively 88%, 100%, 84%, and 96%, which improves on the current best methods 76%, 100%, 78%, and 87%.</p>
  </sec>
  <sec id="Sec2">
    <title>Method</title>
    <sec id="Sec3">
      <title>Matrix factorization by deep neural network</title>
      <p>In this section, we introduce the DeepMF architecture and the loss function used for its training. Unless stated otherwise, symbols in bold font refer to vectors or matrices.</p>
      <sec id="Sec4">
        <title>Matrix factorization</title>
        <p>In Fig. <xref rid="Fig1" ref-type="fig">1</xref>a, assume the input matrix <bold><italic>A</italic></bold> is of dimension <italic>M</italic>×<italic>N</italic>, where <italic>M</italic> is the number of features, and <italic>N</italic> is the number of samples. A row represents a feature, while a column represents a sample or a replication. The element <bold><italic>A</italic></bold><sub><italic>ij</italic></sub> refers to the measured values for feature <italic>F</italic><sup><italic>i</italic></sup> on sample <italic>S</italic><sup><italic>j</italic></sup>,0≤<italic>i</italic>≤<italic>M</italic>−1,0≤<italic>j</italic>≤<italic>N</italic>−1.</p>
        <p>Matrix factorization assumes the dot product of feature latent factor <bold><italic>u</italic></bold><sup><italic>i</italic></sup> and sample latent factor <bold><italic>v</italic></bold><sup><italic>j</italic></sup> to capture the interactions between feature <italic>F</italic><sup><italic>i</italic></sup> and sample <italic>S</italic><sup><italic>j</italic></sup>, where <bold><italic>u</italic></bold><sup><italic>i</italic></sup> and <bold><italic>v</italic></bold><sup><italic>j</italic></sup> are vectors of size <italic>K</italic> which encode structures that underlie the data; that is, the predicted element of feature <italic>F</italic><sup><italic>i</italic></sup> on sample <italic>S</italic><sup><italic>j</italic></sup> is calculated as:
<disp-formula id="Equa"><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$\hat{\boldsymbol{A}}_{ij} \approx \sum_{k} \boldsymbol{u}^{i}_{k} \boldsymbol{v}^{j}_{k} = \boldsymbol{u}^{\top i}\boldsymbol{v}^{j} $$ \end{document}</tex-math><mml:math id="M8"><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold-italic">A</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">ij</mml:mtext></mml:mrow></mml:msub><mml:mo>≈</mml:mo><mml:munder><mml:mrow><mml:mo mathsize="big">∑</mml:mo></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:munder><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">u</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">v</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">u</mml:mi></mml:mrow><mml:mrow><mml:mo>⊤</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">v</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math><graphic xlink:href="12859_2019_3291_Article_Equa.gif" position="anchor"/></alternatives></disp-formula></p>
        <p>The predicted matrix <inline-formula id="IEq4"><alternatives><tex-math id="M9">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\hat {\boldsymbol {A}}$\end{document}</tex-math><mml:math id="M10"><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold-italic">A</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math><inline-graphic xlink:href="12859_2019_3291_Article_IEq4.gif"/></alternatives></inline-formula> can be thought of as the product of the feature latent factor matrix <bold><italic>U</italic></bold> and sample latent factor matrix <inline-formula id="IEq5"><alternatives><tex-math id="M11">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\boldsymbol {V}, \hat {\boldsymbol {A}} \in \mathbb {R}^{M \times N} \approx \boldsymbol {U} \times \boldsymbol {V} $\end{document}</tex-math><mml:math id="M12"><mml:mi mathvariant="bold-italic">V</mml:mi><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold-italic">A</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi>ℝ</mml:mi></mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mo>×</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:msup><mml:mo>≈</mml:mo><mml:mi mathvariant="bold-italic">U</mml:mi><mml:mo>×</mml:mo><mml:mi mathvariant="bold-italic">V</mml:mi></mml:math><inline-graphic xlink:href="12859_2019_3291_Article_IEq5.gif"/></alternatives></inline-formula>, where <inline-formula id="IEq6"><alternatives><tex-math id="M13">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\boldsymbol {U} \in \mathbb {R}^{M \times K}, \boldsymbol {V} \in \mathbb {R}^{K \times N}, K \ll M, N$\end{document}</tex-math><mml:math id="M14"><mml:mi mathvariant="bold-italic">U</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi>ℝ</mml:mi></mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mo>×</mml:mo><mml:mi>K</mml:mi></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">V</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi>ℝ</mml:mi></mml:mrow><mml:mrow><mml:mi>K</mml:mi><mml:mo>×</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mi>K</mml:mi><mml:mo>≪</mml:mo><mml:mi>M</mml:mi><mml:mo>,</mml:mo><mml:mi>N</mml:mi></mml:math><inline-graphic xlink:href="12859_2019_3291_Article_IEq6.gif"/></alternatives></inline-formula>. The objective function is <inline-formula id="IEq7"><alternatives><tex-math id="M15">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$ \min _{\boldsymbol {U},\boldsymbol {V}} ||\boldsymbol {A} - \hat {\boldsymbol {A}}||^{2}_{2}$\end{document}</tex-math><mml:math id="M16"><mml:munder><mml:mrow><mml:mo>min</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">U</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">V</mml:mi></mml:mrow></mml:munder><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:mi mathvariant="bold-italic">A</mml:mi><mml:mo>−</mml:mo><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold-italic">A</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover><mml:mo>|</mml:mo><mml:msubsup><mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2019_3291_Article_IEq7.gif"/></alternatives></inline-formula>.</p>
      </sec>
      <sec id="Sec5">
        <title>Framework architecture</title>
        <p>Figure <xref rid="Fig1" ref-type="fig">1</xref>b illustrates the network architecture of DeepMF. The input layer has <italic>M</italic> neurons, corresponding to <italic>M</italic> features in the matrix. The output layer has <italic>N</italic> nodes to model the <italic>N</italic> column samples. The middle of network is <italic>L</italic> hidden layers of <italic>K</italic> nodes each. All the nodes in the hidden layers are fully connected and paired with ReLU activation function. The number of nodes, <italic>K</italic>, corresponds to the dimensionality of the latent space in matrix factorization. The weights of the first and last layers are respectively considered as the feature latent factors <bold><italic>U</italic></bold> and sample latent factors <bold><italic>V</italic></bold>.</p>
      </sec>
      <sec id="Sec6">
        <title>Training</title>
        <p>Figure <xref rid="Fig1" ref-type="fig">1</xref>c reveals the training process of DeepMF. The matrix <inline-formula id="IEq8"><alternatives><tex-math id="M17">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\boldsymbol {A} \in \mathbb {R}^{M \times N}$\end{document}</tex-math><mml:math id="M18"><mml:mi mathvariant="bold-italic">A</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi>ℝ</mml:mi></mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mo>×</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="12859_2019_3291_Article_IEq8.gif"/></alternatives></inline-formula> contains <italic>M</italic> features. Each feature <italic>F</italic><sup><italic>i</italic></sup> corresponds to one input data point <bold><italic>x</italic></bold><sup><italic>i</italic></sup>∈[0,1]<sup><italic>M</italic></sup> and output label <inline-formula id="IEq9"><alternatives><tex-math id="M19">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\boldsymbol {y}^{i} \in \mathbb {R}^{N} $\end{document}</tex-math><mml:math id="M20"><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msup><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi>ℝ</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="12859_2019_3291_Article_IEq9.gif"/></alternatives></inline-formula>, where <bold><italic>x</italic></bold><sup><italic>i</italic></sup> is one-hot encoded and <bold><italic>y</italic></bold><sup><italic>i</italic></sup> is the <italic>i</italic>-th row of matrix <bold><italic>A</italic></bold>.
<disp-formula id="Equb"><alternatives><tex-math id="M21">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$\begin{array}{*{20}l} \boldsymbol{x}^{i} &amp;= \left[\overbrace{0... 0 \underbrace{1}_{i\texttt{-th feature, \(F^{i}\)}} 0... 0}^{M}\right] \\ \boldsymbol{y}^{i} &amp;= \boldsymbol{A}_{i} \end{array} $$ \end{document}</tex-math><mml:math id="M22"><mml:mtable class="align" columnalign="left"><mml:mtr><mml:mtd class="align-1"><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msup></mml:mtd><mml:mtd class="align-2"><mml:mo>=</mml:mo><mml:mfenced close="]" open="[" separators=""><mml:mrow><mml:mover><mml:mrow><mml:mover accent="false"><mml:mrow><mml:mn>0</mml:mn><mml:mi>...</mml:mi><mml:mn>0</mml:mn><mml:munder><mml:mrow><mml:munder accentunder="false"><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mo>⏟</mml:mo></mml:munder></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mtext mathvariant="monospace">-th feature,</mml:mtext><mml:mspace width="1em"/><mml:msup><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msup><mml:mtext mathvariant="monospace"/></mml:mrow></mml:munder><mml:mn>0</mml:mn><mml:mi>...</mml:mi><mml:mn>0</mml:mn></mml:mrow><mml:mo>⏞</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:mover></mml:mrow></mml:mfenced><mml:mspace width="2em"/></mml:mtd><mml:mtd><mml:mspace width="2em"/></mml:mtd></mml:mtr><mml:mtr><mml:mtd class="align-1"><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msup></mml:mtd><mml:mtd class="align-2"><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">A</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mspace width="2em"/></mml:mtd><mml:mtd><mml:mspace width="2em"/></mml:mtd></mml:mtr></mml:mtable></mml:math><graphic xlink:href="12859_2019_3291_Article_Equb.gif" position="anchor"/></alternatives></disp-formula></p>
        <p>The loss function consists of two parts, one for global trends and one for local trends. For a pair of feature <italic>F</italic><sup><italic>i</italic></sup> and sample <italic>S</italic><sup><italic>j</italic></sup>,<italic>global</italic>
<italic>proximity</italic> refers to the proximity between real measurement <bold><italic>A</italic></bold><sub><italic>ij</italic></sub> and predicted value <inline-formula id="IEq10"><alternatives><tex-math id="M23">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\hat {\boldsymbol {A}}_{ij}$\end{document}</tex-math><mml:math id="M24"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold-italic">A</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">ij</mml:mtext></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12859_2019_3291_Article_IEq10.gif"/></alternatives></inline-formula>. The preservation of global proximity is fundamental in matrix factorization. On the other hand, if two samples possess many common features, they tend to be similar. We refer to this similarity as <italic>sample</italic>
<italic>local</italic>
<italic>proximity</italic>. We define <italic>feature</italic>
<italic>local</italic>
<italic>proximity</italic> similarly in the same way. By introducing these local proximities into the loss function, we aim to identify and preserve the sample-pairwise and feature-pairwise structures in the low-dimensional latent space.</p>
        <p>For global proximity, we minimize the <inline-formula id="IEq11"><alternatives><tex-math id="M25">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\mathcal {L}$\end{document}</tex-math><mml:math id="M26"><mml:mi mathvariant="script">ℒ</mml:mi></mml:math><inline-graphic xlink:href="12859_2019_3291_Article_IEq11.gif"/></alternatives></inline-formula>2-norm of the residual:
<disp-formula id="Equ1"><label>1</label><alternatives><tex-math id="M27">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$\begin{array}{*{20}l} \mathcal{L}_{global} &amp;= \frac{1}{M} \sum_{i=1}^{M} || \boldsymbol{y}^{i} - \hat{\boldsymbol{y}}^{i} ||^{2}_{2} \end{array} $$ \end{document}</tex-math><mml:math id="M28"><mml:mtable class="align" columnalign="left"><mml:mtr><mml:mtd class="align-1"><mml:msub><mml:mrow><mml:mi mathvariant="script">ℒ</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">global</mml:mtext></mml:mrow></mml:msub></mml:mtd><mml:mtd class="align-2"><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:mfrac><mml:munderover accent="false" accentunder="false"><mml:mrow><mml:mo mathsize="big">∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:munderover><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msup><mml:mo>|</mml:mo><mml:msubsup><mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mspace width="2em"/></mml:mtd></mml:mtr></mml:mtable></mml:math><graphic xlink:href="12859_2019_3291_Article_Equ1.gif" position="anchor"/></alternatives></disp-formula></p>
        <p>For the local proximities, we use feature local proximity <inline-formula id="IEq12"><alternatives><tex-math id="M29">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\boldsymbol {S}^{F}_{M \times M}$\end{document}</tex-math><mml:math id="M30"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">S</mml:mi></mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mo>×</mml:mo><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>F</mml:mi></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2019_3291_Article_IEq12.gif"/></alternatives></inline-formula> and sample local proximity <inline-formula id="IEq13"><alternatives><tex-math id="M31">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\boldsymbol {S}^{S}_{N \times N}$\end{document}</tex-math><mml:math id="M32"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">S</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mo>×</mml:mo><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>S</mml:mi></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2019_3291_Article_IEq13.gif"/></alternatives></inline-formula> as supervised information. Given matrix <bold><italic>A</italic></bold><sub><italic>M</italic>×<italic>N</italic></sub>, we obtain the feature similarity matrix <inline-formula id="IEq14"><alternatives><tex-math id="M33">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\boldsymbol {S}^{F}_{M \times M}$\end{document}</tex-math><mml:math id="M34"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">S</mml:mi></mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mo>×</mml:mo><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>F</mml:mi></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2019_3291_Article_IEq14.gif"/></alternatives></inline-formula> and sample similarity matrix <inline-formula id="IEq15"><alternatives><tex-math id="M35">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\boldsymbol {S}^{S}_{N \times N}$\end{document}</tex-math><mml:math id="M36"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">S</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mo>×</mml:mo><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>S</mml:mi></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2019_3291_Article_IEq15.gif"/></alternatives></inline-formula> as following.
<disp-formula id="Equ2"><label>2</label><alternatives><tex-math id="M37">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$\begin{array}{*{20}l} s^{F}_{kl} &amp;= \frac{1}{1 + || \boldsymbol{A}_{k} - \boldsymbol{A}_{l} ||^{2}_{2}} \end{array} $$ \end{document}</tex-math><mml:math id="M38"><mml:mtable class="align" columnalign="left"><mml:mtr><mml:mtd class="align-1"><mml:msubsup><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">kl</mml:mtext></mml:mrow><mml:mrow><mml:mi>F</mml:mi></mml:mrow></mml:msubsup></mml:mtd><mml:mtd class="align-2"><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">A</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">A</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:msubsup><mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mfrac><mml:mspace width="2em"/></mml:mtd></mml:mtr></mml:mtable></mml:math><graphic xlink:href="12859_2019_3291_Article_Equ2.gif" position="anchor"/></alternatives></disp-formula></p>
        <p>
          <disp-formula id="Equ3">
            <label>3</label>
            <alternatives>
              <tex-math id="M39">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$\begin{array}{*{20}l} s^{S}_{kl} &amp;= \frac{1}{1 + || \boldsymbol{A}^{\top}_{k} - \boldsymbol{A}^{\top}_{l}||^{2}_{2}} \end{array} $$ \end{document}</tex-math>
              <mml:math id="M40">
                <mml:mtable class="align" columnalign="left">
                  <mml:mtr>
                    <mml:mtd class="align-1">
                      <mml:msubsup>
                        <mml:mrow>
                          <mml:mi>s</mml:mi>
                        </mml:mrow>
                        <mml:mrow>
                          <mml:mtext mathvariant="italic">kl</mml:mtext>
                        </mml:mrow>
                        <mml:mrow>
                          <mml:mi>S</mml:mi>
                        </mml:mrow>
                      </mml:msubsup>
                    </mml:mtd>
                    <mml:mtd class="align-2">
                      <mml:mo>=</mml:mo>
                      <mml:mfrac>
                        <mml:mrow>
                          <mml:mn>1</mml:mn>
                        </mml:mrow>
                        <mml:mrow>
                          <mml:mn>1</mml:mn>
                          <mml:mo>+</mml:mo>
                          <mml:mo>|</mml:mo>
                          <mml:mo>|</mml:mo>
                          <mml:msubsup>
                            <mml:mrow>
                              <mml:mi mathvariant="bold-italic">A</mml:mi>
                            </mml:mrow>
                            <mml:mrow>
                              <mml:mi>k</mml:mi>
                            </mml:mrow>
                            <mml:mrow>
                              <mml:mo>⊤</mml:mo>
                            </mml:mrow>
                          </mml:msubsup>
                          <mml:mo>−</mml:mo>
                          <mml:msubsup>
                            <mml:mrow>
                              <mml:mi mathvariant="bold-italic">A</mml:mi>
                            </mml:mrow>
                            <mml:mrow>
                              <mml:mi>l</mml:mi>
                            </mml:mrow>
                            <mml:mrow>
                              <mml:mo>⊤</mml:mo>
                            </mml:mrow>
                          </mml:msubsup>
                          <mml:mo>|</mml:mo>
                          <mml:msubsup>
                            <mml:mrow>
                              <mml:mo>|</mml:mo>
                            </mml:mrow>
                            <mml:mrow>
                              <mml:mn>2</mml:mn>
                            </mml:mrow>
                            <mml:mrow>
                              <mml:mn>2</mml:mn>
                            </mml:mrow>
                          </mml:msubsup>
                        </mml:mrow>
                      </mml:mfrac>
                      <mml:mspace width="2em"/>
                    </mml:mtd>
                  </mml:mtr>
                </mml:mtable>
              </mml:math>
              <graphic xlink:href="12859_2019_3291_Article_Equ3.gif" position="anchor"/>
            </alternatives>
          </disp-formula>
        </p>
        <p>where <bold><italic>A</italic></bold><sub><italic>k</italic></sub> and <bold><italic>A</italic></bold><sub><italic>l</italic></sub> refer to the <italic>k</italic>-th and <italic>l</italic>-th row of matrix <bold><italic>A</italic></bold>. <inline-formula id="IEq16"><alternatives><tex-math id="M41">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\boldsymbol {A}^{\top }_{k}$\end{document}</tex-math><mml:math id="M42"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">A</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mo>⊤</mml:mo></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2019_3291_Article_IEq16.gif"/></alternatives></inline-formula> and <inline-formula id="IEq17"><alternatives><tex-math id="M43">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\boldsymbol {A}^{\top }_{l}$\end{document}</tex-math><mml:math id="M44"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">A</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mo>⊤</mml:mo></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2019_3291_Article_IEq17.gif"/></alternatives></inline-formula> refer to the <italic>k</italic>-th and <italic>l</italic>-th column of matrix <bold><italic>A</italic></bold>.</p>
        <p>To preserve the local proximity, we use <bold><italic>S</italic></bold><sup><italic>F</italic></sup> and <bold><italic>S</italic></bold><sup><italic>S</italic></sup> respectively constrain the similarity of the latent representations of features <bold><italic>U</italic></bold> and samples <bold><italic>V</italic></bold>.
<disp-formula id="Equ4"><label>4</label><alternatives><tex-math id="M45">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$\begin{array}{*{20}l} \mathcal{L}_{local} &amp;= \sum_{k,l=1}^{M} s^{F}_{kl} || \boldsymbol{U}_{k} - \boldsymbol{U}_{l} ||^{2}_{2} \\ &amp;+ \sum_{k,l=1}^{N} s^{S}_{kl} || \boldsymbol{V}^{\top}_{k} - \boldsymbol{V}^{\top}_{l} ||^{2}_{2} \\ &amp; = 2\text{trace}\left(\boldsymbol{U}^{\top}\boldsymbol{L}^{F}\boldsymbol{U}\right) + 2\text{trace}\left(\boldsymbol{V}\boldsymbol{L}^{S}\boldsymbol{V}^{\top}\right) \end{array} $$ \end{document}</tex-math><mml:math id="M46"><mml:mtable class="align" columnalign="left"><mml:mtr><mml:mtd class="align-1"><mml:msub><mml:mrow><mml:mi mathvariant="script">ℒ</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">local</mml:mtext></mml:mrow></mml:msub></mml:mtd><mml:mtd class="align-2"><mml:mo>=</mml:mo><mml:munderover accent="false" accentunder="false"><mml:mrow><mml:mo mathsize="big">∑</mml:mo></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:munderover><mml:msubsup><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">kl</mml:mtext></mml:mrow><mml:mrow><mml:mi>F</mml:mi></mml:mrow></mml:msubsup><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">U</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">U</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:msubsup><mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mspace width="2em"/></mml:mtd><mml:mtd><mml:mspace width="2em"/></mml:mtd></mml:mtr><mml:mtr><mml:mtd class="align-1"/><mml:mtd class="align-2"><mml:mo>+</mml:mo><mml:munderover accent="false" accentunder="false"><mml:mrow><mml:mo mathsize="big">∑</mml:mo></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:msubsup><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">kl</mml:mtext></mml:mrow><mml:mrow><mml:mi>S</mml:mi></mml:mrow></mml:msubsup><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">V</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mo>⊤</mml:mo></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">V</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mo>⊤</mml:mo></mml:mrow></mml:msubsup><mml:mo>|</mml:mo><mml:msubsup><mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mspace width="2em"/></mml:mtd><mml:mtd><mml:mspace width="2em"/></mml:mtd></mml:mtr><mml:mtr><mml:mtd class="align-1"/><mml:mtd class="align-2"><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mtext>trace</mml:mtext><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">U</mml:mi></mml:mrow><mml:mrow><mml:mo>⊤</mml:mo></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">L</mml:mi></mml:mrow><mml:mrow><mml:mi>F</mml:mi></mml:mrow></mml:msup><mml:mi mathvariant="bold-italic">U</mml:mi></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:mn>2</mml:mn><mml:mtext>trace</mml:mtext><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mi mathvariant="bold-italic">V</mml:mi><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">L</mml:mi></mml:mrow><mml:mrow><mml:mi>S</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">V</mml:mi></mml:mrow><mml:mrow><mml:mo>⊤</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mfenced><mml:mspace width="2em"/></mml:mtd></mml:mtr></mml:mtable></mml:math><graphic xlink:href="12859_2019_3291_Article_Equ4.gif" position="anchor"/></alternatives></disp-formula></p>
        <p>where <bold><italic>U</italic></bold><sub><italic>k</italic></sub> and <bold><italic>U</italic></bold><sub><italic>l</italic></sub> refer to the <italic>k</italic>-th and <italic>l</italic>-th row of feature latent matrix <bold><italic>U</italic></bold>. <inline-formula id="IEq18"><alternatives><tex-math id="M47">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\boldsymbol {V}^{\top }_{k}$\end{document}</tex-math><mml:math id="M48"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">V</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mo>⊤</mml:mo></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2019_3291_Article_IEq18.gif"/></alternatives></inline-formula> and <inline-formula id="IEq19"><alternatives><tex-math id="M49">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\boldsymbol {V}^{\top }_{l}$\end{document}</tex-math><mml:math id="M50"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">V</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mo>⊤</mml:mo></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2019_3291_Article_IEq19.gif"/></alternatives></inline-formula> refer to the <italic>k</italic>-th and <italic>l</italic>-th column of sample latent matrix <bold><italic>V</italic></bold>. <bold><italic>L</italic></bold><sup><italic>F</italic></sup>=<bold><italic>D</italic></bold><sup><italic>F</italic></sup>−<bold><italic>S</italic></bold><sup><italic>F</italic></sup> and <bold><italic>L</italic></bold><sup><italic>S</italic></sup>=<bold><italic>D</italic></bold><sup><italic>S</italic></sup>−<bold><italic>S</italic></bold><sup><italic>S</italic></sup> are the Laplacian matrices for features and samples, respectively. <inline-formula id="IEq20"><alternatives><tex-math id="M51">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\boldsymbol {D}^{F} \in \mathbb {R}^{M \times M}$\end{document}</tex-math><mml:math id="M52"><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">D</mml:mi></mml:mrow><mml:mrow><mml:mi>F</mml:mi></mml:mrow></mml:msup><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi>ℝ</mml:mi></mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mo>×</mml:mo><mml:mi>M</mml:mi></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="12859_2019_3291_Article_IEq20.gif"/></alternatives></inline-formula> and <inline-formula id="IEq21"><alternatives><tex-math id="M53">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$ \boldsymbol {D}^{S} \in \mathbb {R}^{N \times N}$\end{document}</tex-math><mml:math id="M54"><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">D</mml:mi></mml:mrow><mml:mrow><mml:mi>S</mml:mi></mml:mrow></mml:msup><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi>ℝ</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mo>×</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="12859_2019_3291_Article_IEq21.gif"/></alternatives></inline-formula> are diagonal matrices with <inline-formula id="IEq22"><alternatives><tex-math id="M55">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$d^{F}_{kk} = \sum _{l}s^{F}_{kl}$\end{document}</tex-math><mml:math id="M56"><mml:msubsup><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">kk</mml:mtext></mml:mrow><mml:mrow><mml:mi>F</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:munder><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:munder><mml:msubsup><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">kl</mml:mtext></mml:mrow><mml:mrow><mml:mi>F</mml:mi></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2019_3291_Article_IEq22.gif"/></alternatives></inline-formula> and <inline-formula id="IEq23"><alternatives><tex-math id="M57">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$d^{S}_{kk} = \sum _{l}s^{S}_{kl}$\end{document}</tex-math><mml:math id="M58"><mml:msubsup><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">kk</mml:mtext></mml:mrow><mml:mrow><mml:mi>S</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:munder><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:munder><mml:msubsup><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">kl</mml:mtext></mml:mrow><mml:mrow><mml:mi>S</mml:mi></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2019_3291_Article_IEq23.gif"/></alternatives></inline-formula>.</p>
        <p>The objective function <inline-formula id="IEq24"><alternatives><tex-math id="M59">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\mathcal {L}_{local}$\end{document}</tex-math><mml:math id="M60"><mml:msub><mml:mrow><mml:mi mathvariant="script">ℒ</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">local</mml:mtext></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12859_2019_3291_Article_IEq24.gif"/></alternatives></inline-formula> incurs a graph Laplacian penalty when similar features and similar samples are embedded far away in the latent space. Hence, two features or samples with low similarity will be driven nearer in the embedding space. To prevent this, we first identify the remote sample-sample or feature-feature pair from feature and sample local proximity matrices by <italic>k</italic>-means. Then we mark their local similarity to zero to exclude them from <inline-formula id="IEq25"><alternatives><tex-math id="M61">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\mathcal {L}_{local}$\end{document}</tex-math><mml:math id="M62"><mml:msub><mml:mrow><mml:mi mathvariant="script">ℒ</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">local</mml:mtext></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12859_2019_3291_Article_IEq25.gif"/></alternatives></inline-formula> constraints.</p>
        <p>To avoid overfitting and constrain the latent matrices <bold><italic>U</italic></bold> and <bold><italic>V</italic></bold>, an <inline-formula id="IEq26"><alternatives><tex-math id="M63">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\mathcal {L}$\end{document}</tex-math><mml:math id="M64"><mml:mi mathvariant="script">ℒ</mml:mi></mml:math><inline-graphic xlink:href="12859_2019_3291_Article_IEq26.gif"/></alternatives></inline-formula>2-norm regularization is incorporated with <bold><italic>U</italic></bold>,<bold><italic>V</italic></bold>, and model hidden layer weights <bold><italic>W</italic></bold><sub><italic>hidden</italic></sub>.
<disp-formula id="Equ5"><label>5</label><alternatives><tex-math id="M65">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$\begin{array}{*{20}l} \mathcal{L}_{reg} = ||\boldsymbol{U}||^{2}_{2} + ||\boldsymbol{V}||^{2}_{2} + ||\boldsymbol{W}_{hidden}||^{2}_{2} \end{array} $$ \end{document}</tex-math><mml:math id="M66"><mml:mtable class="align" columnalign="left"><mml:mtr><mml:mtd class="align-1"><mml:msub><mml:mrow><mml:mi mathvariant="script">ℒ</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">reg</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:mi mathvariant="bold-italic">U</mml:mi><mml:mo>|</mml:mo><mml:msubsup><mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:mi mathvariant="bold-italic">V</mml:mi><mml:mo>|</mml:mo><mml:msubsup><mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">W</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">hidden</mml:mtext></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:msubsup><mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mtd></mml:mtr></mml:mtable></mml:math><graphic xlink:href="12859_2019_3291_Article_Equ5.gif" position="anchor"/></alternatives></disp-formula></p>
        <p>Our final loss function incorporates all the above constraints, with two additional hyperparameters <italic>α</italic> and <italic>β</italic>, as follows:
<disp-formula id="Equ6"><label>6</label><alternatives><tex-math id="M67">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$\begin{array}{*{20}l} \mathcal{L}_{mix} = \mathcal{L}_{global} + \alpha\mathcal{L}_{local} + \beta\mathcal{L}_{reg}. \end{array} $$ \end{document}</tex-math><mml:math id="M68"><mml:mtable class="align" columnalign="left"><mml:mtr><mml:mtd class="align-1"><mml:msub><mml:mrow><mml:mi mathvariant="script">ℒ</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">mix</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="script">ℒ</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">global</mml:mtext></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>α</mml:mi><mml:msub><mml:mrow><mml:mi mathvariant="script">ℒ</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">local</mml:mtext></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:msub><mml:mrow><mml:mi mathvariant="script">ℒ</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">reg</mml:mtext></mml:mrow></mml:msub><mml:mi>.</mml:mi></mml:mtd></mml:mtr></mml:mtable></mml:math><graphic xlink:href="12859_2019_3291_Article_Equ6.gif" position="anchor"/></alternatives></disp-formula></p>
      </sec>
      <sec id="Sec7">
        <title>Dealing with missing value</title>
        <p>To be tolerant of missing values, DeepMF discards the missing entries in back-propagation by a variational <inline-formula id="IEq27"><alternatives><tex-math id="M69">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\mathcal {L}$\end{document}</tex-math><mml:math id="M70"><mml:mi mathvariant="script">ℒ</mml:mi></mml:math><inline-graphic xlink:href="12859_2019_3291_Article_IEq27.gif"/></alternatives></inline-formula>2-norm (see Fig. <xref rid="Fig1" ref-type="fig">1</xref>c). Denote <italic>ξ</italic> as a missing value.
<disp-formula id="Equ7"><label>7</label><alternatives><tex-math id="M71">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$\begin{array}{*{20}l} \mathcal{L}_{global}^{missing} &amp;= \frac{1}{M} \sum_{i=1}^{M}\sum_{j=1}^{N} loss^{ij} \\ loss^{ij} &amp;= \left\{ \begin{array}{ll} 0, \boldsymbol{y}^{i}_{j}=\xi, \\ || \boldsymbol{y}^{i}_{j} - \hat{\boldsymbol{y}}^{i}_{j} ||^{2}_{2}, \boldsymbol{y}^{i}_{j}\ne\xi. \end{array} \right. \end{array} $$ \end{document}</tex-math><mml:math id="M72"><mml:mtable class="align" columnalign="left"><mml:mtr><mml:mtd class="align-1"><mml:msubsup><mml:mrow><mml:mi mathvariant="script">ℒ</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">global</mml:mtext></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">missing</mml:mtext></mml:mrow></mml:msubsup></mml:mtd><mml:mtd class="align-2"><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:mfrac><mml:munderover accent="false" accentunder="false"><mml:mrow><mml:mo mathsize="big">∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:munderover><mml:munderover accent="false" accentunder="false"><mml:mrow><mml:mo mathsize="big">∑</mml:mo></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:mtext mathvariant="italic">los</mml:mtext><mml:msup><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">ij</mml:mtext></mml:mrow></mml:msup><mml:mspace width="2em"/></mml:mtd><mml:mtd><mml:mspace width="2em"/></mml:mtd></mml:mtr><mml:mtr><mml:mtd class="align-1"><mml:mtext mathvariant="italic">los</mml:mtext><mml:msup><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">ij</mml:mtext></mml:mrow></mml:msup></mml:mtd><mml:mtd class="align-2"><mml:mo>=</mml:mo><mml:mfenced close="" open="{" separators=""><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mi>ξ</mml:mi><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo>|</mml:mo><mml:msubsup><mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo>≠</mml:mo><mml:mi>ξ.</mml:mi></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mfenced><mml:mspace width="2em"/></mml:mtd></mml:mtr></mml:mtable></mml:math><graphic xlink:href="12859_2019_3291_Article_Equ7.gif" position="anchor"/></alternatives></disp-formula></p>
        <p>Then, DeepMF can infer a missing value of <bold><italic>A</italic></bold><sub><italic>α</italic><italic>β</italic></sub> by utilizing the trained model.
<disp-formula id="Equc"><alternatives><tex-math id="M73">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$\begin{array}{*{20}l} \boldsymbol{x}^{\alpha} &amp;= [\overbrace{0... 0 \underbrace{1}_{\alpha\texttt{-th feature, \(F^{\alpha}\)}} 0... 0}^{M}]\\ \hat{\boldsymbol{y}}^{\alpha} &amp;= \texttt{DeepMF.predict}(\boldsymbol{x}^{\alpha}) \\ \hat{\boldsymbol{A}}_{\alpha\beta} &amp;= \hat{\boldsymbol{y}}^{\alpha}_{\beta}. \end{array} $$ \end{document}</tex-math><mml:math id="M74"><mml:mtable class="align" columnalign="left"><mml:mtr><mml:mtd class="align-1"><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:msup></mml:mtd><mml:mtd class="align-2"><mml:mo>=</mml:mo><mml:mo>[</mml:mo><mml:mover><mml:mrow><mml:mover accent="false"><mml:mrow><mml:mn>0</mml:mn><mml:mi>...</mml:mi><mml:mn>0</mml:mn><mml:munder><mml:mrow><mml:munder accentunder="false"><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mo>⏟</mml:mo></mml:munder></mml:mrow><mml:mrow><mml:mi>α</mml:mi><mml:mtext mathvariant="monospace">-th feature,</mml:mtext><mml:mspace width="1em"/><mml:msup><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:msup><mml:mtext mathvariant="monospace"/></mml:mrow></mml:munder><mml:mn>0</mml:mn><mml:mi>...</mml:mi><mml:mn>0</mml:mn></mml:mrow><mml:mo>⏞</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:mover><mml:mo>]</mml:mo><mml:mspace width="2em"/></mml:mtd><mml:mtd><mml:mspace width="2em"/></mml:mtd></mml:mtr><mml:mtr><mml:mtd class="align-1"><mml:msup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:msup></mml:mtd><mml:mtd class="align-2"><mml:mo>=</mml:mo><mml:mtext mathvariant="monospace">DeepMF.predict</mml:mtext><mml:mo>(</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:msup><mml:mo>)</mml:mo><mml:mspace width="2em"/></mml:mtd><mml:mtd><mml:mspace width="2em"/></mml:mtd></mml:mtr><mml:mtr><mml:mtd class="align-1"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold-italic">A</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>αβ</mml:mi></mml:mrow></mml:msub></mml:mtd><mml:mtd class="align-2"><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:msubsup><mml:mi>.</mml:mi><mml:mspace width="2em"/></mml:mtd><mml:mtd><mml:mspace width="2em"/></mml:mtd></mml:mtr></mml:mtable></mml:math><graphic xlink:href="12859_2019_3291_Article_Equc.gif" position="anchor"/></alternatives></disp-formula></p>
      </sec>
      <sec id="Sec8">
        <title>DeepMF architecture parameter selection</title>
        <p>If the data assumes <italic>C</italic> (<italic>C</italic>≥2) clusters with respect to samples, we recommend that the network structure be pruned as guided by the validation loss <inline-formula id="IEq28"><alternatives><tex-math id="M75">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\mathcal {L}_{mix}$\end{document}</tex-math><mml:math id="M76"><mml:msub><mml:mrow><mml:mi mathvariant="script">ℒ</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">mix</mml:mtext></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12859_2019_3291_Article_IEq28.gif"/></alternatives></inline-formula> in the range of <italic>K</italic>∈[2,<italic>C</italic>] and <italic>L</italic>∈[1,+<italic>∞</italic>). For a matrix <bold><italic>V</italic></bold><sub><italic>K</italic>×<italic>N</italic>,(<italic>K</italic>&lt;<italic>N</italic>)</sub>, a rank of <italic>C</italic> is enough to represent the latent hierarchical structure for a <italic>C</italic>-clustering problem, thus <italic>K</italic>≤<italic>C</italic>. To extract simple patterns between feature and sample, <italic>L</italic>=1 suffices. A larger <italic>L</italic> would provide more complexity in the latent space of DeepMF. For hyperparameter tuning, we recommend running each <italic>K,L</italic> combination more than ten times with different random weights initialization to avoid possible local optima.</p>
      </sec>
    </sec>
    <sec id="Sec9">
      <title>Simulation data generation</title>
      <p>To evaluate DeepMF, we simulated three patterns, each which consists of matrices of sizes 1000×600,10×6, and 100×60 as shown in Fig. <xref rid="Fig2" ref-type="fig">2</xref>, Additional files <xref rid="MOESM1" ref-type="media">1</xref> and <xref rid="MOESM2" ref-type="media">2</xref>. Then, we randomly removed 10%, 50%, and 70% of the matrices to make them sparse.
<fig id="Fig2"><label>Fig. 2</label><caption><p>DeepMF performance on 1000×600 synthetic matrices. DeepMF denoising, imputation, and factorization performance on 1000×600 synthetic matrices with different pattern. Inside each pattern, from left to right: raw matrix, 10% random dropout, 50% random dropout, 70% random dropout; from top to bottom: before DeepMF, and DeepMF. The horizontal line plot show the sample latent factors, the vertical line plot refer to feature latent factors. <bold>a</bold> Matrix with pattern A <bold>b</bold> Matrix with pattern B <bold>c</bold> The transpose matrix of pattern B</p></caption><graphic xlink:href="12859_2019_3291_Fig2_HTML" id="MO2"/></fig></p>
    </sec>
    <sec id="Sec10">
      <title>Cancer subtyping experiments</title>
      <p>For real datasets, the four cancer datasets as follows are used.</p>
      <sec id="Sec11">
        <title>Cancer data preparation</title>
        <p><bold>Medulloblastoma data set</bold> Gene expression profiles from childhood brain tumors medulloblastomas were obtained from Brunet’s work [<xref ref-type="bibr" rid="CR2">2</xref>]. It consists of classic and desmoplastic subtypes of size 25 and 9, respectively. We further extracted the top 100 differentially expressed genes using the “limma" R package [<xref ref-type="bibr" rid="CR20">20</xref>].</p>
        <p><bold>Leukemia data set</bold> The Leukemia data set was obtained from R package “NMF” with the command “data(esGolub)” [<xref ref-type="bibr" rid="CR14">14</xref>]. It stores Affymetrix Hgu6800 microarray expression data from 38 Leukemia cancer patients, where 19 patients with B cell Acute Lymphoblastic Leukemia (B-cell ALL), eight patients with T cell Acute Lymphoblastic Leukemia (T-cell ALL), as well as 11 patients with Acute Myelogenous Leukemia (AML). The 236 most highly diverging genes were selected by comparison on their coefficient of variation using the “limma” R package [<xref ref-type="bibr" rid="CR20">20</xref>].</p>
        <p><bold>TCGA BRCA data set</bold> A subset of human breast cancer data generated by The Cancer Genome Atlas Network (TCGA) was obtained from R package mixOmics [<xref ref-type="bibr" rid="CR21">21</xref>]. It holds 150 samples with three subtypes Basal-like, Her2, and LumA, of size 45, 30, and 75, respectively. The top 55 correlated mRNA, miRNA, and proteins that discriminate against the breast cancer subgroups Basal, Her2, and LumA were selected using the mixOmics DIABLO model.</p>
        <p><bold>SRBCT data set</bold> The Small Round Blue Cell Tumors (SRBCT) data set holds the expression profiles of the top 96 ranked genes [<xref ref-type="bibr" rid="CR22">22</xref>]. It contains 63 samples of four classes, Burkitt Lymphoma (BL, eight samples), Ewing Sarcoma (EWS, 23 samples), Neuroblastoma (NB, 12 samples), and Rhabdomyosarcoma (RMS, 20 samples). The processed and normalized data were acquired from the R mixOmics package [<xref ref-type="bibr" rid="CR21">21</xref>].</p>
      </sec>
      <sec id="Sec12">
        <title>Decomposition baselines</title>
        <p>We compared the decomposition efficacy on DeepMF against four methods, PCA (FactoMineR [<xref ref-type="bibr" rid="CR23">23</xref>]), ICA (fastICA[<xref ref-type="bibr" rid="CR24">24</xref>]), Bayesian-based NMF (CoGAPS[<xref ref-type="bibr" rid="CR15">15</xref>]), and gradient-based NMF (NMF [<xref ref-type="bibr" rid="CR14">14</xref>]). We fit all model with log-treated matrices. All tools were executed with their recommended settings; that is, prcomp function in package “FactoMineR”; fastICA with algorithm type “parallel”, function “logcosh”, alpha 1, method “R”, row normalization 1, maxit 200, tol 0.0001; CoGAPS with 5000 iterations; NMF with method “brunet" and 200 runs.</p>
        <p>As CoGAPS and NMF accept only non-negative values, we used NMF.posneg to transform the input matrices into corresponding non-negative matrices.</p>
      </sec>
      <sec id="Sec13">
        <title>Imputation baselines</title>
        <p>We evaluated the DeepMF imputation efficiency by comparing it with two popular imputation approaches, MeanImpute, and SVDImpute.</p>
        <p><bold>MeanImpute</bold> MeanImpute adopted the approach that the missing entries are to be substituted by the mean of the current values of a particular feature in all samples. We used the mean impute function in the R package “CancerSubtypes”.</p>
        <p><bold>SVDImpute</bold> SVDImpute first centers the matrix, replaces all missing values by 0, decomposes the matrix into the eigenvectors. Then, SVDImpute predicts the NA values as a linear combination of the <italic>k</italic> most significant eigenvectors [<xref ref-type="bibr" rid="CR25">25</xref>]. We chose SVDImpute as an imputation baseline since the mechanism behind it is similar to DeepMF. The <italic>k</italic> most significant eigenvectors can be analogized to the <italic>k</italic>-dimensional latent matrix in DeepMF. We used R package “pcaMethods” in practice.</p>
      </sec>
      <sec id="Sec14">
        <title>Deep matrix factorization model baseline</title>
        <p>There are some deep learning-basedd matrix factorization architectures in the recommendation system field [<xref ref-type="bibr" rid="CR18">18</xref>, <xref ref-type="bibr" rid="CR19">19</xref>]. Given a rating matrix for pairs of user and item, those architectures are designed to respectively map users and items into low-dimensional embedding space, refine the existing and predict the missing rating scores in the meantime. Nevertheless, we fail to find the available source codes. To evaluate the imputing, denoising, and embedding of those deep learning matrix factorization architectures in biological omics data, we implement them using PyTorch and refer it as DMF model in this study. DMF employs two encoders to separately obtain the feature latent factor <bold><italic>u</italic></bold><sup><italic>i</italic></sup> and sample latent factor <bold><italic>v</italic></bold><sup><italic>j</italic></sup> into low-dimensional embedding space. Then, DMF concatenate <inline-formula id="IEq29"><alternatives><tex-math id="M77">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\boldsymbol {u}^{i} \in \mathbb {R}^{K}$\end{document}</tex-math><mml:math id="M78"><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">u</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msup><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi>ℝ</mml:mi></mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="12859_2019_3291_Article_IEq29.gif"/></alternatives></inline-formula> and <inline-formula id="IEq30"><alternatives><tex-math id="M79">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\boldsymbol {v}^{j} \in \mathbb {R}^{K}$\end{document}</tex-math><mml:math id="M80"><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">v</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msup><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi>ℝ</mml:mi></mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="12859_2019_3291_Article_IEq30.gif"/></alternatives></inline-formula> into <inline-formula id="IEq31"><alternatives><tex-math id="M81">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\boldsymbol {z}^{ij} \in \mathbb {R}^{2K}$\end{document}</tex-math><mml:math id="M82"><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">z</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">ij</mml:mtext></mml:mrow></mml:msup><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi>ℝ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mi>K</mml:mi></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="12859_2019_3291_Article_IEq31.gif"/></alternatives></inline-formula>, fit <bold><italic>z</italic></bold><sup><italic>ij</italic></sup> into a multiple layer perceptron to get the predicted value <inline-formula id="IEq32"><alternatives><tex-math id="M83">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\hat {\boldsymbol {A}}_{ij}$\end{document}</tex-math><mml:math id="M84"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold-italic">A</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">ij</mml:mtext></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12859_2019_3291_Article_IEq32.gif"/></alternatives></inline-formula>. The loss function is binary cross-entropy with sigmoid activation.</p>
      </sec>
      <sec id="Sec15">
        <title>Evaluation metrics</title>
        <p><bold>Silhouette width</bold> The silhouette width measures the similarity of a sample to its class compared to other classes [<xref ref-type="bibr" rid="CR26">26</xref>]. It ranges from -1 to 1. A higher silhouette value implies a more appropriate clustering. A silhouette value near 0 intimates overlapping clusters, and a negative value indicates that the clustering has been performed incorrectly.</p>
        <p>We adopted the silhouette width to evaluate the model’s denoising and imputation power. We used the ground-truth subtype classes as the input cluster labels. Then, the silhouette width for a given matrix was calculated with Euclidean distance using the R package “cluster”.</p>
        <p><bold>Adjusted Rand Index</bold> We also used the adjusted Rand index to evaluate the clustering accuracy. The adjusted Rand index measures the similarity between predicted clustering results and actual clustering labels [<xref ref-type="bibr" rid="CR27">27</xref>]. A negative value or value close to 0 indicates random labeling, and a value of 1 demonstrates 100% accuracy of clustering.</p>
        <p>To check the cancer subtyping effectiveness of different matrix factorization tools. We first used the R hierarchy clustering packaging “hclust” to obtain the sample latent factor matrices in order to partition samples into subgroups, through the Euclidean distance and “ward.D2" linkage. Then, we computed the adjusted Rand index to measure the clustering accuracy via the R package “fpc”.</p>
      </sec>
    </sec>
  </sec>
  <sec id="Sec16" sec-type="results">
    <title>Results</title>
    <p>Given matrix <inline-formula id="IEq33"><alternatives><tex-math id="M85">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\boldsymbol {A} \in \mathbb {R}^{M \times N}$\end{document}</tex-math><mml:math id="M86"><mml:mi mathvariant="bold-italic">A</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi>ℝ</mml:mi></mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mo>×</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="12859_2019_3291_Article_IEq33.gif"/></alternatives></inline-formula>, DeepMF operates matrix factorization on the basis of deep neural network, outputs three matrices <inline-formula id="IEq34"><alternatives><tex-math id="M87">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\boldsymbol {U} \in \mathbb {R}^{M \times K}, \boldsymbol {V} \in \mathbb {R}^{K \times N}$\end{document}</tex-math><mml:math id="M88"><mml:mi mathvariant="bold-italic">U</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi>ℝ</mml:mi></mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mo>×</mml:mo><mml:mi>K</mml:mi></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">V</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi>ℝ</mml:mi></mml:mrow><mml:mrow><mml:mi>K</mml:mi><mml:mo>×</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="12859_2019_3291_Article_IEq34.gif"/></alternatives></inline-formula>, and <inline-formula id="IEq35"><alternatives><tex-math id="M89">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\hat {\boldsymbol {A}} \in \mathbb {R}^{M \times N}$\end{document}</tex-math><mml:math id="M90"><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold-italic">A</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi>ℝ</mml:mi></mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mo>×</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="12859_2019_3291_Article_IEq35.gif"/></alternatives></inline-formula> (see Fig. <xref rid="Fig1" ref-type="fig">1</xref>). <bold><italic>U</italic></bold> is the weights of the first layer, we considered it as the low-dimensional feature latent factors. The weights of the last layer <bold><italic>V</italic></bold> is the sample latent factors in embedding space. Hence we can apply <bold><italic>U</italic></bold> and <bold><italic>V</italic></bold> to features and samples related clustering and subgroups identification. DeepMF learns about missing values and minimizes the loss between <bold><italic>A</italic></bold> and <inline-formula id="IEq36"><alternatives><tex-math id="M91">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\hat {\boldsymbol {A}}$\end{document}</tex-math><mml:math id="M92"><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold-italic">A</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math><inline-graphic xlink:href="12859_2019_3291_Article_IEq36.gif"/></alternatives></inline-formula> during training, <inline-formula id="IEq37"><alternatives><tex-math id="M93">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\hat {\boldsymbol {A}}$\end{document}</tex-math><mml:math id="M94"><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold-italic">A</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math><inline-graphic xlink:href="12859_2019_3291_Article_IEq37.gif"/></alternatives></inline-formula> is the refined matrix with no missing and noisy entries.</p>
    <sec id="Sec17">
      <title>Denoising, imputation, and embedding evaluation on synthetic data</title>
      <p>To evaluate the denoising, imputation, and embedding efficacy of DeepMF, we first generated three simple patterns A, B, and C, each which consists of matrices of size 1000×600,10×6, and 100×60 (see Fig. <xref rid="Fig2" ref-type="fig">2</xref>, Additional files <xref rid="MOESM1" ref-type="media">1</xref> and <xref rid="MOESM2" ref-type="media">2</xref>). Matrices with pattern A hold three subgroups in feature and sample. Pattern B has two subgroups in feature and three subgroups in sample. Pattern C matrices are transposed of pattern B of dimension 600×1000,6×10, and 60×100. Then we generated sparse matrices randomly by dropping the entries of matrices with rate 10%, 50%, and 70%.</p>
      <p>Figure <xref rid="Fig2" ref-type="fig">2</xref>, Additional files <xref rid="MOESM1" ref-type="media">1</xref> and <xref rid="MOESM2" ref-type="media">2</xref> show the performance of DeepMF on the raw matrix and sparse matrix with size 1000×600,10×6, and 100×60, respectively. In Fig. <xref rid="Fig2" ref-type="fig">2</xref>a, Additional files <xref rid="MOESM1" ref-type="media">1</xref>A and <xref rid="MOESM2" ref-type="media">2</xref>A, the DeepMF predicted matrices significantly reduced the noisy and missing entries. In spite of the noise and 70% missing entries, the feature latent factors and sample latent factors generated by DeepMF consistently uncovered ground truth feature subgroups and sample subgroups with 100% accuracy. The same conclusion applies to pattern B and pattern C (see Fig. <xref rid="Fig2" ref-type="fig">2</xref>b-c, Additional files <xref rid="MOESM1" ref-type="media">1</xref>B-C and <xref rid="MOESM2" ref-type="media">2</xref>B-C). We note that pattern B matrices and pattern C matrices are transposed, which suggests that DeepMF can uncover the feature and sample subclasses either from a feature-sample matrix or its transposed matrix. Since fitting a matrix with <italic>N</italic>&lt;<italic>M</italic> is more efficient than a matrix with <italic>N</italic>&gt;<italic>M</italic> in DeepMF, it is unnecessary to adhere to the paradigm of “treating the feature as row and sample as column” [<xref ref-type="bibr" rid="CR1">1</xref>].</p>
    </sec>
    <sec id="Sec18">
      <title>DeepMF accurately elucidates cancer subtypes on multiple cancer omics data sets</title>
      <p>Then, we demonstrate the use of DeepMF in the problem of clarifying cancer subtypes. We collected four cancer omics data sets as benchmark, namely the Medulloblastoma data set (mRNA) [<xref ref-type="bibr" rid="CR2">2</xref>], Leukemia data set(mRNA) [<xref ref-type="bibr" rid="CR2">2</xref>, <xref ref-type="bibr" rid="CR14">14</xref>], TCGA BRCA data set (mRNA, miRNA, protein) [<xref ref-type="bibr" rid="CR21">21</xref>], and small blue round cell tumor (SRBCT) data set (mRNA) [<xref ref-type="bibr" rid="CR21">21</xref>, <xref ref-type="bibr" rid="CR22">22</xref>]. Firstly, we verified the denoising power of DeepMF compared with deep learning based MF (DMF [<xref ref-type="bibr" rid="CR18">18</xref>, <xref ref-type="bibr" rid="CR19">19</xref>]), by utilizing the silhouette validation to corroborate whether the in-cluster similarity and out-cluster separation were enhanced after processing. Secondly, incorporating hierarchy clustering, we compared the decomposition efficacy on DeepMF against five baseline methods: PCA (FactoMineR [<xref ref-type="bibr" rid="CR23">23</xref>]), ICA (fastICA [<xref ref-type="bibr" rid="CR24">24</xref>]), Bayesian based NMF (CoGAPS [<xref ref-type="bibr" rid="CR15">15</xref>]), gradient based NMF(NMF [<xref ref-type="bibr" rid="CR14">14</xref>]), and DMF. Clustering accuracy is evaluated by the adjusted Rand index, which measures the overlap between the inferred clusters and ground-truth subtypes, negative score, or a score close to 0 signifies random labeling, and 1 denotes perfect inference.</p>
      <p>We first analyzed the benchmark dataset, Medulloblastoma dataset, used in Brunet’s paper to evaluate the gradient-descent NMF tool [<xref ref-type="bibr" rid="CR2">2</xref>]. Medulloblastomas are childhood brain tumors, and consist of two generally accepted histological subtypes: classic and desmoplastic. We applied PCA, ICA, Bayesian based NMF, gradient based NMF, DMF, and DeepMF to the expression profiles of 34 Medulloblastoma patients with rank <italic>K</italic>=2. The DeepMF structure configuration in training is listed in Additional file <xref rid="MOESM3" ref-type="media">3</xref>. To escape from local optima caused by DeepMF random weight initialization, we conducted ten different runs and selected the latent matrices with the model selection criteria defined in Method, that is, we chose the minimum loss <inline-formula id="IEq38"><alternatives><tex-math id="M95">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\mathcal {L}_{mix}$\end{document}</tex-math><mml:math id="M96"><mml:msub><mml:mrow><mml:mi mathvariant="script">ℒ</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">mix</mml:mtext></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12859_2019_3291_Article_IEq38.gif"/></alternatives></inline-formula>. We first verified the correctness of the refined matrices. Figure <xref rid="Fig3" ref-type="fig">3</xref>a shows that DeepMF diminished the noise in raw matrices while preserving cancer subtype structures. Silhouette validation corroborated that the in-cluster similarity and out-cluster separation were enhanced after DeepMF processing; that is, the average silhouette value was increased from 0.26 to 0.56. While after multiple tries, DMF can only produce a faulty output with a silhouette value of 0 (see Additional file <xref rid="MOESM4" ref-type="media">4</xref>A).
<fig id="Fig3"><label>Fig. 3</label><caption><p>DeepMF denoising and factorization on cancer data sets. <bold>a-d</bold> The heatmap presentation and Silhouette width of four cancer data sets. Left: before DeepMF. Right: after DeepMF. <bold>a</bold> Medulloblastoma data set <bold>b</bold> Leukemia data set <bold>c</bold> TCGA BRCA data set <bold>d</bold> SRBCT data set <bold>e</bold> Clustering accuracy of cancer subtyping on sample latent matrices generated by five matrix factorization tools on different cancer data sets</p></caption><graphic xlink:href="12859_2019_3291_Fig3_HTML" id="MO3"/></fig></p>
      <p>Then, we fitted the obtained sample latent matrices into hierarchical clustering. Figure <xref rid="Fig3" ref-type="fig">3</xref>e and Additional file <xref rid="MOESM5" ref-type="media">5</xref> demonstrate that DeepMF outperforms five baseline methods with the highest clustering accuracy of 76%. Additional files <xref rid="MOESM4" ref-type="media">4</xref>A, <xref rid="MOESM6" ref-type="media">6</xref>A, and <xref rid="MOESM7" ref-type="media">7</xref>A illustrate the hierarchical structures and clustering results of the obtained sample latent matrices. All methods consistently misclassify two samples, the classic Brain_MD_49 and desmoplastic Brain_MD_28. Possible explanations might be the incorrect diagnosis of the samples. If we treat them as outliers, then DeepMF correctly distinguished the remaining patients. However, ICA and NMF still incorrectly assign one classic patient Brain_MD_1. PCA and CoGAPs still misclassify two classic patients, Brain_MD_1 and Brain_MD_5. DMF yields a sample latent matrix with no distinction between classic and desmoplastic subgroups, thus fail to identify any sample subtype.</p>
      <p>We next employed the six tools to a classic cancer subtyping dataset Golub Leukemia Data Set [<xref ref-type="bibr" rid="CR2">2</xref>, <xref ref-type="bibr" rid="CR14">14</xref>]. It has 38 bone marrow samples consisting of three subgroups, 19 B-cell acute lymphoblastic leukemia (ALL), 8 T-cell ALL, and 11 acute myelogenous leukemia (AML). Thus, rank <italic>K</italic>=3 was selected for all six tools. DeepMF was trained in ten different runs with structure configuration listed in Additional file <xref rid="MOESM3" ref-type="media">3</xref>, result with minimum model selection criteria <inline-formula id="IEq39"><alternatives><tex-math id="M97">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\mathcal {L}_{mix}$\end{document}</tex-math><mml:math id="M98"><mml:msub><mml:mrow><mml:mi mathvariant="script">ℒ</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">mix</mml:mtext></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12859_2019_3291_Article_IEq39.gif"/></alternatives></inline-formula> was selected for evaluation and analysis. We first verified the correctness of the output matrices. Figure <xref rid="Fig3" ref-type="fig">3</xref>b shows that DeepMF reduces the noise in the raw matrix while preserving the three leukemia cancer subtype structures. After DeepMF processing, the average silhouette value was increased from 0.35 to 0.66. While DMF masks all subtype-specific signals, yields a silhouette value of -0.1 (see Additional file <xref rid="MOESM4" ref-type="media">4</xref>B). Then, we checked whether the DeepMF produced sample latent matrix preserves the cancer subtype information. We applied hierarchical clustering into obtained sample latent matrix (see Additional file <xref rid="MOESM6" ref-type="media">6</xref>B). The sample latent matrices derived from DeepMF, Bayesian based NMF, and gradient based NMF generate compact latent structures, thus leading to 100% hierarchical clustering accuracy (see Fig. <xref rid="Fig3" ref-type="fig">3</xref>e and Additional file <xref rid="MOESM6" ref-type="media">6</xref>B). While PCA and ICA generate sample latent matrices with looser structures among ground-truth labels, leading to one misclassification (ALL_14749_B’cell) and five misclassifications (ALL_14749_B’cell, ALL_21302_B’cell, ALL_18239_B’cell, ALL_R23_B’cell, AML_6), respectively (see Additional file <xref rid="MOESM7" ref-type="media">7</xref>B). There are also no subtype-specific signals in sample latent matrix produced by DMF; thus hierarchical clustering shatters B-cell ALL, T-cell ALL, and AML samples into different clusters (see Additional file <xref rid="MOESM4" ref-type="media">4</xref>B).</p>
      <p>We then collected a subset of human breast cancer (BRCA) data generated by The Cancer Genome Atlas Network (TCGA). It holds 150 samples with three subtypes Basal-like, Her2, and LumA, of size 45, 30, and 75, respectively. It is an omics profile containing the most varying mRNA, miRNA, and proteins, which together discriminate the breast cancer subtypes. The analysis process and evaluation metrics are the same as the previous two benchmarks, except we set the rank as the number of BRCA subtypes, <italic>K</italic>=3. Firstly, DeepMF reduced the noise in the raw matrix and yielded a compact output, with the average silhouette width was increased from 0.19 to 0.47 (see Fig. <xref rid="Fig3" ref-type="fig">3</xref>c). Secondly, DeepMF outperformed all baselines and manifested the best embedding strength, with the highest clustering accuracy of 92% (see Fig. <xref rid="Fig3" ref-type="fig">3</xref>e, Additional files <xref rid="MOESM4" ref-type="media">4</xref>C and <xref rid="MOESM6" ref-type="media">6</xref>C). In Additional file <xref rid="MOESM7" ref-type="media">7</xref>C, within 150 patients, only five patients were misclassified (A143, A131, A0E0, A12T, A0RH). CoGAPS displayed ten misclassifications. PCA, ICA, gradient based NMF shared similar subtype assignment, and wrongly attributed subtype to six, eight, eight patients, respectively. In terms of DMF, DMF revealed better denoising ability with a silhouette value of 0.52, while it displayed the worse embedding potency with clustering accuracy of 29% (see Additional files <xref rid="MOESM4" ref-type="media">4</xref>C and <xref rid="MOESM5" ref-type="media">5</xref>).</p>
      <p>The last benchmark data set is the small round blue cell tumors (SRBCT) data set, which holds the expression profiles of the top 96 ranked genes [<xref ref-type="bibr" rid="CR22">22</xref>]. It contains 63 samples of four classes, Burkitt Lymphoma (BL), Ewing Sarcoma (EWS), Neuroblastoma (NB), and Rhabdomyosarcoma (RMS). Thus, we set the rank as the number of subtypes, <italic>K</italic>=4. The analysis process and evaluation metrics are the same as the previous benchmarks. From the perspective of denoising ability, DMF and DeepMF enhanced average silhouette width from 0.31 to 0.45 and 0.58, respectively (see Fig. <xref rid="Fig3" ref-type="fig">3</xref>d and Additional file <xref rid="MOESM4" ref-type="media">4</xref>D). In terms of embedding strength, PCA, ICA, CoGAPS, and DeepMF perfectly assign samples to their ground-truth subtypes with 100% accuracy (see Fig. <xref rid="Fig3" ref-type="fig">3</xref>e, Additional files <xref rid="MOESM6" ref-type="media">6</xref>D and <xref rid="MOESM7" ref-type="media">7</xref>D), while Gradient based NMF improperly attributed one patient EWS.T13 to RMS category. DMF successfully identified all BL samples, while the latent representation of the other three subtypes are homologous, leads to the worse clustering accuracy of 59% (see Additional files <xref rid="MOESM4" ref-type="media">4</xref>D and <xref rid="MOESM5" ref-type="media">5</xref>).</p>
    </sec>
    <sec id="Sec19">
      <title>DeepMF captures the cancer subtype patterns despite 70% random dropouts</title>
      <p>Several studies have suggested that missing values in large-scale omics data can drastically obstruct the interpretation of unsupervised cancer subtyping [<xref ref-type="bibr" rid="CR28">28</xref>]. At present, this is most commonly treated by imputing the missing values before performing the downstream dimension reduction and subtype clustering. To tackle this, DeepMF provides a two-pronged solution by assigning predicted values into missing entries and conducting low-dimensional embedding simultaneously.</p>
      <p>To evaluate the efficacy of DeepMF with missing entries, we generate four sparse datasets by randomly discarding 70% entries of the four benchmark data sets. Then we fit the sparse matrices into DMF, DeepMF, and two imputation baselines: MeanImpute and SVDImpute. We selected MeanImpute by considering its popularity. From the perspective of the imputation mechanism, we can regard SVDImpute as a linear analogy of DeepMF. We conducted ten different runs for each data set configuration (see Additional file <xref rid="MOESM3" ref-type="media">3</xref>) and picked the one with minimal module selection criteria <inline-formula id="IEq40"><alternatives><tex-math id="M99">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\mathcal {L}_{mix}$\end{document}</tex-math><mml:math id="M100"><mml:msub><mml:mrow><mml:mi mathvariant="script">ℒ</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">mix</mml:mtext></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12859_2019_3291_Article_IEq40.gif"/></alternatives></inline-formula>. Fig. <xref rid="Fig4" ref-type="fig">4</xref> demonstrates that for all 70% missing rate data sets, both DeepMF and SVDImpute recovered distinctive cancer subtype structures, while the MeanImpute approach was unable to reconstruct a clearly visible pattern. Silhouette validation confirmed that DeepMF reduced the most substantial interior cluster heterogeneity and out-cluster similarity, with the largest average silhouette value of 0.47 for the Medulloblastoma data set, 0.6 for the Leukemia data set, 0.28 for TCGA BRCA data set, and 0.44 for SRBCT data set. DMF conducted unsatisfactory imputation jobs, produced negative or close to 0 silhouette values on all sparse benchmark sets (see Additional file <xref rid="MOESM8" ref-type="media">8</xref>).
<fig id="Fig4"><label>Fig. 4</label><caption><p>DeepMF’s imputation and factorization effect on cancer data sets with 70% random dropout. <bold>a-d</bold> The heatmap presentation and Silhouette width of four cancer data sets with 70% random dropout. The gray tiles in heatmap indicate missing entries. From left to right: matrix with 70% random dropout, after mean impute, after SVDImpute, after DeepMF. <bold>a</bold> Medulloblastoma data set <bold>b</bold> Leukemia data set <bold>c</bold> TCGA BRCA data set <bold>d</bold> SRBCT data set <bold>e</bold> Clustering accuracy of cancer subtyping on sample latent matrices generated by two imputations and five matrix factorization tools on different cancer data sets with 70% random dropout</p></caption><graphic xlink:href="12859_2019_3291_Fig4_HTML" id="MO4"/></fig></p>
      <p>Remainder that we can uncover the cancer subtypes utilizing the sample latent matrices produced by DeepMF. To investigate whether missing entries will hinder DeepMF’s ability in cancer subtyping, we applied hierarchical clustering into sample latent matrices generated by sparse matrices (see Additional file <xref rid="MOESM9" ref-type="media">9</xref>) and computed the clustering accuracy with ground-truth subtyping labels (see Fig. <xref rid="Fig4" ref-type="fig">4</xref>e). Since the four traditional baseline matrix factorization tools do not accept input with missing values, we fitted the high dimensional matrices treated by MeanImpute and SVDImpute into four baseline approaches. Then we obtained the corresponding low-dimensional sample latent matrices with rank <italic>K</italic>=2 for Medulloblastoma data set, rank <italic>K</italic>=3 for Leukemia data set, rank <italic>K</italic>=3 for TCGA BRCA data set, and rank <italic>K</italic>=4 for SRBCT data set, respectively. Figure <xref rid="Fig4" ref-type="fig">4</xref>e shows that in terms of clustering accuracy, DeepMF outperforms all eight imputation and factorization combinations, exhibiting the best embedding power with clustering accuracy of 88% for Medulloblastoma data set, 100% for TCGA BRCA data set, 84% for Leukemia, and 96% for SRBCT data sets. For Medulloblastoma sparse data, DeepMF only incorrectly assigned one desmoplastic sample Brain_MD_28 to classic category, the other eight imputation and MF combinations produced misclassifications range from two to twelve (see Additional files <xref rid="MOESM9" ref-type="media">9</xref>A and <xref rid="MOESM10" ref-type="media">10</xref>A). In spite of 70% sparsity, SVDImpute + PCA and DeepMF correctly attach each leukemia sample to its right subtype, the other seven baseline tools combinations misclassify leukemia patients range from one to ten (see Additional files <xref rid="MOESM9" ref-type="media">9</xref>B and <xref rid="MOESM10" ref-type="media">10</xref>B). For 150 TCGA BRCA samples, after removing 70% entries, the clustering accuracy of all tools declined dramatically. DeepMF clustering errors increased from five to nine, the other eight baseline tools combinations produced misclassifications range from 12 to 29 (see Additional files <xref rid="MOESM9" ref-type="media">9</xref>C and <xref rid="MOESM10" ref-type="media">10</xref>C). In terms of SRBCT data with 70% sparsity, except sample NB.C7, DeepMF correctly attaches each sample to its right subtype. Additional files <xref rid="MOESM9" ref-type="media">9</xref>D and <xref rid="MOESM10" ref-type="media">10</xref>D illustrate the number of misclassification range from three to eleven for baseline tool combinations. Overall, the clustering results vary on different imputation and MF combinations among different sparse benchmark sets, while DeepMF always demonstrates the best embedding ability with the highest clustering accuracy. Concerning DMF, the sample latent representation among cancer subtypes are not distinguishable, leads to the worse clustering accuracy on all sparse benchmark sets (see Additional files <xref rid="MOESM5" ref-type="media">5</xref> and <xref rid="MOESM8" ref-type="media">8</xref>).</p>
    </sec>
  </sec>
  <sec id="Sec20" sec-type="discussion">
    <title>Discussion</title>
    <p>In this study, we presented DeepMF, a supervised learning approach to the dimension reduction problem. Unlike current approaches, the method is designed to have high tolerance with respect to noisy data and missing values. Experiments using synthetic and real data corroborated this fact, showing DeepMF to be particularly suited for cancer subtype discovery on omics data, and beats all state of the art MF tools on imputation, denoising, and embedding.</p>
    <p>We have not addressed several issues. The first is with regard to the choice of the three hyper-parameters <italic>K,L</italic>,<italic>W</italic> in DeepMF. The choice of the reduced dimensionality <italic>K</italic> is arguably difficult since it is an open problem for the entire dimension reduction research community. A larger <italic>L</italic> would provide more complexity in the latent space of DeepML. To extract simple pattern between feature and sample, <italic>L</italic>=1 suffices. As discussed in methods, if the samples assume <italic>C</italic> (<italic>C</italic>≥2) cancer subtypes, we may search the optimal structure from <italic>K</italic>∈[2,<italic>C</italic>] and <italic>L</italic>∈[1,+<italic>∞</italic>). To find the optimal network structure for accurate cancer subtyping, we defined <inline-formula id="IEq41"><alternatives><tex-math id="M101">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\mathcal {L}_{mix}$\end{document}</tex-math><mml:math id="M102"><mml:msub><mml:mrow><mml:mi mathvariant="script">ℒ</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">mix</mml:mtext></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12859_2019_3291_Article_IEq41.gif"/></alternatives></inline-formula> to guide the hyperparameter search. Otherwise, we resort to multiple trials for the tuning of these parameters. Even though different combinations of <italic>K,L</italic> might lead to disparate molecular feature and sample latent matrices, all latent matrices enable to preserve the underlying structures of cancer samples as we imposed the graph Laplacian penalty during training.</p>
    <p>In this study, we only adopted DeepMF on mRNA, miRNA, and protein data for cancer subtype identification. However, DeepMF is not limited to these data modality and this clustering problem. Human metabolome profiles can undoubtedly benefit from analysis using DeepMF, since the data is known to often suffer from missing values. We intend to apply DeepMF to metabolome and discover signatures beneficial to human health. Furthermore, we plan to employ molecular feature latent matrix to uncover functional pathways in future work.</p>
  </sec>
  <sec id="Sec21" sec-type="conclusion">
    <title>Conclusion</title>
    <p>MF-based analyses are commonly used in the interpretation of high-throughput biological data. Our proposed DeepMF is an MF-based deep learning framework that overcomes traditional shortcomings such as noise and missing data. Our experiments on simulation data and four omics cancer data sets established DeepMF’s feasibility in denoising, imputation, and in discovering the underlying structure of data.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary information</title>
    <sec id="Sec22">
      <p>
        <supplementary-material content-type="local-data" id="MOESM1">
          <media xlink:href="12859_2019_3291_MOESM1_ESM.pdf">
            <caption>
              <p><bold>Additional file 1</bold> DeepMF performance on 10×6 synthetic matrices. DeepMF denoising, imputation, and factorization performance on 10×6 synthetic matrices with different pattern. Inside each pattern, from left to right: raw matrix, 10% random dropout, 50% random dropout, 70% random dropout; from top to bottom: before DeepMF, and DeepMF. The horizontal line plot show the sample latent factors, the vertical line plot refer to feature latent factors. <bold>A</bold> Matrix with pattern A; <bold>B</bold> Matrix with pattern B; <bold>C</bold> The transpose matrix of pattern B.</p>
            </caption>
          </media>
        </supplementary-material>
      </p>
      <p>
        <supplementary-material content-type="local-data" id="MOESM2">
          <media xlink:href="12859_2019_3291_MOESM2_ESM.pdf">
            <caption>
              <p><bold>Additional file 2</bold> DeepMF performance on 1000×600 synthetic matrices. DeepMF denoising, imputation, and factorization performance on 1000×600 synthetic matrices with different pattern. Inside each pattern, from left to right: raw matrix, 10% random dropout, 50% random dropout, 70% random dropout; from top to bottom: before DeepMF, and DeepMF. The horizontal line plot show the sample latent factors, the vertical line plot refer to feature latent factors. <bold>A</bold> Matrix with pattern A; <bold>B</bold> Matrix with pattern B; <bold>C</bold> The transpose matrix of pattern B.</p>
            </caption>
          </media>
        </supplementary-material>
      </p>
      <p>
        <supplementary-material content-type="local-data" id="MOESM3">
          <media xlink:href="12859_2019_3291_MOESM3_ESM.xlsx">
            <caption>
              <p><bold>Additional file 3</bold> DeepMF training configuration on cancer data sets.</p>
            </caption>
          </media>
        </supplementary-material>
      </p>
      <p>
        <supplementary-material content-type="local-data" id="MOESM4">
          <media xlink:href="12859_2019_3291_MOESM4_ESM.pdf">
            <caption>
              <p><bold>Additional file 4</bold> DMF denoising and factorization results on cancer data sets. <bold>A-D</bold> The heatmap presentation and Silhouette width of four cancer data sets. From left to right: matrix with before DMF, after DMF. The bottom: hierarchical clustering plots for sample latent matrice generated by DMF. <bold>A</bold> Medulloblastoma data set; <bold>B</bold> Leukemia data set; <bold>C</bold> TCGA BRCA data set; <bold>D</bold> SRBCT data set.</p>
            </caption>
          </media>
        </supplementary-material>
      </p>
      <p>
        <supplementary-material content-type="local-data" id="MOESM5">
          <media xlink:href="12859_2019_3291_MOESM5_ESM.xlsx">
            <caption>
              <p><bold>Additional file 5</bold> DMF adjusted rand index on cancer data sets.</p>
            </caption>
          </media>
        </supplementary-material>
      </p>
      <p>
        <supplementary-material content-type="local-data" id="MOESM6">
          <media xlink:href="12859_2019_3291_MOESM6_ESM.pdf">
            <caption>
              <p><bold>Additional file 6</bold> Hierarchical clustering plots for sample latent matrices. Sample latent matrices are generated by five matrix factorization tools on different cancer data sets. From top to bottom, each row represents sample latent matrices generated by PCA, ICA, CoGAPS, NMF, DeepMF. <bold>A</bold> Medulloblastoma data set; <bold>B</bold> Leukemia data set; <bold>C</bold> TCGA BRCA data set; <bold>D</bold> SRBCT data set.</p>
            </caption>
          </media>
        </supplementary-material>
      </p>
      <p>
        <supplementary-material content-type="local-data" id="MOESM7">
          <media xlink:href="12859_2019_3291_MOESM7_ESM.pdf">
            <caption>
              <p><bold>Additional file 7</bold> Hierarchical clustering results for sample latent matrices. The top row is the ground truth subtype label for each patients. The rest rows represent patient subtype assigned by PCA, ICA, CoGAPS, NMF, DeepMF, respectively. <bold>A</bold> Medulloblastoma data set; <bold>B</bold> Leukemia data set; <bold>C</bold> TCGA BRCA data set; <bold>D</bold> SRBCT data set.</p>
            </caption>
          </media>
        </supplementary-material>
      </p>
      <p>
        <supplementary-material content-type="local-data" id="MOESM8">
          <media xlink:href="12859_2019_3291_MOESM8_ESM.pdf">
            <caption>
              <p><bold>Additional file 8</bold> DMF imputation and factorization results on 70% sparse cancer data sets. <bold>A-D</bold> The heatmap presentation and Silhouette width of four cancer data sets with 70% random dropout. The gray tiles in heatmap indicate missing entries. From left to right: matrix with 70% random dropout, after DMF. The bottom: hierarchical clustering plots for sample latent matrice generated by DMF. <bold>A</bold> Medulloblastoma data set; <bold>B</bold> Leukemia data set; <bold>C</bold> TCGA BRCA data set; <bold>D</bold> SRBCT data set.</p>
            </caption>
          </media>
        </supplementary-material>
      </p>
      <p>
        <supplementary-material content-type="local-data" id="MOESM9">
          <media xlink:href="12859_2019_3291_MOESM9_ESM.pdf">
            <caption>
              <p><bold>Additional file 9</bold> Hierarchical clustering plots for sample latent matrices generated from 70% random dropout data sets. Sample latent matrices are generated by two imputation tools and five matrix factorization tools on different cancer data sets with 70% random dropout. From top to bottom, each row represents sample latent matrices generated by meanImpute + PCA, meanImpute + ICA, meanImpute + CoGAPS, meanImpute + NMF, SVDImpute + PCA, SVDImpute + ICA, SVDImpute + CoGAPS, SVDImpute + NMF, DeepMF. <bold>A</bold> Medulloblastoma data set; <bold>B</bold> Leukemia data set; <bold>C</bold> TCGA BRCA data set; <bold>D</bold> SRBCT data set.</p>
            </caption>
          </media>
        </supplementary-material>
      </p>
      <p>
        <supplementary-material content-type="local-data" id="MOESM10">
          <media xlink:href="12859_2019_3291_MOESM10_ESM.pdf">
            <caption>
              <p><bold>Additional file 10</bold> Hierarchical clustering results for sample latent matrices generated from 70% random dropout data sets. The top row is the ground truth subtype label for each patients. The rest rows represent patient subtype assigned by meanImpute + PCA, meanImpute + ICA, meanImpute + CoGAPS, meanImpute + NMF, SVDImpute + PCA, SVDImpute + ICA, SVDImpute + CoGAPS, SVDImpute + NMF, DeepMF, respectively. <bold>A</bold> Medulloblastoma data set; <bold>B</bold> Leukemia data set; <bold>C</bold> TCGA BRCA data set; <bold>D</bold> SRBCT data set.</p>
            </caption>
          </media>
        </supplementary-material>
      </p>
    </sec>
  </sec>
</body>
<back>
  <glossary>
    <title>Abbreviations</title>
    <def-list>
      <def-item>
        <term>ALL</term>
        <def>
          <p>Acute lymphoblastic leukemia</p>
        </def>
      </def-item>
      <def-item>
        <term>AML</term>
        <def>
          <p>Acute myelogenous leukemia</p>
        </def>
      </def-item>
      <def-item>
        <term>BL</term>
        <def>
          <p>Burkitt lymphoma</p>
        </def>
      </def-item>
      <def-item>
        <term>BRCA</term>
        <def>
          <p>Breast cancer</p>
        </def>
      </def-item>
      <def-item>
        <term>EWS</term>
        <def>
          <p>Ewing sarcoma</p>
        </def>
      </def-item>
      <def-item>
        <term>ICA</term>
        <def>
          <p>Independent component analysis</p>
        </def>
      </def-item>
      <def-item>
        <term>MF</term>
        <def>
          <p>Matrix factorization</p>
        </def>
      </def-item>
      <def-item>
        <term>NB</term>
        <def>
          <p>Neuroblastoma</p>
        </def>
      </def-item>
      <def-item>
        <term>NGS</term>
        <def>
          <p>Next-generation sequencing</p>
        </def>
      </def-item>
      <def-item>
        <term>NMF</term>
        <def>
          <p>Non-negative matrix factorization</p>
        </def>
      </def-item>
      <def-item>
        <term>PCA</term>
        <def>
          <p>Principal component analysis</p>
        </def>
      </def-item>
      <def-item>
        <term>RMS</term>
        <def>
          <p>Rhabdomyosarcoma</p>
        </def>
      </def-item>
      <def-item>
        <term>SRBCT</term>
        <def>
          <p>Small round blue cell tumors</p>
        </def>
      </def-item>
      <def-item>
        <term>TCGA</term>
        <def>
          <p>The cancer genome atlas network</p>
        </def>
      </def-item>
    </def-list>
  </glossary>
  <fn-group>
    <fn>
      <p>
        <bold>Publisher’s Note</bold>
      </p>
      <p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
    </fn>
    <fn>
      <p>Lingxi Chen and Jiao Xu contributed equally to this work.</p>
    </fn>
  </fn-group>
  <sec>
    <title>Supplementary information</title>
    <p><bold>Supplementary information</bold> accompanies this paper at 10.1186/s12859-019-3291-6.</p>
  </sec>
  <ack>
    <title>Acknowledgements</title>
    <p>We would like to express sincere gratitude to Prof. Yen Kaow Ng (Universiti Tunku Abdul Rahman) for manuscript revision.</p>
    <sec id="d29e3636">
      <title>About this supplement</title>
      <p>This article has been published as part of <italic>BMC Bioinformatics Volume 20 Supplement 23, 2019: Proceedings of the Joint International GIW &amp; ABACBS-2019 Conference: bioinformatics</italic>. The full contents of the supplement are available online at <ext-link ext-link-type="uri" xlink:href="https://bmcbioinformatics.biomedcentral.com/articles/supplements/volume-20-supplement-23">https://bmcbioinformatics.biomedcentral.com/articles/supplements/volume-20-supplement-23</ext-link>.</p>
    </sec>
  </ack>
  <notes notes-type="author-contribution">
    <title>Authors’ contributions</title>
    <p>SCL conceived the idea. SCL, LC designed the network. LC, JX implemented the network. LC, JX conducted the analysis. LC drafted the manuscript. SCL supervised the project, revised the manuscript. All authors read and approved the final manuscript.</p>
  </notes>
  <notes notes-type="funding-information">
    <title>Funding</title>
    <p>Publication costs are funded by the GRF Research Projects 9042348 (CityU 11257316). The work described in this paper was also supported by the project.</p>
  </notes>
  <notes notes-type="data-availability">
    <title>Availability of data and materials</title>
    <p>The data and source code included in this study can be found in <ext-link ext-link-type="uri" xlink:href="https://github.com/paprikachan/DeepMF">https://github.com/paprikachan/DeepMF</ext-link>.</p>
  </notes>
  <notes>
    <title>Ethics approval and consent to participate</title>
    <p>Not applicable.</p>
  </notes>
  <notes>
    <title>Consent for publication</title>
    <p>Not applicable.</p>
  </notes>
  <notes notes-type="COI-statement">
    <title>Competing interests</title>
    <p>The authors declare that they have no competing interests.</p>
  </notes>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <label>1</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Stein-O’Brien</surname>
            <given-names>Genevieve L.</given-names>
          </name>
          <name>
            <surname>Arora</surname>
            <given-names>Raman</given-names>
          </name>
          <name>
            <surname>Culhane</surname>
            <given-names>Aedin C.</given-names>
          </name>
          <name>
            <surname>Favorov</surname>
            <given-names>Alexander V.</given-names>
          </name>
          <name>
            <surname>Garmire</surname>
            <given-names>Lana X.</given-names>
          </name>
          <name>
            <surname>Greene</surname>
            <given-names>Casey S.</given-names>
          </name>
          <name>
            <surname>Goff</surname>
            <given-names>Loyal A.</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>Yifeng</given-names>
          </name>
          <name>
            <surname>Ngom</surname>
            <given-names>Aloune</given-names>
          </name>
          <name>
            <surname>Ochs</surname>
            <given-names>Michael F.</given-names>
          </name>
          <name>
            <surname>Xu</surname>
            <given-names>Yanxun</given-names>
          </name>
          <name>
            <surname>Fertig</surname>
            <given-names>Elana J.</given-names>
          </name>
        </person-group>
        <article-title>Enter the Matrix: Factorization Uncovers Knowledge from Omics</article-title>
        <source>Trends in Genetics</source>
        <year>2018</year>
        <volume>34</volume>
        <issue>10</issue>
        <fpage>790</fpage>
        <lpage>805</lpage>
        <pub-id pub-id-type="doi">10.1016/j.tig.2018.07.003</pub-id>
        <pub-id pub-id-type="pmid">30143323</pub-id>
      </element-citation>
    </ref>
    <ref id="CR2">
      <label>2</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Brunet</surname>
            <given-names>J-P</given-names>
          </name>
          <name>
            <surname>Tamayo</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Golub</surname>
            <given-names>TR</given-names>
          </name>
          <name>
            <surname>Mesirov</surname>
            <given-names>JP</given-names>
          </name>
        </person-group>
        <article-title>Metagenes and molecular pattern discovery using matrix factorization</article-title>
        <source>Proc Natl Acad Sci</source>
        <year>2004</year>
        <volume>101</volume>
        <issue>12</issue>
        <fpage>4164</fpage>
        <lpage>9</lpage>
        <pub-id pub-id-type="doi">10.1073/pnas.0308531101</pub-id>
        <pub-id pub-id-type="pmid">15016911</pub-id>
      </element-citation>
    </ref>
    <ref id="CR3">
      <label>3</label>
      <mixed-citation publication-type="other">Hu F, Zhou Y, Wang Q, Yang Z, Shi Y, Chi Q. Gene expression classification of lung adenocarcinoma into molecular subtypes. IEEE/ACM Trans Comput Biol Bioinform. 2019. 10.1109/tcbb.2019.2905553.</mixed-citation>
    </ref>
    <ref id="CR4">
      <label>4</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ochs</surname>
            <given-names>MF</given-names>
          </name>
          <name>
            <surname>Rink</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Tarn</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Mburu</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Taguchi</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Eisenberg</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Godwin</surname>
            <given-names>AK</given-names>
          </name>
        </person-group>
        <article-title>Detection of treatment-induced changes in signaling pathways in gastrointestinal stromal tumors using transcriptomic data</article-title>
        <source>Cancer Res</source>
        <year>2009</year>
        <volume>69</volume>
        <issue>23</issue>
        <fpage>9125</fpage>
        <lpage>32</lpage>
        <pub-id pub-id-type="doi">10.1158/0008-5472.CAN-09-1709</pub-id>
        <pub-id pub-id-type="pmid">19903850</pub-id>
      </element-citation>
    </ref>
    <ref id="CR5">
      <label>5</label>
      <mixed-citation publication-type="other">Ochs MF, Fertig EJ. Matrix factorization for transcriptional regulatory network inference. In: 2012 IEEE Symposium on Computational Intelligence in Bioinformatics and Computational Biology (CIBCB). IEEE: 2012. p. 387–96. 10.1109/cibcb.2012.6217256.</mixed-citation>
    </ref>
    <ref id="CR6">
      <label>6</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Fertig</surname>
            <given-names>EJ</given-names>
          </name>
          <name>
            <surname>Favorov</surname>
            <given-names>AV</given-names>
          </name>
          <name>
            <surname>Ochs</surname>
            <given-names>MF</given-names>
          </name>
        </person-group>
        <article-title>Identifying context-specific transcription factor targets from prior knowledge and gene expression data</article-title>
        <source>IEEE Trans Nanobioscience</source>
        <year>2013</year>
        <volume>12</volume>
        <issue>3</issue>
        <fpage>142</fpage>
        <lpage>9</lpage>
        <pub-id pub-id-type="doi">10.1109/TNB.2013.2263390</pub-id>
        <pub-id pub-id-type="pmid">23694699</pub-id>
      </element-citation>
    </ref>
    <ref id="CR7">
      <label>7</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Alexandrov</surname>
            <given-names>LB</given-names>
          </name>
          <name>
            <surname>Nik-Zainal</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Wedge</surname>
            <given-names>DC</given-names>
          </name>
          <name>
            <surname>Campbell</surname>
            <given-names>PJ</given-names>
          </name>
          <name>
            <surname>Stratton</surname>
            <given-names>MR</given-names>
          </name>
        </person-group>
        <article-title>Deciphering signatures of mutational processes operative in human cancer</article-title>
        <source>Cell Rep</source>
        <year>2013</year>
        <volume>3</volume>
        <issue>1</issue>
        <fpage>246</fpage>
        <lpage>59</lpage>
        <pub-id pub-id-type="doi">10.1016/j.celrep.2012.12.008</pub-id>
        <pub-id pub-id-type="pmid">23318258</pub-id>
      </element-citation>
    </ref>
    <ref id="CR8">
      <label>8</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Alexandrov</surname>
            <given-names>LB</given-names>
          </name>
          <name>
            <surname>Nik-Zainal</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Wedge</surname>
            <given-names>DC</given-names>
          </name>
          <name>
            <surname>Aparicio</surname>
            <given-names>SA</given-names>
          </name>
          <name>
            <surname>Behjati</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Biankin</surname>
            <given-names>AV</given-names>
          </name>
          <name>
            <surname>Bignell</surname>
            <given-names>GR</given-names>
          </name>
          <name>
            <surname>Bolli</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Borg</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Børresen-Dale</surname>
            <given-names>A-L</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Signatures of mutational processes in human cancer</article-title>
        <source>Nature</source>
        <year>2013</year>
        <volume>500</volume>
        <issue>7463</issue>
        <fpage>415</fpage>
        <pub-id pub-id-type="doi">10.1038/nature12477</pub-id>
        <pub-id pub-id-type="pmid">23945592</pub-id>
      </element-citation>
    </ref>
    <ref id="CR9">
      <label>9</label>
      <mixed-citation publication-type="other">Alexandrov L, Kim J, Haradhvala NJ, Huang MN, Ng AW, Boot A, Covington KR, Gordenin DA, Bergstrom E, Lopez-Bigas N, et al. The repertoire of mutational signatures in human cancer. BioRxiv. 2018:322859. 10.1101/322859.</mixed-citation>
    </ref>
    <ref id="CR10">
      <label>10</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Fertig</surname>
            <given-names>EJ</given-names>
          </name>
          <name>
            <surname>Markovic</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Danilova</surname>
            <given-names>LV</given-names>
          </name>
          <name>
            <surname>Gaykalova</surname>
            <given-names>DA</given-names>
          </name>
          <name>
            <surname>Cope</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Chung</surname>
            <given-names>CH</given-names>
          </name>
          <name>
            <surname>Ochs</surname>
            <given-names>MF</given-names>
          </name>
          <name>
            <surname>Califano</surname>
            <given-names>JA</given-names>
          </name>
        </person-group>
        <article-title>Preferential activation of the hedgehog pathway by epigenetic modulations in hpv negative hnscc identified with meta-pathway analysis</article-title>
        <source>PLoS ONE</source>
        <year>2013</year>
        <volume>8</volume>
        <issue>11</issue>
        <fpage>78127</fpage>
        <pub-id pub-id-type="doi">10.1371/journal.pone.0078127</pub-id>
      </element-citation>
    </ref>
    <ref id="CR11">
      <label>11</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hofree</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Shen</surname>
            <given-names>JP</given-names>
          </name>
          <name>
            <surname>Carter</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Gross</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Ideker</surname>
            <given-names>T</given-names>
          </name>
        </person-group>
        <article-title>Network-based stratification of tumor mutations</article-title>
        <source>Nat Methods</source>
        <year>2013</year>
        <volume>10</volume>
        <issue>11</issue>
        <fpage>1108</fpage>
        <pub-id pub-id-type="doi">10.1038/nmeth.2651</pub-id>
        <pub-id pub-id-type="pmid">24037242</pub-id>
      </element-citation>
    </ref>
    <ref id="CR12">
      <label>12</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhao</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Luo</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Jiao</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>Comprehensive characterization of cancer subtype associated long non-coding rnas and their clinical implications</article-title>
        <source>Sci Rep</source>
        <year>2014</year>
        <volume>4</volume>
        <fpage>6591</fpage>
        <pub-id pub-id-type="doi">10.1038/srep06591</pub-id>
        <pub-id pub-id-type="pmid">25307233</pub-id>
      </element-citation>
    </ref>
    <ref id="CR13">
      <label>13</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lee</surname>
            <given-names>S-I</given-names>
          </name>
          <name>
            <surname>Batzoglou</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>Application of independent component analysis to microarrays</article-title>
        <source>Genome Biol</source>
        <year>2003</year>
        <volume>4</volume>
        <issue>11</issue>
        <fpage>76</fpage>
        <pub-id pub-id-type="doi">10.1186/gb-2003-4-11-r76</pub-id>
      </element-citation>
    </ref>
    <ref id="CR14">
      <label>14</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Gaujoux</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Seoighe</surname>
            <given-names>C</given-names>
          </name>
        </person-group>
        <article-title>A flexible r package for nonnegative matrix factorization</article-title>
        <source>BMC Bioinformatics</source>
        <year>2010</year>
        <volume>11</volume>
        <issue>1</issue>
        <fpage>367</fpage>
        <pub-id pub-id-type="doi">10.1186/1471-2105-11-367</pub-id>
        <pub-id pub-id-type="pmid">20598126</pub-id>
      </element-citation>
    </ref>
    <ref id="CR15">
      <label>15</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Fertig</surname>
            <given-names>EJ</given-names>
          </name>
          <name>
            <surname>Ding</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Favorov</surname>
            <given-names>AV</given-names>
          </name>
          <name>
            <surname>Parmigiani</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Ochs</surname>
            <given-names>MF</given-names>
          </name>
        </person-group>
        <article-title>Cogaps: an r/c++ package to identify patterns and biological process activity in transcriptomic data</article-title>
        <source>Bioinformatics</source>
        <year>2010</year>
        <volume>26</volume>
        <issue>21</issue>
        <fpage>2792</fpage>
        <lpage>3</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btq503</pub-id>
        <pub-id pub-id-type="pmid">20810601</pub-id>
      </element-citation>
    </ref>
    <ref id="CR16">
      <label>16</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wilhelm-Benartzi</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Koestler</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Karagas</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Flanagan</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Christensen</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Kelsey</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Marsit</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Houseman</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Brown</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>Review of processing and analysis methods for dna methylation array data</article-title>
        <source>British J Cancer</source>
        <year>2013</year>
        <volume>109</volume>
        <issue>6</issue>
        <fpage>1394</fpage>
        <pub-id pub-id-type="doi">10.1038/bjc.2013.496</pub-id>
      </element-citation>
    </ref>
    <ref id="CR17">
      <label>17</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Aittokallio</surname>
            <given-names>T</given-names>
          </name>
        </person-group>
        <article-title>Dealing with missing values in large-scale studies: microarray data imputation and beyond</article-title>
        <source>Brief Bioinform</source>
        <year>2009</year>
        <volume>11</volume>
        <issue>2</issue>
        <fpage>253</fpage>
        <lpage>64</lpage>
        <pub-id pub-id-type="doi">10.1093/bib/bbp059</pub-id>
        <pub-id pub-id-type="pmid">19965979</pub-id>
      </element-citation>
    </ref>
    <ref id="CR18">
      <label>18</label>
      <mixed-citation publication-type="other">Xue H-J, Dai X, Zhang J, Huang S, Chen J. Deep matrix factorization models for recommender systems. In: IJCAI: 2017. p. 3203–9. 10.24963/ijcai.2017/447.</mixed-citation>
    </ref>
    <ref id="CR19">
      <label>19</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhang</surname>
            <given-names>Fei</given-names>
          </name>
          <name>
            <surname>Song</surname>
            <given-names>Jiaxing</given-names>
          </name>
          <name>
            <surname>Peng</surname>
            <given-names>Shiyu</given-names>
          </name>
        </person-group>
        <article-title>Deep Matrix Factorization for Recommender Systems with Missing Data not at Random</article-title>
        <source>Journal of Physics: Conference Series</source>
        <year>2018</year>
        <volume>1060</volume>
        <fpage>012001</fpage>
      </element-citation>
    </ref>
    <ref id="CR20">
      <label>20</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ritchie</surname>
            <given-names>ME</given-names>
          </name>
          <name>
            <surname>Phipson</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Wu</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Hu</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Law</surname>
            <given-names>CW</given-names>
          </name>
          <name>
            <surname>Shi</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Smyth</surname>
            <given-names>GK</given-names>
          </name>
        </person-group>
        <article-title>limma powers differential expression analyses for rna-sequencing and microarray studies</article-title>
        <source>Nucleic Acids Res</source>
        <year>2015</year>
        <volume>43</volume>
        <issue>7</issue>
        <fpage>47</fpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkv007</pub-id>
      </element-citation>
    </ref>
    <ref id="CR21">
      <label>21</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Rohart</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Gautier</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Singh</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Lê Cao</surname>
            <given-names>K-A</given-names>
          </name>
        </person-group>
        <article-title>mixomics: An r package for ’omics feature selection and multiple data integration</article-title>
        <source>PLoS Comput Biol</source>
        <year>2017</year>
        <volume>13</volume>
        <issue>11</issue>
        <fpage>1005752</fpage>
        <pub-id pub-id-type="doi">10.1371/journal.pcbi.1005752</pub-id>
      </element-citation>
    </ref>
    <ref id="CR22">
      <label>22</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Khan</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Wei</surname>
            <given-names>JS</given-names>
          </name>
          <name>
            <surname>Ringner</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Saal</surname>
            <given-names>LH</given-names>
          </name>
          <name>
            <surname>Ladanyi</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Westermann</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Berthold</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Schwab</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Antonescu</surname>
            <given-names>CR</given-names>
          </name>
          <name>
            <surname>Peterson</surname>
            <given-names>C</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Classification and diagnostic prediction of cancers using gene expression profiling and artificial neural networks</article-title>
        <source>Nat Med</source>
        <year>2001</year>
        <volume>7</volume>
        <issue>6</issue>
        <fpage>673</fpage>
        <pub-id pub-id-type="doi">10.1038/89044</pub-id>
        <pub-id pub-id-type="pmid">11385503</pub-id>
      </element-citation>
    </ref>
    <ref id="CR23">
      <label>23</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lê</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Josse</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Husson</surname>
            <given-names>F</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Factominer: an r package for multivariate analysis</article-title>
        <source>J Stat Softw</source>
        <year>2008</year>
        <volume>25</volume>
        <issue>1</issue>
        <fpage>1</fpage>
        <lpage>18</lpage>
        <pub-id pub-id-type="doi">10.18637/jss.v025.i01</pub-id>
      </element-citation>
    </ref>
    <ref id="CR24">
      <label>24</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Marchini</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Heaton</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Ripley</surname>
            <given-names>B</given-names>
          </name>
        </person-group>
        <article-title>fastica: Fastica algorithms to perform ica and projection pursuit</article-title>
        <source>R Packag Vers</source>
        <year>2013</year>
        <volume>1</volume>
        <issue>0</issue>
        <fpage>1</fpage>
      </element-citation>
    </ref>
    <ref id="CR25">
      <label>25</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Troyanskaya</surname>
            <given-names>O</given-names>
          </name>
          <name>
            <surname>Cantor</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Sherlock</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Brown</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Hastie</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Tibshirani</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Botstein</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Altman</surname>
            <given-names>RB</given-names>
          </name>
        </person-group>
        <article-title>Missing value estimation methods for dna microarrays</article-title>
        <source>Bioinformatics</source>
        <year>2001</year>
        <volume>17</volume>
        <issue>6</issue>
        <fpage>520</fpage>
        <lpage>5</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/17.6.520</pub-id>
        <pub-id pub-id-type="pmid">11395428</pub-id>
      </element-citation>
    </ref>
    <ref id="CR26">
      <label>26</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Rousseeuw</surname>
            <given-names>PJ</given-names>
          </name>
        </person-group>
        <article-title>Silhouettes: a graphical aid to the interpretation and validation of cluster analysis</article-title>
        <source>J Comput Appl Math</source>
        <year>1987</year>
        <volume>20</volume>
        <fpage>53</fpage>
        <lpage>65</lpage>
        <pub-id pub-id-type="doi">10.1016/0377-0427(87)90125-7</pub-id>
      </element-citation>
    </ref>
    <ref id="CR27">
      <label>27</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Rand</surname>
            <given-names>WM</given-names>
          </name>
        </person-group>
        <article-title>Objective criteria for the evaluation of clustering methods</article-title>
        <source>J Am Stat Assoc</source>
        <year>1971</year>
        <volume>66</volume>
        <issue>336</issue>
        <fpage>846</fpage>
        <lpage>50</lpage>
        <pub-id pub-id-type="doi">10.1080/01621459.1971.10482356</pub-id>
      </element-citation>
    </ref>
    <ref id="CR28">
      <label>28</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lin</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Xu</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Deng</surname>
            <given-names>H-W</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>Y-P</given-names>
          </name>
        </person-group>
        <article-title>An integrative imputation method based on multi-omics datasets</article-title>
        <source>BMC Bioinformatics</source>
        <year>2016</year>
        <volume>17</volume>
        <issue>1</issue>
        <fpage>247</fpage>
        <pub-id pub-id-type="doi">10.1186/s12859-016-1122-6</pub-id>
        <pub-id pub-id-type="pmid">27329642</pub-id>
      </element-citation>
    </ref>
  </ref-list>
</back>
