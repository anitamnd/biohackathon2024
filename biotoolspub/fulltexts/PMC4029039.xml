<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//NLM//DTD Journal Publishing DTD v2.3 20070202//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName journalpublishing.dtd?>
<?SourceDTD.Version 2.3?>
<?ConverterInfo.XSLTName jp2nlmx2.xsl?>
<?ConverterInfo.Version 2?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id>
    <journal-id journal-id-type="publisher-id">bioinformatics</journal-id>
    <journal-id journal-id-type="hwp">bioinfo</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1367-4803</issn>
    <issn pub-type="epub">1367-4811</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">4029039</article-id>
    <article-id pub-id-type="doi">10.1093/bioinformatics/btu080</article-id>
    <article-id pub-id-type="publisher-id">btu080</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Original Papers</subject>
        <subj-group subj-group-type="heading">
          <subject>Bioimage Informatics</subject>
        </subj-group>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>A benchmark for comparison of cell tracking algorithms</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Maška</surname>
          <given-names>Martin</given-names>
        </name>
        <xref ref-type="aff" rid="btu080-AFF1">
          <sup>1</sup>
        </xref>
        <xref ref-type="aff" rid="btu080-AFF1">
          <sup>2</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Ulman</surname>
          <given-names>Vladimír</given-names>
        </name>
        <xref ref-type="aff" rid="btu080-AFF1">
          <sup>1</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Svoboda</surname>
          <given-names>David</given-names>
        </name>
        <xref ref-type="aff" rid="btu080-AFF1">
          <sup>1</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Matula</surname>
          <given-names>Pavel</given-names>
        </name>
        <xref ref-type="aff" rid="btu080-AFF1">
          <sup>1</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Matula</surname>
          <given-names>Petr</given-names>
        </name>
        <xref ref-type="aff" rid="btu080-AFF1">
          <sup>1</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Ederra</surname>
          <given-names>Cristina</given-names>
        </name>
        <xref ref-type="aff" rid="btu080-AFF1">
          <sup>2</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Urbiola</surname>
          <given-names>Ainhoa</given-names>
        </name>
        <xref ref-type="aff" rid="btu080-AFF1">
          <sup>2</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>España</surname>
          <given-names>Tomás</given-names>
        </name>
        <xref ref-type="aff" rid="btu080-AFF1">
          <sup>2</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Venkatesan</surname>
          <given-names>Subramanian</given-names>
        </name>
        <xref ref-type="aff" rid="btu080-AFF1">
          <sup>3</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Balak</surname>
          <given-names>Deepak M.W.</given-names>
        </name>
        <xref ref-type="aff" rid="btu080-AFF1">
          <sup>3</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Karas</surname>
          <given-names>Pavel</given-names>
        </name>
        <xref ref-type="aff" rid="btu080-AFF1">
          <sup>1</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Bolcková</surname>
          <given-names>Tereza</given-names>
        </name>
        <xref ref-type="aff" rid="btu080-AFF1">
          <sup>1</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Štreitová</surname>
          <given-names>Markéta</given-names>
        </name>
        <xref ref-type="aff" rid="btu080-AFF1">
          <sup>1</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Carthel</surname>
          <given-names>Craig</given-names>
        </name>
        <xref ref-type="aff" rid="btu080-AFF1">
          <sup>4</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Coraluppi</surname>
          <given-names>Stefano</given-names>
        </name>
        <xref ref-type="aff" rid="btu080-AFF1">
          <sup>4</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Harder</surname>
          <given-names>Nathalie</given-names>
        </name>
        <xref ref-type="aff" rid="btu080-AFF1">
          <sup>5</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Rohr</surname>
          <given-names>Karl</given-names>
        </name>
        <xref ref-type="aff" rid="btu080-AFF1">
          <sup>5</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Magnusson</surname>
          <given-names>Klas E. G.</given-names>
        </name>
        <xref ref-type="aff" rid="btu080-AFF1">
          <sup>6</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Jaldén</surname>
          <given-names>Joakim</given-names>
        </name>
        <xref ref-type="aff" rid="btu080-AFF1">
          <sup>6</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Blau</surname>
          <given-names>Helen M.</given-names>
        </name>
        <xref ref-type="aff" rid="btu080-AFF1">
          <sup>7</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Dzyubachyk</surname>
          <given-names>Oleh</given-names>
        </name>
        <xref ref-type="aff" rid="btu080-AFF1">
          <sup>8</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Křížek</surname>
          <given-names>Pavel</given-names>
        </name>
        <xref ref-type="aff" rid="btu080-AFF1">
          <sup>9</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Hagen</surname>
          <given-names>Guy M.</given-names>
        </name>
        <xref ref-type="aff" rid="btu080-AFF1">
          <sup>9</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Pastor-Escuredo</surname>
          <given-names>David</given-names>
        </name>
        <xref ref-type="aff" rid="btu080-AFF1">
          <sup>10</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Jimenez-Carretero</surname>
          <given-names>Daniel</given-names>
        </name>
        <xref ref-type="aff" rid="btu080-AFF1">
          <sup>10</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Ledesma-Carbayo</surname>
          <given-names>Maria J.</given-names>
        </name>
        <xref ref-type="aff" rid="btu080-AFF1">
          <sup>10</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Muñoz-Barrutia</surname>
          <given-names>Arrate</given-names>
        </name>
        <xref ref-type="aff" rid="btu080-AFF1">
          <sup>2</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Meijering</surname>
          <given-names>Erik</given-names>
        </name>
        <xref ref-type="aff" rid="btu080-AFF1">
          <sup>3</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Kozubek</surname>
          <given-names>Michal</given-names>
        </name>
        <xref ref-type="aff" rid="btu080-AFF1">
          <sup>1</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Ortiz-de-Solorzano</surname>
          <given-names>Carlos</given-names>
        </name>
        <xref ref-type="aff" rid="btu080-AFF1">
          <sup>2</sup>
        </xref>
        <xref ref-type="corresp" rid="btu080-COR1">*</xref>
      </contrib>
      <aff id="btu080-AFF1"><sup>1</sup>Center for Biomedical Image Analysis, Masaryk University, 602 00 Brno, Czech Republic, <sup>2</sup>Cancer Imaging Laboratory, Oncology Division, Center for Applied Medical Research, University of Navarra, 31008 Pamplona, Spain, <sup>3</sup>Biomedical Imaging Group Rotterdam, Erasmus University Medical Center, 3015 GE Rotterdam, The Netherlands, <sup>4</sup>Fusion Technology and Systems Department, Compunetix Inc., Monroeville, PA 15146, USA, <sup>5</sup>Biomedical Computer Vision Group, Department of Bioinformatics and Functional Genomics, University of Heidelberg, BIOQUANT, IPMB and DKFZ, 69120 Heidelberg, Germany, <sup>6</sup>KTH Royal Institute of Technology, ACCESS Linnaeus Center, Department of Signal Processing, 100 44 Stockholm, Sweden, <sup>7</sup>Baxter Laboratory for Stem Cell Biology, Department of Microbiology and Immunology, Institute for Stem Cell Biology and Regenerative Medicine, Stanford University School of Medicine, Stanford, CA 94305, USA, <sup>8</sup>Division of Image Processing, Leiden University Medical Center, 2300 RC Leiden, The Netherlands, <sup>9</sup>Institute of Cellular Biology and Pathology, First Faculty of Medicine, Charles University in Prague, 12801 Prague 2, Czech Republic and <sup>10</sup>Biomedical Image Technologies, Universidad Politécnica de Madrid &amp; CIBER BBN, 28040 Madrid, Spain</aff>
    </contrib-group>
    <author-notes>
      <corresp id="btu080-COR1">*To whom correspondence should be addressed.</corresp>
      <fn>
        <p>Associate Editor: Jonathan Wren</p>
      </fn>
    </author-notes>
    <pub-date pub-type="ppub">
      <day>1</day>
      <month>6</month>
      <year>2014</year>
    </pub-date>
    <pub-date pub-type="epub">
      <day>12</day>
      <month>2</month>
      <year>2014</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>12</day>
      <month>2</month>
      <year>2014</year>
    </pub-date>
    <!-- PMC Release delay is 0 months and 0 days and was based on the
							<pub-date pub-type="epub"/>. -->
    <volume>30</volume>
    <issue>11</issue>
    <fpage>1609</fpage>
    <lpage>1617</lpage>
    <history>
      <date date-type="received">
        <day>29</day>
        <month>8</month>
        <year>2013</year>
      </date>
      <date date-type="rev-recd">
        <day>15</day>
        <month>1</month>
        <year>2014</year>
      </date>
      <date date-type="accepted">
        <day>31</day>
        <month>1</month>
        <year>2014</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author 2014. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2014</copyright-year>
      <license license-type="creative-commons" xlink:href="http://creativecommons.org/licenses/by-nc/3.0">
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by-nc/3.0/">http://creativecommons.org/licenses/by-nc/3.0/</ext-link>), which permits non-commercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited. For commercial re-use, please contact journals.permissions@oup.com</license-p>
      </license>
    </permissions>
    <abstract>
      <p><bold>Motivation:</bold> Automatic tracking of cells in multidimensional time-lapse fluorescence microscopy is an important task in many biomedical applications. A novel framework for objective evaluation of cell tracking algorithms has been established under the auspices of the IEEE International Symposium on Biomedical Imaging 2013 Cell Tracking Challenge. In this article, we present the logistics, datasets, methods and results of the challenge and lay down the principles for future uses of this benchmark.</p>
      <p><bold>Results:</bold> The main contributions of the challenge include the creation of a comprehensive video dataset repository and the definition of objective measures for comparison and ranking of the algorithms. With this benchmark, six algorithms covering a variety of segmentation and tracking paradigms have been compared and ranked based on their performance on both synthetic and real datasets. Given the diversity of the datasets, we do not declare a single winner of the challenge. Instead, we present and discuss the results for each individual dataset separately.</p>
      <p><bold>Availability and implementation:</bold> The challenge Web site (<ext-link ext-link-type="uri" xlink:href="http://www.codesolorzano.com/celltrackingchallenge">http://www.codesolorzano.com/celltrackingchallenge</ext-link>) provides access to the training and competition datasets, along with the ground truth of the training videos. It also provides access to Windows and Linux executable files of the evaluation software and most of the algorithms that competed in the challenge.</p>
      <p>
        <bold>Contact:</bold>
        <email>codesolorzano@unav.es</email>
      </p>
      <p><bold>Supplementary information:</bold><ext-link ext-link-type="uri" xlink:href="http://bioinformatics.oxfordjournals.org/lookup/suppl/doi:10.1093/bioinformatics/btu080/-/DC1">Supplementary data</ext-link> are available at <italic>Bioinformatics</italic> online.</p>
    </abstract>
    <counts>
      <page-count count="9"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 INTRODUCTION</title>
    <p>Cell migration is an essential process in normal tissue development, tissue repair and disease (<xref rid="btu080-B12" ref-type="bibr">Friedl and Gilmour, 2009</xref>). The dynamics of cell movement (e.g. speed, directionality) and migration type (i.e. the morphological changes that the cell undergoes during the movement) are closely related to the biomechanical properties of the surrounding environment (<xref rid="btu080-B11" ref-type="bibr">Friedl and Alexander, 2011</xref>). Therefore, accurate quantification of both is the key to understanding the complex mechanobiology of cell migration.</p>
    <p>Traditionally, cell migration experiments have been performed in two dimensions (2D) using phase or differential interference contrast microscopy. Nowadays, it is increasingly acknowledged that proper evaluation of the cellular movement, as well as related forces, requires looking at the cells in their three-dimensional (3D) tissue environment (<xref rid="btu080-B16" ref-type="bibr">Legant <italic>et al.</italic>, 2010</xref>). This can be done by taking advantage of the versatility of fluorescence labeling and the optical sectioning capability of multidimensional fluorescence <italic>in vivo</italic> microscopy (<xref rid="btu080-B9" ref-type="bibr">Fernandez-Gonzalez <italic>et al.</italic>, 2006</xref>). Fluorescence microscopy has several advantages (e.g. multidimensionality, specificity). However, tracking fluorescent cells poses specific challenges compared with more traditional phase contrast enhancing techniques: non-homogenous staining, low signal-to-noise ratio, uneven background illumination, photobleaching, phototoxicity, etc. Moreover, an important challenge, specific to the use of green fluorescent protein (GFP) transfection-based staining, is the cell-to-cell intensity variability caused by differential transfection efficiency. Therefore, tracking of fluorescent cells requires specialized tools.</p>
    <p>Several methods have been described for the segmentation of cells in static 3D fluorescence microscopy images (<xref rid="btu080-B14" ref-type="bibr">Indhumathi <italic>et al.</italic>, 2011</xref>; <xref rid="btu080-B19" ref-type="bibr">Lin <italic>et al.</italic>, 2005</xref>; <xref rid="btu080-B20" ref-type="bibr">Long <italic>et al.</italic>, 2007</xref>; <xref rid="btu080-B24" ref-type="bibr">Ortiz-de-Solorzano <italic>et al.</italic>, 1999</xref>). These methods have been extended to account for the temporal variable in multidimensional time-lapse microscopy, combining accurate segmentation of the cells with proper tracking of their movements and lineage events (e.g. apoptosis, mitosis, cell merging and overlapping). They can be classified into two broad categories: <italic>tracking by detection</italic> and <italic>tracking by model evolution</italic> (<xref rid="btu080-B23" ref-type="bibr">Meijering <italic>et al.</italic>, 2009</xref>; <xref rid="btu080-B27" ref-type="bibr">Rohr <italic>et al.</italic>, 2010</xref>; <xref rid="btu080-B31" ref-type="bibr">Zimmer <italic>et al.</italic>, 2006</xref>). In the former paradigm, cells are first detected in all the frames of the video independently using gradient features (<xref rid="btu080-B1" ref-type="bibr">Al-Kofahi <italic>et al.</italic>, 2006</xref>), intensity (<xref rid="btu080-B18" ref-type="bibr">Li <italic>et al.</italic>, 2010</xref>) or wavelet decomposition (<xref rid="btu080-B25" ref-type="bibr">Padfield <italic>et al.</italic>, 2011</xref>). Subsequently, an optimization strategy, such as multiple-hypothesis tracking (<xref rid="btu080-B4" ref-type="bibr">Chenouard <italic>et al.</italic>, 2013</xref>), integer programming (<xref rid="btu080-B18" ref-type="bibr">Li <italic>et al.</italic>, 2010</xref>), dynamic programming (<xref rid="btu080-B21" ref-type="bibr">Magnusson and Jaldén, 2012</xref>) or coupled minimum-cost flow tracking (<xref rid="btu080-B25" ref-type="bibr">Padfield <italic>et al.</italic>, 2011</xref>), is used to determine the most likely cell correspondence between frames. In the latter paradigm, cells are segmented and tracked simultaneously, using the final result of each frame as the initial condition for the analysis of the following frame. This is mostly done by evolving the contours of the cells, represented either parametrically (<xref rid="btu080-B7" ref-type="bibr">Dufour <italic>et al.</italic>, 2011</xref>; <xref rid="btu080-B30" ref-type="bibr">Zimmer <italic>et al.</italic>, 2002</xref>) or implicitly (<xref rid="btu080-B6" ref-type="bibr">Dufour <italic>et al.</italic>, 2005</xref>; <xref rid="btu080-B8" ref-type="bibr">Dzyubachyk <italic>et al.</italic>, 2010</xref>; <xref rid="btu080-B17" ref-type="bibr">Li <italic>et al.</italic>, 2008</xref>; <xref rid="btu080-B22" ref-type="bibr">Maška <italic>et al.</italic>, 2013</xref>), using a velocity term defined by the content of the “target” frame (e.g. gradient features or intra- and inter-region heterogeneity) and by the internal properties of the evolved contours (e.g. mean curvature, shape or topology). The main benefit of the first paradigm is the mutual independence of detection and association steps, which allows straightforward tracking of new cells entering the field of view as well as forward-backward spatiotemporal data association (<xref rid="btu080-B2" ref-type="bibr">Bise <italic>et al.</italic>, 2011</xref>). On the contrary, the tracking by model evolution approaches is popular for easy accommodation of morphological and behavioral clues into the model to inherently deal with the topologically flexible behavior of live cells. Bridging both paradigms together to take advantage of their benefits, <xref rid="btu080-B17" ref-type="bibr">Li <italic>et al.</italic> (2008)</xref> proposed a complex cell tracking system that combines a fast level set framework with a local spatiotemporal data association step.</p>
    <p>The tracking methods described until this date have been tested in one or few private datasets using different metrics and have seldom been compared against other algorithms. A noteworthy attempt toward a formalization of the evaluation of cell tracking algorithms was described by <xref rid="btu080-B15" ref-type="bibr">Kan <italic>et al.</italic> (2011)</xref>. They compared a novel cell tracking strategy to a publicly available probabilistic tracker using a customized tracking measurement and mostly publicly available data. Similarly, <xref rid="btu080-B26" ref-type="bibr">Rapoport <italic>et al.</italic> (2011)</xref> partly addressed this issue by providing a method for the validation of the accuracy of cell tracking results and a dataset composed of two manually annotated brightfield microscopy videos. Finally, two recent studies (<xref rid="btu080-B5" ref-type="bibr">Dima <italic>et al.</italic>, 2011</xref>; <xref rid="btu080-B13" ref-type="bibr">Held <italic>et al.</italic>, 2011</xref>) presented two rigorous comparisons of algorithms developed for the segmentation of fluorescently labeled cells from static 2D images, using their own image repositories and adapted accuracy measures.</p>
    <p>The limitations of these studies, such as being monomodality, using 2D or static images, one or two cell types only, or comparing with none or few competing algorithms, highlight the need for common standards to evaluate new and existing algorithms. Bearing this in mind, we organized the first Cell Tracking Challenge (<ext-link ext-link-type="uri" xlink:href="http://www.codesolorzano.com/celltrackingchallenge">http://www.codesolorzano.com/celltrackingchallenge</ext-link>) hosted by the 2013 IEEE International Symposium on Biomedical Imaging (ISBI 2013, <ext-link ext-link-type="uri" xlink:href="http://www.biomedicalimaging.org/2013/">http://www.biomedicalimaging.org/2013/</ext-link>). In this article, we present the methods used in the challenge, briefly describe the competing algorithms and report on the results of the comparison, which was based on common accuracy measures and datasets covering a wide variety of scenarios of live cell imaging in fluorescence microscopy.</p>
  </sec>
  <sec>
    <title>2 METHODS</title>
    <sec id="SEC2.1">
      <title>2.1 Logistics</title>
      <p>The challenge was organized by members of three research institutions: Center for Biomedical Image Analysis, Masaryk University, Brno, Czech Republic (<bold>CBIA-CZ</bold>); Center for Applied Medical Research, University of Navarra, Pamplona, Spain (<bold>CIMA-ES</bold>); and Erasmus University Medical Center, Rotterdam, The Netherlands (<bold>ERASMUS-NL</bold>). The challenge, announced via various media including targeted emails, mailing lists and the ISBI 2013 Web site, was opened for registration through the challenge Web site. Four weeks after opening the challenge for registration, all registered participants were given individual access to the challenge FTP server, where they could download the training datasets, along with the ground truth, and self-evaluation software. The registered participants worked on the training datasets during the 4 weeks before the competition datasets were released. The participants were then given six additional weeks to submit their results and the algorithms used to produce them. After the deadline, the consistency and the compliance of the submissions were verified by the organizers before the presentation of the preliminary results at ISBI 2013. After the ISBI 2013 workshop, the organizing committee confirmed the accuracy of the submitted results and compiled the final rankings presented in this article.</p>
    </sec>
    <sec id="SEC2.2">
      <title>2.2 Datasets</title>
      <p>Forty-eight time-lapse sequences used in the challenge were evenly distributed between the training and competition phases. Each group of 24 videos consisted of 12 real microscopy time-lapse sequences and 12 computer-simulated videos, 6 2D and 6 3D, with various cell densities and noise levels. The acquisition setup for each dataset is listed in <xref ref-type="table" rid="btu080-T1">Table 1</xref>, and representative regions of each dataset are displayed in <xref ref-type="fig" rid="btu080-F1">Figure 1</xref>. Representative sample videos can also be found as <ext-link ext-link-type="uri" xlink:href="http://bioinformatics.oxfordjournals.org/lookup/suppl/doi:10.1093/bioinformatics/btu080/-/DC1">Supplementary Videos S1–S8</ext-link>. The complete raw data are available at the challenge Web site. The datasets were named using the following convention: a four-letter prefix (LNDR) identifies the labeling (L) method -cytoplasmic (C) or nuclear (N); the dimensionality (ND) -2D or 3D; and the resolution (R) -low (L) or high (H). The suffix, separated by a hyphen from the prefix, describes the cell line.
<fig id="btu080-F1" position="float"><label>Fig. 1.</label><caption><p>Representative regions from the video dataset repository. (<bold>A</bold>) <bold>C2DL-MSC</bold>; (<bold>B</bold>) <bold>C3DH-H157</bold> (selected z-slice); (<bold>C</bold>) <bold>C3DL-MDA231</bold> (selected z-slice); (<bold>D</bold>) <bold>N2DH-GOWT1</bold>; (<bold>E</bold>) <bold>N2DL-HeLa</bold>; (<bold>F</bold>) <bold>N3DH-CHO</bold> (selected z-slice); (<bold>G</bold>) <bold>N2DH-SIM</bold> (also representative of a selected z-slice of <bold>N3DH-SIM</bold>)</p></caption><graphic xlink:href="btu080f1p"/></fig>
<table-wrap id="btu080-T1" position="float"><label>Table 1.</label><caption><p>Acquisition parameters and properties of the datasets</p></caption><table frame="hsides" rules="groups"><thead align="left"><tr><th rowspan="1" colspan="1">Name</th><th rowspan="1" colspan="1">Objective lens/Numerical aperture</th><th rowspan="1" colspan="1">Frame size (grid points)</th><th rowspan="1" colspan="1">Voxel size (µm)</th><th rowspan="1" colspan="1">Time step (min)</th><th rowspan="1" colspan="1">Number of frames</th><th rowspan="1" colspan="1">Difficulty</th></tr></thead><tbody align="left"><tr><td rowspan="1" colspan="1">C2DL-MSC</td><td rowspan="1" colspan="1">20× Plan-apochromat/0.75</td><td rowspan="1" colspan="1">992 × 832 (1200 × 782)</td><td rowspan="1" colspan="1">0.397 × 0.397</td><td rowspan="1" colspan="1">20 (30)</td><td rowspan="1" colspan="1">48</td><td rowspan="1" colspan="1">High</td></tr><tr><td rowspan="1" colspan="1">C3DH-H157</td><td rowspan="1" colspan="1">63× Plan-apochromat/1.2 water</td><td rowspan="1" colspan="1">992 × 832 × 35 (80)</td><td rowspan="1" colspan="1">0.126 × 0.126 × 0.5</td><td rowspan="1" colspan="1">1 (2)</td><td rowspan="1" colspan="1">60</td><td rowspan="1" colspan="1">Low</td></tr><tr><td rowspan="1" colspan="1">C3DL-MDA231</td><td rowspan="1" colspan="1">20× Plan/0.7</td><td rowspan="1" colspan="1">512 × 512 × 30</td><td rowspan="1" colspan="1">1.242 × 1.242 × 6.0</td><td rowspan="1" colspan="1">80</td><td rowspan="1" colspan="1">12</td><td rowspan="1" colspan="1">Very High</td></tr><tr><td rowspan="1" colspan="1">N2DH-GOWT1</td><td rowspan="1" colspan="1">63× Plan-apochromat/1.4 oil</td><td rowspan="1" colspan="1">1024 × 1024</td><td rowspan="1" colspan="1">0.240 × 0.240</td><td rowspan="1" colspan="1">5</td><td rowspan="1" colspan="1">92</td><td rowspan="1" colspan="1">Medium</td></tr><tr><td rowspan="1" colspan="1">N2DL-HeLa</td><td rowspan="1" colspan="1">10× Plan/0.4</td><td rowspan="1" colspan="1">1100 × 700</td><td rowspan="1" colspan="1">0.644 × 0.644</td><td rowspan="1" colspan="1">30</td><td rowspan="1" colspan="1">92</td><td rowspan="1" colspan="1">High</td></tr><tr><td rowspan="1" colspan="1">N3DH-CHO</td><td rowspan="1" colspan="1">63× Plan-apochromat/1.4 oil</td><td rowspan="1" colspan="1">512 × 443 × 5</td><td rowspan="1" colspan="1">0.202 × 0.202 × 1.0</td><td rowspan="1" colspan="1">9.5</td><td rowspan="1" colspan="1">92</td><td rowspan="1" colspan="1">Medium</td></tr><tr><td rowspan="1" colspan="1">N2DH-SIM</td><td rowspan="1" colspan="1">40× Plan-apochromat/1.3 oil</td><td rowspan="1" colspan="1">505–755 × 535–775</td><td rowspan="1" colspan="1">0.125 × 0.125</td><td rowspan="1" colspan="1">28.8 (57.6)</td><td rowspan="1" colspan="1">56–100</td><td rowspan="1" colspan="1">Medium</td></tr><tr><td rowspan="1" colspan="1">N3DH-SIM</td><td rowspan="1" colspan="1">40× Plan-apochromat/1.3 oil</td><td rowspan="1" colspan="1">520–755 × 520–730 × 49 (60)</td><td rowspan="1" colspan="1">0.125 × 0.125 × 0.2</td><td rowspan="1" colspan="1">28.8 (57.6)</td><td rowspan="1" colspan="1">56–100</td><td rowspan="1" colspan="1">Medium</td></tr></tbody></table><table-wrap-foot><fn id="btu080-TF1"><p><italic>Note</italic>: The numbers in parentheses indicate particular values for the second half of a given dataset.</p></fn></table-wrap-foot></table-wrap></p>
      <sec id="SEC2.2.1">
        <title>2.2.1 Real videos</title>
        <p>The real video repository consists of six datasets.</p>
        <p><bold>C2DL-MSC</bold> (<xref ref-type="fig" rid="btu080-F1">Fig. 1</xref>A and <ext-link ext-link-type="uri" xlink:href="http://bioinformatics.oxfordjournals.org/lookup/suppl/doi:10.1093/bioinformatics/btu080/-/DC1">Supplementary Video S1</ext-link>). GFP transfected rat mesenchymal stems cells on a flat polyacrylamide substrate, acquired using a Perkin Elmer UltraVIEW ERS spinning disk confocal microscope (courtesy of Dr F. Prósper, <bold>CIMA-ES</bold>). The difficulty of the dataset is high because of the low signal-to-noise ratio and the presence of filament-like protruding areas caused by cell stretching, which sometimes appear as discontinuous extensions of the cells. Further complicating the analysis of the scenes, these protrusions often come in contact with other cells.</p>
        <p><bold>C3DH-H157</bold> (<xref ref-type="fig" rid="btu080-F1">Fig. 1</xref>B and <ext-link ext-link-type="uri" xlink:href="http://bioinformatics.oxfordjournals.org/lookup/suppl/doi:10.1093/bioinformatics/btu080/-/DC1">Supplementary Video S2</ext-link>). GFP transfected H157 human squamous lung carcinoma cells embedded in a 3D matrigel matrix, acquired using a Perkin Elmer UltraVIEW ERS spinning disk confocal microscope (courtesy of Dr A. Rouzaut, <bold>CIMA-ES</bold>). The difficulty of the dataset is low because of low cell density and high resolution. However, the presence of cell blebbing and cells entering and leaving the field of view impose a certain degree of complexity for segmentation and tracking.</p>
        <p><bold>C3DL-MDA231</bold> (<xref ref-type="fig" rid="btu080-F1">Fig. 1</xref>C and <ext-link ext-link-type="uri" xlink:href="http://bioinformatics.oxfordjournals.org/lookup/suppl/doi:10.1093/bioinformatics/btu080/-/DC1">Supplementary Video S3</ext-link>). MDA231 human breast carcinoma cells infected with a pure Murine Stem Cell Virus (pMSCV) vector including GFP. The cells were embedded in a 3D collagen matrix and acquired using an Olympus FluoView F1000 laser scanning confocal microscope (courtesy of Prof R. Kamm, Massachusetts Institute of Technology, Cambridge, MA, USA). The difficulty of the dataset is high because it was acquired under high-throughput conditions (i.e. low signal-to-noise ratio, low resolution, especially in the axial direction, and large time step). Moreover, there are a high number of colliding elongated cells as well as cells entering and leaving the field of view.</p>
        <p><bold>N2DH-GOWT1</bold> (<xref ref-type="fig" rid="btu080-F1">Fig. 1</xref>D and <ext-link ext-link-type="uri" xlink:href="http://bioinformatics.oxfordjournals.org/lookup/suppl/doi:10.1093/bioinformatics/btu080/-/DC1">Supplementary Video S4</ext-link>). GFP transfected GOWT1 mouse embryonic stem cells on a flat substrate, acquired using a Leica TCS SP5 laser scanning confocal microscope (courtesy of Dr E. Bártová, Academy of Sciences of the Czech Republic, Brno, Czech Republic). The difficulty of the dataset is considered medium because of heterogeneous staining, prominent nucleoli, mitoses, cells entering and leaving the field of view and frequent cell collisions.</p>
        <p><bold>N2DL-HeLa</bold> (<xref ref-type="fig" rid="btu080-F1">Fig. 1</xref>E and <ext-link ext-link-type="uri" xlink:href="http://bioinformatics.oxfordjournals.org/lookup/suppl/doi:10.1093/bioinformatics/btu080/-/DC1">Supplementary Video S5</ext-link>). Histone 2B (H2B)-GFP expressing HeLa cells on a flat substrate, acquired using an Olympus IX81 inverted epifluorescence microscope. The videos were obtained with permission from the Mitocheck consortium video repository (<ext-link ext-link-type="uri" xlink:href="http://www.mitocheck.org">http://www.mitocheck.org</ext-link>). The difficulty of the dataset is classified as high because of the high cell density and low resolution. In particular, the videos display frequent mitoses, both normal and abnormal, in addition to the presence of colliding, entering and leaving cells with low fluorescence intensity.</p>
        <p><bold>N3DH-CHO</bold> (<xref ref-type="fig" rid="btu080-F1">Fig. 1</xref>F and <ext-link ext-link-type="uri" xlink:href="http://bioinformatics.oxfordjournals.org/lookup/suppl/doi:10.1093/bioinformatics/btu080/-/DC1">Supplementary Video S6</ext-link>). Chinese hamster ovarian cells overexpressing proliferating cell nuclear antigen tagged with GFP, acquired using a Zeiss LSM 510 laser scanning confocal microscope (courtesy of Dr J. Essers, <bold>ERASMUS-NL</bold>). The dataset is considered of medium difficulty because of nuclei with heterogeneous staining, the presence of prominent nucleoli, mitotic cells with unstained nuclear periods, colliding cells and cells entering and leaving the field of view.</p>
      </sec>
      <sec id="SEC2.2.2">
        <title>2.2.2 Simulated videos</title>
        <p>The synthetic image data, along with the inherent ground truth, were generated using a simulation toolkit based on our previous work in <bold>CBIA-CZ</bold> (<xref rid="btu080-B29" ref-type="bibr">Svoboda and Ulman, 2012</xref>; <xref rid="btu080-B28" ref-type="bibr">Svoboda <italic>et al.</italic>, 2009</xref>). As this challenge was dedicated to cell tracking, special attention was paid to the accuracy of cell movement during the cell cycle and to the mitotic events. The simulated videos displayed fluorescently labeled nuclei of the HL60 cell line migrating on a flat 2D surface (<bold>N2DH-SIM</bold>) and in a 3D matrix (<bold>N3DH-SIM</bold>) (<xref ref-type="fig" rid="btu080-F1">Fig. 1</xref>G and <ext-link ext-link-type="uri" xlink:href="http://bioinformatics.oxfordjournals.org/lookup/suppl/doi:10.1093/bioinformatics/btu080/-/DC1">Supplementary Videos S7</ext-link> and <ext-link ext-link-type="uri" xlink:href="http://bioinformatics.oxfordjournals.org/lookup/suppl/doi:10.1093/bioinformatics/btu080/-/DC1">S8</ext-link>). They differ in the level of noise, cell density of the initial population, the number of cells leaving and entering the field of view and the number of simulated mitotic events, yielding up to 70 cells in the field of view. Therefore, both datasets are considered of medium difficulty.</p>
      </sec>
    </sec>
    <sec id="SEC2.3">
      <title>2.3 Ground truth generation for real datasets</title>
      <p>One expert from <bold>CIMA-ES</bold> annotated all the real datasets used in the training phase. For the competition phase, all real videos were manually annotated by three experts from three sites (<bold>CBIA-CZ, CIMA-ES</bold> and <bold>ERASMUS-NL</bold>). Each expert created ground truth for tracking (<bold>TRA-GT</bold>) and ground truth for segmentation (<bold>SEG-GT</bold>) for each video. Each pair of <bold>SEG-GT</bold> and <bold>TRA-GT</bold> was manually revised by its creator to correct for automatically detected inconsistencies of two types: a segmentation mask either overlapping with multiple tracking markers or without any complete tracking marker. Finally, to account for inter-subject variability, two final ground truths (<bold>SEG-GT-F</bold> and <bold>TRA-GT-F</bold>) were created by combining the three existing ground truths, using a majority-voting scheme, as suggested, for instance, by <xref rid="btu080-B10" ref-type="bibr">Foggia <italic>et al.</italic> (2013)</xref>. The way the majority voting was performed is described in detail in the <ext-link ext-link-type="uri" xlink:href="http://bioinformatics.oxfordjournals.org/lookup/suppl/doi:10.1093/bioinformatics/btu080/-/DC1">Supplementary Note</ext-link>.</p>
      <sec id="SEC2.3.1">
        <title>2.3.1 Field of interest</title>
        <p>To simplify dealing with incomplete objects, entering or leaving the image frame, only objects that had substantially advanced into the image frame were analyzed. This is equivalent to defining a virtual inner field of interest (<bold>FoI</bold>) and analyzing only those objects that are at least partially inside the <bold>FoI</bold>. The distance in grid points (pixels or voxels) between the image frame border and the <bold>FoI</bold> border varied between datasets depending on the size of the objects of interest (50 grid points in <bold>C2DL-MSC</bold>, <bold>C3DH-H157</bold>, <bold>N2DH-GOWT1</bold> and <bold>N3DH-CHO</bold>; 25 grid points in <bold>C3DL-MDA231</bold> and <bold>N2DL-HeLa</bold>).</p>
      </sec>
      <sec id="SEC2.3.2">
        <title>2.3.2 Ground truth for segmentation</title>
        <p>The task for annotators was to mark grid points belonging to cells as accurately as possible. Therefore, each cell was segmented as a set of grid points with the same unique label. The length of the videos and the high number of cells per frame in some of the datasets prevented from having a complete manual annotation of all the cells. Therefore, we first randomly permutated all the frames of each video to unbiasedly select the cells that were used as ground truth. In the 3D videos, we also randomly selected at least one of its 2D z-slices, excluding empty slices. Then, the annotators were asked to segment all the cells within each frame in the given random order until at least 100 cells were segmented and two frames were fully segmented. The segmentation masks were drawn in the entire image frame and not just in the <bold>FoI</bold>. Cells visible only outside the <bold>FoI</bold> were not segmented at all. After reaching the limit of 100 cells and two full frames, the annotators inspected the remaining frames in the random order provided, and they were asked to identify and annotate cells that in their opinion were prone to causing segmentation problems, such as cells undergoing abnormal mitoses, dimly stained cells, oddly shaped cells and colliding pairs of cells. They segmented at least 20 instances of each problematic event.</p>
      </sec>
      <sec id="SEC2.3.3">
        <title>2.3.3 Ground truth for tracking</title>
        <p>The task for the annotators was to draw a quintessential “marker” (i.e. a set of grid points with the same unique label) inside each cell and in every frame where the cell consecutively appears entirely or partly within the limits of the <bold>FoI</bold>. These markers do not need to accurately follow the boundaries of the cells. Markers of a given label located in consecutive frames are called “tracks”. Tracks end when a cell entirely leaves the <bold>FoI</bold>, the video reaches the final frame or the cell divides into two, or abnormally more than two, daughter cells. When this happens, new tracks are created, one for each daughter cell, and the parental connection is stored in the <bold>TRA-GT</bold> file.</p>
      </sec>
    </sec>
    <sec id="SEC2.4">
      <title>2.4 Evaluation</title>
      <sec id="SEC2.4.1">
        <title>2.4.1 Segmentation measure</title>
        <p>The main purpose of the segmentation (<bold>SEG</bold><bold>)</bold> accuracy measurement is to understand how well the segmented cells match the actual cell regions. To quantify it, we used the Jaccard similarity index, defined as:
<disp-formula><graphic xlink:href="btu080um1.jpg" position="float"/></disp-formula>
where <italic>R</italic> is a reference segmentation of a cell in <bold>SEG-GT-F</bold> and <italic>S</italic> is an automatic segmentation of the particular cell provided by a participant. A reference cell, <italic>R</italic>, and a segmented one, <italic>S</italic>, are considered matching if the following condition holds:
<disp-formula><graphic xlink:href="btu080um2.jpg" position="float"/></disp-formula>
</p>
        <p>Note, for each reference cell, there can be one segmented object at most. If there is no significant overlap with any segmented object, the matching function is set to empty. The Jaccard index always falls in the [0, 1] interval, where 1 means perfect match and 0 means no match. The final <bold>SEG</bold> measure for a particular video is calculated as the mean of the Jaccard indices of all the reference objects in the video.</p>
      </sec>
      <sec id="SEC2.4.2">
        <title>2.4.2 Tracking measure</title>
        <p>The goal of the tracking (<bold>TRA</bold><bold>)</bold> measurement is to evaluate the ability of the tracking algorithms to detect the cells and follow them in time. Although <bold>TRA</bold> does not evaluate the segmentation accuracy, reliable cell detection is the key to this measurement. To the best of our knowledge, there is no standardized, commonly used cell tracking accuracy measure currently available. Two popular approaches for measuring the performance of tracking algorithms are based on either the ratio of completely reconstructed tracks to the total number of ground-truth tracks (<xref rid="btu080-B17" ref-type="bibr">Li <italic>et al.</italic>, 2008</xref>) or the ratio of correct temporal relations within reconstructed tracks to the total number of temporal relations within ground-truth tracks (<xref rid="btu080-B15" ref-type="bibr">Kan <italic>et al.</italic>, 2011</xref>). Obviously, both approaches quantify, at different scales, how well the cell tracking algorithms are able to reconstruct a particular ground-truth reference. However, they neither penalize for spurious tracks nor account for division events, which are often evaluated separately (<xref rid="btu080-B15" ref-type="bibr">Kan <italic>et al.</italic>, 2011</xref>; <xref rid="btu080-B17" ref-type="bibr">Li <italic>et al.</italic>, 2008</xref>). Therefore, we developed a novel cell tracking accuracy measure that penalizes for all possible errors in tracking results and combines them with different weights, reflecting the manual effort needed to correct a particular error, into a single number.</p>
        <p>Cell tracking results can be represented using an acyclic oriented graph. The nodes of such a graph correspond to the detected cells, whereas its edges coincide with temporal relations between them. They are of two kinds: <italic>track links</italic> (the cell continues with the same label in the consecutive frames) and <italic>parent links</italic> (the cell continues with a different label not necessarily in the consecutive frames). Non-dividing cells have one successor at most, whereas those that undergo division have two or even more successors in the case of abnormal division. The <bold>TRA</bold> measurement computes the difference between the acyclic oriented graph provided by a participant algorithm and the reference <bold>TRA-GT-F</bold>. To this end, we automatically quantify how difficult it is to transform the computed graph into the reference one as the least number of operations needed to make the graphs identical. The operations allowed (<italic>split</italic>/<italic>delete</italic>/<italic>add</italic> a node; <italic>delete</italic>/<italic>add</italic> or <italic>change the semantics</italic> of an edge) are penalized differently based on the effort that would be required if manually performed. The correspondence between operations and weights (w) is as follows: delete a node (w = 1, requires one mouse click); split a node (w = 5, requires drawing a divider); add a node (w = 10, requires adding a whole mask); delete an edge (w = 1, requires one mouse click); change an edge semantics (w = 1, requires one mouse click); add an edge (w = 1.5, it is slightly more difficult than deleting an edge, as it requires to determine both nodes of the edge). The <bold>TRA</bold> measure is defined as the weighted sum of graph operations, normalized by the number of markers (i.e. by the number of nodes in the reference graph) to facilitate the comparison between videos (datasets) with different numbers of cells. The best result, which requires no changes, has a <bold>TRA</bold> measure equal to zero.</p>
        <p>To establish the optimal transformation of a participant graph into the reference graph, we have implemented the following automatic procedure. First, correspondences between the nodes of both graphs are determined using the same criterion that is used for finding matching segmentation masks. Then, the nodes are classified into four categories: <italic>false negatives</italic> (ground-truth nodes without any match to the participant nodes), <italic>false positives</italic> (participant nodes without any match to the ground-truth nodes), <italic>true positives</italic> (ground-truth nodes that match to some participant nodes) and <italic>non-split nodes</italic> (participant nodes that match to multiple ground-truth nodes). Knowing the category of each node, the procedure directly computes how many edges need to be removed from the participant graph. They are either connected to at least one false-positive node or they connect two correctly detected nodes, which are not linked in the ground-truth graph. Analogously, it counts the number of missing edges in the participant graph. These are the ground-truth edges without counterpart in the participant graph. Finally, the number of edges between matching nodes, which differ in semantics, is counted. The optimal transformation making the participant graph identical to the reference graph first involves separating all non-split nodes, adding false-negative nodes and removing all false-positive nodes. Having the sets of nodes of both graphs unified, redundant edges are removed, missing edges added and finally those with wrong semantics corrected. The whole procedure is fully automatic, requires no optimization and is easy to implement.</p>
      </sec>
      <sec id="SEC2.4.3">
        <title>2.4.3 Time consumption</title>
        <p>Time consumption (<bold>TIM</bold>) was evaluated on a common workstation (Intel Core i7-3770 3.40 GHz, 24 GB RAM) running the 64-bit Windows 7 or the Ubuntu 13.10 operating system. The total execution time needed to analyze each video of a given dataset was measured. The memory consumption was not considered for the performance evaluation, but the participants were asked to ensure that their algorithms would not require more than the given physical memory limit on that PC configuration.</p>
      </sec>
      <sec id="SEC2.4.4">
        <title>2.4.4 Evaluation tools</title>
        <p>Two command-line executable programs, one for segmentation and one for the tracking accuracy evaluation, were provided along with the training datasets to help the participants with the self-evaluation and refinement of their algorithms. These programs were also used by the organizers to evaluate <bold>SEG</bold> and <bold>TRA</bold> for the results submitted by the participating teams for the competition datasets. Both programs were written in C++ and are publicly available at the challenge Web site.</p>
      </sec>
      <sec id="SEC2.4.5">
        <title>2.4.5 Compilation of rankings</title>
        <p>First, for each method, the <bold>SEG</bold>, <bold>TRA</bold> and <bold>TIM</bold> measures were averaged over all the videos of a given dataset. For each dataset, all the methods were ranked (1 = best) and, subsequently, a final ranking was compiled based on the following formula:
<disp-formula><graphic xlink:href="btu080um3.jpg" position="float"/></disp-formula>
where <italic>N</italic> is the number of ranked methods for a particular dataset. The reason for using different weights for accuracy (<bold>SEG</bold> and <bold>TRA</bold>) and speed (<bold>TIM</bold>) is to prefer more accurate, but possibly slower, methods to faster, but less accurate, ones.</p>
        <p>The best performing method is that with the lowest <bold>Final rank</bold> for a particular dataset. Note that the methods having partial or empty submitted results for a particular dataset were not ranked for that dataset. Instead, their <bold>Final rank</bold> was established as NA (not applicable).</p>
      </sec>
    </sec>
  </sec>
  <sec>
    <title>3 RESULTS AND DISCUSSION</title>
    <sec sec-type="subjects">
      <title>3.1 Participants and algorithms</title>
      <p>At the time the challenge was closed, six groups had uploaded consistent results to the challenge FTP server. The main principles of the competing algorithms are briefly described in <xref ref-type="table" rid="btu080-T2">Table 2</xref> and are fully described in <ext-link ext-link-type="uri" xlink:href="http://bioinformatics.oxfordjournals.org/lookup/suppl/doi:10.1093/bioinformatics/btu080/-/DC1">Supplementary Methods</ext-link>. Furthermore, executable versions of most of the competing algorithms, along with the instructions of use, are available through the challenge Web site.
<table-wrap id="btu080-T2" position="float"><label>Table 2.</label><caption><p>Summarized description of the algorithms competing in the challenge</p></caption><table frame="hsides" rules="groups"><thead align="left"><tr><th rowspan="1" colspan="1">Methods</th><th rowspan="1" colspan="1">T</th><th rowspan="1" colspan="1">Preprocessing</th><th rowspan="1" colspan="1">Segmentation</th><th rowspan="1" colspan="1">Tracking</th><th rowspan="1" colspan="1">Post-processing</th></tr></thead><tbody align="left"><tr><td rowspan="1" colspan="1">COM-US</td><td rowspan="1" colspan="1">D</td><td rowspan="1" colspan="1">Mean filtering</td><td rowspan="1" colspan="1">Iterative histogram analysis</td><td rowspan="1" colspan="1">Multiple-hypothesis tracking of extracted cell baricenters</td><td rowspan="1" colspan="1">Identification of parent links</td></tr><tr><td rowspan="1" colspan="1">HEID-GE</td><td rowspan="1" colspan="1">D</td><td rowspan="1" colspan="1">Gaussian and median filtering</td><td rowspan="1" colspan="1">Region adaptive thresholding followed by a watershed transform for splitting clusters</td><td rowspan="1" colspan="1">Local optimization using a cost function within spatially-limited search regions</td><td rowspan="1" colspan="1">Detection of mitotic events based on likelihood measurements</td></tr><tr><td rowspan="1" colspan="1">KTH-SE</td><td rowspan="1" colspan="1">D</td><td rowspan="1" colspan="1">Gaussian band-pass filtering</td><td rowspan="1" colspan="1">Global thresholding followed by a watershed transform for splitting clusters</td><td rowspan="1" colspan="1">State-space diagram optimization in a greedy fashion.</td><td rowspan="1" colspan="1">Seeded <italic>k</italic>-means clustering; Merging segments without tracks into adjacent segments with tracks</td></tr><tr><td rowspan="1" colspan="1">LEID-NL</td><td rowspan="1" colspan="1">M</td><td rowspan="1" colspan="1">Not used</td><td colspan="2" rowspan="1">Region-based contour evolution using the multi-phase level set framework. Radon transform for splitting clusters; Compensation for inter-frame cell motion</td><td rowspan="1" colspan="1">Improved handling of mitotic events (for cytoplasmic labeling) based on shape solidity measurements</td></tr><tr><td rowspan="1" colspan="1">PRAG-CZ</td><td rowspan="1" colspan="1">D</td><td rowspan="1" colspan="1">Gaussian filtering</td><td rowspan="1" colspan="1">Adaptive <italic>k</italic>-means thresholding followed by a watershed transform for splitting clusters</td><td rowspan="1" colspan="1">Nearest-neighbor tracking of extracted centers of mass</td><td rowspan="1" colspan="1">Not used</td></tr><tr><td rowspan="1" colspan="1">UPM-ES</td><td rowspan="1" colspan="1">D</td><td rowspan="1" colspan="1">Median filtering; Grayscale spatial area opening</td><td rowspan="1" colspan="1">Stochastic spatio-temporal morphological reconstruction combined with hierarchical clustering</td><td rowspan="1" colspan="1">Iterative spatio-temporal association based on three-dimensional connectivity for 2D data</td><td rowspan="1" colspan="1">Not used</td></tr></tbody></table><table-wrap-foot><fn id="btu080-TF2"><p><italic>Note</italic>: T, tracking paradigm (D: tracking by detection; M: tracking by model evolution).</p></fn></table-wrap-foot></table-wrap></p>
    </sec>
    <sec id="SEC3.2">
      <title>3.2 Submissions and rankings</title>
      <p>The percentage of submissions received for each dataset is listed in <ext-link ext-link-type="uri" xlink:href="http://bioinformatics.oxfordjournals.org/lookup/suppl/doi:10.1093/bioinformatics/btu080/-/DC1">Supplementary Table S1</ext-link>. This table also displays the mean and standard deviation of the <bold>SEG</bold>, <bold>TRA</bold> and <bold>TIM</bold> measures obtained for each dataset, combining all the submissions received.</p>
      <p><xref ref-type="table" rid="btu080-T3">Table 3</xref> presents a summary of the rankings obtained for each dataset, considering each measurement separately, and also combined, as described in Methods. The specific results for each dataset, including the values of the three performance measures for each video are listed in <ext-link ext-link-type="uri" xlink:href="http://bioinformatics.oxfordjournals.org/lookup/suppl/doi:10.1093/bioinformatics/btu080/-/DC1">Supplementary Table 1</ext-link>. Sample results are presented as <ext-link ext-link-type="uri" xlink:href="http://bioinformatics.oxfordjournals.org/lookup/suppl/doi:10.1093/bioinformatics/btu080/-/DC1">Supplementary Videos 9–16</ext-link>.</p>
    </sec>
    <sec sec-type="discussion">
      <title>3.3 Discussion</title>
      <p>In the next paragraphs, we will discuss the main contributions of the challenge.</p>
      <p><italic>Datasets.</italic> We have created a public data repository composed of 24 annotated time-lapse sequences obtained from conventional and confocal fluorescence microscopes, along with 24 realistic computer simulations of moving nuclei. The cell types selected are relevant in the context of cell migration, being cells with stem-like properties involved in embryonic and adult organ development and homeostasis, or cancer cell lines with metastatic properties. These videos cover a wide variety of cell types, microscopy and experimental setups, cell density and motility, resolution, image quality and dimensionality. There are 2D sequences of nuclearly stained cells, commonly used in cell population studies (e.g. <bold>N2DL-HeLa</bold>), and 3D sequences of cytoplasmically stained cells, more appropriate for single-cell studies that demand a realistic rendering of the cellular environment (e.g. <bold>C3DL-MDA231</bold>). The characteristics of the videos in terms of contrast, resolution and signal-to-noise ratio are also diverse, covering conditions ranging from those that could be considered “high quality” (i.e. high numerical aperture lens, homogeneous and bright fluorescent staining) to conditions that could be classified as “high-throughput” (i.e. low magnification, low numerical aperture lens, heterogeneous and dim fluorescent staining). All real videos used in the competition were manually annotated at three different sites, and a final ground truth per video was generated using a majority voting approach, to account for inter-subject variability. The two additional simulated datasets provide an absolute ground truth for the comparison of the algorithms, eliminating the possible bias introduced by the annotators of the real videos.</p>
      <p><italic>Measures and rankings.</italic> Key to the establishment of a credible benchmark is the use of common measures for algorithm evaluation and comparison. We have described and used measures that account for two aspects of the cell tracking problem: segmentation and tracking accuracy. The segmentation accuracy measure was based on the Jaccard similarity index, which evaluates how close the cell segmentations are to the ground truth. Tracking accuracy was evaluated using a novel measure, based on matching acyclic oriented graphs. This method automatically assesses the difficulty of transforming a computed graph into the ground-truth reference. The difficulty is measured as the weighted sum of the least number of operations needed to make the graphs identical. Therefore, the tracking accuracy was measured by one comprehensive scalar measure, whereas in most previous works it required evaluating multiple measures to characterize various cell tracking events (<xref rid="btu080-B15" ref-type="bibr">Kan <italic>et al.</italic>, 2011</xref>; <xref rid="btu080-B17" ref-type="bibr">Li <italic>et al.</italic>, 2008</xref>). The weights are not biologically motivated; therefore, the measure is application-independent. The highest weight is put on missing nodes in the weighted sum; therefore, the ability of the method to detect all the cells is important for achieving low score. Because both parameters (i.e. segmentation and tracking accuracy) are of similar importance, they were weighted equally in the final ranking function. Only when the algorithms achieved the same rank in terms of accuracy, the faster one was preferred, which was guaranteed by adding time performance with a smaller adaptive weight.</p>
      <p><italic>Results: Participants and algorithms.</italic> Six algorithms were submitted to the first Cell Tracking Challenge, covering a wide variety of methods, stemming from the two main tracking paradigms: <italic>tracking by detection</italic> and <italic>tracking by model evolution</italic>. Most of the existing state-of-the-art methods for filtering, enhancement, segmentation, particle analysis and track association are represented. Four of the six participating groups (<bold>COM-US</bold>, <bold>HEID-GE</bold>, <bold>KTH-SE</bold> and <bold>PRAG-CZ</bold>) provided results for all the datasets. This is a remarkable fact that emphasizes the generalization of the results.</p>
      <p><italic>Results: Global analysis.</italic> Based on the numbers provided in <ext-link ext-link-type="uri" xlink:href="http://bioinformatics.oxfordjournals.org/lookup/suppl/doi:10.1093/bioinformatics/btu080/-/DC1">Supplementary Table S1</ext-link>, both <bold>SEG</bold> and <bold>TRA</bold> accuracy measures were higher for nuclear labeling than for cytoplasmic labeling. Furthermore, they both reflected the level of complexity provided in <xref ref-type="table" rid="btu080-T1">Table 1</xref>, along with the description of the datasets.</p>
      <p>There were large differences in the segmentation accuracy, the lowest mean values being for <bold>C2DL-MSC</bold> and <bold>C3DL-MDA231</bold> (both with cytoplasmic labeling), the highest mean value being for <bold>N3DH-CHO</bold>. This could be explained by the fact that the algorithms seem to be developed and tuned for the segmentation of nuclei, as they often incorporate cluster separation routines based on the circularity of segmented objects. Therefore, they are not appropriate for cellular shapes, which are seldom uniform, present protrusions and frequently establish contacts or overlaps.</p>
      <p>The <bold>TRA</bold> measure generally provided more uniform results among datasets, with the exception of <bold>C2DL-MSC</bold>. Interestingly, the algorithms achieved significantly higher tracking accuracy on the simulated datasets than on the real ones. This is likely because of the fact that the computer-simulated nuclei are in general uniformly sized, and the simulated cell motility does not cover all possible random events that occur in real live-cell experiments.</p>
      <p>Finally, the <bold>TIM</bold> measure strongly depended on the size of each video, being the lowest for <bold>C2DL-MSC</bold> and <bold>N2DH-SIM</bold> and the highest for <bold>N3DH-SIM</bold> and <bold>C3DH-H157</bold>. Another important factor influencing time consumption of the competing algorithms was the number of objects to be analyzed. Note that the standard deviations of the <bold>TIM</bold> measure indicate significant differences in the speed of competing algorithms for all the datasets.</p>
      <p><italic>Results: Rankings.</italic> The <bold>FINAL</bold> ranking in <xref ref-type="table" rid="btu080-T3">Table 3</xref> shows that <bold>KTH-SE</bold> performed best in four real datasets (<bold>C2DL-MSC</bold>, <bold>C3DL-MDA231</bold>, <bold>N2DH-GOWT1</bold> and <bold>N2DL-HeLa</bold>). <bold>HEID-GE</bold> and <bold>PRAG-CZ</bold> performed best in one real dataset (<bold>N3DH-CHO</bold> and <bold>C3DH-H157</bold>, respectively). <bold>LEID-NL</bold> performed best in the two simulated datasets (<bold>N2DH-SIM</bold> and <bold>N3DH-SIM</bold>). When we look at the number of appearances of each method among the top three best performing methods, both <bold>KTH-SE</bold> and <bold>HEID-GE</bold> appeared in all eight datasets, <bold>LEID-NL</bold> and <bold>PRAG-CZ</bold> appeared in three datasets and finally <bold>UPM-ES</bold> and <bold>COM-US</bold> appeared in one dataset.
<table-wrap id="btu080-T3" position="float"><label>Table 3.</label><caption><p>Summary of top-3 rankings per dataset and measure, along with the combined (FINAL) rankings</p></caption><table frame="hsides" rules="groups"><thead align="left"><tr><th rowspan="1" colspan="1">Rank</th><th rowspan="1" colspan="1">C2DL-MSC</th><th rowspan="1" colspan="1">C3DH-H157</th><th rowspan="1" colspan="1">C3DL-MDA231</th><th rowspan="1" colspan="1">N2DH-GOWT1</th><th rowspan="1" colspan="1">N2DL-HeLa</th><th rowspan="1" colspan="1">N3DH-CHO</th><th rowspan="1" colspan="1">N2DH-SIM</th><th rowspan="1" colspan="1">N3DH-SIM</th></tr></thead><tbody align="left"><tr><td colspan="9" rowspan="1">FINAL</td></tr><tr><td rowspan="1" colspan="1"> #1</td><td rowspan="1" colspan="1">KTH-SE</td><td rowspan="1" colspan="1">PRAG-CZ</td><td rowspan="1" colspan="1">KTH-SE</td><td rowspan="1" colspan="1">KTH-SE</td><td rowspan="1" colspan="1">KTH-SE</td><td rowspan="1" colspan="1">HEID-GE</td><td rowspan="1" colspan="1">LEID-NL</td><td rowspan="1" colspan="1">LEID-NL</td></tr><tr><td rowspan="1" colspan="1"> #2</td><td rowspan="1" colspan="1">HEID-GE</td><td rowspan="1" colspan="1">KTH-SE</td><td rowspan="1" colspan="1">HEID-GE</td><td rowspan="1" colspan="1">PRAG-CZ</td><td rowspan="1" colspan="1">HEID-GE</td><td rowspan="1" colspan="1">KTH-SE</td><td rowspan="1" colspan="1">KTH-SE</td><td rowspan="1" colspan="1">KTH-SE</td></tr><tr><td rowspan="1" colspan="1"> #3</td><td rowspan="1" colspan="1">UPM-ES</td><td rowspan="1" colspan="1">HEID-GE</td><td rowspan="1" colspan="1">COM-US</td><td rowspan="1" colspan="1">HEID-GE</td><td rowspan="1" colspan="1">PRAG-CZ</td><td rowspan="1" colspan="1">LEID-NL</td><td rowspan="1" colspan="1">HEID-GE</td><td rowspan="1" colspan="1">HEID-GE</td></tr><tr><td rowspan="1" colspan="1">SEG</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/></tr><tr><td rowspan="1" colspan="1"> #1</td><td rowspan="1" colspan="1">KTH-SE</td><td rowspan="1" colspan="1">HEID-GE</td><td rowspan="1" colspan="1">KTH-SE</td><td rowspan="1" colspan="1">PRAG-CZ</td><td rowspan="1" colspan="1">KTH-SE</td><td rowspan="1" colspan="1">HEID-GE</td><td rowspan="1" colspan="1">LEID-NL</td><td rowspan="1" colspan="1">LEID-NL</td></tr><tr><td rowspan="1" colspan="1"> #2</td><td rowspan="1" colspan="1">HEID-GE</td><td rowspan="1" colspan="1">KTH-SE</td><td rowspan="1" colspan="1">COM-US</td><td rowspan="1" colspan="1">KTH-SE</td><td rowspan="1" colspan="1">HEID-GE</td><td rowspan="1" colspan="1">LEID-NL</td><td rowspan="1" colspan="1">HEID-GE</td><td rowspan="1" colspan="1">HEID-GE</td></tr><tr><td rowspan="1" colspan="1"> #3</td><td rowspan="1" colspan="1">UPM-ES</td><td rowspan="1" colspan="1">PRAG-CZ</td><td rowspan="1" colspan="1">HEID-GE</td><td rowspan="1" colspan="1">HEID-GE</td><td rowspan="1" colspan="1">PRAG-CZ</td><td rowspan="1" colspan="1">COM-US</td><td rowspan="1" colspan="1">KTH-SE</td><td rowspan="1" colspan="1">KTH-SE</td></tr><tr><td rowspan="1" colspan="1">TRA</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/></tr><tr><td rowspan="1" colspan="1"> #1</td><td rowspan="1" colspan="1">KTH-SE</td><td rowspan="1" colspan="1">PRAG-CZ</td><td rowspan="1" colspan="1">KTH-SE</td><td rowspan="1" colspan="1">KTH-SE</td><td rowspan="1" colspan="1">HEID-GE</td><td rowspan="1" colspan="1">KTH-SE</td><td rowspan="1" colspan="1">KTH-SE</td><td rowspan="1" colspan="1">LEID-NL</td></tr><tr><td rowspan="1" colspan="1"> #2</td><td rowspan="1" colspan="1">HEID-GE</td><td rowspan="1" colspan="1">KTH-SE</td><td rowspan="1" colspan="1">HEID-GE</td><td rowspan="1" colspan="1">PRAG-CZ</td><td rowspan="1" colspan="1">KTH-SE</td><td rowspan="1" colspan="1">PRAG-CZ</td><td rowspan="1" colspan="1">LEID-NL</td><td rowspan="1" colspan="1">KTH-SE</td></tr><tr><td rowspan="1" colspan="1"> #3</td><td rowspan="1" colspan="1">UPM-ES</td><td rowspan="1" colspan="1">HEID-GE</td><td rowspan="1" colspan="1">PRAG-CZ</td><td rowspan="1" colspan="1">HEID-GE</td><td rowspan="1" colspan="1">PRAG-CZ</td><td rowspan="1" colspan="1">HEID-GE</td><td rowspan="1" colspan="1">HEID-GE</td><td rowspan="1" colspan="1">HEID-GE</td></tr><tr><td rowspan="1" colspan="1">TIM</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/></tr><tr><td rowspan="1" colspan="1"> #1</td><td rowspan="1" colspan="1">COM-US</td><td rowspan="1" colspan="1">PRAG-CZ</td><td rowspan="1" colspan="1">PRAG-CZ</td><td rowspan="1" colspan="1">COM-US</td><td rowspan="1" colspan="1">COM-US</td><td rowspan="1" colspan="1">COM-US</td><td rowspan="1" colspan="1">COM-US</td><td rowspan="1" colspan="1">PRAG-CZ</td></tr><tr><td rowspan="1" colspan="1"> #2</td><td rowspan="1" colspan="1">KTH-SE</td><td rowspan="1" colspan="1">COM-US</td><td rowspan="1" colspan="1">COM-US</td><td rowspan="1" colspan="1">KTH-SE</td><td rowspan="1" colspan="1">KTH-SE</td><td rowspan="1" colspan="1">PRAG-CZ</td><td rowspan="1" colspan="1">KTH-SE</td><td rowspan="1" colspan="1">COM-US</td></tr><tr><td rowspan="1" colspan="1"> #3</td><td rowspan="1" colspan="1">PRAG-CZ</td><td rowspan="1" colspan="1">KTH-SE</td><td rowspan="1" colspan="1">KTH-SE</td><td rowspan="1" colspan="1">PRAG-CZ</td><td rowspan="1" colspan="1">PRAG-CZ</td><td rowspan="1" colspan="1">KTH-SE</td><td rowspan="1" colspan="1">PRAG-CZ</td><td rowspan="1" colspan="1">KTH-SE</td></tr></tbody></table></table-wrap></p>
      <p>It is also important to note that in the case of <bold>C3DH-H157</bold>, <bold>N2DH-GOWT1</bold>, <bold>N2DL-HeLa</bold> and <bold>N3DH-SIM</bold>, the decisive factor for establishing the final ranking was the speed of competing algorithms because multiple methods were evenly ranked based on the <bold>SEG</bold> and <bold>TRA</bold> accuracy measures only.</p>
      <p>Looking at each accuracy measure separately, <bold>HEID-GE</bold> and <bold>KTH-SE</bold> ranked among the top three most accurate methods for all the datasets, with the exception of the segmentation accuracy for <bold>N3DH-CHO</bold>, where <bold>KTH-SE</bold> ranked fourth. However, one should note that in this specific case, the difference in <bold>SEG</bold> between the most accurate method, <bold>HEID-GE</bold>, and <bold>KTH-SE</bold> was small. The other two methods that often belonged to the top three most accurate methods were <bold>PRAG-CZ</bold> and <bold>LEID-NL</bold>. In terms of <bold>TIM</bold> measure, <bold>COM-US</bold>, <bold>PRAG-CZ</bold> and <bold>KTH-SE</bold> were consistently the top three fastest methods for all the datasets. It is remarkable that <bold>KTH-SE</bold> was, at worst, second fastest among the top three best performers in terms of <bold>SEG</bold> and <bold>TRA</bold>.</p>
      <p><italic>Results per dataset:</italic> We will now look at the results of each particular dataset in detail, trying to extract relevant conclusions about the best performing methods (see <xref ref-type="table" rid="btu080-T3">Table 3</xref> and <ext-link ext-link-type="uri" xlink:href="http://bioinformatics.oxfordjournals.org/lookup/suppl/doi:10.1093/bioinformatics/btu080/-/DC1">Supplementary Table S1</ext-link>):</p>
      <p><bold>C2DL-MS</bold>C (<ext-link ext-link-type="uri" xlink:href="http://bioinformatics.oxfordjournals.org/lookup/suppl/doi:10.1093/bioinformatics/btu080/-/DC1">Supplementary Video S9</ext-link>). The accuracy measures were generally poor, especially because of problems with the segmentation of elongated protrusions, often incorrectly considered as whole cells. <bold>KTH-SE</bold> achieved significantly better accuracy than the other methods because of the optimized track-linking algorithm used, and an adaptive post-processing step, which merges segmented object portions into adjacent segments with tracks. Regardless of this additional post-processing step, the method was still fast, being the second fastest in terms of <bold>TIM</bold> and &gt;2× faster than the other two top three best performing methods, <bold>HEID-GE</bold> and <bold>UPM-ES</bold>.</p>
      <p><bold>C3DH-H157</bold> (<ext-link ext-link-type="uri" xlink:href="http://bioinformatics.oxfordjournals.org/lookup/suppl/doi:10.1093/bioinformatics/btu080/-/DC1">Supplementary Video S10</ext-link>). All the algorithms that competed for this dataset achieved comparable segmentation accuracy, <bold>HEID-GE</bold> being the most accurate. Compared with the segmentation accuracy, the tracking accuracy was more spread out, <bold>PRAG-CZ</bold> being the most accurate. The decisive factor for establishing the final ranking of the top three best performing methods was <bold>TIM</bold>. Globally, <bold>PRAG-CZ</bold> was ranked first, having the lowest time consumption, namely, because the preprocessing step, involving Gaussian filtering, is applied only in 2D, slice-by-slice.</p>
      <p><bold>C3DL-MDA231</bold> (<ext-link ext-link-type="uri" xlink:href="http://bioinformatics.oxfordjournals.org/lookup/suppl/doi:10.1093/bioinformatics/btu080/-/DC1">Supplementary Video S11</ext-link>). The calculated accuracy measures were generally poor, because of the high-throughput acquisition conditions, making it difficult to properly separate tightly packed clusters as well as accurately segment elongated protrusions. Analogously to <bold>C2DL-MSC</bold>, <bold>KTH-SE</bold> significantly outperformed the other methods in terms of accuracy. This is due to the additional arcs included in the state space diagram, which allow the delayed creation of correct tracks originally blocked by incorrect preexisting tracks (<xref rid="btu080-B21" ref-type="bibr">Magnusson and Jaldén, 2012</xref>). Moreover, this is also a benefit of the track-free object merging used as an adaptive post-processing step.</p>
      <p><bold>N2DH-GOWT1</bold> (<ext-link ext-link-type="uri" xlink:href="http://bioinformatics.oxfordjournals.org/lookup/suppl/doi:10.1093/bioinformatics/btu080/-/DC1">Supplementary Video S12</ext-link>). Both accuracy measures were high, especially <bold>SEG</bold>. A decisive factor for achieving these good results was the use of a cluster separation routine (e.g. watershed or the Radon transform), and a hole-filling approach to remove small background components within segmented cells at places of prominent nucleoli. The top two best performing methods, <bold>KTH-SE</bold> and <bold>PRAG-CZ</bold>, performed similarly. Based on the <bold>SEG</bold> and <bold>TRA</bold> measures, they were assigned the same rank of 3, with <bold>PRAG-CZ</bold> the best in segmenting and <bold>KTH-SE</bold> the best in tracking. Globally, <bold>KTH-SE</bold> was ranked first because it was ∼5× faster than <bold>PRAG-CZ</bold>.</p>
      <p><bold>N2DL-HeLa</bold> (<ext-link ext-link-type="uri" xlink:href="http://bioinformatics.oxfordjournals.org/lookup/suppl/doi:10.1093/bioinformatics/btu080/-/DC1">Supplementary Video S13</ext-link>). The accuracy measures were high, especially <bold>TRA</bold>. Analogously to <bold>N2DH-GOWT1</bold>, the use of a cluster separation routine resulted in more accurate results, although such routine sometimes led to over-segmentation, especially when multiple touching nuclei formed clusters of highly irregular shape. The top two best performing methods, <bold>KTH-SE</bold> and <bold>HEID-GE</bold>, produced results of comparable accuracy. Based on the <bold>SEG</bold> and <bold>TRA</bold> measures, they were assigned the same rank of 3, <bold>KTH-SE</bold> being the best in segmenting and <bold>HEID-GE</bold> being the best in tracking, mainly because of the specific mitosis detection phase implemented in their method. Globally, <bold>KTH-SE</bold> was ranked first as it was &gt;2× faster than <bold>HEID-GE</bold>.</p>
      <p><bold>N3DH-CHO</bold> (<ext-link ext-link-type="uri" xlink:href="http://bioinformatics.oxfordjournals.org/lookup/suppl/doi:10.1093/bioinformatics/btu080/-/DC1">Supplementary Video S14</ext-link>). The accuracy measures were the best among all the real datasets. This can be explained by the high magnification objective lens used and low cell density. Furthermore, these videos contain little of noise. Analogously to <bold>N2DH-GOWT1</bold>, a crucial factor for achieving more accurate results was to involve a hole-filling approach to deal with nucleoli. Globally, <bold>HEID-GE</bold> was ranked first, thanks to its ability to deal with the presence of cell invaginations and a morphology-based likelihood measure used to identify candidates for mitotic events.</p>
      <p><bold>N2DH-SIM and N3DH-SIM</bold> (<ext-link ext-link-type="uri" xlink:href="http://bioinformatics.oxfordjournals.org/lookup/suppl/doi:10.1093/bioinformatics/btu080/-/DC1">Supplementary Videos S15</ext-link> and <ext-link ext-link-type="uri" xlink:href="http://bioinformatics.oxfordjournals.org/lookup/suppl/doi:10.1093/bioinformatics/btu080/-/DC1">S16</ext-link>). The obtained <bold>SEG</bold> measures were similar to those for the real datasets displaying stained nuclei. This indicates that our simulator generates images of realistic static content in terms of cell texture, noise level and image degradations. However, in terms of tracking accuracy, as mentioned before, the algorithms performed generally better than in the real datasets. Globally, <bold>LEID-NL</bold> was ranked first for both simulated datasets, fitting with the idea that the model behind this method highly conforms to computer-simulated nuclei of controlled cell motility. However, it needs further optimization to properly work in real scenarios. From the analysis of the submitted results, we can finally stress the importance of the mitosis detection phase implemented by <bold>HEID-GE</bold>, and the linking and adaptive track post-processing phases implemented by <bold>KTH-SE</bold>, especially in low signal-to-noise ratio conditions.</p>
    </sec>
  </sec>
  <sec>
    <title>4 CONCLUSION</title>
    <p>In this article, we have presented the implementation of a benchmark for objective comparison of cell tracking algorithms, based on the use of a common diverse video dataset repository and ground truth, specific measures for both the evaluation of the segmentation and tracking accuracy, and unified criteria for comparing and ranking the algorithms. This is something recently highlighted by <xref rid="btu080-B3" ref-type="bibr">Carpenter <italic>et al.</italic> (2012)</xref> as a requirement for the usability of biomedical imaging software. The logistics, datasets, methods and results of the challenge have been described herein. In the future, we expect this benchmark to serve as a reference for the development and evaluation of novel cell tracking algorithms. To this end, the training and competition datasets are available to the general public, along with the ground truth for the training datasets and the self-evaluation software. Moreover, executable versions of most of the competing algorithms will be available through the challenge Web site. We expect the challenge to remain open for online submissions, because there are open problems that need to be addressed and new algorithms that can be developed to improve the existing ones. Namely, accurately segmenting and tracking cytoplasmically labeled cells is still something far from being solved. Automated segmentation and tracking of other cell types, other modalities (e.g. brightfield time-lapse microscopy) and existing or new high-throughput modalities, such as selected plane illumination microscopy, may require further algorithmic developments, and therefore proper testing and validation that could be achieved through this benchmark.</p>
    <p><italic>Funding</italic>: The <funding-source>Spanish Ministry of Economy</funding-source> (<award-id>DPI2012-38090-C03-02</award-id> to C.O.d.S. and M.M.); the <funding-source>Czech Science Foundation</funding-source> (<award-id>302/12/G157</award-id> to M.K., P.M., P.M., D.S., G.M.H.); the <funding-source>European Social Fund</funding-source> and the <funding-source>Czech Ministry of Education</funding-source> (<award-id>1.07/2.3.00/30.0009</award-id> to M.M.); the <funding-source>Swedish Research Council</funding-source> (VR) (<award-id>621-2011-5884</award-id> to K.M. and J.J.); the <funding-source>National Institutes of Health</funding-source> (<award-id>R01 HL096113</award-id> to H.B.) and <funding-source>California Institute for Regenerative Medicine</funding-source> (<award-id>RT1-01001-1</award-id>, to H.B.); the <funding-source>Grant Agency of the Czech Republic</funding-source> (<award-id>P205/12/P392</award-id> to P.Křížek); the project <award-id>UNCE 204022</award-id> from the <funding-source>Charles University</funding-source> (P.Křížek); the <funding-source>BMBF projects ENGINE</funding-source> (NGFN+) and <funding-source>FANCI</funding-source> (SysTec) (N.H., K.R.); <funding-source>Spain's Gov. projects</funding-source> (<award-id>CDTI-AMIT</award-id>, <award-id>TEC2010-21619-C04-03</award-id>, <award-id>TEC2011-28972-C02-02</award-id>) and <funding-source>European Development Funds</funding-source> (D.P-E, D.J-C and M.J.L-C.).</p>
    <p><italic>Conflict of Interest</italic>: none declared.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material id="PMC_1" content-type="local-data">
      <caption>
        <title>Supplementary Data</title>
      </caption>
      <media mimetype="text" mime-subtype="html" xlink:href="supp_30_11_1609__index.html"/>
      <media xlink:role="associated-file" mimetype="application" mime-subtype="msword" xlink:href="supp_btu080_Supplementary-Methods.docx"/>
      <media xlink:role="associated-file" mimetype="application" mime-subtype="msword" xlink:href="supp_btu080_Supplementary-Note.docx"/>
      <media xlink:role="associated-file" mimetype="application" mime-subtype="msword" xlink:href="supp_btu080_Supplementary-Table-1.docx"/>
    </supplementary-material>
  </sec>
</body>
<back>
  <ref-list>
    <title>REFERENCES</title>
    <ref id="btu080-B1">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Al-Kofahi</surname>
            <given-names>O</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Automated cell lineage construction: a rapid method to analyze clonal development established with murine neural progenitor cells</article-title>
        <source>Cell Cycle</source>
        <year>2006</year>
        <volume>5</volume>
        <fpage>327</fpage>
        <lpage>335</lpage>
        <pub-id pub-id-type="pmid">16434878</pub-id>
      </element-citation>
    </ref>
    <ref id="btu080-B2">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Bise</surname>
            <given-names>R</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Reliable cell tracking by global data association</article-title>
        <source>Proceedings of the IEEE International Symposium on Biomedical Imaging: From Nano to Macro</source>
        <year>2011</year>
        <fpage>1004</fpage>
        <lpage>1010</lpage>
      </element-citation>
    </ref>
    <ref id="btu080-B3">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Carpenter</surname>
            <given-names>AE</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>A call for bioimaging software usability</article-title>
        <source>Nat. Methods</source>
        <year>2012</year>
        <volume>7</volume>
        <fpage>666</fpage>
        <lpage>670</lpage>
        <pub-id pub-id-type="pmid">22743771</pub-id>
      </element-citation>
    </ref>
    <ref id="btu080-B4">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chenouard</surname>
            <given-names>N</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Multiple-hypothesis tracking for cluttered biological image sequences</article-title>
        <source>IEEE Trans. Pattern Anal. Mach. Intell.</source>
        <year>2013</year>
        <volume>35</volume>
        <fpage>2736</fpage>
        <lpage>3750</lpage>
        <pub-id pub-id-type="pmid">24051732</pub-id>
      </element-citation>
    </ref>
    <ref id="btu080-B5">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Dima</surname>
            <given-names>AA</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Comparison of segmentation algorithms for fluorescence microscopy images of cells</article-title>
        <source>Cytometry A</source>
        <year>2011</year>
        <volume>79</volume>
        <fpage>545</fpage>
        <lpage>559</lpage>
        <pub-id pub-id-type="pmid">21674772</pub-id>
      </element-citation>
    </ref>
    <ref id="btu080-B6">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Dufour</surname>
            <given-names>A</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Segmenting and tracking fluorescent cells in dynamic 3-D microscopy with coupled active surfaces</article-title>
        <source>IEEE Trans. Image Process.</source>
        <year>2005</year>
        <volume>14</volume>
        <fpage>1396</fpage>
        <lpage>1410</lpage>
        <pub-id pub-id-type="pmid">16190474</pub-id>
      </element-citation>
    </ref>
    <ref id="btu080-B7">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Dufour</surname>
            <given-names>A</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>3-D active meshes: fast discrete deformable models for cell tracking in 3-D time-lapse microscopy</article-title>
        <source>IEEE Trans. Image Process.</source>
        <year>2011</year>
        <volume>20</volume>
        <fpage>1925</fpage>
        <lpage>1937</lpage>
        <pub-id pub-id-type="pmid">21193379</pub-id>
      </element-citation>
    </ref>
    <ref id="btu080-B8">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Dzyubachyk</surname>
            <given-names>O</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Advanced level-set-based cell tracking in time-lapse fluorescence microscopy</article-title>
        <source>IEEE Trans. Med. Imaging</source>
        <year>2010</year>
        <volume>29</volume>
        <fpage>852</fpage>
        <lpage>867</lpage>
        <pub-id pub-id-type="pmid">20199920</pub-id>
      </element-citation>
    </ref>
    <ref id="btu080-B9">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Fernandez-Gonzalez</surname>
            <given-names>R</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Quantitative <italic>in vivo</italic> microscopy: the return from the ‘omics’</article-title>
        <source>Curr. Opin. Biotechnol.</source>
        <year>2006</year>
        <volume>17</volume>
        <fpage>501</fpage>
        <lpage>510</lpage>
        <pub-id pub-id-type="pmid">16899361</pub-id>
      </element-citation>
    </ref>
    <ref id="btu080-B10">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Foggia</surname>
            <given-names>P</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Benchmarking HEp′2 cells classification methods</article-title>
        <source>IEEE Trans. Med. Imaging</source>
        <year>2013</year>
        <volume>32</volume>
        <fpage>1878</fpage>
        <lpage>1889</lpage>
        <pub-id pub-id-type="pmid">23797238</pub-id>
      </element-citation>
    </ref>
    <ref id="btu080-B11">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Friedl</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Alexander</surname>
            <given-names>D</given-names>
          </name>
        </person-group>
        <article-title>Cancer invasion and the microenvironment: plasticity and reciprocity</article-title>
        <source>Cell</source>
        <year>2011</year>
        <volume>147</volume>
        <fpage>992</fpage>
        <lpage>1009</lpage>
        <pub-id pub-id-type="pmid">22118458</pub-id>
      </element-citation>
    </ref>
    <ref id="btu080-B12">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Friedl</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Gilmour</surname>
            <given-names>D</given-names>
          </name>
        </person-group>
        <article-title>Collective cell migration in morphogenesis, regeneration and cancer</article-title>
        <source>Nat. Rev. Mol. Cell Biol.</source>
        <year>2009</year>
        <volume>10</volume>
        <fpage>445</fpage>
        <lpage>457</lpage>
        <pub-id pub-id-type="pmid">19546857</pub-id>
      </element-citation>
    </ref>
    <ref id="btu080-B13">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Held</surname>
            <given-names>C</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Comparison of parameter-adapted segmentation methods for fluorescence micrographs</article-title>
        <source>Cytometry A</source>
        <year>2011</year>
        <volume>79</volume>
        <fpage>933</fpage>
        <lpage>945</lpage>
        <pub-id pub-id-type="pmid">22002887</pub-id>
      </element-citation>
    </ref>
    <ref id="btu080-B14">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Indhumathi</surname>
            <given-names>C</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>An automatic segmentation algorithm for 3D cell cluster splitting using volumetric confocal images</article-title>
        <source>J. Microsc.</source>
        <year>2011</year>
        <volume>243</volume>
        <fpage>60</fpage>
        <lpage>76</lpage>
        <pub-id pub-id-type="pmid">21288236</pub-id>
      </element-citation>
    </ref>
    <ref id="btu080-B15">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kan</surname>
            <given-names>A</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Automated and semi-automated tracking: addressing portability challenges</article-title>
        <source>J. Microsc.</source>
        <year>2011</year>
        <volume>244</volume>
        <fpage>194</fpage>
        <lpage>213</lpage>
        <pub-id pub-id-type="pmid">21895653</pub-id>
      </element-citation>
    </ref>
    <ref id="btu080-B16">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Legant</surname>
            <given-names>WR</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Measurement of mechanical tractions exerted by cells in three-dimensional matrices</article-title>
        <source>Nat. Methods</source>
        <year>2010</year>
        <volume>7</volume>
        <fpage>969</fpage>
        <lpage>971</lpage>
        <pub-id pub-id-type="pmid">21076420</pub-id>
      </element-citation>
    </ref>
    <ref id="btu080-B17">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Li</surname>
            <given-names>K</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Cell population tracking and lineage construction with spatiotemporal context</article-title>
        <source>Med. Image Anal.</source>
        <year>2008</year>
        <volume>12</volume>
        <fpage>546</fpage>
        <lpage>566</lpage>
        <pub-id pub-id-type="pmid">18656418</pub-id>
      </element-citation>
    </ref>
    <ref id="btu080-B18">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Li</surname>
            <given-names>F</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Multiple nuclei tracking using integer programming for quantitative cancer cell cycle analysis</article-title>
        <source>IEEE Trans. Med. Imaging</source>
        <year>2010</year>
        <volume>29</volume>
        <fpage>96</fpage>
        <lpage>105</lpage>
        <pub-id pub-id-type="pmid">19643704</pub-id>
      </element-citation>
    </ref>
    <ref id="btu080-B19">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lin</surname>
            <given-names>G</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Hierarchical, model-based merging of multiple fragments for improved three-dimensional segmentation of nuclei</article-title>
        <source>Cytometry A</source>
        <year>2005</year>
        <volume>63</volume>
        <fpage>20</fpage>
        <lpage>33</lpage>
        <pub-id pub-id-type="pmid">15584021</pub-id>
      </element-citation>
    </ref>
    <ref id="btu080-B20">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Long</surname>
            <given-names>F</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Automatic segmentation of nuclei in 3D microscopy images of <italic>C. Elegans</italic></article-title>
        <source>Proceedings of the 4th IEEE International Symposium on Biomedical Imaging</source>
        <year>2007</year>
        <fpage>536</fpage>
        <lpage>539</lpage>
      </element-citation>
    </ref>
    <ref id="btu080-B21">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Magnusson</surname>
            <given-names>KEG</given-names>
          </name>
          <name>
            <surname>Jaldén</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>A batch algorithm using iterative application of the Viterbi algorithm to track cells and construct cell lineages</article-title>
        <source>Proceedings of the 9th IEEE International Symposium on Biomedical Imaging</source>
        <year>2012</year>
        <fpage>382</fpage>
        <lpage>385</lpage>
      </element-citation>
    </ref>
    <ref id="btu080-B22">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Maška</surname>
            <given-names>M</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Segmentation and shape tracking of whole fluorescent cells based on the Chan-Vese model</article-title>
        <source>IEEE Trans. Med. Imaging</source>
        <year>2013</year>
        <volume>32</volume>
        <fpage>995</fpage>
        <lpage>1006</lpage>
        <pub-id pub-id-type="pmid">23372077</pub-id>
      </element-citation>
    </ref>
    <ref id="btu080-B23">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Meijering</surname>
            <given-names>E</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Tracking in cell and developmental biology</article-title>
        <source>Semin. Cell Dev. Biol.</source>
        <year>2009</year>
        <volume>20</volume>
        <fpage>894</fpage>
        <lpage>902</lpage>
        <pub-id pub-id-type="pmid">19660567</pub-id>
      </element-citation>
    </ref>
    <ref id="btu080-B24">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ortiz-de-Solorzano</surname>
            <given-names>C</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Segmentation of confocal microscope images of cell nuclei in thick tissue sections</article-title>
        <source>J. Microsc.</source>
        <year>1999</year>
        <volume>193</volume>
        <fpage>212</fpage>
        <lpage>226</lpage>
        <pub-id pub-id-type="pmid">10199001</pub-id>
      </element-citation>
    </ref>
    <ref id="btu080-B25">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Padfield</surname>
            <given-names>D</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Coupled minimum-cost flow cell tracking for high-throughput quantitative analysis</article-title>
        <source>Med. Image Anal.</source>
        <year>2011</year>
        <volume>15</volume>
        <fpage>650</fpage>
        <lpage>668</lpage>
        <pub-id pub-id-type="pmid">20864383</pub-id>
      </element-citation>
    </ref>
    <ref id="btu080-B26">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Rapoport</surname>
            <given-names>DH</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>A novel validation algorithm allows for automated cell tracking and the extraction of biologically meaningful parameters</article-title>
        <source>PLoS One</source>
        <year>2011</year>
        <volume>11</volume>
        <fpage>e27315</fpage>
        <pub-id pub-id-type="pmid">22087288</pub-id>
      </element-citation>
    </ref>
    <ref id="btu080-B27">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Rohr</surname>
            <given-names>K</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Tracking and quantitative analysis of dynamic movements of cells and particles</article-title>
        <source>Cold Spring Harb. Protoc.</source>
        <year>2010</year>
        <volume>6</volume>
        <comment>pdb.top80</comment>
      </element-citation>
    </ref>
    <ref id="btu080-B28">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Svoboda</surname>
            <given-names>D</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Generation of digital phantoms of cell nuclei and simulation of image formation in 3D image cytometry</article-title>
        <source>Cytometry A</source>
        <year>2009</year>
        <volume>75</volume>
        <fpage>494</fpage>
        <lpage>509</lpage>
        <pub-id pub-id-type="pmid">19291805</pub-id>
      </element-citation>
    </ref>
    <ref id="btu080-B29">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Svoboda</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Ulman</surname>
            <given-names>V</given-names>
          </name>
        </person-group>
        <article-title>Generation of synthetic image datasets for time-lapse fluorescence microscopy</article-title>
        <source>International Conference on Image Analysis and Recognition</source>
        <year>2012</year>
        <fpage>473</fpage>
        <lpage>482</lpage>
      </element-citation>
    </ref>
    <ref id="btu080-B30">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zimmer</surname>
            <given-names>C</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Segmentation and tracking of migrating cells in videomicroscopy with parametric active contours: a tool for cell-based drug testing</article-title>
        <source>IEEE Trans. Med. Imaging.</source>
        <year>2002</year>
        <volume>21</volume>
        <fpage>1212</fpage>
        <lpage>1221</lpage>
        <pub-id pub-id-type="pmid">12585703</pub-id>
      </element-citation>
    </ref>
    <ref id="btu080-B31">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zimmer</surname>
            <given-names>C</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>On the digital trail of mobile cells</article-title>
        <source>IEEE Signal Process. Mag.</source>
        <year>2006</year>
        <volume>23</volume>
        <fpage>54</fpage>
        <lpage>62</lpage>
      </element-citation>
    </ref>
  </ref-list>
</back>
