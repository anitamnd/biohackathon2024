<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1d3 20150301//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 39.96?>
<?ConverterInfo.XSLTName jp2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
    <journal-id journal-id-type="iso-abbrev">PLoS Comput Biol</journal-id>
    <journal-id journal-id-type="publisher-id">plos</journal-id>
    <journal-id journal-id-type="pmc">ploscomp</journal-id>
    <journal-title-group>
      <journal-title>PLoS Computational Biology</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1553-734X</issn>
    <issn pub-type="epub">1553-7358</issn>
    <publisher>
      <publisher-name>Public Library of Science</publisher-name>
      <publisher-loc>San Francisco, CA USA</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">7990174</article-id>
    <article-id pub-id-type="pmid">33711013</article-id>
    <article-id pub-id-type="doi">10.1371/journal.pcbi.1008799</article-id>
    <article-id pub-id-type="publisher-id">PCOMPBIOL-D-20-02229</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Research Article</subject>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Microbiology</subject>
          <subj-group>
            <subject>Medical Microbiology</subject>
            <subj-group>
              <subject>Microbiome</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Genetics</subject>
          <subj-group>
            <subject>Genomics</subject>
            <subj-group>
              <subject>Microbial Genomics</subject>
              <subj-group>
                <subject>Microbiome</subject>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Microbiology</subject>
          <subj-group>
            <subject>Microbial Genomics</subject>
            <subj-group>
              <subject>Microbiome</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Computer and Information Sciences</subject>
        <subj-group>
          <subject>Artificial Intelligence</subject>
          <subj-group>
            <subject>Machine Learning</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Medicine and Health Sciences</subject>
        <subj-group>
          <subject>Oncology</subject>
          <subj-group>
            <subject>Cancers and Neoplasms</subject>
            <subj-group>
              <subject>Colorectal Cancer</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Research and Analysis Methods</subject>
        <subj-group>
          <subject>Simulation and Modeling</subject>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Computer and Information Sciences</subject>
        <subj-group>
          <subject>Artificial Intelligence</subject>
          <subj-group>
            <subject>Machine Learning</subject>
            <subj-group>
              <subject>Support Vector Machines</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Physical Sciences</subject>
        <subj-group>
          <subject>Mathematics</subject>
          <subj-group>
            <subject>Applied Mathematics</subject>
            <subj-group>
              <subject>Algorithms</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Research and Analysis Methods</subject>
        <subj-group>
          <subject>Simulation and Modeling</subject>
          <subj-group>
            <subject>Algorithms</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Physical Sciences</subject>
        <subj-group>
          <subject>Materials Science</subject>
          <subj-group>
            <subject>Materials</subject>
            <subj-group>
              <subject>Mixtures</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Engineering and Technology</subject>
        <subj-group>
          <subject>Measurement</subject>
          <subj-group>
            <subject>Distance Measurement</subject>
          </subj-group>
        </subj-group>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>DCMD: Distance-based classification using mixture distributions on microbiome data</article-title>
      <alt-title alt-title-type="running-head">DCMD</alt-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" equal-contrib="yes">
        <name>
          <surname>Shestopaloff</surname>
          <given-names>Konstantin</given-names>
        </name>
        <role content-type="https://casrai.org/credit/">Conceptualization</role>
        <role content-type="https://casrai.org/credit/">Formal analysis</role>
        <role content-type="https://casrai.org/credit/">Funding acquisition</role>
        <role content-type="https://casrai.org/credit/">Methodology</role>
        <role content-type="https://casrai.org/credit/">Resources</role>
        <role content-type="https://casrai.org/credit/">Software</role>
        <role content-type="https://casrai.org/credit/">Validation</role>
        <role content-type="https://casrai.org/credit/">Writing – original draft</role>
        <role content-type="https://casrai.org/credit/">Writing – review &amp; editing</role>
        <xref ref-type="aff" rid="aff001">
          <sup>1</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author" equal-contrib="yes">
        <contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-1735-5361</contrib-id>
        <name>
          <surname>Dong</surname>
          <given-names>Mei</given-names>
        </name>
        <role content-type="https://casrai.org/credit/">Data curation</role>
        <role content-type="https://casrai.org/credit/">Formal analysis</role>
        <role content-type="https://casrai.org/credit/">Funding acquisition</role>
        <role content-type="https://casrai.org/credit/">Methodology</role>
        <role content-type="https://casrai.org/credit/">Resources</role>
        <role content-type="https://casrai.org/credit/">Software</role>
        <role content-type="https://casrai.org/credit/">Validation</role>
        <role content-type="https://casrai.org/credit/">Visualization</role>
        <role content-type="https://casrai.org/credit/">Writing – original draft</role>
        <role content-type="https://casrai.org/credit/">Writing – review &amp; editing</role>
        <xref ref-type="aff" rid="aff001">
          <sup>1</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Gao</surname>
          <given-names>Fan</given-names>
        </name>
        <role content-type="https://casrai.org/credit/">Formal analysis</role>
        <role content-type="https://casrai.org/credit/">Writing – original draft</role>
        <role content-type="https://casrai.org/credit/">Writing – review &amp; editing</role>
        <xref ref-type="aff" rid="aff001">
          <sup>1</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Xu</surname>
          <given-names>Wei</given-names>
        </name>
        <role content-type="https://casrai.org/credit/">Conceptualization</role>
        <role content-type="https://casrai.org/credit/">Formal analysis</role>
        <role content-type="https://casrai.org/credit/">Funding acquisition</role>
        <role content-type="https://casrai.org/credit/">Investigation</role>
        <role content-type="https://casrai.org/credit/">Methodology</role>
        <role content-type="https://casrai.org/credit/">Project administration</role>
        <role content-type="https://casrai.org/credit/">Supervision</role>
        <role content-type="https://casrai.org/credit/">Validation</role>
        <role content-type="https://casrai.org/credit/">Writing – original draft</role>
        <role content-type="https://casrai.org/credit/">Writing – review &amp; editing</role>
        <xref ref-type="aff" rid="aff001">
          <sup>1</sup>
        </xref>
        <xref ref-type="aff" rid="aff002">
          <sup>2</sup>
        </xref>
        <xref ref-type="corresp" rid="cor001">*</xref>
      </contrib>
    </contrib-group>
    <aff id="aff001">
      <label>1</label>
      <addr-line>Dalla Lana School of Public Health, University of Toronto, Toronto, Ontario, CANADA</addr-line>
    </aff>
    <aff id="aff002">
      <label>2</label>
      <addr-line>Princess Margaret Cancer Centre, University Health Network, Toronto, Ontario, CANADA</addr-line>
    </aff>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Borenstein</surname>
          <given-names>Elhanan</given-names>
        </name>
        <role>Editor</role>
        <xref ref-type="aff" rid="edit1"/>
      </contrib>
    </contrib-group>
    <aff id="edit1">
      <addr-line>University of Washington, UNITED STATES</addr-line>
    </aff>
    <author-notes>
      <fn fn-type="COI-statement" id="coi001">
        <p>The authors have declared that no competing interests exist.</p>
      </fn>
      <corresp id="cor001">* E-mail: <email>wxu@uhnres.utoronto.ca</email></corresp>
    </author-notes>
    <pub-date pub-type="epub">
      <day>12</day>
      <month>3</month>
      <year>2021</year>
    </pub-date>
    <pub-date pub-type="collection">
      <month>3</month>
      <year>2021</year>
    </pub-date>
    <volume>17</volume>
    <issue>3</issue>
    <elocation-id>e1008799</elocation-id>
    <history>
      <date date-type="received">
        <day>10</day>
        <month>12</month>
        <year>2020</year>
      </date>
      <date date-type="accepted">
        <day>15</day>
        <month>2</month>
        <year>2021</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© 2021 Shestopaloff et al</copyright-statement>
      <copyright-year>2021</copyright-year>
      <copyright-holder>Shestopaloff et al</copyright-holder>
      <license xlink:href="http://creativecommons.org/licenses/by/4.0/">
        <license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
      </license>
    </permissions>
    <self-uri content-type="pdf" xlink:href="pcbi.1008799.pdf"/>
    <abstract>
      <p>Current advances in next-generation sequencing techniques have allowed researchers to conduct comprehensive research on the microbiome and human diseases, with recent studies identifying associations between the human microbiome and health outcomes for a number of chronic conditions. However, microbiome data structure, characterized by sparsity and skewness, presents challenges to building effective classifiers. To address this, we present an innovative approach for distance-based classification using mixture distributions (DCMD). The method aims to improve classification performance using microbiome community data, where the predictors are composed of sparse and heterogeneous count data. This approach models the inherent uncertainty in sparse counts by estimating a mixture distribution for the sample data and representing each observation as a distribution, conditional on observed counts and the estimated mixture, which are then used as inputs for distance-based classification. The method is implemented into a <italic>k</italic>-means classification and <italic>k</italic>-nearest neighbours framework. We develop two distance metrics that produce optimal results. The performance of the model is assessed using simulated and human microbiome study data, with results compared against a number of existing machine learning and distance-based classification approaches. The proposed method is competitive when compared to the other machine learning approaches, and shows a clear improvement over commonly used distance-based classifiers, underscoring the importance of modelling sparsity for achieving optimal results. The range of applicability and robustness make the proposed method a viable alternative for classification using sparse microbiome count data. The source code is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/kshestop/DCMD"><italic>https</italic>:<italic>//github</italic>.<italic>com/kshestop/DCMD</italic></ext-link> for academic use.</p>
    </abstract>
    <abstract abstract-type="summary">
      <title>Author summary</title>
      <p>The uneven performance of conventional distanced-based classifiers when using microbiome profiles to predict disease status has motivated us to develop a novel distance-based method that accounts for uncertainty when modeling sparse counts. We propose a classification algorithm that uses mixture distributions to measure normed distances between microbiome distributions, which better models the underlying structure by handling excess zeros and sparsity inherent in microbial abundance counts. Applications of DCMD have shown improved classification performance and robustness, making the proposed method an improved alternative for classification using microbiome data.</p>
    </abstract>
    <funding-group>
      <award-group id="award001">
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/501100000038</institution-id>
            <institution>Natural Sciences and Engineering Research Council of Canada</institution>
          </institution-wrap>
        </funding-source>
        <award-id>RGPIN-2017-06672</award-id>
        <principal-award-recipient>
          <name>
            <surname>Xu</surname>
            <given-names>Wei</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
      <award-group id="award002">
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/501100000038</institution-id>
            <institution>Natural Sciences and Engineering Research Council of Canada</institution>
          </institution-wrap>
        </funding-source>
        <award-id>RGPIN-2017-06672</award-id>
        <principal-award-recipient>
          <contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-1735-5361</contrib-id>
          <name>
            <surname>Dong</surname>
            <given-names>Mei</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
      <award-group id="award003">
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/501100007658</institution-id>
            <institution>Crohn's and Colitis Canada</institution>
          </institution-wrap>
        </funding-source>
        <award-id>CCC-GEMIII</award-id>
        <principal-award-recipient>
          <name>
            <surname>Xu</surname>
            <given-names>Wei</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
      <award-group id="award004">
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/501100007658</institution-id>
            <institution>Crohn's and Colitis Canada</institution>
          </institution-wrap>
        </funding-source>
        <award-id>CCC-GEMIII</award-id>
        <principal-award-recipient>
          <name>
            <surname>Shestopaloff</surname>
            <given-names>Konstantin</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
      <award-group id="award005">
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/501100007658</institution-id>
            <institution>Crohn's and Colitis Canada</institution>
          </institution-wrap>
        </funding-source>
        <award-id>CCC-GEMIII</award-id>
        <principal-award-recipient>
          <contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-1735-5361</contrib-id>
          <name>
            <surname>Dong</surname>
            <given-names>Mei</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
      <award-group id="award006">
        <funding-source>
          <institution>Leona M. and Harry B. Helmsley Charitable Trust (US)</institution>
        </funding-source>
        <principal-award-recipient>
          <name>
            <surname>Xu</surname>
            <given-names>Wei</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
      <funding-statement>W.X. was funded by Natural Sciences and Engineering Research Council of Canada (NSERC Grant RGPIN-2017-06672), Crohn’s and Colitis Canada (CCC Grant CCC-GEMIII), and Helmsley Charitable Trust. K.S. was supported by CCC Grant CCC-GEMIII. M.D. was supported by NSERC Grant RGPIN-2017-06672 and CCC Grant CCC-GEMIII. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
    </funding-group>
    <counts>
      <fig-count count="4"/>
      <table-count count="5"/>
      <page-count count="18"/>
    </counts>
    <custom-meta-group>
      <custom-meta>
        <meta-name>PLOS Publication Stage</meta-name>
        <meta-value>vor-update-to-uncorrected-proof</meta-value>
      </custom-meta>
      <custom-meta>
        <meta-name>Publication Update</meta-name>
        <meta-value>2021-03-24</meta-value>
      </custom-meta>
      <custom-meta id="data-availability">
        <meta-name>Data Availability</meta-name>
        <meta-value>The dataset analysed in this study is publicly available in the MLRepo repository. The colorectal cancer: <ext-link ext-link-type="uri" xlink:href="https://knights-lab.github.io/MLRepo/docs/kostic_healthy_tumor.html">https://knights-lab.github.io/MLRepo/docs/kostic_healthy_tumor.html</ext-link>; and the Crohn’s disease: <ext-link ext-link-type="uri" xlink:href="https://knights-lab.github.io/MLRepo/docs/gevers_control_cd_ileum.html">https://knights-lab.github.io/MLRepo/docs/gevers_control_cd_ileum.html</ext-link>.</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
  <notes>
    <title>Data Availability</title>
    <p>The dataset analysed in this study is publicly available in the MLRepo repository. The colorectal cancer: <ext-link ext-link-type="uri" xlink:href="https://knights-lab.github.io/MLRepo/docs/kostic_healthy_tumor.html">https://knights-lab.github.io/MLRepo/docs/kostic_healthy_tumor.html</ext-link>; and the Crohn’s disease: <ext-link ext-link-type="uri" xlink:href="https://knights-lab.github.io/MLRepo/docs/gevers_control_cd_ileum.html">https://knights-lab.github.io/MLRepo/docs/gevers_control_cd_ileum.html</ext-link>.</p>
  </notes>
</front>
<body>
  <disp-quote>
    <p>This is a <italic>PLOS Computational Biology</italic> Methods paper.</p>
  </disp-quote>
  <sec sec-type="intro" id="sec001">
    <title>Introduction</title>
    <p>The increasing accessibility of high-throughput technology has generated a wide array of data types for analysis. One type of data that has recently gained popularity is the microbiome community data, which is composed of site-specific counts for identified bacteria. There is a steadily growing number of studies that have demonstrated associations between the human microbiome and health outcomes, such as inflammatory bowel disease [<xref rid="pcbi.1008799.ref001" ref-type="bibr">1</xref>], type 2 diabetes [<xref rid="pcbi.1008799.ref002" ref-type="bibr">2</xref>], and cardiovascular disease [<xref rid="pcbi.1008799.ref003" ref-type="bibr">3</xref>], making it an important topic of research. However, the presence of sparsity and skewness, which characterizes this type of data, brings a number of challenges to statistical modelling. These challenges have motivated methodological developments that expand the existing algorithms, particularly for classification tasks related to disease risks.</p>
    <p>One popular class of approaches often used with microbiome data are distance-based methods, which differentiate and classify samples using distances derived from multivariate measures. Ubiquitous methods include <italic>k</italic>-means [<xref rid="pcbi.1008799.ref004" ref-type="bibr">4</xref>] and <italic>k</italic>-Nearest Neighbours (<italic>k</italic>-NN) [<xref rid="pcbi.1008799.ref005" ref-type="bibr">5</xref>], which have been adapted to such data with variable transformations using Euclidean distances, Manhattan distance, and several other measures [<xref rid="pcbi.1008799.ref006" ref-type="bibr">6</xref>–<xref rid="pcbi.1008799.ref008" ref-type="bibr">8</xref>]. Other adaptations such as the distance-based nearest shrunken centroid (NSC) classifier, which was developed for the use of microarray data [<xref rid="pcbi.1008799.ref009" ref-type="bibr">9</xref>]. NSC takes the average of the relative abundances for each class as class centroids [<xref rid="pcbi.1008799.ref010" ref-type="bibr">10</xref>,<xref rid="pcbi.1008799.ref011" ref-type="bibr">11</xref>] and then calculate standardized squared distances between new samples and class centroids.</p>
    <p>A number of linear and additive machine learning classifiers; such as LASSO, ridge regression (RR), random forest (RF), gradient boosting (GB), and support vector machines (SVM) are also commonly used for high-throughput data [<xref rid="pcbi.1008799.ref007" ref-type="bibr">7</xref>,<xref rid="pcbi.1008799.ref011" ref-type="bibr">11</xref>–<xref rid="pcbi.1008799.ref013" ref-type="bibr">13</xref>]. Some methods rely on penalization (LASSO and RR) in logistic models [<xref rid="pcbi.1008799.ref014" ref-type="bibr">14</xref>,<xref rid="pcbi.1008799.ref015" ref-type="bibr">15</xref>], typically with log-transformed adjusted counts or relative abundances of operational taxonomic units (OTUs) to address skewness [<xref rid="pcbi.1008799.ref016" ref-type="bibr">16</xref>]. The RF and GB algorithms rely on sequentially constructed classifiers and automatically incorporate feature selection [<xref rid="pcbi.1008799.ref017" ref-type="bibr">17</xref>,<xref rid="pcbi.1008799.ref018" ref-type="bibr">18</xref>]. Other recent methodological developments for microbiome data include regression models with a phylogenetic tree-guided penalty term [<xref rid="pcbi.1008799.ref019" ref-type="bibr">19</xref>] and inverse regression to deal with the over-dispersion of zeros in count data [<xref rid="pcbi.1008799.ref020" ref-type="bibr">20</xref>]. However, the tree-guided method can be overly influenced by tree information [<xref rid="pcbi.1008799.ref019" ref-type="bibr">19</xref>], and the phylogenetic tree is not always available. The existing methods incorporate observed count data or relative abundance directly when computing distances or defining covariates, with some kinds of transformation of OTUs to account for skewness. None of the methods explicitly account for and model the underlying uncertainty inherent in sparse count data.</p>
    <p>This paper aims to address these problems in a classification framework, where predictors are sparse and heterogeneous count data. Shestopaloff et al. [<xref rid="pcbi.1008799.ref021" ref-type="bibr">21</xref>] proposed representing count data using a mixture distribution to analyze the differences between microbiome communities. We extend the method to distance-based classification using mixture distributions (DCMD) that specifically addresses the uncertainty in sparse and low-count data. DCMD measures the distance between the sample-specific distributions of OTUs rather than between counts or relative abundances, which better models the structure of microbiome data for the distance measure. DCMD is also able to handle excess zero counts, which can potentially improve the predictive accuracy when using sparse OTUs. In this paper, we use two simulation studies to show the advantage of DCMD for classification over existing distance metrics and compare it against common machine learning methods. We provide a comprehensive comparison of distance-based classification methods (<italic>k</italic>-means, <italic>k</italic>-NN, and NSC) and machine learning methods (RF, GB, LASSO, RR, and SVM) in different simulation settings, which to our knowledge has not been studied before. We also illustrate the effectiveness of DCMD on two human microbiome studies [<xref rid="pcbi.1008799.ref022" ref-type="bibr">22</xref>,<xref rid="pcbi.1008799.ref023" ref-type="bibr">23</xref>]. The paper concludes with a discussion of the merits, drawbacks and the scope of applicability of the proposed methodology.</p>
  </sec>
  <sec sec-type="materials|methods" id="sec002">
    <title>Method</title>
    <p>In this section we outline the framework of DCMD. The main steps of the model include mixture distribution specification and parameter estimation for modelling observed data, calculation of conditional distributions for each sample, and calculating distances between samples and cluster centres to use in distance-based classification methods. The mixture model and conditional distribution estimation are described in Shestopaloff et al. [<xref rid="pcbi.1008799.ref021" ref-type="bibr">21</xref>]. It is proposed to model the underlying population rate structure of the observed count data using a mixture distribution with Poisson-Gamma components, then conditioning on observed sample counts and resolution to obtain sample-specific distributions. In the next step, we use the sample-specific distributions for classification by calculating the distances between distributions.</p>
    <sec id="sec003">
      <title>Model specification and estimation</title>
      <p>Microbiome data typically consists of OTU counts, as illustrated in <xref rid="pcbi.1008799.t001" ref-type="table">Table 1</xref>. The notations used in our method formulation are as follows:</p>
      <p><italic>n</italic><sub><italic>ij</italic></sub>, <italic>i</italic> = 1,…,<italic>I</italic> for <italic>j</italic> = 1,…,<italic>J</italic>, the count of the <italic>j</italic>th OTU of the <italic>i</italic>th sample.</p>
      <p><italic>N</italic><sub><italic>i</italic></sub>, the total number of aligned reads of sample <italic>i</italic>, <italic>N</italic><sub><italic>i</italic></sub> = ∑<sub><italic>j</italic></sub><italic>n</italic><sub><italic>ij</italic></sub></p>
      <table-wrap id="pcbi.1008799.t001" orientation="portrait" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1008799.t001</object-id>
        <label>Table 1</label>
        <caption>
          <title>An OTU table for microbiome data.</title>
        </caption>
        <alternatives>
          <graphic id="pcbi.1008799.t001g" xlink:href="pcbi.1008799.t001"/>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th align="center" style="background-color:#AEAAAA" rowspan="1" colspan="1"/>
                <th align="center" style="background-color:#AEAAAA" rowspan="1" colspan="1">OTU 1</th>
                <th align="center" style="background-color:#AEAAAA" rowspan="1" colspan="1">…</th>
                <th align="center" style="background-color:#AEAAAA" rowspan="1" colspan="1">OTU J</th>
                <th align="center" style="background-color:#AEAAAA" rowspan="1" colspan="1">Total Reads</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">Sample 1</td>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">
                  <italic>n</italic>
                  <sub>11</sub>
                </td>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">
                  <bold>…</bold>
                </td>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">
                  <italic>n</italic>
                  <sub>1<italic>j</italic></sub>
                </td>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">
                  <italic>N</italic>
                  <sub>1</sub>
                </td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">⁝</td>
                <td align="center" rowspan="1" colspan="1">
                  <bold>⁝</bold>
                </td>
                <td align="center" rowspan="1" colspan="1"/>
                <td align="center" rowspan="1" colspan="1">
                  <bold>⁝</bold>
                </td>
                <td align="center" rowspan="1" colspan="1"/>
              </tr>
              <tr>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">Sample I</td>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">
                  <italic>n</italic>
                  <sub><italic>I</italic>1</sub>
                </td>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">
                  <bold>…</bold>
                </td>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">
                  <italic>n</italic>
                  <sub>
                    <italic>IJ</italic>
                  </sub>
                </td>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">
                  <italic>N</italic>
                  <sub>
                    <italic>I</italic>
                  </sub>
                </td>
              </tr>
            </tbody>
          </table>
        </alternatives>
      </table-wrap>
      <p>Without loss of generality, we focus on a specific OTU and omit the <italic>j</italic>th subscript for subsequent notation. Assume that the observed counts, <italic>n</italic><sub><italic>i</italic></sub>, are Poisson distributed with rate <italic>r</italic><sub><italic>i</italic></sub> = <italic>q</italic><sub><italic>i</italic></sub><italic>N</italic><sub><italic>i</italic></sub>, <italic>i</italic> = 1,…,<italic>I</italic> for sample <italic>i</italic>, where <italic>q</italic><sub><italic>i</italic></sub> is the individual-specific relative abundance and is sampled from some general OTU relative abundance distribution <italic>G</italic><sub><italic>q</italic></sub>. Then we have,
<disp-formula id="pcbi.1008799.e001"><alternatives><graphic xlink:href="pcbi.1008799.e001.jpg" id="pcbi.1008799.e001g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M1"><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo>*</mml:mo></mml:mrow></mml:msubsup><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:math></alternatives></disp-formula>
where <inline-formula id="pcbi.1008799.e002"><alternatives><graphic xlink:href="pcbi.1008799.e002.jpg" id="pcbi.1008799.e002g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M2"><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>/</mml:mo><mml:mover accent="true"><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mo>¯</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>*</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mover accent="true"><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mo>¯</mml:mo></mml:mover></mml:math></alternatives></inline-formula>, and <inline-formula id="pcbi.1008799.e003"><alternatives><graphic xlink:href="pcbi.1008799.e003.jpg" id="pcbi.1008799.e003g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M3"><mml:mover accent="true"><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mo>¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>/</mml:mo><mml:mi>I</mml:mi></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>, with <inline-formula id="pcbi.1008799.e004"><alternatives><graphic xlink:href="pcbi.1008799.e004.jpg" id="pcbi.1008799.e004g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M4"><mml:msubsup><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>*</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> sampled from <inline-formula id="pcbi.1008799.e005"><alternatives><graphic xlink:href="pcbi.1008799.e005.jpg" id="pcbi.1008799.e005g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M5"><mml:mi>G</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mi>q</mml:mi></mml:mrow></mml:msub><mml:mover accent="true"><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mo>¯</mml:mo></mml:mover></mml:math></alternatives></inline-formula>, which is the rate normalized to the average sample reads to make sure that the counts are treated on the same scale. Thus, the observed count for a specific site of OTU is
<disp-formula id="pcbi.1008799.e006"><alternatives><graphic xlink:href="pcbi.1008799.e006.jpg" id="pcbi.1008799.e006g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M6"><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo>*</mml:mo></mml:mrow></mml:msubsup><mml:mo>~</mml:mo><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo>*</mml:mo></mml:mrow></mml:msubsup><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo><mml:mo>,</mml:mo></mml:math></alternatives></disp-formula>
<disp-formula id="pcbi.1008799.e007"><alternatives><graphic xlink:href="pcbi.1008799.e007.jpg" id="pcbi.1008799.e007g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M7"><mml:msubsup><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo>*</mml:mo></mml:mrow></mml:msubsup><mml:mo>∼</mml:mo><mml:mi>G</mml:mi><mml:mo>.</mml:mo></mml:math></alternatives></disp-formula></p>
      <p>Since the distribution of OTU is zero-inflated, skewed, and heavy tailed, we propose a mixture distribution to approximate <italic>G</italic>. For positive rates on a given interval, we specify a set of Gamma components, Γ(<italic>α</italic>, <italic>β</italic>), with shape <italic>α</italic> and rate <italic>β</italic>, to cover the range of the data. To separate structural zeros from low-rate and undetected samples, we include a zero-point mass, <inline-formula id="pcbi.1008799.e008"><alternatives><graphic xlink:href="pcbi.1008799.e008.jpg" id="pcbi.1008799.e008g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M8"><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo>*</mml:mo></mml:mrow></mml:msubsup><mml:mo>∼</mml:mo><mml:mn>0</mml:mn></mml:math></alternatives></inline-formula>, where <italic>P</italic>(<italic>n</italic><sub><italic>i</italic></sub> = 0) = 1. Additionally, for sparse high rates, we define a high-count point mass, <inline-formula id="pcbi.1008799.e009"><alternatives><graphic xlink:href="pcbi.1008799.e009.jpg" id="pcbi.1008799.e009g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M9"><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo>*</mml:mo></mml:mrow></mml:msubsup><mml:mo>∼</mml:mo><mml:mi>C</mml:mi><mml:mo>·</mml:mo><mml:mn mathvariant="bold">1</mml:mn><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:mi>C</mml:mi><mml:mo>)</mml:mo></mml:math></alternatives></inline-formula>, where <italic>P</italic>(<italic>n</italic><sub><italic>i</italic></sub>&gt;<italic>C</italic>) = 1, <italic>C</italic> is the truncation point and <bold>1</bold>(∙) is the indicator function. The full set of mixture components is <bold>Ω</bold> = (<italic>G</italic><sub><italic>z</italic></sub>, <italic>G</italic><sub>1</sub>, <italic>G</italic><sub>2</sub>,…,<italic>G</italic><sub><italic>M</italic></sub>, <italic>G</italic><sub><italic>C</italic>+</sub>) where <italic>G</italic><sub><italic>z</italic></sub> is a zero-point mass, <italic>G</italic><sub><italic>m</italic></sub>, <italic>m</italic> = 1,2,…,<italic>M</italic>, is a set of Gammas components Γ(<italic>α</italic><sub><italic>m</italic></sub>, <italic>β</italic><sub><italic>m</italic></sub>), and <italic>G</italic><sub><italic>C</italic>+</sub> is a high-count point mass. The process for defining the mixture model components is described in detail in the Simulation section.</p>
      <p>Define the weight of each component as
<disp-formula id="pcbi.1008799.e010"><alternatives><graphic xlink:href="pcbi.1008799.e010.jpg" id="pcbi.1008799.e010g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M10"><mml:mi mathvariant="bold-italic">w</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mo>+</mml:mo></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>′</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo></mml:math></alternatives></disp-formula>
where <italic>w</italic><sub><italic>z</italic></sub> is the weight of the zero-point mass, <italic>w</italic><sub><italic>m</italic></sub>, <italic>m</italic> = 1,2,…,<italic>M</italic>, is the weight for <italic>m</italic>th corresponding Gamma component, and <italic>w</italic><sub><italic>C</italic>+</sub> is the weight of high-count point mass. Define
<disp-formula id="pcbi.1008799.e011"><alternatives><graphic xlink:href="pcbi.1008799.e011.jpg" id="pcbi.1008799.e011g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M11"><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mstyle><mml:mrow><mml:msub><mml:mrow><mml:mn mathvariant="bold">1</mml:mn><mml:mo>(</mml:mo><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives></disp-formula>
the number of species observed <italic>x</italic> times across all samples for <italic>x</italic> = <italic>z</italic>, 0,1,2,…,<italic>C</italic>,<italic>C</italic>+. Then our goal is to minimize <inline-formula id="pcbi.1008799.e012"><alternatives><graphic xlink:href="pcbi.1008799.e012.jpg" id="pcbi.1008799.e012g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M12"><mml:mrow><mml:msubsup><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mo>+</mml:mo></mml:mrow></mml:msubsup><mml:mrow><mml:msup><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msubsup><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>E</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>, where <inline-formula id="pcbi.1008799.e013"><alternatives><graphic xlink:href="pcbi.1008799.e013.jpg" id="pcbi.1008799.e013g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M13"><mml:msubsup><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>E</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> is the expected aggregate counts of <italic>y</italic><sub><italic>x</italic></sub>. Note that given Γ(<italic>α</italic><sub><italic>m</italic></sub>, <italic>β</italic><sub><italic>m</italic></sub>), sample counts conditional on <italic>t</italic><sub><italic>i</italic></sub> are distributed as a negative binomial <italic>NB</italic>[<italic>α</italic><sub><italic>m</italic></sub>, <italic>β</italic><sub><italic>m</italic></sub>/(<italic>t</italic><sub><italic>i</italic></sub>+<italic>β</italic><sub><italic>m</italic></sub>)] [<xref rid="pcbi.1008799.ref021" ref-type="bibr">21</xref>]. Define
<disp-formula id="pcbi.1008799.e014"><alternatives><graphic xlink:href="pcbi.1008799.e014.jpg" id="pcbi.1008799.e014g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M14"><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mi>m</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi>X</mml:mi><mml:mo>=</mml:mo><mml:mi>x</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:math></alternatives></disp-formula>
as the probability of observing count x from the mth mixture component conditional on the resolution <italic>t</italic><sub><italic>i</italic></sub>. Then <inline-formula id="pcbi.1008799.e015"><alternatives><graphic xlink:href="pcbi.1008799.e015.jpg" id="pcbi.1008799.e015g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M15"><mml:msubsup><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:mi mathvariant="bold-italic">w</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mo>∙</mml:mo><mml:mi>I</mml:mi></mml:math></alternatives></inline-formula>, where <italic>p</italic><sub><italic>xm</italic></sub> = ∑<sub><italic>i</italic></sub><italic>p</italic><sub><italic>xmi</italic></sub>/<italic>I</italic>. Thus, we have the objective function:
<disp-formula id="pcbi.1008799.e016"><alternatives><graphic xlink:href="pcbi.1008799.e016.jpg" id="pcbi.1008799.e016g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M16"><mml:mrow><mml:mi mathvariant="italic">arg</mml:mi><mml:mspace width="0.25em"/><mml:munder><mml:mrow><mml:mi mathvariant="italic">min</mml:mi></mml:mrow><mml:mover accent="true"><mml:mi>w</mml:mi><mml:mo>→</mml:mo></mml:mover></mml:munder><mml:msubsup><mml:mstyle displaystyle="false"><mml:mo>∑</mml:mo></mml:mstyle><mml:mrow><mml:mi>x</mml:mi><mml:mo>=</mml:mo><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mo>+</mml:mo></mml:mrow></mml:msubsup><mml:msup><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mstyle displaystyle="false"><mml:mo>∑</mml:mo></mml:mstyle><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:mi mathvariant="bold-italic">w</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>w</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>x</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mi>I</mml:mi></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives><label>(1)</label></disp-formula>
<disp-formula id="pcbi.1008799.e017"><alternatives><graphic xlink:href="pcbi.1008799.e017.jpg" id="pcbi.1008799.e017g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M17"><mml:mi>s</mml:mi><mml:mo>.</mml:mo><mml:mi>t</mml:mi><mml:mo>.</mml:mo><mml:mrow><mml:msub><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo>≥</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mo>∀</mml:mo><mml:mi>m</mml:mi><mml:mo>.</mml:mo></mml:math></alternatives></disp-formula></p>
      <p>The estimate, <inline-formula id="pcbi.1008799.e018"><alternatives><graphic xlink:href="pcbi.1008799.e018.jpg" id="pcbi.1008799.e018g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M18"><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold-italic">w</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula>, is obtained by optimizing the least-squares objective function (1), using the Broyden-Fletcher-Goldfarb-Shanno (BFGS) algorithm [<xref rid="pcbi.1008799.ref024" ref-type="bibr">24</xref>] with the augmented Lagrangian method [<xref rid="pcbi.1008799.ref025" ref-type="bibr">25</xref>] for the constraints.</p>
      <p>Due to the sparse nature of the data, we only optimize the weights and fix the Gamma parameters. Attempting to model the low-rate structure by optimizing both weights and Gamma parameters (<italic>α</italic><sub><italic>m</italic></sub>, <italic>β</italic><sub><italic>m</italic></sub>) via expectation-maximization (EM) results in biased structural zero estimates and a poor overall fit of the low counts [<xref rid="pcbi.1008799.ref026" ref-type="bibr">26</xref>]. In this context, the EM is also prone to numerical issues, convergence to local minima and can often be too slow computationally for this type of application [<xref rid="pcbi.1008799.ref026" ref-type="bibr">26</xref>]. On the other hand, BFGS provides a much faster and robust alternative.</p>
    </sec>
    <sec id="sec004">
      <title>Weighted mixture distribution</title>
      <p>To address the uncertainty around specifying components for the mixture model, particularly for the low rates where sparsity is often an issue, we define a set of nested models Φ<sub><italic>l</italic></sub>, <italic>l</italic> = 1,…,<italic>L</italic>, with varying components for modelling the rate structure around zero. We estimate the joint mixture model using a nonparametric bootstrap algorithm. As stated in Shestopaloff et al. [<xref rid="pcbi.1008799.ref021" ref-type="bibr">21</xref>], we can obtain the weight <italic>v</italic>(<italic>l</italic>) of each candidate model, which is the proportion of times each model is selected as optimal relative to the observed data, and calculate the weights for the joint mixture distribution. Let <bold><italic>w</italic></bold><sub><italic>l</italic></sub> be the estimated weights for each candidate model, Φ<sub><italic>l</italic></sub>, with zeros assigned to the weights of components not included in a specific model, then the weights of the joint model are <bold><italic>w</italic></bold> = ∑<sub><italic>l</italic></sub><italic>v</italic>(<italic>l</italic>)<bold><italic>w</italic></bold><sub><italic>l</italic></sub>.</p>
    </sec>
    <sec id="sec005">
      <title>Sample-specific distribution</title>
      <p>Once we have a distribution for the OTU, we can estimate sample-specific distributions by conditioning on the observed count <italic>n</italic><sub><italic>i</italic></sub>, estimated mixture weights <bold><italic>w</italic></bold>, and resolution <italic>t</italic><sub><italic>i</italic></sub>. We can obtain the probability that sample <italic>i</italic> sampled from a specific component, as:
<disp-formula id="pcbi.1008799.e019"><alternatives><graphic xlink:href="pcbi.1008799.e019.jpg" id="pcbi.1008799.e019g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M19"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mi>G</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">w</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:msub><mml:mi>G</mml:mi><mml:mi>m</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">Γ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mi>m</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">Γ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi mathvariant="normal">Γ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>α</mml:mi><mml:mi>m</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mi>β</mml:mi><mml:mi>m</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mi>m</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mi>α</mml:mi><mml:mi>m</mml:mi></mml:msub></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>β</mml:mi><mml:mi>m</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mi>m</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msup><mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives><label>(2)</label></disp-formula></p>
      <p>The probability of being assigned to the zero-point mass is <italic>P</italic>(<italic>i</italic>∈<italic>G</italic><sub>0</sub>) = <bold>1</bold>(<italic>n</italic><sub><italic>i</italic></sub> = 0) and to the high-count point mass is <italic>P</italic>(<italic>i</italic>∈<italic>G</italic><sub><italic>C</italic>+</sub>) = <bold>1</bold>(<italic>n</italic><sub><italic>i</italic></sub>&gt;<italic>C</italic>). Define the sample-specific mixture weights as
<disp-formula id="pcbi.1008799.e020"><alternatives><graphic xlink:href="pcbi.1008799.e020.jpg" id="pcbi.1008799.e020g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M20"><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">w</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>C</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>C</mml:mi><mml:mo>+</mml:mo></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>′</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo></mml:math></alternatives></disp-formula>
where
<disp-formula id="pcbi.1008799.e021"><alternatives><graphic xlink:href="pcbi.1008799.e021.jpg" id="pcbi.1008799.e021g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M21"><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>P</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo><mml:mo>/</mml:mo><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mo>∑</mml:mo><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:mstyle><mml:mrow><mml:mi>P</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo>/</mml:mo><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mo>∑</mml:mo><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:mstyle><mml:mrow><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives></disp-formula></p>
      <p>Since the sample-specific weights have been adjusted for the individual resolutions <italic>t</italic><sub><italic>i</italic></sub> through the <italic>p</italic><sub><italic>im</italic></sub> probabilities, the Poisson-Gamma mixture probabilities are <italic>NB</italic>(<italic>α</italic>, <italic>β</italic>/(1+<italic>β</italic>)). Also note that we have differentiated the zeros in our mixture distribution, which are defined as structural zeros, <italic>x = z</italic>, and observed zeros, <italic>x =</italic> 0. Given the underlying rate distribution from the joint mixture model, we can then calculate the probability of observing count <italic>x</italic> = <italic>z</italic>, 0,1,…,<italic>C</italic>, <italic>C</italic>+ from each mixture component <italic>G</italic><sub><italic>m</italic></sub> as
<disp-formula id="pcbi.1008799.e022"><alternatives><graphic xlink:href="pcbi.1008799.e022.jpg" id="pcbi.1008799.e022g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M22"><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mi>P</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi>X</mml:mi><mml:mo>=</mml:mo><mml:mi>x</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>X</mml:mi><mml:mo>=</mml:mo><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo><mml:mo>.</mml:mo></mml:math></alternatives></disp-formula></p>
      <p>For the point masses we have <italic>P</italic>(<italic>X</italic> = <italic>x</italic>|<italic>G</italic><sub><italic>z</italic></sub>) = <bold>1</bold>(<italic>n</italic><sub><italic>i</italic></sub> = 0) and <italic>P</italic>(<italic>X</italic> = <italic>x</italic>|<italic>G</italic><sub><italic>C</italic>+</sub>) = <bold>1</bold>(<italic>n</italic><sub><italic>i</italic></sub>&gt;<italic>C</italic>), respectively. To simplify the representation of the distribution, define a vector of probabilities
<disp-formula id="pcbi.1008799.e023"><alternatives><graphic xlink:href="pcbi.1008799.e023.jpg" id="pcbi.1008799.e023g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M23"><mml:mi mathvariant="bold-italic">P</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mo>[</mml:mo><mml:mrow><mml:mi>P</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi>X</mml:mi><mml:mo>=</mml:mo><mml:mi>x</mml:mi></mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo><mml:mo>,</mml:mo><mml:mi>P</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi>X</mml:mi><mml:mo>=</mml:mo><mml:mi>x</mml:mi></mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>P</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi>X</mml:mi><mml:mo>=</mml:mo><mml:mi>x</mml:mi></mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo><mml:mo>,</mml:mo><mml:mi>P</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi>X</mml:mi><mml:mo>=</mml:mo><mml:mi>x</mml:mi></mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mo>+</mml:mo></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>]</mml:mo></mml:math></alternatives></disp-formula>
<disp-formula id="pcbi.1008799.e024"><alternatives><graphic xlink:href="pcbi.1008799.e024.jpg" id="pcbi.1008799.e024g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M24"><mml:mo>=</mml:mo><mml:mo>[</mml:mo><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mo>+</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>]</mml:mo><mml:mo>,</mml:mo></mml:math></alternatives></disp-formula>
for <italic>x</italic> = <italic>z</italic>, 0,1,…,<italic>C</italic>, <italic>C</italic>+. Then we can define the discrete probability density for sample <italic>i</italic> as
<disp-formula id="pcbi.1008799.e025"><alternatives><graphic xlink:href="pcbi.1008799.e025.jpg" id="pcbi.1008799.e025g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M25"><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">P</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mn>0</mml:mn></mml:mrow><mml:mo>)</mml:mo><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>C</mml:mi><mml:mo>+</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>]</mml:mo><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">w</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mo>′</mml:mo></mml:mrow></mml:msup><mml:mi mathvariant="bold-italic">P</mml:mi><mml:mo>,</mml:mo></mml:math></alternatives></disp-formula>
where
<disp-formula id="pcbi.1008799.e026"><alternatives><graphic xlink:href="pcbi.1008799.e026.jpg" id="pcbi.1008799.e026g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M26"><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:math></alternatives></disp-formula>
<disp-formula id="pcbi.1008799.e027"><alternatives><graphic xlink:href="pcbi.1008799.e027.jpg" id="pcbi.1008799.e027g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M27"><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>C</mml:mi><mml:mo>+</mml:mo></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mo>[</mml:mo><mml:mrow><mml:mstyle displaystyle="false"><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mi>C</mml:mi></mml:mrow></mml:msubsup></mml:mstyle><mml:mrow><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>]</mml:mo><mml:mo>,</mml:mo></mml:math></alternatives></disp-formula>
<disp-formula id="pcbi.1008799.e028"><alternatives><graphic xlink:href="pcbi.1008799.e028.jpg" id="pcbi.1008799.e028g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M28"><mml:mi mathvariant="bold-italic">P</mml:mi><mml:mo>=</mml:mo><mml:mo>[</mml:mo><mml:mi mathvariant="bold-italic">P</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">P</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mn>0</mml:mn></mml:mrow><mml:mo>)</mml:mo><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">P</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">P</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi>C</mml:mi><mml:mo>+</mml:mo></mml:mrow><mml:mo>)</mml:mo><mml:mo>]</mml:mo><mml:mo>.</mml:mo></mml:math></alternatives></disp-formula></p>
      <p>The <bold><italic>P</italic></bold>(<italic>x</italic>) vectors in the matrix <bold><italic>P</italic></bold> are the vectors giving the probability of observing <italic>x</italic> from each mixture component, which can be pre-calculated for distance calculations. The overview of how to obtain sample-specific mixture distributions given a set of mixture distribution components is shown in <xref ref-type="fig" rid="pcbi.1008799.g001">Fig 1</xref>.</p>
      <fig id="pcbi.1008799.g001" orientation="portrait" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1008799.g001</object-id>
        <label>Fig 1</label>
        <caption>
          <p>Workflow for obtaining a sample-specific mixture distribution for each sample i in OTU j: 1) Specify a set of nested candidate mixture distributions using a specific set of components; 2) Apply bootstrap to the set of nested models and calculate the weights of each candidate mixture model, then calculate the weights of the joint mixture distribution; 3) Estimate sample-specific distributions conditional on <italic>n</italic><sub><italic>i</italic></sub>, <italic>t</italic><sub><italic>i</italic></sub>, and the joint mixture distribution.</p>
        </caption>
        <graphic xlink:href="pcbi.1008799.g001"/>
      </fig>
    </sec>
    <sec id="sec006">
      <title>Classification</title>
      <p>Once the distribution for each sample has been computed, we use <italic>k-</italic>means and <italic>k-</italic>Nearest Neighbours (<italic>k</italic>-NN) algorithms for classification. In this section, we outline how to apply these algorithms using two distance measures, discrete <italic>L</italic><sup>2</sup> (D-<italic>L</italic><sup>2</sup>) norm and continuous cumulative <italic>L</italic><sup>2</sup> (CC-<italic>L</italic><sup>2</sup>) norm.</p>
    </sec>
    <sec id="sec007">
      <title>Distance measures</title>
      <p>Given posterior probability <italic>f</italic><sub><italic>i</italic></sub>, cumulative posterior probability <italic>F</italic><sub><italic>i</italic></sub>, and an estimated set of weights <italic>w</italic><sub><italic>i</italic></sub> for sample <italic>i</italic>, the distance metrics are:</p>
      <p><bold>D-<italic>L</italic><sup>2</sup> Norm</bold>:
<disp-formula id="pcbi.1008799.e029"><alternatives><graphic xlink:href="pcbi.1008799.e029.jpg" id="pcbi.1008799.e029g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M29"><mml:msub><mml:mrow><mml:mi>δ</mml:mi></mml:mrow><mml:mrow><mml:mi>D</mml:mi><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:munder><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:msup><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></alternatives></disp-formula><disp-formula id="pcbi.1008799.e030"><alternatives><graphic xlink:href="pcbi.1008799.e030.jpg" id="pcbi.1008799.e030g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M30"><mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mstyle displaystyle="false"><mml:mo>∑</mml:mo></mml:mstyle><mml:mi>x</mml:mi></mml:msub><mml:msup><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">w</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">w</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mi mathvariant="bold-italic">P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives><label>(3)</label></disp-formula>
where <italic>x</italic> = <italic>z</italic>, 0,1,…,<italic>C</italic>, <italic>C</italic>+. Note that we include the structural zero component, z, separately and that the distances only depend on the weights. For multiple predictors, j = 1, …, J, the total distance between samples <italic>i</italic><sub>1</sub> and <italic>i</italic><sub>2</sub> is the sum across all predictors, <inline-formula id="pcbi.1008799.e031"><alternatives><graphic xlink:href="pcbi.1008799.e031.jpg" id="pcbi.1008799.e031g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M31"><mml:mi>D</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:msub><mml:mrow><mml:mi>δ</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>.</p>
      <p><bold>CC-<italic>L</italic></bold><sup><bold>2</bold></sup><bold>Norm</bold>:
<disp-formula id="pcbi.1008799.e032"><alternatives><graphic xlink:href="pcbi.1008799.e032.jpg" id="pcbi.1008799.e032g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M32"><mml:msub><mml:mrow><mml:mi>δ</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mi>C</mml:mi><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:msubsup><mml:mo stretchy="false">∫</mml:mo><mml:mrow><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mi>C</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:msup><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow><mml:mi>d</mml:mi><mml:mi>x</mml:mi></mml:math></alternatives></disp-formula><disp-formula id="pcbi.1008799.e033"><alternatives><graphic xlink:href="pcbi.1008799.e033.jpg" id="pcbi.1008799.e033g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M33"><mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">w</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">w</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">G</mml:mi><mml:mrow><mml:msub><mml:mi>m</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:msub><mml:mi>m</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:msub><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">w</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">w</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>′</mml:mo></mml:msup><mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives><label>(4)</label></disp-formula>
where <inline-formula id="pcbi.1008799.e034"><alternatives><graphic xlink:href="pcbi.1008799.e034.jpg" id="pcbi.1008799.e034g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M34"><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">G</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math></alternatives></inline-formula> is a matrix with the (<italic>m</italic><sub>1</sub>, <italic>m</italic><sub>2</sub>) entry set to <inline-formula id="pcbi.1008799.e035"><alternatives><graphic xlink:href="pcbi.1008799.e035.jpg" id="pcbi.1008799.e035g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M35"><mml:mrow><mml:mo stretchy="false">∫</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo><mml:msub><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mi>d</mml:mi><mml:mi>x</mml:mi></mml:math></alternatives></inline-formula> for each of the continuous mixture component. Details of the derivation can be found in Shestopaloff [<xref rid="pcbi.1008799.ref026" ref-type="bibr">26</xref>].</p>
      <sec id="sec008">
        <title>Distance-based classification</title>
        <p>We use the distances calculated in Eqs (<xref ref-type="disp-formula" rid="pcbi.1008799.e030">3</xref>) and (<xref ref-type="disp-formula" rid="pcbi.1008799.e033">4</xref>) in a <italic>k</italic>-means and <italic>k</italic>-NN framework. In <italic>k</italic>-means, the mean of each class is calculated from the training data and points are classified to the nearest class. In <italic>k</italic>-NN, samples are classified as the mode of the labels from <italic>k</italic> closest neighbours of the training set. The steps of <italic>k</italic>-means and <italic>k</italic>-NN algorithms are as follows:</p>
        <p><bold><italic>K</italic>-means</bold>: To adapt the <italic>k</italic>-means algorithm, we estimate the mean distribution for each class by minimizing the distributional distances between it and the class samples, conditional on a specified distance. Since distances are <italic>L</italic><sup>2</sup> norms and only depend on the weights, as shown in Eqs (<xref ref-type="disp-formula" rid="pcbi.1008799.e030">3</xref>) and (<xref ref-type="disp-formula" rid="pcbi.1008799.e033">4</xref>), the mean of the weights for each class gives the optimum. The algorithm is implemented as follows:</p>
        <list list-type="simple">
          <list-item>
            <p>Step 1: Determine the mean of the weights for the <italic>j</italic>th predictor in class <italic>k</italic>,</p>
          </list-item>
        </list>
        <p><inline-formula id="pcbi.1008799.e036"><alternatives><graphic xlink:href="pcbi.1008799.e036.jpg" id="pcbi.1008799.e036g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M36"><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">w</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">μ</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">k</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">w</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">k</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mo>/</mml:mo><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>|</mml:mo></mml:math></alternatives></inline-formula>, where |<italic>N</italic><sub><italic>k</italic>,<italic>j</italic></sub>| is the number of samples in class <italic>k</italic> of predictor j, <italic>k</italic> = 1,…,<italic>K</italic> and <italic>j</italic> = 1,…,<italic>J</italic>;</p>
        <list list-type="simple">
          <list-item>
            <p>Step 2: Compute the distance to the mean for sample <italic>i</italic> across all predictors,</p>
          </list-item>
        </list>
        <disp-formula id="pcbi.1008799.e037">
          <alternatives>
            <graphic xlink:href="pcbi.1008799.e037.jpg" id="pcbi.1008799.e037g" mimetype="image" position="anchor" orientation="portrait"/>
            <mml:math id="M37">
              <mml:mi>D</mml:mi>
              <mml:mo>(</mml:mo>
              <mml:mrow>
                <mml:mi>i</mml:mi>
                <mml:mo>,</mml:mo>
                <mml:msub>
                  <mml:mrow>
                    <mml:mi>μ</mml:mi>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mi>k</mml:mi>
                  </mml:mrow>
                </mml:msub>
              </mml:mrow>
              <mml:mo>)</mml:mo>
              <mml:mo>=</mml:mo>
              <mml:mrow>
                <mml:mstyle displaystyle="false">
                  <mml:msub>
                    <mml:mo>∑</mml:mo>
                    <mml:mrow>
                      <mml:mi>j</mml:mi>
                    </mml:mrow>
                  </mml:msub>
                </mml:mstyle>
                <mml:mrow>
                  <mml:mi>δ</mml:mi>
                  <mml:mo>(</mml:mo>
                  <mml:mrow>
                    <mml:msub>
                      <mml:mrow>
                        <mml:mi mathvariant="bold-italic">P</mml:mi>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mi mathvariant="bold-italic">i</mml:mi>
                        <mml:mo>,</mml:mo>
                        <mml:mi mathvariant="bold-italic">j</mml:mi>
                      </mml:mrow>
                    </mml:msub>
                    <mml:mo>,</mml:mo>
                    <mml:msub>
                      <mml:mrow>
                        <mml:mi mathvariant="bold-italic">P</mml:mi>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:msub>
                          <mml:mrow>
                            <mml:mi mathvariant="bold-italic">μ</mml:mi>
                          </mml:mrow>
                          <mml:mrow>
                            <mml:mi mathvariant="bold-italic">k</mml:mi>
                          </mml:mrow>
                        </mml:msub>
                        <mml:mo>,</mml:mo>
                        <mml:mi mathvariant="bold-italic">j</mml:mi>
                      </mml:mrow>
                    </mml:msub>
                  </mml:mrow>
                  <mml:mo>)</mml:mo>
                </mml:mrow>
                <mml:mo>;</mml:mo>
              </mml:mrow>
            </mml:math>
          </alternatives>
        </disp-formula>
        <list list-type="simple">
          <list-item>
            <p>Step 3: Predict the label of sample <italic>i</italic> as the closest mean,</p>
          </list-item>
        </list>
        <disp-formula id="pcbi.1008799.e038">
          <alternatives>
            <graphic xlink:href="pcbi.1008799.e038.jpg" id="pcbi.1008799.e038g" mimetype="image" position="anchor" orientation="portrait"/>
            <mml:math id="M38">
              <mml:msub>
                <mml:mrow>
                  <mml:mover accent="true">
                    <mml:mrow>
                      <mml:mi>y</mml:mi>
                    </mml:mrow>
                    <mml:mo>^</mml:mo>
                  </mml:mover>
                </mml:mrow>
                <mml:mrow>
                  <mml:mi>i</mml:mi>
                </mml:mrow>
              </mml:msub>
              <mml:mo>=</mml:mo>
              <mml:mrow>
                <mml:mrow>
                  <mml:munder>
                    <mml:mrow>
                      <mml:mi mathvariant="italic">argmin</mml:mi>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mi>k</mml:mi>
                    </mml:mrow>
                  </mml:munder>
                </mml:mrow>
                <mml:mspace width="0.25em"/>
                <mml:mrow>
                  <mml:mi>D</mml:mi>
                  <mml:mo>(</mml:mo>
                  <mml:mi>i</mml:mi>
                  <mml:mo>,</mml:mo>
                  <mml:msub>
                    <mml:mrow>
                      <mml:mi>μ</mml:mi>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mi>k</mml:mi>
                    </mml:mrow>
                  </mml:msub>
                  <mml:mo>)</mml:mo>
                </mml:mrow>
              </mml:mrow>
              <mml:mo>.</mml:mo>
            </mml:math>
          </alternatives>
        </disp-formula>
        <p><bold><italic>K</italic>-NN:</bold> After computing the pairwise distances between samples and summing across predictors, these can be used directly to identify the nearest neighbours for classification. The algorithm for <italic>k</italic>-NN is as follows:</p>
        <list list-type="simple">
          <list-item>
            <p>Step 1: Compute the pairwise distance of sample <italic>i</italic><sub>1</sub> and <italic>i</italic><sub>2</sub>, <italic>i</italic><sub>1</sub>, <italic>i</italic><sub>2</sub> = 1,…,<italic>I</italic>, <italic>i</italic><sub>1</sub>≠<italic>i</italic><sub>2</sub>,</p>
          </list-item>
        </list>
        <disp-formula id="pcbi.1008799.e039">
          <alternatives>
            <graphic xlink:href="pcbi.1008799.e039.jpg" id="pcbi.1008799.e039g" mimetype="image" position="anchor" orientation="portrait"/>
            <mml:math id="M39">
              <mml:mi>D</mml:mi>
              <mml:mo>(</mml:mo>
              <mml:mrow>
                <mml:msub>
                  <mml:mrow>
                    <mml:mi>i</mml:mi>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mn>1</mml:mn>
                  </mml:mrow>
                </mml:msub>
                <mml:mo>,</mml:mo>
                <mml:msub>
                  <mml:mrow>
                    <mml:mi>i</mml:mi>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mn>2</mml:mn>
                  </mml:mrow>
                </mml:msub>
              </mml:mrow>
              <mml:mo>)</mml:mo>
              <mml:mo>=</mml:mo>
              <mml:mrow>
                <mml:mstyle displaystyle="false">
                  <mml:msub>
                    <mml:mo>∑</mml:mo>
                    <mml:mrow>
                      <mml:mi>j</mml:mi>
                    </mml:mrow>
                  </mml:msub>
                </mml:mstyle>
                <mml:mrow>
                  <mml:mi>δ</mml:mi>
                  <mml:mo>(</mml:mo>
                  <mml:mrow>
                    <mml:msub>
                      <mml:mrow>
                        <mml:mi mathvariant="bold-italic">P</mml:mi>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:msub>
                          <mml:mrow>
                            <mml:mi mathvariant="bold-italic">i</mml:mi>
                          </mml:mrow>
                          <mml:mrow>
                            <mml:mn mathvariant="bold">1</mml:mn>
                          </mml:mrow>
                        </mml:msub>
                        <mml:mo>,</mml:mo>
                        <mml:mi mathvariant="bold-italic">j</mml:mi>
                      </mml:mrow>
                    </mml:msub>
                    <mml:mo>,</mml:mo>
                    <mml:msub>
                      <mml:mrow>
                        <mml:mi mathvariant="bold-italic">P</mml:mi>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:msub>
                          <mml:mrow>
                            <mml:mi mathvariant="bold-italic">i</mml:mi>
                          </mml:mrow>
                          <mml:mrow>
                            <mml:mn mathvariant="bold">2</mml:mn>
                          </mml:mrow>
                        </mml:msub>
                        <mml:mo>,</mml:mo>
                        <mml:mi mathvariant="bold-italic">j</mml:mi>
                      </mml:mrow>
                    </mml:msub>
                  </mml:mrow>
                  <mml:mo>)</mml:mo>
                </mml:mrow>
                <mml:mo>;</mml:mo>
              </mml:mrow>
            </mml:math>
          </alternatives>
        </disp-formula>
        <list list-type="simple">
          <list-item>
            <p>Step 2: For sample i, pick the k samples with smallest distance to sample <italic>i</italic>, the optimal <italic>k</italic> can be determined using cross-validation (CV) in the training set or existing heuristics.</p>
          </list-item>
          <list-item>
            <p>Step 3: Tally the labels of the k nearest neighbours, then sample i is predicted as the mode of the <italic>k</italic> labels.</p>
          </list-item>
        </list>
        <p>The overall workflow of DCMD within the <italic>k</italic>-means and <italic>k</italic>-NN frameworks is presented in <xref ref-type="fig" rid="pcbi.1008799.g002">Fig 2</xref>.</p>
        <fig id="pcbi.1008799.g002" orientation="portrait" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1008799.g002</object-id>
          <label>Fig 2</label>
          <caption>
            <title>Illustration of k-means and k-NN framework using sample-specific distributions.</title>
            <p>For k-means (top panel), the distance between the new sample to the mean of class A is smaller than to the mean of class B, hence the new sample is predicted as class A. For k-NN (bottom panel), using 3 nearest neighbours, the new sample is predicted as class A.</p>
          </caption>
          <graphic xlink:href="pcbi.1008799.g002"/>
        </fig>
      </sec>
    </sec>
    <sec id="sec009">
      <title>Predictive metrics</title>
      <p>Let <inline-formula id="pcbi.1008799.e040"><alternatives><graphic xlink:href="pcbi.1008799.e040.jpg" id="pcbi.1008799.e040g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M40"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></alternatives></inline-formula> be the predicted class for sample <italic>i</italic>. The classification accuracy is defined as the proportion of correctly predicted cases: <inline-formula id="pcbi.1008799.e041"><alternatives><graphic xlink:href="pcbi.1008799.e041.jpg" id="pcbi.1008799.e041g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M41"><mml:mi mathvariant="normal">Accuracy</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>I</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:msubsup><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mi>I</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>. For binary outcomes we also include precision, recall, and F1 score as metrics to measure predictive performance. We count the number of true positive (<italic>TP</italic>), false positive (<italic>FP</italic>), and false negative (<italic>FN</italic>) and defined these metrics as follows [<xref rid="pcbi.1008799.ref027" ref-type="bibr">27</xref>]:
<disp-formula id="pcbi.1008799.e042"><alternatives><graphic xlink:href="pcbi.1008799.e042.jpg" id="pcbi.1008799.e042g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M42"><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mo>=</mml:mo><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>/</mml:mo><mml:mo>(</mml:mo><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi><mml:mo>)</mml:mo><mml:mo>,</mml:mo></mml:math></alternatives></disp-formula>
<disp-formula id="pcbi.1008799.e043"><alternatives><graphic xlink:href="pcbi.1008799.e043.jpg" id="pcbi.1008799.e043g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M43"><mml:mi mathvariant="normal">R</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mo>=</mml:mo><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>/</mml:mo><mml:mo>(</mml:mo><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi><mml:mo>)</mml:mo><mml:mo>,</mml:mo></mml:math></alternatives></disp-formula>
<disp-formula id="pcbi.1008799.e044"><alternatives><graphic xlink:href="pcbi.1008799.e044.jpg" id="pcbi.1008799.e044g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M44"><mml:mi mathvariant="normal">F</mml:mi><mml:mn>1</mml:mn><mml:mspace width="0.25em"/><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mo>×</mml:mo><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mo>×</mml:mo><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mo>/</mml:mo><mml:mo>(</mml:mo><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mo>)</mml:mo><mml:mo>.</mml:mo></mml:math></alternatives></disp-formula></p>
    </sec>
  </sec>
  <sec id="sec010">
    <title>Simulation</title>
    <sec id="sec011">
      <title>Data generation</title>
      <p>To evaluate the performance of the DCMD method, we design simulation studies that mimic microbiome community count data and assess classification performance. We simulate a separate mixture distribution for each class, individual sample rates, and resolutions to generate observed counts. For the mixture distribution, the number of components, M, is sampled from <italic>Unif</italic>(5, 15). And the number of samples to be taken from each mixture component is set by binning samples from a <italic>Beta</italic>(<italic>α</italic><sub><italic>b</italic></sub>, <italic>β</italic><sub><italic>b</italic></sub>) at uniform intervals, with the <italic>α</italic><sub><italic>b</italic></sub> varied to give different class means and levels of sparsity and with <italic>β</italic><sub><italic>b</italic></sub>~<italic>Unif</italic>(2, 6.5) to control dispersion. The observed counts for each sample are then generated as <inline-formula id="pcbi.1008799.e045"><alternatives><graphic xlink:href="pcbi.1008799.e045.jpg" id="pcbi.1008799.e045g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M45"><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>∼</mml:mo><mml:mi>P</mml:mi><mml:mi>o</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>s</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo>(</mml:mo><mml:msubsup><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>*</mml:mi></mml:mrow></mml:msubsup><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:math></alternatives></inline-formula>, where <inline-formula id="pcbi.1008799.e046"><alternatives><graphic xlink:href="pcbi.1008799.e046.jpg" id="pcbi.1008799.e046g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M46"><mml:msubsup><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo>*</mml:mo></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> is the sampled rate and resolution <italic>t</italic><sub><italic>i</italic></sub>~<italic>Unif</italic>(2/3, 5/4).</p>
      <p>We consider two- and three-class outcomes with several simulation scenarios for each case. For the two-class outcome, parameter settings and summary statistics for each scenario are shown in <xref rid="pcbi.1008799.t002" ref-type="table">Table 2</xref>. Scenarios 1 and 2 have low sparsity data, and scenarios 3 and 4 are highly sparse. Scenarios 1 and 3 have weakly differentiated classes (small difference in <italic>α<sub>b</sub></italic>), while scenarios 2 and 4 have strongly differentiated classes (large difference in <italic>α<sub>b</sub></italic>). The sample size is <italic>I</italic> = 800, with 400 samples per class and <italic>J</italic> = 25 OTUs. For the three-class outcome, parameter settings and summary statistics are shown in <xref ref-type="supplementary-material" rid="pcbi.1008799.s002">S1 Table</xref>. Scenarios 1–3 have strongly differentiated classes, with varying levels of sparsity. The sample size is <italic>I</italic> = 1200, with 400 samples in each class and <italic>J</italic> = 25 OTUs. A null case scenario is also generated by permuting class labels, and performance metrics for each outcome and scenario are computed over 100 simulation replicates.</p>
      <table-wrap id="pcbi.1008799.t002" orientation="portrait" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1008799.t002</object-id>
        <label>Table 2</label>
        <caption>
          <title>Two-class outcome: the parameter settings for each scenario and the corresponding summary statistics of each class over 100 replicates.</title>
        </caption>
        <alternatives>
          <graphic id="pcbi.1008799.t002g" xlink:href="pcbi.1008799.t002"/>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th align="center" style="background-color:#AEAAAA" rowspan="1" colspan="1">Scenario</th>
                <th align="center" style="background-color:#AEAAAA" rowspan="1" colspan="1">Signal</th>
                <th align="center" style="background-color:#AEAAAA" rowspan="1" colspan="1">Sparsity</th>
                <th align="center" style="background-color:#AEAAAA" rowspan="1" colspan="1">Class</th>
                <th align="center" style="background-color:#AEAAAA" rowspan="1" colspan="1">Size</th>
                <th align="center" style="background-color:#AEAAAA" rowspan="1" colspan="1"><italic>α</italic><sub><italic>b</italic></sub> range</th>
                <th align="center" style="background-color:#AEAAAA" rowspan="1" colspan="1">Mean ZP (SD)</th>
                <th align="center" style="background-color:#AEAAAA" rowspan="1" colspan="1">Mean</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="center" rowspan="2" style="background-color:#E7E6E6" colspan="1">1</td>
                <td align="center" rowspan="2" style="background-color:#E7E6E6" colspan="1">Weak</td>
                <td align="center" rowspan="2" style="background-color:#E7E6E6" colspan="1">Low</td>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">1</td>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">400</td>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">(1.5, 1.8)</td>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">0.32 (0.13)</td>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">7.91</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">2</td>
                <td align="center" rowspan="1" colspan="1">400</td>
                <td align="center" rowspan="1" colspan="1">(1.8, 2.1)</td>
                <td align="center" rowspan="1" colspan="1">0.26 (0.12)</td>
                <td align="center" rowspan="1" colspan="1">9.63</td>
              </tr>
              <tr>
                <td align="center" rowspan="2" style="background-color:#E7E6E6" colspan="1">2</td>
                <td align="center" rowspan="2" style="background-color:#E7E6E6" colspan="1">Strong</td>
                <td align="center" rowspan="2" style="background-color:#E7E6E6" colspan="1">Low</td>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">1</td>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">400</td>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">(1.5, 1.8)</td>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">0.33 (0.13)</td>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">7.74</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">2</td>
                <td align="center" rowspan="1" colspan="1">400</td>
                <td align="center" rowspan="1" colspan="1">(2.7, 3.0)</td>
                <td align="center" rowspan="1" colspan="1">0.14 (0.09)</td>
                <td align="center" rowspan="1" colspan="1">15.12</td>
              </tr>
              <tr>
                <td align="center" rowspan="2" style="background-color:#E7E6E6" colspan="1">3</td>
                <td align="center" rowspan="2" style="background-color:#E7E6E6" colspan="1">Weak</td>
                <td align="center" rowspan="2" style="background-color:#E7E6E6" colspan="1">High</td>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">1</td>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">400</td>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">(0.2, 0.4)</td>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">0.84 (0.07)</td>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">1.05</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">2</td>
                <td align="center" rowspan="1" colspan="1">400</td>
                <td align="center" rowspan="1" colspan="1">(0.4, 0.6)</td>
                <td align="center" rowspan="1" colspan="1">0.74 (0.10)</td>
                <td align="center" rowspan="1" colspan="1">1.92</td>
              </tr>
              <tr>
                <td align="center" rowspan="2" style="background-color:#E7E6E6" colspan="1">4</td>
                <td align="center" rowspan="2" style="background-color:#E7E6E6" colspan="1">Strong</td>
                <td align="center" rowspan="2" style="background-color:#E7E6E6" colspan="1">High</td>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">1</td>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">400</td>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">(0.2, 0.4)</td>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">0.84 (0.07)</td>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">0.98</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">2</td>
                <td align="center" rowspan="1" colspan="1">400</td>
                <td align="center" rowspan="1" colspan="1">(0.8, 1.0)</td>
                <td align="center" rowspan="1" colspan="1">0.56 (0.13)</td>
                <td align="center" rowspan="1" colspan="1">3.61</td>
              </tr>
            </tbody>
          </table>
        </alternatives>
      </table-wrap>
    </sec>
    <sec id="sec012">
      <title>Mixture model specification</title>
      <p>The specification of the mixture model components should be data-driven, and the main requirement is that the Gammas allow for appropriate coverage of the observed data. We split the count data into five intervals and apply different strategies to specify components on each interval. Modelling of the zeros and low-rate structures is based on [<xref rid="pcbi.1008799.ref028" ref-type="bibr">28</xref>], and modelling of the higher counts is based on [<xref rid="pcbi.1008799.ref021" ref-type="bibr">21</xref>].</p>
      <list list-type="order">
        <list-item>
          <p>Structural zeros: For data with observed zeros, a zero-point mass P(<italic>X</italic> = 0) = 1 is included to model zero inflation.</p>
        </list-item>
        <list-item>
          <p>Low counts (<italic>x</italic>∈[0,1,2,3]): We specify components as Poisson rate posteriors with uniform priors for each of the counts, which is <italic>Γ</italic>(<italic>x</italic>+1, 1). Hence, we include <italic>Γ</italic>(1,1), <italic>Γ</italic>(2,1), <italic>Γ</italic>(3,1) and <italic>Γ</italic>(4,1). The cut-off is set to <italic>x</italic> = 3 because rate posteriors for higher values have a low probability of observing zero, and we want to differentiate the distributions relevant to modelling zero inflation. We also want to examine whether more mass close to zero improves the fit for the low rates. Therefore, we add exponentials with a higher rate, <italic>β</italic>, to have more mass near zero. In this case, we include <italic>Γ</italic>(1,2) into the candidate models. We can potentially include <italic>Γ</italic>(1,3) or other terms into the model, then apply the procedure described above to select the optimal mix. A fuller discussion, drawn from modelling sparse counts for total species estimation, can be found in [<xref rid="pcbi.1008799.ref028" ref-type="bibr">28</xref>].</p>
        </list-item>
        <list-item>
          <p>Integer counts (<italic>x</italic>∈[4,5,6,7]): Components in this range are also specified as the rate posterior <italic>Γ</italic>(<italic>x</italic>+1, 1) at integer intervals. This block exists as a buffer to ensure no gaps in the coverage after the low-count distributions, as this can potentially bias the structural zero and low-rate estimates. This is specified until the last integer component has little overlap with the previous low-rate component. In our formulation, we use an upper limit of <italic>x</italic> = 7 as simulations showed negligible differences between <italic>x</italic> = 7 and <italic>x</italic> = 8. The integer components include <italic>Γ</italic>(4,1),…,<italic>Γ</italic>(7,1).</p>
        </list-item>
        <list-item>
          <p>High counts (<italic>x</italic>∈[8,…,<italic>C</italic>]): The higher counts tend to have a large range, and it’s not practical to specify them on integer intervals. In this case, we set the number of components based on the range of the data and specify <italic>α</italic><sub><italic>m</italic></sub> at uniform intervals on a linear-log scale from 8 to <italic>C</italic> = <italic>q</italic><sub><italic>p</italic></sub>, a set quantile of the data. Using between 10 and 15 components worked well in past applications [<xref rid="pcbi.1008799.ref021" ref-type="bibr">21</xref>]. For our modelling, p = 0.85 is an effective threshold, which means C is the 85% quantile of the sample.</p>
        </list-item>
        <list-item>
          <p>Extreme high counts (<italic>x</italic>&gt;C): These counts are truncated to a point mass P(<italic>X</italic>&gt;<italic>C</italic>) = 1, in part because of the low density in this range and the uncertainty in modelling them and in part to decrease computation time. The mixture model specification heuristics described above are primarily for modelling low-abundance OTU, which covers the most information of the microbiome data. Higher abundance OTU can be modelled by restricting the component specification to higher counts and increasing p.</p>
        </list-item>
      </list>
      <p>The full model we use for our data includes [<italic>Γ</italic>(1,2), <italic>Γ</italic>(1,1),…,<italic>Γ</italic>(7,1), <italic>Γ</italic>(8,1)], along with varying high-count components. Nested models are generated by progressively excluding <italic>Γ</italic>(1,2), [<italic>Γ</italic>(1,2), <italic>Γ</italic>(1,1)],… for a total of five models. A sample model specification for one of the OTU is presented in <xref ref-type="supplementary-material" rid="pcbi.1008799.s003">S2 Table</xref>.</p>
    </sec>
    <sec id="sec013">
      <title>Model fitting and comparison methods</title>
      <p>The proposed method is compared with <italic>k</italic>-means and <italic>k</italic>-NN using Euclidean and Manhattan distances of relative abundances, distance-based NSC, as well as LASSO, RF, GB, RF and SVM classifiers [<xref rid="pcbi.1008799.ref029" ref-type="bibr">29</xref>]. Models are trained using a 60/40 training and test set split [<xref rid="pcbi.1008799.ref030" ref-type="bibr">30</xref>], with the training set remaining the same for all classifiers within each replicate. For the machine learning methods, we use existing packages and tune the hyper-parameters using cross-validation when appropriate, see details in <xref ref-type="supplementary-material" rid="pcbi.1008799.s001">S1 Text</xref>.</p>
    </sec>
    <sec id="sec014">
      <title>Simulation results</title>
      <p>For the two-class outcome, classification accuracy for each model and scenario is presented in <xref ref-type="fig" rid="pcbi.1008799.g003">Fig 3</xref>. The orange boxplots are the results for the proposed DCMD method in a <italic>k</italic>-means and <italic>k</italic>-NN framework. The blue boxplots are the other distance-based methods, including <italic>k</italic>-means and <italic>k</italic>-NN with Euclidean and Manhattan distance and NSC. The green boxplots give results for the machine learning methods, including RF, GB, LASSO, RR, and SVM. The dashed red line gives the average accuracy of the best method in each scenario. The results show that in Scenarios 1 and 2, when sparsity is low, <italic>k</italic>-means with <italic>CC-L</italic><sup><italic>2</italic></sup> norm performs best, followed by <italic>k</italic>-means with D-<italic>L</italic><sup>2</sup> norm, while in Scenarios 3 and 4, when sparsity is high, <italic>k</italic>-means with D-<italic>L</italic><sup>2</sup> norm gives the best performance, followed by <italic>k</italic>-means with <italic>CC-L</italic><sup><italic>2</italic></sup> norm. Overall, DCMD in a <italic>k</italic>-means framework with <italic>L</italic><sup><italic>2</italic></sup> norms outperforms the other classification methods for all types of signals and data structures for the two-class outcome. Differences in accuracy within the distance-based methods are also progressively more pronounced in favour of DCMD, among which <italic>k</italic>-means outperforming <italic>k</italic>-NN. The specialized NSC approach performed similarly to DCMD within the <italic>k</italic>-NN framework. However, NSC generally falls short of <italic>k</italic>-means DCMD and other machine learning methods.</p>
      <fig id="pcbi.1008799.g003" orientation="portrait" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1008799.g003</object-id>
        <label>Fig 3</label>
        <caption>
          <title>Two-class outcome: boxplot of the accuracy over 100 replicates for each method and scenario.</title>
          <p>The proposed DCMD method is shown in orange for <italic>k</italic>-means and <italic>k</italic>-NN with D-<italic>L</italic><sup>2</sup> and CC-<italic>L</italic><sup>2</sup> distances. The other distance-based methods are shown in blue, including <italic>k</italic>-means and <italic>k</italic>-NN with Euclidean and Manhattan distances and NSC. Machine learning methods are shown in green, including random forest (RF), gradient boosting (GB), LASSO, ridge regression (RR), support vector machine (SVM). The dashed red line gives the average accuracy of the best method in each scenario.</p>
        </caption>
        <graphic xlink:href="pcbi.1008799.g003"/>
      </fig>
      <p><xref rid="pcbi.1008799.t003" ref-type="table">Table 3</xref> shows the summary statistics of the F1 Score over 100 replicates for the two-class outcome. The top results in each scenario are highlighted. Similar to accuracy, DCMD with <italic>L</italic><sup><italic>2</italic></sup> norms produce the highest F1 Scores (F1 Score (SD) = 0.68 (0.034), 0.92 (0.017), 0.77 (0.028), 0.95 (0.014) in Scenarios 1–4, respectively), which are better than the best machine learning method (GB: 0.64 (0.033), RF and RR: 0.89 (0.019), LASSO: 0.75 (0.030), GB: 0.94 (0.016) in Scenarios 1–4, respectively). DCMD shows consistent good performance in each scenario compared among the methods.</p>
      <table-wrap id="pcbi.1008799.t003" orientation="portrait" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1008799.t003</object-id>
        <label>Table 3</label>
        <caption>
          <title>Two-class outcome: the summary of F1 Scores for each model over 100 replicates.</title>
        </caption>
        <alternatives>
          <graphic id="pcbi.1008799.t003g" xlink:href="pcbi.1008799.t003"/>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th align="center" style="background-color:#AEAAAA" rowspan="1" colspan="1">Model</th>
                <th align="center" style="background-color:#AEAAAA" rowspan="1" colspan="1">Scenario 1 (SD)</th>
                <th align="center" style="background-color:#AEAAAA" rowspan="1" colspan="1">Scenario 2 (SD)</th>
                <th align="center" style="background-color:#AEAAAA" rowspan="1" colspan="1">Scenario 3 (SD)</th>
                <th align="center" style="background-color:#AEAAAA" rowspan="1" colspan="1">Scenario 4 (SD)</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="center" style="background-color:#D9D9D9" rowspan="1" colspan="1"><italic>k</italic>-means-<italic>D-L</italic><sup><italic>2</italic></sup></td>
                <td align="center" style="background-color:#D9D9D9" rowspan="1" colspan="1">0.67 (0.033)</td>
                <td align="center" style="background-color:#D9D9D9" rowspan="1" colspan="1">0.90 (0.019)</td>
                <td align="center" style="background-color:#D9D9D9" rowspan="1" colspan="1">
                  <bold>0.77 (0.028)</bold>
                </td>
                <td align="center" style="background-color:#D9D9D9" rowspan="1" colspan="1">
                  <bold>0.95 (0.014)</bold>
                </td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1"><italic>k</italic>-means-<italic>CC-L</italic><sup><italic>2</italic></sup></td>
                <td align="center" rowspan="1" colspan="1">
                  <bold>0.68 (0.034)</bold>
                </td>
                <td align="center" rowspan="1" colspan="1">
                  <bold>0.92 (0.017)</bold>
                </td>
                <td align="center" rowspan="1" colspan="1">0.76 (0.028)</td>
                <td align="center" rowspan="1" colspan="1">0.94 (0.016)</td>
              </tr>
              <tr>
                <td align="center" style="background-color:#D9D9D9" rowspan="1" colspan="1"><italic>k</italic>-means-Euclidean</td>
                <td align="center" style="background-color:#D9D9D9" rowspan="1" colspan="1">0.56 (0.054)</td>
                <td align="center" style="background-color:#D9D9D9" rowspan="1" colspan="1">0.73 (0.047)</td>
                <td align="center" style="background-color:#D9D9D9" rowspan="1" colspan="1">0.66 (0.039)</td>
                <td align="center" style="background-color:#D9D9D9" rowspan="1" colspan="1">0.79 (0.026)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1"><italic>k</italic>-means-Manhattan</td>
                <td align="center" rowspan="1" colspan="1">0.58 (0.065)</td>
                <td align="center" rowspan="1" colspan="1">0.78 (0.040)</td>
                <td align="center" rowspan="1" colspan="1">0.69 (0.030)</td>
                <td align="center" rowspan="1" colspan="1">0.77 (0.022)</td>
              </tr>
              <tr>
                <td align="center" style="background-color:#D9D9D9" rowspan="1" colspan="1"><italic>k</italic>-NN-<italic>D-L</italic><sup><italic>2</italic></sup></td>
                <td align="center" style="background-color:#D9D9D9" rowspan="1" colspan="1">0.59 (0.050)</td>
                <td align="center" style="background-color:#D9D9D9" rowspan="1" colspan="1">0.85 (0.028)</td>
                <td align="center" style="background-color:#D9D9D9" rowspan="1" colspan="1">0.74 (0.022)</td>
                <td align="center" style="background-color:#D9D9D9" rowspan="1" colspan="1">0.85 (0.021)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1"><italic>k</italic>-NN-<italic>CC-L</italic><sup><italic>2</italic></sup></td>
                <td align="center" rowspan="1" colspan="1">0.59 (0.048)</td>
                <td align="center" rowspan="1" colspan="1">0.88 (0.028)</td>
                <td align="center" rowspan="1" colspan="1">0.73 (0.025)</td>
                <td align="center" rowspan="1" colspan="1">0.85 (0.020)</td>
              </tr>
              <tr>
                <td align="center" style="background-color:#D9D9D9" rowspan="1" colspan="1"><italic>k</italic>-NN-Euclidean</td>
                <td align="center" style="background-color:#D9D9D9" rowspan="1" colspan="1">0.60 (0.043)</td>
                <td align="center" style="background-color:#D9D9D9" rowspan="1" colspan="1">0.77 (0.023)</td>
                <td align="center" style="background-color:#D9D9D9" rowspan="1" colspan="1">0.68 (0.031)</td>
                <td align="center" style="background-color:#D9D9D9" rowspan="1" colspan="1">0.79 (0.020)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1"><italic>k</italic>-NN-Manhattan</td>
                <td align="center" rowspan="1" colspan="1">0.66 (0.037)</td>
                <td align="center" rowspan="1" colspan="1">0.77 (0.015)</td>
                <td align="center" rowspan="1" colspan="1">0.71 (0.017)</td>
                <td align="center" rowspan="1" colspan="1">0.75 (0.016)</td>
              </tr>
              <tr>
                <td align="center" style="background-color:#D9D9D9" rowspan="1" colspan="1">NSC</td>
                <td align="center" style="background-color:#D9D9D9" rowspan="1" colspan="1">0.56 (0.067)</td>
                <td align="center" style="background-color:#D9D9D9" rowspan="1" colspan="1">0.85 (0.023)</td>
                <td align="center" style="background-color:#D9D9D9" rowspan="1" colspan="1">0.69 (0.046)</td>
                <td align="center" style="background-color:#D9D9D9" rowspan="1" colspan="1">0.86 (0.022)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">RF</td>
                <td align="center" rowspan="1" colspan="1">0.63 (0.036)</td>
                <td align="center" rowspan="1" colspan="1">
                  <bold>0.89 (0.019)</bold>
                </td>
                <td align="center" rowspan="1" colspan="1">0.74 (0.038)</td>
                <td align="center" rowspan="1" colspan="1">0.94 (0.017)</td>
              </tr>
              <tr>
                <td align="center" style="background-color:#D9D9D9" rowspan="1" colspan="1">GB</td>
                <td align="center" style="background-color:#D9D9D9" rowspan="1" colspan="1">
                  <bold>0.64 (0.033)</bold>
                </td>
                <td align="center" style="background-color:#D9D9D9" rowspan="1" colspan="1">0.89 (0.020)</td>
                <td align="center" style="background-color:#D9D9D9" rowspan="1" colspan="1">0.75 (0.033)</td>
                <td align="center" style="background-color:#D9D9D9" rowspan="1" colspan="1">
                  <bold>0.94 (0.016)</bold>
                </td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">LASSO</td>
                <td align="center" rowspan="1" colspan="1">0.64 (0.039)</td>
                <td align="center" rowspan="1" colspan="1">0.89 (0.021)</td>
                <td align="center" rowspan="1" colspan="1">
                  <bold>0.75 (0.030)</bold>
                </td>
                <td align="center" rowspan="1" colspan="1">0.93 (0.015)</td>
              </tr>
              <tr>
                <td align="center" style="background-color:#D9D9D9" rowspan="1" colspan="1">RR</td>
                <td align="center" style="background-color:#D9D9D9" rowspan="1" colspan="1">0.62 (0.052)</td>
                <td align="center" style="background-color:#D9D9D9" rowspan="1" colspan="1">
                  <bold>0.89 (0.019)</bold>
                </td>
                <td align="center" style="background-color:#D9D9D9" rowspan="1" colspan="1">0.74 (0.037)</td>
                <td align="center" style="background-color:#D9D9D9" rowspan="1" colspan="1">0.93 (0.015)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">SVM</td>
                <td align="center" rowspan="1" colspan="1">0.64 (0.031)</td>
                <td align="center" rowspan="1" colspan="1">0.82 (0.028)</td>
                <td align="center" rowspan="1" colspan="1">0.72 (0.026)</td>
                <td align="center" rowspan="1" colspan="1">0.86 (0.021)</td>
              </tr>
            </tbody>
          </table>
        </alternatives>
      </table-wrap>
      <p>The classification accuracy of each model and scenario for a three-class outcome is presented in <xref ref-type="fig" rid="pcbi.1008799.g004">Fig 4</xref>. For Scenarios 1–3, the classes are differentiated under varying levels of sparsity, and we observe that DCMD is competitive with the optimal machine learning methods. Although RR has similar predictive accuracy to DCMD in Scenario 1 and 3, and GB has similar predictive accuracy in Scenario 2, DCMD is consistently improved over the optimal comparison method. None of the models is systematically over-fit, as predictive accuracy in the null case (Scenario 4) is near the baseline accuracy of 0.33.</p>
      <fig id="pcbi.1008799.g004" orientation="portrait" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1008799.g004</object-id>
        <label>Fig 4</label>
        <caption>
          <title>Three-class outcome: boxplot of accuracy over 100 replicates for each method and scenario.</title>
          <p>The proposed DCMD method is shown in orange for k-means and k-NN with D-L<sup>2</sup> and CC-L<sup>2</sup> distances. The other distance-based methods are shown in blue, including k-means and k-NN with Euclidean and Manhattan distances and NSC. Machine learning methods are shown in green, including random forest (RF), gradient boosting (GB), LASSO, ridge regression (RR), support vector machine (SVM). The dashed red line gives the average accuracy of the best method in each scenario.</p>
        </caption>
        <graphic xlink:href="pcbi.1008799.g004"/>
      </fig>
    </sec>
  </sec>
  <sec id="sec015">
    <title>Application</title>
    <sec id="sec016">
      <title>Data description</title>
      <p>We test our method on data from two microbiome studies. The first is a study on colorectal cancer reported by [<xref rid="pcbi.1008799.ref022" ref-type="bibr">22</xref>]. A total of 190 samples (95 pairs) were collected from 95 patients in Vall d’Hebron University Hospital in Barcelona and Genomics Collaborative. The study aimed to identify associations between tumor microbiome and colorectal carcinoma. Both the colorectal adenocarcinoma tissue and adjacent non-affected tissues were collected. The OTU count table generated by 16S amplification was obtained from the Microbiome Learning Repo [<xref rid="pcbi.1008799.ref012" ref-type="bibr">12</xref>]. Prior to model training, eighteen samples with total reads less than 100 were dropped from the dataset, and we also excluded OTUs with mean relative abundance less than 0.001, resulting in 149 OTUs and 172 samples (86 pairs) used to differentiate tumour and normal tissue. The second study is a case-control study of Crohn’s disease (CD) from a multi-center cohort, which was designed to examine how microbiota contributes to CD pathogenesis [<xref rid="pcbi.1008799.ref023" ref-type="bibr">23</xref>]. The profiles were obtained using Illumina 16S rRNA sequencing. The dataset was downloaded from the Microbiome Learning Repo [<xref rid="pcbi.1008799.ref012" ref-type="bibr">12</xref>] and consisted of 140 ileal tissue biopsy samples. Minimal sample depth is set at 100, and OTUs are restricted to less than 90% zero proportion, leaving 140 samples (78 cases and 62 controls) and 31 OTUs for analysis.</p>
    </sec>
    <sec id="sec017">
      <title>Model fitting and evaluation</title>
      <p>For both datasets, we compare our proposed <italic>L</italic><sup>2</sup>-norm based <italic>k</italic>-means and <italic>k</italic>-NN classifier with five other distance-based classifiers (<italic>k</italic>-means-Euclidean, <italic>k</italic>-means-Manhattan, <italic>k</italic>-NN-Euclidean, <italic>k</italic>-NN-Manhattan, NSC) and six machine learning methods (RF, GB, LASSO, RR, SVM). We assess model performance using 10-fold CV. In each iteration, one fold of the data is treated as the test set, and the remaining nine are used for training. The specification of DCMD and other classifiers is the same as that in the simulations (see <xref ref-type="supplementary-material" rid="pcbi.1008799.s001">S1 Text</xref>). We calculate accuracy, precision, recall, and F1 score as metrics for comparison.</p>
      <p>For the colorectal cancer data, we reduce the predictor space for distance-based classifiers by the univariate screening of OTUs with a nonparametric Mann-Whitney U test on the training set. To adjust for multiple comparisons, we use q-values obtained by the Benjamini–Hochberg (BH) method [<xref rid="pcbi.1008799.ref031" ref-type="bibr">31</xref>] and retain OTUs with q-values less than 0.05 in each training set. The mean number of OTUs selected from each training set is 42 (range: 13–57). For the machine learning approaches, we include all 149 OTUs. For the CD dataset, 31 OTUs are included for all methods.</p>
    </sec>
    <sec id="sec018">
      <title>Applied results</title>
      <p>The predictive performance of each classifier for the colorectal cancer and CD studies are presented in Tables <xref rid="pcbi.1008799.t004" ref-type="table">4</xref> and <xref rid="pcbi.1008799.t005" ref-type="table">5</xref>, respectively. The accuracy of <italic>k</italic>-means with <italic>D-L</italic><sup><italic>2</italic></sup> norm is 0.67 for colorectal cancer and 0.73 for CD, which is the best method for colorectal cancer and the second-best for CD. The F1 scores are also among the highest for both datasets, indicating that DCMD has consistently optimal performance and an improvement over the other classifiers. Predictive accuracy of <italic>k</italic>-means with <italic>CC-L</italic><sup><italic>2</italic></sup> norm is slightly worse, likely due to high zero proportions in the predictors, which is consistent with the simulation results. Similarly, DCMD outperforms Euclidean and Manhattan distances within <italic>k</italic>-means, and <italic>k</italic>-means outperforms <italic>k</italic>-NN overall. Within <italic>k</italic>-NN, accuracy and F1 score indicate that DCMD has predictive performance comparable to Euclidean or Manhattan distances. The NSC approach has an accuracy of 0.67 and a precision of 0.72 for colorectal cancer, with a recall of 0.56 and an F1 score of 0.63, notably lower than that of the <italic>k</italic>-means classifiers. The performance is unstable in the CD data.</p>
      <table-wrap id="pcbi.1008799.t004" orientation="portrait" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1008799.t004</object-id>
        <label>Table 4</label>
        <caption>
          <title>Dataset 1—Colorectal Cancer: the predictive performance of the 14 classifiers.</title>
        </caption>
        <alternatives>
          <graphic id="pcbi.1008799.t004g" xlink:href="pcbi.1008799.t004"/>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th align="center" style="background-color:#AEAAAA" rowspan="1" colspan="1">Method</th>
                <th align="center" style="background-color:#AEAAAA" rowspan="1" colspan="1">Accuracy</th>
                <th align="center" style="background-color:#AEAAAA" rowspan="1" colspan="1">Precision</th>
                <th align="center" style="background-color:#AEAAAA" rowspan="1" colspan="1">Recall</th>
                <th align="center" style="background-color:#AEAAAA" rowspan="1" colspan="1">F1 score</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1"><italic>k</italic>-means-<italic>D-L</italic><sup><italic>2</italic></sup></td>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">
                  <bold>0.67</bold>
                </td>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">0.66</td>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">
                  <bold>0.69</bold>
                </td>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">
                  <bold>0.67</bold>
                </td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1"><italic>k</italic>-means-<italic>CC-L</italic><sup><italic>2</italic></sup></td>
                <td align="center" rowspan="1" colspan="1">0.63</td>
                <td align="center" rowspan="1" colspan="1">0.62</td>
                <td align="center" rowspan="1" colspan="1">0.67</td>
                <td align="center" rowspan="1" colspan="1">0.65</td>
              </tr>
              <tr>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1"><italic>k</italic>-means-Euclidean</td>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">0.62</td>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">0.62</td>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">0.60</td>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">0.61</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1"><italic>k</italic>-means-Manhattan</td>
                <td align="center" rowspan="1" colspan="1">0.65</td>
                <td align="center" rowspan="1" colspan="1">0.66</td>
                <td align="center" rowspan="1" colspan="1">0.60</td>
                <td align="center" rowspan="1" colspan="1">0.63</td>
              </tr>
              <tr>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1"><italic>k</italic>-NN-<italic>D-L</italic><sup><italic>2</italic></sup></td>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">0.65</td>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">
                  <bold>0.77</bold>
                </td>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">0.43</td>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">0.55</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1"><italic>k</italic>-NN-<italic>CC-L</italic><sup><italic>2</italic></sup></td>
                <td align="center" rowspan="1" colspan="1">0.63</td>
                <td align="center" rowspan="1" colspan="1">0.65</td>
                <td align="center" rowspan="1" colspan="1">0.57</td>
                <td align="center" rowspan="1" colspan="1">0.61</td>
              </tr>
              <tr>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1"><italic>k</italic>-NN-Euclidean</td>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">0.63</td>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">0.66</td>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">0.55</td>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">0.60</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1"><italic>k</italic>-NN-Manhattan</td>
                <td align="center" rowspan="1" colspan="1">0.61</td>
                <td align="center" rowspan="1" colspan="1">0.69</td>
                <td align="center" rowspan="1" colspan="1">0.40</td>
                <td align="center" rowspan="1" colspan="1">0.50</td>
              </tr>
              <tr>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">NSC</td>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">
                  <bold>0.67</bold>
                </td>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">
                  <bold>0.72</bold>
                </td>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">0.56</td>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">0.63</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">RF</td>
                <td align="center" rowspan="1" colspan="1">0.60</td>
                <td align="center" rowspan="1" colspan="1">0.61</td>
                <td align="center" rowspan="1" colspan="1">0.59</td>
                <td align="center" rowspan="1" colspan="1">0.60</td>
              </tr>
              <tr>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">GB</td>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">0.63</td>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">0.63</td>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">0.64</td>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">0.64</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">LASSO</td>
                <td align="center" rowspan="1" colspan="1">0.59</td>
                <td align="center" rowspan="1" colspan="1">0.59</td>
                <td align="center" rowspan="1" colspan="1">0.59</td>
                <td align="center" rowspan="1" colspan="1">0.59</td>
              </tr>
              <tr>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">RR</td>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">0.64</td>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">0.63</td>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">
                  <bold>0.69</bold>
                </td>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">
                  <bold>0.66</bold>
                </td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">SVM</td>
                <td align="center" rowspan="1" colspan="1">0.66</td>
                <td align="center" rowspan="1" colspan="1">0.67</td>
                <td align="center" rowspan="1" colspan="1">0.63</td>
                <td align="center" rowspan="1" colspan="1">0.65</td>
              </tr>
            </tbody>
          </table>
        </alternatives>
      </table-wrap>
      <table-wrap id="pcbi.1008799.t005" orientation="portrait" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1008799.t005</object-id>
        <label>Table 5</label>
        <caption>
          <title>Dataset 2—Crohn’s Disease: the predictive performance of the 14 classifiers.</title>
        </caption>
        <alternatives>
          <graphic id="pcbi.1008799.t005g" xlink:href="pcbi.1008799.t005"/>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th align="center" style="background-color:#AEAAAA" rowspan="1" colspan="1">Method</th>
                <th align="center" style="background-color:#AEAAAA" rowspan="1" colspan="1">Accuracy</th>
                <th align="center" style="background-color:#AEAAAA" rowspan="1" colspan="1">Precision</th>
                <th align="center" style="background-color:#AEAAAA" rowspan="1" colspan="1">Recall</th>
                <th align="center" style="background-color:#AEAAAA" rowspan="1" colspan="1">F1 score</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1"><italic>k</italic>-means-<italic>D-L</italic><sup><italic>2</italic></sup></td>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">
                  <bold>0.73</bold>
                </td>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">
                  <bold>0.75</bold>
                </td>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">0.78</td>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">
                  <bold>0.76</bold>
                </td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1"><italic>k</italic>-means-<italic>CC-L</italic><sup><italic>2</italic></sup></td>
                <td align="center" rowspan="1" colspan="1">0.72</td>
                <td align="center" rowspan="1" colspan="1">
                  <bold>0.75</bold>
                </td>
                <td align="center" rowspan="1" colspan="1">0.74</td>
                <td align="center" rowspan="1" colspan="1">0.75</td>
              </tr>
              <tr>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1"><italic>k</italic>-means-Euclidean</td>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">0.68</td>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">0.69</td>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">0.76</td>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">0.72</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1"><italic>k</italic>-means-Manhattan</td>
                <td align="center" rowspan="1" colspan="1">0.66</td>
                <td align="center" rowspan="1" colspan="1">0.67</td>
                <td align="center" rowspan="1" colspan="1">0.76</td>
                <td align="center" rowspan="1" colspan="1">0.71</td>
              </tr>
              <tr>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1"><italic>k</italic>-NN-<italic>D-L</italic><sup><italic>2</italic></sup></td>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">0.62</td>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">0.62</td>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">
                  <bold>0.85</bold>
                </td>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">0.71</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1"><italic>k</italic>-NN-<italic>CC-L</italic><sup><italic>2</italic></sup></td>
                <td align="center" rowspan="1" colspan="1">0.61</td>
                <td align="center" rowspan="1" colspan="1">0.61</td>
                <td align="center" rowspan="1" colspan="1">0.83</td>
                <td align="center" rowspan="1" colspan="1">0.71</td>
              </tr>
              <tr>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1"><italic>k</italic>-NN-Euclidean</td>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">0.65</td>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">0.66</td>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">0.78</td>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">0.71</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1"><italic>k</italic>-NN-Manhattan</td>
                <td align="center" rowspan="1" colspan="1">0.61</td>
                <td align="center" rowspan="1" colspan="1">0.62</td>
                <td align="center" rowspan="1" colspan="1">0.77</td>
                <td align="center" rowspan="1" colspan="1">0.69</td>
              </tr>
              <tr>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">NSC</td>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">0.66</td>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">0.64</td>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">
                  <bold>0.90</bold>
                </td>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">0.74</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">RF</td>
                <td align="center" rowspan="1" colspan="1">0.69</td>
                <td align="center" rowspan="1" colspan="1">0.71</td>
                <td align="center" rowspan="1" colspan="1">0.76</td>
                <td align="center" rowspan="1" colspan="1">0.73</td>
              </tr>
              <tr>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">GB</td>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">0.68</td>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">0.69</td>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">0.76</td>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">0.72</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">LASSO</td>
                <td align="center" rowspan="1" colspan="1">
                  <bold>0.74</bold>
                </td>
                <td align="center" rowspan="1" colspan="1">
                  <bold>0.76</bold>
                </td>
                <td align="center" rowspan="1" colspan="1">0.78</td>
                <td align="center" rowspan="1" colspan="1">0.73</td>
              </tr>
              <tr>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">RR</td>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">0.69</td>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">0.69</td>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">0.78</td>
                <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">0.73</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">SVM</td>
                <td align="center" rowspan="1" colspan="1">
                  <bold>0.74</bold>
                </td>
                <td align="center" rowspan="1" colspan="1">0.74</td>
                <td align="center" rowspan="1" colspan="1">0.81</td>
                <td align="center" rowspan="1" colspan="1">
                  <bold>0.77</bold>
                </td>
              </tr>
            </tbody>
          </table>
        </alternatives>
      </table-wrap>
      <p>Compared to the machine learning methods, DCMD with <italic>k</italic>-means is superior to RF, GB, LASSO, RR, and SVM in the first dataset. When results are replicated controlling for distance-based classifier variable selection (<xref ref-type="supplementary-material" rid="pcbi.1008799.s004">S3 Table</xref>), machine learning methods has improved performance, except for GB. In the second dataset, LASSO and SVM are the best methods with accuracies of 0.74, slightly outperforming the accuracy of 0.73 for <italic>k</italic>-means with <italic>D-L</italic><sup><italic>2</italic></sup> norm. Otherwise, DCMD <italic>k</italic>-means with <italic>D-L</italic><sup><italic>2</italic></sup> and <italic>CC-L</italic><sup><italic>2</italic></sup> norms either equivalent or outperform the machine learning approaches.</p>
    </sec>
  </sec>
  <sec sec-type="conclusions" id="sec019">
    <title>Discussion</title>
    <p>The results of our simulation studies and microbiome applications indicate that the proposed DCMD method performs well over a range of scenarios, achieving good classification performance when using sparse data as predictors. The predictive accuracy is consistently improved compared to other distances within distance-based classifiers. It is either advantageous or competitive compared to a number of machine learning methods under a wide range of scenarios. The improved performance of DCMD on sparse data results from the use of mixture distributions to represent the observed count data because the mixture distributions can not only model the underlying uncertainty in the observed sample counts but also account for zero inflation. The improvement is particularly significant in comparison to other distances within the regular <italic>k</italic>-means and <italic>k</italic>-NN classifiers.</p>
    <p>The performance differences between the <italic>D-L</italic><sup><italic>2</italic></sup> and <italic>CC-L</italic><sup><italic>2</italic></sup> norms can be attributed to the data structure. In less sparse scenarios, the data structure is better modelled by a continuous rate structure, resulting in a slight advantage for the <italic>CC-L</italic><sup><italic>2</italic></sup> metric. While in the higher ZP and low-count scenarios, the <italic>D-L</italic><sup><italic>2</italic></sup> norm allows us to use specific differentiation of zeros into structural and non-structural and modelling expected counts directly, which can further capture the general structure of predictors used for differentiation better.</p>
    <p>As the DCMD method derives its major improvement from a focus on modelling lower count data and the associated uncertainty, it is necessary to accurately specify an underlying set of mixture components for the low rates. The mixture also has to model low- and high-count data on the same scale, where the density of the latter is often sparse due to sparse observation intervals. Moreover, it is not feasible to apply a transformation to make the data denser due to abundant zeros and the discrete nature of the low counts. However, the weighing of nested candidate models and the suggested heuristic of specifying higher count distributions on a log-linear scale has worked well in our simulations, as it partially mimics the log-transformation commonly applied to such data.</p>
    <p>The proposed DCMD method is formulated in a distance-based framework, so it does not include specific mechanisms for variable selection. While different predictors can alternatively be included in the distance sum, the process is not automated. In our case, we used a simple nonparametric Mann-Whitney U test for feature selection, which worked well in the study data. However, more advanced and specialized methods for feature selection can be applied separately for other applications. Additionally, we note that the model is specified to use microbiome site counts, and continuous covariates need to be modelled separately using continuous distributions, while categorical covariates can only be included as dummy variables. These variables will also be treated on the same scale in the distance metric unless specified otherwise.</p>
    <p>Despite these drawbacks, we believe that our core contribution, the representation of observations as distributions to reflect uncertainty and the use of distributional distance metrics, will be valuable to anyone analyzing sparse data. This formulation can compensate for some of the disadvantages inherent in distance-based methods to such an extent that it achieved competitive performance with more sophisticated classifiers, as well as specially designed approaches like NSC. The techniques that made DCMD advantageous for classification when data is expected to be sparse, particularly within a distance-based framework, should be considered for improving model performance.</p>
  </sec>
  <sec sec-type="conclusions" id="sec020">
    <title>Conclusion</title>
    <p>In this paper, we present a distance-based classification method for microbiome count data. The DCMD approach models the observed data using mixture distributions and calculates <italic>L</italic><sup>2</sup>-norms for distance-based classification algorithms. The method is specifically designed to accurately model low-count structures, addressing the inherent sparsity by representing each observed count as a distribution, and is demonstrated to have improved performance by simulation studies and two microbiome applications. The importance of accounting for uncertainty in sparse data is emphasized, and the resulting improvements in classification accuracy when using distributions are demonstrated. The performance of the proposed DCMD is competitive to a number of machine learning methods and significantly outperforms other common metrics in distance-based classification models. The consistent and improved performances across a variety of different data structures make this approach a viable alternative for modelling and classification of microbiome count data, particularly within a distance-based framework.</p>
  </sec>
  <sec sec-type="supplementary-material" id="sec021">
    <title>Supporting information</title>
    <supplementary-material content-type="local-data" id="pcbi.1008799.s001">
      <label>S1 Text</label>
      <caption>
        <title>Supporting information for model specification of classifiers.</title>
        <p>(DOCX)</p>
      </caption>
      <media xlink:href="pcbi.1008799.s001.docx">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material content-type="local-data" id="pcbi.1008799.s002">
      <label>S1 Table</label>
      <caption>
        <title>Three-class outcome: the parameter setting for each scenario and the corresponding ZP and mean count for each class over 100 replicates.</title>
        <p>(DOCX)</p>
      </caption>
      <media xlink:href="pcbi.1008799.s002.docx">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material content-type="local-data" id="pcbi.1008799.s003">
      <label>S2 Table</label>
      <caption>
        <title>The nested models of mixture distribution components used in fitting one of the simulated data.</title>
        <p>(DOCX)</p>
      </caption>
      <media xlink:href="pcbi.1008799.s003.docx">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material content-type="local-data" id="pcbi.1008799.s004">
      <label>S3 Table</label>
      <caption>
        <title>Dataset 1—Colorectal Cancer: the predictive performance of the 14 classifiers using the OTUs selected from Mann–Whitney U test on the colorectal cancer data.</title>
        <p>(DOCX)</p>
      </caption>
      <media xlink:href="pcbi.1008799.s004.docx">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ack>
    <p>The authors acknowledge and are grateful for the support of the Tomcyzk AI and Microbiome Working Group.</p>
  </ack>
  <ref-list>
    <title>References</title>
    <ref id="pcbi.1008799.ref001">
      <label>1</label>
      <mixed-citation publication-type="journal"><name><surname>Morgan</surname><given-names>XC</given-names></name>, <name><surname>Tickle</surname><given-names>TL</given-names></name>, <name><surname>Sokol</surname><given-names>H</given-names></name>, <name><surname>Gevers</surname><given-names>D</given-names></name>, <name><surname>Devaney</surname><given-names>KL</given-names></name>, <name><surname>Ward</surname><given-names>DV</given-names></name>, <etal>et al</etal>. <article-title>Dysfunction of the intestinal microbiome in inflammatory bowel disease and treatment</article-title>. <source>Genome Biol.</source><year>2012</year>;<volume>13</volume>:<fpage>R79</fpage>. <pub-id pub-id-type="doi">10.1186/gb-2012-13-9-r79</pub-id><?supplied-pmid 23013615?><pub-id pub-id-type="pmid">23013615</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1008799.ref002">
      <label>2</label>
      <mixed-citation publication-type="journal"><name><surname>Karlsson</surname><given-names>FH</given-names></name>, <name><surname>Tremaroli</surname><given-names>V</given-names></name>, <name><surname>Nookaew</surname><given-names>I</given-names></name>, <name><surname>Bergström</surname><given-names>G</given-names></name>, <name><surname>Behre</surname><given-names>CJ</given-names></name>, <name><surname>Fagerberg</surname><given-names>B</given-names></name>, <etal>et al</etal>. <article-title>Gut metagenome in European women with normal, impaired and diabetic glucose control</article-title>. <source>Nature.</source><year>2013</year>;<volume>498</volume>:<fpage>99</fpage>–<lpage>103</lpage>. <pub-id pub-id-type="doi">10.1038/nature12198</pub-id><?supplied-pmid 23719380?><pub-id pub-id-type="pmid">23719380</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1008799.ref003">
      <label>3</label>
      <mixed-citation publication-type="journal"><name><surname>Shreiner</surname><given-names>AB</given-names></name>, <name><surname>Kao</surname><given-names>JY</given-names></name>, <name><surname>Young</surname><given-names>VB</given-names></name>. <article-title>The gut microbiome in health and in disease</article-title>. <source>Curr Opin Gastroenterol.</source><year>2015</year>;<volume>31</volume>:<fpage>69</fpage>–<lpage>75</lpage>. <pub-id pub-id-type="doi">10.1097/MOG.0000000000000139</pub-id><?supplied-pmid 25394236?><pub-id pub-id-type="pmid">25394236</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1008799.ref004">
      <label>4</label>
      <mixed-citation publication-type="book"><name><surname>Cam</surname><given-names>LML</given-names></name>, <name><surname>Neyman</surname><given-names>J</given-names></name>. <source>Proceedings of the Fifth Berkeley Symposium on Mathematical Statistics and Probability: Biology and problems of health</source>. <publisher-name>University of California Press</publisher-name>; <year>1967</year>;<fpage>281</fpage>–<lpage>297</lpage>.</mixed-citation>
    </ref>
    <ref id="pcbi.1008799.ref005">
      <label>5</label>
      <mixed-citation publication-type="journal"><name><surname>Zhang</surname><given-names>Z</given-names></name>. <article-title>Introduction to machine learning: k-nearest neighbors</article-title>. <source>Ann Transl Med.</source><year>2016</year>;<volume>4</volume>. <pub-id pub-id-type="doi">10.21037/atm.2016.03.37</pub-id><?supplied-pmid 27386492?><pub-id pub-id-type="pmid">27386492</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1008799.ref006">
      <label>6</label>
      <mixed-citation publication-type="journal"><name><surname>Liu</surname><given-names>Z</given-names></name>, <name><surname>Hsiao</surname><given-names>W</given-names></name>, <name><surname>Cantarel</surname><given-names>BL</given-names></name>, <name><surname>Drábek</surname><given-names>EF</given-names></name>, <name><surname>Fraser-Liggett</surname><given-names>C</given-names></name>. <article-title>Sparse distance-based learning for simultaneous multiclass classification and feature selection of metagenomic data</article-title>. <source>Bioinformatics</source>. <year>2011</year>;<volume>27</volume>:<fpage>3242</fpage>–<lpage>9</lpage>. <pub-id pub-id-type="doi">10.1093/bioinformatics/btr547</pub-id><?supplied-pmid 21984758?><pub-id pub-id-type="pmid">21984758</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1008799.ref007">
      <label>7</label>
      <mixed-citation publication-type="journal"><name><surname>Statnikov</surname><given-names>A</given-names></name>, <name><surname>Henaff</surname><given-names>M</given-names></name>, <name><surname>Narendra</surname><given-names>V</given-names></name>, <name><surname>Konganti</surname><given-names>K</given-names></name>, <name><surname>Li</surname><given-names>Z</given-names></name>, <name><surname>Yang</surname><given-names>L</given-names></name>, <etal>et al</etal>. <article-title>A comprehensive evaluation of multicategory classification methods for microbiomic data</article-title>. <source>Microbiome</source>. <year>2013</year>;<volume>1</volume>:<fpage>11</fpage>. <pub-id pub-id-type="doi">10.1186/2049-2618-1-11</pub-id><?supplied-pmid 24456583?><pub-id pub-id-type="pmid">24456583</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1008799.ref008">
      <label>8</label>
      <mixed-citation publication-type="journal"><name><surname>Rosenthal</surname><given-names>M</given-names></name>, <name><surname>Aiello</surname><given-names>AE</given-names></name>, <name><surname>Chenoweth</surname><given-names>C</given-names></name>, <name><surname>Goldberg</surname><given-names>D</given-names></name>, <name><surname>Larson</surname><given-names>E</given-names></name>, <name><surname>Gloor</surname><given-names>G</given-names></name>, <etal>et al</etal>. <article-title>Impact of Technical Sources of Variation on the Hand Microbiome Dynamics of Healthcare Workers</article-title>. <source>PLoS One.</source><year>2014</year>;<volume>9</volume>. <pub-id pub-id-type="doi">10.1371/journal.pone.0088999</pub-id><?supplied-pmid 24551205?><pub-id pub-id-type="pmid">24551205</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1008799.ref009">
      <label>9</label>
      <mixed-citation publication-type="journal"><name><surname>Tibshirani</surname><given-names>R</given-names></name>, <name><surname>Hastie</surname><given-names>T</given-names></name>, <name><surname>Narasimhan</surname><given-names>B</given-names></name>, <name><surname>Chu</surname><given-names>G</given-names></name>. <article-title>Diagnosis of multiple cancer types by shrunken centroids of gene expression</article-title>. <source>Proceedings of the National Academy of Sciences</source>. <year>2002</year>;<volume>99</volume>:<fpage>6567</fpage>–<lpage>72</lpage>. <pub-id pub-id-type="doi">10.1073/pnas.082099299</pub-id><?supplied-pmid 12011421?><pub-id pub-id-type="pmid">12011421</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1008799.ref010">
      <label>10</label>
      <mixed-citation publication-type="journal"><name><surname>Zhang</surname><given-names>X</given-names></name>, <name><surname>Zhao</surname><given-names>Y</given-names></name>, <name><surname>Xu</surname><given-names>J</given-names></name>, <name><surname>Xue</surname><given-names>Z</given-names></name>, <name><surname>Zhang</surname><given-names>M</given-names></name>, <name><surname>Pang</surname><given-names>X</given-names></name>, <etal>et al</etal>. <article-title>Modulation of gut microbiota by berberine and metformin during the treatment of high-fat diet-induced obesity in rats</article-title>. <source>Scientific reports</source>. <year>2015</year>;<volume>5</volume>:<fpage>14405</fpage>. <pub-id pub-id-type="doi">10.1038/srep14405</pub-id><?supplied-pmid 26396057?><pub-id pub-id-type="pmid">26396057</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1008799.ref011">
      <label>11</label>
      <mixed-citation publication-type="journal"><name><surname>Knights</surname><given-names>D</given-names></name>, <name><surname>Costello</surname><given-names>EK</given-names></name>, <name><surname>Knight</surname><given-names>R</given-names></name>. <article-title>Supervised classification of human microbiota</article-title>. <source>FEMS Microbiology reviews</source>. <year>2011</year>;<volume>35</volume>:<fpage>343</fpage>–<lpage>59</lpage>. <pub-id pub-id-type="doi">10.1111/j.1574-6976.2010.00251.x</pub-id><?supplied-pmid 21039646?><pub-id pub-id-type="pmid">21039646</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1008799.ref012">
      <label>12</label>
      <mixed-citation publication-type="journal"><name><surname>Vangay</surname><given-names>P</given-names></name>, <name><surname>Hillmann</surname><given-names>BM</given-names></name>, <name><surname>Knights</surname><given-names>D</given-names></name>. <article-title>Microbiome Learning Repo (ML Repo): A public repository of microbiome regression and classification tasks</article-title>. <source>Gigascience</source>. <year>2019</year>;<volume>8</volume>. <pub-id pub-id-type="doi">10.1093/gigascience/giz042</pub-id><?supplied-pmid 31042284?><pub-id pub-id-type="pmid">31042284</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1008799.ref013">
      <label>13</label>
      <mixed-citation publication-type="journal"><name><surname>Galkin</surname><given-names>F</given-names></name>, <name><surname>Aliper</surname><given-names>A</given-names></name>, <name><surname>Putin</surname><given-names>E</given-names></name>, <name><surname>Kuznetsov</surname><given-names>I</given-names></name>, <name><surname>Gladyshev</surname><given-names>VN</given-names></name>, <name><surname>Zhavoronkov</surname><given-names>A</given-names></name>. <article-title>Human microbiome aging clocks based on deep learning and tandem of permutation feature importance and accumulated local effects. preprint</article-title>. <source>Bioinformatics</source>; <year>2018</year>. <italic><ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1101/507780">https://doi.org/10.1101/507780</ext-link></italic>.</mixed-citation>
    </ref>
    <ref id="pcbi.1008799.ref014">
      <label>14</label>
      <mixed-citation publication-type="journal"><name><surname>Tibshirani</surname><given-names>R</given-names></name>. <article-title>Regression Shrinkage and Selection Via the Lasso</article-title>. <source>Journal of the Royal Statistical Society: Series B (Methodological).</source><year>1996</year>;<volume>58</volume>:<fpage>267</fpage>–<lpage>88</lpage>.</mixed-citation>
    </ref>
    <ref id="pcbi.1008799.ref015">
      <label>15</label>
      <mixed-citation publication-type="journal"><name><surname>Hoerl</surname><given-names>AE</given-names></name>, <name><surname>Kennard</surname><given-names>RW</given-names></name>. <article-title>Ridge Regression: Biased Estimation for Nonorthogonal Problems</article-title>. <source>Technometrics</source>. <year>1970</year>;<volume>12</volume>:<fpage>55</fpage>–<lpage>67</lpage>.</mixed-citation>
    </ref>
    <ref id="pcbi.1008799.ref016">
      <label>16</label>
      <mixed-citation publication-type="journal"><name><surname>Weiss</surname><given-names>S</given-names></name>, <name><surname>Xu</surname><given-names>ZZ</given-names></name>, <name><surname>Peddada</surname><given-names>S</given-names></name>, <name><surname>Amir</surname><given-names>A</given-names></name>, <name><surname>Bittinger</surname><given-names>K</given-names></name>, <name><surname>Gonzalez</surname><given-names>A</given-names></name>, <etal>et al</etal>. <article-title>Normalization and microbial differential abundance strategies depend upon data characteristics</article-title>. <source>Microbiome</source>. <year>2017</year>;<volume>5</volume>:<fpage>27</fpage>. <pub-id pub-id-type="doi">10.1186/s40168-017-0237-y</pub-id><?supplied-pmid 28253908?><pub-id pub-id-type="pmid">28253908</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1008799.ref017">
      <label>17</label>
      <mixed-citation publication-type="journal"><name><surname>Breiman</surname><given-names>L</given-names></name>. <article-title>Random Forests</article-title>. <source>Machine Learning</source>. <year>2001</year>;<volume>45</volume>:<fpage>5</fpage>–<lpage>32</lpage>.</mixed-citation>
    </ref>
    <ref id="pcbi.1008799.ref018">
      <label>18</label>
      <mixed-citation publication-type="journal"><name><surname>Friedman</surname><given-names>JH</given-names></name>. <article-title>Greedy Function Approximation: A Gradient Boosting Machine</article-title>. <source>Annals of statistics</source>. <year>2001</year>;<volume>29</volume>:<fpage>1189</fpage>–<lpage>232</lpage>.</mixed-citation>
    </ref>
    <ref id="pcbi.1008799.ref019">
      <label>19</label>
      <mixed-citation publication-type="journal"><name><surname>Wang</surname><given-names>T</given-names></name>, <name><surname>Zhao</surname><given-names>H</given-names></name>. <article-title>Constructing Predictive Microbial Signatures at Multiple Taxonomic Levels</article-title>. <source>Journal of the American Statistical Association</source>. <year>2017</year>;<volume>112</volume>:<fpage>1022</fpage>–<lpage>31</lpage>.</mixed-citation>
    </ref>
    <ref id="pcbi.1008799.ref020">
      <label>20</label>
      <mixed-citation publication-type="journal"><name><surname>Wang</surname><given-names>T</given-names></name>, <name><surname>Yang</surname><given-names>C</given-names></name>, <name><surname>Zhao</surname><given-names>H</given-names></name>. <article-title>Prediction analysis for microbiome sequencing data</article-title>. <source>Biometrics</source>. <year>2019</year>;<volume>75</volume>:<fpage>875</fpage>–<lpage>84</lpage>. <pub-id pub-id-type="doi">10.1111/biom.13061</pub-id><?supplied-pmid 30994187?><pub-id pub-id-type="pmid">30994187</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1008799.ref021">
      <label>21</label>
      <mixed-citation publication-type="journal"><name><surname>Shestopaloff</surname><given-names>K</given-names></name>, <name><surname>Escobar</surname><given-names>MD</given-names></name>, <name><surname>Xu</surname><given-names>W</given-names></name>. <article-title>Analyzing differences between microbiome communities using mixture distributions: Analyzing Differences Between Microbiome Communities</article-title>. <source>Statistics in Medicine.</source><year>2018</year>;<volume>37</volume>:<fpage>4036</fpage>–<lpage>53</lpage>. <pub-id pub-id-type="doi">10.1002/sim.7896</pub-id><?supplied-pmid 30039541?><pub-id pub-id-type="pmid">30039541</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1008799.ref022">
      <label>22</label>
      <mixed-citation publication-type="journal"><name><surname>Kostic</surname><given-names>AD</given-names></name>, <name><surname>Gevers</surname><given-names>D</given-names></name>, <name><surname>Pedamallu</surname><given-names>CS</given-names></name>, <name><surname>Michaud</surname><given-names>M</given-names></name>, <name><surname>Duke</surname><given-names>F</given-names></name>, <name><surname>Earl</surname><given-names>AM</given-names></name>, <etal>et al</etal>. <article-title>Genomic analysis identifies association of Fusobacterium with colorectal carcinoma</article-title>. <source>Genome research.</source><year>2012</year>;<volume>22</volume>:<fpage>292</fpage>–<lpage>98</lpage>. <pub-id pub-id-type="doi">10.1101/gr.126573.111</pub-id><?supplied-pmid 22009990?><pub-id pub-id-type="pmid">22009990</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1008799.ref023">
      <label>23</label>
      <mixed-citation publication-type="journal"><name><surname>Gevers</surname><given-names>D.</given-names></name>, <name><surname>Kugathasan</surname><given-names>S.</given-names></name>, <name><surname>Denson</surname><given-names>L. A</given-names></name>, <etal>et al</etal>. <article-title>The treatment-naive microbiome in new-onset Crohn’s disease</article-title>. <source>Cell host &amp; microbe</source>. <year>2014</year>;<volume>15</volume>:<fpage>382</fpage>–<lpage>92</lpage>. <pub-id pub-id-type="doi">10.1016/j.chom.2014.02.005</pub-id><?supplied-pmid 24629344?><pub-id pub-id-type="pmid">24629344</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1008799.ref024">
      <label>24</label>
      <mixed-citation publication-type="journal"><name><surname>Nocedal</surname><given-names>J</given-names></name>. <article-title>Updating Quasi-Newton Matrices with Limited Storage</article-title>. <source>Mathematics of Computation</source>. <year>1980</year>;<volume>35</volume>:<fpage>773</fpage>–<lpage>82</lpage>.</mixed-citation>
    </ref>
    <ref id="pcbi.1008799.ref025">
      <label>25</label>
      <mixed-citation publication-type="journal"><name><surname>Conn</surname><given-names>AR</given-names></name>, <name><surname>Gould</surname><given-names>NIM</given-names></name>, <article-title>Toint Philippe. A Globally Convergent Augmented Lagrangian Algorithm for Optimization with General Constraints and Simple Bounds</article-title>. <source>SIAM Journal on Numerical Analysis</source>. <year>1991</year>;<volume>28</volume>:<fpage>545</fpage>–<lpage>72</lpage>.</mixed-citation>
    </ref>
    <ref id="pcbi.1008799.ref026">
      <label>26</label>
      <mixed-citation publication-type="other">Shestopaloff K. Analysis of Ecological Communities Using Mixture Models [PhD thesis]. Toronto, Canada: University of Toronto. 2017.</mixed-citation>
    </ref>
    <ref id="pcbi.1008799.ref027">
      <label>27</label>
      <mixed-citation publication-type="book"><name><surname>Goutte</surname><given-names>C</given-names></name>, <name><surname>Gaussier</surname><given-names>E</given-names></name>. <chapter-title>A Probabilistic Interpretation of Precision, Recall and F-Score, with Implication for Evaluation</chapter-title>. In: <name><surname>Losada</surname><given-names>DE</given-names></name>, <name><surname>Fernández-Luna</surname><given-names>JM</given-names></name>, editors. <source>Advances in Information Retrieval</source>. <publisher-loc>Berlin, Heidelberg</publisher-loc>: <collab>Springer</collab>. <year>2005</year>;<fpage>345</fpage>–<lpage>59</lpage>. <pub-id pub-id-type="doi">10.1016/j.ijmedinf.2004.04.017</pub-id><?supplied-pmid 15694638?></mixed-citation>
    </ref>
    <ref id="pcbi.1008799.ref028">
      <label>28</label>
      <mixed-citation publication-type="journal"><name><surname>Shestopaloff</surname><given-names>K</given-names></name>, <name><surname>Xu</surname><given-names>W</given-names></name>, <name><surname>Escobar</surname><given-names>MD</given-names></name>. <article-title>Estimating total species using a weighted combination of expected mixture distribution component counts</article-title>. <source>Environmental and Ecological Statistics</source>. <year>2020</year>;<volume>27</volume>:<fpage>447</fpage>–<lpage>65</lpage>.</mixed-citation>
    </ref>
    <ref id="pcbi.1008799.ref029">
      <label>29</label>
      <mixed-citation publication-type="journal"><name><surname>Suykens</surname><given-names>JA</given-names></name>, <name><surname>Vandewalle</surname><given-names>J</given-names></name>. <article-title>Least squares support vector machine classifiers</article-title>. <source>Neural processing letters</source>. <year>1999</year>;<volume>9</volume>:<fpage>293</fpage>–<lpage>300</lpage>.</mixed-citation>
    </ref>
    <ref id="pcbi.1008799.ref030">
      <label>30</label>
      <mixed-citation publication-type="book"><name><surname>Pedrycz</surname><given-names>W</given-names></name>, <name><surname>Skowron</surname><given-names>A</given-names></name>, <name><surname>Kreinovich</surname><given-names>V</given-names></name>. <source>Handbook of granular computing</source>. <publisher-name>John Wiley &amp; Sons</publisher-name>. <year>2008</year>;<fpage>133</fpage>–<lpage>36</lpage>.</mixed-citation>
    </ref>
    <ref id="pcbi.1008799.ref031">
      <label>31</label>
      <mixed-citation publication-type="journal"><name><surname>Benjamini</surname><given-names>Y</given-names></name>, <name><surname>Hochberg</surname><given-names>Y</given-names></name>. <article-title>Controlling the False Discovery Rate: A Practical and Powerful Approach to Multiple Testing</article-title>. <source>Journal of the Royal Statistical Society Series B (Methodological).</source><year>1995</year>;<volume>57</volume>:<fpage>289</fpage>–<lpage>300</lpage>.</mixed-citation>
    </ref>
  </ref-list>
</back>
