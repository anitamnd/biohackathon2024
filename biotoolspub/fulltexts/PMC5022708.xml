<?properties open_access?>
<?subarticle report16219?>
<?DTDIdentifier.IdentifierValue -//NLM//DTD Journal Publishing DTD v3.0 20080202//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName journalpublishing3.dtd?>
<?SourceDTD.Version 3.0?>
<?ConverterInfo.XSLTName jp2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">F1000Res</journal-id>
    <journal-id journal-id-type="iso-abbrev">F1000Res</journal-id>
    <journal-id journal-id-type="pmc">F1000Research</journal-id>
    <journal-title-group>
      <journal-title>F1000Research</journal-title>
    </journal-title-group>
    <issn pub-type="epub">2046-1402</issn>
    <publisher>
      <publisher-name>F1000Research</publisher-name>
      <publisher-loc>London, UK</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">5022708</article-id>
    <article-id pub-id-type="doi">10.12688/f1000research.7082.3</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Software Tool Article</subject>
      </subj-group>
      <subj-group>
        <subject>Articles</subject>
        <subj-group>
          <subject>Bioinformatics</subject>
        </subj-group>
        <subj-group>
          <subject>Evolutionary/Comparative Genetics</subject>
        </subj-group>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>EvolQG - An R package for evolutionary quantitative genetics</article-title>
      <fn-group content-type="pub-status">
        <fn>
          <p>[version 3; referees: 1 approved</p>
        </fn>
      </fn-group>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Melo</surname>
          <given-names>Diogo</given-names>
        </name>
        <xref ref-type="corresp" rid="c1">a</xref>
        <xref ref-type="aff" rid="a1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Garcia</surname>
          <given-names>Guilherme</given-names>
        </name>
        <xref ref-type="aff" rid="a1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Hubbe</surname>
          <given-names>Alex</given-names>
        </name>
        <xref ref-type="aff" rid="a2">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Assis</surname>
          <given-names>Ana Paula</given-names>
        </name>
        <xref ref-type="aff" rid="a1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Marroig</surname>
          <given-names>Gabriel</given-names>
        </name>
        <xref ref-type="aff" rid="a1">1</xref>
      </contrib>
      <aff id="a1"><label>1</label>Departamento de Genética e Biologia Evolutiva, Instituto de Biociências, Universidade de São Paulo, São Paulo, Brazil</aff>
      <aff id="a2"><label>2</label>Departamento de Oceanografia, Instituto de Geociências, Universidade Federal da Bahia, Salvador, Brazil</aff>
    </contrib-group>
    <author-notes>
      <corresp id="c1">
        <label>a</label>
        <email xlink:href="mailto:diogro@usp.br">diogro@usp.br</email>
      </corresp>
      <fn fn-type="con">
        <p>D.M. compiled existing implementations, re-factored existing functions and contributed new code, documentation and unit tests. G.G. provided the initial set of functions and first implementations. A.H. tested and revised code and documentation. A.P.A. contributed code and documentation, G.M. developed methods and devised necessary elements for package. All authors wrote the paper.</p>
      </fn>
      <fn fn-type="COI-statement">
        <p><bold>Competing interests: </bold>No competing interests were disclosed.</p>
      </fn>
    </author-notes>
    <pub-date pub-type="epub">
      <day>8</day>
      <month>11</month>
      <year>2016</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2015</year>
    </pub-date>
    <volume>4</volume>
    <elocation-id>925</elocation-id>
    <history>
      <date date-type="accepted">
        <day>7</day>
        <month>11</month>
        <year>2016</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>Copyright: © 2016 Melo D et al.</copyright-statement>
      <copyright-year>2016</copyright-year>
      <license xlink:href="http://creativecommons.org/licenses/by/4.0/">
        <license-p>This is an open access article distributed under the terms of the Creative Commons Attribution Licence, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri content-type="pdf" xlink:type="simple" xlink:href="f1000research-4-10833.pdf"/>
    <abstract>
      <p>We present an open source package for performing evolutionary quantitative genetics analyses in the R environment for statistical computing. Evolutionary theory shows that evolution depends critically on the available variation in a given population. When dealing with many quantitative traits this variation is expressed in the form of a covariance matrix, particularly the additive genetic covariance matrix or sometimes the phenotypic matrix, when the genetic matrix is unavailable and there is evidence the phenotypic matrix is sufficiently similar to the genetic matrix. Given this mathematical representation of available variation, the \textbf{EvolQG} package provides functions for calculation of relevant evolutionary statistics; estimation of sampling error; corrections for this error; matrix comparison via correlations, distances and matrix decomposition; analysis of modularity patterns; and functions for testing evolutionary hypotheses on taxa diversification.</p>
    </abstract>
    <kwd-group kwd-group-type="author">
      <kwd>P-matrix</kwd>
      <kwd>G-matrix</kwd>
      <kwd>multivariate evolution</kwd>
      <kwd>drift</kwd>
      <kwd>morphological evolution</kwd>
      <kwd>directional selection</kwd>
      <kwd>matrix comparison</kwd>
      <kwd>covariance matrix</kwd>
    </kwd-group>
    <funding-group>
      <funding-statement>This work was supported by funding from FAPESP. D.M. was funded by grants 2012/20180-0 and 2014/01694-9; G.G. was funded by grant 2011/52469-4; A.H. was funded by grant 2012/24937-9; A.P.A was funded by grants 2008/56886-6 and 2010/52369-0; G.M. was funded by grant 2011/14295-7.</funding-statement>
      <funding-statement>
        <italic>I confirm that the funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</italic>
      </funding-statement>
    </funding-group>
  </article-meta>
  <notes notes-type="version-changes">
    <sec sec-type="version-changes">
      <label>Revised</label>
      <title>Amendments from Version 2</title>
      <p>We now make clear that the functions related to matrix error estimation should only be used with phenotypic co-variance matrices.</p>
    </sec>
  </notes>
</front>
<body>
  <sec sec-type="intro">
    <title>Introduction</title>
    <p>Quantitative genetics deals with the evolution and inheritance of continuous traits, like body size, bone lengths, gene expressions or any other inheritable characteristic that can be measured on a continuous scale, or which can be transformed to a continuous scale. This framework has been used in selective breeding and in describing the different sources of variation in natural populations, as well as understanding the interaction of evolutionary processes with this variation
<sup><xref rid="ref-32" ref-type="bibr">32</xref></sup>. Quantitative genetics has been successful in describing short term evolution, and is also useful in understanding diversification at a macroevolutionary level. The core development of modern evolutionary quantitative genetics started with the generalization of the univariate breeders equation to the multivariate response to selection equation, derived by Lande and also referred to as the Lande equation
<sup><xref rid="ref-28" ref-type="bibr">28</xref>,
<xref rid="ref-55" ref-type="bibr">55</xref></sup>. The Lande equation relates the evolutionary change in trait means of a given population (Δ
<italic>z</italic>) to the interaction between the additive genetic variation (
<bold>G</bold>-matrix) of this population and the directional selection (
<italic>β</italic>) acting on this population. The additive genetic variation of a population is represented by a symmetric square matrix called the
<bold>G</bold>-matrix, which contains the additive genetic variance of each trait on the diagonal and the additive genetic covariance between traits on the off-diagonal elements. From the Lande equation, Δ
<italic>z</italic> =
<bold>G</bold>
<italic>β</italic>, we can see that different populations may present markedly different responses (Δ
<italic>z</italic>) to the same directional selection (
<italic>β</italic>) simply because these populations have distinct
<bold>G</bold>-matrices. Other evolutionary forces affecting populations are also influenced by available variation, e. g., based on the
<bold>G</bold>-matrix it is possible to test if morphological differentiation of extant taxa is compatible with genetic drift or stabilizing selection (e.g.,
<xref rid="ref-2" ref-type="bibr">2</xref>,
<xref rid="ref-35" ref-type="bibr">35</xref>). Thus, describing and understanding changes in standing variation among populations
<sup><xref rid="ref-7" ref-type="bibr">7</xref>,
<xref rid="ref-31" ref-type="bibr">31</xref>,
<xref rid="ref-34" ref-type="bibr">34</xref></sup> as well as understanding constraints imposed by populations standing variation (e.g.,
<xref rid="ref-19" ref-type="bibr">19</xref>,
<xref rid="ref-33" ref-type="bibr">33</xref>,
<xref rid="ref-51" ref-type="bibr">51</xref>,
<xref rid="ref-58" ref-type="bibr">58</xref>) are major elements in evolutionary quantitative genetics.</p>
    <p>In this article we describe the
<bold>EvolQG</bold> package, developed to deal with the evolutionary quantitative genetics questions addressed above in the R environment for statistical computing
<sup><xref rid="ref-53" ref-type="bibr">53</xref></sup>. Our goal was to provide a suite of tools in a single consistent source, and to standardize and facilitate the adoption of these tools.</p>
  </sec>
  <sec>
    <title>Measurement error estimation</title>
    <p>Before estimating a
<bold>G</bold>-matrix, it is important to evaluate the influence of measurement error in data collection, since measurement error can drastically bias further analyses
<sup><xref rid="ref-11" ref-type="bibr">11</xref></sup>. Measurement error can be estimated by measuring each individual at least twice and estimating the amount of variation associated with each individual, which is the measurement error, in relation to total variation (i.e., the sum of within and between individuals variation) using an analysis of variance. The proportion of variance associated with among individual variation, and not within individual variation, is called the repeatability
<sup><xref rid="ref-30" ref-type="bibr">30</xref></sup>. A repeatability of 1 means that no variation is associated with measurement error. The function
<bold>CalcRepeatability()</bold> performs the calculation described in
<xref rid="ref-30" ref-type="bibr">30</xref> for a set of multivariate traits measured at least twice for each individual.</p>
  </sec>
  <sec>
    <title>Matrix estimation</title>
    <p>In the rest of this article we assume that the covariance matrix of interest has already been estimated by some procedure. This matrix can be a simple covariance of all the observed traits, or an estimated parameter from a more complicated linear model. The simplest case of a linear model approach would be using a multivariate analysis of covariance (MANCOVA) to control for differences in trait means that are not of immediate interest in the analyses (e.g., sexual dimorphism, geographic variation, etc.). The residual pooled within-group covariance matrix can be used in subsequent analysis
<sup><xref rid="ref-34" ref-type="bibr">34</xref></sup>. The
<bold>EvolQG</bold> function
<bold>CalculateMatrix()</bold> uses R’s
<bold>lm()</bold> model object to calculate variance-covariance matrices adjusting for the proper degrees of freedom in a simple fixed-effects MANCOVA. More complicated methods may be used to obtain
<bold>G</bold>-matrices, such as an animal model or a mixed model
<sup><xref rid="ref-32" ref-type="bibr">32</xref>,
<xref rid="ref-57" ref-type="bibr">57</xref></sup>, and these can be used for further analysis using
<bold>EvolQG</bold>.</p>
    <p><bold>EvolQG</bold> also provides a simple Bayesian model for phenotypic matrix estimation using a conjugate inverse Wishart prior, implemented in the function
<bold>BayesianCalculateMatrix()</bold>. The default behavior is to use a prior covariance matrix with the observed variances (from the data) on the diagonal and zeros in the off-diagonal elements. This method uses a type of regularization prior which provides a “shrinkage” posterior estimate which has some attractive properties when compared to the maximum likelihood estimate, such a lower mean squared error and a well behaved inverse
<sup><xref rid="ref-29" ref-type="bibr">29</xref>,
<xref rid="ref-44" ref-type="bibr">44</xref>,
<xref rid="ref-59" ref-type="bibr">59</xref></sup>. The maximum
<italic>a posteriori</italic> estimate is calculated analytically, and optionally the function also provides a sample from the posterior distribution and the median of these samples. These samples can be used in other Bayesian methods described in the next sections, or to calculate confidence intervals for any analysis using the covariance matrices.</p>
    <p>Ideally all the analysis we describe should be performed on
<bold>G</bold>-matrices, but accurate
<bold>G</bold>-matrix estimation can be hard, requiring large sample sizes, many families and known genealogies
<sup><xref rid="ref-60" ref-type="bibr">60</xref></sup>. One alternative we advocate for, which is usually more feasible, is to use the phenotypic covariance matrix (the
<bold>P</bold>-matrix) as a proxy of the population’s
<bold>G</bold>-matrix
<sup><xref rid="ref-8" ref-type="bibr">8</xref>,
<xref rid="ref-56" ref-type="bibr">56</xref></sup>. Conditions on where this approximation is reasonable depend on the structure of developmental and environmental effects, and testing for similarity is an empirical question that should be undertaken before using the
<bold>P</bold>-matrix as a proxy for the
<bold>G</bold>-matrix, ideally by direct comparison (e.g.,
<xref rid="ref-13" ref-type="bibr">13</xref>). As a general rule, high similarity between populations’
<bold>P</bold>-matrices is a good indicator of high similarity between
<bold>P</bold> and
<bold>G</bold>, and of a stable shared
<bold>G</bold>-matrix pattern, since the similarity between populations must come from either a common genetic structure, or the unlikely scenario of a different genetic structure buffered by an exactly compensating environmental structure in each population that leads to high similarity between phenotypic covariation.</p>
    <p>Some of the methods described below are not applicable to covariance matrices, only to correlation matrices. Correlations are standardized measures of association that are bounded between [−1, 1], and, unlike covariances, can be directly compared for pairs of traits with different scales. In most instances, correlation matrices can be obtained directly from covariance matrices by using the R function
<bold>cov2cor()</bold>.</p>
  </sec>
  <sec>
    <title>Matrix error and repeatabilities</title>
    <p>A
<bold>G</bold>-matrix will always be estimated with error
<sup><xref rid="ref-20" ref-type="bibr">20</xref>,
<xref rid="ref-37" ref-type="bibr">37</xref>,
<xref rid="ref-41" ref-type="bibr">41</xref></sup>, and it is important to take this error into account in further analyses. In some circumstances we want to compare two or more
<bold>G</bold>-matrices, calculating the matrices correlations (see section
<bold>Matrix Comparison</bold>). However, due to error in estimating these matrices, their correlations will never be one, even if the actual population parameter values are identical
<sup><xref rid="ref-8" ref-type="bibr">8</xref></sup>. Thus, matrix repeatabilities are used to correct matrix correlations by taking sampling error into account. The basic premise of all the methods is that taking repeated samples from the same population and comparing the resulting matrices would still give correlations that are lower than 1. We estimate the maximum correlation between matrices taken from the same population and correct the observed correlation by this maximum value. The corrected correlation between two observed matrices will be given by the original correlation divided by the geometric mean of their repeatabilities. If the repeatability of both matrices is one, the observed correlation does not change under the correction, and lower repeatabilities yield larger corrections. Estimating error for
<bold>G</bold>- and
<bold>P</bold>-matrices require different methods. The objective when estimating error is usually to create a sample of matrices that reflects our uncertainty regarding the estimated matrix. Because
<bold>G</bold>-matrix are estimated using mixed models or animal models
<sup><xref rid="ref-32" ref-type="bibr">32</xref>,
<xref rid="ref-57" ref-type="bibr">57</xref></sup> this model structure must be taken into account, and sampling strategies that work in P-matrices will severely underestimate error in
<bold>G</bold>-matrices. Given these restrictions, we can generate a distribution of
<bold>G</bold>-matrices in several ways: (i) mixed model packages often provide the functionality of bootstrapping over the exchangeable units in the design (i.e. permuting sires in a half-sib or full-sib design) and generate error estimates using these samples; (ii) Houle &amp; Meyer
<sup><xref rid="ref-23" ref-type="bibr">23</xref></sup> use an asymptotic approximation for the the parametric sampling distribution of the estimated
<bold>G</bold>-matrix to generate samples and estimate error, a method called MVN-REML available in the program WOMBAT
<sup><xref rid="ref-40" ref-type="bibr">40</xref></sup>; (iii) in a fully Bayesian context, samples from the posterior distribution of the
<bold>G</bold>-matrix can be used. These samples can then be used to calculate repeatabilities or confidence intervals for derived quantities. Using any of these sampling methods the repeatability can be estimated as the average comparison value for all pairs of sampled matrices or as the average comparison of the estimated matrix and the sampled matrices. </p>
    <p>When working with
<bold>P</bold>-matrices things are simpler, and repeatabilities are straight forward to calculate using
<bold>EvolQG</bold>. We provide a number of methods for estimating repeatability in
<bold>P</bold>-matrices, and their results can be passed on to the functions that calculate matrix correlations (section
<bold>Matrix Comparison</bold>):</p>
    <p><bold>AlphaRep():</bold> Cheverud
<sup><xref rid="ref-8" ref-type="bibr">8</xref></sup> describes an analytical expression for the repeatability of a correlation matrix. This expression is asymptotically convergent, so it should be used only when sample sizes are large, at least larger than the number of traits.</p>
    <p><bold>BootstrapRep():</bold> We may estimate the repeatability of the covariance (or correlation) structure of a given data set using a bootstrap procedure, sampling individuals with replacement from the data set and calculating a covariance (or correlation) matrix from each sample. The mean value of the correlation between the random sample matrix and the original estimated matrix is an estimate of the repeatability. This method has the advantage of not assuming any distribution on the data, but does provide inflated estimates of repeatabilities for small data sets. Even so, upwardly biased matrix repeatabilities are not so problematic, because they lead to conservative corrections of matrix correlations. However, users should be aware of this bias and should not interpret a high repeatability obtained from a small data set as indicating that the parameter is well estimated.</p>
    <p><bold>MonteCarloRep():</bold> We can use the observed covariance matrix as the Σ parameter in a multivariate normal distribution, and produce samples from this distribution, using a fixed sample size. The covariance (or correlation) matrix for each sample is compared to the observed matrix, and the mean of these comparisons is an estimate of the repeatability
<sup><xref rid="ref-34" ref-type="bibr">34</xref></sup>. This method has the advantage of being easy to apply to matrices coming from linear models with many fixed effects, and not requiring the original data; but can also lead to inflated repeatabilities for small samples.</p>
    <p>Both
<bold>MonteCarloRep()</bold> and
<bold>BootstrapRep()</bold> are based on generic functions (
<bold>MonteCarloStat()</bold> and
<bold>BootstrapStat()</bold>) which can be used for general sampling from covariance matrices using normal distributions or to generate bootstrap samples from a set of individuals, respectively. These functions can be used to generate confidence intervals for
<bold>P</bold>-matrices for any of the evolutionary statistics described below, or any user defined function.</p>
    <p>Sometimes the question we are trying to answer does not involve matrix comparisons, so other methods of assessing and correcting for error are needed.</p>
    <p><bold>Rarefaction():</bold> Rarefaction consists of taking progressively smaller samples with replacement from the original data set, calculating some statistic on each data set and comparing this with the full data set. These comparisons gives a general idea of how the inferences would change if we had smaller sample sizes, and how robust our data set is with respect to sampling, given that an appropriately large initial sample is available. The default operation is to calculate the covariance or correlation matrices and compare them using any of the matrix comparison methods (see section
<bold>Matrix Comparison</bold>). The generic
<bold>Rarefaction-Stat()</bold> can also be used to generate rarefaction curves for any user defined function.</p>
    <p><bold>ExtendMatrix():</bold> Marroig
<italic>et al.</italic>
<sup><xref rid="ref-37" ref-type="bibr">37</xref></sup> showed that sampling error on covariance matrix estimation can have a dramatic effect on the reconstruction of net selection gradients using the multivariate response to selection equation
<sup><xref rid="ref-28" ref-type="bibr">28</xref></sup>. One way to improve estimates is the simple procedure of "extending" the eigenvalues of the covariance matrix, where all the eigenvalues lower than a certain threshold are substituted by the smallest eigenvalue above the threshold. This substitution causes minimal changes in the distribution of phenotypes, but improves dramatically the estimates of net selection gradients. Alternatives to the extension method involve using regularized estimators for the covariance matrix, like Bayesian or shrinkage estimators
<sup><xref rid="ref-29" ref-type="bibr">29</xref>,
<xref rid="ref-59" ref-type="bibr">59</xref></sup>, available from package
<bold>corpcor</bold>. See
<xref rid="ref-37" ref-type="bibr">37</xref> for a thorough examination of the performance and consequences of the extension and shrinkage methods on simulated and real data sets.</p>
  </sec>
  <sec>
    <title>Evolutionary statistics</title>
    <p>Hansen &amp; Houle
<sup><xref rid="ref-19" ref-type="bibr">19</xref></sup> provide a suite of statistics that have fairly good biological interpretations for a given
<bold>G</bold>- or
<bold>P</bold>-matrix. Marroig
<italic>et al.</italic>
<sup><xref rid="ref-38" ref-type="bibr">38</xref></sup> is a comprehensive example of how these statistics may be used for interpreting morphological data.</p>
    <p>The function
<bold>MeanMatrixStatistics()</bold> calculates most of these statistics and their distributions, as shown below.
<bold>MonteCarloStat()</bold> and
<bold>BootstrapStat()</bold> can be used to generate confidence intervals for these statistics when using
<bold>P</bold>-matrices. Also, the previously available R package
<bold>evolvability</bold>
<sup><xref rid="ref-5" ref-type="bibr">5</xref></sup> implements some of these functions and provides confidence intervals.</p>
    <p>In the following,
<italic>E</italic>[·]
<sub><italic>β</italic></sub> represents the expected value over many random
<italic>β</italic> vectors with unit norm, &lt; ·, · &gt; represents the dot product between two vectors,
<italic>cos</italic>(·, ·) is the cosine between two vectors,
<bold>G</bold> is an arbitrary covariance matrix,
<bold>G</bold>
<sup>−1</sup> is the inverse
<bold>G</bold>,
<italic>tr</italic>(
<bold>G</bold>) is the trace of
<bold>G</bold>, and ॥ · ॥ the Euclidean norm of a vector.
<bold>MeanMatrixStatistics()</bold> calculates:
<list list-type="simple"><list-item><label>•</label><p>Mean squared correlation (
<italic>r</italic>
<sup>2</sup>): Given a correlation matrix, the elements below the diagonal are squared and averaged resulting in a measure of integration, that is, overall association between traits (also see the section
<bold>Modularity and Integration</bold> and
<xref rid="ref-49" ref-type="bibr">49</xref>).</p></list-item><list-item><label>•</label><p>Coefficient of variation of eigenvalues (ICV): A measure of integration that is suitable for covariance matrices, as it takes the amount of variation into account. Notice that at least for mammals, mean squared correlations and ICV generally have high correlation, but can lead to different conclusions if the traits included in the analysis have very different variances (due to scale, for example). If σ
<sub><italic>λ</italic></sub> is the standard deviation of the eigenvalues of a covariance matrix, and
<inline-formula><mml:math id="math1"><mml:mrow><mml:mover><mml:mi>λ</mml:mi><mml:mo>–</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> is the mean of the eigenvalues, the ICV is:</p><p><inline-formula><mml:math id="math2"><mml:mrow><mml:mi>I</mml:mi><mml:mi>C</mml:mi><mml:mi>V</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mi>λ</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mover><mml:mi>λ</mml:mi><mml:mo>–</mml:mo></mml:mover></mml:mrow></mml:mfrac></mml:mrow></mml:math></inline-formula></p></list-item><list-item><label>•</label><p>Percent of variation in first principal component: If
<inline-formula><mml:math id="math3"><mml:mrow><mml:msubsup><mml:mi>λ</mml:mi><mml:mn>1</mml:mn><mml:mo>G</mml:mo></mml:msubsup></mml:mrow></mml:math></inline-formula> is the leading eigenvalue of
<bold>G</bold>, we calculate this percentage as:</p><p><inline-formula><mml:math id="math4"><mml:mrow><mml:mi>P</mml:mi><mml:mi>C</mml:mi><mml:mn>1</mml:mn><mml:mi>%</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mi>λ</mml:mi><mml:mn>1</mml:mn><mml:mo mathvariant="bold">G</mml:mo></mml:msubsup></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo mathvariant="bold">G</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:math></inline-formula></p></list-item><list-item><label>•</label><p>Evolvability (
<xref ref-type="fig" rid="f1">Figure 1</xref>): The mean projection of the response to random selection gradients with unit norm onto the selection gradient. This projection is a measure of a population’s available variation in the direction of a particular selection gradient, averaged across all directions
<sup><xref rid="ref-19" ref-type="bibr">19</xref></sup>.</p><p><disp-formula><mml:math id="math5"><mml:mrow><mml:mover accent="true"><mml:mi>e</mml:mi><mml:mo stretchy="true">¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mi>E</mml:mi><mml:msub><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mo>&lt;</mml:mo><mml:mo mathvariant="bold">G</mml:mo><mml:mi>β</mml:mi><mml:mo>,</mml:mo><mml:mi>β</mml:mi><mml:mo>&gt;</mml:mo></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mi>β</mml:mi></mml:msub></mml:mrow></mml:math></disp-formula></p></list-item><list-item><label>•</label><p>Flexibility (
<xref ref-type="fig" rid="f1">Figure 1</xref>): The mean cosine of the angle between random selection gradients and the corresponding responses. Flexibility measures on average how the response to selection aligns with the selection gradient
<sup><xref rid="ref-38" ref-type="bibr">38</xref></sup>.</p><p><disp-formula><mml:math id="math6"><mml:mrow><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo stretchy="true">¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mi>E</mml:mi><mml:msub><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi mathvariant="italic">cos</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo mathvariant="bold">G</mml:mo><mml:mi>β</mml:mi><mml:mo>,</mml:mo><mml:mi>β</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mi>β</mml:mi></mml:msub></mml:mrow></mml:math></disp-formula></p></list-item><list-item><label>•</label><p>Respondability (
<xref ref-type="fig" rid="f1">Figure 1</xref>): Mean norm of the response to random selection gradients with unit norm. It also estimates how fast the population mean will change under directional selection
<sup><xref rid="ref-19" ref-type="bibr">19</xref>,
<xref rid="ref-38" ref-type="bibr">38</xref></sup>.</p><p><disp-formula><mml:math id="math7"><mml:mrow><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="true">¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mi>E</mml:mi><mml:msub><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mrow><mml:mo>‖</mml:mo><mml:mrow><mml:mo mathvariant="bold">G</mml:mo><mml:mrow><mml:mi>β</mml:mi><mml:mo>‖</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mi>β</mml:mi></mml:msub></mml:mrow></mml:math></disp-formula></p></list-item><list-item><label>•</label><p>Conditional Evolvability: Measures the mean response to selection in the direction of a given
<italic>β</italic> when other directions are under stabilizing selection
<sup><xref rid="ref-19" ref-type="bibr">19</xref></sup>.</p><p><disp-formula><mml:math id="math8"><mml:mrow><mml:mover accent="true"><mml:mi>c</mml:mi><mml:mo stretchy="true">¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mi>E</mml:mi><mml:msub><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>&lt;</mml:mo><mml:msup><mml:mo mathvariant="bold">G</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mi>β</mml:mi><mml:mo>,</mml:mo><mml:mi>β</mml:mi><mml:mo>&gt;</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mi>β</mml:mi></mml:msub></mml:mrow></mml:math></disp-formula></p></list-item><list-item><label>•</label><p>Autonomy: Measures the proportion of variance in the direction of a given
<italic>β</italic> that is independent from variation in other directions. Therefore, mean Autonomy can also be calculated as the mean ratio between Conditional Evolvability
<inline-formula><mml:math id="math9"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>c</mml:mi><mml:mo stretchy="true">¯</mml:mo></mml:mover></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and Evolvability
<inline-formula><mml:math id="math10"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>e</mml:mi><mml:mo stretchy="true">¯</mml:mo></mml:mover></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>
<sup><xref rid="ref-19" ref-type="bibr">19</xref></sup>.</p><p><disp-formula><mml:math id="math11"><mml:mrow><mml:mover accent="true"><mml:mi>a</mml:mi><mml:mo stretchy="true">¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mi>E</mml:mi><mml:msub><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>&lt;</mml:mo><mml:msup><mml:mo mathvariant="bold">G</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mi>β</mml:mi><mml:mo>,</mml:mo><mml:mi>β</mml:mi><mml:mo>&gt;</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>&lt;</mml:mo><mml:mo mathvariant="bold">G</mml:mo><mml:mi>β</mml:mi><mml:mo>,</mml:mo><mml:mi>β</mml:mi><mml:mo>&gt;</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mi>β</mml:mi></mml:msub></mml:mrow></mml:math></disp-formula></p></list-item><list-item><label>•</label><p>Constraints: The mean correlation between the response vector to random selection gradients and the matrix’s first principal component
<sup><xref rid="ref-38" ref-type="bibr">38</xref></sup>. If
<inline-formula><mml:math id="math12"><mml:mrow><mml:msubsup><mml:mo>Λ</mml:mo><mml:mn>1</mml:mn><mml:mo mathvariant="bold">G</mml:mo></mml:msubsup></mml:mrow></mml:math></inline-formula> is the first principal component of
<bold>G</bold>, constraints are measured as:</p><p><disp-formula><mml:math id="math13"><mml:mrow><mml:mi>E</mml:mi><mml:msub><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi mathvariant="italic">cos</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo mathvariant="bold">G</mml:mo><mml:mi>β</mml:mi><mml:mo>,</mml:mo><mml:msubsup><mml:mo>Λ</mml:mo><mml:mn>1</mml:mn><mml:mo mathvariant="bold">G</mml:mo></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mi>β</mml:mi></mml:msub></mml:mrow></mml:math></disp-formula></p></list-item></list>
</p>
    <fig fig-type="figure" id="f1" orientation="portrait" position="float">
      <label>Figure 1. </label>
      <caption>
        <title>Graphical representation of evolvability
<inline-formula><mml:math id="math14"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>e</mml:mi><mml:mo stretchy="true">¯</mml:mo></mml:mover></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></inline-formula> respondability
<inline-formula><mml:math id="math15"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="true">¯</mml:mo></mml:mover></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and flexibility
<inline-formula><mml:math id="math16"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo stretchy="true">¯</mml:mo></mml:mover></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> for a single selection gradient (
<italic>β</italic>) and the corresponding response (Δ
<italic>z</italic>) in the two dimensions defined by traits
<italic>x</italic> and
<italic>y</italic>.</title>
      </caption>
      <graphic xlink:href="f1000research-4-10833-g0000"/>
    </fig>
  </sec>
  <sec>
    <title>Matrix comparison</title>
    <p>A
<bold>G</bold>-matrix describes how the variation in particular populations is structured, but frequently the relevant question is how similar or dissimilar two populations are with respect to this standing variation. Because no two populations are identical, different patterns of variation are the norm. Depending on the evolutionary question at hand, different methods of comparing variation may be required. One possible application of matrix comparisons is when we wish to apply the Lande equation to micro and macroevolution, because doing so requires some additional assumptions, such as a relative stability of the
<bold>G</bold>-matrix over generations
<sup><xref rid="ref-24" ref-type="bibr">24</xref></sup>. Comparing extant covariance matrices is a test of this required stability (e.g.
<xref rid="ref-34" ref-type="bibr">34</xref>). For a thoughtful discussion on the biological relevance of statistical significance in matrix comparisons, see the discussion in
<xref rid="ref-16" ref-type="bibr">16</xref>.</p>
    <sec>
      <title>Matrix correlations</title>
      <p>One approach to estimate the similarity or dissimilarity between matrices is to calculate the correlation between these matrices.
<bold>EvolQG</bold> provides several functions for pairwise matrix correlation.</p>
      <p><bold>RandomSkewers():</bold> The Random Skewers (RS) method makes use of the Lande equation
<sup><xref rid="ref-28" ref-type="bibr">28</xref></sup>, Δ
<italic>z</italic> =
<italic>Gβ</italic>, where Δ
<italic>z</italic> represents the vector of response to selection,
<bold>G</bold> the
<bold>G</bold>-matrix and
<italic>β</italic> the directional selection vector, or selection gradient. In the RS method, the two matrices being compared are multiplied by a large number of normalized random selection vectors, and the resulting response vectors to the same selection vector are compared via a vector correlation (the cosine between the two vectors). The mean value of the correlation between the responses to the same selective pressure is used as a simple statistic of how often two populations respond similarly (in the same direction) to the same selective pressure:
<disp-formula id="e1"><mml:math id="math17"><mml:mrow><mml:mi>R</mml:mi><mml:mi>S</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>B</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>E</mml:mi><mml:msub><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi mathvariant="italic">cos</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>A</mml:mi><mml:mi>β</mml:mi><mml:mo>,</mml:mo><mml:mi>B</mml:mi><mml:mi>β</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mi>β</mml:mi></mml:msub><mml:mspace width="2.5em"/><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></disp-formula>
</p>
      <p>Where
<italic>E</italic>[·]
<sub><italic>β</italic></sub> is the expected value over random selection vectors
<italic>β</italic>. Significance in the random skewers comparison can be determined using a null expectation of correlation between random vectors. If the observed correlation between two matrices is above the 95% percentile of the distribution of correlations between random vectors, we consider the correlation significant and infer that there is evidence the two populations behave similarly under directional selection. Other implementations of the RS method sometimes resort to other forms of calculating significance, such as generating random matrices and creating a random distribution of correlations between matrices. Generating this distribution is difficult to do because generating random matrices with the properties of biological covariance structures is hard, see the
<bold>RandomMatrix()</bold> function for a quick discussion on this problem. But perhaps more important than the significance test, the RS method measure the overall similarity of the responses predicted by the two matrices under directional selection, a property that is at the core of applications of quantitative genetics theory to evolutionary problems. In this sense, a significant similarity measure by Random Skewers might still be low for a given application, when small differences in the direction of response are important. The RS values range between -1 (the matrices have opposite structures) and 1 (the matrices share the same structure), and zero means the matrices have distinct structures.</p>
      <p><bold>MantelCor():</bold> Correlation between matrices can be done using a simple Pearson correlation between the corresponding elements. Significance of this comparison must take the structure into account, so it is calculated by a permutation scheme, in which a null distribution is generated by permutation of rows and columns in one of the matrices and repeating the element-by-element correlation (i.e. Mantel test). The observed correlation is significant when it is larger than the 95% quantile of the permuted distribution. This method should only be used in correlation matrices, and cannot be used on covariance matrices because the variances might be very different, leading to large differences in the scale of the covariances. This scale difference can lead to a massive inflation in the correlation between matrices. The correlation between matrices range between -1 and 1, and higher correlations indicate matrices have more similar structures, null correlations indicate the matrices have distinct correlation structures. Correlations near zero can also occur if the elements of the matrices have nonlinear relations between them, as in all Pearson correlations. Negative correlations indicate the pattern of association between traits is reversed in the two matrices.</p>
      <p><bold>KzrCor():</bold> The Krzanowski shared space, or Krzanowski correlation, measures the degree to which the first principal components (eigenvectors) span the same subspace
<sup><xref rid="ref-3" ref-type="bibr">3</xref>,
<xref rid="ref-26" ref-type="bibr">26</xref></sup>, and is suitable for covariance or correlation matrices. If two
<italic>n × n</italic> matrices are being compared, the first
<inline-formula><mml:math id="math18"><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mi>n</mml:mi><mml:mn>2</mml:mn></mml:mfrac><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> principal components from one matrix are compared to the first
<italic>k</italic> principal components of the other matrix using the square of the vector correlations, and the sum of the correlations is a measure of how congruent the spanned subspaces are. We can write the Krzanowski correlation in terms of the matrices’ principal components (
<inline-formula><mml:math id="math19"><mml:mrow><mml:msubsup><mml:mi>Λ</mml:mi><mml:mi>i</mml:mi><mml:mi>A</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula> being the i
<italic>th</italic> principal component of matrix
<italic>A</italic>):
<disp-formula id="e2"><mml:math id="math20"><mml:mrow><mml:mi>K</mml:mi><mml:mi>r</mml:mi><mml:mi>z</mml:mi><mml:mi>C</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>B</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo> </mml:mo><mml:mo>=</mml:mo><mml:mo> </mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>k</mml:mi></mml:mfrac><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>k</mml:mi></mml:munderover><mml:mrow><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>k</mml:mi></mml:munderover><mml:mrow><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:msup><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mo>Λ</mml:mo><mml:mi>i</mml:mi><mml:mi>A</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mo>Λ</mml:mo><mml:mi>j</mml:mi><mml:mi>B</mml:mi></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle><mml:mspace width="2.5em"/><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:math></disp-formula>
</p>
      <p>The Krzanowski correlation values range between 0 (two subspaces are dissimilar) and 1 (two subspaces are identical).</p>
      <p><bold>PCAsimilarity():</bold> The Krzanowski correlation compares only the subspace shared by roughly the first half of the principal components, but does not consider the amount of variation each population has in these directions of the morphological space
<sup><xref rid="ref-62" ref-type="bibr">62</xref></sup>. In order to take the variation into account, we can add the eigenvalue associated with each principal component into the calculation, effectively weighting each correlation by the variance in the associated directions. If
<inline-formula><mml:math id="math21"><mml:mrow><mml:msubsup><mml:mi>λ</mml:mi><mml:mi>i</mml:mi><mml:mi>A</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula> is the i
<italic>th</italic> eigenvalue of matrix A, we have:
<disp-formula id="e3"><mml:math id="math22"><mml:mtable columnalign="right"><mml:mtr><mml:mtd><mml:mi>P</mml:mi><mml:mi>C</mml:mi><mml:mi>A</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>l</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>y</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>B</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mstyle displaystyle="true"><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:mrow><mml:mstyle displaystyle="true"><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:mrow><mml:msubsup><mml:mi>λ</mml:mi><mml:mi>i</mml:mi><mml:mi>A</mml:mi></mml:msubsup><mml:msubsup><mml:mi>λ</mml:mi><mml:mi>j</mml:mi><mml:mi>B</mml:mi></mml:msubsup><mml:msup><mml:mrow><mml:mi mathvariant="italic">cos</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mo>Λ</mml:mo><mml:mi>i</mml:mi><mml:mi>A</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mo>Λ</mml:mo><mml:mi>j</mml:mi><mml:mi>B</mml:mi></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:mrow><mml:mrow><mml:mstyle displaystyle="true"><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:mrow><mml:msubsup><mml:mi>λ</mml:mi><mml:mi>i</mml:mi><mml:mi>A</mml:mi></mml:msubsup><mml:msubsup><mml:mi>λ</mml:mi><mml:mi>j</mml:mi><mml:mi>B</mml:mi></mml:msubsup></mml:mrow></mml:mstyle></mml:mrow></mml:mfrac></mml:mtd><mml:mtd><mml:mspace width="7em"/><mml:mo stretchy="false">(</mml:mo><mml:mn>3</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>
</p>
      <p>Note the sum spans all the principal components, not just the first
<italic>k</italic> as in the Krzanowski correlation method. This method gives correlations that are very similar to the RS method, but is much faster. The PCA similarity values range between 0 (the shared subspaces have no common variation) and 1 (the shared subspaces have identical variation).</p>
    </sec>
    <sec>
      <title>Matrix decomposition</title>
      <p>Some methods attempt to characterize how a set of matrices differ, going beyond simple correlations.
<bold>EvolQG</bold> provides efficient implementations of some of these methods.</p>
      <p><bold>SRD():</bold> The RS method can be extended to give information into which traits contribute to differences in terms of the pattern of correlated selection due to covariation between traits in two populations
<sup><xref rid="ref-36" ref-type="bibr">36</xref></sup>. The Selection Response Decomposition does this by treating the terms of correlated response in the Lande equation as separate entities. Writing out the terms in the multivariate response to selection equation:
<disp-formula id="e4"><mml:math id="math23"><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:mo mathvariant="bold">A</mml:mo><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtable columnalign="left"><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mn>11</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mn>12</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mo>⋯</mml:mo></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mn>21</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mn>22</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mo>⋯</mml:mo></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="center"><mml:mo>⋮</mml:mo></mml:mtd><mml:mtd columnalign="center"><mml:mo>⋮</mml:mo></mml:mtd><mml:mtd columnalign="center"><mml:mo>⋱</mml:mo></mml:mtd><mml:mtd columnalign="center"><mml:mo>⋮</mml:mo></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd columnalign="center"><mml:mo>⋯</mml:mo></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtable columnalign="left"><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>β</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>β</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="center"><mml:mo>⋮</mml:mo></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>β</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mspace width="2em"/><mml:mo stretchy="false">(</mml:mo><mml:mn>4</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtable columnalign="left"><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mn>11</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>β</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mn>12</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>β</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mo>⋯</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>β</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mn>21</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>β</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mn>22</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>β</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mo>⋯</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>β</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="center"><mml:mo>⋮</mml:mo></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>β</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>β</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mo>⋯</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>β</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo>Δ</mml:mo><mml:mi>z</mml:mi></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>
</p>
      <p>Separating the terms in the sums of the right hand side:
<disp-formula id="e5"><mml:math id="math24"><mml:mrow><mml:mtable columnalign="left"><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mn>11</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>β</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mn>12</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>β</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mo>⋯</mml:mo></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>β</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mn>21</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>β</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mn>22</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>β</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mo>⋯</mml:mo></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>β</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="center"><mml:mo>⋮</mml:mo></mml:mtd><mml:mtd columnalign="center"><mml:mo>⋮</mml:mo></mml:mtd><mml:mtd columnalign="left"><mml:mo>⋱</mml:mo></mml:mtd><mml:mtd columnalign="center"><mml:mo>⋮</mml:mo></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>β</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>β</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mo>⋯</mml:mo></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>β</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable><mml:mspace width="2.5em"/><mml:mo stretchy="false">(</mml:mo><mml:mn>5</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></disp-formula>
</p>
      <p>Each of these row vectors
<inline-formula><mml:math id="math25"><mml:mrow><mml:msubsup><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>β</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>β</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>…</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> are the components of the response to the selection gradient
<italic>β</italic> on trait
<italic>i</italic>. The term
<italic>A
<sub>ii</sub>β
<sub>i</sub></italic> represents the response to direct selection on trait
<italic>i</italic>, and the terms (
<italic>A
<sub>ij</sub>β
<sub>j</sub></italic>)
<sub><italic>i</italic>≠
<italic>j</italic></sub> represent the response to indirect selection due to correlation with the other traits. Given two matrices,
<italic>A</italic> and
<italic>B</italic>, we can measure how similar they are in their pattern of correlated selection on each trait by calculating the correlation between the vectors
<italic>r
<sub>i</sub></italic> for each trait for random selection vectors of unit norm. The mean SRD score for trait
<italic>i</italic> is then:
<disp-formula id="e6"><mml:math id="math26"><mml:mrow><mml:mi>μ</mml:mi><mml:mi>S</mml:mi><mml:mi>R</mml:mi><mml:mi>D</mml:mi><mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>B</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>E</mml:mi><mml:msub><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>β</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mi>β</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mi>β</mml:mi></mml:msub><mml:mspace width="2.5em"/><mml:mo stretchy="false">(</mml:mo><mml:mn>6</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></disp-formula>
</p>
      <p>And the standard deviation of the correlations gives the variation in SRD scores:
<disp-formula id="e7"><mml:math id="math27"><mml:mrow><mml:mi>σ</mml:mi><mml:mi>S</mml:mi><mml:mi>R</mml:mi><mml:mi>D</mml:mi><mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>B</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msqrt><mml:mrow><mml:mi>E</mml:mi><mml:msub><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>β</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mi>β</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi>μ</mml:mi><mml:mi>S</mml:mi><mml:mi>R</mml:mi><mml:msub><mml:mi>D</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mi>β</mml:mi></mml:msub></mml:mrow></mml:msqrt><mml:mspace width="2.5em"/><mml:mo stretchy="false">(</mml:mo><mml:mn>7</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></disp-formula>
</p>
      <p>When the same trait in different matrices share a correlated response pattern,
<italic>µSRD</italic> is high and
<italic>σSRD</italic> is low; if the correlated response pattern is different,
<italic>µSRD</italic> is low and
<italic>σSRD</italic> is high. See
<xref rid="ref-36" ref-type="bibr">36</xref> for details and examples.</p>
      <p><bold>RSprojection():</bold> Aguirre
<italic>et al.</italic>
<sup><xref rid="ref-3" ref-type="bibr">3</xref></sup> used a modification of the Random Skewers method to examine differences in the magnitude of variation in different directions in a set of covariance matrices. This method is most useful when a posterior sample of covariance matrices is available, as this sample allows us to identify directions in the morphospace that show relevant differences in the amount of variation between any two matrices. The function
<bold>RSprojection()</bold> uses a set of posterior samples to identify the directions that represent the most significant differences in variance, and to compare the amount of variation in each matrix for each of these directions. The posterior samples of covariance matrices can be obtained using any Bayesian linear model package, such as MCMCglmm
<sup><xref rid="ref-17" ref-type="bibr">17</xref></sup>, or, for simple cases,
<bold>BayesianCalculateMatrix()</bold>. This method identifies directions where there is a significant difference in the amount of variation, so it is most useful when the matrices being compared have similar scales, since matrices with identical structure might have different amounts of variation in all directions simply because the total amount of variation is larger in one of the matrices.</p>
      <p><bold>EigenTensorDecomposition():</bold> Hine
<italic>et al.</italic>
<sup><xref rid="ref-21" ref-type="bibr">21</xref></sup> proposes using covariance tensors for characterizing covariance matrix variation, based on Basser &amp; Pajevic
<sup><xref rid="ref-4" ref-type="bibr">4</xref></sup>. Covariance tensors can be further decomposed into orthogonal eigentensors and eigenvalues; each covariance matrix in the sample can thus be represented as a combination of such eigentensors, in a manner analogous to Principal Component Analysis. Considering the non-Euclidean (Riemannian) nature of the space of symmetric positive-definite matrices (
<xref ref-type="fig" rid="f2">Figure 2</xref>), the implementation of this procedure in
<bold>EvolQG</bold> relies on estimating a geometric mean matrix (which minimizes the sum of Riemannian distances among observations
<sup><xref rid="ref-43" ref-type="bibr">43</xref></sup>; implemented as
<bold>MeanMatrix()</bold>) and mapping such observations into an actual Euclidean space using the function
<disp-formula id="e8"><mml:math id="math28"><mml:mrow><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo mathvariant="bold">X</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>L</mml:mi><mml:mi>o</mml:mi><mml:mi>g</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mo mathvariant="bold">M</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mrow></mml:msup><mml:mo mathvariant="bold">X</mml:mo><mml:msup><mml:mo mathvariant="bold">M</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mspace width="2.5em"/><mml:mo stretchy="false">(</mml:mo><mml:mn>8</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></disp-formula>
</p>
      <fig fig-type="figure" id="f2" orientation="portrait" position="float">
        <label>Figure 2. </label>
        <caption>
          <title>Graphical depiction of the eigentensor decomposition of covariance matrices A, B and C.</title>
          <p>The mean matrix M is estimated within the non-Euclidean space of symmetric positive-definite matrices; the transformation
<inline-formula><mml:math id="math29"><mml:mrow><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>X</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi mathvariant="italic">Log</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mo>M</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mtext>XM</mml:mtext></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> maps A, B and C into an Euclidean space centered on M. Only in this Euclidean space are the eigentensors (PM1 and PM2) estimated.</p>
        </caption>
        <graphic xlink:href="f1000research-4-10833-g0001"/>
      </fig>
      <p>where
<bold>M</bold> refers to the estimated geometric mean matrix and
<italic>Log</italic> refers to the matrix logarithm operator. Only then a covariance tensor can be estimated, considering that the estimation of orthogonal eigentensors assumes that observations are contained within an Euclidean space, equipped with definitions for both angle and distance. The function
<bold>EigenTensorDecomposition()</bold> implements these steps; furthermore, given an eigentensor decomposition estimated using this function, it is possible to project other covariance matrices of the same size as the original sample onto the obtained eigentensors (
<bold>ProjectMatrix()</bold>), and also reconstruct covariance matrices based on their scores over eigentensors (
<bold>RevertMatrix()</bold>), which may be useful for observing the direction associated with each eigentensor as actual covariance matrices. This function uses the inverse operation to
<xref ref-type="disp-formula" rid="e8">equation 8</xref>, that is
<disp-formula id="e9"><mml:math id="math30"><mml:mrow><mml:msup><mml:mi>f</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mo mathvariant="bold">X</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msup><mml:mo mathvariant="bold">M</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mrow></mml:msup><mml:mi>E</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo mathvariant="bold">X</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mo mathvariant="bold">M</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mspace width="2.5em"/><mml:mo stretchy="false">(</mml:mo><mml:mn>9</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></disp-formula> where
<italic>Exp</italic> refers to the matrix exponential operator. This operation maps the matrix
<bold>X</bold> back onto the non-Euclidean space of symmetric positive-definite matrices. If a posterior sample of covariances matrices is available, this function can be used to implement the hypothesis-testing method described in Aguirre
<italic>et al.</italic>
<sup><xref rid="ref-3" ref-type="bibr">3</xref></sup> using covariance tensors, but this test also requires a null distribution of matrices that has to be tailored to the data at hand. Also, since the covariance tensor is calculated using the covariation between elements in the covariance matrix, these methods require two levels of replication in the data: individuals within populations for the calculation of the covariance matrices, and several populations for the calculation of the covariance tensor. This requirement should be kept in mind when interpreting the results, as small samples at either level can lead to poorly estimated parameters and misleading results.</p>
    </sec>
    <sec>
      <title>Matrix distances</title>
      <p>Another approach to estimate the similarity or dissimilarity between matrices is to calculate the distance between a pair of matrices. Matrices distances are different from correlations in that correlations are limited to [−1, +1], while distances must only be positive. Also, smaller values of distances mean more similarity. Two distances are in use in the current evolutionary literature, and are implemented in the function
<bold>MatrixDistance()</bold>.</p>
      <list list-type="bullet">
        <list-item>
          <p>Overlap distance: Ovaskainen
<italic>et al.</italic>
<sup><xref rid="ref-48" ref-type="bibr">48</xref></sup> proposed a distance based on probability distributions, where two covariance matrices would have a distance proportional to how distinguishable they are. This distance is natural if we think of covariance matrices as describing the probability distribution of phenotypes or additive values in the population. The higher the probability of a random draw coming from the distribution defined by one of the matrices being misclassified as coming from the distribution defined by the other, the lower the distance. For two probability distributions
<italic>f</italic> and
<italic>g</italic>, the probability of misclassifying a draw from
<italic>f</italic> as coming from
<italic>g</italic> is:
<disp-formula id="e10"><mml:math id="math31"><mml:mrow><mml:mi>q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>f</mml:mi><mml:mo>,</mml:mo><mml:mi>g</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:mrow><mml:msub><mml:mo>∫</mml:mo><mml:mrow><mml:msup><mml:mi>R</mml:mi><mml:mi>n</mml:mi></mml:msup></mml:mrow></mml:msub><mml:mrow><mml:mfrac><mml:mrow><mml:mi>g</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>g</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>d</mml:mi><mml:mi>x</mml:mi><mml:mspace width="2.5em"/><mml:mo stretchy="false">(</mml:mo><mml:mn>10</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:math></disp-formula> where
<italic>n</italic> is the dimensionality of the space in which the distributions are defined. If the distributions are indistinguishable,
<italic>q</italic>(
<italic>f</italic>,
<italic>g</italic>) = 1/2, if they are completely distinguishable
<italic>q</italic>(
<italic>f</italic>,
<italic>g</italic>) = 0. We can then define the distance as:
<disp-formula id="e11"><mml:math id="math32"><mml:mrow><mml:mi>d</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>f</mml:mi><mml:mo>,</mml:mo><mml:mi>g</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msqrt><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:mi>q</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>f</mml:mi><mml:mo>,</mml:mo><mml:mi>g</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msqrt><mml:mspace width="2.5em"/><mml:mo stretchy="false">(</mml:mo><mml:mn>11</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></disp-formula>
</p>
          <p>Since
<italic>q</italic>(
<italic>f</italic>,
<italic>g</italic>) is symmetrical,
<italic>d</italic>(
<italic>f</italic>,
<italic>g</italic>) is also symmetrical, and the square root guaranties that
<italic>d</italic>(
<italic>f</italic>,
<italic>g</italic>) satisfies the triangle inequality
<sup><xref rid="ref-48" ref-type="bibr">48</xref></sup>. Calculation is straight forward and can be done with a simple sampling Monte Carlo scheme, see
<xref rid="ref-48" ref-type="bibr">48</xref> for details.</p>
        </list-item>
        <list-item>
          <p>Riemann distance: Mitteroecker and Bookstein
<sup><xref rid="ref-42" ref-type="bibr">42</xref></sup> use a Riemannian metric in the space of positive definite matrices (either covariance or correlation matrices), based on exponential mapping
<sup><xref rid="ref-43" ref-type="bibr">43</xref></sup> to quantify transition in the ontogenetic trajectory of phenotypic covariance matrices. This metric is based on the eigenvalues of the product of one matrix to the inverse of the other. If
<italic>λ
<sub>i</sub></italic> are the eigenvalues of
<italic>A</italic>
<sup>−1</sup>
<italic>B</italic> (or
<italic>AB</italic>
<sup>−1</sup>), we have:
<disp-formula id="e12"><mml:math id="math33"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mo>‖</mml:mo><mml:mrow><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mi>B</mml:mi><mml:mo>‖</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="italic">cov</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>‖</mml:mo><mml:mrow><mml:mi>B</mml:mi><mml:mo>,</mml:mo></mml:mrow></mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mo>‖</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="italic">cov</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msqrt><mml:mrow><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>p</mml:mi></mml:munderover><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi mathvariant="italic">log</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mstyle></mml:mrow></mml:msqrt><mml:mspace width="2.5em"/><mml:mo stretchy="false">(</mml:mo><mml:mn>12</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></disp-formula>
</p>
          <p>This distance has the advantage of being invariable under changes in the base used to represent the matrices. See
<xref rid="ref-42" ref-type="bibr">42</xref> for a discussion on the biological relevance of this distance.</p>
        </list-item>
      </list>
    </sec>
  </sec>
  <sec>
    <title>Phylogenetic comparisons</title>
    <p><bold>PhyloW():</bold> Given a set of covariance matrices for the terminal taxa in a phylogeny, we can estimate the covariance matrix for internal nodes by taking means over sister taxa, weighted by sample size. The mean matrix at the root node is the within-group covariance matrix in a MANCOVA with the terminal clades as the fixed effects.
<bold>PhyloW()</bold> does this estimation by taking a tree and a set of measurements (covariance matrices) and returns means weighted by sample size for internal nodes. The implementation is generic, so this function can also be used to calculate weighted means for any numerical measurement with an addition operation implemented in R.</p>
    <p>For G-matrices it might not be clear what the appropriate weight to use in each node, as the linear mixed models used in G-matrix estimation do not assign a clear degree of freedom for the covariance matrix. Number of families could plausibly be a good weighing factor, but one should proceed with caution, or use a more direct approach of including the phylogeny in G-matrix estimation.</p>
    <p>While using the within-group covariance matrix is a reasonable alternative as the estimator of an ancestral covariance matrix, it ignores branch lengths, and so should be used carefully when matrix differences are correlated to phylogenetic distance. An alternative when matrix evolution depends of branch lengths is to reconstruct every position of the covariance matrix independently via maximum likelihood, but this method can result in non positive-definite estimates.</p>
    <p><bold>PhyloCompare():</bold> Sometimes it is not practical to pairwise compare every single population in a study, since for a large number of populations these results can be difficult to interpret. In these cases, comparing populations in a phylogeneticaly structured way can be helpful in detecting major transitions or differences between clades.
<bold>PhyloCompare()</bold> takes estimates for all the nodes in a tree and compares sister groups by any comparison method, providing comparison values for every inner node.</p>
  </sec>
  <sec>
    <title>Hypothesis testing</title>
    <sec>
      <title>Modularity and integration</title>
      <p>Modularity is a general concept in biology, and refers to a pattern of organization that is widespread in many biological systems. In modular systems, we find that some components of a given structure are more related or interact more between themselves than with other components. These highly related groups are termed modules. The nature of this interaction will depend on the components being considered, but may be of any kind, like physical contact between proteins, joint participation of enzymes in given biochemical pathways, or high correlation between quantitative traits in a population. This last kind of modularity is called variational modularity, and is characterized by high correlations between traits belonging to the same module and low correlation between traits in different modules
<sup><xref rid="ref-61" ref-type="bibr">61</xref></sup>. In the context of morphological traits, variational modularity is associated with the concept of integration
<sup><xref rid="ref-47" ref-type="bibr">47</xref></sup>, that is, the tendency of morphological systems to exhibit correlations due to common developmental factors and functional demands
<sup><xref rid="ref-9" ref-type="bibr">9</xref>,
<xref rid="ref-18" ref-type="bibr">18</xref></sup>.</p>
      <p>Both modularity and integration may have important evolutionary consequences, since sets of integrated traits will tend to respond to directional selection in an orchestrated fashion due to genetic correlations between them; if these sets are organized in a modular fashion, they will also respond to selection independently of one another
<sup><xref rid="ref-38" ref-type="bibr">38</xref></sup>. At the same time, selection can alter existing patterns of integration and modularity, leading to traits becoming more or less correlated
<sup><xref rid="ref-24" ref-type="bibr">24</xref>,
<xref rid="ref-39" ref-type="bibr">39</xref></sup>. The correlations between traits in a
<bold>G</bold>-matrix then carries important information on the expected response to selection and on the history of evolutionary change of a given population.</p>
      <p><bold>TestModularity():</bold> Variational modularity can be assessed by comparing a modularity hypothesis (derived from development and functional considerations) with the observed correlation matrix. If two traits are in the same variational module, we expect the correlation between them to be higher than between traits belonging to different modules. We test this partition by creating a modularity hypothesis matrix and comparing it via Pearson correlation between the corresponding elements in the observed correlation matrix. The modularity hypothesis matrix consists of a binary matrix where each row and column corresponds to a trait. If the trait in row
<italic>i</italic> is in the same module of the trait in column
<italic>j</italic>, position (
<italic>i</italic>,
<italic>j</italic>) in the modularity hypothesis matrix is set to one, if these traits are not in the same module, position (
<italic>i</italic>,
<italic>j</italic>) is set to zero. Significant correlation between the hypothetical matrix representing a modularity hypothesis and the observed correlation matrix represents evidence of the existence of this variational module in the population. We also measure the ratio between correlations within a module (AVG+) and outside the module (AVG-). This ratio (AVG+/AVG-) is called the AVG Ratio, and measures the strength of the within-module association compared to the overall association for traits outside the module. The higher the AVG Ratio, the bigger the correlations within a module in relation to all other traits associations in the matrix (e.g.,
<xref rid="ref-50" ref-type="bibr">50</xref>).
<bold>TestModularity()</bold> also provides the Modularity Hypothesis Index, which is the difference between AVG+ and AVG- divided by the coefficient of variation of eigenvalues. Although the AVG Ratio is easier to interpret (how many times greater the within-module correlation is compared to the between-module correlation) than the Modularity Hypothesis Index, the AVG Ratio cannot be used when the observed correlation matrix presents correlations that differ in sign, and this is usually the case for residual matrices after size removal (for example with
<bold>RemoveSize()</bold>, but see
<xref rid="ref-25" ref-type="bibr">25</xref> for other alternatives). In these cases, the Modularity Hypothesis Index is useful and allows comparing results between raw and residual matrices
<sup><xref rid="ref-51" ref-type="bibr">51</xref></sup>.</p>
      <p><bold>LModularity():</bold> If no empirical or theoretical information is available for creating a modularity hypothesis, such as functional or developmental data, we can try to infer the modular partition of a given population by looking only at the correlation matrix and searching for the trait partition that minimizes some indicator of modularity. Borrowing from network theory, we can treat a correlation matrix as a fully connected weighted graph, and define a Newman-like modularity index
<sup><xref rid="ref-45" ref-type="bibr">45</xref></sup>. If
<italic>A</italic> is a correlation matrix we define
<italic>L</italic> modularity as:
<disp-formula id="e13"><mml:math id="math34"><mml:mrow><mml:mi>L</mml:mi><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>≠</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mi>k</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mi>m</mml:mi></mml:mrow></mml:mfrac></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mi>δ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mspace width="2.5em"/><mml:mo stretchy="false">(</mml:mo><mml:mn>13</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:math></disp-formula>
</p>
      <p>The terms
<italic>g
<sub>i</sub></italic> and
<italic>g
<sub>j</sub></italic> represent the partition of traits, that is, in what modules the traits
<italic>i</italic> and
<italic>j</italic> belong to. The function
<italic>δ</italic>(
<italic>·</italic>,
<italic>·</italic>) is the Kronecker delta, where:
<disp-formula id="e14"><mml:math id="math35"><mml:mrow><mml:mi>δ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mtable columnalign="left"><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mn>1</mml:mn></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mtext>if</mml:mtext><mml:mo> </mml:mo><mml:mi>x</mml:mi><mml:mo>=</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mn>0</mml:mn></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mtext>if</mml:mtext><mml:mo> </mml:mo><mml:mi>x</mml:mi><mml:mo>≠</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mrow><mml:mspace width="2.5em"/><mml:mo stretchy="false">(</mml:mo><mml:mn>14</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></disp-formula>
</p>
      <p>This means only traits in the same module contribute to the value of
<italic>L</italic>. The term
<italic>k
<sub>i</sub></italic> represent the total amount of correlation attributed to trait
<italic>i</italic>, or the sum of the correlation with trait
<italic>i</italic>:
<disp-formula id="e15"><mml:math id="math36"><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>≠</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mspace width="2.5em"/><mml:mo stretchy="false">(</mml:mo><mml:mn>15</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:math></disp-formula>
</p>
      <p>And
<italic>m</italic> is the sum of all
<inline-formula><mml:math id="math37"><mml:mrow><mml:mi>k</mml:mi><mml:mo> </mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:msub><mml:mo>∑</mml:mo><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mstyle><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:math></inline-formula> The term
<inline-formula><mml:math id="math38"><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mi>k</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mi>m</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math></inline-formula> plays the role of a null expectation for the correlation between the traits
<italic>i</italic> and
<italic>j</italic>. This choice for the null expectation is natural when we impose that it must depend on the values of
<italic>k
<sub>i</sub></italic> and
<italic>k
<sub>j</sub></italic> and must be symmetrical
<sup><xref rid="ref-45" ref-type="bibr">45</xref></sup>. So, traits in the same module with correlations higher than the null expectation will contribute to increase the value of
<italic>L</italic>, while traits in the same module with correlation less than the null expectation will contribute to decrease
<italic>L</italic>. With this definition of
<italic>L</italic>, we use an optimization procedure to find the partition of traits (values of
<italic>g
<sub>i</sub></italic>) that maximizes
<italic>L</italic>. This partition corresponds to the modularity hypothesis inferred from the correlation matrix, and the value of
<italic>L</italic> is a measure of modularity comparable to the AVG Ratio. The igraph package
<sup><xref rid="ref-10" ref-type="bibr">10</xref></sup> provides a number of community detection algorithms that can be used on correlation matrices using this function.</p>
      <p><bold>RemoveSize():</bold> If the first principal component of a covariance or correlation matrix corresponds to a very large portion of its variation, and all (or most) of the entries of the first principal component are of the same sign (a
<italic>size</italic> principal component, see
<xref rid="ref-33" ref-type="bibr">33</xref>), it is useful to look at the structure of modularity after removing this dominant integrating factor. This removal is done using the method described in
<xref rid="ref-6" ref-type="bibr">6</xref>. Porto
<italic>et al.</italic>
<sup><xref rid="ref-51" ref-type="bibr">51</xref></sup> show that modularity is frequently more easily detected in matrices where the first principal component variation was removed and provide biological interpretations for these results.</p>
    </sec>
    <sec>
      <title>Drift</title>
      <p>Selection is frequently invoked to explain morphological diversification, but the null hypothesis of drift being sufficient to explain current observed patterns must always be entertained. We can test the plausibility of drift for explaining multivariate diversification by using the regression method
<sup><xref rid="ref-1" ref-type="bibr">1</xref></sup>, or the correlation of principal component scores
<sup><xref rid="ref-1" ref-type="bibr">1</xref>,
<xref rid="ref-35" ref-type="bibr">35</xref></sup>. Since both these tests use drift as a null hypothesis, failure to reject the null hypothesis is not evidence that selection was not involved in the observed pattern of diversification, only that the observed pattern is compatible with drift. Also, these methods assume that the matrices involved share some degree of similarity, and should ideally be proportional to each other. We would be very weary of using these methods if the matrices are too dissimilar, or if the results change radically if different matrices are used as the ancestral matrix. Also, these tests rely on two levels of replication, taxa and traits. As a general guideline, at least 20 traits and at least 8 taxa should be sampled for using these methods with any confidence, and results should be analyzed in conjunction with other lines of evidence.</p>
      <p><bold>DriftTest()</bold>: Under drift and without gene flow, we expect that the current between group variance for many populations will be proportional to the ancestral population’s covariance structure, which is approximated by the pooled within-group covariance matrix. This test assumes matrices remain proportional to the ancestral matrix, but this might not always be the case
<sup><xref rid="ref-14" ref-type="bibr">14</xref></sup>. Conditions for the validity of these assumptions are reviewed in
<xref rid="ref-52" ref-type="bibr">52</xref>, and matrices for the extant groups should always be tested for similarity. Under these conditions, if
<italic>B</italic> is the between group covariance matrix, and
<italic>W</italic> is the within group covariance matrix,
<italic>t</italic> is the time in number of generations and
<italic>N
<sub>e</sub></italic> is the effective population size, we have:
<disp-formula id="e16"><mml:math id="math39"><mml:mrow><mml:mi>B</mml:mi><mml:mo> </mml:mo><mml:mi>∝</mml:mi><mml:mo> </mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>/</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mi>e</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mi>W</mml:mi><mml:mspace width="2.5em"/><mml:mo stretchy="false">(</mml:mo><mml:mn>16</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></disp-formula>
</p>
      <p>If we express all these matrices in terms of the eigenvectors of
<italic>W</italic>, so that
<italic>W</italic> is diagonal, we can write
<italic>B</italic> as the variance of the scores of the means on these eigenvectors. The relationship between
<italic>B</italic> and
<italic>W</italic> can be expressed as a log regression, where
<italic>B
<sub>i</sub></italic> is the variance between groups in the projected means and
<inline-formula><mml:math id="math40"><mml:mrow><mml:msubsup><mml:mi>λ</mml:mi><mml:mi>i</mml:mi><mml:mi>W</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula> are the eigenvalues of
<italic>W</italic>:
<disp-formula id="e17"><mml:math id="math41"><mml:mrow><mml:mo mathvariant="italic">log</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>B</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo mathvariant="italic">log</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>/</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mi>e</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:mo mathvariant="italic">log</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>λ</mml:mi><mml:mi>i</mml:mi><mml:mi>W</mml:mi></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mspace width="2.5em"/><mml:mo stretchy="false">(</mml:mo><mml:mn>17</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></disp-formula>
</p>
      <p>where
<italic>β</italic> is the regression coefficient. Under drift we expect
<italic>β</italic> to be one. If
<italic>β</italic> is significantly different from one, we have evidence that drift is not sufficient to explain currently observed diversification.</p>
      <p><bold>MultivDriftTest()</bold>: This drift test verifies the plausibility of drift in a multivariate context when only two populations are available, one ancestral (or reference) and one derived. Let
<italic>z</italic><sub>0</sub> represent a vector of means from
<italic>m</italic> traits in an ancestral population. After
<italic>t</italic> generations, the expected traits mean for
<italic>n</italic> populations under drift would correspond to
<italic>z</italic>
<sub>0</sub> with variance given by
<italic>B</italic> = (
<italic>t/N
<sub>e</sub></italic>)
<italic>W</italic>, where
<italic>B</italic> represents the expected between group covariance matrix,
<italic>W</italic> is the genetic covariance matrix from the ancestral (or reference) population, and
<italic>N
<sub>e</sub></italic> is the effective population size
<sup><xref rid="ref-22" ref-type="bibr">22</xref>,
<xref rid="ref-27" ref-type="bibr">27</xref>,
<xref rid="ref-28" ref-type="bibr">28</xref></sup>. So, given the ancestral population mean and
<italic>G</italic>-matrix, we can use this model to estimate the
<italic>B</italic>-matrix expected under drift. We can then use this
<italic>B</italic>-matrix as the Σ parameter in a multivariate normal distribution and sample
<italic>n</italic> populations from this distribution. Using this sample of random populations, we can assess the amount of divergence expected by drift, estimated as the norm of the difference vectors between ancestral (or reference) and simulated population means. Then, we can compare the observed amount of divergence between the ancestral and derived populations, calculated as the norm of the difference vector between them, taking into account the standard error of traits means. An observed divergence higher than the expectations under drift indicates that genetic drift is not sufficient to explain currently observed divergence, suggesting a selective scenario.</p>
      <p><bold>PCScoreCorrelation():</bold> This test of drift relies on the correlation between principal component scores of different populations. Under drift alone, we expect the mean scores of different populations in the principal components of the within-group covariance matrix to be uncorrelated
<sup><xref rid="ref-35" ref-type="bibr">35</xref></sup>. Significant correlations between the scores of the means on any two principal components is an indication of correlated directional selection
<sup><xref rid="ref-12" ref-type="bibr">12</xref></sup>.</p>
    </sec>
    <sec>
      <title>Random matrices</title>
      <p><bold>RandomMatrix():</bold> Generating realistic random covariance matrices for null hypothesis testing is a challenging task, because random matrices must adequately sample the space of biologically plausible evolutionary parameters, like integration and flexibility. Most common covariance and correlation matrix sampling schemes fail at this, producing matrices with unrealistically low levels of integration, unless the level of integration is supplied
<italic>a priori</italic> (as in
<xref rid="ref-15" ref-type="bibr">15</xref>). The function
<bold>RandomMatrix()</bold> implements the method described in
<xref rid="ref-46" ref-type="bibr">46</xref>, which provides correlation matrices with a reasonable range of evolutionary characteristics. However, the adequacy of the generated matrices in hypothesis testing has not been well established, and we recommend these random matrices be used only for informal tests requiring an arbitrary covariance or correlation matrix.</p>
    </sec>
  </sec>
  <sec>
    <title>Summary</title>
    <p>We have described a suite of functions dedicated to analyzing multivariate data sets within an evolutionary quantitative genetics framework. These functions focus on the central role that covariance and correlation matrices play in this framework; therefore, we provide functions that perform both descriptive statistics and hypothesis testing related to such matrices within an evolutionary context.</p>
    <p>We have intentionally neglected to include techniques like phylogenetic regression or more extensive linear model functionality. Our reasons for this are twofold: the difficulty in transposing these methods efficiently to multiple traits, and the many different robust packages for performing some of these analyses, such as phytools, phylolm, pgls, nlme, MCMCglmm and others.</p>
    <p>Some of the material implemented here is available in other sources or through custom implementations. We have attempted to create a single consistent source for these techniques. This is by no means an exhaustive effort, and we hope to expand it given demand from the community and further developments in the field. We hope to contribute to standardization and wide adoption of these tools, and, since we opted for an open source implementation under R, this also allows the involvement of the R community in using, debugging and complementing these tools, in an effort to contribute to an open scientific environment in which, for example, truly reproducible results are the norm rather than the exception.</p>
  </sec>
  <sec>
    <title>Software availability</title>
    <p>The most recent version of the
<bold>EvolQG</bold> package can be installed from GitHub using the package
<bold>devtools</bold>:</p>
    <p>
      <preformat>
        <styled-content style="font-size:15px;">&gt;</styled-content>
        <styled-content style="font-size:15px;font-weight:bold;">library</styled-content>
        <styled-content style="font-size:15px;">(devtools)
&gt;</styled-content>
        <styled-content style="font-size:15px;font-weight:bold;">install_</styled-content>
        <styled-content style="font-size:15px;">github ("lem-usp/evolqg")</styled-content>
      </preformat>
    </p>
    <p>A less up-to-date version is also available from CRAN:</p>
    <p>
      <preformat>
        <styled-content style="font-size:15px;">&gt;</styled-content>
        <styled-content style="font-size:15px;font-weight:bold;">install.packages</styled-content>
        <styled-content style="font-size:15px;">("evolqg")</styled-content>
      </preformat>
    </p>
    <list list-type="simple">
      <list-item>
        <label>1.</label>
        <p>Software available from:
<ext-link ext-link-type="uri" xlink:href="http://cran.r-project.org/web/packages/evolqg/">http://cran.r-project.org/web/packages/evolqg/</ext-link>
</p>
      </list-item>
      <list-item>
        <label>2.</label>
        <p>Latest source code:
<ext-link ext-link-type="uri" xlink:href="https://github.com/lem-usp/EvolQG">https://github.com/lem-usp/EvolQG</ext-link>
</p>
      </list-item>
      <list-item>
        <label>3.</label>
        <p>Archived source code as at time of publication:
<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.5281/zenodo.55121">http://dx.doi.org/10.5281/zenodo.55121</ext-link>
<sup><xref rid="ref-63" ref-type="bibr">63</xref></sup>
</p>
      </list-item>
      <list-item>
        <label>4.</label>
        <p>License: The MIT License (
<ext-link ext-link-type="uri" xlink:href="https://opensource.org/licenses/MIT">https://opensource.org/licenses/MIT</ext-link>)</p>
      </list-item>
    </list>
  </sec>
</body>
<back>
  <ack>
    <title>Acknowledgements</title>
    <p>We would like to thank Barbara Costa, Daniela Rossoni, Edgar Zanella and Fabio Machado for contributing code and revising documentation and results.</p>
  </ack>
  <ref-list>
    <ref id="ref-1">
      <label>1</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ackermann</surname><given-names>RR</given-names></name><name><surname>Cheverud</surname><given-names>JM</given-names></name></person-group>:
<article-title>Discerning evolutionary processes in patterns of tamarin (genus
<italic>Saguinus</italic>) craniofacial variation.</article-title><source><italic>Am J Phys Anthropol.</italic></source><year>2002</year>;<volume>117</volume>(<issue>3</issue>):<fpage>260</fpage>–<lpage>271</lpage>.
<pub-id pub-id-type="doi">10.1002/ajpa.10038</pub-id><?supplied-pmid 11842405?><pub-id pub-id-type="pmid">11842405</pub-id></mixed-citation>
    </ref>
    <ref id="ref-2">
      <label>2</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ackermann</surname><given-names>RR</given-names></name><name><surname>Cheverud</surname><given-names>JM</given-names></name></person-group>:
<article-title>Detecting genetic drift versus selection in human evolution.</article-title><source><italic>Proc Natl Acad Sci U S A.</italic></source><year>2004</year>;<volume>101</volume>(<issue>52</issue>):<fpage>17946</fpage>–<lpage>17951</lpage>.
<pub-id pub-id-type="doi">10.1073/pnas.0405919102</pub-id><!--<pub-id pub-id-type="pmcid">539739</pub-id>--><?supplied-pmid 15604148?><pub-id pub-id-type="pmid">15604148</pub-id></mixed-citation>
    </ref>
    <ref id="ref-3">
      <label>3</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aguirre</surname><given-names>JD</given-names></name><name><surname>Hine</surname><given-names>E</given-names></name><name><surname>McGuigan</surname><given-names>K</given-names></name><etal/></person-group>:
<article-title>Comparing G: multivariate analysis of genetic variation in multiple populations.</article-title><source><italic>Heredity (Edinb).</italic></source><year>2014</year>;<volume>112</volume>(<issue>1</issue>):<fpage>21</fpage>–<lpage>29</lpage>.
<pub-id pub-id-type="doi">10.1038/hdy.2013.12</pub-id><!--<pub-id pub-id-type="pmcid">3860158</pub-id>--><?supplied-pmid 23486079?><pub-id pub-id-type="pmid">23486079</pub-id></mixed-citation>
    </ref>
    <ref id="ref-4">
      <label>4</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname> Basser</surname><given-names>PJ</given-names></name><name><surname>Pajevic</surname><given-names>S</given-names></name></person-group>:
<article-title>Spectral decomposition of a 4th-order covariance tensor: Applications to diffusion tensor MRI.</article-title><source><italic>Signal Process.</italic></source><year>2007</year>;<volume>87</volume>(<issue>2</issue>):<fpage>220</fpage>–<lpage>236</lpage>.
<pub-id pub-id-type="doi">10.1016/j.sigpro.2006.02.050</pub-id></mixed-citation>
    </ref>
    <ref id="ref-5">
      <label>5</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bolstad</surname><given-names>GH</given-names></name><name><surname>Hansen</surname><given-names>TF</given-names></name><name><surname> Pélabon</surname><given-names>C</given-names></name><etal/></person-group>:
<article-title>Genetic constraints predict evolutionary divergence in
<italic>dalechampia</italic> blossoms.</article-title><source><italic>Philos Trans R Soc Lond B Biol Sci.</italic></source><year>2014</year>;<volume>369</volume>(<issue>1649</issue>):<fpage>20130255</fpage>.
<pub-id pub-id-type="doi">10.1098/rstb.2013.0255</pub-id><!--<pub-id pub-id-type="pmcid">4084540</pub-id>--><?supplied-pmid 25002700?><pub-id pub-id-type="pmid">25002700</pub-id></mixed-citation>
    </ref>
    <ref id="ref-6">
      <label>6</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Bookstein</surname><given-names>FL</given-names></name><name><surname>Chernoff</surname><given-names>B</given-names></name><name><surname>Elder</surname><given-names>RL</given-names></name><etal/></person-group>:
<article-title>Morphometrics in evolutionary biology: the geometry of size and shape change, with examples from fishes</article-title>.<year>1985</year><ext-link ext-link-type="uri" xlink:href="http://www.worldcat.org/title/morphometrics-in-evolutionary-biology-the-geometry-of-size-and-shape-change-with-examples-from-fishes/oclc/476849732?referer=di&amp;ht=edition">Reference Source</ext-link></mixed-citation>
    </ref>
    <ref id="ref-7">
      <label>7</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cheverud</surname><given-names>JM</given-names></name></person-group>:
<article-title>Phenotypic, Genetic, and Environmental Morphological Integration in the Cranium.</article-title><source><italic>Evolution.</italic></source><year>1982</year>;<volume>36</volume>(<issue>3</issue>):<fpage>499</fpage>–<lpage>516</lpage>.
<pub-id pub-id-type="doi">10.2307/2408096</pub-id><pub-id pub-id-type="pmid">28568050</pub-id></mixed-citation>
    </ref>
    <ref id="ref-8">
      <label>8</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cheverud</surname><given-names>JM</given-names></name></person-group>:
<article-title>A Comparison of Genetic and Phenotypic Correlations.</article-title><source><italic>Evolution.</italic></source><year>1988</year>;<volume>42</volume>(<issue>5</issue>):<fpage>958</fpage>–<lpage>968</lpage>.
<pub-id pub-id-type="doi">10.2307/2408911</pub-id><pub-id pub-id-type="pmid">28581166</pub-id></mixed-citation>
    </ref>
    <ref id="ref-9">
      <label>9</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cheverud</surname><given-names>JM</given-names></name></person-group>:
<article-title>Developmental Integration and the Evolution of Pleiotropy.</article-title><source><italic>Integr Comp Biol.</italic></source><year>1996</year>;<volume>36</volume>(<issue>1</issue>):<fpage>44</fpage>–<lpage>50</lpage>.
<pub-id pub-id-type="doi">10.1093/icb/36.1.44</pub-id></mixed-citation>
    </ref>
    <ref id="ref-10">
      <label>10</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Csardi</surname><given-names>G</given-names></name><name><surname>Nepusz</surname><given-names>T</given-names></name></person-group>:
<article-title>The igraph software package for complex network research.</article-title><source><italic>Inter Journal.</italic></source>Complex Systems:1695,<year>2006</year><ext-link ext-link-type="uri" xlink:href="http://www.necsi.edu/events/iccs6/papers/c1602a3c126ba822d0bc4293371c.pdf">Reference Source</ext-link></mixed-citation>
    </ref>
    <ref id="ref-11">
      <label>11</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Falconer</surname><given-names>DS</given-names></name><name><surname>Mackay</surname><given-names>TF</given-names></name></person-group>:
<article-title>Introduction to Quantitative Genetics</article-title>. Benjamin Cummings, London, 4th edition,<year>1996</year><ext-link ext-link-type="uri" xlink:href="http://www.abebooks.com/9780582243026/Introduction-Quantitative-Genetics-4th-Edition-0582243025/plp">Reference Source</ext-link></mixed-citation>
    </ref>
    <ref id="ref-12">
      <label>12</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Felsenstein</surname><given-names>J</given-names></name></person-group>:
<article-title>Phylogenies And Quantitative Characters.</article-title><source><italic>Annu Rev Ecol Syst.</italic></source><year>1988</year>;<volume>19</volume>(<issue>1</issue>):<fpage>445</fpage>–<lpage>471</lpage>.
<pub-id pub-id-type="doi">10.1146/annurev.es.19.110188.002305</pub-id></mixed-citation>
    </ref>
    <ref id="ref-13">
      <label>13</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Garcia</surname><given-names>G</given-names></name><name><surname>Hingst-Zaher</surname><given-names>E</given-names></name><name><surname>Cerqueira</surname><given-names>R</given-names></name><etal/></person-group>:
<article-title>Quantitative Genetics and Modularity in Cranial and Mandibular Morphology of
<italic>Calomys expulsus</italic>.</article-title><source><italic>Evol Biol.</italic></source><year>2014</year>;<volume>41</volume>(<issue>4</issue>):<fpage>619</fpage>–<lpage>636</lpage>.
<pub-id pub-id-type="doi">10.1007/s11692-014-9293-4</pub-id></mixed-citation>
    </ref>
    <ref id="ref-14">
      <label>14</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Griswold</surname><given-names>CK</given-names></name><name><surname>Logsdon</surname><given-names>B</given-names></name><name><surname>Gomulkiewicz</surname><given-names>R</given-names></name></person-group>:
<article-title>Neutral evolution of multiple quantitative characters: a genealogical approach.</article-title><source><italic>Genetics.</italic></source><year>2007</year>;<volume>176</volume>(<issue>1</issue>):<fpage>455</fpage>–<lpage>466</lpage>.
<pub-id pub-id-type="doi">10.1534/genetics.106.069658</pub-id><!--<pub-id pub-id-type="pmcid">1893077</pub-id>--><?supplied-pmid 17339224?><pub-id pub-id-type="pmid">17339224</pub-id></mixed-citation>
    </ref>
    <ref id="ref-15">
      <label>15</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Haber</surname><given-names>A</given-names></name></person-group>:
<article-title>A Comparative Analysis of Integration Indices.</article-title><source><italic>Evol Biol.</italic></source><year>2011</year>;<volume>38</volume>(<issue>4</issue>):<fpage>476</fpage>–<lpage>488</lpage>.
<pub-id pub-id-type="doi">10.1007/s11692-011-9137-4</pub-id></mixed-citation>
    </ref>
    <ref id="ref-16">
      <label>16</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Haber</surname><given-names>A</given-names></name></person-group>:
<article-title>The Evolution of Morphological Integration in the Ruminant Skull.</article-title><source><italic>Evol Biol.</italic></source><year>2015</year>;<volume>42</volume>(<issue>1</issue>):<fpage>99</fpage>–<lpage>114</lpage>.
<pub-id pub-id-type="doi">10.1007/s11692-014-9302-7</pub-id></mixed-citation>
    </ref>
    <ref id="ref-17">
      <label>17</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hadfield</surname><given-names>JD</given-names></name></person-group>:
<article-title>MCMC methods for multi-response generalized linear mixed models: the MCMCglmm R package.</article-title><source><italic>J Stat Softw.</italic></source><year>2010</year>;<volume>33</volume>(<issue>2</issue>):<fpage>1</fpage>–<lpage>22</lpage>.
<pub-id pub-id-type="doi">10.18637/jss.v033.i02</pub-id><pub-id pub-id-type="pmid">20808728</pub-id></mixed-citation>
    </ref>
    <ref id="ref-18">
      <label>18</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hallgrímsson</surname><given-names>B</given-names></name><name><surname>Jamniczky</surname><given-names>H</given-names></name><name><surname>Young</surname><given-names>NM</given-names></name><etal/></person-group>:
<article-title>Deciphering the Palimpsest: Studying the Relationship Between Morphological Integration and Phenotypic Covariation.</article-title><source><italic>Evol Biol.</italic></source><year>2009</year>;<volume>36</volume>(<issue>4</issue>):<fpage>355</fpage>–<lpage>376</lpage>.
<pub-id pub-id-type="doi">10.1007/s11692-009-9076-5</pub-id><!--<pub-id pub-id-type="pmcid">3537827</pub-id>--><?supplied-pmid 23293400?><pub-id pub-id-type="pmid">23293400</pub-id></mixed-citation>
    </ref>
    <ref id="ref-19">
      <label>19</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hansen</surname><given-names>TF</given-names></name><name><surname>Houle</surname><given-names>D</given-names></name></person-group>:
<article-title>Measuring and comparing evolvability and constraint in multivariate characters.</article-title><source><italic>J Evol Biol.</italic></source><year>2008</year>;<volume>21</volume>(<issue>5</issue>):<fpage>1201</fpage>–<lpage>1219</lpage>.
<pub-id pub-id-type="doi">10.1111/j.1420-9101.2008.01573.x</pub-id><?supplied-pmid 18662244?><pub-id pub-id-type="pmid">18662244</pub-id></mixed-citation>
    </ref>
    <ref id="ref-20">
      <label>20</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hill</surname><given-names>WG</given-names></name><name><surname>Thompson</surname><given-names>R</given-names></name></person-group>:
<article-title>Probabilities of Non-Positive Definite between-Group or Genetic Covariance Matrices.</article-title><source><italic>Biometrics.</italic></source><year>1978</year>;<volume>34</volume>(<issue>3</issue>):<fpage>429</fpage>–<lpage>439</lpage>.
<pub-id pub-id-type="doi">10.2307/2530605</pub-id></mixed-citation>
    </ref>
    <ref id="ref-21">
      <label>21</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hine</surname><given-names>E</given-names></name><name><surname>Chenoweth</surname><given-names>SF</given-names></name><name><surname>Rundle</surname><given-names>HD</given-names></name><etal/></person-group>:
<article-title>Characterizing the evolution of genetic variance using genetic covariance tensors.</article-title><source><italic>Philos Trans R Soc Lond B Biol Sci.</italic></source><year>2009</year>;<volume>364</volume>(<issue>1523</issue>):<fpage>1567</fpage>–<lpage>78</lpage>.
<pub-id pub-id-type="doi">10.1098/rstb.2008.0313</pub-id><!--<pub-id pub-id-type="pmcid">2691006</pub-id>--><?supplied-pmid 19414471?><pub-id pub-id-type="pmid">19414471</pub-id></mixed-citation>
    </ref>
    <ref id="ref-22">
      <label>22</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hohenlohe</surname><given-names>PA</given-names></name><name><surname>Arnold</surname><given-names>SJ</given-names></name></person-group>:
<article-title>MIPoD: a hypothesis-testing framework for microevolutionary inference from patterns of divergence.</article-title><source><italic>Am Nat.</italic></source><year>2008</year>;<volume>171</volume>(<issue>3</issue>):<fpage>366</fpage>–<lpage>385</lpage>.
<pub-id pub-id-type="doi">10.1086/527498</pub-id><!--<pub-id pub-id-type="pmcid">2432089</pub-id>--><?supplied-pmid 18194086?><pub-id pub-id-type="pmid">18194086</pub-id></mixed-citation>
    </ref>
    <ref id="ref-23">
      <label>23</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Houle</surname><given-names>D</given-names></name><name><surname>Meyer</surname><given-names>K</given-names></name></person-group>:
<article-title>Estimating sampling error of evolutionary statistics based on genetic covariance matrices using maximum likelihood.</article-title><source><italic>J Evol Biol.</italic></source><year>2015</year>;<volume>28</volume>(<issue>8</issue>):<fpage>1542</fpage>–<lpage>9</lpage>.
<pub-id pub-id-type="doi">10.1111/jeb.12674</pub-id><?supplied-pmid 26079756?><pub-id pub-id-type="pmid">26079756</pub-id></mixed-citation>
    </ref>
    <ref id="ref-24">
      <label>24</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jones</surname><given-names>AG</given-names></name><name><surname>Arnold</surname><given-names>SJ</given-names></name><name><surname>Bürger</surname><given-names>R</given-names></name></person-group>:
<article-title>Evolution and stability of the G-matrix on a landscape with a moving optimum.</article-title><source><italic>Evolution.</italic></source><year>2004</year>;<volume>58</volume>(<issue>8</issue>):<fpage>1639</fpage>–<lpage>1654</lpage>.
<pub-id pub-id-type="doi">10.1111/j.0014-3820.2004.tb00450.x</pub-id><?supplied-pmid 15446419?><pub-id pub-id-type="pmid">15446419</pub-id></mixed-citation>
    </ref>
    <ref id="ref-25">
      <label>25</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jungers</surname><given-names>WL</given-names></name><name><surname>Falsetti</surname><given-names>AB</given-names></name><name><surname>Wall</surname><given-names>CE</given-names></name></person-group>:
<article-title>Shape, relative size, and size-adjustments in morphometrics.</article-title><source><italic>Am J Phys Anthropol.</italic></source><year>1995</year>;<volume>38</volume>(<issue>S21</issue>):<fpage>137</fpage>–<lpage>161</lpage>.
<pub-id pub-id-type="doi">10.1002/ajpa.1330380608</pub-id></mixed-citation>
    </ref>
    <ref id="ref-26">
      <label>26</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Krzanowski</surname><given-names>WJ</given-names></name></person-group>:
<article-title>Between-Groups Comparison of Principal Components.</article-title><source><italic>J Am Stat Assoc.</italic></source><year>1979</year>;<volume>74</volume>(<issue>367</issue>):<fpage>703</fpage>–<lpage>707</lpage>.
<pub-id pub-id-type="doi">10.2307/2286995</pub-id></mixed-citation>
    </ref>
    <ref id="ref-27">
      <label>27</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lande</surname><given-names>R</given-names></name></person-group>:
<article-title>Natural Selection and Random Genetic Drift in Phenotypic Evolution.</article-title><source><italic>Evolution.</italic></source><year>1976</year>;<volume>30</volume>(<issue>2</issue>):<fpage>314</fpage>–<lpage>334</lpage>.
<pub-id pub-id-type="doi">10.2307/2407703</pub-id><pub-id pub-id-type="pmid">28563044</pub-id></mixed-citation>
    </ref>
    <ref id="ref-28">
      <label>28</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lande</surname><given-names>R</given-names></name></person-group>:
<article-title>Quantitative Genetic Analysis of Multivariate Evolution, Applied to Brain: Body Size Allometry.</article-title><source><italic>Evolution.</italic></source><year>1979</year>;<volume>33</volume>(<issue>1</issue>):<fpage>402</fpage>–<lpage>416</lpage>.
<pub-id pub-id-type="doi">10.2307/2407630</pub-id><pub-id pub-id-type="pmid">28568194</pub-id></mixed-citation>
    </ref>
    <ref id="ref-29">
      <label>29</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ledoit</surname><given-names>O</given-names></name><name><surname>Wolf</surname><given-names>M</given-names></name></person-group>:
<article-title>A well-conditioned estimator for large-dimensional covariance matrices.</article-title><source><italic>J Multivar Anal.</italic></source><year>2004</year>;<volume>88</volume>(<issue>2</issue>):<fpage>365</fpage>–<lpage>411</lpage>.
<pub-id pub-id-type="doi">10.1016/S0047-259X(03)00096-4</pub-id></mixed-citation>
    </ref>
    <ref id="ref-30">
      <label>30</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lessells</surname><given-names>CM</given-names></name><name><surname>Boag</surname><given-names>PT</given-names></name></person-group>:
<article-title>Unrepeatable repeatabilities: a common mistake.</article-title><source><italic>Auk.</italic></source><year>1987</year>;<volume>104</volume>(<issue>1</issue>):<fpage>116</fpage>–<lpage>121</lpage>.
<pub-id pub-id-type="doi">10.2307/4087240</pub-id></mixed-citation>
    </ref>
    <ref id="ref-31">
      <label>31</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lofsvold</surname><given-names>D</given-names></name></person-group>:
<article-title>Quantitative Genetics of Morphological Differentiation in Peromyscus. I. Tests of the Homogeneity of Genetic Covariance Structure Among Species and Subspecies.</article-title><source><italic>Evolution.</italic></source><year>1986</year>;<volume>40</volume>(<issue>3</issue>):<fpage>559</fpage>–<lpage>573</lpage>.
<pub-id pub-id-type="doi">10.2307/2408577</pub-id><pub-id pub-id-type="pmid">28556319</pub-id></mixed-citation>
    </ref>
    <ref id="ref-32">
      <label>32</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Lynch</surname><given-names>M</given-names></name><name><surname>Walsh</surname><given-names>B</given-names></name></person-group>:
<article-title>Genetics and analysis of quantitative traits</article-title>. Sinauer, Sunderland, MA.,<year>1998</year><ext-link ext-link-type="uri" xlink:href="http://www.sinauer.com/genetics-and-analysis-of-quantitative-traits.html">Reference Source</ext-link></mixed-citation>
    </ref>
    <ref id="ref-33">
      <label>33</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Marroig</surname><given-names>G</given-names></name><name><surname>Cheverud</surname><given-names>J</given-names></name></person-group>:
<article-title>Size as a line of least resistance II: Direct selection on size or correlated response due to constraints.</article-title><source><italic>Evolution.</italic></source><year>2010</year>;<volume>64</volume>(<issue>5</issue>):<fpage>1470</fpage>–<lpage>1488</lpage>.
<pub-id pub-id-type="doi">10.1111/j.1558-5646.2009.00920.x</pub-id><?supplied-pmid 20015239?><pub-id pub-id-type="pmid">20015239</pub-id></mixed-citation>
    </ref>
    <ref id="ref-34">
      <label>34</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Marroig</surname><given-names>G</given-names></name><name><surname>Cheverud</surname><given-names>JM</given-names></name></person-group>:
<article-title>A comparison of phenotypic variation and covariation patterns and the role of phylogeny, ecology, and ontogeny during cranial evolution of new world monkeys.</article-title><source><italic>Evolution.</italic></source><year>2001</year>;<volume>55</volume>(<issue>12</issue>):<fpage>2576</fpage>–<lpage>2600</lpage>.
<pub-id pub-id-type="doi">10.1111/j.0014-3820.2001.tb00770.x</pub-id><?supplied-pmid 11831671?><pub-id pub-id-type="pmid">11831671</pub-id></mixed-citation>
    </ref>
    <ref id="ref-35">
      <label>35</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Marroig</surname><given-names>G</given-names></name><name><surname>Cheverud</surname><given-names>JM</given-names></name></person-group>:
<article-title>Did natural selection or genetic drift produce the cranial diversification of neotropical monkeys?</article-title><source><italic>Am Nat.</italic></source><year>2004</year>;<volume>163</volume>(<issue>3</issue>):<fpage>417</fpage>–<lpage>428</lpage>.
<pub-id pub-id-type="doi">10.1086/381693</pub-id><?supplied-pmid 15026977?><pub-id pub-id-type="pmid">15026977</pub-id></mixed-citation>
    </ref>
    <ref id="ref-36">
      <label>36</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Marroig</surname><given-names>G</given-names></name><name><surname>Melo</surname><given-names>D</given-names></name><name><surname>Porto</surname><given-names>A</given-names></name><etal/></person-group>:
<article-title>Selection Response Decomposition (SRD): A New Tool for Dissecting Differences and Similarities Between Matrices.</article-title><source><italic>Evol Biol.</italic></source><year>2011</year>;<volume>38</volume>(<issue>2</issue>):<fpage>225</fpage>–<lpage>241</lpage>.
<pub-id pub-id-type="doi">10.1007/s11692-010-9107-2</pub-id></mixed-citation>
    </ref>
    <ref id="ref-37">
      <label>37</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Marroig</surname><given-names>G</given-names></name><name><surname>Melo</surname><given-names>DA</given-names></name><name><surname>Garcia</surname><given-names>G</given-names></name></person-group>:
<article-title>Modularity, noise, and natural selection.</article-title><source><italic>Evolution.</italic></source><year>2012</year>;<volume>66</volume>(<issue>5</issue>):<fpage>1506</fpage>–<lpage>1524</lpage>.
<pub-id pub-id-type="doi">10.1111/j.1558-5646.2011.01555.x</pub-id><?supplied-pmid 22519787?><pub-id pub-id-type="pmid">22519787</pub-id></mixed-citation>
    </ref>
    <ref id="ref-38">
      <label>38</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Marroig</surname><given-names>G</given-names></name><name><surname>Shirai</surname><given-names>LT</given-names></name><name><surname>Porto</surname><given-names>A</given-names></name><etal/></person-group>:
<article-title>The Evolution of Modularity in the Mammalian Skull II: Evolutionary Consequences.</article-title><source><italic>Evol Biol.</italic></source><year>2009</year>;<volume>36</volume>(<issue>1</issue>):<fpage>136</fpage>–<lpage>148</lpage>.
<pub-id pub-id-type="doi">10.1007/s11692-009-9051-1</pub-id></mixed-citation>
    </ref>
    <ref id="ref-39">
      <label>39</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Melo</surname><given-names>D</given-names></name><name><surname>Marroig</surname><given-names>G</given-names></name></person-group>:
<article-title>Directional selection can drive the evolution of modularity in complex traits.</article-title><source><italic>Proc Natl Acad Sci U S A.</italic></source><year>2015</year>;<volume>112</volume>(<issue>2</issue>):<fpage>470</fpage>–<lpage>475</lpage>.
<pub-id pub-id-type="doi">10.1073/pnas.1322632112</pub-id><!--<pub-id pub-id-type="pmcid">4299217</pub-id>--><?supplied-pmid 25548154?><pub-id pub-id-type="pmid">25548154</pub-id></mixed-citation>
    </ref>
    <ref id="ref-40">
      <label>40</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meyer</surname><given-names>K</given-names></name></person-group>:
<article-title>WOMBAT: a tool for mixed model analyses in quantitative genetics by restricted maximum likelihood (REML).</article-title><source><italic>J Zhejiang Univ Sci B.</italic></source><year>2007</year>;<volume>8</volume>(<issue>11</issue>):<fpage>815</fpage>–<lpage>821</lpage>.
<pub-id pub-id-type="doi">10.1631/jzus.2007.B0815</pub-id><!--<pub-id pub-id-type="pmcid">2064953</pub-id>--><?supplied-pmid 17973343?><pub-id pub-id-type="pmid">17973343</pub-id></mixed-citation>
    </ref>
    <ref id="ref-41">
      <label>41</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meyer</surname><given-names>K</given-names></name><name><surname>Kirkpatrick</surname><given-names>M</given-names></name></person-group>:
<article-title>Perils of parsimony: properties of reduced-rank estimates of genetic covariance matrices.</article-title><source><italic>Genetics.</italic></source><year>2008</year>;<volume>180</volume>(<issue>2</issue>):<fpage>1153</fpage>–<lpage>66</lpage>.
<pub-id pub-id-type="doi">10.1534/genetics.108.090159</pub-id><!--<pub-id pub-id-type="pmcid">2567364</pub-id>--><?supplied-pmid 18757923?><pub-id pub-id-type="pmid">18757923</pub-id></mixed-citation>
    </ref>
    <ref id="ref-42">
      <label>42</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mitteroecker</surname><given-names>P</given-names></name><name><surname>Bookstein</surname><given-names>F</given-names></name></person-group>:
<article-title>The ontogenetic trajectory of the phenotypic covariance matrix, with examples from craniofacial shape in rats and humans.</article-title><source><italic>Evolution.</italic></source><year>2009</year>;<volume>63</volume>(<issue>3</issue>):<fpage>727</fpage>–<lpage>737</lpage>.
<pub-id pub-id-type="doi">10.1111/j.1558-5646.2008.00587.x</pub-id><?supplied-pmid 19087182?><pub-id pub-id-type="pmid">19087182</pub-id></mixed-citation>
    </ref>
    <ref id="ref-43">
      <label>43</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moakher</surname><given-names>M</given-names></name></person-group>:
<article-title>On the Averaging of Symmetric Positive-Definite Tensors.</article-title><source><italic>J Elast.</italic></source><year>2006</year>;<volume>82</volume>(<issue>3</issue>):<fpage>273</fpage>–<lpage>296</lpage>.
<pub-id pub-id-type="doi">10.1007/s10659-005-9035-z</pub-id></mixed-citation>
    </ref>
    <ref id="ref-44">
      <label>44</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Murphy</surname><given-names>KP</given-names></name></person-group>:
<article-title>Machine learning: a probabilistic perspective</article-title>. MIT press,<year>2012</year><ext-link ext-link-type="uri" xlink:href="http://www.cs.ubc.ca/~murphyk/MLbook/pml-toc-1may12.pdf">Reference Source</ext-link></mixed-citation>
    </ref>
    <ref id="ref-45">
      <label>45</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Newman</surname><given-names>ME</given-names></name></person-group>:
<article-title>Modularity and community structure in networks.</article-title><source><italic>Proc Natl Acad Sci U S A.</italic></source><year>2006</year>;<volume>103</volume>(<issue>23</issue>):<fpage>8577</fpage>–<lpage>8582</lpage>.
<pub-id pub-id-type="doi">10.1073/pnas.0601602103</pub-id><!--<pub-id pub-id-type="pmcid">1482622</pub-id>--><?supplied-pmid 16723398?><pub-id pub-id-type="pmid">16723398</pub-id></mixed-citation>
    </ref>
    <ref id="ref-46">
      <label>46</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Numpacharoen</surname><given-names>K</given-names></name><name><surname>Atsawarungruangkit</surname><given-names>A</given-names></name></person-group>:
<article-title>Generating correlation matrices based on the boundaries of their coefficients.</article-title><source><italic>PLoS One.</italic></source><year>2012</year>;<volume>7</volume>(<issue>11</issue>):<fpage>e48902</fpage>.
<pub-id pub-id-type="doi">10.1371/journal.pone.0048902</pub-id><!--<pub-id pub-id-type="pmcid">3495965</pub-id>--><?supplied-pmid 23152816?><pub-id pub-id-type="pmid">23152816</pub-id></mixed-citation>
    </ref>
    <ref id="ref-47">
      <label>47</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Olson</surname><given-names>R</given-names></name><name><surname>Miller</surname><given-names>E</given-names></name></person-group>:
<article-title>Morphological integration</article-title>. University of Chicago Press, Chicago,<year>1958</year><ext-link ext-link-type="uri" xlink:href="http://press.uchicago.edu/ucp/books/book/chicago/M/bo3620375.html">Reference Source</ext-link></mixed-citation>
    </ref>
    <ref id="ref-48">
      <label>48</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ovaskainen</surname><given-names>O</given-names></name><name><surname>Cano</surname><given-names>JM</given-names></name><name><surname>Merilä</surname><given-names>J</given-names></name></person-group>:
<article-title>A Bayesian framework for comparative quantitative genetics.</article-title><source><italic>Proc Biol Sci.</italic></source><year>2008</year>;<volume>275</volume>(<issue>1635</issue>):<fpage>669</fpage>–<lpage>678</lpage>.
<pub-id pub-id-type="doi">10.1098/rspb.2007.0949</pub-id><!--<pub-id pub-id-type="pmcid">2596838</pub-id>--><?supplied-pmid 18211881?><pub-id pub-id-type="pmid">18211881</pub-id></mixed-citation>
    </ref>
    <ref id="ref-49">
      <label>49</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pavlicev</surname><given-names>M</given-names></name><name><surname>Cheverud</surname><given-names>JM</given-names></name><name><surname>Wagner</surname><given-names>GP</given-names></name></person-group>:
<article-title>Measuring Morphological Integration Using Eigenvalue Variance.</article-title><source><italic>Evol Biol.</italic></source><year>2009</year>;<volume>36</volume>(<issue>1</issue>):<fpage>157</fpage>–<lpage>170</lpage>.
<pub-id pub-id-type="doi">10.1007/s11692-008-9042-7</pub-id></mixed-citation>
    </ref>
    <ref id="ref-50">
      <label>50</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Porto</surname><given-names>A</given-names></name><name><surname>de Oliveira</surname><given-names>FB</given-names></name><name><surname>Shirai</surname><given-names>LT</given-names></name><etal/></person-group>:
<article-title>The Evolution of Modularity in the Mammalian Skull I: Morphological Integration Patterns and Magnitudes.</article-title><source><italic>Evol Biol.</italic></source><year>2009</year>;<volume>36</volume>(<issue>1</issue>):<fpage>118</fpage>–<lpage>135</lpage>.
<pub-id pub-id-type="doi">10.1007/s11692-008-9038-3</pub-id></mixed-citation>
    </ref>
    <ref id="ref-51">
      <label>51</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Porto</surname><given-names>A</given-names></name><name><surname>Shirai</surname><given-names>LT</given-names></name><name><surname>de Oliveira</surname><given-names>FB</given-names></name><etal/></person-group>:
<article-title>Size variation, growth strategies, and the evolution of modularity in the mammalian skull.</article-title><source><italic>Evolution.</italic></source><year>2013</year>;<volume>67</volume>(<issue>11</issue>):<fpage>3305</fpage>–<lpage>3322</lpage>.
<pub-id pub-id-type="doi">10.1111/evo.12177</pub-id><?supplied-pmid 24152009?><pub-id pub-id-type="pmid">24152009</pub-id></mixed-citation>
    </ref>
    <ref id="ref-52">
      <label>52</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Prôa</surname><given-names>M</given-names></name><name><surname>O’Higgins</surname><given-names>P</given-names></name><name><surname>Monteiro</surname><given-names>LR</given-names></name></person-group>:
<article-title>Type I error rates for testing genetic drift with phenotypic covariance matrices: a simulation study.</article-title><source><italic>Evolution.</italic></source><year>2013</year>;<volume>67</volume>(<issue>1</issue>):<fpage>185</fpage>–<lpage>195</lpage>.
<pub-id pub-id-type="doi">10.1111/j.1558-5646.2012.01746.x</pub-id><?supplied-pmid 23289571?><pub-id pub-id-type="pmid">23289571</pub-id></mixed-citation>
    </ref>
    <ref id="ref-53">
      <label>53</label>
      <mixed-citation publication-type="book"><collab>R Core Team</collab>:
<article-title>R: A Language and Environment for Statistical Computing</article-title>. R Foundation for Statistical Computing, Vienna, Austria,<year>2014</year><ext-link ext-link-type="uri" xlink:href="http://www.R-project.org/">Reference Source</ext-link></mixed-citation>
    </ref>
    <ref id="ref-54">
      <label>54</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Revell</surname><given-names>LJ</given-names></name></person-group>:
<article-title>phytools: An R package for phylogenetic comparative biology (and other things).</article-title><source><italic>Methods Ecol Evol.</italic></source><year>2012</year>;<volume>3</volume>(<issue>2</issue>):<fpage>217</fpage>–<lpage>223</lpage>.
<pub-id pub-id-type="doi">10.1111/j.2041-210X.2011.00169.x</pub-id></mixed-citation>
    </ref>
    <ref id="ref-55">
      <label>55</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Roff</surname><given-names>D</given-names></name></person-group>:
<article-title>Evolutionary quantitative genetics: Are we in danger of throwing out the baby with the bathwater?</article-title><source><italic>Ann Zool Fennici.</italic></source><year>2003</year>;<volume>40</volume>(<issue>4</issue>):<fpage>315</fpage>–<lpage>320</lpage>.
<ext-link ext-link-type="uri" xlink:href="http://www.sekj.org/PDF/anzf40/anzf40-315.pdf">Reference Source</ext-link></mixed-citation>
    </ref>
    <ref id="ref-56">
      <label>56</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Roff</surname><given-names>DA</given-names></name></person-group>:
<article-title>The estimation of genetic correlations from phenotypic correlations: a test of Cheverud’s conjecture.</article-title><source><italic>Heredity.</italic></source><year>1995</year>;<volume>74</volume>(<issue>5</issue>):<fpage>481</fpage>–<lpage>490</lpage>.
<pub-id pub-id-type="doi">10.1038/hdy.1995.68</pub-id></mixed-citation>
    </ref>
    <ref id="ref-57">
      <label>57</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Runcie</surname><given-names>DE</given-names></name><name><surname>Mukherjee</surname><given-names>S</given-names></name></person-group>:
<article-title>Dissecting high-dimensional phenotypes with Bayesian sparse factor analysis of genetic covariance matrices.</article-title><source><italic>Genetics.</italic></source><year>2013</year>;<volume>194</volume>(<issue>3</issue>):<fpage>753</fpage>–<lpage>767</lpage>.
<pub-id pub-id-type="doi">10.1534/genetics.113.151217</pub-id><!--<pub-id pub-id-type="pmcid">3697978</pub-id>--><?supplied-pmid 23636737?><pub-id pub-id-type="pmid">23636737</pub-id></mixed-citation>
    </ref>
    <ref id="ref-58">
      <label>58</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schluter</surname><given-names>D</given-names></name></person-group>:
<article-title>Adaptive Radiation Along Genetic Lines of Least Resistance.</article-title><source><italic>Evolution.</italic></source><year>1996</year>;<volume>50</volume>(<issue>5</issue>):<fpage>1766</fpage>–<lpage>1774</lpage>.
<pub-id pub-id-type="doi">10.2307/2410734</pub-id><pub-id pub-id-type="pmid">28565589</pub-id></mixed-citation>
    </ref>
    <ref id="ref-59">
      <label>59</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schäfer</surname><given-names>J</given-names></name><name><surname>Strimmer</surname><given-names>K</given-names></name></person-group>:
<article-title>A shrinkage approach to large-scale covariance matrix estimation and implications for functional genomics.</article-title><source><italic>Stat Appl Genet Mol Biol.</italic></source><year>2005</year>;<volume>4</volume>: Article32.
<pub-id pub-id-type="doi">10.2202/1544-6115.1175</pub-id><?supplied-pmid 16646851?><pub-id pub-id-type="pmid">16646851</pub-id></mixed-citation>
    </ref>
    <ref id="ref-60">
      <label>60</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Steppan</surname><given-names>SJ</given-names></name><name><surname>Phillips</surname><given-names>PC</given-names></name><name><surname>Houle</surname><given-names>D</given-names></name></person-group>:
<article-title>Comparative quantitative genetics: evolution of the G matrix.</article-title><source><italic>Trends Ecol Evol.</italic></source><year>2002</year>;<volume>17</volume>(<issue>7</issue>):<fpage>320</fpage>–<lpage>327</lpage>.
<pub-id pub-id-type="doi">10.1016/S0169-5347(02)02505-3</pub-id></mixed-citation>
    </ref>
    <ref id="ref-61">
      <label>61</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wagner</surname><given-names>GP</given-names></name><name><surname>Pavlicev</surname><given-names>M</given-names></name><name><surname>Cheverud</surname><given-names>JM</given-names></name></person-group>:
<article-title>The road to modularity.</article-title><source><italic>Nat Rev Genet.</italic></source><year>2007</year>;<volume>8</volume>(<issue>12</issue>):<fpage>921</fpage>–<lpage>931</lpage>.
<pub-id pub-id-type="doi">10.1038/nrg2267</pub-id><?supplied-pmid 18007649?><pub-id pub-id-type="pmid">18007649</pub-id></mixed-citation>
    </ref>
    <ref id="ref-62">
      <label>62</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Yang</surname><given-names>K</given-names></name><name><surname>Shahabi</surname><given-names>C</given-names></name></person-group>:
<article-title>A PCA-based similarity measure for multivariate time series</article-title>. In
<italic>Proceedings of the 2nd ACM international workshop on Multimedia databases</italic> ACM,<year>2004</year>;<fpage>65</fpage>–<lpage>74</lpage>.
<pub-id pub-id-type="doi">10.1145/1032604.1032616</pub-id>
</mixed-citation>
    </ref>
    <ref id="ref-63">
      <label>63</label>
      <mixed-citation publication-type="data"><person-group person-group-type="author"><name><surname>Melo</surname><given-names>D</given-names></name><name><surname>Alvarenga</surname><given-names>EZ</given-names></name><name><surname>Hubbe</surname><given-names>A</given-names></name><etal/></person-group>:
<article-title>EvolQG: F1000Research v2.0.</article-title><source><italic>Zenodo.</italic></source><year>2016</year><ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.5281/zenodo.55121">Data Source</ext-link></mixed-citation>
    </ref>
  </ref-list>
</back>
<sub-article id="report16219" article-type="peer-review">
  <front-stub>
    <article-id pub-id-type="doi">10.5256/f1000research.9735.r16219</article-id>
    <title-group>
      <article-title>Referee response for version 2</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Roseman</surname>
          <given-names>Charles</given-names>
        </name>
        <xref ref-type="aff" rid="r16219a1">1</xref>
        <role>Referee</role>
      </contrib>
      <aff id="r16219a1"><label>1</label>Department of Anthropology, University of Illinois at Urbana-Champaign, Urbana, IL, USA</aff>
    </contrib-group>
    <author-notes>
      <fn fn-type="COI-statement">
        <p><bold>Competing interests: </bold>No competing interests were disclosed.</p>
      </fn>
    </author-notes>
    <pub-date pub-type="epub">
      <day>12</day>
      <month>9</month>
      <year>2016</year>
    </pub-date>
    <related-article id="d35e6730" related-article-type="peer-reviewed-article" ext-link-type="doi" xlink:href="10.12688/f1000research.7082.2">Version 2</related-article>
    <custom-meta-group>
      <custom-meta>
        <meta-name>recommendation</meta-name>
        <meta-value>approve-with-reservations</meta-value>
      </custom-meta>
    </custom-meta-group>
  </front-stub>
  <body>
    <p>Thank you for the opportunity to review the article “EvolQG - An R package for evolutionary quantitative genetics.” I am reviewing the version of 27 June 2016 (V.2). My overall impression of the paper and the associated package, which I have gone through in some detail, is that it makes a useful contribution to the study of the evolution of complex traits. Having many of these techniques available in an easily useable form will be a a boon to many researchers. I have some reservations that echo those of reviewers of previous and current versions of this manuscript.</p>
    <p> I think that a useful revision to the paper might be to clearly distinguish between applications and treatments of the P and G matrices. For morphological characteristics, I concur that there are good reasons to believe that P and G will be roughly proportional to one another (there are issues with what that might mean for evolutionary analyses), but handling errors in either case are rather different. The BootStrapRep() and MonteCarloRep() functions will work as described for a phenotypic correlation matrix, but not for a genetic correlation matrix, which would require some kind of resampling or simulation procedure that considered relatedness among individuals. This is not easy even in simple circumstances like those found in experimental studies (full-sib designs and the like) and very taxing in the kinds of pedigree based studies of wild organisms that are becoming the norm in the field.</p>
    <p>  A work-around that I would accept only for analysis of legacy results from the literature would be to include a way to include effective sample sizes (Cheverud 1996, 1988). This would give an estimate of the number of effectively independently estimated breeding values worth of information in a sample and would be a better reflection of the errors in the genetic quantities. In the absence of this, adding explicit ways of working with the posterior distributions or estimated matrix of errors from the estimate of the G matrix would be welcome in your package. At the very least, you should make the distinction between these cases clearer in the text.</p>
    <p> I think the random skewers procedure should be revisited in one respect. The Marroig and Cheverud (2007) procedure describes drawing random selection gradient values from a uniform distribution and then standardizing the resulting vector to unit length. This is meant to provide random directions in the phenotypic space. This procedure, however, does not achieve this as the distribution of random points before standardization is from a hypercube of the same dimensionality as the number of traits. This will lead to an uneven distribution of points around the hypersphere on which the unit length vectors of standardized simulated selection gradients would occupy. In effect, the extra space in the corners of the hypersphere cause patches of excess vectors. This could cause considerable mischief if, for example, the first principal component of a covariance matrix was oriented directly at  corner of the hypercube. It might be worth modifying the procedure to draw random Gaussian variables, which are then standardized to unit length following Muller (1959) and Marsaglia (1972). This would ensure truly random simulated directional selection.</p>
    <p> I would like to second Prof. Houle’s point that there are many aspects of the different techniques that do not have much to do with evolution in an explicit way. Many of the matrix comparisons don’t have much to do with the degree to which responses to evolution might differ given a difference in the matrices. We could easily extend this critique to the parts of the package linking covariation to development. Phenotypic covariance/correlation matrices underdetermine the developmental processes through which covariation is generated and without some kind of independent assessment of developmental process. LModularity() arbitrarily assumes a lot about how organisms work. Without some extra information about the perturbations to developmental process, we have no idea what the biological meaning resulting clusters of traits might be or whether they relate to development at all.</p>
    <p> That said, I do think most of the techniques contained in the package will be very useful for many people. On balance, I regard EvolQG as a welcome contribution to the toolkit available to scholars interested in the evolution of complex traits. I would like to see the issues dealing with the errors in G and P to be clarified and the correction to the sampling in the random skewers to be implemented.</p>
    <p> Some smaller comments:</p>
    <p> “The Krzanowski shared space, or Krzanowski correlation, measures the degree to which the first principal components (eigenvectors) span the same subspace”</p>
    <p> This sentence and the section in which it is nested is a little opaque. Please reword so that it is clear how many principal components we need to consider.</p>
    <p> “transposing these methods efficiently to multiple traits, and the many different robust packages for performing some of these analyses..”</p>
    <p> “Transposing” does not strike me as the right word here. Please reword.</p>
    <p>I have read this submission. I believe that I have an appropriate level of expertise to confirm that it is of an acceptable scientific standard, however I have significant reservations, as outlined above.</p>
  </body>
  <back>
    <ref-list>
      <title>References</title>
      <ref id="rep-ref-16219-1">
        <label>1</label>
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cheverud</surname><given-names>J</given-names></name></person-group>:
<article-title>A Comparison of Genetic and Phenotypic Correlations</article-title>.
<source><italic>Evolution</italic></source>.<year>1988</year>;<volume>42</volume>(<issue>5</issue>) :
<elocation-id>10.2307/2408911</elocation-id><pub-id pub-id-type="doi">10.2307/2408911</pub-id></mixed-citation>
      </ref>
      <ref id="rep-ref-16219-2">
        <label>2</label>
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cheverud</surname><given-names>J</given-names></name></person-group>:
<article-title>Quantitative genetic analysis of cranial morphology in the cotton-top (Saguinus oedipus) and saddle-back (S. fuscicollis) tamarins</article-title>.
<source><italic>Journal of Evolutionary Biology</italic></source>.<year>1996</year>;<volume>9</volume>(<issue>1</issue>) :
<elocation-id>10.1046/j.1420-9101.1996.9010005.x</elocation-id><fpage>5</fpage>-<lpage>42</lpage><pub-id pub-id-type="doi">10.1046/j.1420-9101.1996.9010005.x</pub-id></mixed-citation>
      </ref>
      <ref id="rep-ref-16219-3">
        <label>3</label>
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Marsaglia</surname><given-names>G</given-names></name></person-group>:
<article-title>Choosing a Point from the Surface of a Sphere</article-title>.
<source><italic>The Annals of Mathematical Statistics</italic></source>.<year>1972</year>;<volume>43</volume>(<issue>2</issue>) :
<elocation-id>10.1214/aoms/1177692644</elocation-id><fpage>645</fpage>-<lpage>646</lpage><pub-id pub-id-type="doi">10.1214/aoms/1177692644</pub-id></mixed-citation>
      </ref>
      <ref id="rep-ref-16219-4">
        <label>4</label>
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Muller</surname><given-names>M</given-names></name></person-group>:
<article-title>A note on a method for generating points uniformly on n-dimensional spheres</article-title>.
<source><italic>Communications of the ACM</italic></source>.<year>1959</year>;<volume>2</volume>(<issue>4</issue>) :
<elocation-id>10.1145/377939.377946</elocation-id><fpage>19</fpage>-<lpage>20</lpage><pub-id pub-id-type="doi">10.1145/377939.377946</pub-id></mixed-citation>
      </ref>
    </ref-list>
  </back>
  <sub-article id="comment2263" article-type="response">
    <front-stub>
      <contrib-group>
        <contrib contrib-type="author">
          <name>
            <surname>Melo</surname>
            <given-names>Diogo</given-names>
          </name>
          <aff>Universidade de São Paulo, Brazil</aff>
        </contrib>
      </contrib-group>
      <author-notes>
        <fn fn-type="COI-statement">
          <p><bold>Competing interests: </bold>No competing interests were disclosed.</p>
        </fn>
      </author-notes>
      <pub-date pub-type="epub">
        <day>31</day>
        <month>10</month>
        <year>2016</year>
      </pub-date>
    </front-stub>
    <body>
      <p>Thank you for the careful review! We respond to some of the specific comments below:</p>
      <p>
        <bold>I think that a useful revision to the paper might be to clearly distinguish between applications and treatments of the P and G matrices. For morphological characteristics, I concur that there are good reasons to believe that P and G will be roughly proportional to one another (there are issues with what that might mean for evolutionary analyses), but handling errors in either case are rather different. The BootStrapRep() and MonteCarloRep() functions will work as described for a phenotypic correlation matrix, but not for a genetic correlation matrix, which would require some kind of resampling or simulation procedure that considered relatedness among individuals. This is not easy even in simple circumstances like those found in experimental studies (full-sib designs and the like) and very taxing in the kinds of pedigree based studies of wild organisms that are becoming the norm in the field.</bold>
      </p>
      <p> This is correct, and we have modified the text to make this clear.</p>
      <p>
        <bold>A work-around that I would accept only for analysis of legacy results from the literature would be to include a way to include effective sample sizes (Cheverud 1996, 1988). This would give an estimate of the number of effectively independently estimated breeding values worth of information in a sample and would be a better reflection of the errors in the genetic quantities. </bold>
      </p>
      <p> I believe this is already possible in the package, if I understood correctly. Both BootstrapRep and MonteCarloRep have sample size arguments. </p>
      <p>
        <bold>In the absence of this, adding explicit ways of working with the posterior distributions or estimated matrix of errors from the estimate of the G matrix would be welcome in your package. At the very least, you should make the distinction between these cases clearer in the text.</bold>
      </p>
      <p> As much as we would like to provide general methods for G matrix error estimation, the current available mixed model packages in R for ML estimation make this difficult. We recommend using MCMCglmm or some other Bayesian framework to incorporate uncertainty, and the posterior samples can be trivially used with the functions in the package.</p>
      <p>
        <bold>I think the random skewers procedure should be revisited in one respect. The Marroig and Cheverud (2007) procedure describes drawing random selection gradient values from a uniform distribution and then standardizing the resulting vector to unit length. This is meant to provide random directions in the phenotypic space. This procedure, however, does not achieve this as the distribution of random points before standardization is from a hypercube of the same dimensionality as the number of traits. This will lead to an uneven distribution of points around the hypersphere on which the unit length vectors of standardized simulated selection gradients would occupy. In effect, the extra space in the corners of the hypersphere cause patches of excess vectors. This could cause considerable mischief if, for example, the first principal component of a covariance matrix was oriented directly at  corner of the hypercube. It might be worth modifying the procedure to draw random Gaussian variables, which are then standardized to unit length following Muller (1959) and Marsaglia (1972). This would ensure truly random simulated directional selection.</bold>
      </p>
      <p> We generate random vectors using normal distributions for the elements to avoid this problem. Since the multivariate normal is spherically symmetrical, there are no privileged directions.</p>
    </body>
  </sub-article>
</sub-article>
<sub-article id="report14607" article-type="peer-review">
  <front-stub>
    <article-id pub-id-type="doi">10.5256/f1000research.9735.r14607</article-id>
    <title-group>
      <article-title>Referee response for version 2</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Houle</surname>
          <given-names>David</given-names>
        </name>
        <xref ref-type="aff" rid="r14607a1">1</xref>
        <role>Referee</role>
      </contrib>
      <aff id="r14607a1"><label>1</label>Department of Biological Science, Florida State University, Tallahassee, FL, USA</aff>
    </contrib-group>
    <author-notes>
      <fn fn-type="COI-statement">
        <p><bold>Competing interests: </bold>No competing interests were disclosed.</p>
      </fn>
    </author-notes>
    <pub-date pub-type="epub">
      <day>20</day>
      <month>7</month>
      <year>2016</year>
    </pub-date>
    <related-article id="d35e7031" related-article-type="peer-reviewed-article" ext-link-type="doi" xlink:href="10.12688/f1000research.7082.2">Version 2</related-article>
    <custom-meta-group>
      <custom-meta>
        <meta-name>recommendation</meta-name>
        <meta-value>approve-with-reservations</meta-value>
      </custom-meta>
    </custom-meta-group>
  </front-stub>
  <body>
    <p>This article has been improved in response to the previous comments of the reviewers.  The authors have added several important and difficult-to-implement new analyses to the package, especially those discussed in Aguirre et al. 2014. The text  has been altered to make clearer the limitations of some of the procedures.  </p>
    <p> On the other hand, many of my more general comments about the shortcomings of the package still hold, and I refer the reader to my first set of comments. </p>
    <p> One problem has, however, gotten worse, and that is how the package discusses the estimation of errors in G matrices and other variance component matrices. The text and code does not properly distinguish between sampling error of estimates of G matrices and sampling error of  simple statistics based directly on the data.   Consequently at many points the package could be used to produce misleading estimates of error in evolutionary statistics. </p>
    <p> The section on matrix error and repeatability is the locus of this problem.  The opening paragraph in this section is about error in the G matrices, but none of the methods in that section actually apply to G matrices.  In particular  the text equates the REML-MVN method (Houle and Meyer, 2015) with this package's MonteCarloRep, but this is incorrect.  REML-MVN requires you to have an estimate of the sampling variance-covariance of matrix elements, but the software implements the assumption that the only parameter that is needed to construct an estimate of error is the sample size.  This works for a P matrix of multivariate normal data, but is NOT the REML-MVN method. </p>
    <p> Similarly, the bootstrap routine seems only to bootstrap at the level of individuals.  Bootstrapping over individuals will always severely underestimate the error in G. For a designed experiment like a full and half-sib estimation of G, one could get proper estimates of error in G by bootstrapping over sires, which are the exchangeable units in that design.  A pedigree cannot be effectively bootstrapped as individuals are not exchangeable.  For a G matrix, you need additional estimates of error from either the posterior distribution of matrices, the variance-covariance matrix of estimates from a ML procedure, or  samples drawn from such a distribution.   Consequently the statement at the start of the Evolutionary Statistics section that
<bold>"MonteCarloStat()</bold> and 
<bold>BootstrapStat()</bold> can be used to generate confidence intervals for these statistics" is incorrect. To properly deal with this problem all of the routines should allow the user to furnish samples of matrices from the sampling distributions (e.g. samples from the posterior distribution), and then produce measures of uncertainty from those.  </p>
    <p> It would be ideal for the package to implement the ability to utilize such samples in every procedure.</p>
    <p>I have read this submission. I believe that I have an appropriate level of expertise to confirm that it is of an acceptable scientific standard, however I have significant reservations, as outlined above.</p>
  </body>
  <back>
    <ref-list>
      <title>References</title>
      <ref id="rep-ref-14607-1">
        <label>1</label>
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Houle</surname><given-names>D</given-names></name><name><surname>Meyer</surname><given-names>K</given-names></name></person-group>:
<article-title>Estimating sampling error of evolutionary statistics based on genetic covariance matrices using maximum likelihood.</article-title><source><italic>J Evol Biol</italic></source>.<year>2015</year>;<volume>28</volume>(<issue>8</issue>) :
<elocation-id>10.1111/jeb.12674</elocation-id><fpage>1542</fpage>-<lpage>9</lpage><pub-id pub-id-type="doi">10.1111/jeb.12674</pub-id><?supplied-pmid 26079756?><pub-id pub-id-type="pmid">25439133</pub-id></mixed-citation>
      </ref>
      <ref id="rep-ref-14607-2">
        <label>2</label>
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aguirre</surname><given-names>JD</given-names></name><name><surname>Hine</surname><given-names>E</given-names></name><name><surname>McGuigan</surname><given-names>K</given-names></name><name><surname>Blows</surname><given-names>MW</given-names></name></person-group>:
<article-title>Comparing G: multivariate analysis of genetic variation in multiple populations.</article-title><source><italic>Heredity (Edinb)</italic></source>.<year>2014</year>;<volume>112</volume>(<issue>1</issue>) :
<elocation-id>10.1038/hdy.2013.12</elocation-id><fpage>21</fpage>-<lpage>9</lpage><pub-id pub-id-type="doi">10.1038/hdy.2013.12</pub-id><?supplied-pmid 23486079?><pub-id pub-id-type="pmid">23486079</pub-id></mixed-citation>
      </ref>
    </ref-list>
  </back>
  <sub-article id="comment2262" article-type="response">
    <front-stub>
      <contrib-group>
        <contrib contrib-type="author">
          <name>
            <surname>Melo</surname>
            <given-names>Diogo</given-names>
          </name>
          <aff>Universidade de São Paulo, Brazil</aff>
        </contrib>
      </contrib-group>
      <author-notes>
        <fn fn-type="COI-statement">
          <p><bold>Competing interests: </bold>No competing interests were disclosed.</p>
        </fn>
      </author-notes>
      <pub-date pub-type="epub">
        <day>31</day>
        <month>10</month>
        <year>2016</year>
      </pub-date>
    </front-stub>
    <body>
      <p>Thank you for the second careful review! We agree completely with the problems regarding G-matrix error and have modified the text to make these limitations clear. As much as we would like to provide general methods for G matrix error estimation, the current available mixed model packages in R for ML estimation make this difficult. We recommend using MCMCglmm or some other Bayesian framework to incorporate uncertainty.</p>
    </body>
  </sub-article>
</sub-article>
<sub-article id="report10610" article-type="peer-review">
  <front-stub>
    <article-id pub-id-type="doi">10.5256/f1000research.7623.r10610</article-id>
    <title-group>
      <article-title>Referee response for version 1</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Houle</surname>
          <given-names>David</given-names>
        </name>
        <xref ref-type="aff" rid="r10610a1">1</xref>
        <role>Referee</role>
      </contrib>
      <aff id="r10610a1"><label>1</label>Department of Biological Science, Florida State University, Tallahassee, FL, USA</aff>
    </contrib-group>
    <author-notes>
      <fn fn-type="COI-statement">
        <p><bold>Competing interests: </bold>No competing interests were disclosed.</p>
      </fn>
    </author-notes>
    <pub-date pub-type="epub">
      <day>16</day>
      <month>11</month>
      <year>2015</year>
    </pub-date>
    <related-article id="d35e7247" related-article-type="peer-reviewed-article" ext-link-type="doi" xlink:href="10.12688/f1000research.7082.1">Version 1</related-article>
    <custom-meta-group>
      <custom-meta>
        <meta-name>recommendation</meta-name>
        <meta-value>approve-with-reservations</meta-value>
      </custom-meta>
    </custom-meta-group>
  </front-stub>
  <body>
    <p>This paper describes the functions implemented in the R package “evolvqg.”  This package implements a large set of methods for characterizing and comparing variance-covariance matrices. A compendium of such methods is useful, but the user should be aware of shortcomings in this package. </p>
    <p>First, the authors justify grouping these methods together under the umbrella of “evolutionary quantitative genetics.” Under this label, the very diversity of methods is a bit misleading - the majority of implemented methods have no explicit relationship to evolution, and this is not clear in the paper. To a large degree this confusion reflects the state of the field. A great many ad hoc methods are proposed and widely applied, such as the popular Mantel test. For example, this package implements methods for quantifying repeatability of the phenotypic covariance and correlation matrices, which is a fine thing to do, but has little relevance to the genetic matrices that underlie evolution. For those matrices, any procedure for estimating them will partition out the non-genetic factors as part of the hierarchical model fitting. Repeatability is usually the least of our estimation problems. Other methods that are in this not-really-evolutionary category include, matrix correlations, the ‘modularity’ analyses. </p>
    <p>A related issue is that this package does not include state-of-the-art techniques. In particular, the advent of MCMC methods (plus other methods for getting sampling variation of matrices: Houle and Meyer 2015) provides proper measures of uncertainty for the evolutionarily relevant G matrices. The previously available R package “evolvability” uses the posterior distributions for G matrices as well as selection gradients, when available, to place confidence intervals on the Hansen and Houle measures of evolvabilities. The “evolqg” package under review here primarily implements methods developed and used by the Marroig group, lacking some of the most promising approaches and metrics developed by others (e.g. Hine
<italic>et al</italic>. 2009, Houle and Fierst 2013; Aguirre
<italic>et al</italic>. 2014). Programming time is of course a limitation, and no one is under obligation to implement everything. However, it is deficient scholarship that this paper makes no mention of these approaches, or of the availability of software that does these analyses.  </p>
    <p>Based on their descriptions here, the phylogenetic comparison methods implemented in this package seem to be quite deficient. AncestralStates is contradictorily described as dealing with multivariate data, but reconstructs each character independently. It appears to implement an interface to a univariate method, and is not actually a multivariate approach. PhyloW and PhloCompare compute “weighted” estimates of matrices at internal nodes, but the proper weight to apply to a G matrix is not clear at all. This appears to only deal with sampling variance at the individual level, neglecting the more important sources of matrix variation. This disconnect appears to rest on the author's assumption that “As a general rule, high similarity between populations’ P-matrices is a good indicator of high similarity between P and G”. This is certainly not a general rule, as P and G matrices for traits with low heritability can be very different from each other. The classic examples are life history traits.</p>
    <p>For drift models, this implementation shares a major deficiency with previous work, in assuming that the expectation is that matrices will remain proportional. This is indeed the large-sample expectation, but any actual population will deviate from that expectation in ways that depend on the unknown parameters of the underlying system – the number of loci, their relative mutability, the underlying M matrix, and of course the effective population size of each part of the genome. For example, Griswold
<italic>et al</italic>. 2007 show that even when the underlying M matrix is spherical, realizations based on this will have substantial deviations from sphericity. There is no general treatment of this problem, so all results from such analyses need to be treated with caution. A failure to reject a departure from proportionality is meaningful, but rejections of proportionality do not necessarily indicate that drift is not responsible.</p>
    <p>Finally, like much of the software being made freely available, there is no description of what the authors did to validate their implementation of these techniques, and no comparisons with previous analyses to indirectly validate them. One or both of these should really be standard with new software. I know that it is not standard, and do not want to single these authors out on that account. The user, however, should be aware of all unvalidated software, and should perform their own checks. Unfortunately, this is only easy for simple procedures for which a package is not really necessary.</p>
    <p>Some very specific issues:
<list list-type="order"><list-item><p>Errors: “The proportion of variance not associated with the individuals is called the repeatability.”</p></list-item><list-item><p>The description of Mantel tests is misleading, as a high correlation does not mean that matrices are the “same,” nor does a negative correlation mean that matrices are “opposite.”</p></list-item><list-item><p>The description of the PCA similarity algorithm is opaque. What is “pondering”? </p></list-item></list>
</p>
    <p>I have read this submission. I believe that I have an appropriate level of expertise to confirm that it is of an acceptable scientific standard, however I have significant reservations, as outlined above.</p>
  </body>
  <back>
    <ref-list>
      <title>References</title>
      <ref id="rep-ref-10610-1">
        <label>1</label>
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Griswold</surname><given-names>CK</given-names></name><name><surname>Logsdon</surname><given-names>B</given-names></name><name><surname>Gomulkiewicz</surname><given-names>R</given-names></name></person-group>:
<article-title>Neutral evolution of multiple quantitative characters: a genealogical approach.</article-title><source><italic>Genetics</italic></source>.<year>2007</year>;<volume>176</volume>(<issue>1</issue>) :
<elocation-id>10.1534/genetics.106.069658</elocation-id><fpage>455</fpage>-<lpage>66</lpage><pub-id pub-id-type="doi">10.1534/genetics.106.069658</pub-id><?supplied-pmid 17339224?><pub-id pub-id-type="pmid">17339224</pub-id></mixed-citation>
      </ref>
      <ref id="rep-ref-10610-2">
        <label>2</label>
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hine</surname><given-names>E</given-names></name><name><surname>Chenoweth</surname><given-names>SF</given-names></name><name><surname>Rundle</surname><given-names>HD</given-names></name><name><surname>Blows</surname><given-names>MW</given-names></name></person-group>:
<article-title>Characterizing the evolution of genetic variance using genetic covariance tensors.</article-title><source><italic>Philos Trans R Soc Lond B Biol Sci</italic></source>.<year>2009</year>;<volume>364</volume>(<issue>1523</issue>) :
<elocation-id>10.1098/rstb.2008.0313</elocation-id><fpage>1567</fpage>-<lpage>78</lpage><pub-id pub-id-type="doi">10.1098/rstb.2008.0313</pub-id><?supplied-pmid 19414471?><pub-id pub-id-type="pmid">19414471</pub-id></mixed-citation>
      </ref>
      <ref id="rep-ref-10610-3">
        <label>3</label>
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Houle</surname><given-names>D</given-names></name><name><surname>Meyer</surname><given-names>K</given-names></name></person-group>:
<article-title>Estimating sampling error of evolutionary statistics based on genetic covariance matrices using maximum likelihood.</article-title><source><italic>J Evol Biol</italic></source>.<year>2015</year>;<volume>28</volume>(<issue>8</issue>) :
<elocation-id>10.1111/jeb.12674</elocation-id><fpage>1542</fpage>-<lpage>9</lpage><pub-id pub-id-type="doi">10.1111/jeb.12674</pub-id><?supplied-pmid 26079756?><pub-id pub-id-type="pmid">25439133</pub-id></mixed-citation>
      </ref>
      <ref id="rep-ref-10610-4">
        <label>4</label>
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Houle</surname><given-names>D</given-names></name><name><surname>Fierst</surname><given-names>J</given-names></name></person-group>:
<article-title>Properties of spontaneous mutational variance and covariance for wing size and shape in Drosophila melanogaster.</article-title><source><italic>Evolution</italic></source>.<year>2013</year>;<volume>67</volume>(<issue>4</issue>) :
<elocation-id>10.1111/j.1558-5646.2012.01838.x</elocation-id><fpage>1116</fpage>-<lpage>30</lpage><pub-id pub-id-type="doi">10.1111/j.1558-5646.2012.01838.x</pub-id><?supplied-pmid 23550760?><pub-id pub-id-type="pmid">23289558</pub-id></mixed-citation>
      </ref>
      <ref id="rep-ref-10610-5">
        <label>5</label>
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aguirre</surname><given-names>JD</given-names></name><name><surname>Hine</surname><given-names>E</given-names></name><name><surname>McGuigan</surname><given-names>K</given-names></name><name><surname>Blows</surname><given-names>MW</given-names></name></person-group>:
<article-title>Comparing G: multivariate analysis of genetic variation in multiple populations.</article-title><source><italic>Heredity (Edinb)</italic></source>.<year>2014</year>;<volume>112</volume>(<issue>1</issue>) :
<elocation-id>10.1038/hdy.2013.12</elocation-id><fpage>21</fpage>-<lpage>9</lpage><pub-id pub-id-type="doi">10.1038/hdy.2013.12</pub-id><?supplied-pmid 23486079?><pub-id pub-id-type="pmid">23486079</pub-id></mixed-citation>
      </ref>
    </ref-list>
  </back>
  <sub-article id="comment2022" article-type="response">
    <front-stub>
      <contrib-group>
        <contrib contrib-type="author">
          <name>
            <surname>Melo</surname>
            <given-names>Diogo</given-names>
          </name>
          <aff>Universidade de São Paulo, Brazil</aff>
        </contrib>
      </contrib-group>
      <author-notes>
        <fn fn-type="COI-statement">
          <p><bold>Competing interests: </bold>No competing interests were disclosed.No competing interests were disclosed.</p>
        </fn>
      </author-notes>
      <pub-date pub-type="epub">
        <day>13</day>
        <month>6</month>
        <year>2016</year>
      </pub-date>
    </front-stub>
    <body>
      <p>
        <italic>
          <bold>- This paper describes the functions implemented in the R package “evolqg.”  This package implements a large set of methods for characterizing and comparing variance-covariance matrices. A compendium of such methods is useful, but the user should be aware of shortcomings in this package. </bold>
        </italic>
      </p>
      <p> Thank you for your insightful comments. One of the reasons we chose F1000research for this article is our perception that something is amiss in the current system of peer-review, where good reviewers are burdened and swamped by manuscripts and authors tend to often ignore their criticisms and take the short road to the next journal inline instead of dealing with the criticisms and polish their manuscripts. The fully open system implemented by F1000 seems like a good way out of this trap we express our gratitude to Drs. Houle and Grabowsky for taking their time to criticize this package.</p>
      <p> We respond to comments individually after each of your considerations.</p>
      <p>
        <bold>
          <italic>- First, the authors justify grouping these methods together under the umbrella of “evolutionary quantitative genetics.” Under this label, the very diversity of methods is a bit misleading - the majority of implemented methods have no explicit relationship to evolution, and this is not clear in the paper. To a large degree this confusion reflects the state of the field. A great many ad hoc methods are proposed and widely applied, such as the popular Mantel test. For example, this package implements methods for quantifying repeatability of the phenotypic covariance and correlation matrices, which is a fine thing to do, but has little relevance to the genetic matrices that underlie evolution. For those matrices, any procedure for estimating them will partition out the non-genetic factors as part of the hierarchical model fitting. Repeatability is usually the least of our estimation problems. Other methods that are in this not-really-evolutionary category include, matrix correlations, the ‘modularity’ analyses. </italic>
        </bold>
      </p>
      <p> This is a fair comment, and indeed an argument could be made to separate the different aspects of evolutionary research that are presented here into different packages. We chose to keep these different methods in a single source since we feel a consistent workflow is very beneficial to research on evolution and covariation. For example, many of the latter hypothesis-testing methods presented in our paper should only be used if some level of matrix similarity is detected, and the matrix similarities, in turn, should not be interpreted without matrices' repeatabilities. Furthermore, while the development of multivariate evolutionary theory and the theory of integration and modularity were separate, Lande's, Cheverud's and Wagner's work since the 80s have linked these fields very intimately, to a point that it is hard for us to think of these fields as separate. From our point of view, the influence of covariation in evolution, and the genetic and developmental origin of these variational associations make integration and modularity central to modern evolutionary theory, even though admittedly there are a number of researchers who consider morphological integration and comparative quantitative genetics as two separate fields. We feel this integrative approach links the developmental and intra-populational causes of genetic covariation to their evolutionary consequences, leading to a more complete and robust understanding of micro- and macro-evolution.</p>
      <p> Finally, the inclusion of methods that are mostly "statistical" and not "evolutionary" should make it easier for researchers to check the quality of their data and its appropriateness for further analyses.</p>
      <p>
        <bold>
          <italic>- A related issue is that this package does not include state-of-the-art techniques. In particular, the advent of MCMC methods (plus other methods for getting sampling variation of matrices: Houle and Meyer 2015) provides proper measures of uncertainty for the evolutionarily relevant G matrices. The previously available R package “evolvability” uses the posterior distributions for G matrices as well as selection gradients, when available, to place confidence intervals on the Hansen and Houle measures of evolvabilities. The “evolqg” package under review here primarily implements methods developed and used by the Marroig group, lacking some of the most promising approaches and metrics developed by others (e.g. Hine et al. 2009, Houle and Fierst 2013; Aguirre et al. 2014). Programming time is of course a limitation, and no one is under obligation to implement everything. However, it is deficient scholarship that this paper makes no mention of these approaches, or of the availability of software that does these analyses.  </italic>
        </bold>
      </p>
      <p> While we challenge the reviewer's assertion that we fail to mention these methods (see the second paragraph of our Summary section; and the method described in Houle and Meyer is implemented by the function MonteCarloStat()), the point is well taken. Another reason for choosing F1000Research was the ease of updating the manuscript as we add new functionality to the EvolQG package. In this spirit of continuous development, we added in the revised version of the package three of the methods described in Aguirre et al. 2014, including the eigentensor decomposition described by Hine et al. 2009, using fast and flexible implementations in R.</p>
      <p>
        <bold>
          <italic>- Based on their descriptions here, the phylogenetic comparison methods implemented in this package seem to be quite deficient. </italic>
        </bold>
      </p>
      <p> We would argue that the available methods in the literature are deficient in dealing with multivariate correlated traits, and we provide the rather simple available methods.</p>
      <p>
        <italic>
          <bold>- AncestralStates is contradictorily described as dealing with multivariate data, but reconstructs each character independently. It appears to implement an interface to a univariate method, and is not actually a multivariate approach.</bold>
        </italic>
      </p>
      <p> We clearly stated that AncestralStates is not a multivariate approach. Indeed AncestralStates is just a wrapper to facilitate reconstructing multiple traits independently. If the reviewer has a suggestion on how to implement this taking the multivariate covariance structure into account for many traits we would be very interested, but this remains an active research topic, and we have not found a satisfactory solution for this problem. Since this seems to be more misleading than helpful, we have removed this function from the package and manuscript.</p>
      <p>
        <italic>
          <bold>- PhyloW and PhyloCompare compute “weighted” estimates of matrices at internal nodes, but the proper weight to apply to a G matrix is not clear at all. This appears to only deal with sampling variance at the individual level, neglecting the more important sources of matrix variation. </bold>
        </italic>
      </p>
      <p> This is another unambitious method, and was intended only to calculate within-group phenotypic covariance matrices in a phylogenetically structured way. The use with G-matrices coming from more complex linear models would indeed be non-trivial, and we now make this explicit in the description.</p>
      <p>
        <bold>
          <italic>- This disconnect appears to rest on the author's assumption that “As a general rule, high similarity between populations’ P-matrices is a good indicator of high similarity between P and G”. This is certainly not a general rule, as P and G matrices for traits with low heritability can be very different from each other. The classic examples are life history traits.</italic>
        </bold>
      </p>
      <p> We would argue that in the case of low heritability the P-matrices between populations would also be dissimilar. The point here is not that P and G are always similar, but that similar Ps between populations are a fair indication of similar Gs and Ps, at least in the groups we have worked with. In mammals, this conclusion is supported empirically by the comparisons of 5 different G-matrices with P-matrices of several groups, which indicate similar responses to random selection on average (Porto, 2009). In any event, we add a caveat on the function description that structurally similar matrices are a key component of the methods implemented here.</p>
      <p>
        <italic>
          <bold>- For drift models, this implementation shares a major deficiency with previous work, in assuming that the expectation is that matrices will remain proportional. This is indeed the large-sample expectation, but any actual population will deviate from that expectation in ways that depend on the unknown parameters of the underlying system – the number of loci, their relative mutability, the underlying M matrix, and of course the effective population size of each part of the genome. For example, Griswold et al. 2007 show that even when the underlying M matrix is spherical, realizations based on this will have substantial deviations from sphericity. There is no general treatment of this problem, so all results from such analyses need to be treated with caution. A failure to reject a departure from proportionality is meaningful, but rejections of proportionality do not necessarily indicate that drift is not responsible.</bold>
        </italic>
      </p>
      <p> This is indeed a problem, and we try to remedy this by ensuring the matrices share some minimum level of similarity before using these drift models. Proa et al. 2013 analysed the type I error rate in the DriftTest method, and found that if matrices are similar the test is well behaved. This similarity must be tested on a case by case basis. Error rate analysis of the other tests is an open problem. Another option is to repeat the analysis using different matrices from the terminal taxa that represent extremes of variability, and check if the results are robust to this. We make these caveats and problems clear in the revised manuscript.</p>
      <p> This paragraph now reads:</p>
      <p> "Since both these tests use drift as a null hypothesis, failure to reject the null hypothesis is not evidence that selection was not involved in the observed pattern of diversification, only that the observed pattern is compatible with drift. Also, these methods assume that the matrices involved share some degree of similarity, and should ideally be proportional to each other. We would be very weary of using these methods if the matrices are too dissimilar, or if the results change radically if different matrices are used as the ancestral matrix. Also, these tests rely on two levels of replication, taxa and traits. As a general guideline, at least 20 traits and at least 8 taxa should be sampled for using these methods with any confidence, and results should be analyzed in conjunction with other lines of evidence."</p>
      <p> With regards to Griswold et al. 2007, we believe that verifying the extant matrices are similar somewhat sidesteps these problems, and in any event their simulations do not include stabilizing selection on covariance patterns, which is very likely to exist if matrices are stable in evolutionary timescales. It’s important to realize that the methods we describe are for identifying drift on species means, not covariances. Evolution of covariance patterns is a different matter altogether.</p>
      <p>
        <bold>
          <italic>- Finally, like much of the software being made freely available, there is no description of what the authors did to validate their implementation of these techniques, and no comparisons with previous analyses to indirectly validate them. One or both of these should really be standard with new software. I know that it is not standard, and do not want to single these authors out on that account. The user, however, should be aware of all unvalidated software, and should perform their own checks. Unfortunately, this is only easy for simple procedures for which a package is not really necessary.</italic>
        </bold>
      </p>
      <p> We agree entirely, and feel that the bar for scientific software should be high, and so we took additional steps in this direction. While no implementation is bug free, we compared all results from our initial set of functions between different implementations done by members of our lab and available implementations in the literature. Also, all development for the package was done in a test driven development framework, and all functions have unit tests for the most or all of their functionality, that is run every time the package is built. This insures modifications do not alter previous results. The implementations in the package follow a modular design for most functionality, minimizing code duplication and reducing the chance of bugs. We also have a fast and constantly maintained issue and bug tracker in github, where users can ask questions, request new functionality, and report bugs.</p>
      <p>
        <bold>
          <italic>- Some very specific issues:</italic>
        </bold>
      </p>
      <p>
        <italic>
          <bold>- Errors: “The proportion of variance not associated with the individuals is called the repeatability.”</bold>
        </italic>
      </p>
      <p> Changed to something clearer. Now reads: "The proportion of variance associated with among individual variation, and not within individual variation, is called the repeatability"</p>
      <p>
        <bold>
          <italic>- The description of Mantel tests is misleading, as a high correlation does not mean that matrices are the “same,” nor does a negative correlation mean that matrices are “opposite.” </italic>
        </bold>
      </p>
      <p> We chose a more cautious wording of these general guidelines. Now reads: "The correlation between matrices range between -1 and 1, and higher correlations indicate matrices have more similar structures, while null correlations indicate the matrices have very distinct correlation structures. Correlations near zero can also occur if the elements of the matrices have nonlinear relationships between them, as in all Pearson correlations. Negative correlations indicate the pattern of association between traits is reversed in the two matrices."</p>
      <p>
        <bold>
          <italic>- The description of the PCA similarity algorithm is opaque. What is “pondering”?</italic>
        </bold>
      </p>
      <p> Sorry, this was a rather hard false cognate with portuguese for us to catch, and now reads:  "In order to take the variation into account, we can add the eigenvalue associated with each principal component into the calculation, effectively weighting each correlation by the variance in the associated directions"</p>
      <p> Literature cited
<list list-type="order"><list-item><p>Cheverud, J. M. (1996). Quantitative genetic analysis of cranial morphology in the cotton‐top (Saguinus oedipus) and saddle‐back (S. fuscicollis) tamarins. Journal of Evolutionary Biology, 9(1), 5-42.</p></list-item><list-item><p>Marroig, G., &amp; Cheverud, J. M. (2001). A comparison of phenotypic variation and covariation patterns and the role of phylogeny, ecology, and ontogeny during cranial evolution of New World monkeys. Evolution, 55(12), 2576-2600.</p></list-item><list-item><p>Prôa, M., O'Higgins, P., &amp; Monteiro, L. R. (2013). Type I error rates for testing genetic drift with phenotypic covariance matrices: a simulation study. Evolution, 67(1), 185-195.</p></list-item><list-item><p>Porto, A., de Oliveira, F. B., Shirai, L. T., De Conto, V., Marroig, G., (2009). The Evolution of Modularity in the Mammalian Skull I: Morphological Integration Patterns and Magnitudes. Evolutionary Biology, 36(1), 118–135. doi:10.1007/s11692-008-9038-3</p></list-item></list>
</p>
    </body>
  </sub-article>
</sub-article>
<sub-article id="report10607" article-type="peer-review">
  <front-stub>
    <article-id pub-id-type="doi">10.5256/f1000research.7623.r10607</article-id>
    <title-group>
      <article-title>Referee response for version 1</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Grabowsky</surname>
          <given-names>Mark</given-names>
        </name>
        <xref ref-type="aff" rid="r10607a1">1</xref>
        <role>Referee</role>
      </contrib>
      <aff id="r10607a1"><label>1</label>Centre for Ecological and Evolutionary Synthesis (CEES), Department of Biosciences, The Faculty of Mathematics and Natural Sciences, University of Olso, Oslo, Norway</aff>
    </contrib-group>
    <author-notes>
      <fn fn-type="COI-statement">
        <p><bold>Competing interests: </bold>No competing interests were disclosed.</p>
      </fn>
    </author-notes>
    <pub-date pub-type="epub">
      <day>16</day>
      <month>10</month>
      <year>2015</year>
    </pub-date>
    <related-article id="d35e7815" related-article-type="peer-reviewed-article" ext-link-type="doi" xlink:href="10.12688/f1000research.7082.1">Version 1</related-article>
    <custom-meta-group>
      <custom-meta>
        <meta-name>recommendation</meta-name>
        <meta-value>approve</meta-value>
      </custom-meta>
    </custom-meta-group>
  </front-stub>
  <body>
    <p>This Software Tool is an open source R package for performing a wide variety of evolutionary genetic analyses. It comes at a particularly useful time when large data sets required to use these analytical techniques are more and more available. I predict this package will be used to a greater and greater extent over time.</p>
    <p>The team, with lead author Diogo Melo, has made a number of major innovations in the field of evolutionary quantitative genetics and this software tool is well within their purview.</p>
    <p>The group describes the potential application of the new software well, cites the sources for the development of the different methods included, and briefly explains each function with an adequate level of discussion. I found the section on Phylogenetic Comparisons most interesting, and would have liked more discussion of these points.</p>
    <p>Issues:
<list list-type="order"><list-item><p>It would be nice to include data for which the tools could be tried out on and examples of the output included in the text.</p></list-item><list-item><p>I also worry about the power of some of these tests, and would appreciate if the authors were to think about adding in caveats where available. There are a few papers out currently that address these issues (e.g. Haber, 2011). For example, I have both heard and performed some analyses using another version of the DriftTest() function and it appears about 20 traits are required to ever reject the null hypothesis. As this package is sure to be used by researchers who are less acquainted with these issues they may be unaware of issues with sample sizes, etc.</p></list-item></list>
</p>
    <p>I have read this submission. I believe that I have an appropriate level of expertise to confirm that it is of an acceptable scientific standard.</p>
  </body>
  <sub-article id="comment2023" article-type="response">
    <front-stub>
      <contrib-group>
        <contrib contrib-type="author">
          <name>
            <surname>Melo</surname>
            <given-names>Diogo</given-names>
          </name>
          <aff>Universidade de São Paulo, Brazil</aff>
        </contrib>
      </contrib-group>
      <author-notes>
        <fn fn-type="COI-statement">
          <p><bold>Competing interests: </bold>No competing interests were disclosed.</p>
        </fn>
      </author-notes>
      <pub-date pub-type="epub">
        <day>13</day>
        <month>6</month>
        <year>2016</year>
      </pub-date>
    </front-stub>
    <body>
      <p>Thank you for your kind comments. We have included some additional caveats in relation to the power and level of replication required for some of the tests. With regards to examples, we fell a package vignette tutorial is much more suited to this, and we are working on more documentation to be distributed with the package.</p>
    </body>
  </sub-article>
</sub-article>
