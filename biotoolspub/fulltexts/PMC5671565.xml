<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Neuroinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Neuroinformatics</journal-id>
    <journal-title-group>
      <journal-title>Neuroinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1539-2791</issn>
    <issn pub-type="epub">1559-0089</issn>
    <publisher>
      <publisher-name>Springer US</publisher-name>
      <publisher-loc>New York</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">5671565</article-id>
    <article-id pub-id-type="publisher-id">9340</article-id>
    <article-id pub-id-type="doi">10.1007/s12021-017-9340-2</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Software Original Article</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>CAS: Cell Annotation Software – Research on Neuronal Tissue Has Never Been so Transparent</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-5137-5732</contrib-id>
        <name>
          <surname>Nurzynska</surname>
          <given-names>Karolina</given-names>
        </name>
        <address>
          <email>Karolina.Nurzynska@polsl.pl</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Mikhalkin</surname>
          <given-names>Aleksandr</given-names>
        </name>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Piorkowski</surname>
          <given-names>Adam</given-names>
        </name>
        <xref ref-type="aff" rid="Aff3">3</xref>
      </contrib>
      <aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0001 2335 3149</institution-id><institution-id institution-id-type="GRID">grid.6979.1</institution-id><institution>Institute of Informatics, </institution><institution>Silesian University of Technology, </institution></institution-wrap>Gliwice, Poland </aff>
      <aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0001 2217 1298</institution-id><institution-id institution-id-type="GRID">grid.417772.0</institution-id><institution>Laboratory of Neuromorphology, </institution><institution>Pavlov Institute of Physiology RAS, </institution></institution-wrap>St. Petersburg, Russia </aff>
      <aff id="Aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0000 9174 1488</institution-id><institution-id institution-id-type="GRID">grid.9922.0</institution-id><institution>Department of Geoinformatics and Applied Computer Science, </institution><institution>AGH University of Science and Technology, </institution></institution-wrap>Cracow, Poland </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>29</day>
      <month>8</month>
      <year>2017</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>29</day>
      <month>8</month>
      <year>2017</year>
    </pub-date>
    <pub-date pub-type="ppub">
      <year>2017</year>
    </pub-date>
    <volume>15</volume>
    <issue>4</issue>
    <fpage>365</fpage>
    <lpage>382</lpage>
    <permissions>
      <copyright-statement>© The Author(s) 2017</copyright-statement>
    </permissions>
    <abstract id="Abs1">
      <p id="Par1">CAS (Cell Annotation Software) is a novel tool for analysis of microscopic images and selection of the cell soma or nucleus, depending on the research objectives in medicine, biology, bioinformatics, etc. It replaces time-consuming and tiresome manual analysis of single images not only with automatic methods for object segmentation based on the Statistical Dominance Algorithm, but also semi-automatic tools for object selection within a marked region of interest. For each image, a broad set of object parameters is computed, including shape features and optical and topographic characteristics, thus giving additional insight into data. Our solution for cell detection and analysis has been verified by microscopic data and its application in the annotation of the lateral geniculate nucleus has been examined in a case study.</p>
    </abstract>
    <kwd-group xml:lang="en">
      <title>Keywords</title>
      <kwd>Neuroscientific data</kwd>
      <kwd>Image processing</kwd>
      <kwd>Image understanding</kwd>
      <kwd>Neuron segmentation</kwd>
      <kwd>Nuclei segmentation</kwd>
      <kwd>Cell segmentation</kwd>
      <kwd>Microscopic images</kwd>
      <kwd>Statistical Dominance Algorithm</kwd>
      <kwd>Histological images</kwd>
      <kwd>Immunohistological images</kwd>
      <kwd>Fluorescent microscopy</kwd>
      <kwd>2D microscopy</kwd>
      <kwd>Shape features</kwd>
    </kwd-group>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>© Springer Science+Business Media, LLC 2017</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="Sec1">
    <title>Introduction</title>
    <p id="Par2">Studying the principles of the structure of neuronal nets can bring us closer to unraveling the functioning of heterogenic populations of neurons within the central nervous system. The investigation of these nets involves consideration of the characteristics of neurons and their distribution within a particular nervous structure. In some cases, the distribution of neurons is enough to predict their characteristics. Often neurons form repetitive, regularly organized groups within which they share common physiological and neurochemical characteristics. For example, this phenomenon is pronounced within the visual cortex (Dyck &amp; Cynader <xref ref-type="bibr" rid="CR11">1993</xref>; Kaas <xref ref-type="bibr" rid="CR24">2012</xref>; Ohki et al. <xref ref-type="bibr" rid="CR42">2005</xref>) and the spinal cord (Merkulyeva et al. <xref ref-type="bibr" rid="CR35">2016</xref>). However, in many other cases the structure of the object of interest is not so highly ordered; however, this does not mean that neurons are randomly distributed. A good example is a laminated visual thalamic structure, the lateral geniculate nucleus, LGN, which contains neurons differentiated by multiple features, such as input from ipsilateral or contralateral eye, the visuotopic position of retinal projections, or the type of projecting ganglion cell (Sanderson <xref ref-type="bibr" rid="CR50">1971</xref>; Payne &amp; Peters <xref ref-type="bibr" rid="CR45">2002</xref>; Schiller <xref ref-type="bibr" rid="CR51">2010</xref>). In such cases, we expect these neuronal nets to have a complex structure; a full description of them can be obtained only by means of thorough analysis of cell parameters measured within the entire structure. Obviously, this leads to a significant increase in the effort needed to detect and analyze neuronal data, but this can be significantly facilitated with the use of specialized software.</p>
    <p id="Par3">The software applications designed for this purpose offer a wealth of opportunities for manual cell detection; however, in many cases only restricted opportunities for automatic cell detection are provided, usually based on brightness and color filters. Sometimes these techniques are suitable, but there are many cases in which biological objects have staining that is too difficult to be entrusted to automatic detection modes. Examples include a high level of noise, such as stained fibers and dendritic arbors, or high variability of the color intensity of objects of interest. Moreover, subsequent analysis is performed in statistical data processing software such as Statistica (StatSoft) and SPSS Statistics (IBM). These applications have a specific way of organizing data, but image processing software cannot export data to these programs; therefore, a lot of additional work is necessary for data preparation.</p>
    <p id="Par4">Cell Annotation Software, CAS<xref ref-type="fn" rid="Fn1">1</xref>, was created in order to meet the needs arising from investigations of objects in histological specimens. ’Object’ is a general term we use throughout whole paper, but it should be understood as cell soma or cell nucleus, since either can be selected with CAS depending on the chosen parameters. The selection procedure ensures that any artifacts that are a result of tissue processing are considered. Comparative analysis of neuronal populations is also possible. Moreover, easy navigation between various levels of analysis and final data storage in files whose format is easily accessible to other software makes CAS a unique and fully functional program.</p>
    <p id="Par6">The program is designed to work with histologically and immunohistologically prepared specimens of neuronal tissue for which topological information about neural object placement is crucial. It allows different parts of stratified structures (e.g. laminae of neocortex, thalamic nuclei, spinal cord) to be compared and their intrinsic inhomogeneity to be examined. Definition of a region of interest of any shape is very practical and easy to apply. The semi-automatic detection of objects depends on only a few parameters; the rules of how to set these parameters are given in this work. Data unification in the X-axis allows for better comparison between several specimens; this is important in ontogenetic research, in which the absolute size of brain structures changes progressively.</p>
    <p id="Par7">Brightness normalization is important for quantitative comparison of the degree of histochemical or immunohistochemical staining of tissues. This makes it possible to analyze the amount of stained substance in objects indirectly, which in turn allows examination of the accumulation (or degradation) of a substance during maturation of the nervous system or under experimental conditions</p>
    <p id="Par8">Combining the aforementioned functionality of this tool makes CAS a powerful solution which facilitates histological structure analysis and removes the manual work which is normally necessary with other open-source software.</p>
    <p id="Par9">The basic discussion of selecting the most accurate image processing algorithms for object detection is presented in “<xref rid="Sec2" ref-type="sec">Object Segmentation</xref>”. This draws attention to many problems which must be considered in order to choose a suitable method for data segmentation. Detecting objects requires automatic description of shape, size, and distribution. The implemented measures and their interpretations are given in “<xref rid="Sec9" ref-type="sec">Shape Parameters</xref>”. Finally, Section “<xref rid="Sec13" ref-type="sec">Case Study</xref>” presents an example of the application of CAS in research on the LGN. The “<xref rid="Sec16" ref-type="sec">Conclusions</xref>” summarize the article.</p>
  </sec>
  <sec id="Sec2">
    <title>Object Segmentation</title>
    <p id="Par10">Although it has already been addressed, the problem of correct segmentation between cell soma/nucleus and backgrounds in extensive groups of microscopic images does not yet seem to have been universally solved. This is interesting because the problem of object detection in biplanar images (in which there are only objects and a well-defined background) is widely discussed in the literature and there are many methods with various degrees of accuracy for solving it (Irshad et al. <xref ref-type="bibr" rid="CR21">2014</xref>).</p>
    <p id="Par11">The standard approach is based on a family of binarization methods and other more advanced algorithms dedicated to this problem. In most cases, researchers conduct object segmentation manually, exploiting the tool-set in ImageJ/Fiji (Papadopulos et al. <xref ref-type="bibr" rid="CR44">2007</xref>; Collins &amp; et al. <xref ref-type="bibr" rid="CR9">2007</xref>; Schneider et al. <xref ref-type="bibr" rid="CR53">2012</xref>; Schindelin et al. <xref ref-type="bibr" rid="CR52">2012</xref>; Hartig <xref ref-type="bibr" rid="CR18">2001</xref>). Researchers, who specialize in image processing, have also created solutions dedicated to specific applications. Examples include the ImageJ plug-in (Forero et al. <xref ref-type="bibr" rid="CR13">2010</xref>; Pool et al. <xref ref-type="bibr" rid="CR48">2008</xref>), an ImageJ framework expansion (Gulyás et al. <xref ref-type="bibr" rid="CR17">2016</xref>), software for the Matlab environment (La Torre et al. <xref ref-type="bibr" rid="CR31">2013</xref>), and stand-alone applications such as CellProfiler (Kamentsky et al. <xref ref-type="bibr" rid="CR25">2011</xref>; Carpenter et al. <xref ref-type="bibr" rid="CR7">2006</xref>). Commercial solutions also exist, but their license usually precludes them from comparison. In many of the aforementioned solutions, extended H-minima is exploited for segmentation, while in our work the Statistical Dominance Algorithm SDA (Piorkowski <xref ref-type="bibr" rid="CR46">2016</xref>) is applied; this is novel in this field.</p>
    <p id="Par12">This section presents the common problems which should be considered when object segmentation is performed on microscopic images. The discussion starts with the choice of color space and its influence on the accuracy of the location of the border of the final object. The difficulties which must be overcome by binarization procedures are then described. Finally, a comparison of the standard procedures exploiting the extended H-minima method and the novel approach based on the SDA algorithm applied in the presented software is given.</p>
    <sec id="Sec3">
      <title>Adjusting Color space</title>
      <p id="Par13">Data gathered by microscopic examination is stored as color images. Generally, the correct approach to further analysis of color data assumes the necessity of color-space normalization (Ing et al. <xref ref-type="bibr" rid="CR20">2016</xref>). However, in the case of microscopic nerve tissue data, which is the main objective of CAS development, normalization is not necessary due to the monochromatic nature of the input data, which holds most information in one or two channels of the three used for acquisition (usually in RGB format). Moreover, the differences between channels are not substantial. Previous attempts at selecting the most representative color channel of various tissues have shown that the best solution is to choose the channel with the highest variance (in RGB) for processing (Kolodziejczyk et al. <xref ref-type="bibr" rid="CR27">2014</xref>).</p>
    </sec>
    <sec id="Sec4">
      <title>Standard approach to image binarization</title>
      <p id="Par14">The standard approach to object segmentation has already been established and is based on microscopic preparations, a commonly used solution that was introduced in neuro-science (Selinummi et al. <xref ref-type="bibr" rid="CR54">2005</xref>; Baecker <xref ref-type="bibr" rid="CR1">2010</xref>; Hartig <xref ref-type="bibr" rid="CR18">2001</xref>). This technique consists of two stages of image processing: background correction and application of one of a range of binarization methods.</p>
      <p id="Par15">Background correction aims to remove the very common phenomenon of uneven illumination. This can be achieved in various ways, for instance by high-pass filtering (which removes low frequencies). However, the rolling ball algorithm, which is the most widely applied, is based on background subtraction, as suggested by Sternberg (<xref ref-type="bibr" rid="CR57">1983</xref>). This procedure subtracts average illuminance in a usually disc-shaped given neighborhood and prompts the operator to specify its dimensions. It is assumed that this size (the radius) should be a few times larger than the object’s area in order to avoid distorting objects while maintaining the effective removal of uneven illumination. A discussion on the influence of changing radius on the performance of the rolling ball algorithm was presented by Ekstrom et al. (<xref ref-type="bibr" rid="CR12">2016</xref>).</p>
      <p id="Par16">Binarization is the second stage; it assigns 1s for pixels belonging to the object and 0s for the background. The easiest approach uses global thresholding, which defines one threshold value for the whole image. This is an efficient solution for a group of selected images; however, when larger variations in image content are considered or noise and distortions are present, more sophisticated approaches are necessary. In such cases, adaptive methods are useful, such as the essential method introduced by Otsu (<xref ref-type="bibr" rid="CR43">1975</xref>). ImageJ/Fiji software (Hartig <xref ref-type="bibr" rid="CR18">2001</xref>) also implements other methods which can be exploited (e.g. Huang, Li, Max Entropy, Renyi Entropy, Shanbhag, Yen, etc.). The common advantage of all adaptive methods is the lack of necessity for the operator to set parameters, hence the human influence on data processing is removed. Still, these techniques may misinterpret areas of images that have different object density and background type than the rest of the image, or where images containing tissues have varying structures.</p>
    </sec>
    <sec id="Sec5">
      <title>Extended H-minima Technique</title>
      <p id="Par17">Two of the basic methods of object segmentation in biplanar images are the H-minima technique and the extended regional version (extended H-minima) described by Soille (<xref ref-type="bibr" rid="CR56">1999</xref>). The main idea assumes that objects are sought that differ in intensity from the background by least the value of <italic>H</italic>. This algorithm is often applied for cellular nuclei segmentation or detection of whole cells (Cheng et al. <xref ref-type="bibr" rid="CR8">2009</xref>; Jung &amp; Kim <xref ref-type="bibr" rid="CR23">2010</xref>; Koyuncu et al. <xref ref-type="bibr" rid="CR30">2016</xref>; Gertych et al. <xref ref-type="bibr" rid="CR15">2016</xref>). In the case of LGN images, this method gives unstable results. Figure <xref rid="Fig1" ref-type="fig">1</xref>a presents an exemplary part of an image and the segmentation results achieved for consecutive <italic>H</italic> parameter values: Fig. <xref rid="Fig1" ref-type="fig">1</xref>b – d. One can see that different cells are present with increasing <italic>H</italic>. In the next steps, some cells disappear, while others appear or reappear; therefore, image segmentation is not consistent, which is not acceptable.
<fig id="Fig1"><label>Fig. 1</label><caption><p>Example of cell segmentation with extended H-minima for LGN. Red color denotes objects which should be located</p></caption><graphic xlink:href="12021_2017_9340_Fig1_HTML" id="MO2"/></fig>
</p>
    </sec>
    <sec id="Sec6">
      <title>Statistical Dominance Algorithm</title>
      <p id="Par18">We suggest a novel approach for object segmentation based on the recently introduced Statistical Dominance Algorithm (SDA) Piorkowski (<xref ref-type="bibr" rid="CR46">2016</xref>), which exploits statistics to specify image content. For each pixel in a monochromatic image, a number of neighboring pixels are defined such that the currently analyzed pixel is dominant over them (or inversely, neighboring pixels are dominant over the current pixel). As with H-minima, it is possible to define an additional threshold that must be reached to assume dominance. Thus, the output image contains statistics of point distribution in the input data; however, it is interesting that this method makes it possible to keep the original shapes. Because relations between points instead of illumination differences are computed, sensitivity to uneven illumination and structure variation diminishes. Moreover, this technique can derive indirect information about an object’s area.</p>
      <p id="Par19">The concept of the SDA algorithm is based on a statistical calculation of how many points dominate the central point of a neighborhood. The algorithm seems simple, especially if it is presented in the form of the code given in Listing <xref rid="Figo" ref-type="fig">1</xref>, where:
<list list-type="bullet"><list-item><p id="Par20"><italic>imgin</italic> – input image,</p></list-item><list-item><p id="Par21"><italic>imgout</italic> – output image,</p></list-item><list-item><p id="Par22"><italic>SX</italic>, <italic>SY</italic> – width and height of input/output image,</p></list-item><list-item><p id="Par23"><italic>R</italic> – radius of neighborhood,</p></list-item><list-item><p id="Par24"><italic>N</italic> – size of neighborhood mask (also size of mirror margin used here), <italic>N</italic> = ⌈<italic>R</italic>⌉</p></list-item><list-item><p id="Par25"><italic>T</italic> - the threshold to be checked (especially for noisy images); its value usually is positive.</p></list-item></list>
<fig id="Figo"><label>Listing 1</label><caption><p>The Statistical Dominance Algorithm</p></caption><graphic xlink:href="12021_2017_9340_Figo_HTML" id="MO1"/></fig>
</p>
      <p id="Par26">The SDA algorithm for each pixel statistically determines its reference in the neighborhood. If a point dominates most of the surrounding points, it is qualified as a fragment of the sought object; otherwise, it is treated as part of the background. Adjusting the minimum level of brightness accordingly can eliminate background noise. Figure <xref rid="Fig2" ref-type="fig">2</xref> shows an illustrative picture of a sample bitmap that assumes dark colors for objects (levels 0, 10, ...) and bright for background (levels 90, 80, ...). The fragment of the input image (see Fig. <xref rid="Fig3" ref-type="fig">2</xref>a) contains four different objects:
<list list-type="bullet"><list-item><p id="Par27">in the upper left: fragment of larger, uniform tissue (or aggregation of objects);
</p></list-item><list-item><p id="Par28">in the lower left corner: regular cell, with lighter luminance;</p></list-item><list-item><p id="Par29">in the upper right corner: cell with dendrites, with a darker luminance;</p></list-item><list-item><p id="Par30">in the bottom right corner: background luminance unevenness (levels 60–70–80).</p></list-item></list>
<fig id="Fig2"><label>Fig. 2</label><caption><p>The illustrative picture of SDA algorithm processing principles</p></caption><graphic xlink:href="12021_2017_9340_Fig2_HTML" id="MO3"/></fig>
<fig id="Fig3"><label>Fig. 3</label><caption><p>Rat DAPI neural image with the SDA normalisation</p></caption><graphic xlink:href="12021_2017_9340_Fig3_HTML" id="MO5"/></fig>
</p>
      <p id="Par31">Using the SDA algorithm, statistics were calculated for each point of the input image to produce an output image (see Fig. <xref rid="Fig2" ref-type="fig">2</xref>b). The following parameters were adopted: <italic>t</italic>
<italic>h</italic>
<italic>r</italic>
<italic>e</italic>
<italic>s</italic>
<italic>h</italic>
<italic>o</italic>
<italic>l</italic>
<italic>d</italic> = 50 and a disc-shaped mask with radius <italic>R</italic> = 3.75 (see Fig. <xref rid="Fig2" ref-type="fig">2</xref>c) that covers an area of 45 pixels (output range: 0–45). By analyzing the received statistics the following can be concluded: 
<list list-type="bullet"><list-item><p id="Par32">objects of a small, round shape, regardless of real brightness, are clearly promoted if only the minimum threshold condition is met;</p></list-item><list-item><p id="Par33">both cells have comparable statistical values despite the difference in brightness in the input image; the normalization of these values is shown in the real microscopic image (Fig. <xref rid="Fig3" ref-type="fig">3</xref>b);</p></list-item><list-item><p id="Par34">dendrites have the highest statistical values;</p></list-item><list-item><p id="Par35">uniform larger objects are suppressed and can be removed by simple binarization (Fig. <xref rid="Fig3" ref-type="fig">2</xref>d); this corresponds to the real case presented in Fig. <xref rid="Fig5" ref-type="fig">5</xref>.</p></list-item></list>
</p>
      <p id="Par36">The aforementioned features are quite well suited to biplanar images. In the case of additional interference, spots with a different average brightness than the background (Fig. <xref rid="Fig4" ref-type="fig">4</xref>) can be removed using adaptive binarization, e.g. Otsu.
<fig id="Fig4"><label>Fig. 4</label><caption><p>An example of LGN image processed by the suggested approach using SDA and Otsu</p></caption><graphic xlink:href="12021_2017_9340_Fig4_HTML" id="MO6"/></fig>
</p>
      <p id="Par37">The above considerations show that the characteristics of the SDA algorithm justify its use in the analysis of nerve cells. Preliminary studies have shown the utility of segmentation algorithms in other tissues and histopathological images for which classical methods such as Otsu or adaptive thresholding do not provide accurate solutions (Kowal et al. <xref ref-type="bibr" rid="CR29">2013</xref>).</p>
      <p id="Par38">As described, it is necessary to set two parameters: the size of the neighborhood, specified by radius <italic>R</italic> (which defines a circular neighborhood), and minimal difference threshold <italic>T</italic>, which is analogous to the binarization threshold <italic>H</italic> exploited in H-minima. In the case of the neighborhood radius, the procedure is similar to the one used in background subtraction: usually a radius two or three times longer than the object is sufficient and testing for larger values does not change the outcome (this is presented more precisely in “<xref rid="Sec7" ref-type="sec">Comparison of Object Detection Methods</xref>”). The selection of thresholding value, as in H-minima, also demands operator interaction. However, some datasets containing large groups of images give similar, stable results for the same parameter settings (a group of images accessible at BrainMaps (<xref ref-type="bibr" rid="CR4">2005</xref>) was used for verification). The novel approach implemented in CAS assumes exploitation of the SDA algorithm in the background subtraction stage, followed by manual or automatic application of global or adaptive binarization. The image obtained from SDA should also be binarized, which can be done automatically (in the case of CAS, the Otsu method is suggested as it can remove some types of disturbance; refer to Fig. <xref rid="Fig4" ref-type="fig">4</xref>), or the global threshold can be set manually. The presented research focuses on object detection with the application of SDA, whose compatibility with other techniques has been proved.</p>
      <p id="Par39">The main advantage of SDA compared to other techniques is the representation of objects not as a binary map, but as an estimation of the probability that each pixel belongs to the object. This is well visualized in Fig. <xref rid="Fig5" ref-type="fig">5</xref>.
<fig id="Fig5"><label>Fig. 5</label><caption><p>Example of SDA (<bold>c</bold>,<bold>d</bold>) over performance on standard segmentation methods (<bold>b</bold>) for cell detection. Image is taken from work (Mikula et al. <xref ref-type="bibr" rid="CR36">2007</xref>) and presents the sagittal section of the molecular layer, Nissl stained in cerebellum brain of the cat characterised by uneven nuclei distribution</p></caption><graphic xlink:href="12021_2017_9340_Fig5_HTML" id="MO4"/></fig>
</p>
      <p id="Par40">This image is too difficult for the standard object segmentation method, but was successfully segmented by applying SDA. The complex input data (see Fig. <xref rid="Fig5" ref-type="fig">5</xref>a) shows sagittal sections of cerebellum cut on a Leica microtome and stained with cresyl violet. The greatest challenge here is the presence of different tissues in the image. The standard approach based on binarization does not correctly segment the cells from the (darker) tissue – the granular layer – regardless of whether the manual or automatic global thresholding method implemented in ImageJ/Fiji is used. An example of the outcome is depicted in Fig. <xref rid="Fig5" ref-type="fig">5</xref>b. Since the SDA’s output gives greyscale values (see light-grey and dark-grey objects in Fig. <xref rid="Fig5" ref-type="fig">5</xref>c), it was possible to continue with further segmentation and select an appropriate threshold in order to obtain accurate cell detection, as annotated on the original image in Fig. <xref rid="Fig5" ref-type="fig">5</xref>c. This feature proves the attractiveness of the SDA method for semi-automatic segmentation of cells in nerve tissues (Kopacz &amp; Piorkowski <xref ref-type="bibr" rid="CR28">2017</xref>). The presented solution does not perform automatic segmentation of clustered nuclei; although this problem is still unresolved, some approaches are addressed by (Koyuncu et al. <xref ref-type="bibr" rid="CR30">2016</xref>; Jung &amp; Kim <xref ref-type="bibr" rid="CR23">2010</xref>; Cheng et al. <xref ref-type="bibr" rid="CR8">2009</xref>; Gertych et al. <xref ref-type="bibr" rid="CR14">2012</xref>; Skobel et al. <xref ref-type="bibr" rid="CR55">2017</xref>).</p>
    </sec>
    <sec id="Sec7">
      <title>Comparison of Object Detection Methods</title>
      <p id="Par41">In order to choose a method for further processing, the agreement in object detection in biplanar microscopic images was evaluated. Good quality resolution of objects and backgrounds was assured in all examples. For the standard approach, the global threshold was selected manually to assure correct segmentation. The radius applied in background subtraction methods and SDA was set to 50 pixels.</p>
      <p id="Par42">The goal of the first experiment was to evaluate the similarity of object segmentation masks achieved for various threshold values applied for standard and SDA methods. A similar problem was presented by (Ekstrom et al. <xref ref-type="bibr" rid="CR12">2016</xref>), but with lower precision. Here, the tests were performed on images presenting the LGN and perigeniculate nucleus PGN of 123-day-old cats acquired with a Leica MDI6000 inverted fluorescence microscope (Fig. <xref rid="Fig6" ref-type="fig">6</xref>a shows an example.). The coincidence of object detection was evaluated using the Dice coefficient (Dice <xref ref-type="bibr" rid="CR10">1945</xref>), which is expressed by following formula:
<disp-formula id="Equ1"><label>1</label><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \text{Dice} = \frac{2\cdot TP}{2 \cdot TP + FP + FN}, $$\end{document}</tex-math><mml:math id="M2"><mml:mtext>Dice</mml:mtext><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mo>⋅</mml:mo><mml:mi>TP</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>⋅</mml:mo><mml:mi>TP</mml:mi><mml:mo>+</mml:mo><mml:mi>FP</mml:mi><mml:mo>+</mml:mo><mml:mi>FN</mml:mi></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:math><graphic xlink:href="12021_2017_9340_Article_Equ1.gif" position="anchor"/></alternatives></disp-formula>where <italic>TP</italic> stands for true positives (count of pixels belonging to objects), <italic>FP</italic> describes false positives (count of pixels wrongly assigned to the object), and <italic>FN</italic> is a false negative (count of object pixels which were wrongly assigned to the background). In medical research, coefficient values above 0.9 are assumed to have good correspondence. Figure <xref rid="Fig6" ref-type="fig">6</xref>b presents a 3D plot in which varying threshold values are given on the X and Y axes, while the Dice coefficient score change is presented by the surface. It can be observed that for several threshold combinations, the coefficient value reaches and exceeds 0.8–0.9; the maximum value of 0.99 clearly shows that both methods can be applied interchangeably.
<fig id="Fig6"><label>Fig. 6</label><caption><p>Different aspects of SDA superiority over standards methods</p></caption><graphic xlink:href="12021_2017_9340_Fig6_HTML" id="MO7"/></fig>
</p>
      <p id="Par43">We then concentrated on the relation between SDA parameters applied for images of objects of varying sizes. The influence of varying radius on detected object area is presented in Fig. <xref rid="Fig6" ref-type="fig">6</xref>d for the image presented in Fig. <xref rid="Fig6" ref-type="fig">6</xref>c, which was taken from a public dataset prepared for the Nucleus Counting Challenge competition that took place at the 2015 BioImage Informatics Conference. From this plot, one can see that the outcome stabilizes for radii above 20 pixels; the bigger the detected threshold value, the smaller the influence of data size. Of course, when the image is resized, the radius should be scaled as well. Moreover, the radius is always related to the object size, but the relation to the threshold value is nevertheless maintained.</p>
      <p id="Par44">The suggested methodology for object segmentation has been also tested on various tissues taken from an interactive multi-resolution brain atlas (BrainMaps <xref ref-type="bibr" rid="CR4">2005</xref>; Mikula et al. <xref ref-type="bibr" rid="CR36">2007</xref>). This database provided us with tissues from various species prepared using different types of staining; this gave a good overview of the possible problems that should be addressed in the developed tool. Using CAS, it was possible to perform segmentation quickly (about 2 minutes per slice), as presented in Fig. <xref rid="Fig7" ref-type="fig">7</xref>, while the parameters set in the program are gathered in Table <xref rid="Tab1" ref-type="table">1</xref>. As one can see, the program enables accurate segmentation and labeling of objects regardless of their shape and the input data type.
<fig id="Fig7"><label>Fig. 7</label><caption><p>Examples of object segmentaton with CAS on images presenting various tissues with diverse stainig. The exemplary data was gathered from BrainMaps (<xref ref-type="bibr" rid="CR4">2005</xref>). The description contains – spieces: stain, plane, methodx</p></caption><graphic xlink:href="12021_2017_9340_Fig7_HTML" id="MO8"/></fig>
<table-wrap id="Tab1"><label>Table 1</label><caption><p>CAS parameters for which the results presented in Fig. <xref rid="Fig7" ref-type="fig">7</xref> were obtained</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Figure <xref rid="Fig7" ref-type="fig">7</xref>
</th><th align="left">Specie</th><th align="left">SDA R</th><th align="left">SDA T</th><th align="left">Binarisation</th><th align="left">Area</th><th align="left">Dendrites</th></tr></thead><tbody><tr><td align="left">a</td><td align="left">the makaka</td><td align="left">40</td><td align="left">30</td><td align="left">Otsu</td><td align="left">40</td><td align="left">3</td></tr><tr><td align="left">b</td><td align="left">the human</td><td align="left">70</td><td align="left">70</td><td align="left">Otsu</td><td align="left">100</td><td align="left">3</td></tr><tr><td align="left">c</td><td align="left">the mouse</td><td align="left">40</td><td align="left">13</td><td align="left">Otsu</td><td align="left">40</td><td align="left">3</td></tr><tr><td align="left">d</td><td align="left">the grivet</td><td align="left">40</td><td align="left">25</td><td align="left">Otsu</td><td align="left">10</td><td align="left">3</td></tr><tr><td align="left">e</td><td align="left">the titi monkey</td><td align="left">40</td><td align="left">40</td><td align="left">Otsu</td><td align="left">90</td><td align="left">3</td></tr><tr><td align="left">f</td><td align="left">the titi monkey</td><td align="left">50</td><td align="left">50</td><td align="left">Otsu</td><td align="left">120</td><td align="left">3</td></tr></tbody></table></table-wrap>
</p>
    </sec>
    <sec id="Sec8">
      <title>Discussion</title>
      <p id="Par45">The presented experiments and considerations address all the problems encountered in achieving accurate object segmentation in microscopic images of various tissues. From the elaborated results, it was decided that the CAS tool should interpret input images using only one data channel. The SDA was suggested as a segmentation method; however, to maintain compatibility with other research tools, the extended H-minima is also accessible. Finally, setting method parameters demands knowledge about object size, which for method radius is straightforward, while the SDA threshold should be adjusted and the final binarisation threshold can be chosen automatically using the Otsu approach.</p>
    </sec>
  </sec>
  <sec id="Sec9">
    <title>Shape Parameters</title>
    <p id="Par46">It is not sufficient to develop techniques for automatic detection of objects in images: in most tasks, especially when general insight into object population is sought, this is the starting point for further analysis which demands thorough inspection of object features. Depending on the requirements, the desired characteristics vary, yet in general they concentrate on basic shape features which allow analysis of not only circularity or elongation, but also spatial and size distribution within a sample. This area of research is very tiresome, therefore automation is of great importance. Below, several shape parameters implemented in CAS are detailed and an interpretation is given with some examples.</p>
    <sec id="Sec10">
      <title>General Features</title>
      <p id="Par47">The area and perimeter of an object are computed in order to obtain general information about the detected cell soma or cell nucleus (for complex shapes a fractal area could be considered Mazurek and Oszutowska-Mazurek <xref ref-type="bibr" rid="CR34">2014</xref>). Initially, the number of pixels belonging to the object is treated as the area value; similarly, pixels on the object boundary form the perimeter. However, for convenience it is also possible to compute these features in real units if this information was stored during data collection. Figure <xref rid="Fig8" ref-type="fig">8</xref> presents an exemplary cell with the perimeter denoted by a white line, while Table <xref rid="Tab2" ref-type="table">2</xref> contains general features. The next feature – a centroid – holds information about object placement in the entire image. However, when necessary, it is possible in CAS to define start (<italic>x</italic> = 0<italic>%</italic>) and end (<italic>x</italic> = 100<italic>%</italic>) reference points and recalculate the x centroid coefficient for all objects.
<fig id="Fig8"><label>Fig. 8</label><caption><p>Exemplary neural cell with marked perimeter by white line</p></caption><graphic xlink:href="12021_2017_9340_Fig8_HTML" id="MO9"/></fig>
<table-wrap id="Tab2"><label>Table 2</label><caption><p>General features computed for exemplary neural cell presented in Fig. <xref rid="Fig8" ref-type="fig">8</xref>
</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Feature</th><th align="left">Value</th></tr></thead><tbody><tr><td align="left">Area [<italic>μ</italic>
<italic>m</italic>
<sup>2</sup>]</td><td align="left">145.90</td></tr><tr><td align="left">Perimeter [<italic>μ</italic>
<italic>m</italic>]</td><td align="left">61.12</td></tr><tr><td align="left">Centroid (x,y)</td><td align="left">(392, 104)</td></tr><tr><td align="left">Average brightness</td><td align="left">93.04</td></tr><tr><td align="left">Relative brightness</td><td align="left">0.36</td></tr></tbody></table></table-wrap>
</p>
      <p id="Par48">Other global information about an object is provided by its intensity. The average brightness is defined for image <italic>I</italic> as the average intensity of all pixels <italic>p</italic> that belong to the object:
<disp-formula id="Equ2"><label>2</label><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \mathrm{Avg.B} = \frac{1}{|p|}\sum\limits_{p}{I(p)}. $$\end{document}</tex-math><mml:math id="M4"><mml:mstyle mathvariant="normal"><mml:mi>Avg</mml:mi><mml:mn>.</mml:mn><mml:mi>B</mml:mi></mml:mstyle><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mi>p</mml:mi><mml:mo>|</mml:mo></mml:mrow></mml:mfrac><mml:munder><mml:mrow><mml:mi>∑</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:munder><mml:mi>I</mml:mi><mml:mo>(</mml:mo><mml:mi>p</mml:mi><mml:mo>)</mml:mo><mml:mn>.</mml:mn></mml:math><graphic xlink:href="12021_2017_9340_Article_Equ2.gif" position="anchor"/></alternatives></disp-formula>Since the intensities may vary depending on the data sampling procedure, this measure is very subjective when comparison between samples is considered. Therefore, a reference brightness was defined for which a reference intensity RI denoted by the user is exploited in order to obtain objective object brightness information:
<disp-formula id="Equ3"><label>3</label><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \mathrm{Ref.B} = \frac{\mathrm{Avg.B} - \text{RI}}{\mathrm{Avg.B} + \text{RI}}. $$\end{document}</tex-math><mml:math id="M6"><mml:mstyle mathvariant="normal"><mml:mi>Ref</mml:mi><mml:mn>.</mml:mn><mml:mi>B</mml:mi></mml:mstyle><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mstyle mathvariant="normal"><mml:mi>Avg</mml:mi><mml:mn>.</mml:mn><mml:mi>B</mml:mi></mml:mstyle><mml:mo>−</mml:mo><mml:mtext>RI</mml:mtext></mml:mrow><mml:mrow><mml:mstyle mathvariant="normal"><mml:mi>Avg</mml:mi><mml:mn>.</mml:mn><mml:mi>B</mml:mi></mml:mstyle><mml:mo>+</mml:mo><mml:mtext>RI</mml:mtext></mml:mrow></mml:mfrac><mml:mn>.</mml:mn></mml:math><graphic xlink:href="12021_2017_9340_Article_Equ3.gif" position="anchor"/></alternatives></disp-formula>
</p>
    </sec>
    <sec id="Sec11">
      <title>Circularity Measures</title>
      <p id="Par49">An object’s shape is described by topological attributes (Russ <xref ref-type="bibr" rid="CR49">1998</xref>; Gonzalez &amp; Woods <xref ref-type="bibr" rid="CR16">2001</xref>; Jahne <xref ref-type="bibr" rid="CR22">2002</xref>), of which only those not affected by translation and rotation were chosen in this research. These have found applications in research, where shape plays an important role (Nurzynska et al. <xref ref-type="bibr" rid="CR41">2013</xref>; Nurzynska &amp; Piorkowski <xref ref-type="bibr" rid="CR40">2016</xref>; Piorkowski et al. <xref ref-type="bibr" rid="CR47">2017</xref>). The formulation of many attributes exploits information about area <italic>A</italic> and perimeter <italic>P</italic> to define a circularity measure. Here are some examples implemented in the described software:
<disp-formula id="Equ4"><label>4</label><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{array}{@{}rcl@{}} C_{1} &amp;=&amp; \frac{4 \cdot \pi \cdot A}{P^{2}}, \end{array} $$\end{document}</tex-math><mml:math id="M8"><mml:mtable class="eqnarray" columnalign="right center left"><mml:mtr><mml:mtd class="eqnarray-1"><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mtd><mml:mtd class="eqnarray-2"><mml:mo>=</mml:mo></mml:mtd><mml:mtd class="eqnarray-3"><mml:mfrac><mml:mrow><mml:mn>4</mml:mn><mml:mo>⋅</mml:mo><mml:mi>π</mml:mi><mml:mo>⋅</mml:mo><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math><graphic xlink:href="12021_2017_9340_Article_Equ4.gif" position="anchor"/></alternatives></disp-formula>
<disp-formula id="Equ5"><label>5</label><alternatives><tex-math id="M9">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{array}{@{}rcl@{}} C_{2} &amp;=&amp; \frac{P^{2}}{A}, \end{array} $$\end{document}</tex-math><mml:math id="M10"><mml:mtable class="eqnarray" columnalign="right center left"><mml:mtr><mml:mtd class="eqnarray-1"><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mtd><mml:mtd class="eqnarray-2"><mml:mo>=</mml:mo></mml:mtd><mml:mtd class="eqnarray-3"><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math><graphic xlink:href="12021_2017_9340_Article_Equ5.gif" position="anchor"/></alternatives></disp-formula>
<disp-formula id="Equ6"><label>6</label><alternatives><tex-math id="M11">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{array}{@{}rcl@{}} C_{3} &amp;=&amp; \frac{2 \cdot \pi \cdot A}{P}, \end{array} $$\end{document}</tex-math><mml:math id="M12"><mml:mtable class="eqnarray" columnalign="right center left"><mml:mtr><mml:mtd class="eqnarray-1"><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:mtd><mml:mtd class="eqnarray-2"><mml:mo>=</mml:mo></mml:mtd><mml:mtd class="eqnarray-3"><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mo>⋅</mml:mo><mml:mi>π</mml:mi><mml:mo>⋅</mml:mo><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math><graphic xlink:href="12021_2017_9340_Article_Equ6.gif" position="anchor"/></alternatives></disp-formula>
<disp-formula id="Equ7"><label>7</label><alternatives><tex-math id="M13">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{array}{@{}rcl@{}} C_{4} &amp;=&amp; \frac{P}{\pi}, \end{array} $$\end{document}</tex-math><mml:math id="M14"><mml:mtable class="eqnarray" columnalign="right center left"><mml:mtr><mml:mtd class="eqnarray-1"><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>4</mml:mn></mml:mrow></mml:msub></mml:mtd><mml:mtd class="eqnarray-2"><mml:mo>=</mml:mo></mml:mtd><mml:mtd class="eqnarray-3"><mml:mfrac><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>π</mml:mi></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math><graphic xlink:href="12021_2017_9340_Article_Equ7.gif" position="anchor"/></alternatives></disp-formula>
<disp-formula id="Equ8"><label>8</label><alternatives><tex-math id="M15">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{array}{@{}rcl@{}} C_{5} &amp;=&amp; \frac{A_{MAX}}{P}, \end{array} $$\end{document}</tex-math><mml:math id="M16"><mml:mtable class="eqnarray" columnalign="right center left"><mml:mtr><mml:mtd class="eqnarray-1"><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>5</mml:mn></mml:mrow></mml:msub></mml:mtd><mml:mtd class="eqnarray-2"><mml:mo>=</mml:mo></mml:mtd><mml:mtd class="eqnarray-3"><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>MAX</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>P</mml:mi></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math><graphic xlink:href="12021_2017_9340_Article_Equ8.gif" position="anchor"/></alternatives></disp-formula>
<disp-formula id="Equ9"><label>9</label><alternatives><tex-math id="M17">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{array}{@{}rcl@{}} \text{Malinowska} &amp;=&amp; \frac{P}{2\sqrt{\pi \cdot A}} - 1, \end{array} $$\end{document}</tex-math><mml:math id="M18"><mml:mtable class="eqnarray" columnalign="right center left"><mml:mtr><mml:mtd class="eqnarray-1"><mml:mtext>Malinowska</mml:mtext></mml:mtd><mml:mtd class="eqnarray-2"><mml:mo>=</mml:mo></mml:mtd><mml:mtd class="eqnarray-3"><mml:mfrac><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:msqrt><mml:mrow><mml:mi>π</mml:mi><mml:mo>⋅</mml:mo><mml:mi>A</mml:mi></mml:mrow></mml:msqrt></mml:mrow></mml:mfrac><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math><graphic xlink:href="12021_2017_9340_Article_Equ9.gif" position="anchor"/></alternatives></disp-formula>
<disp-formula id="Equ10"><label>10</label><alternatives><tex-math id="M19">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{array}{@{}rcl@{}} \text{Roundness} &amp;=&amp; \frac{4 \cdot A}{\pi \cdot M_{AXIS}^{2}}, \end{array} $$\end{document}</tex-math><mml:math id="M20"><mml:mtable class="eqnarray" columnalign="right center left"><mml:mtr><mml:mtd class="eqnarray-1"><mml:mtext>Roundness</mml:mtext></mml:mtd><mml:mtd class="eqnarray-2"><mml:mo>=</mml:mo></mml:mtd><mml:mtd class="eqnarray-3"><mml:mfrac><mml:mrow><mml:mn>4</mml:mn><mml:mo>⋅</mml:mo><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>π</mml:mi><mml:mo>⋅</mml:mo><mml:msubsup><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>AXIS</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math><graphic xlink:href="12021_2017_9340_Article_Equ10.gif" position="anchor"/></alternatives></disp-formula>
<disp-formula id="Equ11"><label>11</label><alternatives><tex-math id="M21">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{array}{@{}rcl@{}} \text{Roughness} &amp;=&amp; 2 \cdot \sqrt{\frac{A}{\pi}}, \end{array} $$\end{document}</tex-math><mml:math id="M22"><mml:mtable class="eqnarray" columnalign="right center left"><mml:mtr><mml:mtd class="eqnarray-1"><mml:mtext>Roughness</mml:mtext></mml:mtd><mml:mtd class="eqnarray-2"><mml:mo>=</mml:mo></mml:mtd><mml:mtd class="eqnarray-3"><mml:mn>2</mml:mn><mml:mo>⋅</mml:mo><mml:msqrt><mml:mrow><mml:mfrac><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>π</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:msqrt><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math><graphic xlink:href="12021_2017_9340_Article_Equ11.gif" position="anchor"/></alternatives></disp-formula>
<disp-formula id="Equ12"><label>12</label><alternatives><tex-math id="M23">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{array}{@{}rcl@{}} \text{Shapeless} &amp;=&amp; \frac{P^{2}}{4 \cdot \pi \cdot A}, \end{array} $$\end{document}</tex-math><mml:math id="M24"><mml:mtable class="eqnarray" columnalign="right center left"><mml:mtr><mml:mtd class="eqnarray-1"><mml:mtext>Shapeless</mml:mtext></mml:mtd><mml:mtd class="eqnarray-2"><mml:mo>=</mml:mo></mml:mtd><mml:mtd class="eqnarray-3"><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mn>4</mml:mn><mml:mo>⋅</mml:mo><mml:mi>π</mml:mi><mml:mo>⋅</mml:mo><mml:mi>A</mml:mi></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math><graphic xlink:href="12021_2017_9340_Article_Equ12.gif" position="anchor"/></alternatives></disp-formula>where <italic>A</italic>
<sub><italic>M</italic><italic>A</italic><italic>X</italic></sub> is a maximal area calculated as a multiplication of the maximal width and height of the object, and <italic>M</italic>
<sub><italic>A</italic><italic>X</italic><italic>I</italic><italic>S</italic></sub> is the length of the major axis of an object.</p>
      <p id="Par50">Table <xref rid="Tab3" ref-type="table">3</xref> presents examples of various shapes and their calculated features. The objects are ordered by ascending area size to better check the influence of scale on the result. It can be observed that in case of the <italic>C</italic>
<sub>1</sub> parameter, a value equal to 1 corresponds to a circular shape, while a smaller value corresponds to a more elongated shape. In contrast, smaller values of <italic>C</italic>
<sub>2</sub> and <italic>C</italic>
<sub>3</sub> better describe round shapes, while bigger values are obtained for elongated ones.
<table-wrap id="Tab3"><label>Table 3</label><caption><p>Topological features computed for different cells</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Feature</th><th align="left">A [ <italic>μ</italic>
<italic>m</italic>
<sup>2</sup>]</th><th align="left">P [ <italic>μ</italic>
<italic>m</italic>]</th><th align="left"><italic>C</italic><sub>1</sub></th><th align="left"><italic>C</italic><sub>2</sub></th><th align="left"><italic>C</italic><sub>3</sub></th><th align="left"><italic>C</italic><sub>4</sub></th><th align="left"><italic>C</italic><sub>5</sub></th><th align="left">Malinowska</th><th align="left">Roundness</th><th align="left">Roughness</th><th align="left">Shapeless</th></tr></thead><tbody><tr><td align="left"><inline-graphic xlink:href="12021_2017_9340_Figa_HTML.gif" id="d29e1759"/></td><td align="left">1</td><td align="left">4</td><td align="left">0.79</td><td align="left">16</td><td align="left">1.57</td><td align="left">1.27</td><td align="left">0.5</td><td align="left">0.13</td><td align="left">0.64</td><td align="left">1.13</td><td align="left">1.27</td></tr><tr><td align="left"><inline-graphic xlink:href="12021_2017_9340_Figb_HTML.gif" id="d29e1800"/></td><td align="left">1.57</td><td align="left">4.84</td><td align="left">0.84</td><td align="left">15</td><td align="left">2.04</td><td align="left">1.54</td><td align="left">0.41</td><td align="left">0.09</td><td align="left">0.50</td><td align="left">1.41</td><td align="left">1.19</td></tr><tr><td align="left"><inline-graphic xlink:href="12021_2017_9340_Figc_HTML.gif" id="d29e1841"/></td><td align="left">3.14</td><td align="left">8.58</td><td align="left">0.54</td><td align="left">23</td><td align="left">2.30</td><td align="left">2.73</td><td align="left">0.47</td><td align="left">0.37</td><td align="left">0.25</td><td align="left">2.00</td><td align="left">1.87</td></tr><tr><td align="left"><inline-graphic xlink:href="12021_2017_9340_Figd_HTML.gif" id="d29e1882"/></td><td align="left">3.14</td><td align="left">6.28</td><td align="left">1.00</td><td align="left">13</td><td align="left">3.14</td><td align="left">2.00</td><td align="left">0.32</td><td align="left">0.00</td><td align="left">1.00</td><td align="left">2.00</td><td align="left">1.00</td></tr><tr><td align="left"><inline-graphic xlink:href="12021_2017_9340_Fige_HTML.gif" id="d29e1923"/></td><td align="left">75.12</td><td align="left">53.38</td><td align="left">0.33</td><td align="left">37</td><td align="left">22</td><td align="left">43</td><td align="left">179</td><td align="left">0.74</td><td align="left">0.42</td><td align="left">25</td><td align="left">3.02</td></tr><tr><td align="left"><inline-graphic xlink:href="12021_2017_9340_Figf_HTML.gif" id="d29e1964"/></td><td align="left">83.20</td><td align="left">44.49</td><td align="left">0.53</td><td align="left">23</td><td align="left">30</td><td align="left">36</td><td align="left">501</td><td align="left">0.38</td><td align="left">0.58</td><td align="left">26</td><td align="left">1.89</td></tr><tr><td align="left"><inline-graphic xlink:href="12021_2017_9340_Figg_HTML.gif" id="d29e2005"/></td><td align="left">84.55</td><td align="left">61.51</td><td align="left">0.28</td><td align="left">44</td><td align="left">22</td><td align="left">50</td><td align="left">92</td><td align="left">0.89</td><td align="left">0.40</td><td align="left">26</td><td align="left">3.56</td></tr><tr><td align="left"><inline-graphic xlink:href="12021_2017_9340_Figh_HTML.gif" id="d29e2046"/></td><td align="left">92.93</td><td align="left">47.19</td><td align="left">0.52</td><td align="left">23</td><td align="left">31</td><td align="left">38</td><td align="left">581</td><td align="left">0.38</td><td align="left">0.42</td><td align="left">28</td><td align="left">1.91</td></tr><tr><td align="left"><inline-graphic xlink:href="12021_2017_9340_Figi_HTML.gif" id="d29e2087"/></td><td align="left">94.57</td><td align="left">50.68</td><td align="left">0.46</td><td align="left">27</td><td align="left">30</td><td align="left">41</td><td align="left">1294</td><td align="left">0.47</td><td align="left">0.73</td><td align="left">28</td><td align="left">2.16</td></tr><tr><td align="left"><inline-graphic xlink:href="12021_2017_9340_Figj_HTML.gif" id="d29e2128"/></td><td align="left">139.16</td><td align="left">50.68</td><td align="left">0.68</td><td align="left">18</td><td align="left">44</td><td align="left">41</td><td align="left">490</td><td align="left">0.21</td><td align="left">0.73</td><td align="left">34</td><td align="left">1.47</td></tr><tr><td align="left"><inline-graphic xlink:href="12021_2017_9340_Figk_HTML.gif" id="d29e2169"/></td><td align="left">145.90</td><td align="left">61.12</td><td align="left">0.49</td><td align="left">25</td><td align="left">38</td><td align="left">50</td><td align="left">316</td><td align="left">0.43</td><td align="left">0.68</td><td align="left">35</td><td align="left">2.04</td></tr><tr><td align="left"><inline-graphic xlink:href="12021_2017_9340_Figl_HTML.gif" id="d29e2211"/></td><td align="left">184.06</td><td align="left">74.66</td><td align="left">0.41</td><td align="left">30</td><td align="left">40</td><td align="left">61</td><td align="left">176</td><td align="left">0.55</td><td align="left">0.37</td><td align="left">39</td><td align="left">2.41</td></tr><tr><td align="left"><inline-graphic xlink:href="12021_2017_9340_Figm_HTML.gif" id="d29e2252"/></td><td align="left">237.03</td><td align="left">76.59</td><td align="left">0.51</td><td align="left">24</td><td align="left">50</td><td align="left">63</td><td align="left">1168</td><td align="left">0.40</td><td align="left">0.58</td><td align="left">44</td><td align="left">1.97</td></tr><tr><td align="left"><inline-graphic xlink:href="12021_2017_9340_Fign_HTML.gif" id="d29e2293"/></td><td align="left">257.98</td><td align="left">120.30</td><td align="left">0.22</td><td align="left">56</td><td align="left">34</td><td align="left">98</td><td align="left">423</td><td align="left">1.11</td><td align="left">0.27</td><td align="left">46</td><td align="left">4.46</td></tr></tbody></table></table-wrap>
</p>
      <p id="Par51">It is difficult to find a pattern in which <italic>C</italic>
<sub>4</sub>, <italic>C</italic>
<sub>5</sub>, and Roughness are considered. The results gathered for <italic>C</italic>
<sub>4</sub> seem completely unrelated to the shape, as one can see that using only the circumference for description is insufficient. A similar observation is also seen for the Roughness parameter, for which only area was exploited in the calculation. However, for <italic>C</italic>
<sub>5</sub>, the feature value is still strongly related to the object size, yet smaller values represent more circular shapes when objects with comparable area are considered (for instance, check the outcomes in rows 4–6, 7 with 8, etc.).</p>
      <p id="Par52">Next, when the Malinowska parameter is taken into account, values close to 0 describe circular objects, while higher values are related to longer shapes; this is also true of the Shapeless parameter. Moreover, we can additionally state that this works inversely for <italic>C</italic>
<sub>1</sub> when the formulas are compared. Finally, Roundness is equal to 1 for circular objects and gets smaller for longer shapes.</p>
    </sec>
    <sec id="Sec12">
      <title>Other</title>
      <p id="Par53">The last group of parameters that describe objects should help to organize this data and obtain more spatial information about it. First of all, it is possible to mark a region (bigger patch) on the image and work only with the objects belonging to it. Such a region can be automatically divided into three perpendicular horizontal layers. Next, for each object the major and minor axes are found. Here, two algorithms are exploited:</p>
      <p>
        <def-list>
          <def-item>
            <term>Ellipse Fit</term>
            <def>
              <p id="Par54">– chooses the best fitted ellipse that can be inscribed in the object. The major and minor axes correspond to those of the ellipse. Moreover, the centroid can be recalculated to overlap the ellipse center point.</p>
            </def>
          </def-item>
          <def-item>
            <term>Feret</term>
            <def>
              <p id="Par55">– a shape feature parameter that computes the relation between the two longest and perpendicular dimensions of an object. Principal component analysis (PCA) is exploited to gather the results. The major axis corresponds to the direction of the first eigenvector; the minor axis is related to the second one.</p>
            </def>
          </def-item>
        </def-list>
      </p>
      <p id="Par56">In both cases, the reference angle is computed as the angle between the object’s major axis and the image’s x-axis. This is used to position objects better in the input data.</p>
    </sec>
  </sec>
  <sec id="Sec13">
    <title>Case Study</title>
    <sec id="Sec14">
      <title>Data Processing Example</title>
      <p id="Par57">Comprehensive investigation of cell populations is especially needed in sophisticated structures in which characteristics of neurons are dependent upon their location. A good example is the LGN of cats; this is the visual thalamic nucleus, which provides the main transmission of information from the retina to the primary visual cortex. The LGN has a 6-layered structure in which the principal ones, A, A1, and C <sub>M</sub> receive input from different eyes: the ipsilateral side (A1) and the contralateral side (A, C <sub>M</sub>) (Payne and Peters, <xref ref-type="bibr" rid="CR45">2002</xref>, pp. 5–9). Moreover, the retinal afferents from different parts of the visual space project to the LGN, thus forming a highly ordered map—the so-called visuotopic map (Sanderson <xref ref-type="bibr" rid="CR50">1971</xref>)—which is depicted in Fig. <xref rid="Fig9" ref-type="fig">9</xref>. There is a lot of information in the literature about the non-uniform distribution of neurons in LGN layers according to their functional features (Bowling &amp; Wieniawa-Narkiewicz <xref ref-type="bibr" rid="CR3">1986</xref>; LeVay <xref ref-type="bibr" rid="CR32">1977</xref>; Mitzdorf &amp; Singer <xref ref-type="bibr" rid="CR37">1977</xref>). For example, particular types of LGN relay cells—so-called Y cells (Burnat et al. <xref ref-type="bibr" rid="CR5">2002</xref>; Kaplan <xref ref-type="bibr" rid="CR26">2014</xref>; Schiller <xref ref-type="bibr" rid="CR51">2010</xref>)—tend to be located close to the interlaminar borders of layers A and A1 (Bickford et al. <xref ref-type="bibr" rid="CR2">1998</xref>; Bowling &amp; Wieniawa-Narkiewicz <xref ref-type="bibr" rid="CR3">1986</xref>; Mitzdorf &amp; Singer <xref ref-type="bibr" rid="CR37">1977</xref>); in general, they tend to be located in the representation of the visual field periphery (Hoffmann et al. <xref ref-type="bibr" rid="CR19">1972</xref>; LeVay <xref ref-type="bibr" rid="CR32">1977</xref>). Herein, we used LGN slices labeled with a specific Y cell marker for demonstration of CAS: SMI-32 antibodies (labeling nonphosphorylated heavy-chain neurofilament proteins) (Bickford et al. <xref ref-type="bibr" rid="CR2">1998</xref>; Carden et al. <xref ref-type="bibr" rid="CR6">2000</xref>). These antibodies visualize the cell soma and proximal dendrites of immunopositive cells. They are complex to detect because the cell soma is often labeled unevenly and the unvisualized nucleus disturbs the outline of the soma.
<fig id="Fig9"><label>Fig. 9</label><caption><p>The scheme of the frontal slice of the LGN with aligned visuotopic coordinates (Sanderson <xref ref-type="bibr" rid="CR50">1971</xref>). A, A1, C <sub>M</sub> layers of the LGN. The visuotopic coordinates assigned in degrees are on the top of the figure</p></caption><graphic xlink:href="12021_2017_9340_Fig9_HTML" id="MO10"/></fig>
</p>
    </sec>
    <sec id="Sec15">
      <title>Histology and Image Acquisition</title>
      <p id="Par58">All experimental procedures were approved by the Ethics Commission of the Pavlov Institute of Physiology. Experiments were performed in strong accordance with the requirements of Council Directive (2010/63/EU) of the European Parliament on the protection of animals used for experimental and other scientific purposes.</p>
      <p id="Par59">All presented research exploits images of the LGN of 123-day-old cats. The animals were perfused transcardially with 0.9% NaCl (0.6L) and 4% paraformaldehyde (1.0L, 0.1M PBS at pH = 7.4) under deep anesthesia (zoletil and xylazine mixture (1:3)). After perfusion, the brain was stored in 20 and 30% sucrose until it sank. The visual thalamus was cut on a freezing microtome into 50 <italic>μ</italic> m frontal sections. Sections were collected in 0.1M PBS, pH = 7.4. Immunohistochemical staining was performed with Vectastain reagents (Vector Laboratories, Peterborough, United Kingdom) in accordance with the manufacturer’s recommendations. One of three primary antibodies was applied for antigen labeling:
<list list-type="bullet"><list-item><p id="Par60">monoclonal mouse primary antibodies to NeuN (Millipore, MAB377, in 1:5000 dilution);</p></list-item><list-item><p id="Par61">monoclonal mouse primary antibodies to non-phosphorylated Neurofilament H (NF-H) (Covance, SMI-32, in 1:3000 dilution);</p></list-item><list-item><p id="Par62">polyclonal rabbit primary antibodies to the parvalbumin (Abcam, ab11427, in 1:10000 dilution).</p></list-item></list>
</p>
      <p id="Par63">The primary antibodies were labeled with:
<list list-type="bullet"><list-item><p id="Par64">Biotinylated secondary antibodies (goat anti-rabbit IgG, BA-1000, or horse anti-mouse IgG, BA-9200; Vector Laboratories, Peterborough, United Kingdom) for further DAB/Ni staining protocol for light microscopy.</p></list-item><list-item><p id="Par65">Fluorochrome-conjugated secondary antibodies (Alexa Fluor488 goat anti-mouse IgG or Alexa Fluor568 goat anti-rabbit IgG, Thermo Fisher Scientific, Waltham, MA, USA) for cell detection with a fluorescence microscope.</p></list-item></list>
</p>
      <p id="Par66">DAB-reacted slices were analyzed with an Olympus microscope (Olympus Corporation, Tokyo, Japan, a 10 × magnification lens) using a Nikon photo camera (Nikon Corporation, Tokyo, Japan). Fluorescent slices were analyzed with a Leica DMI6000 inverted fluorescence microscope (at the Center for Molecular and Cell Technologies, Research Park, St. Petersburg State University).</p>
      <p id="Par67">The image data preparation procedure: 
<list list-type="order"><list-item><p id="Par68">Mark the layer borders.</p></list-item><list-item><p id="Par69">Mark the sub-layer parts of layers.</p></list-item><list-item><p id="Par70">Outline all labelled cells with appropriate parameters one-by-one.</p></list-item><list-item><p id="Par71">Measure data and copy the results to an external file.</p></list-item><list-item><p id="Par72">Complete the measurement file with additional information about the layer, sublayer, cell location, etc.</p></list-item><list-item><p id="Par73">Perform cell distribution normalization on the X axis.</p></list-item><list-item><p id="Par74">Perform cell brightness normalization using a reference region.</p></list-item></list>
</p>
      <p id="Par75">Table <xref rid="Tab4" ref-type="table">4</xref> compares how the analyses of input data were performed before and after the dedicated software was implemented. Actually, in CAS the order of steps is slightly different due to its automatic character. Firstly, parameters necessary for correct cell soma segmentation are sought, followed by manual annotation of layers A, A1 and C <sub>M</sub> (see Fig. <xref rid="Fig10" ref-type="fig">10</xref>b). Next, the automatic procedures compute the three sub-layers and detect cells (see Fig. <xref rid="Fig10" ref-type="fig">10</xref>c). Manual correction is sometimes necessary when several cells are detected as one. In such cases, the software supports division of the object and deletion of unsuitably selected objects and artifacts. It is worth noting that at the end of the selection, the cutting of dendrites can be performed in CAS; therefore, the soma is selected in all cells using uniform parameters. Although, there are solutions which may need to preserve dendrites for visualization of the LGN network (Morgan et al. <xref ref-type="bibr" rid="CR38">2016</xref>). In the case of manual outlining, the cell soma was detected by an operator for each cell in the delineation process. The automatic cell detection procedure, manual correction, and dendrite cutting are shown in Fig. <xref rid="Fig11" ref-type="fig">11</xref>. Next, the reference brightness region and points for spatial normalization are selected. Finally, all prepared data can be saved for further processing. The summary table contains the number and location marks of each cell soma, chosen measurement parameters, and additional normalized data. In addition, the current status of the processed image (with region borders and chosen objects) can be saved in a CSV file for subsequent correction of measurements. Also, the processed image can be saved in two additional forms. The first form has labeled cells with their serial numbers (similar to those in the text file) (Fig. <xref rid="Fig11" ref-type="fig">10</xref>a) and is used for an experimental protocol. The second, depicted in Fig. <xref rid="Fig11" ref-type="fig">10</xref>d, has bordered regions of interest and color dots in the place of labeled cells, which significantly facilitates the primary assessment of cell distribution and subsequent data presentation.
<fig id="Fig10"><label>Fig. 10</label><caption><p>The stages of slice processing with CAS</p></caption><graphic xlink:href="12021_2017_9340_Fig10_HTML" id="MO11"/></fig>
<fig id="Fig11"><label>Fig. 11</label><caption><p>The stages of slice processing</p></caption><graphic xlink:href="12021_2017_9340_Fig11_HTML" id="MO12"/></fig>
<table-wrap id="Tab4"><label>Table 4</label><caption><p>Description how data preparation staps are performed with and without CAS</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Action</th><th align="left">Previous approach</th><th align="left">Cell annotation software</th></tr></thead><tbody><tr><td align="left">1</td><td align="left">Manual</td><td align="left">Manual</td></tr><tr><td align="left">2</td><td align="left">Manual</td><td align="left">Automatic</td></tr><tr><td align="left">3</td><td align="left">Manual</td><td align="left">Semi-manual (needs parameter setting)</td></tr><tr><td align="left">4</td><td align="left">Manual (Excel)</td><td align="left">Automatic (allows parameter selection)</td></tr><tr><td align="left">5</td><td align="left">Manual (Excel)</td><td align="left">Automatic (uses data generated by user)</td></tr><tr><td align="left">6</td><td align="left">Automatic (SPSS)</td><td align="left">Automatic (user sets the normalization coefficients)</td></tr><tr><td align="left">7</td><td align="left">Automatic (SPSS)</td><td align="left">Automatic (user sets the reference region)</td></tr></tbody></table></table-wrap>
</p>
      <p id="Par76">SMI-32 antibodies are just one of many markers used to study the LGN and other neuronal structures. To demonstrate the abilities of the software, we would like to additionally show the detection of small inhibitory interneurons labeled with antibodies against parvalbumin (Stichel et al. <xref ref-type="bibr" rid="CR58">1988</xref>) and all neurons within the LGN labeled with NeuN antibodies (Mullen et al. <xref ref-type="bibr" rid="CR39">1992</xref>). We examined cell detection in images obtained with light and fluorescent microscopes. The original images are shown in Figs. <xref rid="Fig13" ref-type="fig">12</xref>a,c and <xref rid="Fig14" ref-type="fig">13</xref>a,c; the results of detection are shown in Figs. <xref rid="Fig13" ref-type="fig">12</xref>b,d and <xref rid="Fig14" ref-type="fig">13</xref>b,d. The same quality of detection could be achieved in slices prepared for light as for fluorescent microscopy. The parvalbumin positive cells (see Fig. <xref rid="Fig13" ref-type="fig">12</xref>) were easy to detect and manual correction was almost not needed. In the case of NeuN-positive cells (Fig. <xref rid="Fig14" ref-type="fig">13</xref>), the difficulties of cell detection can be seen. The cell borders are detected correctly, but their density does not allow each cell to be recognized separately. This was due to the high neuronal density in the examined nucleus and the use of 50 <italic>μ</italic> m thick slices containing several layers of cells that overlap each other in the resulting image. This was overcome with manual correction tools and the program can still be used to measure restricted sample areas in structures of interest.
<fig id="Fig13"><label>Fig. 12</label><caption><p>The examples of cell detection with CAS. The samples of tissue with parvalbumin positive cells acquired under light (<bold>a</bold>, <bold>b</bold>) and fluorescent (<bold>c</bold>, <bold>d</bold>) microscopes. The original images are on the left and the processed ones on the right</p></caption><graphic xlink:href="12021_2017_9340_Fig12_HTML" id="MO13"/></fig>
<fig id="Fig14"><label>Fig. 13</label><caption><p>The examples of cell detection with CAS. The samples of tissue with NeuN positive cells acquired under light (<bold>a</bold>, <bold>c</bold>, <bold>e</bold>) and fluorescent (<bold>b</bold>, <bold>d</bold>, <bold>f</bold>) microscopes. The original images are on the top and the processed ones on the bottom. The middle shows the operation applied for object detection: red – automatic cell detection; cyan – cell division line; yellow – removed objects (when placed next to red line, the division line (cyan) was omitted for clarity); green – manually drawn elements</p></caption><graphic xlink:href="12021_2017_9340_Fig13_HTML" id="MO14"/></fig>
</p>
      <p id="Par77">The application of CAS in research on the distribution of neuronal populations in the LGN considerably reduced the workload needed in data analysis. Two of the most time-consuming procedures— outlining cell borders and primary data preparation (adding of slice/region marks in the result table, spatial and brightness normalization)—are done automatically, thus shortening the analysis. In order to obtain some measurable data, 10 samples of spinal cord, LGN, and cortex were prepared. In the experimental group, various types of immunohistochemical staining were applied: parvalbumin, calretinin, NeuN, and SMI-32. The number of cells varied from 84 to 210 (with average equal to 142.9). Manual outlining (depending on complexity) took from 540 to 1380 seconds (average 873), while CAS needed from 10 to 30 seconds (average 19 seconds) for automatic cell segmentation. The computation was performed on a personal computer running Windows 10 with a 3.2GHz Intel CPU and 16GB of RAM. Additional manual cell improvement was applied to some slices: the operator checked the correctness of automatic selection and removal or cutting of some cells, which took from 180 to 600 seconds (average 378). In the results, we can see that 55 times speed-up was achieved for automatic cell selection, which is the most tiresome work. Of course, to improve the result, some additional semi-automatic action was necessary, which resulted in achieving a final speed-up of 2.29 times. Figure <xref rid="Fig15" ref-type="fig">14</xref> presents an example of manual and automatic location of cell borders while Table <xref rid="Tab5" ref-type="table">5</xref> summarises the performance.
<fig id="Fig15"><label>Fig. 14</label><caption><p>Comparison between manual annotation (<bold>a</bold>) and automatic segmentation with CAS (<bold>b</bold>). (<bold>c</bold>) Red stands for manual annotation, blue for automatic, and black is shown when the contour overlaps</p></caption><graphic xlink:href="12021_2017_9340_Fig14_HTML" id="MO15"/></fig>
<table-wrap id="Tab5"><label>Table 5</label><caption><p>Comparison of performance when manual outlining and semi-automated solution accessible in CAS were exploited</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Action</th><th align="left">Minimal</th><th align="left">Maximal</th><th align="left">Average</th></tr></thead><tbody><tr><td align="left">Manual outlining</td><td align="left">540</td><td align="left">1380</td><td align="left">873</td></tr><tr><td align="left">Automatic segmentation</td><td align="left">10</td><td align="left">30</td><td align="left">19</td></tr><tr><td align="left">Manual corrections</td><td align="left">180</td><td align="left">600</td><td align="left">378</td></tr><tr><td align="left">Cell segmentation speed-up</td><td align="left">-</td><td align="left">-</td><td align="left">55.3 times</td></tr><tr><td align="left">Cell segmentation with corrections speed-up</td><td align="left">-</td><td align="left">-</td><td align="left">2.29 times</td></tr></tbody></table></table-wrap>
</p>
      <p id="Par78">In addition, the software has convenient instruments for data presentation and re-examination. It is also worth pointing out that if changes are made (e.g. removing or adding cells, etc.), the results are recomputed automatically without operator intervention, which makes corrections and changes easy to apply. As a result, we have a convenient tool to detect specific changes of the LGN under experimental conditions or as a consequence of age-related development.</p>
    </sec>
  </sec>
  <sec id="Sec16">
    <title>Conclusions</title>
    <p id="Par79">This work addresses the problem of automatic cell soma or nucleus segmentation and annotation in microscopic images. A detailed comparison of the standard image processing method against a novel approach exploiting SDA was presented. The research shows that the method used in CAS enables object border detection with comparable quality to standard methods. In difficult cases in which there are more types of object to be recognized, it outperforms the current leading techniques. In addition, shape features were introduced for description of object characteristics and specific analysis and interpretation were performed. Additional features implemented in CAS which enable data scale changes, data division into layers, and other functionality were presented with a case study of semi-automatic annotation of the LGN of cats.</p>
    <p id="Par80">Cell Annotation Software was designed to meet the need for a system which combines the various functionalities necessary for segmentation and analysis of objects in neural specimens. The presented approach proved to fulfill all demands and allows: saving topological information about cell distribution by region definition; comparative analysis of different slices and investigation of changes in the neuronal population due to x-axis normalization; and quantitative comparison of the degree of histological or immunohistological staining of tissues in slices when a change in the production quantity of a particular substance due to the influence of experimental factors is investigated. Moreover, simple recalculation of results and storage in open-format files make this software easy to incorporate in research pipelines.</p>
    <p id="Par81">The practical application of CAS in research conducted at the Pavlov Institute of Physiology proved to be a great culmination of this research, but a new development frontier has also arisen. In future work, we plan to address the problem of multiple labeling, working with tissues with various cell types and 3D reconstruction.</p>
  </sec>
  <sec id="Sec17">
    <title>Information Sharing Statement</title>
    <p>In the article we worked with data from the following data sources: 
<list list-type="order"><list-item><p id="Par82">Dataset provided for the Nucleus Counting Challenge (Fig. <xref rid="Fig3" ref-type="fig">3</xref>, <xref rid="Fig6" ref-type="fig">6</xref>c) (Maric <xref ref-type="bibr" rid="CR33">2015</xref>).</p></list-item><list-item><p id="Par83">BrainMaps: An Interactive Multiresolution Brain Atlas (BrainMaps <xref ref-type="bibr" rid="CR4">2005</xref>) decribed by Mikula et al. (<xref ref-type="bibr" rid="CR36">2007</xref>) (Figs. <xref rid="Fig5" ref-type="fig">5</xref> and <xref rid="Fig7" ref-type="fig">7</xref>)</p></list-item><list-item><p id="Par84">Data acquired by A. Mikhalkin (other figures).</p></list-item></list>
</p>
    <p>The presented Cell Annotation Software can be downloaded from <ext-link ext-link-type="uri" xlink:href="http://home.agh.edu.pl/pioro/cas/">http://home.agh.edu.pl/pioro/cas/</ext-link>.</p>
  </sec>
</body>
<back>
  <fn-group>
    <fn id="Fn1">
      <label>1</label>
      <p id="Par5">
        <ext-link ext-link-type="uri" xlink:href="http://home.agh.edu.pl/pioro/cas/">http://home.agh.edu.pl/pioro/cas/</ext-link>
      </p>
    </fn>
  </fn-group>
  <ack>
    <title>Acknowledgements</title>
    <p>The authors thank Shkorbatova P. for NeuN primary antibody, prof. Musienko P. for microscopic equipment, and the Center for Molecular and Cell Technologies, Research Park, St. Petersburg State University.</p>
    <p>K. Nurzynska was supported by statutory funds for young researchers (BKM/507/RAU2/2016) from the Institute of Informatics, Silesian University of Technology, Poland.</p>
    <p>A. Piorkowski was supported by AGH University of Science and Technology, Faculty of Geology, Geophysics and Environmental Protection as a part of a statutory project.</p>
  </ack>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <mixed-citation publication-type="other">Baecker, V. (2010). Workshop: Image processing and analysis with ImageJ and MRI Cell Image Analyzer.</mixed-citation>
    </ref>
    <ref id="CR2">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Bickford</surname>
            <given-names>ME</given-names>
          </name>
          <name>
            <surname>Guido</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Godwin</surname>
            <given-names>DW</given-names>
          </name>
        </person-group>
        <article-title>Neurofilament proteins in Y-cells of the cat lateral geniculate nucleus: Normal expression and alteration with visual deprivation</article-title>
        <source>The Journal of neuroscience</source>
        <year>1998</year>
        <volume>18</volume>
        <issue>16</issue>
        <fpage>6549</fpage>
        <lpage>57</lpage>
        <?supplied-pmid 9698342?>
        <pub-id pub-id-type="pmid">9698342</pub-id>
      </element-citation>
    </ref>
    <ref id="CR3">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Bowling</surname>
            <given-names>DB</given-names>
          </name>
          <name>
            <surname>Wieniawa-Narkiewicz</surname>
            <given-names>E</given-names>
          </name>
        </person-group>
        <article-title>The distribution of on- and off-centre X- and Y-like cells in the A layers of the cat’s lateral geniculate nucleus</article-title>
        <source>The Journal of Physiology</source>
        <year>1986</year>
        <volume>375</volume>
        <fpage>561</fpage>
        <lpage>72</lpage>
        <pub-id pub-id-type="doi">10.1113/jphysiol.1986.sp016133</pub-id>
        <?supplied-pmid 3795069?>
        <pub-id pub-id-type="pmid">3795069</pub-id>
      </element-citation>
    </ref>
    <ref id="CR4">
      <mixed-citation publication-type="other">BrainMaps (2005). BrainMaps: An Interactive Multiresolution Brain Atlas. <ext-link ext-link-type="uri" xlink:href="http://brainmaps.org">http://brainmaps.org</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR5">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Burnat</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Vandenbussche</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Ernicki</surname>
            <given-names>B</given-names>
          </name>
        </person-group>
        <article-title>Global motion detection is impaired in cats deprived early of pattern vision</article-title>
        <source>Behavioural Brain Research</source>
        <year>2002</year>
        <volume>134</volume>
        <issue>1-2</issue>
        <fpage>59</fpage>
        <lpage>65</lpage>
        <pub-id pub-id-type="doi">10.1016/S0166-4328(01)00456-9</pub-id>
        <?supplied-pmid 12191792?>
        <pub-id pub-id-type="pmid">12191792</pub-id>
      </element-citation>
    </ref>
    <ref id="CR6">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Carden</surname>
            <given-names>WB</given-names>
          </name>
          <name>
            <surname>Guido</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Ziburkus</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Datskovskaia</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Godwin</surname>
            <given-names>DW</given-names>
          </name>
          <name>
            <surname>Bickford</surname>
            <given-names>ME</given-names>
          </name>
        </person-group>
        <article-title>A novel means of Y cell identification in the developing lateral geniculate nucleus of the cat.</article-title>
        <source>Neuroscience Letters</source>
        <year>2000</year>
        <volume>295</volume>
        <fpage>5</fpage>
        <lpage>8</lpage>
        <pub-id pub-id-type="doi">10.1016/S0304-3940(00)01581-0</pub-id>
        <?supplied-pmid 11078923?>
        <pub-id pub-id-type="pmid">11078923</pub-id>
      </element-citation>
    </ref>
    <ref id="CR7">
      <mixed-citation publication-type="other">Carpenter, A. E., Jones, T. R., Lamprecht, M. R., Clarke, C., Kang, I. H., Friman, O., Guertin, D. A., Chang, J. H., Lindquist, R. A., Moffat, J., et al. (2006). Cellprofiler: image analysis software for identifying and quantifying cell phenotypes. <italic>Genome Biology</italic>, <italic>7</italic>(10), R100.</mixed-citation>
    </ref>
    <ref id="CR8">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Cheng</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Rajapakse</surname>
            <given-names>JC</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Segmentation of clustered nuclei with shape markers and marking function</article-title>
        <source>IEEE Transactions on Biomedical Engineering</source>
        <year>2009</year>
        <volume>56</volume>
        <issue>3</issue>
        <fpage>741</fpage>
        <lpage>748</lpage>
        <pub-id pub-id-type="doi">10.1109/TBME.2008.2008635</pub-id>
        <?supplied-pmid 19272880?>
        <pub-id pub-id-type="pmid">19272880</pub-id>
      </element-citation>
    </ref>
    <ref id="CR9">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Collins</surname>
            <given-names>TJ</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Imagej for microscopy</article-title>
        <source>Biotechniques</source>
        <year>2007</year>
        <volume>43</volume>
        <issue>1 Suppl</issue>
        <fpage>25</fpage>
        <lpage>30</lpage>
        <pub-id pub-id-type="doi">10.2144/000112517</pub-id>
        <?supplied-pmid 17936939?>
        <pub-id pub-id-type="pmid">17936939</pub-id>
      </element-citation>
    </ref>
    <ref id="CR10">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Dice</surname>
            <given-names>LR</given-names>
          </name>
        </person-group>
        <article-title>Measures of the amount of ecologic association between species</article-title>
        <source>Ecology</source>
        <year>1945</year>
        <volume>26</volume>
        <issue>3</issue>
        <fpage>297</fpage>
        <lpage>302</lpage>
        <pub-id pub-id-type="doi">10.2307/1932409</pub-id>
      </element-citation>
    </ref>
    <ref id="CR11">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Dyck</surname>
            <given-names>RH</given-names>
          </name>
          <name>
            <surname>Cynader</surname>
            <given-names>MS</given-names>
          </name>
        </person-group>
        <article-title>An interdigitated columnar mosaic of cytochrome oxidase, zinc, and neurotransmitter-related molecules in cat and monkey visual cortex</article-title>
        <source>Proceedings of the National Academy of Sciences of the United States of America</source>
        <year>1993</year>
        <volume>90</volume>
        <issue>19</issue>
        <fpage>9066</fpage>
        <lpage>9069</lpage>
        <pub-id pub-id-type="doi">10.1073/pnas.90.19.9066</pub-id>
        <?supplied-pmid 8415654?>
        <pub-id pub-id-type="pmid">8415654</pub-id>
      </element-citation>
    </ref>
    <ref id="CR12">
      <mixed-citation publication-type="other">Ekstrom, A., Suvanto, R. W., Yang, T., Ye, B., &amp; Zhou, J. (2016). Robust neuron counting based on fusion of shape map and multi-cue learning. In <italic>International conference on brain and health informatics (pp. 313).</italic> Springer.</mixed-citation>
    </ref>
    <ref id="CR13">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Forero</surname>
            <given-names>MG</given-names>
          </name>
          <name>
            <surname>Pennack</surname>
            <given-names>JA</given-names>
          </name>
          <name>
            <surname>Hidalgo</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Deadeasy neurons: automatic counting of hb9 neuronal nuclei in drosophila</article-title>
        <source>Cytometry Part A</source>
        <year>2010</year>
        <volume>77</volume>
        <issue>4</issue>
        <fpage>371</fpage>
        <lpage>378</lpage>
        <pub-id pub-id-type="doi">10.1002/cyto.a.20877</pub-id>
      </element-citation>
    </ref>
    <ref id="CR14">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Gertych</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Joseph</surname>
            <given-names>AO</given-names>
          </name>
          <name>
            <surname>Walts</surname>
            <given-names>AE</given-names>
          </name>
          <name>
            <surname>Bose</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>Automated detection of dual p16/ki67 nuclear immunoreactivity in liquid-based pap tests for improved cervical cancer risk stratification</article-title>
        <source>Annals of Biomedical Engineering</source>
        <year>2012</year>
        <volume>40</volume>
        <issue>5</issue>
        <fpage>1192</fpage>
        <lpage>1204</lpage>
        <pub-id pub-id-type="doi">10.1007/s10439-011-0498-8</pub-id>
        <?supplied-pmid 22215277?>
        <pub-id pub-id-type="pmid">22215277</pub-id>
      </element-citation>
    </ref>
    <ref id="CR15">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Gertych</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Ma</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Tajbakhsh</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Velásquez-Vacca</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Knudsen</surname>
            <given-names>BS</given-names>
          </name>
        </person-group>
        <article-title>Rapid 3-d delineation of cell nuclei for high-content screening platforms</article-title>
        <source>Computers in Biology and Medicine</source>
        <year>2016</year>
        <volume>69</volume>
        <fpage>328</fpage>
        <lpage>338</lpage>
        <pub-id pub-id-type="doi">10.1016/j.compbiomed.2015.04.025</pub-id>
        <?supplied-pmid 25982066?>
        <pub-id pub-id-type="pmid">25982066</pub-id>
      </element-citation>
    </ref>
    <ref id="CR16">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Gonzalez</surname>
            <given-names>RC</given-names>
          </name>
          <name>
            <surname>Woods</surname>
            <given-names>RE</given-names>
          </name>
        </person-group>
        <source>Digital image processing, 2nd Edn.</source>
        <year>2001</year>
        <publisher-loc>MA, USA</publisher-loc>
        <publisher-name>Addison-Wesley Longman Publishing Co., Inc.</publisher-name>
      </element-citation>
    </ref>
    <ref id="CR17">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Gulyás</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Bencsik</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Pusztai</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Liliom</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Schlett</surname>
            <given-names>K</given-names>
          </name>
        </person-group>
        <article-title>Animaltracker: An imagej-based tracking api to create a customized behaviour analyser program</article-title>
        <source>Neuroinformatics</source>
        <year>2016</year>
        <volume>14</volume>
        <issue>4</issue>
        <fpage>479</fpage>
        <lpage>481</lpage>
        <pub-id pub-id-type="doi">10.1007/s12021-016-9303-z</pub-id>
        <?supplied-pmid 27166960?>
        <pub-id pub-id-type="pmid">27166960</pub-id>
      </element-citation>
    </ref>
    <ref id="CR18">
      <mixed-citation publication-type="other">Hartig, S. M. (2001). Basic image analysis and manipulation in ImageJ. In <italic>Current protocols in molecular biology</italic>. Wiley. ISBN 9780471142720. 10.1002/0471142727.mb1415s102.</mixed-citation>
    </ref>
    <ref id="CR19">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hoffmann</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Stone</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Sherman</surname>
            <given-names>SM</given-names>
          </name>
        </person-group>
        <article-title>Relay of receptive-field properties in dorsal lateral geniculate nucleus of the cat</article-title>
        <source>Journal Neurophysiology</source>
        <year>1972</year>
        <volume>35</volume>
        <issue>5</issue>
        <fpage>518</fpage>
        <lpage>531</lpage>
        <?supplied-pmid 4338566?>
        <pub-id pub-id-type="pmid">4338566</pub-id>
      </element-citation>
    </ref>
    <ref id="CR20">
      <mixed-citation publication-type="other">Ing, N., Salman, S., Ma, Z., Walts, A., Knudsen, B., &amp; Gertych, A. (2016). Machine learning can reliably distinguish histological patterns of micropapillary and solid lung adenocarcinomas. In <italic>Information technologies in medicine, advances in intelligent systems and computing (Vol. 471, pp. 193–206).</italic> Springer.</mixed-citation>
    </ref>
    <ref id="CR21">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Irshad</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Veillard</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Roux</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Racoceanu</surname>
            <given-names>D</given-names>
          </name>
        </person-group>
        <article-title>Methods for nuclei detection, segmentation, and classification in digital histopathology: A review—current status and future potential</article-title>
        <source>IEEE Reviews in Biomedical Engineering</source>
        <year>2014</year>
        <volume>7</volume>
        <fpage>97</fpage>
        <lpage>114</lpage>
        <pub-id pub-id-type="doi">10.1109/RBME.2013.2295804</pub-id>
        <?supplied-pmid 24802905?>
        <pub-id pub-id-type="pmid">24802905</pub-id>
      </element-citation>
    </ref>
    <ref id="CR22">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Jahne</surname>
            <given-names>B</given-names>
          </name>
        </person-group>
        <source>Digital image processing: Concepts, algorithms and scientific applications, 5th Edn.</source>
        <year>2002</year>
        <publisher-loc>NJ, USA</publisher-loc>
        <publisher-name>Springer-Verlag New York, Inc., Secaucus</publisher-name>
      </element-citation>
    </ref>
    <ref id="CR23">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Jung</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Kim</surname>
            <given-names>C</given-names>
          </name>
        </person-group>
        <article-title>Segmenting clustered nuclei using H-minima transform-based marker extraction and contour parameterization</article-title>
        <source>IEEE Transactions on Biomedical Engineering</source>
        <year>2010</year>
        <volume>57</volume>
        <issue>10</issue>
        <fpage>2600</fpage>
        <lpage>2604</lpage>
        <pub-id pub-id-type="doi">10.1109/TBME.2010.2060336</pub-id>
        <?supplied-pmid 20656653?>
        <pub-id pub-id-type="pmid">20656653</pub-id>
      </element-citation>
    </ref>
    <ref id="CR24">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kaas</surname>
            <given-names>JH</given-names>
          </name>
        </person-group>
        <article-title>Evolution of columns, modules, and domains in the neocortex of primates</article-title>
        <source>Proceedings of the National Academy of Sciences of the United States of America</source>
        <year>2012</year>
        <volume>109</volume>
        <issue>Suppl</issue>
        <fpage>10,655</fpage>
        <lpage>10,660</lpage>
        <pub-id pub-id-type="doi">10.1073/pnas.1201892109</pub-id>
      </element-citation>
    </ref>
    <ref id="CR25">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kamentsky</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Jones</surname>
            <given-names>TR</given-names>
          </name>
          <name>
            <surname>Fraser</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Bray</surname>
            <given-names>MA</given-names>
          </name>
          <name>
            <surname>Logan</surname>
            <given-names>DJ</given-names>
          </name>
          <name>
            <surname>Madden</surname>
            <given-names>KL</given-names>
          </name>
          <name>
            <surname>Ljosa</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Rueden</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Eliceiri</surname>
            <given-names>KW</given-names>
          </name>
          <name>
            <surname>Carpenter</surname>
            <given-names>AE</given-names>
          </name>
        </person-group>
        <article-title>Improved structure, function and compatibility for cellprofiler: Modular high-throughput image analysis software</article-title>
        <source>Bioinformatics</source>
        <year>2011</year>
        <volume>27</volume>
        <issue>8</issue>
        <fpage>1179</fpage>
        <lpage>1180</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btr095</pub-id>
        <?supplied-pmid 21349861?>
        <pub-id pub-id-type="pmid">21349861</pub-id>
      </element-citation>
    </ref>
    <ref id="CR26">
      <mixed-citation publication-type="other">Kaplan, E. (2014). The new visual neurosciences. In Werner, J.S., &amp; Chalupa, L.M. (Eds.) <italic>The M, P, and K pathways of the primate visual system revisited</italic> (pp. 215–227). Cambridge: MIT Press.</mixed-citation>
    </ref>
    <ref id="CR27">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kolodziejczyk</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Ladniak</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Piorkowski</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Constructing software for analysis of neuron, glial and endothelial cell numbers and density in histological nissl-stained rodent brain tissue</article-title>
        <source>Journal of Medical Informatics and Technologies</source>
        <year>2014</year>
        <volume>23</volume>
        <fpage>77</fpage>
        <lpage>86</lpage>
      </element-citation>
    </ref>
    <ref id="CR28">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kopacz</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Piorkowski</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>A Review of the Efficient Algorithm Implementation for Image Processing in the ImageJ and Matlab Environments (Przeglad moŻliwości wydajnej implementacji algorytmów przetwarzania obrazów w środowisku Matlab)</article-title>
        <source>Studia Informatica</source>
        <year>2017</year>
        <volume>38</volume>
        <issue>132</issue>
        <fpage>177</fpage>
        <lpage>190</lpage>
      </element-citation>
    </ref>
    <ref id="CR29">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kowal</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Filipczuk</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Obuchowicz</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Korbicz</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Monczak</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>Computer-aided diagnosis of breast cancer based on fine needle biopsy microscopic images</article-title>
        <source>Computers in Biology and Medicine</source>
        <year>2013</year>
        <volume>43</volume>
        <issue>10</issue>
        <fpage>1563</fpage>
        <lpage>1572</lpage>
        <pub-id pub-id-type="doi">10.1016/j.compbiomed.2013.08.003</pub-id>
        <?supplied-pmid 24034748?>
        <pub-id pub-id-type="pmid">24034748</pub-id>
      </element-citation>
    </ref>
    <ref id="CR30">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Koyuncu</surname>
            <given-names>CF</given-names>
          </name>
          <name>
            <surname>Akhan</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Ersahin</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Cetin-Atalay</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Gunduz-Demir</surname>
            <given-names>C</given-names>
          </name>
        </person-group>
        <article-title>Iterative H-minima-based marker-controlled watershed for cell nucleus segmentation</article-title>
        <source>Cytometry Part A</source>
        <year>2016</year>
        <volume>89</volume>
        <fpage>338</fpage>
        <lpage>349</lpage>
        <pub-id pub-id-type="doi">10.1002/cyto.a.22824</pub-id>
      </element-citation>
    </ref>
    <ref id="CR31">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>La Torre</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Alonso Nanclares</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Muelas Pascual</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Peña Sanchez</surname>
            <given-names>JM</given-names>
          </name>
          <name>
            <surname>Oroquieta</surname>
            <given-names>F</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>3d segmentations of neuronal nuclei from confocal microscope image stacks</article-title>
        <source>Frontiers in neuroanatomy</source>
        <year>2013</year>
        <volume>7</volume>
        <fpage>1</fpage>
        <lpage>10</lpage>
        <pub-id pub-id-type="pmid">23423949</pub-id>
      </element-citation>
    </ref>
    <ref id="CR32">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>LeVay</surname>
            <given-names>S,Ferster,D</given-names>
          </name>
        </person-group>
        <article-title>Relay cell classes in the lateral geniculate nucleus of the cat and the effects of visual deprivation</article-title>
        <source>The Journal of Comparative Neurology</source>
        <year>1977</year>
        <volume>172</volume>
        <issue>4</issue>
        <fpage>563</fpage>
        <lpage>84</lpage>
        <pub-id pub-id-type="doi">10.1002/cne.901720402</pub-id>
        <?supplied-pmid 190274?>
        <pub-id pub-id-type="pmid">190274</pub-id>
      </element-citation>
    </ref>
    <ref id="CR33">
      <mixed-citation publication-type="other">Maric, D. (2015). 2015 BioImage Informatics Conference: Nucleus Counting Challenge. <ext-link ext-link-type="uri" xlink:href="https://isg.nist.gov/BII_2015/webPages/pages/nucleusCounting/NucleusCounting.html">https://isg.nist.gov/BII_2015/webPages/pages/nucleusCounting/NucleusCounting.html</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR34">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Mazurek</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Oszutowska-Mazurek</surname>
            <given-names>D</given-names>
          </name>
        </person-group>
        <article-title>From the slit-island method to the ising model: Analysis of irregular grayscale objects</article-title>
        <source>International Journal of Applied Mathematics and Computer Science</source>
        <year>2014</year>
        <volume>24</volume>
        <issue>1</issue>
        <fpage>49</fpage>
        <lpage>63</lpage>
        <pub-id pub-id-type="doi">10.2478/amcs-2014-0004</pub-id>
      </element-citation>
    </ref>
    <ref id="CR35">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Merkulyeva</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Veshchitskii</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Makarov</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Gerasimenko</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Musienko</surname>
            <given-names>P</given-names>
          </name>
        </person-group>
        <article-title>Distribution of 28 kDa calbindin-immunopositive neurons in the cat spinal cord</article-title>
        <source>Frontiers in Neuroanatomy</source>
        <year>2016</year>
        <volume>9</volume>
        <fpage>166</fpage>
        <pub-id pub-id-type="doi">10.3389/fnana.2015.00166</pub-id>
        <?supplied-pmid 26858610?>
        <pub-id pub-id-type="pmid">26858610</pub-id>
      </element-citation>
    </ref>
    <ref id="CR36">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Mikula</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Trotts</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Stone</surname>
            <given-names>JM</given-names>
          </name>
          <name>
            <surname>Jones</surname>
            <given-names>EG</given-names>
          </name>
        </person-group>
        <article-title>Internet-enabled high-resolution brain mapping and virtual microscopy</article-title>
        <source>Neuroimage</source>
        <year>2007</year>
        <volume>35</volume>
        <issue>1</issue>
        <fpage>9</fpage>
        <lpage>15</lpage>
        <pub-id pub-id-type="doi">10.1016/j.neuroimage.2006.11.053</pub-id>
        <?supplied-pmid 17229579?>
        <pub-id pub-id-type="pmid">17229579</pub-id>
      </element-citation>
    </ref>
    <ref id="CR37">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Mitzdorf</surname>
            <given-names>U</given-names>
          </name>
          <name>
            <surname>Singer</surname>
            <given-names>W</given-names>
          </name>
        </person-group>
        <article-title>Laminar segregation of afferents to lateral geniculate nucleus of the cat: an analysis of current source density</article-title>
        <source>Journal of Neurophysiology</source>
        <year>1977</year>
        <volume>40</volume>
        <issue>6</issue>
        <fpage>1227</fpage>
        <lpage>44</lpage>
        <?supplied-pmid 925725?>
        <pub-id pub-id-type="pmid">925725</pub-id>
      </element-citation>
    </ref>
    <ref id="CR38">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Morgan</surname>
            <given-names>JL</given-names>
          </name>
          <name>
            <surname>Berger</surname>
            <given-names>DR</given-names>
          </name>
          <name>
            <surname>Wetzel</surname>
            <given-names>AW</given-names>
          </name>
          <name>
            <surname>Lichtman</surname>
            <given-names>JW</given-names>
          </name>
        </person-group>
        <article-title>The fuzzy logic of network connectivity in mouse visual thalamus</article-title>
        <source>Cell</source>
        <year>2016</year>
        <volume>165</volume>
        <issue>1</issue>
        <fpage>192</fpage>
        <lpage>206</lpage>
        <pub-id pub-id-type="doi">10.1016/j.cell.2016.02.033</pub-id>
        <?supplied-pmid 27015312?>
        <pub-id pub-id-type="pmid">27015312</pub-id>
      </element-citation>
    </ref>
    <ref id="CR39">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Mullen</surname>
            <given-names>RJ</given-names>
          </name>
          <name>
            <surname>Buck</surname>
            <given-names>CR</given-names>
          </name>
          <name>
            <surname>Smith</surname>
            <given-names>AM</given-names>
          </name>
        </person-group>
        <article-title>NeuN, a neuronal specific nuclear protein in vertebrates</article-title>
        <source>Development</source>
        <year>1992</year>
        <volume>116</volume>
        <fpage>201</fpage>
        <lpage>211</lpage>
        <?supplied-pmid 1483388?>
        <pub-id pub-id-type="pmid">1483388</pub-id>
      </element-citation>
    </ref>
    <ref id="CR40">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Nurzynska</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Piorkowski</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>The correlation analysis of the shape parameters for endothelial image characterisation</article-title>
        <source>Image Analysis and Stereology</source>
        <year>2016</year>
        <volume>35</volume>
        <issue>3</issue>
        <fpage>149</fpage>
        <lpage>158</lpage>
        <pub-id pub-id-type="doi">10.5566/ias.1554</pub-id>
      </element-citation>
    </ref>
    <ref id="CR41">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Nurzynska</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Kubo</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Muramoto</surname>
            <given-names>K</given-names>
          </name>
        </person-group>
        <article-title>Shape parameters for automatic classification of snow particles into snowflake and graupel</article-title>
        <source>Meteorological Applications</source>
        <year>2013</year>
        <volume>20</volume>
        <issue>3</issue>
        <fpage>257</fpage>
        <lpage>265</lpage>
        <pub-id pub-id-type="doi">10.1002/met.299</pub-id>
      </element-citation>
    </ref>
    <ref id="CR42">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ohki</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Chung</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Ch’ng</surname>
            <given-names>YH</given-names>
          </name>
          <name>
            <surname>Kara</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Reid</surname>
            <given-names>RC</given-names>
          </name>
        </person-group>
        <article-title>Functional imaging with cellular resolution reveals precise micro-architecture in visual cortex</article-title>
        <source>Nature</source>
        <year>2005</year>
        <volume>433</volume>
        <issue>7026</issue>
        <fpage>597</fpage>
        <lpage>603</lpage>
        <pub-id pub-id-type="doi">10.1038/nature03274</pub-id>
        <?supplied-pmid 15660108?>
        <pub-id pub-id-type="pmid">15660108</pub-id>
      </element-citation>
    </ref>
    <ref id="CR43">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Otsu</surname>
            <given-names>N</given-names>
          </name>
        </person-group>
        <article-title>A threshold selection method from gray-level histograms</article-title>
        <source>Automatica</source>
        <year>1975</year>
        <volume>11</volume>
        <issue>285–296</issue>
        <fpage>23</fpage>
        <lpage>27</lpage>
      </element-citation>
    </ref>
    <ref id="CR44">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Papadopulos</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Spinelli</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Valente</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Foroni</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Orrico</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Alviano</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Pasquinelli</surname>
            <given-names>G</given-names>
          </name>
        </person-group>
        <article-title>Common tasks in microscopic and ultrastructural image analysis using imagej</article-title>
        <source>Ultrastructural Pathology</source>
        <year>2007</year>
        <volume>31</volume>
        <issue>6</issue>
        <fpage>401</fpage>
        <lpage>407</lpage>
        <pub-id pub-id-type="doi">10.1080/01913120701719189</pub-id>
        <?supplied-pmid 18098058?>
        <pub-id pub-id-type="pmid">18098058</pub-id>
      </element-citation>
    </ref>
    <ref id="CR45">
      <mixed-citation publication-type="other">Payne, B. R., &amp; Peters, A. (2002). The cat primary visual cortex. In Payne, B.R. &amp; Peters, A. (Eds.) <italic>The concept of cat primary visual cortex</italic> (pp. 1–129). San Diego, London, Boston, New York, Sydney, Tokyo, Toronto: Academic Press.</mixed-citation>
    </ref>
    <ref id="CR46">
      <mixed-citation publication-type="other">Piorkowski, A. (2016). A statistical dominance algorithm for edge detection and segmentation of medical images. In <italic>Information technologies in medicine, advances in intelligent systems and computing (Vol. 471, pp. 3–14).</italic> Springer.</mixed-citation>
    </ref>
    <ref id="CR47">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Piorkowski</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Nurzynska</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Gronkowska-Serafin</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Selig</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Boldak</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Reska</surname>
            <given-names>D</given-names>
          </name>
        </person-group>
        <article-title>Influence of applied corneal endothelium image segmentation techniques on the clinical parameters</article-title>
        <source>Computerized Medical Imaging and Graphics</source>
        <year>2017</year>
        <volume>55</volume>
        <fpage>13</fpage>
        <lpage>27</lpage>
        <pub-id pub-id-type="doi">10.1016/j.compmedimag.2016.07.010</pub-id>
        <?supplied-pmid 27553657?>
        <pub-id pub-id-type="pmid">27553657</pub-id>
      </element-citation>
    </ref>
    <ref id="CR48">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Pool</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Thiemann</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Bar-Or</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Fournier</surname>
            <given-names>AE</given-names>
          </name>
        </person-group>
        <article-title>Neuritetracer: a novel imagej plugin for automated quantification of neurite outgrowth</article-title>
        <source>Journal of Neuroscience Methods</source>
        <year>2008</year>
        <volume>168</volume>
        <issue>1</issue>
        <fpage>134</fpage>
        <lpage>139</lpage>
        <pub-id pub-id-type="doi">10.1016/j.jneumeth.2007.08.029</pub-id>
        <?supplied-pmid 17936365?>
        <pub-id pub-id-type="pmid">17936365</pub-id>
      </element-citation>
    </ref>
    <ref id="CR49">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Russ</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <source>The image processing handbook, 3rd Edn</source>
        <year>1998</year>
        <publisher-loc>Springer, and IEEE Press</publisher-loc>
        <publisher-name>CRC Press</publisher-name>
      </element-citation>
    </ref>
    <ref id="CR50">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Sanderson</surname>
            <given-names>KJ</given-names>
          </name>
        </person-group>
        <article-title>The projection of the visual field to the lateral geniculate and medial interlaminar nuclei in the cat</article-title>
        <source>The Journal of Comparative Neurology</source>
        <year>1971</year>
        <volume>143</volume>
        <issue>1</issue>
        <fpage>101</fpage>
        <lpage>108</lpage>
        <pub-id pub-id-type="doi">10.1002/cne.901430107</pub-id>
        <?supplied-pmid 5097579?>
        <pub-id pub-id-type="pmid">5097579</pub-id>
      </element-citation>
    </ref>
    <ref id="CR51">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Schiller</surname>
            <given-names>PH</given-names>
          </name>
        </person-group>
        <article-title>Parallel information processing channels created in the retina</article-title>
        <source>Proceedings of the National Academy of Sciences of the United States of America</source>
        <year>2010</year>
        <volume>107</volume>
        <issue>40</issue>
        <fpage>17,087</fpage>
        <lpage>17,094</lpage>
        <pub-id pub-id-type="doi">10.1073/pnas.1011782107</pub-id>
      </element-citation>
    </ref>
    <ref id="CR52">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Schindelin</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Arganda-Carreras</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Frise</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Kaynig</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Longair</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Pietzsch</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Preibisch</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Rueden</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Saalfeld</surname>
            <given-names>S</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Fiji: an open-source platform for biological-image analysis</article-title>
        <source>Nature Methods</source>
        <year>2012</year>
        <volume>9</volume>
        <issue>7</issue>
        <fpage>676</fpage>
        <lpage>682</lpage>
        <pub-id pub-id-type="doi">10.1038/nmeth.2019</pub-id>
        <?supplied-pmid 22743772?>
        <pub-id pub-id-type="pmid">22743772</pub-id>
      </element-citation>
    </ref>
    <ref id="CR53">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Schneider</surname>
            <given-names>CA</given-names>
          </name>
          <name>
            <surname>Rasband</surname>
            <given-names>WS</given-names>
          </name>
          <name>
            <surname>Eliceiri</surname>
            <given-names>KW</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>NIH Image to ImageJ: 25 years of image analysis</article-title>
        <source>Nature Methods</source>
        <year>2012</year>
        <volume>9</volume>
        <issue>7</issue>
        <fpage>671</fpage>
        <lpage>675</lpage>
        <pub-id pub-id-type="doi">10.1038/nmeth.2089</pub-id>
        <?supplied-pmid 22930834?>
        <pub-id pub-id-type="pmid">22930834</pub-id>
      </element-citation>
    </ref>
    <ref id="CR54">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Selinummi</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Seppala</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Yli-Harja</surname>
            <given-names>O</given-names>
          </name>
          <name>
            <surname>Puhakka</surname>
            <given-names>JA</given-names>
          </name>
        </person-group>
        <article-title>Software for quantification of labeled bacteria from digital microscope images by automated image analysis</article-title>
        <source>Biotechniques</source>
        <year>2005</year>
        <volume>39</volume>
        <issue>6</issue>
        <fpage>859</fpage>
        <lpage>862</lpage>
        <pub-id pub-id-type="doi">10.2144/000112018</pub-id>
        <?supplied-pmid 16382904?>
        <pub-id pub-id-type="pmid">16382904</pub-id>
      </element-citation>
    </ref>
    <ref id="CR55">
      <mixed-citation publication-type="other">Skobel, M., Kowal, M., &amp; Korbicz, J. (2017). Nuclei recognition using iterated conditional modes approach. In <italic>International conference on computer recognition systems (pp. 326–335).</italic> Springer.</mixed-citation>
    </ref>
    <ref id="CR56">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Soille</surname>
            <given-names>P</given-names>
          </name>
        </person-group>
        <source>Morphological Image Analysis: Principles and Applications</source>
        <year>1999</year>
        <publisher-loc>NJ, USA</publisher-loc>
        <publisher-name>Springer-Verlag New York, Inc. Secaucus</publisher-name>
      </element-citation>
    </ref>
    <ref id="CR57">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Sternberg</surname>
            <given-names>SR</given-names>
          </name>
        </person-group>
        <article-title>Biomedical image processing</article-title>
        <source>Computer</source>
        <year>1983</year>
        <volume>16</volume>
        <issue>1</issue>
        <fpage>22</fpage>
        <lpage>34</lpage>
        <pub-id pub-id-type="doi">10.1109/MC.1983.1654163</pub-id>
      </element-citation>
    </ref>
    <ref id="CR58">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Stichel</surname>
            <given-names>CC</given-names>
          </name>
          <name>
            <surname>Singer</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Heizmann</surname>
            <given-names>CW</given-names>
          </name>
        </person-group>
        <article-title>Light and electron microscopic immunocytochemical localization of parvalbumin in the dorsal lateral geniculate nucleus of the cat: evidence for coexistence with GABA</article-title>
        <source>The Journal of Comparative Neurology</source>
        <year>1988</year>
        <volume>268</volume>
        <issue>1</issue>
        <fpage>29</fpage>
        <lpage>37</lpage>
        <pub-id pub-id-type="doi">10.1002/cne.902680104</pub-id>
        <?supplied-pmid 3346382?>
        <pub-id pub-id-type="pmid">3346382</pub-id>
      </element-citation>
    </ref>
  </ref-list>
</back>
