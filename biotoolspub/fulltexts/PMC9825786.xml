<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id>
    <journal-id journal-id-type="publisher-id">bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1367-4803</issn>
    <issn pub-type="epub">1367-4811</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">9825786</article-id>
    <article-id pub-id-type="pmid">36495181</article-id>
    <article-id pub-id-type="doi">10.1093/bioinformatics/btac799</article-id>
    <article-id pub-id-type="publisher-id">btac799</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Original Paper</subject>
        <subj-group subj-group-type="category-toc-heading">
          <subject>Bioimage Informatics</subject>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI01060</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>LapTrack: linear assignment particle tracking with tunable metrics</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-8860-7178</contrib-id>
        <name>
          <surname>Fukai</surname>
          <given-names>Yohsuke T</given-names>
        </name>
        <aff><institution>Nonequilibrium Physics of Living Matter RIKEN Hakubi Research Team, RIKEN Center for Biosystems Dynamics Research</institution>, Kobe 650-0047, <country country="JP">Japan</country></aff>
        <xref rid="btac799-cor1" ref-type="corresp"/>
        <!--ysk@yfukai.net-->
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0001-9395-9875</contrib-id>
        <name>
          <surname>Kawaguchi</surname>
          <given-names>Kyogo</given-names>
        </name>
        <aff><institution>Nonequilibrium Physics of Living Matter RIKEN Hakubi Research Team, RIKEN Center for Biosystems Dynamics Research</institution>, Kobe 650-0047, <country country="JP">Japan</country></aff>
        <aff><institution>RIKEN Cluster for Pioneering Research</institution>, Kobe 650-0047, <country country="JP">Japan</country></aff>
        <aff><institution>Universal Biology Institute, The University of Tokyo</institution>, Tokyo 113-0033, <country country="JP">Japan</country></aff>
      </contrib>
    </contrib-group>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Peng</surname>
          <given-names>Hanchuan</given-names>
        </name>
        <role>Associate Editor</role>
      </contrib>
    </contrib-group>
    <author-notes>
      <corresp id="btac799-cor1">To whom correspondence should be addressed. <email>ysk@yfukai.net</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <month>1</month>
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2022-12-10">
      <day>10</day>
      <month>12</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>10</day>
      <month>12</month>
      <year>2022</year>
    </pub-date>
    <volume>39</volume>
    <issue>1</issue>
    <elocation-id>btac799</elocation-id>
    <history>
      <date date-type="received">
        <day>13</day>
        <month>9</month>
        <year>2022</year>
      </date>
      <date date-type="rev-recd">
        <day>09</day>
        <month>11</month>
        <year>2022</year>
      </date>
      <date date-type="editorial-decision">
        <day>03</day>
        <month>12</month>
        <year>2022</year>
      </date>
      <date date-type="accepted">
        <day>08</day>
        <month>12</month>
        <year>2022</year>
      </date>
      <date date-type="corrected-typeset">
        <day>21</day>
        <month>12</month>
        <year>2022</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>Â© The Author(s) 2022. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2022</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="btac799.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Motivation</title>
        <p>Particle tracking is an important step of analysis in a variety of scientific fields and is particularly indispensable for the construction of cellular lineages from live images. Although various supervised machine learning methods have been developed for cell tracking, the diversity of the data still necessitates heuristic methods that require parameter estimations from small amounts of data. For this, solving tracking as a linear assignment problem (LAP) has been widely applied and demonstrated to be efficient. However, there has been no implementation that allows custom connection costs, parallel parameter tuning with ground truth annotations, and the functionality to preserve ground truth connections, limiting the application to datasets with partial annotations.</p>
      </sec>
      <sec id="s2">
        <title>Results</title>
        <p>We developed LapTrack, a LAP-based tracker which allows including arbitrary cost functions and inputs, parallel parameter tuning and ground-truth track preservation. Analysis of real and artificial datasets demonstrates the advantage of custom metric functions for tracking score improvement from distance-only cases. The tracker can be easily combined with other Python-based tools for particle detection, segmentation and visualization.</p>
      </sec>
      <sec id="s3">
        <title>Availability and implementation</title>
        <p>LapTrack is available as a Python package on PyPi, and the notebook examples are shared at <ext-link xlink:href="https://github.com/yfukai/laptrack" ext-link-type="uri">https://github.com/yfukai/laptrack</ext-link>. The data and code for this publication are hosted at <ext-link xlink:href="https://github.com/NoneqPhysLivingMatterLab/laptrack-optimisation" ext-link-type="uri">https://github.com/NoneqPhysLivingMatterLab/laptrack-optimisation</ext-link>.</p>
      </sec>
      <sec id="s5">
        <title>Supplementary information</title>
        <p><xref rid="sup1" ref-type="supplementary-material">Supplementary data</xref> are available at <italic toggle="yes">Bioinformatics</italic> online.</p>
      </sec>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>JSPS KAKENHI</institution>
          </institution-wrap>
        </funding-source>
        <award-id>JP22K14016</award-id>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="6"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 Introduction</title>
    <p>Automated tracking of particles in timelapse images is important in a wide range of fields in science and is especially crucial in creating large datasets of cell lineages in biological studies. Recently there has been considerable development in tracking algorithms, where methods based on probabilistic modeling (<xref rid="btac799-B4" ref-type="bibr">Bise <italic toggle="yes">et al.</italic>, 2011</xref>; <xref rid="btac799-B5" ref-type="bibr">Bove <italic toggle="yes">et al.</italic>, 2017</xref>; <xref rid="btac799-B7" ref-type="bibr">Chen, 2021</xref>; <xref rid="btac799-B8" ref-type="bibr">Chenouard <italic toggle="yes">et al.</italic>, 2009</xref>, <xref rid="btac799-B9" ref-type="bibr">2014</xref>; <xref rid="btac799-B23" ref-type="bibr">Meijering <italic toggle="yes">et al.</italic>, 2009</xref>; <xref rid="btac799-B35" ref-type="bibr">Ulicna <italic toggle="yes">et al.</italic>, 2021</xref>; <xref rid="btac799-B36" ref-type="bibr">Ulman <italic toggle="yes">et al.</italic>, 2017</xref>) and supervised machine learning (<xref rid="btac799-B3" ref-type="bibr">Ben-Haim and Riklin-Raviv, 2022</xref>; <xref rid="btac799-B7" ref-type="bibr">Chen, 2021</xref>; <xref rid="btac799-B21" ref-type="bibr">Lou and Hamprecht, 2011</xref>; <xref rid="btac799-B36" ref-type="bibr">Ulman <italic toggle="yes">et al.</italic>, 2017</xref>) are increasingly being developed. The diverse nature of live imaging tasks, however, frequently requires tracking without underlining model or large-scale ground-truth annotations, emphasizing the need for a robust tracking algorithm with a small number of parameters that can be tuned by manual annotations.</p>
    <p>Defining and optimizing a global cost function to appropriately penalize wrong connections is a common approach in robust tracking methods. If the cost function is a linear sum of the costs associated with the connections, we can employ efficient algorithms (<xref rid="btac799-B16" ref-type="bibr">Jonker and Volgenant, 1987</xref>; <xref rid="btac799-B19" ref-type="bibr">Kuhn, 1955</xref>) to solve the global optimization problem called the linear assignment problem (LAP). The LAP-based tracking method has proven to be accurate and robust, especially for data with higher particle density. To deal with particle splitting (by division or oversegmentation) or merging (by undersegmentation), which is common in live cell data, <xref rid="btac799-B15" ref-type="bibr">Jaqaman <italic toggle="yes">et al.</italic> (2008)</xref> further developed a two-stage LAP method, with the second stage dedicated to the connection of splitting and merging branches. The cost function in their case was the squared Euclidean distance between the positions of the objects, with additional intensity-associated costs for splitting and merging.</p>
    <p>Tools have been developed to provide similar LAP-based algorithms with splitting and merging detection; TrackMate (<xref rid="btac799-B13" ref-type="bibr">Ershov <italic toggle="yes">et al.</italic>, 2022</xref>; <xref rid="btac799-B34" ref-type="bibr">Tinevez <italic toggle="yes">et al.</italic>, 2017</xref>), for example, provides distance-based LAP tracker with particle detection and segmentation workflow and a method to conduct manual correction, all within the Java-based framework in ImageJ (<xref rid="btac799-B28" ref-type="bibr">Schindelin <italic toggle="yes">et al.</italic>, 2012</xref>; <xref rid="btac799-B29" ref-type="bibr">Schneider <italic toggle="yes">et al.</italic>, 2012</xref>). Cell-ACDC (<xref rid="btac799-B26" ref-type="bibr">Padovani <italic toggle="yes">et al.</italic>, 2022</xref>), which was originally designed for yeast analysis, also implements an overlap-based LAP tracker with splitting detection, as well as various functions ranging from image alignment to manual correction that support the entire analysis workflow in Python. In addition, TracX (<xref rid="btac799-B11" ref-type="bibr">Cuny <italic toggle="yes">et al.</italic>, 2022</xref>) employs a multi-round tracking and correction workflow using a LAP tracker and mistracking detector by matching image features.</p>
    <p>Although other highly accurate methods have been proposed to work for the tracking problem with cell divisions, no single tracking algorithm will be perfect for all the diverse experimental situations (<xref rid="btac799-B36" ref-type="bibr">Ulman <italic toggle="yes">et al.</italic>, 2017</xref>). To obtain near-perfect segmentation and tracking for specific data, users must still optimize the segmentation and tracking steps, automatically or manually. In this regard, the LAP-based algorithm that robustly works with a small number of parameters continues to play a key role in generating the initial tracking data without large-scale manual annotation.</p>
    <p>An adaptive improvement to the original LAP-based tracking with distance can be made by using additional features taken from the cell images. For example, we can extract the morphology of each cell, such as its shape and size, from typical live cell images, as well as the signal levels from multiple fluorescent channels. The consistency of cell shape and fluorescent signals across time frames is useful when tracking is conducted by human eyes, especially when the frame rate of the data is not high enough. Therefore, it is desirable to be able to implement arbitrary inputs and cost functions in the LAP-based tracking scheme, as well as to tune the parameters using partial ground-truth annotations.</p>
    <p>These requirements motivated us to build a tool that recapitulates the LAP algorithm (<xref rid="btac799-B15" ref-type="bibr">Jaqaman <italic toggle="yes">et al.</italic>, 2008</xref>; <xref rid="btac799-B34" ref-type="bibr">Tinevez <italic toggle="yes">et al.</italic>, 2017</xref>) with additional flexibility and modularity; LapTrack is designed as a simple intermediate in the entire tracking pipeline that takes the positions and features of particles and returns LAP-optimized tracks. The three unique features of LapTrack are (i) arbitrary tunable cost functions for particle connection, (ii) integrability with other Python tools and (iii) the functionality to preserve ground-truth (annotated) connections. Within this framework, we can implement user-defined cost functions for connections that can take an arbitrary number of inputs. The tracking function is modularized and documented as an application programming interface (API) so that it can be integrated into any custom workflow in Python, allowing parallel parameter optimization as well as visualization of results in easy steps.</p>
    <p>In this article, we demonstrate how this pipeline can be used not only to optimize the tracking in a supervised manner, but how it is also useful for efficient manual correction of the tracks when combined with visualization tools such as napari (<xref rid="btac799-B31" ref-type="bibr">Sofroniew <italic toggle="yes">et al.</italic>, 2022</xref>).</p>
  </sec>
  <sec>
    <title>2 Materials and methods</title>
    <sec>
      <title>2.1 Datasets</title>
      <p>We here describe the data that we used to demonstrate the use cases of LapTrack: live cell images with ground truth segmentation and tracking (mouse paw epidermis dataset, cell migration dataset, Yeast Image Toolkit dataset and C2C12 dataset) and simulated data (colored particles) provided in <ext-link xlink:href="https://github.com/NoneqPhysLivingMatterLab/laptrack-optimisation" ext-link-type="uri">https://github.com/NoneqPhysLivingMatterLab/laptrack-optimisation</ext-link>. We also used high-density vesicles, yeast and 3D <italic toggle="yes">Drosophilla</italic> data to show that the tracking pipeline works for a wide range of applications.</p>
      <sec>
        <title>2.1.1 Mouse paw epidermis dataset</title>
        <p>The segmentation data and the ground truth tracking result collected and analyzed in <xref rid="btac799-B24" ref-type="bibr">Mesa <italic toggle="yes">et al.</italic> (2018)</xref>; <xref rid="btac799-B41" ref-type="bibr">Yamamoto <italic toggle="yes">et al.</italic> (2022)</xref> were used as a reference. The dataset contains 236 to 327 cells in the observation area and has 15 frames.</p>
      </sec>
      <sec>
        <title>2.1.2 Cell migration dataset</title>
        <p>Images, segmentation data for a portion of frames and the ground truth tracking result were downloaded from Zenodo (<xref rid="btac799-B27" ref-type="bibr">PylvÃ¤nÃ¤inen <italic toggle="yes">et al.</italic>, 2022</xref>). Segmentation was conducted by Cellpose (<xref rid="btac799-B32" ref-type="bibr">Stringer <italic toggle="yes">et al.</italic>, 2021</xref>) and manually corrected in napari (<xref rid="btac799-B31" ref-type="bibr">Sofroniew <italic toggle="yes">et al.</italic>, 2022</xref>). The ground-truth tracking result was also manually validated and corrected. The dataset contains 218 to 434 cells in the 648.95âÂµmâÃâ648.95âÂµm observation area and has 86 frames.</p>
      </sec>
      <sec>
        <title>2.1.3 Yeast image toolkit dataset</title>
        <p>The dataset was downloaded from the Yeast Image Toolkit website <ext-link xlink:href="http://yeast-image-toolkit.org/" ext-link-type="uri">http://yeast-image-toolkit.org/</ext-link> (<xref rid="btac799-B38" ref-type="bibr">Versari <italic toggle="yes">et al.</italic>, 2017</xref>). The data included the ground-truth cell positions at each time frame, which were used for the tracking in the benchmark (Section 3.2).</p>
      </sec>
      <sec>
        <title>2.1.4 C2C12 dataset</title>
        <p>The dataset (<xref rid="btac799-B18" ref-type="bibr">Ker <italic toggle="yes">et al.</italic>, 2018</xref>) was downloaded from the public repository (<xref rid="btac799-B17" ref-type="bibr">Ker, 2017</xref>). We used the first 780 frames of sequence 9 with the âBMP2â condition for the benchmark (Section 3.2), since it included the annotation for all cells in the field. We manually validated the dataset and removed duplicated annotations on a single cell.</p>
      </sec>
      <sec>
        <title>2.1.5 Colored particles</title>
        <p>We simulated the Brownian motion of 400 particles with colors in a 2D box of size 20âÃâ20 with periodic boundary conditions. The particles were split into two species, <italic toggle="yes">a</italic> and <italic toggle="yes">b</italic>, where the interaction between the particles was set as harmonic repulsion with the spring constants set as 1 for <italic toggle="yes">a</italic> and <italic toggle="yes">a</italic> pairs, 1.2 for <italic toggle="yes">a</italic> and <italic toggle="yes">b</italic> pairs, and 1.4 for <italic toggle="yes">b</italic> and <italic toggle="yes">b</italic> pairs. The dynamics was simulated with the <monospace>simulate.brownian</monospace> routine in Jax-MD (<xref rid="btac799-B30" ref-type="bibr">Schoenholz and Cubuk, 2020</xref>) with the parameters <italic toggle="yes">kTâ</italic>=<italic toggle="yes">â</italic>0.1 and <italic toggle="yes">dtâ</italic>=<italic toggle="yes">â</italic>0.001, where the mass and friction coefficient were set to the default values, 1 and 0.1. For each particle, labeled by <italic toggle="yes">i</italic>, a random integer <italic toggle="yes">n<sub>i</sub></italic> between 0 and 7 is assigned. The <italic toggle="yes">feature vector</italic>â<inline-formula id="IE1"><mml:math id="IM1" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>â</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mn>3</mml:mn></mml:msup></mml:mrow></mml:math></inline-formula>, corresponding to RGB colors, of each particle at each time step is then assigned as <inline-formula id="IE2"><mml:math id="IM2" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>R</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mi>i</mml:mi><mml:mn>3</mml:mn></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mi>R</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mi>i</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mi>R</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mi>i</mml:mi><mml:mn>1</mml:mn></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, where <inline-formula id="IE3"><mml:math id="IM3" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mi>i</mml:mi><mml:mi>k</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula> is the <italic toggle="yes">k</italic>th digit of <italic toggle="yes">n<sub>i</sub></italic> in the binary representation and <inline-formula id="IE4"><mml:math id="IM4" display="inline" overflow="scroll"><mml:mrow><mml:mi>R</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mo>Î´</mml:mo></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mi mathvariant="script" class="calligraphy">N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>0.5</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mo>Î´</mml:mo></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mi mathvariant="script" class="calligraphy">N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>6</mml:mn><mml:mo>,</mml:mo><mml:mn>0.5</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, where <inline-formula id="IE5"><mml:math id="IM5" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="script" class="calligraphy">N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>Î¼</mml:mo><mml:mo>,</mml:mo><mml:mo>Ï</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the normal random variable with mean <italic toggle="yes">Î¼</italic> and the standard deviation <italic toggle="yes">Ï</italic>. When used for the tracking benchmark, particles crossing the boundary are regarded as disconnected and belong to different tracks.</p>
      </sec>
      <sec>
        <title>2.1.6 Demonstration</title>
        <p>The simulated single-molecule dataset was downloaded from the Particle Tracking Challenge website <ext-link xlink:href="http://bioimageanalysis.org/track/" ext-link-type="uri">http://bioimageanalysis.org/track/</ext-link> (<xref rid="btac799-B9" ref-type="bibr">Chenouard <italic toggle="yes">et al.</italic>, 2014</xref>). We used the high-density vesicles dataset with the signal-to-noise ratio<italic toggle="yes">â</italic>7. Blobs were detected by the Laplacian-of-Gaussian (LoG) detector, <monospace>skimage.feature.blob_log</monospace> function in scikit-image (<xref rid="btac799-B37" ref-type="bibr">van der Walt <italic toggle="yes">et al.</italic>, 2014</xref>), with the parameters <monospace>min_sigma</monospace>â<monospace>=</monospace>â<monospace>1, max_sigma</monospace>â<monospace>=</monospace>â<monospace>5, num_sigma</monospace>â<monospace>=</monospace>â<monospace>5</monospace> and <monospace>threshold</monospace>â<monospace>=</monospace>â<monospace>0.05</monospace>. The detected points were tracked by <monospace>LapTrack</monospace> with <monospace>track_cost_cutoff</monospace>â<monospace>=</monospace>â<monospace>100</monospace>.</p>
        <p>For <xref rid="btac799-F1" ref-type="fig">FigureÂ 1c</xref>, the Yeast Image Toolkit data in <monospace>IT-Benchmark2/TestSet4/RawData</monospace> were segmented by Cellpose 0.7.2 (<xref rid="btac799-B32" ref-type="bibr">Stringer <italic toggle="yes">et al.</italic>, 2021</xref>) with the parameters <monospace>model_type=</monospace><monospace>â</monospace><monospace>cyto</monospace><monospace>â</monospace>, <monospace>net_avg=True</monospace>, and <monospace>diameter</monospace>â<monospace>=</monospace>â<monospace>30</monospace> in the <monospace>eval</monospace> function. The centroids of each segmented region were tracked by <monospace>LapTrack</monospace> with the default metric and <monospace>track_cost_cutoff</monospace>â<monospace>=</monospace>â<monospace>100, splitting_cost_cutoff</monospace>â<monospace>=</monospace>â<monospace>2500</monospace>.</p>
        <fig position="float" id="btac799-F1">
          <label>Fig. 1.</label>
          <caption>
            <p>(<bold>a</bold>) The schematic for the tracking algorithm (see main text). (<bold>b</bold>) Expected workflow for cell segmentation, tracking and analysis using tools in Python. The particle detection or segmentation results can be directly supplied to LapTrack. The tracking result can be directly visualized and analyzed in Python. (<bold>c</bold>) Examples of tracks generated by LapTrack. The lines indicate the result tracks. (Top) The dataset from Particle Tracking Challenge, detected by the LoG detector. (Middle) The dataset from the Yeast Image Toolkit website, detected by Cellpose. (Bottom) The <italic toggle="yes">Caenorhabditis elegans</italic> developing embryo dataset from the Cell Tracking Challenge website. (<bold>d</bold>) The schematic for the tracking algorithm with freezing annotated connections. (Top) Annotated connections (red solid lines). (Middle) Connections from (to) a point that has an annotated connection from (to) itself are forbidden. (Bottom) The verified connections are added to the tracking tree. The split and merges are treated similarly. (<bold>e</bold>) Illustration of the manual-correction-aware tracking with napari (see main text) using the cell migration dataset. (Left) Original tracking result with mistakes (gray solid lines). (Middle) Annotation points are added in napari (red points) to specify a correct connection (red solid line). (Right) Updated tracking result after annotation. The annotated track as well as tracks nearby are automatically corrected (gray solid lines) (A color version of this figure appears in the online version of this article)</p>
          </caption>
          <graphic xlink:href="btac799f1" position="float"/>
        </fig>
        <p>The 3D <italic toggle="yes">Drosophilla</italic> dataset (Fluo-N3DH-CE) was downloaded from the Cell Tracking Challenge website <ext-link xlink:href="http://celltrackingchallenge.net/" ext-link-type="uri">http://celltrackingchallenge.net/</ext-link> (<xref rid="btac799-B36" ref-type="bibr">Ulman <italic toggle="yes">et al.</italic>, 2017</xref>). The data included marked cell positions in each time frame, which were connected to generate tracks by <monospace>LapTrack</monospace> with <monospace>track_cost_cutoff</monospace>â<monospace>=</monospace>â<monospace>10000, splitting_cost _cutoff</monospace>â<monospace>=</monospace>â<monospace>2500</monospace>.</p>
      </sec>
    </sec>
    <sec>
      <title>2.2 Tracking implementation</title>
      <p>The implemented particle tracking algorithm follows the method proposed in <xref rid="btac799-B15" ref-type="bibr">Jaqaman <italic toggle="yes">et al.</italic> (2008)</xref>, with modifications following TrackMate (<xref rid="btac799-B13" ref-type="bibr">Ershov <italic toggle="yes">et al.</italic>, 2022</xref>; <xref rid="btac799-B34" ref-type="bibr">Tinevez <italic toggle="yes">et al.</italic>, 2017</xref>) and additional flexibility, as we describe in the following sections.</p>
      <sec>
        <title>2.2.1 Frame-to-frame LAP</title>
        <p>In the first step, the points in successive frames are connected by solving LAP, and then generating tracks without splits and merges (<xref rid="btac799-F1" ref-type="fig">Fig.Â 1a</xref>, left top). Specifically, for every pair of points with properties (such as Euclidean coordinates) <italic toggle="yes">x<sub>i</sub></italic> and <italic toggle="yes">x<sub>j</sub></italic> at frames <italic toggle="yes">t</italic> and <italic toggle="yes">tâ</italic>+<italic toggle="yes">â</italic>1, the costs <inline-formula id="IE6"><mml:math id="IM6" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>l</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> are computed using a user-definable metric function <italic toggle="yes">l</italic>. The costs <italic toggle="yes">d</italic> and <italic toggle="yes">b</italic> are then assigned to the particles not connected to any of the particles in the next and previous timesteps, respectively. The optimal assignment is found by minimizing the cost (<xref rid="btac799-B15" ref-type="bibr">Jaqaman <italic toggle="yes">et al.</italic>, 2008</xref>):
<disp-formula id="E1"><label>(1)</label><mml:math id="M1" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mtext>ff</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:munder><mml:mo>â</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>â</mml:mo><mml:mi mathvariant="script" class="calligraphy">C</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mn>0</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>D</mml:mi><mml:mi>d</mml:mi><mml:mo>+</mml:mo><mml:mi>B</mml:mi><mml:mi>b</mml:mi></mml:mrow><mml:mo>,</mml:mo></mml:math></disp-formula>where <inline-formula id="IE7"><mml:math id="IM7" display="inline" overflow="scroll"><mml:mi mathvariant="script" class="calligraphy">C</mml:mi></mml:math></inline-formula> is the set of all connected index pairs, <italic toggle="yes">B</italic> and <italic toggle="yes">D</italic> are the numbers of the points which does not have a connection to the previous and next timesteps, respectively, and <inline-formula id="IE8"><mml:math id="IM8" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mn>0</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mi>min</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>d</mml:mi><mml:mo>,</mml:mo><mml:mi>b</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> (see <xref rid="sup1" ref-type="supplementary-material">Supplementary Material</xref> for algorithm details). In the default setting, <italic toggle="yes">d</italic> and <italic toggle="yes">b</italic> are calculated as <inline-formula id="IE9"><mml:math id="IM9" display="inline" overflow="scroll"><mml:mrow><mml:mn>1.05</mml:mn><mml:mo>Ã</mml:mo><mml:msup><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mn>90</mml:mn><mml:mo>%</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>, where <inline-formula id="IE10"><mml:math id="IM10" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mn>90</mml:mn><mml:mo>%</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> is the 90% percentile value of the all finite entries in <inline-formula id="IE11"><mml:math id="IM11" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> (<xref rid="btac799-B15" ref-type="bibr">Jaqaman <italic toggle="yes">et al.</italic>, 2008</xref>). The default metric for <italic toggle="yes">l</italic> is set to the squared Euclidean distance <inline-formula id="IE12"><mml:math id="IM12" display="inline" overflow="scroll"><mml:mrow><mml:mi>l</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mrow><mml:mo>â</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>â</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>â</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mn>2</mml:mn><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> (<xref rid="btac799-B13" ref-type="bibr">Ershov <italic toggle="yes">et al.</italic>, 2022</xref>; <xref rid="btac799-B15" ref-type="bibr">Jaqaman <italic toggle="yes">et al.</italic>, 2008</xref>; <xref rid="btac799-B34" ref-type="bibr">Tinevez <italic toggle="yes">et al.</italic>, 2017</xref>) with which the cost-minimizing association can be interpreted as the maximum log-likelihood solution for Brownian particles when we ignore splitting and merging (<xref rid="btac799-B10" ref-type="bibr">Crocker and Grier, 1996</xref>).</p>
      </sec>
      <sec>
        <title>2.2.2 Segment-connecting LAP</title>
        <p>In the second step, another LAP is solved to predict splitting, merging, and gap closing (<xref rid="btac799-F1" ref-type="fig">Fig.Â 1a</xref>, left bottom). Gap closing connects free segment ends with allowing frame skips. The gap closing cost <inline-formula id="IE13"><mml:math id="IM13" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:mo>Î±</mml:mo><mml:mo>Î²</mml:mo></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>g</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo>Î±</mml:mo></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo>Î²</mml:mo></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> is calculated by a user-definable metric <italic toggle="yes">g</italic> for all possible connections between free ends up to a specified frame difference, and the splitting and merging costs <inline-formula id="IE14"><mml:math id="IM14" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mo>Î±</mml:mo><mml:mo>Î²</mml:mo></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo>Î±</mml:mo></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo>Î²</mml:mo></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE15"><mml:math id="IM15" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mo>Î±</mml:mo><mml:mo>Î²</mml:mo></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>m</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo>Î±</mml:mo></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo>Î²</mml:mo></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> are calculated for all possible connections between a free end and a track midpoint by user-definable metrics <italic toggle="yes">s</italic> and <italic toggle="yes">m</italic>. The metrics <italic toggle="yes">g</italic>, <italic toggle="yes">s</italic> and <italic toggle="yes">m</italic> default to the squared Euclidean distance. Then, the optimal assignment is calculated by minimizing the overall cost:
<disp-formula id="E2"><label>(2)</label><mml:math id="M2" display="block" overflow="scroll"><mml:mtable><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mtext>sc</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:munder><mml:mo>â</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>Î±</mml:mo><mml:mo>,</mml:mo><mml:mo>Î²</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>â</mml:mo><mml:mi mathvariant="script" class="calligraphy">G</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:mo>Î±</mml:mo><mml:mo>Î²</mml:mo></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mn>0</mml:mn><mml:mo>â²</mml:mo></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:munder><mml:mo>â</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>Î±</mml:mo><mml:mo>,</mml:mo><mml:mo>Î²</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>â</mml:mo><mml:mi mathvariant="script" class="calligraphy">S</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mo>Î±</mml:mo><mml:mo>Î²</mml:mo></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mn>0</mml:mn><mml:mo>â²</mml:mo></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:munder><mml:mo>â</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>Î±</mml:mo><mml:mo>,</mml:mo><mml:mo>Î²</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>â</mml:mo><mml:mi mathvariant="script" class="calligraphy">M</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mo>Î±</mml:mo><mml:mo>Î²</mml:mo></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mn>0</mml:mn><mml:mo>â²</mml:mo></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>+</mml:mo><mml:mi>D</mml:mi><mml:mi>d</mml:mi><mml:mo>+</mml:mo><mml:mi>B</mml:mi><mml:mi>b</mml:mi><mml:mo>+</mml:mo><mml:mi>D</mml:mi><mml:mo>â²</mml:mo><mml:mi>d</mml:mi><mml:mo>â²</mml:mo><mml:mo>+</mml:mo><mml:mi>B</mml:mi><mml:mo>â²</mml:mo><mml:mi>b</mml:mi><mml:mo>â²</mml:mo><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>where <inline-formula id="IE16"><mml:math id="IM16" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="script" class="calligraphy">G</mml:mi><mml:mo>,</mml:mo><mml:mo>â</mml:mo><mml:mi mathvariant="script" class="calligraphy">S</mml:mi></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE17"><mml:math id="IM17" display="inline" overflow="scroll"><mml:mi mathvariant="script" class="calligraphy">M</mml:mi></mml:math></inline-formula> are the set of all gap-closing, splitting and merging index pairs, <italic toggle="yes">D</italic> and <italic toggle="yes">B</italic> are the number of the unconnected track ends and starts, <inline-formula id="IE18"><mml:math id="IM18" display="inline" overflow="scroll"><mml:mrow><mml:mi>D</mml:mi><mml:mo>â²</mml:mo></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE19"><mml:math id="IM19" display="inline" overflow="scroll"><mml:mrow><mml:mi>B</mml:mi><mml:mo>â²</mml:mo></mml:mrow></mml:math></inline-formula> are the number of the track middle points that are not connected to other track ends as the split and merge, respectively (costs <inline-formula id="IE20"><mml:math id="IM20" display="inline" overflow="scroll"><mml:mrow><mml:mi>d</mml:mi><mml:mo>â²</mml:mo></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE21"><mml:math id="IM21" display="inline" overflow="scroll"><mml:mrow><mml:mi>b</mml:mi><mml:mo>â²</mml:mo></mml:mrow></mml:math></inline-formula> are assigned to them, respectively) and <inline-formula id="IE22"><mml:math id="IM22" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mn>0</mml:mn><mml:mo>â²</mml:mo></mml:msubsup><mml:mo>=</mml:mo><mml:mi>min</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:mo>Î±</mml:mo><mml:mo>Î²</mml:mo></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mo>Î±</mml:mo><mml:mo>Î²</mml:mo></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mo>Î±</mml:mo><mml:mo>Î²</mml:mo></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>d</mml:mi><mml:mo>,</mml:mo><mml:mi>b</mml:mi><mml:mo>,</mml:mo><mml:mi>d</mml:mi><mml:mo>â²</mml:mo><mml:mo>,</mml:mo><mml:mi>b</mml:mi><mml:mo>â²</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> (see <xref rid="sup1" ref-type="supplementary-material">Supplementary Material</xref> for details). In the default setting, <italic toggle="yes">d</italic>, <italic toggle="yes">b</italic>, <inline-formula id="IE23"><mml:math id="IM23" display="inline" overflow="scroll"><mml:mrow><mml:mi>d</mml:mi><mml:mo>â²</mml:mo></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE24"><mml:math id="IM24" display="inline" overflow="scroll"><mml:mrow><mml:mi>b</mml:mi><mml:mo>â²</mml:mo></mml:mrow></mml:math></inline-formula> are calculated analogously to the frame-to-frame LAP.</p>
      </sec>
      <sec>
        <title>2.2.3 Freezing annotated tracks</title>
        <p>We implemented an option to specify partial tracks within the data to be fixed as ground-truth verified connections (<xref rid="btac799-F1" ref-type="fig">Fig.Â 1d</xref>). Fixing the correct tracks is especially useful when performing manual corrections using visualization tools such as napari. As we demonstrate (<ext-link xlink:href="https://github.com/NoneqPhysLivingMatterLab/laptrack-optimisation" ext-link-type="uri">https://github.com/NoneqPhysLivingMatterLab/laptrack-optimisation</ext-link>) (<xref rid="btac799-F1" ref-type="fig">Fig.Â 1e</xref>), track connections can be specified to be fixed by annotating the cell regions before rerunning the LAP-based tracking. The resulting track preserves the training data tracks due to the masking scheme (<xref rid="btac799-F1" ref-type="fig">Fig.Â 1d</xref>).</p>
      </sec>
      <sec>
        <title>2.2.4 Parameter optimization</title>
        <p>In practice, we introduce the cut-off for the costs <italic toggle="yes">l<sub>ij</sub></italic>, <italic toggle="yes">g<sub>Î±Î²</sub></italic>, <italic toggle="yes">s<sub>Î±Î²</sub></italic> and <italic toggle="yes">m<sub>Î±Î²</sub></italic>, above which those values are regarded as infinity. The values of the cut-offs can affect the performance as demonstrated in Section 3.1, but it is difficult to optimize those values due to the non-differentiability of the LAP algorithm (<xref rid="btac799-B40" ref-type="bibr">Xu <italic toggle="yes">et al.</italic>, 2020</xref>) and the high computational cost for repeating the tracking routine. We therefore used non-gradient optimization methods to optimize the specified sets of the parameters in parallel using the package Ray Tune (<xref rid="btac799-B25" ref-type="bibr">Moritz <italic toggle="yes">et al.</italic>, 2018</xref>) with the Optuna optimizer (<xref rid="btac799-B1" ref-type="bibr">Akiba <italic toggle="yes">et al.</italic>, 2019</xref>) and random search. We selected the parameters that achieved the highest connection Jaccard index value or true positive rate, depending on the type of the training data (Section 2.3.1).</p>
      </sec>
      <sec>
        <title>2.2.5 Analysis pipeline</title>
        <p>LapTrack is written in Python with explicit API documentation and can be integrated with, for example, particle detectors in scikit-image and deep learning-based segmentation packages such as Cellpose (<xref rid="btac799-B32" ref-type="bibr">Stringer <italic toggle="yes">et al.</italic>, 2021</xref>) (<xref rid="btac799-F1" ref-type="fig">Fig.Â 1b and c</xref>). The output data is a networkx (<xref rid="btac799-B14" ref-type="bibr">Hagberg <italic toggle="yes">et al.</italic>, 2008</xref>) directed graph, which can be analyzed using the network analysis functions in the package. We also implemented utilities to convert data into pandas dataframes (<xref rid="btac799-B33" ref-type="bibr">pandas development team, 2020</xref>; <xref rid="btac799-B22" ref-type="bibr">Wes McKinney, 2010</xref>) and shorthand functions to track coordinates organized in a dataframe. In this paper, we used the ground-truth segmentation for each dataset as the input and analyzed the result tracks by networkx and pandas. Python scripts for tracking and analysis are provided at <ext-link xlink:href="https://github.com/NoneqPhysLivingMatterLab/laptrack-optimisation" ext-link-type="uri">https://github.com/NoneqPhysLivingMatterLab/laptrack-optimisation</ext-link>.</p>
      </sec>
    </sec>
    <sec>
      <title>2.3 Metrics for the tracking results</title>
      <p>To measure the performance of tracking, we employed the following metrics, which can also be calculated within LapTrack.</p>
      <sec>
        <title>2.3.1 Overall tracking scores</title>
        <p>To measure the overall track consistency, we calculated the <italic toggle="yes">target effectiveness</italic> (TE) and <italic toggle="yes">track purity</italic> (TP) (<xref rid="btac799-B4" ref-type="bibr">Bise <italic toggle="yes">et al.</italic>, 2011</xref>; <xref rid="btac799-B7" ref-type="bibr">Chen, 2021</xref>), which penalize the false negative and the false positive detections, respectively. Let us denote the set of ground truth tracks by <inline-formula id="IE25"><mml:math id="IM25" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="script" class="calligraphy">T</mml:mi></mml:mrow><mml:mi>j</mml:mi><mml:mi>g</mml:mi></mml:msubsup></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and predicted tracks by <inline-formula id="IE26"><mml:math id="IM26" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="script" class="calligraphy">T</mml:mi></mml:mrow><mml:mi>j</mml:mi><mml:mi>p</mml:mi></mml:msubsup></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>. TE for a single ground truth track <inline-formula id="IE27"><mml:math id="IM27" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="script" class="calligraphy">T</mml:mi></mml:mrow><mml:mi>j</mml:mi><mml:mi>g</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula> is calculated by finding the predicted track <inline-formula id="IE28"><mml:math id="IM28" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="script" class="calligraphy">T</mml:mi></mml:mrow><mml:mi>k</mml:mi><mml:mi>p</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula> that overlaps with <inline-formula id="IE29"><mml:math id="IM29" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="script" class="calligraphy">T</mml:mi></mml:mrow><mml:mi>j</mml:mi><mml:mi>g</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula> in the largest number of the frames and then dividing the overlap frame counts by the total frame counts for <inline-formula id="IE30"><mml:math id="IM30" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="script" class="calligraphy">T</mml:mi></mml:mrow><mml:mi>j</mml:mi><mml:mi>g</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula>. The TE for the total dataset is calculated as the mean of TEs for all ground truth tracks, weighted by the length of the tracks. TP is defined analogously, with <inline-formula id="IE31"><mml:math id="IM31" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="script" class="calligraphy">T</mml:mi></mml:mrow><mml:mi>j</mml:mi><mml:mi>g</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE32"><mml:math id="IM32" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="script" class="calligraphy">T</mml:mi></mml:mrow><mml:mi>j</mml:mi><mml:mi>p</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula> being swapped in the definition. We also measured the <italic toggle="yes">mitotic branching correctness</italic> (<xref rid="btac799-B4" ref-type="bibr">Bise <italic toggle="yes">et al.</italic>, 2011</xref>; <xref rid="btac799-B7" ref-type="bibr">Chen, 2021</xref>), defined as the fraction of the number of correctly detected divisions over the total number of the divisions.</p>
      </sec>
      <sec>
        <title>2.3.2 Overlap between predicted and ground truth connections</title>
        <p>During the parameter optimization, we used a less computationally expensive quantity, the <italic toggle="yes">Jaccard index</italic> and the <italic toggle="yes">true positive rate</italic> of the connections to measure how well the predicted connections overlap with the ground truth. The quantity is defined by <inline-formula id="IE33"><mml:math id="IM33" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="script" class="calligraphy">E</mml:mi></mml:mrow><mml:mi>p</mml:mi></mml:msup><mml:mo>â©</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="script" class="calligraphy">E</mml:mi></mml:mrow><mml:mi>g</mml:mi></mml:msup></mml:mrow></mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="script" class="calligraphy">E</mml:mi></mml:mrow><mml:mi>p</mml:mi></mml:msup><mml:mo>âª</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="script" class="calligraphy">E</mml:mi></mml:mrow><mml:mi>g</mml:mi></mml:msup></mml:mrow></mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE34"><mml:math id="IM34" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="script" class="calligraphy">E</mml:mi></mml:mrow><mml:mi>p</mml:mi></mml:msup><mml:mo>â©</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="script" class="calligraphy">E</mml:mi></mml:mrow><mml:mi>g</mml:mi></mml:msup></mml:mrow></mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="script" class="calligraphy">E</mml:mi></mml:mrow><mml:mi>g</mml:mi></mml:msup></mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, respectively, where we denote the set of predicted and ground-truth connections by <inline-formula id="IE35"><mml:math id="IM35" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="script" class="calligraphy">E</mml:mi></mml:mrow><mml:mi>p</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE36"><mml:math id="IM36" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="script" class="calligraphy">E</mml:mi></mml:mrow><mml:mi>g</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula>, respectively, and the size of a set <inline-formula id="IE37"><mml:math id="IM37" display="inline" overflow="scroll"><mml:mi mathvariant="script" class="calligraphy">E</mml:mi></mml:math></inline-formula> by <inline-formula id="IE38"><mml:math id="IM38" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mi mathvariant="script" class="calligraphy">E</mml:mi><mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. In the benchmark of the Yeast Image Toolkit dataset (Section 3.2), we additionally calculated the F-score of the assignment <inline-formula id="IE39"><mml:math id="IM39" display="inline" overflow="scroll"><mml:mrow><mml:mn>2</mml:mn><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="script" class="calligraphy">E</mml:mi></mml:mrow><mml:mi>p</mml:mi></mml:msup><mml:mo>â©</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="script" class="calligraphy">E</mml:mi></mml:mrow><mml:mi>g</mml:mi></mml:msup></mml:mrow></mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="script" class="calligraphy">E</mml:mi></mml:mrow><mml:mi>p</mml:mi></mml:msup></mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="script" class="calligraphy">E</mml:mi></mml:mrow><mml:mi>g</mml:mi></mml:msup></mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> to compare the performance with previously reported results.</p>
      </sec>
    </sec>
  </sec>
  <sec>
    <title>3 Results</title>
    <sec>
      <title>3.1 Distance cut-off points can be optimized to increase performance</title>
      <p>We first investigated the performance against various cost cut-off points in the simplest cases where the costs for connecting, gap closing and splitting are the squared Euclidean distance between the centroids. Specifically, we varied the maximum distance allowed for frame-to-frame particle association (<monospace>max_distance</monospace>) and splitting and gap-closing association (<monospace>splitting_max_distance</monospace>), which defines the cut-off for <italic toggle="yes">l<sub>ij</sub></italic> and <italic toggle="yes">s<sub>Î±Î²</sub></italic> (<italic toggle="yes">g<sub>Î±Î²</sub></italic>), respectively, and investigated how the overall performance changes. In the mouse epidermis dataset (<xref rid="btac799-F2" ref-type="fig">Fig.Â 2a</xref>), we performed grid search in the parameters <monospace>max_distance</monospace> and <monospace>splitting_max_distance</monospace>. We found that there exists a maxima in the TE around some finite length scale, suggesting that optimization is useful in performance improvement even for the cut-off parameters (<xref rid="btac799-F2" ref-type="fig">Fig.Â 2b</xref>). We also found that the correlation of the tracking scores between mouse epidermis data from different regions are high upon changing of the parameters [<italic toggle="yes">râ</italic>=<italic toggle="yes">â</italic>0.96 (<italic toggle="yes">râ</italic>=<italic toggle="yes">â</italic>0.90) for TE (TP) using data with <inline-formula id="IE40"><mml:math id="IM40" display="inline" overflow="scroll"><mml:mrow><mml:mtext>TE</mml:mtext><mml:mo>&gt;</mml:mo><mml:mn>0.75</mml:mn></mml:mrow></mml:math></inline-formula> (<inline-formula id="IE41"><mml:math id="IM41" display="inline" overflow="scroll"><mml:mrow><mml:mtext>TP</mml:mtext><mml:mo>&gt;</mml:mo><mml:mn>0.75</mml:mn></mml:mrow></mml:math></inline-formula>), respectively (<xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S1</xref>)], meaning that the optimized parameters are transferable within similar data.</p>
      <fig position="float" id="btac799-F2">
        <label>Fig. 2.</label>
        <caption>
          <p>(<bold>a</bold>) An example snapshot for the mouse epidermis dataset. The white lines indicate the centroid displacement between frames. (<bold>b</bold>) TE as a function of <monospace>max_distance</monospace> and <monospace>splitting_max_distance</monospace> for the mouse epidermis dataset. The red point indicates the maxima. (<bold>c</bold>) An example snapshot for the cell migration dataset. (<bold>d</bold>) TE score for the cell migration dataset with skipped frames, with or without the drift term in the metric. (<bold>e</bold>) An example snapshot for the colored particles dataset. (<bold>f</bold>) TE score for the colored particles dataset with different frame intervals, with or without the feature difference term in the metric. The error bar indicates the standard deviation of five trials. (<bold>g</bold>) Mitotic branching correctness score for the mouse epidermis dataset, tracked with the centroid distances (centroid) or the overlap ratio (overlap). The error bar indicates the standard deviation of five trials</p>
        </caption>
        <graphic xlink:href="btac799f2" position="float"/>
      </fig>
    </sec>
    <sec>
      <title>3.2 Distance-only LAP tracker can achieve comparable performance to data-specific methods</title>
      <p>We then benchmarked the tracking performance of the simple distance-only LAP tracker with the Yeast Image Toolkit dataset. Since the published benchmark results in <xref rid="btac799-B38" ref-type="bibr">Versari <italic toggle="yes">et al.</italic> (2017)</xref> do not include divisions, we tracked ground truth segmentation positions without splitting, with different cut-off points <monospace>max_distance</monospace> and <monospace>gap_closing_max_distance</monospace> (the cut-off point for <italic toggle="yes">g<sub>Î±Î²</sub></italic>). We then calculated the TE, the assignment F-score (tracking F-score), and the F-score for the assignments between the first and the last frames (long-term tracking F-score). We used the <italic toggle="yes">Evaluation Platform</italic> software (<xref rid="btac799-B38" ref-type="bibr">Versari <italic toggle="yes">et al.</italic>, 2017</xref>) to calculate the F-scores. <xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S2</xref> shows that this simple tracker achieves TE higher than 0.9 for all the datasets, and the F-scores are comparable to or higher than most published methods (<xref rid="btac799-B38" ref-type="bibr">Versari <italic toggle="yes">et al.</italic>, 2017</xref>), except the long-term tracking F-score for TestSet 3 and 4, which have frames with large cell displacements. Note that the previous methods track the cells after their segmentation pipeline, whereas we started with the ground-truth segmentation which can be advantageous. Nevertheless, this result suggests that the distance-based LAP tracker can generate tracks with accuracy comparable to data-specific tracking methods, as long as we start with sufficiently accurate segmentation.</p>
      <p>We also performed a similar benchmark with the C2C12 dataset and found that the distance-only tracker yields the maximum TE of 0.998 when starting from ground-truth segmentation (<xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S3</xref>). This is higher than the score from the cutting-edge graph neural network-based tracking method; 0.976, which was obtained from the test including segmentation and in a larger dataset (<xref rid="btac799-B3" ref-type="bibr">Ben-Haim and Riklin-Raviv, 2022</xref>).</p>
    </sec>
    <sec>
      <title>3.3 Tunable cost function improves tracking performance</title>
      <p>We next investigated if variable cost functions help improve the tracking score for different datasets.</p>
      <p>In <xref rid="btac799-F2" ref-type="fig">FigureÂ 2c</xref>, we show a snapshot of the cell migration dataset. Here, the cells are moving collectively toward the upper open region. Due to this drift, LAP-based tracking based solely on Euclidean distance fails with large frame intervals, as demonstrated in <xref rid="btac799-F2" ref-type="fig">FigureÂ 2d</xref> using datasets with skipped frames. This situation can be easily fixed by changing the cost function by adding a drift term to the Euclidean distance as
<disp-formula id="E3"><label>(3)</label><mml:math id="M3" display="block" overflow="scroll"><mml:mrow><mml:mi>l</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mrow><mml:mo>â</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>â</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>d</mml:mi></mml:mrow><mml:mo>â</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mn>2</mml:mn><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:math></disp-formula>with the drift parameter <inline-formula id="IE42"><mml:math id="IM42" display="inline" overflow="scroll"><mml:mrow><mml:mi>d</mml:mi><mml:mo>â</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math></inline-formula> and defining <italic toggle="yes">g</italic> and <italic toggle="yes">s</italic> analogously (<xref rid="btac799-F2" ref-type="fig">Fig.Â 2d</xref>, <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S4</xref>). We used 5% of the non-dividing and dividing connections to tune <italic toggle="yes">d</italic> as well as the cut-offs so that they optimize the true positive rate of the connections. The details are summarized in the <xref rid="sup1" ref-type="supplementary-material">Supplementary Material</xref>.</p>
      <p>In real experimental data, particles may have features that help to identify species, such as the size, shape, and fluorescent intensities of genetic labels. In those cases, we can use those features in addition to the Euclidean distances to improve the performance. To illustrate this, we measured the tracking performance for simulated particles with eight species, characterized by different sets of feature values corresponding to RGB colors (<xref rid="btac799-F1" ref-type="fig">Fig.Â 1e</xref>, see Section 2.1.5 for details). We then defined the cost function as
<disp-formula id="E4"><label>(4)</label><mml:math id="M4" display="block" overflow="scroll"><mml:mrow><mml:mi>l</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>}</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>}</mml:mo></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mrow><mml:mo>â</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>â</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>â</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mn>2</mml:mn><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mi>w</mml:mi><mml:msubsup><mml:mrow><mml:mrow><mml:mrow><mml:mo>â</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>â</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>â</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mn>2</mml:mn><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>,</mml:mo></mml:math></disp-formula>where <inline-formula id="IE43"><mml:math id="IM43" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo>â</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mn>3</mml:mn></mml:msup></mml:mrow></mml:math></inline-formula> are the feature vectors. We tuned the parameter <italic toggle="yes">w</italic> as well as the distance cut-off using the training data with 100 frames so that the tracking result maximizes the connection Jaccard index. We then measured the tracking scores for an independent dataset with 100 frames. As shown in <xref rid="btac799-F2" ref-type="fig">Fig.Â 2f</xref>, with the features used in the metric, the target effectiveness with large frame interval remains above 0.8 while it drops to <inline-formula id="IE44"><mml:math id="IM44" display="inline" overflow="scroll"><mml:mrow><mml:mo>â¼</mml:mo><mml:mn>0.4</mml:mn></mml:mrow></mml:math></inline-formula> when only Euclidean distance is in the metric (<italic toggle="yes">wâ</italic>=<italic toggle="yes">â</italic>0), illustrating the performance improvement by including the particle features. We also observed an improvement in the other scores (<xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S5</xref>).</p>
      <p>For segmented images, we can also use the overlap between segmented regions to calculate the cost (<xref rid="btac799-B6" ref-type="bibr">Chalfoun <italic toggle="yes">et al.</italic>, 2010</xref>; <xref rid="btac799-B13" ref-type="bibr">Ershov <italic toggle="yes">et al.</italic>, 2022</xref>; <xref rid="btac799-B26" ref-type="bibr">Padovani <italic toggle="yes">et al.</italic>, 2022</xref>). The flexible implementation allows us to integrate the overlap metric in addition to the distance in the LAP framework. We define <italic toggle="yes">l</italic> (with <italic toggle="yes">g</italic> and <italic toggle="yes">s</italic> analogously) as
<disp-formula id="E5"><label>(5)</label><mml:math id="M5" display="block" overflow="scroll"><mml:mrow><mml:mi>l</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo>â</mml:mo><mml:mtext>log</mml:mtext><mml:mo>â</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mfrac><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>â©</mml:mo><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>A</mml:mi></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>which measures the overlap, where <italic toggle="yes">L<sub>i</sub></italic> and <italic toggle="yes">L<sub>j</sub></italic> are the set of pixel coordinates of the segmentation area for the particle <italic toggle="yes">i</italic> and <italic toggle="yes">j</italic> and <italic toggle="yes">A</italic> is a parameter. By comparing the tracking performance for the mouse epidermis dataset with the squared centroid Euclidean distance cases, we found that replacing the metric improves the mitotic branching correctness by <inline-formula id="IE45"><mml:math id="IM45" display="inline" overflow="scroll"><mml:mrow><mml:mo>â¼</mml:mo><mml:mn>10</mml:mn><mml:mo>%</mml:mo></mml:mrow></mml:math></inline-formula> (<xref rid="btac799-F2" ref-type="fig">Fig.Â 2g</xref>).</p>
    </sec>
  </sec>
  <sec>
    <title>4 Conclusion</title>
    <p>In this article, we showed how the LAP-based tracking pipeline with additional flexibility and optimizability can be useful in improving tracking performance in certain situations, and easily combined with visualization tools to conduct manual corrections. LapTrack, in large part, is complementary to TrackMate (<xref rid="btac799-B13" ref-type="bibr">Ershov <italic toggle="yes">et al.</italic>, 2022</xref>), which has a useful graphical user interface, support for including feature value differences, and its own optimization pipeline. Compared with TrackMate, LapTrack can take arbitrary inputs and cost functions and is flexible in its output, making it easier to connect with other upstream and downstream analysis pipelines. Trackpy (<xref rid="btac799-B2" ref-type="bibr">Allan <italic toggle="yes">et al.</italic>, 2021</xref>) provides a tracking routine based on the algorithm by <xref rid="btac799-B10" ref-type="bibr">Crocker and Grier (1996)</xref> in Python, as well as functions for particle detection, analysis and data input/output. One major difference is LapTrackâs ability to detect splitting and merging particles, which makes it more suitable for cell tracking. The tracking function in LapTrack is designed to help make accurate and validated tracks quickly and efficiently, with the hope to increase the amount of ground-truth data that can be used in training more sophisticated tracking methods.</p>
    <p>With a sufficient amount of manually annotated ground-truth data, machine learning-based approaches will likely outperform the current parameter optimization strategy of simple affinity metrics. Due to its flexibility, our package can be easily combined with strategies such as one-to-one association affinity learning (<xref rid="btac799-B12" ref-type="bibr">Emami <italic toggle="yes">et al.</italic>, 2020</xref>; <xref rid="btac799-B20" ref-type="bibr">Li <italic toggle="yes">et al.</italic>, 2009</xref>), structured learning (<xref rid="btac799-B21" ref-type="bibr">Lou and Hamprecht, 2011</xref>), and the metric learning approach combined with graph neural networks (<xref rid="btac799-B39" ref-type="bibr">Weng <italic toggle="yes">et al.</italic>, 2020</xref>), serving as a reusable platform for implementation.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material id="sup1" position="float" content-type="local-data">
      <label>btac799_Supplementary_Data</label>
      <media xlink:href="btac799_supplementary_data.zip">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ack id="ack1">
    <title>Acknowledgements</title>
    <p>We appreciate Dominik Waibel, Benedikt Mairhoermann, Tingying Peng, Carsten Marr and Matthias Meier for discussion; and Rory Cerbus, Somayeh Zeraati and Takaki Yamamoto for the reading of the manuscript. We acknowledge support by the RIKEN Information systems division for the use of the Supercomputer HOKUSAI BigWaterfall.</p>
    <sec>
      <title>Funding</title>
      <p>This work was supported by JSPS KAKENHI [JP22K14016 to Y.T.F.]; JSPS KAKENHI [JP18H04760, JP18K13515, JP19H05275 and JP19H05795 to K.K.].</p>
      <p><italic toggle="yes">Conflict of Interest</italic>: none declared.</p>
    </sec>
  </ack>
  <sec sec-type="data-availability">
    <title>Data availability</title>
    <p>The data underlying this article are available in GitHub at <ext-link xlink:href="https://github.com/yfukai/laptrack" ext-link-type="uri">https://github.com/yfukai/laptrack</ext-link> and <ext-link xlink:href="https://github.com/NoneqPhysLivingMatterLab/laptrack-optimisation" ext-link-type="uri">https://github.com/NoneqPhysLivingMatterLab/laptrack-optimisation</ext-link>, and archived in Zenodo at <ext-link xlink:href="https://doi.org/10.5281/zenodo.5519537" ext-link-type="uri">https://doi.org/10.5281/zenodo.5519537</ext-link> and <ext-link xlink:href="https://doi.org/10.5281/zenodo.7435087" ext-link-type="uri">https://doi.org/10.5281/zenodo.7435087</ext-link>.</p>
  </sec>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="btac799-B1">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Akiba</surname><given-names>T.</given-names></string-name></person-group><etal>et al</etal> (<year>2019</year>) Optuna: a next-generation hyperparameter optimization framework. In: <italic toggle="yes">Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</italic>, KDD â19. Association for Computing Machinery, New York, NY, USA. pp. <fpage>2623</fpage>â<lpage>2631</lpage>.</mixed-citation>
    </ref>
    <ref id="btac799-B2">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Allan</surname><given-names>D.B.</given-names></string-name></person-group><etal>et al</etal> (<year>2021</year>) soft-matter/trackpy: Trackpy v0.5.0. Zenodo. <pub-id pub-id-type="doi">10.5281/zenodo.4682814</pub-id>.</mixed-citation>
    </ref>
    <ref id="btac799-B3">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Ben-Haim</surname><given-names>T.</given-names></string-name>, <string-name><surname>Riklin-Raviv</surname><given-names>T.</given-names></string-name></person-group> (<year>2022</year>) Graph neural network for cell tracking in microscopy videos. In: Avidan,S. et al. (eds.)Â <italic toggle="yes">Computer Vision â ECCV 2022. ECCV 2022. Lecture Notes in Computer Science</italic>, Vol. 13681. Springer, Cham. <pub-id pub-id-type="doi">10.1007/978-3-031-19803-8_36</pub-id>.</mixed-citation>
    </ref>
    <ref id="btac799-B4">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Bise</surname><given-names>R.</given-names></string-name></person-group><etal>et al</etal> (<year>2011</year>) Reliable cell tracking by global data association. In: <italic toggle="yes">2011 IEEE International Symposium on Biomedical Imaging: From Nano to Macro</italic>. IEEE, Chicago, IL, USA. pp. <fpage>1004</fpage>â<lpage>1010</lpage>. <pub-id pub-id-type="doi">10.1109/ISBI.2011.5872571</pub-id>.</mixed-citation>
    </ref>
    <ref id="btac799-B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bove</surname><given-names>A.</given-names></string-name></person-group><etal>et al</etal> (<year>2017</year>) <article-title>Local cellular neighborhood controls proliferation in cell competition</article-title>. <source>Mol. Biol. Cell</source>., <volume>28</volume>, <fpage>3215</fpage>â<lpage>3228</lpage>.<pub-id pub-id-type="pmid">28931601</pub-id></mixed-citation>
    </ref>
    <ref id="btac799-B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chalfoun</surname><given-names>J.</given-names></string-name></person-group><etal>et al</etal> (<year>2010</year>) <article-title>Overlap-based cell tracker</article-title>. <source>J. Res. Natl. Inst. Stand. Technol</source>., <volume>115</volume>, <fpage>477</fpage>â<lpage>486</lpage>.<pub-id pub-id-type="pmid">27134800</pub-id></mixed-citation>
    </ref>
    <ref id="btac799-B7">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Chen</surname><given-names>M.</given-names></string-name></person-group> (<year>2021</year>) <part-title>Chapter 5 - Cell tracking in time-lapse microscopy image sequences</part-title>. In: <person-group person-group-type="editor"><string-name><surname>Chen</surname><given-names>M.</given-names></string-name></person-group> (ed.) <source>Computer Vision for Microscopy Image Analysis, Computer Vision and Pattern Recognition</source>. <publisher-name>Academic Press, Cambridge, MA, USA</publisher-name>, pp. <fpage>101</fpage>â<lpage>129</lpage>.</mixed-citation>
    </ref>
    <ref id="btac799-B8">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chenouard</surname><given-names>N.</given-names></string-name></person-group><etal>et al</etal> (<year>2009</year>) <article-title>Tracking algorithms chase down pathogens</article-title>. <source>Biotechnol. J</source>., <volume>4</volume>, <fpage>838</fpage>â<lpage>845</lpage>.<pub-id pub-id-type="pmid">19548236</pub-id></mixed-citation>
    </ref>
    <ref id="btac799-B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chenouard</surname><given-names>N.</given-names></string-name></person-group><etal>et al</etal> (<year>2014</year>) <article-title>Objective comparison of particle tracking methods</article-title>. <source>Nat. Methods</source>, <volume>11</volume>, <fpage>281</fpage>â<lpage>289</lpage>.<pub-id pub-id-type="pmid">24441936</pub-id></mixed-citation>
    </ref>
    <ref id="btac799-B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Crocker</surname><given-names>J.C.</given-names></string-name>, <string-name><surname>Grier</surname><given-names>D.G.</given-names></string-name></person-group> (<year>1996</year>) <article-title>Methods of digital video microscopy for colloidal studies</article-title>. <source>J. Colloid Interface Sci</source>., <volume>179</volume>, <fpage>298</fpage>â<lpage>310</lpage>.</mixed-citation>
    </ref>
    <ref id="btac799-B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cuny</surname><given-names>A.P.</given-names></string-name></person-group><etal>et al</etal> (<year>2022</year>) <article-title>Cell region fingerprints enable highly precise single-cell tracking and lineage reconstruction</article-title>. <source>Nat. Methods</source>, <volume>19</volume>, <fpage>1276</fpage>â<lpage>1285</lpage>.<pub-id pub-id-type="pmid">36138173</pub-id></mixed-citation>
    </ref>
    <ref id="btac799-B12">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Emami</surname><given-names>P.</given-names></string-name></person-group><etal>et al</etal> (<year>2020</year>) <article-title>Machine learning methods for data association in multi-object tracking</article-title>. <source>ACM Comput. Surv</source>., <volume>53</volume>, <fpage>1</fpage>â<lpage>34</lpage>.</mixed-citation>
    </ref>
    <ref id="btac799-B13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ershov</surname><given-names>D.</given-names></string-name></person-group><etal>et al</etal> (<year>2022</year>) <article-title>TrackMate 7: integrating state-of-the-art segmentation algorithms into tracking pipelines</article-title>. <source>Nat. Methods</source>, <volume>19</volume>, <fpage>829</fpage>â<lpage>832</lpage>.<pub-id pub-id-type="pmid">35654950</pub-id></mixed-citation>
    </ref>
    <ref id="btac799-B14">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Hagberg</surname><given-names>A.A.</given-names></string-name></person-group><etal>et al</etal> (<year>2008</year>) <part-title>Exploring network structure, dynamics, and function using NetworkX</part-title>. In: <person-group person-group-type="editor"><string-name><surname>Varoquaux</surname><given-names>G.</given-names></string-name></person-group><etal>et al</etal> (eds) <source>Proceedings of the 7th Python in Science Conference</source>. <publisher-loc>Pasadena, CA, USA</publisher-loc>, pp. <fpage>11</fpage>â<lpage>15</lpage>.</mixed-citation>
    </ref>
    <ref id="btac799-B15">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jaqaman</surname><given-names>K.</given-names></string-name></person-group><etal>et al</etal> (<year>2008</year>) <article-title>Robust single-particle tracking in live-cell time-lapse sequences</article-title>. <source>Nat. Methods</source>., <volume>5</volume>, <fpage>695</fpage>â<lpage>702</lpage>.<pub-id pub-id-type="pmid">18641657</pub-id></mixed-citation>
    </ref>
    <ref id="btac799-B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jonker</surname><given-names>R.</given-names></string-name>, <string-name><surname>Volgenant</surname><given-names>A.</given-names></string-name></person-group> (<year>1987</year>) <article-title>A shortest augmenting path algorithm for dense and sparse linear assignment problems</article-title>. <source>Computing</source>, <volume>38</volume>, <fpage>325</fpage>â<lpage>340</lpage>.</mixed-citation>
    </ref>
    <ref id="btac799-B17">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Ker</surname><given-names>D.F.E.</given-names></string-name></person-group> (<year>2017</year>) Phase contrast time lapse microscopy image datasets with human-generated ground truths and computer-aided cell tracking annotations. OSF. <pub-id pub-id-type="doi">10.17605/OSF.IO/YSAQ2</pub-id>.</mixed-citation>
    </ref>
    <ref id="btac799-B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ker</surname><given-names>D.F.E.</given-names></string-name></person-group><etal>et al</etal> (<year>2018</year>) <article-title>Phase contrast time-lapse microscopy datasets with automated and manual cell tracking annotations</article-title>. <source>Sci. Data</source>, <volume>5</volume>, <fpage>180237</fpage>.<pub-id pub-id-type="pmid">30422120</pub-id></mixed-citation>
    </ref>
    <ref id="btac799-B19">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kuhn</surname><given-names>H.W.</given-names></string-name></person-group> (<year>1955</year>) <article-title>The Hungarian method for the assignment problem</article-title>. <source>Naval Res. Logistics</source>, <volume>2</volume>, <fpage>83</fpage>â<lpage>97</lpage>.</mixed-citation>
    </ref>
    <ref id="btac799-B20">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Li</surname><given-names>Y.</given-names></string-name></person-group><etal>et al</etal> (<year>2009</year>) Learning to associate: HybridBoosted multi-target tracker for crowded scene. In: <italic toggle="yes">2009 IEEE Conference on Computer Vision and Pattern Recognition</italic>, <italic toggle="yes">Miami, FL, USA</italic>, pp. <fpage>2953</fpage>â<lpage>2960</lpage>. <pub-id pub-id-type="doi">10.1109/CVPR.2009.5206735</pub-id>.</mixed-citation>
    </ref>
    <ref id="btac799-B21">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Lou</surname><given-names>X.</given-names></string-name>, <string-name><surname>Hamprecht</surname><given-names>F.A.</given-names></string-name></person-group> (<year>2011</year>) <part-title>Structured learning for cell tracking</part-title>. In: <source>Advances in Neural Information Processing Systems</source>, Vol. <volume>24</volume>. <publisher-name>Curran Associates, Inc</publisher-name>., pp. <fpage>1296</fpage>â<lpage>1304</lpage>.</mixed-citation>
    </ref>
    <ref id="btac799-B22">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>McKinney</surname><given-names>W.</given-names></string-name></person-group> (<year>2010</year>) Data structures for statistical computing in Python. In: <person-group person-group-type="editor"><string-name><surname>van der Walt</surname><given-names>S.</given-names></string-name>, <string-name><surname>Millman</surname><given-names>J.</given-names></string-name></person-group> (eds) <italic toggle="yes">Proceedings of the 9th Python in Science Conference,</italic>Â <italic toggle="yes">Austin, TX, USA</italic>, pp. <fpage>56</fpage>â<lpage>61</lpage>. <pub-id pub-id-type="doi">10.25080/Majora-92bf1922-00a</pub-id>.</mixed-citation>
    </ref>
    <ref id="btac799-B23">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Meijering</surname><given-names>E.</given-names></string-name></person-group><etal>et al</etal> (<year>2009</year>) <article-title>Tracking in cell and developmental biology</article-title>. <source>Semin. Cell Dev. Biol</source>., <volume>20</volume>, <fpage>894</fpage>â<lpage>902</lpage>.<pub-id pub-id-type="pmid">19660567</pub-id></mixed-citation>
    </ref>
    <ref id="btac799-B24">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mesa</surname><given-names>K.R.</given-names></string-name></person-group><etal>et al</etal> (<year>2018</year>) <article-title>Homeostatic epidermal stem cell self-renewal is driven by local differentiation</article-title>. <source>Cell Stem Cell</source>, <volume>23</volume>, <fpage>677</fpage>â<lpage>686.e4</lpage>.<pub-id pub-id-type="pmid">30269903</pub-id></mixed-citation>
    </ref>
    <ref id="btac799-B25">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Moritz</surname><given-names>P.</given-names></string-name></person-group><etal>et al</etal> (<year>2018</year>) Ray: a distributed framework for emerging AI applications. In:Â <italic toggle="yes">13th USENIX Symposium on Operating Systems Design and Implementation (OSDI 18)</italic>. USENIX Association, Carlsbad, CA, USA, pp. <fpage>561</fpage>â<lpage>577</lpage>.</mixed-citation>
    </ref>
    <ref id="btac799-B26">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Padovani</surname><given-names>F.</given-names></string-name></person-group><etal>et al</etal> (<year>2022</year>) <article-title>Segmentation, tracking and cell cycle analysis of live-cell imaging data with Cell-ACDC</article-title>. <source>BMC Biol</source>., <volume>20</volume>, <fpage>174</fpage>.<pub-id pub-id-type="pmid">35932043</pub-id></mixed-citation>
    </ref>
    <ref id="btac799-B27">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>PylvÃ¤nÃ¤inen</surname><given-names>J.W.</given-names></string-name></person-group><etal>et al</etal> (<year>2022</year>) Quantitative comparison of tracking performance using TrackMate-Helper. Zenodo. <pub-id pub-id-type="doi">10.5281/zenodo.6255991</pub-id>.</mixed-citation>
    </ref>
    <ref id="btac799-B28">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Schindelin</surname><given-names>J.</given-names></string-name></person-group><etal>et al</etal> (<year>2012</year>) <article-title>Fiji: an open-source platform for biological-image analysis</article-title>. <source>Nat. Methods</source>, <volume>9</volume>, <fpage>676</fpage>â<lpage>682</lpage>.<pub-id pub-id-type="pmid">22743772</pub-id></mixed-citation>
    </ref>
    <ref id="btac799-B29">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Schneider</surname><given-names>C.A.</given-names></string-name></person-group><etal>et al</etal> (<year>2012</year>) <article-title>NIH image to ImageJ: 25 years of image analysis</article-title>. <source>Nat. Methods</source>, <volume>9</volume>, <fpage>671</fpage>â<lpage>675</lpage>.<pub-id pub-id-type="pmid">22930834</pub-id></mixed-citation>
    </ref>
    <ref id="btac799-B30">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Schoenholz</surname><given-names>S.</given-names></string-name>, <string-name><surname>Cubuk</surname><given-names>E.D.</given-names></string-name></person-group> (<year>2020</year>) <part-title>JAX MD: a framework for differentiable physics</part-title>. In <source>Advances in Neural Information Processing Systems</source>, Vol. <volume>33</volume>. <publisher-name>Curran Associates, Inc</publisher-name>., pp. <fpage>11428</fpage>â<lpage>11441</lpage>.</mixed-citation>
    </ref>
    <ref id="btac799-B31">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Sofroniew</surname><given-names>N.</given-names></string-name></person-group><etal>et al</etal> (<year>2022</year>) napari: a multi-dimensional image viewer for Python. Zenodo. <pub-id pub-id-type="doi">10.5281/zenodo.6598542</pub-id>.</mixed-citation>
    </ref>
    <ref id="btac799-B32">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Stringer</surname><given-names>C.</given-names></string-name></person-group><etal>et al</etal> (<year>2021</year>) <article-title>Cellpose: a generalist algorithm for cellular segmentation</article-title>. <source>Nat. Methods</source>, <volume>18</volume>, <fpage>100</fpage>â<lpage>106</lpage>.<pub-id pub-id-type="pmid">33318659</pub-id></mixed-citation>
    </ref>
    <ref id="btac799-B33">
      <mixed-citation publication-type="other"><collab>The pandas development team</collab>. (<year>2020</year>) pandas-dev/pandas: pandas. Zenodo. <pub-id pub-id-type="doi">10.5281/zenodo.3509134</pub-id>.</mixed-citation>
    </ref>
    <ref id="btac799-B34">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tinevez</surname><given-names>J.-Y.</given-names></string-name></person-group><etal>et al</etal> (<year>2017</year>) <article-title>Trackmate: an open and extensible platform for single-particle tracking</article-title>. <source>Methods</source>, <volume>115</volume>, <fpage>80</fpage>â<lpage>90</lpage>.<pub-id pub-id-type="pmid">27713081</pub-id></mixed-citation>
    </ref>
    <ref id="btac799-B35">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ulicna</surname><given-names>K.</given-names></string-name></person-group><etal>et al</etal> (<year>2021</year>) <article-title>Automated deep lineage tree analysis using a Bayesian single cell tracking approach</article-title>. <source>Front. Comput. Sci</source>., <volume>3</volume>, <fpage>92</fpage>.</mixed-citation>
    </ref>
    <ref id="btac799-B36">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ulman</surname><given-names>V.</given-names></string-name></person-group><etal>et al</etal> (<year>2017</year>) <article-title>An objective comparison of cell-tracking algorithms</article-title>. <source>Nat. Methods</source>, <volume>14</volume>, <fpage>1141</fpage>â<lpage>1152</lpage>.<pub-id pub-id-type="pmid">29083403</pub-id></mixed-citation>
    </ref>
    <ref id="btac799-B37">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>van der Walt</surname><given-names>S.</given-names></string-name></person-group><etal>et al</etal>; <collab>scikit-image contributors</collab>. (<year>2014</year>) <article-title>Scikit-image: image processing in python</article-title>. <source>PeerJ</source>, <volume>2</volume>, <fpage>e453</fpage>.<pub-id pub-id-type="pmid">25024921</pub-id></mixed-citation>
    </ref>
    <ref id="btac799-B38">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Versari</surname><given-names>C.</given-names></string-name></person-group><etal>et al</etal> (<year>2017</year>) <article-title>Long-term tracking of budding yeast cells in brightfield microscopy: cellStar and the evaluation platform</article-title>. <source>J. R. Soc. Interface</source>, <volume>14</volume>, <fpage>20160705</fpage>.<pub-id pub-id-type="pmid">28179544</pub-id></mixed-citation>
    </ref>
    <ref id="btac799-B39">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Weng</surname><given-names>X.</given-names></string-name></person-group><etal>et al</etal> (<year>2020</year>) GNN3DMOT: graph neural network for 3D multi-object tracking with 2D-3D multi-feature learning. In: <source><italic toggle="yes">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,</italic></source><italic toggle="yes">Seattle, WA, USA,</italic> pp. <fpage>6499</fpage>â<lpage>6508</lpage>. <pub-id pub-id-type="doi">10.1109/CVPR42600.2020.00653</pub-id>.</mixed-citation>
    </ref>
    <ref id="btac799-B40">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Xu</surname><given-names>Y.</given-names></string-name></person-group><etal>et al</etal> (<year>2020</year>) How to train your deep multi-object tracker. In: <italic toggle="yes">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</italic>,Â <italic toggle="yes">Seattle, WA, USA</italic>, pp. <fpage>6787</fpage>â<lpage>6796</lpage>. <pub-id pub-id-type="doi">10.1109/CVPR42600.2020.00682</pub-id>.</mixed-citation>
    </ref>
    <ref id="btac799-B41">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yamamoto</surname><given-names>T.</given-names></string-name></person-group><etal>et al</etal> (<year>2022</year>) <article-title>Probing the rules of cell coordination in live tissues by interpretable machine learning based on graph neural networks</article-title>. <source>PLoS Comput. Biol</source>., <volume>18</volume>, <fpage>e1010477</fpage>.<pub-id pub-id-type="pmid">36067226</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
