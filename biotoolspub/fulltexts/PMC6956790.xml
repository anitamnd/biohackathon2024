<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1 20151215//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.1?>
<?ConverterInfo.XSLTName jp2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id>
    <journal-id journal-id-type="publisher-id">bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1367-4803</issn>
    <issn pub-type="epub">1367-4811</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">6956790</article-id>
    <article-id pub-id-type="doi">10.1093/bioinformatics/btz512</article-id>
    <article-id pub-id-type="publisher-id">btz512</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Original Papers</subject>
        <subj-group subj-group-type="category-toc-heading">
          <subject>Sequence Analysis</subject>
        </subj-group>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>DeepMito: accurate prediction of protein sub-mitochondrial localization using convolutional neural networks</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0002-7359-0633</contrib-id>
        <name>
          <surname>Savojardo</surname>
          <given-names>Castrense</given-names>
        </name>
        <xref ref-type="aff" rid="btz512-aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Bruciaferri</surname>
          <given-names>Niccolò</given-names>
        </name>
        <xref ref-type="aff" rid="btz512-aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Tartari</surname>
          <given-names>Giacomo</given-names>
        </name>
        <xref ref-type="aff" rid="btz512-aff1">1</xref>
        <xref ref-type="aff" rid="btz512-aff2">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Martelli</surname>
          <given-names>Pier Luigi</given-names>
        </name>
        <xref ref-type="aff" rid="btz512-aff1">1</xref>
        <xref ref-type="corresp" rid="btz512-cor1"/>
        <!--<email>pierluigi.martelli@unibo.it</email>-->
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Casadio</surname>
          <given-names>Rita</given-names>
        </name>
        <xref ref-type="aff" rid="btz512-aff1">1</xref>
        <xref ref-type="aff" rid="btz512-aff2">2</xref>
      </contrib>
    </contrib-group>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Cowen</surname>
          <given-names>Lenore</given-names>
        </name>
        <role>Associate Editor</role>
      </contrib>
    </contrib-group>
    <aff id="btz512-aff1"><label>1</label><institution>Biocomputing Group, Department of Pharmacy and Biotechnology (FaBiT), University of Bologna</institution>, Bologna, <country country="IT">Italy</country></aff>
    <aff id="btz512-aff2"><label>2</label><institution>Institute of Biomembranes, Bioenergetics and Molecular Biotechnologies (IBIOM), Italian National Research Council (CNR)</institution>, Bari, <country country="IT">Italy</country></aff>
    <author-notes>
      <corresp id="btz512-cor1">To whom correspondence should be addressed. E-mail: <email>pierluigi.martelli@unibo.it</email></corresp>
    </author-notes>
    <pub-date pub-type="ppub">
      <day>01</day>
      <month>1</month>
      <year>2020</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2019-06-20">
      <day>20</day>
      <month>6</month>
      <year>2019</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>20</day>
      <month>6</month>
      <year>2019</year>
    </pub-date>
    <!-- PMC Release delay is 0 months and 0 days and was based on the <pub-date pub-type="epub"/>. -->
    <volume>36</volume>
    <issue>1</issue>
    <fpage>56</fpage>
    <lpage>64</lpage>
    <history>
      <date date-type="received">
        <day>29</day>
        <month>3</month>
        <year>2019</year>
      </date>
      <date date-type="rev-recd">
        <day>31</day>
        <month>5</month>
        <year>2019</year>
      </date>
      <date date-type="accepted">
        <day>17</day>
        <month>6</month>
        <year>2019</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2019. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2019</copyright-year>
      <license license-type="cc-by" xlink:href="http://creativecommons.org/licenses/by/4.0/">
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="btz512.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Motivation</title>
        <p>The correct localization of proteins in cell compartments is a key issue for their function. Particularly, mitochondrial proteins are physiologically active in different compartments and their aberrant localization contributes to the pathogenesis of human mitochondrial pathologies. Many computational methods exist to assign protein sequences to subcellular compartments such as nucleus, cytoplasm and organelles. However, a substantial lack of experimental evidence in public sequence databases hampered so far a finer grain discrimination, including also intra-organelle compartments.</p>
      </sec>
      <sec id="s2">
        <title>Results</title>
        <p>We describe DeepMito, a novel method for predicting protein sub-mitochondrial cellular localization. Taking advantage of powerful deep-learning approaches, such as convolutional neural networks, our method is able to achieve very high prediction performances when discriminating among four different mitochondrial compartments (matrix, outer, inner and intermembrane regions). The method is trained and tested in cross-validation on a newly generated, high-quality dataset comprising 424 mitochondrial proteins with experimental evidence for sub-organelle localizations. We benchmark DeepMito towards the only one recent approach developed for the same task. Results indicate that DeepMito performances are superior. Finally, genomic-scale prediction on a highly-curated dataset of human mitochondrial proteins further confirms the effectiveness of our approach and suggests that DeepMito is a good candidate for genome-scale annotation of mitochondrial protein subcellular localization.</p>
      </sec>
      <sec id="s3">
        <title>Availability and implementation</title>
        <p>The DeepMito web server as well as all datasets used in this study are available at <ext-link ext-link-type="uri" xlink:href="http://busca.biocomp.unibo.it/deepmito">http://busca.biocomp.unibo.it/deepmito</ext-link>. A standalone version of DeepMito is available on DockerHub at <ext-link ext-link-type="uri" xlink:href="https://hub.docker.com/r/bolognabiocomp/deepmito">https://hub.docker.com/r/bolognabiocomp/deepmito</ext-link>. DeepMito source code is available on GitHub at <ext-link ext-link-type="uri" xlink:href="https://github.com/BolognaBiocomp/deepmito">https://github.com/BolognaBiocomp/deepmito</ext-link></p>
      </sec>
      <sec id="s4">
        <title>Supplementary information</title>
        <p><xref ref-type="supplementary-material" rid="sup1">Supplementary data</xref> are available at <italic>Bioinformatics</italic> online.</p>
      </sec>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <named-content content-type="funder-name">PRIN 2017</named-content>
        </funding-source>
        <award-id>2017483NH8</award-id>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="9"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 Introduction</title>
    <p>Mitochondria are double-membrane bound organelles present in all Eukaryotic cells and performing very important biological functions, which include energy production, calcium signaling, regulation of cell metabolism and apoptosis (<xref rid="btz512-B26" ref-type="bibr">Poveda-Huertes <italic>et al.</italic>, 2017</xref>).</p>
    <p>Mitochondria are endowed with their own genome, coding for only few proteins. The vast majority of proteins that are localized into mitochondria are instead encoded by the nuclear genome, synthesized in cytoplasmic ribosomes and subsequently translocated into the organelle by means of different mechanisms, the most well-characterized of which is based on the molecular recognition of specific targeting signals at the N-terminus of the nascent protein (<xref rid="btz512-B11" ref-type="bibr">Dudek <italic>et al.</italic>, 2013</xref>).</p>
    <p>The mitochondrial outer membrane separates the interior of the organelle from the rest of the cell, while the inner membrane encloses the mitochondrial matrix. In turn, the two membranes are separated by the intermembrane space. The existence of such internal compartmentalization suggests that proteins localized in the different mitochondrial compartments are specialized to fulfill different tasks or functions: hence, knowing the precise location of a protein inside mitochondria is crucial for its accurate functional characterization (<xref rid="btz512-B21" ref-type="bibr">Martelli <italic>et al.</italic>, 2015</xref>).</p>
    <p>In the past years, many computational methods could discriminate mitochondrial from non-mitochondrial proteins, taking advantage of machine-learning algorithms to detect highly specific targeting signals localized at the N-terminal region of the protein sequence (<xref rid="btz512-B7" ref-type="bibr">Bannai <italic>et al.</italic>, 2002</xref>; <xref rid="btz512-B12" ref-type="bibr">Emanuelsson <italic>et al.</italic>, 2007</xref>; <xref rid="btz512-B27" ref-type="bibr">Savojardo <italic>et al.</italic>, 2014</xref>; <xref rid="btz512-B14" ref-type="bibr">Fukasawa <italic>et al.</italic>, 2015</xref>; <xref rid="btz512-B28" ref-type="bibr">Savojardo <italic>et al.</italic>, 2015</xref>).</p>
    <p>A substantial lack of experimental information constrained the discriminative capability of tools to a small number of compartments. Recently, the increasing amount of sequence data and the availability of richer experimental evidence, allowed the development of computational methods suited to predict protein subcellular localization at a finer grain. Currently, tools make it possible to discriminate sub-nuclear (<xref rid="btz512-B16" ref-type="bibr">Kumar <italic>et al.</italic>, 2014</xref>), sub-chloroplastic (<xref rid="btz512-B29" ref-type="bibr">Savojardo <italic>et al.</italic>, 2017</xref>; <xref rid="btz512-B34" ref-type="bibr">Wang <italic>et al.</italic>, 2015</xref>; <xref rid="btz512-B31" ref-type="bibr">Shi <italic>et al.</italic>, 2011</xref>) and sub-mitochondrial (<xref rid="btz512-B9" ref-type="bibr">Du and Li, 2006</xref>; <xref rid="btz512-B31" ref-type="bibr">Shi <italic>et al.</italic>, 2011</xref>; <xref rid="btz512-B10" ref-type="bibr">Du and Yu, 2013</xref>; <xref rid="btz512-B13" ref-type="bibr">Fan and Li, 2012</xref>; <xref rid="btz512-B17" ref-type="bibr">Kumar <italic>et al.</italic>, 2018</xref>; <xref rid="btz512-B20" ref-type="bibr">Lin <italic>et al.</italic>, 2013</xref>; <xref rid="btz512-B22" ref-type="bibr">Mei, 2012</xref>; <xref rid="btz512-B23" ref-type="bibr">Nanni and Lumini, 2008</xref>; <xref rid="btz512-B35" ref-type="bibr">Zeng <italic>et al.</italic>, 2009</xref>) localizations. When considering sub-mitochondrial compartments, only the method of <xref rid="btz512-B17" ref-type="bibr">Kumar <italic>et al.</italic> (2018)</xref> allows discriminating up to four different possible localizations (matrix, outer, inner and intermembrane regions). All the approaches rely on different types of global protein features extracted from sequence, including sequence composition, pseudo-amino acid composition, residue physicochemical attributes and/or evolutionary information extracted from multiple sequence alignments (MSAs).</p>
    <p>Here, we describe DeepMito, a novel method for predicting sub-mitochondrial localization. DeepMito is based on artificial neural networks and it adopts the convolutional neural network (CNN) architecture to extract relevant patterns from primary features. DeepMito discriminates four different sub-mitochondrial compartments and our implementation outperforms the only method previously described (<xref rid="btz512-B17" ref-type="bibr">Kumar <italic>et al.</italic>, 2018</xref>), addressing the same task.</p>
    <p>We optimized the CNN architecture of DeepMito adopting a non-redundant, rigorous cross-validation procedure performed on a new dataset comprising 424 highly curated protein sequences extracted from UniprotKB/SwissProt and endowed with experimental evidence for sub-mitochondrial localization. Cross-validation results on this dataset highlighted good performances with Matthews Correlation values ranging from 0.46 to 0.65, depending on the compartment. These values well compare with the results of <xref rid="btz512-B17" ref-type="bibr">Kumar <italic>et al.</italic> (2018)</xref>, ranging from 0.42 to 0.51, when discriminating the same compartments. In addition, we retrained our CNN architecture on the same dataset previously adopted (<xref rid="btz512-B17" ref-type="bibr">Kumar <italic>et al.</italic>, 2018</xref>), and further confirmed the effectiveness of DeepMito, with performances overpassing the previously reported ones.</p>
    <p>Finally, we analyzed the ability of DeepMito in performing genome-scale analysis. To this aim, we extracted a dataset of 1050 mitochondrial human proteins from the Cell Atlas section of the Human Protein Atlas resource (<xref rid="btz512-B33" ref-type="bibr">Thul <italic>et al.</italic>, 2017</xref>). Computed localizations were assessed towards the fraction of human mitochondrial proteins endowed with experimentally annotated GO terms for one of the sub-mitochondrial compartment. In this test, DeepMito shows a very high level of agreement with available experimental annotations (ranging from 93% to 100%, depending on the discriminated compartment).</p>
  </sec>
  <sec>
    <title>2 Materials and methods</title>
    <sec>
      <title>2.1 Datasets</title>
      <sec>
        <title>2.1.1 The SM424-18 dataset</title>
        <p>The main dataset used in this study was derived from UniprotKB/SwissProt (release 2018_02). We first selected all non-fragment protein sequences with evidence at protein level and endowed with experimentally determined subcellular localization (evidence code ECO: 0000269) in one of the four sub-mitochondrial compartments: outer membrane (SL-0172), intermembrane space (SL-0169), inner membrane (SL-0168) and matrix (SL-0170). For sake of selecting the best possible set of annotations, proteins that are also localized in compartments other than mitochondria were excluded.</p>
        <p>In order to obtain a non-redundant set of protein sequences, we performed clustering using the CD-HIT program (<xref rid="btz512-B19" ref-type="bibr">Li and Godzik, 2006</xref>) with global alignment and sequence identity threshold set to 40%. For each cluster generated by CD-HIT, we retained only the longest sequence.</p>
        <p>After this filtering procedure, we ended-up with 424 mitochondrial proteins sharing at most 40% sequence identity computed at a global level. The dataset comprises 193 proteins from Metazoa, 166 from fungi, 60 from plants, 4 from Euglenozoa and 1 from Amoebozoa. Overall, the dataset comprises 74 outer membrane, 190 inner membrane, 25 intermembrane and 135 matrix proteins (<xref rid="btz512-T1" ref-type="table">Table 1</xref>).
</p>
        <table-wrap id="btz512-T1" orientation="portrait" position="float">
          <label>Table 1.</label>
          <caption>
            <p>Summary statistics of the SM424-18 and the SubMitoPred datasets</p>
          </caption>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col valign="top" align="left" span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th rowspan="1" colspan="1">Compartment</th>
                <th rowspan="1" colspan="1">SM424-18<xref ref-type="table-fn" rid="tblfn1"><sup>a</sup></xref><sup>,b</sup></th>
                <th rowspan="1" colspan="1">SubMitoPred<xref ref-type="table-fn" rid="tblfn2"><sup>b</sup></xref><sup>,c</sup></th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td rowspan="1" colspan="1">Outer membrane</td>
                <td rowspan="1" colspan="1">74</td>
                <td rowspan="1" colspan="1">82</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">Inner membrane</td>
                <td rowspan="1" colspan="1">190</td>
                <td rowspan="1" colspan="1">282</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">Intermembrane space</td>
                <td rowspan="1" colspan="1">25</td>
                <td rowspan="1" colspan="1">32</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">Matrix</td>
                <td rowspan="1" colspan="1">135</td>
                <td rowspan="1" colspan="1">174</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">Total</td>
                <td rowspan="1" colspan="1">424</td>
                <td rowspan="1" colspan="1">570</td>
              </tr>
            </tbody>
          </table>
          <table-wrap-foot>
            <fn id="tblfn1">
              <label>a</label>
              <p>This paper.</p>
            </fn>
            <fn id="tblfn2">
              <label>b</label>
              <p>Number of sequences.</p>
            </fn>
            <fn id="tblfn3">
              <label>c</label>
              <p>From <xref rid="btz512-B17" ref-type="bibr">Kumar <italic>et al.</italic> (2018)</xref>.</p>
            </fn>
          </table-wrap-foot>
        </table-wrap>
        <p>On our dataset (SM424-18) we adopted a 10-fold cross-validation. In order to avoid any possible bias between training and testing, we applied the following clustering procedure to generate cross-validation sets. First, the 424 protein sequences were cross-compared running all-against-all pairwise blastp with e-value threshold set to 0.001. From blast output, we built a similarity graph where nodes are protein sequences and edges among pairs of nodes were added if at least one blast hit with more than 30% sequence identity was found (no coverage threshold was set). On this graph, single-linkage clustering was performed computing connected components. Finally, all proteins falling in the same cluster were assigned to the same cross-validation set. In this way, we eliminated any possible sequence identity bias among training and testing, confining any residual sequence redundancy (even occurring locally) in the same cross-validation set. SM424-18 is available for download at <ext-link ext-link-type="uri" xlink:href="http://busca.biocomp.unibo.it/deepmito/datasets">http://busca.biocomp.unibo.it/deepmito/datasets</ext-link>.</p>
      </sec>
      <sec>
        <title>2.1.2 The SubMitoPred dataset</title>
        <p>SubMitoPred is a dataset previously introduced to train and test the most recent approach for sub-mitochondrial localization prediction, addressing a four-compartment discrimination (<xref rid="btz512-T1" ref-type="table">Table 1</xref>, SubMitoPred, <xref rid="btz512-B17" ref-type="bibr">Kumar <italic>et al.</italic>, 2018</xref>). According to the authors, SubMitoPred (available at <ext-link ext-link-type="uri" xlink:href="http://proteininformatics.org/mkumar/submitopred/download.html">http://proteininformatics.org/mkumar/submitopred/download.html</ext-link>) was derived from UniprotKB/SwissProt release 2014_10, selecting protein sequences with the following criteria:
<list list-type="bullet"><list-item><p>Full-length proteins (no fragments) with experimental existence evidence.</p></list-item><list-item><p>Protein length &gt; 50 residues.</p></list-item><list-item><p>Experimental sub-mitochondrial subcellular localization, retaining only proteins localized into a single compartment.</p></list-item><list-item><p>Dataset internal redundancy reduced at 40% sequence identity using CD-HIT.</p></list-item></list></p>
        <p>Overall, the dataset comprises 570 mitochondrial proteins distributed in the four different sub-compartments (<xref rid="btz512-T1" ref-type="table">Table 1</xref>).</p>
        <p>SubMitoPred contains more proteins than our dataset. Our dataset SM424-18 and the one generated by <xref rid="btz512-B17" ref-type="bibr">Kumar <italic>et al</italic>. (2018)</xref> share 238 common proteins. Of the remaining 332 included in the SubMitoPred dataset but not in SM424-18, 326 are not present in our dataset because they are not annotated with the experimental evidence code ECO: 0000269; six proteins were excluded because they are annotated as localized in multiple compartments.</p>
        <p>For sake of comparison, when necessary and as previously described (<xref rid="btz512-B17" ref-type="bibr">Kumar <italic>et al.</italic>, 2018</xref>), we split the SubMitoPred set into five cross-validation subsets. According to <xref rid="btz512-B17" ref-type="bibr">Kumar <italic>et al.</italic> (2018)</xref>, they performed cross-validation by randomly splitting the set of 570 proteins into five subsets. In this study, we performed two different cross-validation splits: (i) random split as described in <xref rid="btz512-B17" ref-type="bibr">Kumar <italic>et al.</italic> (2018)</xref> and (ii) random split after sequence clustering using blastp (applying the same procedure described in the previous section for our SM424-18).</p>
      </sec>
      <sec>
        <title>2.1.3 The Human Cell Atlas dataset</title>
        <p>To assess the capability of DeepMito in performing genome-scale analysis, we here adopted a dataset extracted from the Cell Atlas section of the Human Protein Atlas project (<xref rid="btz512-B33" ref-type="bibr">Thul <italic>et al.</italic>, 2017</xref>). This resource provides a comprehensive catalog of subcellular localization of proteins in human cells derived from transcriptomics experiments or antibody-based image profiling techniques. By this, it provides experimental evidence for subcellular localization of 12 073 human proteins.</p>
        <p>Here, we focused on the subset of 1074 proteins that are found to be localized into mitochondria (Cell Atlas does not provide for these proteins sub-mitochondrial localization). The Cell Atlas database assigns a label to each annotation, representing its quality. Four different labels are defined (in decreasing order of quality): Enhanced, Supported, Approved and Uncertain. For the 1074 mitochondrial proteins considered in this study, Enhanced and Supported annotations cover about 50% of the dataset (165 + 347 = 512), 506 annotations are Approved while only a small fraction are Uncertain (56 annotations). In order to obtain a sufficient number of sequences, here, we decided to retain all annotations available for mitochondrial proteins.</p>
        <p>ENSEMBL gene identifiers for the 1074 mitochondrial proteins were mapped to UniprotKB entries: after this step we were able to map 1050 ENSEMBL identifiers to UniprotKB entries. Twenty-four ENSEMBL genes were excluded because of non-clear or multiple mapping to UniprotKB.</p>
        <p>On this set, we extracted available Gene Ontology term information using the QuickGO website (<ext-link ext-link-type="uri" xlink:href="https://www.ebi.ac.uk/QuickGO/">https://www.ebi.ac.uk/QuickGO/</ext-link>). We focused only on annotations of the GO Cellular Component, endowed with experimental evidence (ECO: 0000269) and derived from any source databank. As a result, 179 out of 1050 gene products were annotated with GO terms that are equal to or descendants of any of the four mitochondrial compartments considered in this study: 19 proteins in mitochondrial outer membrane (GO: 0005741), 67 in mitochondrial inner membrane (GO: 0005743), 12 in mitochondrial intermembrane space (GO: 0005758) and 81 in mitochondrial matrix (GO: 0005759). Proteins that were annotated with GO terms related to multiple mitochondrial compartments were filtered-out form this set.</p>
        <p>We refer to the full Cell Atlas dataset comprising 1050 protein sequences as Mito-CA-Full and to the subset of 179 annotated as Mito-CA-Annotated.</p>
      </sec>
    </sec>
    <sec>
      <title>2.2 Feature descriptors</title>
      <p>In this study, we considered three different feature types and evaluated their contribution (both individual and combined) to the prediction of protein sub-mitochondrial localization, when provided in input to the DeepMito convolutional network. In particular, the following features were considered:
<list list-type="bullet"><list-item><p>Residue one-hot encoding (SEQ), where each residue in a protein sequence is encoded using a 20-dimensional vector with all zero components except for the one representing the residue. Overall, each protein sequence is represented by a matrix with <inline-formula id="IE1"><mml:math id="IM1"><mml:mi>L</mml:mi></mml:math></inline-formula> rows and <inline-formula id="IE2"><mml:math id="IM2"><mml:mn>20</mml:mn></mml:math></inline-formula> columns, where <italic>L</italic> is the length of the sequence.</p></list-item><list-item><p>Residue physical–chemical properties (PROP), where each residue in a protein sequence is encoded using the 10 different numerical values introduced by <xref rid="btz512-B15" ref-type="bibr">Kidera <italic>et al.</italic> (1985)</xref>. These values derive from a multivariate statistical analysis of a set of 188 different properties of naturally occurring amino acids and can be used to compactly represent the physical–chemical nature of each residue. Overall, each protein is encoded with a matrix with <inline-formula id="IE3"><mml:math id="IM3"><mml:mi>L</mml:mi></mml:math></inline-formula> rows and <inline-formula id="IE4"><mml:math id="IM4"><mml:mn>10</mml:mn></mml:math></inline-formula> columns, where <italic>L</italic> is the length of the sequence.</p></list-item><list-item><p>Evolutionary information, in the form of Position Specific Scoring Matrices (PSSM) as computed, for each sequence in the datasets, by running the PSI-BLAST (<xref rid="btz512-B4" ref-type="bibr">Altschul <italic>et al.</italic>, 1997</xref>) program against the Uniref90 dataset (release March 2018) for three iterations and e-value threshold set to 0.001. Overall, PSSM for a given protein is a matrix with <inline-formula id="IE5"><mml:math id="IM5"><mml:mi>L</mml:mi></mml:math></inline-formula> rows and <inline-formula id="IE6"><mml:math id="IM6"><mml:mn>20</mml:mn></mml:math></inline-formula> columns, where <italic>L</italic> is the length of the sequence. Internally, the program computes the matrix by considering the MSA obtained by (i) stacking all pairwise alignments between query and similar sequences found after each iteration and (ii) removing MSA columns corresponding to gaps in the query sequence. In this way, the PSSMs have always a number of rows that coincides with the length of the query sequence. Raw PSSM values extracted from the PSI-BLAST checkpoint file (generated by the program after each iteration) were mapped in the range [0-1] using a sigmoid function, defined as:
<disp-formula id="E1"><label>(1)</label><mml:math id="M1"><mml:mi>f</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:math></disp-formula></p></list-item></list></p>
      <p>Feature descriptors are combined protein-wise with simple concatenation along the sequence axis. For instance, combining PSSM and PROP matrices of dimensions <inline-formula id="IE7"><mml:math id="IM7"><mml:mi>L</mml:mi><mml:mo>×</mml:mo><mml:mn>20</mml:mn></mml:math></inline-formula> and <inline-formula id="IE8"><mml:math id="IM8"><mml:mi>L</mml:mi><mml:mo>×</mml:mo><mml:mn>10</mml:mn></mml:math></inline-formula> leads to a <inline-formula id="IE9"><mml:math id="IM9"><mml:mi>L</mml:mi><mml:mo>×</mml:mo><mml:mn>30</mml:mn></mml:math></inline-formula> matrix.</p>
    </sec>
    <sec>
      <title>2.3 CNNs</title>
      <p>CNNs have their main application domain in the Computer Vision area (<xref rid="btz512-B18" ref-type="bibr">LeCun <italic>et al.</italic>, 2015</xref>). Nevertheless, they have been proven to be very effective also for sequence analysis tasks in Genomics and Computational Biology, as highlighted by the increasing number of successful applications available in literature (<xref rid="btz512-B2" ref-type="bibr">Alipanahi <italic>et al.</italic>, 2015</xref>; <xref rid="btz512-B3" ref-type="bibr">Almagro Armenteros <italic>et al.</italic>, 2017</xref>; <xref rid="btz512-B5" ref-type="bibr">Angermueller <italic>et al.</italic>, 2016</xref>; <xref rid="btz512-B30" ref-type="bibr">Savojardo <italic>et al.</italic>, 2018</xref>).</p>
      <p>In the context of bio-sequence analysis, inputs are routinely protein or a DNA sequences of variable length on which one wants to detect some feature or attribute, both at the level of individual residues (i.e. sequence labeling) or at a global level (i.e. sequence classification).</p>
      <p>Each residue in a sequence is represented with low-level features, e.g. residue properties, one-hot encoding or sequence profiles. The number of features encoding for a given residues is referred to as channels in the CNN context.</p>
      <p>A typical CNN is a feed-forward architecture comprising two different types of layers: convolutional and pooling layers. Formers are used to extract salient features from the input by means of filters or motif detectors, whose parameters are learnt during training and are used to scan the input. Pooling layers are instead parameter-free, and they are used for downsampling, namely to reduce the input dimensionality by selecting/aggregating the most relevant features extracted by convolutional layers according to some predefined function (e.g. average, max or min functions).</p>
      <p>More formally, let be <inline-formula id="IE10"><mml:math id="IM10"><mml:mi>X</mml:mi><mml:mo>=</mml:mo><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math></inline-formula> an input sequence of length <inline-formula id="IE11"><mml:math id="IM11"><mml:mi>L</mml:mi></mml:math></inline-formula> where each <inline-formula id="IE12"><mml:math id="IM12"><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> is a <inline-formula id="IE13"><mml:math id="IM13"><mml:mi>d</mml:mi></mml:math></inline-formula>-dimensional vector (i.e. <inline-formula id="IE14"><mml:math id="IM14"><mml:mi>d</mml:mi></mml:math></inline-formula> is the number of input channels). We restrict our attention to CNN architectures suited to sequence classification, i.e. the task of classifying the input sequence <inline-formula id="IE15"><mml:math id="IM15"><mml:mi>X</mml:mi></mml:math></inline-formula> into <inline-formula id="IE16"><mml:math id="IM16"><mml:mi>K</mml:mi></mml:math></inline-formula> different classes.</p>
      <p>A convolutional layer is a collection <inline-formula id="IE17"><mml:math id="IM17"><mml:mi mathvariant="script">M</mml:mi><mml:mo>=</mml:mo><mml:mfenced separators="|"><mml:mrow><mml:msup><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>F</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mfenced></mml:math></inline-formula> of <inline-formula id="IE18"><mml:math id="IM18"><mml:mi>F</mml:mi></mml:math></inline-formula> different motif detectors, each of which can be seen as a weight matrix of dimension <inline-formula id="IE19"><mml:math id="IM19"><mml:mi>w</mml:mi><mml:mo>×</mml:mo><mml:mi>d</mml:mi></mml:math></inline-formula>:
<disp-formula id="E2"><label>(2)</label><mml:math id="M2"><mml:msup><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mfenced open="[" close="]" separators="|"><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:msubsup><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup></mml:mtd><mml:mtd><mml:mo>⋯</mml:mo></mml:mtd><mml:mtd><mml:msubsup><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>⋮</mml:mo></mml:mtd><mml:mtd><mml:mo>⋱</mml:mo></mml:mtd><mml:mtd><mml:mo>⋮</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msubsup><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>w</mml:mi><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup></mml:mtd><mml:mtd><mml:mo>⋯</mml:mo></mml:mtd><mml:mtd><mml:msubsup><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>w</mml:mi><mml:mo>,</mml:mo><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>w</mml:mi><mml:mo>×</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:math></disp-formula>where <inline-formula id="IE20"><mml:math id="IM20"><mml:mi>w</mml:mi></mml:math></inline-formula> is the width of the motif and <inline-formula id="IE21"><mml:math id="IM21"><mml:mi>d</mml:mi></mml:math></inline-formula> is the number of input channels.</p>
      <p>Using a sliding-window approach, the <inline-formula id="IE22"><mml:math id="IM22"><mml:mi>i</mml:mi></mml:math></inline-formula>-th motif detector produces an output sequence <inline-formula id="IE23"><mml:math id="IM23"><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="normal"> </mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>L</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math></inline-formula> having the same length <inline-formula id="IE24"><mml:math id="IM24"><mml:mi>L</mml:mi></mml:math></inline-formula> of the input and where each <inline-formula id="IE25"><mml:math id="IM25"><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is computed as:
<disp-formula id="E3"><label>(3)</label><mml:math id="M3"><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>g</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mrow><mml:msubsup><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mrow><mml:msubsup><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:msubsup><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>+</mml:mo><mml:mi>k</mml:mi><mml:mo>-</mml:mo><mml:mfenced open="⌊" close="⌋" separators="|"><mml:mrow><mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:mrow></mml:mfenced><mml:mo>,</mml:mo><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mfenced></mml:math></disp-formula></p>
      <p>Sequence termini are handled by adding explicit zero-padding at the beginning and end of the input sequence <inline-formula id="IE26"><mml:math id="IM26"><mml:mi>X</mml:mi></mml:math></inline-formula>. In <xref ref-type="disp-formula" rid="E3">Equation (3)</xref>, <inline-formula id="IE27"><mml:math id="IM27"><mml:mi>g</mml:mi></mml:math></inline-formula> is an activation function used to transform the raw motif score. Many different activation functions exist; however, routinely Rectified Linear Units (ReLUs) are adopted, defined as:
<disp-formula id="E4"><label>(4)</label><mml:math id="M4"><mml:mi>g</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">max</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p>
      <p>Overall, a convolutional layer endowed with <inline-formula id="IE28"><mml:math id="IM28"><mml:mi>F</mml:mi></mml:math></inline-formula> independent motif detectors compute an output matrix <inline-formula id="IE29"><mml:math id="IM29"><mml:mi>C</mml:mi></mml:math></inline-formula> with <inline-formula id="IE30"><mml:math id="IM30"><mml:mi>F</mml:mi></mml:math></inline-formula> rows and <inline-formula id="IE31"><mml:math id="IM31"><mml:mi>L</mml:mi></mml:math></inline-formula> columns:
<disp-formula id="E5"><label>(5)</label><mml:math id="M5"><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mfenced open="[" close="]" separators="|"><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:mo>⋯</mml:mo></mml:mtd><mml:mtd><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>L</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>⋮</mml:mo></mml:mtd><mml:mtd><mml:mo>⋱</mml:mo></mml:mtd><mml:mtd><mml:mo>⋮</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>F</mml:mi><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:mo>⋯</mml:mo></mml:mtd><mml:mtd><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>F</mml:mi><mml:mo>,</mml:mo><mml:mi>L</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>F</mml:mi><mml:mo>×</mml:mo><mml:mi>L</mml:mi></mml:mrow></mml:msub></mml:math></disp-formula></p>
      <p>Pooling layers following convolutions reduce the dimensionality of the matrix <inline-formula id="IE32"><mml:math id="IM32"><mml:mi>C</mml:mi></mml:math></inline-formula> along the second dimension (i.e. <inline-formula id="IE33"><mml:math id="IM33"><mml:mi>L</mml:mi></mml:math></inline-formula>). Different types of pooling are possible.</p>
      <p>In <italic>local pooling</italic> with pool size <inline-formula id="IE34"><mml:math id="IM34"><mml:mi>p</mml:mi></mml:math></inline-formula>, an aggregating function <inline-formula id="IE35"><mml:math id="IM35"><mml:mi>t</mml:mi></mml:math></inline-formula> is computed row-wise over a set of <inline-formula id="IE36"><mml:math id="IM36"><mml:mi>p</mml:mi></mml:math></inline-formula> non-overlapping neighboring columns of <inline-formula id="IE37"><mml:math id="IM37"><mml:mi>C</mml:mi></mml:math></inline-formula>, transforming it into a new matrix <inline-formula id="IE38"><mml:math id="IM38"><mml:msup><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">local</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> of dimension <inline-formula id="IE39"><mml:math id="IM39"><mml:mi>F</mml:mi><mml:mo>×</mml:mo><mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>:
<disp-formula id="E6"><label>(6)</label><mml:math id="M6"><mml:msup><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">local</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mfenced open="[" close="]" separators="|"><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mi>t</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>p</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mtd><mml:mtd><mml:mo>⋯</mml:mo></mml:mtd><mml:mtd><mml:mi>t</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>L</mml:mi><mml:mo>-</mml:mo><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>L</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>⋮</mml:mo></mml:mtd><mml:mtd><mml:mo>⋱</mml:mo></mml:mtd><mml:mtd><mml:mo>⋮</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>t</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>F</mml:mi><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>F</mml:mi><mml:mo>,</mml:mo><mml:mi>p</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mtd><mml:mtd><mml:mo>⋯</mml:mo></mml:mtd><mml:mtd><mml:mi>t</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>F</mml:mi><mml:mo>,</mml:mo><mml:mi>L</mml:mi><mml:mo>-</mml:mo><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>F</mml:mi><mml:mo>,</mml:mo><mml:mi>L</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>F</mml:mi><mml:mo>×</mml:mo><mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:mrow></mml:mrow></mml:msub></mml:math></disp-formula></p>
      <p>In <italic>global pooling</italic>, the pool size <inline-formula id="IE40"><mml:math id="IM40"><mml:mi>p</mml:mi></mml:math></inline-formula> is equal to <inline-formula id="IE41"><mml:math id="IM41"><mml:mi>L</mml:mi></mml:math></inline-formula> and the input matrix <inline-formula id="IE42"><mml:math id="IM42"><mml:mi>C</mml:mi></mml:math></inline-formula> is completely flattened into a column vector <inline-formula id="IE43"><mml:math id="IM43"><mml:msup><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">global</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> of dimension <inline-formula id="IE44"><mml:math id="IM44"><mml:mi>F</mml:mi><mml:mo>×</mml:mo><mml:mn>1</mml:mn></mml:math></inline-formula>, computing the pooling function <inline-formula id="IE45"><mml:math id="IM45"><mml:mi>t</mml:mi></mml:math></inline-formula> row-wise over the entire set of <inline-formula id="IE46"><mml:math id="IM46"><mml:mi>L</mml:mi></mml:math></inline-formula> columns:
<disp-formula id="E7"><label>(7)</label><mml:math id="M7"><mml:msup><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">global</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mfenced open="[" close="]" separators="|"><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mi>t</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi mathvariant="normal"> </mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>L</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>⋮</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>t</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>F</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="normal"> </mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>F</mml:mi><mml:mo>,</mml:mo><mml:mi>L</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>F</mml:mi><mml:mo>×</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math></disp-formula></p>
      <p>Common pooling functions are average, sum, maximum and minimum.</p>
      <p>Overall, one or more successive applications of convolution-pooling layers transform the input <inline-formula id="IE47"><mml:math id="IM47"><mml:mi>X</mml:mi></mml:math></inline-formula> into a feature map <inline-formula id="IE48"><mml:math id="IM48"><mml:mi>P</mml:mi></mml:math></inline-formula> corresponding to the output of last pooling layer in the architecture. The feature map is then flattened into a single vector <inline-formula id="IE49"><mml:math id="IM49"><mml:mi>v</mml:mi><mml:mi mathvariant="normal"> </mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> (being <inline-formula id="IE50"><mml:math id="IM50"><mml:mi>m</mml:mi></mml:math></inline-formula> the total dimension of the feature map after the last pooling) and provided in input to a standard fully-connected network that first maps <inline-formula id="IE51"><mml:math id="IM51"><mml:mi>v</mml:mi></mml:math></inline-formula> into a hidden layer with <inline-formula id="IE52"><mml:math id="IM52"><mml:mi>H</mml:mi></mml:math></inline-formula> units <inline-formula id="IE53"><mml:math id="IM53"><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>H</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> such that:
<disp-formula id="E8"><label>(8)</label><mml:math id="M8"><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>a</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mrow><mml:msubsup><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:msubsup><mml:mrow><mml:mo>ω</mml:mo></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>h</mml:mi></mml:mrow></mml:msubsup><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>h</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced></mml:math></disp-formula>where <inline-formula id="IE54"><mml:math id="IM54"><mml:msubsup><mml:mrow><mml:mo>ω</mml:mo></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>h</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula> and <inline-formula id="IE55"><mml:math id="IM55"><mml:msubsup><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>h</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula> are the connection weights and bias of the <inline-formula id="IE56"><mml:math id="IM56"><mml:mi>i</mml:mi></mml:math></inline-formula>-th hidden unit, respectively, while the function <inline-formula id="IE57"><mml:math id="IM57"><mml:mi>a</mml:mi></mml:math></inline-formula> is an activation function (e.g. ReLU).</p>
      <p>Finally, the hidden layer is mapped to the output layer comprising <inline-formula id="IE58"><mml:math id="IM58"><mml:mi>K</mml:mi></mml:math></inline-formula> units <inline-formula id="IE59"><mml:math id="IM59"><mml:msub><mml:mrow><mml:mi>o</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>o</mml:mi></mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, one for each class, as follows:
<disp-formula id="E9"><label>(9)</label><mml:math id="M9"><mml:msub><mml:mrow><mml:mi>o</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>u</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mrow><mml:msubsup><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:msubsup><mml:mrow><mml:mo>ω</mml:mo></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msubsup><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced></mml:math></disp-formula>where <inline-formula id="IE60"><mml:math id="IM60"><mml:msubsup><mml:mrow><mml:mo>ω</mml:mo></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula> and <inline-formula id="IE61"><mml:math id="IM61"><mml:msubsup><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula> are the connection weights and bias of the <inline-formula id="IE62"><mml:math id="IM62"><mml:mi>i</mml:mi></mml:math></inline-formula>-th output unit, respectively, and <inline-formula id="IE63"><mml:math id="IM63"><mml:mi>u</mml:mi></mml:math></inline-formula> is the output activation function, typically softmax or sigmoid, depending on the type of output desired.</p>
      <p>In summary, a CNN architecture for sequence classification can be divided into two parts: the first part, where convolution-pooling layers are applied, is devised to feature extraction and selection; the second part, consisting in the final fully connected network, performs the actual classification of the sequence into <inline-formula id="IE64"><mml:math id="IM64"><mml:mi>K</mml:mi></mml:math></inline-formula> different classes.</p>
    </sec>
    <sec>
      <title>2.4 The DeepMito CNN architecture</title>
      <p>Prediction of protein sub-mitochondrial localization can be naturally defined as a multi-class sequence classification problem where each input protein sequence is classified as belonging to one of <inline-formula id="IE65"><mml:math id="IM65"><mml:mi>K</mml:mi><mml:mo>=</mml:mo><mml:mn>4</mml:mn></mml:math></inline-formula> different mitochondrial sub-compartments. In this respect, DeepMito is based on the CNN architecture depicted in <xref ref-type="fig" rid="btz512-F1">Fig. 1</xref>.
</p>
      <fig id="btz512-F1" orientation="portrait" position="float">
        <label>Fig. 1.</label>
        <caption>
          <p>Schematic view of the DeepMito CNN architecture.</p>
        </caption>
        <graphic xlink:href="btz512f1"/>
      </fig>
      <p>The input protein sequence where each residue is encoded as a <inline-formula id="IE66"><mml:math id="IM66"><mml:mi>d</mml:mi></mml:math></inline-formula>-dimensional vector (<inline-formula id="IE67"><mml:math id="IM67"><mml:mi>d</mml:mi></mml:math></inline-formula> varies according to the input feature considered) is scanned using a single convolutional layer comprising <inline-formula id="IE68"><mml:math id="IM68"><mml:mi>F</mml:mi></mml:math></inline-formula> detectors of width <inline-formula id="IE69"><mml:math id="IM69"><mml:mi>w</mml:mi></mml:math></inline-formula> (we tested several different values for these two variables, see next section for details). The convolutional layer output is then processed by two parallel pooling layers computing global average and maximum functions. The rationale behind this choice is to compute both the average motif signal and its peak along the input sequence, trying to capture different types of patterns.</p>
      <p>The two pooling layers are then concatenated into a single vector and provided to the final classification network with <inline-formula id="IE70"><mml:math id="IM70"><mml:mi>H</mml:mi></mml:math></inline-formula> hidden units (also <inline-formula id="IE71"><mml:math id="IM71"><mml:mi>H</mml:mi></mml:math></inline-formula> has been optimized as detailed in the next section). Overall, the network has four independent output units with sigmoid activation function representing scores that quantify the membership of the input protein to each considered compartment: outer membrane, inner membrane, intermembrane space and matrix. The protein is predicted as localized into the highest-scoring compartment.</p>
      <p>The DeepMito CNN was trained using a Stochastic Gradient Descent optimizer by minimizing the cumulative binary cross-entropy loss function. More formally, consider a training set <inline-formula id="IE72"><mml:math id="IM72"><mml:mi mathvariant="script">D</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mfenced open="{" close="}" separators="|"><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:msup><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, where <inline-formula id="IE73"><mml:math id="IM73"><mml:msup><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> is an input protein sequence while <inline-formula id="IE74"><mml:math id="IM74"><mml:msup><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> is a 4-class target vector storing the membership of each protein to one of the compartments.</p>
      <p>The cumulative binary cross-entropy loss function is defined as:
<disp-formula id="E10"><label>(10)</label><mml:math id="M10"><mml:mi mathvariant="script">E</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="script">D</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mrow><mml:munderover><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">E</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi mathvariant="script">D</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>where each <inline-formula id="IE75"><mml:math id="IM75"><mml:msub><mml:mrow><mml:mi mathvariant="script">E</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi mathvariant="script">D</mml:mi><mml:mo>)</mml:mo></mml:math></inline-formula> is the binary cross-entropy loss function for class <inline-formula id="IE76"><mml:math id="IM76"><mml:mi>j</mml:mi></mml:math></inline-formula> and defined as:
<disp-formula id="E11"><label>(11)</label><mml:math id="M11"><mml:msub><mml:mrow><mml:mi mathvariant="script">E</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="script">D</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:munderover><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:msubsup><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup><mml:mrow><mml:mrow><mml:mi mathvariant="normal">log</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>o</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msubsup><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup><mml:mo>)</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">log</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msubsup><mml:mrow><mml:mi>o</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mi mathvariant="normal"> </mml:mi></mml:mrow></mml:mrow></mml:math></disp-formula>where <inline-formula id="IE77"><mml:math id="IM77"><mml:msubsup><mml:mrow><mml:mi>o</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup></mml:math></inline-formula> is the output of the CNN for the <inline-formula id="IE78"><mml:math id="IM78"><mml:mi>j</mml:mi></mml:math></inline-formula>-th class when the sequence <inline-formula id="IE79"><mml:math id="IM79"><mml:msup><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> is provided in input.</p>
    </sec>
    <sec>
      <title>2.5 Model selection and implementation</title>
      <p>A CNN architecture like the one depicted in <xref ref-type="fig" rid="btz512-F1">Fig. 1</xref> has several hyperparameters that need to be optimized. In particular, to define a convolutional layer we need to specify the number <inline-formula id="IE80"><mml:math id="IM80"><mml:mi>F</mml:mi></mml:math></inline-formula> of motif detectors as well as their width <inline-formula id="IE81"><mml:math id="IM81"><mml:mi>w</mml:mi></mml:math></inline-formula>. Analogously, for fully-connected layers, we need to optimize the number <inline-formula id="IE82"><mml:math id="IM82"><mml:mi>H</mml:mi></mml:math></inline-formula> of units in the hidden layers.</p>
      <p>In order to find optimal hyperparameters, we defined a set of possible values for each hyperparameter (see <xref ref-type="supplementary-material" rid="sup1">Supplementary Table S1</xref> for the complete list of tested values) and adopted the following grid-search procedure to search for their optimal combination. In particular, using the SM424-18 dataset, a complete 10-fold cross-validation was running for all possible combination of hyperparameters, using one of the subsets as testing set, eight subsets as training set and one as validation set (different from testing). Each individual training was running for 100 epochs starting with random initialization for all adjustable network weights. Early stopping on validation loss was used to prevent overfitting. We then selected, among all possible combinations of parameters, the one achieving the highest performance on validation data. We used the Generalized Correlation Coefficient (GCC) (<xref rid="btz512-B6" ref-type="bibr">Baldi <italic>et al.</italic>, 2000</xref>) index to compare different architectures (see next section for the formal definition of the GCC). The optimal set of hyperparameters was then frozen and used to score the CNN on testing data.</p>
      <p>DeepMito was implemented in Python 2.7 and using the Keras v. 2.2.4 (<ext-link ext-link-type="uri" xlink:href="https://keras.io">https://keras.io</ext-link>) deep-learning library with Tensorflow v. 1.11 (<ext-link ext-link-type="uri" xlink:href="https://www.tensorflow.org">https://www.tensorflow.org</ext-link>) as backend.</p>
    </sec>
    <sec>
      <title>2.6 Scoring performance</title>
      <p>Performances of our method were scored by computing the multi-class confusion matrix <inline-formula id="IE83"><mml:math id="IM83"><mml:mi>M</mml:mi></mml:math></inline-formula> where <inline-formula id="IE84"><mml:math id="IM84"><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is the number of proteins belonging to class <inline-formula id="IE85"><mml:math id="IM85"><mml:mi>i</mml:mi></mml:math></inline-formula> and predicted in class <inline-formula id="IE86"><mml:math id="IM86"><mml:mi>j</mml:mi></mml:math></inline-formula>.</p>
      <p>Single-class predictions were scored using the Matthews’ Correlation Coefficient (MCC) for each class <inline-formula id="IE87"><mml:math id="IM87"><mml:mi>k</mml:mi></mml:math></inline-formula>, defined as:
<disp-formula id="E12"><label>(12)</label><mml:math id="M12"><mml:mi mathvariant="normal">MCC</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>o</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msqrt><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>o</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>o</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:msqrt></mml:mrow></mml:mfrac></mml:math></disp-formula>where <inline-formula id="IE88"><mml:math id="IM88"><mml:msub><mml:mrow><mml:mi>o</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:munder><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>≠</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> is the number of over-predictions for the class <inline-formula id="IE89"><mml:math id="IM89"><mml:mi>k</mml:mi></mml:math></inline-formula>, <inline-formula id="IE90"><mml:math id="IM90"><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:munder><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>≠</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> is the number of under-predictions for the class <inline-formula id="IE91"><mml:math id="IM91"><mml:mi>k</mml:mi></mml:math></inline-formula> and <inline-formula id="IE92"><mml:math id="IM92"><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:munder><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>≠</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mrow><mml:msub><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>≠</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> is the number of proteins correctly predicted as not being in class <inline-formula id="IE93"><mml:math id="IM93"><mml:mi>k</mml:mi></mml:math></inline-formula> (i.e. correct negative predictions with respect to class <inline-formula id="IE94"><mml:math id="IM94"><mml:mi>k</mml:mi></mml:math></inline-formula>).</p>
      <p>Moreover, we adopted the GCC, described in <xref rid="btz512-B6" ref-type="bibr">Baldi <italic>et al.</italic> (2000)</xref>, and providing a single measure to score classifications involving more than two classes. In particular, for each class <inline-formula id="IE95"><mml:math id="IM95"><mml:mi>k</mml:mi><mml:mo>,</mml:mo></mml:math></inline-formula> we can compute the number <inline-formula id="IE96"><mml:math id="IM96"><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo> </mml:mo></mml:math></inline-formula>of proteins in class <inline-formula id="IE97"><mml:math id="IM97"><mml:mi>k</mml:mi></mml:math></inline-formula> as:
<disp-formula id="E13"><label>(13)</label><mml:math id="M13"><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:munderover><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></disp-formula>and the number <inline-formula id="IE98"><mml:math id="IM98"><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> of proteins predicted in class <inline-formula id="IE99"><mml:math id="IM99"><mml:mi>k</mml:mi></mml:math></inline-formula> as:
<disp-formula id="E14"><label>(14)</label><mml:math id="M14"><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:munderover><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></disp-formula></p>
      <p>Then we define the following matrix <inline-formula id="IE100"><mml:math id="IM100"><mml:mi>e</mml:mi></mml:math></inline-formula> as:
<disp-formula id="E15"><label>(15)</label><mml:math id="M15"><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:mfrac></mml:math></disp-formula>where <inline-formula id="IE101"><mml:math id="IM101"><mml:mi>N</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:msubsup><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mrow><mml:msubsup><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> is the total number of proteins in a dataset.</p>
      <p>The GCC is then defined as:
<disp-formula id="E16"><label>(16)</label><mml:math id="M16"><mml:mi mathvariant="normal">GCC</mml:mi><mml:mo>=</mml:mo><mml:msqrt><mml:mfrac><mml:mrow><mml:mrow><mml:msubsup><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mrow><mml:msubsup><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mo>(</mml:mo><mml:mi>K</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mfrac></mml:msqrt></mml:math></disp-formula></p>
      <p>The GCC value ranges from −1 to 1 and a GCC equal to 0 corresponds to predictions no better than random.</p>
    </sec>
  </sec>
  <sec>
    <title>3 Results</title>
    <sec>
      <title>3.1 Assessing the contribution of the different features</title>
      <p>In order to build an optimal predictor for protein sub-mitochondrial compartment prediction, we first assessed the predictive power of each type of feature. In this study, as already detailed in Section 2.2, three basic type of features were considered: protein primary sequence (encoded using the standard residue one-hot encoding), protein physical–chemical attributes and evolutionary information in the form of PSSMs.</p>
      <p>These three basic feature types were then combined and provided in the input to the DeepMito CNN architecture. In doing this, we considered protein primary sequence and PSSMs as alternative choices, scoring them individually or combined with protein physical–chemical attributes. For each evaluated feature set, a different CNN has been trained in cross-validation on the SM424-18 dataset, optimizing network architecture as explained in Section 2.5. Performance scores are reported in <xref rid="btz512-T2" ref-type="table">Table 2</xref>.
</p>
      <table-wrap id="btz512-T2" orientation="portrait" position="float">
        <label>Table 2.</label>
        <caption>
          <p>Cross-validation performance on the SM424-18 dataset using different feature sets</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1">Feature set</th>
              <th rowspan="1" colspan="1">MCC(O)<xref ref-type="table-fn" rid="tblfn4"><sup>a</sup></xref></th>
              <th rowspan="1" colspan="1">MCC(I)<xref ref-type="table-fn" rid="tblfn4"><sup>a</sup></xref></th>
              <th rowspan="1" colspan="1">MCC(T)<xref ref-type="table-fn" rid="tblfn4"><sup>a</sup></xref></th>
              <th rowspan="1" colspan="1">MCC(M)<xref ref-type="table-fn" rid="tblfn4"><sup>a</sup></xref></th>
              <th rowspan="1" colspan="1">GCC<xref ref-type="table-fn" rid="tblfn5"><sup>b</sup></xref></th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">SEQ<xref ref-type="table-fn" rid="tblfn6"><sup>c</sup></xref></td>
              <td rowspan="1" colspan="1">0.17</td>
              <td rowspan="1" colspan="1">0.15</td>
              <td rowspan="1" colspan="1">0.13</td>
              <td rowspan="1" colspan="1">0.07</td>
              <td rowspan="1" colspan="1">0.15</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">PROP<xref ref-type="table-fn" rid="tblfn7"><sup>d</sup></xref></td>
              <td rowspan="1" colspan="1">0.17</td>
              <td rowspan="1" colspan="1">0.07</td>
              <td rowspan="1" colspan="1">0.22</td>
              <td rowspan="1" colspan="1">0.13</td>
              <td rowspan="1" colspan="1">0.19</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">PSSM<xref ref-type="table-fn" rid="tblfn8"><sup>e</sup></xref></td>
              <td rowspan="1" colspan="1">0.51</td>
              <td rowspan="1" colspan="1">0.47</td>
              <td rowspan="1" colspan="1">0.42</td>
              <td rowspan="1" colspan="1">0.57</td>
              <td rowspan="1" colspan="1">0.50</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">SEQ+PROP</td>
              <td rowspan="1" colspan="1">0.16</td>
              <td rowspan="1" colspan="1">0.07</td>
              <td rowspan="1" colspan="1">0.55</td>
              <td rowspan="1" colspan="1">0.09</td>
              <td rowspan="1" colspan="1">0.34</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">PSSM+PROP</td>
              <td rowspan="1" colspan="1">0.46</td>
              <td rowspan="1" colspan="1">0.47</td>
              <td rowspan="1" colspan="1">0.53</td>
              <td rowspan="1" colspan="1">0.65</td>
              <td rowspan="1" colspan="1">0.54</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn4">
            <label>a</label>
            <p>MCC (O, I, T, M): Matthews Correlation Coefficient of Outer, Inner, Intermembrane and Matrix localization, respectively.</p>
          </fn>
          <fn id="tblfn5">
            <label>b</label>
            <p>GCC: Generalized Correlation Coefficient (<xref ref-type="disp-formula" rid="E16">Equation (16)</xref>).</p>
          </fn>
          <fn id="tblfn6">
            <label>c</label>
            <p>Residue one-hot encoding.</p>
          </fn>
          <fn id="tblfn7">
            <label>d</label>
            <p>Residue physicochemical attributes.</p>
          </fn>
          <fn id="tblfn8">
            <label>e</label>
            <p>PSSM: Position Specific Scoring Matrix.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p>Our results indicate that both primary sequence and protein attributes, when taken alone, are not sufficiently informative and both lead to limited prediction performances, with protein attributes slightly outperforming primary sequence (GCCs are 0.19 and 0.15, respectively).</p>
      <p>As expected, evolutionary information plays a major role in improving prediction performance. In fact, when considered alone, the PSSM input significantly improves prediction performance, leading to a generalized improvement observable in all scoring indices and, in particular in GCC, raising it up to 0.50. When PSSM is combined with protein attributes, performances further improve reaching 0.54 of GCC. We then adopted this feature set for DeepMito and for all subsequence analyses.</p>
      <p>The optimal CNN architecture comprises 256 convolutional motif detectors of width 19 and 256 hidden units in the fully connected hidden layer (see Section 2.4 for details on the DeepMito CNN architecture).</p>
    </sec>
    <sec>
      <title>3.2 Analyzing DeepMito predictions on the SM424-18 dataset</title>
      <p>Having selected the best CNN architecture and features set, we analyzed in detail DeepMito predictions on the SM424-18 dataset. This allowed to highlight strengths and limitations of our method.</p>
      <p>Two aspects were taken into consideration: (i) how prediction performance varies across different taxonomic kingdoms and (ii) how DeepMito performs on different types of membrane proteins, namely single-pass (SP), multi-pass (MP) and peripheral membrane (PM) proteins.</p>
      <p>Concerning the first issue, performance scores obtained on the different subsets of animals, plants and fungi proteins are reported in <xref rid="btz512-T3" ref-type="table">Table 3</xref>. It is worth noting that these results were not obtained by retraining DeepMito on the individual subsets of proteins but simply by isolating cross-validation predictions corresponding to each taxonomic set.
</p>
      <table-wrap id="btz512-T3" orientation="portrait" position="float">
        <label>Table 3.</label>
        <caption>
          <p>DeepMito prediction performance on proteins from different taxonomic kingdoms</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1">Kingdom</th>
              <th rowspan="1" colspan="1">MCC(O)<xref ref-type="table-fn" rid="tblfn9"><sup>a</sup></xref></th>
              <th rowspan="1" colspan="1">MCC(I)<xref ref-type="table-fn" rid="tblfn9"><sup>a</sup></xref></th>
              <th rowspan="1" colspan="1">MCC(T)<xref ref-type="table-fn" rid="tblfn9"><sup>a</sup></xref></th>
              <th rowspan="1" colspan="1">MCC(M)<xref ref-type="table-fn" rid="tblfn9"><sup>a</sup></xref></th>
              <th rowspan="1" colspan="1">GCC<xref ref-type="table-fn" rid="tblfn10"><sup>b</sup></xref></th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">Metazoa (193<xref ref-type="table-fn" rid="tblfn11"><sup>c</sup></xref>)</td>
              <td rowspan="1" colspan="1">0.44</td>
              <td rowspan="1" colspan="1">0.44</td>
              <td rowspan="1" colspan="1">0.52</td>
              <td rowspan="1" colspan="1">0.69</td>
              <td rowspan="1" colspan="1">0.54</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Viridiplantae (60<xref ref-type="table-fn" rid="tblfn11"><sup>c</sup></xref>)</td>
              <td rowspan="1" colspan="1">0.45</td>
              <td rowspan="1" colspan="1">0.52</td>
              <td rowspan="1" colspan="1">0.90</td>
              <td rowspan="1" colspan="1">0.76</td>
              <td rowspan="1" colspan="1">0.71</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Fungi (166<xref ref-type="table-fn" rid="tblfn11"><sup>c</sup></xref>)</td>
              <td rowspan="1" colspan="1">0.49</td>
              <td rowspan="1" colspan="1">0.52</td>
              <td rowspan="1" colspan="1">0.37</td>
              <td rowspan="1" colspan="1">0.59</td>
              <td rowspan="1" colspan="1">0.50</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn9">
            <label>a</label>
            <p>MCC (O, I, T, M): Matthews Correlation Coefficient of Outer, Inner, Intermembrane and Matrix localization, respectively.</p>
          </fn>
          <fn id="tblfn10">
            <label>b</label>
            <p>GCC: Generalized Correlation Coefficient (<xref ref-type="disp-formula" rid="E16">Equation (16)</xref>).</p>
          </fn>
          <fn id="tblfn11">
            <label>c</label>
            <p>Number of sequences.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p>Comparing results in <xref rid="btz512-T3" ref-type="table">Table 3</xref> with overall performance scores (<xref rid="btz512-T2" ref-type="table">Table 2</xref>, last row), we can observe a substantial robustness of the method across the three different kingdoms. In particular, performances are stable on animals (GCC 0.54) and slightly lower on fungi (GCC 0.50). Interestingly, on plant proteins prediction performances are significantly higher, reaching a GCC of 0.71, 17 percentage points higher than the one obtained on the full dataset (0.54).</p>
      <p>In <xref rid="btz512-T4" ref-type="table">Table 4</xref>, results focus on the prediction of the localization of mitochondrial membrane proteins (i.e. experimentally localized into inner and/or outer membranes). In particular, we analyzed prediction results with respect to available experimental information on membrane protein topology, more specifically separating SP proteins (spanning the membrane with a single transmembrane segment), MP proteins (endowed with multiple transmembrane segments) and PM proteins (physically associated to the membrane but not spanning it). Out of 264 membrane proteins included in SM424-18, we were able to retrieve from UniprotKB topological information for 227 proteins.
</p>
      <table-wrap id="btz512-T4" orientation="portrait" position="float">
        <label>Table 4.</label>
        <caption>
          <p>DeepMito prediction performance on mitochondrial membrane proteins with respect to annotated membrane protein topology</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="char" char="(" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1">Topology</th>
              <th rowspan="1" colspan="1"><italic>N</italic><sub>P</sub> (<italic>N</italic><sub>O</sub>+<italic>N</italic><sub>I</sub>)<xref ref-type="table-fn" rid="tblfn12"><sup>a</sup></xref></th>
              <th rowspan="1" colspan="1"><inline-formula id="IE102"><mml:math id="IM102"><mml:msubsup><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mi mathvariant="normal">mem</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula> (%)<xref ref-type="table-fn" rid="tblfn13"><sup>b</sup></xref></th>
              <th rowspan="1" colspan="1">MCC(O)</th>
              <th rowspan="1" colspan="1">MCC(I)</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">SP</td>
              <td rowspan="1" colspan="1">71 (31+40)</td>
              <td rowspan="1" colspan="1">92</td>
              <td rowspan="1" colspan="1">0.43</td>
              <td rowspan="1" colspan="1">0.38</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">MP</td>
              <td rowspan="1" colspan="1">94 (21+73)</td>
              <td rowspan="1" colspan="1">98</td>
              <td rowspan="1" colspan="1">0.47</td>
              <td rowspan="1" colspan="1">0.49</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">PM</td>
              <td rowspan="1" colspan="1">61 (6+55)</td>
              <td rowspan="1" colspan="1">36</td>
              <td rowspan="1" colspan="1">0.36</td>
              <td rowspan="1" colspan="1">0.09</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn12">
            <label>a</label>
            <p><italic>N</italic><sub>P</sub> (<italic>N</italic><sub>O</sub>+<italic>N</italic><sub>I</sub>): number of membrane protein (outer and inner).</p>
          </fn>
          <fn id="tblfn13">
            <label>b</label>
            <p><inline-formula id="IE103"><mml:math id="IM103"><mml:msubsup><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mi mathvariant="normal">mem</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula>: the fraction of proteins correctly predicted in either inner or outer membrane.</p>
          </fn>
          <fn id="tblfn14">
            <p>SP: single-pass membrane protein; MP: multiple-pass membrane protein; PM: peripheral membrane protein.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p>In <xref rid="btz512-T4" ref-type="table">Table 4</xref>, for each topology class, we report the total number of proteins (N<sub>P</sub>), the number of outer and inner membrane proteins (<italic>N</italic><sub>O</sub> and <italic>N</italic><sub>I</sub>, respectively), the fraction of proteins correctly predicted in either inner or outer membrane (<inline-formula id="IE104"><mml:math id="IM104"><mml:msubsup><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mi mathvariant="normal">mem</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula>) and the MCCs for inner and outer membrane classes.</p>
      <p>Results show that the stronger the transmembrane signal is along the sequence the higher is the ability of DeepMito to properly recognize these proteins and discriminate them from non-membrane ones: 98% and 92% of MP and SP proteins, respectively, are correctly predicted as belonging to membrane compartments (either inner or outer membrane). In contrast, only 22 out of 61 (36%), PM proteins are correctly localized into membranes. This suggests that PM proteins are endowed with features that are more similar to proteins of matrix and/or intermembrane space. Thirty-nine PM proteins are incorrectly classified into globular compartments: out of these, 32 are annotated in UniprotKB as residing in the matrix side of the membrane. Interestingly DeepMito correctly assigns 28 out of 32 PM proteins to the matrix compartment.</p>
    </sec>
    <sec>
      <title>3.3 Comparing DeepMito with other approaches</title>
      <p>Performing a comparison among different approaches for sub-mitochondrial localization prediction is a challenging task, mainly because different methods are trained/tested using different datasets and many of the methods presented so far are no more available via respective web servers. For these reasons, we decided to carry out a direct comparison between DeepMito and the most recent approach described for the same four-compartment discriminative task (SubMitoPred, <xref rid="btz512-B17" ref-type="bibr">Kumar <italic>et al.</italic>, 2018</xref>). Furthermore, it is the only method running (at the specified web URL reported in the reference paper) and providing training/testing dataset for downloading.</p>
      <p>For sake of comparison, we trained and tested DeepMito using a 5-fold cross-validation on the SubMitoPred dataset, comprising 570 proteins localized into the four different compartments (<xref rid="btz512-T1" ref-type="table">Table 1</xref>). In particular, two different procedures were applied to perform cross-validation. In a first experiment, we applied exactly the same procedure as described by the SubMitoPred authors, namely, random splitting the set of 570 proteins into five subsets (results labeled as RS in <xref rid="btz512-T5" ref-type="table">Table 5</xref>). In this comparative benchmark, our method significantly outperforms its competitor in all MCC scores. Noticeably, DeepMito performances are more stable across the four different classes, suggesting that our method is able to better cope with class imbalance. Proteins localized in the intermembrane space, despite their low abundance (only 32 out of 570 proteins in the SubMitoPred dataset) are recognized very well by DeepMito, achieving an MCC score of 0.54 against the 0.19 reported by SubMitoPred.
</p>
      <table-wrap id="btz512-T5" orientation="portrait" position="float">
        <label>Table 5.</label>
        <caption>
          <p>Performance comparison of different methods</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1">Method</th>
              <th rowspan="1" colspan="1">Cross-validation</th>
              <th rowspan="1" colspan="1">MCC(O)</th>
              <th rowspan="1" colspan="1">MCC(I)</th>
              <th rowspan="1" colspan="1">MCC(T)</th>
              <th rowspan="1" colspan="1">MCC(M)</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">SubMitoPred<xref ref-type="table-fn" rid="tblfn15"><sup>a</sup></xref></td>
              <td rowspan="1" colspan="1">RS</td>
              <td rowspan="1" colspan="1">0.42</td>
              <td rowspan="1" colspan="1">0.34</td>
              <td rowspan="1" colspan="1">0.19</td>
              <td rowspan="1" colspan="1">0.51</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">DeepMito</td>
              <td rowspan="1" colspan="1">RS</td>
              <td rowspan="1" colspan="1">0.45</td>
              <td rowspan="1" colspan="1">0.68</td>
              <td rowspan="1" colspan="1">0.54</td>
              <td rowspan="1" colspan="1">0.79</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">DeepMito</td>
              <td rowspan="1" colspan="1">CL</td>
              <td rowspan="1" colspan="1">0.42</td>
              <td rowspan="1" colspan="1">0.60</td>
              <td rowspan="1" colspan="1">0.46</td>
              <td rowspan="1" colspan="1">0.76</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn15">
            <label>a</label>
            <p>Results taken from <xref rid="btz512-B17" ref-type="bibr">Kumar <italic>et al.</italic> (2018)</xref>.</p>
          </fn>
          <fn id="tblfn16">
            <p>RS=cross-validation performed by random splitting the dataset. CL=cross-validation performed confining any local similarity into the same cross-validation set (see Sections 2.2.1 and 2.2.2 for details).</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p>To further confirm the ability of DeepMito to capture informative patterns from data, we carried out an additional experiment using a more stringent procedure to perform cross-validation (marked as CL in <xref rid="btz512-T5" ref-type="table">Table 5</xref>). In this experiment, cross-validation split was computed confining pairs of sequence sharing any residual local similarity in the same cross-validation set (as done for our SM424-18 dataset, see Sections 2.2.1 and 2.2.2 for details). As expected, results obtained by DeepMito are slightly worse than those achieved by random splitting (justifying the adoption of the more stringent similarity reduction procedure) but still significantly higher than those achieved by SubMitoPred in all MCC scores.</p>
    </sec>
    <sec>
      <title>3.4 Scoring DeepMito on genomic-scale analysis</title>
      <p>As a final test, we evaluated DeepMito on genomic-scale analysis using the human mitochondrial dataset extracted from the Cell Atlas database (see Section 2.1.3). In particular, DeepMito was trained using the entire SM424-18 dataset and predictions generated for all the 1050 proteins included in the Mito-CA-Full dataset.</p>
      <p>First, we assessed DeepMito predictions with respect to available experimental annotations: for this, we extracted predictions on the Mito-CA-Annotated dataset comprising 179 sequences endowed with experimental GO terms relative to sub-mitochondrial compartments. <xref ref-type="fig" rid="btz512-F2">Figure 2</xref> summarizes distributions of annotations, DeepMito predictions as well as the number of correct predictions for each class. Evidently, DeepMito predictions correlate very well with available experimental evidence: overall, our method achieves a GCC of 0.97 on the Mito-CA-Annotated dataset.
</p>
      <fig id="btz512-F2" orientation="portrait" position="float">
        <label>Fig. 2.</label>
        <caption>
          <p>Distribution of annotations and DeepMito predictions on the Mito-CA-Annotated dataset.</p>
        </caption>
        <graphic xlink:href="btz512f2"/>
      </fig>
      <p>In <xref ref-type="fig" rid="btz512-F3">Fig. 3</xref>, we show the distribution of predicted classes for all the 1050 proteins in the Mito-CA-Full dataset. The relative abundances of predicted compartments are comparable to the ones observed in the Mito-CA-Annotated dataset. Complete results can be examined in detail at <ext-link ext-link-type="uri" xlink:href="http://busca.biocomp.unibo.it/deepmito/hpa">http://busca.biocomp.unibo.it/deepmito/hpa</ext-link>.
</p>
      <fig id="btz512-F3" orientation="portrait" position="float">
        <label>Fig. 3.</label>
        <caption>
          <p>Distribution of DeepMito predictions on the Mito-CA-Full dataset.</p>
        </caption>
        <graphic xlink:href="btz512f3"/>
      </fig>
    </sec>
    <sec>
      <title>3.5 Software availability</title>
      <p>We released DeepMito as web server at <ext-link ext-link-type="uri" xlink:href="http://busca.biocomp.unibo.it/deepmito">http://busca.biocomp.unibo.it/deepmito</ext-link>. The server supports the analysis of up to 200 sequences per submission: for each input protein, the server provides the predicted sub-mitochondrial compartment (as Gene Ontology Cellular Component term) along with a score associated with the prediction. Even though the server is intended to be used with proteins already known to be mitochondrial and for which the user is interested to know the precise localization inside the organelle, there is the possibility that users provide in input proteins that are not mitochondrial. In order to cope with this issue, the server performs a scanning of input proteins using two state-of-the-art predictors of mitochondrial localization: TPpred3 (<xref rid="btz512-B28" ref-type="bibr">Savojardo <italic>et al.</italic>, 2015</xref>), which predict mitochondrial localization by means of recognition of the targeting pre-sequence, and BaCelLo (<xref rid="btz512-B25" ref-type="bibr">Pierleoni <italic>et al.</italic>, 2006</xref>), which provide discrimination of mitochondrial proteins from proteins directed to other compartments. A protein is predicted as mitochondrial if at least one of the above methods classifies it as such. This piece of information is provided as additional output for the user.</p>
      <p>We also provide a standalone version of the program implemented as a Docker container. The image is available on DockerHub at <ext-link ext-link-type="uri" xlink:href="https://hub.docker.com/r/bolognabiocomp/deepmito">https://hub.docker.com/r/bolognabiocomp/deepmito</ext-link>. A tutorial on how to install and use the DeepMito docker container can be found at <ext-link ext-link-type="uri" xlink:href="http://busca.biocomp.unibo.it/deepmito/software">http://busca.biocomp.unibo.it/deepmito/software</ext-link>. DeepMito source code is also available on GitHub at <ext-link ext-link-type="uri" xlink:href="https://github.com/BolognaBiocomp/deepmito">https://github.com/BolognaBiocomp/deepmito</ext-link>.</p>
    </sec>
  </sec>
  <sec>
    <title>4 Conclusions</title>
    <p>DeepMito is a novel method for predicting protein sub-mitochondrial localization. Thanks to the power of a CNN architecture specifically designed to solve this task, DeepMito scores with good performances in different experiments aiming at testing its validity and applicability. In a four-compartment discrimination test, DeepMito scores higher than SubMitoPred, a recent method performing the same task. We tested DeepMito adopting a 10-fold cross-validation procedure on a newly developed training/testing set containing only mitochondrial proteins with location experimentally annotated. Then we also retrained and tested our predictor adopting the same set of proteins and the same cross-validation procedure of SubMitoPred, and again our method overpasses the state-of-the-art.</p>
    <p>SubMitoPred is based on a combination of transfer-by-similarity and support vector machines. In contrast, DeepMito is based on artificial neural networks and it adopts the CNN architecture to extract relevant patterns from primary features. One immediate result is that our approach is robust with respect to class imbalance and provides very accurate predictions even for those compartments that are underrepresented in the training set (such as the intermembrane space, accounting for only few proteins).</p>
    <p>The adoption of more complex architectures like recurrent layers may improve prediction performance in this task. However, in our experiments (data not shown), recurrent approaches lead to poor performance. This fact is maybe due to the scarcity of data which hampers proper training of complex architectures.</p>
    <p>DeepMito well performs also on proteome-scale analysis, carried out on high-quality human proteins from the Cell Atlas database (<xref rid="btz512-B33" ref-type="bibr">Thul <italic>et al.</italic>, 2017</xref>). A present limit of DeepMito, due to the paucity of good quality available data is its present impossibility to predict multiple localization for a single protein sequence.</p>
    <p>We propose DeepMito as a powerful and reliable tool for integration in functional annotation platforms.</p>
  </sec>
  <sec>
    <title>Funding</title>
    <p>PRIN 2017 project 2017483NH8 (to C.S.) (Italian MIUR).</p>
    <p><italic>Conflict of Interest</italic>: none declared.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material content-type="local-data" id="sup1">
      <label>btz512_Supplementary_Material</label>
      <media xlink:href="btz512_supplementary_material.docx">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="btz512-B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Alipanahi</surname><given-names>B.</given-names></name></person-group><etal>et al</etal> (<year>2015</year>) 
<article-title>Predicting the sequence specificities of DNA- and RNA-binding proteins by deep learning</article-title>. <source>Nat. Biotechnol</source>., <volume>33</volume>, <fpage>831</fpage>–<lpage>838</lpage>.<pub-id pub-id-type="pmid">26213851</pub-id></mixed-citation>
    </ref>
    <ref id="btz512-B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Almagro Armenteros</surname><given-names>J.J.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) 
<article-title>DeepLoc: prediction of protein subcellular localization using deep learning</article-title>. <source>Bioinformatics</source>, <volume>33</volume>, <fpage>3387</fpage>–<lpage>3395</lpage>.<pub-id pub-id-type="pmid">29036616</pub-id></mixed-citation>
    </ref>
    <ref id="btz512-B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Altschul</surname><given-names>S.F.</given-names></name></person-group><etal>et al</etal> (<year>1997</year>) 
<article-title>Gapped BLAST and PSI-BLAST: a new generation of protein database search programs</article-title>. <source>Nucleic Acids Res</source>., <volume>25</volume>, <fpage>3389</fpage>–<lpage>3402</lpage>.<pub-id pub-id-type="pmid">9254694</pub-id></mixed-citation>
    </ref>
    <ref id="btz512-B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Angermueller</surname><given-names>C.</given-names></name></person-group><etal>et al</etal> (<year>2016</year>) 
<article-title>Deep learning for computational biology</article-title>. <source>Mol. Syst. Biol</source>., <volume>12</volume>, <fpage>878.</fpage><pub-id pub-id-type="pmid">27474269</pub-id></mixed-citation>
    </ref>
    <ref id="btz512-B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Baldi</surname><given-names>P.</given-names></name></person-group><etal>et al</etal> (<year>2000</year>) 
<article-title>Assessing the accuracy of prediction algorithms for classification: an overview</article-title>. <source>Bioinformatics</source>, <volume>16</volume>, <fpage>412</fpage>–<lpage>424</lpage>.<pub-id pub-id-type="pmid">10871264</pub-id></mixed-citation>
    </ref>
    <ref id="btz512-B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Bannai</surname><given-names>H.</given-names></name></person-group><etal>et al</etal> (<year>2002</year>) 
<article-title>Extensive feature detection of N-terminal protein sorting signals</article-title>. <source>Bioinformatics</source>, <volume>18</volume>, <fpage>298</fpage>–<lpage>305</lpage>.<pub-id pub-id-type="pmid">11847077</pub-id></mixed-citation>
    </ref>
    <ref id="btz512-B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Du</surname><given-names>P.</given-names></name>, <name name-style="western"><surname>Li</surname><given-names>Y.</given-names></name></person-group> (<year>2006</year>) 
<article-title>Prediction of protein submitochondria locations by hybridizing pseudo-amino acid composition with various physicochemical features of segmented sequence</article-title>. <source>BMC Bioinformatics</source>, <volume>7</volume>, <fpage>518</fpage>.<pub-id pub-id-type="pmid">17134515</pub-id></mixed-citation>
    </ref>
    <ref id="btz512-B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Du</surname><given-names>P.</given-names></name>, <name name-style="western"><surname>Yu</surname><given-names>Y.</given-names></name></person-group> (<year>2013</year>) 
<article-title>SubMito-PSPCP: predicting protein submitochondrial locations by hybridizing positional specific physicochemical properties with pseudoamino acid compositions</article-title>. <source>Biomed. Res. Int</source>., <volume>2013</volume>, <fpage>263829.</fpage><pub-id pub-id-type="pmid">24027753</pub-id></mixed-citation>
    </ref>
    <ref id="btz512-B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Dudek</surname><given-names>J.</given-names></name></person-group><etal>et al</etal> (<year>2013</year>) 
<article-title>Mitochondrial protein import: common principles and physiological networks</article-title>. <source>Biochim. Biophys. Acta</source>, <volume>1833</volume>, <fpage>274</fpage>–<lpage>285</lpage>.<pub-id pub-id-type="pmid">22683763</pub-id></mixed-citation>
    </ref>
    <ref id="btz512-B12">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Emanuelsson</surname><given-names>O.</given-names></name></person-group><etal>et al</etal> (<year>2007</year>) 
<article-title>Locating proteins in the cell using TargetP, SignalP and related tools</article-title>. <source>Nat. Protoc</source>., <volume>2</volume>, <fpage>953</fpage>–<lpage>971</lpage>.<pub-id pub-id-type="pmid">17446895</pub-id></mixed-citation>
    </ref>
    <ref id="btz512-B13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Fan</surname><given-names>G.L.</given-names></name>, <name name-style="western"><surname>Li</surname><given-names>Q.Z.</given-names></name></person-group> (<year>2012</year>) 
<article-title>Predicting protein submitochondria locations by combining different descriptors into the general form of Chou's pseudo amino acid composition</article-title>. <source>Amino Acids</source>, <volume>43</volume>, <fpage>545</fpage>–<lpage>555</lpage>.<pub-id pub-id-type="pmid">22102053</pub-id></mixed-citation>
    </ref>
    <ref id="btz512-B14">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Fukasawa</surname><given-names>Y.</given-names></name></person-group><etal>et al</etal> (<year>2015</year>) 
<article-title>MitoFates: improved prediction of mitochondrial targeting sequences and their cleavage sites</article-title>. <source>Mol. Cell Proteomics</source>, <volume>14</volume>, <fpage>1113</fpage>–<lpage>1126</lpage>.<pub-id pub-id-type="pmid">25670805</pub-id></mixed-citation>
    </ref>
    <ref id="btz512-B15">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Kidera</surname><given-names>A.</given-names></name></person-group><etal>et al</etal> (<year>1985</year>) 
<article-title>Statistical analysis of the physical properties of the 20 naturally occurring amino acids</article-title>. <source>J. Prot. Chem</source>., <volume>4</volume>, <fpage>23</fpage>–<lpage>55</lpage>.</mixed-citation>
    </ref>
    <ref id="btz512-B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Kumar</surname><given-names>R.</given-names></name></person-group><etal>et al</etal> (<year>2014</year>) 
<article-title>Protein sub-nuclear localization prediction using SVM and PFAM domain information</article-title>. <source>PLoS One</source>, <volume>9</volume>, <fpage>e98345.</fpage><pub-id pub-id-type="pmid">24897370</pub-id></mixed-citation>
    </ref>
    <ref id="btz512-B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Kumar</surname><given-names>R.</given-names></name></person-group><etal>et al</etal> (<year>2018</year>) 
<article-title>Proteome-wide prediction and annotation of mitochondrial and sub-mitochondrial proteins by incorporating domain information</article-title>. <source>Mitochondrion</source>, <volume>42</volume>, <fpage>11</fpage>–<lpage>22</lpage>.<pub-id pub-id-type="pmid">29032233</pub-id></mixed-citation>
    </ref>
    <ref id="btz512-B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>LeCun</surname><given-names>Y.</given-names></name></person-group><etal>et al</etal> (<year>2015</year>) 
<article-title>Deep learning</article-title>. <source>Nature</source>, <volume>521</volume>, <fpage>436</fpage>–<lpage>444</lpage>.<pub-id pub-id-type="pmid">26017442</pub-id></mixed-citation>
    </ref>
    <ref id="btz512-B19">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Li</surname><given-names>W.</given-names></name>, <name name-style="western"><surname>Godzik</surname><given-names>A.</given-names></name></person-group> (<year>2006</year>) 
<article-title>Cd-hit: a fast program for clustering and comparing large sets of protein or nucleotide sequences</article-title>. <source>Bioinformatics</source>, <volume>22</volume>, <fpage>1658</fpage>–<lpage>1659</lpage>.<pub-id pub-id-type="pmid">16731699</pub-id></mixed-citation>
    </ref>
    <ref id="btz512-B20">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Lin</surname><given-names>H.</given-names></name></person-group><etal>et al</etal> (<year>2013</year>) 
<article-title>Using over-represented tetrapeptides to predict protein submitochondria locations</article-title>. <source>Acta Biotheor</source>., <volume>61</volume>, <fpage>259</fpage>–<lpage>268</lpage>.<pub-id pub-id-type="pmid">23475502</pub-id></mixed-citation>
    </ref>
    <ref id="btz512-B21">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Martelli</surname><given-names>P.L.</given-names></name></person-group><etal>et al</etal> (<year>2015</year>) 
<article-title>Computer-based prediction of mitochondria-targeting peptides</article-title>. <source>Methods Mol. Biol</source>., <volume>1264</volume>, <fpage>305</fpage>–<lpage>320</lpage>.<pub-id pub-id-type="pmid">25631024</pub-id></mixed-citation>
    </ref>
    <ref id="btz512-B22">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Mei</surname><given-names>S.</given-names></name></person-group> (<year>2012</year>) 
<article-title>Multi-kernel transfer learning based on Chou's PseAAC formulation for protein submitochondria localization</article-title>. <source>J. Theor. Biol</source>., <volume>293</volume>, <fpage>121</fpage>–<lpage>130</lpage>.<pub-id pub-id-type="pmid">22037046</pub-id></mixed-citation>
    </ref>
    <ref id="btz512-B23">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Nanni</surname><given-names>L.</given-names></name>, <name name-style="western"><surname>Lumini</surname><given-names>A.</given-names></name></person-group> (<year>2008</year>) 
<article-title>Genetic programming for creating Chou's pseudo amino acid based features for submitochondria localization</article-title>. <source>Amino Acids</source>, <volume>34</volume>, <fpage>653</fpage>–<lpage>660</lpage>.<pub-id pub-id-type="pmid">18175047</pub-id></mixed-citation>
    </ref>
    <ref id="btz512-B24">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Petsalaki</surname><given-names>E.I.</given-names></name></person-group><etal>et al</etal> (<year>2006</year>) 
<article-title>PredSL: a tool for the N-terminal sequence-based prediction of protein subcellular localization</article-title>. <source>Genomics Proteomics Bioinformatics</source>, <volume>4</volume>, <fpage>48</fpage>–<lpage>55</lpage>.<pub-id pub-id-type="pmid">16689702</pub-id></mixed-citation>
    </ref>
    <ref id="btz512-B25">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Pierleoni</surname><given-names>A.</given-names></name></person-group><etal>et al</etal> (<year>2006</year>) 
<article-title>BaCelLo: a balanced subcellular localization predictor</article-title>. <source>Bioinformatics</source>, <volume>22</volume>, <fpage>e408</fpage>–<lpage>e416</lpage>.<pub-id pub-id-type="pmid">16873501</pub-id></mixed-citation>
    </ref>
    <ref id="btz512-B26">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Poveda-Huertes</surname><given-names>D.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) 
<article-title>The versatility of the mitochondrial presequence processing machinery: cleavage, quality control and turnover</article-title>. <source>Cell Tissue Res</source>., <volume>367</volume>, <fpage>73</fpage>–<lpage>81</lpage>.<pub-id pub-id-type="pmid">27595151</pub-id></mixed-citation>
    </ref>
    <ref id="btz512-B27">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Savojardo</surname><given-names>C.</given-names></name></person-group><etal>et al</etal> (<year>2014</year>) 
<article-title>TPpred2: improving the prediction of mitochondrial targeting peptide cleavage sites by exploiting sequence motifs</article-title>. <source>Bioinformatics</source>, <volume>30</volume>, <fpage>2973</fpage>–<lpage>2974</lpage>.<pub-id pub-id-type="pmid">24974200</pub-id></mixed-citation>
    </ref>
    <ref id="btz512-B28">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Savojardo</surname><given-names>C.</given-names></name></person-group><etal>et al</etal> (<year>2015</year>) 
<article-title>TPpred3 detects and discriminates mitochondrial and chloroplastic targeting peptides in eukaryotic proteins</article-title>. <source>Bioinformatics</source>, <volume>31</volume>, <fpage>3269</fpage>–<lpage>3275</lpage>.<pub-id pub-id-type="pmid">26079349</pub-id></mixed-citation>
    </ref>
    <ref id="btz512-B29">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Savojardo</surname><given-names>C.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) 
<article-title>SChloro: directing Viridiplantae proteins to six chloroplastic sub-compartments</article-title>. <source>Bioinformatics</source>, <volume>33</volume>, <fpage>347</fpage>–<lpage>353</lpage>.<pub-id pub-id-type="pmid">28172591</pub-id></mixed-citation>
    </ref>
    <ref id="btz512-B30">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Savojardo</surname><given-names>C.</given-names></name></person-group><etal>et al</etal> (<year>2018</year>) 
<article-title>DeepSig: deep learning improves signal peptide detection in proteins</article-title>. <source>Bioinformatics</source>, <volume>34</volume>, <fpage>1690</fpage>–<lpage>1696</lpage>.<pub-id pub-id-type="pmid">29280997</pub-id></mixed-citation>
    </ref>
    <ref id="btz512-B31">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Shi</surname><given-names>S.P.</given-names></name></person-group><etal>et al</etal> (<year>2011</year>) 
<article-title>Identify submitochondria and subchloroplast locations with pseudo amino acid composition: approach from the strategy of discrete wavelet transform feature extraction</article-title>. <source>Biochim. Biophys. Acta</source>, <volume>1813</volume>, <fpage>424</fpage>–<lpage>430</lpage>.<pub-id pub-id-type="pmid">21255619</pub-id></mixed-citation>
    </ref>
    <ref id="btz512-B32">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Small</surname><given-names>I.</given-names></name></person-group><etal>et al</etal> (<year>2004</year>) 
<article-title>Predotar: a tool for rapidly screening proteomes for N-terminal targeting sequences</article-title>. <source>Proteomics</source>, <volume>4</volume>, <fpage>1581</fpage>–<lpage>1590</lpage>.<pub-id pub-id-type="pmid">15174128</pub-id></mixed-citation>
    </ref>
    <ref id="btz512-B33">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Thul</surname><given-names>P.J.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) 
<article-title>A subcellular map of the human proteome</article-title>. <source>Science</source>, <volume>356</volume>, <fpage>eaal3321.</fpage><pub-id pub-id-type="pmid">28495876</pub-id></mixed-citation>
    </ref>
    <ref id="btz512-B34">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Wang</surname><given-names>X.</given-names></name></person-group><etal>et al</etal> (<year>2015</year>) 
<article-title>MultiP-SChlo: multi-label protein subchloroplast localization prediction with Chou’s pseudo amino acid composition and a novel multi-label classifier</article-title>. <source>Bioinformatics</source>, <volume>31</volume>, <fpage>2639</fpage>–<lpage>2645</lpage>.<pub-id pub-id-type="pmid">25900916</pub-id></mixed-citation>
    </ref>
    <ref id="btz512-B35">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Zeng</surname><given-names>Y.H.</given-names></name></person-group><etal>et al</etal> (<year>2009</year>) 
<article-title>Using the augmented Chou's pseudo amino acid composition for predicting protein submitochondria locations based on auto covariance approach</article-title>. <source>J. Theor. Biol</source>., <volume>259</volume>, <fpage>366</fpage>–<lpage>372</lpage>.<pub-id pub-id-type="pmid">19341746</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1 20151215//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.1?>
<?ConverterInfo.XSLTName jp2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id>
    <journal-id journal-id-type="publisher-id">bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1367-4803</issn>
    <issn pub-type="epub">1367-4811</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">6956790</article-id>
    <article-id pub-id-type="doi">10.1093/bioinformatics/btz512</article-id>
    <article-id pub-id-type="publisher-id">btz512</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Original Papers</subject>
        <subj-group subj-group-type="category-toc-heading">
          <subject>Sequence Analysis</subject>
        </subj-group>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>DeepMito: accurate prediction of protein sub-mitochondrial localization using convolutional neural networks</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0002-7359-0633</contrib-id>
        <name>
          <surname>Savojardo</surname>
          <given-names>Castrense</given-names>
        </name>
        <xref ref-type="aff" rid="btz512-aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Bruciaferri</surname>
          <given-names>Niccolò</given-names>
        </name>
        <xref ref-type="aff" rid="btz512-aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Tartari</surname>
          <given-names>Giacomo</given-names>
        </name>
        <xref ref-type="aff" rid="btz512-aff1">1</xref>
        <xref ref-type="aff" rid="btz512-aff2">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Martelli</surname>
          <given-names>Pier Luigi</given-names>
        </name>
        <xref ref-type="aff" rid="btz512-aff1">1</xref>
        <xref ref-type="corresp" rid="btz512-cor1"/>
        <!--<email>pierluigi.martelli@unibo.it</email>-->
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Casadio</surname>
          <given-names>Rita</given-names>
        </name>
        <xref ref-type="aff" rid="btz512-aff1">1</xref>
        <xref ref-type="aff" rid="btz512-aff2">2</xref>
      </contrib>
    </contrib-group>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Cowen</surname>
          <given-names>Lenore</given-names>
        </name>
        <role>Associate Editor</role>
      </contrib>
    </contrib-group>
    <aff id="btz512-aff1"><label>1</label><institution>Biocomputing Group, Department of Pharmacy and Biotechnology (FaBiT), University of Bologna</institution>, Bologna, <country country="IT">Italy</country></aff>
    <aff id="btz512-aff2"><label>2</label><institution>Institute of Biomembranes, Bioenergetics and Molecular Biotechnologies (IBIOM), Italian National Research Council (CNR)</institution>, Bari, <country country="IT">Italy</country></aff>
    <author-notes>
      <corresp id="btz512-cor1">To whom correspondence should be addressed. E-mail: <email>pierluigi.martelli@unibo.it</email></corresp>
    </author-notes>
    <pub-date pub-type="ppub">
      <day>01</day>
      <month>1</month>
      <year>2020</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2019-06-20">
      <day>20</day>
      <month>6</month>
      <year>2019</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>20</day>
      <month>6</month>
      <year>2019</year>
    </pub-date>
    <!-- PMC Release delay is 0 months and 0 days and was based on the <pub-date pub-type="epub"/>. -->
    <volume>36</volume>
    <issue>1</issue>
    <fpage>56</fpage>
    <lpage>64</lpage>
    <history>
      <date date-type="received">
        <day>29</day>
        <month>3</month>
        <year>2019</year>
      </date>
      <date date-type="rev-recd">
        <day>31</day>
        <month>5</month>
        <year>2019</year>
      </date>
      <date date-type="accepted">
        <day>17</day>
        <month>6</month>
        <year>2019</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2019. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2019</copyright-year>
      <license license-type="cc-by" xlink:href="http://creativecommons.org/licenses/by/4.0/">
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="btz512.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Motivation</title>
        <p>The correct localization of proteins in cell compartments is a key issue for their function. Particularly, mitochondrial proteins are physiologically active in different compartments and their aberrant localization contributes to the pathogenesis of human mitochondrial pathologies. Many computational methods exist to assign protein sequences to subcellular compartments such as nucleus, cytoplasm and organelles. However, a substantial lack of experimental evidence in public sequence databases hampered so far a finer grain discrimination, including also intra-organelle compartments.</p>
      </sec>
      <sec id="s2">
        <title>Results</title>
        <p>We describe DeepMito, a novel method for predicting protein sub-mitochondrial cellular localization. Taking advantage of powerful deep-learning approaches, such as convolutional neural networks, our method is able to achieve very high prediction performances when discriminating among four different mitochondrial compartments (matrix, outer, inner and intermembrane regions). The method is trained and tested in cross-validation on a newly generated, high-quality dataset comprising 424 mitochondrial proteins with experimental evidence for sub-organelle localizations. We benchmark DeepMito towards the only one recent approach developed for the same task. Results indicate that DeepMito performances are superior. Finally, genomic-scale prediction on a highly-curated dataset of human mitochondrial proteins further confirms the effectiveness of our approach and suggests that DeepMito is a good candidate for genome-scale annotation of mitochondrial protein subcellular localization.</p>
      </sec>
      <sec id="s3">
        <title>Availability and implementation</title>
        <p>The DeepMito web server as well as all datasets used in this study are available at <ext-link ext-link-type="uri" xlink:href="http://busca.biocomp.unibo.it/deepmito">http://busca.biocomp.unibo.it/deepmito</ext-link>. A standalone version of DeepMito is available on DockerHub at <ext-link ext-link-type="uri" xlink:href="https://hub.docker.com/r/bolognabiocomp/deepmito">https://hub.docker.com/r/bolognabiocomp/deepmito</ext-link>. DeepMito source code is available on GitHub at <ext-link ext-link-type="uri" xlink:href="https://github.com/BolognaBiocomp/deepmito">https://github.com/BolognaBiocomp/deepmito</ext-link></p>
      </sec>
      <sec id="s4">
        <title>Supplementary information</title>
        <p><xref ref-type="supplementary-material" rid="sup1">Supplementary data</xref> are available at <italic>Bioinformatics</italic> online.</p>
      </sec>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <named-content content-type="funder-name">PRIN 2017</named-content>
        </funding-source>
        <award-id>2017483NH8</award-id>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="9"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 Introduction</title>
    <p>Mitochondria are double-membrane bound organelles present in all Eukaryotic cells and performing very important biological functions, which include energy production, calcium signaling, regulation of cell metabolism and apoptosis (<xref rid="btz512-B26" ref-type="bibr">Poveda-Huertes <italic>et al.</italic>, 2017</xref>).</p>
    <p>Mitochondria are endowed with their own genome, coding for only few proteins. The vast majority of proteins that are localized into mitochondria are instead encoded by the nuclear genome, synthesized in cytoplasmic ribosomes and subsequently translocated into the organelle by means of different mechanisms, the most well-characterized of which is based on the molecular recognition of specific targeting signals at the N-terminus of the nascent protein (<xref rid="btz512-B11" ref-type="bibr">Dudek <italic>et al.</italic>, 2013</xref>).</p>
    <p>The mitochondrial outer membrane separates the interior of the organelle from the rest of the cell, while the inner membrane encloses the mitochondrial matrix. In turn, the two membranes are separated by the intermembrane space. The existence of such internal compartmentalization suggests that proteins localized in the different mitochondrial compartments are specialized to fulfill different tasks or functions: hence, knowing the precise location of a protein inside mitochondria is crucial for its accurate functional characterization (<xref rid="btz512-B21" ref-type="bibr">Martelli <italic>et al.</italic>, 2015</xref>).</p>
    <p>In the past years, many computational methods could discriminate mitochondrial from non-mitochondrial proteins, taking advantage of machine-learning algorithms to detect highly specific targeting signals localized at the N-terminal region of the protein sequence (<xref rid="btz512-B7" ref-type="bibr">Bannai <italic>et al.</italic>, 2002</xref>; <xref rid="btz512-B12" ref-type="bibr">Emanuelsson <italic>et al.</italic>, 2007</xref>; <xref rid="btz512-B27" ref-type="bibr">Savojardo <italic>et al.</italic>, 2014</xref>; <xref rid="btz512-B14" ref-type="bibr">Fukasawa <italic>et al.</italic>, 2015</xref>; <xref rid="btz512-B28" ref-type="bibr">Savojardo <italic>et al.</italic>, 2015</xref>).</p>
    <p>A substantial lack of experimental information constrained the discriminative capability of tools to a small number of compartments. Recently, the increasing amount of sequence data and the availability of richer experimental evidence, allowed the development of computational methods suited to predict protein subcellular localization at a finer grain. Currently, tools make it possible to discriminate sub-nuclear (<xref rid="btz512-B16" ref-type="bibr">Kumar <italic>et al.</italic>, 2014</xref>), sub-chloroplastic (<xref rid="btz512-B29" ref-type="bibr">Savojardo <italic>et al.</italic>, 2017</xref>; <xref rid="btz512-B34" ref-type="bibr">Wang <italic>et al.</italic>, 2015</xref>; <xref rid="btz512-B31" ref-type="bibr">Shi <italic>et al.</italic>, 2011</xref>) and sub-mitochondrial (<xref rid="btz512-B9" ref-type="bibr">Du and Li, 2006</xref>; <xref rid="btz512-B31" ref-type="bibr">Shi <italic>et al.</italic>, 2011</xref>; <xref rid="btz512-B10" ref-type="bibr">Du and Yu, 2013</xref>; <xref rid="btz512-B13" ref-type="bibr">Fan and Li, 2012</xref>; <xref rid="btz512-B17" ref-type="bibr">Kumar <italic>et al.</italic>, 2018</xref>; <xref rid="btz512-B20" ref-type="bibr">Lin <italic>et al.</italic>, 2013</xref>; <xref rid="btz512-B22" ref-type="bibr">Mei, 2012</xref>; <xref rid="btz512-B23" ref-type="bibr">Nanni and Lumini, 2008</xref>; <xref rid="btz512-B35" ref-type="bibr">Zeng <italic>et al.</italic>, 2009</xref>) localizations. When considering sub-mitochondrial compartments, only the method of <xref rid="btz512-B17" ref-type="bibr">Kumar <italic>et al.</italic> (2018)</xref> allows discriminating up to four different possible localizations (matrix, outer, inner and intermembrane regions). All the approaches rely on different types of global protein features extracted from sequence, including sequence composition, pseudo-amino acid composition, residue physicochemical attributes and/or evolutionary information extracted from multiple sequence alignments (MSAs).</p>
    <p>Here, we describe DeepMito, a novel method for predicting sub-mitochondrial localization. DeepMito is based on artificial neural networks and it adopts the convolutional neural network (CNN) architecture to extract relevant patterns from primary features. DeepMito discriminates four different sub-mitochondrial compartments and our implementation outperforms the only method previously described (<xref rid="btz512-B17" ref-type="bibr">Kumar <italic>et al.</italic>, 2018</xref>), addressing the same task.</p>
    <p>We optimized the CNN architecture of DeepMito adopting a non-redundant, rigorous cross-validation procedure performed on a new dataset comprising 424 highly curated protein sequences extracted from UniprotKB/SwissProt and endowed with experimental evidence for sub-mitochondrial localization. Cross-validation results on this dataset highlighted good performances with Matthews Correlation values ranging from 0.46 to 0.65, depending on the compartment. These values well compare with the results of <xref rid="btz512-B17" ref-type="bibr">Kumar <italic>et al.</italic> (2018)</xref>, ranging from 0.42 to 0.51, when discriminating the same compartments. In addition, we retrained our CNN architecture on the same dataset previously adopted (<xref rid="btz512-B17" ref-type="bibr">Kumar <italic>et al.</italic>, 2018</xref>), and further confirmed the effectiveness of DeepMito, with performances overpassing the previously reported ones.</p>
    <p>Finally, we analyzed the ability of DeepMito in performing genome-scale analysis. To this aim, we extracted a dataset of 1050 mitochondrial human proteins from the Cell Atlas section of the Human Protein Atlas resource (<xref rid="btz512-B33" ref-type="bibr">Thul <italic>et al.</italic>, 2017</xref>). Computed localizations were assessed towards the fraction of human mitochondrial proteins endowed with experimentally annotated GO terms for one of the sub-mitochondrial compartment. In this test, DeepMito shows a very high level of agreement with available experimental annotations (ranging from 93% to 100%, depending on the discriminated compartment).</p>
  </sec>
  <sec>
    <title>2 Materials and methods</title>
    <sec>
      <title>2.1 Datasets</title>
      <sec>
        <title>2.1.1 The SM424-18 dataset</title>
        <p>The main dataset used in this study was derived from UniprotKB/SwissProt (release 2018_02). We first selected all non-fragment protein sequences with evidence at protein level and endowed with experimentally determined subcellular localization (evidence code ECO: 0000269) in one of the four sub-mitochondrial compartments: outer membrane (SL-0172), intermembrane space (SL-0169), inner membrane (SL-0168) and matrix (SL-0170). For sake of selecting the best possible set of annotations, proteins that are also localized in compartments other than mitochondria were excluded.</p>
        <p>In order to obtain a non-redundant set of protein sequences, we performed clustering using the CD-HIT program (<xref rid="btz512-B19" ref-type="bibr">Li and Godzik, 2006</xref>) with global alignment and sequence identity threshold set to 40%. For each cluster generated by CD-HIT, we retained only the longest sequence.</p>
        <p>After this filtering procedure, we ended-up with 424 mitochondrial proteins sharing at most 40% sequence identity computed at a global level. The dataset comprises 193 proteins from Metazoa, 166 from fungi, 60 from plants, 4 from Euglenozoa and 1 from Amoebozoa. Overall, the dataset comprises 74 outer membrane, 190 inner membrane, 25 intermembrane and 135 matrix proteins (<xref rid="btz512-T1" ref-type="table">Table 1</xref>).
</p>
        <table-wrap id="btz512-T1" orientation="portrait" position="float">
          <label>Table 1.</label>
          <caption>
            <p>Summary statistics of the SM424-18 and the SubMitoPred datasets</p>
          </caption>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col valign="top" align="left" span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th rowspan="1" colspan="1">Compartment</th>
                <th rowspan="1" colspan="1">SM424-18<xref ref-type="table-fn" rid="tblfn1"><sup>a</sup></xref><sup>,b</sup></th>
                <th rowspan="1" colspan="1">SubMitoPred<xref ref-type="table-fn" rid="tblfn2"><sup>b</sup></xref><sup>,c</sup></th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td rowspan="1" colspan="1">Outer membrane</td>
                <td rowspan="1" colspan="1">74</td>
                <td rowspan="1" colspan="1">82</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">Inner membrane</td>
                <td rowspan="1" colspan="1">190</td>
                <td rowspan="1" colspan="1">282</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">Intermembrane space</td>
                <td rowspan="1" colspan="1">25</td>
                <td rowspan="1" colspan="1">32</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">Matrix</td>
                <td rowspan="1" colspan="1">135</td>
                <td rowspan="1" colspan="1">174</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">Total</td>
                <td rowspan="1" colspan="1">424</td>
                <td rowspan="1" colspan="1">570</td>
              </tr>
            </tbody>
          </table>
          <table-wrap-foot>
            <fn id="tblfn1">
              <label>a</label>
              <p>This paper.</p>
            </fn>
            <fn id="tblfn2">
              <label>b</label>
              <p>Number of sequences.</p>
            </fn>
            <fn id="tblfn3">
              <label>c</label>
              <p>From <xref rid="btz512-B17" ref-type="bibr">Kumar <italic>et al.</italic> (2018)</xref>.</p>
            </fn>
          </table-wrap-foot>
        </table-wrap>
        <p>On our dataset (SM424-18) we adopted a 10-fold cross-validation. In order to avoid any possible bias between training and testing, we applied the following clustering procedure to generate cross-validation sets. First, the 424 protein sequences were cross-compared running all-against-all pairwise blastp with e-value threshold set to 0.001. From blast output, we built a similarity graph where nodes are protein sequences and edges among pairs of nodes were added if at least one blast hit with more than 30% sequence identity was found (no coverage threshold was set). On this graph, single-linkage clustering was performed computing connected components. Finally, all proteins falling in the same cluster were assigned to the same cross-validation set. In this way, we eliminated any possible sequence identity bias among training and testing, confining any residual sequence redundancy (even occurring locally) in the same cross-validation set. SM424-18 is available for download at <ext-link ext-link-type="uri" xlink:href="http://busca.biocomp.unibo.it/deepmito/datasets">http://busca.biocomp.unibo.it/deepmito/datasets</ext-link>.</p>
      </sec>
      <sec>
        <title>2.1.2 The SubMitoPred dataset</title>
        <p>SubMitoPred is a dataset previously introduced to train and test the most recent approach for sub-mitochondrial localization prediction, addressing a four-compartment discrimination (<xref rid="btz512-T1" ref-type="table">Table 1</xref>, SubMitoPred, <xref rid="btz512-B17" ref-type="bibr">Kumar <italic>et al.</italic>, 2018</xref>). According to the authors, SubMitoPred (available at <ext-link ext-link-type="uri" xlink:href="http://proteininformatics.org/mkumar/submitopred/download.html">http://proteininformatics.org/mkumar/submitopred/download.html</ext-link>) was derived from UniprotKB/SwissProt release 2014_10, selecting protein sequences with the following criteria:
<list list-type="bullet"><list-item><p>Full-length proteins (no fragments) with experimental existence evidence.</p></list-item><list-item><p>Protein length &gt; 50 residues.</p></list-item><list-item><p>Experimental sub-mitochondrial subcellular localization, retaining only proteins localized into a single compartment.</p></list-item><list-item><p>Dataset internal redundancy reduced at 40% sequence identity using CD-HIT.</p></list-item></list></p>
        <p>Overall, the dataset comprises 570 mitochondrial proteins distributed in the four different sub-compartments (<xref rid="btz512-T1" ref-type="table">Table 1</xref>).</p>
        <p>SubMitoPred contains more proteins than our dataset. Our dataset SM424-18 and the one generated by <xref rid="btz512-B17" ref-type="bibr">Kumar <italic>et al</italic>. (2018)</xref> share 238 common proteins. Of the remaining 332 included in the SubMitoPred dataset but not in SM424-18, 326 are not present in our dataset because they are not annotated with the experimental evidence code ECO: 0000269; six proteins were excluded because they are annotated as localized in multiple compartments.</p>
        <p>For sake of comparison, when necessary and as previously described (<xref rid="btz512-B17" ref-type="bibr">Kumar <italic>et al.</italic>, 2018</xref>), we split the SubMitoPred set into five cross-validation subsets. According to <xref rid="btz512-B17" ref-type="bibr">Kumar <italic>et al.</italic> (2018)</xref>, they performed cross-validation by randomly splitting the set of 570 proteins into five subsets. In this study, we performed two different cross-validation splits: (i) random split as described in <xref rid="btz512-B17" ref-type="bibr">Kumar <italic>et al.</italic> (2018)</xref> and (ii) random split after sequence clustering using blastp (applying the same procedure described in the previous section for our SM424-18).</p>
      </sec>
      <sec>
        <title>2.1.3 The Human Cell Atlas dataset</title>
        <p>To assess the capability of DeepMito in performing genome-scale analysis, we here adopted a dataset extracted from the Cell Atlas section of the Human Protein Atlas project (<xref rid="btz512-B33" ref-type="bibr">Thul <italic>et al.</italic>, 2017</xref>). This resource provides a comprehensive catalog of subcellular localization of proteins in human cells derived from transcriptomics experiments or antibody-based image profiling techniques. By this, it provides experimental evidence for subcellular localization of 12 073 human proteins.</p>
        <p>Here, we focused on the subset of 1074 proteins that are found to be localized into mitochondria (Cell Atlas does not provide for these proteins sub-mitochondrial localization). The Cell Atlas database assigns a label to each annotation, representing its quality. Four different labels are defined (in decreasing order of quality): Enhanced, Supported, Approved and Uncertain. For the 1074 mitochondrial proteins considered in this study, Enhanced and Supported annotations cover about 50% of the dataset (165 + 347 = 512), 506 annotations are Approved while only a small fraction are Uncertain (56 annotations). In order to obtain a sufficient number of sequences, here, we decided to retain all annotations available for mitochondrial proteins.</p>
        <p>ENSEMBL gene identifiers for the 1074 mitochondrial proteins were mapped to UniprotKB entries: after this step we were able to map 1050 ENSEMBL identifiers to UniprotKB entries. Twenty-four ENSEMBL genes were excluded because of non-clear or multiple mapping to UniprotKB.</p>
        <p>On this set, we extracted available Gene Ontology term information using the QuickGO website (<ext-link ext-link-type="uri" xlink:href="https://www.ebi.ac.uk/QuickGO/">https://www.ebi.ac.uk/QuickGO/</ext-link>). We focused only on annotations of the GO Cellular Component, endowed with experimental evidence (ECO: 0000269) and derived from any source databank. As a result, 179 out of 1050 gene products were annotated with GO terms that are equal to or descendants of any of the four mitochondrial compartments considered in this study: 19 proteins in mitochondrial outer membrane (GO: 0005741), 67 in mitochondrial inner membrane (GO: 0005743), 12 in mitochondrial intermembrane space (GO: 0005758) and 81 in mitochondrial matrix (GO: 0005759). Proteins that were annotated with GO terms related to multiple mitochondrial compartments were filtered-out form this set.</p>
        <p>We refer to the full Cell Atlas dataset comprising 1050 protein sequences as Mito-CA-Full and to the subset of 179 annotated as Mito-CA-Annotated.</p>
      </sec>
    </sec>
    <sec>
      <title>2.2 Feature descriptors</title>
      <p>In this study, we considered three different feature types and evaluated their contribution (both individual and combined) to the prediction of protein sub-mitochondrial localization, when provided in input to the DeepMito convolutional network. In particular, the following features were considered:
<list list-type="bullet"><list-item><p>Residue one-hot encoding (SEQ), where each residue in a protein sequence is encoded using a 20-dimensional vector with all zero components except for the one representing the residue. Overall, each protein sequence is represented by a matrix with <inline-formula id="IE1"><mml:math id="IM1"><mml:mi>L</mml:mi></mml:math></inline-formula> rows and <inline-formula id="IE2"><mml:math id="IM2"><mml:mn>20</mml:mn></mml:math></inline-formula> columns, where <italic>L</italic> is the length of the sequence.</p></list-item><list-item><p>Residue physical–chemical properties (PROP), where each residue in a protein sequence is encoded using the 10 different numerical values introduced by <xref rid="btz512-B15" ref-type="bibr">Kidera <italic>et al.</italic> (1985)</xref>. These values derive from a multivariate statistical analysis of a set of 188 different properties of naturally occurring amino acids and can be used to compactly represent the physical–chemical nature of each residue. Overall, each protein is encoded with a matrix with <inline-formula id="IE3"><mml:math id="IM3"><mml:mi>L</mml:mi></mml:math></inline-formula> rows and <inline-formula id="IE4"><mml:math id="IM4"><mml:mn>10</mml:mn></mml:math></inline-formula> columns, where <italic>L</italic> is the length of the sequence.</p></list-item><list-item><p>Evolutionary information, in the form of Position Specific Scoring Matrices (PSSM) as computed, for each sequence in the datasets, by running the PSI-BLAST (<xref rid="btz512-B4" ref-type="bibr">Altschul <italic>et al.</italic>, 1997</xref>) program against the Uniref90 dataset (release March 2018) for three iterations and e-value threshold set to 0.001. Overall, PSSM for a given protein is a matrix with <inline-formula id="IE5"><mml:math id="IM5"><mml:mi>L</mml:mi></mml:math></inline-formula> rows and <inline-formula id="IE6"><mml:math id="IM6"><mml:mn>20</mml:mn></mml:math></inline-formula> columns, where <italic>L</italic> is the length of the sequence. Internally, the program computes the matrix by considering the MSA obtained by (i) stacking all pairwise alignments between query and similar sequences found after each iteration and (ii) removing MSA columns corresponding to gaps in the query sequence. In this way, the PSSMs have always a number of rows that coincides with the length of the query sequence. Raw PSSM values extracted from the PSI-BLAST checkpoint file (generated by the program after each iteration) were mapped in the range [0-1] using a sigmoid function, defined as:
<disp-formula id="E1"><label>(1)</label><mml:math id="M1"><mml:mi>f</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:math></disp-formula></p></list-item></list></p>
      <p>Feature descriptors are combined protein-wise with simple concatenation along the sequence axis. For instance, combining PSSM and PROP matrices of dimensions <inline-formula id="IE7"><mml:math id="IM7"><mml:mi>L</mml:mi><mml:mo>×</mml:mo><mml:mn>20</mml:mn></mml:math></inline-formula> and <inline-formula id="IE8"><mml:math id="IM8"><mml:mi>L</mml:mi><mml:mo>×</mml:mo><mml:mn>10</mml:mn></mml:math></inline-formula> leads to a <inline-formula id="IE9"><mml:math id="IM9"><mml:mi>L</mml:mi><mml:mo>×</mml:mo><mml:mn>30</mml:mn></mml:math></inline-formula> matrix.</p>
    </sec>
    <sec>
      <title>2.3 CNNs</title>
      <p>CNNs have their main application domain in the Computer Vision area (<xref rid="btz512-B18" ref-type="bibr">LeCun <italic>et al.</italic>, 2015</xref>). Nevertheless, they have been proven to be very effective also for sequence analysis tasks in Genomics and Computational Biology, as highlighted by the increasing number of successful applications available in literature (<xref rid="btz512-B2" ref-type="bibr">Alipanahi <italic>et al.</italic>, 2015</xref>; <xref rid="btz512-B3" ref-type="bibr">Almagro Armenteros <italic>et al.</italic>, 2017</xref>; <xref rid="btz512-B5" ref-type="bibr">Angermueller <italic>et al.</italic>, 2016</xref>; <xref rid="btz512-B30" ref-type="bibr">Savojardo <italic>et al.</italic>, 2018</xref>).</p>
      <p>In the context of bio-sequence analysis, inputs are routinely protein or a DNA sequences of variable length on which one wants to detect some feature or attribute, both at the level of individual residues (i.e. sequence labeling) or at a global level (i.e. sequence classification).</p>
      <p>Each residue in a sequence is represented with low-level features, e.g. residue properties, one-hot encoding or sequence profiles. The number of features encoding for a given residues is referred to as channels in the CNN context.</p>
      <p>A typical CNN is a feed-forward architecture comprising two different types of layers: convolutional and pooling layers. Formers are used to extract salient features from the input by means of filters or motif detectors, whose parameters are learnt during training and are used to scan the input. Pooling layers are instead parameter-free, and they are used for downsampling, namely to reduce the input dimensionality by selecting/aggregating the most relevant features extracted by convolutional layers according to some predefined function (e.g. average, max or min functions).</p>
      <p>More formally, let be <inline-formula id="IE10"><mml:math id="IM10"><mml:mi>X</mml:mi><mml:mo>=</mml:mo><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math></inline-formula> an input sequence of length <inline-formula id="IE11"><mml:math id="IM11"><mml:mi>L</mml:mi></mml:math></inline-formula> where each <inline-formula id="IE12"><mml:math id="IM12"><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> is a <inline-formula id="IE13"><mml:math id="IM13"><mml:mi>d</mml:mi></mml:math></inline-formula>-dimensional vector (i.e. <inline-formula id="IE14"><mml:math id="IM14"><mml:mi>d</mml:mi></mml:math></inline-formula> is the number of input channels). We restrict our attention to CNN architectures suited to sequence classification, i.e. the task of classifying the input sequence <inline-formula id="IE15"><mml:math id="IM15"><mml:mi>X</mml:mi></mml:math></inline-formula> into <inline-formula id="IE16"><mml:math id="IM16"><mml:mi>K</mml:mi></mml:math></inline-formula> different classes.</p>
      <p>A convolutional layer is a collection <inline-formula id="IE17"><mml:math id="IM17"><mml:mi mathvariant="script">M</mml:mi><mml:mo>=</mml:mo><mml:mfenced separators="|"><mml:mrow><mml:msup><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>F</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mfenced></mml:math></inline-formula> of <inline-formula id="IE18"><mml:math id="IM18"><mml:mi>F</mml:mi></mml:math></inline-formula> different motif detectors, each of which can be seen as a weight matrix of dimension <inline-formula id="IE19"><mml:math id="IM19"><mml:mi>w</mml:mi><mml:mo>×</mml:mo><mml:mi>d</mml:mi></mml:math></inline-formula>:
<disp-formula id="E2"><label>(2)</label><mml:math id="M2"><mml:msup><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mfenced open="[" close="]" separators="|"><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:msubsup><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup></mml:mtd><mml:mtd><mml:mo>⋯</mml:mo></mml:mtd><mml:mtd><mml:msubsup><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>⋮</mml:mo></mml:mtd><mml:mtd><mml:mo>⋱</mml:mo></mml:mtd><mml:mtd><mml:mo>⋮</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msubsup><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>w</mml:mi><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup></mml:mtd><mml:mtd><mml:mo>⋯</mml:mo></mml:mtd><mml:mtd><mml:msubsup><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>w</mml:mi><mml:mo>,</mml:mo><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>w</mml:mi><mml:mo>×</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:math></disp-formula>where <inline-formula id="IE20"><mml:math id="IM20"><mml:mi>w</mml:mi></mml:math></inline-formula> is the width of the motif and <inline-formula id="IE21"><mml:math id="IM21"><mml:mi>d</mml:mi></mml:math></inline-formula> is the number of input channels.</p>
      <p>Using a sliding-window approach, the <inline-formula id="IE22"><mml:math id="IM22"><mml:mi>i</mml:mi></mml:math></inline-formula>-th motif detector produces an output sequence <inline-formula id="IE23"><mml:math id="IM23"><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="normal"> </mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>L</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math></inline-formula> having the same length <inline-formula id="IE24"><mml:math id="IM24"><mml:mi>L</mml:mi></mml:math></inline-formula> of the input and where each <inline-formula id="IE25"><mml:math id="IM25"><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is computed as:
<disp-formula id="E3"><label>(3)</label><mml:math id="M3"><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>g</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mrow><mml:msubsup><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mrow><mml:msubsup><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:msubsup><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>+</mml:mo><mml:mi>k</mml:mi><mml:mo>-</mml:mo><mml:mfenced open="⌊" close="⌋" separators="|"><mml:mrow><mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:mrow></mml:mfenced><mml:mo>,</mml:mo><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mfenced></mml:math></disp-formula></p>
      <p>Sequence termini are handled by adding explicit zero-padding at the beginning and end of the input sequence <inline-formula id="IE26"><mml:math id="IM26"><mml:mi>X</mml:mi></mml:math></inline-formula>. In <xref ref-type="disp-formula" rid="E3">Equation (3)</xref>, <inline-formula id="IE27"><mml:math id="IM27"><mml:mi>g</mml:mi></mml:math></inline-formula> is an activation function used to transform the raw motif score. Many different activation functions exist; however, routinely Rectified Linear Units (ReLUs) are adopted, defined as:
<disp-formula id="E4"><label>(4)</label><mml:math id="M4"><mml:mi>g</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">max</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p>
      <p>Overall, a convolutional layer endowed with <inline-formula id="IE28"><mml:math id="IM28"><mml:mi>F</mml:mi></mml:math></inline-formula> independent motif detectors compute an output matrix <inline-formula id="IE29"><mml:math id="IM29"><mml:mi>C</mml:mi></mml:math></inline-formula> with <inline-formula id="IE30"><mml:math id="IM30"><mml:mi>F</mml:mi></mml:math></inline-formula> rows and <inline-formula id="IE31"><mml:math id="IM31"><mml:mi>L</mml:mi></mml:math></inline-formula> columns:
<disp-formula id="E5"><label>(5)</label><mml:math id="M5"><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mfenced open="[" close="]" separators="|"><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:mo>⋯</mml:mo></mml:mtd><mml:mtd><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>L</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>⋮</mml:mo></mml:mtd><mml:mtd><mml:mo>⋱</mml:mo></mml:mtd><mml:mtd><mml:mo>⋮</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>F</mml:mi><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:mo>⋯</mml:mo></mml:mtd><mml:mtd><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>F</mml:mi><mml:mo>,</mml:mo><mml:mi>L</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>F</mml:mi><mml:mo>×</mml:mo><mml:mi>L</mml:mi></mml:mrow></mml:msub></mml:math></disp-formula></p>
      <p>Pooling layers following convolutions reduce the dimensionality of the matrix <inline-formula id="IE32"><mml:math id="IM32"><mml:mi>C</mml:mi></mml:math></inline-formula> along the second dimension (i.e. <inline-formula id="IE33"><mml:math id="IM33"><mml:mi>L</mml:mi></mml:math></inline-formula>). Different types of pooling are possible.</p>
      <p>In <italic>local pooling</italic> with pool size <inline-formula id="IE34"><mml:math id="IM34"><mml:mi>p</mml:mi></mml:math></inline-formula>, an aggregating function <inline-formula id="IE35"><mml:math id="IM35"><mml:mi>t</mml:mi></mml:math></inline-formula> is computed row-wise over a set of <inline-formula id="IE36"><mml:math id="IM36"><mml:mi>p</mml:mi></mml:math></inline-formula> non-overlapping neighboring columns of <inline-formula id="IE37"><mml:math id="IM37"><mml:mi>C</mml:mi></mml:math></inline-formula>, transforming it into a new matrix <inline-formula id="IE38"><mml:math id="IM38"><mml:msup><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">local</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> of dimension <inline-formula id="IE39"><mml:math id="IM39"><mml:mi>F</mml:mi><mml:mo>×</mml:mo><mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>:
<disp-formula id="E6"><label>(6)</label><mml:math id="M6"><mml:msup><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">local</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mfenced open="[" close="]" separators="|"><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mi>t</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>p</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mtd><mml:mtd><mml:mo>⋯</mml:mo></mml:mtd><mml:mtd><mml:mi>t</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>L</mml:mi><mml:mo>-</mml:mo><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>L</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>⋮</mml:mo></mml:mtd><mml:mtd><mml:mo>⋱</mml:mo></mml:mtd><mml:mtd><mml:mo>⋮</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>t</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>F</mml:mi><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>F</mml:mi><mml:mo>,</mml:mo><mml:mi>p</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mtd><mml:mtd><mml:mo>⋯</mml:mo></mml:mtd><mml:mtd><mml:mi>t</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>F</mml:mi><mml:mo>,</mml:mo><mml:mi>L</mml:mi><mml:mo>-</mml:mo><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>F</mml:mi><mml:mo>,</mml:mo><mml:mi>L</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>F</mml:mi><mml:mo>×</mml:mo><mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:mrow></mml:mrow></mml:msub></mml:math></disp-formula></p>
      <p>In <italic>global pooling</italic>, the pool size <inline-formula id="IE40"><mml:math id="IM40"><mml:mi>p</mml:mi></mml:math></inline-formula> is equal to <inline-formula id="IE41"><mml:math id="IM41"><mml:mi>L</mml:mi></mml:math></inline-formula> and the input matrix <inline-formula id="IE42"><mml:math id="IM42"><mml:mi>C</mml:mi></mml:math></inline-formula> is completely flattened into a column vector <inline-formula id="IE43"><mml:math id="IM43"><mml:msup><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">global</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> of dimension <inline-formula id="IE44"><mml:math id="IM44"><mml:mi>F</mml:mi><mml:mo>×</mml:mo><mml:mn>1</mml:mn></mml:math></inline-formula>, computing the pooling function <inline-formula id="IE45"><mml:math id="IM45"><mml:mi>t</mml:mi></mml:math></inline-formula> row-wise over the entire set of <inline-formula id="IE46"><mml:math id="IM46"><mml:mi>L</mml:mi></mml:math></inline-formula> columns:
<disp-formula id="E7"><label>(7)</label><mml:math id="M7"><mml:msup><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">global</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mfenced open="[" close="]" separators="|"><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mi>t</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi mathvariant="normal"> </mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>L</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>⋮</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>t</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>F</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="normal"> </mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>F</mml:mi><mml:mo>,</mml:mo><mml:mi>L</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>F</mml:mi><mml:mo>×</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math></disp-formula></p>
      <p>Common pooling functions are average, sum, maximum and minimum.</p>
      <p>Overall, one or more successive applications of convolution-pooling layers transform the input <inline-formula id="IE47"><mml:math id="IM47"><mml:mi>X</mml:mi></mml:math></inline-formula> into a feature map <inline-formula id="IE48"><mml:math id="IM48"><mml:mi>P</mml:mi></mml:math></inline-formula> corresponding to the output of last pooling layer in the architecture. The feature map is then flattened into a single vector <inline-formula id="IE49"><mml:math id="IM49"><mml:mi>v</mml:mi><mml:mi mathvariant="normal"> </mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> (being <inline-formula id="IE50"><mml:math id="IM50"><mml:mi>m</mml:mi></mml:math></inline-formula> the total dimension of the feature map after the last pooling) and provided in input to a standard fully-connected network that first maps <inline-formula id="IE51"><mml:math id="IM51"><mml:mi>v</mml:mi></mml:math></inline-formula> into a hidden layer with <inline-formula id="IE52"><mml:math id="IM52"><mml:mi>H</mml:mi></mml:math></inline-formula> units <inline-formula id="IE53"><mml:math id="IM53"><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>H</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> such that:
<disp-formula id="E8"><label>(8)</label><mml:math id="M8"><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>a</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mrow><mml:msubsup><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:msubsup><mml:mrow><mml:mo>ω</mml:mo></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>h</mml:mi></mml:mrow></mml:msubsup><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>h</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced></mml:math></disp-formula>where <inline-formula id="IE54"><mml:math id="IM54"><mml:msubsup><mml:mrow><mml:mo>ω</mml:mo></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>h</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula> and <inline-formula id="IE55"><mml:math id="IM55"><mml:msubsup><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>h</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula> are the connection weights and bias of the <inline-formula id="IE56"><mml:math id="IM56"><mml:mi>i</mml:mi></mml:math></inline-formula>-th hidden unit, respectively, while the function <inline-formula id="IE57"><mml:math id="IM57"><mml:mi>a</mml:mi></mml:math></inline-formula> is an activation function (e.g. ReLU).</p>
      <p>Finally, the hidden layer is mapped to the output layer comprising <inline-formula id="IE58"><mml:math id="IM58"><mml:mi>K</mml:mi></mml:math></inline-formula> units <inline-formula id="IE59"><mml:math id="IM59"><mml:msub><mml:mrow><mml:mi>o</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>o</mml:mi></mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, one for each class, as follows:
<disp-formula id="E9"><label>(9)</label><mml:math id="M9"><mml:msub><mml:mrow><mml:mi>o</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>u</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mrow><mml:msubsup><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:msubsup><mml:mrow><mml:mo>ω</mml:mo></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msubsup><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced></mml:math></disp-formula>where <inline-formula id="IE60"><mml:math id="IM60"><mml:msubsup><mml:mrow><mml:mo>ω</mml:mo></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula> and <inline-formula id="IE61"><mml:math id="IM61"><mml:msubsup><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula> are the connection weights and bias of the <inline-formula id="IE62"><mml:math id="IM62"><mml:mi>i</mml:mi></mml:math></inline-formula>-th output unit, respectively, and <inline-formula id="IE63"><mml:math id="IM63"><mml:mi>u</mml:mi></mml:math></inline-formula> is the output activation function, typically softmax or sigmoid, depending on the type of output desired.</p>
      <p>In summary, a CNN architecture for sequence classification can be divided into two parts: the first part, where convolution-pooling layers are applied, is devised to feature extraction and selection; the second part, consisting in the final fully connected network, performs the actual classification of the sequence into <inline-formula id="IE64"><mml:math id="IM64"><mml:mi>K</mml:mi></mml:math></inline-formula> different classes.</p>
    </sec>
    <sec>
      <title>2.4 The DeepMito CNN architecture</title>
      <p>Prediction of protein sub-mitochondrial localization can be naturally defined as a multi-class sequence classification problem where each input protein sequence is classified as belonging to one of <inline-formula id="IE65"><mml:math id="IM65"><mml:mi>K</mml:mi><mml:mo>=</mml:mo><mml:mn>4</mml:mn></mml:math></inline-formula> different mitochondrial sub-compartments. In this respect, DeepMito is based on the CNN architecture depicted in <xref ref-type="fig" rid="btz512-F1">Fig. 1</xref>.
</p>
      <fig id="btz512-F1" orientation="portrait" position="float">
        <label>Fig. 1.</label>
        <caption>
          <p>Schematic view of the DeepMito CNN architecture.</p>
        </caption>
        <graphic xlink:href="btz512f1"/>
      </fig>
      <p>The input protein sequence where each residue is encoded as a <inline-formula id="IE66"><mml:math id="IM66"><mml:mi>d</mml:mi></mml:math></inline-formula>-dimensional vector (<inline-formula id="IE67"><mml:math id="IM67"><mml:mi>d</mml:mi></mml:math></inline-formula> varies according to the input feature considered) is scanned using a single convolutional layer comprising <inline-formula id="IE68"><mml:math id="IM68"><mml:mi>F</mml:mi></mml:math></inline-formula> detectors of width <inline-formula id="IE69"><mml:math id="IM69"><mml:mi>w</mml:mi></mml:math></inline-formula> (we tested several different values for these two variables, see next section for details). The convolutional layer output is then processed by two parallel pooling layers computing global average and maximum functions. The rationale behind this choice is to compute both the average motif signal and its peak along the input sequence, trying to capture different types of patterns.</p>
      <p>The two pooling layers are then concatenated into a single vector and provided to the final classification network with <inline-formula id="IE70"><mml:math id="IM70"><mml:mi>H</mml:mi></mml:math></inline-formula> hidden units (also <inline-formula id="IE71"><mml:math id="IM71"><mml:mi>H</mml:mi></mml:math></inline-formula> has been optimized as detailed in the next section). Overall, the network has four independent output units with sigmoid activation function representing scores that quantify the membership of the input protein to each considered compartment: outer membrane, inner membrane, intermembrane space and matrix. The protein is predicted as localized into the highest-scoring compartment.</p>
      <p>The DeepMito CNN was trained using a Stochastic Gradient Descent optimizer by minimizing the cumulative binary cross-entropy loss function. More formally, consider a training set <inline-formula id="IE72"><mml:math id="IM72"><mml:mi mathvariant="script">D</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mfenced open="{" close="}" separators="|"><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:msup><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, where <inline-formula id="IE73"><mml:math id="IM73"><mml:msup><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> is an input protein sequence while <inline-formula id="IE74"><mml:math id="IM74"><mml:msup><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> is a 4-class target vector storing the membership of each protein to one of the compartments.</p>
      <p>The cumulative binary cross-entropy loss function is defined as:
<disp-formula id="E10"><label>(10)</label><mml:math id="M10"><mml:mi mathvariant="script">E</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="script">D</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mrow><mml:munderover><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">E</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi mathvariant="script">D</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>where each <inline-formula id="IE75"><mml:math id="IM75"><mml:msub><mml:mrow><mml:mi mathvariant="script">E</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi mathvariant="script">D</mml:mi><mml:mo>)</mml:mo></mml:math></inline-formula> is the binary cross-entropy loss function for class <inline-formula id="IE76"><mml:math id="IM76"><mml:mi>j</mml:mi></mml:math></inline-formula> and defined as:
<disp-formula id="E11"><label>(11)</label><mml:math id="M11"><mml:msub><mml:mrow><mml:mi mathvariant="script">E</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="script">D</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:munderover><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:msubsup><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup><mml:mrow><mml:mrow><mml:mi mathvariant="normal">log</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>o</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msubsup><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup><mml:mo>)</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">log</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msubsup><mml:mrow><mml:mi>o</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mi mathvariant="normal"> </mml:mi></mml:mrow></mml:mrow></mml:math></disp-formula>where <inline-formula id="IE77"><mml:math id="IM77"><mml:msubsup><mml:mrow><mml:mi>o</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup></mml:math></inline-formula> is the output of the CNN for the <inline-formula id="IE78"><mml:math id="IM78"><mml:mi>j</mml:mi></mml:math></inline-formula>-th class when the sequence <inline-formula id="IE79"><mml:math id="IM79"><mml:msup><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> is provided in input.</p>
    </sec>
    <sec>
      <title>2.5 Model selection and implementation</title>
      <p>A CNN architecture like the one depicted in <xref ref-type="fig" rid="btz512-F1">Fig. 1</xref> has several hyperparameters that need to be optimized. In particular, to define a convolutional layer we need to specify the number <inline-formula id="IE80"><mml:math id="IM80"><mml:mi>F</mml:mi></mml:math></inline-formula> of motif detectors as well as their width <inline-formula id="IE81"><mml:math id="IM81"><mml:mi>w</mml:mi></mml:math></inline-formula>. Analogously, for fully-connected layers, we need to optimize the number <inline-formula id="IE82"><mml:math id="IM82"><mml:mi>H</mml:mi></mml:math></inline-formula> of units in the hidden layers.</p>
      <p>In order to find optimal hyperparameters, we defined a set of possible values for each hyperparameter (see <xref ref-type="supplementary-material" rid="sup1">Supplementary Table S1</xref> for the complete list of tested values) and adopted the following grid-search procedure to search for their optimal combination. In particular, using the SM424-18 dataset, a complete 10-fold cross-validation was running for all possible combination of hyperparameters, using one of the subsets as testing set, eight subsets as training set and one as validation set (different from testing). Each individual training was running for 100 epochs starting with random initialization for all adjustable network weights. Early stopping on validation loss was used to prevent overfitting. We then selected, among all possible combinations of parameters, the one achieving the highest performance on validation data. We used the Generalized Correlation Coefficient (GCC) (<xref rid="btz512-B6" ref-type="bibr">Baldi <italic>et al.</italic>, 2000</xref>) index to compare different architectures (see next section for the formal definition of the GCC). The optimal set of hyperparameters was then frozen and used to score the CNN on testing data.</p>
      <p>DeepMito was implemented in Python 2.7 and using the Keras v. 2.2.4 (<ext-link ext-link-type="uri" xlink:href="https://keras.io">https://keras.io</ext-link>) deep-learning library with Tensorflow v. 1.11 (<ext-link ext-link-type="uri" xlink:href="https://www.tensorflow.org">https://www.tensorflow.org</ext-link>) as backend.</p>
    </sec>
    <sec>
      <title>2.6 Scoring performance</title>
      <p>Performances of our method were scored by computing the multi-class confusion matrix <inline-formula id="IE83"><mml:math id="IM83"><mml:mi>M</mml:mi></mml:math></inline-formula> where <inline-formula id="IE84"><mml:math id="IM84"><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is the number of proteins belonging to class <inline-formula id="IE85"><mml:math id="IM85"><mml:mi>i</mml:mi></mml:math></inline-formula> and predicted in class <inline-formula id="IE86"><mml:math id="IM86"><mml:mi>j</mml:mi></mml:math></inline-formula>.</p>
      <p>Single-class predictions were scored using the Matthews’ Correlation Coefficient (MCC) for each class <inline-formula id="IE87"><mml:math id="IM87"><mml:mi>k</mml:mi></mml:math></inline-formula>, defined as:
<disp-formula id="E12"><label>(12)</label><mml:math id="M12"><mml:mi mathvariant="normal">MCC</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>o</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msqrt><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>o</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>o</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:msqrt></mml:mrow></mml:mfrac></mml:math></disp-formula>where <inline-formula id="IE88"><mml:math id="IM88"><mml:msub><mml:mrow><mml:mi>o</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:munder><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>≠</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> is the number of over-predictions for the class <inline-formula id="IE89"><mml:math id="IM89"><mml:mi>k</mml:mi></mml:math></inline-formula>, <inline-formula id="IE90"><mml:math id="IM90"><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:munder><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>≠</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> is the number of under-predictions for the class <inline-formula id="IE91"><mml:math id="IM91"><mml:mi>k</mml:mi></mml:math></inline-formula> and <inline-formula id="IE92"><mml:math id="IM92"><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:munder><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>≠</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mrow><mml:msub><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>≠</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> is the number of proteins correctly predicted as not being in class <inline-formula id="IE93"><mml:math id="IM93"><mml:mi>k</mml:mi></mml:math></inline-formula> (i.e. correct negative predictions with respect to class <inline-formula id="IE94"><mml:math id="IM94"><mml:mi>k</mml:mi></mml:math></inline-formula>).</p>
      <p>Moreover, we adopted the GCC, described in <xref rid="btz512-B6" ref-type="bibr">Baldi <italic>et al.</italic> (2000)</xref>, and providing a single measure to score classifications involving more than two classes. In particular, for each class <inline-formula id="IE95"><mml:math id="IM95"><mml:mi>k</mml:mi><mml:mo>,</mml:mo></mml:math></inline-formula> we can compute the number <inline-formula id="IE96"><mml:math id="IM96"><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo> </mml:mo></mml:math></inline-formula>of proteins in class <inline-formula id="IE97"><mml:math id="IM97"><mml:mi>k</mml:mi></mml:math></inline-formula> as:
<disp-formula id="E13"><label>(13)</label><mml:math id="M13"><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:munderover><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></disp-formula>and the number <inline-formula id="IE98"><mml:math id="IM98"><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> of proteins predicted in class <inline-formula id="IE99"><mml:math id="IM99"><mml:mi>k</mml:mi></mml:math></inline-formula> as:
<disp-formula id="E14"><label>(14)</label><mml:math id="M14"><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:munderover><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></disp-formula></p>
      <p>Then we define the following matrix <inline-formula id="IE100"><mml:math id="IM100"><mml:mi>e</mml:mi></mml:math></inline-formula> as:
<disp-formula id="E15"><label>(15)</label><mml:math id="M15"><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:mfrac></mml:math></disp-formula>where <inline-formula id="IE101"><mml:math id="IM101"><mml:mi>N</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:msubsup><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mrow><mml:msubsup><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> is the total number of proteins in a dataset.</p>
      <p>The GCC is then defined as:
<disp-formula id="E16"><label>(16)</label><mml:math id="M16"><mml:mi mathvariant="normal">GCC</mml:mi><mml:mo>=</mml:mo><mml:msqrt><mml:mfrac><mml:mrow><mml:mrow><mml:msubsup><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mrow><mml:msubsup><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mo>(</mml:mo><mml:mi>K</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mfrac></mml:msqrt></mml:math></disp-formula></p>
      <p>The GCC value ranges from −1 to 1 and a GCC equal to 0 corresponds to predictions no better than random.</p>
    </sec>
  </sec>
  <sec>
    <title>3 Results</title>
    <sec>
      <title>3.1 Assessing the contribution of the different features</title>
      <p>In order to build an optimal predictor for protein sub-mitochondrial compartment prediction, we first assessed the predictive power of each type of feature. In this study, as already detailed in Section 2.2, three basic type of features were considered: protein primary sequence (encoded using the standard residue one-hot encoding), protein physical–chemical attributes and evolutionary information in the form of PSSMs.</p>
      <p>These three basic feature types were then combined and provided in the input to the DeepMito CNN architecture. In doing this, we considered protein primary sequence and PSSMs as alternative choices, scoring them individually or combined with protein physical–chemical attributes. For each evaluated feature set, a different CNN has been trained in cross-validation on the SM424-18 dataset, optimizing network architecture as explained in Section 2.5. Performance scores are reported in <xref rid="btz512-T2" ref-type="table">Table 2</xref>.
</p>
      <table-wrap id="btz512-T2" orientation="portrait" position="float">
        <label>Table 2.</label>
        <caption>
          <p>Cross-validation performance on the SM424-18 dataset using different feature sets</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1">Feature set</th>
              <th rowspan="1" colspan="1">MCC(O)<xref ref-type="table-fn" rid="tblfn4"><sup>a</sup></xref></th>
              <th rowspan="1" colspan="1">MCC(I)<xref ref-type="table-fn" rid="tblfn4"><sup>a</sup></xref></th>
              <th rowspan="1" colspan="1">MCC(T)<xref ref-type="table-fn" rid="tblfn4"><sup>a</sup></xref></th>
              <th rowspan="1" colspan="1">MCC(M)<xref ref-type="table-fn" rid="tblfn4"><sup>a</sup></xref></th>
              <th rowspan="1" colspan="1">GCC<xref ref-type="table-fn" rid="tblfn5"><sup>b</sup></xref></th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">SEQ<xref ref-type="table-fn" rid="tblfn6"><sup>c</sup></xref></td>
              <td rowspan="1" colspan="1">0.17</td>
              <td rowspan="1" colspan="1">0.15</td>
              <td rowspan="1" colspan="1">0.13</td>
              <td rowspan="1" colspan="1">0.07</td>
              <td rowspan="1" colspan="1">0.15</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">PROP<xref ref-type="table-fn" rid="tblfn7"><sup>d</sup></xref></td>
              <td rowspan="1" colspan="1">0.17</td>
              <td rowspan="1" colspan="1">0.07</td>
              <td rowspan="1" colspan="1">0.22</td>
              <td rowspan="1" colspan="1">0.13</td>
              <td rowspan="1" colspan="1">0.19</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">PSSM<xref ref-type="table-fn" rid="tblfn8"><sup>e</sup></xref></td>
              <td rowspan="1" colspan="1">0.51</td>
              <td rowspan="1" colspan="1">0.47</td>
              <td rowspan="1" colspan="1">0.42</td>
              <td rowspan="1" colspan="1">0.57</td>
              <td rowspan="1" colspan="1">0.50</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">SEQ+PROP</td>
              <td rowspan="1" colspan="1">0.16</td>
              <td rowspan="1" colspan="1">0.07</td>
              <td rowspan="1" colspan="1">0.55</td>
              <td rowspan="1" colspan="1">0.09</td>
              <td rowspan="1" colspan="1">0.34</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">PSSM+PROP</td>
              <td rowspan="1" colspan="1">0.46</td>
              <td rowspan="1" colspan="1">0.47</td>
              <td rowspan="1" colspan="1">0.53</td>
              <td rowspan="1" colspan="1">0.65</td>
              <td rowspan="1" colspan="1">0.54</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn4">
            <label>a</label>
            <p>MCC (O, I, T, M): Matthews Correlation Coefficient of Outer, Inner, Intermembrane and Matrix localization, respectively.</p>
          </fn>
          <fn id="tblfn5">
            <label>b</label>
            <p>GCC: Generalized Correlation Coefficient (<xref ref-type="disp-formula" rid="E16">Equation (16)</xref>).</p>
          </fn>
          <fn id="tblfn6">
            <label>c</label>
            <p>Residue one-hot encoding.</p>
          </fn>
          <fn id="tblfn7">
            <label>d</label>
            <p>Residue physicochemical attributes.</p>
          </fn>
          <fn id="tblfn8">
            <label>e</label>
            <p>PSSM: Position Specific Scoring Matrix.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p>Our results indicate that both primary sequence and protein attributes, when taken alone, are not sufficiently informative and both lead to limited prediction performances, with protein attributes slightly outperforming primary sequence (GCCs are 0.19 and 0.15, respectively).</p>
      <p>As expected, evolutionary information plays a major role in improving prediction performance. In fact, when considered alone, the PSSM input significantly improves prediction performance, leading to a generalized improvement observable in all scoring indices and, in particular in GCC, raising it up to 0.50. When PSSM is combined with protein attributes, performances further improve reaching 0.54 of GCC. We then adopted this feature set for DeepMito and for all subsequence analyses.</p>
      <p>The optimal CNN architecture comprises 256 convolutional motif detectors of width 19 and 256 hidden units in the fully connected hidden layer (see Section 2.4 for details on the DeepMito CNN architecture).</p>
    </sec>
    <sec>
      <title>3.2 Analyzing DeepMito predictions on the SM424-18 dataset</title>
      <p>Having selected the best CNN architecture and features set, we analyzed in detail DeepMito predictions on the SM424-18 dataset. This allowed to highlight strengths and limitations of our method.</p>
      <p>Two aspects were taken into consideration: (i) how prediction performance varies across different taxonomic kingdoms and (ii) how DeepMito performs on different types of membrane proteins, namely single-pass (SP), multi-pass (MP) and peripheral membrane (PM) proteins.</p>
      <p>Concerning the first issue, performance scores obtained on the different subsets of animals, plants and fungi proteins are reported in <xref rid="btz512-T3" ref-type="table">Table 3</xref>. It is worth noting that these results were not obtained by retraining DeepMito on the individual subsets of proteins but simply by isolating cross-validation predictions corresponding to each taxonomic set.
</p>
      <table-wrap id="btz512-T3" orientation="portrait" position="float">
        <label>Table 3.</label>
        <caption>
          <p>DeepMito prediction performance on proteins from different taxonomic kingdoms</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1">Kingdom</th>
              <th rowspan="1" colspan="1">MCC(O)<xref ref-type="table-fn" rid="tblfn9"><sup>a</sup></xref></th>
              <th rowspan="1" colspan="1">MCC(I)<xref ref-type="table-fn" rid="tblfn9"><sup>a</sup></xref></th>
              <th rowspan="1" colspan="1">MCC(T)<xref ref-type="table-fn" rid="tblfn9"><sup>a</sup></xref></th>
              <th rowspan="1" colspan="1">MCC(M)<xref ref-type="table-fn" rid="tblfn9"><sup>a</sup></xref></th>
              <th rowspan="1" colspan="1">GCC<xref ref-type="table-fn" rid="tblfn10"><sup>b</sup></xref></th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">Metazoa (193<xref ref-type="table-fn" rid="tblfn11"><sup>c</sup></xref>)</td>
              <td rowspan="1" colspan="1">0.44</td>
              <td rowspan="1" colspan="1">0.44</td>
              <td rowspan="1" colspan="1">0.52</td>
              <td rowspan="1" colspan="1">0.69</td>
              <td rowspan="1" colspan="1">0.54</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Viridiplantae (60<xref ref-type="table-fn" rid="tblfn11"><sup>c</sup></xref>)</td>
              <td rowspan="1" colspan="1">0.45</td>
              <td rowspan="1" colspan="1">0.52</td>
              <td rowspan="1" colspan="1">0.90</td>
              <td rowspan="1" colspan="1">0.76</td>
              <td rowspan="1" colspan="1">0.71</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Fungi (166<xref ref-type="table-fn" rid="tblfn11"><sup>c</sup></xref>)</td>
              <td rowspan="1" colspan="1">0.49</td>
              <td rowspan="1" colspan="1">0.52</td>
              <td rowspan="1" colspan="1">0.37</td>
              <td rowspan="1" colspan="1">0.59</td>
              <td rowspan="1" colspan="1">0.50</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn9">
            <label>a</label>
            <p>MCC (O, I, T, M): Matthews Correlation Coefficient of Outer, Inner, Intermembrane and Matrix localization, respectively.</p>
          </fn>
          <fn id="tblfn10">
            <label>b</label>
            <p>GCC: Generalized Correlation Coefficient (<xref ref-type="disp-formula" rid="E16">Equation (16)</xref>).</p>
          </fn>
          <fn id="tblfn11">
            <label>c</label>
            <p>Number of sequences.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p>Comparing results in <xref rid="btz512-T3" ref-type="table">Table 3</xref> with overall performance scores (<xref rid="btz512-T2" ref-type="table">Table 2</xref>, last row), we can observe a substantial robustness of the method across the three different kingdoms. In particular, performances are stable on animals (GCC 0.54) and slightly lower on fungi (GCC 0.50). Interestingly, on plant proteins prediction performances are significantly higher, reaching a GCC of 0.71, 17 percentage points higher than the one obtained on the full dataset (0.54).</p>
      <p>In <xref rid="btz512-T4" ref-type="table">Table 4</xref>, results focus on the prediction of the localization of mitochondrial membrane proteins (i.e. experimentally localized into inner and/or outer membranes). In particular, we analyzed prediction results with respect to available experimental information on membrane protein topology, more specifically separating SP proteins (spanning the membrane with a single transmembrane segment), MP proteins (endowed with multiple transmembrane segments) and PM proteins (physically associated to the membrane but not spanning it). Out of 264 membrane proteins included in SM424-18, we were able to retrieve from UniprotKB topological information for 227 proteins.
</p>
      <table-wrap id="btz512-T4" orientation="portrait" position="float">
        <label>Table 4.</label>
        <caption>
          <p>DeepMito prediction performance on mitochondrial membrane proteins with respect to annotated membrane protein topology</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="char" char="(" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1">Topology</th>
              <th rowspan="1" colspan="1"><italic>N</italic><sub>P</sub> (<italic>N</italic><sub>O</sub>+<italic>N</italic><sub>I</sub>)<xref ref-type="table-fn" rid="tblfn12"><sup>a</sup></xref></th>
              <th rowspan="1" colspan="1"><inline-formula id="IE102"><mml:math id="IM102"><mml:msubsup><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mi mathvariant="normal">mem</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula> (%)<xref ref-type="table-fn" rid="tblfn13"><sup>b</sup></xref></th>
              <th rowspan="1" colspan="1">MCC(O)</th>
              <th rowspan="1" colspan="1">MCC(I)</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">SP</td>
              <td rowspan="1" colspan="1">71 (31+40)</td>
              <td rowspan="1" colspan="1">92</td>
              <td rowspan="1" colspan="1">0.43</td>
              <td rowspan="1" colspan="1">0.38</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">MP</td>
              <td rowspan="1" colspan="1">94 (21+73)</td>
              <td rowspan="1" colspan="1">98</td>
              <td rowspan="1" colspan="1">0.47</td>
              <td rowspan="1" colspan="1">0.49</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">PM</td>
              <td rowspan="1" colspan="1">61 (6+55)</td>
              <td rowspan="1" colspan="1">36</td>
              <td rowspan="1" colspan="1">0.36</td>
              <td rowspan="1" colspan="1">0.09</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn12">
            <label>a</label>
            <p><italic>N</italic><sub>P</sub> (<italic>N</italic><sub>O</sub>+<italic>N</italic><sub>I</sub>): number of membrane protein (outer and inner).</p>
          </fn>
          <fn id="tblfn13">
            <label>b</label>
            <p><inline-formula id="IE103"><mml:math id="IM103"><mml:msubsup><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mi mathvariant="normal">mem</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula>: the fraction of proteins correctly predicted in either inner or outer membrane.</p>
          </fn>
          <fn id="tblfn14">
            <p>SP: single-pass membrane protein; MP: multiple-pass membrane protein; PM: peripheral membrane protein.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p>In <xref rid="btz512-T4" ref-type="table">Table 4</xref>, for each topology class, we report the total number of proteins (N<sub>P</sub>), the number of outer and inner membrane proteins (<italic>N</italic><sub>O</sub> and <italic>N</italic><sub>I</sub>, respectively), the fraction of proteins correctly predicted in either inner or outer membrane (<inline-formula id="IE104"><mml:math id="IM104"><mml:msubsup><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mi mathvariant="normal">mem</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula>) and the MCCs for inner and outer membrane classes.</p>
      <p>Results show that the stronger the transmembrane signal is along the sequence the higher is the ability of DeepMito to properly recognize these proteins and discriminate them from non-membrane ones: 98% and 92% of MP and SP proteins, respectively, are correctly predicted as belonging to membrane compartments (either inner or outer membrane). In contrast, only 22 out of 61 (36%), PM proteins are correctly localized into membranes. This suggests that PM proteins are endowed with features that are more similar to proteins of matrix and/or intermembrane space. Thirty-nine PM proteins are incorrectly classified into globular compartments: out of these, 32 are annotated in UniprotKB as residing in the matrix side of the membrane. Interestingly DeepMito correctly assigns 28 out of 32 PM proteins to the matrix compartment.</p>
    </sec>
    <sec>
      <title>3.3 Comparing DeepMito with other approaches</title>
      <p>Performing a comparison among different approaches for sub-mitochondrial localization prediction is a challenging task, mainly because different methods are trained/tested using different datasets and many of the methods presented so far are no more available via respective web servers. For these reasons, we decided to carry out a direct comparison between DeepMito and the most recent approach described for the same four-compartment discriminative task (SubMitoPred, <xref rid="btz512-B17" ref-type="bibr">Kumar <italic>et al.</italic>, 2018</xref>). Furthermore, it is the only method running (at the specified web URL reported in the reference paper) and providing training/testing dataset for downloading.</p>
      <p>For sake of comparison, we trained and tested DeepMito using a 5-fold cross-validation on the SubMitoPred dataset, comprising 570 proteins localized into the four different compartments (<xref rid="btz512-T1" ref-type="table">Table 1</xref>). In particular, two different procedures were applied to perform cross-validation. In a first experiment, we applied exactly the same procedure as described by the SubMitoPred authors, namely, random splitting the set of 570 proteins into five subsets (results labeled as RS in <xref rid="btz512-T5" ref-type="table">Table 5</xref>). In this comparative benchmark, our method significantly outperforms its competitor in all MCC scores. Noticeably, DeepMito performances are more stable across the four different classes, suggesting that our method is able to better cope with class imbalance. Proteins localized in the intermembrane space, despite their low abundance (only 32 out of 570 proteins in the SubMitoPred dataset) are recognized very well by DeepMito, achieving an MCC score of 0.54 against the 0.19 reported by SubMitoPred.
</p>
      <table-wrap id="btz512-T5" orientation="portrait" position="float">
        <label>Table 5.</label>
        <caption>
          <p>Performance comparison of different methods</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1">Method</th>
              <th rowspan="1" colspan="1">Cross-validation</th>
              <th rowspan="1" colspan="1">MCC(O)</th>
              <th rowspan="1" colspan="1">MCC(I)</th>
              <th rowspan="1" colspan="1">MCC(T)</th>
              <th rowspan="1" colspan="1">MCC(M)</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">SubMitoPred<xref ref-type="table-fn" rid="tblfn15"><sup>a</sup></xref></td>
              <td rowspan="1" colspan="1">RS</td>
              <td rowspan="1" colspan="1">0.42</td>
              <td rowspan="1" colspan="1">0.34</td>
              <td rowspan="1" colspan="1">0.19</td>
              <td rowspan="1" colspan="1">0.51</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">DeepMito</td>
              <td rowspan="1" colspan="1">RS</td>
              <td rowspan="1" colspan="1">0.45</td>
              <td rowspan="1" colspan="1">0.68</td>
              <td rowspan="1" colspan="1">0.54</td>
              <td rowspan="1" colspan="1">0.79</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">DeepMito</td>
              <td rowspan="1" colspan="1">CL</td>
              <td rowspan="1" colspan="1">0.42</td>
              <td rowspan="1" colspan="1">0.60</td>
              <td rowspan="1" colspan="1">0.46</td>
              <td rowspan="1" colspan="1">0.76</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn15">
            <label>a</label>
            <p>Results taken from <xref rid="btz512-B17" ref-type="bibr">Kumar <italic>et al.</italic> (2018)</xref>.</p>
          </fn>
          <fn id="tblfn16">
            <p>RS=cross-validation performed by random splitting the dataset. CL=cross-validation performed confining any local similarity into the same cross-validation set (see Sections 2.2.1 and 2.2.2 for details).</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p>To further confirm the ability of DeepMito to capture informative patterns from data, we carried out an additional experiment using a more stringent procedure to perform cross-validation (marked as CL in <xref rid="btz512-T5" ref-type="table">Table 5</xref>). In this experiment, cross-validation split was computed confining pairs of sequence sharing any residual local similarity in the same cross-validation set (as done for our SM424-18 dataset, see Sections 2.2.1 and 2.2.2 for details). As expected, results obtained by DeepMito are slightly worse than those achieved by random splitting (justifying the adoption of the more stringent similarity reduction procedure) but still significantly higher than those achieved by SubMitoPred in all MCC scores.</p>
    </sec>
    <sec>
      <title>3.4 Scoring DeepMito on genomic-scale analysis</title>
      <p>As a final test, we evaluated DeepMito on genomic-scale analysis using the human mitochondrial dataset extracted from the Cell Atlas database (see Section 2.1.3). In particular, DeepMito was trained using the entire SM424-18 dataset and predictions generated for all the 1050 proteins included in the Mito-CA-Full dataset.</p>
      <p>First, we assessed DeepMito predictions with respect to available experimental annotations: for this, we extracted predictions on the Mito-CA-Annotated dataset comprising 179 sequences endowed with experimental GO terms relative to sub-mitochondrial compartments. <xref ref-type="fig" rid="btz512-F2">Figure 2</xref> summarizes distributions of annotations, DeepMito predictions as well as the number of correct predictions for each class. Evidently, DeepMito predictions correlate very well with available experimental evidence: overall, our method achieves a GCC of 0.97 on the Mito-CA-Annotated dataset.
</p>
      <fig id="btz512-F2" orientation="portrait" position="float">
        <label>Fig. 2.</label>
        <caption>
          <p>Distribution of annotations and DeepMito predictions on the Mito-CA-Annotated dataset.</p>
        </caption>
        <graphic xlink:href="btz512f2"/>
      </fig>
      <p>In <xref ref-type="fig" rid="btz512-F3">Fig. 3</xref>, we show the distribution of predicted classes for all the 1050 proteins in the Mito-CA-Full dataset. The relative abundances of predicted compartments are comparable to the ones observed in the Mito-CA-Annotated dataset. Complete results can be examined in detail at <ext-link ext-link-type="uri" xlink:href="http://busca.biocomp.unibo.it/deepmito/hpa">http://busca.biocomp.unibo.it/deepmito/hpa</ext-link>.
</p>
      <fig id="btz512-F3" orientation="portrait" position="float">
        <label>Fig. 3.</label>
        <caption>
          <p>Distribution of DeepMito predictions on the Mito-CA-Full dataset.</p>
        </caption>
        <graphic xlink:href="btz512f3"/>
      </fig>
    </sec>
    <sec>
      <title>3.5 Software availability</title>
      <p>We released DeepMito as web server at <ext-link ext-link-type="uri" xlink:href="http://busca.biocomp.unibo.it/deepmito">http://busca.biocomp.unibo.it/deepmito</ext-link>. The server supports the analysis of up to 200 sequences per submission: for each input protein, the server provides the predicted sub-mitochondrial compartment (as Gene Ontology Cellular Component term) along with a score associated with the prediction. Even though the server is intended to be used with proteins already known to be mitochondrial and for which the user is interested to know the precise localization inside the organelle, there is the possibility that users provide in input proteins that are not mitochondrial. In order to cope with this issue, the server performs a scanning of input proteins using two state-of-the-art predictors of mitochondrial localization: TPpred3 (<xref rid="btz512-B28" ref-type="bibr">Savojardo <italic>et al.</italic>, 2015</xref>), which predict mitochondrial localization by means of recognition of the targeting pre-sequence, and BaCelLo (<xref rid="btz512-B25" ref-type="bibr">Pierleoni <italic>et al.</italic>, 2006</xref>), which provide discrimination of mitochondrial proteins from proteins directed to other compartments. A protein is predicted as mitochondrial if at least one of the above methods classifies it as such. This piece of information is provided as additional output for the user.</p>
      <p>We also provide a standalone version of the program implemented as a Docker container. The image is available on DockerHub at <ext-link ext-link-type="uri" xlink:href="https://hub.docker.com/r/bolognabiocomp/deepmito">https://hub.docker.com/r/bolognabiocomp/deepmito</ext-link>. A tutorial on how to install and use the DeepMito docker container can be found at <ext-link ext-link-type="uri" xlink:href="http://busca.biocomp.unibo.it/deepmito/software">http://busca.biocomp.unibo.it/deepmito/software</ext-link>. DeepMito source code is also available on GitHub at <ext-link ext-link-type="uri" xlink:href="https://github.com/BolognaBiocomp/deepmito">https://github.com/BolognaBiocomp/deepmito</ext-link>.</p>
    </sec>
  </sec>
  <sec>
    <title>4 Conclusions</title>
    <p>DeepMito is a novel method for predicting protein sub-mitochondrial localization. Thanks to the power of a CNN architecture specifically designed to solve this task, DeepMito scores with good performances in different experiments aiming at testing its validity and applicability. In a four-compartment discrimination test, DeepMito scores higher than SubMitoPred, a recent method performing the same task. We tested DeepMito adopting a 10-fold cross-validation procedure on a newly developed training/testing set containing only mitochondrial proteins with location experimentally annotated. Then we also retrained and tested our predictor adopting the same set of proteins and the same cross-validation procedure of SubMitoPred, and again our method overpasses the state-of-the-art.</p>
    <p>SubMitoPred is based on a combination of transfer-by-similarity and support vector machines. In contrast, DeepMito is based on artificial neural networks and it adopts the CNN architecture to extract relevant patterns from primary features. One immediate result is that our approach is robust with respect to class imbalance and provides very accurate predictions even for those compartments that are underrepresented in the training set (such as the intermembrane space, accounting for only few proteins).</p>
    <p>The adoption of more complex architectures like recurrent layers may improve prediction performance in this task. However, in our experiments (data not shown), recurrent approaches lead to poor performance. This fact is maybe due to the scarcity of data which hampers proper training of complex architectures.</p>
    <p>DeepMito well performs also on proteome-scale analysis, carried out on high-quality human proteins from the Cell Atlas database (<xref rid="btz512-B33" ref-type="bibr">Thul <italic>et al.</italic>, 2017</xref>). A present limit of DeepMito, due to the paucity of good quality available data is its present impossibility to predict multiple localization for a single protein sequence.</p>
    <p>We propose DeepMito as a powerful and reliable tool for integration in functional annotation platforms.</p>
  </sec>
  <sec>
    <title>Funding</title>
    <p>PRIN 2017 project 2017483NH8 (to C.S.) (Italian MIUR).</p>
    <p><italic>Conflict of Interest</italic>: none declared.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material content-type="local-data" id="sup1">
      <label>btz512_Supplementary_Material</label>
      <media xlink:href="btz512_supplementary_material.docx">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="btz512-B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Alipanahi</surname><given-names>B.</given-names></name></person-group><etal>et al</etal> (<year>2015</year>) 
<article-title>Predicting the sequence specificities of DNA- and RNA-binding proteins by deep learning</article-title>. <source>Nat. Biotechnol</source>., <volume>33</volume>, <fpage>831</fpage>–<lpage>838</lpage>.<pub-id pub-id-type="pmid">26213851</pub-id></mixed-citation>
    </ref>
    <ref id="btz512-B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Almagro Armenteros</surname><given-names>J.J.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) 
<article-title>DeepLoc: prediction of protein subcellular localization using deep learning</article-title>. <source>Bioinformatics</source>, <volume>33</volume>, <fpage>3387</fpage>–<lpage>3395</lpage>.<pub-id pub-id-type="pmid">29036616</pub-id></mixed-citation>
    </ref>
    <ref id="btz512-B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Altschul</surname><given-names>S.F.</given-names></name></person-group><etal>et al</etal> (<year>1997</year>) 
<article-title>Gapped BLAST and PSI-BLAST: a new generation of protein database search programs</article-title>. <source>Nucleic Acids Res</source>., <volume>25</volume>, <fpage>3389</fpage>–<lpage>3402</lpage>.<pub-id pub-id-type="pmid">9254694</pub-id></mixed-citation>
    </ref>
    <ref id="btz512-B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Angermueller</surname><given-names>C.</given-names></name></person-group><etal>et al</etal> (<year>2016</year>) 
<article-title>Deep learning for computational biology</article-title>. <source>Mol. Syst. Biol</source>., <volume>12</volume>, <fpage>878.</fpage><pub-id pub-id-type="pmid">27474269</pub-id></mixed-citation>
    </ref>
    <ref id="btz512-B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Baldi</surname><given-names>P.</given-names></name></person-group><etal>et al</etal> (<year>2000</year>) 
<article-title>Assessing the accuracy of prediction algorithms for classification: an overview</article-title>. <source>Bioinformatics</source>, <volume>16</volume>, <fpage>412</fpage>–<lpage>424</lpage>.<pub-id pub-id-type="pmid">10871264</pub-id></mixed-citation>
    </ref>
    <ref id="btz512-B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Bannai</surname><given-names>H.</given-names></name></person-group><etal>et al</etal> (<year>2002</year>) 
<article-title>Extensive feature detection of N-terminal protein sorting signals</article-title>. <source>Bioinformatics</source>, <volume>18</volume>, <fpage>298</fpage>–<lpage>305</lpage>.<pub-id pub-id-type="pmid">11847077</pub-id></mixed-citation>
    </ref>
    <ref id="btz512-B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Du</surname><given-names>P.</given-names></name>, <name name-style="western"><surname>Li</surname><given-names>Y.</given-names></name></person-group> (<year>2006</year>) 
<article-title>Prediction of protein submitochondria locations by hybridizing pseudo-amino acid composition with various physicochemical features of segmented sequence</article-title>. <source>BMC Bioinformatics</source>, <volume>7</volume>, <fpage>518</fpage>.<pub-id pub-id-type="pmid">17134515</pub-id></mixed-citation>
    </ref>
    <ref id="btz512-B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Du</surname><given-names>P.</given-names></name>, <name name-style="western"><surname>Yu</surname><given-names>Y.</given-names></name></person-group> (<year>2013</year>) 
<article-title>SubMito-PSPCP: predicting protein submitochondrial locations by hybridizing positional specific physicochemical properties with pseudoamino acid compositions</article-title>. <source>Biomed. Res. Int</source>., <volume>2013</volume>, <fpage>263829.</fpage><pub-id pub-id-type="pmid">24027753</pub-id></mixed-citation>
    </ref>
    <ref id="btz512-B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Dudek</surname><given-names>J.</given-names></name></person-group><etal>et al</etal> (<year>2013</year>) 
<article-title>Mitochondrial protein import: common principles and physiological networks</article-title>. <source>Biochim. Biophys. Acta</source>, <volume>1833</volume>, <fpage>274</fpage>–<lpage>285</lpage>.<pub-id pub-id-type="pmid">22683763</pub-id></mixed-citation>
    </ref>
    <ref id="btz512-B12">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Emanuelsson</surname><given-names>O.</given-names></name></person-group><etal>et al</etal> (<year>2007</year>) 
<article-title>Locating proteins in the cell using TargetP, SignalP and related tools</article-title>. <source>Nat. Protoc</source>., <volume>2</volume>, <fpage>953</fpage>–<lpage>971</lpage>.<pub-id pub-id-type="pmid">17446895</pub-id></mixed-citation>
    </ref>
    <ref id="btz512-B13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Fan</surname><given-names>G.L.</given-names></name>, <name name-style="western"><surname>Li</surname><given-names>Q.Z.</given-names></name></person-group> (<year>2012</year>) 
<article-title>Predicting protein submitochondria locations by combining different descriptors into the general form of Chou's pseudo amino acid composition</article-title>. <source>Amino Acids</source>, <volume>43</volume>, <fpage>545</fpage>–<lpage>555</lpage>.<pub-id pub-id-type="pmid">22102053</pub-id></mixed-citation>
    </ref>
    <ref id="btz512-B14">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Fukasawa</surname><given-names>Y.</given-names></name></person-group><etal>et al</etal> (<year>2015</year>) 
<article-title>MitoFates: improved prediction of mitochondrial targeting sequences and their cleavage sites</article-title>. <source>Mol. Cell Proteomics</source>, <volume>14</volume>, <fpage>1113</fpage>–<lpage>1126</lpage>.<pub-id pub-id-type="pmid">25670805</pub-id></mixed-citation>
    </ref>
    <ref id="btz512-B15">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Kidera</surname><given-names>A.</given-names></name></person-group><etal>et al</etal> (<year>1985</year>) 
<article-title>Statistical analysis of the physical properties of the 20 naturally occurring amino acids</article-title>. <source>J. Prot. Chem</source>., <volume>4</volume>, <fpage>23</fpage>–<lpage>55</lpage>.</mixed-citation>
    </ref>
    <ref id="btz512-B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Kumar</surname><given-names>R.</given-names></name></person-group><etal>et al</etal> (<year>2014</year>) 
<article-title>Protein sub-nuclear localization prediction using SVM and PFAM domain information</article-title>. <source>PLoS One</source>, <volume>9</volume>, <fpage>e98345.</fpage><pub-id pub-id-type="pmid">24897370</pub-id></mixed-citation>
    </ref>
    <ref id="btz512-B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Kumar</surname><given-names>R.</given-names></name></person-group><etal>et al</etal> (<year>2018</year>) 
<article-title>Proteome-wide prediction and annotation of mitochondrial and sub-mitochondrial proteins by incorporating domain information</article-title>. <source>Mitochondrion</source>, <volume>42</volume>, <fpage>11</fpage>–<lpage>22</lpage>.<pub-id pub-id-type="pmid">29032233</pub-id></mixed-citation>
    </ref>
    <ref id="btz512-B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>LeCun</surname><given-names>Y.</given-names></name></person-group><etal>et al</etal> (<year>2015</year>) 
<article-title>Deep learning</article-title>. <source>Nature</source>, <volume>521</volume>, <fpage>436</fpage>–<lpage>444</lpage>.<pub-id pub-id-type="pmid">26017442</pub-id></mixed-citation>
    </ref>
    <ref id="btz512-B19">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Li</surname><given-names>W.</given-names></name>, <name name-style="western"><surname>Godzik</surname><given-names>A.</given-names></name></person-group> (<year>2006</year>) 
<article-title>Cd-hit: a fast program for clustering and comparing large sets of protein or nucleotide sequences</article-title>. <source>Bioinformatics</source>, <volume>22</volume>, <fpage>1658</fpage>–<lpage>1659</lpage>.<pub-id pub-id-type="pmid">16731699</pub-id></mixed-citation>
    </ref>
    <ref id="btz512-B20">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Lin</surname><given-names>H.</given-names></name></person-group><etal>et al</etal> (<year>2013</year>) 
<article-title>Using over-represented tetrapeptides to predict protein submitochondria locations</article-title>. <source>Acta Biotheor</source>., <volume>61</volume>, <fpage>259</fpage>–<lpage>268</lpage>.<pub-id pub-id-type="pmid">23475502</pub-id></mixed-citation>
    </ref>
    <ref id="btz512-B21">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Martelli</surname><given-names>P.L.</given-names></name></person-group><etal>et al</etal> (<year>2015</year>) 
<article-title>Computer-based prediction of mitochondria-targeting peptides</article-title>. <source>Methods Mol. Biol</source>., <volume>1264</volume>, <fpage>305</fpage>–<lpage>320</lpage>.<pub-id pub-id-type="pmid">25631024</pub-id></mixed-citation>
    </ref>
    <ref id="btz512-B22">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Mei</surname><given-names>S.</given-names></name></person-group> (<year>2012</year>) 
<article-title>Multi-kernel transfer learning based on Chou's PseAAC formulation for protein submitochondria localization</article-title>. <source>J. Theor. Biol</source>., <volume>293</volume>, <fpage>121</fpage>–<lpage>130</lpage>.<pub-id pub-id-type="pmid">22037046</pub-id></mixed-citation>
    </ref>
    <ref id="btz512-B23">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Nanni</surname><given-names>L.</given-names></name>, <name name-style="western"><surname>Lumini</surname><given-names>A.</given-names></name></person-group> (<year>2008</year>) 
<article-title>Genetic programming for creating Chou's pseudo amino acid based features for submitochondria localization</article-title>. <source>Amino Acids</source>, <volume>34</volume>, <fpage>653</fpage>–<lpage>660</lpage>.<pub-id pub-id-type="pmid">18175047</pub-id></mixed-citation>
    </ref>
    <ref id="btz512-B24">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Petsalaki</surname><given-names>E.I.</given-names></name></person-group><etal>et al</etal> (<year>2006</year>) 
<article-title>PredSL: a tool for the N-terminal sequence-based prediction of protein subcellular localization</article-title>. <source>Genomics Proteomics Bioinformatics</source>, <volume>4</volume>, <fpage>48</fpage>–<lpage>55</lpage>.<pub-id pub-id-type="pmid">16689702</pub-id></mixed-citation>
    </ref>
    <ref id="btz512-B25">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Pierleoni</surname><given-names>A.</given-names></name></person-group><etal>et al</etal> (<year>2006</year>) 
<article-title>BaCelLo: a balanced subcellular localization predictor</article-title>. <source>Bioinformatics</source>, <volume>22</volume>, <fpage>e408</fpage>–<lpage>e416</lpage>.<pub-id pub-id-type="pmid">16873501</pub-id></mixed-citation>
    </ref>
    <ref id="btz512-B26">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Poveda-Huertes</surname><given-names>D.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) 
<article-title>The versatility of the mitochondrial presequence processing machinery: cleavage, quality control and turnover</article-title>. <source>Cell Tissue Res</source>., <volume>367</volume>, <fpage>73</fpage>–<lpage>81</lpage>.<pub-id pub-id-type="pmid">27595151</pub-id></mixed-citation>
    </ref>
    <ref id="btz512-B27">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Savojardo</surname><given-names>C.</given-names></name></person-group><etal>et al</etal> (<year>2014</year>) 
<article-title>TPpred2: improving the prediction of mitochondrial targeting peptide cleavage sites by exploiting sequence motifs</article-title>. <source>Bioinformatics</source>, <volume>30</volume>, <fpage>2973</fpage>–<lpage>2974</lpage>.<pub-id pub-id-type="pmid">24974200</pub-id></mixed-citation>
    </ref>
    <ref id="btz512-B28">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Savojardo</surname><given-names>C.</given-names></name></person-group><etal>et al</etal> (<year>2015</year>) 
<article-title>TPpred3 detects and discriminates mitochondrial and chloroplastic targeting peptides in eukaryotic proteins</article-title>. <source>Bioinformatics</source>, <volume>31</volume>, <fpage>3269</fpage>–<lpage>3275</lpage>.<pub-id pub-id-type="pmid">26079349</pub-id></mixed-citation>
    </ref>
    <ref id="btz512-B29">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Savojardo</surname><given-names>C.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) 
<article-title>SChloro: directing Viridiplantae proteins to six chloroplastic sub-compartments</article-title>. <source>Bioinformatics</source>, <volume>33</volume>, <fpage>347</fpage>–<lpage>353</lpage>.<pub-id pub-id-type="pmid">28172591</pub-id></mixed-citation>
    </ref>
    <ref id="btz512-B30">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Savojardo</surname><given-names>C.</given-names></name></person-group><etal>et al</etal> (<year>2018</year>) 
<article-title>DeepSig: deep learning improves signal peptide detection in proteins</article-title>. <source>Bioinformatics</source>, <volume>34</volume>, <fpage>1690</fpage>–<lpage>1696</lpage>.<pub-id pub-id-type="pmid">29280997</pub-id></mixed-citation>
    </ref>
    <ref id="btz512-B31">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Shi</surname><given-names>S.P.</given-names></name></person-group><etal>et al</etal> (<year>2011</year>) 
<article-title>Identify submitochondria and subchloroplast locations with pseudo amino acid composition: approach from the strategy of discrete wavelet transform feature extraction</article-title>. <source>Biochim. Biophys. Acta</source>, <volume>1813</volume>, <fpage>424</fpage>–<lpage>430</lpage>.<pub-id pub-id-type="pmid">21255619</pub-id></mixed-citation>
    </ref>
    <ref id="btz512-B32">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Small</surname><given-names>I.</given-names></name></person-group><etal>et al</etal> (<year>2004</year>) 
<article-title>Predotar: a tool for rapidly screening proteomes for N-terminal targeting sequences</article-title>. <source>Proteomics</source>, <volume>4</volume>, <fpage>1581</fpage>–<lpage>1590</lpage>.<pub-id pub-id-type="pmid">15174128</pub-id></mixed-citation>
    </ref>
    <ref id="btz512-B33">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Thul</surname><given-names>P.J.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) 
<article-title>A subcellular map of the human proteome</article-title>. <source>Science</source>, <volume>356</volume>, <fpage>eaal3321.</fpage><pub-id pub-id-type="pmid">28495876</pub-id></mixed-citation>
    </ref>
    <ref id="btz512-B34">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Wang</surname><given-names>X.</given-names></name></person-group><etal>et al</etal> (<year>2015</year>) 
<article-title>MultiP-SChlo: multi-label protein subchloroplast localization prediction with Chou’s pseudo amino acid composition and a novel multi-label classifier</article-title>. <source>Bioinformatics</source>, <volume>31</volume>, <fpage>2639</fpage>–<lpage>2645</lpage>.<pub-id pub-id-type="pmid">25900916</pub-id></mixed-citation>
    </ref>
    <ref id="btz512-B35">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Zeng</surname><given-names>Y.H.</given-names></name></person-group><etal>et al</etal> (<year>2009</year>) 
<article-title>Using the augmented Chou's pseudo amino acid composition for predicting protein submitochondria locations based on auto covariance approach</article-title>. <source>J. Theor. Biol</source>., <volume>259</volume>, <fpage>366</fpage>–<lpage>372</lpage>.<pub-id pub-id-type="pmid">19341746</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
