<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1 20151215//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.1?>
<?ConverterInfo.XSLTName jp2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Gigascience</journal-id>
    <journal-id journal-id-type="iso-abbrev">Gigascience</journal-id>
    <journal-id journal-id-type="publisher-id">gigascience</journal-id>
    <journal-title-group>
      <journal-title>GigaScience</journal-title>
    </journal-title-group>
    <issn pub-type="epub">2047-217X</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">5569921</article-id>
    <article-id pub-id-type="doi">10.1093/gigascience/gix042</article-id>
    <article-id pub-id-type="publisher-id">gix042</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Research</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Kronos: a workflow assembler for genome analytics and informatics</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Taghiyar</surname>
          <given-names>M. Jafar</given-names>
        </name>
        <xref ref-type="aff" rid="aff1">1</xref>
        <xref ref-type="aff" rid="aff2">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Rosner</surname>
          <given-names>Jamie</given-names>
        </name>
        <xref ref-type="aff" rid="aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Grewal</surname>
          <given-names>Diljot</given-names>
        </name>
        <xref ref-type="aff" rid="aff1">1</xref>
        <xref ref-type="aff" rid="aff2">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Grande</surname>
          <given-names>Bruno M.</given-names>
        </name>
        <xref ref-type="aff" rid="aff3">3</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Aniba</surname>
          <given-names>Radhouane</given-names>
        </name>
        <xref ref-type="aff" rid="aff1">1</xref>
        <xref ref-type="aff" rid="aff2">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Grewal</surname>
          <given-names>Jasleen</given-names>
        </name>
        <xref ref-type="aff" rid="aff3">3</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Boutros</surname>
          <given-names>Paul C.</given-names>
        </name>
        <xref ref-type="aff" rid="aff4">4</xref>
        <xref ref-type="aff" rid="aff5">5</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Morin</surname>
          <given-names>Ryan D.</given-names>
        </name>
        <xref ref-type="aff" rid="aff3">3</xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Bashashati</surname>
          <given-names>Ali</given-names>
        </name>
        <!--<email>abashash@bccrc.ca</email>-->
        <xref ref-type="aff" rid="aff1">1</xref>
        <xref ref-type="aff" rid="aff2">2</xref>
        <xref ref-type="corresp" rid="cor1"/>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Shah</surname>
          <given-names>Sohrab P.</given-names>
        </name>
        <!--<email>sshah@bccrc.ca</email>-->
        <xref ref-type="aff" rid="aff1">1</xref>
        <xref ref-type="aff" rid="aff2">2</xref>
        <xref ref-type="corresp" rid="cor1"/>
      </contrib>
    </contrib-group>
    <aff id="aff1"><label>1</label>Department of Molecular Oncology, British Columbia Cancer Agency, 675 West 10th Ave, V5Z 1L3 Vancouver, BC, Canada</aff>
    <aff id="aff2"><label>2</label>Department of Pathology and Laboratory Medicine, University of British Columbia, 2211 Wesbrook Mall, V6T 2B5 Vancouver, BC, Canada</aff>
    <aff id="aff3"><label>3</label>Department of Molecular Biology and Biochemistry, Simon Fraser University, 8888 University Drive, V5A 1S6 Burnaby, BC, Canada</aff>
    <aff id="aff4"><label>4</label>Ontario Institute for Cancer Research (OICR), 661 University Avenue, M5G 0A3 Toronto, ON, Canada</aff>
    <aff id="aff5"><label>5</label>Department of Medical Biophysics, University of Toronto, 101 College Street, M5G 1L7 Toronto, ON, Canada</aff>
    <author-notes>
      <corresp id="cor1"><label>*</label><bold>Correspondence address.</bold> Ali Bashashati, Department of Molecular Oncology, British Columbia Cancer Agency, 675 West 10th Ave, V5Z 1L3 Vancouver, BC, Canada; E-mail: <email>abashash@bccrc.ca</email>; Sohrab P. Shah, Department of Molecular Oncology, British Columbia Cancer Agency, 675 West 10th Ave, V5Z 1L3 Vancouver, BC, Canada; E-mail: <email>sshah@bccrc.ca</email></corresp>
    </author-notes>
    <pub-date pub-type="epub" iso-8601-date="2017-06-26">
      <day>26</day>
      <month>6</month>
      <year>2017</year>
    </pub-date>
    <pub-date pub-type="collection">
      <month>7</month>
      <year>2017</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>26</day>
      <month>6</month>
      <year>2017</year>
    </pub-date>
    <!-- PMC Release delay is 0 months and 0 days and was based on the <pub-date pub-type="epub"/>. -->
    <volume>6</volume>
    <issue>7</issue>
    <fpage>1</fpage>
    <lpage>10</lpage>
    <history>
      <date date-type="accepted">
        <day>07</day>
        <month>6</month>
        <year>2017</year>
      </date>
      <date date-type="received">
        <day>07</day>
        <month>3</month>
        <year>2017</year>
      </date>
      <date date-type="rev-recd">
        <day>06</day>
        <month>6</month>
        <year>2017</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Authors 2017. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2017</copyright-year>
      <license license-type="cc-by" xlink:href="http://creativecommons.org/licenses/by/4.0/">
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<uri xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</uri>), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="gix042.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="gix042s1">
        <title>Background:</title>
        <p>The field of next-generation sequencing informatics has matured to a point where algorithmic advances in sequence alignment and individual feature detection methods have stabilized. Practical and robust implementation of complex analytical workflows (where such tools are structured into “best practices” for automated analysis of next-generation sequencing datasets) still requires significant programming investment and expertise.</p>
      </sec>
      <sec id="gix042s2">
        <title>Results:</title>
        <p>We present Kronos, a software platform for facilitating the development and execution of modular, auditable, and distributable bioinformatics workflows. Kronos obviates the need for explicit coding of workflows by compiling a text configuration file into executable Python applications. Making analysis modules would still require programming. The framework of each workflow includes a run manager to execute the encoded workflows locally (or on a cluster or cloud), parallelize tasks, and log all runtime events. The resulting workflows are highly modular and configurable by construction, facilitating flexible and extensible meta-applications that can be modified easily through configuration file editing. The workflows are fully encoded for ease of distribution and can be instantiated on external systems, a step toward reproducible research and comparative analyses. We introduce a framework for building Kronos components that function as shareable, modular nodes in Kronos workflows.</p>
      </sec>
      <sec id="gix042s3">
        <title>Conclusions:</title>
        <p>The Kronos platform provides a standard framework for developers to implement custom tools, reuse existing tools, and contribute to the community at large. Kronos is shipped with both Docker and Amazon Web Services Machine Images. It is free, open source, and available through the Python Package Index and at <ext-link ext-link-type="uri" xlink:href="https://github.com/jtaghiyar/kronos">https://github.com/jtaghiyar/kronos</ext-link>.</p>
      </sec>
    </abstract>
    <kwd-group kwd-group-type="keywords">
      <kwd>genomics</kwd>
      <kwd>workflow</kwd>
      <kwd>pipeline</kwd>
      <kwd>reproducibility</kwd>
    </kwd-group>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <named-content content-type="funder-name">Genome Canada</named-content>
          <named-content content-type="funder-identifier">10.13039/100008762</named-content>
        </funding-source>
        <funding-source>
          <named-content content-type="funder-name">Genome British Columbia</named-content>
          <named-content content-type="funder-identifier">10.13039/501100000233</named-content>
        </funding-source>
        <award-id>173CIC</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <named-content content-type="funder-name">Science and Engineering Research Council</named-content>
          <named-content content-type="funder-identifier">10.13039/501100005049</named-content>
        </funding-source>
        <award-id>RGPGR 488167-2013</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <named-content content-type="funder-name">Terry Fox Research Institute</named-content>
          <named-content content-type="funder-identifier">10.13039/501100004376</named-content>
        </funding-source>
        <award-id>1021</award-id>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="10"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec id="sec1">
    <title>Background</title>
    <p>The emergence of next-generation sequencing (NGS) technology has created unprecedented opportunities to identify and study the impact of genomic aberrations on genome-wide scales. Data generation technology for NGS is stabilizing, and exponential declines in cost have made sequencing accessible to most research and clinical groups. Alongside progress in data generation capacity, a myriad of analytical approaches and software tools have been developed to identify and interpret relevant biological features. These include computational methods for raw data preprocessing, sequence alignment and assembly, variant identification, and variant annotation. However, major challenges are induced by rapid development and improvement of analytical methods. This makes construction of analytical workflows a near dynamic process, creating a roadblock to seamless implementation of linked processes that navigate from raw input to annotated variants.</p>
    <p>As a consequence, robust analysis and continuous iterative improvements in the analysis of large sets of sequencing data remain labor intensive and costly and require considerable analytical expertise. As best practices (e.g., [<xref rid="bib1" ref-type="bibr">1</xref>]) remain a moving target, software systems that can rapidly adapt to new (and optimal) solutions for domain-specific problems are necessary to facilitate high-throughput comparisons.</p>
    <p>Several tools and frameworks for NGS data analysis and workflow management have been developed to address these needs. Galaxy [<xref rid="bib2" ref-type="bibr">2</xref>] is an open, web-based platform to perform, reproduce, and share analyses. Using the Galaxy user interface, users can build analysis workflows from a collection of tools available through the Galaxy Tool Shed [<xref rid="bib3" ref-type="bibr">3</xref>]. The Taverna suite [<xref rid="bib4" ref-type="bibr">4</xref>] allows the execution of workflows that typically mix web services and local tools. Tight integration with myExperiment [<xref rid="bib5" ref-type="bibr">5</xref>] gives Taverna access to a network of shared workflows, including NGS data processing.</p>
    <p>Although the current workflow management systems such as Galaxy are great for routine bioinformatics tasks, the development of customized tools and workflows is not convenient, and experienced bioinformaticians commonly work at a lower programming level and write their own workflows in scripting languages such as Bash, Perl, or Python [<xref rid="bib6" ref-type="bibr">6</xref>]. A number of lightweight workflow management tools have been specifically developed to simplify scripting for these target users, including Ruffus [<xref rid="bib7" ref-type="bibr">7</xref>], Bpipe [<xref rid="bib8" ref-type="bibr">8</xref>], and Snakemake [<xref rid="bib9" ref-type="bibr">9</xref>]. Common Workflow Language [<xref rid="bib10" ref-type="bibr">10</xref>] is another similar tool that has roots in GNU make and aims to build portable workflows across a variety of platforms by using a set of standard specification to define wrappers around command line tools as well as creating nested workflows. While these workflow management tools reduce development overhead, users still need to write a substantial amount of routine code to create their own workflows, maintain the existing ones, replace subsets of workflows with new ones, and run subsets of existing workflows.</p>
    <p>To further facilitate the process of creating workflows, Omics-Pipe proposed a framework to automate best practice multi-omics data analysis workflows based on Ruffus [<xref rid="bib11" ref-type="bibr">11</xref>]. It offers several preexisting workflows and reduces the development overhead for tracking the run of each workflow and logging the progress of each analysis step. However, it remains cumbersome to create a custom workflow with Omics-Pipe as users need to manually write a Python script for the new workflow by copy/pasting a specific header to the script and writing the analysis functions using Ruffus decorators. The same applies when adding or removing an analysis step to an existing workflow.</p>
    <p>We introduce a highly flexible open source Python-based software tool (Kronos) that enables bioinformatics developers, i.e., bioinformaticians who develop workflows for analyzing genomic data, to quickly create a workflow. It uses Ruffus [<xref rid="bib7" ref-type="bibr">7</xref>] as the underlying workflow management system and adds a level of abstraction on top of it, which significantly reduces programming overhead for workflow development and provides a mechanism to represent a workflow by a top-level YAML configuration file.</p>
    <p>Kronos is shipped with Docker and Amazon Machine Images to further facilitate its use locally on high performance computing clusters and in the cloud infrastructures. A number of workflows for the analysis of single human genomes and cancer tumour-normal pairs following best analysis practices accompany Kronos and are freely available. </p>
  </sec>
  <sec sec-type="results" id="sec2">
    <title>Results</title>
    <p>Kronos creates modular workflows that can be easily updated by editing their corresponding configuration file. Each module in the workflow corresponds to a component, which is a wrapped command line tool (i.e., described in more detail later). As shown in Fig. <xref ref-type="fig" rid="fig1">1</xref>, users can create a workflow from a set of existing components by following the 3 steps listed below (referred to as Steps 1, 2, and 3 in the remainder of this paper). Section 2 of Additional file 1 provides an example of how to make a variant calling workflow.
<list list-type="bullet"><list-item><p>Step 1. Given a set of existing components, create a configuration file template by running the following Kronos command:
<boxed-text id="box1" position="float" orientation="portrait"><sec><title/><p> kronos make_config</p><p> [list of components] -o &lt;output_name&gt;</p></sec></boxed-text>
where [list of components] refers to the component names that we aim at using in our workflow.</p></list-item><list-item><p>Step 2. In the configuration file template, specify the order by which the components in the workflow should be run. This does not require programming skills and is merely text-based.</p></list-item><list-item><p>Step 3. Create the workflow by running the following Kronos command with the configuration file as its input:
<boxed-text id="box2" position="float" orientation="portrait"><sec><title/><p> kronos init -y &lt;config_file.yaml&gt;</p><p> -o &lt;workflow_name&gt;</p></sec></boxed-text></p></list-item></list></p>
    <p>The output is an executable Python script that runs the workflow. Depending on its corresponding configuration file, the script is encoded to automatically parallelize eligible tasks, provide pause/resume functionality, make unique run IDs, make the desired output directory tree, submit jobs to cluster or run them locally, and log the events.</p>
    <sec id="sec2-1">
      <title>Kronos components</title>
      <p>A component is a wrapper around a command line tool that encapsulates all the required programming. The purpose of components is to modularize workflows with reusable building blocks that require minimal development. As shown in Section 1 of Additional file 1, the number of lines of codes for making a new component is very small. The simple development instructions eliminate, e.g., the need to use Ruffus decorators, input/output management using regex expressions, and complicated dependency management in the code that can easily become very complex with the number of tasks in a workflow. Furthermore, a large workflow can be divided into a set of small components that results in a much faster and more manageable workflow development. Kronos also provides a command for making component templates that helps develop a new component in a few minutes.</p>
      <p>All command line tools, such as a simple copy command or a complicated single nucleotide variant (SNV) caller, can be wrapped as Kronos components. Regardless of how complicated they are, their corresponding components have a standard directory structure composed of specific wrappers and subdirectories. The wrappers are also independent of the programming language used for developing the command line tool.</p>
      <p>The components should be developed prior to making the workflow. However, since they are individually and independently developed and due to their reusability, the initial preparation of a component happens only once, and various workflows can use the already developed component.</p>
      <fig id="fig1" orientation="portrait" position="float">
        <label>Figure 1:</label>
        <caption>
          <p>Make a workflow. Making a new workflow with Kronos includes 3 steps: (A) make a configuration file template: given a set of existing components, users can generate this file by running the command <monospace>make_config</monospace>; (B) configure the workflow: users can specify the desirable flow of their workflow using the connections and dependencies, customize output directory names, and specify input arguments and data to the required fields in the configuration file template; (C) initialize the workflow: this is achieved by running the command <monospace>init</monospace> on the configuration file, which transforms the YAML file into the Python workflow script.</p>
        </caption>
        <graphic xlink:href="gix042fig1"/>
      </fig>
      <fig id="fig2" orientation="portrait" position="float">
        <label>Figure 2:</label>
        <caption>
          <p>Make a component. Making a new component for Kronos includes the following steps: (A1) make a new component template by running the command <monospace>make_component</monospace>; (B2) fill in the resulting template accordingly; (C3) copy or link the source code of the <italic>seed</italic> used in the component; (D4) optionally create <monospace>README.md</monospace> and tests for the component.</p>
        </caption>
        <graphic xlink:href="gix042fig2"/>
      </fig>
    </sec>
    <sec id="sec2-2">
      <title>Kronos configuration file</title>
      <p>Kronos workflows are represented by a YAML configuration file. For a given set of components, the Kronos <monospace>make_config</monospace> command generates a configuration file template that is mostly prefilled with default values. For each input component, there is a corresponding section with a unique name in the configuration file called task. Users should use these sections to specify the order by which each task in the workflow should be run (Step 2 of creating a workflow). This can be done by a simple convention called IO-connection. An IO-connection is basically a pair of values comprising a task name and 1 of its parameters. It determines which task should be followed by the current task and is specified as an argument to 1 of the parameters of the current task. For example, in the following configuration file, <monospace>(’__TASK_1__’, ’out_file’)</monospace> is an IO-connection that makes <monospace>__TASK_2__</monospace> follow <monospace>__TASK_1__</monospace>, i.e., the input to the parameter <monospace>in_file</monospace> of <monospace>__TASK_2__</monospace> comes from the parameter <monospace>out_file</monospace> of <monospace>__TASK_1__</monospace>.</p>
      <boxed-text id="box3" position="float" orientation="portrait">
        <sec>
          <title/>
          <p>__TASK_1__:</p>
          <p> out_file: ’foo.txt’</p>
          <p>__TASK_2__:</p>
          <p> in_file: (’__TASK_1__’, ’out_file’)</p>
        </sec>
      </boxed-text>
      <p>The run options for each task are also set in the configuration file, including granular resource requests such as free memory or the number of CPUs, running locally or on cluster, running with parallelization, pause/resume functionality, etc.</p>
      <p>A configuration file has the following blocks (see Additional file 1: Fig. S1):
<list list-type="bullet"><list-item><p>system-specific, which captures the system-dependant requirements of the workflow (such as the paths to the local installations) and includes the <monospace>GENERAL</monospace> and <monospace>PIPELINE_INFO</monospace> sections;</p></list-item><list-item><p>user-specific, which contains the input files and arguments and includes the <monospace>SHARED</monospace> and <monospace>SAMPLES</monospace> sections</p></list-item><list-item><p>workflow-specific, which defines the connection between the components in the workflow. Task sections related to each component are in this group.</p></list-item></list></p>
      <p>This design has the following advantages: (i) if users want to rerun the same workflow for various sets of input files and arguments, they would only need to update the user-specific sections. This prevents inadvertent changes in the flow of the workflow when changing the inputs; and (ii) the segregation of system-specific information from the rest of the sections enables users to run a workflow practically anywhere. In other words, by simply updating the system-specific sections with proper values, the requirements of the workflow can be observed on any machine.</p>
    </sec>
    <sec id="sec2-3">
      <title>Kronos workflows</title>
      <p>Each workflow made by Kronos is a directed acyclic graph (DAG) of components where every node in the graph corresponds to a task section in the configuration file. Task sections can independently be added, removed, or replaced in the configuration file (Fig. <xref ref-type="fig" rid="fig3">3</xref>). Therefore, to add, remove, or replace a component in the workflow or equivalently a node in the DAG, users simply need to change the corresponding task section in the configuration file and run the command in Step 3. As a result, the workflows are highly modular and maintaining them is as easy as updating the configuration file without having to rewrite the workflow. Finally, a workflow can be run by simply running the Python workflow script using the command line as depicted in Fig. <xref ref-type="fig" rid="fig4">4</xref>.</p>
      <fig id="fig3" orientation="portrait" position="float">
        <label>Figure 3:</label>
        <caption>
          <p>Replace a component in a workflow. The configuration file has different sections as shown in the figure. These sections are: GENERAL, PIPELINE_INFO, SHARED, SAMPLES, and TASKs. The modular organization of the configuration file allows for easy customization of workflows, which can serve different purposes such as tool comparison. Adding, removing, or replacing nodes in the DAG of the workflows can be easily done by adding, removing, or replacing the corresponding TASK sections in the configuration file. For instance, to go from workflow <monospace>DAG1</monospace> to workflow <monospace>DAG2</monospace>, i.e., to replace <monospace>comp_1</monospace> (e.g., variant caller 1) in the first workflow with <monospace>comp_5</monospace> (e.g., variant caller 2) in the second, the user only needs to replace the <monospace>TASK_1</monospace> section with the <monospace>TASK_5</monospace> section in the configuration file and perform Step 3.</p>
        </caption>
        <graphic xlink:href="gix042fig3"/>
      </fig>
      <fig id="fig4" orientation="portrait" position="float">
        <label>Figure 4:</label>
        <caption>
          <p>Run a workflow. Workflows generated by Kronos are ready to run locally on a cluster of computing nodes and in the cloud. To run a workflow, users only need to run the Python workflow script. Each run of a workflow generates a specific directory structure tagged with a run-ID. When running a workflow for multiple samples, a separate directory is made for each sample to make it convenient to locate the results corresponding to each sample. This figure shows the tree structure of the resulting directory. There are 4 subdirectories that are always generated for each sample: (Ai) logs: to store the log files; (Bii) outputs: to store all the output files generated by all the components in the workflow; (iii) scripts: to store the scripts automatically generated by Kronos to run each component in the workflow; (iv) sentinels: to store sentinel files used by Kronos to pick up the workflow from where it left off in a previous run.</p>
        </caption>
        <graphic xlink:href="gix042fig4"/>
      </fig>
    </sec>
    <sec id="sec2-4">
      <title>Kronos features and benefits</title>
      <p>Full details of how to use each of the following features can be found in the software documentation.</p>
      <sec id="sec2-4-1">
        <title>Parameter sweeping</title>
        <p>It is sometimes desired to run a particular tool or algorithm with various sets of parameters in order to select the parameter set with superior performance for a given problem. For example, a user may want to find the proper model parameters (such as mapping quality and base quality thresholds) for a variant calling tool to accurately detect single nucleotide variants. Kronos provides a mechanism for this purpose where users can specify all different sets of input arguments (or parameters) in the <monospace>SAMPLES</monospace> section of the configuration file. In this case, running Step 3 creates a number of intermediate workflows, each for 1 set of input arguments, along with the main workflow. When running the main workflow, Kronos runs the intermediate workflows in parallel, each on one set of the input arguments. We have provided a variant calling workflow with parameter sweeping functionality in Section 3 of Additional file 1 to demonstrate this feature.</p>
      </sec>
      <sec id="sec2-4-2">
        <title>Tool comparison</title>
        <p>In bioinformatics, it is often required to compare the performance of 2 or more algorithms or compare a new analysis tool to the existing ones to select the 1 that best fits the particular goals of a project. For example, it is often helpful to evaluate the performance of different variant calling algorithms [<xref rid="bib12" ref-type="bibr">12</xref>]. The modularity of the workflows generated by Kronos facilitates the comparison of different algorithms and tools. For this purpose, as shown in Fig. <xref ref-type="fig" rid="fig3">3</xref>, the user can simply replace a task section corresponding to an analysis tool with another task section corresponding to another similar tool and run Step 3.</p>
      </sec>
      <sec id="sec2-4-3">
        <title>Automatic parallelization and merge</title>
        <p>Most of the recent tools developed in the bioinformatics field are parallelizable or have the potential to run in parallel. However, the majority of these tools are shipped without the built-in functionality and require the users to manually break the analysis into smaller analyses. For example, many variant calling algorithms are capable of running on user-specified coordinates of the genome but are not shipped with parallelization functionality. However, a user can analyze whole genome sequencing data chunk by chunk in parallel with the caveat of manually scripting the parallelization steps. Due to the cumbersome nature of manual parallelization, many users might avoid running the tools in parallel, which considerably increases the runtime of the analysis. To resolve this issue, Kronos automatically parallelizes tasks in the workflow if feasible. Then, it aggregates the outputs of all child tasks and merges them if necessary.</p>
      </sec>
      <sec id="sec2-4-4">
        <title>Reproducible workflows</title>
        <p>The configuration file and components of a workflow are portable.</p>
        <p>Therefore, users can readily duplicate a workflow elsewhere by only running the <monospace>kronos init</monospace> command in Step 3. To show this functionality, we have included an example of a workflow that performs somatic variant calling on whole genome data of a breast cancer case using the Strelka algorithm [<xref rid="bib13" ref-type="bibr">13</xref>] and generates a number of plots based on Strelka calls (Fig. <xref ref-type="fig" rid="fig5">5</xref>). Detailed step-by-step instructions to reproduce this figure are in Section 3 of Additional file 1. It should be noted that Kronos workflows can be duplicated elsewhere but the user would still need to manage tool installations and dependencies.</p>
        <fig id="fig5" orientation="portrait" position="float">
          <label>Figure 5:</label>
          <caption>
            <p>Strelka workflow. Results from the tumour-normal variant calling workflow on whole genome data of a breast cancer case (SA500 - EGA accession number EGAS00001000952). (A) Schematic of the workflow, which is comprised of 2 tasks. The plots generated by the workflow are in fact the output of TASK_2: (B) box plot of coverage and variant allelic ratios for the SNVs detected by Strelka, (C) base substitution patterns for the somatic SNVs, and (D) total number of SNVs and their histogram based on the quality score (QSS), (E) distribution of the number of SNVs across different chromosomes.</p>
          </caption>
          <graphic xlink:href="gix042fig5"/>
        </fig>
      </sec>
      <sec id="sec2-4-5">
        <title>Cloud support</title>
        <p>The massive scale of genomic data justifies a move to the cloud for storage and analyses in order to minimize cost and handle the ebb and flow of computational demands. Kronos’ flexibility addresses the emerging need for rapid deployment of analysis workflows in the cloud. Several command line tools exist for managing fleets of compute nodes on cloud platforms such as Amazon Web Services, including StarCluster, CfnCluster, and Elasticluster. A guide on the creation and management of a cloud cluster using StarCluster software and deployment of Kronos is provided in the online documentation, and an Amazon Machine Image is provided for convenience.</p>
      </sec>
      <sec id="sec2-4-6">
        <title>Controlled pause/resume by breakpoints</title>
        <p>When running a workflow, certain blocks of the workflow may need to run multiple times, e.g., to tune a particular parameter of a component or to inspect the results of the previous tasks in the workflow before the next tasks are triggered. Analogous to the debuggers, Kronos provides users with breakpoints to perform a controlled pause/resume action.</p>
        <p>In addition, with the breakpoint mechanism, users can break the flow of a workflow into several subworkflows and run each part on a different machine or cluster. In other words, once a breakpoint happens, i.e., 1 subworkflow is complete, the main workflow can be transferred to a different machine and it will pick up running from where it left off on the previous machine, provided that all the intermediate files are present. For example, a workflow can contain a component as its last step that loads the final results to a local database that can be reached only from a specific IP or machine. In this case, the user can run the workflow on a powerful computing node or a cluster with a breakpoint set for the component prior to the last component, i.e., database loader in this example. Once the breakpoint is applied, the user can resume the workflow on the other machine, so that the results can be loaded to the local database.</p>
      </sec>
      <sec id="sec2-4-7">
        <title>Forced dependency</title>
        <p>Often in a workflow, a task requires the output of the previous one. As explained earlier, Kronos handles this explicit dependency by IO-connection. However, sometimes a task might need to wait for 1 one or more other steps in the workflow to finish although there are no explicit IO-connections between them. For example, when 2 tasks intend to write results in the same file, one needs to make sure that both tasks do not run at the same time. Another example would be a variant calling algorithm (e.g., GATK) that accepts a bam file as input. However, it also expects the index of the bam file to be present in the same directory as the bam file. If the index is created in 1 of the previous tasks in the workflow, then the current task that needs the bam file and its index would depend implicitly on the other task that creates the index file. In this case, a mechanism is required to force the variant calling task to wait until the index file is ready. Kronos provides a forced dependency feature to overcome this problem (see Additional file 1: Fig. S2).</p>
      </sec>
      <sec id="sec2-4-8">
        <title>Results directory customization</title>
        <p>It is desirable to have full control of the structure of the results directory when running a workflow. With Kronos, users can readily determine the structure of the results directory in the configuration file. This provides easy file management for the users. Figure <xref ref-type="fig" rid="fig4">4</xref> shows an example of the tree structure of the results directory generated for a workflow.</p>
      </sec>
      <sec id="sec2-4-9">
        <title>Boilerplates</title>
        <p>Users can use this feature to insert a command or a script into the begining of the command used to run a task in a workflow. This is particularly useful for setting up the environments using the Environment Modules package [<xref rid="bib14" ref-type="bibr">14</xref>]. It also provides a means to run preprocessing steps for a specific task prior to running the task itself.</p>
      </sec>
      <sec id="sec2-4-10">
        <title>Keywords</title>
        <p>There are several specific keywords that users can use in the configuration file that will be automatically replaced by proper values in runtime. This enables users to customize the paths and file names based on the workflow-specific values in runtime such as run-ID, workflow name, or sample ID.</p>
      </sec>
    </sec>
  </sec>
  <sec id="sec3">
    <title>Workflows</title>
    <p>We have developed a number of standard genome analysis workflows using Kronos. These workflows utilize many of the Kronos features introduced earlier and are publicly available.</p>
  </sec>
  <sec id="sec4">
    <title/>
    <sec disp-level="2" id="sec4-1">
      <title>Alignment workflow</title>
      <p>This workflow accepts paired-end FASTQ files as input and aligns them using the Burrows-Wheeler aligner [<xref rid="bib15" ref-type="bibr">15</xref>]. It also sorts the aligned bam file, flags the duplicates, indexes the file, and generates statistics for the final bam file.</p>
    </sec>
  </sec>
  <sec id="sec5">
    <title/>
    <sec disp-level="2" id="sec5-1">
      <title>Germline variant calling workflow</title>
      <p>This workflow is an implementation of the best practices guide established by the Broad Institute [<xref rid="bib1" ref-type="bibr">1</xref>] applied to variant discovery using haplotypecaller. In short, it runs the Bowtie2 aligner, creates targets using GATK RealignerTargetCreator, and calls SNVs and indels using GATK.</p>
    </sec>
  </sec>
  <sec id="sec6">
    <title/>
    <sec disp-level="2" id="sec6-1">
      <title>Copy number estimation workflow</title>
      <p>HMMCopy is a suite of tools for copy number estimation of whole genome sequencing data [<xref rid="bib16" ref-type="bibr">16</xref>]. This workflow takes a bam file as an input and estimates the copy number with GC and mappability correction using HMMCopy. It also segments and classifies the copy number profiles with a robust Hidden Markov Model.</p>
    </sec>
  </sec>
  <sec id="sec7">
    <title/>
    <sec disp-level="2" id="sec7-1">
      <title>Somatic variant calling workflow</title>
      <p>This workflow takes a pair of tumour/normal bam files as inputs and detects the somatic SNVs and indels using the Strelka algorithm [<xref rid="bib13" ref-type="bibr">13</xref>], annotates the resulting VCF files using SnpEff [<xref rid="bib17" ref-type="bibr">17</xref>], and flags the variants observed in 1000 genomes and dbSNP databases.</p>
    </sec>
  </sec>
  <sec id="sec8">
    <title/>
    <sec disp-level="2" id="sec8-1">
      <title>RNA-seq analysis workflow</title>
      <p>This workflow aligns RNA-seq FASTQ files using STAR aligner [<xref rid="bib18" ref-type="bibr">18</xref>], followed by Cufflinks, which assembles transcriptomes from RNA-seq data and quantifies their expression [<xref rid="bib19" ref-type="bibr">19</xref>].</p>
    </sec>
  </sec>
  <sec sec-type="conclusions" id="sec9">
    <title>Conclusions</title>
    <p>A foundation for rapid and reliable implementation of genomic analysis workflows is an essential need as a myriad of potential applications of genomics (ranging from personalized cancer therapies to monitoring the evolution and spread of infectious diseases) are projected to produce massive amounts of genomic data in the next few years. We have developed Kronos to address this need by expediting workflow development. It minimizes the tedious process of writing code by transforming a YAML configuration file into a Python script and manages its execution. Given a set of premade components, constructing a workflow by Kronos does not need programming skills as the user only needs to fill out specific sections of the configuration file. Making components still requires programming. However, their development time and effort is minimal given their design structure. They also provide a powerful and highly flexible framework for bioinformatics developers to fully customize their workflows with reusable modules.</p>
    <p>A number of standard genomic analysis workflows and their building components that have been made by Kronos accompany this software and are available to the public. Kronos has been developed for genomics applications, but it can be readily utilized in other scientific and nonscientific fields.</p>
    <p>The configuration file and components of a Kronos workflow are portable. This is a step toward reproducible research; however, it should be noted that while Kronos workflows can be duplicated elsewhere, the user would still need to manage tool installations and dependencies. For fully reproducible research, a Docker image of the whole workflow or the environment is perhaps more plausible. Kronos is complementary to other efforts for reproducible research. For example, in order to unify representation of workflow definitions and tool wrappers, the Common Workflow Language working group [<xref rid="bib10" ref-type="bibr">10</xref>] and the Workfow Description Language [<xref rid="bib20" ref-type="bibr">20</xref>] offer specifications that enable data scientists to describe analysis tools and workflows that are human-readable, easy to use, portable, and support reproducibility. It would be beneficial for workflow management tools to adopt these representation standards once they are agreed upon in the field.</p>
    <p>In conclusion, this work provides a framework toward rapid integration of new (and optimal) genomic analysis advances in high-throughput studies. The flexibility, customization, and modularity of Kronos make it an attractive system to use in any high-throughput genomics analysis endeavour. We expect that Kronos will provide a foundational platform to accelerate toward the need to standardize and distribute NGS workflows in both clinical and research applications.</p>
  </sec>
  <sec id="sec10">
    <title>Additional files</title>
    <sec id="sec10-1">
      <title>Additional file 1 — Supplementary information</title>
      <p>The supplementary information is in pdf format and expalins (a) how to make a component, (b) how to make a workflow, (c) how to run a workflow, and (d) Fig. S1 and Fig. S2.</p>
    </sec>
  </sec>
  <sec id="sec11">
    <title>Abbreviations</title>
    <p>DAG: directed acyclic graph; NGS: next-generation sequencing; SNV: single nucleotide variant.</p>
  </sec>
  <sec id="sec12">
    <title>Availability and requirements</title>
    <p>Project name: Kronos</p>
    <p>Project home page: <ext-link ext-link-type="uri" xlink:href="https://github.com/jtaghiyar/kronos">https://github.com/jtaghiyar/kronos</ext-link></p>
    <p>Operating system(s): Linux, Windows, Mac OS</p>
    <p>Programming language: Python 2.7.5</p>
    <p>Other requirements: Ruffus, PyYaml</p>
    <p>License: MIT</p>
  </sec>
  <sec id="sec13">
    <title>Availability of supporting data</title>
    <p>Snapshots of the code can be found in the <italic>GigaScience</italic> repository, GigaDB [<xref rid="bib21" ref-type="bibr">21</xref>].</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material content-type="local-data" id="sup1">
      <label>GIGA-D-17-00052_Original-Submission.pdf</label>
      <media xlink:href="gix042_GIGA-D-17-00052_Original-Submission.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material content-type="local-data" id="sup2">
      <label>GIGA-D-17-00052_Revision-1.pdf</label>
      <media xlink:href="gix042_GIGA-D-17-00052_Revision-1.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material content-type="local-data" id="sup3">
      <label>Response-to-Reviewer-Comments_Original-Submission.pdf</label>
      <media xlink:href="gix042_Response-to-Reviewer-Comments_Original-Submission.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material content-type="local-data" id="sup4">
      <label>Reviewer-1-Report-(Original-Submission).pdf</label>
      <media xlink:href="gix042_Reviewer-1-Report-(Original-Submission).pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material content-type="local-data" id="sup5">
      <label>Supplementary Information</label>
      <media xlink:href="gix042_Supplementary-information.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ack>
    <title>Acknowledgements</title>
    <p>The authors would like to thank Shadrielle Melijah G. Espiritu and Andre Masella for their feedback on the manuscript/software. This project has been supported by funding from Genome Canada/Genome British Columbia (grant No. 173CIC), the Natural Science and Engineering Research Council of Canada (grant No. RGPGR 488167-2013), and Terry Fox Research Institute - Program Project Grants (grant No. 1021).</p>
  </ack>
  <sec id="sec14">
    <title>Competing interests</title>
    <p>The authors declare that they have no competing interests.</p>
  </sec>
  <sec id="sec15">
    <title>Author contributions</title>
    <p>J.T. developed the software, wrote the documentation, and contributed to manuscript writing. J.R. assisted in developing part of the logger and a few of the helper functions for the software, testing software features, and providing feedback on the manuscript. D.G. developed a number of pipelines accompanying the manuscript, tested the software, and provided feedback on the software features and manuscript. B.G. deployed and tested Kronos in the cloud, wrote the documentation for cloud deployment, tested software, and provided feedback on the software features and manuscript. R.A. developed the germline variant calling workflow and provided feedback on the manuscript. J.G. tested and provided feedback on the software. P.B. provided feedback on the manuscript. R.M. provided resources, supervised testing Kronos in the cloud, and provided feedback on the manuscript. A.B. contributed to the design and development of the software. A.B. and S.S. co-supervised, provided intellectual contributions to the work, and contributed to manuscript writing. A.B. and S.S. are joint senior authors.</p>
  </sec>
  <ref-list>
    <title>References</title>
    <ref id="bib1">
      <label>1.</label>
      <mixed-citation publication-type="other"><collab>GATK Best Practices - Recommended workflows for variant analysis with GATK</collab>. <comment>Available from: <ext-link ext-link-type="uri" xlink:href="https://www.broadinstitute.org/gatk/guide/best-practices">https://www.broadinstitute.org/gatk/guide/best-practices</ext-link></comment>.</mixed-citation>
    </ref>
    <ref id="bib2">
      <label>2.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Goecks</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Nekrutenko</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Taylor</surname><given-names>J</given-names></name><etal/></person-group><article-title>Galaxy: a comphrehensible approach for supporting accessible, reproducible, and transparent computational research in the life sciences</article-title>. <source>Genome Biol</source><year>2010</year>;<volume>11</volume>(<issue>R86</issue>):<fpage>1</fpage>–<lpage>13</lpage>.</mixed-citation>
    </ref>
    <ref id="bib3">
      <label>3.</label>
      <mixed-citation publication-type="other"><collab>Galaxy Tool Shed</collab>. <comment>Available from: <ext-link ext-link-type="uri" xlink:href="https://toolshed.g2.bx.psu.edu">https://toolshed.g2.bx.psu.edu</ext-link></comment>.</mixed-citation>
    </ref>
    <ref id="bib4">
      <label>4.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Wolstencroft</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Haines</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Fellows</surname><given-names>D</given-names></name><etal/></person-group><source>The Taverna workflow suite: designing and executing workflows of Web Services on the desktop, web or in the cloud</source>. <publisher-name>Nucl Acids Res</publisher-name><year>2013</year>;<volume>41</volume>:<fpage>W557</fpage>–<lpage>W561</lpage>.<pub-id pub-id-type="pmid">23640334</pub-id></mixed-citation>
    </ref>
    <ref id="bib5">
      <label>5.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Goble</surname><given-names>CA</given-names></name>, <name name-style="western"><surname>Bhagat</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Aleksejevs</surname><given-names>S</given-names></name><etal/></person-group><article-title>Myexperiment: a repository and social network for the sharing of bioinformatics workflows</article-title>. <source>Nucl Acids Res</source><year>2010</year>;<volume>38</volume>(<issue>2</issue>):<fpage>W677</fpage>–<lpage>W682</lpage>.<pub-id pub-id-type="pmid">20501605</pub-id></mixed-citation>
    </ref>
    <ref id="bib6">
      <label>6.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Spjuth</surname><given-names>O</given-names></name>, <name name-style="western"><surname>Bongcam-Rudloff</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Hernández</surname><given-names>GC</given-names></name><etal/></person-group><source>Experiences with workflows for automating data-intensive bioinformatics</source>. <publisher-name>Biology direct</publisher-name><year>2015</year>;<volume>10</volume>(<issue>1</issue>):<fpage>1</fpage>–<lpage>12</lpage>.</mixed-citation>
    </ref>
    <ref id="bib7">
      <label>7.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Goodstadt</surname><given-names>L.</given-names></name></person-group><article-title>Ruffus: A lightweight Python library for computational pipelines</article-title>. <source>Bioinformatics</source><year>2010</year>;<volume>26</volume>(<issue>21</issue>):<fpage>2778</fpage>–<lpage>9</lpage>.<pub-id pub-id-type="pmid">20847218</pub-id></mixed-citation>
    </ref>
    <ref id="bib8">
      <label>8.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Sadedin</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Pope</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Oshlack</surname><given-names>A</given-names></name></person-group><article-title>Bpipe: A tool for running and managing bioinformatics pipelines</article-title>. <publisher-name>Bioinformatics</publisher-name><year>2012</year>;<volume>28</volume>(<issue>11</issue>):<fpage>1525</fpage>–<lpage>6</lpage>.</mixed-citation>
    </ref>
    <ref id="bib9">
      <label>9.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Koster</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Rahmann</surname><given-names>S</given-names></name></person-group><article-title>Snakemake - A scalable bioinformatics workflow engine</article-title>. <publisher-name>Bioinformatics</publisher-name><year>2012</year>;<volume>28</volume>(<issue>19</issue>):<fpage>2520</fpage>–<lpage>2</lpage>.</mixed-citation>
    </ref>
    <ref id="bib10">
      <label>10.</label>
      <mixed-citation publication-type="other"><collab>Common Workflow Language (CWL)</collab>. <comment>Available from: <ext-link ext-link-type="uri" xlink:href="http://www.commonwl.org/draft-3/index.html">http://www.commonwl.org/draft-3/index.html</ext-link></comment>.</mixed-citation>
    </ref>
    <ref id="bib11">
      <label>11.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Fisch</surname><given-names>KM</given-names></name>, <name name-style="western"><surname>Meißner</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Gioia</surname><given-names>L</given-names></name><etal/></person-group><article-title>Omics Pipe: a community-based framework for reproducible multi-omics data analysis</article-title>. <source>Bioinformatics</source>. <year>2015</year>.</mixed-citation>
    </ref>
    <ref id="bib12">
      <label>12.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Ewing</surname><given-names>AD</given-names></name>, <name name-style="western"><surname>Houlahan</surname><given-names>KE</given-names></name>, <name name-style="western"><surname>Hu</surname><given-names>Y</given-names></name><etal/></person-group><article-title>Combining tumor genome simulation with crowdsourcing to benchmark somatic single-nucleotide-variant detection</article-title>. <source>Nat methods</source>. <year>2015</year>.</mixed-citation>
    </ref>
    <ref id="bib13">
      <label>13.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Saunders</surname><given-names>CT</given-names></name>, <name name-style="western"><surname>Wong</surname><given-names>WS</given-names></name>, <name name-style="western"><surname>Swamy</surname><given-names>S</given-names></name><etal/></person-group><article-title>Strelka: accurate somatic small-variant calling from sequenced tumor–normal sample pairs</article-title>. <source>Bioinformatics</source><year>2012</year>;<volume>28</volume>(<issue>14</issue>):<fpage>1811</fpage>–<lpage>7</lpage>.<pub-id pub-id-type="pmid">22581179</pub-id></mixed-citation>
    </ref>
    <ref id="bib14">
      <label>14.</label>
      <mixed-citation publication-type="other"><collab>Environment Modules Project - Software environment management</collab>. <comment>Available from: <ext-link ext-link-type="uri" xlink:href="http://modules.sourceforge.net/">http://modules.sourceforge.net/</ext-link>.</comment></mixed-citation>
    </ref>
    <ref id="bib15">
      <label>15.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Li</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Durbin</surname><given-names>R</given-names></name></person-group><article-title>Fast and accurate short read alignment with burrows-wheeler transform</article-title>. <publisher-name>Bioinformatics</publisher-name><year>2009</year>;<volume>25</volume>:<fpage>1754</fpage>–<lpage>60</lpage>.</mixed-citation>
    </ref>
    <ref id="bib16">
      <label>16.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Ha</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Roth</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Lai</surname><given-names>D</given-names></name><etal/></person-group><article-title>Integrative analysis of genome-wide loss of heterozygosity and mono-allelic expression at nucleotide resolution reveals disrupted pathways in triple negative breast cancer</article-title>. <source>Genome Res</source><year>2012</year>;<volume>22</volume>(<issue>10</issue>):<fpage>1995</fpage>–<lpage>2007</lpage>.<pub-id pub-id-type="pmid">22637570</pub-id></mixed-citation>
    </ref>
    <ref id="bib17">
      <label>17.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Cingolani</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Platts</surname><given-names>A</given-names></name>, <name name-style="western"><surname>le Wang</surname><given-names>L</given-names></name><etal/></person-group><article-title>A program for annotating and predicting the effects of single nucleotide polymorphisms, snpeff: SNPs in the genome of Drosophila melanogaster strain w1118; iso-2; iso-3</article-title>. <source>Fly</source><year>2012</year>;<volume>6</volume>:<fpage>80</fpage>–<lpage>92</lpage>.<pub-id pub-id-type="pmid">22728672</pub-id></mixed-citation>
    </ref>
    <ref id="bib18">
      <label>18.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Dobin</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Davis</surname><given-names>CA</given-names></name>, <name name-style="western"><surname>Schlesinger</surname><given-names>F</given-names></name><etal/></person-group><article-title>STAR: ultrafast universal RNA-seq aligner</article-title>. <source>Bioinformatics</source><year>2013</year>;<volume>29</volume>(<issue>1</issue>):<fpage>15</fpage>–<lpage>21</lpage>.<pub-id pub-id-type="pmid">23104886</pub-id></mixed-citation>
    </ref>
    <ref id="bib19">
      <label>19.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Trapnell</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Roberts</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Goff</surname><given-names>L</given-names></name><etal/></person-group><publisher-name>Differential gene and transcript expression analysis of RNA-seq experiments with TopHat and Cufflinks</publisher-name><source>Nat Protoc</source><year>2012</year>;<volume>7</volume>(<issue>3</issue>):<fpage>562</fpage>–<lpage>78</lpage>.<pub-id pub-id-type="pmid">22383036</pub-id></mixed-citation>
    </ref>
    <ref id="bib20">
      <label>20.</label>
      <mixed-citation publication-type="other"><collab>Workflow Description Language (WDL)</collab>. <comment>Available from: <ext-link ext-link-type="uri" xlink:href="https://github.com/broadinstitute/wdl">https://github.com/broadinstitute/wdl</ext-link></comment>.</mixed-citation>
    </ref>
    <ref id="bib21">
      <label>21.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Taghiyar</surname><given-names>JM</given-names></name>, <name name-style="western"><surname>Rosner</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Grewal</surname><given-names>D</given-names></name><etal/></person-group><article-title>Supporting materials for “Kronos: a workflow assembler for genome analytics and informatics.”</article-title><source>Gigascience Database</source><year>2017</year><comment>Available from: <ext-link ext-link-type="uri" xlink:href="http://dxdoiorg/105524/100307">http://dxdoiorg/105524/100307</ext-link></comment>.</mixed-citation>
    </ref>
  </ref-list>
</back>
