<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Nucleic Acids Res</journal-id>
    <journal-id journal-id-type="iso-abbrev">Nucleic Acids Res</journal-id>
    <journal-id journal-id-type="publisher-id">nar</journal-id>
    <journal-title-group>
      <journal-title>Nucleic Acids Research</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">0305-1048</issn>
    <issn pub-type="epub">1362-4962</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">9252760</article-id>
    <article-id pub-id-type="pmid">35648435</article-id>
    <article-id pub-id-type="doi">10.1093/nar/gkac439</article-id>
    <article-id pub-id-type="publisher-id">gkac439</article-id>
    <article-categories>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI00010</subject>
      </subj-group>
      <subj-group subj-group-type="heading">
        <subject>Web Server Issue</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>NetSurfP-3.0: accurate and fast prediction of protein structural features by protein language models and deep learning</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0003-2567-758X</contrib-id>
        <name>
          <surname>Høie</surname>
          <given-names>Magnus Haraldson</given-names>
        </name>
        <aff><institution>Department of Health Technology, Technical University of Denmark</institution>, DK Lyngby, <country country="DK">Denmark</country></aff>
        <xref rid="FN1" ref-type="author-notes"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Kiehl</surname>
          <given-names>Erik Nicolas</given-names>
        </name>
        <aff><institution>Department of Health Technology, Technical University of Denmark</institution>, DK Lyngby, <country country="DK">Denmark</country></aff>
        <xref rid="FN1" ref-type="author-notes"/>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-2472-8317</contrib-id>
        <name>
          <surname>Petersen</surname>
          <given-names>Bent</given-names>
        </name>
        <aff><institution>Center for Evolutionary Hologenomics, GLOBE Institute, University of Copenhagen</institution>, <country country="DK">Denmark</country></aff>
        <aff><institution>Centre of Excellence for Omics-Driven Computational Biodiscovery (COMBio), Faculty of Applied Sciences, AIMST University</institution>, Kedah, <country country="MY">Malaysia</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0001-7885-4311</contrib-id>
        <name>
          <surname>Nielsen</surname>
          <given-names>Morten</given-names>
        </name>
        <aff><institution>Department of Health Technology, Technical University of Denmark</institution>, DK Lyngby, <country country="DK">Denmark</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-1966-3205</contrib-id>
        <name>
          <surname>Winther</surname>
          <given-names>Ole</given-names>
        </name>
        <aff><institution>Section for Cognitive Systems, DTU Compute, Technical University of Denmark (DTU)</institution>, <country country="DK">Denmark</country></aff>
        <aff><institution>Center for Genomic Medicine, Rigshospitalet (Copenhagen University Hospital)</institution>, Copenhagen, <country country="DK">Denmark</country></aff>
        <aff><institution>Department of Biology, Bioinformatics Centre, University of Copenhagen</institution>, Copenhagen, <country country="DK">Denmark</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-9412-9643</contrib-id>
        <name>
          <surname>Nielsen</surname>
          <given-names>Henrik</given-names>
        </name>
        <aff><institution>Department of Health Technology, Technical University of Denmark</institution>, DK Lyngby, <country country="DK">Denmark</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0001-5377-2643</contrib-id>
        <name>
          <surname>Hallgren</surname>
          <given-names>Jeppe</given-names>
        </name>
        <aff><institution>BioLib Technologies</institution>, Copenhagen, <country country="DK">Denmark</country></aff>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0003-2615-5695</contrib-id>
        <name>
          <surname>Marcatili</surname>
          <given-names>Paolo</given-names>
        </name>
        <!--paolo.marcatili@gmail.com-->
        <aff><institution>Department of Health Technology, Technical University of Denmark</institution>, DK Lyngby, <country country="DK">Denmark</country></aff>
        <xref rid="COR1" ref-type="corresp"/>
      </contrib>
    </contrib-group>
    <author-notes>
      <corresp id="COR1">To whom correspondence should be addressed. Tel: +45 28232413; Email: <email>paolo.marcatili@gmail.com</email></corresp>
      <fn id="FN1">
        <p>The authors wish it to be known that, in their opinion, the first two authors should be regarded as Joint First Authors.</p>
      </fn>
    </author-notes>
    <pub-date pub-type="collection">
      <day>05</day>
      <month>7</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2022-06-01">
      <day>01</day>
      <month>6</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>01</day>
      <month>6</month>
      <year>2022</year>
    </pub-date>
    <volume>50</volume>
    <issue>W1</issue>
    <fpage>W510</fpage>
    <lpage>W515</lpage>
    <history>
      <date date-type="accepted">
        <day>27</day>
        <month>5</month>
        <year>2022</year>
      </date>
      <date date-type="rev-recd">
        <day>04</day>
        <month>5</month>
        <year>2022</year>
      </date>
      <date date-type="received">
        <day>25</day>
        <month>3</month>
        <year>2022</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2022. Published by Oxford University Press on behalf of Nucleic Acids Research.</copyright-statement>
      <copyright-year>2022</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="gkac439.pdf"/>
    <abstract>
      <title>Abstract</title>
      <p>Recent advances in machine learning and natural language processing have made it possible to profoundly advance our ability to accurately predict protein structures and their functions. While such improvements are significantly impacting the fields of biology and biotechnology at large, such methods have the downside of high demands in terms of computing power and runtime, hampering their applicability to large datasets. Here, we present NetSurfP-3.0, a tool for predicting solvent accessibility, secondary structure, structural disorder and backbone dihedral angles for each residue of an amino acid sequence. This NetSurfP update exploits recent advances in pre-trained protein language models to drastically improve the runtime of its predecessor by two orders of magnitude, while displaying similar prediction performance. We assessed the accuracy of NetSurfP-3.0 on several independent test datasets and found it to consistently produce state-of-the-art predictions for each of its output features, with a runtime that is up to to 600 times faster than the most commonly available methods performing the same tasks. The tool is freely available as a web server with a user-friendly interface to navigate the results, as well as a standalone downloadable package.</p>
    </abstract>
    <abstract abstract-type="graphical">
      <title>Graphical Abstract</title>
      <p>
        <fig position="float" id="ga1">
          <label>Graphical Abstract</label>
          <caption>
            <p>NetSurfP-3.0: accurate and fast prediction of protein structural features by protein language models and deep learning.</p>
          </caption>
          <graphic xlink:href="gkac439figgra1" position="float"/>
        </fig>
      </p>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Sino-Danish Center</institution>
            <institution-id institution-id-type="DOI">10.13039/501100020733</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>2021</award-id>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="6"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec sec-type="intro" id="SEC1">
    <title>INTRODUCTION</title>
    <p>In 2020, AlphaFold demonstrated the full potential of deep-learning methods for prediction of protein structures from amino acid sequences, by achieving extraordinary results at the 14th edition of the CASP competition (<xref rid="B1" ref-type="bibr">1</xref>,<xref rid="B2" ref-type="bibr">2</xref>). As of March 2022, the pre-calculated AlphaFold database (<xref rid="B3" ref-type="bibr">3</xref>) contains 3D models for almost a million different proteins, substantially increasing our understanding of protein structure and function. However, while impressive, this number covers only a minute fraction of the known protein sequences, at the current time limited to &lt;0.5% of the UniProt database (<xref rid="B4" ref-type="bibr">4</xref>) originating from a small group of model organisms. The bottleneck resides in the immense computational demands of running the AlphaFold model, both in terms of computing power and runtime. Therefore, there is still a need for prediction tools that can annotate protein sequences in a faster, yet accurate, manner.</p>
    <p>One of the time-consuming steps in most of the modern tools that predict global and local structural features is the search and alignment of homologs of the target protein, usually referred to as multiple sequence alignment (MSA) (<xref rid="B5" ref-type="bibr">5</xref>). MSAs are used to create a compact and informative numerical representation of the residues in a collection of sequences, based on statistics derived from evolutionary-related sequences. MSAs can be generated using different tools (<xref rid="B6" ref-type="bibr">6–11</xref>), which vary in their precision and speed of execution. Until recently, the general paradigm has been that accurate prediction performance depends on an exhaustive search and high information content in the MSA, thus limiting the speed of such methods (<xref rid="B12" ref-type="bibr">12</xref>).</p>
    <p>Recent breakthroughs in the field of natural language processing (NLP) (<xref rid="B13" ref-type="bibr">13</xref>) have allowed for generating information-rich representations of protein sequences without the explicit need for MSAs (<xref rid="B14" ref-type="bibr">14</xref>,<xref rid="B15" ref-type="bibr">15</xref>). This is achieved by pre-training language models (LMs) on large datasets of unannotated sequences. These LMs are trained to predict the probability of a masked residue in a protein sequence, only based on the rest of the sequence itself. In doing so, they generate complex numerical representations of protein sequences (also referred to as sequence embeddings), that can be exploited to perform downstream prediction tasks, thus bypassing the need to generate computationally expensive MSAs.</p>
    <p>NetSurfP-2.0 is a tool that generates state-of-the-art predictions for protein secondary structure, solvent accessibility, disorder, and backbone geometry of any given protein from its primary sequence only (<xref rid="B16" ref-type="bibr">16</xref>). Since its launch in 2019, NetsurfP-2.0 has been used extensively by the research community to annotate proteins. The web server has received 27 456 job submissions and the stand-alone package has been downloaded 995 times. Here, we present NetSurfP-3.0, an updated version of NetSurfP, that uses the ESM-1b protein LM (<xref rid="B14" ref-type="bibr">14</xref>) to replace the time-consuming MSA generation used in version 2.0, thus decreasing the runtime of the tool by &gt;2 orders of magnitude, without any substantial trade-off in terms of accuracy.</p>
    <p>When assessed on multiple independent test sets selected to have no &gt;25% sequence identity to any protein used in the training, its accuracy is consistently on par with or better than version 2.0 or other similar tools. At the same time, it is consistently the fastest of all the tools we tested by a large margin <xref rid="F1" ref-type="fig">1</xref>. It has a user-friendly interface allowing non-expert users to access and analyze their results via a browser thanks to its graphical output, and with its easily downloadable output in several common formats it can be used for further analysis.</p>
    <fig position="float" id="F1">
      <label>Figure 1.</label>
      <caption>
        <p>Runtime analysis in seconds for submissions of 1 to 1000 sequences for NetsurfP-3.0, SPOT-1D-LM and NetsurfP-2.0. We note a 5.3× speed-up for NetSurfP-3.0 versus its closest competitor SPOT-1D-LM, and 665× speed-up versus the older NetSurfP-2.0, when processing 1000 sequences. The runtime for a single AlphaFold2 model is shown with a dashed line. We performed all benchmarks on the same AWS EC2 G4 instance, with a 16GB NVIDIA T4 GPU (see Methods).</p>
      </caption>
      <graphic xlink:href="gkac439fig1" position="float"/>
    </fig>
  </sec>
  <sec sec-type="materials|methods" id="SEC2">
    <title>MATERIALS AND METHODS</title>
    <sec id="SEC2-1">
      <title>Datasets</title>
      <p>The NetSurfP-3.0 method has been trained and tested on the same datasets used for NetSurfP-2.0. Its training and validation set consist of 10 337 and 500 non-redundant proteins, respectively, and the testing is performed on the three test sets TS115 (115 proteins) (<xref rid="B17" ref-type="bibr">17</xref>), CB513 (513 protein regions from 434 proteins) (<xref rid="B18" ref-type="bibr">18</xref>), and CASP12 (21 proteins) (<xref rid="B19" ref-type="bibr">19</xref>). For an accurate description of these datasets, we refer to the original paper (<xref rid="B16" ref-type="bibr">16</xref>). Additionally, we tested NetSurfP-3.0 and other tools on a novel external dataset, named CASP14_FM (<xref rid="B1" ref-type="bibr">1</xref>). This dataset consists of all the protein domains from the CASP14 competition labelled as free modeling (FM) targets, that are targets for which no structural template, at the time of the competition, could be identified by using sequence-based homology searches. In fact, when comparing this dataset to our training and validation sets using the MMseqs2 easy-cluster tool (<xref rid="B10" ref-type="bibr">10</xref>), no hit with &gt;20% sequence identity and 50% coverage was found.</p>
    </sec>
    <sec id="SEC2-2">
      <title>Network architecture</title>
      <p>The NetSurfP-3.0 model and the other models used as a comparison in this paper differ in the way they encode the input sequences, while sharing the same downstream architecture of the NetSurfP-2.0 model. The previously mentioned NetSurfP-2.0 model first generates sequence profiles by utilizing either a HHBlits (<xref rid="B9" ref-type="bibr">9</xref>) or MMSeqs2 (<xref rid="B10" ref-type="bibr">10</xref>) search on the Uniref30 database (<xref rid="B20" ref-type="bibr">20</xref>). The probabilities extracted from these profiles are then used to encode the input sequences. The NetSurfP-2.0 sequence encoding consists of 50 variables per residue. The encoding of the baseline model, named NSP_OH, consists of the one-hot sparse encoding of each amino acid, for a total of 20 variables per residue. The NetSurfP-3.0 model exploits the embeddings generated by a pre-trained language model, ESM-1b (<xref rid="B14" ref-type="bibr">14</xref>). This embedding consists of 1280 variables per residue. Regardless of the embedding scheme, the embeddings are fed into two separate 1D CNN layers, using the ReLU activation function and a dropout probability of <italic toggle="yes">P</italic> = 0.5. The first 1D CNN layer has 32 output channels, kernel size of 129, and padding of size 64. The second 1D CNN layer consists of 32 output channels, a kernel size of 257, and a padding of size 128. Consequently, the output of the 1D CNNs is concatenated with the initial input, and a 1D batch normalization is applied. The output is then passed to a two-layer biLSTM with a hidden size of 1024, and a dropout probability of <italic toggle="yes">P</italic> = 0.5. The output from the last biLSTM is then fed into a fully connected layer which finally provides the outputs for the linear layers related to each of the six tasks: eight-state secondary structure (Q8), three-state secondary structure (Q3), disorder, relative solvent-accessible area (RSA), and the dihedral angles phi and psi. The Q8 output layer is configured to generate predictions for eight features, corresponding to the secondary structure classes, whereas three features are predicted in the Q3 output layer. The disorder output generated binary predictions. The RSA output generated a single feature, followed by sigmoid activation, to keep values between 0 and 1. Both phi and psi generated two features, corresponding to sine-cosine encoding of the torsion angles. The tanh activation function was applied in the prediction of phi and psi in order to maintain values between –1 and 1. Moreover, absolute solvent-accessible area (ASA) was calculated from the predicted RSA, by multiplying the RSA and ASA max. In addition to the existing NetSurfP 2.0 architecture, we investigated if other downstream architectures would improve the NetSurfP 3.0 benchmarks. The NetSurf 2.0’s CNN-LSTM downstream architecture was replaced with transformer encoder layers. The output from the ESM-1b embeddings were fed into a transformer encoder, with eight heads and two encoder layers, and used a positional encoder based on a cyclic solution. The transformer encoder output was fed into the same multitask output as in NetSurfP 2.0. Moreover, a similar approach was used by replacing the NetSurfP 2.0 LSTM only with transformer encoder layers. All the networks are implemented in PyTorch (<xref rid="B21" ref-type="bibr">21</xref>).</p>
    </sec>
    <sec id="SEC2-3">
      <title>Processing of long sequences</title>
      <p>By default, the ESM-1b model is limited to input sequence lengths of no more than 1024 amino acids. To overcome this limitation, we use a moving window representation. For sequences exceeding the 1024 limit, we create a moving window across 1024 residues, moving with a stride of 824, corresponding to an overlap of 200 amino acids across windows. Each moving window’s sequence output representation is then trimmed by removing the first 50 and last 50 residues, and the trimmed sequence is then concatenated with the previous and next moving windows.</p>
    </sec>
    <sec id="SEC2-4">
      <title>Training</title>
      <p>The validation dataset was used to perform early stopping during training. Early stopping was performed after 3 epochs in which the loss did not decrease. The training was done using mini batches of size 15. We used the default Pytorch implementation of the Adam optimizer (<xref rid="B22" ref-type="bibr">22</xref>), with a learning rate of 5e–4, epsilon of 1e–8, betas of 0.9 and 0.99, and zero weight decay.</p>
      <p>Backpropagation loss was calculated using a multi-task loss function, which included a weighted loss for each task to predict the local structural features of protein structure. We used a categorical cross entropy loss function for the Q8, Q3 and disorder classification tasks, while RSA, phi and psi regression tasks used the mean squared error loss function. To keep the losses from each task even, they were weighted and summed. We normalized the weights based on the Q8 loss (which had a weight of 1 in the final total loss), with weights applied to the other losses to achieve equal influence. In order to prevent the needed padding of sequence lengths to have an impact on the loss, we masked the loss for the padded positions. RSA, phi, and psi uses additional masking for disordered regions and unknown amino acids. The weights for the different loss components were 1, 5, 5, 100, 5 and 5 for Q8, Q3, disorder, RSA, phi and psi, respectively.</p>
    </sec>
    <sec id="SEC2-5">
      <title>Evaluation</title>
      <p>The models with the lowest validation loss were selected after training. When evaluating the models, the test datasets were used to predict and compare predictions, with mini batches of size 15. We used several metrics for assessing the performance of the various prediction tasks. For Q3 and Q8 secondary structure prediction, we calculated accuracy (ACC) based on the class predictions and target classes. For disorder predictions, we used the metrics false positive rate (FPR) and Matthews correlation coefficient (MCC). For relative surface accessibility (RSA), we calculated the Pearson correlation coefficient (PCC), and for phi and psi, the mean absolute error (MAE) between predictions and target values.</p>
    </sec>
    <sec id="SEC2-6">
      <title>Runtime analysis</title>
      <p>Benchmarking of model runtimes was performed on the same standard Amazon web-services EC2 G4 instance with a single 16GB NVIDIA T4 GPU. Each model was given the same input FASTA file containing either 1, 10, 100 or 1000 sequences. The runtime for a single AlphaFold2 model for the single-sequence FASTA was evaluated using AlphaFold v2.0 (<xref rid="B2" ref-type="bibr">2</xref>) with default settings.</p>
    </sec>
  </sec>
  <sec sec-type="results" id="SEC3">
    <title>RESULTS</title>
    <sec id="SEC3-1">
      <title>Model performance</title>
      <p>We compared the performance of NetSurfP-3.0 with NetSurfP-2.0 on the original test sets used for the NetSurfP-2.0 publication. As shown in Table <xref rid="tbl2" ref-type="table">2</xref>, NetSurfP-3.0 and NetSurfP-2.0 achieve similar accuracy on all datasets. As a baseline, we also include the results obtained using a simple one hot encoding strategy. The gains obtained by using either encoding derived from MSAs or LMs are evident.</p>
      <table-wrap position="float" id="tbl1">
        <label>Table 1.</label>
        <caption>
          <p>Performance benchmark on CASP14_fm test set proteins</p>
        </caption>
        <table frame="hsides" rules="groups">
          <thead>
            <tr>
              <th rowspan="1" colspan="1">Model</th>
              <th rowspan="1" colspan="1">Q3 ↑</th>
              <th rowspan="1" colspan="1">Q8 ↑</th>
              <th rowspan="1" colspan="1">RSA ↑</th>
              <th rowspan="1" colspan="1">Phi ↓</th>
              <th rowspan="1" colspan="1">Psi ↓</th>
            </tr>
            <tr>
              <th rowspan="1" colspan="1"/>
              <th rowspan="1" colspan="1">(ACC)</th>
              <th rowspan="1" colspan="1">(ACC)</th>
              <th rowspan="1" colspan="1">(PCC)</th>
              <th rowspan="1" colspan="1">(MAE)</th>
              <th rowspan="1" colspan="1">(MAE)</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">NetSurfP-3.0</td>
              <td rowspan="1" colspan="1">0.601</td>
              <td rowspan="1" colspan="1">0.607</td>
              <td rowspan="1" colspan="1">0.599</td>
              <td rowspan="1" colspan="1">
                <bold>52.71</bold>
              </td>
              <td rowspan="1" colspan="1">42.02</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">NetSurfP-2.0</td>
              <td rowspan="1" colspan="1">0.581</td>
              <td rowspan="1" colspan="1">0.618</td>
              <td rowspan="1" colspan="1">
                <bold>0.632</bold>
              </td>
              <td rowspan="1" colspan="1">52.73</td>
              <td rowspan="1" colspan="1">
                <bold>41.37</bold>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">SPOT-1D</td>
              <td rowspan="1" colspan="1">0.576</td>
              <td rowspan="1" colspan="1">0.572</td>
              <td rowspan="1" colspan="1">0.556</td>
              <td rowspan="1" colspan="1">71.56</td>
              <td rowspan="1" colspan="1">84.92</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">SPOT-1D-LM</td>
              <td rowspan="1" colspan="1">
                <bold>0.615</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.623</bold>
              </td>
              <td rowspan="1" colspan="1">0.601</td>
              <td rowspan="1" colspan="1">66.64</td>
              <td rowspan="1" colspan="1">81.72</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="T1TFN1">
            <p>Performance of NetSurfP-3.0, NetSurfP-2.0, SPOT-1D-Single (SPOT-1D) and SPOT-1D-LM (SPOT-1D-LM) on the CASP14_FM dataset. Each column represents a different output variable, with the associated metric. Up- and down-facing arrows indicate metrics for which an improvement is represented by larger or lower values, respectively. The values corresponding to the best performances are in bold.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <table-wrap position="float" id="tbl2">
        <label>Table 2.</label>
        <caption>
          <p>Model performance when applying one-hot encodings or ESM1b embeddings to predict protein local structure</p>
        </caption>
        <table frame="hsides" rules="groups">
          <thead>
            <tr>
              <th rowspan="1" colspan="1">Test dataset</th>
              <th rowspan="1" colspan="1">Model</th>
              <th rowspan="1" colspan="1">RSA ↑</th>
              <th rowspan="1" colspan="1">ASA ↑</th>
              <th rowspan="1" colspan="1">Q8 ↑</th>
              <th rowspan="1" colspan="1">Q3 ↑</th>
              <th rowspan="1" colspan="1">Disorder ↑</th>
              <th rowspan="1" colspan="1">Disorder ↓</th>
              <th rowspan="1" colspan="1">Phi ↓</th>
              <th rowspan="1" colspan="1">Psi ↓</th>
            </tr>
            <tr>
              <th rowspan="1" colspan="1"/>
              <th rowspan="1" colspan="1"/>
              <th rowspan="1" colspan="1">(PCC)</th>
              <th rowspan="1" colspan="1">(PCC)</th>
              <th rowspan="1" colspan="1">(ACC)</th>
              <th rowspan="1" colspan="1">(ACC)</th>
              <th rowspan="1" colspan="1">(MCC)</th>
              <th rowspan="1" colspan="1">(FNR)</th>
              <th rowspan="1" colspan="1">(MAE)</th>
              <th rowspan="1" colspan="1">(MAE)</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">CB513</td>
              <td rowspan="1" colspan="1">NSP One-Hot</td>
              <td rowspan="1" colspan="1">0.628</td>
              <td rowspan="1" colspan="1">0.669</td>
              <td rowspan="1" colspan="1">0.573</td>
              <td rowspan="1" colspan="1">0.719</td>
              <td rowspan="1" colspan="1">-</td>
              <td rowspan="1" colspan="1">-</td>
              <td rowspan="1" colspan="1">25.80</td>
              <td rowspan="1" colspan="1">46.16</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">NetSurfP-2.0</td>
              <td rowspan="1" colspan="1">0.791</td>
              <td rowspan="1" colspan="1">0.804</td>
              <td rowspan="1" colspan="1">
                <bold>0.713</bold>
              </td>
              <td rowspan="1" colspan="1">0.845</td>
              <td rowspan="1" colspan="1">-</td>
              <td rowspan="1" colspan="1">-</td>
              <td rowspan="1" colspan="1">20.35</td>
              <td rowspan="1" colspan="1">
                <bold>29.04</bold>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">NetSurfP-3.0</td>
              <td rowspan="1" colspan="1">
                <bold>0.793</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.810</bold>
              </td>
              <td rowspan="1" colspan="1">0.711</td>
              <td rowspan="1" colspan="1">
                <bold>0.846</bold>
              </td>
              <td rowspan="1" colspan="1">-</td>
              <td rowspan="1" colspan="1">-</td>
              <td rowspan="1" colspan="1">
                <bold>20.22</bold>
              </td>
              <td rowspan="1" colspan="1">29.25</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">TS115</td>
              <td rowspan="1" colspan="1">NSP One-Hot</td>
              <td rowspan="1" colspan="1">0.633</td>
              <td rowspan="1" colspan="1">0.679</td>
              <td rowspan="1" colspan="1">0.628</td>
              <td rowspan="1" colspan="1">0.746</td>
              <td rowspan="1" colspan="1">0.561</td>
              <td rowspan="1" colspan="1">
                <bold>0.006</bold>
              </td>
              <td rowspan="1" colspan="1">22.60</td>
              <td rowspan="1" colspan="1">41.40</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">NetSurfP-2.0</td>
              <td rowspan="1" colspan="1">0.771</td>
              <td rowspan="1" colspan="1">0.793</td>
              <td rowspan="1" colspan="1">0.740</td>
              <td rowspan="1" colspan="1">0.849</td>
              <td rowspan="1" colspan="1">0.624</td>
              <td rowspan="1" colspan="1">0.013</td>
              <td rowspan="1" colspan="1">17.40</td>
              <td rowspan="1" colspan="1">26.80</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">NetSurfP-3.0</td>
              <td rowspan="1" colspan="1">
                <bold>0.776</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.799</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.749</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.856</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.662</bold>
              </td>
              <td rowspan="1" colspan="1">0.015</td>
              <td rowspan="1" colspan="1">
                <bold>17.16</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>25.80</bold>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">CASP12</td>
              <td rowspan="1" colspan="1">NSP One-Hot</td>
              <td rowspan="1" colspan="1">0.570</td>
              <td rowspan="1" colspan="1">0.608</td>
              <td rowspan="1" colspan="1">0.576</td>
              <td rowspan="1" colspan="1">0.704</td>
              <td rowspan="1" colspan="1">0.573</td>
              <td rowspan="1" colspan="1">
                <bold>0.007</bold>
              </td>
              <td rowspan="1" colspan="1">26.30</td>
              <td rowspan="1" colspan="1">46.70</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">NetSurfP-2.0</td>
              <td rowspan="1" colspan="1">
                <bold>0.728</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.739</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.699</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.810</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.653</bold>
              </td>
              <td rowspan="1" colspan="1">0.015</td>
              <td rowspan="1" colspan="1">
                <bold>20.90</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>32.80</bold>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">NetSurfP-3.0</td>
              <td rowspan="1" colspan="1">0.707</td>
              <td rowspan="1" colspan="1">0.722</td>
              <td rowspan="1" colspan="1">0.669</td>
              <td rowspan="1" colspan="1">0.791</td>
              <td rowspan="1" colspan="1">0.621</td>
              <td rowspan="1" colspan="1">0.024</td>
              <td rowspan="1" colspan="1">21.25</td>
              <td rowspan="1" colspan="1">33.92</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="T2TFN1">
            <p>Assessment of NetSurfP-3.0, NetSurfP-2.0, and NetSurfP with one-hot encoding (NSP One-Hot) on the CB513, TS115 and CASP12 datasets. Each column reports an output variable with the corresponding metrics: Pearson correlation coefficient (PCC), accuracy (ACC), Matthews correlation coefficient (MCC), false positive rate (FPR) and mean absolute error (MAE). Up- and down-facing arrows indicate metrics for which an improvement is reprepresented by larger or lower values, respectively. For each dataset, the values corresponding to the best performances are in bold.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p>A marginal decrease in performance is observed on the CASP12 dataset; it should be noted that, because of the limited size of this dataset, such an effect might be due to statistical fluctuations in training and assessment. From these results, it appears that the ESM-1b encoding can successfully replace the MSA giving a similar accuracy in performance, while at the same time giving a dramatic increase in speed, hence allowing for large-scale analyses on the proteome level. Interestingly, we tried to replace the NetSurfP-2.0 downstream architecture by the transformer-based architectures described in the methods, and in all cases, when using ESM-1b encodings, we obtained sub-optimal performances. We also tested these models, together with other available similar models, on the new dataset CASP14_FM. The results are shown in Table <xref rid="tbl1" ref-type="table">1</xref>.</p>
      <p>The models compared are NetSurfP version 2.0 and 3.0, Spot-1D-Single (<xref rid="B23" ref-type="bibr">23</xref>) and SPOT-1D-LM (<xref rid="B24" ref-type="bibr">24</xref>). Both SPOT-1D-Single and SPOT-1D-LM do not make use of MSAs in their prediction. Moreover, SPOT-1D-LM uses a combination of different protein LMs to encode the target sequences, thus making it the closest comparison to NetSurfP-3.0. From these results, it appears that NetSurfP-3.0 generates results that are on par with the other tools for secondary structure and solvent accessibility. In particular, when compared with SPOT-1D-LM, it shows better results for phi and psi prediction. Given the similar accuracy displayed by the best performing tools, i.e NetSurfP-2.0, NetSurfP-3.0 and Spot1d-LM, we have also compared such tools in terms of their runtime. The results are shown in Figure <xref rid="F1" ref-type="fig">1</xref>.</p>
      <p>NetSurfP-3.0 is consistently the fastest tool, being able to generate predictions for a thousand proteins in ∼100 s. From the runtime analysis, we see that the two fastest models are NetSurfP-3.0 and SPOT-1D-LM, with the former being 3.8–5.3 times faster than the latter. Both of these tools, after the initial overhead due to the language models being loaded into memory, scale very gradually on larger datasets, and their performance is mainly limited by the amount of memory on the device used for predictions.</p>
    </sec>
    <sec id="SEC3-2">
      <title>Interface</title>
      <p>NetSurfP-3.0 can be accessed via a web server. It is sufficient to input the target sequences in FASTA format, either in the text box or upload as a file. Once the job is submitted, it enters a queue. Once the results are ready, they are displayed in the browser. An example of the output is reported in Figure <xref rid="F2" ref-type="fig">2</xref>. For each protein, the predictions are displayed in an easily understandable format, and the individual numeric predicted values can be observed by hovering the cursor over individual residues in the plot. Finally, the results can also be downloaded in different formats, either individually or as a compressed archive for all the predictions.</p>
      <fig position="float" id="F2">
        <label>Figure 2.</label>
        <caption>
          <p>The web interface of NetSurfP-3.0. A graphical representation displays Q3 secondary structure, RSA, and disorder predictions together with the sequence. By hovering on a residue, the user can visualize all predictions. Through the Export menus it is possible to download individual predictions in different file formats, as well as the complete results as a compressed archive.</p>
        </caption>
        <graphic xlink:href="gkac439fig2" position="float"/>
      </fig>
    </sec>
  </sec>
  <sec sec-type="discussion" id="SEC4">
    <title>DISCUSSION</title>
    <p>The NetSurfP-3.0 web server provides state-of-the-art sequence-based predictions for solvent accessibility, secondary structure, disorder, and backbone geometry at an unprecedented speed. This is made possible by the pre-trained ESM-1b language model used to encode the proteins and by replacing the MSAs used in the previous version while retaining similar accuracy. This allows for predictions on complete proteomes in less than an hour. Other works (<xref rid="B24" ref-type="bibr">24</xref>) combine the embeddings from different LMs (<xref rid="B14" ref-type="bibr">14</xref>)(<xref rid="B15" ref-type="bibr">15</xref>), thus obtaining a small increment in accuracy, at the price of a slower run time. While we have focused primarily on the time efficiency of our tool, we believe that, as new and more elaborate LMs are released, it will be of utter importance to test and compare their ability to provide powerful representations of protein sequences for different downstream tasks.</p>
    <p>Our tool is available both as a stand-alone package and as a web server. The web server, thanks to its informative and easy interface, allows the users to access and analyse their results in an intuitive and thorough way.</p>
  </sec>
  <sec sec-type="data-availability" id="SEC5">
    <title>DATA AVAILABILITY</title>
    <p>NetSurfP-3.0 is available both as a web server, and as stand-alone software including datasets at the below URLs. The web server version accepts up to 10 000 sequences with lengths between 10 and 5000 residues each. The maximum number of residues in a job can not exceed 10 000 000.</p>
    <list list-type="bullet">
      <list-item>
        <p>Webserver, DTU: <italic toggle="yes"><ext-link xlink:href="https://services.healthtech.dtu.dk/service.php?NetSurfP-3.0" ext-link-type="uri">https://services.healthtech.dtu.dk/service.php?NetSurfP-3.0</ext-link></italic></p>
      </list-item>
      <list-item>
        <p>Webserver, BioLib: <italic toggle="yes"><ext-link xlink:href="https://dtu.biolib.com/nsp3" ext-link-type="uri">https://dtu.biolib.com/nsp3</ext-link></italic></p>
      </list-item>
    </list>
  </sec>
</body>
<back>
  <sec id="SEC6">
    <title>FUNDING</title>
    <p>M.H.H. acknowledges the Sino-Danish Center [2021]. Funding for open access charge: Internal Funding from the University.</p>
    <p><italic toggle="yes">Conflict of interest statement</italic>. None declared.</p>
  </sec>
  <ref-list id="REF1">
    <title>REFERENCES</title>
    <ref id="B1">
      <label>1.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pereira</surname><given-names>J.</given-names></string-name>, <string-name><surname>Simpkin</surname><given-names>A.J.</given-names></string-name>, <string-name><surname>Hartmann</surname><given-names>M.D.</given-names></string-name>, <string-name><surname>Rigden</surname><given-names>D.J.</given-names></string-name>, <string-name><surname>Keegan</surname><given-names>R.M.</given-names></string-name>, <string-name><surname>Lupas</surname><given-names>A.N.</given-names></string-name></person-group><article-title>High-accuracy protein structure prediction in CASP14</article-title>. <source>Proteins</source>. <year>2021</year>; <volume>89</volume>:<fpage>1687</fpage>–<lpage>1699</lpage>.<pub-id pub-id-type="pmid">34218458</pub-id></mixed-citation>
    </ref>
    <ref id="B2">
      <label>2.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jumper</surname><given-names>J.</given-names></string-name>, <string-name><surname>Evans</surname><given-names>R.</given-names></string-name>, <string-name><surname>Pritzel</surname><given-names>A.</given-names></string-name>, <string-name><surname>Green</surname><given-names>T.</given-names></string-name>, <string-name><surname>Figurnov</surname><given-names>M.</given-names></string-name>, <string-name><surname>Ronneberger</surname><given-names>O.</given-names></string-name>, <string-name><surname>Tunyasuvunakool</surname><given-names>K.</given-names></string-name>, <string-name><surname>Bates</surname><given-names>R.</given-names></string-name>, <string-name><surname>Žídek</surname><given-names>A.</given-names></string-name>, <string-name><surname>Potapenko</surname><given-names>A.</given-names></string-name><etal>et al</etal>.</person-group><article-title>Highly accurate protein structure prediction with AlphaFold</article-title>. <source>Nature</source>. <year>2021</year>; <volume>596</volume>:<fpage>583</fpage>–<lpage>589</lpage>.<pub-id pub-id-type="pmid">34265844</pub-id></mixed-citation>
    </ref>
    <ref id="B3">
      <label>3.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Varadi</surname><given-names>M.</given-names></string-name>, <string-name><surname>Anyango</surname><given-names>S.</given-names></string-name>, <string-name><surname>Deshpande</surname><given-names>M.</given-names></string-name>, <string-name><surname>Nair</surname><given-names>S.</given-names></string-name>, <string-name><surname>Natassia</surname><given-names>C.</given-names></string-name>, <string-name><surname>Yordanova</surname><given-names>G.</given-names></string-name>, <string-name><surname>Yuan</surname><given-names>D.</given-names></string-name>, <string-name><surname>Stroe</surname><given-names>O.</given-names></string-name>, <string-name><surname>Wood</surname><given-names>G.</given-names></string-name>, <string-name><surname>Laydon</surname><given-names>A.</given-names></string-name><etal>et al</etal>.</person-group><article-title>AlphaFold Protein Structure Database: massively expanding the structural coverage of protein-sequence space with high-accuracy models</article-title>. <source>Nucleic Acids Res.</source><year>2022</year>; <volume>50</volume>:<fpage>D439</fpage>–<lpage>D444</lpage>.<pub-id pub-id-type="pmid">34791371</pub-id></mixed-citation>
    </ref>
    <ref id="B4">
      <label>4.</label>
      <mixed-citation publication-type="journal"><collab>UniProt Consortium</collab><article-title>UniProt: the universal protein knowledgebase in 2021</article-title>. <source>Nucleic Acids Res.</source><year>2021</year>; <volume>49</volume>:<fpage>D480</fpage>–<lpage>D489</lpage>.<pub-id pub-id-type="pmid">33237286</pub-id></mixed-citation>
    </ref>
    <ref id="B5">
      <label>5.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rost</surname><given-names>B.</given-names></string-name>, <string-name><surname>Sander</surname><given-names>C.</given-names></string-name>, <string-name><surname>Schneider</surname><given-names>R.</given-names></string-name></person-group><article-title>PHD–an automatic mail server for protein secondary structure prediction</article-title>. <source>Comput. Applic. Biosci.</source><year>1994</year>; <volume>10</volume>:<fpage>53</fpage>–<lpage>60</lpage>.</mixed-citation>
    </ref>
    <ref id="B6">
      <label>6.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Camacho</surname><given-names>C.</given-names></string-name>, <string-name><surname>Coulouris</surname><given-names>G.</given-names></string-name>, <string-name><surname>Avagyan</surname><given-names>V.</given-names></string-name>, <string-name><surname>Ma</surname><given-names>N.</given-names></string-name>, <string-name><surname>Papadopoulos</surname><given-names>J.</given-names></string-name>, <string-name><surname>Bealer</surname><given-names>K.</given-names></string-name>, <string-name><surname>Madden</surname><given-names>T.L.</given-names></string-name></person-group><article-title>BLAST+: architecture and applications</article-title>. <source>BMC Bioinformatics</source>. <year>2009</year>; <volume>10</volume>:<fpage>421</fpage>.<pub-id pub-id-type="pmid">20003500</pub-id></mixed-citation>
    </ref>
    <ref id="B7">
      <label>7.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Edgar</surname><given-names>R.C.</given-names></string-name></person-group><article-title>MUSCLE: multiple sequence alignment with high accuracy and high throughput</article-title>. <source>Nucleic Acids Res.</source><year>2004</year>; <volume>32</volume>:<fpage>1792</fpage>–<lpage>1797</lpage>.<pub-id pub-id-type="pmid">15034147</pub-id></mixed-citation>
    </ref>
    <ref id="B8">
      <label>8.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Katoh</surname><given-names>K.</given-names></string-name>, <string-name><surname>Standley</surname><given-names>D.M.</given-names></string-name></person-group><article-title>MAFFT multiple sequence alignment software version 7: improvements in performance and usability</article-title>. <source>Mol. Biol. Evol.</source><year>2013</year>; <volume>30</volume>:<fpage>772</fpage>–<lpage>780</lpage>.<pub-id pub-id-type="pmid">23329690</pub-id></mixed-citation>
    </ref>
    <ref id="B9">
      <label>9.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Remmert</surname><given-names>M.</given-names></string-name>, <string-name><surname>Biegert</surname><given-names>A.</given-names></string-name>, <string-name><surname>Hauser</surname><given-names>A.</given-names></string-name>, <string-name><surname>Söding</surname><given-names>J.</given-names></string-name></person-group><article-title>HHblits: lightning-fast iterative protein sequence searching by HMM-HMM alignment</article-title>. <source>Nat. Methods</source>. <year>2011</year>; <volume>9</volume>:<fpage>173</fpage>–<lpage>175</lpage>.<pub-id pub-id-type="pmid">22198341</pub-id></mixed-citation>
    </ref>
    <ref id="B10">
      <label>10.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mirdita</surname><given-names>M.</given-names></string-name>, <string-name><surname>Steinegger</surname><given-names>M.</given-names></string-name>, <string-name><surname>Söding</surname><given-names>J.</given-names></string-name></person-group><article-title>MMseqs2 desktop and local web server app for fast, interactive sequence searches</article-title>. <source>Bioinformatics (Oxford, England)</source>. <year>2019</year>; <volume>35</volume>:<fpage>2856</fpage>–<lpage>2858</lpage>.</mixed-citation>
    </ref>
    <ref id="B11">
      <label>11.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Potter</surname><given-names>S.C.</given-names></string-name>, <string-name><surname>Luciani</surname><given-names>A.</given-names></string-name>, <string-name><surname>Eddy</surname><given-names>S.R.</given-names></string-name>, <string-name><surname>Park</surname><given-names>Y.</given-names></string-name>, <string-name><surname>Lopez</surname><given-names>R.</given-names></string-name>, <string-name><surname>Finn</surname><given-names>R.D.</given-names></string-name></person-group><article-title>HMMER web server: 2018 update</article-title>. <source>Nucleic Acids Res.</source><year>2018</year>; <volume>46</volume>:<fpage>W200</fpage>–<lpage>W204</lpage>.<pub-id pub-id-type="pmid">29905871</pub-id></mixed-citation>
    </ref>
    <ref id="B12">
      <label>12.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Urban</surname><given-names>G.</given-names></string-name>, <string-name><surname>Torrisi</surname><given-names>M.</given-names></string-name>, <string-name><surname>Magnan</surname><given-names>C.N.</given-names></string-name>, <string-name><surname>Pollastri</surname><given-names>G.</given-names></string-name>, <string-name><surname>Baldi</surname><given-names>P.</given-names></string-name></person-group><article-title>Protein profiles: Biases and protocols</article-title>. <source>Comput. Struct. Biotechnol. J.</source><year>2020</year>; <volume>18</volume>:<fpage>2281</fpage>–<lpage>2289</lpage>.<pub-id pub-id-type="pmid">32994887</pub-id></mixed-citation>
    </ref>
    <ref id="B13">
      <label>13.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Chowdhary</surname><given-names>K.R.</given-names></string-name></person-group><source>Natural Language Processing</source>. <year>2020</year>; <publisher-loc>India</publisher-loc><publisher-name>Springer</publisher-name><fpage>603</fpage>–<lpage>649</lpage>.</mixed-citation>
    </ref>
    <ref id="B14">
      <label>14.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rives</surname><given-names>A.</given-names></string-name>, <string-name><surname>Meier</surname><given-names>J.</given-names></string-name>, <string-name><surname>Sercu</surname><given-names>T.</given-names></string-name>, <string-name><surname>Goyal</surname><given-names>S.</given-names></string-name>, <string-name><surname>Lin</surname><given-names>Z.</given-names></string-name>, <string-name><surname>Liu</surname><given-names>J.</given-names></string-name>, <string-name><surname>Guo</surname><given-names>D.</given-names></string-name>, <string-name><surname>Ott</surname><given-names>M.</given-names></string-name>, <string-name><surname>Zitnick</surname><given-names>C.L.</given-names></string-name>, <string-name><surname>Ma</surname><given-names>J.</given-names></string-name><etal>et al</etal>.</person-group><article-title>Biological structure and function emerge from scaling unsupervised learning to 250 million protein sequences</article-title>. <source>Proc. Nat. Acad. Sci. U.S.A.</source><year>2021</year>; <volume>118</volume>:<fpage>e2016239118</fpage>.</mixed-citation>
    </ref>
    <ref id="B15">
      <label>15.</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Elnaggar</surname><given-names>A.</given-names></string-name>, <string-name><surname>Heinzinger</surname><given-names>M.</given-names></string-name>, <string-name><surname>Dallago</surname><given-names>C.</given-names></string-name>, <string-name><surname>Rihawi</surname><given-names>G.</given-names></string-name>, <string-name><surname>Wang</surname><given-names>Y.</given-names></string-name>, <string-name><surname>Jones</surname><given-names>L.</given-names></string-name>, <string-name><surname>Gibbs</surname><given-names>T.</given-names></string-name>, <string-name><surname>Feher</surname><given-names>T.</given-names></string-name>, <string-name><surname>Angerer</surname><given-names>C.</given-names></string-name>, <string-name><surname>Steinegger</surname><given-names>M.</given-names></string-name><etal>et al</etal>.</person-group><article-title>ProtTrans: towards cracking the language of life’s code through self-supervised deep learning and high performance computing</article-title>. <year>2021</year>; <comment>arXiv doi:</comment><comment>4 May 2021, preprint: not peer reviewed</comment><uri xlink:href="https://arxiv.org/abs/2007.06225">https://arxiv.org/abs/2007.06225</uri>.</mixed-citation>
    </ref>
    <ref id="B16">
      <label>16.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Klausen</surname><given-names>M.S.</given-names></string-name>, <string-name><surname>Jespersen</surname><given-names>M.C.</given-names></string-name>, <string-name><surname>Nielsen</surname><given-names>H.</given-names></string-name>, <string-name><surname>Jensen</surname><given-names>K.K.</given-names></string-name>, <string-name><surname>Jurtz</surname><given-names>V.I.</given-names></string-name>, <string-name><surname>Sønderby</surname><given-names>C.K.</given-names></string-name>, <string-name><surname>Sommer</surname><given-names>M.O.A.</given-names></string-name>, <string-name><surname>Winther</surname><given-names>O.</given-names></string-name>, <string-name><surname>Nielsen</surname><given-names>M.</given-names></string-name>, <string-name><surname>Petersen</surname><given-names>B.</given-names></string-name><etal>et al</etal>.</person-group><article-title>NetSurfP-2.0: Improved prediction of protein structural features by integrated deep learning</article-title>. <source>Proteins</source>. <year>2019</year>; <volume>87</volume>:<fpage>520</fpage>–<lpage>527</lpage>.<pub-id pub-id-type="pmid">30785653</pub-id></mixed-citation>
    </ref>
    <ref id="B17">
      <label>17.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yang</surname><given-names>Y.</given-names></string-name>, <string-name><surname>Gao</surname><given-names>J.</given-names></string-name>, <string-name><surname>Wang</surname><given-names>J.</given-names></string-name>, <string-name><surname>Heffernan</surname><given-names>R.</given-names></string-name>, <string-name><surname>Hanson</surname><given-names>J.</given-names></string-name>, <string-name><surname>Paliwal</surname><given-names>K.</given-names></string-name>, <string-name><surname>Zhou</surname><given-names>Y.</given-names></string-name></person-group><article-title>Sixty-five years of the long march in protein secondary structure prediction: the final stretch?</article-title>. <source>Brief. Bioinform.</source><year>2018</year>; <volume>19</volume>:<fpage>482</fpage>–<lpage>494</lpage>.<pub-id pub-id-type="pmid">28040746</pub-id></mixed-citation>
    </ref>
    <ref id="B18">
      <label>18.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cuff</surname><given-names>J.A.</given-names></string-name>, <string-name><surname>Barton</surname><given-names>G. J</given-names></string-name></person-group><article-title>Evaluation and improvement of multiple sequence methods for protein secondary structure prediction</article-title>. <source>Proteins</source>. <year>1999</year>; <volume>34</volume>:<fpage>508</fpage>–<lpage>519</lpage>.<pub-id pub-id-type="pmid">10081963</pub-id></mixed-citation>
    </ref>
    <ref id="B19">
      <label>19.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Abriata</surname><given-names>L.A.</given-names></string-name>, <string-name><surname>Tamò</surname><given-names>G.E.</given-names></string-name>, <string-name><surname>Monastyrskyy</surname><given-names>B.</given-names></string-name>, <string-name><surname>Kryshtafovych</surname><given-names>A.</given-names></string-name>, <string-name><surname>Dal Peraro</surname><given-names>M.</given-names></string-name></person-group><article-title>Assessment of hard target modeling in CASP12 reveals an emerging role of alignment-based contact prediction methods</article-title>. <source>Proteins</source>. <year>2018</year>; <volume>86</volume>:<fpage>97</fpage>–<lpage>112</lpage>.<pub-id pub-id-type="pmid">29139163</pub-id></mixed-citation>
    </ref>
    <ref id="B20">
      <label>20.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Suzek</surname><given-names>B.E.</given-names></string-name>, <string-name><surname>Wang</surname><given-names>Y.</given-names></string-name>, <string-name><surname>Huang</surname><given-names>H.</given-names></string-name>, <string-name><surname>McGarvey</surname><given-names>P.B.</given-names></string-name>, <string-name><surname>Wu</surname><given-names>C.H.</given-names></string-name><collab>UniProt Consortium</collab></person-group><article-title>UniRef clusters: a comprehensive and scalable alternative for improving sequence similarity searches</article-title>. <source>Bioinformatics (Oxford, England)</source>. <year>2015</year>; <volume>31</volume>:<fpage>926</fpage>–<lpage>932</lpage>.</mixed-citation>
    </ref>
    <ref id="B21">
      <label>21.</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Paszke</surname><given-names>A.</given-names></string-name>, <string-name><surname>Gross</surname><given-names>S.</given-names></string-name>, <string-name><surname>Massa</surname><given-names>F.</given-names></string-name>, <string-name><surname>Lerer</surname><given-names>A.</given-names></string-name>, <string-name><surname>Bradbury</surname><given-names>J.</given-names></string-name>, <string-name><surname>Chanan</surname><given-names>G.</given-names></string-name>, <string-name><surname>Killeen</surname><given-names>T.</given-names></string-name>, <string-name><surname>Lin</surname><given-names>Z.</given-names></string-name>, <string-name><surname>Gimelshein</surname><given-names>N.</given-names></string-name>, <string-name><surname>Antiga</surname><given-names>L.</given-names></string-name><etal>et al</etal>.</person-group><article-title>PyTorch: an imperative style, high-performance deep learning library</article-title>. <year>2019</year>; <comment>arXiv doi:</comment><comment>3 December 2019, preprint: not peer reviewed</comment><uri xlink:href="https://arxiv.org/abs/1912.01703">https://arxiv.org/abs/1912.01703</uri>.</mixed-citation>
    </ref>
    <ref id="B22">
      <label>22.</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Kingma</surname><given-names>D.P.</given-names></string-name>, <string-name><surname>Ba</surname><given-names>J.</given-names></string-name></person-group><article-title>Adam: a method for stochastic optimization</article-title>. <year>2017</year>; <comment>arXiv doi:</comment><comment>30 January 2017,preprint: not peer reviewed</comment><uri xlink:href="https://arxiv.org/abs/1412.6980">https://arxiv.org/abs/1412.6980</uri>.</mixed-citation>
    </ref>
    <ref id="B23">
      <label>23.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Singh</surname><given-names>J.</given-names></string-name>, <string-name><surname>Litfin</surname><given-names>T.</given-names></string-name>, <string-name><surname>Paliwal</surname><given-names>K.</given-names></string-name>, <string-name><surname>Singh</surname><given-names>J.</given-names></string-name>, <string-name><surname>Hanumanthappa</surname><given-names>A.K.</given-names></string-name>, <string-name><surname>Zhou</surname><given-names>Y.</given-names></string-name></person-group><article-title>SPOT-1D-single: improving the single-sequence-based prediction of protein secondary structure, backbone angles, solvent accessibility and half-sphere exposures using a large training set and ensembled deep learning</article-title>. <source>Bioinformatics (Oxford, England)</source>. <year>2021</year>; <fpage>btab316</fpage>.</mixed-citation>
    </ref>
    <ref id="B24">
      <label>24.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Singh</surname><given-names>J.</given-names></string-name>, <string-name><surname>Paliwal</surname><given-names>K.</given-names></string-name>, <string-name><surname>Singh</surname><given-names>J.</given-names></string-name>, <string-name><surname>Zhou</surname><given-names>Y.</given-names></string-name></person-group><article-title>Reaching alignment-profile-based accuracy in predicting protein secondary and tertiary structural properties without alignment</article-title>. <source>Sci Rep.</source><year>2021</year>; <uri xlink:href="https://www.biorxiv.org/content/10.1101/2021.10.16.464622v1.full">https://doi.org/10.1038/s41598-022-11684-w</uri>.</mixed-citation>
    </ref>
  </ref-list>
</back>
