<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Sci Rep</journal-id>
    <journal-id journal-id-type="iso-abbrev">Sci Rep</journal-id>
    <journal-title-group>
      <journal-title>Scientific Reports</journal-title>
    </journal-title-group>
    <issn pub-type="epub">2045-2322</issn>
    <publisher>
      <publisher-name>Nature Publishing Group UK</publisher-name>
      <publisher-loc>London</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">9381718</article-id>
    <article-id pub-id-type="publisher-id">18205</article-id>
    <article-id pub-id-type="doi">10.1038/s41598-022-18205-9</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Article</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>S-Pred: protein structural property prediction using MSA transformer</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Hong</surname>
          <given-names>Yiyu</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Song</surname>
          <given-names>Jinung</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Ko</surname>
          <given-names>Junsu</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Lee</surname>
          <given-names>Juyong</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Shin</surname>
          <given-names>Woong-Hee</given-names>
        </name>
        <address>
          <email>whshin@scnu.ac.kr</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff3">3</xref>
        <xref ref-type="aff" rid="Aff4">4</xref>
      </contrib>
      <aff id="Aff1"><label>1</label>Arontier Co., Seoul, 06735 Republic of Korea </aff>
      <aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="GRID">grid.412010.6</institution-id><institution-id institution-id-type="ISNI">0000 0001 0707 9039</institution-id><institution>Division of Chemistry and Biochemistry, Department of Chemistry, </institution><institution>Kangwon National University, </institution></institution-wrap>Chuncheon, 24341 Republic of Korea </aff>
      <aff id="Aff3"><label>3</label><institution-wrap><institution-id institution-id-type="GRID">grid.412871.9</institution-id><institution-id institution-id-type="ISNI">0000 0000 8543 5345</institution-id><institution>Department of Chemistry Education, </institution><institution>Sunchon National University, </institution></institution-wrap>Suncheon, 57922 Republic of Korea </aff>
      <aff id="Aff4"><label>4</label><institution-wrap><institution-id institution-id-type="GRID">grid.412871.9</institution-id><institution-id institution-id-type="ISNI">0000 0000 8543 5345</institution-id><institution>Department of Advanced Components and Materials Engineering, </institution><institution>Sunchon National University, </institution></institution-wrap>Suncheon, 57922 Republic of Korea </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>16</day>
      <month>8</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>16</day>
      <month>8</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2022</year>
    </pub-date>
    <volume>12</volume>
    <elocation-id>13891</elocation-id>
    <history>
      <date date-type="received">
        <day>17</day>
        <month>5</month>
        <year>2022</year>
      </date>
      <date date-type="accepted">
        <day>8</day>
        <month>8</month>
        <year>2022</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2022</copyright-statement>
      <license>
        <ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>.</license-p>
      </license>
    </permissions>
    <abstract id="Abs1">
      <p id="Par1">Predicting the local structural features of a protein from its amino acid sequence helps its function prediction to be revealed and assists in three-dimensional structural modeling. As the sequence-structure gap increases, prediction methods have been developed to bridge this gap. Additionally, as the size of the structural database and computing power increase, the performance of these methods have also significantly improved. Herein, we present a powerful new tool called S-Pred, which can predict eight-state secondary structures (SS8), accessible surface areas (ASAs), and intrinsically disordered regions (IDRs) from a given sequence. For feature prediction, S-Pred uses multiple sequence alignment (MSA) of a query sequence as an input. The MSA input is converted to features by the MSA Transformer, which is a protein language model that uses an attention mechanism. A long short-term memory (LSTM) was employed to produce the final prediction. The performance of S-Pred was evaluated on several test sets, and the program consistently provided accurate predictions. The accuracy of the SS8 prediction was approximately 76%, and the Pearson’s correlation between the experimental and predicted ASAs was 0.84. Additionally, an IDR could be accurately predicted with an F1-score of 0.514. The program is freely available at <ext-link ext-link-type="uri" xlink:href="https://github.com/arontier/S_Pred_Paper">https://github.com/arontier/S_Pred_Paper</ext-link> and <ext-link ext-link-type="uri" xlink:href="https://ad3.io">https://ad3.io</ext-link> as a code and a web server.</p>
    </abstract>
    <kwd-group kwd-group-type="npg-subject">
      <title>Subject terms</title>
      <kwd>Structural biology</kwd>
      <kwd>Molecular modelling</kwd>
      <kwd>Machine learning</kwd>
      <kwd>Protein structure predictions</kwd>
    </kwd-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100003725</institution-id>
            <institution>National Research Foundation of Korea</institution>
          </institution-wrap>
        </funding-source>
        <award-id>NRF-2022M3E5F3081268</award-id>
        <award-id>2020R1F1A1075998</award-id>
        <principal-award-recipient>
          <name>
            <surname>Lee</surname>
            <given-names>Juyong</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
    </funding-group>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>© The Author(s) 2022</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="Sec1">
    <title>Introduction</title>
    <p id="Par2">Proteins play an important role in biological processes, and their structures are closely linked to their functions. To characterize their structures, various experimental methods, such as X-ray crystallography, nuclear magnetic resonance spectroscopy, and cryogenic electron microscopy have been employed. However, because experimental protein conformation is difficult to obtain, the gap between the number of experimentally solved protein structures and the number of determined amino acid sequences is gradually increasing<sup><xref ref-type="bibr" rid="CR1">1</xref></sup>. As of February 2022, approximately 225 million sequences have been compiled in the UniProt database<sup><xref ref-type="bibr" rid="CR2">2</xref></sup>, and the structures of 108 thousand unique proteins structures have been deposited in the Protein Data Bank (PDB)<sup><xref ref-type="bibr" rid="CR3">3</xref></sup>. Several protein structure prediction algorithms have been developed and are being routinely utilized to bridge the sequence-structure gap.</p>
    <p id="Par3">Several methods exist for extracting protein structural features from the amino acid sequence, known as the primary structure of proteins, to study its function. In 1961, Anfinsen<sup><xref ref-type="bibr" rid="CR4">4</xref></sup> discovered that a protein's tertiary structure is encoded by its amino acid sequence. Based on this observation, numerous approaches for predicting the structural properties of proteins, such as secondary structures, accessible surface areas (ASAs), and intrinsically disordered regions (IDRs), have been developed<sup><xref ref-type="bibr" rid="CR5">5</xref>–<xref ref-type="bibr" rid="CR17">17</xref></sup>. These features can also be useful for protein structural modeling by providing insights into local structures.</p>
    <p id="Par4">Since the early 2010s, numerous structural feature prediction approaches have been proposed, and as structural datasets expand, machine learning techniques, especially deep learning, have become more powerful. SPOT-1D<sup><xref ref-type="bibr" rid="CR8">8</xref></sup> uses long short-term memory (LSTM) and ResNet hybrid models to predict the eight-state secondary structures (SS8), ASAs, backbone dihedral angles, and contact numbers. The program uses a position-specific scoring matrix (PSSM) from multiple sequence alignment (MSA) and the predicted contact map from SPOT-Contact as input features. SPOT-Disorder<sup><xref ref-type="bibr" rid="CR9">9</xref>,<xref ref-type="bibr" rid="CR10">10</xref></sup> predicts IDRs by employing multiple models sequentially, such as IncReSeNet, LSTM, and fully linked topological segments. The software uses both PSSM and structural information predicted by SPOT-1D to predict the disordered regions. NetSurfP-2.0<sup><xref ref-type="bibr" rid="CR14">14</xref></sup> uses a convolutional neural and LSTM from the protein sequence profile to predict the secondary structures, relative surface areas, IDRs, and backbone dihedral angles. MUFOLD-SS uses inception-inside-inception networks to predict the secondary structure from PSSM and seven physicochemical attributes of amino acids<sup><xref ref-type="bibr" rid="CR16">16</xref></sup>. AUCpreD<sup><xref ref-type="bibr" rid="CR17">17</xref></sup> predicts IDRs using a convolutional neural network, considering seven physicochemical properties of amino acids, predicted secondary structures, solvent-accessible areas, and PSSM as input features.</p>
    <p id="Par5">In this paper, we present a new structural feature prediction method, S-Pred, which uses an LSTM and MSA Transformer<sup><xref ref-type="bibr" rid="CR18">18</xref></sup> for feature extraction from the MSA. The MSA Transformer is an unsupervised protein sequence language model introduced by Rao et al.<sup><xref ref-type="bibr" rid="CR18">18</xref></sup>, which uses the MSA of a query sequence instead of a single amino acid sequence. The key attribute of this model is the use of row and column attentions for a given MSA and masked language model objectives. This model was successful in predicting long-range contacts between residues. Ultimately, this demonstrates that this protein language model is effective in extracting protein properties from MSA profiles. S-Pred uses the extracted features from the MSA Transformer and an LSTM to predict three structural features: SS8s, ASAs, and IDRs. The results indicate that S-Pred successfully predicts structural features accurately, and its performance is comparable to or superior to that of other state-of-the-art programs.</p>
  </sec>
  <sec id="Sec2">
    <title>Methods</title>
    <sec id="Sec3">
      <title>Network architecture</title>
      <p id="Par6">The overall architecture of the algorithm is illustrated in Fig. <xref rid="Fig1" ref-type="fig">1</xref>. The input to the network is the MSA of a query sequence. The MSA is defined as an <inline-formula id="IEq1"><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathrm{r}\times \mathrm{c}$$\end{document}</tex-math><mml:math id="M2"><mml:mrow><mml:mi mathvariant="normal">r</mml:mi><mml:mo>×</mml:mo><mml:mi mathvariant="normal">c</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="41598_2022_18205_Article_IEq1.gif"/></alternatives></inline-formula> matrix, where <inline-formula id="IEq2"><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathrm{r}$$\end{document}</tex-math><mml:math id="M4"><mml:mi mathvariant="normal">r</mml:mi></mml:math><inline-graphic xlink:href="41598_2022_18205_Article_IEq2.gif"/></alternatives></inline-formula> is the number of sequences, and <inline-formula id="IEq3"><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathrm{c}$$\end{document}</tex-math><mml:math id="M6"><mml:mi mathvariant="normal">c</mml:mi></mml:math><inline-graphic xlink:href="41598_2022_18205_Article_IEq3.gif"/></alternatives></inline-formula> is the sequence length. Through the token and position embedding of the MSA Transformer, the matrix is embedded into an <inline-formula id="IEq4"><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathrm{r}\times \mathrm{c}\times 768$$\end{document}</tex-math><mml:math id="M8"><mml:mrow><mml:mi mathvariant="normal">r</mml:mi><mml:mo>×</mml:mo><mml:mi mathvariant="normal">c</mml:mi><mml:mo>×</mml:mo><mml:mn>768</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="41598_2022_18205_Article_IEq4.gif"/></alternatives></inline-formula> tensor, which is the input and output of each attention block<sup><xref ref-type="bibr" rid="CR18">18</xref></sup>. The MSA Transformer is composed of a stack of 12 attention blocks. The attention blocks consist of three layers: two attention layers (row and column attention layer) with 12 attention heads and one feed-forward layer. Herein, for each layer, a normalization operation was performed.<fig id="Fig1"><label>Figure 1</label><caption><p>Architecture of the S-Pred method. The MSA Transformer extracts features and row attention maps from the input MSA of a query sequence. Next, through a series of transformations, the MSA features corresponding to the query sequence and the row attention maps are combined to 1D feature vectors. The 1D feature vectors are then input in an LSTM to predict protein structural properties including, SS8, ASA, and IDR.</p></caption><graphic xlink:href="41598_2022_18205_Fig1_HTML" id="MO1"/></fig></p>
      <p id="Par7">A one-dimensional (1D) feature vector for each residue of a given sequence was generated by extracting two feature types from the MSA Transformer. The first was labelled as MSA features, which is the output tensor of the last attention block with dimensions of <inline-formula id="IEq5"><alternatives><tex-math id="M9">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathrm{r}\times \mathrm{c}\times 768$$\end{document}</tex-math><mml:math id="M10"><mml:mrow><mml:mi mathvariant="normal">r</mml:mi><mml:mo>×</mml:mo><mml:mi mathvariant="normal">c</mml:mi><mml:mo>×</mml:mo><mml:mn>768</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="41598_2022_18205_Article_IEq5.gif"/></alternatives></inline-formula>. From the MSA features, only the row that corresponded to the query sequence was selected, yielding a <inline-formula id="IEq6"><alternatives><tex-math id="M11">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$1\times \mathrm{c}\times 768$$\end{document}</tex-math><mml:math id="M12"><mml:mrow><mml:mn>1</mml:mn><mml:mo>×</mml:mo><mml:mi mathvariant="normal">c</mml:mi><mml:mo>×</mml:mo><mml:mn>768</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="41598_2022_18205_Article_IEq6.gif"/></alternatives></inline-formula> dimensional tensor. The dimension of the tensor was further reduced to <inline-formula id="IEq7"><alternatives><tex-math id="M13">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$1\times \mathrm{c}\times 192$$\end{document}</tex-math><mml:math id="M14"><mml:mrow><mml:mn>1</mml:mn><mml:mo>×</mml:mo><mml:mi mathvariant="normal">c</mml:mi><mml:mo>×</mml:mo><mml:mn>192</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="41598_2022_18205_Article_IEq7.gif"/></alternatives></inline-formula> using a multilayer perceptron (MLP) neural network consisting of three linear layers with 768, 384, and 192 neurons.</p>
      <p id="Par8">The second feature was the row attention map from every attention head. The MSA Transformer is composed of attention layers derived from 12 blocks with 12 attention heads. Thus, 144 attention maps were collated in the shape of a <inline-formula id="IEq8"><alternatives><tex-math id="M15">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathrm{c}\times \mathrm{c}\times 144$$\end{document}</tex-math><mml:math id="M16"><mml:mrow><mml:mi mathvariant="normal">c</mml:mi><mml:mo>×</mml:mo><mml:mi mathvariant="normal">c</mml:mi><mml:mo>×</mml:mo><mml:mn>144</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="41598_2022_18205_Article_IEq8.gif"/></alternatives></inline-formula> tensor. The average pooling operation was applied to the row- and column-wise tensor to obtain <inline-formula id="IEq9"><alternatives><tex-math id="M17">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$1\times \mathrm{c}\times 144$$\end{document}</tex-math><mml:math id="M18"><mml:mrow><mml:mn>1</mml:mn><mml:mo>×</mml:mo><mml:mi mathvariant="normal">c</mml:mi><mml:mo>×</mml:mo><mml:mn>144</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="41598_2022_18205_Article_IEq9.gif"/></alternatives></inline-formula> and <inline-formula id="IEq10"><alternatives><tex-math id="M19">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathrm{c}\times 1\times 144$$\end{document}</tex-math><mml:math id="M20"><mml:mrow><mml:mi mathvariant="normal">c</mml:mi><mml:mo>×</mml:mo><mml:mn>1</mml:mn><mml:mo>×</mml:mo><mml:mn>144</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="41598_2022_18205_Article_IEq10.gif"/></alternatives></inline-formula> tensors. The second tensor was transposed and concatenated with the first to yield a <inline-formula id="IEq11"><alternatives><tex-math id="M21">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$1\times \mathrm{c}\times 288$$\end{document}</tex-math><mml:math id="M22"><mml:mrow><mml:mn>1</mml:mn><mml:mo>×</mml:mo><mml:mi mathvariant="normal">c</mml:mi><mml:mo>×</mml:mo><mml:mn>288</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="41598_2022_18205_Article_IEq11.gif"/></alternatives></inline-formula> tensor.</p>
      <p id="Par9">The aforementioned two features were further concatenated to produce a <inline-formula id="IEq12"><alternatives><tex-math id="M23">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$1\times \mathrm{c}\times 480$$\end{document}</tex-math><mml:math id="M24"><mml:mrow><mml:mn>1</mml:mn><mml:mo>×</mml:mo><mml:mi mathvariant="normal">c</mml:mi><mml:mo>×</mml:mo><mml:mn>480</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="41598_2022_18205_Article_IEq12.gif"/></alternatives></inline-formula> tensor. Consequently, each residue for a given query sequence had a 480-dimensional feature vector. The feature tensors were sequentially proceeded to a set of two LSTM layers with 256 hidden units and a classification layer designed to predict the structural properties of each residue of a protein.</p>
      <p id="Par10">Three independent models were trained for the three structural properties by changing only the output neuron sizes of the final classification layer. Here, the classification layer possessed eight output neurons for SS8 and a single output neuron for ASA and IDR prediction.</p>
    </sec>
    <sec id="Sec4">
      <title>MSA generation</title>
      <p id="Par11">A procedure similar to that used for the MSA Transformer was used to generate the MSA of a query protein<sup><xref ref-type="bibr" rid="CR18">18</xref></sup>. HHblits 3.3.0<sup><xref ref-type="bibr" rid="CR19">19</xref></sup> with the uniclus-ter30_2017_10<sup><xref ref-type="bibr" rid="CR20">20</xref></sup> and BFD<sup><xref ref-type="bibr" rid="CR21">21</xref></sup> databases were used to generate the MSA of the query sequence. The maximum number of sequences used in the MSA was set to 256. If the number of homologous sequences detected by HHblits was greater than the maximum number, 256 sequences were selected by minimizing the diversity.</p>
    </sec>
    <sec id="Sec5">
      <title>Training and inference</title>
      <p id="Par12">The parameters of the MSA Transformer have been fixed and described by Rao et al.<sup><xref ref-type="bibr" rid="CR18">18</xref></sup>. The parameters of the other networks (i.e., MLP, LSTM, and classification layer) were trained using a batch size of 16 with gradient accumulation steps and a learning rate of 1e-3 using the RAdam optimizer<sup><xref ref-type="bibr" rid="CR22">22</xref></sup>. Three independent models were used to individually train the SS8, ASA, and IDR datasets. The SS8, ASA, and IDR datasets were classified as multi-classification, regression, and binary classification, respectively. Thus, three different loss functions were generated including categorical cross-entropy for the SS8 data, mean squared error for the ASA data, and binary cross-entropy for the IDR data. For the ASA dataset, the values were divided by 200 prior to training to make the values smaller. All the models were trained for approximately 15 epochs using an NVIDIA Quadro RTX 8000 graphics processing unit (GPU) (48 GB).</p>
      <p id="Par13">An MSA subsampling strategy was applied during training. This was done not only for data augmentation to train a robust model, but also to prevent the GPU from running out of memory when filled with a large MSA. MSA rows were randomly selected for subsampling, with a maximum of <inline-formula id="IEq13"><alternatives><tex-math id="M25">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${2}^{14}/c$$\end{document}</tex-math><mml:math id="M26"><mml:mrow><mml:msup><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mn>14</mml:mn></mml:msup><mml:mo stretchy="false">/</mml:mo><mml:mi>c</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="41598_2022_18205_Article_IEq13.gif"/></alternatives></inline-formula> and a minimum of 16, to ensure that the query sequences in the first row were always included. Large proteins with a length greater than 1023 residues were discarded during training. The MSA was subsampled with 256 sequences at the inference stage by adding the sequence with the lowest average Hamming distance.</p>
    </sec>
    <sec id="Sec6">
      <title>Datasets for SS8 and ASA</title>
      <p id="Par14">Datasets from Hanson et al.<sup><xref ref-type="bibr" rid="CR8">8</xref></sup> were used to train and test the SS8 and ASA networks. From the PIECES server<sup><xref ref-type="bibr" rid="CR23">23</xref></sup>, 12,450 proteins with a resolution &lt; 2.5 Å, R-free &lt; 1, and sequence identity cutoff of 25% were extracted in February 2017. The proteins were further classified into three datasets: training (10,200 proteins), validation (1000 proteins), and test (1250 proteins) datasets. The authors generated another test set composed of 250 proteins, which were deposited in the PDB<sup><xref ref-type="bibr" rid="CR3">3</xref></sup> between 1/1/2018 and 7/16/2018 under identical conditions of resolution, R-free, and sequence identity. The two test sets were labeled as TEST2016 (collected February 2017) and TEST2018.</p>
      <p id="Par15">In addition, S-Pred’s SS8 prediction module was further tested on the Critical Assessment of protein Structure Prediction 13 (CASP13) dataset. To compare with other programs, the target list was kept the same as the DNSS2 paper<sup><xref ref-type="bibr" rid="CR24">24</xref></sup>. Since the CASP13 was held in 2018 and our training set was culled in Feb. 2017, there is no overlap between the two datasets. The proteins were categorized as template-based modeling (TBM) and free modeling (FM) following the official classification.</p>
    </sec>
    <sec id="Sec7">
      <title>Datasets for IDR</title>
      <p id="Par16">Datasets from the SPOT-Disorder study were used to obtain the IDR prediction model<sup><xref ref-type="bibr" rid="CR9">9</xref></sup>. Zhou et al. collected 4229 proteins from DisProt 5.0<sup><xref ref-type="bibr" rid="CR25">25</xref></sup>, composed of 4157 X-ray crystallography structures and 72 fully disordered proteins. These data were divided into 2700 proteins for training, 300 proteins for validation, and 1229 proteins for testing. Proteins that contained more than 1023 amino acids were eliminated because the MSA Transformer could not treat large proteins. Thus, the remaining 2689 proteins were used for training, 300 proteins were used for validation, and 1225 proteins were used for testing. To compare with methods other than SPOT-Disorder, the IDR prediction model was also tested on three independent datasets: SL250, DisProt228<sup><xref ref-type="bibr" rid="CR10">10</xref></sup>, and the Critical Assessment of Protein Intrinsic Disorder (CAID) dataset<sup><xref ref-type="bibr" rid="CR26">26</xref></sup>. As its name suggests, SL250 is composed of 250 proteins and re-annotated DisProt proteins that include reliable disordered and ordered regions. DisProt228 contains 228 proteins collated from DisProt 7.0 but not included in DisProt 5.0; therefore, the proteins were not included in any training, validation, or test sets. The last dataset used was the CAID<sup><xref ref-type="bibr" rid="CR26">26</xref></sup>. CAID is a blind IDR prediction experiment organized by Dr. Tosatto of Padua University. The dataset was constructed using 646 proteins that were annotated in the DisProt database from June 2018 to November 2018 and have been evaluated using 32 IDR prediction programs. The complete CAID prediction data were collected, and only the sequences predicted by all 33 predictors (32 from CAID and S-Pred) were retained (550 proteins) to provide a reasonable performance comparison.</p>
    </sec>
    <sec id="Sec8">
      <title>AlphaFold2 dataset</title>
      <p id="Par17">The aim of S-Pred is to predict the structural features of a protein from its sequence to study the molecule’s structure and function. In the recent CASP, AlphaFold2<sup><xref ref-type="bibr" rid="CR27">27</xref></sup> (AF2) showed the highest performance, which was around twice as high as the second-placed group<sup><xref ref-type="bibr" rid="CR28">28</xref></sup>. Additionally, the AF2 predicted model is used to resolve the phasing problem in many proteins. Sequence-based structural feature prediction techniques might become obsolete due to AF2's strength. We gathered a dataset called the AF2 dataset to see if S-Pred might provide any further value beyond AF2 prediction. 2176 protein structures deposited in PDB database<sup><xref ref-type="bibr" rid="CR3">3</xref></sup> from 4/26<sup>/</sup>2022 to 6/28/2022 were collected. To remove the redundancy, PIECES server<sup><xref ref-type="bibr" rid="CR23">23</xref></sup> were used with the conditions of sequence identity &lt; 25%, resolution &lt; 2.5 Å, R value &lt; 0.25, and sequence length between 50 and 1000, resulting 263 chains. We searched AlphaFold Protein Structure Database<sup><xref ref-type="bibr" rid="CR29">29</xref></sup> (Accessed 7/12/2022) with the UniProt ID<sup><xref ref-type="bibr" rid="CR2">2</xref></sup> of the chains and downloaded 92 structures. The structural features of predicted structures and corresponding crystal structures were calculated using DSSP<sup><xref ref-type="bibr" rid="CR30">30</xref></sup> and compared with S-Pred prediction results from their sequences. The qualities of models were measured by using TM-align<sup><xref ref-type="bibr" rid="CR31">31</xref></sup>.</p>
    </sec>
    <sec id="Sec9">
      <title>Evaluation metrics and performance comparison</title>
      <p id="Par18">Because the S-Pred method predicts three different features (i.e., SS8, ASA, and IDR), several metrics and methods were utilized to evaluate its performance. For SS8, accuracy was evaluated to compare overall performance against previous data obtained from Hanson et al.<sup><xref ref-type="bibr" rid="CR8">8</xref></sup>, Uddin et al.<sup><xref ref-type="bibr" rid="CR11">11</xref></sup>, and Guo et al<italic>.</italic><sup><xref ref-type="bibr" rid="CR24">24</xref></sup>. To further investigate the performance of S-Pred on each secondary structure state, the precision, recall, and F1-score were calculated for the TEST2016 dataset. Pearson’s correlation coefficient (PCC) was used to assess the performance of the ASA model and was compared with that obtained in the study by Hanson et al.<sup><xref ref-type="bibr" rid="CR8">8</xref></sup>. The IDR model was evaluated by calculating the area under the receiver operating curve (AUC<sub>ROC</sub>), Matthew’s correlation coefficient (MCC), and F1-score. The performance of the S-Pred IDR prediction model was compared with that of several methods presented in the SPOT-Disorder2<sup><xref ref-type="bibr" rid="CR10">10</xref></sup> and CAID studies<sup><xref ref-type="bibr" rid="CR26">26</xref></sup>.</p>
    </sec>
  </sec>
  <sec id="Sec10">
    <title>Results and discussion</title>
    <sec id="Sec11">
      <title>SS8 prediction</title>
      <p id="Par19">The secondary structure of a protein is defined by the local structure of its peptide backbone. In general, the local backbone conformation is categorized into three states (SS3): helix (H), strand (E), and coil (C). Kabsch and Sander<sup><xref ref-type="bibr" rid="CR30">30</xref></sup> introduced a more detailed SS8 classification: α-helix (H), 3<sub>10</sub>-helix (G), π-helix (I), β-strand (E), isolated β-bridge (B), turn (T), bend (S), and others (C). H, G, and I in the SS8 classification correspond to the helix states in SS3, E and B are members of the strand states of SS3, and the remaining (T, S, C) are classified as the coil states of SS3. As the secondary structure provides information on the local conformation, SS8 may provide information for structure prediction that is more useful than the information provided by SS3 when used as a classifier.</p>
      <p id="Par20">The accuracy of the S-Pred method in classifying the validation dataset was 0.780, which is comparable with that of the state-of-the-art SS8 prediction methods, SPOT-1D (0.776)<sup><xref ref-type="bibr" rid="CR8">8</xref></sup> and SAINT (0.782)<sup><xref ref-type="bibr" rid="CR11">11</xref></sup>, using the same training, test, and validation datasets. The SPOT-1D and SAINT programs use identical input features: 50 features of a PSSM derived from PSI-BLAST<sup><xref ref-type="bibr" rid="CR32">32</xref></sup> and HHblits<sup><xref ref-type="bibr" rid="CR19">19</xref></sup>, seven physicochemical properties such as Van der Waal’s volume and polarizability, and a contact prediction map from SPOT-Contact<sup><xref ref-type="bibr" rid="CR33">33</xref></sup>. SPOT-1D operates by employing an ensemble of LSTM networks in a bidirectional recurrent neural network and ResNet hybrid models<sup><xref ref-type="bibr" rid="CR8">8</xref></sup>, whereas SAINT utilizes an ensemble of a self-attention mechanism with Deep3I network<sup><xref ref-type="bibr" rid="CR11">11</xref></sup>. In contrast, S-Pred only requires an MSA constructed from HHblits and uses a single model to predict the SS8s.</p>
      <p id="Par21">The performance of S-Pred on the TEST2016 and TEST2018 datasets for SS8 prediction is presented in Table <xref rid="Tab1" ref-type="table">1</xref>. S-Pred demonstrates a prediction accuracy of 0.776 for the TEST2016 set, which ranks 2nd among the tested methods in SPOT-1D<sup><xref ref-type="bibr" rid="CR8">8</xref></sup> and SAINT<sup><xref ref-type="bibr" rid="CR11">11</xref></sup> papers. The prediction accuracy of S-Pred is similar to that of SAINT, which is the best-performing method, and outperforms the SPOT-1D method. Additionally, S-Pred outperforms SPOT-1D-base, which utilizes an ensemble collection of nine models trained without contact map prediction, and SAINT-base, which uses a single model. With the TEST2018 set, the S-Pred method achieves the highest accuracy (0.764), whereas the accuracy of SAINT is slightly lower (0.761). Interestingly, S-Pred is the best-performing program in terms of the accuracy for SS3 prediction (0.865, Supporting Information Table S1). An example of SS8 prediction using the 7,8-dihydro-8-oxoguanine triphosphatase sequence (PDB ID: 5WS7) from the TEST2016 dataset is illustrated in Fig. <xref rid="Fig2" ref-type="fig">2</xref>.<table-wrap id="Tab1"><label>Table 1</label><caption><p>Comparison of the SS8 accuracy obtained from several methods on the TEST2016 and TEST2018 datasets.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Method</th><th align="left">TEST2016</th><th align="left">TEST2018</th></tr></thead><tbody><tr><td align="left">S-Pred</td><td align="left">0.776</td><td char="." align="char"><bold>0.764</bold></td></tr><tr><td align="left">SPIDER-3-Single<sup>a</sup></td><td align="left">N/A</td><td char="." align="char">0.598</td></tr><tr><td align="left">DNSS2</td><td align="left">N/A</td><td char="." align="char">0.655</td></tr><tr><td align="left">RaptorX<sup>a</sup></td><td align="left">N/A</td><td char="." align="char">0.704</td></tr><tr><td align="left">POTTER-5<sup>a</sup></td><td align="left">N/A</td><td char="." align="char">0.732</td></tr><tr><td align="left">MUFOLD-SS<sup>b</sup></td><td align="left">0.756</td><td char="." align="char">0.737</td></tr><tr><td align="left">NetSurfP-2.0<sup>b</sup></td><td align="left">0.757</td><td char="." align="char">0.730</td></tr><tr><td align="left">SPOT-1D-base<sup>a</sup></td><td align="left">0.760</td><td char="." align="char">0.743</td></tr><tr><td align="left">SPOT-1 Da</td><td align="left">0.771</td><td char="." align="char">0.754</td></tr><tr><td align="left">SAINT-base<sup>b</sup></td><td align="left">0.762</td><td char="." align="char">0.745</td></tr><tr><td align="left">SAINT<sup>b</sup></td><td align="left"><bold>0.777</bold></td><td char="." align="char">0.761</td></tr></tbody></table><table-wrap-foot><p>The data acquired from other methods except DNSS2 were obtained from Hanson et al<italic>.</italic><sup><xref ref-type="bibr" rid="CR8">8</xref></sup> and Uddin et al<italic>.</italic><sup><xref ref-type="bibr" rid="CR11">11</xref></sup>. The method that performs the best is represented in bold.</p><p><sup>a</sup>Data adapted from Hanson et al.<sup><xref ref-type="bibr" rid="CR8">8</xref></sup>.</p><p><sup>b</sup>Data adapted from Uddin et al.<sup><xref ref-type="bibr" rid="CR11">11</xref></sup>.</p></table-wrap-foot></table-wrap><fig id="Fig2"><label>Figure 2</label><caption><p>S-Pred SS8 predictions mapped on the 7,8-dihydro-8-oxoguanine triphosphatase (PDB ID: 5WS7) structure. The color codes for α-helix (H), 3<sub>10</sub>-helix (G), β-strand (E), turn (T), bend (S), and others (C) are red, orange-red, blue, green, light green, and lime green, respectively. It should be noted that none of the residues were predicted as π-helices (I) or β-bridges (B).</p></caption><graphic xlink:href="41598_2022_18205_Fig2_HTML" id="MO2"/></fig></p>
      <p id="Par22">To provide a better understanding, we further investigated the performance of the individual secondary structure state from the TEST2016 dataset with regards to precision, recall, and F1-score, and the results are presented in Table <xref rid="Tab2" ref-type="table">2</xref>. The F1-score is a harmonic average of the precision and recall, balancing the two metrics, thus widely used for imbalanced data. As can be observed, the S-Pred method performs better than the other methods in predicting four of the eight secondary structure classes (H, E, G, and C). Interestingly, our methodology produces an F1-score higher than 0.6 for states with more than 30,000 residues (H, E, T, and C) in the dataset. For non-ordinary states, such as B, G, I, and S, the program generates F1-scores lower than 0.5. SAINT and SPOT-1D, which use two-dimensional contact map information as the primary additional input features, perform better than S-Pred for non-ordinary secondary structure states. Because the secondary structure is defined by the local hydrogen bond patterns of the backbone, two-dimensional contact map information may be useful in predicting non-ordinary secondary structures. This predictive trend on non-ordinary states was also observed in studies conducted by Wang et al.<sup><xref ref-type="bibr" rid="CR12">12</xref></sup> and Zhang et al.<sup><xref ref-type="bibr" rid="CR13">13</xref></sup> that used deep learning for SS8 prediction. This result suggests that S-Pred may improve its performance when contact information is included.<table-wrap id="Tab2"><label>Table 2</label><caption><p>Precision, recall, and F1-score for individual secondary structure states obtained from the TEST2016 dataset.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" rowspan="2">Label</th><th align="left" colspan="5">Precision</th><th align="left" colspan="5">Recall</th><th align="left" colspan="5">F1-score</th></tr><tr><th align="left">SP<sup>a</sup></th><th align="left">SA<sup>b</sup></th><th align="left">S1<sup>c</sup></th><th align="left">NS<sup>d</sup></th><th align="left">MU<sup>e</sup></th><th align="left">SP<sup>a</sup></th><th align="left">SA<sup>b</sup></th><th align="left">S1<sup>c</sup></th><th align="left">NS<sup>d</sup></th><th align="left">MU<sup>e</sup></th><th align="left">SP<sup>a</sup></th><th align="left">SA<sup>b</sup></th><th align="left">S1<sup>c</sup></th><th align="left">NS<sup>d</sup></th><th align="left">MU<sup>e</sup></th></tr></thead><tbody><tr><td align="left">H (98139)</td><td char="." align="char"><bold>0.886</bold></td><td char="." align="char">0.879</td><td char="." align="char">0.884</td><td char="." align="char">0.885</td><td char="." align="char">0.868</td><td char="." align="char"><bold>0.953</bold></td><td char="." align="char">0.948</td><td char="." align="char">0.941</td><td char="." align="char">0.933</td><td char="." align="char">0.943</td><td char="." align="char"><bold>0.918</bold></td><td char="." align="char">0.912</td><td char="." align="char">0.911</td><td char="." align="char">0.908</td><td char="." align="char">0.904</td></tr><tr><td align="left">B (3018)</td><td char="." align="char">0.660</td><td char="." align="char"><bold>0.760</bold></td><td char="." align="char">0.671</td><td char="." align="char">0.650</td><td char="." align="char">0.609</td><td char="." align="char">0.101</td><td char="." align="char">0.104</td><td char="." align="char">0.097</td><td char="." align="char">0.070</td><td char="." align="char"><bold>0.115</bold></td><td char="." align="char">0.176</td><td char="." align="char"><bold>0.183</bold></td><td char="." align="char">0.169</td><td char="." align="char">0.126</td><td char="." align="char">0.193</td></tr><tr><td align="left">E (62657)</td><td char="." align="char"><bold>0.859</bold></td><td char="." align="char">0.843</td><td char="." align="char">0.852</td><td char="." align="char">0.822</td><td char="." align="char">0.850</td><td char="." align="char">0.874</td><td char="." align="char">0.887</td><td char="." align="char">0.878</td><td char="." align="char"><bold>0.903</bold></td><td char="." align="char">0.842</td><td char="." align="char"><bold>0.866</bold></td><td char="." align="char">0.864</td><td char="." align="char">0.865</td><td char="." align="char">0.861</td><td char="." align="char">0.846</td></tr><tr><td align="left">G (10770)</td><td char="." align="char"><bold>0.588</bold></td><td char="." align="char">0.581</td><td char="." align="char">0.547</td><td char="." align="char">0.536</td><td char="." align="char">0.519</td><td char="." align="char"><bold>0.394</bold></td><td char="." align="char">0.390</td><td char="." align="char">0.375</td><td char="." align="char">0.334</td><td char="." align="char">0.348</td><td char="." align="char"><bold>0.471</bold></td><td char="." align="char">0.467</td><td char="." align="char">0.445</td><td char="." align="char">0.412</td><td char="." align="char">0.417</td></tr><tr><td align="left">I (47)</td><td char="." align="char">0.235</td><td char="." align="char"><bold>1.000</bold></td><td char="." align="char"><bold>1.000</bold></td><td char="." align="char">0.044</td><td char="." align="char">0.857</td><td char="." align="char">0.085</td><td char="." align="char"><bold>0.447</bold></td><td char="." align="char">0.128</td><td char="." align="char">0.426</td><td char="." align="char">0.383</td><td char="." align="char">0.125</td><td char="." align="char"><bold>0.618</bold></td><td char="." align="char">0.227</td><td char="." align="char">0.079</td><td char="." align="char">0.529</td></tr><tr><td align="left">T (32297)</td><td char="." align="char">0.622</td><td char="." align="char"><bold>0.663</bold></td><td char="." align="char">0.641</td><td char="." align="char">0.615</td><td char="." align="char">0.631</td><td char="." align="char"><bold>0.648</bold></td><td char="." align="char">0.618</td><td char="." align="char">0.612</td><td char="." align="char">0.585</td><td char="." align="char">0.586</td><td char="." align="char">0.635</td><td char="." align="char"><bold>0.639</bold></td><td char="." align="char">0.626</td><td char="." align="char">0.599</td><td char="." align="char">0.608</td></tr><tr><td align="left">S (23466)</td><td char="." align="char"><bold>0.674</bold></td><td char="." align="char">0.639</td><td char="." align="char">0.624</td><td char="." align="char">0.579</td><td char="." align="char">0.589</td><td char="." align="char">0.286</td><td char="." align="char"><bold>0.367</bold></td><td char="." align="char">0.337</td><td char="." align="char">0.278</td><td char="." align="char">0.313</td><td char="." align="char">0.402</td><td char="." align="char"><bold>0.466</bold></td><td char="." align="char">0.438</td><td char="." align="char">0.376</td><td char="." align="char">0.409</td></tr><tr><td align="left">C (57483)</td><td char="." align="char">0.640</td><td char="." align="char"><bold>0.648</bold></td><td char="." align="char">0.631</td><td char="." align="char">0.613</td><td char="." align="char">0.607</td><td char="." align="char"><bold>0.748</bold></td><td char="." align="char">0.731</td><td char="." align="char">0.741</td><td char="." align="char">0.704</td><td char="." align="char">0.727</td><td char="." align="char"><bold>0.690</bold></td><td char="." align="char">0.687</td><td char="." align="char">0.682</td><td char="." align="char">0.655</td><td char="." align="char">0.662</td></tr></tbody></table><table-wrap-foot><p>The numbers in parentheses represent frequencies of the secondary structure states. The data from all other methods except S-Pred were obtained from Uddin et al.<sup><xref ref-type="bibr" rid="CR11">11</xref></sup>. The method that performs the best is represented in bold.</p><p><sup>a</sup>S-Pred (SP).</p><p><sup>b</sup>SAINT (SA).</p><p><sup>c</sup>SPOT-1D (S1).</p><p><sup>d</sup>NetSurfP-2.0 (NS).</p><p><sup>e</sup>MUFOLD-SS (MU).</p></table-wrap-foot></table-wrap></p>
      <p id="Par23">S-Pred also showed a good performance on the CASP13 benchmark (Table <xref rid="Tab3" ref-type="table">3</xref>). Among the tested methods, S-Pred showed the second highest accuracy in the All and TBM category (0.724 and 0.738, respectively), comparable to DNSS2, the top-performed method (0.727 and 0.753 for the All and TBM category). Interestingly, our program performed best in the FM category (0.714), which is composed of proteins with few available templates to model the structure. The difference in accuracy between the TBM and FM categories is only 0.024, the smallest gap among the tested methods. This implies that S-Pred could perform consistently although there are few or no structural templates.<table-wrap id="Tab3"><label>Table 3</label><caption><p>Prediction of SS8 on CASP13 dataset. All values except S-Pred were taken from Guo et al.<sup><xref ref-type="bibr" rid="CR24">24</xref></sup>.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Method</th><th align="left">All</th><th align="left">TBM</th><th align="left">FM</th></tr></thead><tbody><tr><td align="left">S-Pred</td><td char="." align="char">0.724</td><td char="." align="char">0.738</td><td char="." align="char"><bold>0.714</bold></td></tr><tr><td align="left">SSPro5.2</td><td char="." align="char">0.644</td><td char="." align="char">0.664</td><td char="." align="char">0.640</td></tr><tr><td align="left">DeepCNF</td><td char="." align="char">0.665</td><td char="." align="char">0.689</td><td char="." align="char">0.653</td></tr><tr><td align="left">MUFOLD</td><td char="." align="char">0.667</td><td char="." align="char">0.684</td><td char="." align="char">0.661</td></tr><tr><td align="left">Porter 5</td><td char="." align="char">0.677</td><td char="." align="char">0.709</td><td char="." align="char">0.657</td></tr><tr><td align="left">DNSS2</td><td char="." align="char"><bold>0.727</bold></td><td char="." align="char"><bold>0.753</bold></td><td char="." align="char">0.710</td></tr></tbody></table><table-wrap-foot><p>The method that performs the best is represented in bold.</p></table-wrap-foot></table-wrap></p>
    </sec>
    <sec id="Sec12">
      <title>ASA prediction</title>
      <p id="Par24">A key structural feature of a protein residue is its ASA. This metric is regarded as a significant factor in protein folding and stability<sup><xref ref-type="bibr" rid="CR34">34</xref></sup>. The ASA metric can be used to classify the residue as buried inside a protein or exposed on the surface. Thus, for protein structure prediction, the ASA metric is crucial in indicating the location of the residue. The S-Pred predictive performance was evaluated by the PCC for the predicted and real ASA values, which were calculated using the DSSP algorithm<sup><xref ref-type="bibr" rid="CR30">30</xref></sup>. The PCC for the validation set was 0.850, which was higher than that of SPOT-1D (0.823) with the same dataset.</p>
      <p id="Par25">Table <xref rid="Tab4" ref-type="table">4</xref> compares the performance on the TEST2016 and TEST2018 datasets. As can be observed, PCC values of S-Pred for the TEST2016 (0.843) and TEST2018 (0.831) datasets are larger in magnitude than the PCCs obtained from the other computational methods on the same datasets. Similar to the validation set, S-Pred produces larger PCCs than SPOT-1D. However, unlike SPOT-1D, which requires PSSM as well as physicochemical features and contact map information, S-Pred only requires an MSA from HHblits and provides improved performance. Zhou et al. compared the performance of the retrained SPIDER3 and SPOT-1D algorithms by calculating PCCs on the same training set<sup><xref ref-type="bibr" rid="CR8">8</xref></sup> because the size of the SPOT-1D training set is twice as large as that of SPIDER3 (4590 proteins). The PCC obtained from SPIDER3 increased to 0.796, from 0.76, but was still lower than that obtained from S-Pred. NetSurfP-2.0, which uses an MSA from HHblits<sup><xref ref-type="bibr" rid="CR14">14</xref></sup> similar to S-Pred, also generates lower PCCs than our computational method. An example of ASAs predicted by S-Pred is displayed on chain A of PDB ID 6FC6, the nuclear fusion protein BIK1, from TEST2018 (Fig. <xref rid="Fig3" ref-type="fig">3</xref>).<table-wrap id="Tab4"><label>Table 4</label><caption><p>Prediction of ASAs and comparison among methods.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Method</th><th align="left">TEST2016</th><th align="left">TEST2018</th></tr></thead><tbody><tr><td align="left">S-Pred</td><td align="left"><bold>0.843</bold></td><td char="." align="char"><bold>0.831</bold></td></tr><tr><td align="left">SPIDER-3</td><td align="left">0.787</td><td char="." align="char">0.768</td></tr><tr><td align="left">NetSurfP-2.0</td><td align="left">N/A</td><td char="." align="char">0.801</td></tr><tr><td align="left">SPOT-1D-base</td><td align="left">0.813</td><td char="." align="char">0.799</td></tr><tr><td align="left">SPOT-1D</td><td align="left">0.816</td><td char="." align="char">0.803</td></tr></tbody></table><table-wrap-foot><p>PCCs between the predicted and experimental values. The PCCs obtained from methods except S-Pred were used from the study conducted by Hanson et al.<sup><xref ref-type="bibr" rid="CR8">8</xref></sup>. The method that performs the best is represented in bold.</p></table-wrap-foot></table-wrap><fig id="Fig3"><label>Figure 3</label><caption><p>S-Pred ASA predictions mapped on the structure of nuclear fusion protein BIK1 (PDB ID: 6FC6). The residues are represented using a gradient color scale from cyan (buried) to maroon (exposed).</p></caption><graphic xlink:href="41598_2022_18205_Fig3_HTML" id="MO3"/></fig></p>
      <p id="Par26">SPOT-1D is an improvement on the SPOT-1D-base method because it incorporates the contact map information from SPOT-Contact. As the contact information contains the number of residues surrounding the target amino acid, it may provide additional information on ASAs. This implies that the performance of S-Pred in predicting ASAs can potentially be improved if the contact information is used as a supplementary input feature.</p>
    </sec>
    <sec id="Sec13">
      <title>IDR prediction</title>
      <p id="Par27">IDRs and intrinsically disordered proteins (IDPs) do not possess fixed three-dimensional structures. IDPs and IDRs are involved in various biological processes because they can adopt multiple conformations and bind to several protein partners. According to a recent study<sup><xref ref-type="bibr" rid="CR35">35</xref></sup>, eukaryotic proteomes are more disordered than other domains, with a 20.5% disordered content. In addition, IDRs are linked to various human diseases, such as cancers and Alzheimer’s disease; therefore, they have been employed as potential drug targets. From a structural prediction perspective, eliminating the IDRs before modeling can be helpful in excluding regions that cannot be successfully modeled. Thus, IDR prediction is crucial for both the biological function prediction and computational modeling of proteins.</p>
      <p id="Par28">The S-Pred model produced AUC<sub>ROC</sub> values of 0.929 and 0.914 for the validation and test sets, respectively. For comparison, two additional independent datasets (i.e., SL250 and DisProt228) were employed (Table <xref rid="Tab5" ref-type="table">5</xref>). The performance of S-Pred on these datasets was evaluated using two metrics, AUC<sub>ROC</sub> and MCC. S-Pred and the other state-of-the-art methods performed comparably on both test sets. For the SL250 set, S-Pred ranked 2nd for both the AUC<sub>ROC</sub> and MCC metrics (0.884 and 0.650, respectively), whereas for the DisProt228 dataset, it ranked 2nd for AUC<sub>ROC</sub> (0.797) and 4th for MCC metrics (0.457). An example of IDR prediction using the DisProt ID DP00874 (actin-related protein 7) is illustrated in Fig. <xref rid="Fig4" ref-type="fig">4</xref>. As can be observed, S-Pred predicts three disordered regions that are in a location similar to that of the annotated regions.<table-wrap id="Tab5"><label>Table 5</label><caption><p>Comparison of IDR predictions by several methods.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Set</th><th align="left">Program</th><th align="left">AUC<sub>ROC</sub></th><th align="left">MCC</th></tr></thead><tbody><tr><td align="left" rowspan="13">SL250</td><td align="left">S-Pred</td><td char="." align="char">0.884</td><td char="." align="char">0.650</td></tr><tr><td align="left">s2D</td><td char="." align="char">0.737</td><td char="." align="char">0.360</td></tr><tr><td align="left">MobiDB-lite</td><td char="." align="char">0.818</td><td char="." align="char">0.534</td></tr><tr><td align="left">DISOPRED2</td><td char="." align="char">0.825</td><td char="." align="char">0.508</td></tr><tr><td align="left">ESpritz-N</td><td char="." align="char">0.833</td><td char="." align="char">0.454</td></tr><tr><td align="left">ESpritz-D</td><td char="." align="char">0.843</td><td char="." align="char">0.555</td></tr><tr><td align="left">DISOPRED3</td><td char="." align="char">0.857</td><td char="." align="char">0.596</td></tr><tr><td align="left">ESpritz-X</td><td char="." align="char">0.859</td><td char="." align="char">0.566</td></tr><tr><td align="left">NetSurfP-2.0</td><td char="." align="char">0.869</td><td char="." align="char">0.572</td></tr><tr><td align="left">ACUpreD</td><td char="." align="char">0.869</td><td char="." align="char">0.605</td></tr><tr><td align="left">SPINE-D</td><td char="." align="char">0.875</td><td char="." align="char">0.599</td></tr><tr><td align="left">SPOT-Disorder</td><td char="." align="char">0.893</td><td char="." align="char">0.629</td></tr><tr><td align="left">SPOT-Disorder2</td><td char="." align="char"><bold>0.901</bold></td><td char="." align="char"><bold>0.679</bold></td></tr><tr><td align="left" rowspan="15">DisProt228</td><td align="left">S-Pred</td><td char="." align="char">0.797</td><td char="." align="char">0.457</td></tr><tr><td align="left">s2D</td><td char="." align="char">0.727</td><td char="." align="char">0.267</td></tr><tr><td align="left">AUCpreD</td><td char="." align="char">0.748</td><td char="." align="char">0.434</td></tr><tr><td align="left">JRONN</td><td char="." align="char">0.753</td><td char="." align="char">0.379</td></tr><tr><td align="left">ESpritz-D</td><td char="." align="char">0.759</td><td char="." align="char">0.379</td></tr><tr><td align="left">MFDp2</td><td char="." align="char">0.768</td><td char="." align="char">0.371</td></tr><tr><td align="left">DISOPRED</td><td char="." align="char">0.771</td><td char="." align="char">0.406</td></tr><tr><td align="left">MobiDB-lite</td><td char="." align="char">0.772</td><td char="." align="char">0.422</td></tr><tr><td align="left">NetSurfP-2.0</td><td char="." align="char">0.774</td><td char="." align="char">0.421</td></tr><tr><td align="left">Espritz-N</td><td char="." align="char">0.776</td><td char="." align="char">0.432</td></tr><tr><td align="left">MFDp</td><td char="." align="char">0.776</td><td char="." align="char">0.357</td></tr><tr><td align="left">SPINE-D</td><td char="." align="char">0.786</td><td char="." align="char">0.423</td></tr><tr><td align="left">SPOT-Disorder</td><td char="." align="char">0.792</td><td char="." align="char">0.462</td></tr><tr><td align="left">ESpritz-X</td><td char="." align="char">0.796</td><td char="." align="char">0.476</td></tr><tr><td align="left">SPOT-Disorder2</td><td char="." align="char"><bold>0.809</bold></td><td char="." align="char"><bold>0.499</bold></td></tr></tbody></table><table-wrap-foot><p>The AUC<sub>ROC</sub> and MCC metrics for methods other than S-Pred were obtained from the study conducted by Hanson et al.<sup><xref ref-type="bibr" rid="CR10">10</xref></sup>. For the DisProt228 dataset, only sequence-profile-based methods are presented. The method that performs the best is represented in bold.</p></table-wrap-foot></table-wrap><fig id="Fig4"><label>Figure 4</label><caption><p>S-Pred IDR prediction for the DisProt ID DP00874 protein. (<bold>A</bold>) DisProt annotations. Disordered annotated residues are highlighted in brown. (<bold>B</bold>) S-Pred prediction. The probability of disorder is represented as a function of the background color intensity. Thus, the higher probability of disorder is portrayed as a darker brown color.</p></caption><graphic xlink:href="41598_2022_18205_Fig4_HTML" id="MO4"/></fig></p>
      <p id="Par29">The top-performing method in both datasets was SPOT-Disorder2. SPOT-Disorder2 is a profile-based IDR prediction method that utilizes PSSM profiles from PSI-BLAST and HHblits<sup><xref ref-type="bibr" rid="CR10">10</xref></sup>. In addition, it also employs 23 structural properties predicted by SPOT-1D (SS8, SS3, four sine and cosine values of backbone dihedral angles (θ, τ, φ, and Ψ), ASA, contact number, and two half-sphere exposure values) as input features<sup><xref ref-type="bibr" rid="CR10">10</xref></sup>. The final prediction of SPOT-Disorder2 is based on a combination of five models. By contrast, S-Pred uses only an MSA as the input feature and a single model. Zhou et al. examined the effects of the structural input features predicted by SPOT-1D<sup><xref ref-type="bibr" rid="CR10">10</xref></sup>. The AUC<sub>ROC</sub> of Model 0 on the Mobi9414 test set was 0.943; however, it reduced to 0.920 when the features from SPOT-1D were omitted. This implies that the performance of S-Pred in IDR prediction can be potentially improved by incorporating structural features from the SS8 and ASA modules.</p>
    </sec>
    <sec id="Sec14">
      <title>CAID IDR prediction</title>
      <p id="Par30">The final benchmark was the CAID experiment. A probability threshold for estimating the IDR residue of each method was optimized to acquire the highest F1-score (<italic>F</italic><sub>max</sub>), the same as in the original benchmark study<sup><xref ref-type="bibr" rid="CR26">26</xref></sup>. After relabeling the residues with the thresholds, all metrics were examined. Table <xref rid="Tab6" ref-type="table">6</xref> presents the results obtained from the CAID experiment. As can be observed, among the 33 predictors, S-Pred ranks 2nd for all metrics: 0.514, 0.791, and 0.384 for the F1-score, AUC<sub>ROC</sub>, and MCC, respectively. The top-performing method is fIDPnn<sup><xref ref-type="bibr" rid="CR15">15</xref></sup>, which is a meta-predictor of DFLpred, DisoRDPbind, and fMoRFpred using a neural network. Thus, S-Pred is the best performing method among non-meta-predictors.<table-wrap id="Tab6"><label>Table 6</label><caption><p>CAID benchmark results. Raw predictions were obtained from Necci et al.<sup><xref ref-type="bibr" rid="CR26">26</xref></sup>.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Method</th><th align="left">F1-score</th><th align="left">AUC<sub>ROC</sub></th><th align="left">MCC</th></tr></thead><tbody><tr><td align="left">SPred</td><td char="." align="char">0.514</td><td char="." align="char">0.791</td><td char="." align="char">0.384</td></tr><tr><td align="left">fIDPnn</td><td char="." align="char"><bold>0.521</bold></td><td char="." align="char"><bold>0.813</bold></td><td char="." align="char"><bold>0.390</bold></td></tr><tr><td align="left">SPOT-Disorder2</td><td char="." align="char">0.507</td><td char="." align="char">0.780</td><td char="." align="char">0.378</td></tr><tr><td align="left">fIDPln</td><td char="." align="char">0.504</td><td char="." align="char">0.794</td><td char="." align="char">0.367</td></tr><tr><td align="left">SPOT-Disorder</td><td char="." align="char">0.499</td><td char="." align="char">0.769</td><td char="." align="char">0.367</td></tr><tr><td align="left">RawMSA</td><td char="." align="char">0.496</td><td char="." align="char">0.791</td><td char="." align="char">0.357</td></tr><tr><td align="left">SPOT-Disorder-Single</td><td char="." align="char">0.488</td><td char="." align="char">0.769</td><td char="." align="char">0.348</td></tr><tr><td align="left">AUCpreD</td><td char="." align="char">0.483</td><td char="." align="char">0.762</td><td char="." align="char">0.346</td></tr><tr><td align="left">AUCpreD-np</td><td char="." align="char">0.481</td><td char="." align="char">0.761</td><td char="." align="char">0.335</td></tr><tr><td align="left">ESpritz-D</td><td char="." align="char">0.479</td><td char="." align="char">0.775</td><td char="." align="char">0.332</td></tr><tr><td align="left">MobiDB-lite</td><td char="." align="char">0.473</td><td char="." align="char">0.745</td><td char="." align="char">0.325</td></tr><tr><td align="left">IUPred-long</td><td char="." align="char">0.473</td><td char="." align="char">0.752</td><td char="." align="char">0.324</td></tr><tr><td align="left">IUPred2A-short</td><td char="." align="char">0.473</td><td char="." align="char">0.752</td><td char="." align="char">0.324</td></tr><tr><td align="left">Predisorder</td><td char="." align="char">0.472</td><td char="." align="char">0.753</td><td char="." align="char">0.322</td></tr><tr><td align="left">DisoMine</td><td char="." align="char">0.472</td><td char="." align="char">0.771</td><td char="." align="char">0.323</td></tr><tr><td align="left">IsUnstruct</td><td char="." align="char">0.471</td><td char="." align="char">0.756</td><td char="." align="char">0.321</td></tr><tr><td align="left">IUPred-short</td><td char="." align="char">0.471</td><td char="." align="char">0.751</td><td char="." align="char">0.321</td></tr><tr><td align="left">IUPred2A-long</td><td char="." align="char">0.471</td><td char="." align="char">0.751</td><td char="." align="char">0.321</td></tr><tr><td align="left">ESpritz-X</td><td char="." align="char">0.471</td><td char="." align="char">0.752</td><td char="." align="char">0.321</td></tr><tr><td align="left">VSL2B</td><td char="." align="char">0.464</td><td char="." align="char">0.746</td><td char="." align="char">0.311</td></tr><tr><td align="left">DISOPRED-3</td><td char="." align="char">0.463</td><td char="." align="char">0.727</td><td char="." align="char">0.313</td></tr><tr><td align="left">JRONN</td><td char="." align="char">0.454</td><td char="." align="char">0.736</td><td char="." align="char">0.297</td></tr><tr><td align="left">ESpritz-N</td><td char="." align="char">0.447</td><td char="." align="char">0.724</td><td char="." align="char">0.286</td></tr><tr><td align="left">DynaMine</td><td char="." align="char">0.437</td><td char="." align="char">0.719</td><td char="." align="char">0.271</td></tr><tr><td align="left">PyHCA</td><td char="." align="char">0.432</td><td char="." align="char">0.709</td><td char="." align="char">0.264</td></tr><tr><td align="left">FoldUnfold</td><td char="." align="char">0.422</td><td char="." align="char">0.655</td><td char="." align="char">0.249</td></tr><tr><td align="left">DisEMBL-465</td><td char="." align="char">0.413</td><td char="." align="char">0.695</td><td char="." align="char">0.239</td></tr><tr><td align="left">S2D-1</td><td char="." align="char">0.401</td><td char="." align="char">0.668</td><td char="." align="char">0.216</td></tr><tr><td align="left">S2D-2</td><td char="." align="char">0.387</td><td char="." align="char">0.653</td><td char="." align="char">0.192</td></tr><tr><td align="left">DisEMBL-HL</td><td char="." align="char">0.375</td><td char="." align="char">0.657</td><td char="." align="char">0.174</td></tr><tr><td align="left">DisPredict-2</td><td char="." align="char">0.368</td><td char="." align="char">0.634</td><td char="." align="char">0.158</td></tr><tr><td align="left">GlobPlot</td><td char="." align="char">0.358</td><td char="." align="char">0.625</td><td char="." align="char">0.147</td></tr><tr><td align="left">DFLpred</td><td char="." align="char">0.322</td><td char="." align="char">0.411</td><td char="." align="char">-0.029</td></tr></tbody></table><table-wrap-foot><p>The threshold value of each method for labeling IDR residues was optimized to obtain a <italic>F</italic><sub>max</sub>. The method that performs the best is represented in bold.</p></table-wrap-foot></table-wrap></p>
      <p id="Par31">The organizers of the CAID experiment also tested the predictors to determine whether they could predict fully disordered proteins, also referred to as IDPs. IDPs are targets of interest because they are difficult to be structurally characterized experimentally, but they possess unique biological functions. In the CAID benchmark set, proteins were considered as IDPs if the percentage of disordered annotated residues was higher than 95%. Using these criteria, 41 of 550 proteins were labeled as IDPs. Under the same conditions, the IDR prediction program predicted IDPs after labeling all amino acids as an input. The performance of the IDP prediction is presented in Supporting Information Table S2. As can be observed, S-Pred provides the most accurate IDP prediction (F1-score: 0.637; MCC: 0.609). Even if a more rigid IDP definition (99%) is used, the result does not substantially change. S-Pred is still the best IDP predictor with an F1-score and MCC of 0.652 and 0.624, respectively.</p>
    </sec>
    <sec id="Sec15">
      <title>Comparison with AF2 models</title>
      <p id="Par32">To investigate whether S-Pred could still provide valuable information beyond AF2, the most powerful tertiary structure prediction method, we collected 92 crystal structures from PDB that do not share high sequence identities (&lt; 25%). S-Pred predicted SS8 and ASA from their UniProt sequences and compared them with AF2 models extracted from AlphaFold Protein Structure Database.</p>
      <p id="Par33">S-Pred reported that ASA PCC was 0.844 and SS8 accuracy was 0.778. In contrast, AF2 models outperformed S-Pred, scoring 0.900 and 0.915 for ASA PCC and SS8 accuracy, respectively. It is natural that AF2 has higher accuracy than S-Pred since AF2 might infer structural information from templates and contact maps, while S-Pred only has MSA as an input without structural information. When we examine the individual proteins, S-Pred performed better than AF2 in 7 (SS8) and 18 (ASA) cases out of 92 proteins. It's interesting to note that the AF2 models for the proteins that S-Pred surpassed are not very accurate. The seven proteins with greater S-Pred SS8 predictions have an average TM-score of 0.747, while the remaining proteins have an average TM-score of 0.959. The 18 proteins that S-Pred outperformed in ASA prediction have an average TM-score of 0.841, compared to 0.968 for the other proteins. In four protein cases, S-Pred performed better in both SS8 and ASA than AF2 models. The four proteins have a mean TM-score of 0.682, while the other proteins have an average TM-score of 0.955. This result implies that the quality of AF2 models might be improved by S-Pred prediction.</p>
      <p id="Par34">In addition, even though the AF2 model has improved accuracy, S-Pred is still valuable due of its quickness. S-Pred takes roughly 10 min to complete the input MSA construction for proteins with around 300 amino acids, and less than a second to complete the prediction. On the other hand, AF2 takes around 10 min for modeling and 4 h for MSA with a single GPU<sup><xref ref-type="bibr" rid="CR36">36</xref></sup>. Protein structural characteristics might be quickly predicted and applied to studies like IDP prediction using S-Pred.</p>
    </sec>
  </sec>
  <sec id="Sec16">
    <title>Conclusions</title>
    <p id="Par35">Prediction of the structural properties of proteins from an amino acid sequence can aid in the prediction of the structure and biological function of proteins. In this paper, we report a novel structural feature prediction program called S-Pred. The program utilizes the MSA Transformer to obtain input features and predicts three structural features (SS8, ASA, and IDR) using an LSTM. This study demonstrated that our program successfully predicted all the three features, and the performance was better than or comparable with that of other state-of-the-art algorithms.</p>
    <p id="Par36">The benchmark result also provided useful information for improving the performance. For SS8 prediction, S-Pred failed to predict non-ordinary secondary structure states, such as isolated β-bridges and π-helices. In contrast, the SAINT and SPOT-1D methods successfully predicted these states because contact prediction was used as an input feature. For IDP prediction, SPOT-Disorder2, which demonstrated better performance in both the SL250 and DisProt228 benchmark sets, employed structural features predicted by SPOT-1D. Further studies should investigate approaches to improve the performance of S-Pred by incorporating components or modules from other prediction programs.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Information</title>
    <sec id="Sec17">
      <p>
        <supplementary-material content-type="local-data" id="MOESM1">
          <media xlink:href="41598_2022_18205_MOESM1_ESM.docx">
            <caption>
              <p>Supplementary Information.</p>
            </caption>
          </media>
        </supplementary-material>
      </p>
    </sec>
  </sec>
</body>
<back>
  <fn-group>
    <fn>
      <p>
        <bold>Publisher's note</bold>
      </p>
      <p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
    </fn>
  </fn-group>
  <sec>
    <title>Supplementary Information</title>
    <p>The online version contains supplementary material available at 10.1038/s41598-022-18205-9.</p>
  </sec>
  <ack>
    <title>Acknowledgements</title>
    <p>This research was supported by the Bio &amp; Medical Technology Development Program of the National Research Foundation (NRF) funded by the Korean Government (MSIT) (No. NRF-2022M3E5F3081268). W. H. S. acknowledges support from the NRF of Korea with a Grant funded by the Korean Government (MSIT) (No. 2020R1F1A1075998, 2020R1A4A1016695).</p>
  </ack>
  <notes notes-type="author-contribution">
    <title>Author contributions</title>
    <p>W.H.S. conceived the study. Y.H. developed the algorithm and wrote the code. J.K. generated the MSAs. J.S. collected and performed a benchmark on the AF2 dataset. All authors analyzed the results. W.H.S. and Y.H. drafted the manuscript. W.H.S. edited and finalized the manuscript. All authors have reviewed the manuscript.</p>
  </notes>
  <notes notes-type="data-availability">
    <title>Data availability</title>
    <p>The datasets analyzed during current study are available at <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5281/zenodo.6873654">https://doi.org/10.5281/zenodo.6873654</ext-link>.</p>
  </notes>
  <notes notes-type="data-availability">
    <title>Code availability</title>
    <p>The code can be accessed at <ext-link ext-link-type="uri" xlink:href="https://github.com/arontier/S_Pred_Paper">https://github.com/arontier/S_Pred_Paper</ext-link>.</p>
  </notes>
  <notes id="FPar1" notes-type="COI-statement">
    <title>Competing interests</title>
    <p id="Par37">The authors declare no competing interests.</p>
  </notes>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <label>1.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zheng</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Bell</surname>
            <given-names>EW</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>Y</given-names>
          </name>
        </person-group>
        <article-title>I-TASSER gateway: A protein structure and function prediction server powered by XSEDE</article-title>
        <source>Future Gener. Comput. Syst.</source>
        <year>2019</year>
        <volume>99</volume>
        <fpage>73</fpage>
        <lpage>85</lpage>
        <pub-id pub-id-type="doi">10.1016/j.future.2019.04.011</pub-id>
        <pub-id pub-id-type="pmid">31427836</pub-id>
      </element-citation>
    </ref>
    <ref id="CR2">
      <label>2.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <collab>The UniProt Consortium</collab>
        </person-group>
        <article-title>UniProt: The universal protein knowledgebase in 2021</article-title>
        <source>Nucleic Acids Res.</source>
        <year>2021</year>
        <volume>49</volume>
        <fpage>D480</fpage>
        <lpage>489</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkaa1100</pub-id>
        <pub-id pub-id-type="pmid">33237286</pub-id>
      </element-citation>
    </ref>
    <ref id="CR3">
      <label>3.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Berman</surname>
            <given-names>HM</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>The Protein Data Bank</article-title>
        <source>Nucleic Acids Res.</source>
        <year>2000</year>
        <volume>28</volume>
        <issue>1</issue>
        <fpage>235</fpage>
        <lpage>242</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/28.1.235</pub-id>
        <pub-id pub-id-type="pmid">10592235</pub-id>
      </element-citation>
    </ref>
    <ref id="CR4">
      <label>4.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Anfinsen</surname>
            <given-names>CB</given-names>
          </name>
          <name>
            <surname>Harber</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Sela</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>White</surname>
            <given-names>FH</given-names>
          </name>
        </person-group>
        <article-title>The kinetics of formation of native ribonuclease during oxidation of the reduced polypeptide chain</article-title>
        <source>Proc. Natl. Acad. Sci. USA</source>
        <year>1961</year>
        <volume>47</volume>
        <fpage>1309</fpage>
        <lpage>1314</lpage>
        <pub-id pub-id-type="doi">10.1073/pnas.47.9.1309</pub-id>
        <pub-id pub-id-type="pmid">13683522</pub-id>
      </element-citation>
    </ref>
    <ref id="CR5">
      <label>5.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Drozdetskiy</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Cole</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Procter</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Barton</surname>
            <given-names>GJ</given-names>
          </name>
        </person-group>
        <article-title>JPred4: A protein secondary structure prediction server</article-title>
        <source>Nucleic Acids Res.</source>
        <year>2015</year>
        <volume>43</volume>
        <fpage>W389</fpage>
        <lpage>W394</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkv332</pub-id>
        <pub-id pub-id-type="pmid">25883141</pub-id>
      </element-citation>
    </ref>
    <ref id="CR6">
      <label>6.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Jones</surname>
            <given-names>DT</given-names>
          </name>
        </person-group>
        <article-title>Protein secondary structure prediction based on position-specific scoring matrices</article-title>
        <source>J. Mol. Biol.</source>
        <year>1999</year>
        <volume>292</volume>
        <fpage>195</fpage>
        <lpage>202</lpage>
        <pub-id pub-id-type="doi">10.1006/jmbi.1999.3091</pub-id>
        <pub-id pub-id-type="pmid">10493868</pub-id>
      </element-citation>
    </ref>
    <ref id="CR7">
      <label>7.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Buchan</surname>
            <given-names>DWA</given-names>
          </name>
          <name>
            <surname>Jones</surname>
            <given-names>DT</given-names>
          </name>
        </person-group>
        <article-title>The PSIPRED protein analysis workbench: 20 years on</article-title>
        <source>Nucleic Acids Res.</source>
        <year>2019</year>
        <volume>47</volume>
        <fpage>W402</fpage>
        <lpage>W407</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkz297</pub-id>
        <pub-id pub-id-type="pmid">31251384</pub-id>
      </element-citation>
    </ref>
    <ref id="CR8">
      <label>8.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hanson</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Paliwal</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Litfin</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Zhou</surname>
            <given-names>Y</given-names>
          </name>
        </person-group>
        <article-title>Improving prediction of protein secondary structure, backbone angles, solvent accessibility and contact numbers by using predicted contact maps and an ensemble of recurrent and residual convolutional neural networks</article-title>
        <source>Bioinformatics</source>
        <year>2019</year>
        <volume>35</volume>
        <fpage>2403</fpage>
        <lpage>2410</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/bty1006</pub-id>
        <pub-id pub-id-type="pmid">30535134</pub-id>
      </element-citation>
    </ref>
    <ref id="CR9">
      <label>9.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hanson</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Paliwal</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Zhou</surname>
            <given-names>Y</given-names>
          </name>
        </person-group>
        <article-title>Improving protein disorder prediction by deep bidirectional long short-term memory recurrent neural networks</article-title>
        <source>Bioinformatics</source>
        <year>2017</year>
        <volume>33</volume>
        <fpage>685</fpage>
        <lpage>692</lpage>
        <?supplied-pmid 28011771?>
        <pub-id pub-id-type="pmid">28011771</pub-id>
      </element-citation>
    </ref>
    <ref id="CR10">
      <label>10.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hanson</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Paliwal</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Litfin</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Zhou</surname>
            <given-names>Y</given-names>
          </name>
        </person-group>
        <article-title>SPOT-disorder 2: Improved protein intrinsic disorder prediction by ensembled deep learning</article-title>
        <source>Genom. Proteom. Bioinform.</source>
        <year>2019</year>
        <volume>17</volume>
        <issue>6</issue>
        <fpage>645</fpage>
        <lpage>656</lpage>
        <pub-id pub-id-type="doi">10.1016/j.gpb.2019.01.004</pub-id>
      </element-citation>
    </ref>
    <ref id="CR11">
      <label>11.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Uddin</surname>
            <given-names>MR</given-names>
          </name>
          <name>
            <surname>Mahbub</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Rahman</surname>
            <given-names>MS</given-names>
          </name>
          <name>
            <surname>Bayzid</surname>
            <given-names>MS</given-names>
          </name>
        </person-group>
        <article-title>SAINT: Self-attention augmented inception-inside-inception network improves protein secondary structure prediction</article-title>
        <source>Bioinformatics</source>
        <year>2020</year>
        <volume>36</volume>
        <fpage>4599</fpage>
        <lpage>4608</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btaa531</pub-id>
        <pub-id pub-id-type="pmid">32437517</pub-id>
      </element-citation>
    </ref>
    <ref id="CR12">
      <label>12.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wang</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Peng</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Ma</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Xu</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Protein secondary structure prediction using deep convolutional neural fields</article-title>
        <source>Sci. Rep.</source>
        <year>2016</year>
        <volume>6</volume>
        <fpage>18962</fpage>
        <pub-id pub-id-type="doi">10.1038/srep18962</pub-id>
        <?supplied-pmid 26752681?>
        <pub-id pub-id-type="pmid">26752681</pub-id>
      </element-citation>
    </ref>
    <ref id="CR13">
      <label>13.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhang</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Lü</surname>
            <given-names>Q</given-names>
          </name>
        </person-group>
        <article-title>Prediction of 8-state protein secondary structures by a novel deep learning architecture</article-title>
        <source>BMC Bioinform.</source>
        <year>2018</year>
        <volume>19</volume>
        <fpage>293</fpage>
        <pub-id pub-id-type="doi">10.1186/s12859-018-2280-5</pub-id>
      </element-citation>
    </ref>
    <ref id="CR14">
      <label>14.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Klausen</surname>
            <given-names>MS</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>NetSurfP-2.0: Improved prediction of protein structural features by integrated deep learning</article-title>
        <source>Proteins</source>
        <year>2019</year>
        <volume>87</volume>
        <fpage>520</fpage>
        <lpage>527</lpage>
        <pub-id pub-id-type="doi">10.1002/prot.25674</pub-id>
        <pub-id pub-id-type="pmid">30785653</pub-id>
      </element-citation>
    </ref>
    <ref id="CR15">
      <label>15.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hu</surname>
            <given-names>G</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>fIDPnn: Accurate intrinsic disorder prediction with putative propensities of disorder functions</article-title>
        <source>Nat. Commun.</source>
        <year>2021</year>
        <volume>12</volume>
        <fpage>4438</fpage>
        <pub-id pub-id-type="doi">10.1038/s41467-021-24773-7</pub-id>
        <?supplied-pmid 34290238?>
        <pub-id pub-id-type="pmid">34290238</pub-id>
      </element-citation>
    </ref>
    <ref id="CR16">
      <label>16.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Feng</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Sheng</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Xu</surname>
            <given-names>D</given-names>
          </name>
        </person-group>
        <article-title>MUFOLD-SS: New deep inception-inside-inception networks for protein secondary structure prediction</article-title>
        <source>Proteins</source>
        <year>2018</year>
        <volume>86</volume>
        <fpage>592</fpage>
        <lpage>598</lpage>
        <pub-id pub-id-type="doi">10.1002/prot.25487</pub-id>
        <pub-id pub-id-type="pmid">29492997</pub-id>
      </element-citation>
    </ref>
    <ref id="CR17">
      <label>17.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wang</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Ma</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Xu</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>AUCpreD: Proteome-level protein disorder prediction by AUC-maximized deep convolutional neural fields</article-title>
        <source>Bioinformatics</source>
        <year>2016</year>
        <volume>32</volume>
        <fpage>i672</fpage>
        <lpage>i679</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btw446</pub-id>
        <pub-id pub-id-type="pmid">27587688</pub-id>
      </element-citation>
    </ref>
    <ref id="CR18">
      <label>18.</label>
      <mixed-citation publication-type="other">Rao, R. <italic>et al</italic>. MSA Transformer. Preprint at <ext-link ext-link-type="uri" xlink:href="https://www.biorxiv.org/content/10.1101/2021.02.12.430858v1">https://www.biorxiv.org/content/10.1101/2021.02.12.430858v1</ext-link> (2021).</mixed-citation>
    </ref>
    <ref id="CR19">
      <label>19.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Remmert</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Biegert</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Hauser</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Söding</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>HHblits: Lightning-fast iterative protein sequence searching by HMM-HMM alignment</article-title>
        <source>Nat. Methods</source>
        <year>2012</year>
        <volume>9</volume>
        <fpage>173</fpage>
        <lpage>175</lpage>
        <pub-id pub-id-type="doi">10.1038/nmeth.1818</pub-id>
      </element-citation>
    </ref>
    <ref id="CR20">
      <label>20.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Mirdita</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>von den Driesch</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Galiez</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Martin</surname>
            <given-names>MJ</given-names>
          </name>
          <name>
            <surname>Söding</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Steinegger</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>Uniclust databases of clustered and deeply annotated protein sequences and alignments</article-title>
        <source>Nucleic Acids Res.</source>
        <year>2017</year>
        <volume>45</volume>
        <fpage>D170</fpage>
        <lpage>176</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkw1081</pub-id>
        <pub-id pub-id-type="pmid">27899574</pub-id>
      </element-citation>
    </ref>
    <ref id="CR21">
      <label>21.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Steinegger</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Mirdita</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Söding</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Protein-level assembly increases protein sequence recovery from metagenomic samples manyfold</article-title>
        <source>Nat. Methods</source>
        <year>2019</year>
        <volume>16</volume>
        <fpage>603</fpage>
        <lpage>606</lpage>
        <pub-id pub-id-type="doi">10.1038/s41592-019-0437-4</pub-id>
        <pub-id pub-id-type="pmid">31235882</pub-id>
      </element-citation>
    </ref>
    <ref id="CR22">
      <label>22.</label>
      <mixed-citation publication-type="other">Liu, L. <italic>et al</italic>. On the variance of the adaptive learning rate and beyond. <ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1908.03265">https://arxiv.org/abs/1908.03265</ext-link> (2020).</mixed-citation>
    </ref>
    <ref id="CR23">
      <label>23.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wang</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Dunbrack</surname>
            <given-names>RL</given-names>
          </name>
        </person-group>
        <article-title>PISCES: A protein sequence culling server</article-title>
        <source>Bioinformatics</source>
        <year>2003</year>
        <volume>19</volume>
        <fpage>1589</fpage>
        <lpage>1591</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btg224</pub-id>
        <pub-id pub-id-type="pmid">12912846</pub-id>
      </element-citation>
    </ref>
    <ref id="CR24">
      <label>24.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Guo</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Hou</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Cheng</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>DNSS2: Improved ab initio protein secondary structure prediction using advanced deep learning architectures</article-title>
        <source>Proteins</source>
        <year>2021</year>
        <volume>89</volume>
        <fpage>207</fpage>
        <lpage>217</lpage>
        <pub-id pub-id-type="doi">10.1002/prot.26007</pub-id>
        <pub-id pub-id-type="pmid">32893403</pub-id>
      </element-citation>
    </ref>
    <ref id="CR25">
      <label>25.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Piovesan</surname>
            <given-names>D</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>DisProt 7.0: A major update of the database of disordered proteins</article-title>
        <source>Nucleic Acids Res.</source>
        <year>2017</year>
        <volume>45</volume>
        <fpage>D219</fpage>
        <lpage>D227</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkw1056</pub-id>
        <pub-id pub-id-type="pmid">27899601</pub-id>
      </element-citation>
    </ref>
    <ref id="CR26">
      <label>26.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Necci</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Piovesan</surname>
            <given-names>D</given-names>
          </name>
          <collab>CAID Predictors</collab>
          <collab>DisProt Curators</collab>
          <name>
            <surname>Tosatto</surname>
            <given-names>SCE</given-names>
          </name>
        </person-group>
        <article-title>Critical assessment of protein intrinsic disorder prediction</article-title>
        <source>Nat. Methods</source>
        <year>2021</year>
        <volume>18</volume>
        <fpage>472</fpage>
        <lpage>481</lpage>
        <pub-id pub-id-type="doi">10.1038/s41592-021-01117-3</pub-id>
        <pub-id pub-id-type="pmid">33875885</pub-id>
      </element-citation>
    </ref>
    <ref id="CR27">
      <label>27.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Jumper</surname>
            <given-names>J</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Highly accurate protein structure prediction with AlphaFold</article-title>
        <source>Nature</source>
        <year>2021</year>
        <volume>596</volume>
        <fpage>583</fpage>
        <lpage>589</lpage>
        <pub-id pub-id-type="doi">10.1038/s41586-021-03819-2</pub-id>
        <pub-id pub-id-type="pmid">34265844</pub-id>
      </element-citation>
    </ref>
    <ref id="CR28">
      <label>28.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Pereira</surname>
            <given-names>J</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>High-accuracy protein structure prediction in CASP14</article-title>
        <source>Proteins</source>
        <year>2021</year>
        <volume>89</volume>
        <fpage>1687</fpage>
        <lpage>1699</lpage>
        <pub-id pub-id-type="doi">10.1002/prot.26171</pub-id>
        <pub-id pub-id-type="pmid">34218458</pub-id>
      </element-citation>
    </ref>
    <ref id="CR29">
      <label>29.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Varadi</surname>
            <given-names>M</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>AlphaFold Protein Structure Database: Massively expanding the structural coverage of protein-sequence space with high-accurate models</article-title>
        <source>Nucleic Acids Res.</source>
        <year>2022</year>
        <volume>50</volume>
        <fpage>D439</fpage>
        <lpage>D444</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkab1061</pub-id>
        <pub-id pub-id-type="pmid">34791371</pub-id>
      </element-citation>
    </ref>
    <ref id="CR30">
      <label>30.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kabsch</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Sander</surname>
            <given-names>C</given-names>
          </name>
        </person-group>
        <article-title>Dictionary of protein secondary structure: Pattern recognition of hydrogen-bonded geometrical features</article-title>
        <source>Biopolymers</source>
        <year>1983</year>
        <volume>22</volume>
        <fpage>2577</fpage>
        <lpage>2637</lpage>
        <pub-id pub-id-type="doi">10.1002/bip.360221211</pub-id>
        <pub-id pub-id-type="pmid">6667333</pub-id>
      </element-citation>
    </ref>
    <ref id="CR31">
      <label>31.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Skolnick</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>TM-align: A protein structure alignment algorithm based on the TM-score</article-title>
        <source>Nucleic Acids Res.</source>
        <year>2005</year>
        <volume>33</volume>
        <fpage>2302</fpage>
        <lpage>2309</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gki524</pub-id>
        <pub-id pub-id-type="pmid">15849316</pub-id>
      </element-citation>
    </ref>
    <ref id="CR32">
      <label>32.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Altschul</surname>
            <given-names>SF</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Gapped BLAST and PSI-BLAST: A new generation of protein database search programs</article-title>
        <source>Nucleic Acids Res.</source>
        <year>1997</year>
        <volume>25</volume>
        <fpage>3389</fpage>
        <lpage>3402</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/25.17.3389</pub-id>
        <pub-id pub-id-type="pmid">9254694</pub-id>
      </element-citation>
    </ref>
    <ref id="CR33">
      <label>33.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hanson</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Paliwal</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Litfin</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Zhou</surname>
            <given-names>Y</given-names>
          </name>
        </person-group>
        <article-title>Accurate prediction of protein contact maps by coupling residual two-dimensional bidirectional long short-term memory with convolutional neural networks</article-title>
        <source>Bioinformatics</source>
        <year>2018</year>
        <volume>34</volume>
        <fpage>4039</fpage>
        <lpage>4045</lpage>
        <?supplied-pmid 29931279?>
        <pub-id pub-id-type="pmid">29931279</pub-id>
      </element-citation>
    </ref>
    <ref id="CR34">
      <label>34.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ali</surname>
            <given-names>SA</given-names>
          </name>
          <name>
            <surname>Hassan</surname>
            <given-names>MI</given-names>
          </name>
          <name>
            <surname>Islam</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Ahmad</surname>
            <given-names>F</given-names>
          </name>
        </person-group>
        <article-title>A review of methods available to estimate solvent-accessible surface areas of soluble proteins in the folded and unfolded states</article-title>
        <source>Curr. Protein Pept. Sci.</source>
        <year>2014</year>
        <volume>15</volume>
        <fpage>456</fpage>
        <lpage>476</lpage>
        <pub-id pub-id-type="doi">10.2174/1389203715666140327114232</pub-id>
        <pub-id pub-id-type="pmid">24678666</pub-id>
      </element-citation>
    </ref>
    <ref id="CR35">
      <label>35.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Peng</surname>
            <given-names>Z</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Exceptionally abundant exceptions: Comprehensive characterization of intrinsic disorder in all domains of life</article-title>
        <source>Cell. Mol. Life Sci.</source>
        <year>2015</year>
        <volume>72</volume>
        <fpage>137</fpage>
        <lpage>151</lpage>
        <pub-id pub-id-type="doi">10.1007/s00018-014-1661-9</pub-id>
        <pub-id pub-id-type="pmid">24939692</pub-id>
      </element-citation>
    </ref>
    <ref id="CR36">
      <label>36.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Mirdita</surname>
            <given-names>M</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>ColabFold: Making protein folding accessible to all</article-title>
        <source>Nat. Methods</source>
        <year>2022</year>
        <volume>19</volume>
        <fpage>679</fpage>
        <lpage>682</lpage>
        <pub-id pub-id-type="doi">10.1038/s41592-022-01488-1</pub-id>
        <pub-id pub-id-type="pmid">35637307</pub-id>
      </element-citation>
    </ref>
  </ref-list>
</back>
