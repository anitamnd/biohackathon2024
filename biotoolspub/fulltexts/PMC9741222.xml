<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.3 20210610//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1-3.dtd?>
<?SourceDTD.Version 1.3?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Sensors (Basel)</journal-id>
    <journal-id journal-id-type="iso-abbrev">Sensors (Basel)</journal-id>
    <journal-id journal-id-type="publisher-id">sensors</journal-id>
    <journal-title-group>
      <journal-title>Sensors (Basel, Switzerland)</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1424-8220</issn>
    <publisher>
      <publisher-name>MDPI</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">9741222</article-id>
    <article-id pub-id-type="doi">10.3390/s22239205</article-id>
    <article-id pub-id-type="publisher-id">sensors-22-09205</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Article</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>SUREHYP: An Open Source Python Package for Preprocessing Hyperion Radiance Data and Retrieving Surface Reflectance</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0003-0428-5034</contrib-id>
        <name>
          <surname>Miraglio</surname>
          <given-names>Thomas</given-names>
        </name>
        <role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Conceptualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role>
        <role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Formal analysis" vocab-term-identifier="https://credit.niso.org/contributor-roles/formal-analysis/">Formal analysis</role>
        <role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Investigation" vocab-term-identifier="https://credit.niso.org/contributor-roles/investigation/">Investigation</role>
        <role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Methodology" vocab-term-identifier="https://credit.niso.org/contributor-roles/methodology/">Methodology</role>
        <role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Software" vocab-term-identifier="https://credit.niso.org/contributor-roles/software/">Software</role>
        <role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Validation" vocab-term-identifier="https://credit.niso.org/contributor-roles/validation/">Validation</role>
        <role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Visualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/visualization/">Visualization</role>
        <role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Writing – original draft" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-original-draft/">Writing – original draft</role>
        <xref rid="c1-sensors-22-09205" ref-type="corresp">*</xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0002-0151-9037</contrib-id>
        <name>
          <surname>Coops </surname>
          <given-names>Nicholas C.</given-names>
        </name>
      </contrib>
    </contrib-group>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Fuentes</surname>
          <given-names>Sigfredo</given-names>
        </name>
        <role>Academic Editor</role>
      </contrib>
    </contrib-group>
    <aff id="af1-sensors-22-09205">Integrated Remote Sensing Studio, Department of Forest Resources Management, University of British Columbia, 2424 Main Mall, Vancouver, BC V6T 1Z4, Canada</aff>
    <author-notes>
      <corresp id="c1-sensors-22-09205"><label>*</label>Correspondence: <email>tmiragli@mail.ubc.ca</email></corresp>
    </author-notes>
    <pub-date pub-type="epub">
      <day>26</day>
      <month>11</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="collection">
      <month>12</month>
      <year>2022</year>
    </pub-date>
    <volume>22</volume>
    <issue>23</issue>
    <elocation-id>9205</elocation-id>
    <history>
      <date date-type="received">
        <day>20</day>
        <month>10</month>
        <year>2022</year>
      </date>
      <date date-type="accepted">
        <day>24</day>
        <month>11</month>
        <year>2022</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© 2022 by the authors.</copyright-statement>
      <copyright-year>2022</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>).</license-p>
      </license>
    </permissions>
    <abstract>
      <p>Surface reflectance is an essential product from remote sensing Earth observations critical for a wide variety of applications, including consistent land cover mapping and change, and estimation of vegetation attributes. From 2000 to 2017 the Earth Observing-1 Hyperion instrument acquired the first satellite based hyperspectral image archive from space resulting in over 83,138 publicly available images. Hyperion imagery however requires significant preprocessing to derive surface reflectance. SUREHYP is a Python package designed to process batches of Hyperion images, bringing together a number of published algorithms and methods to correct at sensor radiance and derive surface reflectance. In this paper, we present the SUREHYP workflow and demonstrate its application on Hyperion imagery. Results indicate SUREHYP produces flat terrain surface reflectance results comparable to commercially available software, with reflectance values for the whole spectral range almost entirely within 10% of the software’s over a reference target, yet it is publicly available and open source, allowing the exploitation of this valuable hyperspectral archive on a global scale.</p>
    </abstract>
    <kwd-group>
      <kwd>atmospheric correction</kwd>
      <kwd>batch processing</kwd>
      <kwd>satellite</kwd>
    </kwd-group>
    <funding-group>
      <award-group>
        <funding-source>Natural Sciences and Engineering Research Council</funding-source>
        <award-id>BRDV-201-2019-495</award-id>
      </award-group>
      <funding-statement>This work was done as part of the Canadian Airborne Biodiversity Observatory (CABO), funded by the Natural Sciences and Engineering Research Council of Canada (NSERC) / Discovery Frontiers (Grant No. BRDV-201-2019-495).</funding-statement>
    </funding-group>
  </article-meta>
</front>
<body>
  <sec sec-type="intro" id="sec1-sensors-22-09205">
    <title>1. Introduction</title>
    <p>Remote sensing Earth observations are used extensively for the estimation of vegetation attributes and land cover/land cover change monitoring [<xref rid="B1-sensors-22-09205" ref-type="bibr">1</xref>,<xref rid="B2-sensors-22-09205" ref-type="bibr">2</xref>,<xref rid="B3-sensors-22-09205" ref-type="bibr">3</xref>,<xref rid="B4-sensors-22-09205" ref-type="bibr">4</xref>] due to their ability to image large swathes of the Earth surface and revisit sites of interest. Images acquired by satellites equipped with multispectral sensors, such as Landsat [<xref rid="B5-sensors-22-09205" ref-type="bibr">5</xref>], Sentinel-2A/B [<xref rid="B6-sensors-22-09205" ref-type="bibr">6</xref>], or Terra and Aqua [<xref rid="B7-sensors-22-09205" ref-type="bibr">7</xref>] are preprocessed to produce analysis ready data products, facilitating fast and accurate application development [<xref rid="B8-sensors-22-09205" ref-type="bibr">8</xref>]. The first hyperspectral satellite sensor, Hyperion [<xref rid="B9-sensors-22-09205" ref-type="bibr">9</xref>], launched on EO-1 in 2000 acquired images over 17 years, leading to a significant image archive of hyperspectral data [<xref rid="B10-sensors-22-09205" ref-type="bibr">10</xref>]. Hyperion images are distributed as at-satellite radiance data and as a result require significant preprocessing before use, due to a poor calibration of the pushbroom detector leading to along-track striping and the presence of a spectral smile that must be addressed [<xref rid="B11-sensors-22-09205" ref-type="bibr">11</xref>]. In order to derive surface reflectance image-based or physically-based atmospheric correction (AC) methods must then be applied.</p>
    <p>A number of methods have been published to preprocess Hyperion data. Scheffler and Karrasch [<xref rid="B12-sensors-22-09205" ref-type="bibr">12</xref>], for example, evaluated the performances of six destriping algorithms, either distributed as part of the ERDAS Imagine, Environment for Visualizing Images (ENVI) software, or that have to be implemented by users. More recently, Pal et al. [<xref rid="B13-sensors-22-09205" ref-type="bibr">13</xref>] presented a new method based on local statistics to reduce striping in Hyperion images. To estimate surface reflectance, most AC methods used with Hyperion images have relied on processors using radiative transfer models (RTM), such as ATCOR [<xref rid="B14-sensors-22-09205" ref-type="bibr">14</xref>], FLAASH [<xref rid="B15-sensors-22-09205" ref-type="bibr">15</xref>], or other specific algorithms [<xref rid="B16-sensors-22-09205" ref-type="bibr">16</xref>,<xref rid="B17-sensors-22-09205" ref-type="bibr">17</xref>,<xref rid="B18-sensors-22-09205" ref-type="bibr">18</xref>,<xref rid="B19-sensors-22-09205" ref-type="bibr">19</xref>,<xref rid="B20-sensors-22-09205" ref-type="bibr">20</xref>,<xref rid="B21-sensors-22-09205" ref-type="bibr">21</xref>,<xref rid="B22-sensors-22-09205" ref-type="bibr">22</xref>]. However, empirical or analytical methods can also be used: Prieto-Amparan et al. [<xref rid="B23-sensors-22-09205" ref-type="bibr">23</xref>] demonstrated that the empirical line [<xref rid="B24-sensors-22-09205" ref-type="bibr">24</xref>] could be sufficient for biomass estimation of grasslands, and Katkovsky et al. [<xref rid="B25-sensors-22-09205" ref-type="bibr">25</xref>] proposed an algorithm based on the solutions of radiative transfer equations, and demonstrated that its results were in agreement with the FLAASH outputs when used over Hyperion images. Ientilucci and Adler-Golden [<xref rid="B26-sensors-22-09205" ref-type="bibr">26</xref>] presented an overview of various atmospheric correction methods and software dedicated to hyperspectral imagery.</p>
    <p>While many of these approaches have been applied to Hyperion imagery successfully, there is no definite software package available which can guide the user through the entire process of obtaining surface reflectance from the downloaded Hyperion at-sensor radiance. This lack of access to a free and open framework to bring together these published approaches limits the large-scale use of Hyperion data. Indeed, ease of access to remote sensing data is critical for their use by the scientific community, as preprocessing steps may be difficult to implement for non specialists. In the same spirit, Petropoulos and Anagnostopoulos [<xref rid="B27-sensors-22-09205" ref-type="bibr">27</xref>] developed the freely distributed SEVIRI PrePro software to process data from the SEVIRI satellite sensor, and more recently Li et al. [<xref rid="B28-sensors-22-09205" ref-type="bibr">28</xref>] proposed Python and Javascript tools to produce user-ready Landsat images from Google Earth Engine (GEE).</p>
    <p>In this paper, we present SUREHYP, a Python library aggregating multiple methods to preprocess and retrieve surface reflectance from the Hyperion radiance data distributed by the USGS (<ext-link xlink:href="https://earthexplorer.usgs.gov/" ext-link-type="uri">earthexplorer.usgs.gov</ext-link>, accessed 7 February 2022). The framework utilizes GEE and the SMARTS radiative transfer model [<xref rid="B29-sensors-22-09205" ref-type="bibr">29</xref>,<xref rid="B30-sensors-22-09205" ref-type="bibr">30</xref>], both freely available, to perform the AC. Users can also easily adapt it to their specific needs due to the widespread use of Python in the scientific community, and suggest improvements or additional methods to complement the existing ones. The source code is freely available on GitHub (<ext-link xlink:href="https://github.com/tmiraglio/SUREHYP" ext-link-type="uri">tmiraglio/SUREHYP</ext-link>, accessed on 19 October 2022) and the library can be installed as a <monospace>pip</monospace> package.</p>
    <p>This paper presents the methods implemented into SUREHYP for the preprocessing, as well as the AC algorithm available to retrieve surface reflectance. A demonstration case is provided, SUREHYP and FLAASH are used to retrieve surface reflectance and their outputs are compared.</p>
  </sec>
  <sec id="sec2-sensors-22-09205">
    <title>2. Materials and Methods</title>
    <sec id="sec2dot1-sensors-22-09205">
      <title>2.1. Hyperion Data</title>
      <p>The Hyperion sensor used two spectrometers covering the visible and near-infrared (VNIR) and the shortwave-infrared (SWIR), with a four bands of overlap between the VNIR and SWIR arrays. As a result the imagery consists of 242 bands covering the 356–2577 nm range with a spectral bandwidth of 10 nm and a spatial resolution of 30 m. Hyperion data is distributed by the USGS at three different processing levels: L1R, L1Gst, and L1T. The L1R dataset is distributed as HDF4 files, and contains radiometrically-corrected images that are not terrain-corrected. Two spectral bands of a Hyperion L1R dataset are shown in <xref rid="sensors-22-09205-f001" ref-type="fig">Figure 1</xref> and demonstrate a number of preprocessing challenges including the spectral smile and stripping. The L1Gst and L1T datasets are radiometrically- and terrain-corrected images and distributed as GeoTIFF files. However, due to the georeferencing, rows and columns do not correspond to track directions. Along with these datasets, informations pertaining to the acquisition dates and conditions, such as the solar and satellite angles, are available.</p>
    </sec>
    <sec id="sec2dot2-sensors-22-09205">
      <title>2.2. Workflow</title>
      <p>SUREHYP has two main components. First, the framework applies corrections specific to Hyperion, such as desmiling, destriping, and alignment of the VNIR and SWIR bands. The desmiling and destriping are related to the sensor across- and along-track directions, and have to be done on the L1R data. Second, once the sensor radiance is corrected, atmospheric correction can be applied to derive surface reflectance. The workflow of SUREHYP is presented in <xref rid="sensors-22-09205-f002" ref-type="fig">Figure 2</xref>.</p>
    </sec>
    <sec id="sec2dot3-sensors-22-09205">
      <title>2.3. SUREHYP Preprocessing</title>
      <p>Hyperion images are delivered as digital numbers that are converted to radiance values by dividing VNIR bands by 40 and SWIR bands by 80. However only 200 of the 242 bands were actually calibrated, and bands 1 to 7, 58 to 76, and 225 to 242 were unused [<xref rid="B11-sensors-22-09205" ref-type="bibr">11</xref>] and need to be removed before additional processing.</p>
      <sec id="sec2dot3dot1-sensors-22-09205">
        <title>2.3.1. Desmiling</title>
        <p>To correct the spectral smile on Hyperion bands, the across-track illumination correction presented by San and Süzen [<xref rid="B31-sensors-22-09205" ref-type="bibr">31</xref>] is implemented. This method assumes that, after transformation in the Minimum Noise Fraction (MNF [<xref rid="B32-sensors-22-09205" ref-type="bibr">32</xref>]) space, the spectral smile, if present, is visible in the first band of the array. To remove the smile, a polynomial function is fitted on the column means of the first MNF band, and its values are then subtracted to all the rows of the band with Equation (<xref rid="FD1-sensors-22-09205" ref-type="disp-formula">1</xref>):<disp-formula id="FD1-sensors-22-09205"><label>(1)</label><mml:math id="mm1" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></disp-formula>
with <inline-formula><mml:math id="mm2" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup></mml:mrow></mml:math></inline-formula> the desmiled MNF value, <inline-formula><mml:math id="mm3" overflow="scroll"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> the original MNF value, and <inline-formula><mml:math id="mm4" overflow="scroll"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> the value of the polynom for column <italic toggle="yes">i</italic>, row <italic toggle="yes">j</italic>. The corrected MNF array is then transformed back into the radiance space. However, most of the studies using the MNF band 1 were applied over subsets of Hyperion images [<xref rid="B1-sensors-22-09205" ref-type="bibr">1</xref>,<xref rid="B11-sensors-22-09205" ref-type="bibr">11</xref>,<xref rid="B31-sensors-22-09205" ref-type="bibr">31</xref>,<xref rid="B33-sensors-22-09205" ref-type="bibr">33</xref>]; when applied over entire Hyperion images, the impact of the spectral smile may manifest on multiple MNF images (see an example in <xref rid="sensors-22-09205-f003" ref-type="fig">Figure 3</xref>). While not necessarily problematic when only processing single images, as the user can assess which MNF band is most affected by the spectral smile, this becomes a larger issue when processing large batches of Hyperion images as user action is unrealistic. To allow for automatic implementation, an empirical method was developed to automatically identify the smiled band: a polynomial function of degree <italic toggle="yes">d</italic> is fitted to the column means of each MNF band. Then, the polynoms for which the coefficient of order <italic toggle="yes">d</italic> is beyond three standard deviations of the mean value of all coefficients of order <italic toggle="yes">d</italic> are flagged as belonging to a smiled band, and the desmiling can proceed. The degree of the polynomial function can be user defined.</p>
      </sec>
      <sec id="sec2dot3dot2-sensors-22-09205">
        <title>2.3.2. Destriping</title>
        <p>Two destriping methods are available in SUREHYP. The first destriping method is the local destriping presented by Datt et al. [<xref rid="B11-sensors-22-09205" ref-type="bibr">11</xref>]: the mean value <inline-formula><mml:math id="mm5" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>m</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mi>k</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> and the standard deviation <inline-formula><mml:math id="mm6" overflow="scroll"><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> of pixel values at column <italic toggle="yes">i</italic>, band <italic toggle="yes">k</italic> are computed. The outlier columns are detected using Equation (<xref rid="FD2-sensors-22-09205" ref-type="disp-formula">2</xref>):<disp-formula id="FD2-sensors-22-09205"><label>(2)</label><mml:math id="mm7" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mfrac><mml:mrow><mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:msub><mml:mi>m</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>l</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>m</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mi>l</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo>≥</mml:mo><mml:mi>threshold</mml:mi></mml:mrow></mml:mrow></mml:math></disp-formula>
with <inline-formula><mml:math id="mm8" overflow="scroll"><mml:mrow><mml:msub><mml:mi>l</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> a median filter of selectable neighbourhood along the columns, and <inline-formula><mml:math id="mm9" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>h</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>h</mml:mi><mml:mi>o</mml:mi><mml:mi>l</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> a user-defined value. The outlier pixels are then desmiled according to Equation (<xref rid="FD3-sensors-22-09205" ref-type="disp-formula">3</xref>):<disp-formula id="FD3-sensors-22-09205"><label>(3)</label><mml:math id="mm10" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi><mml:mi>k</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>l</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mfrac><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>l</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>m</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>l</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mfrac><mml:msub><mml:mi>m</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></disp-formula>
with <inline-formula><mml:math id="mm11" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi><mml:mi>k</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup></mml:mrow></mml:math></inline-formula> the updated pixel value at row <italic toggle="yes">i</italic>, column <italic toggle="yes">j</italic>, band <italic toggle="yes">k</italic>, <inline-formula><mml:math id="mm12" overflow="scroll"><mml:mrow><mml:msub><mml:mi>l</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> a mean filter of selectable neighbourhood along the columns, and <inline-formula><mml:math id="mm13" overflow="scroll"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> the original pixel values. The dimension of the selected neighbourhood and the threshold are user specified and will vary on an image-to-image basis. For instance, Datt et al. [<xref rid="B11-sensors-22-09205" ref-type="bibr">11</xref>] used a local average of five pixels in the VNIR, and up to 41 in the SWIR, while Scheffler and Karrasch [<xref rid="B12-sensors-22-09205" ref-type="bibr">12</xref>] used local neighbourhoods of 21 and 41 for the VNIR and SWIR, respectively. In order to remove the maximum number of stripes regardless of the width, SUREHYP iteratively lowers the neighbourhood from 21 to 5 for the VNIR and 41 to 5 for the SWIR.</p>
        <p>The second implemented destriping method is described by Pal et al. [<xref rid="B13-sensors-22-09205" ref-type="bibr">13</xref>] and is twofold: first, a global destriping is undergone. For each band <italic toggle="yes">k</italic> in the image, columns means <inline-formula><mml:math id="mm14" overflow="scroll"><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> are computed and the width of the largest trough/crest <inline-formula><mml:math id="mm15" overflow="scroll"><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mi>c</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is measured. To do so automatically, Scipy’s <monospace>find_peaks</monospace> is used, and <inline-formula><mml:math id="mm16" overflow="scroll"><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mi>c</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> if set to the median value of the 20% largest widths, rounded up to the next integer. Then, a Savitzky-Golay filter of width 10<inline-formula><mml:math id="mm17" overflow="scroll"><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mi>c</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and order 2 is applied to the columns means of each band to obtain a smoothed curve <inline-formula><mml:math id="mm18" overflow="scroll"><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>f</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>. The image cleaned of global stripes is obtained with Equation (<xref rid="FD4-sensors-22-09205" ref-type="disp-formula">4</xref>).
<disp-formula id="FD4-sensors-22-09205"><label>(4)</label><mml:math id="mm19" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi><mml:mi>k</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>f</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula></p>
        <p>Finally, local stripes, that do not span entire columns of the image, can be removed. For each band, a 3<inline-formula><mml:math id="mm20" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mo>×</mml:mo><mml:mrow/></mml:mrow></mml:mrow></mml:math></inline-formula>3<inline-formula><mml:math id="mm21" overflow="scroll"><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mi>c</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> moving window is used to compute the local mean <inline-formula><mml:math id="mm22" overflow="scroll"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>C</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi><mml:mo>_</mml:mo><mml:mi>m</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mi>j</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> and standard deviation <inline-formula><mml:math id="mm23" overflow="scroll"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>C</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi><mml:mo>_</mml:mo><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mi>v</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mi>j</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>. Pixels are flagged as outliers according to Equation (<xref rid="FD5-sensors-22-09205" ref-type="disp-formula">5</xref>):<disp-formula id="FD5-sensors-22-09205"><label>(5)</label><mml:math id="mm24" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>C</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi><mml:mo>_</mml:mo><mml:mi>m</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mi>j</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>C</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi><mml:mo>_</mml:mo><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mi>v</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mi>j</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></disp-formula></p>
        <p>If 90% of the pixels in a column of the moving window are flagged as outliers, then the column is flagged as a local stripe and its values replaced by those of <inline-formula><mml:math id="mm25" overflow="scroll"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>C</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi><mml:mo>_</mml:mo><mml:mi>m</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> for these pixels.</p>
      </sec>
      <sec id="sec2dot3dot3-sensors-22-09205">
        <title>2.3.3. Aligning VNIR and SWIR, Georeferencing</title>
        <p>An along-track one pixel shift is present between pixels 128 and 129 of the SWIR array due to the spectrometer design. The VNIR and SWIR spectrometers were also slightly misaligned, leading to incorrect registration between VNIR and SWIR arrays [<xref rid="B34-sensors-22-09205" ref-type="bibr">34</xref>]. The along-track shift is corrected by moving the right-hand side of the SWIR array one pixel up. To correct the registration, Khurshid et al. [<xref rid="B34-sensors-22-09205" ref-type="bibr">34</xref>] used a counter-clockwise rotation of 0.22° of the VNIR array. Alternatively, Thenkabail et al. [<xref rid="B35-sensors-22-09205" ref-type="bibr">35</xref>] proposed the use of the overlapping spectral bands in the VNIR and SWIR to realign the images. SUREHYP implements a mix of both methods. First, the right-hand side of the SWIR is adjusted. Then the VNIR and SWIR bands closest to 925 nm are used to detect spatial features in both images using an Oriented FAST and Rotated BRIEF (ORB) detector [<xref rid="B36-sensors-22-09205" ref-type="bibr">36</xref>], that presents the advantage of being fast, rotation invariant, and resistant to noise. The best 15% matches are used to realign the VNIR and SWIR arrays.</p>
        <p>The georeferencing of the corrected radiance data is similar, and uses the bands from the georeferenced L1T and the corrected L1R data corresponding to 833 nm. The processed radiance image in then saved along with its various acquisition parameters.</p>
      </sec>
    </sec>
    <sec id="sec2dot4-sensors-22-09205">
      <title>2.4. Atmospheric Correction</title>
      <p>Numerous methods exist to implement an atmospheric correction, belonging either to the (i) image-based family (e.g., empirical line) or (ii) physically-based family (using radiative transfer processors). SUREHYP relies on a physically-based method, using the SMARTS radiative transfer model, which has been widely used [<xref rid="B37-sensors-22-09205" ref-type="bibr">37</xref>,<xref rid="B38-sensors-22-09205" ref-type="bibr">38</xref>,<xref rid="B39-sensors-22-09205" ref-type="bibr">39</xref>] and is freely available at <uri xlink:href="https://www.nrel.gov/grid/solar-resource/smarts.html">https://www.nrel.gov/grid/solar-resource/smarts.html</uri> (accessed on 19 October 2022). SMARTS requires several input variables to define the atmosphere and illumination conditions at the time of the image acquisition, including solar angles, acquisition dates, atmosphere water vapor and ozone concentrations, site altitude, or ground slope angle data. While the user can use its own inputs, SUREHYP contains submodules to retrieve these information from the Hyperion metadata, from GEE, or directly from the radiance image when possible. More specifically, the digital elevation model (DEM) and the atmosphere ozone and water vapor contents can be retrieved from GEE using datasets specified by the user. Retrieval of the water vapor concentration can also be done using water vapor absorption bands and a Look-Up Table (LUT) generated with SMARTS.</p>
      <p>If adjacency effects are neglected, top-of-atmosphere (TOA) reflectance <inline-formula><mml:math id="mm26" overflow="scroll"><mml:mrow><mml:msub><mml:mi>ρ</mml:mi><mml:mrow><mml:mi>T</mml:mi><mml:mi>O</mml:mi><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> and the surface reflectance <inline-formula><mml:math id="mm27" overflow="scroll"><mml:mrow><mml:msub><mml:mi>ρ</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>u</mml:mi><mml:mi>r</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> can be derived with Equations (<xref rid="FD6-sensors-22-09205" ref-type="disp-formula">6</xref>) and (<xref rid="FD7-sensors-22-09205" ref-type="disp-formula">7</xref>) [<xref rid="B35-sensors-22-09205" ref-type="bibr">35</xref>,<xref rid="B40-sensors-22-09205" ref-type="bibr">40</xref>]:<disp-formula id="FD6-sensors-22-09205"><label>(6)</label><mml:math id="mm28" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>ρ</mml:mi><mml:mrow><mml:mi>T</mml:mi><mml:mi>O</mml:mi><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>π</mml:mi><mml:mrow/><mml:mi>L</mml:mi><mml:msup><mml:mi>d</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mrow><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>u</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi>z</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:mrow></mml:math></disp-formula>
<disp-formula id="FD7-sensors-22-09205"><label>(7)</label><mml:math id="mm29" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>ρ</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>u</mml:mi><mml:mi>r</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>π</mml:mi><mml:mrow/><mml:mo>(</mml:mo><mml:mi>L</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi><mml:mi>u</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>a</mml:mi><mml:mi>z</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>g</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>g</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>u</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi>z</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mi>i</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>ρ</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>E</mml:mi><mml:mi>g</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:mrow></mml:math></disp-formula>
with <italic toggle="yes">L</italic> the at-satellite radiance, <italic toggle="yes">d</italic> the Earth-Sun distance correction factor, <inline-formula><mml:math id="mm30" overflow="scroll"><mml:mrow><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>u</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> the extraterrestrial irradiance, <inline-formula><mml:math id="mm31" overflow="scroll"><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mi>z</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> the angle of solar incidence, <inline-formula><mml:math id="mm32" overflow="scroll"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>a</mml:mi><mml:mi>z</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> the path radiance, <inline-formula><mml:math id="mm33" overflow="scroll"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi><mml:mi>u</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> the cirrus clouds radiance, <inline-formula><mml:math id="mm34" overflow="scroll"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>g</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> the transmittance along the ground-sensor optical path, <inline-formula><mml:math id="mm35" overflow="scroll"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>g</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> the transmittance along the sun-ground optical path, <inline-formula><mml:math id="mm36" overflow="scroll"><mml:mrow><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mi>i</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> the diffuse irradiance, <inline-formula><mml:math id="mm37" overflow="scroll"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>ρ</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> the local terrain reflectance, and <inline-formula><mml:math id="mm38" overflow="scroll"><mml:mrow><mml:msub><mml:mi>E</mml:mi><mml:mi>g</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> the global irradiance on the ground. <inline-formula><mml:math id="mm39" overflow="scroll"><mml:mrow><mml:msub><mml:mi>E</mml:mi><mml:mi>g</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is null in the case of a flat surface.</p>
      <p>SMARTS gives <inline-formula><mml:math id="mm40" overflow="scroll"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>g</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="mm41" overflow="scroll"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>g</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="mm42" overflow="scroll"><mml:mrow><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>u</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, and the total diffuse irradiance <inline-formula><mml:math id="mm43" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mi>i</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>ρ</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>E</mml:mi><mml:mi>g</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>, while <inline-formula><mml:math id="mm44" overflow="scroll"><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mi>z</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is known through the acquisition parameters. The path radiance, <inline-formula><mml:math id="mm45" overflow="scroll"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>a</mml:mi><mml:mi>z</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> represents the haze radiance within the scene due to aerosols, and <inline-formula><mml:math id="mm46" overflow="scroll"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi><mml:mi>u</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> that of transparent thin cirrus clouds. Preliminary removal of their signal from the image is necessary to perform the AC.</p>
      <sec id="sec2dot4dot1-sensors-22-09205">
        <title>2.4.1. Thin Cirrus and Haze Radiance Correction</title>
        <p>Gao et al. [<xref rid="B41-sensors-22-09205" ref-type="bibr">41</xref>] presented a thin cirrus correction method involving the 1380 nm band and more recently extended it to the 400–2450 nm range [<xref rid="B42-sensors-22-09205" ref-type="bibr">42</xref>]. As Hyperion measures the 1380 nm band, this method was implemented in SUREHYP. From the radiance image, <inline-formula><mml:math id="mm47" overflow="scroll"><mml:mrow><mml:msub><mml:mi>ρ</mml:mi><mml:mrow><mml:mi>T</mml:mi><mml:mi>O</mml:mi><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> is computed and scatterplots of the reflectance at 1380 nm versus the reflectance at other wavelengths are used to derive a slope factor <inline-formula><mml:math id="mm48" overflow="scroll"><mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> Then, the cirrus reflectance is removed using Equation (<xref rid="FD8-sensors-22-09205" ref-type="disp-formula">8</xref>) and the corrected <inline-formula><mml:math id="mm49" overflow="scroll"><mml:mrow><mml:msub><mml:mi>ρ</mml:mi><mml:mrow><mml:mi>T</mml:mi><mml:mi>O</mml:mi><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> is back transformed into at-satellite radiance, with <inline-formula><mml:math id="mm50" overflow="scroll"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi><mml:mi>u</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> removed.
<disp-formula id="FD8-sensors-22-09205"><label>(8)</label><mml:math id="mm51" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi><mml:mi>k</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mfrac><mml:msub><mml:mi>ρ</mml:mi><mml:mrow><mml:mi>T</mml:mi><mml:mi>O</mml:mi><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mn>1380</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mfrac></mml:mrow></mml:mrow></mml:math></disp-formula></p>
        <p>Haze is removed using a dark-object subtraction technique [<xref rid="B43-sensors-22-09205" ref-type="bibr">43</xref>] on the assumption that, provided a scene is large enough, there will be a dark object within the scene whose reflectance over the entire spectrum should be close to zero, and therefore measured radiance from this object should also be close to zero. For each band, the minimum radiance value is stored. Then, as haze is due to scattering within the atmosphere, Chavez [<xref rid="B43-sensors-22-09205" ref-type="bibr">43</xref>] argues that the relative scattering in an atmosphere follows a wavelength powerlaw <inline-formula><mml:math id="mm52" overflow="scroll"><mml:mrow><mml:msup><mml:mi>λ</mml:mi><mml:mi>c</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula>, the <italic toggle="yes">c</italic> coefficient depending on the atmospheric conditions (−4 for a very clear atmosphere, −0.5 for a very hazy one). Therefore, the haze radiance <inline-formula><mml:math id="mm53" overflow="scroll"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>a</mml:mi><mml:mi>z</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> is obtained by fitting a <inline-formula><mml:math id="mm54" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:msup><mml:mi>λ</mml:mi><mml:mi>c</mml:mi></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula> function so as to be as close as possible, and below, the minimum radiance value of each band, and subtracted from the at-satellite radiance.</p>
      </sec>
      <sec id="sec2dot4dot2-sensors-22-09205">
        <title>2.4.2. Image-Based Retrieval of the Water Vapor Concentration</title>
        <p>The image-based water vapor retrieval method implemented in SUREHYP relies on the water vapor absorption bands at 940 and 1120 nm, assuming that the effect of diffuse irradiance around the water absorption bands is negligible. First, a LUT is generated with SMARTS using all known scene parameters and sampling the water vapor concentration over the 0–12 cm range. The LUT links the water vapor concentration with the relative absorption depth, that is, the ratio between the mean radiance at the shoulders around the absorption band and the radiance at the absorption band (see <xref rid="sensors-22-09205-f004" ref-type="fig">Figure 4</xref>).</p>
        <p>The 1120 nm Hyperion band is used by default. However, if the band is saturated, the algorithm switches to the 940 nm band to estimate water vapor content. The scene average water vapor concentration is interpolated from the LUT values for which the relative absorption depths are the closest to that of the image.</p>
      </sec>
      <sec id="sec2dot4dot3-sensors-22-09205">
        <title>2.4.3. Flat and Rough Terrain Atmospheric Corrections</title>
        <p>Once the previous steps have been applied, the flat terrain AC can proceed using SMARTS and Equation (<xref rid="FD7-sensors-22-09205" ref-type="disp-formula">7</xref>). This AC assumes that the pixel terrain is a flat surface, which may be an acceptable hypothesis depending on the spatial resolution of the images and the actual terrain elevation.</p>
        <p>If the pixel locations are heavily sloped, terrain elevation can be taken into account, requiring a DEM. SUREHYP can download a freely available DEM from GEE, or use one provided as input by the user. Terrain elevation, slopes, and slope azimuths are computed, and several SMARTS runs are used to sample the (elevation, slope, slope azimuth) space and build a LUT. The SMARTS outputs are then interpolated to obtain the irradiance values for each pixel, and surface reflectance is derived using Equation (<xref rid="FD7-sensors-22-09205" ref-type="disp-formula">7</xref>). However, rough terrain correction obtained with this equation, which assumes the surface to be Lambertian [<xref rid="B44-sensors-22-09205" ref-type="bibr">44</xref>], may lead to overly bright pixels in the shadowed areas. Various methods exist to account for the bidirectional reflectance distribution function (BRDF) of the surface, Richter et al. [<xref rid="B45-sensors-22-09205" ref-type="bibr">45</xref>] undertook a comparison and concluded that no single method performed the best, however recommended the modified Minnaert approach. From the rough surface reflectance <inline-formula><mml:math id="mm55" overflow="scroll"><mml:mrow><mml:msub><mml:mi>ρ</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>u</mml:mi><mml:mi>g</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, the corrected reflectance <inline-formula><mml:math id="mm56" overflow="scroll"><mml:mrow><mml:msub><mml:mi>ρ</mml:mi><mml:mrow><mml:mi>M</mml:mi><mml:mi>M</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> is obtained using Equation (<xref rid="FD9-sensors-22-09205" ref-type="disp-formula">9</xref>):<disp-formula id="FD9-sensors-22-09205"><label>(9)</label><mml:math id="mm57" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>ρ</mml:mi><mml:mrow><mml:mi>M</mml:mi><mml:mi>M</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>ρ</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>u</mml:mi><mml:mi>g</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mfenced separators="" open="(" close=")"><mml:mfrac><mml:mrow><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mo>(</mml:mo><mml:mi>β</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mi>T</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mfrac></mml:mfenced><mml:mi>b</mml:mi></mml:msup></mml:mrow></mml:mrow></mml:math></disp-formula>
with <inline-formula><mml:math id="mm58" overflow="scroll"><mml:mrow><mml:mi>β</mml:mi></mml:mrow></mml:math></inline-formula> the local solar illumination angle, and <inline-formula><mml:math id="mm59" overflow="scroll"><mml:mrow><mml:msub><mml:mi>β</mml:mi><mml:mi>T</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and <italic toggle="yes">b</italic> set to values as per the set of rules (Equations (<xref rid="FD10-sensors-22-09205" ref-type="disp-formula">10</xref>) and (<xref rid="FD11-sensors-22-09205" ref-type="disp-formula">11</xref>)) given by Richter et al. [<xref rid="B45-sensors-22-09205" ref-type="bibr">45</xref>]
<disp-formula id="FD10-sensors-22-09205"><label>(10)</label><mml:math id="mm60" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>β</mml:mi><mml:mi>T</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfenced separators="" open="{" close=""><mml:mtable><mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mn>20</mml:mn><mml:mtext>°</mml:mtext><mml:mspace width="4.0pt"/><mml:mi>if</mml:mi><mml:mspace width="4.0pt"/><mml:msub><mml:mi>θ</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo>&lt;</mml:mo><mml:mn>45</mml:mn><mml:mtext>°</mml:mtext></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mn>15</mml:mn><mml:mtext>°</mml:mtext><mml:mspace width="4.0pt"/><mml:mi>if</mml:mi><mml:mspace width="4.0pt"/><mml:mn>45</mml:mn><mml:mtext>°</mml:mtext><mml:mo>≤</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo>&lt;</mml:mo><mml:mn>55</mml:mn><mml:mtext>°</mml:mtext></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mn>10</mml:mn><mml:mtext>°</mml:mtext><mml:mspace width="4.0pt"/><mml:mi>else</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mfenced></mml:mrow></mml:mrow></mml:math></disp-formula>
<disp-formula id="FD11-sensors-22-09205"><label>(11)</label><mml:math id="mm61" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>b</mml:mi><mml:mo>=</mml:mo><mml:mfenced separators="" open="{" close=""><mml:mtable><mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:mn>0.5</mml:mn><mml:mspace width="4.0pt"/><mml:mi>for</mml:mi><mml:mspace width="4.pt"/><mml:mi>non</mml:mi><mml:mspace width="4.pt"/><mml:mi>vegetation</mml:mi></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:mn>0.75</mml:mn><mml:mspace width="4.0pt"/><mml:mi>for</mml:mi><mml:mspace width="4.pt"/><mml:mi>vegetation</mml:mi><mml:mspace width="4.pt"/><mml:mi>and</mml:mi><mml:mspace width="4.0pt"/><mml:mi>λ</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>720</mml:mn><mml:mspace width="4.0pt"/><mml:mi>nm</mml:mi></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:mn>0.33</mml:mn><mml:mspace width="4.0pt"/><mml:mi>for</mml:mi><mml:mspace width="4.pt"/><mml:mi>vegetation</mml:mi><mml:mspace width="4.pt"/><mml:mi>and</mml:mi><mml:mspace width="4.0pt"/><mml:mi>λ</mml:mi><mml:mo>≥</mml:mo><mml:mn>720</mml:mn><mml:mspace width="4.0pt"/><mml:mi>nm</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mfenced></mml:mrow></mml:mrow></mml:math></disp-formula>
with <inline-formula><mml:math id="mm62" overflow="scroll"><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> the sun zenith angle, and <inline-formula><mml:math id="mm63" overflow="scroll"><mml:mrow><mml:mi>λ</mml:mi></mml:mrow></mml:math></inline-formula> the wavelength. Finally, the surface reflectance image is saved.</p>
      </sec>
    </sec>
    <sec id="sec2dot5-sensors-22-09205">
      <title>2.5. Reflectance Retrieval Comparison</title>
      <p>As a demonstration case, SUREHYP and FLAASH are applied on Hyperion image EO1H0110262016254110KF, acquired over Québec, Canada in September 2016 (see <xref rid="sensors-22-09205-f005" ref-type="fig">Figure 5</xref>) at 12 h 50 GMT. This image contains water bodies (Saint Laurent River and lake Matapédia), small urbans areas, agricultural fields, forests, and has an elevation range of 0–500 m. This variety of land cover types made it a good candidate for comparison purposes, as urban areas, crop fields, and forests are all extensively studied through remote sensing. The L1R data in composed of 256 columns and 3189 rows, covering an area of 735 km<inline-formula><mml:math id="mm64" overflow="scroll"><mml:mrow><mml:msup><mml:mrow/><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math></inline-formula>.</p>
      <p>The L1R image was processed using the entire SUREHYP chain described in <xref rid="sensors-22-09205-f002" ref-type="fig">Figure 2</xref>. The smiled bands were detected automatically, and the destriping was done according to Pal et al. [<xref rid="B13-sensors-22-09205" ref-type="bibr">13</xref>]. For the atmospheric correction, atmosphere was set to Sub-Arctic Summer, ozone concentration was obtained from the TOMS and OMI Merged Ozone Data using GEE, and water vapor concentration was estimated from the image using the method described in <xref rid="sec2dot4dot2-sensors-22-09205" ref-type="sec">Section 2.4.2</xref>. The DEM was retrieved from the Canadian Digital Elevation Model using GEE. Both the flat terrain AC and the rough terrain AC images were saved.</p>
      <p>FLAASH was ran with a Sub-Arctic Summer atmospheric model, water vapor concentration was retrieved using the 1120 nm absorption feature when possible. Finally, the aerosol model was set to Rural and aerosols were retrieved using the 2-Band (KT) option available. FLAASH does not consider the DEM for its atmospheric correction, and the output is therefore a flat terrain AC image.</p>
      <p>At the image scale, reflectance spectra produced by SUREHYP and FLAASH were compared using the spectral angle (SA) on a pixel-to-pixel basis in order to identify areas where the outputs from both software differed significantly (SA &gt; 10°). The SA considers each spectrum as a vector in a <italic toggle="yes">K</italic>-dimensional space (with <italic toggle="yes">K</italic> the number of bands). It is obtained using Equation (<xref rid="FD12-sensors-22-09205" ref-type="disp-formula">12</xref>):<disp-formula id="FD12-sensors-22-09205"><label>(12)</label><mml:math id="mm65" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>SA</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>f</mml:mi><mml:mo>,</mml:mo><mml:mi>s</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>arccos</mml:mi><mml:mfenced separators="" open="(" close=")"><mml:mfrac><mml:mrow><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:munderover></mml:mstyle><mml:msub><mml:mi>f</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:msub><mml:mi>s</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:msqrt><mml:mrow><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:munderover></mml:mstyle><mml:msubsup><mml:mi>f</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:msqrt><mml:msqrt><mml:mrow><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:munderover></mml:mstyle><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:msqrt></mml:mrow></mml:mfrac></mml:mfenced></mml:mrow></mml:mrow></mml:math></disp-formula>
with <italic toggle="yes">f</italic>, <italic toggle="yes">s</italic> the spectra that are being compared. Then, absolute and relative reflectance differences were computed over area (d) (see <xref rid="sensors-22-09205-f006" ref-type="fig">Figure 6</xref>), using FLAASH outputs as a reference, to assess their behaviour over the 400–2500 nm range. Area (d) is a built-up area with an almost constant reflectance value of 0.2 over the whole spectral range, which makes it easier to compare the outputs of both software at different wavelengths.</p>
    </sec>
  </sec>
  <sec sec-type="results" id="sec3-sensors-22-09205">
    <title>3. Results</title>
    <sec>
      <title>Comparison between SUREHYP and FLAASH Outputs</title>
      <p><xref rid="sensors-22-09205-f006" ref-type="fig">Figure 6</xref> shows the spectral similarities over the whole Hyperion image. SA over the majority of landcovers was low, with values between 2 and 6° over the urban area, agricultural fields, and sunlit forests indicating high spectral similarity. Alternatively, darker objects, such as water bodies (subscenes (a) and (b)) and shadowed area (subscenes (b) and (c)) presented significant spectral dissimilarity.</p>
      <p><xref rid="sensors-22-09205-f007" ref-type="fig">Figure 7</xref> shows the average reflectance spectra produced by SUREHYP and FLAASH over the high (SA &lt; 10°) and low (SA ≥ 10°) spectral similarity areas. In the high similarity areas, it appears that SUREHYP reflectance are higher than those of FLAASH over the blue and red regions (0.04 at 475 nm and 0.02 at 675 nm at most). Higher sureface reflectance estimates are also apparent at 770 nm, just short of the oxygen absorption band. Over the green and infrared region, FLAASH and SUREHYP outputs are very similar, and are the same above 1500 nm. Around 450 nm, FLAASH produced negative reflectances.</p>
      <p>In the low similarity areas, reflectances from both FLAASH and SUREHYP were closely matched with differences close to zero over the whole spectrum. It appeared that FLAASH almost exclusively produced negative reflectance, except in the blue and green regions. Reflectances produced by SUREHYP are all above zero, with a peak at 470 nm and a decrease until 750 nm.</p>
      <p><xref rid="sensors-22-09205-f008" ref-type="fig">Figure 8</xref> and <xref rid="sensors-22-09205-t001" ref-type="table">Table 1</xref> display the absolute and relative reflectance differences over area (d). Spectral differences are the most pronounced in the green region, with around 15% reflectance difference. In the NIR, SUREHYP reflectances are slightly above those of FLAASH, with values 10% higher, while for wavelengths &gt;1000 nm, relative reflectance difference is on average 4%. Overall, over the 400–2500 nm range, SUREHYP reflectances are almost entirely within 10% of those obtained with FLAASH.</p>
      <p><xref rid="sensors-22-09205-f009" ref-type="fig">Figure 9</xref> shows RGB compositions of the SUREHYP outputs over a hilly terrain with the flat and rough terrain AC. Over the scene, the radiation incidence angle on the surface, computed from the solar angles and the DEM, varies between 38° and 82°, while the solar zenith, which is the only angle considered for the flat terrain correction, is 63.5°. As visible in the flat AC image, not taking this variation into account leads to one side of the terrain being clearly brighter than the other. The rough terrain AC corrects for this and compensates for the variations of irradiance.</p>
    </sec>
  </sec>
  <sec sec-type="discussion" id="sec4-sensors-22-09205">
    <title>4. Discussion</title>
    <p>Multiple algorithms have been proposed to preprocess Hyperion data, and various commercial software exist to perform AC and retrieve surface reflectance from the images. Previous studies have often employed FLAASH to perform AC when processing Hyperion imagery [<xref rid="B1-sensors-22-09205" ref-type="bibr">1</xref>,<xref rid="B20-sensors-22-09205" ref-type="bibr">20</xref>,<xref rid="B21-sensors-22-09205" ref-type="bibr">21</xref>,<xref rid="B22-sensors-22-09205" ref-type="bibr">22</xref>,<xref rid="B46-sensors-22-09205" ref-type="bibr">46</xref>]. FLAASH is based on the AC model MODTRAN [<xref rid="B47-sensors-22-09205" ref-type="bibr">47</xref>], retrieves water vapor and aerosol concentrations from the hyperspectral image, and does a flat terrain AC. While the outputs of FLAASH and other commercially available software have been shown to be accurate and satisfying for analysis purposes, this commercial distribution may limit the full exploitation of available remote sensing archives. Indeed, regardless of price, a number of the key parameters are set and not easily modified by the user. SUREHYP uses freely available software and tools (Python, SMARTS and GEE), and although the sources of the most recent SMARTS versions are not distributed, those of SMARTS v.2.9.5. are open. As it is written in Python, users are able to examine each step and easily modify the code or add additional functions of interest. Moreover, improvements and new functions can easily be implemented by the community. While SUREHYP mostly implements functions and algorithms that have been previously published, an automatic spectral smile detection algorithm was developed to facilitate batch processing of the Hyperion archive. Likewise, an algorithm to retrieve water vapor content from the images was implemented. It currently takes 68 s to preprocess a L1R Hyperion image and obtain surface reflectance using a flat terrain atmospheric correction on one core of a machine equipped with a 3.2 GHz Intel Xeon Silver 4215R CPU and 128 Gb of RAM.</p>
    <p>Comparisons between FLAASH and SUREHYP indicate very similar outputs with the main difference occurring at shorter wavelengths, in the visible region of the spectrum (see <xref rid="sensors-22-09205-f007" ref-type="fig">Figure 7</xref> and <xref rid="sensors-22-09205-t001" ref-type="table">Table 1</xref>). Reflectances produced by FLAASH in the blue region were particularly low, to the point of being negative for some wavelengths &lt;500 nm. As visible in <xref rid="sensors-22-09205-f008" ref-type="fig">Figure 8</xref>, in the blue, red, and SWIR regions, the median reflectance relative differences were below 10%, while in the NIR the median value was 10.7%. Overall, for wavelengths &lt;1000 nm, relative differences were higher than for those above 1000 nm. As lower wavelengths are the most affected by aerosols and haze, it is assumed that the main cause of difference between SUREHYP and FLAASH outputs is the haze removal step, with different software estimating difference haze values. In the example image, the darkest object identified on the imagery was a shadow visible in subscene (c) of <xref rid="sensors-22-09205-f006" ref-type="fig">Figure 6</xref>, however haze thickness may have been different over the rest of the scene. While it may be possible to look for local dark objects and create a haze thickness map, ensuring that the pixels identified as belonging to a dark objects, and not merely to the darkest object in the area, may be difficult. Conversely, it seemed that FLAASH produced negative reflectances in the darkest areas, as well as in the blue region for the sunlit areas, which indicates over correction. However its source is unclear: as a decrease is visible between 500 and 750 nm, this may not be due to overestimated haze radiance. This overcorrection may also partially explain the differences between SUREHYP and FLAASH in the visible when performing a flat terrain AC.</p>
    <p>The peak at 770 nm that can be observed in <xref rid="sensors-22-09205-f007" ref-type="fig">Figure 7</xref> for the SUREHYP reflectances is a consequence of the oxygen absorption band. SMARTS provides the transmission and irradiance values at an interval of 1 nm over the 400–1700 nm interval, and a gaussian filtering with a 10 nm FWHM is applied to these values to match the characteristics of Hyperion. The consequence is that the 760 nm absorption feature affects the surrounding bands. As this peak should not be present, it may be that the effect of oxygen is overcorrected by SUREHYP, i.e., that the transmission at 760 nm is underestimated. Further work may therefore be necessary to fully account for the oxygen band.</p>
  </sec>
  <sec sec-type="conclusions" id="sec5-sensors-22-09205">
    <title>5. Conclusions</title>
    <p>SUREHYP is a Python package that provides several functions to preprocess Hyperion data and obtain analysis-ready surface reflectance images. It brings together multiple published methods and freely available software to process Hyperion images, and includes algorithms adapted to the batch processing of large quantities of images. Its outputs have been shown to be similar to those of a commercially available software largely used by the scientific community to process Hyperion data. Apart from the fact that it is freely distributed, one of the main advantages of the package is that it is open source and easily tunable to the specific needs of each user. Further works should focus on implementing a cloud and cloud shadows detection, improving the haze removal method, and accelerating the rough terrain atmospheric correction.</p>
  </sec>
</body>
<back>
  <fn-group>
    <fn>
      <p><bold>Publisher’s Note:</bold> MDPI stays neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
    </fn>
  </fn-group>
  <notes>
    <title>Author Contributions</title>
    <p>Conceptualization, T.M.; Methodology, T.M.; Software, T.M.; Validation, T.M.; Formal analysis, T.M.; Investigation, T.M.; Resources, N.C.C.; Writing—original draft, T.M.; Writing—review &amp; editing, N.C.C.; Visualization, T.M.; Supervision, N.C.C.; Project administration, N.C.C.; Funding acquisition, N.C.C. All authors have read and agreed to the published version of the manuscript.</p>
  </notes>
  <notes notes-type="data-availability">
    <title>Data Availability Statement</title>
    <p>Not applicable.</p>
  </notes>
  <notes notes-type="COI-statement">
    <title>Conflicts of Interest</title>
    <p>The authors declare no conflict of interest.</p>
  </notes>
  <ref-list>
    <title>References</title>
    <ref id="B1-sensors-22-09205">
      <label>1.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Farifteh</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Nieuwenhuis</surname>
            <given-names>W.</given-names>
          </name>
          <name>
            <surname>García-Meléndez</surname>
            <given-names>E.</given-names>
          </name>
        </person-group>
        <article-title>Mapping spatial variations of iron oxide by-product minerals from EO-1 Hyperion</article-title>
        <source>Int. J. Remote Sens.</source>
        <year>2013</year>
        <volume>34</volume>
        <fpage>682</fpage>
        <lpage>699</lpage>
        <pub-id pub-id-type="doi">10.1080/01431161.2012.715776</pub-id>
      </element-citation>
    </ref>
    <ref id="B2-sensors-22-09205">
      <label>2.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hermosilla</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Wulder</surname>
            <given-names>M.A.</given-names>
          </name>
          <name>
            <surname>White</surname>
            <given-names>J.C.</given-names>
          </name>
          <name>
            <surname>Coops</surname>
            <given-names>N.C.</given-names>
          </name>
          <name>
            <surname>Hobart</surname>
            <given-names>G.W.</given-names>
          </name>
        </person-group>
        <article-title>Regional detection, characterization, and attribution of annual forest change from 1984 to 2012 using Landsat-derived time-series metrics</article-title>
        <source>Remote Sens. Environ.</source>
        <year>2015</year>
        <volume>170</volume>
        <fpage>121</fpage>
        <lpage>132</lpage>
        <pub-id pub-id-type="doi">10.1016/j.rse.2015.09.004</pub-id>
      </element-citation>
    </ref>
    <ref id="B3-sensors-22-09205">
      <label>3.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Quan</surname>
            <given-names>X.</given-names>
          </name>
          <name>
            <surname>He</surname>
            <given-names>B.</given-names>
          </name>
          <name>
            <surname>Yebra</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Yin</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Liao</surname>
            <given-names>Z.</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>X.</given-names>
          </name>
        </person-group>
        <article-title>Retrieval of forest fuel moisture content using a coupled radiative transfer model</article-title>
        <source>Environ. Model. Softw.</source>
        <year>2017</year>
        <volume>95</volume>
        <fpage>290</fpage>
        <lpage>302</lpage>
        <pub-id pub-id-type="doi">10.1016/j.envsoft.2017.06.006</pub-id>
      </element-citation>
    </ref>
    <ref id="B4-sensors-22-09205">
      <label>4.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Dennison</surname>
            <given-names>P.E.</given-names>
          </name>
          <name>
            <surname>Qi</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Meerdink</surname>
            <given-names>S.K.</given-names>
          </name>
          <name>
            <surname>Kokaly</surname>
            <given-names>R.F.</given-names>
          </name>
          <name>
            <surname>Thompson</surname>
            <given-names>D.R.</given-names>
          </name>
          <name>
            <surname>Daughtry</surname>
            <given-names>C.S.</given-names>
          </name>
          <name>
            <surname>Quemada</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Roberts</surname>
            <given-names>D.A.</given-names>
          </name>
          <name>
            <surname>Gader</surname>
            <given-names>P.D.</given-names>
          </name>
          <name>
            <surname>Wetherley</surname>
            <given-names>E.B.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Comparison of methods for modeling fractional cover using simulated satellite hyperspectral imager spectra</article-title>
        <source>Remote Sens.</source>
        <year>2019</year>
        <volume>11</volume>
        <elocation-id>2072</elocation-id>
        <pub-id pub-id-type="doi">10.3390/rs11182072</pub-id>
      </element-citation>
    </ref>
    <ref id="B5-sensors-22-09205">
      <label>5.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Markham</surname>
            <given-names>B.L.</given-names>
          </name>
          <name>
            <surname>Storey</surname>
            <given-names>J.C.</given-names>
          </name>
          <name>
            <surname>Williams</surname>
            <given-names>D.L.</given-names>
          </name>
          <name>
            <surname>Irons</surname>
            <given-names>J.R.</given-names>
          </name>
        </person-group>
        <article-title>Landsat Sensor Performance: History and Current Status</article-title>
        <source>IEEE Trans. Geosci. Remote Sens.</source>
        <year>2004</year>
        <volume>12</volume>
        <fpage>2691</fpage>
        <lpage>2694</lpage>
        <pub-id pub-id-type="doi">10.1109/TGRS.2004.840720</pub-id>
      </element-citation>
    </ref>
    <ref id="B6-sensors-22-09205">
      <label>6.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Drusch</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Del Bello</surname>
            <given-names>U.</given-names>
          </name>
          <name>
            <surname>Carlier</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Colin</surname>
            <given-names>O.</given-names>
          </name>
          <name>
            <surname>Fernandez</surname>
            <given-names>V.</given-names>
          </name>
          <name>
            <surname>Gascon</surname>
            <given-names>F.</given-names>
          </name>
          <name>
            <surname>Hoersch</surname>
            <given-names>B.</given-names>
          </name>
          <name>
            <surname>Isola</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Laberinti</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>Martimort</surname>
            <given-names>P.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Sentinel-2: ESA’s Optical High-Resolution Mission for GMES Operational Services</article-title>
        <source>Remote Sens. Environ.</source>
        <year>2012</year>
        <volume>120</volume>
        <fpage>25</fpage>
        <lpage>36</lpage>
        <pub-id pub-id-type="doi">10.1016/j.rse.2011.11.026</pub-id>
      </element-citation>
    </ref>
    <ref id="B7-sensors-22-09205">
      <label>7.</label>
      <element-citation publication-type="confproc">
        <person-group person-group-type="author">
          <name>
            <surname>Barnes</surname>
            <given-names>W.L.</given-names>
          </name>
          <name>
            <surname>Xiong</surname>
            <given-names>X.J.</given-names>
          </name>
          <name>
            <surname>Salomonson</surname>
            <given-names>V.V.</given-names>
          </name>
        </person-group>
        <article-title>Status of Terra MODIS and Aqua MODIS</article-title>
        <source>Proceedings of the International Geoscience and Remote Sensing Symposium (IGARSS)</source>
        <conf-loc>Toronto, ON, Canada</conf-loc>
        <conf-date>24–28 June 2002</conf-date>
        <volume>Volume 2</volume>
        <fpage>970</fpage>
        <lpage>972</lpage>
        <pub-id pub-id-type="doi">10.1109/igarss.2002.1025746</pub-id>
      </element-citation>
    </ref>
    <ref id="B8-sensors-22-09205">
      <label>8.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chaves</surname>
            <given-names>M.E.</given-names>
          </name>
          <name>
            <surname>Picoli</surname>
            <given-names>M.C.</given-names>
          </name>
          <name>
            <surname>Sanches</surname>
            <given-names>I.D.</given-names>
          </name>
        </person-group>
        <article-title>Recent applications of Landsat 8/OLI and Sentinel-2/MSI for land use and land cover mapping: A systematic review</article-title>
        <source>Remote Sens.</source>
        <year>2020</year>
        <volume>12</volume>
        <elocation-id>3062</elocation-id>
        <pub-id pub-id-type="doi">10.3390/rs12183062</pub-id>
      </element-citation>
    </ref>
    <ref id="B9-sensors-22-09205">
      <label>9.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Pearlman</surname>
            <given-names>J.S.</given-names>
          </name>
          <name>
            <surname>Barry</surname>
            <given-names>P.S.</given-names>
          </name>
          <name>
            <surname>Segal</surname>
            <given-names>C.C.</given-names>
          </name>
          <name>
            <surname>Shepanski</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Beiso</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Carman</surname>
            <given-names>S.L.</given-names>
          </name>
        </person-group>
        <article-title>Hyperion, a space-based imaging spectrometer</article-title>
        <source>IEEE Trans. Geosci. Remote Sens.</source>
        <year>2003</year>
        <volume>41</volume>
        <fpage>1160</fpage>
        <lpage>1173</lpage>
        <pub-id pub-id-type="doi">10.1109/TGRS.2003.815018</pub-id>
      </element-citation>
    </ref>
    <ref id="B10-sensors-22-09205">
      <label>10.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Transon</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>D’Andrimont</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Maugnard</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Defourny</surname>
            <given-names>P.</given-names>
          </name>
        </person-group>
        <article-title>Survey of hyperspectral Earth Observation applications from space in the Sentinel-2 context</article-title>
        <source>Remote Sens.</source>
        <year>2018</year>
        <volume>10</volume>
        <elocation-id>157</elocation-id>
        <pub-id pub-id-type="doi">10.3390/rs10020157</pub-id>
      </element-citation>
    </ref>
    <ref id="B11-sensors-22-09205">
      <label>11.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Datt</surname>
            <given-names>B.</given-names>
          </name>
          <name>
            <surname>McVicar</surname>
            <given-names>T.R.</given-names>
          </name>
          <name>
            <surname>Van Niel</surname>
            <given-names>T.G.</given-names>
          </name>
          <name>
            <surname>Jupp</surname>
            <given-names>D.L.</given-names>
          </name>
          <name>
            <surname>Pearlman</surname>
            <given-names>J.S.</given-names>
          </name>
        </person-group>
        <article-title>Preprocessing EO-1 Hyperion hyperspectral data to support the application of agricultural indexes</article-title>
        <source>IEEE Trans. Geosci. Remote Sens.</source>
        <year>2003</year>
        <volume>41</volume>
        <fpage>1246</fpage>
        <lpage>1259</lpage>
        <pub-id pub-id-type="doi">10.1109/TGRS.2003.813206</pub-id>
      </element-citation>
    </ref>
    <ref id="B12-sensors-22-09205">
      <label>12.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Scheffler</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Karrasch</surname>
            <given-names>P.</given-names>
          </name>
        </person-group>
        <article-title>Destriping of hyperspectral image data: An evaluation of different algorithms using EO-1 Hyperion data</article-title>
        <source>J. Appl. Remote Sens.</source>
        <year>2014</year>
        <volume>8</volume>
        <fpage>083645</fpage>
        <pub-id pub-id-type="doi">10.1117/1.JRS.8.083645</pub-id>
      </element-citation>
    </ref>
    <ref id="B13-sensors-22-09205">
      <label>13.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Pal</surname>
            <given-names>M.K.</given-names>
          </name>
          <name>
            <surname>Porwal</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Rasmussen</surname>
            <given-names>T.M.</given-names>
          </name>
        </person-group>
        <article-title>Noise reduction and destriping using local spatial statistics and quadratic regression from Hyperion images</article-title>
        <source>J. Appl. Remote Sens.</source>
        <year>2020</year>
        <volume>14</volume>
        <fpage>1</fpage>
        <pub-id pub-id-type="doi">10.1117/1.JRS.14.016515</pub-id>
      </element-citation>
    </ref>
    <ref id="B14-sensors-22-09205">
      <label>14.</label>
      <element-citation publication-type="webpage">
        <person-group person-group-type="author">
          <name>
            <surname>Richter</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Schläpfer</surname>
            <given-names>D.</given-names>
          </name>
        </person-group>
        <article-title>Atmospheric/Topographic Correction for Satellite Imagery (ATCOR-2/3 User Guide). ATCOR-2/3 User Guide, Version 8.3.1</article-title>
        <year>2014</year>
        <comment>Available online: <ext-link xlink:href="https://www.rese.ch/pdf/atcor3_manual.pdf" ext-link-type="uri">https://www.rese.ch/pdf/atcor3_manual.pdf</ext-link></comment>
        <date-in-citation content-type="access-date" iso-8601-date="2022-11-23">(accessed on 23 November 2022)</date-in-citation>
      </element-citation>
    </ref>
    <ref id="B15-sensors-22-09205">
      <label>15.</label>
      <element-citation publication-type="confproc">
        <person-group person-group-type="author">
          <name>
            <surname>Cooley</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Anderson</surname>
            <given-names>G.</given-names>
          </name>
          <name>
            <surname>Felde</surname>
            <given-names>G.</given-names>
          </name>
          <name>
            <surname>Hoke</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Ratkowski</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Chetwynd</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Gardner</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Adler-Golden</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Matthew</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Berk</surname>
            <given-names>A.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>FLAASH, a MODTRAN4-based atmospheric correction algorithm, its application and validation</article-title>
        <source>Proceedings of the IEEE International Geoscience and Remote Sensing Symposium</source>
        <conf-loc>Toronto, ON, Canada</conf-loc>
        <conf-date>24–28 June 2002</conf-date>
        <volume>Volume 3</volume>
        <fpage>1414</fpage>
        <lpage>1418</lpage>
        <pub-id pub-id-type="doi">10.1109/IGARSS.2002.1026134</pub-id>
      </element-citation>
    </ref>
    <ref id="B16-sensors-22-09205">
      <label>16.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ganesh</surname>
            <given-names>B.P.</given-names>
          </name>
          <name>
            <surname>Aravindan</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Raja</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Thirunavukkarasu</surname>
            <given-names>A.</given-names>
          </name>
        </person-group>
        <article-title>Hyperspectral satellite data (Hyperion) preprocessing-a case study on banded magnetite quartzite in Godumalai Hill, Salem, Tamil Nadu, India</article-title>
        <source>Arab. J. Geosci.</source>
        <year>2013</year>
        <volume>6</volume>
        <fpage>3249</fpage>
        <lpage>3256</lpage>
        <pub-id pub-id-type="doi">10.1007/s12517-012-0584-8</pub-id>
      </element-citation>
    </ref>
    <ref id="B17-sensors-22-09205">
      <label>17.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Bannari</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Staenz</surname>
            <given-names>K.</given-names>
          </name>
          <name>
            <surname>Champagne</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Khurshid</surname>
            <given-names>K.S.</given-names>
          </name>
        </person-group>
        <article-title>Spatial variability mapping of crop residue using hyperion (EO-1) hyperspectral data</article-title>
        <source>Remote Sens.</source>
        <year>2015</year>
        <volume>7</volume>
        <fpage>8107</fpage>
        <lpage>8127</lpage>
        <pub-id pub-id-type="doi">10.3390/rs70608107</pub-id>
      </element-citation>
    </ref>
    <ref id="B18-sensors-22-09205">
      <label>18.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Minu</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Shetty</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Minasny</surname>
            <given-names>B.</given-names>
          </name>
          <name>
            <surname>Gomez</surname>
            <given-names>C.</given-names>
          </name>
        </person-group>
        <article-title>The role of atmospheric correction algorithms in the prediction of soil organic carbon from hyperion data</article-title>
        <source>Int. J. Remote Sens.</source>
        <year>2017</year>
        <volume>38</volume>
        <fpage>6435</fpage>
        <lpage>6456</lpage>
        <pub-id pub-id-type="doi">10.1080/01431161.2017.1354265</pub-id>
      </element-citation>
    </ref>
    <ref id="B19-sensors-22-09205">
      <label>19.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Minu</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Shetty</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Gomez</surname>
            <given-names>C.</given-names>
          </name>
        </person-group>
        <article-title>Hybrid atmospheric correction algorithms and evaluation on VNIR/SWIR Hyperion satellite data for soil organic carbon prediction</article-title>
        <source>Int. J. Remote Sens.</source>
        <year>2018</year>
        <volume>39</volume>
        <fpage>8246</fpage>
        <lpage>8270</lpage>
        <pub-id pub-id-type="doi">10.1080/01431161.2018.1483087</pub-id>
      </element-citation>
    </ref>
    <ref id="B20-sensors-22-09205">
      <label>20.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hu</surname>
            <given-names>B.</given-names>
          </name>
          <name>
            <surname>Xu</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Wan</surname>
            <given-names>B.</given-names>
          </name>
          <name>
            <surname>Wu</surname>
            <given-names>X.</given-names>
          </name>
          <name>
            <surname>Yi</surname>
            <given-names>G.</given-names>
          </name>
        </person-group>
        <article-title>Hydrothermally altered mineral mapping using synthetic application of Sentinel-2A MSI, ASTER and Hyperion data in the Duolong area, Tibetan Plateau, China</article-title>
        <source>Ore Geol. Rev.</source>
        <year>2018</year>
        <volume>101</volume>
        <fpage>384</fpage>
        <lpage>397</lpage>
        <pub-id pub-id-type="doi">10.1016/j.oregeorev.2018.07.017</pub-id>
      </element-citation>
    </ref>
    <ref id="B21-sensors-22-09205">
      <label>21.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Sengupta</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Adhikari</surname>
            <given-names>M.D.</given-names>
          </name>
          <name>
            <surname>Maiti</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Maiti</surname>
            <given-names>S.K.</given-names>
          </name>
          <name>
            <surname>Mahanta</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>Bhaumick</surname>
            <given-names>S.</given-names>
          </name>
        </person-group>
        <article-title>Identification and mapping of high-potential iron ore alteration zone across Joda, Odisha using ASTER and EO-1 hyperion data</article-title>
        <source>J. Spat. Sci.</source>
        <year>2019</year>
        <volume>64</volume>
        <fpage>491</fpage>
        <lpage>514</lpage>
        <pub-id pub-id-type="doi">10.1080/14498596.2018.1485120</pub-id>
      </element-citation>
    </ref>
    <ref id="B22-sensors-22-09205">
      <label>22.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Souza</surname>
            <given-names>M.V.</given-names>
          </name>
          <name>
            <surname>Coimbra Horbe</surname>
            <given-names>A.M.</given-names>
          </name>
          <name>
            <surname>Costa da Silva</surname>
            <given-names>B.</given-names>
          </name>
          <name>
            <surname>Peixoto</surname>
            <given-names>S.F.</given-names>
          </name>
          <name>
            <surname>Castro</surname>
            <given-names>R.T.</given-names>
          </name>
        </person-group>
        <article-title>Regolith LANDSAT-8/OLI and Hyperion/EO-1 images classification in midwest of Brazil</article-title>
        <source>J. South Am. Earth Sci.</source>
        <year>2021</year>
        <volume>111</volume>
        <fpage>103460</fpage>
        <pub-id pub-id-type="doi">10.1016/j.jsames.2021.103460</pub-id>
      </element-citation>
    </ref>
    <ref id="B23-sensors-22-09205">
      <label>23.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Prieto-Amparan</surname>
            <given-names>J.A.</given-names>
          </name>
          <name>
            <surname>Villarreal-Guerrero</surname>
            <given-names>F.</given-names>
          </name>
          <name>
            <surname>Martinez-Salvador</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Manjarrez-Domínguez</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Santellano-Estrada</surname>
            <given-names>E.</given-names>
          </name>
          <name>
            <surname>Pinedo-Alvarez</surname>
            <given-names>A.</given-names>
          </name>
        </person-group>
        <article-title>Atmospheric and radiometric correction algorithms for the multitemporal assessment of grasslands productivity</article-title>
        <source>Remote Sens.</source>
        <year>2018</year>
        <volume>10</volume>
        <elocation-id>219</elocation-id>
        <pub-id pub-id-type="doi">10.3390/rs10020219</pub-id>
      </element-citation>
    </ref>
    <ref id="B24-sensors-22-09205">
      <label>24.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Karpouzli</surname>
            <given-names>E.</given-names>
          </name>
          <name>
            <surname>Malthus</surname>
            <given-names>T.</given-names>
          </name>
        </person-group>
        <article-title>The empirical line method for the atmospheric correction of IKONOS imagery</article-title>
        <source>Int. J. Remote Sens.</source>
        <year>2003</year>
        <volume>24</volume>
        <fpage>1143</fpage>
        <lpage>1150</lpage>
        <pub-id pub-id-type="doi">10.1080/0143116021000026779</pub-id>
      </element-citation>
    </ref>
    <ref id="B25-sensors-22-09205">
      <label>25.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Katkovsky</surname>
            <given-names>L.V.</given-names>
          </name>
          <name>
            <surname>Martinov</surname>
            <given-names>A.O.</given-names>
          </name>
          <name>
            <surname>Siliuk</surname>
            <given-names>V.A.</given-names>
          </name>
          <name>
            <surname>Ivanov</surname>
            <given-names>D.A.</given-names>
          </name>
          <name>
            <surname>Kokhanovsky</surname>
            <given-names>A.A.</given-names>
          </name>
        </person-group>
        <article-title>Fast atmospheric correction method for hyperspectral data</article-title>
        <source>Remote Sens.</source>
        <year>2018</year>
        <volume>10</volume>
        <elocation-id>1698</elocation-id>
        <pub-id pub-id-type="doi">10.3390/rs10111698</pub-id>
      </element-citation>
    </ref>
    <ref id="B26-sensors-22-09205">
      <label>26.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ientilucci</surname>
            <given-names>E.J.</given-names>
          </name>
          <name>
            <surname>Adler-Golden</surname>
            <given-names>S.</given-names>
          </name>
        </person-group>
        <article-title>Atmospheric compensation of hyperspectral data: An overview and review of in-scene and physics-based approaches</article-title>
        <source>IEEE Geosci. Remote Sens. Mag.</source>
        <year>2019</year>
        <volume>7</volume>
        <fpage>31</fpage>
        <lpage>50</lpage>
        <pub-id pub-id-type="doi">10.1109/MGRS.2019.2904706</pub-id>
      </element-citation>
    </ref>
    <ref id="B27-sensors-22-09205">
      <label>27.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Petropoulos</surname>
            <given-names>G.P.</given-names>
          </name>
          <name>
            <surname>Anagnostopoulos</surname>
            <given-names>V.</given-names>
          </name>
        </person-group>
        <article-title>SEVIRI PrePro: A novel software tool for the pre-processing of SEVIRI geostationary orbit EO data products</article-title>
        <source>Environ. Model. Softw.</source>
        <year>2016</year>
        <volume>82</volume>
        <fpage>321</fpage>
        <lpage>329</lpage>
        <pub-id pub-id-type="doi">10.1016/j.envsoft.2016.03.015</pub-id>
      </element-citation>
    </ref>
    <ref id="B28-sensors-22-09205">
      <label>28.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Li</surname>
            <given-names>H.</given-names>
          </name>
          <name>
            <surname>Wan</surname>
            <given-names>W.</given-names>
          </name>
          <name>
            <surname>Fang</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Zhu</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>X.</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>B.</given-names>
          </name>
          <name>
            <surname>Hong</surname>
            <given-names>Y.</given-names>
          </name>
        </person-group>
        <article-title>A Google Earth Engine-enabled software for efficiently generating high-quality user-ready Landsat mosaic images</article-title>
        <source>Environ. Model. Softw.</source>
        <year>2019</year>
        <volume>112</volume>
        <fpage>16</fpage>
        <lpage>22</lpage>
        <pub-id pub-id-type="doi">10.1016/j.envsoft.2018.11.004</pub-id>
      </element-citation>
    </ref>
    <ref id="B29-sensors-22-09205">
      <label>29.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Gueymard</surname>
            <given-names>C.A.</given-names>
          </name>
        </person-group>
        <article-title>Parameterized transmittance model for direct beam and circumsolar spectral irradiance</article-title>
        <source>Sol. Energy</source>
        <year>2001</year>
        <volume>71</volume>
        <fpage>325</fpage>
        <lpage>346</lpage>
        <pub-id pub-id-type="doi">10.1016/S0038-092X(01)00054-8</pub-id>
      </element-citation>
    </ref>
    <ref id="B30-sensors-22-09205">
      <label>30.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Gueymard</surname>
            <given-names>C.A.</given-names>
          </name>
        </person-group>
        <article-title>The SMARTS spectral irradiance model after 25 years: New developments and validation of reference spectra</article-title>
        <source>Sol. Energy</source>
        <year>2019</year>
        <volume>187</volume>
        <fpage>233</fpage>
        <lpage>253</lpage>
        <pub-id pub-id-type="doi">10.1016/j.solener.2019.05.048</pub-id>
      </element-citation>
    </ref>
    <ref id="B31-sensors-22-09205">
      <label>31.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>San</surname>
            <given-names>B.T.</given-names>
          </name>
          <name>
            <surname>Süzen</surname>
            <given-names>M.L.</given-names>
          </name>
        </person-group>
        <article-title>Evaluation of cross-track illumination in EO-1 hyperion imagery for lithological mapping</article-title>
        <source>Int. J. Remote Sens.</source>
        <year>2011</year>
        <volume>32</volume>
        <fpage>7873</fpage>
        <lpage>7889</lpage>
        <pub-id pub-id-type="doi">10.1080/01431161.2010.532175</pub-id>
      </element-citation>
    </ref>
    <ref id="B32-sensors-22-09205">
      <label>32.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Green</surname>
            <given-names>R.O.</given-names>
          </name>
          <name>
            <surname>Eastwood</surname>
            <given-names>M.L.</given-names>
          </name>
          <name>
            <surname>Sarture</surname>
            <given-names>C.M.</given-names>
          </name>
          <name>
            <surname>Chrien</surname>
            <given-names>T.G.</given-names>
          </name>
          <name>
            <surname>Aronsson</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Chippendale</surname>
            <given-names>B.J.</given-names>
          </name>
          <name>
            <surname>Faust</surname>
            <given-names>J.A.</given-names>
          </name>
          <name>
            <surname>Pavri</surname>
            <given-names>B.E.</given-names>
          </name>
          <name>
            <surname>Chovit</surname>
            <given-names>C.J.</given-names>
          </name>
          <name>
            <surname>Solis</surname>
            <given-names>M.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Imaging spectroscopy and the Airborne Visible/Infrared Imaging Spectrometer (AVIRIS)</article-title>
        <source>Remote Sens. Environ.</source>
        <year>1998</year>
        <volume>65</volume>
        <fpage>227</fpage>
        <lpage>248</lpage>
        <pub-id pub-id-type="doi">10.1016/S0034-4257(98)00064-9</pub-id>
      </element-citation>
    </ref>
    <ref id="B33-sensors-22-09205">
      <label>33.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Goodenough</surname>
            <given-names>D.G.</given-names>
          </name>
          <name>
            <surname>Dyk</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Niemann</surname>
            <given-names>K.O.</given-names>
          </name>
          <name>
            <surname>Pearlman</surname>
            <given-names>J.S.</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>H.</given-names>
          </name>
          <name>
            <surname>Han</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Murdoch</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>West</surname>
            <given-names>C.</given-names>
          </name>
        </person-group>
        <article-title>Processing Hyperion and ALI for forest classification</article-title>
        <source>IEEE Trans. Geosci. Remote Sens.</source>
        <year>2003</year>
        <volume>41</volume>
        <fpage>1321</fpage>
        <lpage>1331</lpage>
        <pub-id pub-id-type="doi">10.1109/TGRS.2003.813214</pub-id>
      </element-citation>
    </ref>
    <ref id="B34-sensors-22-09205">
      <label>34.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Khurshid</surname>
            <given-names>K.S.</given-names>
          </name>
          <name>
            <surname>Staenz</surname>
            <given-names>K.</given-names>
          </name>
          <name>
            <surname>Sun</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Neville</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>White</surname>
            <given-names>H.P.</given-names>
          </name>
          <name>
            <surname>Bannari</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Champagne</surname>
            <given-names>C.M.</given-names>
          </name>
          <name>
            <surname>Hitchcock</surname>
            <given-names>R.</given-names>
          </name>
        </person-group>
        <article-title>Preprocessing of EO-1 Hyperion data</article-title>
        <source>Can. J. Remote Sens.</source>
        <year>2006</year>
        <volume>32</volume>
        <fpage>84</fpage>
        <lpage>97</lpage>
        <pub-id pub-id-type="doi">10.5589/m06-014</pub-id>
      </element-citation>
    </ref>
    <ref id="B35-sensors-22-09205">
      <label>35.</label>
      <element-citation publication-type="book">
        <person-group person-group-type="editor">
          <name>
            <surname>Thenkabail</surname>
            <given-names>P.S.</given-names>
          </name>
          <name>
            <surname>Lyon</surname>
            <given-names>J.G.</given-names>
          </name>
          <name>
            <surname>Huete</surname>
            <given-names>A.</given-names>
          </name>
        </person-group>
        <source>Fundamentals, Sensor Systems, Spectral Libraries, and Data Mining for Vegetation</source>
        <publisher-name>CRC Press</publisher-name>
        <publisher-loc>Boca Raton, FL, USA</publisher-loc>
        <year>2018</year>
        <pub-id pub-id-type="doi">10.1201/9781315164151</pub-id>
      </element-citation>
    </ref>
    <ref id="B36-sensors-22-09205">
      <label>36.</label>
      <element-citation publication-type="confproc">
        <person-group person-group-type="author">
          <name>
            <surname>Rublee</surname>
            <given-names>E.</given-names>
          </name>
          <name>
            <surname>Rabaud</surname>
            <given-names>V.</given-names>
          </name>
          <name>
            <surname>Konolige</surname>
            <given-names>K.</given-names>
          </name>
          <name>
            <surname>Bradski</surname>
            <given-names>G.</given-names>
          </name>
        </person-group>
        <article-title>ORB: An efficient alternative to SIFT or SURF</article-title>
        <source>Proceedings of the IEEE International Conference on Computer Vision</source>
        <conf-loc>Barcelona, Spain</conf-loc>
        <conf-date>6–13 November 2011</conf-date>
        <fpage>2564</fpage>
        <lpage>2571</lpage>
        <pub-id pub-id-type="doi">10.1109/ICCV.2011.6126544</pub-id>
      </element-citation>
    </ref>
    <ref id="B37-sensors-22-09205">
      <label>37.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zarco-Tejada</surname>
            <given-names>P.J.</given-names>
          </name>
          <name>
            <surname>González-Dugo</surname>
            <given-names>V.</given-names>
          </name>
          <name>
            <surname>Berni</surname>
            <given-names>J.A.</given-names>
          </name>
        </person-group>
        <article-title>Fluorescence, temperature and narrow-band indices acquired from a UAV platform for water stress detection using a micro-hyperspectral imager and a thermal camera</article-title>
        <source>Remote Sens. Environ.</source>
        <year>2012</year>
        <volume>117</volume>
        <fpage>322</fpage>
        <lpage>337</lpage>
        <pub-id pub-id-type="doi">10.1016/j.rse.2011.10.007</pub-id>
      </element-citation>
    </ref>
    <ref id="B38-sensors-22-09205">
      <label>38.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Sola</surname>
            <given-names>I.</given-names>
          </name>
          <name>
            <surname>González-Audícana</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>álvarez Mozos</surname>
            <given-names>J.</given-names>
          </name>
        </person-group>
        <article-title>Validation of a simplified model to generate multispectral synthetic images</article-title>
        <source>Remote Sens.</source>
        <year>2015</year>
        <volume>7</volume>
        <fpage>2942</fpage>
        <lpage>2951</lpage>
        <pub-id pub-id-type="doi">10.3390/rs70302942</pub-id>
      </element-citation>
    </ref>
    <ref id="B39-sensors-22-09205">
      <label>39.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zarco-Tejada</surname>
            <given-names>P.J.</given-names>
          </name>
          <name>
            <surname>Hornero</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Hernández-Clemente</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Beck</surname>
            <given-names>P.S.</given-names>
          </name>
        </person-group>
        <article-title>Understanding the temporal dimension of the red-edge spectral region for forest decline detection using high-resolution hyperspectral and Sentinel-2a imagery</article-title>
        <source>ISPRS J. Photogramm. Remote Sens.</source>
        <year>2018</year>
        <volume>137</volume>
        <fpage>134</fpage>
        <lpage>148</lpage>
        <pub-id pub-id-type="doi">10.1016/j.isprsjprs.2018.01.017</pub-id>
        <pub-id pub-id-type="pmid">29551855</pub-id>
      </element-citation>
    </ref>
    <ref id="B40-sensors-22-09205">
      <label>40.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Richter</surname>
            <given-names>R.</given-names>
          </name>
        </person-group>
        <article-title>Correction of satellite imagery over mountainous terrain</article-title>
        <source>Appl. Opt.</source>
        <year>1998</year>
        <volume>37</volume>
        <fpage>4004</fpage>
        <lpage>4015</lpage>
        <pub-id pub-id-type="doi">10.1364/AO.37.004004</pub-id>
        <?supplied-pmid 18273372?>
        <pub-id pub-id-type="pmid">18273372</pub-id>
      </element-citation>
    </ref>
    <ref id="B41-sensors-22-09205">
      <label>41.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Gao</surname>
            <given-names>B.C.</given-names>
          </name>
          <name>
            <surname>Kaufman</surname>
            <given-names>Y.J.</given-names>
          </name>
          <name>
            <surname>Han</surname>
            <given-names>W.</given-names>
          </name>
          <name>
            <surname>Wiscombe</surname>
            <given-names>W.J.</given-names>
          </name>
        </person-group>
        <article-title>Corection of thin cirrus path radiances in the 0.4-1.0 <italic toggle="yes">μ</italic>m spectral region using the sensitive 1.375 <italic toggle="yes">μ</italic>m cirrus detecting channel</article-title>
        <source>J. Geophys. Res. Atmos.</source>
        <year>1998</year>
        <volume>103</volume>
        <fpage>32169</fpage>
        <lpage>32176</lpage>
        <pub-id pub-id-type="doi">10.1029/98JD02006</pub-id>
      </element-citation>
    </ref>
    <ref id="B42-sensors-22-09205">
      <label>42.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Gao</surname>
            <given-names>B.C.</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>R.R.</given-names>
          </name>
        </person-group>
        <article-title>Removal of thin cirrus scattering effects in landsat 8 OLI images using the cirrus detecting channel</article-title>
        <source>Remote Sens.</source>
        <year>2017</year>
        <volume>9</volume>
        <elocation-id>834</elocation-id>
        <pub-id pub-id-type="doi">10.3390/rs9080834</pub-id>
      </element-citation>
    </ref>
    <ref id="B43-sensors-22-09205">
      <label>43.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chavez</surname>
            <given-names>P.S.</given-names>
          </name>
        </person-group>
        <article-title>An improved dark-object subtraction technique for atmospheric scattering correction of multispectral data</article-title>
        <source>Remote Sens. Environ.</source>
        <year>1988</year>
        <volume>24</volume>
        <fpage>459</fpage>
        <lpage>479</lpage>
        <pub-id pub-id-type="doi">10.1016/0034-4257(88)90019-3</pub-id>
      </element-citation>
    </ref>
    <ref id="B44-sensors-22-09205">
      <label>44.</label>
      <element-citation publication-type="webpage">
        <person-group person-group-type="author">
          <name>
            <surname>Richter</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Schläpfer</surname>
            <given-names>D.</given-names>
          </name>
        </person-group>
        <article-title>Atmospheric/Topographic Correction for Satellite Imagery (ATCOR-2/3 User Guide). ATCOR-2/3 User Guide, Version 9.1.1</article-title>
        <year>2017</year>
        <comment>Available online: <ext-link xlink:href="https://www.atcor.com/wp-content/uploads/2017/02/theory.pdf" ext-link-type="uri">https://www.atcor.com/wp-content/uploads/2017/02/theory.pdf</ext-link></comment>
        <date-in-citation content-type="access-date" iso-8601-date="2022-11-23">(accessed on 23 November 2022)</date-in-citation>
      </element-citation>
    </ref>
    <ref id="B45-sensors-22-09205">
      <label>45.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Richter</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Kellenberger</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Kaufmann</surname>
            <given-names>H.</given-names>
          </name>
        </person-group>
        <article-title>Comparison of topographic correction methods</article-title>
        <source>Remote Sens.</source>
        <year>2009</year>
        <volume>1</volume>
        <fpage>184</fpage>
        <lpage>196</lpage>
        <pub-id pub-id-type="doi">10.3390/rs1030184</pub-id>
      </element-citation>
    </ref>
    <ref id="B46-sensors-22-09205">
      <label>46.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>White</surname>
            <given-names>J.C.</given-names>
          </name>
          <name>
            <surname>Gómez</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Wulder</surname>
            <given-names>M.A.</given-names>
          </name>
          <name>
            <surname>Coops</surname>
            <given-names>N.C.</given-names>
          </name>
        </person-group>
        <article-title>Characterizing temperate forest structural and spectral diversity with Hyperion EO-1 data</article-title>
        <source>Remote Sens. Environ.</source>
        <year>2010</year>
        <volume>114</volume>
        <fpage>1576</fpage>
        <lpage>1589</lpage>
        <pub-id pub-id-type="doi">10.1016/j.rse.2010.02.012</pub-id>
      </element-citation>
    </ref>
    <ref id="B47-sensors-22-09205">
      <label>47.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Berk</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Hawes</surname>
            <given-names>F.</given-names>
          </name>
        </person-group>
        <article-title>Validation of MODTRAN<sup>®</sup>6 and its line-by-line algorithm</article-title>
        <source>J. Quant. Spectrosc. Radiat. Transf.</source>
        <year>2017</year>
        <volume>203</volume>
        <fpage>542</fpage>
        <lpage>556</lpage>
        <pub-id pub-id-type="doi">10.1016/j.jqsrt.2017.03.004</pub-id>
      </element-citation>
    </ref>
  </ref-list>
</back>
<floats-group>
  <fig position="float" id="sensors-22-09205-f001">
    <label>Figure 1</label>
    <caption>
      <p>Raw hyperion bands from the L1R dataset. Although present in all bands, striping is clearly visible in band 1.</p>
    </caption>
    <graphic xlink:href="sensors-22-09205-g001" position="float"/>
  </fig>
  <fig position="float" id="sensors-22-09205-f002">
    <label>Figure 2</label>
    <caption>
      <p>Workflow of SUREHYP to retrieve surface reflectance from Hyperion L1R data. (<bold>a</bold>) Preprocessing steps; (<bold>b</bold>) Atmospheric correction steps.</p>
    </caption>
    <graphic xlink:href="sensors-22-09205-g002" position="float"/>
  </fig>
  <fig position="float" id="sensors-22-09205-f003">
    <label>Figure 3</label>
    <caption>
      <p>First six bands of the VNIR array in the MNF space computed using the whole Hyperion image, and associated column means. The spectral smile can be observed on band 4.</p>
    </caption>
    <graphic xlink:href="sensors-22-09205-g003" position="float"/>
  </fig>
  <fig position="float" id="sensors-22-09205-f004">
    <label>Figure 4</label>
    <caption>
      <p>The relative absorption depths at 940 nm and 1120 nm between (<bold>a</bold>) the sun irradiance multiplied by the atmosphere transmittance along the sun-ground-sensor optical path, as generated by SMARTS and (<bold>b</bold>) at-satellite radiance are compared to estimate the water vapor concentration in the scene.</p>
    </caption>
    <graphic xlink:href="sensors-22-09205-g004" position="float"/>
  </fig>
  <fig position="float" id="sensors-22-09205-f005">
    <label>Figure 5</label>
    <caption>
      <p>RGB (bands 29, 20, 12) composition of the Hyperion image used as a demonstration case.</p>
    </caption>
    <graphic xlink:href="sensors-22-09205-g005" position="float"/>
  </fig>
  <fig position="float" id="sensors-22-09205-f006">
    <label>Figure 6</label>
    <caption>
      <p>Spectral angle between the outputs of FLAASH and SUREHYP over the Hyperion image. Subscene (<bold>a</bold>) covers water, urban, and agricultural areas, subscene (<bold>b</bold>) contains agricultural areas, water, and hilly terrain, and subscene (<bold>c</bold>) contains hilly terrain and agricultural areas. Area (<bold>d</bold>) is a built-up area with a parking lot presenting a uniform reflectance of 0.2.</p>
    </caption>
    <graphic xlink:href="sensors-22-09205-g006" position="float"/>
  </fig>
  <fig position="float" id="sensors-22-09205-f007">
    <label>Figure 7</label>
    <caption>
      <p>Median reflectance spectra of SUREHYP and FLAASH from (top) the areas with SA &lt; 10° and (bottom) the areas with SA ≥ 10°.</p>
    </caption>
    <graphic xlink:href="sensors-22-09205-g007" position="float"/>
  </fig>
  <fig position="float" id="sensors-22-09205-f008">
    <label>Figure 8</label>
    <caption>
      <p>(<bold>top</bold>) Reflectance spectra of SUREHYP and FLAASH over area (d), (<bold>middle</bold>) absolute reflectance difference and (<bold>bottom</bold>) relative reflectance difference between SUREHYP and FLAASH outputs.</p>
    </caption>
    <graphic xlink:href="sensors-22-09205-g008" position="float"/>
  </fig>
  <fig position="float" id="sensors-22-09205-f009">
    <label>Figure 9</label>
    <caption>
      <p>For a hilly subscene, from left to right: RGB (bands 29, 20, 12) composition of SUREHYP output with a flat AC, RGB composition of SUREHYP output with the rough terrain AC, and the solar incidence angle on the surface.</p>
    </caption>
    <graphic xlink:href="sensors-22-09205-g009" position="float"/>
  </fig>
  <table-wrap position="float" id="sensors-22-09205-t001">
    <object-id pub-id-type="pii">sensors-22-09205-t001_Table 1</object-id>
    <label>Table 1</label>
    <caption>
      <p>Median absolute and relative reflectance differences between SUREHYP and FLAASH outputs over the 400–2500 nm range for area (d) (see <xref rid="sensors-22-09205-f006" ref-type="fig">Figure 6</xref> for the location).</p>
    </caption>
    <table frame="hsides" rules="groups">
      <thead>
        <tr>
          <th align="center" valign="middle" style="border-top:solid thin" rowspan="1" colspan="1">
</th>
          <th align="center" valign="middle" style="border-top:solid thin" rowspan="1" colspan="1">Blue</th>
          <th align="center" valign="middle" style="border-top:solid thin" rowspan="1" colspan="1">Green</th>
          <th align="center" valign="middle" style="border-top:solid thin" rowspan="1" colspan="1">Red</th>
          <th align="center" valign="middle" style="border-top:solid thin" rowspan="1" colspan="1">NIR</th>
          <th align="center" valign="middle" style="border-top:solid thin" rowspan="1" colspan="1">SWIR</th>
        </tr>
        <tr>
          <th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Spectral Range (nm)</th>
          <th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">450–510</th>
          <th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">510–580</th>
          <th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">580–750</th>
          <th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">750–1000</th>
          <th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1000–2500</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td align="center" valign="middle" rowspan="1" colspan="1">absolute diff. [0–1]</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">−0.008</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">−0.032</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">−0.020</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">0.022</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">0.006</td>
        </tr>
        <tr>
          <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">relative diff. (%)</td>
          <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">−4.4</td>
          <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">−14.6</td>
          <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">−9.7</td>
          <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">10.7</td>
          <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">3.76</td>
        </tr>
      </tbody>
    </table>
  </table-wrap>
</floats-group>
