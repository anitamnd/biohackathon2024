<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">J Cheminform</journal-id>
    <journal-id journal-id-type="iso-abbrev">J Cheminform</journal-id>
    <journal-title-group>
      <journal-title>Journal of Cheminformatics</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1758-2946</issn>
    <publisher>
      <publisher-name>Springer International Publishing</publisher-name>
      <publisher-loc>Cham</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">5833896</article-id>
    <article-id pub-id-type="pmid">29492726</article-id>
    <article-id pub-id-type="publisher-id">265</article-id>
    <article-id pub-id-type="doi">10.1186/s13321-018-0265-z</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Methodology</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Efficient iterative virtual screening with Apache Spark and conformal prediction</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-6877-3702</contrib-id>
        <name>
          <surname>Ahmed</surname>
          <given-names>Laeeq</given-names>
        </name>
        <address>
          <email>laeeq@kth.se</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Georgiev</surname>
          <given-names>Valentin</given-names>
        </name>
        <address>
          <email>valentin.georgiev@farmbio.uu.se</email>
        </address>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Capuccini</surname>
          <given-names>Marco</given-names>
        </name>
        <address>
          <email>marco.capuccini@it.uu.se</email>
        </address>
        <xref ref-type="aff" rid="Aff2">2</xref>
        <xref ref-type="aff" rid="Aff3">3</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Toor</surname>
          <given-names>Salman</given-names>
        </name>
        <address>
          <email>salman.toor@it.uu.se</email>
        </address>
        <xref ref-type="aff" rid="Aff3">3</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Schaal</surname>
          <given-names>Wesley</given-names>
        </name>
        <address>
          <email>wesley.schaal@farmbio.uu.se</email>
        </address>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Laure</surname>
          <given-names>Erwin</given-names>
        </name>
        <address>
          <email>erwinl@pdc.kth.se</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Spjuth</surname>
          <given-names>Ola</given-names>
        </name>
        <address>
          <email>ola.spjuth@farmbio.uu.se</email>
        </address>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ISNI">0000000121581746</institution-id><institution-id institution-id-type="GRID">grid.5037.1</institution-id><institution>Department of Computational Science and Technology, </institution><institution>Royal Institute of Technology (KTH), </institution></institution-wrap>Lindstedtsvägen 5, 10044 Stockholm, Sweden </aff>
      <aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0004 1936 9457</institution-id><institution-id institution-id-type="GRID">grid.8993.b</institution-id><institution>Department of Pharmaceutical Biosciences, </institution><institution>Uppsala University, </institution></institution-wrap>Box 591, 75124 Uppsala, Sweden </aff>
      <aff id="Aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0004 1936 9457</institution-id><institution-id institution-id-type="GRID">grid.8993.b</institution-id><institution>Department of Information Technology, </institution><institution>Uppsala University, </institution></institution-wrap>Box 337, 75105 Uppsala, Sweden </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>1</day>
      <month>3</month>
      <year>2018</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>1</day>
      <month>3</month>
      <year>2018</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2018</year>
    </pub-date>
    <volume>10</volume>
    <elocation-id>8</elocation-id>
    <history>
      <date date-type="received">
        <day>12</day>
        <month>7</month>
        <year>2017</year>
      </date>
      <date date-type="accepted">
        <day>17</day>
        <month>2</month>
        <year>2018</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2018</copyright-statement>
      <license license-type="OpenAccess">
        <license-p><bold>Open Access</bold>This article is distributed under the terms of the Creative Commons Attribution 4.0 International License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted use, distribution, and reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/publicdomain/zero/1.0/">http://creativecommons.org/publicdomain/zero/1.0/</ext-link>) applies to the data made available in this article, unless otherwise stated.</license-p>
      </license>
    </permissions>
    <abstract id="Abs1">
      <sec>
        <title>Background</title>
        <p id="Par1">Docking and scoring large libraries of ligands against target proteins forms the basis of structure-based virtual screening. The problem is trivially parallelizable, and calculations are generally carried out on computer clusters or on large workstations in a brute force manner, by docking and scoring all available ligands.</p>
      </sec>
      <sec>
        <title>Contribution</title>
        <p id="Par2">In this study we propose a strategy that is based on iteratively docking a set of ligands to form a training set, training a ligand-based model on this set, and predicting the remainder of the ligands to exclude those predicted as ‘low-scoring’ ligands. Then, another set of ligands are docked, the model is retrained and the process is repeated until a certain model efficiency level is reached. Thereafter, the remaining ligands are docked or excluded based on this model. We use SVM and conformal prediction to deliver valid prediction intervals for ranking the predicted ligands, and Apache Spark to parallelize both the docking and the modeling.</p>
      </sec>
      <sec>
        <title>Results</title>
        <p id="Par3">We show on 4 different targets that conformal prediction based virtual screening (CPVS) is able to reduce the number of docked molecules by 62.61% while retaining an accuracy for the top 30 hits of 94% on average and a speedup of 3.7. The implementation is available as open source via GitHub (<ext-link ext-link-type="uri" xlink:href="https://github.com/laeeq80/spark-cpvs">https://github.com/laeeq80/spark-cpvs</ext-link>) and can be run on high-performance computers as well as on cloud resources.</p>
        <graphic position="anchor" xlink:href="13321_2018_265_Figa_HTML" id="MO1001"/>
      </sec>
    </abstract>
    <kwd-group xml:lang="en">
      <title>Keywords</title>
      <kwd>Virtual screening</kwd>
      <kwd>Docking</kwd>
      <kwd>Conformal prediction</kwd>
      <kwd>Cloud computing</kwd>
      <kwd>Apache Spark</kwd>
    </kwd-group>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>© The Author(s) 2018</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="Sec1">
    <title>Background</title>
    <p id="Par4">An important part of the drug discovery process is lead identification, where compounds that bind to a selected target protein are identified. A well-established approach for this is high-throughput screening (HTS), which includes screening a large number of chemical compounds against a target using an automated bioassay [<xref ref-type="bibr" rid="CR1">1</xref>]. An alternative approach is in silico screening, where virtual chemical libraries are screened against a target receptor using computational methods [<xref ref-type="bibr" rid="CR2">2</xref>–<xref ref-type="bibr" rid="CR4">4</xref>]. A common method for this is molecular docking and scoring, where a docking algorithm is applied to find the best pose of the ligand in, e.g., the active site of a receptor, and a scoring function is used to evaluate the docking [<xref ref-type="bibr" rid="CR5">5</xref>]. Virtual screening is trivially parallelizable on a per-ligand basis, and there have been many approaches developed for doing this [<xref ref-type="bibr" rid="CR6">6</xref>].</p>
    <p id="Par5">Due to the recent availability of large molecule datasets (e.g., ZINC [<xref ref-type="bibr" rid="CR7">7</xref>]) and their structure being highly parallelizable, parallel approaches have been used for virtual screening. In our previous studies [<xref ref-type="bibr" rid="CR8">8</xref>, <xref ref-type="bibr" rid="CR9">9</xref>], we have shown that these large chemical libraries can be efficiently processed in parallel using Apache Spark [<xref ref-type="bibr" rid="CR10">10</xref>] and scales well with increasing computation power. However, the docking step in virtual screening takes a notable amount of time even in a parallel setting. Also, only a small number of high-scoring ligands are found in these chemical libraries during the virtual screening process and much of time is wasted docking ‘low-scoring’ ligands. The docking time can be substantially reduced if high-scoring ligands can be inferred with confidence in advance so the ligands expected to be low-scoring can be skipped.</p>
    <sec id="Sec2">
      <title>Inference and machine learning</title>
      <p id="Par6">With the availability of large datasets in the last two decades, learning from data and extracting value from such large quantities of data has become a prominent field, generally known as machine learning. Supervised machine learning is the most common technique, where the aim is to derive a mapping from input <italic>x</italic> to output <italic>y</italic>, given a labeled set of input–output pairs [<xref ref-type="bibr" rid="CR11">11</xref>]. The dataset is divided into training and test sets. Each input <italic>x</italic> in the training set is a vector of numbers representing some characteristics of the input, known as features. A model is trained using the training set and then used against the test set to get the predictions. The accuracy of the test set prediction is used to assess the model validity/performance.</p>
      <p id="Par7">Machine learning has been extensively utilized in a variety of fields and possesses nice theoretical properties. However, a common deficiency in conventional machine-learning algorithms is that they don't provide valid information about the reliability or confidence of the predictions made on the new examples [<xref ref-type="bibr" rid="CR12">12</xref>]. The most common approach is to report and assume that a model will predict with comparable performance on future examples as it performed on the test examples. However, there is then an uncertainty that the new observation might be different from the test set, which has led to discussions and fuzzy definitions on a model's 'applicability domain'. What is desired is instead object-based confidence levels, and Conformal prediction is one such mathematical framework that gives valid confidence levels on predictions for each example, and answers the question: How good is your prediction?</p>
    </sec>
    <sec id="Sec3">
      <title>Conformal prediction</title>
      <p id="Par8">Conformal prediction is a method devised by Vovk et al. [<xref ref-type="bibr" rid="CR13">13</xref>] that utilizes earlier knowledge to decide exact levels of confidence in new predictions. Conformal prediction can be used in combination with almost any underlying regression or classification algorithm, e.g., support-vector machines, gradient boosting, neural networks, and random forests. In the case of classification models, conformal prediction produces a set of labels, e.g., in binary classification it produces {0}, {1}, {0, 1} and { } sets. Although the output is a region or multi-classed rather than a point prediction, the main benefit of the technique is the model validity with user-provided confidence threshold. For example, in a binary classifier the true label is on average not excluded more than the confidence threshold, e.g., if the confidence level is 90%, then in 10% of the cases the true label will be excluded.</p>
      <p id="Par9">One of the basic setups for conformal prediction is the transductive approach. In this scenario, the model is retrained for each new observation. However, this is quite computationally expensive especially for problems with large datasets and therefore an inductive or batch setting has become popular, called Inductive Conformal Prediction (ICP) [<xref ref-type="bibr" rid="CR14">14</xref>].</p>
      <p id="Par10">The way ICP works in a classification setting is fairly simple. Initially, a training set and a test set of examples with labels is required. The training set is divided into a proper training set and a calibration set. The training set is used to train a model using any underlying algorithm. The calibration set is used to measure a <italic>nonconformity score</italic> for each observation in the calibration set, which is a measure of how different the current example is compared to the training set. The model is then used to predict the examples in the test set, and for each class label <inline-formula id="IEq1"><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$l = 1, \ldots , k$$\end{document}</tex-math><mml:math id="M2"><mml:mrow><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="13321_2018_265_Article_IEq1.gif"/></alternatives></inline-formula>, a p-value of <italic>x</italic> for class <italic>l</italic> is computed. If the p-value for class label <italic>l</italic> is greater than <inline-formula id="IEq2"><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\upvarepsilon }$$\end{document}</tex-math><mml:math id="M4"><mml:mi mathvariant="normal">ε</mml:mi></mml:math><inline-graphic xlink:href="13321_2018_265_Article_IEq2.gif"/></alternatives></inline-formula>, it is added to the prediction set. Using this strategy, it is guaranteed that on average the true label of <italic>x</italic> will be present in the prediction set with probability <inline-formula id="IEq3"><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$1-{\upvarepsilon }$$\end{document}</tex-math><mml:math id="M6"><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi mathvariant="normal">ε</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="13321_2018_265_Article_IEq3.gif"/></alternatives></inline-formula> [<xref ref-type="bibr" rid="CR14">14</xref>].</p>
      <p id="Par11">Conformal prediction has been successfully used for moderate to small datasets in quantitative structure-activity relationship (QSAR) predictive modeling [<xref ref-type="bibr" rid="CR15">15</xref>, <xref ref-type="bibr" rid="CR16">16</xref>], complication risk prediction following a coronary drug eluting stent procedure (<inline-formula id="IEq4"><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sim$$\end{document}</tex-math><mml:math id="M8"><mml:mo>∼</mml:mo></mml:math><inline-graphic xlink:href="13321_2018_265_Article_IEq4.gif"/></alternatives></inline-formula> 2 K examples) [<xref ref-type="bibr" rid="CR17">17</xref>], and anomaly detection of trajectories [<xref ref-type="bibr" rid="CR18">18</xref>]. In a recent study by Svensson et al. [<xref ref-type="bibr" rid="CR19">19</xref>], a conformal prediction based iterative approach is proposed for efficient screening. Docking was performed on an initial small dataset and then conformal predictors were used to find active molecules in an iterative fashion.</p>
    </sec>
    <sec id="Sec4">
      <title>Apache Spark and MLlib</title>
      <p id="Par12">Apache Spark [<xref ref-type="bibr" rid="CR10">10</xref>] is a parallel programming and execution framework for cluster computing that is fast and easy to use. In terms of speed, it's much faster than the well-known Google MapReduce [<xref ref-type="bibr" rid="CR20">20</xref>] and its open source implementation, Apache Hadoop. One reason for its agility is keeping the data in-memory with support for iterative processing. A detailed discussion is provided in our earlier work [<xref ref-type="bibr" rid="CR8">8</xref>, <xref ref-type="bibr" rid="CR9">9</xref>] on choosing Spark for parallel virtual screening in comparison to other parallel frameworks, such as OpenMPI, MPI and Google MapReduce.</p>
      <p id="Par13">Another advantage of Spark is the scalable machine learning library, MLlib. MLlib includes many machine learning algorithms such as classification, regression, clustering and collaborative filtering and useful tools such as featurization, machine learning pipelines, statistics and linear algebra utilities. It is an open source project and has a rapidly growing community of developers. It has been successfully used for various parallel machine learning projects, e.g., Capuccini et al. [<xref ref-type="bibr" rid="CR21">21</xref>] presents an MLlib-based distributed conformal prediction implementation for valid confidence estimation for large dataset problems and shows the validity and scalability of the algorithms using two large datasets.</p>
      <p id="Par14">Here we present a novel strategy for distributed structure-based virtual screening using Spark's MLlib library, distributed conformal prediction [<xref ref-type="bibr" rid="CR21">21</xref>] and support vector machines (SVM) [<xref ref-type="bibr" rid="CR22">22</xref>]. The objective is to avoid docking molecules that can be predicted as ‘low-scoring’ ligands with a certain confidence. To achieve this we dock a subset of molecules iteratively and the conformal predictor is re-trained until the model reaches a certain efficiency level, whereafter all remaining ligands predicted as 'high-scoring' are docked. Our results show that with this strategy we are able to dock much fewer molecules than in normal virtual screening while retaining a high sensitivity.</p>
    </sec>
  </sec>
  <sec id="Sec5">
    <title>Methods</title>
    <sec id="Sec6">
      <title>Data</title>
      <p id="Par15">We used the SureChEMBL molecule library [<xref ref-type="bibr" rid="CR23">23</xref>] for our benchmarks, downloaded from ZINC [<xref ref-type="bibr" rid="CR7">7</xref>] in ready-to-dock SDF format. The library contains <inline-formula id="IEq5"><alternatives><tex-math id="M9">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sim$$\end{document}</tex-math><mml:math id="M10"><mml:mo>∼</mml:mo></mml:math><inline-graphic xlink:href="13321_2018_265_Article_IEq5.gif"/></alternatives></inline-formula> 2.2 M molecules and takes <inline-formula id="IEq6"><alternatives><tex-math id="M11">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sim$$\end{document}</tex-math><mml:math id="M12"><mml:mo>∼</mml:mo></mml:math><inline-graphic xlink:href="13321_2018_265_Article_IEq6.gif"/></alternatives></inline-formula> 8 GB of disk space. Molecules were described using the signature molecular descriptor [<xref ref-type="bibr" rid="CR24">24</xref>], which is a 2D graph based on the signature of atoms in the molecule, where an atom signature is a representation of the atom's local environment in terms of neighboring atoms up to a specified distance (height). We used a parallel spark based implementation of the signature descriptor [<xref ref-type="bibr" rid="CR25">25</xref>] and set the consecutive signature heights 1–3, i.e., an atom at a distance of max 3 edges. An earlier study [<xref ref-type="bibr" rid="CR26">26</xref>] suggests that signature height 1–3 produces good results for molecular classification with SVM based models. OEDocking TK [<xref ref-type="bibr" rid="CR27">27</xref>] was used as the underlying docking software and as target proteins for the docking we chose the HIV-1 protease [<xref ref-type="bibr" rid="CR28">28</xref>], PTPN22, MMP13 and CTDSP1 [<xref ref-type="bibr" rid="CR29">29</xref>].</p>
    </sec>
    <sec id="Sec7">
      <title>Analysis workflow</title>
      <p id="Par16">The objective of conformal prediction based virtual screening (CPVS) is to reduce total time by avoiding the docking of molecules that can be predicted as ‘low-scoring’ ligands and only dock compounds that are predicted as ‘high-scoring’ ligands with a certain confidence. The workflow is shown in Fig. <xref rid="Fig1" ref-type="fig">1</xref>.<fig id="Fig1"><label>Fig. 1</label><caption><p>Workflow of CPVS. Signatures were generated for the whole dataset with two copies named <italic>Ds</italic> and <italic>DsComplete</italic>. An initial sample of <italic>DsInit</italic> number of molecules was randomly taken from <italic>Ds</italic> and docked against a chosen receptor and scores were calculated. To form a training set, docking scores were converted to class labels {0} and {1} representing ‘low-scoring’ and ‘high-scoring’ ligands, respectively. This was done using a 10-bin histogram of the docking scores where labels were assigned to ligands in different bins. An SVM-based conformal predictor model was trained on the training set and predictions were made on the whole Dataset <italic>DsComplete</italic>. The molecules were classified as ‘low-scoring’ ligands {0}, ‘high-scoring’ ligands {1} and 'unknown'. The predicted ‘low-scoring’ ligands were removed from <italic>Ds</italic> in each iteration and were hence never docked. Model efficiency was computed by finding the ratio of single label predictions [<xref ref-type="bibr" rid="CR30">30</xref>], i.e., {0} and {1} against all predictions. The process was then repeated iteratively with a smaller data sample <italic>DsIncr</italic> from <italic>Ds</italic> which was docked and labeled, and the model was re-trained until it reached an acceptable efficiency. Thereafter all remaining ‘high-scoring’ ligands were docked. The scores of all docked molecules were sorted and accuracy for top 30 molecules was computed against the results from an experiment where all molecules were docked [<xref ref-type="bibr" rid="CR9">9</xref>]</p></caption><graphic xlink:href="13321_2018_265_Fig1_HTML" id="MO1"/></fig>
</p>
      <p id="Par17">Initially, signatures were calculated for all molecules in the whole dataset, and two copies of it were made: <italic>Ds</italic> and <italic>DsComplete</italic>. An initial sample of <italic>DsInit</italic> number of molecules was randomly taken from <italic>Ds</italic> and docked against a chosen receptor and scores were calculated. To form a training set, docking scores were converted to class labels {0} and {1} representing ‘low-scoring’ and ‘high-scoring’ ligands, respectively. This was done using a 10-bin histogram of the docking scores where labels were assigned to molecules in different bins. A conformal predictor was trained on the training set and predictions were made on the whole dataset, <italic>DsComplete</italic>. The molecules were classified as ‘low-scoring’ ligands {0}, ‘high-scoring’ ligands {1} and ‘unknown’, i.e., both lables {0, 1} or empty {}. The predicted ‘low-scoring’ ligands were removed from <italic>Ds</italic> in each iteration and were hence never docked. Model efficiency was computed by finding the ratio of single label predictions [<xref ref-type="bibr" rid="CR30">30</xref>], i.e., {0} and {1} against all predictions. The process was then repeated iteratively with a smaller data sample <italic>DsIncr</italic> from <italic>Ds</italic>. The predictor was re-trained until it reached an acceptable efficiency, and all remaining ‘high-scoring’ ligands were docked. The scores of all docked molecules were sorted and accuracy for top 30 molecules was computed against the results from an experiment where all molecules were docked [<xref ref-type="bibr" rid="CR9">9</xref>].</p>
      <sec id="Sec8">
        <title>Modeling</title>
        <p id="Par18">We used a mondrian inductive conformal prediction (ICP) approach with SVM as underlying modeling method, a widely-used machine learning algorithm for predictive modeling [<xref ref-type="bibr" rid="CR31">31</xref>, <xref ref-type="bibr" rid="CR32">32</xref>]. We used linear SVM, which has previously shown good results for QSAR modeling [<xref ref-type="bibr" rid="CR33">33</xref>, <xref ref-type="bibr" rid="CR34">34</xref>], and used the implementation in Spark MLlib with L-BFGS for optimization because it works well with imbalanced datasets. A maximum of 50 iterations were used for L-BFGS optimization. The training set was randomly divided into 10% as calibration set and 90% as proper training set and the confidence level was set at 80%, which has been shown to work well in earlier studies with imbalanced datasets [<xref ref-type="bibr" rid="CR35">35</xref>].</p>
      </sec>
    </sec>
  </sec>
  <sec id="Sec9">
    <title>Results</title>
    <p id="Par19">In order to tune our workflow, a number of parameters need to be selected in order to reduce the overall time for the virtual screening. This includes minimizing the number of docked molecules and keeping the size of training sets used for modeling as small as possible to avoid overly time-consuming training.</p>
    <sec id="Sec10">
      <title>Initial training set and labeling strategy</title>
      <p id="Par20">A critical component in the analysis is the first predictive model, and the initial training set must be of sufficient size to produce robust results with a minimum of false positives. The sizes of initial training set <italic>DsInit</italic> tested were 50, 100, 200 and 300 K.</p>
      <p id="Par21">Docking scores were divided into 10-bin histograms, where some bins were assigned as ‘low-scoring’ or ‘high-scoring’. Four combinations were evaluated: 1_6, 1_5, 1_4, 2_4, where the first number is the highest bin for ‘low-scoring’ and the second number is lowest bin for ‘high-scoring’ ligands. For example, 2_4 declares that bins 1 and 2 contain ‘low-scoring’ ligands while bins 4 through 10 contain ‘high-scoring’ ligands. The unassigned bin 3 is excluded from training. Figure <xref rid="Fig2" ref-type="fig">2</xref> shows an example docking score histogram for a sample of 200 K ligands in log scale. The data distribution is skewed because we have fewer molecules with high scores, which is normal for these types of datasets as only a few ligands have a good fit with the target protein and the majority will not bind with high affinity.<fig id="Fig2"><label>Fig. 2</label><caption><p>Docking score histogram for 200 K ligands shows an example docking score histogram for a sample of 200 K ligands in log scale. The data distribution is skewed right because we have fewer molecules with high scores, which is normal for these types of datasets as only a few ligands have a good fit with the target protein and the majority will not bind with high affinity</p></caption><graphic xlink:href="13321_2018_265_Fig2_HTML" id="MO2"/></fig>
</p>
      <p id="Par22">The labeling of the initial sample of <italic>DsInit</italic> as ‘low-scoring’ ligands needs to contain as few (observed) high-scoring binders as possible, hence the number of bins selected as class 0 should be kept low. The labeling of ‘high-scoring’ ligands should minimize the chance of not including (observed) high-scoring binders, hence the number of bins selected as class 1 should be kept high. This formed the basis for choosing the evaluated bin combinations (see Table <xref rid="Tab1" ref-type="table">1</xref>).<table-wrap id="Tab1"><label>Table 1</label><caption><p>Effect of <italic>DsInit</italic> size and bin combination on accuracy and efficiency for the initial trained model (repeated 10 times)</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Trail no.</th><th align="left"><italic>DsInit</italic> (K)</th><th align="left">Bins</th><th align="left">Accu. (avg)</th><th align="left">Accu. (SD)</th><th align="left">Eff. (avg)</th><th align="left">Eff. (SD)</th></tr></thead><tbody><tr><td align="left">1</td><td char="." align="char">50</td><td align="left">1_6</td><td char="." align="char">45.33</td><td char="." align="char">47.22</td><td char="." align="char">65</td><td char="." align="char">23</td></tr><tr><td align="left">2</td><td char="." align="char">50</td><td align="left">1_5</td><td char="." align="char">65.33</td><td char="." align="char">43.95</td><td char="." align="char">63</td><td char="." align="char">23</td></tr><tr><td align="left">3</td><td char="." align="char">50</td><td align="left">1_4</td><td char="." align="char">78.34</td><td char="." align="char">41.31</td><td char="." align="char">44</td><td char="." align="char">17</td></tr><tr><td align="left">4</td><td char="." align="char">50</td><td align="left">2_4</td><td char="." align="char">94.34</td><td char="." align="char">4.46</td><td char="." align="char">79</td><td char="." align="char">18</td></tr><tr><td align="left">5</td><td char="." align="char">100</td><td align="left">1_6</td><td char="." align="char">89.67</td><td char="." align="char">6.37</td><td char="." align="char">73</td><td char="." align="char">16</td></tr><tr><td align="left">6</td><td char="." align="char">100</td><td align="left">1_5</td><td char="." align="char">94.67</td><td char="." align="char">5.92</td><td char="." align="char">75</td><td char="." align="char">18</td></tr><tr><td align="left">7</td><td char="." align="char">100</td><td align="left">1_4</td><td char="." align="char">88.34</td><td char="." align="char">29.91</td><td char="." align="char">31</td><td char="." align="char">12</td></tr><tr><td align="left">8</td><td char="." align="char">100</td><td align="left">2_4</td><td char="." align="char">89.67</td><td char="." align="char">7.45</td><td char="." align="char">91</td><td char="." align="char">11</td></tr><tr><td align="left">9</td><td char="." align="char">200</td><td align="left">1_6</td><td char="." align="char">93.00</td><td char="." align="char">3.99</td><td char="." align="char">65</td><td char="." align="char">15</td></tr><tr><td align="left">10</td><td char="." align="char">200</td><td align="left">1_5</td><td char="." align="char">96.34</td><td char="." align="char">1.89</td><td char="." align="char">76</td><td char="." align="char">17</td></tr><tr><td align="left">11</td><td char="." align="char">200</td><td align="left">1_4</td><td char="." align="char">97.67</td><td char="." align="char">2.25</td><td char="." align="char">43</td><td char="." align="char">20</td></tr><tr><td align="left">12</td><td char="." align="char">200</td><td align="left">2_4</td><td char="." align="char">90.34</td><td char="." align="char">9.74</td><td char="." align="char">91</td><td char="." align="char">6</td></tr><tr><td align="left">13</td><td char="." align="char">300</td><td align="left">1_6</td><td char="." align="char">86.67</td><td char="." align="char">8.01</td><td char="." align="char">44</td><td char="." align="char">12</td></tr><tr><td align="left">14</td><td char="." align="char">300</td><td align="left">1_5</td><td char="." align="char">95.34</td><td char="." align="char">4.50</td><td char="." align="char">63</td><td char="." align="char">17</td></tr><tr><td align="left">15</td><td char="." align="char">300</td><td align="left">1_4</td><td char="." align="char">98.34</td><td char="." align="char">1.76</td><td char="." align="char">54</td><td char="." align="char">22</td></tr><tr><td align="left">16</td><td char="." align="char">300</td><td align="left">2_4</td><td char="." align="char">86.00</td><td char="." align="char">7.17</td><td char="." align="char">94</td><td char="." align="char">5</td></tr></tbody></table></table-wrap>
</p>
      <p id="Par23">Table <xref rid="Tab1" ref-type="table">1</xref> shows the effect of the different combinations of <italic>DsInit</italic> size and labeling parameters on accuracy and efficiency after the first iteration. Each run was repeated 10 times and the average and standard deviation for accuracy and efficiency was computed. In general, increased efficiency and accuracy was reported with increased size of <italic>DsInit</italic>, but the labeling strategy based on bins combination also affected the results. Runs with <italic>DsInit</italic> size 50 and 100 K were discarded because of the risk of fluctuation in the first model due to sampling issues with smaller datasets, observable by higher variance in the accuracy. For the remaining runs, the best combination of high model accuracy and efficiency was sought. Higher accuracy of the initial model reduces the chances of discarding actual high-scoring binders, and higher efficiency implies fewer iterations to reach sufficient model efficiency in the iterative model building. We selected run 10 in Table <xref rid="Tab1" ref-type="table">1</xref>, i.e., the parameters with <italic>DsInit</italic> size 200 K and bins 1_5, which had a mean accuracy of 96.34% and an efficiency of 76%.</p>
    </sec>
    <sec id="Sec11">
      <title>Incremental model building</title>
      <p id="Par24">Improving the efficiency of the model in each iteration requires sufficient amount of new data added to the training set. Table <xref rid="Tab2" ref-type="table">2</xref> shows the effect of <italic>DsIncr</italic> size on accuracy and model efficiency. We evaluated values 50, 100 and 200 K for <italic>DsIncr</italic> and ran the iterative implementation until the desired efficiency was reached. Each run was performed 20 times. Accuracy and efficiency of the final models in all three setting were good and similar to each other. In terms of time consumption, a <italic>DsIncr</italic> size of 100 K required the least total time to complete. The two core factors that contribute to the total time are the number of docked molecules and the time used for model training and predictions. The number of molecules docked for all three settings were rather similar, i.e, <inline-formula id="IEq7"><alternatives><tex-math id="M13">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sim$$\end{document}</tex-math><mml:math id="M14"><mml:mo>∼</mml:mo></mml:math><inline-graphic xlink:href="13321_2018_265_Article_IEq7.gif"/></alternatives></inline-formula> 0.8 million. In all three settings, the model eventually reached the required 80% efficiency though the smaller <italic>DsIncr</italic> needed more iterations. With <italic>DsIncr</italic> size as 50 K, an average of 3.90 models needed to be trained whereas with <italic>DsIncr</italic> size as 200 K, although we need to train only 3.15 models, each model training takes more time because of larger size of data. Based on this argumentation, <italic>DsIncr</italic> size was set to 100 K for the final runs.<table-wrap id="Tab2"><label>Table 2</label><caption><p>Selecting <italic>DsIncr</italic> size for incremental model building (repeated 20 times, mean values reported)</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left"><italic>DsIncr</italic> (K)</th><th align="left">Iterations</th><th align="left">Accu.</th><th align="left">Eff.</th><th align="left">Docked mols (millions)</th><th align="left">Total time (relative)</th></tr></thead><tbody><tr><td align="left">50</td><td char="." align="char">3.9</td><td char="." align="char">96.5</td><td char="." align="char">0.91</td><td char="." align="char">0.77</td><td align="left">1</td></tr><tr><td align="left">100</td><td char="." align="char">3.35</td><td char="." align="char">96.84</td><td char="." align="char">0.91</td><td char="." align="char">0.81</td><td align="left">0.96</td></tr><tr><td align="left">200</td><td char="." align="char">3.15</td><td char="." align="char">97.17</td><td char="." align="char">0.91</td><td char="." align="char">0.79</td><td align="left">1.12</td></tr></tbody></table><table-wrap-foot><p>Paremeters <italic>DsInit</italic> size = 200 K and Bins = 1_5 for all runs. Time was calculated relative to 50 K</p></table-wrap-foot></table-wrap>
</p>
    </sec>
    <sec id="Sec12">
      <title>Efficiency of CPVS</title>
      <p id="Par25">We evaluated the performance of CPVS in terms of reduction of total time, benchmarked against our previous study [<xref ref-type="bibr" rid="CR9">9</xref>] (referred to as PVS) where the same dataset was processed in the same parallel fashion but without the machine learning component to filter out ‘low-scoring’ leads.</p>
      <sec id="Sec13">
        <title>Experimental environment</title>
        <p id="Par26">A standalone Spark cluster, along with HDFS was launched on the SNIC Science Cloud (SSC) [<xref ref-type="bibr" rid="CR36">36</xref>] using SparkNow [<xref ref-type="bibr" rid="CR37">37</xref>] for automated image creation and initiating required services on virtual machines. A total of 12 nodes were launched each with 8 virtual CPUs (vCPUs), 16 GB of RAM, 160 GB of disk storage and 40 GB of block storage. It was a completely virtualized environment and in that sense similar to commodity computing based clusters. One node was used as the Spark driver, which did not take part in processing. The remaining 11 nodes were used as workers with a total of 88 cores.</p>
      </sec>
      <sec id="Sec14">
        <title>Benchmarking</title>
        <p id="Par27">As summarized in Fig. <xref rid="Fig3" ref-type="fig">3</xref>, both the PVS and CPVS runs were executed on the same computational infrastructure and the time for job completion was recorded. PVS, performing an exhaustive search, was executed once and took 11.8, 8.30, 8.20 and 9.30 hours to complete against HIV-1, PTPN22, MMP13 and CTDSP1 receptors respectively.<fig id="Fig3"><label>Fig. 3</label><caption><p>Benchmarking CPVS against parallel VS. On average, only 37.39% of the ligands were docked to reach an accuracy level of <inline-formula id="IEq8"><alternatives><tex-math id="M15">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sim$$\end{document}</tex-math><mml:math id="M16"><mml:mo>∼</mml:mo></mml:math><inline-graphic xlink:href="13321_2018_265_Article_IEq8.gif"/></alternatives></inline-formula> 94%. By decreasing the number of docked molecules, CPVS saves more than two-thirds of the time and got an average speedup of 3.7 in comparison to Parallel VS [<xref ref-type="bibr" rid="CR9">9</xref>]</p></caption><graphic xlink:href="13321_2018_265_Fig3_HTML" id="MO3"/></fig>
</p>
        <p id="Par28">CPVS was executed 10 times for each target receptor and the results are given in Table <xref rid="Tab3" ref-type="table">3</xref>. For all four receptors, CPVS completed at least three times faster than PVS and the accuracy was at least 90%. The average accuracy for all four receptors is <inline-formula id="IEq9"><alternatives><tex-math id="M17">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sim$$\end{document}</tex-math><mml:math id="M18"><mml:mo>∼</mml:mo></mml:math><inline-graphic xlink:href="13321_2018_265_Article_IEq9.gif"/></alternatives></inline-formula> 94%. In general, the variance in results was low showing that the results were consistent. The average speedup (PVS total time / CPVS total time) for four receptors was computed to 3.7.<table-wrap id="Tab3"><label>Table 3</label><caption><p>Results of the CPVS method for a set of target receptors</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Receptor</th><th align="left">Iterations</th><th align="left">Accu.</th><th align="left">Docked mols (%)</th><th align="left">Time (hours)</th><th align="left">Speed up</th></tr></thead><tbody><tr><td align="left">HIV-1</td><td char="." align="char">3.9</td><td char="." align="char">97.33</td><td char="." align="char">37.15</td><td char="." align="char">4.03</td><td char="." align="char">2.93</td></tr><tr><td align="left">PTPN22</td><td char="." align="char">4.7</td><td char="." align="char">98.34</td><td char="." align="char">44.77</td><td char="." align="char">2.48</td><td char="." align="char">3.35</td></tr><tr><td align="left">MMP13</td><td char="." align="char">3.5</td><td char="." align="char">89.00</td><td char="." align="char">33.34</td><td char="." align="char">2.10</td><td char="." align="char">3.90</td></tr><tr><td align="left">CTDSP1</td><td char="." align="char">3.6</td><td char="." align="char">92.67</td><td char="." align="char">34.29</td><td char="." align="char">2.03</td><td char="." align="char">4.58</td></tr></tbody></table><table-wrap-foot><p>Results were averaged over 10 runs for each receptor</p></table-wrap-foot></table-wrap>
</p>
      </sec>
    </sec>
  </sec>
  <sec id="Sec15">
    <title>Discussion</title>
    <p id="Par29">The docking step makes structure-based virtual screening a compute intensive task that requires high-performance clusters or cloud computing resources to complete in a timely manner. Our iterative virtual screening methodology using conformal prediction to filter out molecules from the actual docking shows effective results in that on average only 37.39% of the ligands were docked to reach an accuracy level of <inline-formula id="IEq10"><alternatives><tex-math id="M19">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sim$$\end{document}</tex-math><mml:math id="M20"><mml:mo>∼</mml:mo></mml:math><inline-graphic xlink:href="13321_2018_265_Article_IEq10.gif"/></alternatives></inline-formula> 94% based on the top 30 top binders, and saving about two-thirds of the total computation time. These results complement the earlier study by Svensson et al. [<xref ref-type="bibr" rid="CR19">19</xref>] who showed that 57% of the active compounds could be found by only docking 9.4% of the compounds using the DUD ligand set of 2950 compounds using a conformal prediction approach. In CPVS we use a more realistic screening dataset of over 2.2 M compounds, and the stepwise iterative docking and machine learning on such a large dataset was facilitated by the use of Apache Spark for distributed computations and would have been complex and inefficient to carry out without a distributed data framework.</p>
    <p id="Par30">Some common data manipulation operations can be quite expensive even in a distributed environment as it could lead to a lot of data shuffling among the nodes. For labeling purposes, the histogram approach was used to tackle one such problem. Another straightforward approach could have been to compute the top and bottom percentiles but this would include initial sorting of the data based on scores which is an expensive operation in a distributed environment. Thus a lighter histogram operation was utilized, which also showed good results.</p>
    <p id="Par31">While the major advantage of the method is to shorten the virtual screening execution time, it also opens up opportunities for large-scale studies which may involve multiple target receptors and multiple large molecule libraries. The ability to execute the analyses in parallel on HPC and cloud resources makes it only limited by resources and/or costs. The instantiation of Apache Spark clusters on-demand has been a complex task earlier, but it is nowadays a straightforward operation on the major cloud providers, and there are frameworks developed that greatly simplifies this process on private clouds (e.g., SparkNow [<xref ref-type="bibr" rid="CR37">37</xref>]) or in HPC environments (e.g., spark-on-slurm [<xref ref-type="bibr" rid="CR38">38</xref>], sparkhpc [<xref ref-type="bibr" rid="CR39">39</xref>]).</p>
    <p id="Par32">Processing large datasets is time consuming and costly in that it requires large compute infrastructures to complete jobs within reasonable time. This limited our opportunity for parameter sweeps in the study and necessitated a more tailored approach. We also note that our results depend on the docking time and hence the docking implementation (OEDocking TK in our case). However we do not believe that major changes to parameters will be required in order to reach an efficient iterative docking with machine learning for other docking toolkits.</p>
  </sec>
  <sec id="Sec16">
    <title>Conclusion</title>
    <p id="Par33">In this work we present an efficient methodology for parallel virtual screening using conformal prediction to filter out ‘low-scoring’ ligands and only dock molecules that are predicted as 'high-scoring' ligands with a specified accuracy. We were able to reduce the number of docked molecules by 62.61% while retaining <inline-formula id="IEq11"><alternatives><tex-math id="M21">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sim$$\end{document}</tex-math><mml:math id="M22"><mml:mo>∼</mml:mo></mml:math><inline-graphic xlink:href="13321_2018_265_Article_IEq11.gif"/></alternatives></inline-formula> 94% accuracy for the top 30 binders. The CPVS average total time for each receptor was at least 3 times less than for PVS [<xref ref-type="bibr" rid="CR9">9</xref>] on the same dataset in the same computational environment. This makes CPVS a vital and cost effective alternative for parallel virtual screening. The source code of the implementation is publicly available on GitHub (<ext-link ext-link-type="uri" xlink:href="https://github.com/laeeq80/spark-cpvs">https://github.com/laeeq80/spark-cpvs</ext-link>).</p>
  </sec>
</body>
<back>
  <ack>
    <title>Authors' contributions</title>
    <p>LA, VG, MC and OS designed the study. LA and VG implemented the method and carried out experiments. WS and ST contributed with expertise in modeling. EL contributed with expertise in HPC. All authors read and approved the final manuscript.</p>
    <sec id="FPar1">
      <title>Acknowledgements</title>
      <p id="Par35">This project was supported by the Swedish e-Science Research Center (SeRC) and the strategic research programme eSSENCE. HPC computations were performed on resources provided by SNIC through Uppsala Multidisciplinary Center for Advanced Computational Science (UPPMAX) [<xref ref-type="bibr" rid="CR40">40</xref>] under Project b2015245. Cloud resources were provided by SNIC Science Cloud (SSC) [<xref ref-type="bibr" rid="CR36">36</xref>] under Project SNIC 2017/13-6.</p>
    </sec>
    <sec id="FPar2">
      <title>Competing interests</title>
      <p id="Par36">The authors declare that they have no competing interests.</p>
    </sec>
    <sec id="FPar3">
      <title>Availability of data and materials</title>
      <p id="Par37">The SureChEMBL molecule library [<xref ref-type="bibr" rid="CR23">23</xref>] used for our benchmarks can be downloaded from ZINC [<xref ref-type="bibr" rid="CR7">7</xref>] in ready-to-dock SDF format.</p>
    </sec>
    <sec id="FPar5">
      <title>Consent for publication</title>
      <p id="Par39">Not applicable</p>
    </sec>
    <sec id="FPar4">
      <title>Ethics approval and consent to participate</title>
      <p id="Par38">Not applicable</p>
    </sec>
    <sec id="FPar6">
      <title>Publisher's Note</title>
      <p id="Par40">Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
    </sec>
  </ack>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <label>1.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Mayr</surname>
            <given-names>LM</given-names>
          </name>
          <name>
            <surname>Bojanic</surname>
            <given-names>D</given-names>
          </name>
        </person-group>
        <article-title>Novel trends in high-throughput screening</article-title>
        <source>Curr Opin Pharmacol</source>
        <year>2009</year>
        <volume>2</volume>
        <fpage>580</fpage>
        <lpage>588</lpage>
        <pub-id pub-id-type="doi">10.1016/j.coph.2009.08.004</pub-id>
      </element-citation>
    </ref>
    <ref id="CR2">
      <label>2.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Shoichet</surname>
            <given-names>BK</given-names>
          </name>
        </person-group>
        <article-title>Virtual screening of chemical libraries</article-title>
        <source>Nature</source>
        <year>2004</year>
        <volume>432</volume>
        <issue>7019</issue>
        <fpage>862</fpage>
        <pub-id pub-id-type="doi">10.1038/nature03197</pub-id>
        <pub-id pub-id-type="pmid">15602552</pub-id>
      </element-citation>
    </ref>
    <ref id="CR3">
      <label>3.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Subramaniam</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Mehrotra</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Gupta</surname>
            <given-names>D</given-names>
          </name>
        </person-group>
        <article-title>Virtual high throughput screening (vHTS)-a perspective</article-title>
        <source>Bioinformation</source>
        <year>2008</year>
        <volume>3</volume>
        <issue>1</issue>
        <fpage>14</fpage>
        <lpage>17</lpage>
        <pub-id pub-id-type="doi">10.6026/97320630003014</pub-id>
        <pub-id pub-id-type="pmid">19052660</pub-id>
      </element-citation>
    </ref>
    <ref id="CR4">
      <label>4.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Shen</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Tian</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Pan</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Sun</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Zhou</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Lee</surname>
            <given-names>SMY</given-names>
          </name>
          <name>
            <surname>Hou</surname>
            <given-names>T</given-names>
          </name>
        </person-group>
        <article-title>Discovery of novel rock1 inhibitors via integrated virtual screening strategy and bioassays</article-title>
        <source>Sci Rep</source>
        <year>2015</year>
        <volume>5</volume>
        <fpage>16749</fpage>
        <pub-id pub-id-type="doi">10.1038/srep16749</pub-id>
        <pub-id pub-id-type="pmid">26568382</pub-id>
      </element-citation>
    </ref>
    <ref id="CR5">
      <label>5.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kitchen</surname>
            <given-names>DB</given-names>
          </name>
          <name>
            <surname>Decornez</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Furr</surname>
            <given-names>JR</given-names>
          </name>
          <name>
            <surname>Bajorath</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Docking and scoring in virtual screening for drug discovery: methods and applications</article-title>
        <source>Nat Rev Drug Discov</source>
        <year>2004</year>
        <volume>3</volume>
        <issue>11</issue>
        <fpage>935</fpage>
        <lpage>949</lpage>
        <pub-id pub-id-type="doi">10.1038/nrd1549</pub-id>
        <pub-id pub-id-type="pmid">15520816</pub-id>
      </element-citation>
    </ref>
    <ref id="CR6">
      <label>6.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Tanrikulu</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Krüger</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Proschak</surname>
            <given-names>E</given-names>
          </name>
        </person-group>
        <article-title>The holistic integration of virtual screening in drug discovery</article-title>
        <source>Drug Discov Today Vanc</source>
        <year>2013</year>
        <volume>18</volume>
        <issue>7</issue>
        <fpage>358</fpage>
        <lpage>364</lpage>
        <pub-id pub-id-type="doi">10.1016/j.drudis.2013.01.007</pub-id>
      </element-citation>
    </ref>
    <ref id="CR7">
      <label>7.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Irwin</surname>
            <given-names>JJ</given-names>
          </name>
          <name>
            <surname>Sterling</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Mysinger</surname>
            <given-names>MM</given-names>
          </name>
          <name>
            <surname>Bolstad</surname>
            <given-names>ES</given-names>
          </name>
          <name>
            <surname>Coleman</surname>
            <given-names>RG</given-names>
          </name>
        </person-group>
        <article-title>Zinc: a free tool to discover chemistry for biology</article-title>
        <source>J Chem Inf Model</source>
        <year>2012</year>
        <volume>52</volume>
        <issue>7</issue>
        <fpage>1757</fpage>
        <lpage>1768</lpage>
        <pub-id pub-id-type="doi">10.1021/ci3001277</pub-id>
        <pub-id pub-id-type="pmid">22587354</pub-id>
      </element-citation>
    </ref>
    <ref id="CR8">
      <label>8.</label>
      <mixed-citation publication-type="other">Ahmed L, Edlund A, Laure E, Spjuth O (2013) Using iterative MapReduce for parallel virtual screening. In: Proceedings of IEEE 5th international conference of cloud computing technology and science (CloudCom), vol 2, pp 27–32</mixed-citation>
    </ref>
    <ref id="CR9">
      <label>9.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Capuccini</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Ahmed</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Schaal</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Laure</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Spjuth</surname>
            <given-names>O</given-names>
          </name>
        </person-group>
        <article-title>Large-scale virtual screening on public cloud resources with apache spark</article-title>
        <source>J Chem</source>
        <year>2017</year>
        <volume>9</volume>
        <issue>1</issue>
        <fpage>15</fpage>
        <pub-id pub-id-type="doi">10.1186/s13321-017-0204-4</pub-id>
      </element-citation>
    </ref>
    <ref id="CR10">
      <label>10.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zaharia</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Chowdhury</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Franklin</surname>
            <given-names>MJ</given-names>
          </name>
          <name>
            <surname>Shenker</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Stoica</surname>
            <given-names>I</given-names>
          </name>
        </person-group>
        <article-title>Spark: cluster computing with working sets</article-title>
        <source>HotCloud</source>
        <year>2010</year>
        <volume>10</volume>
        <fpage>95</fpage>
      </element-citation>
    </ref>
    <ref id="CR11">
      <label>11.</label>
      <mixed-citation publication-type="other">Murphy KP (2012) Machine learning: a probabilistic perspective. In: Adaptive computation and machine learning. MIT Press. ISBN:0262018020. ISBN:9780262018029</mixed-citation>
    </ref>
    <ref id="CR12">
      <label>12.</label>
      <mixed-citation publication-type="other">Balasubramanian V, Ho SS, Vovk V (2014) Conformal prediction for reliable machine learning: theory, adaptations and applications. Newnes. ISBN:9780124017153</mixed-citation>
    </ref>
    <ref id="CR13">
      <label>13.</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Vovk</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Gammerman</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Shafer</surname>
            <given-names>G</given-names>
          </name>
        </person-group>
        <source>Algorithmic learning in a random world</source>
        <year>2005</year>
        <publisher-loc>Berlin</publisher-loc>
        <publisher-name>Springer</publisher-name>
      </element-citation>
    </ref>
    <ref id="CR14">
      <label>14.</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Papadopoulos</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <source>Inductive conformal prediction: theory and application to neural networks</source>
        <year>2008</year>
        <publisher-loc>Rijeka</publisher-loc>
        <publisher-name>INTECH Open Access Publisher</publisher-name>
      </element-citation>
    </ref>
    <ref id="CR15">
      <label>15.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Norinder</surname>
            <given-names>U</given-names>
          </name>
          <name>
            <surname>Carlsson</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Boyer</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Eklund</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>Introducing conformal prediction in predictive modeling. A transparent and flexible alternative to applicability domain determination</article-title>
        <source>J Chem Inf Model</source>
        <year>2014</year>
        <volume>54</volume>
        <issue>6</issue>
        <fpage>1596</fpage>
        <lpage>1603</lpage>
        <pub-id pub-id-type="doi">10.1021/ci5001168</pub-id>
        <pub-id pub-id-type="pmid">24797111</pub-id>
      </element-citation>
    </ref>
    <ref id="CR16">
      <label>16.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Eklund</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Norinder</surname>
            <given-names>U</given-names>
          </name>
          <name>
            <surname>Boyer</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Carlsson</surname>
            <given-names>L</given-names>
          </name>
        </person-group>
        <article-title>The application of conformal prediction to the drug discovery process</article-title>
        <source>Ann Math Artif Intell</source>
        <year>2015</year>
        <volume>74</volume>
        <issue>1–2</issue>
        <fpage>117</fpage>
        <lpage>132</lpage>
        <pub-id pub-id-type="doi">10.1007/s10472-013-9378-2</pub-id>
      </element-citation>
    </ref>
    <ref id="CR17">
      <label>17.</label>
      <mixed-citation publication-type="other">Balasubramanian VN, Gouripeddi R, Panchanathan S, Vermillion J, Bhaskaran A, Siegel RM (2009) Support vector machine based conformal predictors for risk of complications following a coronary drug eluting stent procedure. In: IEEE Computers in Cardiology, pp 5–8</mixed-citation>
    </ref>
    <ref id="CR18">
      <label>18.</label>
      <mixed-citation publication-type="other">Smith J, Nouretdinov I, Craddock R, Offer C, Gammerman A (2015) Conformal anomaly detection of trajectories with a multi-class hierarchy. In: International symposium on statistical learning and data sciences, pp 281–290</mixed-citation>
    </ref>
    <ref id="CR19">
      <label>19.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Svensson</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Norinder</surname>
            <given-names>U</given-names>
          </name>
          <name>
            <surname>Bender</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Improving screening efficiency through iterative screening using docking and conformal prediction</article-title>
        <source>J Chem Inf Model</source>
        <year>2017</year>
        <volume>57</volume>
        <issue>3</issue>
        <fpage>439</fpage>
        <lpage>444</lpage>
        <pub-id pub-id-type="doi">10.1021/acs.jcim.6b00532</pub-id>
        <pub-id pub-id-type="pmid">28195474</pub-id>
      </element-citation>
    </ref>
    <ref id="CR20">
      <label>20.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Dean</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Ghemawat</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>MapReduce: simplified data processing on large clusters</article-title>
        <source>Commun ACM</source>
        <year>2008</year>
        <volume>51</volume>
        <issue>1</issue>
        <fpage>107</fpage>
        <lpage>113</lpage>
        <pub-id pub-id-type="doi">10.1145/1327452.1327492</pub-id>
      </element-citation>
    </ref>
    <ref id="CR21">
      <label>21.</label>
      <mixed-citation publication-type="other">Capuccini M, Carlsson L, Norinder U, Spjuth O (2015) Conformal prediction in spark: large-scale machine learning with confidence. In: IEEE/ACM 2nd international symposium on big data computing (BDC), pp 61–67</mixed-citation>
    </ref>
    <ref id="CR22">
      <label>22.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Cortes</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Vapnik</surname>
            <given-names>V</given-names>
          </name>
        </person-group>
        <article-title>Support-vector networks</article-title>
        <source>Mach Learn</source>
        <year>1995</year>
        <volume>20</volume>
        <issue>3</issue>
        <fpage>273</fpage>
        <lpage>297</lpage>
      </element-citation>
    </ref>
    <ref id="CR23">
      <label>23.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Papadatos</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Davies</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Dedman</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Chambers</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Gaulton</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Siddle</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Koks</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Irvine</surname>
            <given-names>SA</given-names>
          </name>
          <name>
            <surname>Pettersson</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Goncharoff</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Hersey</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>SureChEMBL: a large-scale, chemically annotated patent document database</article-title>
        <source>Nucleic Acids Res</source>
        <year>2016</year>
        <volume>44</volume>
        <issue>D1</issue>
        <fpage>1220</fpage>
        <lpage>1228</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkv1253</pub-id>
      </element-citation>
    </ref>
    <ref id="CR24">
      <label>24.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Faulon</surname>
            <given-names>JL</given-names>
          </name>
          <name>
            <surname>Visco</surname>
            <given-names>DP</given-names>
          </name>
          <name>
            <surname>Pophale</surname>
            <given-names>RS</given-names>
          </name>
        </person-group>
        <article-title>The signature molecular descriptor. 1. Using extended valence sequences in QSAR and QSPR studies</article-title>
        <source>J Chem Inf Comput Sci</source>
        <year>2003</year>
        <volume>43</volume>
        <issue>3</issue>
        <fpage>707</fpage>
        <lpage>720</lpage>
        <pub-id pub-id-type="doi">10.1021/ci020345w</pub-id>
        <pub-id pub-id-type="pmid">12767129</pub-id>
      </element-citation>
    </ref>
    <ref id="CR25">
      <label>25.</label>
      <mixed-citation publication-type="other">Capuccini M Spark Cheminformatics Utils. <ext-link ext-link-type="uri" xlink:href="https://github.com/mcapuccini/spark-cheminformatics">https://github.com/mcapuccini/spark-cheminformatics</ext-link>. Accessed 11 Oct 2016</mixed-citation>
    </ref>
    <ref id="CR26">
      <label>26.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Alvarsson</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Eklund</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Andersson</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Carlsson</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Spjuth</surname>
            <given-names>O</given-names>
          </name>
          <name>
            <surname>Wikberg</surname>
            <given-names>JE</given-names>
          </name>
        </person-group>
        <article-title>Benchmarking study of parameter variation when using signature fingerprints together with support vector machines</article-title>
        <source>J Chem Inf Model</source>
        <year>2014</year>
        <volume>54</volume>
        <issue>11</issue>
        <fpage>3211</fpage>
        <lpage>3217</lpage>
        <pub-id pub-id-type="doi">10.1021/ci500344v</pub-id>
        <pub-id pub-id-type="pmid">25318024</pub-id>
      </element-citation>
    </ref>
    <ref id="CR27">
      <label>27.</label>
      <mixed-citation publication-type="other">OEDocking TK <ext-link ext-link-type="uri" xlink:href="http://www.eyesopen.com/oedocking-tk">http://www.eyesopen.com/oedocking-tk</ext-link>. Accessed 13 July 2016</mixed-citation>
    </ref>
    <ref id="CR28">
      <label>28.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Bäckbro</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Löwgren</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Österlund</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Atepo</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Unge</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Hultén</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Bonham</surname>
            <given-names>NM</given-names>
          </name>
          <name>
            <surname>Schaal</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Karlén</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Hallberg</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Unexpected binding mode of a cyclic sulfamide HIV-1 protease inhibitor</article-title>
        <source>J Med Chem</source>
        <year>1997</year>
        <volume>40</volume>
        <issue>6</issue>
        <fpage>898</fpage>
        <lpage>902</lpage>
        <pub-id pub-id-type="doi">10.1021/jm960588d</pub-id>
        <pub-id pub-id-type="pmid">9083478</pub-id>
      </element-citation>
    </ref>
    <ref id="CR29">
      <label>29.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lindh</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Svensson</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Schaal</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Sköld</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Brandt</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Karlén</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Toward a benchmarking data set able to evaluate ligand-and structure-based virtual screening using public hts data</article-title>
        <source>J Chem Inf Model</source>
        <year>2015</year>
        <volume>55</volume>
        <issue>2</issue>
        <fpage>343</fpage>
        <lpage>353</lpage>
        <pub-id pub-id-type="doi">10.1021/ci5005465</pub-id>
        <pub-id pub-id-type="pmid">25564966</pub-id>
      </element-citation>
    </ref>
    <ref id="CR30">
      <label>30.</label>
      <mixed-citation publication-type="other">Vovk V, Fedorova V, Nouretdinov I, Gammerman A (2016) Criteria of efficiency for conformal prediction. In: Proceedings of the 5th international symposium on conformal and probabilistic prediction with applications - volume 9653. COPA 2016. Springer, New York, pp 23–39</mixed-citation>
    </ref>
    <ref id="CR31">
      <label>31.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Vogt</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Bajorath</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Chemoinformatics: a view of the field and current trends in method development</article-title>
        <source>Bioorganic Med Chem</source>
        <year>2012</year>
        <volume>20</volume>
        <issue>18</issue>
        <fpage>5317</fpage>
        <lpage>5323</lpage>
        <pub-id pub-id-type="doi">10.1016/j.bmc.2012.03.030</pub-id>
      </element-citation>
    </ref>
    <ref id="CR32">
      <label>32.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Mitchell</surname>
            <given-names>JB</given-names>
          </name>
        </person-group>
        <article-title>Machine learning methods in chemoinformatics</article-title>
        <source>Wiley Interdiscip Rev Comput Mol Sci</source>
        <year>2014</year>
        <volume>4</volume>
        <issue>5</issue>
        <fpage>468</fpage>
        <lpage>481</lpage>
        <pub-id pub-id-type="doi">10.1002/wcms.1183</pub-id>
        <pub-id pub-id-type="pmid">25285160</pub-id>
      </element-citation>
    </ref>
    <ref id="CR33">
      <label>33.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Norinder</surname>
            <given-names>U</given-names>
          </name>
        </person-group>
        <article-title>Support vector machine models in drug design: applications to drug transport processes and QSAR using simplex optimisations and variable selection</article-title>
        <source>Neurocomputing</source>
        <year>2003</year>
        <volume>55</volume>
        <issue>1</issue>
        <fpage>337</fpage>
        <lpage>346</lpage>
        <pub-id pub-id-type="doi">10.1016/S0925-2312(03)00374-6</pub-id>
      </element-citation>
    </ref>
    <ref id="CR34">
      <label>34.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Sun</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Pan</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Tian</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Xu</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Kong</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Hou</surname>
            <given-names>T</given-names>
          </name>
        </person-group>
        <article-title>Constructing and validating high-performance miec-svm models in virtual screening for kinases: a better way for actives discovery</article-title>
        <source>Sci Rep</source>
        <year>2016</year>
        <volume>6</volume>
        <fpage>24817</fpage>
        <pub-id pub-id-type="doi">10.1038/srep24817</pub-id>
        <pub-id pub-id-type="pmid">27102549</pub-id>
      </element-citation>
    </ref>
    <ref id="CR35">
      <label>35.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Norinder</surname>
            <given-names>U</given-names>
          </name>
          <name>
            <surname>Boyer</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>Binary classification of imbalanced datasets using conformal prediction</article-title>
        <source>J Mol Gr Model</source>
        <year>2017</year>
        <volume>72</volume>
        <fpage>256</fpage>
        <lpage>265</lpage>
        <pub-id pub-id-type="doi">10.1016/j.jmgm.2017.01.008</pub-id>
      </element-citation>
    </ref>
    <ref id="CR36">
      <label>36.</label>
      <mixed-citation publication-type="other">SNIC Science Cloud. <ext-link ext-link-type="uri" xlink:href="https://cloud.snic.se/">https://cloud.snic.se/</ext-link>. Accessed 28 May 2017</mixed-citation>
    </ref>
    <ref id="CR37">
      <label>37.</label>
      <mixed-citation publication-type="other">SparkNow. <ext-link ext-link-type="uri" xlink:href="https://github.com/mcapuccini/SparkNow">https://github.com/mcapuccini/SparkNow</ext-link>. Accessed 28 May 2017</mixed-citation>
    </ref>
    <ref id="CR38">
      <label>38.</label>
      <mixed-citation publication-type="other">Spark-on-slurm. <ext-link ext-link-type="uri" xlink:href="https://github.com/mcapuccini/spark-on-slurm">https://github.com/mcapuccini/spark-on-slurm</ext-link>. Accessed 28 May 2017</mixed-citation>
    </ref>
    <ref id="CR39">
      <label>39.</label>
      <mixed-citation publication-type="other">Sparkhpc. <ext-link ext-link-type="uri" xlink:href="https://sparkhpc.readthedocs.io/en/latest/">https://sparkhpc.readthedocs.io/en/latest/</ext-link>. Accessed 28 May 2017</mixed-citation>
    </ref>
    <ref id="CR40">
      <label>40.</label>
      <mixed-citation publication-type="other">Uppmax: Uppsala multidisciplinary center for advanced computational science. <ext-link ext-link-type="uri" xlink:href="http://www.uppmax.uu.se/">http://www.uppmax.uu.se/</ext-link>. Accessed 15 June 2017</mixed-citation>
    </ref>
  </ref-list>
</back>
