<?properties open_access?>
<?properties manuscript?>
<?ManuscriptPrefix new?>
<?iso-abbr Nat. Methods?>
<?submitter-system ukmss?>
<?submitter-canonical-name Nature Publishing Group?>
<?submitter-canonical-id NATURE-STRUCTUR?>
<?submitter-userid 1005?>
<?submitter-authority publisher?>
<?submitter-login NPG?>
<?submitter-name Nature Publishing Group?>
<?domain wtpa?>
<?origin ukpmcpa?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-journal-id">101215604</journal-id>
    <journal-id journal-id-type="pubmed-jr-id">32338</journal-id>
    <journal-id journal-id-type="nlm-ta">Nat Methods</journal-id>
    <journal-id journal-id-type="iso-abbrev">Nat. Methods</journal-id>
    <journal-title-group>
      <journal-title>Nature methods</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1548-7091</issn>
    <issn pub-type="epub">1548-7105</issn>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">4930141</article-id>
    <article-id pub-id-type="pmid">27240256</article-id>
    <article-id pub-id-type="doi">10.1038/nmeth.3885</article-id>
    <article-id pub-id-type="manuscript">ems68345</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Article</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Data-driven hypothesis weighting increases detection power in genome-scale multiple testing</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Ignatiadis</surname>
          <given-names>Nikolaos</given-names>
        </name>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Klaus</surname>
          <given-names>Bernd</given-names>
        </name>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Zaugg</surname>
          <given-names>Judith</given-names>
        </name>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Huber</surname>
          <given-names>Wolfgang</given-names>
        </name>
        <xref ref-type="corresp" rid="CR1">1</xref>
      </contrib>
      <aff id="A1">European Molecular Biology Laboratory, Heidelberg, Germany</aff>
    </contrib-group>
    <author-notes>
      <corresp id="CR1"><label>1</label>Corresponding Author: <email>whuber@embl.de</email></corresp>
    </author-notes>
    <pub-date pub-type="nihms-submitted">
      <day>8</day>
      <month>6</month>
      <year>2016</year>
    </pub-date>
    <pub-date pub-type="epub">
      <day>30</day>
      <month>5</month>
      <year>2016</year>
    </pub-date>
    <pub-date pub-type="ppub">
      <month>7</month>
      <year>2016</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>30</day>
      <month>11</month>
      <year>2016</year>
    </pub-date>
    <volume>13</volume>
    <issue>7</issue>
    <fpage>577</fpage>
    <lpage>580</lpage>
    <!--elocation-id from pubmed: 10.1038/nmeth.3885-->
    <permissions>
      <license>
        <license-p>Users may view, print, copy, and download text and data-mine the content in such documents, for the purposes of academic research, subject always to the full Conditions of use:<ext-link ext-link-type="uri" xlink:href="http://www.nature.com/authors/editorial_policies/license.html#terms">http://www.nature.com/authors/editorial_policies/license.html#terms</ext-link></license-p>
      </license>
    </permissions>
    <abstract>
      <p id="P1">Hypothesis weighting improves the power of large-scale multiple testing. We describe a method that uses covariates independent of the p-values under the null hypothesis, but informative of each test’s power or prior probability of the null hypothesis. Independent hypothesis weighting (IHW) increases power while controlling the false discovery rate (FDR). IHW is a practical approach to discover associations in large datasets as encountered in genomics and high-throughput biology. Availability: <ext-link ext-link-type="uri" xlink:href="http://www.bioconductor.org/packages/IHW">www.bioconductor.org/packages/IHW</ext-link></p>
    </abstract>
  </article-meta>
</front>
<body>
  <p id="P2">Multiple testing is an important part of many high-throughput data analysis workflows. A common objective is to maximize the number of discoveries while controlling the FDR, i. e., the expected fraction of false discoveries. Commonly used procedures, such as that of Benjamini and Hochberg, achieve this objective by working solely off the list of p-values [<xref rid="R1" ref-type="bibr">1</xref>–<xref rid="R5" ref-type="bibr">5</xref>]. However, such an approach has suboptimal power when the individual tests differ in their statistical properties, such as sample size, true effect size, signal-to-noise ratio, or prior probability of being false.</p>
  <p id="P3">For example, in RNA-seq differential expression analysis, each test is associated with a different gene, and because of differences in the number of reads mapped the genes greatly differ in their signal-to-noise ratio. In genome-wise association studies (GWAS), associations are sought between genetic polymorphisms and phenotypic traits; however, the power to detect an association is lower for rarer polymorphisms (all else being equal). In GWAS of gene expression phenotypes (eQTL), cis-effects are a priori more likely than associations between a gene product and a distant polymorphism.</p>
  <p id="P4">To take into account such differences in the statistical properties of the tests, one can associate each test with a weight, a non-negative number as a measure of its priority (<xref ref-type="supplementary-material" rid="SD2">Supplementary Note 1</xref>). The weights fulfill a budget criterion, commonly that they average to one. Hypotheses with higher weights get prioritized [<xref rid="R6" ref-type="bibr">6</xref>]. The procedure of Benjamini and Hochberg (BH) [<xref rid="R1" ref-type="bibr">1</xref>] can be modified to allow weighting simply by replacing the original p-values <italic>p</italic><sub>i</sub> with their weighted versions <italic>p</italic><sub>i</sub>
<italic>/w</italic><sub>i</sub> (where <italic>w</italic><sub>i</sub> is the weight of hypothesis <italic>i</italic>) [<xref rid="R6" ref-type="bibr">6</xref>]. This approach controls the FDR if the weights are pre-specified and thus independent of the data. However, the optimal choice of weights is rarely known in practice, and a generally applicable data-driven method would be desirable [<xref rid="R7" ref-type="bibr">7</xref>–<xref rid="R11" ref-type="bibr">11</xref>].</p>
  <p id="P5">Independent hypothesis weighting (IHW) is a multiple testing procedure that applies the weighted BH method [<xref rid="R6" ref-type="bibr">6</xref>] using weights derived from the data. The input to IHW is a two-column table of p-values and covariates. The covariate can be any continuous-valued or categorical variable that is thought to be informative on the statistical properties of the hypothesis tests, while it is independent of the p-value under the null hypothesis [<xref rid="R9" ref-type="bibr">9</xref>]. Such covariates exist in many applications and are often apparent to domain experts (<xref ref-type="table" rid="T1">Table 1</xref>). The conditional independence property can be verified either mathematically [<xref rid="R9" ref-type="bibr">9</xref>] or empirically [<xref rid="R12" ref-type="bibr">12</xref>]. Simple diagnostic plots of the data can help assess these assumptions (<xref ref-type="fig" rid="F1">Fig. 1</xref>).</p>
  <p id="P6">IHW is motivated by considering multiple testing as a resource allocation problem [<xref rid="R6" ref-type="bibr">6</xref>]: given a budget of acceptable FDR, how can it be distributed among the hypotheses in such a way as to obtain the best possible power overall? The first idea is to use the covariate to assign hypothesis weights. We approximate the covariate-weight relationship by a step-wise constant function. No further assumptions (e. g., monotonicity) are needed.</p>
  <p id="P7">The second idea is that the number of discoveries of the weighted BH procedure with given weights is an empirical indicator of the method’s power. Therefore, a good choice of the covariate-weight function should lead to a high number of discoveries.</p>
  <p id="P8">An initial implementation (“naive IHW”) is easy to explain. The algorithm divides the tests into groups based on the covariate. Then, we associate each group with a weight, so that all hypotheses within a group are assigned the same weight. For each possible choice of weights we apply the weighted BH procedure at level <italic>α</italic> and calculate the total number of discoveries. We choose the weights leading to the highest number of discoveries.</p>
  <p id="P9">In many applications, this approach is already satisfactory, but it has two shortcomings: First, the underlying optimization problem is difficult and does not easily scale to problems with millions of tests. Second, in certain situations, described below, this algorithm leads to loss of type I error control. The reason for the latter is analogous to overfitting in statistical learning, and we use methods from this field to overcome the shortcomings: convex relaxation, data splitting and regularization (<xref ref-type="sec" rid="S2">Online Methods</xref> and <xref ref-type="supplementary-material" rid="SD2">Supplementary Note 2</xref>). The full IHW algorithm employs these three extensions.</p>
  <p id="P10">IHW increases empirical detection power compared to the BH procedure. We illustrate this claim on three exemplary applications (<xref ref-type="supplementary-material" rid="SD2">Supplementary Note 3</xref>). The first, by Bottomly <italic>et al</italic>. [<xref rid="R13" ref-type="bibr">13</xref>, <xref rid="R14" ref-type="bibr">14</xref>], is an RNA-seq dataset used to detect differential gene expression between mouse strains. p-values were calculated using DESeq2 [<xref rid="R12" ref-type="bibr">12</xref>]. Here we used the mean of normalized counts for each gene, across samples, as the informative covariate. We saw an increased number of discoveries compared to BH (<xref ref-type="fig" rid="F2">Fig. 2a</xref>). In addition, we observed that the learned weight function prioritized genes with higher mean normalized counts (<xref ref-type="supplementary-material" rid="SD1">Supplementary Fig. 1a</xref>).</p>
  <p id="P11">Second, we analyzed a quantitative mass-spectrometry (SILAC) experiment in which yeast cells treated with rapamycin were compared to yeast treated with DMSO (2 × 6 biological replicates) [<xref rid="R15" ref-type="bibr">15</xref>]. Differential protein abundance of 2,666 proteins was evaluated using Welch’s <italic>t</italic>-test [<xref rid="R15" ref-type="bibr">15</xref>]. As a covariate we used the total number of peptides that were quantified across all samples for each protein. IHW again showed increased power compared to BH (<xref ref-type="fig" rid="F2">Fig. 2b</xref>), and proteins with more quantified peptides were assigned higher weight, as expected (<xref ref-type="supplementary-material" rid="SD1">Supplementary Fig. 1b</xref>).</p>
  <p id="P12">In a third example, we searched for associations between SNPs and histone modification marks (H3K27ac) [<xref rid="R16" ref-type="bibr">16</xref>] on human Chromosome 21. This yielded 180 million tests. As a covariate we used the genomic distance between the SNP and the ChIP-seq signal. The power increase compared to BH was dramatic (<xref ref-type="fig" rid="F2">Fig. 2c</xref>). IHW automatically assigned most weight to small distances (<xref ref-type="fig" rid="F2">Fig. 2d</xref>). Thus IHW acted similarly to the common practice in eQTL-analysis of searching for associations only within a certain distance, a form of Independent Filtering. However, it had the advantage that no arbitrary choice of distance threshold was needed, and that the weights were more nuanced than a hard distance threshold. IHW does not exclude SNP-phenotype pairs far away, and these can still be detected as long as they have a sufficiently small p-value.</p>
  <p id="P13">The extensions to naive IHW are needed to ensure type I error control. Naive IHW, as well as previous approaches to data-driven hypothesis weighting or filtering, do not maintain FDR control in situations where all hypotheses are true (<xref ref-type="fig" rid="F2">Fig. 2e</xref>) or where there is insufficient power to detect the false hypotheses (<xref ref-type="supplementary-material" rid="SD1">Supplementary Fig. 2a</xref>). In addition, the local fdr methods (Clfdr and FDRreg) often show strong deviations from the target FDR in a direction (conservative or anti-conservative) that is not apparent a priori (<xref ref-type="fig" rid="F2">Fig. 2f,g</xref>). Thus, among all methods benchmarked across these scenarios, only BH, IHW (but not naive IHW) and LSL-GBH generally control the FDR. The results of our method comparisons are summarized in <xref ref-type="table" rid="T2">Table 2</xref> (<xref ref-type="fig" rid="F2">Fig. 2</xref> and <xref ref-type="supplementary-material" rid="SD1">Supplementary Fig. 2</xref>), and the simulations are described in <xref ref-type="supplementary-material" rid="SD2">Supplementary Note 4</xref>.</p>
  <p id="P14">IHW can apply a size investing strategy. IHW assigns low weight to covariate-groups with low signal (such as <xref ref-type="fig" rid="F1">Fig. 1d</xref>). While this may be expected, a less intuitive effect can pertain to groups with very small p-values. IHW can move away weight from these towards groups with more intermediate p-values, since the former will be rejected even with a lower weight. This is called <italic>size investing</italic> [<xref rid="R17" ref-type="bibr">17</xref>]. Several other methods (<xref ref-type="table" rid="T2">Table 2</xref>), including Independent Filtering, stratified BH, LSL-GBH and FDRreg, cannot apply size investing and might even lose power compared to the BH method (<xref ref-type="supplementary-material" rid="SD1">Supplementary Fig. 2d,f</xref> and <xref ref-type="supplementary-material" rid="SD2">Supplementary Note 5</xref>).</p>
  <p id="P15">It is instructive to consider the relation between IHW and the concept of local true discovery rates. p-values are a reduction of data into one number, which typically does not contain all the important information (<xref ref-type="table" rid="T1">Table 1</xref>; [<xref rid="R18" ref-type="bibr">18</xref>, <xref rid="R19" ref-type="bibr">19</xref>]). One might wonder whether there are other quantities that are better suited for selecting discoveries. The theoretically optimal candidate is the <italic>local true discovery rate</italic> (tdr) [<xref rid="R4" ref-type="bibr">4</xref>]. The tdr of the <italic>i</italic><sup>th</sup> hypothesis is [<xref rid="R4" ref-type="bibr">4</xref>] <disp-formula id="FD1"><label>(1)</label><mml:math display="block" id="M1" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mtext>tdr</mml:mtext></mml:mrow><mml:mtext>i</mml:mtext></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mtext>π</mml:mtext><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mtext>i</mml:mtext></mml:mrow></mml:msub><mml:mfrac><mml:mrow><mml:msub><mml:mtext>f</mml:mtext><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>i</mml:mo></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mtext>f</mml:mtext><mml:mtext>i</mml:mtext></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula></p>
  <p id="P16">A schematic explanation is given in <xref ref-type="fig" rid="F3">Fig. 3a</xref> (see also <xref ref-type="supplementary-material" rid="SD1">Supplementary Figs. 3 and 4</xref>). f<sub>i</sub> is the density of the distribution of the p-value <italic>p</italic>. It is a mixture of two distributions, f<sub>i</sub> = π<sub>0,i</sub>f<sub>0</sub> + π<sub>1,i</sub>f<sub>1,i</sub>, where the densities f<sub>0</sub> and f<sub>1,i</sub> are conditional on the null or the alternative being true, respectively, and π<sub>0,i</sub> and π<sub>1,i</sub> (which sum up to 1) are the corresponding prior probabilities. The null distribution of a properly calibrated test is uniform, therefore we can set f<sub>0</sub>(<italic>p</italic>) = 1 irrespective of <italic>p</italic> and <italic>i</italic>. In <xref ref-type="fig" rid="F3">Fig. 3b-d</xref> three hypotheses are shown with different tdr curves corresponding to different power profiles.</p>
  <p id="P17">It can now be shown that to maximize power at a given FDR, one should reject the hypotheses with the highest tdr [<xref rid="R20" ref-type="bibr">20</xref>, <xref rid="R21" ref-type="bibr">21</xref>]. In other words, if we knew the functions in <xref ref-type="disp-formula" rid="FD1">Equation (1)</xref> and could use tdr<sub>i</sub> (<italic>p</italic><sub>i</sub>) as our test statistics, then without any further effort we would have a method for FDR control with optimal power.</p>
  <p id="P18">Similarly to the central idea of IHW, one can now assume that the many different, unknown univariate functions tdr<sub>i</sub> (<italic>p</italic>), one for each hypothesis <italic>i</italic>, can be approximated by a single bivariate function tdr(<italic>p, x</italic>), where <italic>x</italic> is the covariate. The joint density of <italic>p</italic> and <italic>x</italic> (<xref ref-type="fig" rid="F3">Fig. 3e</xref>) gives rise to the joint density of tdr and <italic>x</italic> (<xref ref-type="fig" rid="F3">Fig. 3f</xref>). We can see how in such a scenario the decision boundary of the BH method tends to be suboptimal. As it is defined solely in terms of p-values (<xref ref-type="fig" rid="F3">Fig. 3e</xref>), it differs from the optimal region, whose boundary is a vertical line of constant tdr (<xref ref-type="fig" rid="F3">Fig. 3f</xref>).</p>
  <p id="P19">However, in practice, we neither know the quantities in <xref ref-type="disp-formula" rid="FD1">Equation (1)</xref> nor the bivariate function tdr(<italic>p, x</italic>) and have to estimate them [<xref rid="R22" ref-type="bibr">22</xref>]. Unfortunately, this estimation problem is difficult, and even with the use of additional approximations, such as splines [<xref rid="R23" ref-type="bibr">23</xref>] or piecewise constant functions [<xref rid="R24" ref-type="bibr">24</xref>], there does not seem to be a practical implementation.</p>
  <p id="P20">With IHW we circumvent explicit estimation of the bivariate tdr function and instead derive a powerful testing procedure by assigning data-driven hypothesis weights. In addition, the IHW method readily extends to other weighted multiple testing procedures [<xref rid="R6" ref-type="bibr">6</xref>]. In <xref ref-type="supplementary-material" rid="SD2">Supplementary Note 6</xref> (and <xref ref-type="supplementary-material" rid="SD1">Supplementary Fig. 5</xref>) we describe IHW-Bonferroni, a new powerful method for control of the familywise error rate (FWER). In contrast, local tdr methods are specific to the FDR.</p>
  <p id="P21">We have introduced a weighted multiple testing method that learns the weights from the data. Its appeal lies in its generic applicability. It does not require assumptions about the relationship between the covariate and the power of the individual tests, such as monotonicity, which is necessary for Independent Filtering. It can apply size investing strategies, since it does not assume that the alternative distributions are the same across the different hypotheses. It is computationally robust and scales to millions of hypotheses.</p>
  <p id="P22">The idea of using informative covariates for hypothesis weighting or for shaping optimal decision boundaries is not new (<xref ref-type="table" rid="T2">Table 2</xref>; [<xref rid="R24" ref-type="bibr">24</xref>–<xref rid="R26" ref-type="bibr">26</xref>]). In this work, we provide a general and practical approach. Most importantly, we show how to overcome two major limitations of previous approaches: type I error control and stability.</p>
  <p id="P23">We gave examples of suitable covariates for a variety of applications in <xref ref-type="table" rid="T1">Table 1</xref>. Further work could establish additional domain-specific choices of covariates, formalize and automate the assessment of diagnostic plots such as <xref ref-type="fig" rid="F1">Fig. 1</xref> and extend IHW to higher dimensional covariates.</p>
  <p id="P24">Various approaches to increasing power compared to the BH method have focused on estimating the fraction of true nulls among all hypotheses instead of conservatively approximating it by 1, as the BH method does [<xref rid="R2" ref-type="bibr">2</xref>]. In practice, this tends to have limited impact, since in the most interesting situations the number of true discoveries is small compared to all tests and no substantial power increase is gained. On the other hand, such an extension could be beneficial for IHW, since often the groups that get assigned a high weight also have a reduced proportion of true nulls.</p>
  <p id="P25">The issue of dependence between hypotheses deserves attention. For example, the proof of the BH method was initially provided under the assumption of independent hypothesis tests and later extended to positive regression dependence [<xref rid="R27" ref-type="bibr">27</xref>]. Beyond that, BH has turned out to be remarkably robust to correlations encountered in analyses of real data. In our experience, IHW inherits this property of BH, whenever the covariate is not involved in the joint dependence of the null p-values.</p>
  <p id="P26">In our method we have explicitly avoided estimating the densities in <xref ref-type="disp-formula" rid="FD1">Equation (1)</xref>. Nevertheless, the local true discovery rate is an interesting quantity in its own right, since it provides a posterior probability for each individual hypothesis. Our weighted p-values do not provide this information. Thus, development of stable estimation procedures for the local local true discovery rate that incorporate informative covariates is needed and would be complementary to our work [<xref rid="R19" ref-type="bibr">19</xref>, <xref rid="R22" ref-type="bibr">22</xref>–<xref rid="R24" ref-type="bibr">24</xref>].</p>
  <sec id="S1">
    <title>Code availability</title>
    <p id="P27">The IHW package is available from Bioconductor at <ext-link ext-link-type="uri" xlink:href="http://www.bioconductor.org/packages/IHW">http://www.bioconductor.org/packages/IHW</ext-link>. It comes with detailed documentation and a vignette that showcases the application of IHW to a real dataset. The vignette also provides guidance on the choice of informative covariates and suggests diagnostic plots, so that users can determine if their covariate satisfies the required conditions.</p>
    <p id="P28">Executable documents (Rmarkdown) reproducing all analyses shown here can be downloaded at <ext-link ext-link-type="uri" xlink:href="http://bioconductor.org/packages/IHWpaper">http://bioconductor.org/packages/IHWpaper</ext-link>.</p>
    <p id="P29">Both packages are also available as Supplementary Software to this manuscript.</p>
  </sec>
  <sec sec-type="methods" id="S2" specific-use="web-only">
    <title>Online Methods</title>
    <sec id="S3">
      <title>Description of the IHW algorithm</title>
      <p id="P30">The hypothesis tests are divided into <italic>G</italic> different groups based on the covariate, typically of about equal size. Each group <italic>g</italic> is associated with weight <italic>w</italic><sub>g</sub>. The following optimization problem is solved: find the weight vector <bold><italic>w</italic></bold> = (<italic>w</italic><sub>1</sub>
<italic>, …, w<sub>G</sub></italic>) that maximizes the number of rejections of the weighted BH method at level <italic>α</italic>. This method, <italic>naive IHW</italic>, is modified by the following three extensions.</p>
      <p id="P31">E1. Instead of the above optimization task, we solve a convex relaxation of it. In statistical terms this corresponds to replacing the empirical cumulative distribution functions (ECDF) of the p-values with the Grenander estimators (least concave majorant of the ECDF). The resulting problem is convex and can be efficiently solved even for large numbers of hypotheses.</p>
      <p id="P32">E2. We randomly split the hypotheses into <italic>k</italic> folds. For each fold, we apply convex IHW to the other <italic>k</italic>− 1 folds and assign the learned weights to the remaining fold. Thus the weight assigned to a given hypothesis does not directly depend on its p-value, but only on its covariate.</p>
      <p id="P33">E3. The performance of the algorithm can be further improved by ensuring that the
weights learned with <italic>k</italic>– 1 folds generalize to the
held-out fold. Therefore, we introduce a regularization parameter
<italic>λ ≥</italic> 0, and the optimization is done over a
constrained subset of the weights. For an ordered covariate, we require that,
<disp-formula id="FD2"><mml:math display="block" id="M2" overflow="scroll"><mml:mrow><mml:mstyle displaystyle="true"><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>g</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mi>G</mml:mi></mml:munderover><mml:mfenced open="|" close="|" separators=""><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mi>g</mml:mi></mml:msub></mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>g</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mfenced></mml:mrow></mml:mstyle><mml:mo>≤</mml:mo><mml:mi>λ</mml:mi></mml:mrow></mml:math></disp-formula> i. e., weights of successive groups should not be
too different. For an unordered covariate, we use instead the constraint
<disp-formula id="FD3"><mml:math display="block" id="M3" overflow="scroll"><mml:mrow><mml:mstyle displaystyle="true"><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>g</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>G</mml:mi></mml:munderover><mml:mfenced open="|" close="|" separators=""><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mi>g</mml:mi></mml:msub></mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mfenced></mml:mrow></mml:mstyle><mml:mo>≤</mml:mo><mml:mi>λ</mml:mi></mml:mrow></mml:math></disp-formula> i.e., deviations from 1 are penalized. In the
limit case <italic>λ</italic> = 0, all weights are the same, so
IHW with <italic>λ</italic> = 0 is just the BH method. IHW with
<italic>λ → ∞</italic> is the unconstrained version.
Choice of <italic>λ</italic> is a model selection problem, so within each
split in E2 we apply a second nested layer of cross-validation. E3 is optional;
whether or not to apply it will depend on the data. It will be most beneficial
if the number of hypotheses per group is relatively small.</p>
      <p id="P34">A complete description of the algorithm, including an efficient computational implementation of the optimization task, is provided in <xref ref-type="supplementary-material" rid="SD2">Supplementary Note 2</xref>. <xref ref-type="supplementary-material" rid="SD2">Supplementary Note 7</xref> describes its theoretical justification.</p>
    </sec>
  </sec>
  <sec sec-type="supplementary-material" id="SM">
    <title>Supplementary Material</title>
    <supplementary-material content-type="local-data" id="SD1">
      <label>Supplementary Figures</label>
      <media xlink:href="NIHMS68345-supplement-Supplementary_Figures.doc" mimetype="application" mime-subtype="msword" orientation="portrait" xlink:type="simple" id="d37e754" position="anchor"/>
    </supplementary-material>
    <supplementary-material content-type="local-data" id="SD2">
      <label>Supplementary Notes</label>
      <media xlink:href="NIHMS68345-supplement-Supplementary_Notes.pdf" mimetype="application" mime-subtype="pdf" orientation="portrait" xlink:type="simple" id="d37e758" position="anchor"/>
    </supplementary-material>
  </sec>
</body>
<back>
  <ack id="S4">
    <title>Acknowledgements</title>
    <p>We thank B. Fischer, M. I. Love, M. Savitski and O. Stegle for insightful discussions and comments on the manuscript, the COIN-OR project for the open-source <italic>SYMPHONY</italic> software, and V. Kim for interfacing it to R through the <italic>lpsymphony</italic> package. We acknowledge support from the European Commission through the Horizon 2020 project SOUND.</p>
  </ack>
  <fn-group>
    <fn fn-type="con" id="FN1">
      <p id="P35">
        <bold>Author contributions</bold>
      </p>
      <p id="P36">N.I. and W.H. developed the method and wrote the manuscript. N.I. implemented the method and performed the analyses. J.Z. analyzed the hQTL dataset. B.K. contributed statistical concepts and ideas. All authors read and approved the final manuscript.</p>
    </fn>
    <fn fn-type="financial-disclosure" id="FN2">
      <p id="P37">
        <bold>Competing Financial Interests</bold>
      </p>
      <p id="P38">The authors declare no competing financial interests.</p>
    </fn>
  </fn-group>
  <ref-list>
    <ref id="R1">
      <label>[1]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Benjamini</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Hochberg</surname>
            <given-names>Y</given-names>
          </name>
        </person-group>
        <article-title>Controlling the false discovery rate: a practical and powerful approach to multiple testing</article-title>
        <source>Journal of the Royal Statistical Society. Series B (Statistical Methodology)</source>
        <year>1995</year>
        <fpage>289</fpage>
        <lpage>300</lpage>
      </element-citation>
    </ref>
    <ref id="R2">
      <label>[2]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Benjamini</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Krieger</surname>
            <given-names>AM</given-names>
          </name>
          <name>
            <surname>Yekutieli</surname>
            <given-names>D</given-names>
          </name>
        </person-group>
        <article-title>Adaptive linear step-up procedures that control the false discovery rate</article-title>
        <source>Biometrika</source>
        <year>2006</year>
        <volume>93</volume>
        <fpage>491</fpage>
        <lpage>507</lpage>
      </element-citation>
    </ref>
    <ref id="R3">
      <label>[3]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Storey</surname>
            <given-names>JD</given-names>
          </name>
          <name>
            <surname>Taylor</surname>
            <given-names>JE</given-names>
          </name>
          <name>
            <surname>Siegmund</surname>
            <given-names>D</given-names>
          </name>
        </person-group>
        <article-title>Strong control, conservative point estimation and simultaneous conservative consistency of false discovery rates: a unified approach</article-title>
        <source>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</source>
        <volume>66</volume>
        <year>2004</year>
        <fpage>187</fpage>
        <lpage>205</lpage>
      </element-citation>
    </ref>
    <ref id="R4">
      <label>[4]</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Efron</surname>
            <given-names>B</given-names>
          </name>
        </person-group>
        <source>Large-scale inference: Empirical Bayes methods for estimation, testing, and prediction</source>
        <publisher-name>Cambridge University Press</publisher-name>
        <year>2010</year>
      </element-citation>
    </ref>
    <ref id="R5">
      <label>[5]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Strimmer</surname>
            <given-names>K</given-names>
          </name>
        </person-group>
        <article-title>A unified approach to false discovery rate estimation</article-title>
        <source>BMC Bioinformatics</source>
        <year>2008</year>
        <volume>9</volume>
        <fpage>303</fpage>
        <pub-id pub-id-type="pmid">18613966</pub-id>
      </element-citation>
    </ref>
    <ref id="R6">
      <label>[6]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Genovese</surname>
            <given-names>CR</given-names>
          </name>
          <name>
            <surname>Roeder</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Wasserman</surname>
            <given-names>L</given-names>
          </name>
        </person-group>
        <article-title>False discovery control with p-value weighting</article-title>
        <source>Biometrika</source>
        <year>2006</year>
        <volume>93</volume>
        <fpage>509</fpage>
        <lpage>524</lpage>
      </element-citation>
    </ref>
    <ref id="R7">
      <label>[7]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Roeder</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Devlin</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Wasserman</surname>
            <given-names>L</given-names>
          </name>
        </person-group>
        <article-title>Improving power in genome-wide association studies: weights tip the scale</article-title>
        <source>Genetic Epidemiology</source>
        <year>2007</year>
        <volume>31</volume>
        <fpage>741</fpage>
        <lpage>747</lpage>
        <pub-id pub-id-type="pmid">17549760</pub-id>
      </element-citation>
    </ref>
    <ref id="R8">
      <label>[8]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Roquain</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Van De Wiel</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>Optimal weighting for false discovery rate control</article-title>
        <source>Electronic Journal of Statistics</source>
        <year>2009</year>
        <volume>3</volume>
        <fpage>678</fpage>
        <lpage>711</lpage>
      </element-citation>
    </ref>
    <ref id="R9">
      <label>[9]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Bourgon</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Gentleman</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Huber</surname>
            <given-names>W</given-names>
          </name>
        </person-group>
        <article-title>Independent filtering increases detection power for high-throughput experiments</article-title>
        <source>Proceedings of the National Academy of Sciences</source>
        <year>2010</year>
        <volume>107</volume>
        <fpage>9546</fpage>
        <lpage>9551</lpage>
      </element-citation>
    </ref>
    <ref id="R10">
      <label>[10]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hu</surname>
            <given-names>JX</given-names>
          </name>
          <name>
            <surname>Zhao</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Zhou</surname>
            <given-names>HH</given-names>
          </name>
        </person-group>
        <article-title>False discovery rate control with groups</article-title>
        <source>Journal of the American Statistical Association</source>
        <year>2010</year>
        <volume>105</volume>
      </element-citation>
    </ref>
    <ref id="R11">
      <label>[11]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Dobriban</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Fortney</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Kim</surname>
            <given-names>SK</given-names>
          </name>
          <name>
            <surname>Owen</surname>
            <given-names>AB</given-names>
          </name>
        </person-group>
        <article-title>Optimal multiple testing under a Gaussian prior on the effect sizes</article-title>
        <source>Biometrika</source>
        <year>2015</year>
        <volume>102</volume>
        <fpage>753</fpage>
        <lpage>766</lpage>
        <pub-id pub-id-type="pmid">27046938</pub-id>
      </element-citation>
    </ref>
    <ref id="R12">
      <label>[12]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Love</surname>
            <given-names>MI</given-names>
          </name>
          <name>
            <surname>Huber</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Anders</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>Moderated estimation of fold change and dispersion for RNA-Seq data with DESeq2</article-title>
        <source>Genome Biology</source>
        <year>2014</year>
        <volume>15</volume>
        <fpage>550</fpage>
        <pub-id pub-id-type="pmid">25516281</pub-id>
      </element-citation>
    </ref>
    <ref id="R13">
      <label>[13]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Bottomly</surname>
            <given-names>D</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Evaluating gene expression in C57BL/6J and DBA/2J mouse striatum using RNA-Seq and microarrays</article-title>
        <source>PLoS ONE</source>
        <year>2011</year>
        <volume>6</volume>
        <fpage>e17820</fpage>
        <pub-id pub-id-type="pmid">21455293</pub-id>
      </element-citation>
    </ref>
    <ref id="R14">
      <label>[14]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Frazee</surname>
            <given-names>AC</given-names>
          </name>
          <name>
            <surname>Langmead</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Leek</surname>
            <given-names>JT</given-names>
          </name>
        </person-group>
        <article-title>Recount: a multi-experiment resource of analysis-ready rna-seq gene count datasets</article-title>
        <source>BMC Bioinformatics</source>
        <year>2011</year>
        <volume>12</volume>
        <fpage>449</fpage>
        <pub-id pub-id-type="pmid">22087737</pub-id>
      </element-citation>
    </ref>
    <ref id="R15">
      <label>[15]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Dephoure</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Gygi</surname>
            <given-names>SP</given-names>
          </name>
        </person-group>
        <article-title>Hyperplexing: a method for higher-order multiplexed quantitative proteomics provides a map of the dynamic response to rapamycin in yeast</article-title>
        <source>Science Signaling</source>
        <year>2012</year>
        <volume>5</volume>
        <fpage>rs2</fpage>
        <lpage>rs2</lpage>
        <pub-id pub-id-type="pmid">22457332</pub-id>
      </element-citation>
    </ref>
    <ref id="R16">
      <label>[16]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Grubert</surname>
            <given-names>F</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Genetic control of chromatin states in humans involves local and distal chromosomal interactions</article-title>
        <source>Cell</source>
        <year>2015</year>
        <volume>162</volume>
        <fpage>1051</fpage>
        <lpage>1065</lpage>
        <pub-id pub-id-type="pmid">26300125</pub-id>
      </element-citation>
    </ref>
    <ref id="R17">
      <label>[17]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Peña</surname>
            <given-names>EA</given-names>
          </name>
          <name>
            <surname>Habiger</surname>
            <given-names>JD</given-names>
          </name>
          <name>
            <surname>Wu</surname>
            <given-names>W</given-names>
          </name>
        </person-group>
        <article-title>Power-enhanced multiple decision functions controlling family-wise error and false discovery rates</article-title>
        <source>The Annals of Statistics</source>
        <year>2011</year>
        <volume>39</volume>
        <fpage>556</fpage>
        <lpage>583</lpage>
        <pub-id pub-id-type="pmid">25018568</pub-id>
      </element-citation>
    </ref>
    <ref id="R18">
      <label>[18]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Sun</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Cai</surname>
            <given-names>TT</given-names>
          </name>
        </person-group>
        <article-title>Oracle and adaptive compound decision rules for false discovery rate control</article-title>
        <source>Journal of the American Statistical Association</source>
        <year>2007</year>
        <volume>102</volume>
        <fpage>901</fpage>
        <lpage>912</lpage>
      </element-citation>
    </ref>
    <ref id="R19">
      <label>[19]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Stephens</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>False discovery rates: A new deal</article-title>
        <source>bioRxiv</source>
        <year>2016</year>
        <fpage>038216</fpage>
      </element-citation>
    </ref>
    <ref id="R20">
      <label>[20]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Cai</surname>
            <given-names>TT</given-names>
          </name>
          <name>
            <surname>Sun</surname>
            <given-names>W</given-names>
          </name>
        </person-group>
        <article-title>Simultaneous testing of grouped hypotheses: Finding needles in multiple haystacks</article-title>
        <source>Journal of the American Statistical Association</source>
        <year>2009</year>
        <volume>104</volume>
      </element-citation>
    </ref>
    <ref id="R21">
      <label>[21]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ochoa</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Storey</surname>
            <given-names>JD</given-names>
          </name>
          <name>
            <surname>Llins</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Singh</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>Beyond the E-value: Stratified statistics for protein domain prediction</article-title>
        <source>PLoS Computational Biology</source>
        <year>2015</year>
        <volume>11</volume>
        <fpage>e1004509</fpage>
        <pub-id pub-id-type="pmid">26575353</pub-id>
      </element-citation>
    </ref>
    <ref id="R22">
      <label>[22]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ploner</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Calza</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Gusnanto</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Pawitan</surname>
            <given-names>Y</given-names>
          </name>
        </person-group>
        <article-title>Multidimensional local false discovery rate for microarray studies</article-title>
        <source>Bioinformatics</source>
        <year>2006</year>
        <volume>22</volume>
        <fpage>556</fpage>
        <lpage>565</lpage>
        <pub-id pub-id-type="pmid">16368770</pub-id>
      </element-citation>
    </ref>
    <ref id="R23">
      <label>[23]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Scott</surname>
            <given-names>JG</given-names>
          </name>
          <name>
            <surname>Kelly</surname>
            <given-names>RC</given-names>
          </name>
          <name>
            <surname>Smith</surname>
            <given-names>MA</given-names>
          </name>
          <name>
            <surname>Zhou</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Kass</surname>
            <given-names>RE</given-names>
          </name>
        </person-group>
        <article-title>False discovery rate regression: an application to neural synchrony detection in primary visual cortex</article-title>
        <source>Journal of the American Statistical Association</source>
        <year>2015</year>
        <volume>110</volume>
        <fpage>459</fpage>
        <lpage>471</lpage>
        <pub-id pub-id-type="pmid">26855459</pub-id>
      </element-citation>
    </ref>
    <ref id="R24">
      <label>[24]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ferkingstad</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Frigessi</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Rue</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Thorleifsson</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Kong</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Unsupervised empirical Bayesian multiple testing with external covariates</article-title>
        <source>The Annals of Applied Statistics</source>
        <year>2008</year>
        <fpage>714</fpage>
        <lpage>735</lpage>
      </element-citation>
    </ref>
    <ref id="R25">
      <label>[25]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Efron</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>NR</given-names>
          </name>
        </person-group>
        <article-title>False discovery rates and copy number variation</article-title>
        <source>Biometrika</source>
        <year>2011</year>
        <volume>98</volume>
        <fpage>251</fpage>
        <lpage>271</lpage>
      </element-citation>
    </ref>
    <ref id="R26">
      <label>[26]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Du</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>C</given-names>
          </name>
        </person-group>
        <article-title>Single-index modulated multiple testing</article-title>
        <source>The Annals of Statistics</source>
        <year>2014</year>
        <volume>42</volume>
        <fpage>30</fpage>
        <lpage>79</lpage>
      </element-citation>
    </ref>
    <ref id="R27">
      <label>[27]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Benjamini</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Yekutieli</surname>
            <given-names>D</given-names>
          </name>
        </person-group>
        <article-title>The control of the false discovery rate in multiple testing under dependency</article-title>
        <source>The Annals of Statistics</source>
        <year>2001</year>
        <fpage>1165</fpage>
        <lpage>1188</lpage>
      </element-citation>
    </ref>
    <ref id="R28">
      <label>[28]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Yoo</surname>
            <given-names>YJ</given-names>
          </name>
          <name>
            <surname>Bull</surname>
            <given-names>SB</given-names>
          </name>
          <name>
            <surname>Paterson</surname>
            <given-names>AD</given-names>
          </name>
          <name>
            <surname>Waggott</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Sun</surname>
            <given-names>L</given-names>
          </name>
        </person-group>
        <article-title>Were genome-wide linkage studies a waste of time? Exploiting candidate regions within genome-wide association studies</article-title>
        <source>Genetic Epidemiology</source>
        <year>2010</year>
        <volume>34</volume>
        <fpage>107</fpage>
        <lpage>118</lpage>
        <pub-id pub-id-type="pmid">19626703</pub-id>
      </element-citation>
    </ref>
  </ref-list>
</back>
<floats-group>
  <fig id="F1" orientation="portrait" position="float">
    <label>Figure 1</label>
    <caption>
      <title>Histograms stratified by the covariate as a diagnostic plot.</title>
      <p><bold>a)</bold> The histogram of all p-values shows a mixture of a uniform distribution (corresponding to the true null hypotheses) and an enrichment of small p-values to the left (corresponding to the alternatives). Such a well-calibrated histogram is the starting point for most multiple testing methods. <bold>b-d)</bold> Histograms after splitting the hypotheses into three groups based on the values of the covariate. Shown is an example of a good covariate: each histogram still shows a uniform component, but the mixture proportion and/or the shape of the alternative distribution differ between the groups. If all histograms look the same, the covariate is uninformative, and its use would not lead to an increase in power. If the tails are no longer uniform, independence under the null is violated, and application of IHW is not valid.</p>
    </caption>
    <graphic xlink:href="emss-68345-f001"/>
  </fig>
  <fig id="F2" orientation="portrait" position="float">
    <label>Figure 2</label>
    <caption>
      <title>Performance evaluation.</title>
      <p>Panels <bold>a-c</bold> show the number of discoveries with IHW and BH on real data as a function of the target FDR. <bold>a)</bold> RNA-Seq dataset [<xref rid="R13" ref-type="bibr">13</xref>] with mean of normalized counts for each gene as the covariate. <bold>b)</bold> SILAC dataset [<xref rid="R15" ref-type="bibr">15</xref>], with number of peptides quantified per protein as the covariate. <bold>c)</bold> hQTL dataset [<xref rid="R16" ref-type="bibr">16</xref>] for Chromosome 21, with genomic distance between SNPs and ChIP-seq signals as the covariate. Independent Filtering with different distance cutoffs was also applied. <bold>d)</bold> Weight function learned by IHW at <italic>α</italic> = 0.1 for the hQTL dataset. Shown are the curves for the five folds in the data splitting scheme. Panels <bold>e-h</bold> benchmark different methods based on simulations. Brief descriptions of each method are in <xref ref-type="table" rid="T2">Table 2</xref>. <bold>e–f)</bold> Type I error control if all null hypotheses are true. Shown is the true FDR against the nominal significance level <italic>α</italic>. <bold>e)</bold> All methods shown make too many false discoveries. <bold>f)</bold> BH, FDRreg, and IHW control the FDR. LSL-GBH and Clfdr are slightly anticonservative. <bold>g-h)</bold> Implications of different effect sizes. The two-sample <italic>t</italic>-test was applied to Normal samples (<italic>n</italic> = 2 × 5<italic>, σ</italic> = 1) with either the same mean (nulls) or means differing by the effect size indicated on the <italic>x</italic>-axis (alternatives). The fraction of alternatives was 0.05. The pooled sample variance was used as the covariate. The nominal level was <italic>α</italic> = 0.1 (dotted line). <bold>g)</bold> The <italic>y</italic>-axis shows the actual FDR. <bold>h)</bold> Power analysis. All methods show improvement over BH.</p>
    </caption>
    <graphic xlink:href="emss-68345-f002"/>
  </fig>
  <fig id="F3" orientation="portrait" position="float">
    <label>Figure 3</label>
    <caption>
      <title>True discovery rate and informative covariates.</title>
      <p><bold>a)</bold> Schematic representation of the density f<sub>i</sub>, which is composed of the alternative density f<sub>1,i</sub> weighted by its prior probability π<sub>1,i</sub> and the uniform null density weighted by π<sub>0,i</sub>. <bold>b-d)</bold> The true discovery rate (tdr) of individual tests can vary. In <bold>b)</bold>, the test has high power, and π<sub>0,i</sub> is well below 1. In <bold>c)</bold>, the test has equal power, but π<sub>0,i</sub> is higher, leading to a reduced tdr. In <bold>d)</bold>, π<sub>0,i</sub> is like in <bold>b)</bold>, but the test has little power, again leading to a reduced tdr. <bold>e)</bold> If an informative covariate is associated with each test, the distribution of the p-values from multiple tests is different for different values of the covariate. The contours represent the joint density of p-values and covariate. The BH procedure accounts only for the p-values and not the covariates (dashed red line). In contrast, the decision boundary of IHW is a step function; each step corresponds to one group, i. e., to one weight. <bold>f</bold>) By <xref ref-type="disp-formula" rid="FD1">Equation (1)</xref>, the density of the tdr also depends on the covariate. The decision boundary of the BH procedure (dashed red line) leads to a suboptimal set of discoveries, in this example with higher than optimal tdr for intermediate covariate values and too low otherwise. In contrast, IHW approximates a line of constant tdr, implying efficient use of the FDR budget. An important feature of IHW is that it works directly on p-values and covariates rather than explicitly estimating the tdr.</p>
    </caption>
    <graphic xlink:href="emss-68345-f003"/>
  </fig>
  <table-wrap id="T1" position="float" orientation="portrait">
    <label>Table 1</label>
    <caption>
      <p>Examples of covariates.</p>
    </caption>
    <table frame="border" rules="none">
      <thead>
        <tr>
          <th align="left" rowspan="1" colspan="1">Application</th>
          <th align="left" rowspan="1" colspan="1">Covariate</th>
        </tr>
        <tr>
          <th colspan="2" align="left" valign="top" rowspan="1">
            <hr/>
          </th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td align="left" rowspan="1" colspan="1">Differential expression analysis</td>
          <td align="left" rowspan="1" colspan="1">Sum of read counts per gene across all samples [<xref rid="R12" ref-type="bibr">12</xref>]</td>
        </tr>
        <tr>
          <td align="left" rowspan="1" colspan="1">Genome-wide association study (GWAS)</td>
          <td align="left" rowspan="1" colspan="1">Minor allele frequency</td>
        </tr>
        <tr>
          <td align="left" rowspan="1" colspan="1">Expression-QTL analysis</td>
          <td align="left" rowspan="1" colspan="1">Distance between the genetic variant and genomic location of the phenotype</td>
        </tr>
        <tr>
          <td align="left" rowspan="1" colspan="1">ChIP-QTL analysis</td>
          <td align="left" rowspan="1" colspan="1">Comembership in a topologically associated domain [<xref rid="R16" ref-type="bibr">16</xref>]</td>
        </tr>
        <tr>
          <td align="left" rowspan="1" colspan="1"><italic>t</italic>-test</td>
          <td align="left" rowspan="1" colspan="1">Overall variance [<xref rid="R9" ref-type="bibr">9</xref>]</td>
        </tr>
        <tr>
          <td align="left" rowspan="1" colspan="1">Two-sided tests</td>
          <td align="left" rowspan="1" colspan="1">Sign of the effect</td>
        </tr>
        <tr>
          <td align="left" rowspan="1" colspan="1">Various applications</td>
          <td align="left" rowspan="1" colspan="1">Signal quality, sample size</td>
        </tr>
      </tbody>
    </table>
  </table-wrap>
  <table-wrap id="T2" position="float" orientation="portrait">
    <label>Table 2</label>
    <caption>
      <p>Short description of the different methods benchmarked and summary of the results of <xref ref-type="fig" rid="F2">Fig. 2e–h</xref> and <xref ref-type="supplementary-material" rid="SD1">Supplementary Fig. 2</xref>.</p>
    </caption>
    <table frame="above" rules="rows">
      <thead>
        <tr>
          <th valign="top" align="left" rowspan="2" colspan="1">Method</th>
          <th valign="top" align="left" rowspan="2" colspan="1">Short description</th>
          <th valign="top" align="left" colspan="2" rowspan="1">Type I error control</th>
          <th valign="top" align="left" colspan="2" rowspan="1">Gain in power</th>
          <th valign="top" align="left" rowspan="2" colspan="1">Comment</th>
        </tr>
        <tr>
          <th valign="top" align="left" rowspan="1" colspan="1"><italic>π</italic><sub>0</sub>=1</th>
          <th valign="top" align="left" rowspan="1" colspan="1">t-test</th>
          <th valign="top" align="left" rowspan="1" colspan="1">t-test (vs BH)</th>
          <th valign="top" align="left" rowspan="1" colspan="1">size investing</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td valign="top" align="left" rowspan="1" colspan="1">BH</td>
          <td valign="top" align="left" rowspan="1" colspan="1">Method of Benjamini and Hochberg [<xref rid="R1" ref-type="bibr">1</xref>] to control false-discovery rate (FDR) for multiple exchangeable hypotheses.</td>
          <td valign="top" align="center" rowspan="1" colspan="1">Yes</td>
          <td valign="top" align="center" rowspan="1" colspan="1">Yes</td>
          <td valign="top" align="center" rowspan="1" colspan="1">–</td>
          <td valign="top" align="center" rowspan="1" colspan="1">–</td>
          <th valign="top" align="center" rowspan="1" colspan="1"/>
        </tr>
        <tr>
          <td valign="top" align="left" rowspan="1" colspan="1">IHW</td>
          <td valign="top" align="left" rowspan="1" colspan="1">Independent hypothesis weighting, as proposed here.</td>
          <td valign="top" align="center" rowspan="1" colspan="1">Yes</td>
          <td valign="top" align="center" rowspan="1" colspan="1">Yes</td>
          <td valign="top" align="center" rowspan="1" colspan="1">Yes</td>
          <td valign="top" align="center" rowspan="1" colspan="1">Yes</td>
          <th valign="top" align="center" rowspan="1" colspan="1"/>
        </tr>
        <tr>
          <td valign="top" align="left" rowspan="1" colspan="1">Naive<break/>IHW</td>
          <td valign="top" align="left" rowspan="1" colspan="1">Naive independent hypothesis weighting, as proposed here.</td>
          <td valign="top" align="center" rowspan="1" colspan="1">No</td>
          <td valign="top" align="center" rowspan="1" colspan="1">No</td>
          <td valign="top" align="center" rowspan="1" colspan="1">Yes</td>
          <td valign="top" align="center" rowspan="1" colspan="1">Yes</td>
          <th valign="top" align="center" rowspan="1" colspan="1"/>
        </tr>
        <tr>
          <td valign="top" align="left" rowspan="1" colspan="1">Greedy Independent Filtering</td>
          <td valign="top" align="left" rowspan="1" colspan="1">The Independent Filtering procedure [<xref rid="R9" ref-type="bibr">9</xref>] modified to use a data-driven filter threshold which maximizes the number of discoveries.</td>
          <td valign="top" align="center" rowspan="1" colspan="1">No</td>
          <td valign="top" align="center" rowspan="1" colspan="1">No</td>
          <td valign="top" align="center" rowspan="1" colspan="1">Yes</td>
          <td valign="top" align="center" rowspan="1" colspan="1">No</td>
          <td valign="top" align="left" rowspan="1" colspan="1">The covariate-weights function is a binary step, monotonic.</td>
        </tr>
        <tr>
          <td valign="top" align="left" rowspan="1" colspan="1">SBH</td>
          <td valign="top" align="left" rowspan="1" colspan="1">Stratified Benjamini-Hochberg [<xref rid="R28" ref-type="bibr">28</xref>]: Apply the BH procedure at level <italic>α</italic> within each stratum, then combine the discoveries across the strata.</td>
          <td valign="top" align="center" rowspan="1" colspan="1">No</td>
          <td valign="top" align="center" rowspan="1" colspan="1">No</td>
          <td valign="top" align="center" rowspan="1" colspan="1">Yes</td>
          <td valign="top" align="center" rowspan="1" colspan="1">No</td>
          <th valign="top" align="left" rowspan="1" colspan="1"/>
        </tr>
        <tr>
          <td valign="top" align="left" rowspan="1" colspan="1">TST-GBH</td>
          <td valign="top" align="left" rowspan="1" colspan="1">The Group BH procedure [<xref rid="R10" ref-type="bibr">10</xref>]: An adaptive weighted BH procedure applied with weights proportional to <italic>π</italic><sub>1</sub>/<italic>π</italic><sub>0</sub> within each group. <italic>π</italic><sub>0</sub> is estimated using the TST estimator [<xref rid="R2" ref-type="bibr">2</xref>].</td>
          <td valign="top" align="center" rowspan="1" colspan="1">No</td>
          <td valign="top" align="center" rowspan="1" colspan="1">No</td>
          <td valign="top" align="center" rowspan="1" colspan="1">Yes</td>
          <td valign="top" align="center" rowspan="1" colspan="1">No</td>
          <th valign="top" align="left" rowspan="1" colspan="1"/>
        </tr>
        <tr>
          <td valign="top" align="left" rowspan="1" colspan="1">LSL-GBH</td>
          <td valign="top" align="left" rowspan="1" colspan="1">The Group BH procedure [<xref rid="R10" ref-type="bibr">10</xref>], where <italic>π</italic><sub>0</sub> is estimated using the LSL estimator</td>
          <td valign="top" align="center" rowspan="1" colspan="1">Yes</td>
          <td valign="top" align="center" rowspan="1" colspan="1">Yes</td>
          <td valign="top" align="center" rowspan="1" colspan="1">Yes</td>
          <td valign="top" align="center" rowspan="1" colspan="1">No</td>
          <th valign="top" align="left" rowspan="1" colspan="1"/>
        </tr>
        <tr>
          <td valign="top" align="left" rowspan="1" colspan="1">Clfdr</td>
          <td valign="top" align="left" rowspan="1" colspan="1">In the Clfdr procedure [<xref rid="R20" ref-type="bibr">20</xref>], the local fdr is estimated separately within each group and the estimates are pooled together. For the fdr estimation here we use the modified Grenander estimator [<xref rid="R5" ref-type="bibr">5</xref>].</td>
          <td valign="top" align="center" rowspan="1" colspan="1">Yes</td>
          <td valign="top" align="center" rowspan="1" colspan="1">No</td>
          <td valign="top" align="center" rowspan="1" colspan="1">Yes</td>
          <td valign="top" align="center" rowspan="1" colspan="1">Yes</td>
          <th valign="top" align="left" rowspan="1" colspan="1"/>
        </tr>
        <tr>
          <td valign="top" align="left" rowspan="1" colspan="1">FDRreg</td>
          <td valign="top" align="left" rowspan="1" colspan="1">The FDR regression method [<xref rid="R23" ref-type="bibr">23</xref>] estimates the local fdr by assuming all hypotheses have the same alternative density and <italic>π</italic><sub>0</sub> varies smoothly as a function of the covariate.</td>
          <td valign="top" align="center" rowspan="1" colspan="1">Yes</td>
          <td valign="top" align="center" rowspan="1" colspan="1">No</td>
          <td valign="top" align="center" rowspan="1" colspan="1">Yes</td>
          <td valign="top" align="center" rowspan="1" colspan="1">No</td>
          <td valign="top" align="left" rowspan="1" colspan="1">Requires <italic>z</italic>-scores.</td>
        </tr>
      </tbody>
    </table>
  </table-wrap>
</floats-group>
