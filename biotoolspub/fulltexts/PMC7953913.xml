<?properties open_access?>
<?subarticle report78912?>
<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jp2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">F1000Res</journal-id>
    <journal-id journal-id-type="iso-abbrev">F1000Res</journal-id>
    <journal-id journal-id-type="pmc">F1000Research</journal-id>
    <journal-title-group>
      <journal-title>F1000Research</journal-title>
    </journal-title-group>
    <issn pub-type="epub">2046-1402</issn>
    <publisher>
      <publisher-name>F1000 Research Limited</publisher-name>
      <publisher-loc>London, UK</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">7953913</article-id>
    <article-id pub-id-type="doi">10.12688/f1000research.27112.2</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Software Tool Article</subject>
      </subj-group>
      <subj-group>
        <subject>Articles</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>MosaicExplorerJ: Interactive stitching of terabyte-size tiled datasets from lightsheet microscopy</article-title>
      <fn-group content-type="pub-status">
        <fn>
          <p>[version 2; peer review: 2 approved]</p>
        </fn>
      </fn-group>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Tosi</surname>
          <given-names>Sébastien</given-names>
        </name>
        <role content-type="http://credit.casrai.org/">Conceptualization</role>
        <role content-type="http://credit.casrai.org/">Data Curation</role>
        <role content-type="http://credit.casrai.org/">Formal Analysis</role>
        <role content-type="http://credit.casrai.org/">Investigation</role>
        <role content-type="http://credit.casrai.org/">Methodology</role>
        <role content-type="http://credit.casrai.org/">Project Administration</role>
        <role content-type="http://credit.casrai.org/">Software</role>
        <role content-type="http://credit.casrai.org/">Supervision</role>
        <role content-type="http://credit.casrai.org/">Validation</role>
        <role content-type="http://credit.casrai.org/">Visualization</role>
        <role content-type="http://credit.casrai.org/">Writing – Original Draft Preparation</role>
        <role content-type="http://credit.casrai.org/">Writing – Review &amp; Editing</role>
        <contrib-id contrib-id-type="orcid">https://orcid.org/0000-0001-8348-2778</contrib-id>
        <xref ref-type="corresp" rid="c1">a</xref>
        <xref ref-type="aff" rid="a1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Bardia</surname>
          <given-names>Lídia</given-names>
        </name>
        <role content-type="http://credit.casrai.org/">Resources</role>
        <role content-type="http://credit.casrai.org/">Validation</role>
        <role content-type="http://credit.casrai.org/">Writing – Original Draft Preparation</role>
        <role content-type="http://credit.casrai.org/">Writing – Review &amp; Editing</role>
        <xref ref-type="aff" rid="a1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Barallobre</surname>
          <given-names>Maria Jose</given-names>
        </name>
        <role content-type="http://credit.casrai.org/">Resources</role>
        <role content-type="http://credit.casrai.org/">Validation</role>
        <role content-type="http://credit.casrai.org/">Writing – Review &amp; Editing</role>
        <xref ref-type="aff" rid="a2">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Muñoz-Barrutia</surname>
          <given-names>Arrate</given-names>
        </name>
        <role content-type="http://credit.casrai.org/">Resources</role>
        <role content-type="http://credit.casrai.org/">Validation</role>
        <role content-type="http://credit.casrai.org/">Writing – Review &amp; Editing</role>
        <xref ref-type="aff" rid="a3">3</xref>
        <xref ref-type="aff" rid="a4">4</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Soto-Montenegro</surname>
          <given-names>María Luisa</given-names>
        </name>
        <role content-type="http://credit.casrai.org/">Resources</role>
        <role content-type="http://credit.casrai.org/">Validation</role>
        <role content-type="http://credit.casrai.org/">Writing – Review &amp; Editing</role>
        <xref ref-type="aff" rid="a4">4</xref>
        <xref ref-type="aff" rid="a5">5</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Colombelli</surname>
          <given-names>Julien</given-names>
        </name>
        <role content-type="http://credit.casrai.org/">Data Curation</role>
        <role content-type="http://credit.casrai.org/">Funding Acquisition</role>
        <role content-type="http://credit.casrai.org/">Investigation</role>
        <role content-type="http://credit.casrai.org/">Project Administration</role>
        <role content-type="http://credit.casrai.org/">Resources</role>
        <role content-type="http://credit.casrai.org/">Supervision</role>
        <role content-type="http://credit.casrai.org/">Validation</role>
        <role content-type="http://credit.casrai.org/">Visualization</role>
        <role content-type="http://credit.casrai.org/">Writing – Original Draft Preparation</role>
        <role content-type="http://credit.casrai.org/">Writing – Review &amp; Editing</role>
        <contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-2784-4276</contrib-id>
        <xref ref-type="aff" rid="a1">1</xref>
      </contrib>
      <aff id="a1"><label>1</label>Institute for Research in Biomedicine - IRB Barcelona, the Barcelona Institute for Science and Technology - BIST, Barcelona, Spain</aff>
      <aff id="a2"><label>2</label>Department of Developmental Biology, Instituto de Biología Molecular de Barcelona, CSIC, Barcelona, Spain</aff>
      <aff id="a3"><label>3</label>Departamento de Bioingeniería e Ingeniería Aeroespacial, Universidad Carlos III de Madrid, Leganés, Spain</aff>
      <aff id="a4"><label>4</label>Instituto de Investigación Sanitaria Gregorio Marañón, Madrid, Spain</aff>
      <aff id="a5"><label>5</label>CIBER de Salud Mental (CIBERSAM), Madrid, Spain</aff>
    </contrib-group>
    <author-notes>
      <corresp id="c1">
        <label>a</label>
        <email xlink:href="mailto:sebastien.tosi@irbbarcelona.org">sebastien.tosi@irbbarcelona.org</email>
      </corresp>
      <fn fn-type="COI-statement">
        <p>No competing interests were disclosed.</p>
      </fn>
    </author-notes>
    <pub-date pub-type="epub">
      <day>4</day>
      <month>2</month>
      <year>2021</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2020</year>
    </pub-date>
    <volume>9</volume>
    <elocation-id>1308</elocation-id>
    <history>
      <date date-type="accepted">
        <day>25</day>
        <month>1</month>
        <year>2021</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>Copyright: © 2021 Tosi S et al.</copyright-statement>
      <copyright-year>2021</copyright-year>
      <license xlink:href="http://creativecommons.org/licenses/by/4.0/">
        <license-p>This is an open access article distributed under the terms of the Creative Commons Attribution Licence, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri content-type="pdf" xlink:href="f1000research-9-54151.pdf"/>
    <abstract>
      <p>We introduce MosaicExplorerJ, an ImageJ macro to stitch 3D tiles from terabyte-size microscopy datasets organized on a regular 2D grid. As opposed to existing software, stitching does not require any prior information on the actual positions of the tiles, or conversion of raw TIFF images to a multi-resolution format for interactive exploration and fast processing. MosaicExplorerJ was specifically designed to process lightsheet microscopy datasets from optically cleared samples. It can handle multiple fluorescence channels, dual-sided lightsheet illumination and dual-sided camera detection.</p>
    </abstract>
    <kwd-group kwd-group-type="author">
      <kwd>3D stitching</kwd>
      <kwd>Lightsheet microscopy</kwd>
      <kwd>Tiled scan</kwd>
      <kwd>Mosaic</kwd>
      <kwd>ImageJ</kwd>
    </kwd-group>
    <funding-group>
      <award-group id="fund-1" xlink:href="http://dx.doi.org/10.13039/100014440">
        <funding-source>Ministerio de Ciencia, Innovación y Universidades</funding-source>
        <award-id>RTC2017-6600-1</award-id>
        <award-id>PI17/01766</award-id>
      </award-group>
      <award-group id="fund-2" xlink:href="http://dx.doi.org/10.13039/501100004587">
        <funding-source>Instituto de Salud Carlos III</funding-source>
      </award-group>
      <award-group id="fund-3" xlink:href="http://dx.doi.org/10.13039/501100008530">
        <funding-source>European Regional Development Fund</funding-source>
      </award-group>
      <award-group id="fund-4" xlink:href="http://dx.doi.org/10.13039/501100003329">
        <funding-source>Ministerio de Economía y Competitividad</funding-source>
        <award-id>TEC2016-78052-R</award-id>
      </award-group>
      <funding-statement>The preparation of some of the datasets that were used to test MosaicExplorerJ was partially funded by project TEC2016-78052-R from the Spanish Ministry of Economy and Competitiveness and RTC2017-6600-1 from Ministry of Science, Innovation and Universities, as well as project PI17/01766 from Ministerio de Ciencia, Innovación y Universidades, Instituto de Salud Carlos III (co-financed by European Regional Development Fund (ERDF), “A way of making Europe").</funding-statement>
      <funding-statement>
        <italic>The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</italic>
      </funding-statement>
    </funding-group>
  </article-meta>
  <notes notes-type="version-changes">
    <sec sec-type="version-changes">
      <label>Revised</label>
      <title>Amendments from Version 1</title>
      <p>This new version of the article essentially corrects some incorrectly reported features of BigStitcher. It also introduces new video tutorials. Finally, some new software features were introduced (contextual help and illumination correction).</p>
    </sec>
  </notes>
</front>
<body>
  <sec sec-type="intro">
    <title>Introduction</title>
    <p>A number of open source tools are available to stitch mosaics from optical microscopy 3D tiled scans
<sup><xref rid="ref-1" ref-type="bibr">1</xref>–
<xref rid="ref-4" ref-type="bibr">4</xref></sup> but they systematically implement automated algorithms which results might depend on the starting positions of the tiles and potentially converge to a suboptimal solution. This is especially likely if the initial positions are far from the optimal positions, or if the data suffers from unexpected artifacts. Even worse, this situation can be difficult to detect in practice since these tools often bring no or scarce support to check the results and finely correct for the observable residual errors manually. Additionally, some software limits the size of the datasets
<sup><xref rid="ref-1" ref-type="bibr">1</xref>,
<xref rid="ref-2" ref-type="bibr">2</xref></sup>, or requires the data to be redundantly converted to ad-hoc formats
<sup><xref rid="ref-3" ref-type="bibr">3</xref></sup>. Finally, until now only BigStitcher
<sup><xref rid="ref-4" ref-type="bibr">4</xref></sup> could handle dual-sided illumination and dual-sided camera detection, two useful lightsheet microscopy
<sup><xref rid="ref-5" ref-type="bibr">5</xref></sup> modalities that can advantageously be combined (
<xref ref-type="fig" rid="f1">Figure 1</xref>, Left). We developed MosaicExplorerJ to address these shortcomings and bring a complementary alternative to ImageJ BigStitcher, the reference in the field.</p>
    <fig fig-type="figure" id="f1" orientation="portrait" position="anchor">
      <label>Figure 1. </label>
      <caption>
        <p><bold>Left</bold>: Illuminating the sample and collecting the light from both sides enables to image a sample by lightsheet microscopy in the best conditions.
<bold>Middle</bold>: Overlapping tiles (green, blue, red) from a 3D mosaic are shifted axially to compensate for the tilt of the lightsheet (here exaggerated around Y axis).
<bold>Right</bold>: Reconstructed mosaics from both cameras are aligned before stacking their best section.</p>
      </caption>
      <graphic xlink:href="f1000research-9-54151-g0000"/>
    </fig>
  </sec>
  <sec sec-type="methods">
    <title>Methods</title>
    <sec>
      <title>Implementation</title>
      <p>Whereas stitching the tiles of confocal microscopy datasets chiefly consists in compensating for the scanning head to sample stage tilt (assuming a perfectly orthogonal XYZ translation system), stitching lightsheet microscopy datasets is compounded by the fact that the lightsheet is not necessarily perfectly collinear to the object plane of the detection objective. This can lead to 1) a distortion of the aspect ratio of the images (often negligible), 2) an apparent axial displacement of the tiles while moving across the mosaic. This second effect can be simply compensated by axially offsetting the 3D tiles accordingly (
<xref ref-type="fig" rid="f1">Figure 1</xref>, Middle), but additional lightsheet non-uniformity (or lateral misalignment) can lead to differences in the features visible in the regions of tile overlap; potentially weakening correlation based stitching algorithms. To address these issues, MosaicExplorerJ assists the user in visually aligning the tiles along the possible degrees of freedom set by a predefined physical model by following a step-by-step procedure to compensate for mismatches highlighted in the regions of tiles overlap.</p>
    </sec>
    <sec>
      <title>Operation</title>
      <p>ImageJ/Fiji should be installed and MosaicExplorerJ run from ImageJ macro editor. If no other data is available, the software can be tested with the sample data provided (Extended Data S1
<sup><xref rid="ref-6" ref-type="bibr">6</xref></sup>). First, the mosaics from both cameras (and illumination sides) should be aligned independently before being aligned together. This first operation can be as simple as joining two matching features between two adjacent tiles (
<xref ref-type="fig" rid="f2">Figure 2B</xref>, Extended Data S3-V1
<sup><xref rid="ref-6" ref-type="bibr">6</xref></sup>), while compensating lightsheet tilt (
<xref ref-type="fig" rid="f2">Figures 2C, 2D</xref>) and the axial wobbling of the motors forming the mosaics might require to adjust the axial shift of a selected number of tiles in the top row/column of the mosaic (Extended Data S3-V2
<sup><xref rid="ref-6" ref-type="bibr">6</xref></sup>). Dual-sided camera datasets alignment includes an extra calibration step to compensate for discrepancy between the magnifications of both detection objective lenses (
<xref ref-type="fig" rid="f1">Figure 1</xref>, Right, Extended Data S3-V3
<sup><xref rid="ref-6" ref-type="bibr">6</xref></sup>), while dual-sided illumination datasets can be stitched by following a similar procedure (Extended Data S3-V4
<sup><xref rid="ref-6" ref-type="bibr">6</xref></sup>). Intensity correction can be achieved from either external correction masks or interactively adjusted from XY separable shading correction masks (Extended Data S3-V5
<sup><xref rid="ref-6" ref-type="bibr">6</xref></sup>). Finally, the user can save the overall mosaic alignment for further inspection, or export the stitched dataset as a TIFF series.</p>
      <fig fig-type="figure" id="f2" orientation="portrait" position="anchor">
        <label>Figure 2. </label>
        <caption>
          <p><bold>A</bold>: Two mosaics (2×8 tiles each with a full overlap in the central column along Y) from a dual-sided illumination dataset aligned with MosaicExplorerJ, the arrows show the directions of the light sheets (the view is turned and cropped to fit the figure). Scale bar: 1 mm.
<bold>B</bold>: Zoomed region from the red square prior to adjusting the XY positions of the tiles but after axial shift (Z) correction. The user joins two matching features (white arrow) from two adjacent tiles.
<bold>C</bold>: The XY positions of the tiles are adjusted based on the previous user input and for correct alignment matching features are highlighted in white in the region of overlap.
<bold>D</bold>: Same view but prior to axial shift correction to compensate for lightsheet tilt: no matching features are apparent in the region of overlap. Scale bar: 100 µm.</p>
        </caption>
        <graphic xlink:href="f1000research-9-54151-g0001"/>
      </fig>
    </sec>
    <sec>
      <title>Testing</title>
      <p>MosaicExplorerJ has been extensively tested by stitching several large lightsheet microscopy datasets acquired from diverse optically cleared biological samples (see
<italic>Data availability</italic>).</p>
    </sec>
  </sec>
  <sec>
    <title>Use cases</title>
    <p>All datasets were successfully aligned, each time in under 30 minutes. The results were checked visually by scrolling through the slices and ensuring that the alignment was correct in the regions of overlap between the tiles. The dataset Brain2_izq_2x8Mosaic_LeftSide_300GB was also aligned by BigStitcher, leading to similar results both visually and quantitatively (Extended Data Table S1
<sup><xref rid="ref-6" ref-type="bibr">6</xref></sup>). It took about 2h30 to process this dataset with BigStitcher (from 3D TIF tiles to computed alignment), excluding the conversion from TIFF series (the original format of this dataset) to 3D TIFF tiles. This time is expected to scale at least linearly with increasing dataset size for BigStitcher while alignment time in MosaicExplorerJ is relatively constant, and mostly conditioned by the degrees of freedom of the 3D tiles. After alignment, the exportation of the stitched images to TIFF series could be achieved in a comparable time with both tools.</p>
  </sec>
  <sec sec-type="conclusions">
    <title>Conclusion</title>
    <p>Even though it only supports a subset of its features, MosaicExplorerJ brings a complementary alternative to BigStitcher and presents a number of advantages (Extended Data S2
<sup><xref rid="ref-6" ref-type="bibr">6</xref></sup> and Table S2
<sup><xref rid="ref-6" ref-type="bibr">6</xref></sup>). No fiducials or detectable feature points are required, which makes the tool robust, versatile, and compatible with large optically cleared samples for which introducing fiducials is virtually impossible. The processing is fast, and terabyte-size datasets can be explored on the fly without conversion to an intermediate format, even on laptop computers with limited memory. Finally, all alignment steps are performed visually, which brings direct control and feedback both on the imperfections of the datasets and on the quality of the results, minimizing the risk of leaving coarse errors unnoticed.</p>
  </sec>
  <sec sec-type="data-availability">
    <title>Data availability</title>
    <sec>
      <title>Underlying data</title>
      <p>A complete description of the datasets used to test MosaicExplorerJ, including sample preparation and imaging can be found in Extended Data S1
<sup><xref rid="ref-6" ref-type="bibr">6</xref></sup>. The full datasets are too large (1.5TB) to feasibly host on a data repository; however, datasets can all be accessed publicly on the IRB Barcelona Google Drive at:
<ext-link ext-link-type="uri" xlink:href="https://bit.ly/37iocrP">https://bit.ly/37iocrP</ext-link>.</p>
    </sec>
    <sec>
      <title>Extended data</title>
      <p>Zenodo: MosaicExplorerJ F1000Research article extended data.
<ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5281/zenodo.4455761">10.5281/zenodo.4455761</ext-link>
<sup><xref rid="ref-6" ref-type="bibr">6</xref></sup>.
<italic/>
</p>
      <p>Data are available under the terms of the
<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/legalcode">Creative Commons Attribution 4.0 International license</ext-link> (CC-BY 4.0).</p>
    </sec>
  </sec>
  <sec>
    <title>Software availability</title>
    <p>Source code and documentation are available from:
<ext-link ext-link-type="uri" xlink:href="https://github.com/SebastienTs/MosaicExplorerJ">https://github.com/SebastienTs/MosaicExplorerJ</ext-link>
</p>
    <p>Archived source code at time of publication:
<ext-link ext-link-type="uri" xlink:href="http://www.doi.org/10.5281/zenodo.4453506">http://www.doi.org/10.5281/zenodo.4453506</ext-link>
<sup><xref rid="ref-7" ref-type="bibr">7</xref></sup>.</p>
    <p>License:
<ext-link ext-link-type="uri" xlink:href="https://opensource.org/licenses/GPL-3.0">GNU General Public License v3.0</ext-link>.</p>
  </sec>
</body>
<back>
  <ack>
    <title>Acknowledgements</title>
    <p>This publication was supported by COST Action NEUBIAS (CA15124), funded by COST (European Cooperation in Science and Technology). MJB acknowledges the support of Jérôme Lejeune Foundation.</p>
  </ack>
  <ref-list>
    <ref id="ref-1">
      <label>1</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Emmenlauer</surname><given-names>M</given-names></name><name><surname>Ronneberger</surname><given-names>O</given-names></name><name><surname>Ponti</surname><given-names>A</given-names></name><etal/></person-group>:
<article-title>XuvTools: free, fast and reliable stitching of large 3D datasets.</article-title><source><italic toggle="yes">J Microsc.</italic></source><year>2009</year>;<volume>233</volume>(<issue>1</issue>):<fpage>42</fpage>–<lpage>60</lpage>.
<pub-id pub-id-type="doi">10.1111/j.1365-2818.2008.03094.x</pub-id><?supplied-pmid 19196411?><pub-id pub-id-type="pmid">19196411</pub-id></mixed-citation>
    </ref>
    <ref id="ref-2">
      <label>2</label>
      <mixed-citation publication-type="journal"><article-title><ext-link ext-link-type="uri" xlink:href="https://imagej.net/Grid/Collection_Stitching_Plugin">https://imagej.net/Grid/Collection_Stitching_Plugin</ext-link></article-title>.</mixed-citation>
    </ref>
    <ref id="ref-3">
      <label>3</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bria</surname><given-names>A</given-names></name><name><surname>Iannello</surname><given-names>G</given-names></name></person-group>:
<article-title>TeraStitcher - a tool for fast automatic 3D-stitching of teravoxel-sized microscopy images.</article-title><source><italic toggle="yes">BMC Bioinformatics.</italic></source><year>2012</year>;<volume>13</volume>:<fpage>316</fpage>.
<pub-id pub-id-type="doi">10.1186/1471-2105-13-316</pub-id><!--<pub-id pub-id-type="pmcid">3582611</pub-id>--><?supplied-pmid 23181553?><pub-id pub-id-type="pmid">23181553</pub-id></mixed-citation>
    </ref>
    <ref id="ref-4">
      <label>4</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hörl</surname><given-names>D</given-names></name><name><surname>Rojas Rusak</surname><given-names>F</given-names></name><name><surname>Preusser</surname><given-names>F</given-names></name><etal/></person-group>:
<article-title>BigStitcher: reconstructing high-resolution image datasets of cleared and expanded samples.</article-title><source><italic toggle="yes">Nat Methods.</italic></source><year>2019</year>;<volume>16</volume>(<issue>9</issue>):<fpage>870</fpage>–<lpage>874</lpage>.
<pub-id pub-id-type="doi">10.1038/s41592-019-0501-0</pub-id><?supplied-pmid 31384047?><pub-id pub-id-type="pmid">31384047</pub-id></mixed-citation>
    </ref>
    <ref id="ref-5">
      <label>5</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huisken</surname><given-names>J</given-names></name><name><surname>Swoger</surname><given-names>J</given-names></name><name><surname>Del Bene</surname><given-names>F</given-names></name><etal/></person-group>:
<article-title>Optical sectioning deep inside live embryos by selective plane illumination microscopy.</article-title><source><italic toggle="yes">Science.</italic></source><year>2004</year>;<volume>305</volume>(<issue>5686</issue>):<fpage>1007</fpage>–<lpage>1009</lpage>.
<pub-id pub-id-type="doi">10.1126/science.1100035</pub-id><?supplied-pmid 15310904?><pub-id pub-id-type="pmid">15310904</pub-id></mixed-citation>
    </ref>
    <ref id="ref-6">
      <label>6</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tosi</surname><given-names>S</given-names></name><name><surname>Bardia</surname><given-names>L</given-names></name><name><surname>Colombelli</surname><given-names>J</given-names></name><etal/></person-group>:
<article-title>MosaicExplorerJ F1000Research article extended data (Version 2.0).</article-title><source><italic toggle="yes">Zenodo.</italic></source><year>2021</year>.
<pub-id pub-id-type="doi">10.5281/zenodo.4455761</pub-id></mixed-citation>
    </ref>
    <ref id="ref-7">
      <label>7</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tosi</surname><given-names>S</given-names></name></person-group>:
<article-title>SebastienTs/MosaicExplorerJ: Revised Release (Version 1.5).</article-title><source><italic toggle="yes">Zenodo.</italic></source><year>2021</year>.
<pub-id pub-id-type="doi">10.5281/zenodo.4453506</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
<sub-article id="report78912" article-type="peer-review">
  <front-stub>
    <article-id pub-id-type="doi">10.5256/f1000research.54151.r78912</article-id>
    <title-group>
      <article-title>Reviewer response for version 2</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Preibisch</surname>
          <given-names>Stephan</given-names>
        </name>
        <xref ref-type="aff" rid="r78912a1">1</xref>
        <xref ref-type="aff" rid="r78912a2">2</xref>
        <role>Referee</role>
        <contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-0276-494X</contrib-id>
      </contrib>
      <aff id="r78912a1"><label>1</label>Berlin Institute for Medical Systems Biology, Berlin, Germany</aff>
      <aff id="r78912a2"><label>2</label>HHMI Janelia, Ashburn, VA, USA</aff>
    </contrib-group>
    <author-notes>
      <fn fn-type="COI-statement">
        <p><bold>Competing interests: </bold>No competing interests were disclosed.</p>
      </fn>
    </author-notes>
    <pub-date pub-type="epub">
      <day>11</day>
      <month>3</month>
      <year>2021</year>
    </pub-date>
    <permissions>
      <copyright-statement>Copyright: © 2021 Preibisch S</copyright-statement>
      <copyright-year>2021</copyright-year>
      <license xlink:href="http://creativecommons.org/licenses/by/4.0/">
        <license-p>This is an open access peer review report distributed under the terms of the Creative Commons Attribution Licence, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <related-article related-article-type="peer-reviewed-article" id="d39e815" ext-link-type="doi" xlink:href="10.12688/f1000research.27112.2">Version 2</related-article>
    <custom-meta-group>
      <custom-meta>
        <meta-name>recommendation</meta-name>
        <meta-value>approve</meta-value>
      </custom-meta>
    </custom-meta-group>
  </front-stub>
  <body>
    <p>Thanks so much to the authors for addressing my concerns, I think their work is a useful addition for lightsheet reconstruction.</p>
    <p>Are the conclusions about the tool and its performance adequately supported by the findings presented in the article?</p>
    <p>Partly</p>
    <p>Is the rationale for developing the new software tool clearly explained?</p>
    <p>Partly</p>
    <p>Is the description of the software tool technically sound?</p>
    <p>Partly</p>
    <p>Are sufficient details of the code, methods and analysis (if applicable) provided to allow replication of the software development and its use by others?</p>
    <p>Yes</p>
    <p>Is sufficient information provided to allow interpretation of the expected output datasets and any results generated using the tool?</p>
    <p>Yes</p>
    <p>Reviewer Expertise:</p>
    <p>Image analysis, image registration, lightsheet</p>
    <p>I confirm that I have read this submission and believe that I have an appropriate level of expertise to confirm that it is of an acceptable scientific standard.</p>
  </body>
</sub-article>
<sub-article id="report78911" article-type="peer-review">
  <front-stub>
    <article-id pub-id-type="doi">10.5256/f1000research.54151.r78911</article-id>
    <title-group>
      <article-title>Reviewer response for version 2</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Pampaloni</surname>
          <given-names>Francesco</given-names>
        </name>
        <xref ref-type="aff" rid="r78911a1">1</xref>
        <role>Referee</role>
        <contrib-id contrib-id-type="orcid">https://orcid.org/0000-0003-4357-7320</contrib-id>
      </contrib>
      <aff id="r78911a1"><label>1</label>Buchmann Institute for Molecular Life Sciences, Goethe University Frankfurt, Frankfurt am Main, Germany</aff>
    </contrib-group>
    <author-notes>
      <fn fn-type="COI-statement">
        <p><bold>Competing interests: </bold>No competing interests were disclosed.</p>
      </fn>
    </author-notes>
    <pub-date pub-type="epub">
      <day>1</day>
      <month>3</month>
      <year>2021</year>
    </pub-date>
    <permissions>
      <copyright-statement>Copyright: © 2021 Pampaloni F</copyright-statement>
      <copyright-year>2021</copyright-year>
      <license xlink:href="http://creativecommons.org/licenses/by/4.0/">
        <license-p>This is an open access peer review report distributed under the terms of the Creative Commons Attribution Licence, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <related-article related-article-type="peer-reviewed-article" id="d39e899" ext-link-type="doi" xlink:href="10.12688/f1000research.27112.2">Version 2</related-article>
    <custom-meta-group>
      <custom-meta>
        <meta-name>recommendation</meta-name>
        <meta-value>approve</meta-value>
      </custom-meta>
    </custom-meta-group>
  </front-stub>
  <body>
    <p>The authors added links to five video tutorials in the documentation available on GitHub. The videos greatly support the first user of the MosaicExplorerJ macro in understanding the different steps to align and merge the tiles and to perform the registration of dual-sided LS illumination and dual-sided detection data sets. The changes and the addition in the documentation made by the authors in the reviewed version significantly reduce the time the user has to invest to learn how to apply the macro to her/his own data sets. Especially after following the explanatory videos, all the functions of the macro can be straightforwardly used. Overall, a user-friendly and very useful macro for the light sheet microscopy community.</p>
    <p> Detected bugs:
<list list-type="bullet"><list-item><p>After pressing Cancel, it is not possible to re-open the MosaicExplorerJ GUI with Alt.</p></list-item><list-item><p>The “Register OvIX &amp; YCor -&gt; OvIY &amp;XCor” function works correctly only if the selection line is drawn from east -&gt; west and not vice versa.</p></list-item><list-item><p>The “Register OvY  XCor only” function works correctly only if the selection line is drawn from the bottom to the top (or south -&gt; north), but not vice versa.</p></list-item></list>
</p>
    <p>Are the conclusions about the tool and its performance adequately supported by the findings presented in the article?</p>
    <p>Yes</p>
    <p>Is the rationale for developing the new software tool clearly explained?</p>
    <p>Yes</p>
    <p>Is the description of the software tool technically sound?</p>
    <p>Yes</p>
    <p>Are sufficient details of the code, methods and analysis (if applicable) provided to allow replication of the software development and its use by others?</p>
    <p>Partly</p>
    <p>Is sufficient information provided to allow interpretation of the expected output datasets and any results generated using the tool?</p>
    <p>Yes</p>
    <p>Reviewer Expertise:</p>
    <p>Light Sheet Microscopy, 3D cell biology, stem cell and tumor organoids.</p>
    <p>I confirm that I have read this submission and believe that I have an appropriate level of expertise to confirm that it is of an acceptable scientific standard.</p>
  </body>
</sub-article>
<sub-article id="report75056" article-type="peer-review">
  <front-stub>
    <article-id pub-id-type="doi">10.5256/f1000research.29948.r75056</article-id>
    <title-group>
      <article-title>Reviewer response for version 1</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Pampaloni</surname>
          <given-names>Francesco</given-names>
        </name>
        <xref ref-type="aff" rid="r75056a1">1</xref>
        <role>Referee</role>
        <contrib-id contrib-id-type="orcid">https://orcid.org/0000-0003-4357-7320</contrib-id>
      </contrib>
      <aff id="r75056a1"><label>1</label>Buchmann Institute for Molecular Life Sciences, Goethe University Frankfurt, Frankfurt am Main, Germany</aff>
    </contrib-group>
    <author-notes>
      <fn fn-type="COI-statement">
        <p><bold>Competing interests: </bold>No competing interests were disclosed.</p>
      </fn>
    </author-notes>
    <pub-date pub-type="epub">
      <day>11</day>
      <month>12</month>
      <year>2020</year>
    </pub-date>
    <permissions>
      <copyright-statement>Copyright: © 2020 Pampaloni F</copyright-statement>
      <copyright-year>2020</copyright-year>
      <license xlink:href="http://creativecommons.org/licenses/by/4.0/">
        <license-p>This is an open access peer review report distributed under the terms of the Creative Commons Attribution Licence, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <related-article related-article-type="peer-reviewed-article" id="d39e998" ext-link-type="doi" xlink:href="10.12688/f1000research.27112.1">Version 1</related-article>
    <custom-meta-group>
      <custom-meta>
        <meta-name>recommendation</meta-name>
        <meta-value>approve-with-reservations</meta-value>
      </custom-meta>
    </custom-meta-group>
  </front-stub>
  <body>
    <p>
      <underline>Overview</underline>
    </p>
    <p> The MosaicExplorerJ ImageJ macro-code described in the manuscript is a useful tool to stitch very large data sets recorded with light sheet microscopy. Indeed, the amount of data acquired in a typical session of light-sheet imaging of optically cleared organs (e.g. the mouse brain), reaches easily the TB range with up-to-date equipment. Therefore, user-friendly and straightforward data navigation and stitching software is needed by the scientific community. MosaicExplorerJ, at variance with automatic stitching algorithms such as BigStitcher, it is a fully manual tool, requiring the user manually perform all the alignment steps in order to compensate the tiles mismatch, e.g. the tiles axial shift arising from a tilted light sheet. Moreover, also at variance with BigStitcher, multi-tiff image stacks can be opened directly without conversion.</p>
    <p> I recommend the manuscript for idexing with minor changes and additions as described in the following remarks.</p>
    <p>
      <underline>Remarks</underline>
    </p>
    <p> The dataset deposited by the authors on the IRB Barcelona server allows readily testing the macro. The macro runs from the macro editor. The dataset is quickly loaded into the main window. In order to properly upload the tiles, the different files have to be named sequentially following the explained rule. After opening the dataset, the alignment and stitching are performed by manually setting the shifting parameters (xy translation and axial alignment along z) shown in the control panel.</p>
    <p> In general, a first-time user can achieve the stitching of the mosaic 3D dataset as described in the manuscript by following the steps outlined in the documentation available on GitHub. However, the learning curve is quite steep and some effort and time is necessary by the user in order to understand the working of the macro and to achieve the result. In order to allow for a smoother learning curve, I strongly recommend the authors to upload videos illustrating the stitching procedure for two datasets at increasing difficulty.</p>
    <p> Particularly, the following step described in the documentation (p. 3, end) is not clearly explained, and should be better illustrated with a further figure and in a video:</p>
    <p>
      <italic>“For linear correction, it is recommended to use the top left tile as reference and gradually tweak ZxCor from the tile to the right, until some matching features are apparent in the overlap region. Then ZyCor can be adjusted, this time by considering the tile below. The adjustment of the Z offsets can be performed by typing values in the Panel or by following the procedure described below for free correction.”</italic>
    </p>
    <p> I also recommend to include the documentation in the manuscript extended material as well, and not exclusively in GitHub, as the macro “instructions” are an essential part of the work.</p>
    <p>Are the conclusions about the tool and its performance adequately supported by the findings presented in the article?</p>
    <p>Yes</p>
    <p>Is the rationale for developing the new software tool clearly explained?</p>
    <p>Yes</p>
    <p>Is the description of the software tool technically sound?</p>
    <p>Yes</p>
    <p>Are sufficient details of the code, methods and analysis (if applicable) provided to allow replication of the software development and its use by others?</p>
    <p>Partly</p>
    <p>Is sufficient information provided to allow interpretation of the expected output datasets and any results generated using the tool?</p>
    <p>Yes</p>
    <p>Reviewer Expertise:</p>
    <p>Light Sheet Microscopy, 3D cell biology, stem cell and tumor organoids.</p>
    <p>I confirm that I have read this submission and believe that I have an appropriate level of expertise to confirm that it is of an acceptable scientific standard, however I have significant reservations, as outlined above.</p>
  </body>
  <sub-article id="comment6294-75056" article-type="response">
    <front-stub>
      <contrib-group>
        <contrib contrib-type="author">
          <name>
            <surname>Tosi</surname>
            <given-names>Sebastien</given-names>
          </name>
          <aff/>
        </contrib>
      </contrib-group>
      <author-notes>
        <fn fn-type="COI-statement">
          <p><bold>Competing interests: </bold>No competing interests were disclosed.</p>
        </fn>
      </author-notes>
      <pub-date pub-type="epub">
        <day>21</day>
        <month>1</month>
        <year>2021</year>
      </pub-date>
    </front-stub>
    <body>
      <p>Thank you for reviewing the article and for pointing out these weaknesses of the documentation. We have tried to substantially improve the documentation accordingly and we have created five video tutorials to help illustrate all the steps described in the documentation. Please see our detailed answers below.</p>
      <p> &gt; In general, a first-time user can achieve the stitching of the mosaic 3D dataset as described in the manuscript by following the steps outlined in the documentation available on GitHub. However, the learning curve is quite steep and some effort and time is necessary by the user in order to understand the working of the macro and to achieve the result. In order to allow for a smoother learning curve, I strongly recommend the authors to upload videos illustrating the stitching procedure for two datasets at increasing difficulty.</p>
      <p> We have included five video tutorials that illustrate the main operations and complement the documentation. These videos are available from the GitHub repository and from the new Extended Data 
<bold>S3</bold>.</p>
      <p> &gt; Particularly, the following step described in the documentation (p. 3, end) is not clearly explained, and should be better illustrated with a further figure and in a video: “For linear correction, it is recommended to use the top left tile as reference and gradually tweak ZxCor from the tile to the right, until some matching features are apparent in the overlap region. Then ZyCor can be adjusted, this time by considering the tile below. The adjustment of the Z offsets can be performed by typing values in the Panel or by following the procedure described below for free correction.”</p>
      <p> We have completely rewritten this part of the documentation and the new video tutorial
<bold>S3-V2</bold> is fully dedicated to explaining this critical step.</p>
      <p> &gt; I also recommend to include the documentation in the manuscript extended material as well, and not exclusively in GitHub, as the macro “instructions” are an essential part of the work.</p>
      <p> We created a new Extended Data 
<bold>S3</bold> with links to the documentation of the software and to the five new video tutorials. Both are also available from the GitHub repository.</p>
    </body>
  </sub-article>
</sub-article>
<sub-article id="report74555" article-type="peer-review">
  <front-stub>
    <article-id pub-id-type="doi">10.5256/f1000research.29948.r74555</article-id>
    <title-group>
      <article-title>Reviewer response for version 1</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Preibisch</surname>
          <given-names>Stephan</given-names>
        </name>
        <xref ref-type="aff" rid="r74555a1">1</xref>
        <xref ref-type="aff" rid="r74555a2">2</xref>
        <role>Referee</role>
        <contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-0276-494X</contrib-id>
      </contrib>
      <aff id="r74555a1"><label>1</label>Berlin Institute for Medical Systems Biology, Berlin, Germany</aff>
      <aff id="r74555a2"><label>2</label>HHMI Janelia, Ashburn, VA, USA</aff>
    </contrib-group>
    <author-notes>
      <fn fn-type="COI-statement">
        <p><bold>Competing interests: </bold>No competing interests were disclosed.</p>
      </fn>
    </author-notes>
    <pub-date pub-type="epub">
      <day>7</day>
      <month>12</month>
      <year>2020</year>
    </pub-date>
    <permissions>
      <copyright-statement>Copyright: © 2020 Preibisch S</copyright-statement>
      <copyright-year>2020</copyright-year>
      <license xlink:href="http://creativecommons.org/licenses/by/4.0/">
        <license-p>This is an open access peer review report distributed under the terms of the Creative Commons Attribution Licence, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <related-article related-article-type="peer-reviewed-article" id="d39e1190" ext-link-type="doi" xlink:href="10.12688/f1000research.27112.1">Version 1</related-article>
    <custom-meta-group>
      <custom-meta>
        <meta-name>recommendation</meta-name>
        <meta-value>approve-with-reservations</meta-value>
      </custom-meta>
    </custom-meta-group>
  </front-stub>
  <body>
    <p>The authors present MosaicExplorerJ, an ImageJ macro for manual alignment of tiled lightsheet acquisitions.</p>
    <p> I think it can be useful as it provides simple, editable source code. I personally found it quite hard to use, but more practice might make it more efficient. But more explanations of the parameters and keyboard shortcuts in the application would certainly be helpful (press F1 or similar).</p>
    <p> Most importantly, the paper should clearly state the limitations of the software and correct wrong statements about the comparison to other tools, in particular BigStitcher from my point of view.</p>
    <p><underline>Not mentioned limitations (or implicitly assumed ones)</underline>:
<list list-type="bullet"><list-item><p>all files need to have the same dimensions (also in z)</p></list-item><list-item><p>only 3D translation models are supported</p></list-item><list-item><p>no chromatic aberration correction</p></list-item><list-item><p>maximal xy output size is 2^31 pixels, the limitation of ImageJ (around 47000x47000 pixels)</p></list-item></list><underline>Incorrect comparisons that should be corrected</underline>:</p>
    <p> 1) “As opposed to existing software, stitching does not require any prior information on the actual positions of the tiles, sample fiducials, or conversion of raw TIFF images, and the stitched images can be explored instantly.”
<list list-type="bullet"><list-item><p>That is the same in BigStitcher, conversion to HDF5 is not necessary, TIFFs can be virtually loaded and displayed instantaneously </p></list-item></list> 2) “but they all implement automated algorithms … Even worse, this situation can be difficult to detect in practice since these tools bring no or scarce support to check the results and correct for errors manually.”
<list list-type="bullet"><list-item><p>BigStitcher provides user friendly methods for manual &amp; interactive alignment (3D translation): https://imagej.net/BigStitcher_manual_translation</p></list-item></list> 3) “Finally, none of these solutions handles both dual-side illumination and dual-side camera detection, two useful lightsheet microscopy”
<list list-type="bullet"><list-item><p>BigStitcher supports dual-side illumination and dual-side camera detection (e.g. Supplementary Figure 17)</p></list-item></list> 4) S2-Comparison with BigStitcher:
<list list-type="bullet"><list-item><p>3D TIFF tiles can be natively used through virtual loading, live display in BDV even. HDF5 conversion is optional (yet very useful)</p></list-item><list-item><p>2D TIFF slices are also supported, but it's a quite hidden feature]</p></list-item><list-item><p>BigStitcher supports Dual-camera support</p></list-item><list-item><p>Physical model constrained grid alignment is also possible, see link above, even interactive &amp; manual</p></list-item><list-item><p>Automatic color highlighting of tiles mismatch can be done in BigStitcher</p></list-item><list-item><p>BigStitcher additionally supports per-tile intensity correction using Affine 1D models</p></list-item></list>
</p>
    <p>Are the conclusions about the tool and its performance adequately supported by the findings presented in the article?</p>
    <p>Partly</p>
    <p>Is the rationale for developing the new software tool clearly explained?</p>
    <p>Partly</p>
    <p>Is the description of the software tool technically sound?</p>
    <p>Partly</p>
    <p>Are sufficient details of the code, methods and analysis (if applicable) provided to allow replication of the software development and its use by others?</p>
    <p>Yes</p>
    <p>Is sufficient information provided to allow interpretation of the expected output datasets and any results generated using the tool?</p>
    <p>Yes</p>
    <p>Reviewer Expertise:</p>
    <p>Image analysis, image registration, lightsheet</p>
    <p>I confirm that I have read this submission and believe that I have an appropriate level of expertise to confirm that it is of an acceptable scientific standard, however I have significant reservations, as outlined above.</p>
  </body>
  <sub-article id="comment6293-74555" article-type="response">
    <front-stub>
      <contrib-group>
        <contrib contrib-type="author">
          <name>
            <surname>Tosi</surname>
            <given-names>Sebastien</given-names>
          </name>
          <aff/>
        </contrib>
      </contrib-group>
      <author-notes>
        <fn fn-type="COI-statement">
          <p><bold>Competing interests: </bold>No competing interests were disclosed.</p>
        </fn>
      </author-notes>
      <pub-date pub-type="epub">
        <day>21</day>
        <month>1</month>
        <year>2021</year>
      </pub-date>
    </front-stub>
    <body>
      <p>First of all, we thank the reviewer for his thorough comments and we would like to apologize for overlooking some of BigStitcher's features that we were genuinely unaware of. Also, as rightly pointed out by the reviewer, some limitations of MosaicExplorerJ were not discussed in the article. We have remedied this, as described point by point in our answer, and we hope that the features and the operating workflow of the two applications are now reflected more accurately in the fully updated Extended Data 
<bold>S2</bold>.</p>
      <p> &gt; More explanations of the parameters and keyboard shortcuts in the application would certainly be helpful (press F1 or similar).</p>
      <p> We have tried our best to improve this aspect in MosaicExplorerJ (v1.5, now on GitHub): a help window can now be displayed by pressing F1, contextual information is provided in ImageJ status bar (and strategically in some of the dialog boxes), and the manual operation to perform axial adjustment of the tiles has been simplified. Finally, five video tutorials (
<underline>bit.ly/2KY0BDN</underline>) were created to illustrate the main operations and to complement the documentation.</p>
      <p> &gt; Not mentioned limitations (or implicitly assumed ones) of MosaicExplorerJ:</p>
      <p> 1. All files need to have the same dimensions (also in z)Actually, this is not strictly required as missing tiles or tiles missing Z slices (for 2D TIFF series mode) will not trigger an error but the corresponding images will just be displayed black. However, to answer this comment, we now state in the Abstract of the article (and in Extended Data 
<bold>S2</bold>) that the tiles should be organized on a regular 2D grid.</p>
      <p> 2. Only 3D translation models are supported</p>
      <p> Yes, only these operations are supported for a single camera dataset but 2D similarity (rotation, scaling, translation) is performed (after 3D translations) when registering the mosaics from two opposing cameras (as described in
<bold>Figure 1</bold>).</p>
      <p> 3. No chromatic aberration correction</p>
      <p> We now explicitly state in Extended Data 
<bold>Table S2 </bold>that chromatic aberrations correction is not supported by MosaicExplorerJ (while it is supported by BigStitcher).</p>
      <p> 4. Maximal xy output size is 2^31 pixels, the limitation of ImageJ (around 47000x47000 pixels)</p>
      <p> We now explicitly state in Extended Data 
<bold>Table S2 </bold>that mosaics stitched by MosaicExplorerJ are limited to about 47.000 x 47.000 pixels (and eight channels) while BigStitcher sets no limit. We haven’t included this information in the text of the main article as we believe that it is not really limiting in practice.</p>
      <p><underline>Incorrect comparisons that should be corrected</underline>:</p>
      <p> 1) “As opposed to existing software, stitching does not require any prior information on the actual positions of the tiles, sample fiducials, or conversion of raw TIFF images, and the stitched images can be explored instantly.”</p>
      <p> That is the same in BigStitcher, conversion to HDF5 is not necessary, TIFFs can be virtually loaded and displayed instantaneously.</p>
      <p> We apologize for this misleading statement and we were unaware that tiles could be loaded as a set of 2D TIFF series in BigStitcher. Still, we believe that HDF5 conversion is implicitly required for efficient operations when handling TB datasets, both for interactive 3D viewing and to enable a practical processing time (especially when several rounds of tile placement / parameters optimizations have to be performed to get to satisfying results). We updated this paragraph of the text to reflect this idea, and we stated in Extended Data 
<bold>Table S2</bold> that while not strictly required HDF5 conversion is desirable to speed up operations.</p>
      <p> 2) “but they all implement automated algorithms … Even worse, this situation can be difficult to detect in practice since these tools bring no or scarce support to check the results and correct for errors manually.”</p>
      <p> BigStitcher provides user friendly methods for manual &amp; interactive alignment (3D translation): 
<ext-link ext-link-type="uri" xlink:href="https://imagej.net/BigStitcher_manual_translation">https://imagej.net/BigStitcher_manual_translation</ext-link>
</p>
      <p> We were aware of this feature but, as far as we can tell, tiles are first automatically laid down to a regular grid (with fixed overlap), and then only individual tiles (or whole groups) can be interactively moved. This feature is certainly useful to coarsely set the initial positions of the tiles but not so much to finely adjust the mosaic (that would ultimately require to finely move tiles on a tile by tile basis). In turn, thanks to the predefined physical correction models, as few as two pairs of tiles need to be manually adjusted in MosaicExplorerJ to stitch a whole mosaic (with no further processing). We tried to reflect this more accurately in this paragraph and in Extended Data 
<bold>Table S2</bold>.</p>
      <p> 3) “Finally, none of these solutions handles both dual-side illumination and dual-side camera detection, two useful lightsheet microscopy”</p>
      <p> BigStitcher supports dual-side illumination and dual-side camera detection (e.g. Supplementary Figure 17)</p>
      <p> We apologize for this plainly wrong statement (we did not know that BigStitcher supported dual-sided cameras as the option is not listed in the image loader). We modified the text to exclude BigStitcher from the set of software not supporting the combination of these two modalities and we reflected these features in details in Extended Data
<bold> S2 </bold>and Extended Data 
<bold>Table S2</bold>.</p>
      <p> 4) S2-Comparison with BigStitcher:</p>
      <p> 3D TIFF tiles can be natively used through virtual loading, live display in BDV even. HDF5 conversion is optional (yet very useful)</p>
      <p> 2D TIFF slices are also supported, but it's a quite hidden feature</p>
      <p> Extended Data 
<bold>Table S2</bold> has been updated to reflect this.</p>
      <p> BigStitcher supports Dual-camera support</p>
      <p> Extended Data 
<bold>Table S2</bold> has been updated to reflect this.</p>
      <p> Physical model constrained grid alignment is also possible, see link above, even interactive &amp; manual</p>
      <p> For the mosaic stitching part only (excluding cameras registration), MosaicExplorerJ physical correction models include camera tilt (XY translations), lighshsheet tilt (linearly increasing Z translations) and motor axis axial wobble (XY separable Z translations). BigStitcher global tile layout only supports a regular grid with fixed overlap (not accounting for previously mentioned effects). In our view, this is useful to coarsely set the starting positions of the tiles prior to optimization but it is really practical to finely adjust the positions of the tiles of large mosaics with no further processing. We tried to reflect this more accurately in the text and in Extended Data
<bold> S2</bold>.</p>
      <p> Automatic color highlighting of tiles mismatch can be done in BigStitcher</p>
      <p> Extended Data 
<bold>Table S2</bold> has been updated to reflect this. MosaicExplorerJ supports alternate red/green (and cyan/yellow) while BigStitcher supports random colors.</p>
      <p> BigStitcher additionally supports per-tile intensity correction using Affine 1D models</p>
      <p> Extended Data 
<bold>Table S2</bold> has been updated to reflect this.</p>
    </body>
  </sub-article>
</sub-article>
