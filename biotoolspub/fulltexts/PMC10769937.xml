<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Int J Comput Assist Radiol Surg</journal-id>
    <journal-id journal-id-type="iso-abbrev">Int J Comput Assist Radiol Surg</journal-id>
    <journal-title-group>
      <journal-title>International Journal of Computer Assisted Radiology and Surgery</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1861-6410</issn>
    <issn pub-type="epub">1861-6429</issn>
    <publisher>
      <publisher-name>Springer International Publishing</publisher-name>
      <publisher-loc>Cham</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">10769937</article-id>
    <article-id pub-id-type="pmid">37328716</article-id>
    <article-id pub-id-type="publisher-id">2960</article-id>
    <article-id pub-id-type="doi">10.1007/s11548-023-02960-9</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Original Article</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Non-rigid point cloud registration for middle ear diagnostics with endoscopic optical coherence tomography</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid">http://orcid.org/0009-0002-4280-3672</contrib-id>
        <name>
          <surname>Liu</surname>
          <given-names>Peng</given-names>
        </name>
        <address>
          <email>peng.liu@nct-dresden.de</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff3">3</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Golde</surname>
          <given-names>Jonas</given-names>
        </name>
        <xref ref-type="aff" rid="Aff2">2</xref>
        <xref ref-type="aff" rid="Aff3">3</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Morgenstern</surname>
          <given-names>Joseph</given-names>
        </name>
        <xref ref-type="aff" rid="Aff3">3</xref>
        <xref ref-type="aff" rid="Aff4">4</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Bodenstedt</surname>
          <given-names>Sebastian</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Li</surname>
          <given-names>Chenpan</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Hu</surname>
          <given-names>Yujia</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Chen</surname>
          <given-names>Zhaoyu</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Koch</surname>
          <given-names>Edmund</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Neudert</surname>
          <given-names>Marcus</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff4">4</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Speidel</surname>
          <given-names>Stefanie</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff3">3</xref>
      </contrib>
      <aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/01txwsw02</institution-id><institution-id institution-id-type="GRID">grid.461742.2</institution-id><institution-id institution-id-type="ISNI">0000 0000 8855 0365</institution-id><institution>Translational Surgical Oncology, </institution><institution>National Center for Tumor Diseases, </institution></institution-wrap>Dresden, 01307 Germany </aff>
      <aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/042aqky30</institution-id><institution-id institution-id-type="GRID">grid.4488.0</institution-id><institution-id institution-id-type="ISNI">0000 0001 2111 7257</institution-id><institution>Clinical Sensoring and Monitoring, </institution><institution>TU Dresden, </institution></institution-wrap>Dresden, 01307 Germany </aff>
      <aff id="Aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/042aqky30</institution-id><institution-id institution-id-type="GRID">grid.4488.0</institution-id><institution-id institution-id-type="ISNI">0000 0001 2111 7257</institution-id><institution>Else Kröner Fresenius Center, </institution><institution>TU Dresden, </institution></institution-wrap>Dresden, 01307 Germany </aff>
      <aff id="Aff4"><label>4</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/042aqky30</institution-id><institution-id institution-id-type="GRID">grid.4488.0</institution-id><institution-id institution-id-type="ISNI">0000 0001 2111 7257</institution-id><institution>Ear Research Center Dresden, </institution><institution>TU Dresden, </institution></institution-wrap>Dresden, 01307 Germany </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>17</day>
      <month>6</month>
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>17</day>
      <month>6</month>
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="ppub">
      <year>2024</year>
    </pub-date>
    <volume>19</volume>
    <issue>1</issue>
    <fpage>139</fpage>
    <lpage>145</lpage>
    <history>
      <date date-type="received">
        <day>6</day>
        <month>3</month>
        <year>2023</year>
      </date>
      <date date-type="accepted">
        <day>12</day>
        <month>5</month>
        <year>2023</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2023</copyright-statement>
      <license>
        <ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>.</license-p>
      </license>
    </permissions>
    <abstract id="Abs1">
      <sec>
        <title>
          <bold>Purpose</bold>
        </title>
        <p id="Par1">Middle ear infection is the most prevalent inflammatory disease, especially among the pediatric population. Current diagnostic methods are subjective and depend on visual cues from an otoscope, which is limited for otologists to identify pathology. To address this shortcoming, endoscopic optical coherence tomography (OCT) provides both morphological and functional in vivo measurements of the middle ear. However, due to the shadow of prior structures, interpretation of OCT images is challenging and time-consuming. To facilitate fast diagnosis and measurement, improvement in the readability of OCT data is achieved by merging morphological knowledge from ex vivo middle ear models with OCT volumetric data, so that OCT applications can be further promoted in daily clinical settings.</p>
      </sec>
      <sec>
        <title>
          <bold>Methods</bold>
        </title>
        <p id="Par2">We propose C2P-Net: a two-staged non-rigid registration pipeline for complete to partial point clouds, which are sampled from ex vivo and in vivo OCT models, respectively. To overcome the lack of labeled training data, a fast and effective generation pipeline in Blender3D is designed to simulate middle ear shapes and extract in vivo noisy and partial point clouds.</p>
      </sec>
      <sec>
        <title>
          <bold>Results</bold>
        </title>
        <p id="Par3">We evaluate the performance of C2P-Net through experiments on both synthetic and real OCT datasets. The results demonstrate that C2P-Net is generalized to unseen middle ear point clouds and capable of handling realistic noise and incompleteness in synthetic and real OCT data.</p>
      </sec>
      <sec>
        <title>
          <bold>Conclusions</bold>
        </title>
        <p id="Par4">In this work, we aim to enable diagnosis of middle ear structures with the assistance of OCT images. We propose C2P-Net: a two-staged non-rigid registration pipeline for point clouds to support the interpretation of in vivo noisy and partial OCT images for the first time. Code is available at: <ext-link ext-link-type="uri" xlink:href="https://gitlab.com/nct_tso_public/c2p-net.">https://gitlab.com/nct_tso_public/c2p-net.</ext-link></p>
      </sec>
    </abstract>
    <kwd-group xml:lang="en">
      <title>Keywords</title>
      <kwd>Middle ear</kwd>
      <kwd>Optical coherence tomography</kwd>
      <kwd>Point cloud</kwd>
      <kwd>Deep learning based registration</kwd>
    </kwd-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100014843</institution-id>
            <institution>Else Kröner-Fresenius-Zentrum für Ernährungsmedizin</institution>
          </institution-wrap>
        </funding-source>
      </award-group>
    </funding-group>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>© CARS 2024</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="Sec1">
    <title>Introduction</title>
    <p id="Par5">The middle ear consists of the tympanic membrane (TM) and an air-filled chamber containing the ossicle chain (OC) that connects the TM to the inner ear. From a functional perspective, the middle ear matches the impedance from air to the fluid-filled inner ear [<xref ref-type="bibr" rid="CR1">1</xref>].</p>
    <p id="Par6">Middle ear disorders contain deformation, discontinuation of TM and OC, effusion, and cholesteatoma in the middle ear. These may occur because of middle ear infection (e.g., acute otitis media (AOM), chronic otitis media (COM), otitis media with effusion (OME)) and trauma [<xref ref-type="bibr" rid="CR2">2</xref>, <xref ref-type="bibr" rid="CR3">3</xref>]. Most commonly, serious and chronic middle ear disorder may lead to conductive hearing loss and inner ear disorder [<xref ref-type="bibr" rid="CR4">4</xref>]. Current middle ear diagnostics methods or tools cover only aspects of the pathology and cannot determine the origin and site of transmission loss, e.g., otoscopy, audiometry, tympanometry, etc.<fig id="Fig1"><label>Fig. 1</label><caption><p>Overview of data samples. In <bold>a</bold>, I is the ex vivo template point cloud reconstructed from <inline-formula id="IEq1"><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mu $$\end{document}</tex-math><mml:math id="M2"><mml:mi>μ</mml:mi></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq1.gif"/></alternatives></inline-formula>CT scans on the left. II is the segmented middle ear model, and each color stands for one structure. III shows the model with sparse labels. Accordingly, I, II and III in <bold>b</bold> present in vivo OCT point cloud, segmented OCT model and labels. The simulation pipeline on the top left takes a complete ex vivo ear point cloud, performs non-rigid and rigid simulation, and produces synthetic partial and noisy in vivo point cloud shown in <bold>c</bold></p></caption><graphic xlink:href="11548_2023_2960_Fig1_HTML" id="MO1"/></fig></p>
    <p id="Par7">As an innovative image technology, endoscopic OCT enables the examination of both the morphology and function of the middle ear in vivo by the non-invasive acquisition of depth-resolved and high-resolution images [<xref ref-type="bibr" rid="CR5">5</xref>–<xref ref-type="bibr" rid="CR7">7</xref>]. Nevertheless, multiple sources of noise, e.g., the shadow of preceding structures, reduce the quality of the target structures further away from the endoscopic probe, e.g., ossicles. Therefore, the reconstructed 3D models from the OCT volumetric data are usually noisy and difficult to interpret, especially the identification of the deeper middle ear structures such as incus and stapes (see Fig. <xref rid="Fig1" ref-type="fig">1</xref>).</p>
    <p id="Par8">Our aim is to improve the interpretation of the OCT volumetric data by merging the ex vivo middle ear model reconstructed from micro-Computed Tomography (<inline-formula id="IEq2"><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mu $$\end{document}</tex-math><mml:math id="M4"><mml:mi>μ</mml:mi></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq2.gif"/></alternatives></inline-formula>CT) scan of isolated temporal bones and the in vivo OCT model. Note that a single <inline-formula id="IEq3"><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mu $$\end{document}</tex-math><mml:math id="M6"><mml:mi>μ</mml:mi></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq3.gif"/></alternatives></inline-formula>CT model was used as a template and fitted to all patient-specific OCT scans. We first convert all ex and in vivo middle ear data to point cloud representations for ease of flexible manipulation of middle ear shapes. Nevertheless, finding one-to-one correspondence between such a point cloud pair is still challenging due to the noise and incompleteness of the OCT model, and the difference between the patient data and the template <inline-formula id="IEq4"><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mu $$\end{document}</tex-math><mml:math id="M8"><mml:mi>μ</mml:mi></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq4.gif"/></alternatives></inline-formula>CT data. To tackle these issues, we first employ a neural network that searches the sparse correspondences for the source and target points, then a pyramid deformation algorithm to fit the points in a non-rigid fashion based on the predicted correspondences. The neural network is trained on randomly generated synthetic shape variants of the middle ear that contain random noise and only partial points. This enables the generalization of the neural network to new patient data as well as the adaption to noise and outliers The main contributions of this work are listed as follows: <list list-type="order"><list-item><p id="Par9">A generation pipeline in Blender3D that simulates synthetic shape variants from a complete ex vivo middle ear model, and simulates noisy and partial point clouds comparable to in vivo data.</p></list-item><list-item><p id="Par10">C2P-Net: a two-staged non-rigid registration pipeline for point clouds. It demonstrates that C2P-Net registers the complete point cloud template to partial point clouds of the middle ear effectively and robustly.</p></list-item></list></p>
  </sec>
  <sec id="Sec2">
    <title>Related work</title>
    <p id="Par11">In this section, we review methods that analyze 3D point clouds and solve registration problems. Learning the geometry of 3D point clouds is the foundation of diverse 3D applications, but is also a challenging task due to the irregularity and asymmetry of point clouds. Recently, approaches that focus on learning point features with neural networks have been widely investigated to overcome such issues. One category of methods is to project the point cloud to a regular representation, e.g., voxel grids [<xref ref-type="bibr" rid="CR8">8</xref>], 2D images from multi-views [<xref ref-type="bibr" rid="CR9">9</xref>, <xref ref-type="bibr" rid="CR10">10</xref>], or combined [<xref ref-type="bibr" rid="CR11">11</xref>] that 2/3D convolutional operations can be performed on top of these intermediate data in Euclidean space. Apart from these, PointNet [<xref ref-type="bibr" rid="CR12">12</xref>] leverages multilayer perceptron (MLP) to obtain pointwise features and a max-pool to aggregate global features but without local information. This drawback is alleviated by PointNet++ [<xref ref-type="bibr" rid="CR13">13</xref>], which uses PointNet to aggregate local features in a multi-scale structure. In addition, various explicit convolution kernels are applied directly on the point clouds to extract encodings [<xref ref-type="bibr" rid="CR14">14</xref>–<xref ref-type="bibr" rid="CR16">16</xref>] in which point features are extracted based on the kernel weights.</p>
    <p id="Par12">Conventional methods solve the point cloud registration task as an optimization problem of transformation parameters. Iterative Closest Point (ICP) [<xref ref-type="bibr" rid="CR17">17</xref>] iteratively calculates a rigid transformation matrix based on updated correspondence set from a last iteration, Non-rigid Iterative Closest Point (NICP) [<xref ref-type="bibr" rid="CR18">18</xref>] achieves non-rigid registration by optimizing an energy function including local regularization and stiffness. Coherent Point Drift (CPD) maximizes the probability of Gaussian Mixture Model (GMM) by moving coherent GMM centroids from the two point clouds. Recently, deep learning-based methods using the aforementioned point cloud encoding techniques have been widely investigated [<xref ref-type="bibr" rid="CR19">19</xref>–<xref ref-type="bibr" rid="CR22">22</xref>]. PointNetLK [<xref ref-type="bibr" rid="CR19">19</xref>] extracts semantic point cloud features using an MLP, then performs rigid alignment using the Lucas and Kanade algorithm [<xref ref-type="bibr" rid="CR23">23</xref>].</p>
    <p id="Par13">RegTR [<xref ref-type="bibr" rid="CR20">20</xref>] and NgeNet [<xref ref-type="bibr" rid="CR21">21</xref>] employ KPConv [<xref ref-type="bibr" rid="CR14">14</xref>] to extract both global and local features from the source and target point clouds. Following this, attention mechanisms are introduced to enable the communication of the extracted features and estimate a global transformation from the predicted correspondences of the MLPs.</p>
    <p id="Par14">In contrast to this direct way, NDP [<xref ref-type="bibr" rid="CR22">22</xref>] decomposes the global transformation into sub-motions which are iteratively refined using MLPs at each pyramid level. Inspired by this recent work regarding point cloud analysis and registration, we adopted NgeNet [<xref ref-type="bibr" rid="CR21">21</xref>] and NDP [<xref ref-type="bibr" rid="CR22">22</xref>] as the main components to construct our registration pipeline.</p>
  </sec>
  <sec id="Sec3">
    <title>Methods</title>
    <p id="Par15">The non-rigid registration of the ex and in vivo middle ear point clouds (see Fig. <xref rid="Fig1" ref-type="fig">1</xref>) using neural networks is realized in a supervised learning fashion. Due to lack of real OCT data with ground truth, and the difficulties of finding one-to-one correspondences between the general and ex vivo model and the noisy and partial in vivo model, we generated synthetic in vivo middle ear point clouds based on the ex vivo <inline-formula id="IEq5"><alternatives><tex-math id="M9">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mu $$\end{document}</tex-math><mml:math id="M10"><mml:mi>μ</mml:mi></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq5.gif"/></alternatives></inline-formula>CT model using a two-step simulation pipeline. For point cloud registration, we propose C2P-Net, which is a two-stage registration method. We first train a neural network on the synthetic samples to explore the correspondence along with an initial rigid transformation matrix, then based on this, a hierarchical algorithm is performed to estimate the non-rigid deformation.</p>
    <sec id="Sec4">
      <title>Synthetic data generation</title>
      <p id="Par16">We start with a complete middle ear model <inline-formula id="IEq6"><alternatives><tex-math id="M11">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$M_{\mu {CT}}$$\end{document}</tex-math><mml:math id="M12"><mml:msub><mml:mi>M</mml:mi><mml:mrow><mml:mi>μ</mml:mi><mml:mrow><mml:mi mathvariant="italic">CT</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq6.gif"/></alternatives></inline-formula> reconstructed from <inline-formula id="IEq7"><alternatives><tex-math id="M13">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mu $$\end{document}</tex-math><mml:math id="M14"><mml:mi>μ</mml:mi></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq7.gif"/></alternatives></inline-formula>CT volume as basis for the simulation in Blender3D. The non-rigid simulation is performed with the assistance of lattice modifiers attached to each structure with reasonable resolution. The lattice vertices are assigned to various groups according to length, thickness, and width of the global and local shape of a structure. By transforming and rotating various vertex groups with random parameters with boundary conditions, a random shape of a structure can be generated, e.g., a relatively shorter malleus with a longer lateral process. The non-rigid simulation step is formulated as <inline-formula id="IEq8"><alternatives><tex-math id="M15">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\tilde{T}}_{nr}=\textrm{S}_{nr}(T, p_{nr})$$\end{document}</tex-math><mml:math id="M16"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>T</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mrow><mml:mi mathvariant="italic">nr</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mtext>S</mml:mtext><mml:mrow><mml:mi mathvariant="italic">nr</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi mathvariant="italic">nr</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq8.gif"/></alternatives></inline-formula>, where <italic>T</italic> is the template middle ear, <inline-formula id="IEq9"><alternatives><tex-math id="M17">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$p_{nr}$$\end{document}</tex-math><mml:math id="M18"><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi mathvariant="italic">nr</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq9.gif"/></alternatives></inline-formula> are the input parameters, and <inline-formula id="IEq10"><alternatives><tex-math id="M19">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\tilde{T}_{nr}$$\end{document}</tex-math><mml:math id="M20"><mml:msub><mml:mover accent="true"><mml:mi>T</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mrow><mml:mi mathvariant="italic">nr</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq10.gif"/></alternatives></inline-formula> is the simulated non-rigid shape variants of <italic>T</italic>. Next, armature modifiers are attached to each structure and connected in an end-to-end fashion at the articulations. Then, rigid simulation is accomplished by transforming and rotating the armature bones. We denote the rigid simulation as <inline-formula id="IEq11"><alternatives><tex-math id="M21">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$S_r$$\end{document}</tex-math><mml:math id="M22"><mml:msub><mml:mi>S</mml:mi><mml:mi>r</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq11.gif"/></alternatives></inline-formula>. Thus, a random shape variant of the middle ear <inline-formula id="IEq12"><alternatives><tex-math id="M23">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\tilde{T}$$\end{document}</tex-math><mml:math id="M24"><mml:mover accent="true"><mml:mi>T</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq12.gif"/></alternatives></inline-formula> can be obtained which is considered as the in vivo ear model of a new patient: <inline-formula id="IEq13"><alternatives><tex-math id="M25">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\tilde{T}=\textrm{S}_{r}(\tilde{T}_{nr}, p_{r})$$\end{document}</tex-math><mml:math id="M26"><mml:mrow><mml:mover accent="true"><mml:mi>T</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:msub><mml:mtext>S</mml:mtext><mml:mi>r</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>T</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mrow><mml:mi mathvariant="italic">nr</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mi>r</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq13.gif"/></alternatives></inline-formula>.</p>
      <p id="Par17">In practice, the in vivo OCT model is usually noisy and only partially visible, which limits the registration methods in finding accurate and robust correspondences. To simulate the real data, we extract random partial patches for each structure of the shape variant <inline-formula id="IEq14"><alternatives><tex-math id="M27">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\tilde{T}$$\end{document}</tex-math><mml:math id="M28"><mml:mover accent="true"><mml:mi>T</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq14.gif"/></alternatives></inline-formula> by a combined probability, which is calculated as the distance of each vertex to the support point of each structure and random Gaussian noise. Additionally, for the sake of simulating incomplete posterior structure, e.g., stapes, caused by the occlusion and shadow from the anterior structures, e.g., ear canal wall, we determine the number of points of the posterior structures by the distance to the external ear and a random factor. Furthermore, uniform random displacements are applied to the vertices to generate the final noisy and partial in vivo point cloud <inline-formula id="IEq15"><alternatives><tex-math id="M29">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$P_{inv}$$\end{document}</tex-math><mml:math id="M30"><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi mathvariant="italic">inv</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq15.gif"/></alternatives></inline-formula> (see Fig. <xref rid="Fig1" ref-type="fig">1</xref>).<fig id="Fig2"><label>Fig. 2</label><caption><p>Schematic architecture of C2P-Net. The input of the pipeline is the ex vivo (blue) and in vivo (orange) point cloud. To explore the correspondence between the two inputs, NgeNet is trained on synthetic samples to extract the features for each point at different levels. These are integrated by a voting algorithm. A feature matching routine is performed to obtain the sparse correspondence set as well as a rigid transformation matrix. On top of the previous outputs, NDP maps the input point clouds to sinusoidal space and decomposes the global non-rigid deformation at each pyramid level into sub-motions. With the increase in sinusoidal frequency, the non-rigid deformation of each point is continuously refined at each level. The registered point cloud is shown on the right side</p></caption><graphic xlink:href="11548_2023_2960_Fig2_HTML" id="MO2"/></fig></p>
    </sec>
    <sec id="Sec5">
      <title>C2P-Net</title>
      <p id="Par18">We delineate the architecture of C2P-Net in Fig. <xref rid="Fig2" ref-type="fig">2</xref>. It consists of two components dedicated to two stages: initial rigid registration and pyramid non-rigid registration. Given an ex vivo point cloud as a template extracted from a <inline-formula id="IEq16"><alternatives><tex-math id="M31">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mu $$\end{document}</tex-math><mml:math id="M32"><mml:mi>μ</mml:mi></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq16.gif"/></alternatives></inline-formula>CT model: <inline-formula id="IEq17"><alternatives><tex-math id="M33">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$P_{exv}={\{x_i\in {{\mathcal {R}}^{3}}\}_{i=1,2,...,N}}$$\end{document}</tex-math><mml:math id="M34"><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi mathvariant="italic">exv</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="script">R</mml:mi></mml:mrow><mml:mn>3</mml:mn></mml:msup><mml:mo stretchy="false">}</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>,</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq17.gif"/></alternatives></inline-formula>, and a partial point cloud of the simulated in vivo shape variant: <inline-formula id="IEq18"><alternatives><tex-math id="M35">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$P_{inv}={\{y_j\in {{\mathcal {R}}^{3}}\}_{j=1,2,...,M}}$$\end{document}</tex-math><mml:math id="M36"><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi mathvariant="italic">inv</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="script">R</mml:mi></mml:mrow><mml:mn>3</mml:mn></mml:msup><mml:mo stretchy="false">}</mml:mo></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>,</mml:mo><mml:mi>M</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq18.gif"/></alternatives></inline-formula>, we adopted the Neighborhood-aware Geometric Encoding Network (NgeNet) [<xref ref-type="bibr" rid="CR21">21</xref>] to solve the initial rigid registration task. This stage is formulated as:<disp-formula id="Equ1"><label>1</label><alternatives><tex-math id="M37">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} \tau ,\sigma =\textrm{NgeNet}(P_{exv}, P_{inv})\quad where\ (u, v) \in \sigma \end{aligned}$$\end{document}</tex-math><mml:math id="M38" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>τ</mml:mi><mml:mo>,</mml:mo><mml:mi>σ</mml:mi><mml:mo>=</mml:mo><mml:mtext>NgeNet</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi mathvariant="italic">exv</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi mathvariant="italic">inv</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mspace width="1em"/><mml:mi>w</mml:mi><mml:mi>h</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mspace width="4pt"/><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>∈</mml:mo><mml:mi>σ</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="11548_2023_2960_Article_Equ1.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq19"><alternatives><tex-math id="M39">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\tau \in {SE(3)} $$\end{document}</tex-math><mml:math id="M40"><mml:mrow><mml:mi>τ</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mi>S</mml:mi><mml:mi>E</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>3</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq19.gif"/></alternatives></inline-formula> is the rigid transformation matrix which aligns <inline-formula id="IEq20"><alternatives><tex-math id="M41">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$P_{exv}$$\end{document}</tex-math><mml:math id="M42"><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi mathvariant="italic">exv</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq20.gif"/></alternatives></inline-formula> with <inline-formula id="IEq21"><alternatives><tex-math id="M43">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$P_{inv}$$\end{document}</tex-math><mml:math id="M44"><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi mathvariant="italic">inv</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq21.gif"/></alternatives></inline-formula>, and <inline-formula id="IEq22"><alternatives><tex-math id="M45">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$(u, v) \in \sigma $$\end{document}</tex-math><mml:math id="M46"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>∈</mml:mo><mml:mi>σ</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq22.gif"/></alternatives></inline-formula> is the sparse correspondence set where <italic>u</italic> and <italic>v</italic> are indices for points in <inline-formula id="IEq23"><alternatives><tex-math id="M47">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$P_{exv}$$\end{document}</tex-math><mml:math id="M48"><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi mathvariant="italic">exv</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq23.gif"/></alternatives></inline-formula> and <inline-formula id="IEq24"><alternatives><tex-math id="M49">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$P_{inv}$$\end{document}</tex-math><mml:math id="M50"><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi mathvariant="italic">inv</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq24.gif"/></alternatives></inline-formula>. Due to the multi-scale structure and a voting mechanism integrating features from different resolutions, NgeNet handles noise well and predicts correspondence robustly.</p>
      <p id="Par19">Based on the previous predicted correspondence set and the rigidly aligned source and target point clouds, we employ the Neural Deformation Pyramid (NDP) [<xref ref-type="bibr" rid="CR22">22</xref>] to predict the non-rigid deformation of the given point cloud pair. NDP defines the non-rigid registration problem as a hierarchical motion decomposition problem. At each pyramid level, the input points from last level are mapped to sinusoidal encodings with different frequencies: <inline-formula id="IEq25"><alternatives><tex-math id="M51">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\Gamma (p^{k-1})=(\textrm{sin}(2^{k+k_0}p^{k-1}), \textrm{cos}(2^{k+k_0}p^{k-1}))$$\end{document}</tex-math><mml:math id="M52"><mml:mrow><mml:mi mathvariant="normal">Γ</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>p</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mtext>sin</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mn>2</mml:mn><mml:mrow><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:msup><mml:msup><mml:mi>p</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mtext>cos</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mn>2</mml:mn><mml:mrow><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:msup><mml:msup><mml:mi>p</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq25.gif"/></alternatives></inline-formula>, <italic>k</italic> is the current level number, <inline-formula id="IEq26"><alternatives><tex-math id="M53">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$k_0$$\end{document}</tex-math><mml:math id="M54"><mml:msub><mml:mi>k</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq26.gif"/></alternatives></inline-formula> controls the initial frequency and <inline-formula id="IEq27"><alternatives><tex-math id="M55">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$p^{k-1}$$\end{document}</tex-math><mml:math id="M56"><mml:msup><mml:mi>p</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq27.gif"/></alternatives></inline-formula> is an output point from the last level. Lower frequencies at shallower levels represent rigid sub-motion, while higher frequencies at deep levels emphasize non-rigid deformations. In this way, a sequence of sub-motions is estimated from rigid to non-rigid, and the final displacement field is the combination of such a sequence. Formally, we denote the stage as:<disp-formula id="Equ2"><label>2</label><alternatives><tex-math id="M57">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} \phi _{est}=\textrm{NDP}_{n,m}({\tilde{P}}_{exv}, P_{inv}, \sigma ) \end{aligned}$$\end{document}</tex-math><mml:math id="M58" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi mathvariant="italic">est</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mtext>NDP</mml:mtext><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>P</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mrow><mml:mi mathvariant="italic">exv</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi mathvariant="italic">inv</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>σ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="11548_2023_2960_Article_Equ2.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq28"><alternatives><tex-math id="M59">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\tilde{P}}_{exv}$$\end{document}</tex-math><mml:math id="M60"><mml:msub><mml:mover accent="true"><mml:mi>P</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mrow><mml:mi mathvariant="italic">exv</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq28.gif"/></alternatives></inline-formula> is the source point cloud <inline-formula id="IEq29"><alternatives><tex-math id="M61">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${P}_{exv}$$\end{document}</tex-math><mml:math id="M62"><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi mathvariant="italic">exv</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq29.gif"/></alternatives></inline-formula> transformed by <inline-formula id="IEq30"><alternatives><tex-math id="M63">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\tau $$\end{document}</tex-math><mml:math id="M64"><mml:mi>τ</mml:mi></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq30.gif"/></alternatives></inline-formula>, <italic>n</italic> is the number of pyramid layers of the NDP neural network, <italic>m</italic> is the maximal iteration within a single pyramid layer, and <inline-formula id="IEq31"><alternatives><tex-math id="M65">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\phi _{est}$$\end{document}</tex-math><mml:math id="M66"><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi mathvariant="italic">est</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq31.gif"/></alternatives></inline-formula> is the predicted displacement field describing how each point should move to the target. Combined losses are calculated at each iteration, including correspondence loss and regularization loss, and back-propagated to update the weights of each MLP. Of which, the correspondence loss <inline-formula id="IEq32"><alternatives><tex-math id="M67">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$L_{CD}$$\end{document}</tex-math><mml:math id="M68"><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi mathvariant="italic">CD</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq32.gif"/></alternatives></inline-formula> is defined as the Chamfer distance (<xref rid="Equ3" ref-type="disp-formula">3</xref>) between <inline-formula id="IEq33"><alternatives><tex-math id="M69">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{\tilde{P}}}_{exv}$$\end{document}</tex-math><mml:math id="M70"><mml:msub><mml:mover accent="true"><mml:mi>P</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mrow><mml:mi mathvariant="italic">exv</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq33.gif"/></alternatives></inline-formula> which is masked by the correspondence <inline-formula id="IEq34"><alternatives><tex-math id="M71">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sigma $$\end{document}</tex-math><mml:math id="M72"><mml:mi>σ</mml:mi></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq34.gif"/></alternatives></inline-formula> and <inline-formula id="IEq35"><alternatives><tex-math id="M73">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$P_{inv}$$\end{document}</tex-math><mml:math id="M74"><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi mathvariant="italic">inv</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq35.gif"/></alternatives></inline-formula>.<disp-formula id="Equ3"><label>3</label><alternatives><tex-math id="M75">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned}{} &amp; {} \textrm{CD}(A,B) {=}\frac{1}{|{A}|}\sum _{x_i\in {A}}\min _{y_j\in {B}}|{x_i{-}y_j}|{+}\frac{1}{|{B}|}\sum _{y_j\in {B}}\min _{x_i\in {A}}|{x_i{-}y_j}|\nonumber \\ \end{aligned}$$\end{document}</tex-math><mml:math id="M76" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow/></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mrow/><mml:mtext>CD</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>B</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mi>A</mml:mi><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mfrac><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:mi>A</mml:mi></mml:mrow></mml:munder><mml:munder><mml:mo movablelimits="true">min</mml:mo><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:mi>B</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mo>+</mml:mo></mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mi>B</mml:mi><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mfrac><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:mi>B</mml:mi></mml:mrow></mml:munder><mml:munder><mml:mo movablelimits="true">min</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:mi>A</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right"><mml:mrow/></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="11548_2023_2960_Article_Equ3.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ4"><label>4</label><alternatives><tex-math id="M77">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned}{} &amp; {} L_\textrm{CD} =\textrm{CD}({{\tilde{P}}}_{exv}^{\sigma }, P_{inv}) \end{aligned}$$\end{document}</tex-math><mml:math id="M78" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow/></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mrow/><mml:msub><mml:mi>L</mml:mi><mml:mtext>CD</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mtext>CD</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mover accent="true"><mml:mi>P</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mrow><mml:mi mathvariant="italic">exv</mml:mi></mml:mrow><mml:mi>σ</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi mathvariant="italic">inv</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="11548_2023_2960_Article_Equ4.gif" position="anchor"/></alternatives></disp-formula><inline-formula id="IEq36"><alternatives><tex-math id="M79">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{\tilde{P}}}_{exv}^{\sigma }=\{{{\tilde{P}}}_{exv}[u]|\exists {v}:(u,v)\in \sigma \}$$\end{document}</tex-math><mml:math id="M80"><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>P</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mrow><mml:mi mathvariant="italic">exv</mml:mi></mml:mrow><mml:mi>σ</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>P</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mrow><mml:mi mathvariant="italic">exv</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mo>∃</mml:mo><mml:mi>v</mml:mi><mml:mo>:</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>∈</mml:mo><mml:mi>σ</mml:mi><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:mrow></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq36.gif"/></alternatives></inline-formula> are the masked ex vivo points that have correspondence in the target in vivo point cloud.</p>
    </sec>
  </sec>
  <sec id="Sec6">
    <title>Evaluation</title>
    <p id="Par20">C2P-Net predicts a displacement field to fit the ex vivo point cloud template to the target in vivo point cloud which is noisy and partial. At training time, C2P-Net employs an Adam optimizer and ExpLR scheduler and uses supervised learning to learn on a synthetic dataset with 20,000 in vivo shape variants of the middle ear. During inference, it takes around 3.5 s for C2P-Net to react to a new in vivo shape on RTX 2070 Super. Since the neural network is trained on synthetic data, it is crucial to investigate the generalization of the neural networks on unseen samples as well as the performance on real OCT data. Thus, we conduct two experiments on synthetic data and real OCT data with various metrics: mean displacement error (<xref rid="Equ5" ref-type="disp-formula">5</xref>), Chamfer distance (<xref rid="Equ3" ref-type="disp-formula">3</xref>), and landmarks error (<xref rid="Equ6" ref-type="disp-formula">6</xref>). Furthermore, we compare our results with other popular non-rigid registration methods, e.g., Non-rigid ICP (NICP) and Coherent Point Drift (CPD).<disp-formula id="Equ5"><label>5</label><alternatives><tex-math id="M81">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} M_\textrm{MDE}=\frac{1}{N}\sum _{i}^{N}\Vert {\phi _{est}-\phi _{gt}}\Vert \end{aligned}$$\end{document}</tex-math><mml:math id="M82" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>M</mml:mi><mml:mtext>MDE</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:mrow><mml:mo stretchy="false">‖</mml:mo><mml:mrow><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi mathvariant="italic">est</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi mathvariant="italic">gt</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">‖</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="11548_2023_2960_Article_Equ5.gif" position="anchor"/></alternatives></disp-formula><italic>N</italic> is the size of the test dataset, <inline-formula id="IEq37"><alternatives><tex-math id="M83">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\phi _{est}$$\end{document}</tex-math><mml:math id="M84"><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi mathvariant="italic">est</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq37.gif"/></alternatives></inline-formula> is the estimated displacement field of a sample, and <inline-formula id="IEq38"><alternatives><tex-math id="M85">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\phi _{gt}$$\end{document}</tex-math><mml:math id="M86"><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi mathvariant="italic">gt</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq38.gif"/></alternatives></inline-formula> is the corresponding ground truth.<fig id="Fig3"><label>Fig. 3</label><caption><p><bold>a</bold> shows the relation between the MDE of synthetic samples and the visible points ratio, which is calculated as the ratio between the point number of a target point cloud to the corresponding ground truth point cloud: <inline-formula id="IEq39"><alternatives><tex-math id="M87">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$|{P_{inv} }|{ /} |{\tilde{T}}|{} $$\end{document}</tex-math><mml:math id="M88"><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi mathvariant="italic">inv</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mo stretchy="false">/</mml:mo><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mover accent="true"><mml:mi>T</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mrow/></mml:mrow></mml:mrow></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq39.gif"/></alternatives></inline-formula>. The decreasing trend shows that with more points available in the target in vivo point clouds, the neural network tends to predict better deformation. <bold>b</bold> Depicts the MDE to the initial rigid registration error which is produced by the NgeNet. The better the initial rigid registration and correspondence set predicted by NgeNet, the lower the global non-rigid registration error from NDP becomes</p></caption><graphic xlink:href="11548_2023_2960_Fig3_HTML" id="MO8"/></fig></p>
    <p id="Par21"><bold>In Silico</bold> A synthetic dataset is generated using the pipeline described in “Synthetic data generation” with the same boundary conditions, and the target shape variants are unseen to the neural network during training. For each target shape, we estimated the displacement field for the identical template point cloud using C2P-Net trained on 20,000 samples. The mean target displacement field for the synthetic dataset is 1.54 mm. Figure <xref rid="Fig3" ref-type="fig">3</xref>a illustrates that the neural network tends to predict the deformation of the ex vivo point cloud with higher accuracy if it obtains more information about the target in vivo OCT point cloud. With few exceptions, Fig. <xref rid="Fig3" ref-type="fig">3</xref>b shows when the initial registration error made by NgeNet is low, the final global non-rigid displacement field from NDP tends to be small.<fig id="Fig4"><label>Fig. 4</label><caption><p>Registration results of baseline models and C2P-Net on synthetic (SYN) and real OCT samples (REAL). Blue point clouds are the deformed ex vivo ear models, i.e., the shape template, calculated by all the investigated methods. The orange point clouds stand for the registration target, i.e., in vivo point clouds. From the visualization, we can see baseline non-rigid methods, NICP and CPD, tend to squeeze the points from the ex vivo template largely to match the target point clouds, since they only focus on the position of local points, while C2P-Net retains the global geometry of the middle ear due to the learned correspondence knowledge between the ex and in vivo point clouds</p></caption><graphic xlink:href="11548_2023_2960_Fig4_HTML" id="MO9"/></fig></p>
    <p id="Par22"><bold>In Vivo</bold> A real OCT dataset with 9 samples of the human middle ear was collected with a handheld OCT imaging system [<xref ref-type="bibr" rid="CR5">5</xref>] and segmented manually by surgeons within 3D Slicer along with a set of sparse landmarks for each structure of a sample (see Fig. <xref rid="Fig1" ref-type="fig">1</xref>). Since there is no ground truth correspondence available for the source and target point clouds to calculate <inline-formula id="IEq40"><alternatives><tex-math id="M89">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$M_\textrm{MDE}$$\end{document}</tex-math><mml:math id="M90"><mml:msub><mml:mi>M</mml:mi><mml:mtext>MDE</mml:mtext></mml:msub></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq40.gif"/></alternatives></inline-formula>, we introduce another metric based on the sparse landmarks:<disp-formula id="Equ6"><label>6</label><alternatives><tex-math id="M91">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} M_\textrm{L}=\frac{1}{|{L_{exv}}|}\sum _{l_{i,k}\in {L_{exv}}}\mathop {\textrm{min}}\limits _{l_{j,k}\in {L_{inv}}}\Vert {l_{i,k}-l_{j,k}}\Vert \,_{k=1,2,...,K} \end{aligned}$$\end{document}</tex-math><mml:math id="M92" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>M</mml:mi><mml:mtext>L</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi mathvariant="italic">exv</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:msub><mml:mi>l</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi mathvariant="italic">exv</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munder><mml:munder><mml:mtext>min</mml:mtext><mml:mrow><mml:msub><mml:mi>l</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi mathvariant="italic">inv</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munder><mml:mrow><mml:mo stretchy="false">‖</mml:mo><mml:mrow><mml:msub><mml:mi>l</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mi>l</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">‖</mml:mo></mml:mrow><mml:msub><mml:mspace width="0.166667em"/><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>,</mml:mo><mml:mi>K</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="11548_2023_2960_Article_Equ6.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq41"><alternatives><tex-math id="M93">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$L_{exv}$$\end{document}</tex-math><mml:math id="M94"><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi mathvariant="italic">exv</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq41.gif"/></alternatives></inline-formula> are the landmarks on the ex vivo point cloud from <inline-formula id="IEq42"><alternatives><tex-math id="M95">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mu $$\end{document}</tex-math><mml:math id="M96"><mml:mi>μ</mml:mi></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq42.gif"/></alternatives></inline-formula>CT, which is also marked manually, <inline-formula id="IEq43"><alternatives><tex-math id="M97">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$L_{inv}$$\end{document}</tex-math><mml:math id="M98"><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi mathvariant="italic">inv</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq43.gif"/></alternatives></inline-formula> are the corresponding landmarks on the target in vivo point cloud, and the landmark points belong to <italic>K</italic> different segmentations.</p>
    <p id="Par23">Table <xref rid="Tab1" ref-type="table">1</xref> itemizes the registration results of C2P-Net and baseline models on both datasets. We can observe our registration pipeline outperforms the other methods in terms of <inline-formula id="IEq44"><alternatives><tex-math id="M99">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$M_\textrm{MDE}$$\end{document}</tex-math><mml:math id="M100"><mml:msub><mml:mi>M</mml:mi><mml:mtext>MDE</mml:mtext></mml:msub></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq44.gif"/></alternatives></inline-formula> and <inline-formula id="IEq45"><alternatives><tex-math id="M101">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$M_\textrm{L}$$\end{document}</tex-math><mml:math id="M102"><mml:msub><mml:mi>M</mml:mi><mml:mtext>L</mml:mtext></mml:msub></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq45.gif"/></alternatives></inline-formula>. However, baseline models tend to have smaller <inline-formula id="IEq46"><alternatives><tex-math id="M103">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$M_\textrm{CD}$$\end{document}</tex-math><mml:math id="M104"><mml:msub><mml:mi>M</mml:mi><mml:mtext>CD</mml:mtext></mml:msub></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq46.gif"/></alternatives></inline-formula>, which means the source point clouds are deformed largely to fit the target regardless of the anatomical geometry of the middle ear. Furthermore, this issue is demonstrated visually in Fig. <xref rid="Fig4" ref-type="fig">4</xref>, which depicts several registration results from C2P-Net and baseline models on real OCT samples. Hence, it is manifested that C2P-Net is able to register the partial target point cloud without losing the underlying geometry of source point clouds, which is the critical information clinicians want to obtain with registration. On the contrary, the baseline models only focus on the spatial position of local points regardless of the neighboring and global geometry of the middle ear template.<table-wrap id="Tab1"><label>Table 1</label><caption><p>Experiments results on synthetic data (SYN) and real OCT data (REAL), including mean displacement error (<inline-formula id="IEq47"><alternatives><tex-math id="M105">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$M_\textrm{MDE}$$\end{document}</tex-math><mml:math id="M106"><mml:msub><mml:mi>M</mml:mi><mml:mtext>MDE</mml:mtext></mml:msub></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq47.gif"/></alternatives></inline-formula>)[mm], landmarks error (<inline-formula id="IEq48"><alternatives><tex-math id="M107">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$M_\textrm{L}$$\end{document}</tex-math><mml:math id="M108"><mml:msub><mml:mi>M</mml:mi><mml:mtext>L</mml:mtext></mml:msub></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq48.gif"/></alternatives></inline-formula>)[mm] and Chamfer distance (<inline-formula id="IEq49"><alternatives><tex-math id="M109">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$M_\textrm{CD}$$\end{document}</tex-math><mml:math id="M110"><mml:msub><mml:mi>M</mml:mi><mml:mtext>CD</mml:mtext></mml:msub></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq49.gif"/></alternatives></inline-formula>)[mm]</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left"/><th align="left" colspan="3">SYN</th><th align="left" colspan="2">REAL</th></tr><tr><th align="left"/><th align="left"><inline-formula id="IEq50"><alternatives><tex-math id="M111">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$M_\textrm{MDE}\downarrow $$\end{document}</tex-math><mml:math id="M112"><mml:mrow><mml:msub><mml:mi>M</mml:mi><mml:mtext>MDE</mml:mtext></mml:msub><mml:mrow><mml:mo stretchy="false">↓</mml:mo></mml:mrow></mml:mrow></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq50.gif"/></alternatives></inline-formula></th><th align="left"><inline-formula id="IEq51"><alternatives><tex-math id="M113">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$M_\textrm{CD}\dagger $$\end{document}</tex-math><mml:math id="M114"><mml:mrow><mml:msub><mml:mi>M</mml:mi><mml:mtext>CD</mml:mtext></mml:msub><mml:mo>†</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq51.gif"/></alternatives></inline-formula></th><th align="left"><inline-formula id="IEq52"><alternatives><tex-math id="M115">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$M_\textrm{L}\downarrow $$\end{document}</tex-math><mml:math id="M116"><mml:mrow><mml:msub><mml:mi>M</mml:mi><mml:mtext>L</mml:mtext></mml:msub><mml:mrow><mml:mo stretchy="false">↓</mml:mo></mml:mrow></mml:mrow></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq52.gif"/></alternatives></inline-formula></th><th align="left"><inline-formula id="IEq53"><alternatives><tex-math id="M117">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$M_\textrm{L}\downarrow $$\end{document}</tex-math><mml:math id="M118"><mml:mrow><mml:msub><mml:mi>M</mml:mi><mml:mtext>L</mml:mtext></mml:msub><mml:mrow><mml:mo stretchy="false">↓</mml:mo></mml:mrow></mml:mrow></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq53.gif"/></alternatives></inline-formula></th><th align="left"><inline-formula id="IEq54"><alternatives><tex-math id="M119">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$M_\textrm{CD}\dagger $$\end{document}</tex-math><mml:math id="M120"><mml:mrow><mml:msub><mml:mi>M</mml:mi><mml:mtext>CD</mml:mtext></mml:msub><mml:mo>†</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq54.gif"/></alternatives></inline-formula></th></tr></thead><tbody><tr><td align="left">ICP<inline-formula id="IEq55"><alternatives><tex-math id="M121">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$^*$$\end{document}</tex-math><mml:math id="M122"><mml:msup><mml:mrow/><mml:mo>∗</mml:mo></mml:msup></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq55.gif"/></alternatives></inline-formula></td><td align="left">2.01</td><td align="left">1.85</td><td align="left">1.15</td><td align="left">4.74</td><td align="left">3.03</td></tr><tr><td align="left">NICP</td><td align="left">4.61</td><td align="left"><bold>0</bold>.<bold>22</bold></td><td align="left">0.87</td><td align="left">4.39</td><td align="left">0.68</td></tr><tr><td align="left">CPD</td><td align="left">8.79</td><td align="left">1.07</td><td align="left">0.96</td><td align="left">2.17</td><td align="left"><bold>0</bold>.<bold>059</bold></td></tr><tr><td align="left">C2P-Net (ours)</td><td align="left"><bold>0</bold>.<bold>781</bold></td><td align="left">0.582</td><td align="left"><bold>0</bold>.<bold>424</bold></td><td align="left"><bold>0</bold>.<bold>808</bold></td><td align="left">2.43</td></tr></tbody></table><table-wrap-foot><p>The bold numbers indicate the best-performing methods on each metric</p><p><inline-formula id="IEq56"><alternatives><tex-math id="M123">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$*$$\end{document}</tex-math><mml:math id="M124"><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq56.gif"/></alternatives></inline-formula> rigid registration method(s)</p><p><inline-formula id="IEq57"><alternatives><tex-math id="M125">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\dagger $$\end{document}</tex-math><mml:math id="M126"><mml:mo>†</mml:mo></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq57.gif"/></alternatives></inline-formula> baseline methods tend to fall into local minima and ignore the geometry, though the CD is lower</p></table-wrap-foot></table-wrap></p>
  </sec>
  <sec id="Sec7">
    <title>Conclusion</title>
    <p id="Par24">In this work, we propose to improve the interpretation of OCT data for surgical diagnosis by fusing the knowledge from ex vivo and general <inline-formula id="IEq58"><alternatives><tex-math id="M127">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mu $$\end{document}</tex-math><mml:math id="M128"><mml:mi>μ</mml:mi></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq58.gif"/></alternatives></inline-formula>CT data with the in vivo noisy and incomplete OCT data. To this end, we propose C2P-Net which is based on NgeNet and Neural Deformation Pyramid. It takes the ex and in vivo 3D point clouds as input and explores the sparse correspondence between the two, then aligns them in a non-rigid fashion. Due to the lack of training data, a fast and effective synthetic simulation pipeline was designed using Blender3D, which produces noisy and partial point clouds as seen in vivo based on the randomly generated shape variants of the middle ear. Our neural network was trained based on 20,000 synthetic samples, and it took around 3.5 s to predict the displacement field for a given in vivo point cloud at inference time.</p>
    <p id="Par25">To assess the performance of C2P-Net, experiments on synthetic and real OCT datasets were carried out. Since the real OCT data are noisy and incomplete, we investigated various metrics including mean displacement error, landmark error, and Chamfer distance and compared C2P-Net to the other baseline models from both statistics and geometry aspects. From Table <xref rid="Tab1" ref-type="table">1</xref> and Fig. <xref rid="Fig4" ref-type="fig">4</xref>, we can see that C2P-Net is able to deal with the partial OCT data and retain the anatomical structure during non-rigid registration, while other non-rigid methods do not understand the global geometry of the point clouds and focus only on local points.</p>
    <p id="Par26">Future work will focus on improving registration accuracy. This can be achieved by improving the simulation pipeline with realistic noise to further bridge the gap between synthetic and real data. Furthermore, the segmentation information can be employed by the network to improve the prediction of correspondences. Apart from this, inference time can be further decreased by exploring the optimal configuration of the network for the OCT samples.</p>
  </sec>
</body>
<back>
  <fn-group>
    <fn>
      <p>
        <bold>Publisher's Note</bold>
      </p>
      <p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
    </fn>
  </fn-group>
  <ack>
    <title>Acknowledgements</title>
    <p>Funded by the Else Kröner Fresenius Centre for Digital Health.</p>
  </ack>
  <notes notes-type="funding-information">
    <title>Funding Information</title>
    <p>Open Access funding enabled and organized by Projekt DEAL.</p>
  </notes>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <label>1.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zwislocki</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Normal function of the middle ear and its measurement</article-title>
        <source>Audiology</source>
        <year>1982</year>
        <volume>21</volume>
        <issue>1</issue>
        <fpage>4</fpage>
        <lpage>14</lpage>
        <pub-id pub-id-type="doi">10.3109/00206098209072723</pub-id>
        <?supplied-pmid 7055478?>
        <pub-id pub-id-type="pmid">7055478</pub-id>
      </element-citation>
    </ref>
    <ref id="CR2">
      <label>2.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Won</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Monroy</surname>
            <given-names>GL</given-names>
          </name>
          <name>
            <surname>Dsouza</surname>
            <given-names>RI</given-names>
          </name>
          <name>
            <surname>Spillman</surname>
            <given-names>DR</given-names>
          </name>
          <name>
            <surname>McJunkin</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Porter</surname>
            <given-names>RG</given-names>
          </name>
          <name>
            <surname>Shi</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Aksamitiene</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Sherwood</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Stiger</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Boppart</surname>
            <given-names>SA</given-names>
          </name>
        </person-group>
        <article-title>Handheld briefcase optical coherence tomography with real-time machine learning classifier for middle ear infections</article-title>
        <source>Biosensors</source>
        <year>2021</year>
        <volume>11</volume>
        <issue>5</issue>
        <fpage>143</fpage>
        <lpage>156</lpage>
        <pub-id pub-id-type="doi">10.3390/bios11050143</pub-id>
        <?supplied-pmid 34063695?>
        <pub-id pub-id-type="pmid">34063695</pub-id>
      </element-citation>
    </ref>
    <ref id="CR3">
      <label>3.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Won</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Porter</surname>
            <given-names>RG</given-names>
          </name>
          <name>
            <surname>Novak</surname>
            <given-names>MA</given-names>
          </name>
          <name>
            <surname>Youakim</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Sum</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Barkalifa</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Aksamitiene</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Nolan</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Shelton</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Boppart</surname>
            <given-names>SA</given-names>
          </name>
        </person-group>
        <article-title>In vivo dynamic characterization of the human tympanic membrane using pneumatic optical coherence tomography</article-title>
        <source>J Biophotonics</source>
        <year>2021</year>
        <volume>14</volume>
        <issue>4</issue>
        <fpage>1</fpage>
        <lpage>12</lpage>
        <pub-id pub-id-type="doi">10.1002/jbio.202000215</pub-id>
      </element-citation>
    </ref>
    <ref id="CR4">
      <label>4.</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Snow</surname>
            <given-names>JB</given-names>
          </name>
          <name>
            <surname>Wackym</surname>
            <given-names>PA</given-names>
          </name>
          <name>
            <surname>Ballenger</surname>
            <given-names>JJ</given-names>
          </name>
        </person-group>
        <source>Ballenger’s otorhinolaryngology: head and neck surgery</source>
        <year>2009</year>
        <publisher-loc>Hamilton, ON</publisher-loc>
        <publisher-name>BC Decker</publisher-name>
      </element-citation>
    </ref>
    <ref id="CR5">
      <label>5.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Morgenstern</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Schindler</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Kirsten</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Golde</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Bornitz</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Kemper</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Koch</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Zahnert</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Neudert</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>Endoscopic optical coherence tomography for evaluation of success of tympanoplasty</article-title>
        <source>Otol Neurotol</source>
        <year>2020</year>
        <volume>41</volume>
        <issue>7</issue>
        <fpage>901</fpage>
        <lpage>905</lpage>
        <pub-id pub-id-type="doi">10.1097/MAO.0000000000002486</pub-id>
        <pub-id pub-id-type="pmid">32310837</pub-id>
      </element-citation>
    </ref>
    <ref id="CR6">
      <label>6.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Monroy</surname>
            <given-names>GL</given-names>
          </name>
          <name>
            <surname>Won</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Dsouza</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Pande</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Hill</surname>
            <given-names>MC</given-names>
          </name>
          <name>
            <surname>Porter</surname>
            <given-names>RG</given-names>
          </name>
          <name>
            <surname>Novak</surname>
            <given-names>MA</given-names>
          </name>
          <name>
            <surname>Spillman</surname>
            <given-names>DR</given-names>
          </name>
          <name>
            <surname>Boppart</surname>
            <given-names>SA</given-names>
          </name>
        </person-group>
        <article-title>Automated classification platform for the identification of otitis media using optical coherence tomography</article-title>
        <source>NPJ Dig Med</source>
        <year>2019</year>
        <volume>2</volume>
        <issue>1</issue>
        <fpage>1</fpage>
        <lpage>22</lpage>
      </element-citation>
    </ref>
    <ref id="CR7">
      <label>7.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Monroy</surname>
            <given-names>GL</given-names>
          </name>
          <name>
            <surname>Shelton</surname>
            <given-names>RL</given-names>
          </name>
          <name>
            <surname>Nolan</surname>
            <given-names>RM</given-names>
          </name>
          <name>
            <surname>Nguyen</surname>
            <given-names>CT</given-names>
          </name>
          <name>
            <surname>Novak</surname>
            <given-names>MA</given-names>
          </name>
          <name>
            <surname>Hill</surname>
            <given-names>MC</given-names>
          </name>
          <name>
            <surname>McCormick</surname>
            <given-names>DT</given-names>
          </name>
          <name>
            <surname>Boppart</surname>
            <given-names>SA</given-names>
          </name>
        </person-group>
        <article-title>Noninvasive depth-resolved optical measurements of the tympanic membrane and middle ear for differentiating otitis media</article-title>
        <source>Laryngoscope</source>
        <year>2015</year>
        <volume>125</volume>
        <issue>8</issue>
        <fpage>276</fpage>
        <lpage>282</lpage>
        <pub-id pub-id-type="doi">10.1002/lary.25141</pub-id>
      </element-citation>
    </ref>
    <ref id="CR8">
      <label>8.</label>
      <mixed-citation publication-type="other">Brock A, Lim T, Ritchie JM, Weston NJ (2016) Generative and discriminative voxel modeling with convolutional neural networks. In: Neural inofrmation processing conference: 3D deep learning</mixed-citation>
    </ref>
    <ref id="CR9">
      <label>9.</label>
      <mixed-citation publication-type="other">Su H, Maji S, Kalogerakis E, Learned-Miller E (2015) Multi-view convolutional neural networks for 3d shape recognition. In: Proceedings of the IEEE international conference on computer vision, p 945–953</mixed-citation>
    </ref>
    <ref id="CR10">
      <label>10.</label>
      <mixed-citation publication-type="other">Feng Y, Zhang Z, Zhao X, Ji R, Gao Y (2018) Gvcnn: group-view convolutional neural networks for 3d shape recognition. In: Proceedings of the IEEE conference on computer vision and pattern recognition, p 264–272</mixed-citation>
    </ref>
    <ref id="CR11">
      <label>11.</label>
      <mixed-citation publication-type="other">Qi CR, Su H, Nießner M, Dai A, Yan M, Guibas LJ (2016) Volumetric and multi-view cnns for object classification on 3d data. In: Proceedings of the IEEE conference on computer vision and pattern recognition, p 5648–5656</mixed-citation>
    </ref>
    <ref id="CR12">
      <label>12.</label>
      <mixed-citation publication-type="other">Qi CR, Su H, Mo K, Guibas LJ (2017) Pointnet: deep learning on point sets for 3d classification and segmentation. In: Proceedings of the IEEE conference on computer vision and pattern recognition, p 652–660</mixed-citation>
    </ref>
    <ref id="CR13">
      <label>13.</label>
      <mixed-citation publication-type="other">Qi CR, Yi L, Su H, Guibas LJ (2017) Pointnet++: deep hierarchical feature learning on point sets in a metric space. In: Advances in neural information processing systems, vol 30</mixed-citation>
    </ref>
    <ref id="CR14">
      <label>14.</label>
      <mixed-citation publication-type="other">Thomas H, Qi CR, Deschaud J-E, Marcotegui B, Goulette F, Guibas LJ (2019) Kpconv: flexible and deformable convolution for point clouds. In: Proceedings of the IEEE/CVF international conference on computer vision, p 6411–6420</mixed-citation>
    </ref>
    <ref id="CR15">
      <label>15.</label>
      <mixed-citation publication-type="other">Xu Y, Fan T, Xu M, Zeng L, Qiao Y (2018) Spidercnn: deep learning on point sets with parameterized convolutional filters. In: Proceedings of the European conference on computer vision (ECCV), p 87–102</mixed-citation>
    </ref>
    <ref id="CR16">
      <label>16.</label>
      <mixed-citation publication-type="other">Choy C, Park J, Koltun V (2019) Fully convolutional geometric features. In: Proceedings of the IEEE/CVF international conference on computer vision, p 8958–8966</mixed-citation>
    </ref>
    <ref id="CR17">
      <label>17.</label>
      <mixed-citation publication-type="other">Besl PJ, McKay ND (1992) Method for registration of 3-d shapes. Sensor fusion IV: control paradigms and data structures, vol 1611. Spie, Bellingham, pp 586–606</mixed-citation>
    </ref>
    <ref id="CR18">
      <label>18.</label>
      <mixed-citation publication-type="other">Amberg B, Romdhani S, Vetter T (2007) Optimal step nonrigid icp algorithms for surface registration. In: 2007 IEEE conference on computer vision and pattern recognition, IEEE, p 1–8</mixed-citation>
    </ref>
    <ref id="CR19">
      <label>19.</label>
      <mixed-citation publication-type="other">Aoki Y, Goforth H, Srivatsan RA, Lucey S (2019) Pointnetlk: robust &amp; efficient point cloud registration using pointnet. In: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, p 7163–7172</mixed-citation>
    </ref>
    <ref id="CR20">
      <label>20.</label>
      <mixed-citation publication-type="other">Yew ZJ, Lee GH (2022) Regtr: end-to-end point cloud correspondences with transformers. In: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, p 6677–6686</mixed-citation>
    </ref>
    <ref id="CR21">
      <label>21.</label>
      <mixed-citation publication-type="other">Zhu L, Guan H, Lin C, Han R (2022) Neighborhood-aware geometric encoding network for point cloud registration. arXiv preprint <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/2201.12094">arXiv:2201.12094</ext-link></mixed-citation>
    </ref>
    <ref id="CR22">
      <label>22.</label>
      <mixed-citation publication-type="other">Li Y, Harada T (2022) Non-rigid point cloud registration with neural deformation pyramid. arXiv preprint <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/2205.12796">arXiv:2205.12796</ext-link></mixed-citation>
    </ref>
    <ref id="CR23">
      <label>23.</label>
      <mixed-citation publication-type="other">Lucas BD, Kanade T (1981) An iterative image registration technique with an application to stereo vision. In: IJCAI’81: 7th international joint conference on artificial intelligence, p 674–679</mixed-citation>
    </ref>
  </ref-list>
</back>
<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Int J Comput Assist Radiol Surg</journal-id>
    <journal-id journal-id-type="iso-abbrev">Int J Comput Assist Radiol Surg</journal-id>
    <journal-title-group>
      <journal-title>International Journal of Computer Assisted Radiology and Surgery</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1861-6410</issn>
    <issn pub-type="epub">1861-6429</issn>
    <publisher>
      <publisher-name>Springer International Publishing</publisher-name>
      <publisher-loc>Cham</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">10769937</article-id>
    <article-id pub-id-type="pmid">37328716</article-id>
    <article-id pub-id-type="publisher-id">2960</article-id>
    <article-id pub-id-type="doi">10.1007/s11548-023-02960-9</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Original Article</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Non-rigid point cloud registration for middle ear diagnostics with endoscopic optical coherence tomography</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid">http://orcid.org/0009-0002-4280-3672</contrib-id>
        <name>
          <surname>Liu</surname>
          <given-names>Peng</given-names>
        </name>
        <address>
          <email>peng.liu@nct-dresden.de</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff3">3</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Golde</surname>
          <given-names>Jonas</given-names>
        </name>
        <xref ref-type="aff" rid="Aff2">2</xref>
        <xref ref-type="aff" rid="Aff3">3</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Morgenstern</surname>
          <given-names>Joseph</given-names>
        </name>
        <xref ref-type="aff" rid="Aff3">3</xref>
        <xref ref-type="aff" rid="Aff4">4</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Bodenstedt</surname>
          <given-names>Sebastian</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Li</surname>
          <given-names>Chenpan</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Hu</surname>
          <given-names>Yujia</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Chen</surname>
          <given-names>Zhaoyu</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Koch</surname>
          <given-names>Edmund</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Neudert</surname>
          <given-names>Marcus</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff4">4</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Speidel</surname>
          <given-names>Stefanie</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff3">3</xref>
      </contrib>
      <aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/01txwsw02</institution-id><institution-id institution-id-type="GRID">grid.461742.2</institution-id><institution-id institution-id-type="ISNI">0000 0000 8855 0365</institution-id><institution>Translational Surgical Oncology, </institution><institution>National Center for Tumor Diseases, </institution></institution-wrap>Dresden, 01307 Germany </aff>
      <aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/042aqky30</institution-id><institution-id institution-id-type="GRID">grid.4488.0</institution-id><institution-id institution-id-type="ISNI">0000 0001 2111 7257</institution-id><institution>Clinical Sensoring and Monitoring, </institution><institution>TU Dresden, </institution></institution-wrap>Dresden, 01307 Germany </aff>
      <aff id="Aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/042aqky30</institution-id><institution-id institution-id-type="GRID">grid.4488.0</institution-id><institution-id institution-id-type="ISNI">0000 0001 2111 7257</institution-id><institution>Else Kröner Fresenius Center, </institution><institution>TU Dresden, </institution></institution-wrap>Dresden, 01307 Germany </aff>
      <aff id="Aff4"><label>4</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/042aqky30</institution-id><institution-id institution-id-type="GRID">grid.4488.0</institution-id><institution-id institution-id-type="ISNI">0000 0001 2111 7257</institution-id><institution>Ear Research Center Dresden, </institution><institution>TU Dresden, </institution></institution-wrap>Dresden, 01307 Germany </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>17</day>
      <month>6</month>
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>17</day>
      <month>6</month>
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="ppub">
      <year>2024</year>
    </pub-date>
    <volume>19</volume>
    <issue>1</issue>
    <fpage>139</fpage>
    <lpage>145</lpage>
    <history>
      <date date-type="received">
        <day>6</day>
        <month>3</month>
        <year>2023</year>
      </date>
      <date date-type="accepted">
        <day>12</day>
        <month>5</month>
        <year>2023</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2023</copyright-statement>
      <license>
        <ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>.</license-p>
      </license>
    </permissions>
    <abstract id="Abs1">
      <sec>
        <title>
          <bold>Purpose</bold>
        </title>
        <p id="Par1">Middle ear infection is the most prevalent inflammatory disease, especially among the pediatric population. Current diagnostic methods are subjective and depend on visual cues from an otoscope, which is limited for otologists to identify pathology. To address this shortcoming, endoscopic optical coherence tomography (OCT) provides both morphological and functional in vivo measurements of the middle ear. However, due to the shadow of prior structures, interpretation of OCT images is challenging and time-consuming. To facilitate fast diagnosis and measurement, improvement in the readability of OCT data is achieved by merging morphological knowledge from ex vivo middle ear models with OCT volumetric data, so that OCT applications can be further promoted in daily clinical settings.</p>
      </sec>
      <sec>
        <title>
          <bold>Methods</bold>
        </title>
        <p id="Par2">We propose C2P-Net: a two-staged non-rigid registration pipeline for complete to partial point clouds, which are sampled from ex vivo and in vivo OCT models, respectively. To overcome the lack of labeled training data, a fast and effective generation pipeline in Blender3D is designed to simulate middle ear shapes and extract in vivo noisy and partial point clouds.</p>
      </sec>
      <sec>
        <title>
          <bold>Results</bold>
        </title>
        <p id="Par3">We evaluate the performance of C2P-Net through experiments on both synthetic and real OCT datasets. The results demonstrate that C2P-Net is generalized to unseen middle ear point clouds and capable of handling realistic noise and incompleteness in synthetic and real OCT data.</p>
      </sec>
      <sec>
        <title>
          <bold>Conclusions</bold>
        </title>
        <p id="Par4">In this work, we aim to enable diagnosis of middle ear structures with the assistance of OCT images. We propose C2P-Net: a two-staged non-rigid registration pipeline for point clouds to support the interpretation of in vivo noisy and partial OCT images for the first time. Code is available at: <ext-link ext-link-type="uri" xlink:href="https://gitlab.com/nct_tso_public/c2p-net.">https://gitlab.com/nct_tso_public/c2p-net.</ext-link></p>
      </sec>
    </abstract>
    <kwd-group xml:lang="en">
      <title>Keywords</title>
      <kwd>Middle ear</kwd>
      <kwd>Optical coherence tomography</kwd>
      <kwd>Point cloud</kwd>
      <kwd>Deep learning based registration</kwd>
    </kwd-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100014843</institution-id>
            <institution>Else Kröner-Fresenius-Zentrum für Ernährungsmedizin</institution>
          </institution-wrap>
        </funding-source>
      </award-group>
    </funding-group>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>© CARS 2024</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="Sec1">
    <title>Introduction</title>
    <p id="Par5">The middle ear consists of the tympanic membrane (TM) and an air-filled chamber containing the ossicle chain (OC) that connects the TM to the inner ear. From a functional perspective, the middle ear matches the impedance from air to the fluid-filled inner ear [<xref ref-type="bibr" rid="CR1">1</xref>].</p>
    <p id="Par6">Middle ear disorders contain deformation, discontinuation of TM and OC, effusion, and cholesteatoma in the middle ear. These may occur because of middle ear infection (e.g., acute otitis media (AOM), chronic otitis media (COM), otitis media with effusion (OME)) and trauma [<xref ref-type="bibr" rid="CR2">2</xref>, <xref ref-type="bibr" rid="CR3">3</xref>]. Most commonly, serious and chronic middle ear disorder may lead to conductive hearing loss and inner ear disorder [<xref ref-type="bibr" rid="CR4">4</xref>]. Current middle ear diagnostics methods or tools cover only aspects of the pathology and cannot determine the origin and site of transmission loss, e.g., otoscopy, audiometry, tympanometry, etc.<fig id="Fig1"><label>Fig. 1</label><caption><p>Overview of data samples. In <bold>a</bold>, I is the ex vivo template point cloud reconstructed from <inline-formula id="IEq1"><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mu $$\end{document}</tex-math><mml:math id="M2"><mml:mi>μ</mml:mi></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq1.gif"/></alternatives></inline-formula>CT scans on the left. II is the segmented middle ear model, and each color stands for one structure. III shows the model with sparse labels. Accordingly, I, II and III in <bold>b</bold> present in vivo OCT point cloud, segmented OCT model and labels. The simulation pipeline on the top left takes a complete ex vivo ear point cloud, performs non-rigid and rigid simulation, and produces synthetic partial and noisy in vivo point cloud shown in <bold>c</bold></p></caption><graphic xlink:href="11548_2023_2960_Fig1_HTML" id="MO1"/></fig></p>
    <p id="Par7">As an innovative image technology, endoscopic OCT enables the examination of both the morphology and function of the middle ear in vivo by the non-invasive acquisition of depth-resolved and high-resolution images [<xref ref-type="bibr" rid="CR5">5</xref>–<xref ref-type="bibr" rid="CR7">7</xref>]. Nevertheless, multiple sources of noise, e.g., the shadow of preceding structures, reduce the quality of the target structures further away from the endoscopic probe, e.g., ossicles. Therefore, the reconstructed 3D models from the OCT volumetric data are usually noisy and difficult to interpret, especially the identification of the deeper middle ear structures such as incus and stapes (see Fig. <xref rid="Fig1" ref-type="fig">1</xref>).</p>
    <p id="Par8">Our aim is to improve the interpretation of the OCT volumetric data by merging the ex vivo middle ear model reconstructed from micro-Computed Tomography (<inline-formula id="IEq2"><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mu $$\end{document}</tex-math><mml:math id="M4"><mml:mi>μ</mml:mi></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq2.gif"/></alternatives></inline-formula>CT) scan of isolated temporal bones and the in vivo OCT model. Note that a single <inline-formula id="IEq3"><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mu $$\end{document}</tex-math><mml:math id="M6"><mml:mi>μ</mml:mi></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq3.gif"/></alternatives></inline-formula>CT model was used as a template and fitted to all patient-specific OCT scans. We first convert all ex and in vivo middle ear data to point cloud representations for ease of flexible manipulation of middle ear shapes. Nevertheless, finding one-to-one correspondence between such a point cloud pair is still challenging due to the noise and incompleteness of the OCT model, and the difference between the patient data and the template <inline-formula id="IEq4"><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mu $$\end{document}</tex-math><mml:math id="M8"><mml:mi>μ</mml:mi></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq4.gif"/></alternatives></inline-formula>CT data. To tackle these issues, we first employ a neural network that searches the sparse correspondences for the source and target points, then a pyramid deformation algorithm to fit the points in a non-rigid fashion based on the predicted correspondences. The neural network is trained on randomly generated synthetic shape variants of the middle ear that contain random noise and only partial points. This enables the generalization of the neural network to new patient data as well as the adaption to noise and outliers The main contributions of this work are listed as follows: <list list-type="order"><list-item><p id="Par9">A generation pipeline in Blender3D that simulates synthetic shape variants from a complete ex vivo middle ear model, and simulates noisy and partial point clouds comparable to in vivo data.</p></list-item><list-item><p id="Par10">C2P-Net: a two-staged non-rigid registration pipeline for point clouds. It demonstrates that C2P-Net registers the complete point cloud template to partial point clouds of the middle ear effectively and robustly.</p></list-item></list></p>
  </sec>
  <sec id="Sec2">
    <title>Related work</title>
    <p id="Par11">In this section, we review methods that analyze 3D point clouds and solve registration problems. Learning the geometry of 3D point clouds is the foundation of diverse 3D applications, but is also a challenging task due to the irregularity and asymmetry of point clouds. Recently, approaches that focus on learning point features with neural networks have been widely investigated to overcome such issues. One category of methods is to project the point cloud to a regular representation, e.g., voxel grids [<xref ref-type="bibr" rid="CR8">8</xref>], 2D images from multi-views [<xref ref-type="bibr" rid="CR9">9</xref>, <xref ref-type="bibr" rid="CR10">10</xref>], or combined [<xref ref-type="bibr" rid="CR11">11</xref>] that 2/3D convolutional operations can be performed on top of these intermediate data in Euclidean space. Apart from these, PointNet [<xref ref-type="bibr" rid="CR12">12</xref>] leverages multilayer perceptron (MLP) to obtain pointwise features and a max-pool to aggregate global features but without local information. This drawback is alleviated by PointNet++ [<xref ref-type="bibr" rid="CR13">13</xref>], which uses PointNet to aggregate local features in a multi-scale structure. In addition, various explicit convolution kernels are applied directly on the point clouds to extract encodings [<xref ref-type="bibr" rid="CR14">14</xref>–<xref ref-type="bibr" rid="CR16">16</xref>] in which point features are extracted based on the kernel weights.</p>
    <p id="Par12">Conventional methods solve the point cloud registration task as an optimization problem of transformation parameters. Iterative Closest Point (ICP) [<xref ref-type="bibr" rid="CR17">17</xref>] iteratively calculates a rigid transformation matrix based on updated correspondence set from a last iteration, Non-rigid Iterative Closest Point (NICP) [<xref ref-type="bibr" rid="CR18">18</xref>] achieves non-rigid registration by optimizing an energy function including local regularization and stiffness. Coherent Point Drift (CPD) maximizes the probability of Gaussian Mixture Model (GMM) by moving coherent GMM centroids from the two point clouds. Recently, deep learning-based methods using the aforementioned point cloud encoding techniques have been widely investigated [<xref ref-type="bibr" rid="CR19">19</xref>–<xref ref-type="bibr" rid="CR22">22</xref>]. PointNetLK [<xref ref-type="bibr" rid="CR19">19</xref>] extracts semantic point cloud features using an MLP, then performs rigid alignment using the Lucas and Kanade algorithm [<xref ref-type="bibr" rid="CR23">23</xref>].</p>
    <p id="Par13">RegTR [<xref ref-type="bibr" rid="CR20">20</xref>] and NgeNet [<xref ref-type="bibr" rid="CR21">21</xref>] employ KPConv [<xref ref-type="bibr" rid="CR14">14</xref>] to extract both global and local features from the source and target point clouds. Following this, attention mechanisms are introduced to enable the communication of the extracted features and estimate a global transformation from the predicted correspondences of the MLPs.</p>
    <p id="Par14">In contrast to this direct way, NDP [<xref ref-type="bibr" rid="CR22">22</xref>] decomposes the global transformation into sub-motions which are iteratively refined using MLPs at each pyramid level. Inspired by this recent work regarding point cloud analysis and registration, we adopted NgeNet [<xref ref-type="bibr" rid="CR21">21</xref>] and NDP [<xref ref-type="bibr" rid="CR22">22</xref>] as the main components to construct our registration pipeline.</p>
  </sec>
  <sec id="Sec3">
    <title>Methods</title>
    <p id="Par15">The non-rigid registration of the ex and in vivo middle ear point clouds (see Fig. <xref rid="Fig1" ref-type="fig">1</xref>) using neural networks is realized in a supervised learning fashion. Due to lack of real OCT data with ground truth, and the difficulties of finding one-to-one correspondences between the general and ex vivo model and the noisy and partial in vivo model, we generated synthetic in vivo middle ear point clouds based on the ex vivo <inline-formula id="IEq5"><alternatives><tex-math id="M9">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mu $$\end{document}</tex-math><mml:math id="M10"><mml:mi>μ</mml:mi></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq5.gif"/></alternatives></inline-formula>CT model using a two-step simulation pipeline. For point cloud registration, we propose C2P-Net, which is a two-stage registration method. We first train a neural network on the synthetic samples to explore the correspondence along with an initial rigid transformation matrix, then based on this, a hierarchical algorithm is performed to estimate the non-rigid deformation.</p>
    <sec id="Sec4">
      <title>Synthetic data generation</title>
      <p id="Par16">We start with a complete middle ear model <inline-formula id="IEq6"><alternatives><tex-math id="M11">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$M_{\mu {CT}}$$\end{document}</tex-math><mml:math id="M12"><mml:msub><mml:mi>M</mml:mi><mml:mrow><mml:mi>μ</mml:mi><mml:mrow><mml:mi mathvariant="italic">CT</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq6.gif"/></alternatives></inline-formula> reconstructed from <inline-formula id="IEq7"><alternatives><tex-math id="M13">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mu $$\end{document}</tex-math><mml:math id="M14"><mml:mi>μ</mml:mi></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq7.gif"/></alternatives></inline-formula>CT volume as basis for the simulation in Blender3D. The non-rigid simulation is performed with the assistance of lattice modifiers attached to each structure with reasonable resolution. The lattice vertices are assigned to various groups according to length, thickness, and width of the global and local shape of a structure. By transforming and rotating various vertex groups with random parameters with boundary conditions, a random shape of a structure can be generated, e.g., a relatively shorter malleus with a longer lateral process. The non-rigid simulation step is formulated as <inline-formula id="IEq8"><alternatives><tex-math id="M15">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\tilde{T}}_{nr}=\textrm{S}_{nr}(T, p_{nr})$$\end{document}</tex-math><mml:math id="M16"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>T</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mrow><mml:mi mathvariant="italic">nr</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mtext>S</mml:mtext><mml:mrow><mml:mi mathvariant="italic">nr</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi mathvariant="italic">nr</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq8.gif"/></alternatives></inline-formula>, where <italic>T</italic> is the template middle ear, <inline-formula id="IEq9"><alternatives><tex-math id="M17">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$p_{nr}$$\end{document}</tex-math><mml:math id="M18"><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi mathvariant="italic">nr</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq9.gif"/></alternatives></inline-formula> are the input parameters, and <inline-formula id="IEq10"><alternatives><tex-math id="M19">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\tilde{T}_{nr}$$\end{document}</tex-math><mml:math id="M20"><mml:msub><mml:mover accent="true"><mml:mi>T</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mrow><mml:mi mathvariant="italic">nr</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq10.gif"/></alternatives></inline-formula> is the simulated non-rigid shape variants of <italic>T</italic>. Next, armature modifiers are attached to each structure and connected in an end-to-end fashion at the articulations. Then, rigid simulation is accomplished by transforming and rotating the armature bones. We denote the rigid simulation as <inline-formula id="IEq11"><alternatives><tex-math id="M21">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$S_r$$\end{document}</tex-math><mml:math id="M22"><mml:msub><mml:mi>S</mml:mi><mml:mi>r</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq11.gif"/></alternatives></inline-formula>. Thus, a random shape variant of the middle ear <inline-formula id="IEq12"><alternatives><tex-math id="M23">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\tilde{T}$$\end{document}</tex-math><mml:math id="M24"><mml:mover accent="true"><mml:mi>T</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq12.gif"/></alternatives></inline-formula> can be obtained which is considered as the in vivo ear model of a new patient: <inline-formula id="IEq13"><alternatives><tex-math id="M25">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\tilde{T}=\textrm{S}_{r}(\tilde{T}_{nr}, p_{r})$$\end{document}</tex-math><mml:math id="M26"><mml:mrow><mml:mover accent="true"><mml:mi>T</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:msub><mml:mtext>S</mml:mtext><mml:mi>r</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>T</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mrow><mml:mi mathvariant="italic">nr</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mi>r</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq13.gif"/></alternatives></inline-formula>.</p>
      <p id="Par17">In practice, the in vivo OCT model is usually noisy and only partially visible, which limits the registration methods in finding accurate and robust correspondences. To simulate the real data, we extract random partial patches for each structure of the shape variant <inline-formula id="IEq14"><alternatives><tex-math id="M27">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\tilde{T}$$\end{document}</tex-math><mml:math id="M28"><mml:mover accent="true"><mml:mi>T</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq14.gif"/></alternatives></inline-formula> by a combined probability, which is calculated as the distance of each vertex to the support point of each structure and random Gaussian noise. Additionally, for the sake of simulating incomplete posterior structure, e.g., stapes, caused by the occlusion and shadow from the anterior structures, e.g., ear canal wall, we determine the number of points of the posterior structures by the distance to the external ear and a random factor. Furthermore, uniform random displacements are applied to the vertices to generate the final noisy and partial in vivo point cloud <inline-formula id="IEq15"><alternatives><tex-math id="M29">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$P_{inv}$$\end{document}</tex-math><mml:math id="M30"><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi mathvariant="italic">inv</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq15.gif"/></alternatives></inline-formula> (see Fig. <xref rid="Fig1" ref-type="fig">1</xref>).<fig id="Fig2"><label>Fig. 2</label><caption><p>Schematic architecture of C2P-Net. The input of the pipeline is the ex vivo (blue) and in vivo (orange) point cloud. To explore the correspondence between the two inputs, NgeNet is trained on synthetic samples to extract the features for each point at different levels. These are integrated by a voting algorithm. A feature matching routine is performed to obtain the sparse correspondence set as well as a rigid transformation matrix. On top of the previous outputs, NDP maps the input point clouds to sinusoidal space and decomposes the global non-rigid deformation at each pyramid level into sub-motions. With the increase in sinusoidal frequency, the non-rigid deformation of each point is continuously refined at each level. The registered point cloud is shown on the right side</p></caption><graphic xlink:href="11548_2023_2960_Fig2_HTML" id="MO2"/></fig></p>
    </sec>
    <sec id="Sec5">
      <title>C2P-Net</title>
      <p id="Par18">We delineate the architecture of C2P-Net in Fig. <xref rid="Fig2" ref-type="fig">2</xref>. It consists of two components dedicated to two stages: initial rigid registration and pyramid non-rigid registration. Given an ex vivo point cloud as a template extracted from a <inline-formula id="IEq16"><alternatives><tex-math id="M31">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mu $$\end{document}</tex-math><mml:math id="M32"><mml:mi>μ</mml:mi></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq16.gif"/></alternatives></inline-formula>CT model: <inline-formula id="IEq17"><alternatives><tex-math id="M33">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$P_{exv}={\{x_i\in {{\mathcal {R}}^{3}}\}_{i=1,2,...,N}}$$\end{document}</tex-math><mml:math id="M34"><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi mathvariant="italic">exv</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="script">R</mml:mi></mml:mrow><mml:mn>3</mml:mn></mml:msup><mml:mo stretchy="false">}</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>,</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq17.gif"/></alternatives></inline-formula>, and a partial point cloud of the simulated in vivo shape variant: <inline-formula id="IEq18"><alternatives><tex-math id="M35">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$P_{inv}={\{y_j\in {{\mathcal {R}}^{3}}\}_{j=1,2,...,M}}$$\end{document}</tex-math><mml:math id="M36"><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi mathvariant="italic">inv</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="script">R</mml:mi></mml:mrow><mml:mn>3</mml:mn></mml:msup><mml:mo stretchy="false">}</mml:mo></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>,</mml:mo><mml:mi>M</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq18.gif"/></alternatives></inline-formula>, we adopted the Neighborhood-aware Geometric Encoding Network (NgeNet) [<xref ref-type="bibr" rid="CR21">21</xref>] to solve the initial rigid registration task. This stage is formulated as:<disp-formula id="Equ1"><label>1</label><alternatives><tex-math id="M37">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} \tau ,\sigma =\textrm{NgeNet}(P_{exv}, P_{inv})\quad where\ (u, v) \in \sigma \end{aligned}$$\end{document}</tex-math><mml:math id="M38" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>τ</mml:mi><mml:mo>,</mml:mo><mml:mi>σ</mml:mi><mml:mo>=</mml:mo><mml:mtext>NgeNet</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi mathvariant="italic">exv</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi mathvariant="italic">inv</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mspace width="1em"/><mml:mi>w</mml:mi><mml:mi>h</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mspace width="4pt"/><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>∈</mml:mo><mml:mi>σ</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="11548_2023_2960_Article_Equ1.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq19"><alternatives><tex-math id="M39">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\tau \in {SE(3)} $$\end{document}</tex-math><mml:math id="M40"><mml:mrow><mml:mi>τ</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mi>S</mml:mi><mml:mi>E</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>3</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq19.gif"/></alternatives></inline-formula> is the rigid transformation matrix which aligns <inline-formula id="IEq20"><alternatives><tex-math id="M41">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$P_{exv}$$\end{document}</tex-math><mml:math id="M42"><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi mathvariant="italic">exv</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq20.gif"/></alternatives></inline-formula> with <inline-formula id="IEq21"><alternatives><tex-math id="M43">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$P_{inv}$$\end{document}</tex-math><mml:math id="M44"><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi mathvariant="italic">inv</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq21.gif"/></alternatives></inline-formula>, and <inline-formula id="IEq22"><alternatives><tex-math id="M45">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$(u, v) \in \sigma $$\end{document}</tex-math><mml:math id="M46"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>∈</mml:mo><mml:mi>σ</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq22.gif"/></alternatives></inline-formula> is the sparse correspondence set where <italic>u</italic> and <italic>v</italic> are indices for points in <inline-formula id="IEq23"><alternatives><tex-math id="M47">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$P_{exv}$$\end{document}</tex-math><mml:math id="M48"><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi mathvariant="italic">exv</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq23.gif"/></alternatives></inline-formula> and <inline-formula id="IEq24"><alternatives><tex-math id="M49">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$P_{inv}$$\end{document}</tex-math><mml:math id="M50"><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi mathvariant="italic">inv</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq24.gif"/></alternatives></inline-formula>. Due to the multi-scale structure and a voting mechanism integrating features from different resolutions, NgeNet handles noise well and predicts correspondence robustly.</p>
      <p id="Par19">Based on the previous predicted correspondence set and the rigidly aligned source and target point clouds, we employ the Neural Deformation Pyramid (NDP) [<xref ref-type="bibr" rid="CR22">22</xref>] to predict the non-rigid deformation of the given point cloud pair. NDP defines the non-rigid registration problem as a hierarchical motion decomposition problem. At each pyramid level, the input points from last level are mapped to sinusoidal encodings with different frequencies: <inline-formula id="IEq25"><alternatives><tex-math id="M51">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\Gamma (p^{k-1})=(\textrm{sin}(2^{k+k_0}p^{k-1}), \textrm{cos}(2^{k+k_0}p^{k-1}))$$\end{document}</tex-math><mml:math id="M52"><mml:mrow><mml:mi mathvariant="normal">Γ</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>p</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mtext>sin</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mn>2</mml:mn><mml:mrow><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:msup><mml:msup><mml:mi>p</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mtext>cos</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mn>2</mml:mn><mml:mrow><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:msup><mml:msup><mml:mi>p</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq25.gif"/></alternatives></inline-formula>, <italic>k</italic> is the current level number, <inline-formula id="IEq26"><alternatives><tex-math id="M53">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$k_0$$\end{document}</tex-math><mml:math id="M54"><mml:msub><mml:mi>k</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq26.gif"/></alternatives></inline-formula> controls the initial frequency and <inline-formula id="IEq27"><alternatives><tex-math id="M55">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$p^{k-1}$$\end{document}</tex-math><mml:math id="M56"><mml:msup><mml:mi>p</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq27.gif"/></alternatives></inline-formula> is an output point from the last level. Lower frequencies at shallower levels represent rigid sub-motion, while higher frequencies at deep levels emphasize non-rigid deformations. In this way, a sequence of sub-motions is estimated from rigid to non-rigid, and the final displacement field is the combination of such a sequence. Formally, we denote the stage as:<disp-formula id="Equ2"><label>2</label><alternatives><tex-math id="M57">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} \phi _{est}=\textrm{NDP}_{n,m}({\tilde{P}}_{exv}, P_{inv}, \sigma ) \end{aligned}$$\end{document}</tex-math><mml:math id="M58" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi mathvariant="italic">est</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mtext>NDP</mml:mtext><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>P</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mrow><mml:mi mathvariant="italic">exv</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi mathvariant="italic">inv</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>σ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="11548_2023_2960_Article_Equ2.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq28"><alternatives><tex-math id="M59">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\tilde{P}}_{exv}$$\end{document}</tex-math><mml:math id="M60"><mml:msub><mml:mover accent="true"><mml:mi>P</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mrow><mml:mi mathvariant="italic">exv</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq28.gif"/></alternatives></inline-formula> is the source point cloud <inline-formula id="IEq29"><alternatives><tex-math id="M61">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${P}_{exv}$$\end{document}</tex-math><mml:math id="M62"><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi mathvariant="italic">exv</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq29.gif"/></alternatives></inline-formula> transformed by <inline-formula id="IEq30"><alternatives><tex-math id="M63">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\tau $$\end{document}</tex-math><mml:math id="M64"><mml:mi>τ</mml:mi></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq30.gif"/></alternatives></inline-formula>, <italic>n</italic> is the number of pyramid layers of the NDP neural network, <italic>m</italic> is the maximal iteration within a single pyramid layer, and <inline-formula id="IEq31"><alternatives><tex-math id="M65">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\phi _{est}$$\end{document}</tex-math><mml:math id="M66"><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi mathvariant="italic">est</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq31.gif"/></alternatives></inline-formula> is the predicted displacement field describing how each point should move to the target. Combined losses are calculated at each iteration, including correspondence loss and regularization loss, and back-propagated to update the weights of each MLP. Of which, the correspondence loss <inline-formula id="IEq32"><alternatives><tex-math id="M67">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$L_{CD}$$\end{document}</tex-math><mml:math id="M68"><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi mathvariant="italic">CD</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq32.gif"/></alternatives></inline-formula> is defined as the Chamfer distance (<xref rid="Equ3" ref-type="disp-formula">3</xref>) between <inline-formula id="IEq33"><alternatives><tex-math id="M69">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{\tilde{P}}}_{exv}$$\end{document}</tex-math><mml:math id="M70"><mml:msub><mml:mover accent="true"><mml:mi>P</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mrow><mml:mi mathvariant="italic">exv</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq33.gif"/></alternatives></inline-formula> which is masked by the correspondence <inline-formula id="IEq34"><alternatives><tex-math id="M71">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sigma $$\end{document}</tex-math><mml:math id="M72"><mml:mi>σ</mml:mi></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq34.gif"/></alternatives></inline-formula> and <inline-formula id="IEq35"><alternatives><tex-math id="M73">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$P_{inv}$$\end{document}</tex-math><mml:math id="M74"><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi mathvariant="italic">inv</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq35.gif"/></alternatives></inline-formula>.<disp-formula id="Equ3"><label>3</label><alternatives><tex-math id="M75">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned}{} &amp; {} \textrm{CD}(A,B) {=}\frac{1}{|{A}|}\sum _{x_i\in {A}}\min _{y_j\in {B}}|{x_i{-}y_j}|{+}\frac{1}{|{B}|}\sum _{y_j\in {B}}\min _{x_i\in {A}}|{x_i{-}y_j}|\nonumber \\ \end{aligned}$$\end{document}</tex-math><mml:math id="M76" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow/></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mrow/><mml:mtext>CD</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>B</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mi>A</mml:mi><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mfrac><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:mi>A</mml:mi></mml:mrow></mml:munder><mml:munder><mml:mo movablelimits="true">min</mml:mo><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:mi>B</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mo>+</mml:mo></mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mi>B</mml:mi><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mfrac><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:mi>B</mml:mi></mml:mrow></mml:munder><mml:munder><mml:mo movablelimits="true">min</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:mi>A</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right"><mml:mrow/></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="11548_2023_2960_Article_Equ3.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ4"><label>4</label><alternatives><tex-math id="M77">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned}{} &amp; {} L_\textrm{CD} =\textrm{CD}({{\tilde{P}}}_{exv}^{\sigma }, P_{inv}) \end{aligned}$$\end{document}</tex-math><mml:math id="M78" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow/></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mrow/><mml:msub><mml:mi>L</mml:mi><mml:mtext>CD</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mtext>CD</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mover accent="true"><mml:mi>P</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mrow><mml:mi mathvariant="italic">exv</mml:mi></mml:mrow><mml:mi>σ</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi mathvariant="italic">inv</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="11548_2023_2960_Article_Equ4.gif" position="anchor"/></alternatives></disp-formula><inline-formula id="IEq36"><alternatives><tex-math id="M79">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{\tilde{P}}}_{exv}^{\sigma }=\{{{\tilde{P}}}_{exv}[u]|\exists {v}:(u,v)\in \sigma \}$$\end{document}</tex-math><mml:math id="M80"><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>P</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mrow><mml:mi mathvariant="italic">exv</mml:mi></mml:mrow><mml:mi>σ</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>P</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mrow><mml:mi mathvariant="italic">exv</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mo>∃</mml:mo><mml:mi>v</mml:mi><mml:mo>:</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>∈</mml:mo><mml:mi>σ</mml:mi><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:mrow></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq36.gif"/></alternatives></inline-formula> are the masked ex vivo points that have correspondence in the target in vivo point cloud.</p>
    </sec>
  </sec>
  <sec id="Sec6">
    <title>Evaluation</title>
    <p id="Par20">C2P-Net predicts a displacement field to fit the ex vivo point cloud template to the target in vivo point cloud which is noisy and partial. At training time, C2P-Net employs an Adam optimizer and ExpLR scheduler and uses supervised learning to learn on a synthetic dataset with 20,000 in vivo shape variants of the middle ear. During inference, it takes around 3.5 s for C2P-Net to react to a new in vivo shape on RTX 2070 Super. Since the neural network is trained on synthetic data, it is crucial to investigate the generalization of the neural networks on unseen samples as well as the performance on real OCT data. Thus, we conduct two experiments on synthetic data and real OCT data with various metrics: mean displacement error (<xref rid="Equ5" ref-type="disp-formula">5</xref>), Chamfer distance (<xref rid="Equ3" ref-type="disp-formula">3</xref>), and landmarks error (<xref rid="Equ6" ref-type="disp-formula">6</xref>). Furthermore, we compare our results with other popular non-rigid registration methods, e.g., Non-rigid ICP (NICP) and Coherent Point Drift (CPD).<disp-formula id="Equ5"><label>5</label><alternatives><tex-math id="M81">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} M_\textrm{MDE}=\frac{1}{N}\sum _{i}^{N}\Vert {\phi _{est}-\phi _{gt}}\Vert \end{aligned}$$\end{document}</tex-math><mml:math id="M82" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>M</mml:mi><mml:mtext>MDE</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:mrow><mml:mo stretchy="false">‖</mml:mo><mml:mrow><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi mathvariant="italic">est</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi mathvariant="italic">gt</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">‖</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="11548_2023_2960_Article_Equ5.gif" position="anchor"/></alternatives></disp-formula><italic>N</italic> is the size of the test dataset, <inline-formula id="IEq37"><alternatives><tex-math id="M83">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\phi _{est}$$\end{document}</tex-math><mml:math id="M84"><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi mathvariant="italic">est</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq37.gif"/></alternatives></inline-formula> is the estimated displacement field of a sample, and <inline-formula id="IEq38"><alternatives><tex-math id="M85">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\phi _{gt}$$\end{document}</tex-math><mml:math id="M86"><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi mathvariant="italic">gt</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq38.gif"/></alternatives></inline-formula> is the corresponding ground truth.<fig id="Fig3"><label>Fig. 3</label><caption><p><bold>a</bold> shows the relation between the MDE of synthetic samples and the visible points ratio, which is calculated as the ratio between the point number of a target point cloud to the corresponding ground truth point cloud: <inline-formula id="IEq39"><alternatives><tex-math id="M87">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$|{P_{inv} }|{ /} |{\tilde{T}}|{} $$\end{document}</tex-math><mml:math id="M88"><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi mathvariant="italic">inv</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mo stretchy="false">/</mml:mo><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mover accent="true"><mml:mi>T</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mrow/></mml:mrow></mml:mrow></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq39.gif"/></alternatives></inline-formula>. The decreasing trend shows that with more points available in the target in vivo point clouds, the neural network tends to predict better deformation. <bold>b</bold> Depicts the MDE to the initial rigid registration error which is produced by the NgeNet. The better the initial rigid registration and correspondence set predicted by NgeNet, the lower the global non-rigid registration error from NDP becomes</p></caption><graphic xlink:href="11548_2023_2960_Fig3_HTML" id="MO8"/></fig></p>
    <p id="Par21"><bold>In Silico</bold> A synthetic dataset is generated using the pipeline described in “Synthetic data generation” with the same boundary conditions, and the target shape variants are unseen to the neural network during training. For each target shape, we estimated the displacement field for the identical template point cloud using C2P-Net trained on 20,000 samples. The mean target displacement field for the synthetic dataset is 1.54 mm. Figure <xref rid="Fig3" ref-type="fig">3</xref>a illustrates that the neural network tends to predict the deformation of the ex vivo point cloud with higher accuracy if it obtains more information about the target in vivo OCT point cloud. With few exceptions, Fig. <xref rid="Fig3" ref-type="fig">3</xref>b shows when the initial registration error made by NgeNet is low, the final global non-rigid displacement field from NDP tends to be small.<fig id="Fig4"><label>Fig. 4</label><caption><p>Registration results of baseline models and C2P-Net on synthetic (SYN) and real OCT samples (REAL). Blue point clouds are the deformed ex vivo ear models, i.e., the shape template, calculated by all the investigated methods. The orange point clouds stand for the registration target, i.e., in vivo point clouds. From the visualization, we can see baseline non-rigid methods, NICP and CPD, tend to squeeze the points from the ex vivo template largely to match the target point clouds, since they only focus on the position of local points, while C2P-Net retains the global geometry of the middle ear due to the learned correspondence knowledge between the ex and in vivo point clouds</p></caption><graphic xlink:href="11548_2023_2960_Fig4_HTML" id="MO9"/></fig></p>
    <p id="Par22"><bold>In Vivo</bold> A real OCT dataset with 9 samples of the human middle ear was collected with a handheld OCT imaging system [<xref ref-type="bibr" rid="CR5">5</xref>] and segmented manually by surgeons within 3D Slicer along with a set of sparse landmarks for each structure of a sample (see Fig. <xref rid="Fig1" ref-type="fig">1</xref>). Since there is no ground truth correspondence available for the source and target point clouds to calculate <inline-formula id="IEq40"><alternatives><tex-math id="M89">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$M_\textrm{MDE}$$\end{document}</tex-math><mml:math id="M90"><mml:msub><mml:mi>M</mml:mi><mml:mtext>MDE</mml:mtext></mml:msub></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq40.gif"/></alternatives></inline-formula>, we introduce another metric based on the sparse landmarks:<disp-formula id="Equ6"><label>6</label><alternatives><tex-math id="M91">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} M_\textrm{L}=\frac{1}{|{L_{exv}}|}\sum _{l_{i,k}\in {L_{exv}}}\mathop {\textrm{min}}\limits _{l_{j,k}\in {L_{inv}}}\Vert {l_{i,k}-l_{j,k}}\Vert \,_{k=1,2,...,K} \end{aligned}$$\end{document}</tex-math><mml:math id="M92" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>M</mml:mi><mml:mtext>L</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi mathvariant="italic">exv</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:msub><mml:mi>l</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi mathvariant="italic">exv</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munder><mml:munder><mml:mtext>min</mml:mtext><mml:mrow><mml:msub><mml:mi>l</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi mathvariant="italic">inv</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munder><mml:mrow><mml:mo stretchy="false">‖</mml:mo><mml:mrow><mml:msub><mml:mi>l</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mi>l</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">‖</mml:mo></mml:mrow><mml:msub><mml:mspace width="0.166667em"/><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>,</mml:mo><mml:mi>K</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="11548_2023_2960_Article_Equ6.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq41"><alternatives><tex-math id="M93">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$L_{exv}$$\end{document}</tex-math><mml:math id="M94"><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi mathvariant="italic">exv</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq41.gif"/></alternatives></inline-formula> are the landmarks on the ex vivo point cloud from <inline-formula id="IEq42"><alternatives><tex-math id="M95">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mu $$\end{document}</tex-math><mml:math id="M96"><mml:mi>μ</mml:mi></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq42.gif"/></alternatives></inline-formula>CT, which is also marked manually, <inline-formula id="IEq43"><alternatives><tex-math id="M97">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$L_{inv}$$\end{document}</tex-math><mml:math id="M98"><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi mathvariant="italic">inv</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq43.gif"/></alternatives></inline-formula> are the corresponding landmarks on the target in vivo point cloud, and the landmark points belong to <italic>K</italic> different segmentations.</p>
    <p id="Par23">Table <xref rid="Tab1" ref-type="table">1</xref> itemizes the registration results of C2P-Net and baseline models on both datasets. We can observe our registration pipeline outperforms the other methods in terms of <inline-formula id="IEq44"><alternatives><tex-math id="M99">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$M_\textrm{MDE}$$\end{document}</tex-math><mml:math id="M100"><mml:msub><mml:mi>M</mml:mi><mml:mtext>MDE</mml:mtext></mml:msub></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq44.gif"/></alternatives></inline-formula> and <inline-formula id="IEq45"><alternatives><tex-math id="M101">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$M_\textrm{L}$$\end{document}</tex-math><mml:math id="M102"><mml:msub><mml:mi>M</mml:mi><mml:mtext>L</mml:mtext></mml:msub></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq45.gif"/></alternatives></inline-formula>. However, baseline models tend to have smaller <inline-formula id="IEq46"><alternatives><tex-math id="M103">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$M_\textrm{CD}$$\end{document}</tex-math><mml:math id="M104"><mml:msub><mml:mi>M</mml:mi><mml:mtext>CD</mml:mtext></mml:msub></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq46.gif"/></alternatives></inline-formula>, which means the source point clouds are deformed largely to fit the target regardless of the anatomical geometry of the middle ear. Furthermore, this issue is demonstrated visually in Fig. <xref rid="Fig4" ref-type="fig">4</xref>, which depicts several registration results from C2P-Net and baseline models on real OCT samples. Hence, it is manifested that C2P-Net is able to register the partial target point cloud without losing the underlying geometry of source point clouds, which is the critical information clinicians want to obtain with registration. On the contrary, the baseline models only focus on the spatial position of local points regardless of the neighboring and global geometry of the middle ear template.<table-wrap id="Tab1"><label>Table 1</label><caption><p>Experiments results on synthetic data (SYN) and real OCT data (REAL), including mean displacement error (<inline-formula id="IEq47"><alternatives><tex-math id="M105">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$M_\textrm{MDE}$$\end{document}</tex-math><mml:math id="M106"><mml:msub><mml:mi>M</mml:mi><mml:mtext>MDE</mml:mtext></mml:msub></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq47.gif"/></alternatives></inline-formula>)[mm], landmarks error (<inline-formula id="IEq48"><alternatives><tex-math id="M107">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$M_\textrm{L}$$\end{document}</tex-math><mml:math id="M108"><mml:msub><mml:mi>M</mml:mi><mml:mtext>L</mml:mtext></mml:msub></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq48.gif"/></alternatives></inline-formula>)[mm] and Chamfer distance (<inline-formula id="IEq49"><alternatives><tex-math id="M109">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$M_\textrm{CD}$$\end{document}</tex-math><mml:math id="M110"><mml:msub><mml:mi>M</mml:mi><mml:mtext>CD</mml:mtext></mml:msub></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq49.gif"/></alternatives></inline-formula>)[mm]</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left"/><th align="left" colspan="3">SYN</th><th align="left" colspan="2">REAL</th></tr><tr><th align="left"/><th align="left"><inline-formula id="IEq50"><alternatives><tex-math id="M111">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$M_\textrm{MDE}\downarrow $$\end{document}</tex-math><mml:math id="M112"><mml:mrow><mml:msub><mml:mi>M</mml:mi><mml:mtext>MDE</mml:mtext></mml:msub><mml:mrow><mml:mo stretchy="false">↓</mml:mo></mml:mrow></mml:mrow></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq50.gif"/></alternatives></inline-formula></th><th align="left"><inline-formula id="IEq51"><alternatives><tex-math id="M113">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$M_\textrm{CD}\dagger $$\end{document}</tex-math><mml:math id="M114"><mml:mrow><mml:msub><mml:mi>M</mml:mi><mml:mtext>CD</mml:mtext></mml:msub><mml:mo>†</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq51.gif"/></alternatives></inline-formula></th><th align="left"><inline-formula id="IEq52"><alternatives><tex-math id="M115">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$M_\textrm{L}\downarrow $$\end{document}</tex-math><mml:math id="M116"><mml:mrow><mml:msub><mml:mi>M</mml:mi><mml:mtext>L</mml:mtext></mml:msub><mml:mrow><mml:mo stretchy="false">↓</mml:mo></mml:mrow></mml:mrow></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq52.gif"/></alternatives></inline-formula></th><th align="left"><inline-formula id="IEq53"><alternatives><tex-math id="M117">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$M_\textrm{L}\downarrow $$\end{document}</tex-math><mml:math id="M118"><mml:mrow><mml:msub><mml:mi>M</mml:mi><mml:mtext>L</mml:mtext></mml:msub><mml:mrow><mml:mo stretchy="false">↓</mml:mo></mml:mrow></mml:mrow></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq53.gif"/></alternatives></inline-formula></th><th align="left"><inline-formula id="IEq54"><alternatives><tex-math id="M119">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$M_\textrm{CD}\dagger $$\end{document}</tex-math><mml:math id="M120"><mml:mrow><mml:msub><mml:mi>M</mml:mi><mml:mtext>CD</mml:mtext></mml:msub><mml:mo>†</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq54.gif"/></alternatives></inline-formula></th></tr></thead><tbody><tr><td align="left">ICP<inline-formula id="IEq55"><alternatives><tex-math id="M121">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$^*$$\end{document}</tex-math><mml:math id="M122"><mml:msup><mml:mrow/><mml:mo>∗</mml:mo></mml:msup></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq55.gif"/></alternatives></inline-formula></td><td align="left">2.01</td><td align="left">1.85</td><td align="left">1.15</td><td align="left">4.74</td><td align="left">3.03</td></tr><tr><td align="left">NICP</td><td align="left">4.61</td><td align="left"><bold>0</bold>.<bold>22</bold></td><td align="left">0.87</td><td align="left">4.39</td><td align="left">0.68</td></tr><tr><td align="left">CPD</td><td align="left">8.79</td><td align="left">1.07</td><td align="left">0.96</td><td align="left">2.17</td><td align="left"><bold>0</bold>.<bold>059</bold></td></tr><tr><td align="left">C2P-Net (ours)</td><td align="left"><bold>0</bold>.<bold>781</bold></td><td align="left">0.582</td><td align="left"><bold>0</bold>.<bold>424</bold></td><td align="left"><bold>0</bold>.<bold>808</bold></td><td align="left">2.43</td></tr></tbody></table><table-wrap-foot><p>The bold numbers indicate the best-performing methods on each metric</p><p><inline-formula id="IEq56"><alternatives><tex-math id="M123">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$*$$\end{document}</tex-math><mml:math id="M124"><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq56.gif"/></alternatives></inline-formula> rigid registration method(s)</p><p><inline-formula id="IEq57"><alternatives><tex-math id="M125">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\dagger $$\end{document}</tex-math><mml:math id="M126"><mml:mo>†</mml:mo></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq57.gif"/></alternatives></inline-formula> baseline methods tend to fall into local minima and ignore the geometry, though the CD is lower</p></table-wrap-foot></table-wrap></p>
  </sec>
  <sec id="Sec7">
    <title>Conclusion</title>
    <p id="Par24">In this work, we propose to improve the interpretation of OCT data for surgical diagnosis by fusing the knowledge from ex vivo and general <inline-formula id="IEq58"><alternatives><tex-math id="M127">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mu $$\end{document}</tex-math><mml:math id="M128"><mml:mi>μ</mml:mi></mml:math><inline-graphic xlink:href="11548_2023_2960_Article_IEq58.gif"/></alternatives></inline-formula>CT data with the in vivo noisy and incomplete OCT data. To this end, we propose C2P-Net which is based on NgeNet and Neural Deformation Pyramid. It takes the ex and in vivo 3D point clouds as input and explores the sparse correspondence between the two, then aligns them in a non-rigid fashion. Due to the lack of training data, a fast and effective synthetic simulation pipeline was designed using Blender3D, which produces noisy and partial point clouds as seen in vivo based on the randomly generated shape variants of the middle ear. Our neural network was trained based on 20,000 synthetic samples, and it took around 3.5 s to predict the displacement field for a given in vivo point cloud at inference time.</p>
    <p id="Par25">To assess the performance of C2P-Net, experiments on synthetic and real OCT datasets were carried out. Since the real OCT data are noisy and incomplete, we investigated various metrics including mean displacement error, landmark error, and Chamfer distance and compared C2P-Net to the other baseline models from both statistics and geometry aspects. From Table <xref rid="Tab1" ref-type="table">1</xref> and Fig. <xref rid="Fig4" ref-type="fig">4</xref>, we can see that C2P-Net is able to deal with the partial OCT data and retain the anatomical structure during non-rigid registration, while other non-rigid methods do not understand the global geometry of the point clouds and focus only on local points.</p>
    <p id="Par26">Future work will focus on improving registration accuracy. This can be achieved by improving the simulation pipeline with realistic noise to further bridge the gap between synthetic and real data. Furthermore, the segmentation information can be employed by the network to improve the prediction of correspondences. Apart from this, inference time can be further decreased by exploring the optimal configuration of the network for the OCT samples.</p>
  </sec>
</body>
<back>
  <fn-group>
    <fn>
      <p>
        <bold>Publisher's Note</bold>
      </p>
      <p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
    </fn>
  </fn-group>
  <ack>
    <title>Acknowledgements</title>
    <p>Funded by the Else Kröner Fresenius Centre for Digital Health.</p>
  </ack>
  <notes notes-type="funding-information">
    <title>Funding Information</title>
    <p>Open Access funding enabled and organized by Projekt DEAL.</p>
  </notes>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <label>1.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zwislocki</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Normal function of the middle ear and its measurement</article-title>
        <source>Audiology</source>
        <year>1982</year>
        <volume>21</volume>
        <issue>1</issue>
        <fpage>4</fpage>
        <lpage>14</lpage>
        <pub-id pub-id-type="doi">10.3109/00206098209072723</pub-id>
        <?supplied-pmid 7055478?>
        <pub-id pub-id-type="pmid">7055478</pub-id>
      </element-citation>
    </ref>
    <ref id="CR2">
      <label>2.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Won</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Monroy</surname>
            <given-names>GL</given-names>
          </name>
          <name>
            <surname>Dsouza</surname>
            <given-names>RI</given-names>
          </name>
          <name>
            <surname>Spillman</surname>
            <given-names>DR</given-names>
          </name>
          <name>
            <surname>McJunkin</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Porter</surname>
            <given-names>RG</given-names>
          </name>
          <name>
            <surname>Shi</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Aksamitiene</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Sherwood</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Stiger</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Boppart</surname>
            <given-names>SA</given-names>
          </name>
        </person-group>
        <article-title>Handheld briefcase optical coherence tomography with real-time machine learning classifier for middle ear infections</article-title>
        <source>Biosensors</source>
        <year>2021</year>
        <volume>11</volume>
        <issue>5</issue>
        <fpage>143</fpage>
        <lpage>156</lpage>
        <pub-id pub-id-type="doi">10.3390/bios11050143</pub-id>
        <?supplied-pmid 34063695?>
        <pub-id pub-id-type="pmid">34063695</pub-id>
      </element-citation>
    </ref>
    <ref id="CR3">
      <label>3.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Won</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Porter</surname>
            <given-names>RG</given-names>
          </name>
          <name>
            <surname>Novak</surname>
            <given-names>MA</given-names>
          </name>
          <name>
            <surname>Youakim</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Sum</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Barkalifa</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Aksamitiene</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Nolan</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Shelton</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Boppart</surname>
            <given-names>SA</given-names>
          </name>
        </person-group>
        <article-title>In vivo dynamic characterization of the human tympanic membrane using pneumatic optical coherence tomography</article-title>
        <source>J Biophotonics</source>
        <year>2021</year>
        <volume>14</volume>
        <issue>4</issue>
        <fpage>1</fpage>
        <lpage>12</lpage>
        <pub-id pub-id-type="doi">10.1002/jbio.202000215</pub-id>
      </element-citation>
    </ref>
    <ref id="CR4">
      <label>4.</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Snow</surname>
            <given-names>JB</given-names>
          </name>
          <name>
            <surname>Wackym</surname>
            <given-names>PA</given-names>
          </name>
          <name>
            <surname>Ballenger</surname>
            <given-names>JJ</given-names>
          </name>
        </person-group>
        <source>Ballenger’s otorhinolaryngology: head and neck surgery</source>
        <year>2009</year>
        <publisher-loc>Hamilton, ON</publisher-loc>
        <publisher-name>BC Decker</publisher-name>
      </element-citation>
    </ref>
    <ref id="CR5">
      <label>5.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Morgenstern</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Schindler</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Kirsten</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Golde</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Bornitz</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Kemper</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Koch</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Zahnert</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Neudert</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>Endoscopic optical coherence tomography for evaluation of success of tympanoplasty</article-title>
        <source>Otol Neurotol</source>
        <year>2020</year>
        <volume>41</volume>
        <issue>7</issue>
        <fpage>901</fpage>
        <lpage>905</lpage>
        <pub-id pub-id-type="doi">10.1097/MAO.0000000000002486</pub-id>
        <pub-id pub-id-type="pmid">32310837</pub-id>
      </element-citation>
    </ref>
    <ref id="CR6">
      <label>6.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Monroy</surname>
            <given-names>GL</given-names>
          </name>
          <name>
            <surname>Won</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Dsouza</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Pande</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Hill</surname>
            <given-names>MC</given-names>
          </name>
          <name>
            <surname>Porter</surname>
            <given-names>RG</given-names>
          </name>
          <name>
            <surname>Novak</surname>
            <given-names>MA</given-names>
          </name>
          <name>
            <surname>Spillman</surname>
            <given-names>DR</given-names>
          </name>
          <name>
            <surname>Boppart</surname>
            <given-names>SA</given-names>
          </name>
        </person-group>
        <article-title>Automated classification platform for the identification of otitis media using optical coherence tomography</article-title>
        <source>NPJ Dig Med</source>
        <year>2019</year>
        <volume>2</volume>
        <issue>1</issue>
        <fpage>1</fpage>
        <lpage>22</lpage>
      </element-citation>
    </ref>
    <ref id="CR7">
      <label>7.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Monroy</surname>
            <given-names>GL</given-names>
          </name>
          <name>
            <surname>Shelton</surname>
            <given-names>RL</given-names>
          </name>
          <name>
            <surname>Nolan</surname>
            <given-names>RM</given-names>
          </name>
          <name>
            <surname>Nguyen</surname>
            <given-names>CT</given-names>
          </name>
          <name>
            <surname>Novak</surname>
            <given-names>MA</given-names>
          </name>
          <name>
            <surname>Hill</surname>
            <given-names>MC</given-names>
          </name>
          <name>
            <surname>McCormick</surname>
            <given-names>DT</given-names>
          </name>
          <name>
            <surname>Boppart</surname>
            <given-names>SA</given-names>
          </name>
        </person-group>
        <article-title>Noninvasive depth-resolved optical measurements of the tympanic membrane and middle ear for differentiating otitis media</article-title>
        <source>Laryngoscope</source>
        <year>2015</year>
        <volume>125</volume>
        <issue>8</issue>
        <fpage>276</fpage>
        <lpage>282</lpage>
        <pub-id pub-id-type="doi">10.1002/lary.25141</pub-id>
      </element-citation>
    </ref>
    <ref id="CR8">
      <label>8.</label>
      <mixed-citation publication-type="other">Brock A, Lim T, Ritchie JM, Weston NJ (2016) Generative and discriminative voxel modeling with convolutional neural networks. In: Neural inofrmation processing conference: 3D deep learning</mixed-citation>
    </ref>
    <ref id="CR9">
      <label>9.</label>
      <mixed-citation publication-type="other">Su H, Maji S, Kalogerakis E, Learned-Miller E (2015) Multi-view convolutional neural networks for 3d shape recognition. In: Proceedings of the IEEE international conference on computer vision, p 945–953</mixed-citation>
    </ref>
    <ref id="CR10">
      <label>10.</label>
      <mixed-citation publication-type="other">Feng Y, Zhang Z, Zhao X, Ji R, Gao Y (2018) Gvcnn: group-view convolutional neural networks for 3d shape recognition. In: Proceedings of the IEEE conference on computer vision and pattern recognition, p 264–272</mixed-citation>
    </ref>
    <ref id="CR11">
      <label>11.</label>
      <mixed-citation publication-type="other">Qi CR, Su H, Nießner M, Dai A, Yan M, Guibas LJ (2016) Volumetric and multi-view cnns for object classification on 3d data. In: Proceedings of the IEEE conference on computer vision and pattern recognition, p 5648–5656</mixed-citation>
    </ref>
    <ref id="CR12">
      <label>12.</label>
      <mixed-citation publication-type="other">Qi CR, Su H, Mo K, Guibas LJ (2017) Pointnet: deep learning on point sets for 3d classification and segmentation. In: Proceedings of the IEEE conference on computer vision and pattern recognition, p 652–660</mixed-citation>
    </ref>
    <ref id="CR13">
      <label>13.</label>
      <mixed-citation publication-type="other">Qi CR, Yi L, Su H, Guibas LJ (2017) Pointnet++: deep hierarchical feature learning on point sets in a metric space. In: Advances in neural information processing systems, vol 30</mixed-citation>
    </ref>
    <ref id="CR14">
      <label>14.</label>
      <mixed-citation publication-type="other">Thomas H, Qi CR, Deschaud J-E, Marcotegui B, Goulette F, Guibas LJ (2019) Kpconv: flexible and deformable convolution for point clouds. In: Proceedings of the IEEE/CVF international conference on computer vision, p 6411–6420</mixed-citation>
    </ref>
    <ref id="CR15">
      <label>15.</label>
      <mixed-citation publication-type="other">Xu Y, Fan T, Xu M, Zeng L, Qiao Y (2018) Spidercnn: deep learning on point sets with parameterized convolutional filters. In: Proceedings of the European conference on computer vision (ECCV), p 87–102</mixed-citation>
    </ref>
    <ref id="CR16">
      <label>16.</label>
      <mixed-citation publication-type="other">Choy C, Park J, Koltun V (2019) Fully convolutional geometric features. In: Proceedings of the IEEE/CVF international conference on computer vision, p 8958–8966</mixed-citation>
    </ref>
    <ref id="CR17">
      <label>17.</label>
      <mixed-citation publication-type="other">Besl PJ, McKay ND (1992) Method for registration of 3-d shapes. Sensor fusion IV: control paradigms and data structures, vol 1611. Spie, Bellingham, pp 586–606</mixed-citation>
    </ref>
    <ref id="CR18">
      <label>18.</label>
      <mixed-citation publication-type="other">Amberg B, Romdhani S, Vetter T (2007) Optimal step nonrigid icp algorithms for surface registration. In: 2007 IEEE conference on computer vision and pattern recognition, IEEE, p 1–8</mixed-citation>
    </ref>
    <ref id="CR19">
      <label>19.</label>
      <mixed-citation publication-type="other">Aoki Y, Goforth H, Srivatsan RA, Lucey S (2019) Pointnetlk: robust &amp; efficient point cloud registration using pointnet. In: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, p 7163–7172</mixed-citation>
    </ref>
    <ref id="CR20">
      <label>20.</label>
      <mixed-citation publication-type="other">Yew ZJ, Lee GH (2022) Regtr: end-to-end point cloud correspondences with transformers. In: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, p 6677–6686</mixed-citation>
    </ref>
    <ref id="CR21">
      <label>21.</label>
      <mixed-citation publication-type="other">Zhu L, Guan H, Lin C, Han R (2022) Neighborhood-aware geometric encoding network for point cloud registration. arXiv preprint <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/2201.12094">arXiv:2201.12094</ext-link></mixed-citation>
    </ref>
    <ref id="CR22">
      <label>22.</label>
      <mixed-citation publication-type="other">Li Y, Harada T (2022) Non-rigid point cloud registration with neural deformation pyramid. arXiv preprint <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/2205.12796">arXiv:2205.12796</ext-link></mixed-citation>
    </ref>
    <ref id="CR23">
      <label>23.</label>
      <mixed-citation publication-type="other">Lucas BD, Kanade T (1981) An iterative image registration technique with an application to stereo vision. In: IJCAI’81: 7th international joint conference on artificial intelligence, p 674–679</mixed-citation>
    </ref>
  </ref-list>
</back>
