<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinform Adv</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinform Adv</journal-id>
    <journal-id journal-id-type="publisher-id">bioadv</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics Advances</journal-title>
    </journal-title-group>
    <issn pub-type="epub">2635-0041</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">10751232</article-id>
    <article-id pub-id-type="doi">10.1093/bioadv/vbad185</article-id>
    <article-id pub-id-type="publisher-id">vbad185</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Original Article</subject>
        <subj-group subj-group-type="category-toc-heading">
          <subject>Systems Biology</subject>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI01060</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>StabJGL: a stability approach to sparsity and similarity selection in multiple-network reconstruction</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0003-2701-5686</contrib-id>
        <name>
          <surname>Lingjærde</surname>
          <given-names>Camilla</given-names>
        </name>
        <aff><institution>MRC Biostatistics Unit, University of Cambridge</institution>, Cambridge CB2 0SR, <country country="GB">United Kingdom</country></aff>
        <xref rid="vbad185-cor1" ref-type="corresp"/>
        <!--camilla.lingjaerde@mrc-bsu.cam.ac.uk-->
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Richardson</surname>
          <given-names>Sylvia</given-names>
        </name>
        <aff><institution>MRC Biostatistics Unit, University of Cambridge</institution>, Cambridge CB2 0SR, <country country="GB">United Kingdom</country></aff>
      </contrib>
    </contrib-group>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Lengauer</surname>
          <given-names>Thomas</given-names>
        </name>
        <role>Associate Editor</role>
      </contrib>
    </contrib-group>
    <author-notes>
      <corresp id="vbad185-cor1">Corresponding author. MRC Biostatistics Unit, University of Cambridge, East Forvie Building, Forvie Site, Robinson Way, Cambridge CB2 0SR, United Kingdom. E-mail: <email>camilla.lingjaerde@mrc-bsu.cam.ac.uk</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2023-12-19">
      <day>19</day>
      <month>12</month>
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>19</day>
      <month>12</month>
      <year>2023</year>
    </pub-date>
    <volume>3</volume>
    <issue>1</issue>
    <elocation-id>vbad185</elocation-id>
    <history>
      <date date-type="received">
        <day>28</day>
        <month>6</month>
        <year>2023</year>
      </date>
      <date date-type="rev-recd">
        <day>23</day>
        <month>11</month>
        <year>2023</year>
      </date>
      <date date-type="editorial-decision">
        <day>11</day>
        <month>12</month>
        <year>2023</year>
      </date>
      <date date-type="accepted">
        <day>18</day>
        <month>12</month>
        <year>2023</year>
      </date>
      <date date-type="corrected-typeset">
        <day>26</day>
        <month>12</month>
        <year>2023</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2023. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2023</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="vbad185.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Motivation</title>
        <p>In recent years, network models have gained prominence for their ability to capture complex associations. In statistical omics, networks can be used to model and study the functional relationships between genes, proteins, and other types of omics data. If a Gaussian graphical model is assumed, a gene association network can be determined from the non-zero entries of the inverse covariance matrix of the data. Due to the high-dimensional nature of such problems, integrative methods that leverage similarities between multiple graphical structures have become increasingly popular. The joint graphical lasso is a powerful tool for this purpose, however, the current AIC-based selection criterion used to tune the network sparsities and similarities leads to poor performance in high-dimensional settings.</p>
      </sec>
      <sec id="s2">
        <title>Results</title>
        <p>We propose stabJGL, which equips the joint graphical lasso with a stable and well-performing penalty parameter selection approach that combines the notion of model stability with likelihood-based similarity selection. The resulting method makes the powerful joint graphical lasso available for use in omics settings, and outperforms the standard joint graphical lasso, as well as state-of-the-art joint methods, in terms of all performance measures we consider. Applying stabJGL to proteomic data from a pan-cancer study, we demonstrate the potential for novel discoveries the method brings.</p>
      </sec>
      <sec id="s3">
        <title>Availability and implementation</title>
        <p>A user-friendly R package for stabJGL with tutorials is available on Github <ext-link xlink:href="https://github.com/Camiling/stabJGL" ext-link-type="uri">https://github.com/Camiling/stabJGL</ext-link>.</p>
      </sec>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>UK Medical Research Council programme</institution>
          </institution-wrap>
        </funding-source>
        <award-id>MRC MC UU 00002/10</award-id>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="10"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 Introduction</title>
    <p>Network models have in recent years gained great popularity in many areas. In statistical omics, networks can be used to decode aspects of unknown structures, and hence study the relationships between genes, proteins, and other types of omics data. In health data sciences, rich datasets are more and more frequently encountered, enabling the development of models integrating a variety of biological resources. In the high-dimensional setting commonly found in omics, sharing information between independent observations from data sources with shared structures—which could be different tissues, conditions or patient subgroups—can give a valuable increase in statistical power while elucidating shared biological function. A key question is how to combine the different data sources into a single model.</p>
    <p>If a Gaussian graphical model is assumed, a conditional (in)dependence network can be estimated by determining the non-zero entries of the inverse covariance (precision) matrix of the data. With its good performance in numerical studies, the “graphical lasso” (Glasso) of <xref rid="vbad185-B15" ref-type="bibr">Friedman <italic toggle="yes">et al.</italic> (2008)</xref> is a state-of-the-art method for precision matrix estimation in the setting of Gaussian graphical models. The method combines <inline-formula id="IE1"><mml:math id="IM1" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> regularization with maximum likelihood estimation. Other notable methods include the neighborhood selection approach of <xref rid="vbad185-B27" ref-type="bibr">Meinshausen and Bühlmann (2006)</xref> and the graphical SCAD (<xref rid="vbad185-B13" ref-type="bibr">Fan <italic toggle="yes">et al.</italic> 2009</xref>). Notable Bayesian methods include the Bayesian Glasso (<xref rid="vbad185-B37" ref-type="bibr">Wang 2012</xref>), Bayesian spike-and-slab approaches (<xref rid="vbad185-B36" ref-type="bibr">Wang 2015</xref>), and the graphical horseshoe (<xref rid="vbad185-B22" ref-type="bibr">Li <italic toggle="yes">et al.</italic> 2019a</xref>).</p>
    <p>If multiple related datasets available, there are several ways to leverage common network structures. If focusing on one data type’s network structure, data from other types can enhance inference via weighted Glasso methods (<xref rid="vbad185-B21" ref-type="bibr">Li and Jackson 2015</xref>, <xref rid="vbad185-B24" ref-type="bibr">Lingjærde <italic toggle="yes">et al.</italic> 2021</xref>). However, to compare network structures across datasets, such as patient subgroups, a joint approach that leverages common information while preserving the differences can increase statistical power and provide interpretable insight.</p>
    <p>In the area of multiple Gaussian graphical models, existing methods include the group extension of the Glasso to multiple networks of <xref rid="vbad185-B17" ref-type="bibr">Guo <italic toggle="yes">et al.</italic> (2011)</xref>, the Bayesian spike-and-slab joint graphical lasso (JGL) (<xref rid="vbad185-B23" ref-type="bibr">Li <italic toggle="yes">et al.</italic> 2019b</xref>), and the Markov random field approach of <xref rid="vbad185-B31" ref-type="bibr">Peterson <italic toggle="yes">et al.</italic> (2015)</xref>. The widely used JGL of <xref rid="vbad185-B12" ref-type="bibr">Danaher <italic toggle="yes">et al.</italic> (2014)</xref> extends the Glasso to a multiple-network setting and provides a powerful tool for inferring graphs with common traits. It employs two different penalty functions—group joint graphical lasso (GGL) and fused joint graphical lasso (FGL)—with the latter recommended for most applications. From this point forward, any mention of the JGL will imply the fused version, unless otherwise specified. The method needs tuning of two regularization parameters for controlling (i) the number of non-zero effects, and (ii) the similarity between networks, respectively. However, the default parameter selection routine based on the AIC (<xref rid="vbad185-B1" ref-type="bibr">Akaike <italic toggle="yes">et al.</italic> 1973</xref>) often results in severe over-selection in high-dimensional data, potentially impacting performance negatively (<xref rid="vbad185-B14" ref-type="bibr">Foygel and Drton 2010</xref>, <xref rid="vbad185-B26" ref-type="bibr">Liu <italic toggle="yes">et al.</italic> 2010</xref>).</p>
    <p>We propose a stable and well-performing penalty parameter selection method for the JGL, combining the model stability principle of <xref rid="vbad185-B26" ref-type="bibr">Liu <italic toggle="yes">et al.</italic> (2010)</xref> with likelihood-based selection for high-dimensional data (<xref rid="vbad185-B14" ref-type="bibr">Foygel and Drton 2010</xref>). The resulting method inherits the powerful traits of the JGL while mitigating the risk of severe under- or over-selection of edges in high-dimensional settings. We provide an R package, <monospace>stabJGL</monospace> (stable sparsity and similarity selection for the JGL), which implements the method.</p>
    <p>The article is organized as follows. In Section 2, we first describe the Gaussian graphical model framework and the penalized log-likelihood problem we aim to solve. We then describe our proposed algorithm. In Section 3, we demonstrate the performance of our proposed method on simulated data and apply it proteomic data from a pan-cancer study of hormonally responsive cancers. Finally, we highlight possible extensions in Section 4.</p>
  </sec>
  <sec>
    <title>2 Methods</title>
    <sec>
      <title>2.1 Gaussian graphical models</title>
      <p>In a gene network model, genes are represented by “nodes” and associations between them are represented by “edges.” Given measurable molecular units each corresponding to one gene (e.g. the encoded protein or mRNA), a network, or graph, can be constructed from their observed values.</p>
      <p>Consider <italic toggle="yes">n</italic> observed values of the multivariate random vector <inline-formula id="IE2"><mml:math id="IM2" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mi>p</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mi>T</mml:mi></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula> of node attributes, with each entry corresponding to one of <italic toggle="yes">p</italic> nodes. If we assume multivariate Gaussian node attributes, with an <inline-formula id="IE3"><mml:math id="IM3" display="inline" overflow="scroll"><mml:mrow><mml:mi>n</mml:mi><mml:mo>×</mml:mo><mml:mi>p</mml:mi></mml:mrow></mml:math></inline-formula> observation matrix <inline-formula id="IE4"><mml:math id="IM4" display="inline" overflow="scroll"><mml:mi mathvariant="bold-italic">X</mml:mi></mml:math></inline-formula> with i.i.d. rows <inline-formula id="IE5"><mml:math id="IM5" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msub></mml:mrow><mml:mo>∼</mml:mo><mml:mi mathvariant="script">N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi mathvariant="bold">Σ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, a “partial correlation network” can be determined by estimating the inverse covariance matrix, or precision matrix, <inline-formula id="IE6"><mml:math id="IM6" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold">Θ</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>. Specifically, the partial correlation between nodes <italic toggle="yes">i</italic> and <italic toggle="yes">j</italic>, conditional upon the rest of the graph, is given by
<disp-formula id="E1"><mml:math id="M1" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>ρ</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi><mml:mo>|</mml:mo><mml:mi>V</mml:mi><mml:mo>\</mml:mo><mml:mo>{</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>}</mml:mo></mml:mrow></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>θ</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mrow><mml:msqrt><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>θ</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>θ</mml:mo></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:msqrt></mml:mrow></mml:mfrac></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>
where the <inline-formula id="IE7"><mml:math id="IM7" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>θ</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>’s are the entries of <inline-formula id="IE8"><mml:math id="IM8" display="inline" overflow="scroll"><mml:mi mathvariant="bold">Θ</mml:mi></mml:math></inline-formula> and <italic toggle="yes">V</italic> the set of all node pairs (<xref rid="vbad185-B20" ref-type="bibr">Lauritzen 1996</xref>). The partial correlations coincide with the conditional correlations in the Gaussian setting. Because correlation (resp. partial correlation) equal to zero is equivalent to independence (resp. conditional independence) for Gaussian variables, a conditional independence graph can thus be constructed by determining the non-zero entries of the precision matrix. To ensure invertibility, the precision matrix also required to be positive definite, <inline-formula id="IE9"><mml:math id="IM9" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold">Θ</mml:mi><mml:mo>≻</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>.</p>
      <p>In high-dimensional settings, the sample covariance matrix <inline-formula id="IE10"><mml:math id="IM10" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold-italic">S</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfrac></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">X</mml:mi></mml:mrow><mml:mi>T</mml:mi></mml:msup></mml:mrow><mml:mi mathvariant="bold-italic">X</mml:mi></mml:mrow></mml:math></inline-formula> is rarely of full rank and thus its inverse cannot be estimated directly. It is common to assume sparse network, meaning the number of edges in the edge set <italic toggle="yes">E</italic> is small relative to the number of potential edges in the graph (i.e. the sparsity measure <inline-formula id="IE11"><mml:math id="IM11" display="inline" overflow="scroll"><mml:mrow><mml:mn>2</mml:mn><mml:mo>|</mml:mo><mml:mi>E</mml:mi><mml:mo>|</mml:mo><mml:mo>/</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mo>−</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> is small). Penalized methods, such as the Glasso (<xref rid="vbad185-B15" ref-type="bibr">Friedman <italic toggle="yes">et al.</italic> 2008</xref>) are well established for sparse Gaussian graphical model estimation. In the case of there being multiple (related) datasets available, such as from different tissue types, rather than estimating each network separately much statistical power could be gained by sharing information across networks through a joint approach.</p>
    </sec>
    <sec>
      <title>2.2 Penalized log-likelihood problem</title>
      <p>Assume a network inference problem with <italic toggle="yes">K</italic> groups. We let <inline-formula id="IE12"><mml:math id="IM12" display="inline" overflow="scroll"><mml:mrow><mml:mo>{</mml:mo><mml:mi mathvariant="bold">Θ</mml:mi><mml:mo>}</mml:mo><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">Θ</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">Θ</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>K</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> be the set of their (unknown) precision matrices, and assume that the set of <inline-formula id="IE13"><mml:math id="IM13" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:munderover></mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> observations are independent. We aim to solve the penalized log-likelihood problem (<xref rid="vbad185-B12" ref-type="bibr">Danaher <italic toggle="yes">et al.</italic> 2014</xref>)
<disp-formula id="E2"><label>(1)</label><mml:math id="M2" display="block" overflow="scroll"><mml:mtable><mml:mtr><mml:mtd><mml:mtable><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">Θ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo>}</mml:mo></mml:mrow><mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:munder><mml:mrow><mml:mtext>argmax</mml:mtext></mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mi mathvariant="bold">Θ</mml:mi><mml:mo>≻</mml:mo><mml:mn>0</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:munder></mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:munderover></mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mtext>log</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mi>det</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">Θ</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mtext>tr</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">S</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">Θ</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>−</mml:mo><mml:mi mathvariant="normal">P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>{</mml:mo><mml:mi mathvariant="bold">Θ</mml:mi><mml:mo>}</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>}</mml:mo><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>
where <inline-formula id="IE14"><mml:math id="IM14" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">S</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula> is the sample covariance matrix of group <italic toggle="yes">k</italic> and <inline-formula id="IE15"><mml:math id="IM15" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="normal">P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>⋅</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> is a penalty function. In (1), <inline-formula id="IE16"><mml:math id="IM16" display="inline" overflow="scroll"><mml:mrow><mml:mi>det</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>⋅</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> denotes the determinant and <inline-formula id="IE17"><mml:math id="IM17" display="inline" overflow="scroll"><mml:mrow><mml:mtext>tr</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mo>⋅</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> denotes the trace. The JGL employs the fused penalty function
<disp-formula id="E3"><label>(2)</label><mml:math id="M3" display="block" overflow="scroll"><mml:mrow><mml:mi mathvariant="normal">P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>{</mml:mo><mml:mi mathvariant="bold">Θ</mml:mi><mml:mo>}</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:munderover></mml:mrow><mml:mrow><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>≠</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mtext>abs</mml:mtext></mml:mrow></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mo>θ</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>&lt;</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msup></mml:mrow></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mo>|</mml:mo></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">Θ</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">Θ</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>
where <inline-formula id="IE18"><mml:math id="IM18" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE19"><mml:math id="IM19" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> are positive penalty parameters, <inline-formula id="IE20"><mml:math id="IM20" display="inline" overflow="scroll"><mml:mrow><mml:mtext>abs</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mo>⋅</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> denotes the absolute value function and <inline-formula id="IE21"><mml:math id="IM21" display="inline" overflow="scroll"><mml:mrow><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:mo>⋅</mml:mo><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> denotes the <inline-formula id="IE22"><mml:math id="IM22" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">L</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> penalty. This penalty applies <inline-formula id="IE23"><mml:math id="IM23" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">L</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> penalties to each off-diagonal element of the <italic toggle="yes">K</italic> precision matrices as well as to the differences between corresponding elements of each pair of precision matrices. The parameter <inline-formula id="IE24"><mml:math id="IM24" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> controls the sparsity, and the similarity parameter <inline-formula id="IE25"><mml:math id="IM25" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> controls the degree to which the <italic toggle="yes">K</italic> precision matrices are forced toward each other, encouraging not only similar network structures but also similar precision matrix entries. This way, the dependency between observed datasets is modeled through their underlying graphical structures. It is important to note that a necessary assumption of the resulting model is that given their respective graphical structures, observations are independent across and within each dataset. The current penalty parameter selection approach for <inline-formula id="IE26"><mml:math id="IM26" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE27"><mml:math id="IM27" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> is based on the AIC (<xref rid="vbad185-B12" ref-type="bibr">Danaher <italic toggle="yes">et al.</italic> 2014</xref>), and while suitable for determining network similarities, likelihood-based selection criteria can lead to severe under- or over-selection and thus poor performance in high-dimensional settings (<xref rid="vbad185-B26" ref-type="bibr">Liu <italic toggle="yes">et al.</italic> 2010</xref>).</p>
    </sec>
    <sec>
      <title>2.3 The stabJGL algorithm</title>
      <p>To improve the performance of the JGL with the fused penalty for omics applications and other high-dimensional problems, we propose the stabJGL algorithm for stable sparsity and similarity selection in multiple-network reconstruction. StabJGL jointly estimates multiple networks by leveraging their common information and gives a basis for deeper exploration of their differences, as shown in <xref rid="vbad185-F1" ref-type="fig">Fig. 1</xref>. Below we outline the algorithm, which comprised two steps: (i) selecting the sparsity parameter <inline-formula id="IE28"><mml:math id="IM28" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> in the fused penalty (2) based on the notion of model stability, and (ii) selecting the similarity parameter <inline-formula id="IE29"><mml:math id="IM29" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> based on model likelihood. The full StabJGL algorithm is given in <xref rid="sup1" ref-type="supplementary-material">Supplementary Algorithm S1</xref>.</p>
      <fig position="float" id="vbad185-F1">
        <label>Figure 1.</label>
        <caption>
          <p>The workflow of stabJGL, where the network structures of different data types or conditions are jointly estimated and can then be compared.</p>
        </caption>
        <graphic xlink:href="vbad185f1" position="float"/>
      </fig>
      <sec>
        <title>2.3.1 Selecting <inline-formula id="IE30"><mml:math id="IM30" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">λ</mml:mi></mml:mrow><mml:mi mathvariant="bold">1</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula></title>
        <p>We first select <inline-formula id="IE31"><mml:math id="IM31" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> by extending the framework introduced by <xref rid="vbad185-B26" ref-type="bibr">Liu <italic toggle="yes">et al.</italic> (2010)</xref> in their Stability Approach to regularization Criterion (StARS) to a multiple-network setting. The aim is to select the least amount of penalization that makes graphs sparse as well as reproducible under random subsampling. This is done by drawing many random subsamples from each of the <italic toggle="yes">K</italic> data types and using them to construct JGL graphs over a range of <inline-formula id="IE32"><mml:math id="IM32" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> values. The smallest parameter value for which a given graph estimation variability measure does not surpass a specified threshold is then selected. We use a measure of edge assignment instability across subsamples to quantify the variability.</p>
        <p>Specifically, we consider a grid of <inline-formula id="IE33"><mml:math id="IM33" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> values in a suitable interval, i.e. <inline-formula id="IE34"><mml:math id="IM34" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></inline-formula> and keep the similarity parameter <inline-formula id="IE35"><mml:math id="IM35" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> fixed to some small value, such as 0.01 in the first instance. For <inline-formula id="IE36"><mml:math id="IM36" display="inline" overflow="scroll"><mml:mrow><mml:mo>η</mml:mo><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mtext>sample</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>, we draw a random subsample from each group <italic toggle="yes">k’</italic>s set of <inline-formula id="IE37"><mml:math id="IM37" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> observations without replacement, each of size <inline-formula id="IE38"><mml:math id="IM38" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msub></mml:mrow><mml:mo>&lt;</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>. For each value of <inline-formula id="IE39"><mml:math id="IM39" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> to consider, we next construct the corresponding set of JGL graphs <inline-formula id="IE40"><mml:math id="IM40" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>η</mml:mo></mml:msubsup></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>}</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula> from these <italic toggle="yes">K</italic> sets of subsamples, using the fused penalty (2).</p>
        <p>The following is then done for each value of <inline-formula id="IE41"><mml:math id="IM41" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> we consider. For each group <inline-formula id="IE42"><mml:math id="IM42" display="inline" overflow="scroll"><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>K</mml:mi></mml:mrow></mml:math></inline-formula> and all possible node pairs <inline-formula id="IE43"><mml:math id="IM43" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> we estimate the probability of an edge between the nodes over the <inline-formula id="IE44"><mml:math id="IM44" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mtext>sample</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> inferred sets of graphs
<disp-formula id="E4"><label>(3)</label><mml:math id="M4" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>ψ</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mtext>sample</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mfrac></mml:mrow><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mo>η</mml:mo><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mtext>sample</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:munderover></mml:mrow><mml:mrow><mml:mi mathvariant="double-struck">1</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>∈</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>η</mml:mo></mml:msubsup></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>
where <inline-formula id="IE45"><mml:math id="IM45" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="double-struck">1</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mo>⋅</mml:mo><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the indicator function. Using this estimated probability, we find
<disp-formula id="E5"><label>(4)</label><mml:math id="M5" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>ξ</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>ψ</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>ψ</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>
which is an estimate of two times the variance of the Bernoulli indicator of the edge <inline-formula id="IE46"><mml:math id="IM46" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> in group <italic toggle="yes">k</italic>. It lies in [0, 0.5] and can be regarded as an estimate of the proportion of times two inferred graphs for group <italic toggle="yes">k</italic> found with the given <inline-formula id="IE47"><mml:math id="IM47" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> value will disagree on the presence of the edge <inline-formula id="IE48"><mml:math id="IM48" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>. Due to the <inline-formula id="IE49"><mml:math id="IM49" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> penalty in (2), the number of inferred edges will decrease as <inline-formula id="IE50"><mml:math id="IM50" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> is increased.</p>
        <p>For a given <inline-formula id="IE51"><mml:math id="IM51" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>, <inline-formula id="IE52"><mml:math id="IM52" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>ξ</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> can be regarded as a measure of the variability of the edge <inline-formula id="IE53"><mml:math id="IM53" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> in group <italic toggle="yes">k</italic> across subsamples, and the total variability of graph <italic toggle="yes">k</italic> can be measured by averaging over all edges, yielding the estimate
<disp-formula id="E6"><label>(5)</label><mml:math id="M6" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>D</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mtable><mml:mtr><mml:mtd><mml:mi>p</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>2</mml:mn></mml:mtd></mml:mtr></mml:mtable><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>ξ</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p>
        <p>For each value of <inline-formula id="IE54"><mml:math id="IM54" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>, the total variability of the whole set of graphs found by the JGL is then found by averaging the variability over all <italic toggle="yes">K</italic> networks
<disp-formula id="E7"><label>(6)</label><mml:math id="M7" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>D</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>K</mml:mi></mml:mfrac></mml:mrow><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:munderover></mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>D</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p>
        <p>For sufficiently large <inline-formula id="IE55"><mml:math id="IM55" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>, all edges are excluded from the model and so the variability <inline-formula id="IE56"><mml:math id="IM56" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>D</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> will be 0. The variability will in general increase as the penalty <inline-formula id="IE57"><mml:math id="IM57" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> decreases, however, for small enough <inline-formula id="IE58"><mml:math id="IM58" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> the graphs will become so dense that the variability starts to decrease again. As sparse network inference is the aim, we therefore monotonize the variability function by letting <inline-formula id="IE59"><mml:math id="IM59" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>D</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:munder><mml:mrow><mml:mi>sup</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>≥</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>D</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>.</p>
        <p>Finally, for a given variability threshold <inline-formula id="IE60"><mml:math id="IM60" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>β</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>, the optimal penalty is chosen to be <inline-formula id="IE61"><mml:math id="IM61" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>λ</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mi>inf</mml:mi><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>:</mml:mo><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>D</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>≤</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mo>β</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula>. As opposed to <inline-formula id="IE62"><mml:math id="IM62" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>, <inline-formula id="IE63"><mml:math id="IM63" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>β</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> is an interpretable quantity and we propose a default threshold of <inline-formula id="IE64"><mml:math id="IM64" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>β</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mn>0.1</mml:mn></mml:mrow></mml:math></inline-formula> as suggested by Liu <italic toggle="yes">et al.</italic> for the original StARS algorithm, which reflects an acceptance of <inline-formula id="IE65"><mml:math id="IM65" display="inline" overflow="scroll"><mml:mrow><mml:mn>10</mml:mn><mml:mo>%</mml:mo></mml:mrow></mml:math></inline-formula> variability in the edge assignments.</p>
      </sec>
      <sec>
        <title>2.3.2 Selecting <inline-formula id="IE66"><mml:math id="IM66" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">λ</mml:mi></mml:mrow><mml:mi mathvariant="bold-italic">2</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula></title>
        <p>After <inline-formula id="IE67"><mml:math id="IM67" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> has been selected, we select <inline-formula id="IE68"><mml:math id="IM68" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> with a multiple-network version of the extended BIC (eBIC or <inline-formula id="IE69"><mml:math id="IM69" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mtext>BIC</mml:mtext></mml:mrow></mml:mrow><mml:mo>γ</mml:mo></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>) of <xref rid="vbad185-B14" ref-type="bibr">Foygel and Drton (2010)</xref>. The eBIC is an extension of the Bayesian Information Criterion of <xref rid="vbad185-B32" ref-type="bibr">Schwarz (1978)</xref>, where the prior is reformulated to account for high-dimensional graphical settings. We propose an adaptation the eBIC to a multiple-network setting,
<disp-formula id="E8"><label>(7)</label><mml:math id="M8" display="block" overflow="scroll"><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mrow><mml:mtext>BIC</mml:mtext></mml:mrow><mml:mo>γ</mml:mo></mml:msub></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:munderover></mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msub></mml:mrow><mml:mtext>tr</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">S</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">Θ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msub></mml:mrow><mml:mo> </mml:mo><mml:mtext>log</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mi>det</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">Θ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>+</mml:mo><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msub></mml:mrow><mml:mo>|</mml:mo><mml:mo> </mml:mo><mml:mtext>log</mml:mtext><mml:mo> </mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msub></mml:mrow><mml:mo>+</mml:mo><mml:mn>4</mml:mn><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msub></mml:mrow><mml:mo>|</mml:mo><mml:mo>γ</mml:mo><mml:mo> </mml:mo><mml:mtext>log</mml:mtext><mml:mo> </mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">]</mml:mo><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>
where <inline-formula id="IE70"><mml:math id="IM70" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">Θ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula> is the estimated precision matrix of network <italic toggle="yes">k</italic> obtained with the penalty parameters <inline-formula id="IE71"><mml:math id="IM71" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE72"><mml:math id="IM72" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>, <inline-formula id="IE73"><mml:math id="IM73" display="inline" overflow="scroll"><mml:mrow><mml:mo>γ</mml:mo><mml:mo>∈</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></inline-formula> is an additional penalty parameter and <inline-formula id="IE74"><mml:math id="IM74" display="inline" overflow="scroll"><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msub></mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:math></inline-formula> is the size of the corresponding edge set. A grid of <inline-formula id="IE75"><mml:math id="IM75" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> values is considered, with <inline-formula id="IE76"><mml:math id="IM76" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> fixed to the value selected in the previous step. The value of <inline-formula id="IE77"><mml:math id="IM77" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> that minimizes (7) is selected, and the final graph estimate is obtained by running the JGL with the selected penalty parameters <inline-formula id="IE78"><mml:math id="IM78" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE79"><mml:math id="IM79" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> in the fused penalty (2). An investigation into the effect of selecting the two penalty parameters in reverse order is detailed in <xref rid="sup1" ref-type="supplementary-material">Supplementary Section S5</xref>, where we find that selecting <inline-formula id="IE80"><mml:math id="IM80" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> after <inline-formula id="IE81"><mml:math id="IM81" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> might be desired in settings where one is not concerned about a high false discovery rate.</p>
      </sec>
      <sec>
        <title>2.3.3 Implementation details</title>
        <p>StabJGL is implemented in R, and available as an R package at <ext-link xlink:href="https://github.com/Camiling/stabJGL" ext-link-type="uri">https://github.com/Camiling/stabJGL</ext-link>. The subsampling routine is implemented so it can be done in parallel. The JGL fittings are done as in <xref rid="vbad185-B12" ref-type="bibr">Danaher <italic toggle="yes">et al.</italic> (2014)</xref>, using an ADMM (Alternating Direction Method of Multipliers) algorithm (<xref rid="vbad185-B9" ref-type="bibr">Boyd <italic toggle="yes">et al.</italic> 2010</xref>) for general penalty functions to solve the penalized log-likelihood problem (1) with the fused penalty (2). The stabJGL algorithm itself does not inherently handle missing data, and requires complete data for the precision matrix estimation. In the case of missing data, we recommend using state-of-the-art approaches, such as multiple imputation to defer the issue. By default, 20 subsamples are used and we evaluate 20 values each of <inline-formula id="IE82"><mml:math id="IM82" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>∈</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mn>0.01</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE83"><mml:math id="IM83" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow><mml:mo>∈</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>0.1</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></inline-formula>. We use a subsample size of <inline-formula id="IE84"><mml:math id="IM84" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>⌊</mml:mo><mml:mrow><mml:mn>10</mml:mn><mml:msqrt><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:msqrt></mml:mrow><mml:mo>⌋</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> for group <inline-formula id="IE85"><mml:math id="IM85" display="inline" overflow="scroll"><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>K</mml:mi></mml:mrow></mml:math></inline-formula>, which as <xref rid="vbad185-B26" ref-type="bibr">Liu <italic toggle="yes">et al.</italic> (2010)</xref> show in a single network setting maintains theoretical properties for containing the true graph with high probability as well as high empirical performance. The additional penalty parameter <inline-formula id="IE86"><mml:math id="IM86" display="inline" overflow="scroll"><mml:mo>γ</mml:mo></mml:math></inline-formula> in the eBIC for similarity selection is set to 0 by default, corresponding to the standard BIC. The choice of <inline-formula id="IE87"><mml:math id="IM87" display="inline" overflow="scroll"><mml:mo>γ</mml:mo></mml:math></inline-formula> is not crucial as we are using it for similarity and not sparsity selection, and thus compare graphs of similar sparsity. We found this value to be suitable in most applications but leave the option to increase the penalization. We employ a default variability threshold of <inline-formula id="IE88"><mml:math id="IM88" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>β</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mn>0.1</mml:mn></mml:mrow></mml:math></inline-formula>.</p>
      </sec>
    </sec>
  </sec>
  <sec>
    <title>3 Results</title>
    <sec>
      <title>3.1 Simulated data</title>
      <p>We first assess the performance of stabJGL on simulated data. We compare the network reconstruction ability of stabJGL to that of state-of-the-art methods, including the JGL with the fused penalty (FGL) and group penalty (GGL) with penalty parameters selected with the default AIC-based criterion (<xref rid="vbad185-B12" ref-type="bibr">Danaher <italic toggle="yes">et al.</italic> 2014</xref>). To assess the performance of another selection criterion specifically designed for high-dimensional graph selection, we also consider FGL with penalty parameters tuned by the extended BIC for multiple graphs (7). We further include the Bayesian spike-and-slab JGL (SSJGL) of <xref rid="vbad185-B23" ref-type="bibr">Li <italic toggle="yes">et al.</italic> (2019b</xref>), as well as the Glasso of <xref rid="vbad185-B15" ref-type="bibr">Friedman <italic toggle="yes">et al.</italic> (2008)</xref> tuned by StARS (<xref rid="vbad185-B26" ref-type="bibr">Liu <italic toggle="yes">et al.</italic> 2010</xref>). The latter estimates each network separately. We generate data that closely resembles our omics application of interest, featuring partial correlations between 0.1 and 0.2 in absolute value, while also exhibiting the “scale-free” property—a typical assumption for omics data where the “degree distribution” (i.e. the distribution of the number of edges that are connected to the nodes) adheres to a power-law distribution (<xref rid="vbad185-B11" ref-type="bibr">Chen and Sharp 2004</xref>). We consider a wide range of settings, simulating <inline-formula id="IE89"><mml:math id="IM89" display="inline" overflow="scroll"><mml:mrow><mml:mi>K</mml:mi><mml:mo>∈</mml:mo><mml:mo>{</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>3</mml:mn><mml:mo>,</mml:mo><mml:mn>4</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> networks with <inline-formula id="IE90"><mml:math id="IM90" display="inline" overflow="scroll"><mml:mrow><mml:mi>p</mml:mi><mml:mo>∈</mml:mo><mml:mo>{</mml:mo><mml:mn>100</mml:mn><mml:mo>,</mml:mo><mml:mn>200</mml:mn><mml:mo>,</mml:mo><mml:mn>300</mml:mn><mml:mo>,</mml:mo><mml:mn>1000</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> nodes. We manipulate the degree of similarity in their “true” graphical structures to assess the performance of the method over a wide range of scenarios. We then apply different network reconstruction techniques to determine the networks from the data and report the results averaged over <inline-formula id="IE91"><mml:math id="IM91" display="inline" overflow="scroll"><mml:mrow><mml:mi>N</mml:mi><mml:mo>=</mml:mo><mml:mn>100</mml:mn></mml:mrow></mml:math></inline-formula> replicates. The parameter specifications for the different methods are given in <xref rid="sup1" ref-type="supplementary-material">Supplementary Section S2</xref>. We also investigate the effect of the variability threshold <inline-formula id="IE92"><mml:math id="IM92" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>β</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> in stabJGL on the results in a setting with <inline-formula id="IE93"><mml:math id="IM93" display="inline" overflow="scroll"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>100</mml:mn></mml:mrow></mml:math></inline-formula> nodes and <inline-formula id="IE94"><mml:math id="IM94" display="inline" overflow="scroll"><mml:mrow><mml:mi>K</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula> networks. Finally, to compare the scalability of the respective methods, we consider the time needed to infer networks for various <italic toggle="yes">p</italic> and <italic toggle="yes">K</italic>. Further details and code for the simulation study can be found at <ext-link xlink:href="https://github.com/Camiling/stabJGL_simulations" ext-link-type="uri">https://github.com/Camiling/stabJGL_simulations</ext-link>.</p>
      <p>Estimation accuracy is assessed with the “precision” (positive predictive value), and the “recall” (sensitivity). The precision gives the fraction of predicted edges that were correct, while the recall is the fraction of edges in the true graph that were identified by the inference. Because the sparsity of estimated networks will vary between methods, the precision–recall trade-off should be taken into consideration. In general, the recall will increase with the number of selected edges while the precision will decrease. Since sparsity selection is a main feature of our proposed method, we do not consider threshold-free comparison metrics, such as the AUC. We therefore put emphasis on the following characteristics in our comparative simulation study; (i) suitable sparsity level selection, (ii) utilization of common information at any level of network similarity, i.e. inference improves with increased network similarity, and (iii) a suitable precision–recall trade-off that overly favors either measure.</p>
    </sec>
    <sec>
      <title>3.2 Simulation results</title>
      <p>The results for <inline-formula id="IE95"><mml:math id="IM95" display="inline" overflow="scroll"><mml:mrow><mml:mi>K</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE96"><mml:math id="IM96" display="inline" overflow="scroll"><mml:mrow><mml:mi>K</mml:mi><mml:mo>=</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:math></inline-formula> networks with <inline-formula id="IE97"><mml:math id="IM97" display="inline" overflow="scroll"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>100</mml:mn></mml:mrow></mml:math></inline-formula> nodes are summarized in <xref rid="vbad185-F2" ref-type="fig">Fig. 2</xref>. The full tables of results for these settings and the additional settings with <inline-formula id="IE98"><mml:math id="IM98" display="inline" overflow="scroll"><mml:mrow><mml:mi>K</mml:mi><mml:mo>∈</mml:mo><mml:mo>{</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>3</mml:mn><mml:mo>,</mml:mo><mml:mn>4</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> networks and <inline-formula id="IE99"><mml:math id="IM99" display="inline" overflow="scroll"><mml:mrow><mml:mi>p</mml:mi><mml:mo>∈</mml:mo><mml:mo>{</mml:mo><mml:mn>100</mml:mn><mml:mo>,</mml:mo><mml:mn>200</mml:mn><mml:mo>,</mml:mo><mml:mn>300</mml:mn><mml:mo>,</mml:mo><mml:mn>1000</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> nodes are shown in <xref rid="sup1" ref-type="supplementary-material">Supplementary Section S2</xref>, where details on selected sparsity and penalty parameters are given for all methods. Additional simulations investigating the effect of random noise on the graph reconstruction performance of the different methods are also given in <xref rid="sup1" ref-type="supplementary-material">Supplementary Section S6</xref>. In <xref rid="vbad185-F2" ref-type="fig">Fig. 2</xref>, FGL tuned with eBIC did not select any edges in any of the settings and is therefore not shown. In all settings considered, the FGL and GGL with the default AIC-based penalty parameter selection strongly over-select edges. This leads to high recall, but very low precision. Second, they do not appear to sufficiently utilize network similarities; the performance of the two methods, particularly GGL, differs little between completely unrelated and identical networks. Notably, in all cases, the selected value of <inline-formula id="IE100"><mml:math id="IM100" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> is smaller for FGL and GGL tuned by AIC than it is for stabJGL. Consequently, similarity is not sufficiently encouraged even in settings where the networks are identical. The AIC criterion does not seem to provide sufficient penalization to encourage suitable sparsity and similarity. On the other hand, the alternative eBIC criterion gives extremely sparse FGL estimates, selecting an empty graph in most settings, i.e. no edges. Although the extended BIC is developed specifically for graphical model selection, likelihood-based criteria for sparsity selection tend to perform poorly in high-dimensional settings and risk both severe under- and over-selection (<xref rid="vbad185-B14" ref-type="bibr">Foygel and Drton 2010</xref>). This issue is avoided in the stabJGL algorithm as the eBIC only is used to select similarity and not sparsity.</p>
      <fig position="float" id="vbad185-F2">
        <label>Figure 2.</label>
        <caption>
          <p>Performance of the Glasso, FGL, and GGL tuned by AIC, SSJGL, and stabJGL, reconstructing <inline-formula id="IE101"><mml:math id="IM101" display="inline" overflow="scroll"><mml:mrow><mml:mi>K</mml:mi><mml:mo>∈</mml:mo><mml:mo>{</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>4</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> graphs with <inline-formula id="IE102"><mml:math id="IM102" display="inline" overflow="scroll"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>100</mml:mn></mml:mrow></mml:math></inline-formula> nodes and various similarity of the true graph structures. The similarity between the graphs is shown as the percentage of edges they have in common. The results are averaged over <inline-formula id="IE103"><mml:math id="IM103" display="inline" overflow="scroll"><mml:mrow><mml:mi>N</mml:mi><mml:mo>=</mml:mo><mml:mn>100</mml:mn></mml:mrow></mml:math></inline-formula> replicates and show the precision and recall for the first estimated graph in each setting, reconstructed from <inline-formula id="IE104"><mml:math id="IM104" display="inline" overflow="scroll"><mml:mrow><mml:mi>n</mml:mi><mml:mo>∈</mml:mo><mml:mo>{</mml:mo><mml:mn>100</mml:mn><mml:mo>,</mml:mo><mml:mn>150</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> observations and <inline-formula id="IE105"><mml:math id="IM105" display="inline" overflow="scroll"><mml:mrow><mml:mi>n</mml:mi><mml:mo>∈</mml:mo><mml:mo>{</mml:mo><mml:mn>150</mml:mn><mml:mo>,</mml:mo><mml:mn>200</mml:mn><mml:mo>,</mml:mo><mml:mn>250</mml:mn><mml:mo>,</mml:mo><mml:mn>300</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> observations for <inline-formula id="IE106"><mml:math id="IM106" display="inline" overflow="scroll"><mml:mrow><mml:mi>K</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE107"><mml:math id="IM107" display="inline" overflow="scroll"><mml:mrow><mml:mi>K</mml:mi><mml:mo>=</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:math></inline-formula>, respectively. Standard deviation bars are shown for all methods. All graphs have true sparsity 0.02.</p>
        </caption>
        <graphic xlink:href="vbad185f2" position="float"/>
      </fig>
      <p>The Bayesian SSJGL tends to select very few edges, leading to high precision but low recall. Its performance deteriorates drastically as the network differences increase, leading to extremely low recall. This implies a lack of flexibility to adapt to varying network similarity levels, as has previously been observed (<xref rid="vbad185-B25" ref-type="bibr">Lingjærde <italic toggle="yes">et al.</italic> 2022</xref>). Out of all the joint methods, stabJGL gives the most accurate sparsity estimate. This ensures that we neither get very low precision like FGL and GGL tuned by AIC, nor very low recall like SSJGL and FGL tuned by eBIC. Replacing the mean of the <inline-formula id="IE108"><mml:math id="IM108" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>’s over the <inline-formula id="IE109"><mml:math id="IM109" display="inline" overflow="scroll"><mml:mrow><mml:mi>N</mml:mi><mml:mo>=</mml:mo><mml:mn>100</mml:mn></mml:mrow></mml:math></inline-formula> replicates by alternative measures, such as the median yields the same reported penalty parameter values and hence results in all settings considered in <xref rid="vbad185-F2" ref-type="fig">Fig. 2</xref>. The mean and median could be expected to differ slightly if a finer grid of <inline-formula id="IE110"><mml:math id="IM110" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> values were to be considered, but our findings suggest they would yield highly similar results. StabJGL also appears to adapt well to the similarity between networks, with the prediction accuracy increasing with the number of shared edges. As a result, the method either outperforms the Glasso tuned by StARS for highly similar networks or performs comparably to it for unrelated networks. The similar performance for unrelated networks can be explained by the fact that the sparsity controlling penalty parameters of both methods are tuned with a stability-based approach. The results suggest that stabJGL adapts well to the level of similarity and hence can be employed agnostically in settings where there is no prior knowledge about the degree to which the networks have shared structures.</p>
      <p>A key question is whether stabJGL can achieve as high precision as the methods that give sparser networks (i.e. SSJGL) by using a lower variability threshold. Similarly, we want to see if stabJGL can achieve as high recall as the methods that infer more edges (i.e. FGL and GGL). To investigate this, we consider the same setting as in <xref rid="vbad185-F2" ref-type="fig">Fig. 2</xref> with <inline-formula id="IE111"><mml:math id="IM111" display="inline" overflow="scroll"><mml:mrow><mml:mi>K</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula> networks. <xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S4</xref> compares the performance of stabJGL for different values of the variability threshold <inline-formula id="IE112"><mml:math id="IM112" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>β</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> to the other methods, and we find that by decreasing (resp. increasing) <inline-formula id="IE113"><mml:math id="IM113" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>β</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> we can obtain at least as high precision (resp. recall) as the other methods at any level of similarity. This illustrates that the method can be adapted to reflect the priorities of the user (i.e. concern for false positives versus false negatives). For most applications, a middle-ground value, such as 0.1 yields a good balance between false positives and false negatives as demonstrated in the simulations.</p>
    </sec>
    <sec>
      <title>3.3 Runtime profiling</title>
      <p><xref rid="vbad185-F3" ref-type="fig">Figure 3</xref> shows the CPU time used to jointly infer networks for <inline-formula id="IE114"><mml:math id="IM114" display="inline" overflow="scroll"><mml:mrow><mml:mi>K</mml:mi><mml:mo>∈</mml:mo><mml:mo>{</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>3</mml:mn><mml:mo>,</mml:mo><mml:mn>4</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> networks and various numbers of nodes <italic toggle="yes">p</italic>, with <inline-formula id="IE115"><mml:math id="IM115" display="inline" overflow="scroll"><mml:mrow><mml:mi>n</mml:mi><mml:mo>∈</mml:mo><mml:mo>{</mml:mo><mml:mn>100</mml:mn><mml:mo>,</mml:mo><mml:mn>150</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> observations, for the JGL with the fused penalty (FGL) with penalty parameters tuned with the AIC and stabJGL with the same parameter specifications as in the previously described simulations. Due to an efficient parallelized implementation, stabJGL has an almost identical runtime to FGL when the same number of <inline-formula id="IE116"><mml:math id="IM116" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE117"><mml:math id="IM117" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> values are considered. Thus, the increased estimation accuracy of stabJGL does not come at a computational cost. It is important to note that due to the generalized fused lasso problem having a closed-form expression for the updates in the special case of <inline-formula id="IE118"><mml:math id="IM118" display="inline" overflow="scroll"><mml:mrow><mml:mi>K</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula> (<xref rid="vbad185-B12" ref-type="bibr">Danaher <italic toggle="yes">et al.</italic> 2014</xref>), stabJGL is substantially faster for only two networks than for <inline-formula id="IE119"><mml:math id="IM119" display="inline" overflow="scroll"><mml:mrow><mml:mi>K</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula>. As stabJGL uses the fused penalty this comparison is the most relevant, but a runtime comparison of all methods considered in our simulation study can be found in <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S1</xref>. In the <xref rid="sup1" ref-type="supplementary-material">Supplementary Material</xref>, we also demonstrate that stabJGL can be applied to problems with <inline-formula id="IE120"><mml:math id="IM120" display="inline" overflow="scroll"><mml:mrow><mml:mi>p</mml:mi><mml:mo>≥</mml:mo><mml:mn>2500</mml:mn></mml:mrow></mml:math></inline-formula> nodes or <inline-formula id="IE121"><mml:math id="IM121" display="inline" overflow="scroll"><mml:mrow><mml:mi>K</mml:mi><mml:mo>=</mml:mo><mml:mn>10</mml:mn></mml:mrow></mml:math></inline-formula> networks within reasonable time (<xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S3</xref>).</p>
      <fig position="float" id="vbad185-F3">
        <label>Figure 3.</label>
        <caption>
          <p>CPU time in seconds on a logarithmic scale used to jointly infer networks for <inline-formula id="IE122"><mml:math id="IM122" display="inline" overflow="scroll"><mml:mrow><mml:mi>K</mml:mi><mml:mo>∈</mml:mo><mml:mo>{</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>3</mml:mn><mml:mo>,</mml:mo><mml:mn>4</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> networks and various numbers of nodes <italic toggle="yes">p</italic>, with <inline-formula id="IE123"><mml:math id="IM123" display="inline" overflow="scroll"><mml:mrow><mml:mi>n</mml:mi><mml:mo>∈</mml:mo><mml:mo>{</mml:mo><mml:mn>100</mml:mn><mml:mo>,</mml:mo><mml:mn>150</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> observations, for FGL tuned with AIC and stabJGL. The computations were performed on a 16-core Intel Xeon CPU, 2.60 GHz.</p>
        </caption>
        <graphic xlink:href="vbad185f3" position="float"/>
      </fig>
    </sec>
    <sec>
      <title>3.4 Pan-cancer data</title>
      <p>We perform a proteomic network analysis of Reverse Phase Protein Array (RPPA) data from The Cancer Genome Atlas (TCGA) across different pan-Cancer tumor types (<xref rid="vbad185-B10" ref-type="bibr">Cancer Genome Atlas Network and others 2012</xref>). In a large proteomic pan-Cancer study of 11 TCGA tumor types, <xref rid="vbad185-B2" ref-type="bibr">Akbani <italic toggle="yes">et al.</italic> (2014)</xref> identified a major tumor super cluster consisting of hormonally responsive “women’s cancers” [Luminal breast cancer (BRCA), ovarian cystadenocarcinoma (OVCA), and uterine corpus endometrial carcinoma (UCEC)]. Our objective is to map the proteomic network structure of the respective tumor types, so that we can get a better grasp of the common mechanisms at play in the hormonally responsive tumors. We are also interested in highlighting the differences.</p>
      <p>We consider RPPA data from Luminal BRCA (<inline-formula id="IE124"><mml:math id="IM124" display="inline" overflow="scroll"><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>273</mml:mn></mml:mrow></mml:math></inline-formula>), high-grade serous OVCA (<inline-formula id="IE125"><mml:math id="IM125" display="inline" overflow="scroll"><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>412</mml:mn></mml:mrow></mml:math></inline-formula>), and UCEC (<inline-formula id="IE126"><mml:math id="IM126" display="inline" overflow="scroll"><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>404</mml:mn></mml:mrow></mml:math></inline-formula>). All data are downloaded from the UCSC Xena Browser (<xref rid="vbad185-B16" ref-type="bibr">Goldman <italic toggle="yes">et al.</italic> 2020</xref>). The data are measured with <inline-formula id="IE127"><mml:math id="IM127" display="inline" overflow="scroll"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>131</mml:mn></mml:mrow></mml:math></inline-formula> high-quality antibodies that target (phospho)-proteins. To alleviate batch effects, the RPPA data are normalized with replicate-base normalization (<xref rid="vbad185-B2" ref-type="bibr">Akbani <italic toggle="yes">et al.</italic> 2014</xref>). We use stabJGL to jointly estimate the proteomic networks of the respective tumor types and interpret the results and their implications. We compare the output with that obtained with the FGL of <xref rid="vbad185-B12" ref-type="bibr">Danaher <italic toggle="yes">et al.</italic> (2014)</xref> with the default penalty parameter tuning with AIC as described in Section 3.1. Further details and code for the analysis are given at <ext-link xlink:href="https://github.com/Camiling/stabJGL_analysis" ext-link-type="uri">https://github.com/Camiling/stabJGL_analysis</ext-link>.</p>
    </sec>
    <sec>
      <title>3.5 Pan-cancer analysis results</title>
      <sec>
        <title>3.5.1 Estimated proteomic networks</title>
        <p>The resulting stabJGL proteomic networks of the three tumor types are shown in <xref rid="vbad185-F4" ref-type="fig">Fig. 4</xref>, where we observe plenty of common edges as well as network-specific ones. The sparsity as well as the selected penalty parameter values in the resulting stabJGL and FGL networks is shown in <xref rid="vbad185-T1" ref-type="table">Table 1</xref>. The tendency as observed in the simulations of FGL tuned by the AIC to over-select edges appears to be consistent with the findings in this context. With more than two-thirds of all potential edges being determined as present by FGL, the results are challenging to interpret and derive meaningful conclusions from. From a biological standpoint, we would not expect a proteomic network to be this saturated in terms of associations due to the expected scale-free property of the degree distribution (<xref rid="vbad185-B4" ref-type="bibr">Barabasi and Oltvai 2004</xref>). While the degree distributions of the sparse stabJGL networks all follow a power-law with many low-degree nodes and fewer high-degree ones (hubs), an expected trait for omics data (<xref rid="vbad185-B11" ref-type="bibr">Chen and Sharp 2004</xref>), the degree distributions of the FGL networks do not. The full degree distributions are shown in <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S6</xref>.</p>
        <fig position="float" id="vbad185-F4">
          <label>Figure 4.</label>
          <caption>
            <p>Proteomic network structure identified by stabJGL for the BRCA, OVCA, and UCEC tumors. The nodes represent proteins, and edges common to all three networks are darker.</p>
          </caption>
          <graphic xlink:href="vbad185f4" position="float"/>
        </fig>
        <table-wrap position="float" id="vbad185-T1">
          <label>Table 1.</label>
          <caption>
            <p>Network analysis results for stabJGL and FGL tuned by the AIC, applied to data from BRCA, OVCA, and UCEC tumors.</p>
          </caption>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col valign="top" align="left" span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th rowspan="1" colspan="1"/>
                <th rowspan="1" colspan="1"/>
                <th rowspan="1" colspan="1"/>
                <th colspan="3" rowspan="1">Sparsity<hr/></th>
              </tr>
              <tr>
                <th rowspan="1" colspan="1"/>
                <th rowspan="1" colspan="1">
                  <inline-formula id="IE128">
                    <mml:math id="IM128" display="inline" overflow="scroll">
                      <mml:mrow>
                        <mml:mrow>
                          <mml:msub>
                            <mml:mrow>
                              <mml:mo>λ</mml:mo>
                            </mml:mrow>
                            <mml:mn>1</mml:mn>
                          </mml:msub>
                        </mml:mrow>
                      </mml:mrow>
                    </mml:math>
                  </inline-formula>
                </th>
                <th rowspan="1" colspan="1">
                  <inline-formula id="IE129">
                    <mml:math id="IM129" display="inline" overflow="scroll">
                      <mml:mrow>
                        <mml:mrow>
                          <mml:msub>
                            <mml:mrow>
                              <mml:mo>λ</mml:mo>
                            </mml:mrow>
                            <mml:mn>2</mml:mn>
                          </mml:msub>
                        </mml:mrow>
                      </mml:mrow>
                    </mml:math>
                  </inline-formula>
                </th>
                <th rowspan="1" colspan="1">BRCA</th>
                <th rowspan="1" colspan="1">UCEC</th>
                <th rowspan="1" colspan="1">OVCA</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td rowspan="1" colspan="1">FGL</td>
                <td rowspan="1" colspan="1">0.010</td>
                <td rowspan="1" colspan="1">0.000</td>
                <td rowspan="1" colspan="1">0.689</td>
                <td rowspan="1" colspan="1">0.709</td>
                <td rowspan="1" colspan="1">0.679</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">stabJGL</td>
                <td rowspan="1" colspan="1">0.323</td>
                <td rowspan="1" colspan="1">0.008</td>
                <td rowspan="1" colspan="1">0.049</td>
                <td rowspan="1" colspan="1">0.036</td>
                <td rowspan="1" colspan="1">0.039</td>
              </tr>
            </tbody>
          </table>
        </table-wrap>
        <p>In terms of penalty parameters, we see that just like for the simulated data the AIC selects very small penalty parameters for FGL, resulting in little sparsity and similarity encouragement. Given the findings of <xref rid="vbad185-B2" ref-type="bibr">Akbani <italic toggle="yes">et al.</italic> (2014)</xref> about the presence of a super cluster consisting of the three hormonally responsive cancer types, it is not unreasonable to expect at least some proteomic network similarity to be encouraged by a joint method. This is achieved by stabJGL, which selects a large enough value of <inline-formula id="IE130"><mml:math id="IM130" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> to encourage similarity. A comparison of the pairwise similarities of the proteomic networks reveals that stabJGL indeed finds the networks of the three tumor types to be more similar than FGL, in accordance with the findings of <xref rid="vbad185-B2" ref-type="bibr">Akbani <italic toggle="yes">et al.</italic> (2014)</xref> (<xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S5</xref>).</p>
      </sec>
      <sec>
        <title>3.5.2 Edge validation in STRING</title>
        <p>To compare the level of evidence supporting the edges detected by stabJGL and FGL tuned by the AIC in the literature, we conduct edge validation using the STRING database of known and predicted protein–protein interactions (<xref rid="vbad185-B33" ref-type="bibr">Szklarczyk <italic toggle="yes">et al.</italic> 2019</xref>). To ensure the reliability of the validation process, we only consider the experimentally validated interactions in STRING as evidence, with default confidence score threshold <inline-formula id="IE131"><mml:math id="IM131" display="inline" overflow="scroll"><mml:mrow><mml:mo>≥</mml:mo><mml:mn>0.4</mml:mn></mml:mrow></mml:math></inline-formula>. The number of predicted edges with supporting evidence in the STRING database, as well as the proportion of all predicted edges that have evidence in STRING, is computed for the respective stabJGL and FGL networks and shown in <xref rid="vbad185-T2" ref-type="table">Table 2</xref>. While the fused Glasso identifies a larger number of edges with evidence in STRING, the method also includes far more edges than stabJGL, resulting in an overall lower percentage of edges with supporting evidence in the STRING database than stabJGL, for all three tumor types investigated. Complete lists of the protein–protein edges identified by stabJGL for each tumor type are provided as <xref rid="sup1" ref-type="supplementary-material">Supplementary Files</xref>.</p>
        <table-wrap position="float" id="vbad185-T2">
          <label>Table 2.</label>
          <caption>
            <p>Comparison of evidence for edges in the respective FGL tuned by AIC and stabJGL proteomic networks of BRCA, OVCA, and UCEC tumors, considering experimentally determined protein–protein interactions documented in the STRING database.<sup>a</sup></p>
          </caption>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col valign="top" align="left" span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th rowspan="1" colspan="1"/>
                <th colspan="2" rowspan="1">Edge evidence <inline-formula id="IE132"><mml:math id="IM132" display="inline" overflow="scroll"><mml:mo>%</mml:mo></mml:math></inline-formula><hr/></th>
                <th colspan="2" rowspan="1">Edge evidence #<hr/></th>
              </tr>
              <tr>
                <th rowspan="1" colspan="1">Dataset</th>
                <th rowspan="1" colspan="1">FGL (%)</th>
                <th rowspan="1" colspan="1">stabJGL (%)</th>
                <th rowspan="1" colspan="1">FGL</th>
                <th rowspan="1" colspan="1">stabJGL</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td rowspan="1" colspan="1">BRCA</td>
                <td rowspan="1" colspan="1">5.4</td>
                <td rowspan="1" colspan="1">
                  <bold>12.3</bold>
                </td>
                <td rowspan="1" colspan="1">408</td>
                <td rowspan="1" colspan="1">68</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">UVEC</td>
                <td rowspan="1" colspan="1">5.6</td>
                <td rowspan="1" colspan="1">
                  <bold>10.0</bold>
                </td>
                <td rowspan="1" colspan="1">398</td>
                <td rowspan="1" colspan="1">44</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">OVCA</td>
                <td rowspan="1" colspan="1">5.7</td>
                <td rowspan="1" colspan="1">
                  <bold>12.4</bold>
                </td>
                <td rowspan="1" colspan="1">424</td>
                <td rowspan="1" colspan="1">42</td>
              </tr>
            </tbody>
          </table>
          <table-wrap-foot>
            <fn id="tblfn1">
              <label>a</label>
              <p>Both the percentage of predicted edges with evidence and the number of predicted edges with evidence are shown. The highest percentage of edges with evidence is in bold.</p>
            </fn>
          </table-wrap-foot>
        </table-wrap>
      </sec>
      <sec>
        <title>3.5.3 Findings consistent with literature</title>
        <p>StabJGL successfully identifies protein–protein interactions known from literature. To highlight the findings of the proposed methodology, we only discuss edges and central proteins identified by stabJGL but not FGL. One example is the edge between activated (S345-phosphorylated) Checkpoint kinase 1 (Chk1) and DNA repair protein RAD51 homolog 1 (Rad51) in ovarian and BRCA. The complex between the tumor suppressor BRCA2, which manifests predominantly in ovarian and BRCA, and Rad51, is mediated by the DNA damage checkpoint Chk1 through Rad51 phosphorylation (<xref rid="vbad185-B3" ref-type="bibr">Bahassi <italic toggle="yes">et al.</italic> 2008</xref>, <xref rid="vbad185-B29" ref-type="bibr">Nair <italic toggle="yes">et al.</italic> 2020</xref>). It is also reassuring that stabJGL identifies many relevant tumor type-specific proteins as hubs in the relevant tumor type only, such as mammalian target of rapamycin (mTOR), Tuberous Sclerosis Complex 2, and Ribosomal protein S6 in BRCA, all of which are involved or up/downstream of the PI3K/AKT/mTOR pathway known to frequently be deregulated in Luminal BRCA (<xref rid="vbad185-B28" ref-type="bibr">Miricescu <italic toggle="yes">et al.</italic> 2020</xref>). Lists of the top hubs in the respective stabJGL and FGL networks of the different tumor types, and their node degree, are given in <xref rid="sup1" ref-type="supplementary-material">Supplementary Tables S9</xref> and <xref rid="sup1" ref-type="supplementary-material">S10</xref>.</p>
        <p>StabJGL also captures edges that we expect to be present in all three tumor types, such as the known interaction between the transcription factor Forkhead box O3 and 14–3-3-epsilon, which facilitates cancer cell proliferation (<xref rid="vbad185-B30" ref-type="bibr">Nielsen <italic toggle="yes">et al.</italic> 2008</xref>, <xref rid="vbad185-B35" ref-type="bibr">Tzivion <italic toggle="yes">et al.</italic> 2011</xref>). This common interaction is documented in the STRING database. <xref rid="vbad185-F5" ref-type="fig">Figure 5</xref> shows the network structure identified by stabJGL that is common to all three tumor types. Central proteins in this common network structure include Oncoprotein 18 (Stathmin), which is known to be relevant in all three hormonally responsive cancers due to its role in the regulation of cell growth and motility (<xref rid="vbad185-B7" ref-type="bibr">Bieche <italic toggle="yes">et al.</italic> 1998</xref>, <xref rid="vbad185-B5" ref-type="bibr">Belletti and Baldassarre 2011</xref>, <xref rid="vbad185-B34" ref-type="bibr">Trovik <italic toggle="yes">et al.</italic> 2011</xref>).</p>
        <fig position="float" id="vbad185-F5">
          <label>Figure 5.</label>
          <caption>
            <p>The proteomic network structure identified by stabJGL common to all three tumor types (BRCA, UCEC, and OCVA). The node size indicates the degree in the common network structure, with proteins with more edges being represented by larger nodes.</p>
          </caption>
          <graphic xlink:href="vbad185f5" position="float"/>
        </fig>
      </sec>
      <sec>
        <title>3.5.4 Potential candidate hubs</title>
        <p>The recovery of documented links in the protein networks estimated by stabJGL highlights its capability to detect numerous relevant proteins and interactions. The potential for new discoveries is however an important aspect of stabJGL, as suggested by its good performance on simulated data. For example, stabJGL identifies phosphorylated epidermal growth factor receptor (EGFR) as a central hub protein in all three tumor types. While known to be relevant in ovarian cancer (<xref rid="vbad185-B38" ref-type="bibr">Yang <italic toggle="yes">et al.</italic> 2013</xref>, <xref rid="vbad185-B39" ref-type="bibr">Zhang <italic toggle="yes">et al.</italic> 2016</xref>), the role of activated EGFR in UCEC and Luminal BRCA and is not yet clarified. Our findings suggest it could be relevant in all three hormonally responsive tumor types. Further, Platelet endothelial cell adhesion molecule (CD31) is found to be a central protein in UCEC only. The protein is important for angiogenesis and has been implicated in other tumor types, such as hemangioma (<xref rid="vbad185-B6" ref-type="bibr">Bergom <italic toggle="yes">et al.</italic> 2005</xref>). Its prominence in the proteomic UCEC network suggests it may play a crucial role in this tumor type as well. Overall, these results showcase how stabJGL can aid in generating hypotheses by identifying central proteins and associations.</p>
      </sec>
    </sec>
  </sec>
  <sec>
    <title>4 Discussion</title>
    <p>Suitable sparsity and similarity selection is key for capturing and studying multiple-related biological networks. We have proposed the stabJGL algorithm, which determines the penalty parameters in the fused Glasso for multiple networks based on the principle of model stability. StabJGL demonstrably avoids the under- or over-selection of edges observed in state-of-the-art selection methods based on information criteria and succeeds at leveraging network similarities to a suitable degree. Consequently, the method can be employed in situations where the actual degree of similarity is uncertain, resulting in marked benefits with minimal risks associated with its use. StabJGL offers a fast parallelized implementation, particularly for <inline-formula id="IE133"><mml:math id="IM133" display="inline" overflow="scroll"><mml:mrow><mml:mi>K</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula> networks as a closed-form expression of the updates exists. We successfully apply the method to problems with <inline-formula id="IE134"><mml:math id="IM134" display="inline" overflow="scroll"><mml:mrow><mml:mi>p</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>2000</mml:mn></mml:mrow></mml:math></inline-formula> nodes or <inline-formula id="IE135"><mml:math id="IM135" display="inline" overflow="scroll"><mml:mrow><mml:mi>K</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>10</mml:mn></mml:mrow></mml:math></inline-formula> networks.</p>
    <p>With our novel approach, we can identify both common and distinct mechanisms in the proteomic networks of different types of hormonally responsive women’s cancers. The results obtained with stabJGL are in line with known biology and compliment those of <xref rid="vbad185-B2" ref-type="bibr">Akbani <italic toggle="yes">et al.</italic> (2014)</xref> by offering additional understanding of the underlying mechanisms in action. By recognizing various proteins as highly critical in the proteomic networks, stabJGL suggests their possible involvement in driving the diseases. The method both identifies proteins that are central in all three hormonally responsive cancers (e.g. phosphorylated EGFR) and proteins of tumor-specific relevance (e.g. CD31 in UCEC).</p>
    <p>The proposed approach can be applied to any type of omics data that can be transformed to adhere to the normality assumption. It is however important to note that if the datasets that are to be jointly analyzed are different types of omics data, a one-to-one mapping between the nodes in each dataset would be needed, e.g. having protein and mRNA expression data corresponding to the “same” encoding genes.</p>
    <p>In the setting of the data sources being from the same set of patients, the joint approach is not applicable due to the key assumption that all observations are independent. One such example could be when the data sources are mRNA and protein expression from the same patients. In that case, alternative approaches developed for multi-omic data integration might be more suitable, see, e.g. <xref rid="vbad185-B8" ref-type="bibr">Bonnet <italic toggle="yes">et al.</italic> (2015)</xref> and <xref rid="vbad185-B21" ref-type="bibr">Li and Jackson (2015)</xref>. In the case of multiple shared axes, an extension of our approach could be to concatenate the different omics data types and determine the global network. If independent observations from multiple sources, such as clinical groups or conditions is available as well, stabJGL could then be used to determine links across and within omics data types simultaneously. Such an approach might warrant the introduction of different penalties in (1), both within and across the different omics data types.</p>
    <p>While stabJGL is highly competitive in terms of scalability relative to the existing methodology, all algorithms for estimating Gaussian graphical models have inevitable matrix inversion steps. This is computationally demanding for large <italic toggle="yes">p</italic>, and, at present, joint graphical methods based on Gaussian graphical models are realistically not feasible for the analysis of extremely high-dimensional data with tens of thousands of nodes. It can be argued that even if such an analysis was possible, it is not sensible to attempt to determine the conditional independence structure for problems of this size. For example, if we were to consider the expression of <inline-formula id="IE136"><mml:math id="IM136" display="inline" overflow="scroll"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>20</mml:mn><mml:mo> </mml:mo><mml:mn>000</mml:mn></mml:mrow></mml:math></inline-formula> genes and <inline-formula id="IE137"><mml:math id="IM137" display="inline" overflow="scroll"><mml:mrow><mml:mi>K</mml:mi><mml:mo>=</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:math></inline-formula> groups, we would have the problem of determining over half a billion edges. With only a couple hundred samples in most studies and hence little statistical power, low estimation accuracy and many false discoveries would be expected. Meaningful interpretation of the results would also be a challenge. In settings where <italic toggle="yes">p</italic> is extremely large, an option could instead be to use a fast marginal correlation-based network approach, such as the weighted gene co-expression network analysis method of <xref rid="vbad185-B18" ref-type="bibr">Langfelder and Horvath (2008)</xref>, to identify subnetworks that are relevant for a more refined conditional independence network analysis.</p>
    <p>Future extensions of the method can include alternative measures of variability, such as the entropy [see, e.g. <xref rid="vbad185-B19" ref-type="bibr">Lartigue <italic toggle="yes">et al.</italic> (2020)</xref>]. Further, while the method is formulated specifically for the JGL with the fused penalty, it can in principle be used for any joint network approach requiring the tuning of sparsity- and similarity controlling parameters. Another relevant extension could be the introduction of network-specific sparsity penalty parameters <inline-formula id="IE138"><mml:math id="IM138" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> and network pair-specific similarity penalty parameters <inline-formula id="IE139"><mml:math id="IM139" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mi>k</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> for graphs <inline-formula id="IE140"><mml:math id="IM140" display="inline" overflow="scroll"><mml:mrow><mml:mn>1</mml:mn><mml:mo>≤</mml:mo><mml:mi>k</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>l</mml:mi><mml:mo>≤</mml:mo><mml:mi>K</mml:mi></mml:mrow></mml:math></inline-formula>, which would provide additional flexibility in terms of differing levels of sparsity and similarity across networks. The introduction of these parameters would however invoke a sharp increase in computational complexity, proportional to <inline-formula id="IE141"><mml:math id="IM141" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>K</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>.</p>
    <p>To conclude, stabJGL provides a reliable approach to joint network inference of omics data. The output can provide a better understanding of both common and data type-specific mechanisms, which can be used for hypothesis generation regarding potential therapeutic targets.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material id="sup1" position="float" content-type="local-data">
      <label>vbad185_Supplementary_Data</label>
      <media xlink:href="vbad185_supplementary_data.zip">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <sec>
    <title>Author contributions</title>
    <p>C.L. and S.R. developed the methodology. C.L. performed the data simulation and analysis, developed the software, and drafted the manuscript. Both authors have contributed to the manuscript and read and approved the final version.</p>
  </sec>
  <sec>
    <title>Supplementary data</title>
    <p><xref rid="sup1" ref-type="supplementary-material">Supplementary data</xref> are available at <italic toggle="yes">Bioinformatics Advances</italic> online.</p>
  </sec>
  <sec sec-type="COI-statement">
    <title>Conflict of interest</title>
    <p>None declared.</p>
  </sec>
  <sec>
    <title>Funding</title>
    <p>This work was supported by the UK Medical Research Council programme [MRC MC UU 00002/10 to C.L. and S.R.]; and Aker Scholarship (C.L.).</p>
  </sec>
  <sec sec-type="data-availability">
    <title>Data availability</title>
    <p>The TCGA data sets analysed in this article is publicly available in the University of California Santa Cruz Xena Browser repository (<ext-link xlink:href="http://xena.ucsc.edu" ext-link-type="uri">http://xena.ucsc.edu</ext-link>), from where we downloaded RPPA data for BRCA (dataset ID: TCGA.BRCA.sampleMap/RPPA_RBN), UCEC (dataset ID: TCGA.UCEC.sampleMap/RPPA_RBN) and OVCA (dataset ID: TCGA.OV.sampleMap/RPPA_RBN).</p>
  </sec>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="vbad185-B1">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Akaike</surname><given-names>H</given-names></string-name>, <string-name><surname>Petrov</surname><given-names>BN</given-names></string-name>, <string-name><surname>Csaki</surname><given-names>F.</given-names></string-name></person-group> Information theory and an extension of the maximum likelihood principle. In: <italic toggle="yes">Second International Symposium on Information Theory</italic>, New York, NY. New York: Springer, <year>1973</year>, <fpage>267</fpage>–<lpage>81</lpage>.</mixed-citation>
    </ref>
    <ref id="vbad185-B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Akbani</surname><given-names>R</given-names></string-name>, <string-name><surname>Ng</surname><given-names>PKS</given-names></string-name>, <string-name><surname>Werner</surname><given-names>HM</given-names></string-name></person-group><etal>et al</etal><article-title>A pan-cancer proteomic perspective on The Cancer Genome Atlas</article-title>. <source>Nat Commun</source><year>2014</year>;<volume>5</volume>:<fpage>3887</fpage>.<pub-id pub-id-type="pmid">24871328</pub-id></mixed-citation>
    </ref>
    <ref id="vbad185-B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bahassi</surname><given-names>E</given-names></string-name>, <string-name><surname>Ovesen</surname><given-names>J</given-names></string-name>, <string-name><surname>Riesenberg</surname><given-names>A</given-names></string-name></person-group><etal>et al</etal><article-title>The checkpoint kinases Chk1 and Chk2 regulate the functional associations between hBRCA2 and Rad51 in response to DNA damage</article-title>. <source>Oncogene</source><year>2008</year>;<volume>27</volume>:<fpage>3977</fpage>–<lpage>85</lpage>.<pub-id pub-id-type="pmid">18317453</pub-id></mixed-citation>
    </ref>
    <ref id="vbad185-B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Barabasi</surname><given-names>A-L</given-names></string-name>, <string-name><surname>Oltvai</surname><given-names>ZN.</given-names></string-name></person-group><article-title>Network biology: understanding the cell’s functional organization</article-title>. <source>Nat Rev Genet</source><year>2004</year>;<volume>5</volume>:<fpage>101</fpage>–<lpage>13</lpage>.<pub-id pub-id-type="pmid">14735121</pub-id></mixed-citation>
    </ref>
    <ref id="vbad185-B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Belletti</surname><given-names>B</given-names></string-name>, <string-name><surname>Baldassarre</surname><given-names>G.</given-names></string-name></person-group><article-title>Stathmin: a protein with many tasks. New biomarker and potential target in cancer</article-title>. <source>Expert Opin Ther Targets</source><year>2011</year>;<volume>15</volume>:<fpage>1249</fpage>–<lpage>66</lpage>.<pub-id pub-id-type="pmid">21978024</pub-id></mixed-citation>
    </ref>
    <ref id="vbad185-B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bergom</surname><given-names>C</given-names></string-name>, <string-name><surname>Gao</surname><given-names>C</given-names></string-name>, <string-name><surname>Newman</surname><given-names>PJ.</given-names></string-name></person-group><article-title>Mechanisms of PECAM-1-mediated cytoprotection and implications for cancer cell survival</article-title>. <source>Leuk Lymphoma</source><year>2005</year>;<volume>46</volume>:<fpage>1409</fpage>–<lpage>21</lpage>.<pub-id pub-id-type="pmid">16194886</pub-id></mixed-citation>
    </ref>
    <ref id="vbad185-B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bieche</surname><given-names>I</given-names></string-name>, <string-name><surname>Lachkar</surname><given-names>S</given-names></string-name>, <string-name><surname>Becette</surname><given-names>V</given-names></string-name></person-group><etal>et al</etal><article-title>Overexpression of the stathmin gene in a subset of human breast cancer</article-title>. <source>Br J Cancer</source><year>1998</year>;<volume>78</volume>:<fpage>701</fpage>–<lpage>9</lpage>.<pub-id pub-id-type="pmid">9743287</pub-id></mixed-citation>
    </ref>
    <ref id="vbad185-B8">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bonnet</surname><given-names>E</given-names></string-name>, <string-name><surname>Calzone</surname><given-names>L</given-names></string-name>, <string-name><surname>Michoel</surname><given-names>T.</given-names></string-name></person-group><article-title>Integrative multi-omics module network inference with lemon-tree</article-title>. <source>PLoS Comput Biol</source><year>2015</year>;<volume>11</volume>:<fpage>e1003983</fpage>.<pub-id pub-id-type="pmid">25679508</pub-id></mixed-citation>
    </ref>
    <ref id="vbad185-B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Boyd</surname><given-names>S</given-names></string-name>, <string-name><surname>Parikh</surname><given-names>N</given-names></string-name>, <string-name><surname>Chu</surname><given-names>E</given-names></string-name></person-group><etal>et al</etal><article-title>Distributed optimization and statistical learning via the alternating direction method of multipliers</article-title>. <source>FNT Mach Learn</source><year>2010</year>;<volume>3</volume>:<fpage>1</fpage>–<lpage>122</lpage>.</mixed-citation>
    </ref>
    <ref id="vbad185-B10">
      <mixed-citation publication-type="journal"><collab>Cancer Genome Atlas Network and others</collab>. <article-title>Comprehensive molecular portraits of human breast tumours</article-title>. <source>Nature</source><year>2012</year>;<volume>490</volume>:<fpage>61</fpage>–<lpage>70</lpage>.<pub-id pub-id-type="pmid">23000897</pub-id></mixed-citation>
    </ref>
    <ref id="vbad185-B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chen</surname><given-names>H</given-names></string-name>, <string-name><surname>Sharp</surname><given-names>BM.</given-names></string-name></person-group><article-title>Content-rich biological network constructed by mining PubMed abstracts</article-title>. <source>BMC Bioinformatics</source><year>2004</year>;<volume>5</volume>:<fpage>147</fpage>.<pub-id pub-id-type="pmid">15473905</pub-id></mixed-citation>
    </ref>
    <ref id="vbad185-B12">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Danaher</surname><given-names>P</given-names></string-name>, <string-name><surname>Wang</surname><given-names>P</given-names></string-name>, <string-name><surname>Witten</surname><given-names>DM.</given-names></string-name></person-group><article-title>The joint graphical lasso for inverse covariance estimation across multiple classes</article-title>. <source>J R Stat Soc Series B Stat Methodol</source><year>2014</year>;<volume>76</volume>:<fpage>373</fpage>–<lpage>97</lpage>.<pub-id pub-id-type="pmid">24817823</pub-id></mixed-citation>
    </ref>
    <ref id="vbad185-B13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fan</surname><given-names>J</given-names></string-name>, <string-name><surname>Feng</surname><given-names>Y</given-names></string-name>, <string-name><surname>Wu</surname><given-names>Y.</given-names></string-name></person-group><article-title>Network exploration via the adaptive LASSO and SCAD penalties</article-title>. <source>Ann Appl Stat</source><year>2009</year>;<volume>3</volume>:<fpage>521</fpage>.<pub-id pub-id-type="pmid">21643444</pub-id></mixed-citation>
    </ref>
    <ref id="vbad185-B14">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Foygel</surname><given-names>R</given-names></string-name>, <string-name><surname>Drton</surname><given-names>M.</given-names></string-name></person-group> Extended Bayesian information criteria for Gaussian graphical models. In <italic toggle="yes">Advances in Neural Information Processing Systems, Vancouver, BC</italic>, <fpage>604</fpage>–<lpage>12</lpage>. San Diego, CA: NeurIPS, <year>2010</year>.</mixed-citation>
    </ref>
    <ref id="vbad185-B15">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Friedman</surname><given-names>J</given-names></string-name>, <string-name><surname>Hastie</surname><given-names>T</given-names></string-name>, <string-name><surname>Tibshirani</surname><given-names>R.</given-names></string-name></person-group><article-title>Sparse inverse covariance estimation with the graphical lasso</article-title>. <source>Biostatistics</source><year>2008</year>;<volume>9</volume>:<fpage>432</fpage>–<lpage>41</lpage>.<pub-id pub-id-type="pmid">18079126</pub-id></mixed-citation>
    </ref>
    <ref id="vbad185-B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Goldman</surname><given-names>MJ</given-names></string-name>, <string-name><surname>Craft</surname><given-names>B</given-names></string-name>, <string-name><surname>Hastie</surname><given-names>M</given-names></string-name></person-group><etal>et al</etal><article-title>Visualizing and interpreting cancer genomics data via the Xena platform</article-title>. <source>Nat Biotechnol</source><year>2020</year>;<volume>38</volume>:<fpage>675</fpage>–<lpage>8</lpage>. doi: <pub-id pub-id-type="doi">10.1038/s41587-020-0546-8</pub-id><pub-id pub-id-type="pmid">32444850</pub-id></mixed-citation>
    </ref>
    <ref id="vbad185-B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Guo</surname><given-names>J</given-names></string-name>, <string-name><surname>Levina</surname><given-names>E</given-names></string-name>, <string-name><surname>Michailidis</surname><given-names>G</given-names></string-name></person-group><etal>et al</etal><article-title>Joint estimation of multiple graphical models</article-title>. <source>Biometrika</source><year>2011</year>;<volume>98</volume>:<fpage>1</fpage>–<lpage>15</lpage>.<pub-id pub-id-type="pmid">23049124</pub-id></mixed-citation>
    </ref>
    <ref id="vbad185-B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Langfelder</surname><given-names>P</given-names></string-name>, <string-name><surname>Horvath</surname><given-names>S.</given-names></string-name></person-group><article-title>WGCNA: an R package for weighted correlation network analysis</article-title>. <source>BMC Bioinformatics</source><year>2008</year>;<volume>1</volume>:<fpage>559</fpage>.</mixed-citation>
    </ref>
    <ref id="vbad185-B19">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lartigue</surname><given-names>T</given-names></string-name>, <string-name><surname>Bottani</surname><given-names>S</given-names></string-name>, <string-name><surname>Baron</surname><given-names>S</given-names></string-name></person-group><etal>et al</etal><article-title>Gaussian graphical model exploration and selection in high dimension low sample size setting</article-title>. <source>IEEE Trans Pattern Anal Mach Intell</source><year>2020</year>;<volume>43</volume>:<fpage>3196</fpage>–<lpage>213</lpage>.</mixed-citation>
    </ref>
    <ref id="vbad185-B20">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Lauritzen</surname><given-names>SL.</given-names></string-name></person-group><source>Graphical Models</source>. Vol. <volume>17</volume>. Oxford, UK: <publisher-name>Clarendon Press</publisher-name>, <year>1996</year>.</mixed-citation>
    </ref>
    <ref id="vbad185-B21">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Li</surname><given-names>Y</given-names></string-name>, <string-name><surname>Craig</surname><given-names>BA</given-names></string-name>, <string-name><surname>Bhadra</surname><given-names>A.</given-names></string-name></person-group><article-title>The graphical horseshoe estimator for inverse covariance matrices</article-title>. <source>J Comput Graph Stat</source><year>2019a</year>;<volume>28</volume>:<fpage>747</fpage>–<lpage>57</lpage>.</mixed-citation>
    </ref>
    <ref id="vbad185-B22">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Li</surname><given-names>Y</given-names></string-name>, <string-name><surname>Jackson</surname><given-names>SA.</given-names></string-name></person-group><article-title>Gene network reconstruction by integration of prior biological knowledge</article-title>. <source>G3 (Bethesda)</source><year>2015</year>;<volume>5</volume>:<fpage>1075</fpage>–<lpage>9</lpage>. doi: <pub-id pub-id-type="doi">10.1534/g3.115.018127</pub-id>.<pub-id pub-id-type="pmid">25823587</pub-id></mixed-citation>
    </ref>
    <ref id="vbad185-B23">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Li</surname><given-names>Z</given-names></string-name>, <string-name><surname>Mccormick</surname><given-names>T</given-names></string-name>, <string-name><surname>Clark</surname><given-names>S.</given-names></string-name></person-group> Bayesian joint spike-and-slab graphical lasso. In: <italic toggle="yes">International Conference on Machine Learning, Long Beach, CA</italic>. <fpage>3877</fpage>–<lpage>85</lpage>. <publisher-name>PMLR</publisher-name>, <year>2019b</year>.</mixed-citation>
    </ref>
    <ref id="vbad185-B24">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lingjærde</surname><given-names>C</given-names></string-name>, <string-name><surname>Fairfax</surname><given-names>BP</given-names></string-name>, <string-name><surname>Richardson</surname><given-names>S</given-names></string-name></person-group><etal>et al</etal><article-title>Scalable multiple network inference with the joint graphical horseshoe</article-title>. <source>Ann Appl Stat</source><year>2023</year>; in press.</mixed-citation>
    </ref>
    <ref id="vbad185-B25">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lingjærde</surname><given-names>C</given-names></string-name>, <string-name><surname>Lien</surname><given-names>TG</given-names></string-name>, <string-name><surname>Borgan</surname><given-names>Ø</given-names></string-name></person-group><etal>et al</etal><article-title>Tailored graphical lasso for data integration in gene network reconstruction</article-title>. <source>BMC Bioinformatics</source><year>2021</year>;<volume>22</volume>:<fpage>498</fpage>.<pub-id pub-id-type="pmid">34654363</pub-id></mixed-citation>
    </ref>
    <ref id="vbad185-B26">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Liu</surname><given-names>H</given-names></string-name>, <string-name><surname>Roeder</surname><given-names>K</given-names></string-name>, <string-name><surname>Wasserman</surname><given-names>L.</given-names></string-name></person-group><article-title>Stability approach to regularization selection (StARS) for high dimensional graphical models</article-title>. <source>Adv Neural Inf Process Syst</source><year>2010</year>;<volume>24</volume>:<fpage>1432</fpage>–<lpage>40</lpage>.<pub-id pub-id-type="pmid">25152607</pub-id></mixed-citation>
    </ref>
    <ref id="vbad185-B27">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Meinshausen</surname><given-names>N</given-names></string-name>, <string-name><surname>Bühlmann</surname><given-names>P.</given-names></string-name></person-group><article-title>High-dimensional graphs and variable selection with the lasso</article-title>. <source>Ann Statist</source><year>2006</year>;<volume>34</volume>:<fpage>1436</fpage>–<lpage>62</lpage>.</mixed-citation>
    </ref>
    <ref id="vbad185-B28">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Miricescu</surname><given-names>D</given-names></string-name>, <string-name><surname>Totan</surname><given-names>A</given-names></string-name>, <string-name><surname>Stanescu-Spinu</surname><given-names>I-I</given-names></string-name></person-group><etal>et al</etal><article-title>PI3K/AKT/mTOR signaling pathway in breast cancer: from molecular landscape to clinical aspects</article-title>. <source>Int J Mol Sci</source><year>2020</year>;<volume>22</volume>:<fpage>173</fpage>.<pub-id pub-id-type="pmid">33375317</pub-id></mixed-citation>
    </ref>
    <ref id="vbad185-B29">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nair</surname><given-names>J</given-names></string-name>, <string-name><surname>Huang</surname><given-names>T-T</given-names></string-name>, <string-name><surname>Murai</surname><given-names>J</given-names></string-name></person-group><etal>et al</etal><article-title>Resistance to the CHK1 inhibitor prexasertib involves functionally distinct CHK1 activities in BRCA wild-type ovarian cancer</article-title>. <source>Oncogene</source><year>2020</year>;<volume>39</volume>:<fpage>5520</fpage>–<lpage>35</lpage>.<pub-id pub-id-type="pmid">32647134</pub-id></mixed-citation>
    </ref>
    <ref id="vbad185-B30">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nielsen</surname><given-names>MD</given-names></string-name>, <string-name><surname>Luo</surname><given-names>X</given-names></string-name>, <string-name><surname>Biteau</surname><given-names>B</given-names></string-name></person-group><etal>et al</etal><article-title>14-3-3-Epsilon antagonizes FoxO to control growth, apoptosis and longevity in Drosophila</article-title>. <source>Aging Cell</source><year>2008</year>;<volume>7</volume>:<fpage>688</fpage>–<lpage>99</lpage>.<pub-id pub-id-type="pmid">18665908</pub-id></mixed-citation>
    </ref>
    <ref id="vbad185-B31">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Peterson</surname><given-names>C</given-names></string-name>, <string-name><surname>Stingo</surname><given-names>FC</given-names></string-name>, <string-name><surname>Vannucci</surname><given-names>M.</given-names></string-name></person-group><article-title>Bayesian inference of multiple Gaussian graphical models</article-title>. <source>J Am Stat Assoc</source><year>2015</year>;<volume>110</volume>:<fpage>159</fpage>–<lpage>74</lpage>.<pub-id pub-id-type="pmid">26078481</pub-id></mixed-citation>
    </ref>
    <ref id="vbad185-B32">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Schwarz</surname><given-names>G.</given-names></string-name></person-group><article-title>Estimating the dimension of a model</article-title>. <source>Ann Statist</source><year>1978</year>;<volume>6</volume>:<fpage>461</fpage>–<lpage>4</lpage>.</mixed-citation>
    </ref>
    <ref id="vbad185-B33">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Szklarczyk</surname><given-names>D</given-names></string-name>, <string-name><surname>Gable</surname><given-names>AL</given-names></string-name>, <string-name><surname>Lyon</surname><given-names>D</given-names></string-name></person-group><etal>et al</etal><article-title>STRING v11: protein-protein association networks with increased coverage, supporting functional discovery in genome-wide experimental datasets</article-title>. <source>Nucleic Acids Res</source><year>2019</year>;<volume>47</volume>:<fpage>D607</fpage>–<lpage>13</lpage>.<pub-id pub-id-type="pmid">30476243</pub-id></mixed-citation>
    </ref>
    <ref id="vbad185-B34">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Trovik</surname><given-names>J</given-names></string-name>, <string-name><surname>Wik</surname><given-names>E</given-names></string-name>, <string-name><surname>Stefansson</surname><given-names>IM</given-names></string-name></person-group><etal>et al</etal>; <collab>MoMaTec Study Group</collab>. <article-title>Stathmin overexpression identifies high-risk patients and lymph node metastasis in endometrial cancer</article-title>. <source>Clin Cancer Res</source><year>2011</year>;<volume>17</volume>:<fpage>3368</fpage>–<lpage>77</lpage>.<pub-id pub-id-type="pmid">21242118</pub-id></mixed-citation>
    </ref>
    <ref id="vbad185-B35">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tzivion</surname><given-names>G</given-names></string-name>, <string-name><surname>Dobson</surname><given-names>M</given-names></string-name>, <string-name><surname>Ramakrishnan</surname><given-names>G.</given-names></string-name></person-group><article-title>FoxO transcription factors; Regulation by AKT and 14-3-3 proteins</article-title>. <source>Biochim Biophys Acta</source><year>2011</year>;<volume>1813</volume>:<fpage>1938</fpage>–<lpage>45</lpage>.<pub-id pub-id-type="pmid">21708191</pub-id></mixed-citation>
    </ref>
    <ref id="vbad185-B36">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname><given-names>H.</given-names></string-name></person-group><article-title>Bayesian graphical lasso models and efficient posterior computation</article-title>. <source>Bayesian Anal</source><year>2012</year>;<volume>7</volume>:<fpage>867</fpage>–<lpage>86</lpage>.</mixed-citation>
    </ref>
    <ref id="vbad185-B37">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname><given-names>H.</given-names></string-name></person-group><article-title>Scaling it up: stochastic search structure learning in graphical models</article-title>. <source>Bayesian Anal</source><year>2015</year>;<volume>10</volume>:<fpage>351</fpage>–<lpage>77</lpage>.</mixed-citation>
    </ref>
    <ref id="vbad185-B38">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yang</surname><given-names>J-Y</given-names></string-name>, <string-name><surname>Yoshihara</surname><given-names>K</given-names></string-name>, <string-name><surname>Tanaka</surname><given-names>K</given-names></string-name></person-group><etal>et al</etal>; <collab>Cancer Genome Atlas (TCGA) Research Network</collab>. <article-title>Predicting time to ovarian carcinoma recurrence using protein markers</article-title>. <source>J Clin Investig</source><year>2013</year>;<volume>123</volume>:<fpage>3740</fpage>–<lpage>50</lpage>.<pub-id pub-id-type="pmid">23945238</pub-id></mixed-citation>
    </ref>
    <ref id="vbad185-B39">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname><given-names>H</given-names></string-name>, <string-name><surname>Liu</surname><given-names>T</given-names></string-name>, <string-name><surname>Zhang</surname><given-names>Z</given-names></string-name></person-group><etal>et al</etal>; <collab>CPTAC Investigators</collab>. <article-title>Integrated proteogenomic characterization of human high-grade serous ovarian cancer</article-title>. <source>Cell</source><year>2016</year>;<volume>166</volume>:<fpage>755</fpage>–<lpage>65</lpage>.<pub-id pub-id-type="pmid">27372738</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinform Adv</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinform Adv</journal-id>
    <journal-id journal-id-type="publisher-id">bioadv</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics Advances</journal-title>
    </journal-title-group>
    <issn pub-type="epub">2635-0041</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">10751232</article-id>
    <article-id pub-id-type="doi">10.1093/bioadv/vbad185</article-id>
    <article-id pub-id-type="publisher-id">vbad185</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Original Article</subject>
        <subj-group subj-group-type="category-toc-heading">
          <subject>Systems Biology</subject>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI01060</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>StabJGL: a stability approach to sparsity and similarity selection in multiple-network reconstruction</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0003-2701-5686</contrib-id>
        <name>
          <surname>Lingjærde</surname>
          <given-names>Camilla</given-names>
        </name>
        <aff><institution>MRC Biostatistics Unit, University of Cambridge</institution>, Cambridge CB2 0SR, <country country="GB">United Kingdom</country></aff>
        <xref rid="vbad185-cor1" ref-type="corresp"/>
        <!--camilla.lingjaerde@mrc-bsu.cam.ac.uk-->
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Richardson</surname>
          <given-names>Sylvia</given-names>
        </name>
        <aff><institution>MRC Biostatistics Unit, University of Cambridge</institution>, Cambridge CB2 0SR, <country country="GB">United Kingdom</country></aff>
      </contrib>
    </contrib-group>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Lengauer</surname>
          <given-names>Thomas</given-names>
        </name>
        <role>Associate Editor</role>
      </contrib>
    </contrib-group>
    <author-notes>
      <corresp id="vbad185-cor1">Corresponding author. MRC Biostatistics Unit, University of Cambridge, East Forvie Building, Forvie Site, Robinson Way, Cambridge CB2 0SR, United Kingdom. E-mail: <email>camilla.lingjaerde@mrc-bsu.cam.ac.uk</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2023-12-19">
      <day>19</day>
      <month>12</month>
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>19</day>
      <month>12</month>
      <year>2023</year>
    </pub-date>
    <volume>3</volume>
    <issue>1</issue>
    <elocation-id>vbad185</elocation-id>
    <history>
      <date date-type="received">
        <day>28</day>
        <month>6</month>
        <year>2023</year>
      </date>
      <date date-type="rev-recd">
        <day>23</day>
        <month>11</month>
        <year>2023</year>
      </date>
      <date date-type="editorial-decision">
        <day>11</day>
        <month>12</month>
        <year>2023</year>
      </date>
      <date date-type="accepted">
        <day>18</day>
        <month>12</month>
        <year>2023</year>
      </date>
      <date date-type="corrected-typeset">
        <day>26</day>
        <month>12</month>
        <year>2023</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2023. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2023</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="vbad185.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Motivation</title>
        <p>In recent years, network models have gained prominence for their ability to capture complex associations. In statistical omics, networks can be used to model and study the functional relationships between genes, proteins, and other types of omics data. If a Gaussian graphical model is assumed, a gene association network can be determined from the non-zero entries of the inverse covariance matrix of the data. Due to the high-dimensional nature of such problems, integrative methods that leverage similarities between multiple graphical structures have become increasingly popular. The joint graphical lasso is a powerful tool for this purpose, however, the current AIC-based selection criterion used to tune the network sparsities and similarities leads to poor performance in high-dimensional settings.</p>
      </sec>
      <sec id="s2">
        <title>Results</title>
        <p>We propose stabJGL, which equips the joint graphical lasso with a stable and well-performing penalty parameter selection approach that combines the notion of model stability with likelihood-based similarity selection. The resulting method makes the powerful joint graphical lasso available for use in omics settings, and outperforms the standard joint graphical lasso, as well as state-of-the-art joint methods, in terms of all performance measures we consider. Applying stabJGL to proteomic data from a pan-cancer study, we demonstrate the potential for novel discoveries the method brings.</p>
      </sec>
      <sec id="s3">
        <title>Availability and implementation</title>
        <p>A user-friendly R package for stabJGL with tutorials is available on Github <ext-link xlink:href="https://github.com/Camiling/stabJGL" ext-link-type="uri">https://github.com/Camiling/stabJGL</ext-link>.</p>
      </sec>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>UK Medical Research Council programme</institution>
          </institution-wrap>
        </funding-source>
        <award-id>MRC MC UU 00002/10</award-id>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="10"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 Introduction</title>
    <p>Network models have in recent years gained great popularity in many areas. In statistical omics, networks can be used to decode aspects of unknown structures, and hence study the relationships between genes, proteins, and other types of omics data. In health data sciences, rich datasets are more and more frequently encountered, enabling the development of models integrating a variety of biological resources. In the high-dimensional setting commonly found in omics, sharing information between independent observations from data sources with shared structures—which could be different tissues, conditions or patient subgroups—can give a valuable increase in statistical power while elucidating shared biological function. A key question is how to combine the different data sources into a single model.</p>
    <p>If a Gaussian graphical model is assumed, a conditional (in)dependence network can be estimated by determining the non-zero entries of the inverse covariance (precision) matrix of the data. With its good performance in numerical studies, the “graphical lasso” (Glasso) of <xref rid="vbad185-B15" ref-type="bibr">Friedman <italic toggle="yes">et al.</italic> (2008)</xref> is a state-of-the-art method for precision matrix estimation in the setting of Gaussian graphical models. The method combines <inline-formula id="IE1"><mml:math id="IM1" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> regularization with maximum likelihood estimation. Other notable methods include the neighborhood selection approach of <xref rid="vbad185-B27" ref-type="bibr">Meinshausen and Bühlmann (2006)</xref> and the graphical SCAD (<xref rid="vbad185-B13" ref-type="bibr">Fan <italic toggle="yes">et al.</italic> 2009</xref>). Notable Bayesian methods include the Bayesian Glasso (<xref rid="vbad185-B37" ref-type="bibr">Wang 2012</xref>), Bayesian spike-and-slab approaches (<xref rid="vbad185-B36" ref-type="bibr">Wang 2015</xref>), and the graphical horseshoe (<xref rid="vbad185-B22" ref-type="bibr">Li <italic toggle="yes">et al.</italic> 2019a</xref>).</p>
    <p>If multiple related datasets available, there are several ways to leverage common network structures. If focusing on one data type’s network structure, data from other types can enhance inference via weighted Glasso methods (<xref rid="vbad185-B21" ref-type="bibr">Li and Jackson 2015</xref>, <xref rid="vbad185-B24" ref-type="bibr">Lingjærde <italic toggle="yes">et al.</italic> 2021</xref>). However, to compare network structures across datasets, such as patient subgroups, a joint approach that leverages common information while preserving the differences can increase statistical power and provide interpretable insight.</p>
    <p>In the area of multiple Gaussian graphical models, existing methods include the group extension of the Glasso to multiple networks of <xref rid="vbad185-B17" ref-type="bibr">Guo <italic toggle="yes">et al.</italic> (2011)</xref>, the Bayesian spike-and-slab joint graphical lasso (JGL) (<xref rid="vbad185-B23" ref-type="bibr">Li <italic toggle="yes">et al.</italic> 2019b</xref>), and the Markov random field approach of <xref rid="vbad185-B31" ref-type="bibr">Peterson <italic toggle="yes">et al.</italic> (2015)</xref>. The widely used JGL of <xref rid="vbad185-B12" ref-type="bibr">Danaher <italic toggle="yes">et al.</italic> (2014)</xref> extends the Glasso to a multiple-network setting and provides a powerful tool for inferring graphs with common traits. It employs two different penalty functions—group joint graphical lasso (GGL) and fused joint graphical lasso (FGL)—with the latter recommended for most applications. From this point forward, any mention of the JGL will imply the fused version, unless otherwise specified. The method needs tuning of two regularization parameters for controlling (i) the number of non-zero effects, and (ii) the similarity between networks, respectively. However, the default parameter selection routine based on the AIC (<xref rid="vbad185-B1" ref-type="bibr">Akaike <italic toggle="yes">et al.</italic> 1973</xref>) often results in severe over-selection in high-dimensional data, potentially impacting performance negatively (<xref rid="vbad185-B14" ref-type="bibr">Foygel and Drton 2010</xref>, <xref rid="vbad185-B26" ref-type="bibr">Liu <italic toggle="yes">et al.</italic> 2010</xref>).</p>
    <p>We propose a stable and well-performing penalty parameter selection method for the JGL, combining the model stability principle of <xref rid="vbad185-B26" ref-type="bibr">Liu <italic toggle="yes">et al.</italic> (2010)</xref> with likelihood-based selection for high-dimensional data (<xref rid="vbad185-B14" ref-type="bibr">Foygel and Drton 2010</xref>). The resulting method inherits the powerful traits of the JGL while mitigating the risk of severe under- or over-selection of edges in high-dimensional settings. We provide an R package, <monospace>stabJGL</monospace> (stable sparsity and similarity selection for the JGL), which implements the method.</p>
    <p>The article is organized as follows. In Section 2, we first describe the Gaussian graphical model framework and the penalized log-likelihood problem we aim to solve. We then describe our proposed algorithm. In Section 3, we demonstrate the performance of our proposed method on simulated data and apply it proteomic data from a pan-cancer study of hormonally responsive cancers. Finally, we highlight possible extensions in Section 4.</p>
  </sec>
  <sec>
    <title>2 Methods</title>
    <sec>
      <title>2.1 Gaussian graphical models</title>
      <p>In a gene network model, genes are represented by “nodes” and associations between them are represented by “edges.” Given measurable molecular units each corresponding to one gene (e.g. the encoded protein or mRNA), a network, or graph, can be constructed from their observed values.</p>
      <p>Consider <italic toggle="yes">n</italic> observed values of the multivariate random vector <inline-formula id="IE2"><mml:math id="IM2" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mi>p</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mi>T</mml:mi></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula> of node attributes, with each entry corresponding to one of <italic toggle="yes">p</italic> nodes. If we assume multivariate Gaussian node attributes, with an <inline-formula id="IE3"><mml:math id="IM3" display="inline" overflow="scroll"><mml:mrow><mml:mi>n</mml:mi><mml:mo>×</mml:mo><mml:mi>p</mml:mi></mml:mrow></mml:math></inline-formula> observation matrix <inline-formula id="IE4"><mml:math id="IM4" display="inline" overflow="scroll"><mml:mi mathvariant="bold-italic">X</mml:mi></mml:math></inline-formula> with i.i.d. rows <inline-formula id="IE5"><mml:math id="IM5" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msub></mml:mrow><mml:mo>∼</mml:mo><mml:mi mathvariant="script">N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi mathvariant="bold">Σ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, a “partial correlation network” can be determined by estimating the inverse covariance matrix, or precision matrix, <inline-formula id="IE6"><mml:math id="IM6" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold">Θ</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>. Specifically, the partial correlation between nodes <italic toggle="yes">i</italic> and <italic toggle="yes">j</italic>, conditional upon the rest of the graph, is given by
<disp-formula id="E1"><mml:math id="M1" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>ρ</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi><mml:mo>|</mml:mo><mml:mi>V</mml:mi><mml:mo>\</mml:mo><mml:mo>{</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>}</mml:mo></mml:mrow></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>θ</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mrow><mml:msqrt><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>θ</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>θ</mml:mo></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:msqrt></mml:mrow></mml:mfrac></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>
where the <inline-formula id="IE7"><mml:math id="IM7" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>θ</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>’s are the entries of <inline-formula id="IE8"><mml:math id="IM8" display="inline" overflow="scroll"><mml:mi mathvariant="bold">Θ</mml:mi></mml:math></inline-formula> and <italic toggle="yes">V</italic> the set of all node pairs (<xref rid="vbad185-B20" ref-type="bibr">Lauritzen 1996</xref>). The partial correlations coincide with the conditional correlations in the Gaussian setting. Because correlation (resp. partial correlation) equal to zero is equivalent to independence (resp. conditional independence) for Gaussian variables, a conditional independence graph can thus be constructed by determining the non-zero entries of the precision matrix. To ensure invertibility, the precision matrix also required to be positive definite, <inline-formula id="IE9"><mml:math id="IM9" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold">Θ</mml:mi><mml:mo>≻</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>.</p>
      <p>In high-dimensional settings, the sample covariance matrix <inline-formula id="IE10"><mml:math id="IM10" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold-italic">S</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfrac></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">X</mml:mi></mml:mrow><mml:mi>T</mml:mi></mml:msup></mml:mrow><mml:mi mathvariant="bold-italic">X</mml:mi></mml:mrow></mml:math></inline-formula> is rarely of full rank and thus its inverse cannot be estimated directly. It is common to assume sparse network, meaning the number of edges in the edge set <italic toggle="yes">E</italic> is small relative to the number of potential edges in the graph (i.e. the sparsity measure <inline-formula id="IE11"><mml:math id="IM11" display="inline" overflow="scroll"><mml:mrow><mml:mn>2</mml:mn><mml:mo>|</mml:mo><mml:mi>E</mml:mi><mml:mo>|</mml:mo><mml:mo>/</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mo>−</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> is small). Penalized methods, such as the Glasso (<xref rid="vbad185-B15" ref-type="bibr">Friedman <italic toggle="yes">et al.</italic> 2008</xref>) are well established for sparse Gaussian graphical model estimation. In the case of there being multiple (related) datasets available, such as from different tissue types, rather than estimating each network separately much statistical power could be gained by sharing information across networks through a joint approach.</p>
    </sec>
    <sec>
      <title>2.2 Penalized log-likelihood problem</title>
      <p>Assume a network inference problem with <italic toggle="yes">K</italic> groups. We let <inline-formula id="IE12"><mml:math id="IM12" display="inline" overflow="scroll"><mml:mrow><mml:mo>{</mml:mo><mml:mi mathvariant="bold">Θ</mml:mi><mml:mo>}</mml:mo><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">Θ</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">Θ</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>K</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> be the set of their (unknown) precision matrices, and assume that the set of <inline-formula id="IE13"><mml:math id="IM13" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:munderover></mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> observations are independent. We aim to solve the penalized log-likelihood problem (<xref rid="vbad185-B12" ref-type="bibr">Danaher <italic toggle="yes">et al.</italic> 2014</xref>)
<disp-formula id="E2"><label>(1)</label><mml:math id="M2" display="block" overflow="scroll"><mml:mtable><mml:mtr><mml:mtd><mml:mtable><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">Θ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo>}</mml:mo></mml:mrow><mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:munder><mml:mrow><mml:mtext>argmax</mml:mtext></mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mi mathvariant="bold">Θ</mml:mi><mml:mo>≻</mml:mo><mml:mn>0</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:munder></mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:munderover></mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mtext>log</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mi>det</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">Θ</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mtext>tr</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">S</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">Θ</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>−</mml:mo><mml:mi mathvariant="normal">P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>{</mml:mo><mml:mi mathvariant="bold">Θ</mml:mi><mml:mo>}</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>}</mml:mo><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>
where <inline-formula id="IE14"><mml:math id="IM14" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">S</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula> is the sample covariance matrix of group <italic toggle="yes">k</italic> and <inline-formula id="IE15"><mml:math id="IM15" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="normal">P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>⋅</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> is a penalty function. In (1), <inline-formula id="IE16"><mml:math id="IM16" display="inline" overflow="scroll"><mml:mrow><mml:mi>det</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>⋅</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> denotes the determinant and <inline-formula id="IE17"><mml:math id="IM17" display="inline" overflow="scroll"><mml:mrow><mml:mtext>tr</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mo>⋅</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> denotes the trace. The JGL employs the fused penalty function
<disp-formula id="E3"><label>(2)</label><mml:math id="M3" display="block" overflow="scroll"><mml:mrow><mml:mi mathvariant="normal">P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>{</mml:mo><mml:mi mathvariant="bold">Θ</mml:mi><mml:mo>}</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:munderover></mml:mrow><mml:mrow><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>≠</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mtext>abs</mml:mtext></mml:mrow></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mo>θ</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>&lt;</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msup></mml:mrow></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mo>|</mml:mo></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">Θ</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">Θ</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>
where <inline-formula id="IE18"><mml:math id="IM18" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE19"><mml:math id="IM19" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> are positive penalty parameters, <inline-formula id="IE20"><mml:math id="IM20" display="inline" overflow="scroll"><mml:mrow><mml:mtext>abs</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mo>⋅</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> denotes the absolute value function and <inline-formula id="IE21"><mml:math id="IM21" display="inline" overflow="scroll"><mml:mrow><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:mo>⋅</mml:mo><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> denotes the <inline-formula id="IE22"><mml:math id="IM22" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">L</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> penalty. This penalty applies <inline-formula id="IE23"><mml:math id="IM23" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">L</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> penalties to each off-diagonal element of the <italic toggle="yes">K</italic> precision matrices as well as to the differences between corresponding elements of each pair of precision matrices. The parameter <inline-formula id="IE24"><mml:math id="IM24" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> controls the sparsity, and the similarity parameter <inline-formula id="IE25"><mml:math id="IM25" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> controls the degree to which the <italic toggle="yes">K</italic> precision matrices are forced toward each other, encouraging not only similar network structures but also similar precision matrix entries. This way, the dependency between observed datasets is modeled through their underlying graphical structures. It is important to note that a necessary assumption of the resulting model is that given their respective graphical structures, observations are independent across and within each dataset. The current penalty parameter selection approach for <inline-formula id="IE26"><mml:math id="IM26" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE27"><mml:math id="IM27" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> is based on the AIC (<xref rid="vbad185-B12" ref-type="bibr">Danaher <italic toggle="yes">et al.</italic> 2014</xref>), and while suitable for determining network similarities, likelihood-based selection criteria can lead to severe under- or over-selection and thus poor performance in high-dimensional settings (<xref rid="vbad185-B26" ref-type="bibr">Liu <italic toggle="yes">et al.</italic> 2010</xref>).</p>
    </sec>
    <sec>
      <title>2.3 The stabJGL algorithm</title>
      <p>To improve the performance of the JGL with the fused penalty for omics applications and other high-dimensional problems, we propose the stabJGL algorithm for stable sparsity and similarity selection in multiple-network reconstruction. StabJGL jointly estimates multiple networks by leveraging their common information and gives a basis for deeper exploration of their differences, as shown in <xref rid="vbad185-F1" ref-type="fig">Fig. 1</xref>. Below we outline the algorithm, which comprised two steps: (i) selecting the sparsity parameter <inline-formula id="IE28"><mml:math id="IM28" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> in the fused penalty (2) based on the notion of model stability, and (ii) selecting the similarity parameter <inline-formula id="IE29"><mml:math id="IM29" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> based on model likelihood. The full StabJGL algorithm is given in <xref rid="sup1" ref-type="supplementary-material">Supplementary Algorithm S1</xref>.</p>
      <fig position="float" id="vbad185-F1">
        <label>Figure 1.</label>
        <caption>
          <p>The workflow of stabJGL, where the network structures of different data types or conditions are jointly estimated and can then be compared.</p>
        </caption>
        <graphic xlink:href="vbad185f1" position="float"/>
      </fig>
      <sec>
        <title>2.3.1 Selecting <inline-formula id="IE30"><mml:math id="IM30" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">λ</mml:mi></mml:mrow><mml:mi mathvariant="bold">1</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula></title>
        <p>We first select <inline-formula id="IE31"><mml:math id="IM31" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> by extending the framework introduced by <xref rid="vbad185-B26" ref-type="bibr">Liu <italic toggle="yes">et al.</italic> (2010)</xref> in their Stability Approach to regularization Criterion (StARS) to a multiple-network setting. The aim is to select the least amount of penalization that makes graphs sparse as well as reproducible under random subsampling. This is done by drawing many random subsamples from each of the <italic toggle="yes">K</italic> data types and using them to construct JGL graphs over a range of <inline-formula id="IE32"><mml:math id="IM32" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> values. The smallest parameter value for which a given graph estimation variability measure does not surpass a specified threshold is then selected. We use a measure of edge assignment instability across subsamples to quantify the variability.</p>
        <p>Specifically, we consider a grid of <inline-formula id="IE33"><mml:math id="IM33" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> values in a suitable interval, i.e. <inline-formula id="IE34"><mml:math id="IM34" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></inline-formula> and keep the similarity parameter <inline-formula id="IE35"><mml:math id="IM35" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> fixed to some small value, such as 0.01 in the first instance. For <inline-formula id="IE36"><mml:math id="IM36" display="inline" overflow="scroll"><mml:mrow><mml:mo>η</mml:mo><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mtext>sample</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>, we draw a random subsample from each group <italic toggle="yes">k’</italic>s set of <inline-formula id="IE37"><mml:math id="IM37" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> observations without replacement, each of size <inline-formula id="IE38"><mml:math id="IM38" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msub></mml:mrow><mml:mo>&lt;</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>. For each value of <inline-formula id="IE39"><mml:math id="IM39" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> to consider, we next construct the corresponding set of JGL graphs <inline-formula id="IE40"><mml:math id="IM40" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>η</mml:mo></mml:msubsup></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>}</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula> from these <italic toggle="yes">K</italic> sets of subsamples, using the fused penalty (2).</p>
        <p>The following is then done for each value of <inline-formula id="IE41"><mml:math id="IM41" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> we consider. For each group <inline-formula id="IE42"><mml:math id="IM42" display="inline" overflow="scroll"><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>K</mml:mi></mml:mrow></mml:math></inline-formula> and all possible node pairs <inline-formula id="IE43"><mml:math id="IM43" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> we estimate the probability of an edge between the nodes over the <inline-formula id="IE44"><mml:math id="IM44" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mtext>sample</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> inferred sets of graphs
<disp-formula id="E4"><label>(3)</label><mml:math id="M4" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>ψ</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mtext>sample</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mfrac></mml:mrow><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mo>η</mml:mo><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mtext>sample</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:munderover></mml:mrow><mml:mrow><mml:mi mathvariant="double-struck">1</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>∈</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>η</mml:mo></mml:msubsup></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>
where <inline-formula id="IE45"><mml:math id="IM45" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="double-struck">1</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mo>⋅</mml:mo><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the indicator function. Using this estimated probability, we find
<disp-formula id="E5"><label>(4)</label><mml:math id="M5" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>ξ</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>ψ</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>ψ</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>
which is an estimate of two times the variance of the Bernoulli indicator of the edge <inline-formula id="IE46"><mml:math id="IM46" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> in group <italic toggle="yes">k</italic>. It lies in [0, 0.5] and can be regarded as an estimate of the proportion of times two inferred graphs for group <italic toggle="yes">k</italic> found with the given <inline-formula id="IE47"><mml:math id="IM47" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> value will disagree on the presence of the edge <inline-formula id="IE48"><mml:math id="IM48" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>. Due to the <inline-formula id="IE49"><mml:math id="IM49" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> penalty in (2), the number of inferred edges will decrease as <inline-formula id="IE50"><mml:math id="IM50" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> is increased.</p>
        <p>For a given <inline-formula id="IE51"><mml:math id="IM51" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>, <inline-formula id="IE52"><mml:math id="IM52" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>ξ</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> can be regarded as a measure of the variability of the edge <inline-formula id="IE53"><mml:math id="IM53" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> in group <italic toggle="yes">k</italic> across subsamples, and the total variability of graph <italic toggle="yes">k</italic> can be measured by averaging over all edges, yielding the estimate
<disp-formula id="E6"><label>(5)</label><mml:math id="M6" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>D</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mtable><mml:mtr><mml:mtd><mml:mi>p</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>2</mml:mn></mml:mtd></mml:mtr></mml:mtable><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>ξ</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p>
        <p>For each value of <inline-formula id="IE54"><mml:math id="IM54" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>, the total variability of the whole set of graphs found by the JGL is then found by averaging the variability over all <italic toggle="yes">K</italic> networks
<disp-formula id="E7"><label>(6)</label><mml:math id="M7" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>D</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>K</mml:mi></mml:mfrac></mml:mrow><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:munderover></mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>D</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p>
        <p>For sufficiently large <inline-formula id="IE55"><mml:math id="IM55" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>, all edges are excluded from the model and so the variability <inline-formula id="IE56"><mml:math id="IM56" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>D</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> will be 0. The variability will in general increase as the penalty <inline-formula id="IE57"><mml:math id="IM57" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> decreases, however, for small enough <inline-formula id="IE58"><mml:math id="IM58" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> the graphs will become so dense that the variability starts to decrease again. As sparse network inference is the aim, we therefore monotonize the variability function by letting <inline-formula id="IE59"><mml:math id="IM59" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>D</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:munder><mml:mrow><mml:mi>sup</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>≥</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>D</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>.</p>
        <p>Finally, for a given variability threshold <inline-formula id="IE60"><mml:math id="IM60" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>β</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>, the optimal penalty is chosen to be <inline-formula id="IE61"><mml:math id="IM61" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>λ</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mi>inf</mml:mi><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>:</mml:mo><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>D</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>≤</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mo>β</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula>. As opposed to <inline-formula id="IE62"><mml:math id="IM62" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>, <inline-formula id="IE63"><mml:math id="IM63" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>β</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> is an interpretable quantity and we propose a default threshold of <inline-formula id="IE64"><mml:math id="IM64" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>β</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mn>0.1</mml:mn></mml:mrow></mml:math></inline-formula> as suggested by Liu <italic toggle="yes">et al.</italic> for the original StARS algorithm, which reflects an acceptance of <inline-formula id="IE65"><mml:math id="IM65" display="inline" overflow="scroll"><mml:mrow><mml:mn>10</mml:mn><mml:mo>%</mml:mo></mml:mrow></mml:math></inline-formula> variability in the edge assignments.</p>
      </sec>
      <sec>
        <title>2.3.2 Selecting <inline-formula id="IE66"><mml:math id="IM66" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">λ</mml:mi></mml:mrow><mml:mi mathvariant="bold-italic">2</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula></title>
        <p>After <inline-formula id="IE67"><mml:math id="IM67" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> has been selected, we select <inline-formula id="IE68"><mml:math id="IM68" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> with a multiple-network version of the extended BIC (eBIC or <inline-formula id="IE69"><mml:math id="IM69" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mtext>BIC</mml:mtext></mml:mrow></mml:mrow><mml:mo>γ</mml:mo></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>) of <xref rid="vbad185-B14" ref-type="bibr">Foygel and Drton (2010)</xref>. The eBIC is an extension of the Bayesian Information Criterion of <xref rid="vbad185-B32" ref-type="bibr">Schwarz (1978)</xref>, where the prior is reformulated to account for high-dimensional graphical settings. We propose an adaptation the eBIC to a multiple-network setting,
<disp-formula id="E8"><label>(7)</label><mml:math id="M8" display="block" overflow="scroll"><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mrow><mml:mtext>BIC</mml:mtext></mml:mrow><mml:mo>γ</mml:mo></mml:msub></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:munderover></mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msub></mml:mrow><mml:mtext>tr</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">S</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">Θ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msub></mml:mrow><mml:mo> </mml:mo><mml:mtext>log</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mi>det</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">Θ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>+</mml:mo><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msub></mml:mrow><mml:mo>|</mml:mo><mml:mo> </mml:mo><mml:mtext>log</mml:mtext><mml:mo> </mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msub></mml:mrow><mml:mo>+</mml:mo><mml:mn>4</mml:mn><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msub></mml:mrow><mml:mo>|</mml:mo><mml:mo>γ</mml:mo><mml:mo> </mml:mo><mml:mtext>log</mml:mtext><mml:mo> </mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">]</mml:mo><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>
where <inline-formula id="IE70"><mml:math id="IM70" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">Θ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula> is the estimated precision matrix of network <italic toggle="yes">k</italic> obtained with the penalty parameters <inline-formula id="IE71"><mml:math id="IM71" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE72"><mml:math id="IM72" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>, <inline-formula id="IE73"><mml:math id="IM73" display="inline" overflow="scroll"><mml:mrow><mml:mo>γ</mml:mo><mml:mo>∈</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></inline-formula> is an additional penalty parameter and <inline-formula id="IE74"><mml:math id="IM74" display="inline" overflow="scroll"><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msub></mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:math></inline-formula> is the size of the corresponding edge set. A grid of <inline-formula id="IE75"><mml:math id="IM75" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> values is considered, with <inline-formula id="IE76"><mml:math id="IM76" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> fixed to the value selected in the previous step. The value of <inline-formula id="IE77"><mml:math id="IM77" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> that minimizes (7) is selected, and the final graph estimate is obtained by running the JGL with the selected penalty parameters <inline-formula id="IE78"><mml:math id="IM78" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE79"><mml:math id="IM79" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> in the fused penalty (2). An investigation into the effect of selecting the two penalty parameters in reverse order is detailed in <xref rid="sup1" ref-type="supplementary-material">Supplementary Section S5</xref>, where we find that selecting <inline-formula id="IE80"><mml:math id="IM80" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> after <inline-formula id="IE81"><mml:math id="IM81" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> might be desired in settings where one is not concerned about a high false discovery rate.</p>
      </sec>
      <sec>
        <title>2.3.3 Implementation details</title>
        <p>StabJGL is implemented in R, and available as an R package at <ext-link xlink:href="https://github.com/Camiling/stabJGL" ext-link-type="uri">https://github.com/Camiling/stabJGL</ext-link>. The subsampling routine is implemented so it can be done in parallel. The JGL fittings are done as in <xref rid="vbad185-B12" ref-type="bibr">Danaher <italic toggle="yes">et al.</italic> (2014)</xref>, using an ADMM (Alternating Direction Method of Multipliers) algorithm (<xref rid="vbad185-B9" ref-type="bibr">Boyd <italic toggle="yes">et al.</italic> 2010</xref>) for general penalty functions to solve the penalized log-likelihood problem (1) with the fused penalty (2). The stabJGL algorithm itself does not inherently handle missing data, and requires complete data for the precision matrix estimation. In the case of missing data, we recommend using state-of-the-art approaches, such as multiple imputation to defer the issue. By default, 20 subsamples are used and we evaluate 20 values each of <inline-formula id="IE82"><mml:math id="IM82" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>∈</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mn>0.01</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE83"><mml:math id="IM83" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow><mml:mo>∈</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>0.1</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></inline-formula>. We use a subsample size of <inline-formula id="IE84"><mml:math id="IM84" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>⌊</mml:mo><mml:mrow><mml:mn>10</mml:mn><mml:msqrt><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:msqrt></mml:mrow><mml:mo>⌋</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> for group <inline-formula id="IE85"><mml:math id="IM85" display="inline" overflow="scroll"><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>K</mml:mi></mml:mrow></mml:math></inline-formula>, which as <xref rid="vbad185-B26" ref-type="bibr">Liu <italic toggle="yes">et al.</italic> (2010)</xref> show in a single network setting maintains theoretical properties for containing the true graph with high probability as well as high empirical performance. The additional penalty parameter <inline-formula id="IE86"><mml:math id="IM86" display="inline" overflow="scroll"><mml:mo>γ</mml:mo></mml:math></inline-formula> in the eBIC for similarity selection is set to 0 by default, corresponding to the standard BIC. The choice of <inline-formula id="IE87"><mml:math id="IM87" display="inline" overflow="scroll"><mml:mo>γ</mml:mo></mml:math></inline-formula> is not crucial as we are using it for similarity and not sparsity selection, and thus compare graphs of similar sparsity. We found this value to be suitable in most applications but leave the option to increase the penalization. We employ a default variability threshold of <inline-formula id="IE88"><mml:math id="IM88" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>β</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mn>0.1</mml:mn></mml:mrow></mml:math></inline-formula>.</p>
      </sec>
    </sec>
  </sec>
  <sec>
    <title>3 Results</title>
    <sec>
      <title>3.1 Simulated data</title>
      <p>We first assess the performance of stabJGL on simulated data. We compare the network reconstruction ability of stabJGL to that of state-of-the-art methods, including the JGL with the fused penalty (FGL) and group penalty (GGL) with penalty parameters selected with the default AIC-based criterion (<xref rid="vbad185-B12" ref-type="bibr">Danaher <italic toggle="yes">et al.</italic> 2014</xref>). To assess the performance of another selection criterion specifically designed for high-dimensional graph selection, we also consider FGL with penalty parameters tuned by the extended BIC for multiple graphs (7). We further include the Bayesian spike-and-slab JGL (SSJGL) of <xref rid="vbad185-B23" ref-type="bibr">Li <italic toggle="yes">et al.</italic> (2019b</xref>), as well as the Glasso of <xref rid="vbad185-B15" ref-type="bibr">Friedman <italic toggle="yes">et al.</italic> (2008)</xref> tuned by StARS (<xref rid="vbad185-B26" ref-type="bibr">Liu <italic toggle="yes">et al.</italic> 2010</xref>). The latter estimates each network separately. We generate data that closely resembles our omics application of interest, featuring partial correlations between 0.1 and 0.2 in absolute value, while also exhibiting the “scale-free” property—a typical assumption for omics data where the “degree distribution” (i.e. the distribution of the number of edges that are connected to the nodes) adheres to a power-law distribution (<xref rid="vbad185-B11" ref-type="bibr">Chen and Sharp 2004</xref>). We consider a wide range of settings, simulating <inline-formula id="IE89"><mml:math id="IM89" display="inline" overflow="scroll"><mml:mrow><mml:mi>K</mml:mi><mml:mo>∈</mml:mo><mml:mo>{</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>3</mml:mn><mml:mo>,</mml:mo><mml:mn>4</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> networks with <inline-formula id="IE90"><mml:math id="IM90" display="inline" overflow="scroll"><mml:mrow><mml:mi>p</mml:mi><mml:mo>∈</mml:mo><mml:mo>{</mml:mo><mml:mn>100</mml:mn><mml:mo>,</mml:mo><mml:mn>200</mml:mn><mml:mo>,</mml:mo><mml:mn>300</mml:mn><mml:mo>,</mml:mo><mml:mn>1000</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> nodes. We manipulate the degree of similarity in their “true” graphical structures to assess the performance of the method over a wide range of scenarios. We then apply different network reconstruction techniques to determine the networks from the data and report the results averaged over <inline-formula id="IE91"><mml:math id="IM91" display="inline" overflow="scroll"><mml:mrow><mml:mi>N</mml:mi><mml:mo>=</mml:mo><mml:mn>100</mml:mn></mml:mrow></mml:math></inline-formula> replicates. The parameter specifications for the different methods are given in <xref rid="sup1" ref-type="supplementary-material">Supplementary Section S2</xref>. We also investigate the effect of the variability threshold <inline-formula id="IE92"><mml:math id="IM92" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>β</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> in stabJGL on the results in a setting with <inline-formula id="IE93"><mml:math id="IM93" display="inline" overflow="scroll"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>100</mml:mn></mml:mrow></mml:math></inline-formula> nodes and <inline-formula id="IE94"><mml:math id="IM94" display="inline" overflow="scroll"><mml:mrow><mml:mi>K</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula> networks. Finally, to compare the scalability of the respective methods, we consider the time needed to infer networks for various <italic toggle="yes">p</italic> and <italic toggle="yes">K</italic>. Further details and code for the simulation study can be found at <ext-link xlink:href="https://github.com/Camiling/stabJGL_simulations" ext-link-type="uri">https://github.com/Camiling/stabJGL_simulations</ext-link>.</p>
      <p>Estimation accuracy is assessed with the “precision” (positive predictive value), and the “recall” (sensitivity). The precision gives the fraction of predicted edges that were correct, while the recall is the fraction of edges in the true graph that were identified by the inference. Because the sparsity of estimated networks will vary between methods, the precision–recall trade-off should be taken into consideration. In general, the recall will increase with the number of selected edges while the precision will decrease. Since sparsity selection is a main feature of our proposed method, we do not consider threshold-free comparison metrics, such as the AUC. We therefore put emphasis on the following characteristics in our comparative simulation study; (i) suitable sparsity level selection, (ii) utilization of common information at any level of network similarity, i.e. inference improves with increased network similarity, and (iii) a suitable precision–recall trade-off that overly favors either measure.</p>
    </sec>
    <sec>
      <title>3.2 Simulation results</title>
      <p>The results for <inline-formula id="IE95"><mml:math id="IM95" display="inline" overflow="scroll"><mml:mrow><mml:mi>K</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE96"><mml:math id="IM96" display="inline" overflow="scroll"><mml:mrow><mml:mi>K</mml:mi><mml:mo>=</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:math></inline-formula> networks with <inline-formula id="IE97"><mml:math id="IM97" display="inline" overflow="scroll"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>100</mml:mn></mml:mrow></mml:math></inline-formula> nodes are summarized in <xref rid="vbad185-F2" ref-type="fig">Fig. 2</xref>. The full tables of results for these settings and the additional settings with <inline-formula id="IE98"><mml:math id="IM98" display="inline" overflow="scroll"><mml:mrow><mml:mi>K</mml:mi><mml:mo>∈</mml:mo><mml:mo>{</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>3</mml:mn><mml:mo>,</mml:mo><mml:mn>4</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> networks and <inline-formula id="IE99"><mml:math id="IM99" display="inline" overflow="scroll"><mml:mrow><mml:mi>p</mml:mi><mml:mo>∈</mml:mo><mml:mo>{</mml:mo><mml:mn>100</mml:mn><mml:mo>,</mml:mo><mml:mn>200</mml:mn><mml:mo>,</mml:mo><mml:mn>300</mml:mn><mml:mo>,</mml:mo><mml:mn>1000</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> nodes are shown in <xref rid="sup1" ref-type="supplementary-material">Supplementary Section S2</xref>, where details on selected sparsity and penalty parameters are given for all methods. Additional simulations investigating the effect of random noise on the graph reconstruction performance of the different methods are also given in <xref rid="sup1" ref-type="supplementary-material">Supplementary Section S6</xref>. In <xref rid="vbad185-F2" ref-type="fig">Fig. 2</xref>, FGL tuned with eBIC did not select any edges in any of the settings and is therefore not shown. In all settings considered, the FGL and GGL with the default AIC-based penalty parameter selection strongly over-select edges. This leads to high recall, but very low precision. Second, they do not appear to sufficiently utilize network similarities; the performance of the two methods, particularly GGL, differs little between completely unrelated and identical networks. Notably, in all cases, the selected value of <inline-formula id="IE100"><mml:math id="IM100" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> is smaller for FGL and GGL tuned by AIC than it is for stabJGL. Consequently, similarity is not sufficiently encouraged even in settings where the networks are identical. The AIC criterion does not seem to provide sufficient penalization to encourage suitable sparsity and similarity. On the other hand, the alternative eBIC criterion gives extremely sparse FGL estimates, selecting an empty graph in most settings, i.e. no edges. Although the extended BIC is developed specifically for graphical model selection, likelihood-based criteria for sparsity selection tend to perform poorly in high-dimensional settings and risk both severe under- and over-selection (<xref rid="vbad185-B14" ref-type="bibr">Foygel and Drton 2010</xref>). This issue is avoided in the stabJGL algorithm as the eBIC only is used to select similarity and not sparsity.</p>
      <fig position="float" id="vbad185-F2">
        <label>Figure 2.</label>
        <caption>
          <p>Performance of the Glasso, FGL, and GGL tuned by AIC, SSJGL, and stabJGL, reconstructing <inline-formula id="IE101"><mml:math id="IM101" display="inline" overflow="scroll"><mml:mrow><mml:mi>K</mml:mi><mml:mo>∈</mml:mo><mml:mo>{</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>4</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> graphs with <inline-formula id="IE102"><mml:math id="IM102" display="inline" overflow="scroll"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>100</mml:mn></mml:mrow></mml:math></inline-formula> nodes and various similarity of the true graph structures. The similarity between the graphs is shown as the percentage of edges they have in common. The results are averaged over <inline-formula id="IE103"><mml:math id="IM103" display="inline" overflow="scroll"><mml:mrow><mml:mi>N</mml:mi><mml:mo>=</mml:mo><mml:mn>100</mml:mn></mml:mrow></mml:math></inline-formula> replicates and show the precision and recall for the first estimated graph in each setting, reconstructed from <inline-formula id="IE104"><mml:math id="IM104" display="inline" overflow="scroll"><mml:mrow><mml:mi>n</mml:mi><mml:mo>∈</mml:mo><mml:mo>{</mml:mo><mml:mn>100</mml:mn><mml:mo>,</mml:mo><mml:mn>150</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> observations and <inline-formula id="IE105"><mml:math id="IM105" display="inline" overflow="scroll"><mml:mrow><mml:mi>n</mml:mi><mml:mo>∈</mml:mo><mml:mo>{</mml:mo><mml:mn>150</mml:mn><mml:mo>,</mml:mo><mml:mn>200</mml:mn><mml:mo>,</mml:mo><mml:mn>250</mml:mn><mml:mo>,</mml:mo><mml:mn>300</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> observations for <inline-formula id="IE106"><mml:math id="IM106" display="inline" overflow="scroll"><mml:mrow><mml:mi>K</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE107"><mml:math id="IM107" display="inline" overflow="scroll"><mml:mrow><mml:mi>K</mml:mi><mml:mo>=</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:math></inline-formula>, respectively. Standard deviation bars are shown for all methods. All graphs have true sparsity 0.02.</p>
        </caption>
        <graphic xlink:href="vbad185f2" position="float"/>
      </fig>
      <p>The Bayesian SSJGL tends to select very few edges, leading to high precision but low recall. Its performance deteriorates drastically as the network differences increase, leading to extremely low recall. This implies a lack of flexibility to adapt to varying network similarity levels, as has previously been observed (<xref rid="vbad185-B25" ref-type="bibr">Lingjærde <italic toggle="yes">et al.</italic> 2022</xref>). Out of all the joint methods, stabJGL gives the most accurate sparsity estimate. This ensures that we neither get very low precision like FGL and GGL tuned by AIC, nor very low recall like SSJGL and FGL tuned by eBIC. Replacing the mean of the <inline-formula id="IE108"><mml:math id="IM108" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>’s over the <inline-formula id="IE109"><mml:math id="IM109" display="inline" overflow="scroll"><mml:mrow><mml:mi>N</mml:mi><mml:mo>=</mml:mo><mml:mn>100</mml:mn></mml:mrow></mml:math></inline-formula> replicates by alternative measures, such as the median yields the same reported penalty parameter values and hence results in all settings considered in <xref rid="vbad185-F2" ref-type="fig">Fig. 2</xref>. The mean and median could be expected to differ slightly if a finer grid of <inline-formula id="IE110"><mml:math id="IM110" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> values were to be considered, but our findings suggest they would yield highly similar results. StabJGL also appears to adapt well to the similarity between networks, with the prediction accuracy increasing with the number of shared edges. As a result, the method either outperforms the Glasso tuned by StARS for highly similar networks or performs comparably to it for unrelated networks. The similar performance for unrelated networks can be explained by the fact that the sparsity controlling penalty parameters of both methods are tuned with a stability-based approach. The results suggest that stabJGL adapts well to the level of similarity and hence can be employed agnostically in settings where there is no prior knowledge about the degree to which the networks have shared structures.</p>
      <p>A key question is whether stabJGL can achieve as high precision as the methods that give sparser networks (i.e. SSJGL) by using a lower variability threshold. Similarly, we want to see if stabJGL can achieve as high recall as the methods that infer more edges (i.e. FGL and GGL). To investigate this, we consider the same setting as in <xref rid="vbad185-F2" ref-type="fig">Fig. 2</xref> with <inline-formula id="IE111"><mml:math id="IM111" display="inline" overflow="scroll"><mml:mrow><mml:mi>K</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula> networks. <xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S4</xref> compares the performance of stabJGL for different values of the variability threshold <inline-formula id="IE112"><mml:math id="IM112" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>β</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> to the other methods, and we find that by decreasing (resp. increasing) <inline-formula id="IE113"><mml:math id="IM113" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>β</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> we can obtain at least as high precision (resp. recall) as the other methods at any level of similarity. This illustrates that the method can be adapted to reflect the priorities of the user (i.e. concern for false positives versus false negatives). For most applications, a middle-ground value, such as 0.1 yields a good balance between false positives and false negatives as demonstrated in the simulations.</p>
    </sec>
    <sec>
      <title>3.3 Runtime profiling</title>
      <p><xref rid="vbad185-F3" ref-type="fig">Figure 3</xref> shows the CPU time used to jointly infer networks for <inline-formula id="IE114"><mml:math id="IM114" display="inline" overflow="scroll"><mml:mrow><mml:mi>K</mml:mi><mml:mo>∈</mml:mo><mml:mo>{</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>3</mml:mn><mml:mo>,</mml:mo><mml:mn>4</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> networks and various numbers of nodes <italic toggle="yes">p</italic>, with <inline-formula id="IE115"><mml:math id="IM115" display="inline" overflow="scroll"><mml:mrow><mml:mi>n</mml:mi><mml:mo>∈</mml:mo><mml:mo>{</mml:mo><mml:mn>100</mml:mn><mml:mo>,</mml:mo><mml:mn>150</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> observations, for the JGL with the fused penalty (FGL) with penalty parameters tuned with the AIC and stabJGL with the same parameter specifications as in the previously described simulations. Due to an efficient parallelized implementation, stabJGL has an almost identical runtime to FGL when the same number of <inline-formula id="IE116"><mml:math id="IM116" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE117"><mml:math id="IM117" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> values are considered. Thus, the increased estimation accuracy of stabJGL does not come at a computational cost. It is important to note that due to the generalized fused lasso problem having a closed-form expression for the updates in the special case of <inline-formula id="IE118"><mml:math id="IM118" display="inline" overflow="scroll"><mml:mrow><mml:mi>K</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula> (<xref rid="vbad185-B12" ref-type="bibr">Danaher <italic toggle="yes">et al.</italic> 2014</xref>), stabJGL is substantially faster for only two networks than for <inline-formula id="IE119"><mml:math id="IM119" display="inline" overflow="scroll"><mml:mrow><mml:mi>K</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula>. As stabJGL uses the fused penalty this comparison is the most relevant, but a runtime comparison of all methods considered in our simulation study can be found in <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S1</xref>. In the <xref rid="sup1" ref-type="supplementary-material">Supplementary Material</xref>, we also demonstrate that stabJGL can be applied to problems with <inline-formula id="IE120"><mml:math id="IM120" display="inline" overflow="scroll"><mml:mrow><mml:mi>p</mml:mi><mml:mo>≥</mml:mo><mml:mn>2500</mml:mn></mml:mrow></mml:math></inline-formula> nodes or <inline-formula id="IE121"><mml:math id="IM121" display="inline" overflow="scroll"><mml:mrow><mml:mi>K</mml:mi><mml:mo>=</mml:mo><mml:mn>10</mml:mn></mml:mrow></mml:math></inline-formula> networks within reasonable time (<xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S3</xref>).</p>
      <fig position="float" id="vbad185-F3">
        <label>Figure 3.</label>
        <caption>
          <p>CPU time in seconds on a logarithmic scale used to jointly infer networks for <inline-formula id="IE122"><mml:math id="IM122" display="inline" overflow="scroll"><mml:mrow><mml:mi>K</mml:mi><mml:mo>∈</mml:mo><mml:mo>{</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>3</mml:mn><mml:mo>,</mml:mo><mml:mn>4</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> networks and various numbers of nodes <italic toggle="yes">p</italic>, with <inline-formula id="IE123"><mml:math id="IM123" display="inline" overflow="scroll"><mml:mrow><mml:mi>n</mml:mi><mml:mo>∈</mml:mo><mml:mo>{</mml:mo><mml:mn>100</mml:mn><mml:mo>,</mml:mo><mml:mn>150</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> observations, for FGL tuned with AIC and stabJGL. The computations were performed on a 16-core Intel Xeon CPU, 2.60 GHz.</p>
        </caption>
        <graphic xlink:href="vbad185f3" position="float"/>
      </fig>
    </sec>
    <sec>
      <title>3.4 Pan-cancer data</title>
      <p>We perform a proteomic network analysis of Reverse Phase Protein Array (RPPA) data from The Cancer Genome Atlas (TCGA) across different pan-Cancer tumor types (<xref rid="vbad185-B10" ref-type="bibr">Cancer Genome Atlas Network and others 2012</xref>). In a large proteomic pan-Cancer study of 11 TCGA tumor types, <xref rid="vbad185-B2" ref-type="bibr">Akbani <italic toggle="yes">et al.</italic> (2014)</xref> identified a major tumor super cluster consisting of hormonally responsive “women’s cancers” [Luminal breast cancer (BRCA), ovarian cystadenocarcinoma (OVCA), and uterine corpus endometrial carcinoma (UCEC)]. Our objective is to map the proteomic network structure of the respective tumor types, so that we can get a better grasp of the common mechanisms at play in the hormonally responsive tumors. We are also interested in highlighting the differences.</p>
      <p>We consider RPPA data from Luminal BRCA (<inline-formula id="IE124"><mml:math id="IM124" display="inline" overflow="scroll"><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>273</mml:mn></mml:mrow></mml:math></inline-formula>), high-grade serous OVCA (<inline-formula id="IE125"><mml:math id="IM125" display="inline" overflow="scroll"><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>412</mml:mn></mml:mrow></mml:math></inline-formula>), and UCEC (<inline-formula id="IE126"><mml:math id="IM126" display="inline" overflow="scroll"><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>404</mml:mn></mml:mrow></mml:math></inline-formula>). All data are downloaded from the UCSC Xena Browser (<xref rid="vbad185-B16" ref-type="bibr">Goldman <italic toggle="yes">et al.</italic> 2020</xref>). The data are measured with <inline-formula id="IE127"><mml:math id="IM127" display="inline" overflow="scroll"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>131</mml:mn></mml:mrow></mml:math></inline-formula> high-quality antibodies that target (phospho)-proteins. To alleviate batch effects, the RPPA data are normalized with replicate-base normalization (<xref rid="vbad185-B2" ref-type="bibr">Akbani <italic toggle="yes">et al.</italic> 2014</xref>). We use stabJGL to jointly estimate the proteomic networks of the respective tumor types and interpret the results and their implications. We compare the output with that obtained with the FGL of <xref rid="vbad185-B12" ref-type="bibr">Danaher <italic toggle="yes">et al.</italic> (2014)</xref> with the default penalty parameter tuning with AIC as described in Section 3.1. Further details and code for the analysis are given at <ext-link xlink:href="https://github.com/Camiling/stabJGL_analysis" ext-link-type="uri">https://github.com/Camiling/stabJGL_analysis</ext-link>.</p>
    </sec>
    <sec>
      <title>3.5 Pan-cancer analysis results</title>
      <sec>
        <title>3.5.1 Estimated proteomic networks</title>
        <p>The resulting stabJGL proteomic networks of the three tumor types are shown in <xref rid="vbad185-F4" ref-type="fig">Fig. 4</xref>, where we observe plenty of common edges as well as network-specific ones. The sparsity as well as the selected penalty parameter values in the resulting stabJGL and FGL networks is shown in <xref rid="vbad185-T1" ref-type="table">Table 1</xref>. The tendency as observed in the simulations of FGL tuned by the AIC to over-select edges appears to be consistent with the findings in this context. With more than two-thirds of all potential edges being determined as present by FGL, the results are challenging to interpret and derive meaningful conclusions from. From a biological standpoint, we would not expect a proteomic network to be this saturated in terms of associations due to the expected scale-free property of the degree distribution (<xref rid="vbad185-B4" ref-type="bibr">Barabasi and Oltvai 2004</xref>). While the degree distributions of the sparse stabJGL networks all follow a power-law with many low-degree nodes and fewer high-degree ones (hubs), an expected trait for omics data (<xref rid="vbad185-B11" ref-type="bibr">Chen and Sharp 2004</xref>), the degree distributions of the FGL networks do not. The full degree distributions are shown in <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S6</xref>.</p>
        <fig position="float" id="vbad185-F4">
          <label>Figure 4.</label>
          <caption>
            <p>Proteomic network structure identified by stabJGL for the BRCA, OVCA, and UCEC tumors. The nodes represent proteins, and edges common to all three networks are darker.</p>
          </caption>
          <graphic xlink:href="vbad185f4" position="float"/>
        </fig>
        <table-wrap position="float" id="vbad185-T1">
          <label>Table 1.</label>
          <caption>
            <p>Network analysis results for stabJGL and FGL tuned by the AIC, applied to data from BRCA, OVCA, and UCEC tumors.</p>
          </caption>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col valign="top" align="left" span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th rowspan="1" colspan="1"/>
                <th rowspan="1" colspan="1"/>
                <th rowspan="1" colspan="1"/>
                <th colspan="3" rowspan="1">Sparsity<hr/></th>
              </tr>
              <tr>
                <th rowspan="1" colspan="1"/>
                <th rowspan="1" colspan="1">
                  <inline-formula id="IE128">
                    <mml:math id="IM128" display="inline" overflow="scroll">
                      <mml:mrow>
                        <mml:mrow>
                          <mml:msub>
                            <mml:mrow>
                              <mml:mo>λ</mml:mo>
                            </mml:mrow>
                            <mml:mn>1</mml:mn>
                          </mml:msub>
                        </mml:mrow>
                      </mml:mrow>
                    </mml:math>
                  </inline-formula>
                </th>
                <th rowspan="1" colspan="1">
                  <inline-formula id="IE129">
                    <mml:math id="IM129" display="inline" overflow="scroll">
                      <mml:mrow>
                        <mml:mrow>
                          <mml:msub>
                            <mml:mrow>
                              <mml:mo>λ</mml:mo>
                            </mml:mrow>
                            <mml:mn>2</mml:mn>
                          </mml:msub>
                        </mml:mrow>
                      </mml:mrow>
                    </mml:math>
                  </inline-formula>
                </th>
                <th rowspan="1" colspan="1">BRCA</th>
                <th rowspan="1" colspan="1">UCEC</th>
                <th rowspan="1" colspan="1">OVCA</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td rowspan="1" colspan="1">FGL</td>
                <td rowspan="1" colspan="1">0.010</td>
                <td rowspan="1" colspan="1">0.000</td>
                <td rowspan="1" colspan="1">0.689</td>
                <td rowspan="1" colspan="1">0.709</td>
                <td rowspan="1" colspan="1">0.679</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">stabJGL</td>
                <td rowspan="1" colspan="1">0.323</td>
                <td rowspan="1" colspan="1">0.008</td>
                <td rowspan="1" colspan="1">0.049</td>
                <td rowspan="1" colspan="1">0.036</td>
                <td rowspan="1" colspan="1">0.039</td>
              </tr>
            </tbody>
          </table>
        </table-wrap>
        <p>In terms of penalty parameters, we see that just like for the simulated data the AIC selects very small penalty parameters for FGL, resulting in little sparsity and similarity encouragement. Given the findings of <xref rid="vbad185-B2" ref-type="bibr">Akbani <italic toggle="yes">et al.</italic> (2014)</xref> about the presence of a super cluster consisting of the three hormonally responsive cancer types, it is not unreasonable to expect at least some proteomic network similarity to be encouraged by a joint method. This is achieved by stabJGL, which selects a large enough value of <inline-formula id="IE130"><mml:math id="IM130" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> to encourage similarity. A comparison of the pairwise similarities of the proteomic networks reveals that stabJGL indeed finds the networks of the three tumor types to be more similar than FGL, in accordance with the findings of <xref rid="vbad185-B2" ref-type="bibr">Akbani <italic toggle="yes">et al.</italic> (2014)</xref> (<xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S5</xref>).</p>
      </sec>
      <sec>
        <title>3.5.2 Edge validation in STRING</title>
        <p>To compare the level of evidence supporting the edges detected by stabJGL and FGL tuned by the AIC in the literature, we conduct edge validation using the STRING database of known and predicted protein–protein interactions (<xref rid="vbad185-B33" ref-type="bibr">Szklarczyk <italic toggle="yes">et al.</italic> 2019</xref>). To ensure the reliability of the validation process, we only consider the experimentally validated interactions in STRING as evidence, with default confidence score threshold <inline-formula id="IE131"><mml:math id="IM131" display="inline" overflow="scroll"><mml:mrow><mml:mo>≥</mml:mo><mml:mn>0.4</mml:mn></mml:mrow></mml:math></inline-formula>. The number of predicted edges with supporting evidence in the STRING database, as well as the proportion of all predicted edges that have evidence in STRING, is computed for the respective stabJGL and FGL networks and shown in <xref rid="vbad185-T2" ref-type="table">Table 2</xref>. While the fused Glasso identifies a larger number of edges with evidence in STRING, the method also includes far more edges than stabJGL, resulting in an overall lower percentage of edges with supporting evidence in the STRING database than stabJGL, for all three tumor types investigated. Complete lists of the protein–protein edges identified by stabJGL for each tumor type are provided as <xref rid="sup1" ref-type="supplementary-material">Supplementary Files</xref>.</p>
        <table-wrap position="float" id="vbad185-T2">
          <label>Table 2.</label>
          <caption>
            <p>Comparison of evidence for edges in the respective FGL tuned by AIC and stabJGL proteomic networks of BRCA, OVCA, and UCEC tumors, considering experimentally determined protein–protein interactions documented in the STRING database.<sup>a</sup></p>
          </caption>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col valign="top" align="left" span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th rowspan="1" colspan="1"/>
                <th colspan="2" rowspan="1">Edge evidence <inline-formula id="IE132"><mml:math id="IM132" display="inline" overflow="scroll"><mml:mo>%</mml:mo></mml:math></inline-formula><hr/></th>
                <th colspan="2" rowspan="1">Edge evidence #<hr/></th>
              </tr>
              <tr>
                <th rowspan="1" colspan="1">Dataset</th>
                <th rowspan="1" colspan="1">FGL (%)</th>
                <th rowspan="1" colspan="1">stabJGL (%)</th>
                <th rowspan="1" colspan="1">FGL</th>
                <th rowspan="1" colspan="1">stabJGL</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td rowspan="1" colspan="1">BRCA</td>
                <td rowspan="1" colspan="1">5.4</td>
                <td rowspan="1" colspan="1">
                  <bold>12.3</bold>
                </td>
                <td rowspan="1" colspan="1">408</td>
                <td rowspan="1" colspan="1">68</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">UVEC</td>
                <td rowspan="1" colspan="1">5.6</td>
                <td rowspan="1" colspan="1">
                  <bold>10.0</bold>
                </td>
                <td rowspan="1" colspan="1">398</td>
                <td rowspan="1" colspan="1">44</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">OVCA</td>
                <td rowspan="1" colspan="1">5.7</td>
                <td rowspan="1" colspan="1">
                  <bold>12.4</bold>
                </td>
                <td rowspan="1" colspan="1">424</td>
                <td rowspan="1" colspan="1">42</td>
              </tr>
            </tbody>
          </table>
          <table-wrap-foot>
            <fn id="tblfn1">
              <label>a</label>
              <p>Both the percentage of predicted edges with evidence and the number of predicted edges with evidence are shown. The highest percentage of edges with evidence is in bold.</p>
            </fn>
          </table-wrap-foot>
        </table-wrap>
      </sec>
      <sec>
        <title>3.5.3 Findings consistent with literature</title>
        <p>StabJGL successfully identifies protein–protein interactions known from literature. To highlight the findings of the proposed methodology, we only discuss edges and central proteins identified by stabJGL but not FGL. One example is the edge between activated (S345-phosphorylated) Checkpoint kinase 1 (Chk1) and DNA repair protein RAD51 homolog 1 (Rad51) in ovarian and BRCA. The complex between the tumor suppressor BRCA2, which manifests predominantly in ovarian and BRCA, and Rad51, is mediated by the DNA damage checkpoint Chk1 through Rad51 phosphorylation (<xref rid="vbad185-B3" ref-type="bibr">Bahassi <italic toggle="yes">et al.</italic> 2008</xref>, <xref rid="vbad185-B29" ref-type="bibr">Nair <italic toggle="yes">et al.</italic> 2020</xref>). It is also reassuring that stabJGL identifies many relevant tumor type-specific proteins as hubs in the relevant tumor type only, such as mammalian target of rapamycin (mTOR), Tuberous Sclerosis Complex 2, and Ribosomal protein S6 in BRCA, all of which are involved or up/downstream of the PI3K/AKT/mTOR pathway known to frequently be deregulated in Luminal BRCA (<xref rid="vbad185-B28" ref-type="bibr">Miricescu <italic toggle="yes">et al.</italic> 2020</xref>). Lists of the top hubs in the respective stabJGL and FGL networks of the different tumor types, and their node degree, are given in <xref rid="sup1" ref-type="supplementary-material">Supplementary Tables S9</xref> and <xref rid="sup1" ref-type="supplementary-material">S10</xref>.</p>
        <p>StabJGL also captures edges that we expect to be present in all three tumor types, such as the known interaction between the transcription factor Forkhead box O3 and 14–3-3-epsilon, which facilitates cancer cell proliferation (<xref rid="vbad185-B30" ref-type="bibr">Nielsen <italic toggle="yes">et al.</italic> 2008</xref>, <xref rid="vbad185-B35" ref-type="bibr">Tzivion <italic toggle="yes">et al.</italic> 2011</xref>). This common interaction is documented in the STRING database. <xref rid="vbad185-F5" ref-type="fig">Figure 5</xref> shows the network structure identified by stabJGL that is common to all three tumor types. Central proteins in this common network structure include Oncoprotein 18 (Stathmin), which is known to be relevant in all three hormonally responsive cancers due to its role in the regulation of cell growth and motility (<xref rid="vbad185-B7" ref-type="bibr">Bieche <italic toggle="yes">et al.</italic> 1998</xref>, <xref rid="vbad185-B5" ref-type="bibr">Belletti and Baldassarre 2011</xref>, <xref rid="vbad185-B34" ref-type="bibr">Trovik <italic toggle="yes">et al.</italic> 2011</xref>).</p>
        <fig position="float" id="vbad185-F5">
          <label>Figure 5.</label>
          <caption>
            <p>The proteomic network structure identified by stabJGL common to all three tumor types (BRCA, UCEC, and OCVA). The node size indicates the degree in the common network structure, with proteins with more edges being represented by larger nodes.</p>
          </caption>
          <graphic xlink:href="vbad185f5" position="float"/>
        </fig>
      </sec>
      <sec>
        <title>3.5.4 Potential candidate hubs</title>
        <p>The recovery of documented links in the protein networks estimated by stabJGL highlights its capability to detect numerous relevant proteins and interactions. The potential for new discoveries is however an important aspect of stabJGL, as suggested by its good performance on simulated data. For example, stabJGL identifies phosphorylated epidermal growth factor receptor (EGFR) as a central hub protein in all three tumor types. While known to be relevant in ovarian cancer (<xref rid="vbad185-B38" ref-type="bibr">Yang <italic toggle="yes">et al.</italic> 2013</xref>, <xref rid="vbad185-B39" ref-type="bibr">Zhang <italic toggle="yes">et al.</italic> 2016</xref>), the role of activated EGFR in UCEC and Luminal BRCA and is not yet clarified. Our findings suggest it could be relevant in all three hormonally responsive tumor types. Further, Platelet endothelial cell adhesion molecule (CD31) is found to be a central protein in UCEC only. The protein is important for angiogenesis and has been implicated in other tumor types, such as hemangioma (<xref rid="vbad185-B6" ref-type="bibr">Bergom <italic toggle="yes">et al.</italic> 2005</xref>). Its prominence in the proteomic UCEC network suggests it may play a crucial role in this tumor type as well. Overall, these results showcase how stabJGL can aid in generating hypotheses by identifying central proteins and associations.</p>
      </sec>
    </sec>
  </sec>
  <sec>
    <title>4 Discussion</title>
    <p>Suitable sparsity and similarity selection is key for capturing and studying multiple-related biological networks. We have proposed the stabJGL algorithm, which determines the penalty parameters in the fused Glasso for multiple networks based on the principle of model stability. StabJGL demonstrably avoids the under- or over-selection of edges observed in state-of-the-art selection methods based on information criteria and succeeds at leveraging network similarities to a suitable degree. Consequently, the method can be employed in situations where the actual degree of similarity is uncertain, resulting in marked benefits with minimal risks associated with its use. StabJGL offers a fast parallelized implementation, particularly for <inline-formula id="IE133"><mml:math id="IM133" display="inline" overflow="scroll"><mml:mrow><mml:mi>K</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula> networks as a closed-form expression of the updates exists. We successfully apply the method to problems with <inline-formula id="IE134"><mml:math id="IM134" display="inline" overflow="scroll"><mml:mrow><mml:mi>p</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>2000</mml:mn></mml:mrow></mml:math></inline-formula> nodes or <inline-formula id="IE135"><mml:math id="IM135" display="inline" overflow="scroll"><mml:mrow><mml:mi>K</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>10</mml:mn></mml:mrow></mml:math></inline-formula> networks.</p>
    <p>With our novel approach, we can identify both common and distinct mechanisms in the proteomic networks of different types of hormonally responsive women’s cancers. The results obtained with stabJGL are in line with known biology and compliment those of <xref rid="vbad185-B2" ref-type="bibr">Akbani <italic toggle="yes">et al.</italic> (2014)</xref> by offering additional understanding of the underlying mechanisms in action. By recognizing various proteins as highly critical in the proteomic networks, stabJGL suggests their possible involvement in driving the diseases. The method both identifies proteins that are central in all three hormonally responsive cancers (e.g. phosphorylated EGFR) and proteins of tumor-specific relevance (e.g. CD31 in UCEC).</p>
    <p>The proposed approach can be applied to any type of omics data that can be transformed to adhere to the normality assumption. It is however important to note that if the datasets that are to be jointly analyzed are different types of omics data, a one-to-one mapping between the nodes in each dataset would be needed, e.g. having protein and mRNA expression data corresponding to the “same” encoding genes.</p>
    <p>In the setting of the data sources being from the same set of patients, the joint approach is not applicable due to the key assumption that all observations are independent. One such example could be when the data sources are mRNA and protein expression from the same patients. In that case, alternative approaches developed for multi-omic data integration might be more suitable, see, e.g. <xref rid="vbad185-B8" ref-type="bibr">Bonnet <italic toggle="yes">et al.</italic> (2015)</xref> and <xref rid="vbad185-B21" ref-type="bibr">Li and Jackson (2015)</xref>. In the case of multiple shared axes, an extension of our approach could be to concatenate the different omics data types and determine the global network. If independent observations from multiple sources, such as clinical groups or conditions is available as well, stabJGL could then be used to determine links across and within omics data types simultaneously. Such an approach might warrant the introduction of different penalties in (1), both within and across the different omics data types.</p>
    <p>While stabJGL is highly competitive in terms of scalability relative to the existing methodology, all algorithms for estimating Gaussian graphical models have inevitable matrix inversion steps. This is computationally demanding for large <italic toggle="yes">p</italic>, and, at present, joint graphical methods based on Gaussian graphical models are realistically not feasible for the analysis of extremely high-dimensional data with tens of thousands of nodes. It can be argued that even if such an analysis was possible, it is not sensible to attempt to determine the conditional independence structure for problems of this size. For example, if we were to consider the expression of <inline-formula id="IE136"><mml:math id="IM136" display="inline" overflow="scroll"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>20</mml:mn><mml:mo> </mml:mo><mml:mn>000</mml:mn></mml:mrow></mml:math></inline-formula> genes and <inline-formula id="IE137"><mml:math id="IM137" display="inline" overflow="scroll"><mml:mrow><mml:mi>K</mml:mi><mml:mo>=</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:math></inline-formula> groups, we would have the problem of determining over half a billion edges. With only a couple hundred samples in most studies and hence little statistical power, low estimation accuracy and many false discoveries would be expected. Meaningful interpretation of the results would also be a challenge. In settings where <italic toggle="yes">p</italic> is extremely large, an option could instead be to use a fast marginal correlation-based network approach, such as the weighted gene co-expression network analysis method of <xref rid="vbad185-B18" ref-type="bibr">Langfelder and Horvath (2008)</xref>, to identify subnetworks that are relevant for a more refined conditional independence network analysis.</p>
    <p>Future extensions of the method can include alternative measures of variability, such as the entropy [see, e.g. <xref rid="vbad185-B19" ref-type="bibr">Lartigue <italic toggle="yes">et al.</italic> (2020)</xref>]. Further, while the method is formulated specifically for the JGL with the fused penalty, it can in principle be used for any joint network approach requiring the tuning of sparsity- and similarity controlling parameters. Another relevant extension could be the introduction of network-specific sparsity penalty parameters <inline-formula id="IE138"><mml:math id="IM138" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> and network pair-specific similarity penalty parameters <inline-formula id="IE139"><mml:math id="IM139" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mi>k</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> for graphs <inline-formula id="IE140"><mml:math id="IM140" display="inline" overflow="scroll"><mml:mrow><mml:mn>1</mml:mn><mml:mo>≤</mml:mo><mml:mi>k</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>l</mml:mi><mml:mo>≤</mml:mo><mml:mi>K</mml:mi></mml:mrow></mml:math></inline-formula>, which would provide additional flexibility in terms of differing levels of sparsity and similarity across networks. The introduction of these parameters would however invoke a sharp increase in computational complexity, proportional to <inline-formula id="IE141"><mml:math id="IM141" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>K</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>.</p>
    <p>To conclude, stabJGL provides a reliable approach to joint network inference of omics data. The output can provide a better understanding of both common and data type-specific mechanisms, which can be used for hypothesis generation regarding potential therapeutic targets.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material id="sup1" position="float" content-type="local-data">
      <label>vbad185_Supplementary_Data</label>
      <media xlink:href="vbad185_supplementary_data.zip">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <sec>
    <title>Author contributions</title>
    <p>C.L. and S.R. developed the methodology. C.L. performed the data simulation and analysis, developed the software, and drafted the manuscript. Both authors have contributed to the manuscript and read and approved the final version.</p>
  </sec>
  <sec>
    <title>Supplementary data</title>
    <p><xref rid="sup1" ref-type="supplementary-material">Supplementary data</xref> are available at <italic toggle="yes">Bioinformatics Advances</italic> online.</p>
  </sec>
  <sec sec-type="COI-statement">
    <title>Conflict of interest</title>
    <p>None declared.</p>
  </sec>
  <sec>
    <title>Funding</title>
    <p>This work was supported by the UK Medical Research Council programme [MRC MC UU 00002/10 to C.L. and S.R.]; and Aker Scholarship (C.L.).</p>
  </sec>
  <sec sec-type="data-availability">
    <title>Data availability</title>
    <p>The TCGA data sets analysed in this article is publicly available in the University of California Santa Cruz Xena Browser repository (<ext-link xlink:href="http://xena.ucsc.edu" ext-link-type="uri">http://xena.ucsc.edu</ext-link>), from where we downloaded RPPA data for BRCA (dataset ID: TCGA.BRCA.sampleMap/RPPA_RBN), UCEC (dataset ID: TCGA.UCEC.sampleMap/RPPA_RBN) and OVCA (dataset ID: TCGA.OV.sampleMap/RPPA_RBN).</p>
  </sec>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="vbad185-B1">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Akaike</surname><given-names>H</given-names></string-name>, <string-name><surname>Petrov</surname><given-names>BN</given-names></string-name>, <string-name><surname>Csaki</surname><given-names>F.</given-names></string-name></person-group> Information theory and an extension of the maximum likelihood principle. In: <italic toggle="yes">Second International Symposium on Information Theory</italic>, New York, NY. New York: Springer, <year>1973</year>, <fpage>267</fpage>–<lpage>81</lpage>.</mixed-citation>
    </ref>
    <ref id="vbad185-B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Akbani</surname><given-names>R</given-names></string-name>, <string-name><surname>Ng</surname><given-names>PKS</given-names></string-name>, <string-name><surname>Werner</surname><given-names>HM</given-names></string-name></person-group><etal>et al</etal><article-title>A pan-cancer proteomic perspective on The Cancer Genome Atlas</article-title>. <source>Nat Commun</source><year>2014</year>;<volume>5</volume>:<fpage>3887</fpage>.<pub-id pub-id-type="pmid">24871328</pub-id></mixed-citation>
    </ref>
    <ref id="vbad185-B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bahassi</surname><given-names>E</given-names></string-name>, <string-name><surname>Ovesen</surname><given-names>J</given-names></string-name>, <string-name><surname>Riesenberg</surname><given-names>A</given-names></string-name></person-group><etal>et al</etal><article-title>The checkpoint kinases Chk1 and Chk2 regulate the functional associations between hBRCA2 and Rad51 in response to DNA damage</article-title>. <source>Oncogene</source><year>2008</year>;<volume>27</volume>:<fpage>3977</fpage>–<lpage>85</lpage>.<pub-id pub-id-type="pmid">18317453</pub-id></mixed-citation>
    </ref>
    <ref id="vbad185-B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Barabasi</surname><given-names>A-L</given-names></string-name>, <string-name><surname>Oltvai</surname><given-names>ZN.</given-names></string-name></person-group><article-title>Network biology: understanding the cell’s functional organization</article-title>. <source>Nat Rev Genet</source><year>2004</year>;<volume>5</volume>:<fpage>101</fpage>–<lpage>13</lpage>.<pub-id pub-id-type="pmid">14735121</pub-id></mixed-citation>
    </ref>
    <ref id="vbad185-B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Belletti</surname><given-names>B</given-names></string-name>, <string-name><surname>Baldassarre</surname><given-names>G.</given-names></string-name></person-group><article-title>Stathmin: a protein with many tasks. New biomarker and potential target in cancer</article-title>. <source>Expert Opin Ther Targets</source><year>2011</year>;<volume>15</volume>:<fpage>1249</fpage>–<lpage>66</lpage>.<pub-id pub-id-type="pmid">21978024</pub-id></mixed-citation>
    </ref>
    <ref id="vbad185-B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bergom</surname><given-names>C</given-names></string-name>, <string-name><surname>Gao</surname><given-names>C</given-names></string-name>, <string-name><surname>Newman</surname><given-names>PJ.</given-names></string-name></person-group><article-title>Mechanisms of PECAM-1-mediated cytoprotection and implications for cancer cell survival</article-title>. <source>Leuk Lymphoma</source><year>2005</year>;<volume>46</volume>:<fpage>1409</fpage>–<lpage>21</lpage>.<pub-id pub-id-type="pmid">16194886</pub-id></mixed-citation>
    </ref>
    <ref id="vbad185-B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bieche</surname><given-names>I</given-names></string-name>, <string-name><surname>Lachkar</surname><given-names>S</given-names></string-name>, <string-name><surname>Becette</surname><given-names>V</given-names></string-name></person-group><etal>et al</etal><article-title>Overexpression of the stathmin gene in a subset of human breast cancer</article-title>. <source>Br J Cancer</source><year>1998</year>;<volume>78</volume>:<fpage>701</fpage>–<lpage>9</lpage>.<pub-id pub-id-type="pmid">9743287</pub-id></mixed-citation>
    </ref>
    <ref id="vbad185-B8">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bonnet</surname><given-names>E</given-names></string-name>, <string-name><surname>Calzone</surname><given-names>L</given-names></string-name>, <string-name><surname>Michoel</surname><given-names>T.</given-names></string-name></person-group><article-title>Integrative multi-omics module network inference with lemon-tree</article-title>. <source>PLoS Comput Biol</source><year>2015</year>;<volume>11</volume>:<fpage>e1003983</fpage>.<pub-id pub-id-type="pmid">25679508</pub-id></mixed-citation>
    </ref>
    <ref id="vbad185-B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Boyd</surname><given-names>S</given-names></string-name>, <string-name><surname>Parikh</surname><given-names>N</given-names></string-name>, <string-name><surname>Chu</surname><given-names>E</given-names></string-name></person-group><etal>et al</etal><article-title>Distributed optimization and statistical learning via the alternating direction method of multipliers</article-title>. <source>FNT Mach Learn</source><year>2010</year>;<volume>3</volume>:<fpage>1</fpage>–<lpage>122</lpage>.</mixed-citation>
    </ref>
    <ref id="vbad185-B10">
      <mixed-citation publication-type="journal"><collab>Cancer Genome Atlas Network and others</collab>. <article-title>Comprehensive molecular portraits of human breast tumours</article-title>. <source>Nature</source><year>2012</year>;<volume>490</volume>:<fpage>61</fpage>–<lpage>70</lpage>.<pub-id pub-id-type="pmid">23000897</pub-id></mixed-citation>
    </ref>
    <ref id="vbad185-B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chen</surname><given-names>H</given-names></string-name>, <string-name><surname>Sharp</surname><given-names>BM.</given-names></string-name></person-group><article-title>Content-rich biological network constructed by mining PubMed abstracts</article-title>. <source>BMC Bioinformatics</source><year>2004</year>;<volume>5</volume>:<fpage>147</fpage>.<pub-id pub-id-type="pmid">15473905</pub-id></mixed-citation>
    </ref>
    <ref id="vbad185-B12">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Danaher</surname><given-names>P</given-names></string-name>, <string-name><surname>Wang</surname><given-names>P</given-names></string-name>, <string-name><surname>Witten</surname><given-names>DM.</given-names></string-name></person-group><article-title>The joint graphical lasso for inverse covariance estimation across multiple classes</article-title>. <source>J R Stat Soc Series B Stat Methodol</source><year>2014</year>;<volume>76</volume>:<fpage>373</fpage>–<lpage>97</lpage>.<pub-id pub-id-type="pmid">24817823</pub-id></mixed-citation>
    </ref>
    <ref id="vbad185-B13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fan</surname><given-names>J</given-names></string-name>, <string-name><surname>Feng</surname><given-names>Y</given-names></string-name>, <string-name><surname>Wu</surname><given-names>Y.</given-names></string-name></person-group><article-title>Network exploration via the adaptive LASSO and SCAD penalties</article-title>. <source>Ann Appl Stat</source><year>2009</year>;<volume>3</volume>:<fpage>521</fpage>.<pub-id pub-id-type="pmid">21643444</pub-id></mixed-citation>
    </ref>
    <ref id="vbad185-B14">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Foygel</surname><given-names>R</given-names></string-name>, <string-name><surname>Drton</surname><given-names>M.</given-names></string-name></person-group> Extended Bayesian information criteria for Gaussian graphical models. In <italic toggle="yes">Advances in Neural Information Processing Systems, Vancouver, BC</italic>, <fpage>604</fpage>–<lpage>12</lpage>. San Diego, CA: NeurIPS, <year>2010</year>.</mixed-citation>
    </ref>
    <ref id="vbad185-B15">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Friedman</surname><given-names>J</given-names></string-name>, <string-name><surname>Hastie</surname><given-names>T</given-names></string-name>, <string-name><surname>Tibshirani</surname><given-names>R.</given-names></string-name></person-group><article-title>Sparse inverse covariance estimation with the graphical lasso</article-title>. <source>Biostatistics</source><year>2008</year>;<volume>9</volume>:<fpage>432</fpage>–<lpage>41</lpage>.<pub-id pub-id-type="pmid">18079126</pub-id></mixed-citation>
    </ref>
    <ref id="vbad185-B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Goldman</surname><given-names>MJ</given-names></string-name>, <string-name><surname>Craft</surname><given-names>B</given-names></string-name>, <string-name><surname>Hastie</surname><given-names>M</given-names></string-name></person-group><etal>et al</etal><article-title>Visualizing and interpreting cancer genomics data via the Xena platform</article-title>. <source>Nat Biotechnol</source><year>2020</year>;<volume>38</volume>:<fpage>675</fpage>–<lpage>8</lpage>. doi: <pub-id pub-id-type="doi">10.1038/s41587-020-0546-8</pub-id><pub-id pub-id-type="pmid">32444850</pub-id></mixed-citation>
    </ref>
    <ref id="vbad185-B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Guo</surname><given-names>J</given-names></string-name>, <string-name><surname>Levina</surname><given-names>E</given-names></string-name>, <string-name><surname>Michailidis</surname><given-names>G</given-names></string-name></person-group><etal>et al</etal><article-title>Joint estimation of multiple graphical models</article-title>. <source>Biometrika</source><year>2011</year>;<volume>98</volume>:<fpage>1</fpage>–<lpage>15</lpage>.<pub-id pub-id-type="pmid">23049124</pub-id></mixed-citation>
    </ref>
    <ref id="vbad185-B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Langfelder</surname><given-names>P</given-names></string-name>, <string-name><surname>Horvath</surname><given-names>S.</given-names></string-name></person-group><article-title>WGCNA: an R package for weighted correlation network analysis</article-title>. <source>BMC Bioinformatics</source><year>2008</year>;<volume>1</volume>:<fpage>559</fpage>.</mixed-citation>
    </ref>
    <ref id="vbad185-B19">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lartigue</surname><given-names>T</given-names></string-name>, <string-name><surname>Bottani</surname><given-names>S</given-names></string-name>, <string-name><surname>Baron</surname><given-names>S</given-names></string-name></person-group><etal>et al</etal><article-title>Gaussian graphical model exploration and selection in high dimension low sample size setting</article-title>. <source>IEEE Trans Pattern Anal Mach Intell</source><year>2020</year>;<volume>43</volume>:<fpage>3196</fpage>–<lpage>213</lpage>.</mixed-citation>
    </ref>
    <ref id="vbad185-B20">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Lauritzen</surname><given-names>SL.</given-names></string-name></person-group><source>Graphical Models</source>. Vol. <volume>17</volume>. Oxford, UK: <publisher-name>Clarendon Press</publisher-name>, <year>1996</year>.</mixed-citation>
    </ref>
    <ref id="vbad185-B21">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Li</surname><given-names>Y</given-names></string-name>, <string-name><surname>Craig</surname><given-names>BA</given-names></string-name>, <string-name><surname>Bhadra</surname><given-names>A.</given-names></string-name></person-group><article-title>The graphical horseshoe estimator for inverse covariance matrices</article-title>. <source>J Comput Graph Stat</source><year>2019a</year>;<volume>28</volume>:<fpage>747</fpage>–<lpage>57</lpage>.</mixed-citation>
    </ref>
    <ref id="vbad185-B22">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Li</surname><given-names>Y</given-names></string-name>, <string-name><surname>Jackson</surname><given-names>SA.</given-names></string-name></person-group><article-title>Gene network reconstruction by integration of prior biological knowledge</article-title>. <source>G3 (Bethesda)</source><year>2015</year>;<volume>5</volume>:<fpage>1075</fpage>–<lpage>9</lpage>. doi: <pub-id pub-id-type="doi">10.1534/g3.115.018127</pub-id>.<pub-id pub-id-type="pmid">25823587</pub-id></mixed-citation>
    </ref>
    <ref id="vbad185-B23">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Li</surname><given-names>Z</given-names></string-name>, <string-name><surname>Mccormick</surname><given-names>T</given-names></string-name>, <string-name><surname>Clark</surname><given-names>S.</given-names></string-name></person-group> Bayesian joint spike-and-slab graphical lasso. In: <italic toggle="yes">International Conference on Machine Learning, Long Beach, CA</italic>. <fpage>3877</fpage>–<lpage>85</lpage>. <publisher-name>PMLR</publisher-name>, <year>2019b</year>.</mixed-citation>
    </ref>
    <ref id="vbad185-B24">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lingjærde</surname><given-names>C</given-names></string-name>, <string-name><surname>Fairfax</surname><given-names>BP</given-names></string-name>, <string-name><surname>Richardson</surname><given-names>S</given-names></string-name></person-group><etal>et al</etal><article-title>Scalable multiple network inference with the joint graphical horseshoe</article-title>. <source>Ann Appl Stat</source><year>2023</year>; in press.</mixed-citation>
    </ref>
    <ref id="vbad185-B25">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lingjærde</surname><given-names>C</given-names></string-name>, <string-name><surname>Lien</surname><given-names>TG</given-names></string-name>, <string-name><surname>Borgan</surname><given-names>Ø</given-names></string-name></person-group><etal>et al</etal><article-title>Tailored graphical lasso for data integration in gene network reconstruction</article-title>. <source>BMC Bioinformatics</source><year>2021</year>;<volume>22</volume>:<fpage>498</fpage>.<pub-id pub-id-type="pmid">34654363</pub-id></mixed-citation>
    </ref>
    <ref id="vbad185-B26">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Liu</surname><given-names>H</given-names></string-name>, <string-name><surname>Roeder</surname><given-names>K</given-names></string-name>, <string-name><surname>Wasserman</surname><given-names>L.</given-names></string-name></person-group><article-title>Stability approach to regularization selection (StARS) for high dimensional graphical models</article-title>. <source>Adv Neural Inf Process Syst</source><year>2010</year>;<volume>24</volume>:<fpage>1432</fpage>–<lpage>40</lpage>.<pub-id pub-id-type="pmid">25152607</pub-id></mixed-citation>
    </ref>
    <ref id="vbad185-B27">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Meinshausen</surname><given-names>N</given-names></string-name>, <string-name><surname>Bühlmann</surname><given-names>P.</given-names></string-name></person-group><article-title>High-dimensional graphs and variable selection with the lasso</article-title>. <source>Ann Statist</source><year>2006</year>;<volume>34</volume>:<fpage>1436</fpage>–<lpage>62</lpage>.</mixed-citation>
    </ref>
    <ref id="vbad185-B28">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Miricescu</surname><given-names>D</given-names></string-name>, <string-name><surname>Totan</surname><given-names>A</given-names></string-name>, <string-name><surname>Stanescu-Spinu</surname><given-names>I-I</given-names></string-name></person-group><etal>et al</etal><article-title>PI3K/AKT/mTOR signaling pathway in breast cancer: from molecular landscape to clinical aspects</article-title>. <source>Int J Mol Sci</source><year>2020</year>;<volume>22</volume>:<fpage>173</fpage>.<pub-id pub-id-type="pmid">33375317</pub-id></mixed-citation>
    </ref>
    <ref id="vbad185-B29">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nair</surname><given-names>J</given-names></string-name>, <string-name><surname>Huang</surname><given-names>T-T</given-names></string-name>, <string-name><surname>Murai</surname><given-names>J</given-names></string-name></person-group><etal>et al</etal><article-title>Resistance to the CHK1 inhibitor prexasertib involves functionally distinct CHK1 activities in BRCA wild-type ovarian cancer</article-title>. <source>Oncogene</source><year>2020</year>;<volume>39</volume>:<fpage>5520</fpage>–<lpage>35</lpage>.<pub-id pub-id-type="pmid">32647134</pub-id></mixed-citation>
    </ref>
    <ref id="vbad185-B30">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nielsen</surname><given-names>MD</given-names></string-name>, <string-name><surname>Luo</surname><given-names>X</given-names></string-name>, <string-name><surname>Biteau</surname><given-names>B</given-names></string-name></person-group><etal>et al</etal><article-title>14-3-3-Epsilon antagonizes FoxO to control growth, apoptosis and longevity in Drosophila</article-title>. <source>Aging Cell</source><year>2008</year>;<volume>7</volume>:<fpage>688</fpage>–<lpage>99</lpage>.<pub-id pub-id-type="pmid">18665908</pub-id></mixed-citation>
    </ref>
    <ref id="vbad185-B31">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Peterson</surname><given-names>C</given-names></string-name>, <string-name><surname>Stingo</surname><given-names>FC</given-names></string-name>, <string-name><surname>Vannucci</surname><given-names>M.</given-names></string-name></person-group><article-title>Bayesian inference of multiple Gaussian graphical models</article-title>. <source>J Am Stat Assoc</source><year>2015</year>;<volume>110</volume>:<fpage>159</fpage>–<lpage>74</lpage>.<pub-id pub-id-type="pmid">26078481</pub-id></mixed-citation>
    </ref>
    <ref id="vbad185-B32">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Schwarz</surname><given-names>G.</given-names></string-name></person-group><article-title>Estimating the dimension of a model</article-title>. <source>Ann Statist</source><year>1978</year>;<volume>6</volume>:<fpage>461</fpage>–<lpage>4</lpage>.</mixed-citation>
    </ref>
    <ref id="vbad185-B33">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Szklarczyk</surname><given-names>D</given-names></string-name>, <string-name><surname>Gable</surname><given-names>AL</given-names></string-name>, <string-name><surname>Lyon</surname><given-names>D</given-names></string-name></person-group><etal>et al</etal><article-title>STRING v11: protein-protein association networks with increased coverage, supporting functional discovery in genome-wide experimental datasets</article-title>. <source>Nucleic Acids Res</source><year>2019</year>;<volume>47</volume>:<fpage>D607</fpage>–<lpage>13</lpage>.<pub-id pub-id-type="pmid">30476243</pub-id></mixed-citation>
    </ref>
    <ref id="vbad185-B34">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Trovik</surname><given-names>J</given-names></string-name>, <string-name><surname>Wik</surname><given-names>E</given-names></string-name>, <string-name><surname>Stefansson</surname><given-names>IM</given-names></string-name></person-group><etal>et al</etal>; <collab>MoMaTec Study Group</collab>. <article-title>Stathmin overexpression identifies high-risk patients and lymph node metastasis in endometrial cancer</article-title>. <source>Clin Cancer Res</source><year>2011</year>;<volume>17</volume>:<fpage>3368</fpage>–<lpage>77</lpage>.<pub-id pub-id-type="pmid">21242118</pub-id></mixed-citation>
    </ref>
    <ref id="vbad185-B35">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tzivion</surname><given-names>G</given-names></string-name>, <string-name><surname>Dobson</surname><given-names>M</given-names></string-name>, <string-name><surname>Ramakrishnan</surname><given-names>G.</given-names></string-name></person-group><article-title>FoxO transcription factors; Regulation by AKT and 14-3-3 proteins</article-title>. <source>Biochim Biophys Acta</source><year>2011</year>;<volume>1813</volume>:<fpage>1938</fpage>–<lpage>45</lpage>.<pub-id pub-id-type="pmid">21708191</pub-id></mixed-citation>
    </ref>
    <ref id="vbad185-B36">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname><given-names>H.</given-names></string-name></person-group><article-title>Bayesian graphical lasso models and efficient posterior computation</article-title>. <source>Bayesian Anal</source><year>2012</year>;<volume>7</volume>:<fpage>867</fpage>–<lpage>86</lpage>.</mixed-citation>
    </ref>
    <ref id="vbad185-B37">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname><given-names>H.</given-names></string-name></person-group><article-title>Scaling it up: stochastic search structure learning in graphical models</article-title>. <source>Bayesian Anal</source><year>2015</year>;<volume>10</volume>:<fpage>351</fpage>–<lpage>77</lpage>.</mixed-citation>
    </ref>
    <ref id="vbad185-B38">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yang</surname><given-names>J-Y</given-names></string-name>, <string-name><surname>Yoshihara</surname><given-names>K</given-names></string-name>, <string-name><surname>Tanaka</surname><given-names>K</given-names></string-name></person-group><etal>et al</etal>; <collab>Cancer Genome Atlas (TCGA) Research Network</collab>. <article-title>Predicting time to ovarian carcinoma recurrence using protein markers</article-title>. <source>J Clin Investig</source><year>2013</year>;<volume>123</volume>:<fpage>3740</fpage>–<lpage>50</lpage>.<pub-id pub-id-type="pmid">23945238</pub-id></mixed-citation>
    </ref>
    <ref id="vbad185-B39">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname><given-names>H</given-names></string-name>, <string-name><surname>Liu</surname><given-names>T</given-names></string-name>, <string-name><surname>Zhang</surname><given-names>Z</given-names></string-name></person-group><etal>et al</etal>; <collab>CPTAC Investigators</collab>. <article-title>Integrated proteogenomic characterization of human high-grade serous ovarian cancer</article-title>. <source>Cell</source><year>2016</year>;<volume>166</volume>:<fpage>755</fpage>–<lpage>65</lpage>.<pub-id pub-id-type="pmid">27372738</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinform Adv</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinform Adv</journal-id>
    <journal-id journal-id-type="publisher-id">bioadv</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics Advances</journal-title>
    </journal-title-group>
    <issn pub-type="epub">2635-0041</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">10751232</article-id>
    <article-id pub-id-type="doi">10.1093/bioadv/vbad185</article-id>
    <article-id pub-id-type="publisher-id">vbad185</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Original Article</subject>
        <subj-group subj-group-type="category-toc-heading">
          <subject>Systems Biology</subject>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI01060</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>StabJGL: a stability approach to sparsity and similarity selection in multiple-network reconstruction</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0003-2701-5686</contrib-id>
        <name>
          <surname>Lingjærde</surname>
          <given-names>Camilla</given-names>
        </name>
        <aff><institution>MRC Biostatistics Unit, University of Cambridge</institution>, Cambridge CB2 0SR, <country country="GB">United Kingdom</country></aff>
        <xref rid="vbad185-cor1" ref-type="corresp"/>
        <!--camilla.lingjaerde@mrc-bsu.cam.ac.uk-->
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Richardson</surname>
          <given-names>Sylvia</given-names>
        </name>
        <aff><institution>MRC Biostatistics Unit, University of Cambridge</institution>, Cambridge CB2 0SR, <country country="GB">United Kingdom</country></aff>
      </contrib>
    </contrib-group>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Lengauer</surname>
          <given-names>Thomas</given-names>
        </name>
        <role>Associate Editor</role>
      </contrib>
    </contrib-group>
    <author-notes>
      <corresp id="vbad185-cor1">Corresponding author. MRC Biostatistics Unit, University of Cambridge, East Forvie Building, Forvie Site, Robinson Way, Cambridge CB2 0SR, United Kingdom. E-mail: <email>camilla.lingjaerde@mrc-bsu.cam.ac.uk</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2023-12-19">
      <day>19</day>
      <month>12</month>
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>19</day>
      <month>12</month>
      <year>2023</year>
    </pub-date>
    <volume>3</volume>
    <issue>1</issue>
    <elocation-id>vbad185</elocation-id>
    <history>
      <date date-type="received">
        <day>28</day>
        <month>6</month>
        <year>2023</year>
      </date>
      <date date-type="rev-recd">
        <day>23</day>
        <month>11</month>
        <year>2023</year>
      </date>
      <date date-type="editorial-decision">
        <day>11</day>
        <month>12</month>
        <year>2023</year>
      </date>
      <date date-type="accepted">
        <day>18</day>
        <month>12</month>
        <year>2023</year>
      </date>
      <date date-type="corrected-typeset">
        <day>26</day>
        <month>12</month>
        <year>2023</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2023. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2023</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="vbad185.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Motivation</title>
        <p>In recent years, network models have gained prominence for their ability to capture complex associations. In statistical omics, networks can be used to model and study the functional relationships between genes, proteins, and other types of omics data. If a Gaussian graphical model is assumed, a gene association network can be determined from the non-zero entries of the inverse covariance matrix of the data. Due to the high-dimensional nature of such problems, integrative methods that leverage similarities between multiple graphical structures have become increasingly popular. The joint graphical lasso is a powerful tool for this purpose, however, the current AIC-based selection criterion used to tune the network sparsities and similarities leads to poor performance in high-dimensional settings.</p>
      </sec>
      <sec id="s2">
        <title>Results</title>
        <p>We propose stabJGL, which equips the joint graphical lasso with a stable and well-performing penalty parameter selection approach that combines the notion of model stability with likelihood-based similarity selection. The resulting method makes the powerful joint graphical lasso available for use in omics settings, and outperforms the standard joint graphical lasso, as well as state-of-the-art joint methods, in terms of all performance measures we consider. Applying stabJGL to proteomic data from a pan-cancer study, we demonstrate the potential for novel discoveries the method brings.</p>
      </sec>
      <sec id="s3">
        <title>Availability and implementation</title>
        <p>A user-friendly R package for stabJGL with tutorials is available on Github <ext-link xlink:href="https://github.com/Camiling/stabJGL" ext-link-type="uri">https://github.com/Camiling/stabJGL</ext-link>.</p>
      </sec>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>UK Medical Research Council programme</institution>
          </institution-wrap>
        </funding-source>
        <award-id>MRC MC UU 00002/10</award-id>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="10"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 Introduction</title>
    <p>Network models have in recent years gained great popularity in many areas. In statistical omics, networks can be used to decode aspects of unknown structures, and hence study the relationships between genes, proteins, and other types of omics data. In health data sciences, rich datasets are more and more frequently encountered, enabling the development of models integrating a variety of biological resources. In the high-dimensional setting commonly found in omics, sharing information between independent observations from data sources with shared structures—which could be different tissues, conditions or patient subgroups—can give a valuable increase in statistical power while elucidating shared biological function. A key question is how to combine the different data sources into a single model.</p>
    <p>If a Gaussian graphical model is assumed, a conditional (in)dependence network can be estimated by determining the non-zero entries of the inverse covariance (precision) matrix of the data. With its good performance in numerical studies, the “graphical lasso” (Glasso) of <xref rid="vbad185-B15" ref-type="bibr">Friedman <italic toggle="yes">et al.</italic> (2008)</xref> is a state-of-the-art method for precision matrix estimation in the setting of Gaussian graphical models. The method combines <inline-formula id="IE1"><mml:math id="IM1" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> regularization with maximum likelihood estimation. Other notable methods include the neighborhood selection approach of <xref rid="vbad185-B27" ref-type="bibr">Meinshausen and Bühlmann (2006)</xref> and the graphical SCAD (<xref rid="vbad185-B13" ref-type="bibr">Fan <italic toggle="yes">et al.</italic> 2009</xref>). Notable Bayesian methods include the Bayesian Glasso (<xref rid="vbad185-B37" ref-type="bibr">Wang 2012</xref>), Bayesian spike-and-slab approaches (<xref rid="vbad185-B36" ref-type="bibr">Wang 2015</xref>), and the graphical horseshoe (<xref rid="vbad185-B22" ref-type="bibr">Li <italic toggle="yes">et al.</italic> 2019a</xref>).</p>
    <p>If multiple related datasets available, there are several ways to leverage common network structures. If focusing on one data type’s network structure, data from other types can enhance inference via weighted Glasso methods (<xref rid="vbad185-B21" ref-type="bibr">Li and Jackson 2015</xref>, <xref rid="vbad185-B24" ref-type="bibr">Lingjærde <italic toggle="yes">et al.</italic> 2021</xref>). However, to compare network structures across datasets, such as patient subgroups, a joint approach that leverages common information while preserving the differences can increase statistical power and provide interpretable insight.</p>
    <p>In the area of multiple Gaussian graphical models, existing methods include the group extension of the Glasso to multiple networks of <xref rid="vbad185-B17" ref-type="bibr">Guo <italic toggle="yes">et al.</italic> (2011)</xref>, the Bayesian spike-and-slab joint graphical lasso (JGL) (<xref rid="vbad185-B23" ref-type="bibr">Li <italic toggle="yes">et al.</italic> 2019b</xref>), and the Markov random field approach of <xref rid="vbad185-B31" ref-type="bibr">Peterson <italic toggle="yes">et al.</italic> (2015)</xref>. The widely used JGL of <xref rid="vbad185-B12" ref-type="bibr">Danaher <italic toggle="yes">et al.</italic> (2014)</xref> extends the Glasso to a multiple-network setting and provides a powerful tool for inferring graphs with common traits. It employs two different penalty functions—group joint graphical lasso (GGL) and fused joint graphical lasso (FGL)—with the latter recommended for most applications. From this point forward, any mention of the JGL will imply the fused version, unless otherwise specified. The method needs tuning of two regularization parameters for controlling (i) the number of non-zero effects, and (ii) the similarity between networks, respectively. However, the default parameter selection routine based on the AIC (<xref rid="vbad185-B1" ref-type="bibr">Akaike <italic toggle="yes">et al.</italic> 1973</xref>) often results in severe over-selection in high-dimensional data, potentially impacting performance negatively (<xref rid="vbad185-B14" ref-type="bibr">Foygel and Drton 2010</xref>, <xref rid="vbad185-B26" ref-type="bibr">Liu <italic toggle="yes">et al.</italic> 2010</xref>).</p>
    <p>We propose a stable and well-performing penalty parameter selection method for the JGL, combining the model stability principle of <xref rid="vbad185-B26" ref-type="bibr">Liu <italic toggle="yes">et al.</italic> (2010)</xref> with likelihood-based selection for high-dimensional data (<xref rid="vbad185-B14" ref-type="bibr">Foygel and Drton 2010</xref>). The resulting method inherits the powerful traits of the JGL while mitigating the risk of severe under- or over-selection of edges in high-dimensional settings. We provide an R package, <monospace>stabJGL</monospace> (stable sparsity and similarity selection for the JGL), which implements the method.</p>
    <p>The article is organized as follows. In Section 2, we first describe the Gaussian graphical model framework and the penalized log-likelihood problem we aim to solve. We then describe our proposed algorithm. In Section 3, we demonstrate the performance of our proposed method on simulated data and apply it proteomic data from a pan-cancer study of hormonally responsive cancers. Finally, we highlight possible extensions in Section 4.</p>
  </sec>
  <sec>
    <title>2 Methods</title>
    <sec>
      <title>2.1 Gaussian graphical models</title>
      <p>In a gene network model, genes are represented by “nodes” and associations between them are represented by “edges.” Given measurable molecular units each corresponding to one gene (e.g. the encoded protein or mRNA), a network, or graph, can be constructed from their observed values.</p>
      <p>Consider <italic toggle="yes">n</italic> observed values of the multivariate random vector <inline-formula id="IE2"><mml:math id="IM2" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mi>p</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mi>T</mml:mi></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula> of node attributes, with each entry corresponding to one of <italic toggle="yes">p</italic> nodes. If we assume multivariate Gaussian node attributes, with an <inline-formula id="IE3"><mml:math id="IM3" display="inline" overflow="scroll"><mml:mrow><mml:mi>n</mml:mi><mml:mo>×</mml:mo><mml:mi>p</mml:mi></mml:mrow></mml:math></inline-formula> observation matrix <inline-formula id="IE4"><mml:math id="IM4" display="inline" overflow="scroll"><mml:mi mathvariant="bold-italic">X</mml:mi></mml:math></inline-formula> with i.i.d. rows <inline-formula id="IE5"><mml:math id="IM5" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msub></mml:mrow><mml:mo>∼</mml:mo><mml:mi mathvariant="script">N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi mathvariant="bold">Σ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, a “partial correlation network” can be determined by estimating the inverse covariance matrix, or precision matrix, <inline-formula id="IE6"><mml:math id="IM6" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold">Θ</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>. Specifically, the partial correlation between nodes <italic toggle="yes">i</italic> and <italic toggle="yes">j</italic>, conditional upon the rest of the graph, is given by
<disp-formula id="E1"><mml:math id="M1" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>ρ</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi><mml:mo>|</mml:mo><mml:mi>V</mml:mi><mml:mo>\</mml:mo><mml:mo>{</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>}</mml:mo></mml:mrow></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>θ</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mrow><mml:msqrt><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>θ</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>θ</mml:mo></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:msqrt></mml:mrow></mml:mfrac></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>
where the <inline-formula id="IE7"><mml:math id="IM7" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>θ</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>’s are the entries of <inline-formula id="IE8"><mml:math id="IM8" display="inline" overflow="scroll"><mml:mi mathvariant="bold">Θ</mml:mi></mml:math></inline-formula> and <italic toggle="yes">V</italic> the set of all node pairs (<xref rid="vbad185-B20" ref-type="bibr">Lauritzen 1996</xref>). The partial correlations coincide with the conditional correlations in the Gaussian setting. Because correlation (resp. partial correlation) equal to zero is equivalent to independence (resp. conditional independence) for Gaussian variables, a conditional independence graph can thus be constructed by determining the non-zero entries of the precision matrix. To ensure invertibility, the precision matrix also required to be positive definite, <inline-formula id="IE9"><mml:math id="IM9" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold">Θ</mml:mi><mml:mo>≻</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>.</p>
      <p>In high-dimensional settings, the sample covariance matrix <inline-formula id="IE10"><mml:math id="IM10" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold-italic">S</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfrac></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">X</mml:mi></mml:mrow><mml:mi>T</mml:mi></mml:msup></mml:mrow><mml:mi mathvariant="bold-italic">X</mml:mi></mml:mrow></mml:math></inline-formula> is rarely of full rank and thus its inverse cannot be estimated directly. It is common to assume sparse network, meaning the number of edges in the edge set <italic toggle="yes">E</italic> is small relative to the number of potential edges in the graph (i.e. the sparsity measure <inline-formula id="IE11"><mml:math id="IM11" display="inline" overflow="scroll"><mml:mrow><mml:mn>2</mml:mn><mml:mo>|</mml:mo><mml:mi>E</mml:mi><mml:mo>|</mml:mo><mml:mo>/</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mo>−</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> is small). Penalized methods, such as the Glasso (<xref rid="vbad185-B15" ref-type="bibr">Friedman <italic toggle="yes">et al.</italic> 2008</xref>) are well established for sparse Gaussian graphical model estimation. In the case of there being multiple (related) datasets available, such as from different tissue types, rather than estimating each network separately much statistical power could be gained by sharing information across networks through a joint approach.</p>
    </sec>
    <sec>
      <title>2.2 Penalized log-likelihood problem</title>
      <p>Assume a network inference problem with <italic toggle="yes">K</italic> groups. We let <inline-formula id="IE12"><mml:math id="IM12" display="inline" overflow="scroll"><mml:mrow><mml:mo>{</mml:mo><mml:mi mathvariant="bold">Θ</mml:mi><mml:mo>}</mml:mo><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">Θ</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">Θ</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>K</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> be the set of their (unknown) precision matrices, and assume that the set of <inline-formula id="IE13"><mml:math id="IM13" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:munderover></mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> observations are independent. We aim to solve the penalized log-likelihood problem (<xref rid="vbad185-B12" ref-type="bibr">Danaher <italic toggle="yes">et al.</italic> 2014</xref>)
<disp-formula id="E2"><label>(1)</label><mml:math id="M2" display="block" overflow="scroll"><mml:mtable><mml:mtr><mml:mtd><mml:mtable><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">Θ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo>}</mml:mo></mml:mrow><mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:munder><mml:mrow><mml:mtext>argmax</mml:mtext></mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mi mathvariant="bold">Θ</mml:mi><mml:mo>≻</mml:mo><mml:mn>0</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:munder></mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:munderover></mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mtext>log</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mi>det</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">Θ</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mtext>tr</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">S</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">Θ</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>−</mml:mo><mml:mi mathvariant="normal">P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>{</mml:mo><mml:mi mathvariant="bold">Θ</mml:mi><mml:mo>}</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>}</mml:mo><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>
where <inline-formula id="IE14"><mml:math id="IM14" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">S</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula> is the sample covariance matrix of group <italic toggle="yes">k</italic> and <inline-formula id="IE15"><mml:math id="IM15" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="normal">P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>⋅</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> is a penalty function. In (1), <inline-formula id="IE16"><mml:math id="IM16" display="inline" overflow="scroll"><mml:mrow><mml:mi>det</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>⋅</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> denotes the determinant and <inline-formula id="IE17"><mml:math id="IM17" display="inline" overflow="scroll"><mml:mrow><mml:mtext>tr</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mo>⋅</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> denotes the trace. The JGL employs the fused penalty function
<disp-formula id="E3"><label>(2)</label><mml:math id="M3" display="block" overflow="scroll"><mml:mrow><mml:mi mathvariant="normal">P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>{</mml:mo><mml:mi mathvariant="bold">Θ</mml:mi><mml:mo>}</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:munderover></mml:mrow><mml:mrow><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>≠</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mtext>abs</mml:mtext></mml:mrow></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mo>θ</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>&lt;</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msup></mml:mrow></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mo>|</mml:mo></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">Θ</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">Θ</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>
where <inline-formula id="IE18"><mml:math id="IM18" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE19"><mml:math id="IM19" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> are positive penalty parameters, <inline-formula id="IE20"><mml:math id="IM20" display="inline" overflow="scroll"><mml:mrow><mml:mtext>abs</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mo>⋅</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> denotes the absolute value function and <inline-formula id="IE21"><mml:math id="IM21" display="inline" overflow="scroll"><mml:mrow><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:mo>⋅</mml:mo><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> denotes the <inline-formula id="IE22"><mml:math id="IM22" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">L</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> penalty. This penalty applies <inline-formula id="IE23"><mml:math id="IM23" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">L</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> penalties to each off-diagonal element of the <italic toggle="yes">K</italic> precision matrices as well as to the differences between corresponding elements of each pair of precision matrices. The parameter <inline-formula id="IE24"><mml:math id="IM24" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> controls the sparsity, and the similarity parameter <inline-formula id="IE25"><mml:math id="IM25" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> controls the degree to which the <italic toggle="yes">K</italic> precision matrices are forced toward each other, encouraging not only similar network structures but also similar precision matrix entries. This way, the dependency between observed datasets is modeled through their underlying graphical structures. It is important to note that a necessary assumption of the resulting model is that given their respective graphical structures, observations are independent across and within each dataset. The current penalty parameter selection approach for <inline-formula id="IE26"><mml:math id="IM26" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE27"><mml:math id="IM27" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> is based on the AIC (<xref rid="vbad185-B12" ref-type="bibr">Danaher <italic toggle="yes">et al.</italic> 2014</xref>), and while suitable for determining network similarities, likelihood-based selection criteria can lead to severe under- or over-selection and thus poor performance in high-dimensional settings (<xref rid="vbad185-B26" ref-type="bibr">Liu <italic toggle="yes">et al.</italic> 2010</xref>).</p>
    </sec>
    <sec>
      <title>2.3 The stabJGL algorithm</title>
      <p>To improve the performance of the JGL with the fused penalty for omics applications and other high-dimensional problems, we propose the stabJGL algorithm for stable sparsity and similarity selection in multiple-network reconstruction. StabJGL jointly estimates multiple networks by leveraging their common information and gives a basis for deeper exploration of their differences, as shown in <xref rid="vbad185-F1" ref-type="fig">Fig. 1</xref>. Below we outline the algorithm, which comprised two steps: (i) selecting the sparsity parameter <inline-formula id="IE28"><mml:math id="IM28" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> in the fused penalty (2) based on the notion of model stability, and (ii) selecting the similarity parameter <inline-formula id="IE29"><mml:math id="IM29" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> based on model likelihood. The full StabJGL algorithm is given in <xref rid="sup1" ref-type="supplementary-material">Supplementary Algorithm S1</xref>.</p>
      <fig position="float" id="vbad185-F1">
        <label>Figure 1.</label>
        <caption>
          <p>The workflow of stabJGL, where the network structures of different data types or conditions are jointly estimated and can then be compared.</p>
        </caption>
        <graphic xlink:href="vbad185f1" position="float"/>
      </fig>
      <sec>
        <title>2.3.1 Selecting <inline-formula id="IE30"><mml:math id="IM30" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">λ</mml:mi></mml:mrow><mml:mi mathvariant="bold">1</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula></title>
        <p>We first select <inline-formula id="IE31"><mml:math id="IM31" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> by extending the framework introduced by <xref rid="vbad185-B26" ref-type="bibr">Liu <italic toggle="yes">et al.</italic> (2010)</xref> in their Stability Approach to regularization Criterion (StARS) to a multiple-network setting. The aim is to select the least amount of penalization that makes graphs sparse as well as reproducible under random subsampling. This is done by drawing many random subsamples from each of the <italic toggle="yes">K</italic> data types and using them to construct JGL graphs over a range of <inline-formula id="IE32"><mml:math id="IM32" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> values. The smallest parameter value for which a given graph estimation variability measure does not surpass a specified threshold is then selected. We use a measure of edge assignment instability across subsamples to quantify the variability.</p>
        <p>Specifically, we consider a grid of <inline-formula id="IE33"><mml:math id="IM33" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> values in a suitable interval, i.e. <inline-formula id="IE34"><mml:math id="IM34" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></inline-formula> and keep the similarity parameter <inline-formula id="IE35"><mml:math id="IM35" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> fixed to some small value, such as 0.01 in the first instance. For <inline-formula id="IE36"><mml:math id="IM36" display="inline" overflow="scroll"><mml:mrow><mml:mo>η</mml:mo><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mtext>sample</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>, we draw a random subsample from each group <italic toggle="yes">k’</italic>s set of <inline-formula id="IE37"><mml:math id="IM37" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> observations without replacement, each of size <inline-formula id="IE38"><mml:math id="IM38" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msub></mml:mrow><mml:mo>&lt;</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>. For each value of <inline-formula id="IE39"><mml:math id="IM39" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> to consider, we next construct the corresponding set of JGL graphs <inline-formula id="IE40"><mml:math id="IM40" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>η</mml:mo></mml:msubsup></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>}</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula> from these <italic toggle="yes">K</italic> sets of subsamples, using the fused penalty (2).</p>
        <p>The following is then done for each value of <inline-formula id="IE41"><mml:math id="IM41" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> we consider. For each group <inline-formula id="IE42"><mml:math id="IM42" display="inline" overflow="scroll"><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>K</mml:mi></mml:mrow></mml:math></inline-formula> and all possible node pairs <inline-formula id="IE43"><mml:math id="IM43" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> we estimate the probability of an edge between the nodes over the <inline-formula id="IE44"><mml:math id="IM44" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mtext>sample</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> inferred sets of graphs
<disp-formula id="E4"><label>(3)</label><mml:math id="M4" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>ψ</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mtext>sample</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mfrac></mml:mrow><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mo>η</mml:mo><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mtext>sample</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:munderover></mml:mrow><mml:mrow><mml:mi mathvariant="double-struck">1</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>∈</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>η</mml:mo></mml:msubsup></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>
where <inline-formula id="IE45"><mml:math id="IM45" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="double-struck">1</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mo>⋅</mml:mo><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the indicator function. Using this estimated probability, we find
<disp-formula id="E5"><label>(4)</label><mml:math id="M5" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>ξ</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>ψ</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>ψ</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>
which is an estimate of two times the variance of the Bernoulli indicator of the edge <inline-formula id="IE46"><mml:math id="IM46" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> in group <italic toggle="yes">k</italic>. It lies in [0, 0.5] and can be regarded as an estimate of the proportion of times two inferred graphs for group <italic toggle="yes">k</italic> found with the given <inline-formula id="IE47"><mml:math id="IM47" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> value will disagree on the presence of the edge <inline-formula id="IE48"><mml:math id="IM48" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>. Due to the <inline-formula id="IE49"><mml:math id="IM49" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> penalty in (2), the number of inferred edges will decrease as <inline-formula id="IE50"><mml:math id="IM50" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> is increased.</p>
        <p>For a given <inline-formula id="IE51"><mml:math id="IM51" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>, <inline-formula id="IE52"><mml:math id="IM52" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>ξ</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> can be regarded as a measure of the variability of the edge <inline-formula id="IE53"><mml:math id="IM53" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> in group <italic toggle="yes">k</italic> across subsamples, and the total variability of graph <italic toggle="yes">k</italic> can be measured by averaging over all edges, yielding the estimate
<disp-formula id="E6"><label>(5)</label><mml:math id="M6" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>D</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mtable><mml:mtr><mml:mtd><mml:mi>p</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>2</mml:mn></mml:mtd></mml:mtr></mml:mtable><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>ξ</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p>
        <p>For each value of <inline-formula id="IE54"><mml:math id="IM54" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>, the total variability of the whole set of graphs found by the JGL is then found by averaging the variability over all <italic toggle="yes">K</italic> networks
<disp-formula id="E7"><label>(6)</label><mml:math id="M7" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>D</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>K</mml:mi></mml:mfrac></mml:mrow><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:munderover></mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>D</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p>
        <p>For sufficiently large <inline-formula id="IE55"><mml:math id="IM55" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>, all edges are excluded from the model and so the variability <inline-formula id="IE56"><mml:math id="IM56" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>D</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> will be 0. The variability will in general increase as the penalty <inline-formula id="IE57"><mml:math id="IM57" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> decreases, however, for small enough <inline-formula id="IE58"><mml:math id="IM58" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> the graphs will become so dense that the variability starts to decrease again. As sparse network inference is the aim, we therefore monotonize the variability function by letting <inline-formula id="IE59"><mml:math id="IM59" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>D</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:munder><mml:mrow><mml:mi>sup</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>≥</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>D</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>.</p>
        <p>Finally, for a given variability threshold <inline-formula id="IE60"><mml:math id="IM60" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>β</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>, the optimal penalty is chosen to be <inline-formula id="IE61"><mml:math id="IM61" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>λ</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mi>inf</mml:mi><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>:</mml:mo><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>D</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>≤</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mo>β</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula>. As opposed to <inline-formula id="IE62"><mml:math id="IM62" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>, <inline-formula id="IE63"><mml:math id="IM63" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>β</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> is an interpretable quantity and we propose a default threshold of <inline-formula id="IE64"><mml:math id="IM64" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>β</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mn>0.1</mml:mn></mml:mrow></mml:math></inline-formula> as suggested by Liu <italic toggle="yes">et al.</italic> for the original StARS algorithm, which reflects an acceptance of <inline-formula id="IE65"><mml:math id="IM65" display="inline" overflow="scroll"><mml:mrow><mml:mn>10</mml:mn><mml:mo>%</mml:mo></mml:mrow></mml:math></inline-formula> variability in the edge assignments.</p>
      </sec>
      <sec>
        <title>2.3.2 Selecting <inline-formula id="IE66"><mml:math id="IM66" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">λ</mml:mi></mml:mrow><mml:mi mathvariant="bold-italic">2</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula></title>
        <p>After <inline-formula id="IE67"><mml:math id="IM67" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> has been selected, we select <inline-formula id="IE68"><mml:math id="IM68" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> with a multiple-network version of the extended BIC (eBIC or <inline-formula id="IE69"><mml:math id="IM69" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mtext>BIC</mml:mtext></mml:mrow></mml:mrow><mml:mo>γ</mml:mo></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>) of <xref rid="vbad185-B14" ref-type="bibr">Foygel and Drton (2010)</xref>. The eBIC is an extension of the Bayesian Information Criterion of <xref rid="vbad185-B32" ref-type="bibr">Schwarz (1978)</xref>, where the prior is reformulated to account for high-dimensional graphical settings. We propose an adaptation the eBIC to a multiple-network setting,
<disp-formula id="E8"><label>(7)</label><mml:math id="M8" display="block" overflow="scroll"><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mrow><mml:mtext>BIC</mml:mtext></mml:mrow><mml:mo>γ</mml:mo></mml:msub></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:munderover></mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msub></mml:mrow><mml:mtext>tr</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">S</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">Θ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msub></mml:mrow><mml:mo> </mml:mo><mml:mtext>log</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mi>det</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">Θ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>+</mml:mo><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msub></mml:mrow><mml:mo>|</mml:mo><mml:mo> </mml:mo><mml:mtext>log</mml:mtext><mml:mo> </mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msub></mml:mrow><mml:mo>+</mml:mo><mml:mn>4</mml:mn><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msub></mml:mrow><mml:mo>|</mml:mo><mml:mo>γ</mml:mo><mml:mo> </mml:mo><mml:mtext>log</mml:mtext><mml:mo> </mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">]</mml:mo><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>
where <inline-formula id="IE70"><mml:math id="IM70" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">Θ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula> is the estimated precision matrix of network <italic toggle="yes">k</italic> obtained with the penalty parameters <inline-formula id="IE71"><mml:math id="IM71" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE72"><mml:math id="IM72" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>, <inline-formula id="IE73"><mml:math id="IM73" display="inline" overflow="scroll"><mml:mrow><mml:mo>γ</mml:mo><mml:mo>∈</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></inline-formula> is an additional penalty parameter and <inline-formula id="IE74"><mml:math id="IM74" display="inline" overflow="scroll"><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msub></mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:math></inline-formula> is the size of the corresponding edge set. A grid of <inline-formula id="IE75"><mml:math id="IM75" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> values is considered, with <inline-formula id="IE76"><mml:math id="IM76" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> fixed to the value selected in the previous step. The value of <inline-formula id="IE77"><mml:math id="IM77" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> that minimizes (7) is selected, and the final graph estimate is obtained by running the JGL with the selected penalty parameters <inline-formula id="IE78"><mml:math id="IM78" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE79"><mml:math id="IM79" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> in the fused penalty (2). An investigation into the effect of selecting the two penalty parameters in reverse order is detailed in <xref rid="sup1" ref-type="supplementary-material">Supplementary Section S5</xref>, where we find that selecting <inline-formula id="IE80"><mml:math id="IM80" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> after <inline-formula id="IE81"><mml:math id="IM81" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> might be desired in settings where one is not concerned about a high false discovery rate.</p>
      </sec>
      <sec>
        <title>2.3.3 Implementation details</title>
        <p>StabJGL is implemented in R, and available as an R package at <ext-link xlink:href="https://github.com/Camiling/stabJGL" ext-link-type="uri">https://github.com/Camiling/stabJGL</ext-link>. The subsampling routine is implemented so it can be done in parallel. The JGL fittings are done as in <xref rid="vbad185-B12" ref-type="bibr">Danaher <italic toggle="yes">et al.</italic> (2014)</xref>, using an ADMM (Alternating Direction Method of Multipliers) algorithm (<xref rid="vbad185-B9" ref-type="bibr">Boyd <italic toggle="yes">et al.</italic> 2010</xref>) for general penalty functions to solve the penalized log-likelihood problem (1) with the fused penalty (2). The stabJGL algorithm itself does not inherently handle missing data, and requires complete data for the precision matrix estimation. In the case of missing data, we recommend using state-of-the-art approaches, such as multiple imputation to defer the issue. By default, 20 subsamples are used and we evaluate 20 values each of <inline-formula id="IE82"><mml:math id="IM82" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>∈</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mn>0.01</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE83"><mml:math id="IM83" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow><mml:mo>∈</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>0.1</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></inline-formula>. We use a subsample size of <inline-formula id="IE84"><mml:math id="IM84" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>⌊</mml:mo><mml:mrow><mml:mn>10</mml:mn><mml:msqrt><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:msqrt></mml:mrow><mml:mo>⌋</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> for group <inline-formula id="IE85"><mml:math id="IM85" display="inline" overflow="scroll"><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>K</mml:mi></mml:mrow></mml:math></inline-formula>, which as <xref rid="vbad185-B26" ref-type="bibr">Liu <italic toggle="yes">et al.</italic> (2010)</xref> show in a single network setting maintains theoretical properties for containing the true graph with high probability as well as high empirical performance. The additional penalty parameter <inline-formula id="IE86"><mml:math id="IM86" display="inline" overflow="scroll"><mml:mo>γ</mml:mo></mml:math></inline-formula> in the eBIC for similarity selection is set to 0 by default, corresponding to the standard BIC. The choice of <inline-formula id="IE87"><mml:math id="IM87" display="inline" overflow="scroll"><mml:mo>γ</mml:mo></mml:math></inline-formula> is not crucial as we are using it for similarity and not sparsity selection, and thus compare graphs of similar sparsity. We found this value to be suitable in most applications but leave the option to increase the penalization. We employ a default variability threshold of <inline-formula id="IE88"><mml:math id="IM88" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>β</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mn>0.1</mml:mn></mml:mrow></mml:math></inline-formula>.</p>
      </sec>
    </sec>
  </sec>
  <sec>
    <title>3 Results</title>
    <sec>
      <title>3.1 Simulated data</title>
      <p>We first assess the performance of stabJGL on simulated data. We compare the network reconstruction ability of stabJGL to that of state-of-the-art methods, including the JGL with the fused penalty (FGL) and group penalty (GGL) with penalty parameters selected with the default AIC-based criterion (<xref rid="vbad185-B12" ref-type="bibr">Danaher <italic toggle="yes">et al.</italic> 2014</xref>). To assess the performance of another selection criterion specifically designed for high-dimensional graph selection, we also consider FGL with penalty parameters tuned by the extended BIC for multiple graphs (7). We further include the Bayesian spike-and-slab JGL (SSJGL) of <xref rid="vbad185-B23" ref-type="bibr">Li <italic toggle="yes">et al.</italic> (2019b</xref>), as well as the Glasso of <xref rid="vbad185-B15" ref-type="bibr">Friedman <italic toggle="yes">et al.</italic> (2008)</xref> tuned by StARS (<xref rid="vbad185-B26" ref-type="bibr">Liu <italic toggle="yes">et al.</italic> 2010</xref>). The latter estimates each network separately. We generate data that closely resembles our omics application of interest, featuring partial correlations between 0.1 and 0.2 in absolute value, while also exhibiting the “scale-free” property—a typical assumption for omics data where the “degree distribution” (i.e. the distribution of the number of edges that are connected to the nodes) adheres to a power-law distribution (<xref rid="vbad185-B11" ref-type="bibr">Chen and Sharp 2004</xref>). We consider a wide range of settings, simulating <inline-formula id="IE89"><mml:math id="IM89" display="inline" overflow="scroll"><mml:mrow><mml:mi>K</mml:mi><mml:mo>∈</mml:mo><mml:mo>{</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>3</mml:mn><mml:mo>,</mml:mo><mml:mn>4</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> networks with <inline-formula id="IE90"><mml:math id="IM90" display="inline" overflow="scroll"><mml:mrow><mml:mi>p</mml:mi><mml:mo>∈</mml:mo><mml:mo>{</mml:mo><mml:mn>100</mml:mn><mml:mo>,</mml:mo><mml:mn>200</mml:mn><mml:mo>,</mml:mo><mml:mn>300</mml:mn><mml:mo>,</mml:mo><mml:mn>1000</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> nodes. We manipulate the degree of similarity in their “true” graphical structures to assess the performance of the method over a wide range of scenarios. We then apply different network reconstruction techniques to determine the networks from the data and report the results averaged over <inline-formula id="IE91"><mml:math id="IM91" display="inline" overflow="scroll"><mml:mrow><mml:mi>N</mml:mi><mml:mo>=</mml:mo><mml:mn>100</mml:mn></mml:mrow></mml:math></inline-formula> replicates. The parameter specifications for the different methods are given in <xref rid="sup1" ref-type="supplementary-material">Supplementary Section S2</xref>. We also investigate the effect of the variability threshold <inline-formula id="IE92"><mml:math id="IM92" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>β</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> in stabJGL on the results in a setting with <inline-formula id="IE93"><mml:math id="IM93" display="inline" overflow="scroll"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>100</mml:mn></mml:mrow></mml:math></inline-formula> nodes and <inline-formula id="IE94"><mml:math id="IM94" display="inline" overflow="scroll"><mml:mrow><mml:mi>K</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula> networks. Finally, to compare the scalability of the respective methods, we consider the time needed to infer networks for various <italic toggle="yes">p</italic> and <italic toggle="yes">K</italic>. Further details and code for the simulation study can be found at <ext-link xlink:href="https://github.com/Camiling/stabJGL_simulations" ext-link-type="uri">https://github.com/Camiling/stabJGL_simulations</ext-link>.</p>
      <p>Estimation accuracy is assessed with the “precision” (positive predictive value), and the “recall” (sensitivity). The precision gives the fraction of predicted edges that were correct, while the recall is the fraction of edges in the true graph that were identified by the inference. Because the sparsity of estimated networks will vary between methods, the precision–recall trade-off should be taken into consideration. In general, the recall will increase with the number of selected edges while the precision will decrease. Since sparsity selection is a main feature of our proposed method, we do not consider threshold-free comparison metrics, such as the AUC. We therefore put emphasis on the following characteristics in our comparative simulation study; (i) suitable sparsity level selection, (ii) utilization of common information at any level of network similarity, i.e. inference improves with increased network similarity, and (iii) a suitable precision–recall trade-off that overly favors either measure.</p>
    </sec>
    <sec>
      <title>3.2 Simulation results</title>
      <p>The results for <inline-formula id="IE95"><mml:math id="IM95" display="inline" overflow="scroll"><mml:mrow><mml:mi>K</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE96"><mml:math id="IM96" display="inline" overflow="scroll"><mml:mrow><mml:mi>K</mml:mi><mml:mo>=</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:math></inline-formula> networks with <inline-formula id="IE97"><mml:math id="IM97" display="inline" overflow="scroll"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>100</mml:mn></mml:mrow></mml:math></inline-formula> nodes are summarized in <xref rid="vbad185-F2" ref-type="fig">Fig. 2</xref>. The full tables of results for these settings and the additional settings with <inline-formula id="IE98"><mml:math id="IM98" display="inline" overflow="scroll"><mml:mrow><mml:mi>K</mml:mi><mml:mo>∈</mml:mo><mml:mo>{</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>3</mml:mn><mml:mo>,</mml:mo><mml:mn>4</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> networks and <inline-formula id="IE99"><mml:math id="IM99" display="inline" overflow="scroll"><mml:mrow><mml:mi>p</mml:mi><mml:mo>∈</mml:mo><mml:mo>{</mml:mo><mml:mn>100</mml:mn><mml:mo>,</mml:mo><mml:mn>200</mml:mn><mml:mo>,</mml:mo><mml:mn>300</mml:mn><mml:mo>,</mml:mo><mml:mn>1000</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> nodes are shown in <xref rid="sup1" ref-type="supplementary-material">Supplementary Section S2</xref>, where details on selected sparsity and penalty parameters are given for all methods. Additional simulations investigating the effect of random noise on the graph reconstruction performance of the different methods are also given in <xref rid="sup1" ref-type="supplementary-material">Supplementary Section S6</xref>. In <xref rid="vbad185-F2" ref-type="fig">Fig. 2</xref>, FGL tuned with eBIC did not select any edges in any of the settings and is therefore not shown. In all settings considered, the FGL and GGL with the default AIC-based penalty parameter selection strongly over-select edges. This leads to high recall, but very low precision. Second, they do not appear to sufficiently utilize network similarities; the performance of the two methods, particularly GGL, differs little between completely unrelated and identical networks. Notably, in all cases, the selected value of <inline-formula id="IE100"><mml:math id="IM100" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> is smaller for FGL and GGL tuned by AIC than it is for stabJGL. Consequently, similarity is not sufficiently encouraged even in settings where the networks are identical. The AIC criterion does not seem to provide sufficient penalization to encourage suitable sparsity and similarity. On the other hand, the alternative eBIC criterion gives extremely sparse FGL estimates, selecting an empty graph in most settings, i.e. no edges. Although the extended BIC is developed specifically for graphical model selection, likelihood-based criteria for sparsity selection tend to perform poorly in high-dimensional settings and risk both severe under- and over-selection (<xref rid="vbad185-B14" ref-type="bibr">Foygel and Drton 2010</xref>). This issue is avoided in the stabJGL algorithm as the eBIC only is used to select similarity and not sparsity.</p>
      <fig position="float" id="vbad185-F2">
        <label>Figure 2.</label>
        <caption>
          <p>Performance of the Glasso, FGL, and GGL tuned by AIC, SSJGL, and stabJGL, reconstructing <inline-formula id="IE101"><mml:math id="IM101" display="inline" overflow="scroll"><mml:mrow><mml:mi>K</mml:mi><mml:mo>∈</mml:mo><mml:mo>{</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>4</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> graphs with <inline-formula id="IE102"><mml:math id="IM102" display="inline" overflow="scroll"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>100</mml:mn></mml:mrow></mml:math></inline-formula> nodes and various similarity of the true graph structures. The similarity between the graphs is shown as the percentage of edges they have in common. The results are averaged over <inline-formula id="IE103"><mml:math id="IM103" display="inline" overflow="scroll"><mml:mrow><mml:mi>N</mml:mi><mml:mo>=</mml:mo><mml:mn>100</mml:mn></mml:mrow></mml:math></inline-formula> replicates and show the precision and recall for the first estimated graph in each setting, reconstructed from <inline-formula id="IE104"><mml:math id="IM104" display="inline" overflow="scroll"><mml:mrow><mml:mi>n</mml:mi><mml:mo>∈</mml:mo><mml:mo>{</mml:mo><mml:mn>100</mml:mn><mml:mo>,</mml:mo><mml:mn>150</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> observations and <inline-formula id="IE105"><mml:math id="IM105" display="inline" overflow="scroll"><mml:mrow><mml:mi>n</mml:mi><mml:mo>∈</mml:mo><mml:mo>{</mml:mo><mml:mn>150</mml:mn><mml:mo>,</mml:mo><mml:mn>200</mml:mn><mml:mo>,</mml:mo><mml:mn>250</mml:mn><mml:mo>,</mml:mo><mml:mn>300</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> observations for <inline-formula id="IE106"><mml:math id="IM106" display="inline" overflow="scroll"><mml:mrow><mml:mi>K</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE107"><mml:math id="IM107" display="inline" overflow="scroll"><mml:mrow><mml:mi>K</mml:mi><mml:mo>=</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:math></inline-formula>, respectively. Standard deviation bars are shown for all methods. All graphs have true sparsity 0.02.</p>
        </caption>
        <graphic xlink:href="vbad185f2" position="float"/>
      </fig>
      <p>The Bayesian SSJGL tends to select very few edges, leading to high precision but low recall. Its performance deteriorates drastically as the network differences increase, leading to extremely low recall. This implies a lack of flexibility to adapt to varying network similarity levels, as has previously been observed (<xref rid="vbad185-B25" ref-type="bibr">Lingjærde <italic toggle="yes">et al.</italic> 2022</xref>). Out of all the joint methods, stabJGL gives the most accurate sparsity estimate. This ensures that we neither get very low precision like FGL and GGL tuned by AIC, nor very low recall like SSJGL and FGL tuned by eBIC. Replacing the mean of the <inline-formula id="IE108"><mml:math id="IM108" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>’s over the <inline-formula id="IE109"><mml:math id="IM109" display="inline" overflow="scroll"><mml:mrow><mml:mi>N</mml:mi><mml:mo>=</mml:mo><mml:mn>100</mml:mn></mml:mrow></mml:math></inline-formula> replicates by alternative measures, such as the median yields the same reported penalty parameter values and hence results in all settings considered in <xref rid="vbad185-F2" ref-type="fig">Fig. 2</xref>. The mean and median could be expected to differ slightly if a finer grid of <inline-formula id="IE110"><mml:math id="IM110" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> values were to be considered, but our findings suggest they would yield highly similar results. StabJGL also appears to adapt well to the similarity between networks, with the prediction accuracy increasing with the number of shared edges. As a result, the method either outperforms the Glasso tuned by StARS for highly similar networks or performs comparably to it for unrelated networks. The similar performance for unrelated networks can be explained by the fact that the sparsity controlling penalty parameters of both methods are tuned with a stability-based approach. The results suggest that stabJGL adapts well to the level of similarity and hence can be employed agnostically in settings where there is no prior knowledge about the degree to which the networks have shared structures.</p>
      <p>A key question is whether stabJGL can achieve as high precision as the methods that give sparser networks (i.e. SSJGL) by using a lower variability threshold. Similarly, we want to see if stabJGL can achieve as high recall as the methods that infer more edges (i.e. FGL and GGL). To investigate this, we consider the same setting as in <xref rid="vbad185-F2" ref-type="fig">Fig. 2</xref> with <inline-formula id="IE111"><mml:math id="IM111" display="inline" overflow="scroll"><mml:mrow><mml:mi>K</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula> networks. <xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S4</xref> compares the performance of stabJGL for different values of the variability threshold <inline-formula id="IE112"><mml:math id="IM112" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>β</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> to the other methods, and we find that by decreasing (resp. increasing) <inline-formula id="IE113"><mml:math id="IM113" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>β</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> we can obtain at least as high precision (resp. recall) as the other methods at any level of similarity. This illustrates that the method can be adapted to reflect the priorities of the user (i.e. concern for false positives versus false negatives). For most applications, a middle-ground value, such as 0.1 yields a good balance between false positives and false negatives as demonstrated in the simulations.</p>
    </sec>
    <sec>
      <title>3.3 Runtime profiling</title>
      <p><xref rid="vbad185-F3" ref-type="fig">Figure 3</xref> shows the CPU time used to jointly infer networks for <inline-formula id="IE114"><mml:math id="IM114" display="inline" overflow="scroll"><mml:mrow><mml:mi>K</mml:mi><mml:mo>∈</mml:mo><mml:mo>{</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>3</mml:mn><mml:mo>,</mml:mo><mml:mn>4</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> networks and various numbers of nodes <italic toggle="yes">p</italic>, with <inline-formula id="IE115"><mml:math id="IM115" display="inline" overflow="scroll"><mml:mrow><mml:mi>n</mml:mi><mml:mo>∈</mml:mo><mml:mo>{</mml:mo><mml:mn>100</mml:mn><mml:mo>,</mml:mo><mml:mn>150</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> observations, for the JGL with the fused penalty (FGL) with penalty parameters tuned with the AIC and stabJGL with the same parameter specifications as in the previously described simulations. Due to an efficient parallelized implementation, stabJGL has an almost identical runtime to FGL when the same number of <inline-formula id="IE116"><mml:math id="IM116" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE117"><mml:math id="IM117" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> values are considered. Thus, the increased estimation accuracy of stabJGL does not come at a computational cost. It is important to note that due to the generalized fused lasso problem having a closed-form expression for the updates in the special case of <inline-formula id="IE118"><mml:math id="IM118" display="inline" overflow="scroll"><mml:mrow><mml:mi>K</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula> (<xref rid="vbad185-B12" ref-type="bibr">Danaher <italic toggle="yes">et al.</italic> 2014</xref>), stabJGL is substantially faster for only two networks than for <inline-formula id="IE119"><mml:math id="IM119" display="inline" overflow="scroll"><mml:mrow><mml:mi>K</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula>. As stabJGL uses the fused penalty this comparison is the most relevant, but a runtime comparison of all methods considered in our simulation study can be found in <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S1</xref>. In the <xref rid="sup1" ref-type="supplementary-material">Supplementary Material</xref>, we also demonstrate that stabJGL can be applied to problems with <inline-formula id="IE120"><mml:math id="IM120" display="inline" overflow="scroll"><mml:mrow><mml:mi>p</mml:mi><mml:mo>≥</mml:mo><mml:mn>2500</mml:mn></mml:mrow></mml:math></inline-formula> nodes or <inline-formula id="IE121"><mml:math id="IM121" display="inline" overflow="scroll"><mml:mrow><mml:mi>K</mml:mi><mml:mo>=</mml:mo><mml:mn>10</mml:mn></mml:mrow></mml:math></inline-formula> networks within reasonable time (<xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S3</xref>).</p>
      <fig position="float" id="vbad185-F3">
        <label>Figure 3.</label>
        <caption>
          <p>CPU time in seconds on a logarithmic scale used to jointly infer networks for <inline-formula id="IE122"><mml:math id="IM122" display="inline" overflow="scroll"><mml:mrow><mml:mi>K</mml:mi><mml:mo>∈</mml:mo><mml:mo>{</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>3</mml:mn><mml:mo>,</mml:mo><mml:mn>4</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> networks and various numbers of nodes <italic toggle="yes">p</italic>, with <inline-formula id="IE123"><mml:math id="IM123" display="inline" overflow="scroll"><mml:mrow><mml:mi>n</mml:mi><mml:mo>∈</mml:mo><mml:mo>{</mml:mo><mml:mn>100</mml:mn><mml:mo>,</mml:mo><mml:mn>150</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> observations, for FGL tuned with AIC and stabJGL. The computations were performed on a 16-core Intel Xeon CPU, 2.60 GHz.</p>
        </caption>
        <graphic xlink:href="vbad185f3" position="float"/>
      </fig>
    </sec>
    <sec>
      <title>3.4 Pan-cancer data</title>
      <p>We perform a proteomic network analysis of Reverse Phase Protein Array (RPPA) data from The Cancer Genome Atlas (TCGA) across different pan-Cancer tumor types (<xref rid="vbad185-B10" ref-type="bibr">Cancer Genome Atlas Network and others 2012</xref>). In a large proteomic pan-Cancer study of 11 TCGA tumor types, <xref rid="vbad185-B2" ref-type="bibr">Akbani <italic toggle="yes">et al.</italic> (2014)</xref> identified a major tumor super cluster consisting of hormonally responsive “women’s cancers” [Luminal breast cancer (BRCA), ovarian cystadenocarcinoma (OVCA), and uterine corpus endometrial carcinoma (UCEC)]. Our objective is to map the proteomic network structure of the respective tumor types, so that we can get a better grasp of the common mechanisms at play in the hormonally responsive tumors. We are also interested in highlighting the differences.</p>
      <p>We consider RPPA data from Luminal BRCA (<inline-formula id="IE124"><mml:math id="IM124" display="inline" overflow="scroll"><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>273</mml:mn></mml:mrow></mml:math></inline-formula>), high-grade serous OVCA (<inline-formula id="IE125"><mml:math id="IM125" display="inline" overflow="scroll"><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>412</mml:mn></mml:mrow></mml:math></inline-formula>), and UCEC (<inline-formula id="IE126"><mml:math id="IM126" display="inline" overflow="scroll"><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>404</mml:mn></mml:mrow></mml:math></inline-formula>). All data are downloaded from the UCSC Xena Browser (<xref rid="vbad185-B16" ref-type="bibr">Goldman <italic toggle="yes">et al.</italic> 2020</xref>). The data are measured with <inline-formula id="IE127"><mml:math id="IM127" display="inline" overflow="scroll"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>131</mml:mn></mml:mrow></mml:math></inline-formula> high-quality antibodies that target (phospho)-proteins. To alleviate batch effects, the RPPA data are normalized with replicate-base normalization (<xref rid="vbad185-B2" ref-type="bibr">Akbani <italic toggle="yes">et al.</italic> 2014</xref>). We use stabJGL to jointly estimate the proteomic networks of the respective tumor types and interpret the results and their implications. We compare the output with that obtained with the FGL of <xref rid="vbad185-B12" ref-type="bibr">Danaher <italic toggle="yes">et al.</italic> (2014)</xref> with the default penalty parameter tuning with AIC as described in Section 3.1. Further details and code for the analysis are given at <ext-link xlink:href="https://github.com/Camiling/stabJGL_analysis" ext-link-type="uri">https://github.com/Camiling/stabJGL_analysis</ext-link>.</p>
    </sec>
    <sec>
      <title>3.5 Pan-cancer analysis results</title>
      <sec>
        <title>3.5.1 Estimated proteomic networks</title>
        <p>The resulting stabJGL proteomic networks of the three tumor types are shown in <xref rid="vbad185-F4" ref-type="fig">Fig. 4</xref>, where we observe plenty of common edges as well as network-specific ones. The sparsity as well as the selected penalty parameter values in the resulting stabJGL and FGL networks is shown in <xref rid="vbad185-T1" ref-type="table">Table 1</xref>. The tendency as observed in the simulations of FGL tuned by the AIC to over-select edges appears to be consistent with the findings in this context. With more than two-thirds of all potential edges being determined as present by FGL, the results are challenging to interpret and derive meaningful conclusions from. From a biological standpoint, we would not expect a proteomic network to be this saturated in terms of associations due to the expected scale-free property of the degree distribution (<xref rid="vbad185-B4" ref-type="bibr">Barabasi and Oltvai 2004</xref>). While the degree distributions of the sparse stabJGL networks all follow a power-law with many low-degree nodes and fewer high-degree ones (hubs), an expected trait for omics data (<xref rid="vbad185-B11" ref-type="bibr">Chen and Sharp 2004</xref>), the degree distributions of the FGL networks do not. The full degree distributions are shown in <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S6</xref>.</p>
        <fig position="float" id="vbad185-F4">
          <label>Figure 4.</label>
          <caption>
            <p>Proteomic network structure identified by stabJGL for the BRCA, OVCA, and UCEC tumors. The nodes represent proteins, and edges common to all three networks are darker.</p>
          </caption>
          <graphic xlink:href="vbad185f4" position="float"/>
        </fig>
        <table-wrap position="float" id="vbad185-T1">
          <label>Table 1.</label>
          <caption>
            <p>Network analysis results for stabJGL and FGL tuned by the AIC, applied to data from BRCA, OVCA, and UCEC tumors.</p>
          </caption>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col valign="top" align="left" span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th rowspan="1" colspan="1"/>
                <th rowspan="1" colspan="1"/>
                <th rowspan="1" colspan="1"/>
                <th colspan="3" rowspan="1">Sparsity<hr/></th>
              </tr>
              <tr>
                <th rowspan="1" colspan="1"/>
                <th rowspan="1" colspan="1">
                  <inline-formula id="IE128">
                    <mml:math id="IM128" display="inline" overflow="scroll">
                      <mml:mrow>
                        <mml:mrow>
                          <mml:msub>
                            <mml:mrow>
                              <mml:mo>λ</mml:mo>
                            </mml:mrow>
                            <mml:mn>1</mml:mn>
                          </mml:msub>
                        </mml:mrow>
                      </mml:mrow>
                    </mml:math>
                  </inline-formula>
                </th>
                <th rowspan="1" colspan="1">
                  <inline-formula id="IE129">
                    <mml:math id="IM129" display="inline" overflow="scroll">
                      <mml:mrow>
                        <mml:mrow>
                          <mml:msub>
                            <mml:mrow>
                              <mml:mo>λ</mml:mo>
                            </mml:mrow>
                            <mml:mn>2</mml:mn>
                          </mml:msub>
                        </mml:mrow>
                      </mml:mrow>
                    </mml:math>
                  </inline-formula>
                </th>
                <th rowspan="1" colspan="1">BRCA</th>
                <th rowspan="1" colspan="1">UCEC</th>
                <th rowspan="1" colspan="1">OVCA</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td rowspan="1" colspan="1">FGL</td>
                <td rowspan="1" colspan="1">0.010</td>
                <td rowspan="1" colspan="1">0.000</td>
                <td rowspan="1" colspan="1">0.689</td>
                <td rowspan="1" colspan="1">0.709</td>
                <td rowspan="1" colspan="1">0.679</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">stabJGL</td>
                <td rowspan="1" colspan="1">0.323</td>
                <td rowspan="1" colspan="1">0.008</td>
                <td rowspan="1" colspan="1">0.049</td>
                <td rowspan="1" colspan="1">0.036</td>
                <td rowspan="1" colspan="1">0.039</td>
              </tr>
            </tbody>
          </table>
        </table-wrap>
        <p>In terms of penalty parameters, we see that just like for the simulated data the AIC selects very small penalty parameters for FGL, resulting in little sparsity and similarity encouragement. Given the findings of <xref rid="vbad185-B2" ref-type="bibr">Akbani <italic toggle="yes">et al.</italic> (2014)</xref> about the presence of a super cluster consisting of the three hormonally responsive cancer types, it is not unreasonable to expect at least some proteomic network similarity to be encouraged by a joint method. This is achieved by stabJGL, which selects a large enough value of <inline-formula id="IE130"><mml:math id="IM130" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> to encourage similarity. A comparison of the pairwise similarities of the proteomic networks reveals that stabJGL indeed finds the networks of the three tumor types to be more similar than FGL, in accordance with the findings of <xref rid="vbad185-B2" ref-type="bibr">Akbani <italic toggle="yes">et al.</italic> (2014)</xref> (<xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S5</xref>).</p>
      </sec>
      <sec>
        <title>3.5.2 Edge validation in STRING</title>
        <p>To compare the level of evidence supporting the edges detected by stabJGL and FGL tuned by the AIC in the literature, we conduct edge validation using the STRING database of known and predicted protein–protein interactions (<xref rid="vbad185-B33" ref-type="bibr">Szklarczyk <italic toggle="yes">et al.</italic> 2019</xref>). To ensure the reliability of the validation process, we only consider the experimentally validated interactions in STRING as evidence, with default confidence score threshold <inline-formula id="IE131"><mml:math id="IM131" display="inline" overflow="scroll"><mml:mrow><mml:mo>≥</mml:mo><mml:mn>0.4</mml:mn></mml:mrow></mml:math></inline-formula>. The number of predicted edges with supporting evidence in the STRING database, as well as the proportion of all predicted edges that have evidence in STRING, is computed for the respective stabJGL and FGL networks and shown in <xref rid="vbad185-T2" ref-type="table">Table 2</xref>. While the fused Glasso identifies a larger number of edges with evidence in STRING, the method also includes far more edges than stabJGL, resulting in an overall lower percentage of edges with supporting evidence in the STRING database than stabJGL, for all three tumor types investigated. Complete lists of the protein–protein edges identified by stabJGL for each tumor type are provided as <xref rid="sup1" ref-type="supplementary-material">Supplementary Files</xref>.</p>
        <table-wrap position="float" id="vbad185-T2">
          <label>Table 2.</label>
          <caption>
            <p>Comparison of evidence for edges in the respective FGL tuned by AIC and stabJGL proteomic networks of BRCA, OVCA, and UCEC tumors, considering experimentally determined protein–protein interactions documented in the STRING database.<sup>a</sup></p>
          </caption>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col valign="top" align="left" span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th rowspan="1" colspan="1"/>
                <th colspan="2" rowspan="1">Edge evidence <inline-formula id="IE132"><mml:math id="IM132" display="inline" overflow="scroll"><mml:mo>%</mml:mo></mml:math></inline-formula><hr/></th>
                <th colspan="2" rowspan="1">Edge evidence #<hr/></th>
              </tr>
              <tr>
                <th rowspan="1" colspan="1">Dataset</th>
                <th rowspan="1" colspan="1">FGL (%)</th>
                <th rowspan="1" colspan="1">stabJGL (%)</th>
                <th rowspan="1" colspan="1">FGL</th>
                <th rowspan="1" colspan="1">stabJGL</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td rowspan="1" colspan="1">BRCA</td>
                <td rowspan="1" colspan="1">5.4</td>
                <td rowspan="1" colspan="1">
                  <bold>12.3</bold>
                </td>
                <td rowspan="1" colspan="1">408</td>
                <td rowspan="1" colspan="1">68</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">UVEC</td>
                <td rowspan="1" colspan="1">5.6</td>
                <td rowspan="1" colspan="1">
                  <bold>10.0</bold>
                </td>
                <td rowspan="1" colspan="1">398</td>
                <td rowspan="1" colspan="1">44</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">OVCA</td>
                <td rowspan="1" colspan="1">5.7</td>
                <td rowspan="1" colspan="1">
                  <bold>12.4</bold>
                </td>
                <td rowspan="1" colspan="1">424</td>
                <td rowspan="1" colspan="1">42</td>
              </tr>
            </tbody>
          </table>
          <table-wrap-foot>
            <fn id="tblfn1">
              <label>a</label>
              <p>Both the percentage of predicted edges with evidence and the number of predicted edges with evidence are shown. The highest percentage of edges with evidence is in bold.</p>
            </fn>
          </table-wrap-foot>
        </table-wrap>
      </sec>
      <sec>
        <title>3.5.3 Findings consistent with literature</title>
        <p>StabJGL successfully identifies protein–protein interactions known from literature. To highlight the findings of the proposed methodology, we only discuss edges and central proteins identified by stabJGL but not FGL. One example is the edge between activated (S345-phosphorylated) Checkpoint kinase 1 (Chk1) and DNA repair protein RAD51 homolog 1 (Rad51) in ovarian and BRCA. The complex between the tumor suppressor BRCA2, which manifests predominantly in ovarian and BRCA, and Rad51, is mediated by the DNA damage checkpoint Chk1 through Rad51 phosphorylation (<xref rid="vbad185-B3" ref-type="bibr">Bahassi <italic toggle="yes">et al.</italic> 2008</xref>, <xref rid="vbad185-B29" ref-type="bibr">Nair <italic toggle="yes">et al.</italic> 2020</xref>). It is also reassuring that stabJGL identifies many relevant tumor type-specific proteins as hubs in the relevant tumor type only, such as mammalian target of rapamycin (mTOR), Tuberous Sclerosis Complex 2, and Ribosomal protein S6 in BRCA, all of which are involved or up/downstream of the PI3K/AKT/mTOR pathway known to frequently be deregulated in Luminal BRCA (<xref rid="vbad185-B28" ref-type="bibr">Miricescu <italic toggle="yes">et al.</italic> 2020</xref>). Lists of the top hubs in the respective stabJGL and FGL networks of the different tumor types, and their node degree, are given in <xref rid="sup1" ref-type="supplementary-material">Supplementary Tables S9</xref> and <xref rid="sup1" ref-type="supplementary-material">S10</xref>.</p>
        <p>StabJGL also captures edges that we expect to be present in all three tumor types, such as the known interaction between the transcription factor Forkhead box O3 and 14–3-3-epsilon, which facilitates cancer cell proliferation (<xref rid="vbad185-B30" ref-type="bibr">Nielsen <italic toggle="yes">et al.</italic> 2008</xref>, <xref rid="vbad185-B35" ref-type="bibr">Tzivion <italic toggle="yes">et al.</italic> 2011</xref>). This common interaction is documented in the STRING database. <xref rid="vbad185-F5" ref-type="fig">Figure 5</xref> shows the network structure identified by stabJGL that is common to all three tumor types. Central proteins in this common network structure include Oncoprotein 18 (Stathmin), which is known to be relevant in all three hormonally responsive cancers due to its role in the regulation of cell growth and motility (<xref rid="vbad185-B7" ref-type="bibr">Bieche <italic toggle="yes">et al.</italic> 1998</xref>, <xref rid="vbad185-B5" ref-type="bibr">Belletti and Baldassarre 2011</xref>, <xref rid="vbad185-B34" ref-type="bibr">Trovik <italic toggle="yes">et al.</italic> 2011</xref>).</p>
        <fig position="float" id="vbad185-F5">
          <label>Figure 5.</label>
          <caption>
            <p>The proteomic network structure identified by stabJGL common to all three tumor types (BRCA, UCEC, and OCVA). The node size indicates the degree in the common network structure, with proteins with more edges being represented by larger nodes.</p>
          </caption>
          <graphic xlink:href="vbad185f5" position="float"/>
        </fig>
      </sec>
      <sec>
        <title>3.5.4 Potential candidate hubs</title>
        <p>The recovery of documented links in the protein networks estimated by stabJGL highlights its capability to detect numerous relevant proteins and interactions. The potential for new discoveries is however an important aspect of stabJGL, as suggested by its good performance on simulated data. For example, stabJGL identifies phosphorylated epidermal growth factor receptor (EGFR) as a central hub protein in all three tumor types. While known to be relevant in ovarian cancer (<xref rid="vbad185-B38" ref-type="bibr">Yang <italic toggle="yes">et al.</italic> 2013</xref>, <xref rid="vbad185-B39" ref-type="bibr">Zhang <italic toggle="yes">et al.</italic> 2016</xref>), the role of activated EGFR in UCEC and Luminal BRCA and is not yet clarified. Our findings suggest it could be relevant in all three hormonally responsive tumor types. Further, Platelet endothelial cell adhesion molecule (CD31) is found to be a central protein in UCEC only. The protein is important for angiogenesis and has been implicated in other tumor types, such as hemangioma (<xref rid="vbad185-B6" ref-type="bibr">Bergom <italic toggle="yes">et al.</italic> 2005</xref>). Its prominence in the proteomic UCEC network suggests it may play a crucial role in this tumor type as well. Overall, these results showcase how stabJGL can aid in generating hypotheses by identifying central proteins and associations.</p>
      </sec>
    </sec>
  </sec>
  <sec>
    <title>4 Discussion</title>
    <p>Suitable sparsity and similarity selection is key for capturing and studying multiple-related biological networks. We have proposed the stabJGL algorithm, which determines the penalty parameters in the fused Glasso for multiple networks based on the principle of model stability. StabJGL demonstrably avoids the under- or over-selection of edges observed in state-of-the-art selection methods based on information criteria and succeeds at leveraging network similarities to a suitable degree. Consequently, the method can be employed in situations where the actual degree of similarity is uncertain, resulting in marked benefits with minimal risks associated with its use. StabJGL offers a fast parallelized implementation, particularly for <inline-formula id="IE133"><mml:math id="IM133" display="inline" overflow="scroll"><mml:mrow><mml:mi>K</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula> networks as a closed-form expression of the updates exists. We successfully apply the method to problems with <inline-formula id="IE134"><mml:math id="IM134" display="inline" overflow="scroll"><mml:mrow><mml:mi>p</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>2000</mml:mn></mml:mrow></mml:math></inline-formula> nodes or <inline-formula id="IE135"><mml:math id="IM135" display="inline" overflow="scroll"><mml:mrow><mml:mi>K</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>10</mml:mn></mml:mrow></mml:math></inline-formula> networks.</p>
    <p>With our novel approach, we can identify both common and distinct mechanisms in the proteomic networks of different types of hormonally responsive women’s cancers. The results obtained with stabJGL are in line with known biology and compliment those of <xref rid="vbad185-B2" ref-type="bibr">Akbani <italic toggle="yes">et al.</italic> (2014)</xref> by offering additional understanding of the underlying mechanisms in action. By recognizing various proteins as highly critical in the proteomic networks, stabJGL suggests their possible involvement in driving the diseases. The method both identifies proteins that are central in all three hormonally responsive cancers (e.g. phosphorylated EGFR) and proteins of tumor-specific relevance (e.g. CD31 in UCEC).</p>
    <p>The proposed approach can be applied to any type of omics data that can be transformed to adhere to the normality assumption. It is however important to note that if the datasets that are to be jointly analyzed are different types of omics data, a one-to-one mapping between the nodes in each dataset would be needed, e.g. having protein and mRNA expression data corresponding to the “same” encoding genes.</p>
    <p>In the setting of the data sources being from the same set of patients, the joint approach is not applicable due to the key assumption that all observations are independent. One such example could be when the data sources are mRNA and protein expression from the same patients. In that case, alternative approaches developed for multi-omic data integration might be more suitable, see, e.g. <xref rid="vbad185-B8" ref-type="bibr">Bonnet <italic toggle="yes">et al.</italic> (2015)</xref> and <xref rid="vbad185-B21" ref-type="bibr">Li and Jackson (2015)</xref>. In the case of multiple shared axes, an extension of our approach could be to concatenate the different omics data types and determine the global network. If independent observations from multiple sources, such as clinical groups or conditions is available as well, stabJGL could then be used to determine links across and within omics data types simultaneously. Such an approach might warrant the introduction of different penalties in (1), both within and across the different omics data types.</p>
    <p>While stabJGL is highly competitive in terms of scalability relative to the existing methodology, all algorithms for estimating Gaussian graphical models have inevitable matrix inversion steps. This is computationally demanding for large <italic toggle="yes">p</italic>, and, at present, joint graphical methods based on Gaussian graphical models are realistically not feasible for the analysis of extremely high-dimensional data with tens of thousands of nodes. It can be argued that even if such an analysis was possible, it is not sensible to attempt to determine the conditional independence structure for problems of this size. For example, if we were to consider the expression of <inline-formula id="IE136"><mml:math id="IM136" display="inline" overflow="scroll"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>20</mml:mn><mml:mo> </mml:mo><mml:mn>000</mml:mn></mml:mrow></mml:math></inline-formula> genes and <inline-formula id="IE137"><mml:math id="IM137" display="inline" overflow="scroll"><mml:mrow><mml:mi>K</mml:mi><mml:mo>=</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:math></inline-formula> groups, we would have the problem of determining over half a billion edges. With only a couple hundred samples in most studies and hence little statistical power, low estimation accuracy and many false discoveries would be expected. Meaningful interpretation of the results would also be a challenge. In settings where <italic toggle="yes">p</italic> is extremely large, an option could instead be to use a fast marginal correlation-based network approach, such as the weighted gene co-expression network analysis method of <xref rid="vbad185-B18" ref-type="bibr">Langfelder and Horvath (2008)</xref>, to identify subnetworks that are relevant for a more refined conditional independence network analysis.</p>
    <p>Future extensions of the method can include alternative measures of variability, such as the entropy [see, e.g. <xref rid="vbad185-B19" ref-type="bibr">Lartigue <italic toggle="yes">et al.</italic> (2020)</xref>]. Further, while the method is formulated specifically for the JGL with the fused penalty, it can in principle be used for any joint network approach requiring the tuning of sparsity- and similarity controlling parameters. Another relevant extension could be the introduction of network-specific sparsity penalty parameters <inline-formula id="IE138"><mml:math id="IM138" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> and network pair-specific similarity penalty parameters <inline-formula id="IE139"><mml:math id="IM139" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mi>k</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> for graphs <inline-formula id="IE140"><mml:math id="IM140" display="inline" overflow="scroll"><mml:mrow><mml:mn>1</mml:mn><mml:mo>≤</mml:mo><mml:mi>k</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>l</mml:mi><mml:mo>≤</mml:mo><mml:mi>K</mml:mi></mml:mrow></mml:math></inline-formula>, which would provide additional flexibility in terms of differing levels of sparsity and similarity across networks. The introduction of these parameters would however invoke a sharp increase in computational complexity, proportional to <inline-formula id="IE141"><mml:math id="IM141" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>K</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>.</p>
    <p>To conclude, stabJGL provides a reliable approach to joint network inference of omics data. The output can provide a better understanding of both common and data type-specific mechanisms, which can be used for hypothesis generation regarding potential therapeutic targets.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material id="sup1" position="float" content-type="local-data">
      <label>vbad185_Supplementary_Data</label>
      <media xlink:href="vbad185_supplementary_data.zip">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <sec>
    <title>Author contributions</title>
    <p>C.L. and S.R. developed the methodology. C.L. performed the data simulation and analysis, developed the software, and drafted the manuscript. Both authors have contributed to the manuscript and read and approved the final version.</p>
  </sec>
  <sec>
    <title>Supplementary data</title>
    <p><xref rid="sup1" ref-type="supplementary-material">Supplementary data</xref> are available at <italic toggle="yes">Bioinformatics Advances</italic> online.</p>
  </sec>
  <sec sec-type="COI-statement">
    <title>Conflict of interest</title>
    <p>None declared.</p>
  </sec>
  <sec>
    <title>Funding</title>
    <p>This work was supported by the UK Medical Research Council programme [MRC MC UU 00002/10 to C.L. and S.R.]; and Aker Scholarship (C.L.).</p>
  </sec>
  <sec sec-type="data-availability">
    <title>Data availability</title>
    <p>The TCGA data sets analysed in this article is publicly available in the University of California Santa Cruz Xena Browser repository (<ext-link xlink:href="http://xena.ucsc.edu" ext-link-type="uri">http://xena.ucsc.edu</ext-link>), from where we downloaded RPPA data for BRCA (dataset ID: TCGA.BRCA.sampleMap/RPPA_RBN), UCEC (dataset ID: TCGA.UCEC.sampleMap/RPPA_RBN) and OVCA (dataset ID: TCGA.OV.sampleMap/RPPA_RBN).</p>
  </sec>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="vbad185-B1">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Akaike</surname><given-names>H</given-names></string-name>, <string-name><surname>Petrov</surname><given-names>BN</given-names></string-name>, <string-name><surname>Csaki</surname><given-names>F.</given-names></string-name></person-group> Information theory and an extension of the maximum likelihood principle. In: <italic toggle="yes">Second International Symposium on Information Theory</italic>, New York, NY. New York: Springer, <year>1973</year>, <fpage>267</fpage>–<lpage>81</lpage>.</mixed-citation>
    </ref>
    <ref id="vbad185-B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Akbani</surname><given-names>R</given-names></string-name>, <string-name><surname>Ng</surname><given-names>PKS</given-names></string-name>, <string-name><surname>Werner</surname><given-names>HM</given-names></string-name></person-group><etal>et al</etal><article-title>A pan-cancer proteomic perspective on The Cancer Genome Atlas</article-title>. <source>Nat Commun</source><year>2014</year>;<volume>5</volume>:<fpage>3887</fpage>.<pub-id pub-id-type="pmid">24871328</pub-id></mixed-citation>
    </ref>
    <ref id="vbad185-B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bahassi</surname><given-names>E</given-names></string-name>, <string-name><surname>Ovesen</surname><given-names>J</given-names></string-name>, <string-name><surname>Riesenberg</surname><given-names>A</given-names></string-name></person-group><etal>et al</etal><article-title>The checkpoint kinases Chk1 and Chk2 regulate the functional associations between hBRCA2 and Rad51 in response to DNA damage</article-title>. <source>Oncogene</source><year>2008</year>;<volume>27</volume>:<fpage>3977</fpage>–<lpage>85</lpage>.<pub-id pub-id-type="pmid">18317453</pub-id></mixed-citation>
    </ref>
    <ref id="vbad185-B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Barabasi</surname><given-names>A-L</given-names></string-name>, <string-name><surname>Oltvai</surname><given-names>ZN.</given-names></string-name></person-group><article-title>Network biology: understanding the cell’s functional organization</article-title>. <source>Nat Rev Genet</source><year>2004</year>;<volume>5</volume>:<fpage>101</fpage>–<lpage>13</lpage>.<pub-id pub-id-type="pmid">14735121</pub-id></mixed-citation>
    </ref>
    <ref id="vbad185-B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Belletti</surname><given-names>B</given-names></string-name>, <string-name><surname>Baldassarre</surname><given-names>G.</given-names></string-name></person-group><article-title>Stathmin: a protein with many tasks. New biomarker and potential target in cancer</article-title>. <source>Expert Opin Ther Targets</source><year>2011</year>;<volume>15</volume>:<fpage>1249</fpage>–<lpage>66</lpage>.<pub-id pub-id-type="pmid">21978024</pub-id></mixed-citation>
    </ref>
    <ref id="vbad185-B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bergom</surname><given-names>C</given-names></string-name>, <string-name><surname>Gao</surname><given-names>C</given-names></string-name>, <string-name><surname>Newman</surname><given-names>PJ.</given-names></string-name></person-group><article-title>Mechanisms of PECAM-1-mediated cytoprotection and implications for cancer cell survival</article-title>. <source>Leuk Lymphoma</source><year>2005</year>;<volume>46</volume>:<fpage>1409</fpage>–<lpage>21</lpage>.<pub-id pub-id-type="pmid">16194886</pub-id></mixed-citation>
    </ref>
    <ref id="vbad185-B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bieche</surname><given-names>I</given-names></string-name>, <string-name><surname>Lachkar</surname><given-names>S</given-names></string-name>, <string-name><surname>Becette</surname><given-names>V</given-names></string-name></person-group><etal>et al</etal><article-title>Overexpression of the stathmin gene in a subset of human breast cancer</article-title>. <source>Br J Cancer</source><year>1998</year>;<volume>78</volume>:<fpage>701</fpage>–<lpage>9</lpage>.<pub-id pub-id-type="pmid">9743287</pub-id></mixed-citation>
    </ref>
    <ref id="vbad185-B8">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bonnet</surname><given-names>E</given-names></string-name>, <string-name><surname>Calzone</surname><given-names>L</given-names></string-name>, <string-name><surname>Michoel</surname><given-names>T.</given-names></string-name></person-group><article-title>Integrative multi-omics module network inference with lemon-tree</article-title>. <source>PLoS Comput Biol</source><year>2015</year>;<volume>11</volume>:<fpage>e1003983</fpage>.<pub-id pub-id-type="pmid">25679508</pub-id></mixed-citation>
    </ref>
    <ref id="vbad185-B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Boyd</surname><given-names>S</given-names></string-name>, <string-name><surname>Parikh</surname><given-names>N</given-names></string-name>, <string-name><surname>Chu</surname><given-names>E</given-names></string-name></person-group><etal>et al</etal><article-title>Distributed optimization and statistical learning via the alternating direction method of multipliers</article-title>. <source>FNT Mach Learn</source><year>2010</year>;<volume>3</volume>:<fpage>1</fpage>–<lpage>122</lpage>.</mixed-citation>
    </ref>
    <ref id="vbad185-B10">
      <mixed-citation publication-type="journal"><collab>Cancer Genome Atlas Network and others</collab>. <article-title>Comprehensive molecular portraits of human breast tumours</article-title>. <source>Nature</source><year>2012</year>;<volume>490</volume>:<fpage>61</fpage>–<lpage>70</lpage>.<pub-id pub-id-type="pmid">23000897</pub-id></mixed-citation>
    </ref>
    <ref id="vbad185-B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chen</surname><given-names>H</given-names></string-name>, <string-name><surname>Sharp</surname><given-names>BM.</given-names></string-name></person-group><article-title>Content-rich biological network constructed by mining PubMed abstracts</article-title>. <source>BMC Bioinformatics</source><year>2004</year>;<volume>5</volume>:<fpage>147</fpage>.<pub-id pub-id-type="pmid">15473905</pub-id></mixed-citation>
    </ref>
    <ref id="vbad185-B12">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Danaher</surname><given-names>P</given-names></string-name>, <string-name><surname>Wang</surname><given-names>P</given-names></string-name>, <string-name><surname>Witten</surname><given-names>DM.</given-names></string-name></person-group><article-title>The joint graphical lasso for inverse covariance estimation across multiple classes</article-title>. <source>J R Stat Soc Series B Stat Methodol</source><year>2014</year>;<volume>76</volume>:<fpage>373</fpage>–<lpage>97</lpage>.<pub-id pub-id-type="pmid">24817823</pub-id></mixed-citation>
    </ref>
    <ref id="vbad185-B13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fan</surname><given-names>J</given-names></string-name>, <string-name><surname>Feng</surname><given-names>Y</given-names></string-name>, <string-name><surname>Wu</surname><given-names>Y.</given-names></string-name></person-group><article-title>Network exploration via the adaptive LASSO and SCAD penalties</article-title>. <source>Ann Appl Stat</source><year>2009</year>;<volume>3</volume>:<fpage>521</fpage>.<pub-id pub-id-type="pmid">21643444</pub-id></mixed-citation>
    </ref>
    <ref id="vbad185-B14">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Foygel</surname><given-names>R</given-names></string-name>, <string-name><surname>Drton</surname><given-names>M.</given-names></string-name></person-group> Extended Bayesian information criteria for Gaussian graphical models. In <italic toggle="yes">Advances in Neural Information Processing Systems, Vancouver, BC</italic>, <fpage>604</fpage>–<lpage>12</lpage>. San Diego, CA: NeurIPS, <year>2010</year>.</mixed-citation>
    </ref>
    <ref id="vbad185-B15">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Friedman</surname><given-names>J</given-names></string-name>, <string-name><surname>Hastie</surname><given-names>T</given-names></string-name>, <string-name><surname>Tibshirani</surname><given-names>R.</given-names></string-name></person-group><article-title>Sparse inverse covariance estimation with the graphical lasso</article-title>. <source>Biostatistics</source><year>2008</year>;<volume>9</volume>:<fpage>432</fpage>–<lpage>41</lpage>.<pub-id pub-id-type="pmid">18079126</pub-id></mixed-citation>
    </ref>
    <ref id="vbad185-B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Goldman</surname><given-names>MJ</given-names></string-name>, <string-name><surname>Craft</surname><given-names>B</given-names></string-name>, <string-name><surname>Hastie</surname><given-names>M</given-names></string-name></person-group><etal>et al</etal><article-title>Visualizing and interpreting cancer genomics data via the Xena platform</article-title>. <source>Nat Biotechnol</source><year>2020</year>;<volume>38</volume>:<fpage>675</fpage>–<lpage>8</lpage>. doi: <pub-id pub-id-type="doi">10.1038/s41587-020-0546-8</pub-id><pub-id pub-id-type="pmid">32444850</pub-id></mixed-citation>
    </ref>
    <ref id="vbad185-B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Guo</surname><given-names>J</given-names></string-name>, <string-name><surname>Levina</surname><given-names>E</given-names></string-name>, <string-name><surname>Michailidis</surname><given-names>G</given-names></string-name></person-group><etal>et al</etal><article-title>Joint estimation of multiple graphical models</article-title>. <source>Biometrika</source><year>2011</year>;<volume>98</volume>:<fpage>1</fpage>–<lpage>15</lpage>.<pub-id pub-id-type="pmid">23049124</pub-id></mixed-citation>
    </ref>
    <ref id="vbad185-B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Langfelder</surname><given-names>P</given-names></string-name>, <string-name><surname>Horvath</surname><given-names>S.</given-names></string-name></person-group><article-title>WGCNA: an R package for weighted correlation network analysis</article-title>. <source>BMC Bioinformatics</source><year>2008</year>;<volume>1</volume>:<fpage>559</fpage>.</mixed-citation>
    </ref>
    <ref id="vbad185-B19">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lartigue</surname><given-names>T</given-names></string-name>, <string-name><surname>Bottani</surname><given-names>S</given-names></string-name>, <string-name><surname>Baron</surname><given-names>S</given-names></string-name></person-group><etal>et al</etal><article-title>Gaussian graphical model exploration and selection in high dimension low sample size setting</article-title>. <source>IEEE Trans Pattern Anal Mach Intell</source><year>2020</year>;<volume>43</volume>:<fpage>3196</fpage>–<lpage>213</lpage>.</mixed-citation>
    </ref>
    <ref id="vbad185-B20">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Lauritzen</surname><given-names>SL.</given-names></string-name></person-group><source>Graphical Models</source>. Vol. <volume>17</volume>. Oxford, UK: <publisher-name>Clarendon Press</publisher-name>, <year>1996</year>.</mixed-citation>
    </ref>
    <ref id="vbad185-B21">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Li</surname><given-names>Y</given-names></string-name>, <string-name><surname>Craig</surname><given-names>BA</given-names></string-name>, <string-name><surname>Bhadra</surname><given-names>A.</given-names></string-name></person-group><article-title>The graphical horseshoe estimator for inverse covariance matrices</article-title>. <source>J Comput Graph Stat</source><year>2019a</year>;<volume>28</volume>:<fpage>747</fpage>–<lpage>57</lpage>.</mixed-citation>
    </ref>
    <ref id="vbad185-B22">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Li</surname><given-names>Y</given-names></string-name>, <string-name><surname>Jackson</surname><given-names>SA.</given-names></string-name></person-group><article-title>Gene network reconstruction by integration of prior biological knowledge</article-title>. <source>G3 (Bethesda)</source><year>2015</year>;<volume>5</volume>:<fpage>1075</fpage>–<lpage>9</lpage>. doi: <pub-id pub-id-type="doi">10.1534/g3.115.018127</pub-id>.<pub-id pub-id-type="pmid">25823587</pub-id></mixed-citation>
    </ref>
    <ref id="vbad185-B23">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Li</surname><given-names>Z</given-names></string-name>, <string-name><surname>Mccormick</surname><given-names>T</given-names></string-name>, <string-name><surname>Clark</surname><given-names>S.</given-names></string-name></person-group> Bayesian joint spike-and-slab graphical lasso. In: <italic toggle="yes">International Conference on Machine Learning, Long Beach, CA</italic>. <fpage>3877</fpage>–<lpage>85</lpage>. <publisher-name>PMLR</publisher-name>, <year>2019b</year>.</mixed-citation>
    </ref>
    <ref id="vbad185-B24">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lingjærde</surname><given-names>C</given-names></string-name>, <string-name><surname>Fairfax</surname><given-names>BP</given-names></string-name>, <string-name><surname>Richardson</surname><given-names>S</given-names></string-name></person-group><etal>et al</etal><article-title>Scalable multiple network inference with the joint graphical horseshoe</article-title>. <source>Ann Appl Stat</source><year>2023</year>; in press.</mixed-citation>
    </ref>
    <ref id="vbad185-B25">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lingjærde</surname><given-names>C</given-names></string-name>, <string-name><surname>Lien</surname><given-names>TG</given-names></string-name>, <string-name><surname>Borgan</surname><given-names>Ø</given-names></string-name></person-group><etal>et al</etal><article-title>Tailored graphical lasso for data integration in gene network reconstruction</article-title>. <source>BMC Bioinformatics</source><year>2021</year>;<volume>22</volume>:<fpage>498</fpage>.<pub-id pub-id-type="pmid">34654363</pub-id></mixed-citation>
    </ref>
    <ref id="vbad185-B26">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Liu</surname><given-names>H</given-names></string-name>, <string-name><surname>Roeder</surname><given-names>K</given-names></string-name>, <string-name><surname>Wasserman</surname><given-names>L.</given-names></string-name></person-group><article-title>Stability approach to regularization selection (StARS) for high dimensional graphical models</article-title>. <source>Adv Neural Inf Process Syst</source><year>2010</year>;<volume>24</volume>:<fpage>1432</fpage>–<lpage>40</lpage>.<pub-id pub-id-type="pmid">25152607</pub-id></mixed-citation>
    </ref>
    <ref id="vbad185-B27">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Meinshausen</surname><given-names>N</given-names></string-name>, <string-name><surname>Bühlmann</surname><given-names>P.</given-names></string-name></person-group><article-title>High-dimensional graphs and variable selection with the lasso</article-title>. <source>Ann Statist</source><year>2006</year>;<volume>34</volume>:<fpage>1436</fpage>–<lpage>62</lpage>.</mixed-citation>
    </ref>
    <ref id="vbad185-B28">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Miricescu</surname><given-names>D</given-names></string-name>, <string-name><surname>Totan</surname><given-names>A</given-names></string-name>, <string-name><surname>Stanescu-Spinu</surname><given-names>I-I</given-names></string-name></person-group><etal>et al</etal><article-title>PI3K/AKT/mTOR signaling pathway in breast cancer: from molecular landscape to clinical aspects</article-title>. <source>Int J Mol Sci</source><year>2020</year>;<volume>22</volume>:<fpage>173</fpage>.<pub-id pub-id-type="pmid">33375317</pub-id></mixed-citation>
    </ref>
    <ref id="vbad185-B29">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nair</surname><given-names>J</given-names></string-name>, <string-name><surname>Huang</surname><given-names>T-T</given-names></string-name>, <string-name><surname>Murai</surname><given-names>J</given-names></string-name></person-group><etal>et al</etal><article-title>Resistance to the CHK1 inhibitor prexasertib involves functionally distinct CHK1 activities in BRCA wild-type ovarian cancer</article-title>. <source>Oncogene</source><year>2020</year>;<volume>39</volume>:<fpage>5520</fpage>–<lpage>35</lpage>.<pub-id pub-id-type="pmid">32647134</pub-id></mixed-citation>
    </ref>
    <ref id="vbad185-B30">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nielsen</surname><given-names>MD</given-names></string-name>, <string-name><surname>Luo</surname><given-names>X</given-names></string-name>, <string-name><surname>Biteau</surname><given-names>B</given-names></string-name></person-group><etal>et al</etal><article-title>14-3-3-Epsilon antagonizes FoxO to control growth, apoptosis and longevity in Drosophila</article-title>. <source>Aging Cell</source><year>2008</year>;<volume>7</volume>:<fpage>688</fpage>–<lpage>99</lpage>.<pub-id pub-id-type="pmid">18665908</pub-id></mixed-citation>
    </ref>
    <ref id="vbad185-B31">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Peterson</surname><given-names>C</given-names></string-name>, <string-name><surname>Stingo</surname><given-names>FC</given-names></string-name>, <string-name><surname>Vannucci</surname><given-names>M.</given-names></string-name></person-group><article-title>Bayesian inference of multiple Gaussian graphical models</article-title>. <source>J Am Stat Assoc</source><year>2015</year>;<volume>110</volume>:<fpage>159</fpage>–<lpage>74</lpage>.<pub-id pub-id-type="pmid">26078481</pub-id></mixed-citation>
    </ref>
    <ref id="vbad185-B32">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Schwarz</surname><given-names>G.</given-names></string-name></person-group><article-title>Estimating the dimension of a model</article-title>. <source>Ann Statist</source><year>1978</year>;<volume>6</volume>:<fpage>461</fpage>–<lpage>4</lpage>.</mixed-citation>
    </ref>
    <ref id="vbad185-B33">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Szklarczyk</surname><given-names>D</given-names></string-name>, <string-name><surname>Gable</surname><given-names>AL</given-names></string-name>, <string-name><surname>Lyon</surname><given-names>D</given-names></string-name></person-group><etal>et al</etal><article-title>STRING v11: protein-protein association networks with increased coverage, supporting functional discovery in genome-wide experimental datasets</article-title>. <source>Nucleic Acids Res</source><year>2019</year>;<volume>47</volume>:<fpage>D607</fpage>–<lpage>13</lpage>.<pub-id pub-id-type="pmid">30476243</pub-id></mixed-citation>
    </ref>
    <ref id="vbad185-B34">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Trovik</surname><given-names>J</given-names></string-name>, <string-name><surname>Wik</surname><given-names>E</given-names></string-name>, <string-name><surname>Stefansson</surname><given-names>IM</given-names></string-name></person-group><etal>et al</etal>; <collab>MoMaTec Study Group</collab>. <article-title>Stathmin overexpression identifies high-risk patients and lymph node metastasis in endometrial cancer</article-title>. <source>Clin Cancer Res</source><year>2011</year>;<volume>17</volume>:<fpage>3368</fpage>–<lpage>77</lpage>.<pub-id pub-id-type="pmid">21242118</pub-id></mixed-citation>
    </ref>
    <ref id="vbad185-B35">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tzivion</surname><given-names>G</given-names></string-name>, <string-name><surname>Dobson</surname><given-names>M</given-names></string-name>, <string-name><surname>Ramakrishnan</surname><given-names>G.</given-names></string-name></person-group><article-title>FoxO transcription factors; Regulation by AKT and 14-3-3 proteins</article-title>. <source>Biochim Biophys Acta</source><year>2011</year>;<volume>1813</volume>:<fpage>1938</fpage>–<lpage>45</lpage>.<pub-id pub-id-type="pmid">21708191</pub-id></mixed-citation>
    </ref>
    <ref id="vbad185-B36">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname><given-names>H.</given-names></string-name></person-group><article-title>Bayesian graphical lasso models and efficient posterior computation</article-title>. <source>Bayesian Anal</source><year>2012</year>;<volume>7</volume>:<fpage>867</fpage>–<lpage>86</lpage>.</mixed-citation>
    </ref>
    <ref id="vbad185-B37">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname><given-names>H.</given-names></string-name></person-group><article-title>Scaling it up: stochastic search structure learning in graphical models</article-title>. <source>Bayesian Anal</source><year>2015</year>;<volume>10</volume>:<fpage>351</fpage>–<lpage>77</lpage>.</mixed-citation>
    </ref>
    <ref id="vbad185-B38">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yang</surname><given-names>J-Y</given-names></string-name>, <string-name><surname>Yoshihara</surname><given-names>K</given-names></string-name>, <string-name><surname>Tanaka</surname><given-names>K</given-names></string-name></person-group><etal>et al</etal>; <collab>Cancer Genome Atlas (TCGA) Research Network</collab>. <article-title>Predicting time to ovarian carcinoma recurrence using protein markers</article-title>. <source>J Clin Investig</source><year>2013</year>;<volume>123</volume>:<fpage>3740</fpage>–<lpage>50</lpage>.<pub-id pub-id-type="pmid">23945238</pub-id></mixed-citation>
    </ref>
    <ref id="vbad185-B39">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname><given-names>H</given-names></string-name>, <string-name><surname>Liu</surname><given-names>T</given-names></string-name>, <string-name><surname>Zhang</surname><given-names>Z</given-names></string-name></person-group><etal>et al</etal>; <collab>CPTAC Investigators</collab>. <article-title>Integrated proteogenomic characterization of human high-grade serous ovarian cancer</article-title>. <source>Cell</source><year>2016</year>;<volume>166</volume>:<fpage>755</fpage>–<lpage>65</lpage>.<pub-id pub-id-type="pmid">27372738</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
