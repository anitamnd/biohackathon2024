<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1d3 20150301//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 39.96?>
<?ConverterInfo.XSLTName jp2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">PLoS One</journal-id>
    <journal-id journal-id-type="iso-abbrev">PLoS ONE</journal-id>
    <journal-id journal-id-type="publisher-id">plos</journal-id>
    <journal-id journal-id-type="pmc">plosone</journal-id>
    <journal-title-group>
      <journal-title>PLoS ONE</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1932-6203</issn>
    <publisher>
      <publisher-name>Public Library of Science</publisher-name>
      <publisher-loc>San Francisco, CA USA</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">6857918</article-id>
    <article-id pub-id-type="publisher-id">PONE-D-19-08434</article-id>
    <article-id pub-id-type="doi">10.1371/journal.pone.0224446</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Research Article</subject>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Genetics</subject>
          <subj-group>
            <subject>Gene Expression</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Physical Sciences</subject>
        <subj-group>
          <subject>Mathematics</subject>
          <subj-group>
            <subject>Applied Mathematics</subject>
            <subj-group>
              <subject>Algorithms</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Research and Analysis Methods</subject>
        <subj-group>
          <subject>Simulation and Modeling</subject>
          <subj-group>
            <subject>Algorithms</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Medicine and Health Sciences</subject>
        <subj-group>
          <subject>Oncology</subject>
          <subj-group>
            <subject>Cancers and Neoplasms</subject>
            <subj-group>
              <subject>Breast Tumors</subject>
              <subj-group>
                <subject>Breast Cancer</subject>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Research and Analysis Methods</subject>
        <subj-group>
          <subject>Mathematical and Statistical Techniques</subject>
          <subj-group>
            <subject>Statistical Methods</subject>
            <subj-group>
              <subject>Multivariate Analysis</subject>
              <subj-group>
                <subject>Principal Component Analysis</subject>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Physical Sciences</subject>
        <subj-group>
          <subject>Mathematics</subject>
          <subj-group>
            <subject>Statistics</subject>
            <subj-group>
              <subject>Statistical Methods</subject>
              <subj-group>
                <subject>Multivariate Analysis</subject>
                <subj-group>
                  <subject>Principal Component Analysis</subject>
                </subj-group>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Research and Analysis Methods</subject>
        <subj-group>
          <subject>Mathematical and Statistical Techniques</subject>
          <subj-group>
            <subject>Statistical Methods</subject>
            <subj-group>
              <subject>Forecasting</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Physical Sciences</subject>
        <subj-group>
          <subject>Mathematics</subject>
          <subj-group>
            <subject>Statistics</subject>
            <subj-group>
              <subject>Statistical Methods</subject>
              <subj-group>
                <subject>Forecasting</subject>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Physical Sciences</subject>
        <subj-group>
          <subject>Mathematics</subject>
          <subj-group>
            <subject>Applied Mathematics</subject>
            <subj-group>
              <subject>Algorithms</subject>
              <subj-group>
                <subject>Machine Learning Algorithms</subject>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Research and Analysis Methods</subject>
        <subj-group>
          <subject>Simulation and Modeling</subject>
          <subj-group>
            <subject>Algorithms</subject>
            <subj-group>
              <subject>Machine Learning Algorithms</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Computer and Information Sciences</subject>
        <subj-group>
          <subject>Artificial Intelligence</subject>
          <subj-group>
            <subject>Machine Learning</subject>
            <subj-group>
              <subject>Machine Learning Algorithms</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Research and Analysis Methods</subject>
        <subj-group>
          <subject>Bioassays and Physiological Analysis</subject>
          <subj-group>
            <subject>Microarrays</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Computer and Information Sciences</subject>
        <subj-group>
          <subject>Software Engineering</subject>
          <subj-group>
            <subject>Subroutines</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Engineering and Technology</subject>
        <subj-group>
          <subject>Software Engineering</subject>
          <subj-group>
            <subject>Subroutines</subject>
          </subj-group>
        </subj-group>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Gene expression based survival prediction for cancer patients—A topic modeling approach</article-title>
      <alt-title alt-title-type="running-head">Gene expression based survival prediction</alt-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" equal-contrib="yes">
        <contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-5129-2598</contrib-id>
        <name>
          <surname>Kumar</surname>
          <given-names>Luke</given-names>
        </name>
        <role content-type="http://credit.casrai.org/">Conceptualization</role>
        <role content-type="http://credit.casrai.org/">Formal analysis</role>
        <role content-type="http://credit.casrai.org/">Investigation</role>
        <role content-type="http://credit.casrai.org/">Methodology</role>
        <role content-type="http://credit.casrai.org/">Software</role>
        <role content-type="http://credit.casrai.org/">Validation</role>
        <role content-type="http://credit.casrai.org/">Visualization</role>
        <role content-type="http://credit.casrai.org/">Writing – original draft</role>
        <role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
        <xref ref-type="aff" rid="aff001">
          <sup>1</sup>
        </xref>
        <xref ref-type="aff" rid="aff002">
          <sup>2</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author" equal-contrib="yes">
        <name>
          <surname>Greiner</surname>
          <given-names>Russell</given-names>
        </name>
        <role content-type="http://credit.casrai.org/">Conceptualization</role>
        <role content-type="http://credit.casrai.org/">Funding acquisition</role>
        <role content-type="http://credit.casrai.org/">Methodology</role>
        <role content-type="http://credit.casrai.org/">Project administration</role>
        <role content-type="http://credit.casrai.org/">Resources</role>
        <role content-type="http://credit.casrai.org/">Supervision</role>
        <role content-type="http://credit.casrai.org/">Validation</role>
        <role content-type="http://credit.casrai.org/">Visualization</role>
        <role content-type="http://credit.casrai.org/">Writing – original draft</role>
        <role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
        <xref ref-type="aff" rid="aff001">
          <sup>1</sup>
        </xref>
        <xref ref-type="aff" rid="aff002">
          <sup>2</sup>
        </xref>
        <xref ref-type="corresp" rid="cor001">*</xref>
      </contrib>
    </contrib-group>
    <aff id="aff001">
      <label>1</label>
      <addr-line>Department of Computing Science, University of Alberta, Edmonton, Alberta, Canada</addr-line>
    </aff>
    <aff id="aff002">
      <label>2</label>
      <addr-line>Alberta Machine Intelligence Institute (Amii), Edmonton, Alberta, Canada</addr-line>
    </aff>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Pławiak</surname>
          <given-names>Paweł</given-names>
        </name>
        <role>Editor</role>
        <xref ref-type="aff" rid="edit1"/>
      </contrib>
    </contrib-group>
    <aff id="edit1">
      <addr-line>Politechnika Krakowska im Tadeusza Kosciuszki, POLAND</addr-line>
    </aff>
    <author-notes>
      <fn fn-type="COI-statement" id="coi001">
        <p><bold>Competing Interests: </bold>The authors have declared that no competing interests exist.</p>
      </fn>
      <corresp id="cor001">* E-mail: <email>rgreiner@ualberta.ca</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <year>2019</year>
    </pub-date>
    <pub-date pub-type="epub">
      <day>15</day>
      <month>11</month>
      <year>2019</year>
    </pub-date>
    <volume>14</volume>
    <issue>11</issue>
    <elocation-id>e0224446</elocation-id>
    <history>
      <date date-type="received">
        <day>25</day>
        <month>3</month>
        <year>2019</year>
      </date>
      <date date-type="accepted">
        <day>14</day>
        <month>10</month>
        <year>2019</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© 2019 Kumar, Greiner</copyright-statement>
      <copyright-year>2019</copyright-year>
      <copyright-holder>Kumar, Greiner</copyright-holder>
      <license xlink:href="http://creativecommons.org/licenses/by/4.0/">
        <license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
      </license>
    </permissions>
    <self-uri content-type="pdf" xlink:href="pone.0224446.pdf"/>
    <abstract>
      <p>Cancer is one of the leading cause of death, worldwide. Many believe that genomic data will enable us to better predict the survival time of these patients, which will lead to better, more personalized treatment options and patient care. As standard survival prediction models have a hard time coping with the high-dimensionality of such gene expression data, many projects use some dimensionality reduction techniques to overcome this hurdle. We introduce a novel methodology, inspired by topic modeling from the natural language domain, to derive expressive features from the high-dimensional gene expression data. There, a document is represented as a mixture over a relatively small number of topics, where each topic corresponds to a distribution over the words; here, to accommodate the heterogeneity of a patient’s cancer, we represent each patient (≈ document) as a mixture over cancer-topics, where each cancer-topic is a mixture over gene expression values (≈ words). This required some extensions to the standard LDA model—<italic>e.g</italic>., to accommodate the <italic>real-valued</italic> expression values—leading to our novel <italic>discretized Latent Dirichlet Allocation</italic> (dLDA) procedure. After using this dLDA to learn these cancer-topics, we can then express each patient as a distribution over a small number of cancer-topics, then use this low-dimensional “distribution vector” as input to a learning algorithm—here, we ran the recent survival prediction algorithm, MTLR, on this representation of the cancer dataset. We initially focus on the METABRIC dataset, which describes each of n = 1,981 breast cancer patients using the r = 49,576 gene expression values, from microarrays. Our results show that our approach (dLDA followed by MTLR) provides survival estimates that are more accurate than standard models, in terms of the standard Concordance measure. We then validate this “dLDA+MTLR” approach by running it on the n = 883 Pan-kidney (KIPAN) dataset, over r = 15,529 gene expression values—here using the mRNAseq modality—and find that it again achieves excellent results. In both cases, we also show that the resulting model is calibrated, using the recent “D-calibrated” measure. These successes, in two different cancer types and expression modalities, demonstrates the generality, and the effectiveness, of this approach. The dLDA+MTLR source code is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/nitsanluke/GE-LDA-Survival">https://github.com/nitsanluke/GE-LDA-Survival</ext-link>.</p>
    </abstract>
    <funding-group>
      <funding-statement>This work has been supported by the funding from Alberta Machine Intelligence Institute (Amii), and from NSERC.</funding-statement>
    </funding-group>
    <counts>
      <fig-count count="9"/>
      <table-count count="3"/>
      <page-count count="30"/>
    </counts>
    <custom-meta-group>
      <custom-meta id="data-availability">
        <meta-name>Data Availability</meta-name>
        <meta-value>The datasets underlying this work are public available third-party data, and authors of this study did not have any special access to the datasets which others wouldn’t have. 1. The KIPAN dataset is available from the BROAD database, follow the link <ext-link ext-link-type="uri" xlink:href="http://firebrowse.org/?cohort=KIPAN&amp;download_dialog=true">http://firebrowse.org/?cohort=KIPAN&amp;download_dialog=true</ext-link>. 2. The METABRIC dataset is made available by the Sage Bionetworks-DREAM Breast Cancer Prognosis Challenge. Researches can access the data at <ext-link ext-link-type="uri" xlink:href="https://www.synapse.org/#!Synapse:syn1688369/wiki/27311">https://www.synapse.org/#!Synapse:syn1688369/wiki/27311</ext-link>.</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
  <notes>
    <title>Data Availability</title>
    <p>The datasets underlying this work are public available third-party data, and authors of this study did not have any special access to the datasets which others wouldn’t have. 1. The KIPAN dataset is available from the BROAD database, follow the link <ext-link ext-link-type="uri" xlink:href="http://firebrowse.org/?cohort=KIPAN&amp;download_dialog=true">http://firebrowse.org/?cohort=KIPAN&amp;download_dialog=true</ext-link>. 2. The METABRIC dataset is made available by the Sage Bionetworks-DREAM Breast Cancer Prognosis Challenge. Researches can access the data at <ext-link ext-link-type="uri" xlink:href="https://www.synapse.org/#!Synapse:syn1688369/wiki/27311">https://www.synapse.org/#!Synapse:syn1688369/wiki/27311</ext-link>.</p>
  </notes>
</front>
<body>
  <sec sec-type="intro" id="sec001">
    <title>1 Introduction</title>
    <p>The World Health Organization reports that cancer has become the second leading cause of death globally, as approximately 1 in 6 deaths are caused by some form of cancer [<xref rid="pone.0224446.ref001" ref-type="bibr">1</xref>]. Moreover, cancers are very heterogeneous, in that the outcomes can vary widely for patients with similar diagnoses, who receive the same treatment regimen. This has motivated researchers to seek other features to help predict individual outcomes. Many such analyses use just clinical features. Unfortunately, features such as lymph node status and histological grade, while predictive of metastases, do not appear to be sufficient to reliably categorize clinical outcome [<xref rid="pone.0224446.ref002" ref-type="bibr">2</xref>]. This has led to many efforts to improve the prognosis for cancer, based on genomics data (<italic>e.g</italic>., gene expression (GE) or copy number variation (CNV)), possibly along with the clinical data [<xref rid="pone.0224446.ref002" ref-type="bibr">2</xref>–<xref rid="pone.0224446.ref006" ref-type="bibr">6</xref>]. Focusing for now on breast cancer, van’t Veer <italic>et al</italic>. [<xref rid="pone.0224446.ref002" ref-type="bibr">2</xref>] used the expression of 70 genes to distinguish high vs low risk of distant metastases within five years. Parker <italic>et al</italic>. [<xref rid="pone.0224446.ref004" ref-type="bibr">4</xref>] identified five subtypes of breast cancer, based on a panel of 50 genes (PAM50): luminal A, luminal B, HER2-enriched, basal-like, and normal-like. Later, Curtis <italic>et al</italic>. [<xref rid="pone.0224446.ref007" ref-type="bibr">7</xref>] examined ≈2000 patients from a wide study combining clinical and genomic data, and identified around ten subtypes. All three of these studies showed that their respective subtypes produce significantly different Kaplan-Meier survival curves [<xref rid="pone.0224446.ref008" ref-type="bibr">8</xref>], suggesting such molecular variation does influence the disease progression. There are also many other systems that use such expression information to divide the patients into two categories: high- vs low-risk; <italic>cf</italic>., [<xref rid="pone.0224446.ref002" ref-type="bibr">2</xref>, <xref rid="pone.0224446.ref006" ref-type="bibr">6</xref>].</p>
    <p>More recently, many survival <italic>prediction</italic> models have been applied to cancer cohorts, with the goal of estimating survival times for individual patients; some are based on standard statistical survival analysis techniques, and others based on classic regression algorithms—<italic>e.g</italic>., random survival forests [<xref rid="pone.0224446.ref009" ref-type="bibr">9</xref>] or support vector regression for censored data (SVRc) [<xref rid="pone.0224446.ref010" ref-type="bibr">10</xref>]. With the growing number of gene expression experiments being cataloged for analysis, we need to develop survival prediction models that can utilize such high dimensional data. Our work describes such a system that can learn effective survival prediction models from high-dimensional gene expression data.</p>
    <p>The 2012 DREAM Breast Cancer Challenge (BCC) was designed to focus the community’s efforts to improve breast cancer survival prediction [<xref rid="pone.0224446.ref003" ref-type="bibr">3</xref>]. Its organizers made available clinical and genomic data (GE and CNV) of ≈2000 patients from the [<xref rid="pone.0224446.ref007" ref-type="bibr">7</xref>] study (mentioned above). Each submission to the BCC challenge mapped each patient to a single real value (called “risk”), which is predicting that patients with higher risk should die earlier than those with lower risk. The entries were therefore evaluated based on the concordance measure: basically, the percentage of these pairwise predictions that were correct [<xref rid="pone.0224446.ref011" ref-type="bibr">11</xref>]. This is standard, in that many survival prediction tasks use the concordance as the primary measure to assess the performance of the survival predictors, here and in other challenges [<xref rid="pone.0224446.ref012" ref-type="bibr">12</xref>]. The winning model [<xref rid="pone.0224446.ref013" ref-type="bibr">13</xref>] performed statistically better than the state-of-the-art benchmark models [<xref rid="pone.0224446.ref003" ref-type="bibr">3</xref>].</p>
    <p>This paper explores several dimensionality reduction technique, including a novel approach based on topic modeling, “discretized Latent Dirichlet Allocation” (dLDA), seeking one that can produce highly predictive features from the high-dimensional gene expression data. We explored several ways to apply this topic-modeling approach to gene expression data, to identify the best ways to use it to map the gene expression description into a much lower dimensional description (from ≈50K features to 30 in this METABRIC dataset). We then gave the resulting transformed data as input to a recently-developed non-parametric learning algorithm, multi-task logistic regression (MTLR), which produced a model that can then predict an individual’s survival distribution [<xref rid="pone.0224446.ref014" ref-type="bibr">14</xref>]. We show that this predictor performs better than other standard survival analysis tools in terms of concordance. We also found that it was “D-calibrated” [<xref rid="pone.0224446.ref015" ref-type="bibr">15</xref>, <xref rid="pone.0224446.ref016" ref-type="bibr">16</xref>]; see Appendix B.2.</p>
    <p>To test the generality of our learning approach (dLDA + MTLR), we then applied the same learning algorithm—the one that worked for the METABRIC microarray gene expression dataset—to the Pan-Kidney dataset, which is a different type of cancer (kidney, not breast), and is described using a different type of features (mRNAseq, not microarray). We found that the resulting predictor was also extremely effective, in terms of both concordance and D-calibration.</p>
    <p>This paper provides the following three contributions: (1) We produce an extension to LDA, called “dLDA”, needed to handle continuous data; (2) we use this as input to a survival prediction tool, MTLR—introducing that tool to this bioinformatics community; and (3) we demonstrate that this dLDA+MTLR combination works robustly, in two different datasets, using two different modalities—working better than some other standard approaches, in survival prediction.</p>
    <p>Section 2 introduces the basic concepts, related to the survival prediction task in general and latent dirichlet allocation; Section 3 then describes the datasets used in this study; and Section 4 presents an overview of learning and performance tasks, at a high level. Section 5 (resp., 6, 7) then presents our results (resp., discussions, contributions). The supplementary appendices provide additional figures, tables, and other and material—<italic>e.g</italic>., defining some of the terms, and introducing “D-calibration”.</p>
  </sec>
  <sec id="sec002">
    <title>2 Foundations</title>
    <p>This section provides the foundations: Section 2.1 overviews the survival prediction task in general then Section 2.2 describes Latent Dirichlet Allocation (LDA), first showing its original natural language context, then discussing how we need to extend it for our gene expression context. These significant modifications lead to a discretized variant, dLDA. We also contrast this approach with other survival analysis of gene expressions.</p>
    <sec id="sec003">
      <title>2.1 Survival prediction</title>
      <p>Survival prediction is similar to regression as both involve learning a model that regresses the covariates of an individual to estimate the value of a dependent real-valued response variable—here, that variable is “time to event” (where the standard event is “death”). But survival prediction differs from the standard regression task as its response variable is not fully observed in all training instances—this tasks allows many of the instances to be “right censored”, in that we only see a <italic>lower bound</italic> of the response value. This might happen if a subject was alive when the study ended, meaning we only know that she lived <italic>at least</italic> (say) 5 years after the starting time, but do not know whether she actually lived 5 years and a day, or 30 years. This also happens if a subject drops out of a study, after say 2.3 years, and is then lost to follow-up; etc. Moreover, one cannot simply ignore such instances as it is common for many (or often, <italic>most</italic>) of the training instances to be right-censored; see <xref rid="pone.0224446.t001" ref-type="table">Table 1</xref>. Such “partial label information” is problematic for standard regression techniques, which assume the label is completely specified for each training instance. Fortunately, there are survival prediction algorithms that can learn an effective model, from a cohort that includes such censored data. Each such dataset contains descriptions of a set of instances (<italic>e.g</italic>., patients), as well as two “labels” for each: one is the time, corresponding to the <italic>time from diagnosis to a final date</italic> (either death, or time of last follow-up) and the other is the <italic>status</italic> bit, which indicates whether the patient was alive at that final date (<xref ref-type="fig" rid="pone.0224446.g001">Fig 1</xref>).</p>
      <fig id="pone.0224446.g001" orientation="portrait" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pone.0224446.g001</object-id>
        <label>Fig 1</label>
        <caption>
          <title>Survival prediction training and performance tasks.</title>
          <p><italic>Training-Task</italic>: Historical data with event times and censor-status along with covariates are used to train a model—top-to-bottom. <italic>Performance-Task</italic>: new patient covariates are input to the learned model to produce a prediction of survival time—bottom, left-to-right. (Included picture designed by Freepik.).</p>
        </caption>
        <graphic xlink:href="pone.0224446.g001"/>
      </fig>
      <table-wrap id="pone.0224446.t001" orientation="portrait" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pone.0224446.t001</object-id>
        <label>Table 1</label>
        <caption>
          <title>Characteristics of METABRIC and KIPAN cohorts.</title>
        </caption>
        <alternatives>
          <graphic id="pone.0224446.t001g" xlink:href="pone.0224446.t001"/>
          <table frame="box" rules="all" border="0">
            <colgroup span="1">
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th align="left" style="border-bottom:thick;background-color:#ebebeb" rowspan="1" colspan="1"/>
                <th align="left" style="border-bottom:thick;background-color:#ebebeb" rowspan="1" colspan="1">METABRIC</th>
                <th align="left" style="border-bottom:thick;background-color:#ebebeb" rowspan="1" colspan="1">KIPAN</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="left" rowspan="1" colspan="1"># Patients<xref ref-type="table-fn" rid="t001fn001"><sup>a</sup></xref></td>
                <td align="left" rowspan="1" colspan="1">1,981</td>
                <td align="left" rowspan="1" colspan="1">883</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1"># Censored</td>
                <td align="left" rowspan="1" colspan="1">1,358 (∼ 68.5%)</td>
                <td align="left" rowspan="1" colspan="1">655 (∼ 74.4%)</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1"># Uncensored</td>
                <td align="left" rowspan="1" colspan="1">623</td>
                <td align="left" rowspan="1" colspan="1">228</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Time span in days (Uncensored)</td>
                <td align="left" rowspan="1" colspan="1">3—8,941</td>
                <td align="left" rowspan="1" colspan="1">2—5,925</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1"># Clinical features</td>
                <td align="left" rowspan="1" colspan="1">19</td>
                <td align="left" rowspan="1" colspan="1">10</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1"># Expressions (≈ #genes)<xref ref-type="table-fn" rid="t001fn002"><sup>b</sup></xref></td>
                <td align="left" rowspan="1" colspan="1">49,576 (probes)</td>
                <td align="left" rowspan="1" colspan="1">15,529</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Gender</td>
                <td align="left" rowspan="1" colspan="1">Women (100%)</td>
                <td align="left" rowspan="1" colspan="1">Women (32.7%), Men (67.3%)</td>
              </tr>
            </tbody>
          </table>
        </alternatives>
        <table-wrap-foot>
          <fn id="t001fn001">
            <p><sup>a</sup> We removed the ∼50 patients from the KIPAN dataset that did not contain mRNAseq data.</p>
          </fn>
          <fn id="t001fn002">
            <p><sup>b</sup> While METABRIC also included copy number variations (CNV) data for the patients, here we focus on only gene expression data.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <sec id="sec004">
        <title>2.1.1 Patient specific survival prediction using the MTLR model</title>
        <p>This project considered 3 ways to learn a survival model: The standard approaches—Cox and Regularized Cox (RCox)—are overviewed in Appendix A.5. This subsection describes the relatively-new MTLR [<xref rid="pone.0224446.ref014" ref-type="bibr">14</xref>] system, which learns a model (from survival data) that, given a description of a patient <bold>x</bold> ∈ ℜ<sup><italic>r</italic></sup>, produces a <italic>survival</italic> curve, which specifies the probability of death <italic>D</italic>, <italic>P</italic>(<italic>D</italic> ≥ <italic>t</italic> | <bold>x</bold>) vs <italic>t</italic> for all times <italic>t</italic> ≥ 0. This survival curve is similar to a Kaplan–Meier curve [<xref rid="pone.0224446.ref008" ref-type="bibr">8</xref>], but incorporates all of the patient specific features <bold>x</bold>. In more detail: MTLR first identifies <italic>m</italic> time points {<italic>t</italic><sub><italic>i</italic></sub>}<sub><italic>i</italic>=1‥<italic>m</italic></sub> and then learns a variant of a logistic regression function, parameterized by <italic>W</italic> = {[<italic>w</italic><sub><italic>i</italic></sub>, <italic>b</italic><sub><italic>i</italic></sub>]}<sub><italic>i</italic>=1‥<italic>m</italic></sub> over these <italic>m</italic> time points, a different such function for each time <italic>t</italic><sub><italic>i</italic></sub>—meaning <italic>W</italic> is a matrix of size <italic>m</italic> × (<italic>r</italic> + 1). Using the random variable <italic>D</italic> for the time of death for the patient described by <bold>x</bold>:
<disp-formula id="pone.0224446.e001"><alternatives><graphic xlink:href="pone.0224446.e001.jpg" id="pone.0224446.e001g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M1"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>P</mml:mi><mml:msub><mml:mi>r</mml:mi><mml:mi>W</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mspace width="0.166667em"/><mml:mi>D</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mspace width="4pt"/><mml:mo>|</mml:mo><mml:mspace width="4pt"/><mml:mi mathvariant="bold">x</mml:mi><mml:mspace width="0.166667em"/><mml:mo>)</mml:mo></mml:mrow><mml:mspace width="1.em"/><mml:mo>∝</mml:mo><mml:mspace width="1.em"/><mml:mtext>exp</mml:mtext><mml:mo>(</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>ℓ</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow><mml:mi>m</mml:mi></mml:munderover><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mi>ℓ</mml:mi></mml:msub></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:mi mathvariant="bold">x</mml:mi><mml:mspace width="4pt"/><mml:mo>+</mml:mo><mml:mspace width="4pt"/><mml:msub><mml:mi>b</mml:mi><mml:mi>ℓ</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mspace width="0.166667em"/><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(1)</label></disp-formula>
The MTLR model then combines the values of the PMF (probability mass function) into a CMF (cumulative mass function), by adding them in the reverse order—hence from the probability value of 1 at <italic>t</italic><sub>0</sub> = 0—<italic>i.e</italic>., <italic>Pr</italic><sub><italic>W</italic></sub>(<italic>D</italic> ≥ 0 | <bold>x</bold>) = 1—down to smaller values as the time <italic>t</italic> increases. <xref ref-type="fig" rid="pone.0224446.g002">Fig 2</xref> shows the individual survival curves of several patients. Here, we view a patient’s descretized survival time <italic>d</italic> ∈ ℜ<sup>≥0</sup> as a binary vector (of classification labels) <italic>y</italic>(<italic>d</italic>) = [<italic>y</italic><sub>1</sub>(<italic>d</italic>), <italic>y</italic><sub>2</sub>(<italic>d</italic>), …, <italic>y</italic><sub><italic>m</italic></sub>(<italic>d</italic>)], where each <italic>y</italic><sub><italic>j</italic></sub>(<italic>d</italic>) ∈ {0, 1} encodes that patient’s survival status at each time interval [<italic>t</italic><sub><italic>j</italic></sub>, <italic>t</italic><sub><italic>j</italic>+1</sub>]: <italic>y</italic><sub><italic>j</italic></sub>(<italic>d</italic>) = 0 (no death yet) for all <italic>j</italic> with <italic>t</italic><sub><italic>j</italic></sub> &lt; <italic>d</italic> and <italic>y</italic><sub><italic>j</italic></sub>(<italic>d</italic>) = 1 (death) for all <italic>t</italic><sub><italic>j</italic></sub> ≥ <italic>d</italic>. The learning system attempts to optimize
<disp-formula id="pone.0224446.e002"><alternatives><graphic xlink:href="pone.0224446.e002.jpg" id="pone.0224446.e002g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M2"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mtable><mml:mtr><mml:mtd columnalign="left"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:munder><mml:mtext>min</mml:mtext><mml:mi>W</mml:mi></mml:munder><mml:mspace width="4pt"/><mml:mfrac><mml:mi>C</mml:mi><mml:mn>2</mml:mn></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>m</mml:mi></mml:munderover><mml:msup><mml:mrow><mml:mo>‖</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>‖</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mspace width="1.em"/><mml:mo>-</mml:mo><mml:mspace width="1.em"/><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:mo>[</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>m</mml:mi></mml:munderover><mml:msub><mml:mi>y</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi>w</mml:mi><mml:mi>T</mml:mi></mml:msup><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>-</mml:mo><mml:mtext>log</mml:mtext><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mi>m</mml:mi></mml:munderover><mml:mtext>exp</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mi>W</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>k</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="left"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtext>where</mml:mtext><mml:mspace width="1.em"/><mml:msub><mml:mi>f</mml:mi><mml:mi>W</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>k</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mspace width="1.em"/><mml:mo>=</mml:mo><mml:mspace width="1.em"/><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>ℓ</mml:mi><mml:mo>=</mml:mo><mml:mo>(</mml:mo><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow><mml:mi>m</mml:mi></mml:munderover><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi>w</mml:mi><mml:mi>ℓ</mml:mi><mml:mi>T</mml:mi></mml:msubsup><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mi>ℓ</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mspace width="2.em"/><mml:mtext>for</mml:mtext><mml:mspace width="4pt"/><mml:mspace width="4pt"/><mml:mn>0</mml:mn><mml:mo>≤</mml:mo><mml:mi>k</mml:mi><mml:mo>≤</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(2)</label></disp-formula>
(This formula applies to uncensored patients; we apply the obvious extension to deal with censored instances.) This overall equation includes a L2 regularization term to reduce the risk of overfitting. The MTLR parameter <italic>m</italic> (the number of time points) is set to the square-root of the number of instances in all our experiments.</p>
        <fig id="pone.0224446.g002" orientation="portrait" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pone.0224446.g002</object-id>
          <label>Fig 2</label>
          <caption>
            <title>The dashed line is the Kaplan-Meier plot for this dataset.</title>
            <p>Each of the other 5 curves is a patient-specific survival curve, for 5 different METABRIC patients, from a learned MTLR model. The curves show that there are very different prognoses for the different patients, even though they all are breast cancer patients from the same cohort: here, the patient with the orange survival curve (near the top) has a very good prognosis, especially compared to the patient with the blue survival curve.</p>
          </caption>
          <graphic xlink:href="pone.0224446.g002"/>
        </fig>
        <p>Given the learned parameters <italic>W</italic>, we can then use <xref ref-type="disp-formula" rid="pone.0224446.e001">Eq 1</xref> to produce a curve for each patient; we can then use the (negative of) the mean of the patient’s specific predicted survival distribution as her risk score. Yu <italic>et al</italic>. [<xref rid="pone.0224446.ref014" ref-type="bibr">14</xref>] presents more detailed explanations of model formulation, parameter learning (<italic>W</italic>), and the prediction task. MTLR differs from many other models (such as the standard Cox model) as: (1) MTLR produces a survival function, rather than just a risk score; and (2) MTLR does not make the proportional hazards assumption—<italic>i.e</italic>., it allows effect of each covariate to change with time. See also Haider <italic>et al</italic>. [<xref rid="pone.0224446.ref016" ref-type="bibr">16</xref>]. Note this is the learning process of LearnSurvivalModel (LSM<sub>[Ψ=MTLR]</sub>) appearing below in <xref ref-type="fig" rid="pone.0224446.g003">Fig 3</xref>, and Section 4.1.</p>
        <fig id="pone.0224446.g003" orientation="portrait" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pone.0224446.g003</object-id>
          <label>Fig 3</label>
          <caption>
            <title>Overview of learning process.</title>
            <p>LSM = LearnSurvivalModel Uses Ψ ∈ {MTLR, Cox, RCox} for type of learner; <italic>ρ</italic> ∈ {dLDA, PCA} for the type of basis; <italic>X</italic><sub><italic>GE</italic></sub> are the gene expression values, <italic>X</italic><sub><italic>CF</italic></sub> are clinical features for a set of patients, “<italic>Lbl</italic>” is the set of their (survival prediction) labels, <inline-formula id="pone.0224446.e003"><alternatives><graphic id="pone.0224446.e003g" xlink:href="pone.0224446.e003"/><mml:math id="M3"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>β</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mrow><mml:mi>G</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> is the basis, of type <italic>ρ</italic> based on the instance <italic>X</italic><sub><italic>GE</italic></sub>; <italic>W</italic> is the learned survival model, of type Ψ; and Ω is information about the preprocessing. Each (unrounded) box corresponds to data, whose dimensions appear around it. Each row is a patient, and each column, a feature. Each rounded box is a subroutine; here we show the input and output of each.</p>
          </caption>
          <graphic xlink:href="pone.0224446.g003"/>
        </fig>
      </sec>
    </sec>
    <sec id="sec005">
      <title>2.2 Discretized Latent Dirichlet Allocation (dLDA)</title>
      <p>Latent Dirichlet Allocation (LDA) is a widely used generative model [<xref rid="pone.0224446.ref017" ref-type="bibr">17</xref>], with many successful applications in natural language (NL) processing. LDA views each document as a distribution over multiple topics (document-topics distribution), where each topic is a distribution over a set of words (topic-words distribution)—that is, LDA assumes that each word in a document is generated by first sampling a topic from the document’s document-topics distribution and then sampling a word from the selected topic’s topic-words distribution. Given the set of topics (each corresponding to a specific topic-word distribution), we can view each document as its distribution over topics, which is very low dimensional.</p>
      <p>The LDA <italic>learning process</italic> first identifies the latent topics—that is, the topic-words distributions corresponding to each latent topic—based on the words that frequently co-occur across multiple documents; <italic>n.b</italic>., it just uses the documents themselves, but not the labels. For example, it might find that many documents with the word “ball” also included “opponent” and “score”; and vice versa. Similarly, “finances”, “transaction”, and “bank” often co-occur, as do “saint”, “belief” and “pray”. Speaking loosely, the topic-model-learner might then form one topic, <inline-formula id="pone.0224446.e004"><alternatives><graphic xlink:href="pone.0224446.e004.jpg" id="pone.0224446.e004g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M4"><mml:msup><mml:mover accent="true"><mml:mi>β</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msup></mml:math></alternatives></inline-formula>, that gives high probabilities to the first set of words (and relatively low probabilities to the remaining words)—perhaps
<disp-formula id="pone.0224446.e005"><alternatives><graphic xlink:href="pone.0224446.e005.jpg" id="pone.0224446.e005g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M5"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mtable><mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mrow/></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mspace width="4pt"/><mml:mtext>ball</mml:mtext><mml:mspace width="4pt"/><mml:mo>|</mml:mo><mml:mspace width="4pt"/><mml:msup><mml:mover accent="true"><mml:mi>β</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msup><mml:mspace width="4pt"/><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd><mml:mtd><mml:mo>=</mml:mo></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mn>0</mml:mn><mml:mo>.</mml:mo><mml:mn>05</mml:mn></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mrow/></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mspace width="4pt"/><mml:mtext>opponent</mml:mtext><mml:mspace width="4pt"/><mml:mo>|</mml:mo><mml:mspace width="4pt"/><mml:msup><mml:mover accent="true"><mml:mi>β</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msup><mml:mspace width="4pt"/><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd><mml:mtd><mml:mo>=</mml:mo></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mn>0</mml:mn><mml:mo>.</mml:mo><mml:mn>03</mml:mn></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mrow/></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mspace width="4pt"/><mml:mtext>score</mml:mtext><mml:mspace width="4pt"/><mml:mo>|</mml:mo><mml:mspace width="4pt"/><mml:msup><mml:mover accent="true"><mml:mi>β</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msup><mml:mspace width="4pt"/><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd><mml:mtd><mml:mo>=</mml:mo></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mn>0</mml:mn><mml:mo>.</mml:mo><mml:mn>01</mml:mn></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mrow/></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mspace width="4pt"/><mml:mi>x</mml:mi><mml:mspace width="4pt"/><mml:mo>|</mml:mo><mml:mspace width="4pt"/><mml:msup><mml:mover accent="true"><mml:mi>β</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msup><mml:mspace width="4pt"/><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd><mml:mtd><mml:mo>&lt;</mml:mo></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mtext>1E-4</mml:mtext><mml:mspace width="4.pt"/><mml:mspace width="1.em"/><mml:mtext>for</mml:mtext><mml:mspace width="4.pt"/><mml:mtext>all</mml:mtext><mml:mspace width="4.pt"/><mml:mtext>other</mml:mtext><mml:mspace width="4.pt"/><mml:mtext>words</mml:mtext><mml:mspace width="4.pt"/><mml:mi>x</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
(Technically, each topic is specified as a Dirichlet distribution over the set of words, <italic>β</italic><sup><italic>i</italic></sup>. To simplify the presentation, here we are showing their expected values, these <inline-formula id="pone.0224446.e006"><alternatives><graphic xlink:href="pone.0224446.e006.jpg" id="pone.0224446.e006g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M6"><mml:mrow><mml:msup><mml:mover accent="true"><mml:mi>β</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msup><mml:mo>=</mml:mo><mml:mi>E</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:msup><mml:mi>β</mml:mi><mml:mi>i</mml:mi></mml:msup><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> values are based on the priors; see Appendix A.2(3).)</p>
      <p>This <inline-formula id="pone.0224446.e007"><alternatives><graphic xlink:href="pone.0224446.e007.jpg" id="pone.0224446.e007g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M7"><mml:msup><mml:mover accent="true"><mml:mi>β</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msup></mml:math></alternatives></inline-formula> corresponds to an <italic>n</italic>-tuple over the <italic>n</italic> words; we call this <inline-formula id="pone.0224446.e008"><alternatives><graphic xlink:href="pone.0224446.e008.jpg" id="pone.0224446.e008g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M8"><mml:mrow><mml:msup><mml:mover accent="true"><mml:mi>β</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msup><mml:mo>≈</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mrow/></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mspace width="4pt"/><mml:msub><mml:mi>w</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mspace width="4pt"/><mml:mo>|</mml:mo><mml:mspace width="4pt"/><mml:msup><mml:mover accent="true"><mml:mi>β</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msup><mml:mspace width="4pt"/><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mspace width="4pt"/><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mspace width="4pt"/><mml:msub><mml:mi>P</mml:mi><mml:mrow/></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mspace width="4pt"/><mml:msub><mml:mi>w</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mspace width="4pt"/><mml:mo>|</mml:mo><mml:mspace width="4pt"/><mml:msup><mml:mover accent="true"><mml:mi>β</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msup><mml:mspace width="4pt"/><mml:mo>)</mml:mo></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>. It would similarly identify a second topic <inline-formula id="pone.0224446.e009"><alternatives><graphic xlink:href="pone.0224446.e009.jpg" id="pone.0224446.e009g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M9"><mml:msup><mml:mover accent="true"><mml:mi>β</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msup></mml:math></alternatives></inline-formula> with the <italic>n</italic>-tuple <inline-formula id="pone.0224446.e010"><alternatives><graphic xlink:href="pone.0224446.e010.jpg" id="pone.0224446.e010g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M10"><mml:mrow><mml:msup><mml:mover accent="true"><mml:mi>β</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msup><mml:mo>≈</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mrow/></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mspace width="4pt"/><mml:msub><mml:mi>w</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mspace width="4pt"/><mml:mo>|</mml:mo><mml:mspace width="4pt"/><mml:msup><mml:mover accent="true"><mml:mi>β</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msup><mml:mspace width="4pt"/><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mspace width="4pt"/><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mspace width="4pt"/><mml:msub><mml:mi>P</mml:mi><mml:mrow/></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mspace width="4pt"/><mml:msub><mml:mi>w</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mspace width="4pt"/><mml:mo>|</mml:mo><mml:mspace width="4pt"/><mml:msup><mml:mover accent="true"><mml:mi>β</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msup><mml:mspace width="4pt"/><mml:mo>)</mml:mo></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> that gives high probabilities to the different set of words, etc. (While we might view the first topic as related to sports, the second related to finances, and third to religion, that is simply our interpretation, and is not needed by the learning algorithm. Other topics might not be so obvious to interpret.) This produces the <italic>topic-words distribution</italic>
<inline-formula id="pone.0224446.e011"><alternatives><graphic xlink:href="pone.0224446.e011.jpg" id="pone.0224446.e011g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M11"><mml:mrow><mml:mi mathvariant="script">B</mml:mi><mml:mspace width="4pt"/><mml:mo>=</mml:mo><mml:mspace width="4pt"/><mml:msub><mml:mrow><mml:mo>{</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>β</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msup><mml:mo>}</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>‥</mml:mo><mml:mi>K</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> over <italic>K</italic> topics.</p>
      <p>The learner would then map each document into a “distribution” over this set of <italic>K</italic> topics—perhaps document <italic>f</italic><sub>1</sub> would be decomposed as Θ(<italic>f</italic><sub>1</sub>) = [<italic>θ</italic><sub>1</sub>(<italic>f</italic><sub>1</sub>), <italic>θ</italic><sub>2</sub>(<italic>f</italic><sub>1</sub>) …, <italic>θ</italic><sub><italic>K</italic></sub>(<italic>f</italic><sub>1</sub>)] = [0.01, 13.02, 50.01 …, 0.03]—these are parameters for a Dirichlet distribution, which are non-negative, but do not add up to 1. These are different for different documents—<italic>e.g</italic>., perhaps <italic>f</italic><sub>2</sub> is expressed as Θ(<italic>f</italic><sub>2</sub>) = [12.03, 0.001, 3.1, …, 2.4], etc. This is the <italic>document-topic distribution</italic> {Θ(<italic>f</italic><sub><italic>j</italic></sub>)}<sub><italic>j</italic>=1‥<italic>m</italic></sub> over the <italic>m</italic> documents.</p>
      <p>The specific learning process depends on the distributional form of the document-topics and topic-words distributions (here, we use Dirichlet for both) and also the number of latent topics, <italic>K</italic>. Given this, the LDA learning process finds the inherent structure present in the data—<italic>i.e</italic>., a model (topic-words distributions for each of the <italic>K</italic> topics <inline-formula id="pone.0224446.e012"><alternatives><graphic xlink:href="pone.0224446.e012.jpg" id="pone.0224446.e012g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M12"><mml:msub><mml:mrow><mml:mo>{</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>β</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msup><mml:mo>}</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>‥</mml:mo><mml:mi>K</mml:mi></mml:mrow></mml:msub></mml:math></alternatives></inline-formula>) that maximizes the likelihood of the training data.</p>
      <p>The same way certain sets of words often co-occur in a document, similarly sets of genes are known to be co-regulated: under some condition (corresponding to a “c_topic”), every gene in that set will have some additional regulation—some will be over-expressed, each by its own amount, and the others will be under-expressed. Moreover, just as a natural language (NL) topic typically involves relatively few words, most c_topics effectively involve relatively few genes. Also, just like a document may involve a mixture of many topics, each to its own degree, so a patient’s cancer often involves multiple c_topics; see work on cancer subclones [<xref rid="pone.0224446.ref018" ref-type="bibr">18</xref>]. This has motivated many researchers to use some version of topic modeling to model gene expression values, under various (sets of) conditions.</p>
      <p>For example, Rogers <italic>et al</italic>. [<xref rid="pone.0224446.ref019" ref-type="bibr">19</xref>] proposed Latent Process Decomposition (LPD), a probabilistic graphical model that was inspired by LDA, for microarray data, and presented clustering of genes that led to results comparable to those produced by hierarchical clustering. (Their results are descriptive; they do not use the results in any downstream evaluation). Later Masada <italic>et al</italic>. [<xref rid="pone.0224446.ref020" ref-type="bibr">20</xref>] proposed improvements to the original LPD approach and showed similar results. Bicego <italic>et al</italic>. [<xref rid="pone.0224446.ref021" ref-type="bibr">21</xref>] report topic modeling approaches (including LPD) were useful in classification tasks with gene expression data. They applied several topic models as dimensionality reduction tools to 10 different gene expression data sets, and found that the features from the topic models led to better predictors.</p>
      <p>Further, Lin <italic>et al</italic>. [<xref rid="pone.0224446.ref022" ref-type="bibr">22</xref>] reviewed various different topic models applied to gene expression data, including LDA and probabilistic latent semantic analysis (PLSA) [<xref rid="pone.0224446.ref023" ref-type="bibr">23</xref>], as well as the topic model approaches described above, for gene classification and clustering. They note that the topic model approaches improve over other models as one can easily interpret the topic-words distributions and the mixed membership nature of the document-topic distribution.</p>
      <p>However, none of these tasks were survival analysis. They used shifting and scaling to convert the continuous gene expression values to discrete values; we considered this approach for our data, but found that it was not able to learn distinct topics for our data. Moreover, this gave all patients very similar document-topic distributions. Dawson <italic>et al</italic>. [<xref rid="pone.0224446.ref024" ref-type="bibr">24</xref>] proposed a survival supervised LDA model, called survLDA, as an extension of supervised LDA [<xref rid="pone.0224446.ref025" ref-type="bibr">25</xref>]. survLDA uses a Cox model [<xref rid="pone.0224446.ref026" ref-type="bibr">26</xref>] to model the response variable (survival time) instead of the generalized linear model [<xref rid="pone.0224446.ref027" ref-type="bibr">27</xref>] used in supervised LDA [<xref rid="pone.0224446.ref025" ref-type="bibr">25</xref>]. But Dawson <italic>et al</italic>. [<xref rid="pone.0224446.ref024" ref-type="bibr">24</xref>] reported that the topics learned from survLDA were very similar to the ones learned from the general (unsupervised) LDA model.</p>
      <p>Here, we apply the “standard” topic-modeling approach to gene expression data, for the survival prediction task. While previous systems applied topic modeling techniques to gene expression data, very few have applied topic models to predict a patient’s survival times (and none to our knowledge have used mRNAseq expression data). Our work presents a more direct analogue to the NL topic modeling that can be applied to our cohort of patients with gene expression data, where each patient corresponds to a document and the genes/probes in the expression data correspond to the words that form the document. This requires making some significant modifications to the standard LDA model, which assumes the observations are frequencies of words, which are non-negative integers that generally follows a monotonically decreasing distribution. By contrast, gene expression values are arbitrary real values, believed to follow a skewed Gaussian distribution [<xref rid="pone.0224446.ref028" ref-type="bibr">28</xref>]; see also <xref ref-type="fig" rid="pone.0224446.g004">Fig 4</xref>. (This is also true for mRNAseq, as we need to normalize the expression counts to be comparable, from patient to patient).</p>
      <fig id="pone.0224446.g004" orientation="portrait" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pone.0224446.g004</object-id>
        <label>Fig 4</label>
        <caption>
          <title>Histogram of the normalized Gene Expression values <inline-formula id="pone.0224446.e013"><alternatives><graphic id="pone.0224446.e013g" xlink:href="pone.0224446.e013"/><mml:math id="M13"><mml:mrow><mml:mo>{</mml:mo><mml:msubsup><mml:mi>x</mml:mi><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:msubsup><mml:mo>}</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>, from METABRIC, showing how we descretized them into essentially equal-width bins.</title>
          <p>Note the heights are on a log-scale. The material under the histogram—involving <bold>x</bold> and <bold>y</bold>—compare two ways to compute the discretized Gene Expression Values (dGEV): The top Enc_A discretizes the GEVs into a single count-feature A(⋅), and the bottom Enc_B discretizes the GEVs into two count-features B(⋅) representing over-expression and under-expression, respectively.</p>
        </caption>
        <graphic xlink:href="pone.0224446.g004"/>
      </fig>
      <p>We follow the approach of explicitly discretizing the expression values in a preprocessing step, so the resulting values basically, approximate a Zipf distribution. There are still some subtleties here—<italic>e.g</italic>., while the NL situation involves only non-negative integers, an affected gene can be either over-expressed, or under-expressed—<italic>i.e</italic>., we need to deal with two directions of “deviation”, while NL’s LDA just deals with one direction; see Section 4.1.1. We refer to our model as <italic>dLDA</italic> and the discretized gene expression values as <italic>dGEVs</italic>. The same way the standard LDA approach reduces the description of a document from a ≈ 10<sup>5</sup>-dimensional vector (corresponding to the words used in that document) to a few dozen values (the “distribution” of the topics), this dLDA approach reduces the ≈ 50<italic>K</italic>-dimensional gene expression tuple to a few dozen values—here the “distribution” of the c_topics. <xref ref-type="fig" rid="pone.0224446.g005">Fig 5</xref> summarizes this process: using the subroutines defined in Section 4 below, at learning time, C<sc>ompute</sc>B<sc>asis</sc><sub>[<italic>ρ</italic>=dLDA]</sub> first identifies the set of relevant c_topics <inline-formula id="pone.0224446.e014"><alternatives><graphic xlink:href="pone.0224446.e014.jpg" id="pone.0224446.e014g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M14"><mml:msub><mml:mover accent="true"><mml:mi>β</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mrow><mml:mi>G</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msub></mml:math></alternatives></inline-formula> from the set of gene expression values <inline-formula id="pone.0224446.e015"><alternatives><graphic xlink:href="pone.0224446.e015.jpg" id="pone.0224446.e015g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M15"><mml:msubsup><mml:mi>X</mml:mi><mml:mrow><mml:mi>G</mml:mi><mml:mi>E</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup></mml:math></alternatives></inline-formula>, then later (at performance time), U<sc>se</sc>B<sc>asis</sc><sub>[<italic>ρ</italic>=dLDA]</sub> uses those learned c_topics to transform a new patient’s high-dimensional gene expression profile <inline-formula id="pone.0224446.e016"><alternatives><graphic xlink:href="pone.0224446.e016.jpg" id="pone.0224446.e016g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M16"><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>G</mml:mi><mml:mi>E</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup></mml:math></alternatives></inline-formula> to a low-dimensional c_topic-profile, <italic>x</italic>”<sub><italic>GE</italic></sub>—here going from 50K values to 30.</p>
      <fig id="pone.0224446.g005" orientation="portrait" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pone.0224446.g005</object-id>
        <label>Fig 5</label>
        <caption>
          <title>The C<sc>ompute</sc>B<sc>asis</sc><sub>[<italic>ρ</italic>=dLDA]</sub> process (shown top-to-bottom, on left) uses a set of high-dimensional gene expression vectors <inline-formula id="pone.0224446.e017"><alternatives><graphic id="pone.0224446.e017g" xlink:href="pone.0224446.e017"/><mml:math id="M17"><mml:msubsup><mml:mi>X</mml:mi><mml:mrow><mml:mi>G</mml:mi><mml:mi>E</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup></mml:math></alternatives></inline-formula> from many patients, to produce a set of basis vectors (corresponding the parameters of the LDA) <inline-formula id="pone.0224446.e018"><alternatives><graphic id="pone.0224446.e018g" xlink:href="pone.0224446.e018"/><mml:math id="M18"><mml:msub><mml:mover accent="true"><mml:mi>β</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mrow><mml:mi>G</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msub></mml:math></alternatives></inline-formula>.</title>
          <p>The U<sc>se</sc>B<sc>asis</sc><sub>[<italic>ρ</italic>=dLDA]</sub> process (shown left-to-right horizontally) uses the set of dLDA “basis vectors” <inline-formula id="pone.0224446.e019"><alternatives><graphic id="pone.0224446.e019g" xlink:href="pone.0224446.e019"/><mml:math id="M19"><mml:msub><mml:mover accent="true"><mml:mi>β</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mrow><mml:mi>G</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msub></mml:math></alternatives></inline-formula> to transform a gene expression vector <inline-formula id="pone.0224446.e020"><alternatives><graphic id="pone.0224446.e020g" xlink:href="pone.0224446.e020"/><mml:math id="M20"><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>G</mml:mi><mml:mi>E</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup></mml:math></alternatives></inline-formula> from a novel patient, into a low-dimensional description <inline-formula id="pone.0224446.e021"><alternatives><graphic id="pone.0224446.e021g" xlink:href="pone.0224446.e021"/><mml:math id="M21"><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>G</mml:mi><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mo>″</mml:mo></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>. (Note C<sc>ompute</sc>B<sc>asis</sc><sub>[<italic>ρ</italic>=dLDA]</sub> also uses other information, <inline-formula id="pone.0224446.e022"><alternatives><graphic id="pone.0224446.e022g" xlink:href="pone.0224446.e022"/><mml:math id="M22"><mml:msubsup><mml:mi>X</mml:mi><mml:mrow><mml:mi>C</mml:mi><mml:mi>F</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup></mml:math></alternatives></inline-formula> and <italic>Lbl</italic>, to determine the number <italic>K</italic> of basis vectors; to simplify the figure, we did not show this.).</p>
        </caption>
        <graphic xlink:href="pone.0224446.g005"/>
      </fig>
      <p>Section 5 presents empirical evidence that this method works effectively for our survival prediction task; Appendix C.1 shows that it performs better than the LPD technique.</p>
    </sec>
  </sec>
  <sec id="sec006">
    <title>3 Datasets used</title>
    <p>We apply our methods to two large gene expression datasets: the METABRIC breast cancer cohort [<xref rid="pone.0224446.ref007" ref-type="bibr">7</xref>] (mircroarray) and the Pan-kidney cohort KIPAN (mRNAseq) [<xref rid="pone.0224446.ref029" ref-type="bibr">29</xref>, <xref rid="pone.0224446.ref030" ref-type="bibr">30</xref>]. We initially focus on the METABRIC dataset [<xref rid="pone.0224446.ref040" ref-type="bibr">40</xref>] which is one of the largest available survival studies that includes genomic information. In 2012, the Breast Cancer Prognostic Challenge (BCC) organizers released the METABRIC (Molecular Taxonomy of Breast Cancer International Consortium) dataset for training [<xref rid="pone.0224446.ref007" ref-type="bibr">7</xref>]. While they subsequently released a second dataset (OSLO) for final testing [<xref rid="pone.0224446.ref007" ref-type="bibr">7</xref>], we are not using it for several reasons: (1) METABRIC provided disease-specific survival (DS), which considers only <italic>breast cancer death</italic> (BC-based death), rather than all causes of death [<xref rid="pone.0224446.ref013" ref-type="bibr">13</xref>]. By contrast, OSLO provides “overall survival”, which does not distinguish BC-based deaths from others. As DS is clearly better for our purpose, it is better to evaluate on the METABRIC dataset. (2a) OSLO and METABRIC contained different sets of probes—and in particular, OSLO contains only ∼ 80% of the METABRIC probes. (2b) Similarly, the OSLO dataset is also missing some of the clinical covariates that are present in the METABRIC dataset—<italic>e.g</italic>., menopausal status, group, stage, lymph nodes removed, etc.; see [<xref rid="pone.0224446.ref003" ref-type="bibr">3</xref>, Table 1]. This means a “METABRIC-OSLO study” would need to exclude some METABRIC features and some METABRIC probes.</p>
    <p>We then used a second independent dataset, to verify the effectiveness of our “dLDA+MTLR” approach. Here, we did not use OSLO, as we wanted to explore a different type of cancer, and also use a different platform, to show that our system could still identify an appropriate (and necessarily different) set of cancer-topics (c_topics). We therefore used the KIPAN dataset from TCGA (The Cancer Genome Atlas), as it (also) contains a large number of patients and provides survival information.</p>
    <p><xref rid="pone.0224446.t001" ref-type="table">Table 1</xref> lists some of the important characteristics of these datasets. Note that KIPAN contains 15,529 genes, while METABRIC has 49,576 probes. This is because many METABRIC probes may correspond to the same gene each targeting a different DNA segment of the gene. As different probes for the same gene might behave differently, we gave our learning algorithm the complete set of probes. Our results on the KIPAN dataset show that our approach also works when dealing with gene expression data from a totally different cancer and platform (here kidney not breast, and mRNAseq rather than Microarray)—demonstrating the generality of our approach.</p>
    <sec id="sec007">
      <title>3.1 Training vs test data</title>
      <p>We apply the same experimental procedure to both datasets (METABRIC and KIPAN): We partition each dataset into two subsets, and use 80% of the data for training and the remaining 20% for testing. Both partitions contain instances with comparable ranges of survival times and comparable censored-versus-uncensored ratio. When necessary, we ran internal cross-validation, within the training set, to find good settings for parameters, etc.</p>
    </sec>
  </sec>
  <sec id="sec008">
    <title>4 Overview of learning and performance processes</title>
    <p>As typical for Supervised Machine Learning systems, we need to define two processes:</p>
    <list list-type="bullet">
      <list-item>
        <p>The learning algorithm, LearnSurvivalModel</p>
        <p>LSM<sub>[<italic>ρ</italic>=dLDA; Ψ=MTLR]</sub>([<italic>X</italic><sub><italic>GE</italic></sub>, <italic>X</italic><sub><italic>CF</italic></sub>], <italic>Lbl</italic>) takes a labeled dataset, involving both gene expression data <italic>X</italic><sub><italic>GE</italic></sub> and clinical features <italic>X</italic><sub><italic>CF</italic></sub> (and survival-labels <italic>Lbl</italic>) for many patients, and computes a Ψ = MTLR survival model <italic>W</italic>. (Many subroutines are parameterized by a dimensionality reduction technique <italic>ρ</italic> ∈ {dLDA, PCA}, and/or by a survival learning algorithm Ψ ∈ {MTLR, Cox, RCox}. We use notation “A<sc>lg</sc><sub>[<italic>ρ</italic>; Ψ]</sub>(⋅)” to identify the specific parameters; hence LSM<sub>[<italic>ρ</italic>=dLDA; Ψ=MTLR]</sub>([<italic>X</italic><sub><italic>GE</italic></sub>, <italic>X</italic><sub><italic>CF</italic></sub>], <italic>Lbl</italic>) is dealing with the <italic>ρ</italic> = dLDA encoding and Ψ = MTLR survival learning algorithm).</p>
        <p>It also returns the <italic>ρ</italic> = dLDA “basis set” <inline-formula id="pone.0224446.e023"><alternatives><graphic xlink:href="pone.0224446.e023.jpg" id="pone.0224446.e023g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M23"><mml:msub><mml:mover accent="true"><mml:mi>β</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mrow><mml:mi>G</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msub></mml:math></alternatives></inline-formula> (here, think of a set of c_topic distributions), and some information about the pre-processing performed, Ω. See <xref ref-type="fig" rid="pone.0224446.g003">Fig 3</xref>.</p>
      </list-item>
      <list-item>
        <p>The performance algorithm, UseSurvivalModel</p>
        <p>USM<sub>[<italic>ρ</italic>=dLDA; Ψ=MTLR]</sub>([<italic>x</italic><sub><italic>GE</italic></sub>, <italic>x</italic><sub><italic>CF</italic></sub>], <inline-formula id="pone.0224446.e024"><alternatives><graphic xlink:href="pone.0224446.e024.jpg" id="pone.0224446.e024g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M24"><mml:msub><mml:mover accent="true"><mml:mi>β</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mrow><mml:mi>G</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msub></mml:math></alternatives></inline-formula>, <italic>W</italic>, Ω), takes a description of an individual (both gene expression <italic>x</italic><sub><italic>GE</italic></sub>, and clinical features <italic>x</italic><sub><italic>CF</italic></sub>), as well as the <italic>ρ</italic> = dLDA basis set <inline-formula id="pone.0224446.e025"><alternatives><graphic xlink:href="pone.0224446.e025.jpg" id="pone.0224446.e025g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M25"><mml:msub><mml:mover accent="true"><mml:mi>β</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mrow><mml:mi>G</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msub></mml:math></alternatives></inline-formula> and the Ψ = MTLR survival model <italic>W</italic> (and pre-processing information Ω), and returns a specific survival prediction for this individual, from which we can compute that person’s risk score. See <xref ref-type="fig" rid="pone.0224446.g006">Fig 6</xref>.</p>
      </list-item>
    </list>
    <fig id="pone.0224446.g006" orientation="portrait" position="float">
      <object-id pub-id-type="doi">10.1371/journal.pone.0224446.g006</object-id>
      <label>Fig 6</label>
      <caption>
        <title>Overview of performance process, USM = <monospace>UseSurvivalModel</monospace>.</title>
        <p><italic>x</italic><sub><italic>GE</italic></sub> and <italic>x</italic><sub><italic>CF</italic></sub> are the gene expression values and clinical feature values, for a single patient; see also terms <italic>ρ</italic>, Ψ, Ω, <inline-formula id="pone.0224446.e026"><alternatives><graphic id="pone.0224446.e026g" xlink:href="pone.0224446.e026"/><mml:math id="M26"><mml:msub><mml:mover accent="true"><mml:mi>β</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mrow><mml:mi>G</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msub></mml:math></alternatives></inline-formula>, <italic>W</italic> from <xref ref-type="fig" rid="pone.0224446.g003">Fig 3</xref>.</p>
      </caption>
      <graphic xlink:href="pone.0224446.g006"/>
    </fig>
    <p>To simplify the presentation, the main text will describe the process at a high-level, skipping most of the details. Notice these functions are parameterized by the type of dimensionality reduction <italic>ρ</italic> and the survival learner Ψ. This section will especially focus on the novel aspects here, which are the <italic>ρ</italic> = dLDA transformation (Section 2.2), which complicates the C<sc>ompute</sc>B<sc>asis</sc><sub>[<italic>ρ</italic>=dLDA]</sub>(⋯) function (Section 4.1.1); and the Ψ = MTLR algorithm for learning the survival model (Section 2.1.1). Appendix A summarizes the more standard <italic>ρ</italic> = PCA approach to reducing the number of features, and the more standard survival models Ψ ∈ {Cox, RCox}, as well as other details about the learning, and performance models, in general.</p>
    <sec id="sec009">
      <title>4.1 Learning system LSM</title>
      <p>Here, <monospace>LSM</monospace><sub><monospace>[<italic>ρ</italic>=dLDA; Ψ=MTLR]</monospace></sub> ([<italic>X</italic><sub><italic>GE</italic></sub>, <italic>X</italic><sub><italic>CF</italic></sub>], <italic>Lbl</italic>) first calls P<sc>re</sc>P<sc>rocess</sc>, which fills-in the missing values in the <italic>X</italic><sub><italic>CF</italic></sub> clinical features (producing <inline-formula id="pone.0224446.e027"><alternatives><graphic xlink:href="pone.0224446.e027.jpg" id="pone.0224446.e027g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M27"><mml:msubsup><mml:mi>X</mml:mi><mml:mrow><mml:mi>C</mml:mi><mml:mi>F</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup></mml:math></alternatives></inline-formula>), and normalizes the real-valued <italic>X</italic><sub><italic>GE</italic></sub> genetic features, which is basically computing the z-scores <inline-formula id="pone.0224446.e028"><alternatives><graphic xlink:href="pone.0224446.e028.jpg" id="pone.0224446.e028g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M28"><mml:msubsup><mml:mi>X</mml:mi><mml:mrow><mml:mi>G</mml:mi><mml:mi>E</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup></mml:math></alternatives></inline-formula>, over <italic>all</italic> of the values. It then calls C<sc>ompute</sc>B<sc>asis</sc><sub>[<italic>ρ</italic>=dLDA]</sub>(⋯) to compute a set of c_topics <inline-formula id="pone.0224446.e029"><alternatives><graphic xlink:href="pone.0224446.e029.jpg" id="pone.0224446.e029g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M29"><mml:msub><mml:mover accent="true"><mml:mi>β</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mrow><mml:mi>G</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msub></mml:math></alternatives></inline-formula> from the gene expression data <inline-formula id="pone.0224446.e030"><alternatives><graphic xlink:href="pone.0224446.e030.jpg" id="pone.0224446.e030g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M30"><mml:msubsup><mml:mi>X</mml:mi><mml:mrow><mml:mi>G</mml:mi><mml:mi>E</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup></mml:math></alternatives></inline-formula> (as well as the other inputs), then calls U<sc>se</sc>B<sc>asis</sc>[<italic>ρ</italic> = dLDA](<inline-formula id="pone.0224446.e031"><alternatives><graphic xlink:href="pone.0224446.e031.jpg" id="pone.0224446.e031g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M31"><mml:mrow><mml:msubsup><mml:mi>X</mml:mi><mml:mrow><mml:mi>G</mml:mi><mml:mi>E</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup><mml:mo>,</mml:mo><mml:mspace width="4pt"/><mml:msub><mml:mover accent="true"><mml:mi>β</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mrow><mml:mi>G</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>), which “projects” <inline-formula id="pone.0224446.e032"><alternatives><graphic xlink:href="pone.0224446.e032.jpg" id="pone.0224446.e032g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M32"><mml:msubsup><mml:mi>X</mml:mi><mml:mrow><mml:mi>G</mml:mi><mml:mi>E</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup></mml:math></alternatives></inline-formula> onto this <inline-formula id="pone.0224446.e033"><alternatives><graphic xlink:href="pone.0224446.e033.jpg" id="pone.0224446.e033g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M33"><mml:msub><mml:mover accent="true"><mml:mi>β</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mrow><mml:mi>G</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msub></mml:math></alternatives></inline-formula> to find a low dimensional description of the genetic information; see <xref ref-type="fig" rid="pone.0224446.g005">Fig 5</xref>. These projected values, together with <inline-formula id="pone.0224446.e034"><alternatives><graphic xlink:href="pone.0224446.e034.jpg" id="pone.0224446.e034g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M34"><mml:msubsup><mml:mi>X</mml:mi><mml:mrow><mml:mi>C</mml:mi><mml:mi>F</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup></mml:math></alternatives></inline-formula> and <italic>Lbl</italic>, form the labeled training set given to the Ψ = MTLR learning system, which computes a survival model <italic>W</italic>. Here, the <monospace>LSM</monospace> process returns the dLDA “basis” <inline-formula id="pone.0224446.e035"><alternatives><graphic xlink:href="pone.0224446.e035.jpg" id="pone.0224446.e035g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M35"><mml:msub><mml:mover accent="true"><mml:mi>β</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mrow><mml:mi>G</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msub></mml:math></alternatives></inline-formula> and the MTLR-model <italic>W</italic>. (Further details appear in Appendix A.)</p>
      <sec id="sec010">
        <title>4.1.1 C<sc>ompute</sc>B<sc>asis</sc><sub>[<italic>ρ</italic>=dLDA]</sub>(⋯) function</title>
        <p>As noted above, the ≈50,000 expression values for each patient is so large that most standard learning algorithms would overfit. We consider two ways to reduce the dimensionality. One standard approach, Principal Component Analysis (PCA), is discussed in Appendix A.4. Here, we discuss a different approach, dLDA, that uses the Latent Dirichlet Analysis.</p>
        <p>The P<sc>re</sc>P<sc>rocess</sc> routine computes z-scores <inline-formula id="pone.0224446.e036"><alternatives><graphic xlink:href="pone.0224446.e036.jpg" id="pone.0224446.e036g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M36"><mml:msubsup><mml:mi>X</mml:mi><mml:mrow><mml:mi>G</mml:mi><mml:mi>E</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup></mml:math></alternatives></inline-formula> for the gene expression values <italic>X</italic><sub><italic>GE</italic></sub>; the C<sc>ompute</sc>B<sc>asis</sc><sub>[<italic>ρ</italic>=dLDA]</sub> subroutine then has to transform those real values to the non-negative integers required by LDA—moreover, it was designed to deal with word counts in documents where, in any given document, most words appear 0 times, then many fewer words appear once, then yet fewer words appear twice, etc. We therefore need a method for converting the real values into non-negative integers.</p>
        <p>This process therefore <italic>discretizes</italic> the standardized gene expression values (in <inline-formula id="pone.0224446.e037"><alternatives><graphic xlink:href="pone.0224446.e037.jpg" id="pone.0224446.e037g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M37"><mml:msubsup><mml:mi>X</mml:mi><mml:mrow><mml:mi>G</mml:mi><mml:mi>E</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup></mml:math></alternatives></inline-formula>) into the integers {-10, -9, …, -1, 0, 1, …, 9, 10}, by mapping each real number to the integer indexing some essentially equal-sized bins; see <xref ref-type="fig" rid="pone.0224446.g004">Fig 4</xref>, and Appendix A.2 for details.</p>
        <p>This does map each gene expression to an integer, but this includes both positive and negative values. Given that over-expression is different from under-expression, an obvious encoding uses two non-negative integer values for each gene: mapping +2 to [2, 0], and −3 to [0, 3], etc. Note that the range of each component of the encoding will be non-negative integers, and that most of the values will be 0, then fewer will be 1, etc.—as desired. However, this does double the dimensionality of representation; <italic>i.e</italic>., we now have twice the number of genes: UNDER-‘gene_name’ and OVER-‘gene_name’.</p>
        <p>(Below we call this the Enc_B encoding; see also <italic>B</italic>(⋅) at the bottom of <xref ref-type="fig" rid="pone.0224446.g004">Fig 4</xref>.) Given that very few values are &lt; −1 (in METABRIC, over 14% (normalized) expression values were &gt; 1, but less than less than 0.04% were &lt; −1; recall that heights in <xref ref-type="fig" rid="pone.0224446.g004">Fig 4</xref> are on a log scale), we considered another option: collapsing the +values and −values to a single value—so both +4 and −4 would be encoded as 4. This would mean only half as many features (which would reduce the chance of overfitting), and would continue to note when a gene had an exceptional value. (This is the Enc_A encoding, which corresponds to the <italic>A</italic>(⋅) at the bottom of <xref ref-type="fig" rid="pone.0224446.g004">Fig 4</xref>.) As it was not clear which approach would work better, our implementation explicitly considered both options—and used the training set to decide which worked best; see below.</p>
        <p>The standard LDA algorithm also needs to know the number of topics (here c_topics) <italic>K</italic> to produce. C<sc>ompute</sc>B<sc>asis</sc> uses (internal) cross-validation to find the best value for <italic>K</italic>, over the range <italic>K</italic> ∈ {5, 10, 15, …, 150}, as well as encoding technique <italic>t</italic> ∈ {Enc_A, Enc_B}—seeking the setting leading to the Cox model with the best concordance (on each held-out portion). See Appendix A.2 for details. After finding the best <italic>K</italic>* and encoding <italic>t</italic>*, C<sc>ompute</sc>B<sc>asis</sc> then finds the <italic>K</italic>* c_topics on the <italic>t</italic>*-encoded (preprocessed) training gene expression data <inline-formula id="pone.0224446.e038"><alternatives><graphic xlink:href="pone.0224446.e038.jpg" id="pone.0224446.e038g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M38"><mml:msubsup><mml:mi>X</mml:mi><mml:mrow><mml:mi>G</mml:mi><mml:mi>E</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup></mml:math></alternatives></inline-formula>; this is the c_topic distribution, <inline-formula id="pone.0224446.e039"><alternatives><graphic xlink:href="pone.0224446.e039.jpg" id="pone.0224446.e039g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M39"><mml:msub><mml:mover accent="true"><mml:mi>β</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mrow><mml:mi>G</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msub></mml:math></alternatives></inline-formula>.</p>
        <p>The vertical left-side of <xref ref-type="fig" rid="pone.0224446.g005">Fig 5</xref> gives a high-level description of the C<sc>ompute</sc>B<sc>asis</sc><sub>[<italic>ρ</italic>=dLDA]</sub> process: given a large set of (preprocessed) high-dimensional gene expression profiles, produce a small set of c_topics (each corresponding to a mapping from the gene expression profiles). We will later describe the U<sc>se</sc>B<sc>asis</sc><sub>[<italic>ρ</italic>=dLDA]</sub> process that uses those c_topics to transform the high-dimensional gene expression profile of a novel instance, into a small dimensional set of values—see the left-to-right “Performance Process” part here. At this abstract level, it is easy to see that it nicely matches the <italic>ρ</italic> = PCA process, where C<sc>ompute</sc>B<sc>asis</sc><sub>[<italic>ρ</italic>=PCA]</sub> would find the top principle components of the <inline-formula id="pone.0224446.e040"><alternatives><graphic xlink:href="pone.0224446.e040.jpg" id="pone.0224446.e040g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M40"><mml:msubsup><mml:mi>X</mml:mi><mml:mrow><mml:mi>G</mml:mi><mml:mi>E</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup></mml:math></alternatives></inline-formula> datasets (here, the <inline-formula id="pone.0224446.e041"><alternatives><graphic xlink:href="pone.0224446.e041.jpg" id="pone.0224446.e041g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M41"><mml:msub><mml:mover accent="true"><mml:mi>β</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mrow><mml:mi>G</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msub></mml:math></alternatives></inline-formula> box would be those components), which U<sc>se</sc>B<sc>asis</sc><sub>[<italic>ρ</italic>=PCA]</sub> could then use to transform a new gene expression profile into that low-dimensional “PC-space”.</p>
      </sec>
    </sec>
    <sec id="sec011">
      <title>4.2 Performance system, <monospace>USM</monospace></title>
      <p>As shown in <xref ref-type="fig" rid="pone.0224446.g006">Fig 6</xref>, the USM<sub>[<italic>ρ</italic>=dLDA;Ψ=MTLR]</sub>([<italic>x</italic><sub><italic>GE</italic></sub>, <italic>x</italic><sub><italic>CF</italic></sub>], <inline-formula id="pone.0224446.e042"><alternatives><graphic xlink:href="pone.0224446.e042.jpg" id="pone.0224446.e042g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M42"><mml:msub><mml:mover accent="true"><mml:mi>β</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mrow><mml:mi>G</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msub></mml:math></alternatives></inline-formula>
<italic>W</italic>, Ω) system applies the learned Ψ = MTLR model <italic>W</italic>, to a P<sc>re</sc>P<sc>rocess</sc>’ed description of a novel patient, <inline-formula id="pone.0224446.e043"><alternatives><graphic xlink:href="pone.0224446.e043.jpg" id="pone.0224446.e043g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M43"><mml:mrow><mml:mo>[</mml:mo><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>G</mml:mi><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mo>″</mml:mo></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>C</mml:mi><mml:mi>F</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup><mml:mo>]</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>, whose gene expression values <inline-formula id="pone.0224446.e044"><alternatives><graphic xlink:href="pone.0224446.e044.jpg" id="pone.0224446.e044g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M44"><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>G</mml:mi><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mo>″</mml:mo></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> have been “projected” into the relevant basis <inline-formula id="pone.0224446.e045"><alternatives><graphic xlink:href="pone.0224446.e045.jpg" id="pone.0224446.e045g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M45"><mml:msub><mml:mover accent="true"><mml:mi>β</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mrow><mml:mi>G</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msub></mml:math></alternatives></inline-formula> by U<sc>se</sc>B<sc>asis</sc><sub>[<italic>ρ</italic>=dLDA]</sub>. This produces a survival curve, which it then uses to produce that patient’s predicted risk score: the negative of the expected time for this distribution, which corresponds to the area under its survival curve.</p>
      <p>Each of the various subroutines are described in an appendix: P<sc>re</sc>P<sc>rocess</sc>’, U<sc>se</sc>B<sc>asis</sc><sub>[<italic>ρ</italic>=dLDA]</sub> and U<sc>se</sc>B<sc>asis</sc><sub>[<italic>ρ</italic>=PCA]</sub> are described in Appendices A.1, A.3 and A.4, respectively. The U<sc>se</sc>M<sc>odel</sc><sub>[Ψ=Cox]</sub> and U<sc>se</sc>M<sc>odel</sc><sub>[Ψ=RCox]</sub> produce standard risk scores for each patient, obtained by applying the learned Cox (resp., RCox) model to the patient’s clinical and gene expression features; see Appendix A.5.</p>
    </sec>
  </sec>
  <sec id="sec012">
    <title>5 Experimental results</title>
    <p>As noted above, we intentionally designed our learning and performance systems (Figs <xref ref-type="fig" rid="pone.0224446.g003">3</xref> and <xref ref-type="fig" rid="pone.0224446.g006">6</xref>) to be very general—to allow two types of basis <italic>ρ</italic> ∈ {dLDA, PCA} and three different survival prediction algorithms Ψ ∈ {MTLR, Cox, RCox}. This allows us to explore 2 × 3 frameworks, on the two different datasets (METABRIC and KIPAN). For each, the learner uses internal internal cross-validation to find the optimal parameters. Below we report the results of each optimized model on the held-out set, focusing on the Concordance Index (CI)—a discriminator measure. We also discuss a <italic>calibration</italic> measure of these results; see Appendix B.2.</p>
    <p>We also present our experimental results from the BCC Dream Challenge winner’s model [<xref rid="pone.0224446.ref013" ref-type="bibr">13</xref>]. As discussed in Section 4.1.1, C<sc>ompute</sc>B<sc>asis</sc><sub>[<italic>ρ</italic>=dLDA]</sub> ran internal cross-validation on the training set to determine the appropriate encoding <italic>t</italic>* ∈ {Enc_A, Enc_B} and the optimal number of c_topics for the dLDA model <italic>K</italic>* from a large potential values (see Algorithm 1 in Appendix A.2). Our experiments found that the discretization <italic>t</italic>* = Enc_B, along with <italic>K</italic>* = 30 c_topics, produced the best dLDA algorithm for survival prediction in METABRIC; after fixing the encoding scheme as Enc_B, we used the same technique on the KIPAN dataset and found <italic>K</italic> = 50 c_topics to be the best. We used the C implementation from Blei <italic>et al</italic>. [<xref rid="pone.0224446.ref017" ref-type="bibr">17</xref>, <xref rid="pone.0224446.ref041" ref-type="bibr">41</xref>] to compute the c_topics. On a single 2.66GHz processor with on 16Gb memory, a single fold takes around ∼20–30 hours (more time for larger <italic>K</italic>). We, of course, parallelized each CV fold.</p>
    <p>We experimented with different combinations of the features from three groups: (1) clinical features, (2) SuperPC+ principle components (<italic>ρ</italic> = PCA), and/or (3) the dLDA c_topic (<italic>ρ</italic> = dLDA); and with three different survival prediction algorithms Ψ ∈ {Cox, Cox, MTLR}. Our goal in these experiments is to empirically evaluate the performance of the survival models that use various types of features. Given this goal, we evaluate the performance using different GE basis methods (<italic>ρ</italic>) by comparing their performance to a baseline model that only uses the clinical features with Cox [<xref rid="pone.0224446.ref026" ref-type="bibr">26</xref>]. The other combinations include clinical features as well as various different GE features; each is trained using each of the three aforementioned survival prediction algorithms (Ψ).</p>
    <p>As an additional feature selection step, we removed the covariate “Site” from the METABRIC clinical covariates, based on our experimental results (on the training data) that shows its inclusion led to worse concordance. We experimented with a large, but selective, set of model combinations, to answer our major queries:</p>
    <list list-type="simple">
      <list-item>
        <label>(i)</label>
        <p>does adding GE features improve survival prediction?</p>
      </list-item>
      <list-item>
        <label>(ii)</label>
        <p>which is the best feature combination for survival prediction?</p>
      </list-item>
      <list-item>
        <label>(iii)</label>
        <p>which is better representation of the GE features: dLDA or SuperPC+?</p>
      </list-item>
      <list-item>
        <label>(iv)</label>
        <p>are we deriving GE features that are redundant with PAM50?</p>
      </list-item>
    </list>
    <p>Our results appear in <xref rid="pone.0224446.t002" ref-type="table">Table 2</xref>, shown visually in <xref ref-type="fig" rid="pone.0224446.g007">Fig 7</xref>(left). Note the baseline is “A-Cox”, where the ‘A’ refers to the feature set used, which here is the far left triplet of blocks in <xref ref-type="fig" rid="pone.0224446.g007">Fig 7</xref>(left), and the ‘Cox’ refers to the learning algorithm, which appears left-most in each triplet. These results lead us to claim:</p>
    <list list-type="simple">
      <list-item>
        <label>(i)</label>
        <p>Comparing the baseline, A-Cox, to the other models, we immediately see that adding GE features (using any of the dimensionality reduction technique) leads to better predictive models;—<italic>i.e</italic>., all of the results are better than A-Cox’s CI of 0.6810 (the left-most light-shaded bar in <xref ref-type="fig" rid="pone.0224446.g007">Fig 7</xref>(left)).</p>
      </list-item>
      <list-item>
        <label>(ii)</label>
        <p>The best model for METABRIC is the one that includes all of the types of features derived from the gene expression—here E-MTLR, which is the right-most bar of <xref ref-type="fig" rid="pone.0224446.g007">Fig 7</xref>(left).</p>
        <p>We also performed student’s t-tests on random bootstrap samples from the test data to validate the significance of our results. When we compare this best model, E-MTLR, against models B-RCox (which is the best model using only PCA GE features) and C-MTLR (the best model using only dLDA GE features), we find statistically significant difference between them (respective pairwise p-value: 4.8e-16, 1e-3), showing that the E-MTLR model is significantly better than its closest counterparts.</p>
      </list-item>
      <list-item>
        <label>(iii)</label>
        <p>These empirical results show that, if you are pick only a single GE feature set, the dLDA c_topics perform better than the principle components—that is, the C-<italic>χ</italic> has a higher score than B-<italic>χ</italic>, for <italic>χ</italic> ∈ {Cox, RCox, MTLR}; moreover, a model using both sets of features performs yet better (<italic>i.e</italic>., D-<italic>χ</italic> is better that C-<italic>χ</italic>).</p>
      </list-item>
      <list-item>
        <label>(iv)</label>
        <p>Comparing the D-<italic>χ</italic> to E-<italic>χ</italic>, we see that adding PAM50 subtypes as features to the METABRIC database improves the held-out test concordance.</p>
      </list-item>
    </list>
    <fig id="pone.0224446.g007" orientation="portrait" position="float">
      <object-id pub-id-type="doi">10.1371/journal.pone.0224446.g007</object-id>
      <label>Fig 7</label>
      <caption>
        <title>Test CI: METABRIC (left) and KIPAN (right).</title>
        <p>Note higher values are better. The labels on the x-axis correspond to <xref rid="pone.0224446.t002" ref-type="table">Table 2</xref>.</p>
      </caption>
      <graphic xlink:href="pone.0224446.g007"/>
    </fig>
    <table-wrap id="pone.0224446.t002" orientation="portrait" position="float">
      <object-id pub-id-type="doi">10.1371/journal.pone.0224446.t002</object-id>
      <label>Table 2</label>
      <caption>
        <title>Concordance results of various models from METABRIC (over 395 test instances) and KIPAN (over 176 test instances).</title>
        <p>+ = used these features and − = did not use these features As PAM50 is specific to breast cancer, it is <italic>not applicable</italic> to the kidney (KIPAN) data. The first row, with the ID “A(*)”, is the baseline.</p>
      </caption>
      <alternatives>
        <graphic id="pone.0224446.t002g" xlink:href="pone.0224446.t002"/>
        <table frame="box" rules="all" border="0">
          <colgroup span="1">
            <col align="left" valign="middle" span="1"/>
            <col align="left" valign="middle" span="1"/>
            <col align="left" valign="middle" span="1"/>
            <col align="left" valign="middle" span="1"/>
            <col align="left" valign="middle" span="1"/>
            <col align="left" valign="middle" span="1"/>
            <col align="left" valign="middle" span="1"/>
            <col align="left" valign="middle" span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th align="left" rowspan="2" style="border-bottom:thick;background-color:#ebebeb" colspan="1">ID</th>
              <th align="center" colspan="4" style="background-color:#ebebeb" rowspan="1">Feature Groups</th>
              <th align="center" style="background-color:#ebebeb" rowspan="1" colspan="1">Learning Alg.</th>
              <th align="center" colspan="2" style="background-color:#ebebeb" rowspan="1">Concordance</th>
            </tr>
            <tr>
              <th align="center" style="border-bottom:thick;background-color:#ebebeb" rowspan="1" colspan="1">Clinical</th>
              <th align="center" style="border-bottom:thick;background-color:#ebebeb" rowspan="1" colspan="1">PCA</th>
              <th align="center" style="border-bottom:thick;background-color:#ebebeb" rowspan="1" colspan="1">dLDA</th>
              <th align="center" style="border-bottom:thick;background-color:#ebebeb" rowspan="1" colspan="1">PAM50</th>
              <th align="center" style="border-bottom:thick;background-color:#ebebeb" rowspan="1" colspan="1">Cox | RCox | MTLR</th>
              <th align="center" style="border-bottom:thick;background-color:#ebebeb" rowspan="1" colspan="1">METABRIC</th>
              <th align="center" style="border-bottom:thick;background-color:#ebebeb" rowspan="1" colspan="1">KIPAN</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td align="left" rowspan="1" colspan="1">A (*)</td>
              <td align="center" rowspan="1" colspan="1">+</td>
              <td align="center" rowspan="1" colspan="1">−</td>
              <td align="center" rowspan="1" colspan="1">−</td>
              <td align="center" rowspan="1" colspan="1">−</td>
              <td align="left" rowspan="1" colspan="1">Cox</td>
              <td align="char" char="." rowspan="1" colspan="1">0.6810</td>
              <td align="center" rowspan="1" colspan="1">0.7656</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">A</td>
              <td align="center" rowspan="1" colspan="1">+</td>
              <td align="center" rowspan="1" colspan="1">−</td>
              <td align="center" rowspan="1" colspan="1">−</td>
              <td align="center" rowspan="1" colspan="1">−</td>
              <td align="center" rowspan="1" colspan="1">RCox</td>
              <td align="char" char="." rowspan="1" colspan="1">0.6883</td>
              <td align="center" rowspan="1" colspan="1">0.8156</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">A</td>
              <td align="center" rowspan="1" colspan="1">+</td>
              <td align="center" rowspan="1" colspan="1">−</td>
              <td align="center" rowspan="1" colspan="1">−</td>
              <td align="center" rowspan="1" colspan="1">−</td>
              <td align="right" rowspan="1" colspan="1">MTLR</td>
              <td align="char" char="." rowspan="1" colspan="1">0.6820</td>
              <td align="center" rowspan="1" colspan="1">0.8207</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">B</td>
              <td align="center" rowspan="1" colspan="1">+</td>
              <td align="center" rowspan="1" colspan="1">+</td>
              <td align="center" rowspan="1" colspan="1">−</td>
              <td align="center" rowspan="1" colspan="1">−</td>
              <td align="left" rowspan="1" colspan="1">Cox</td>
              <td align="char" char="." rowspan="1" colspan="1">0.6961</td>
              <td align="center" rowspan="1" colspan="1">0.7691</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">B</td>
              <td align="center" rowspan="1" colspan="1">+</td>
              <td align="center" rowspan="1" colspan="1">+</td>
              <td align="center" rowspan="1" colspan="1">−</td>
              <td align="center" rowspan="1" colspan="1">−</td>
              <td align="center" rowspan="1" colspan="1">RCox</td>
              <td align="char" char="." rowspan="1" colspan="1">0.7048</td>
              <td align="center" rowspan="1" colspan="1">0.8196</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">B</td>
              <td align="center" rowspan="1" colspan="1">+</td>
              <td align="center" rowspan="1" colspan="1">+</td>
              <td align="center" rowspan="1" colspan="1">−</td>
              <td align="center" rowspan="1" colspan="1">−</td>
              <td align="right" rowspan="1" colspan="1">MTLR</td>
              <td align="char" char="." rowspan="1" colspan="1">0.6999</td>
              <td align="center" rowspan="1" colspan="1">0.8232</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">C</td>
              <td align="center" rowspan="1" colspan="1">+</td>
              <td align="center" rowspan="1" colspan="1">−</td>
              <td align="center" rowspan="1" colspan="1">+</td>
              <td align="center" rowspan="1" colspan="1">−</td>
              <td align="left" rowspan="1" colspan="1">Cox</td>
              <td align="char" char="." rowspan="1" colspan="1">0.7073</td>
              <td align="center" rowspan="1" colspan="1">0.7638</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">C</td>
              <td align="center" rowspan="1" colspan="1">+</td>
              <td align="center" rowspan="1" colspan="1">−</td>
              <td align="center" rowspan="1" colspan="1">+</td>
              <td align="center" rowspan="1" colspan="1">−</td>
              <td align="center" rowspan="1" colspan="1">RCox</td>
              <td align="char" char="." rowspan="1" colspan="1">0.7108</td>
              <td align="center" rowspan="1" colspan="1">0.8332</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">C</td>
              <td align="center" rowspan="1" colspan="1">+</td>
              <td align="center" rowspan="1" colspan="1">−</td>
              <td align="center" rowspan="1" colspan="1">+</td>
              <td align="center" rowspan="1" colspan="1">−</td>
              <td align="right" rowspan="1" colspan="1">MTLR</td>
              <td align="char" char="." rowspan="1" colspan="1">0.7139</td>
              <td align="center" rowspan="1" colspan="1">0.8482</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">D</td>
              <td align="center" rowspan="1" colspan="1">+</td>
              <td align="center" rowspan="1" colspan="1">+</td>
              <td align="center" rowspan="1" colspan="1">+</td>
              <td align="center" rowspan="1" colspan="1">−</td>
              <td align="left" rowspan="1" colspan="1">Cox</td>
              <td align="char" char="." rowspan="1" colspan="1">0.7074</td>
              <td align="center" rowspan="1" colspan="1">0.8062</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">D</td>
              <td align="center" rowspan="1" colspan="1">+</td>
              <td align="center" rowspan="1" colspan="1">+</td>
              <td align="center" rowspan="1" colspan="1">+</td>
              <td align="center" rowspan="1" colspan="1">−</td>
              <td align="center" rowspan="1" colspan="1">RCox</td>
              <td align="char" char="." rowspan="1" colspan="1">0.7145</td>
              <td align="center" rowspan="1" colspan="1">0.8401</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">D</td>
              <td align="center" rowspan="1" colspan="1">+</td>
              <td align="center" rowspan="1" colspan="1">+</td>
              <td align="center" rowspan="1" colspan="1">+</td>
              <td align="center" rowspan="1" colspan="1">−</td>
              <td align="right" rowspan="1" colspan="1">MTLR</td>
              <td align="char" char="." rowspan="1" colspan="1">0.7079</td>
              <td align="center" rowspan="1" colspan="1">
                <bold>0.8495</bold>
              </td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">E</td>
              <td align="center" rowspan="1" colspan="1">+</td>
              <td align="center" rowspan="1" colspan="1">+</td>
              <td align="center" rowspan="1" colspan="1">+</td>
              <td align="center" rowspan="1" colspan="1">+</td>
              <td align="left" rowspan="1" colspan="1">Cox</td>
              <td align="char" char="." rowspan="1" colspan="1">0.7075</td>
              <td align="center" rowspan="1" colspan="1">NA</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">E</td>
              <td align="center" rowspan="1" colspan="1">+</td>
              <td align="center" rowspan="1" colspan="1">+</td>
              <td align="center" rowspan="1" colspan="1">+</td>
              <td align="center" rowspan="1" colspan="1">+</td>
              <td align="center" rowspan="1" colspan="1">RCox</td>
              <td align="char" char="." rowspan="1" colspan="1">0.7172</td>
              <td align="center" rowspan="1" colspan="1">NA</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">E</td>
              <td align="center" rowspan="1" colspan="1">+</td>
              <td align="center" rowspan="1" colspan="1">+</td>
              <td align="center" rowspan="1" colspan="1">+</td>
              <td align="center" rowspan="1" colspan="1">+</td>
              <td align="right" rowspan="1" colspan="1">MTLR</td>
              <td align="char" char="." rowspan="1" colspan="1">
                <bold>0.7202</bold>
              </td>
              <td align="center" rowspan="1" colspan="1">NA</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">F</td>
              <td align="center" rowspan="1" colspan="1">+</td>
              <td align="center" colspan="3" rowspan="1">Meta-Genes</td>
              <td align="center" rowspan="1" colspan="1">Ensemble Model</td>
              <td align="char" char="." rowspan="1" colspan="1">0.7293</td>
              <td align="center" rowspan="1" colspan="1">NA</td>
            </tr>
          </tbody>
        </table>
      </alternatives>
    </table-wrap>
    <p>Indeed, we see that the performance of models that include PAM50 are marginally better than similar models that do not (row D), suggesting that the information added by these different representations of GE data are not redundant. Moreover, we see that, in all feature groups, both RCox and MTLR clearly outperform Cox—<italic>i.e</italic>., <italic>ν</italic>-RCox and <italic>ν</italic>-MTLR are better than <italic>ν</italic>-Cox, for <italic>ν</italic> ∈ {A,B,C,D,E}. We then tested the first three claims on the KIPAN dataset; see <xref rid="pone.0224446.t002" ref-type="table">Table 2</xref> (right-most column) and <xref ref-type="fig" rid="pone.0224446.g007">Fig 7</xref>(right). (As KIPAN does not deal with breast cancer, the PAM50 features are not relevant, so we could not test claim (iv).)</p>
    <list list-type="simple">
      <list-item>
        <label>(i)</label>
        <p>As before, we found that adding expression information improves over the baseline A-Cox –<italic>i.e</italic>., essentially all values are better than 0.7656.</p>
      </list-item>
      <list-item>
        <label>(ii)</label>
        <p>We again found that the best model was the one that included all of the features; here D-MTLR. Moreover, a t-test on bootstrap replicas show that this model D-MTLR was <italic>significantly</italic> better than the top model that does not include dLDA features, B-MTLR.</p>
      </list-item>
      <list-item>
        <label>(iii)</label>
        <p>We again see that C-<italic>χ</italic> has a higher score than B-<italic>χ</italic>, meaning (again) that models trained with <italic>only the c_topics performed much better than PCA-features</italic>; but that including both features was yet better (D-<italic>χ</italic>).</p>
      </list-item>
    </list>
    <p>These sets of experiments support our claim that</p>
    <disp-quote>
      <p>a model learned by running MTLR on all GE features, gives very good concordance scores</p>
    </disp-quote>
    <p specific-use="continuation">–statistically better than other options in two different datasets, using different platforms, related to different cancer types.</p>
    <p>In addition to these evaluations using the discriminative concordance measure, we also applied a calibration measure: “D-Calibration” (“D” for “Distribution”) [<xref rid="pone.0224446.ref015" ref-type="bibr">15</xref>, <xref rid="pone.0224446.ref016" ref-type="bibr">16</xref>], which measures how well a individual survival distribution model is calibrated, using the Hosmer-Lemeshow (HL) [<xref rid="pone.0224446.ref030" ref-type="bibr">30</xref>] goodness-of-fit test; see Appendix B.2. We found that all of our models, for both datasets (METABRIC and KIPAN), passed this calibration test; see Appendix C.2, especially <xref rid="pone.0224446.t003" ref-type="table">Table 3</xref>. But we have found that this is not universal. For example, we experimented with another breast cancer dataset BRCA (results not shown here), and found that the Cox model failed for all configurations (of <italic>ρ</italic>), showing that the Cox model does not always produce calibrated results—here, for situations where RCox and MTLR produced D-calibrated predictors. See also Haider <italic>et al</italic>. [<xref rid="pone.0224446.ref016" ref-type="bibr">16</xref>].</p>
    <table-wrap id="pone.0224446.t003" orientation="portrait" position="float">
      <object-id pub-id-type="doi">10.1371/journal.pone.0224446.t003</object-id>
      <label>Table 3</label>
      <caption>
        <title>D-calibration results from METABRIC, KIPAN, and BRCA, on the held-out test data.</title>
        <p>p-values greater than 0.05 suggest the model is good (“D-calibrated”). Note that Cox models fail D-calibration test for all feature combinations, for BRCA dataset.</p>
      </caption>
      <alternatives>
        <graphic id="pone.0224446.t003g" xlink:href="pone.0224446.t003"/>
        <table frame="box" rules="all" border="0">
          <colgroup span="1">
            <col align="left" valign="middle" span="1"/>
            <col align="left" valign="middle" span="1"/>
            <col align="left" valign="middle" span="1"/>
            <col align="left" valign="middle" span="1"/>
            <col align="left" valign="middle" span="1"/>
            <col align="left" valign="middle" span="1"/>
            <col align="left" valign="middle" span="1"/>
            <col align="left" valign="middle" span="1"/>
            <col align="left" valign="middle" span="1"/>
            <col align="left" valign="middle" span="1"/>
            <col align="left" valign="middle" span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th align="left" rowspan="2" style="border-bottom:thick;background-color:#ebebeb" colspan="1">ID</th>
              <th align="center" colspan="3" style="background-color:#ebebeb" rowspan="1">Feature Groups</th>
              <th align="center" rowspan="2" style="border-bottom:thick;background-color:#ebebeb" colspan="1">Algorithms</th>
              <th align="center" colspan="2" style="background-color:#ebebeb" rowspan="1">KIPAN</th>
              <th align="center" colspan="2" style="background-color:#ebebeb" rowspan="1">METABRIC</th>
              <th align="center" colspan="2" style="background-color:#ebebeb" rowspan="1">BRCA</th>
            </tr>
            <tr>
              <th align="center" style="border-bottom:thick;background-color:#ebebeb" rowspan="1" colspan="1">Clinical</th>
              <th align="center" style="border-bottom:thick;background-color:#ebebeb" rowspan="1" colspan="1">PCA</th>
              <th align="center" style="border-bottom:thick;background-color:#ebebeb" rowspan="1" colspan="1">dLDA</th>
              <th align="right" style="border-bottom:thick;background-color:#ebebeb" rowspan="1" colspan="1">HL-Statistic</th>
              <th align="right" style="border-bottom:thick;background-color:#ebebeb" rowspan="1" colspan="1">p-value</th>
              <th align="right" style="border-bottom:thick;background-color:#ebebeb" rowspan="1" colspan="1">HL-Statistic</th>
              <th align="right" style="border-bottom:thick;background-color:#ebebeb" rowspan="1" colspan="1">p-value</th>
              <th align="right" style="border-bottom:thick;background-color:#ebebeb" rowspan="1" colspan="1">HL-Statistic</th>
              <th align="right" style="border-bottom:thick;background-color:#ebebeb" rowspan="1" colspan="1">p-value</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td align="left" rowspan="1" colspan="1">A</td>
              <td align="center" rowspan="1" colspan="1">+</td>
              <td align="center" rowspan="1" colspan="1">−</td>
              <td align="center" rowspan="1" colspan="1">−</td>
              <td align="left" rowspan="1" colspan="1">Cox</td>
              <td align="char" char="." rowspan="1" colspan="1">7.1455</td>
              <td align="char" char="." rowspan="1" colspan="1">0.9888</td>
              <td align="char" char="." rowspan="1" colspan="1">12.6765</td>
              <td align="char" char="." rowspan="1" colspan="1">0.8104</td>
              <td align="char" char="." rowspan="1" colspan="1">52.5289</td>
              <td align="right" rowspan="1" colspan="1">
                <bold>3.1e-05</bold>
              </td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">A</td>
              <td align="center" rowspan="1" colspan="1">+</td>
              <td align="center" rowspan="1" colspan="1">−</td>
              <td align="center" rowspan="1" colspan="1">−</td>
              <td align="center" rowspan="1" colspan="1">RCox</td>
              <td align="char" char="." rowspan="1" colspan="1">7.1279</td>
              <td align="char" char="." rowspan="1" colspan="1">0.9890</td>
              <td align="char" char="." rowspan="1" colspan="1">14.8143</td>
              <td align="char" char="." rowspan="1" colspan="1">0.6747</td>
              <td align="char" char="." rowspan="1" colspan="1">4.8816</td>
              <td align="right" rowspan="1" colspan="1">0.9990</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">A</td>
              <td align="center" rowspan="1" colspan="1">+</td>
              <td align="center" rowspan="1" colspan="1">−</td>
              <td align="center" rowspan="1" colspan="1">−</td>
              <td align="right" rowspan="1" colspan="1">MTLR</td>
              <td align="char" char="." rowspan="1" colspan="1">8.2421</td>
              <td align="char" char="." rowspan="1" colspan="1">0.9748</td>
              <td align="char" char="." rowspan="1" colspan="1">11.2300</td>
              <td align="char" char="." rowspan="1" colspan="1">0.8843</td>
              <td align="char" char="." rowspan="1" colspan="1">6.6300</td>
              <td align="right" rowspan="1" colspan="1">0.9929</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">B</td>
              <td align="center" rowspan="1" colspan="1">+</td>
              <td align="center" rowspan="1" colspan="1">+</td>
              <td align="center" rowspan="1" colspan="1">−</td>
              <td align="left" rowspan="1" colspan="1">Cox</td>
              <td align="char" char="." rowspan="1" colspan="1">5.6697</td>
              <td align="char" char="." rowspan="1" colspan="1">0.9973</td>
              <td align="char" char="." rowspan="1" colspan="1">8.1723</td>
              <td align="char" char="." rowspan="1" colspan="1">0.9760</td>
              <td align="char" char="." rowspan="1" colspan="1">63.7983</td>
              <td align="right" rowspan="1" colspan="1">
                <bold>4.9e-07</bold>
              </td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">B</td>
              <td align="center" rowspan="1" colspan="1">+</td>
              <td align="center" rowspan="1" colspan="1">+</td>
              <td align="center" rowspan="1" colspan="1">−</td>
              <td align="center" rowspan="1" colspan="1">RCox</td>
              <td align="char" char="." rowspan="1" colspan="1">2.5769</td>
              <td align="char" char="." rowspan="1" colspan="1">0.9973</td>
              <td align="char" char="." rowspan="1" colspan="1">6.4499</td>
              <td align="char" char="." rowspan="1" colspan="1">0.9940</td>
              <td align="char" char="." rowspan="1" colspan="1">6.0013</td>
              <td align="right" rowspan="1" colspan="1">0.9962</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">B</td>
              <td align="center" rowspan="1" colspan="1">+</td>
              <td align="center" rowspan="1" colspan="1">+</td>
              <td align="center" rowspan="1" colspan="1">−</td>
              <td align="right" rowspan="1" colspan="1">MTLR</td>
              <td align="char" char="." rowspan="1" colspan="1">8.4315</td>
              <td align="char" char="." rowspan="1" colspan="1">0.9714</td>
              <td align="char" char="." rowspan="1" colspan="1">10.8421</td>
              <td align="char" char="." rowspan="1" colspan="1">0.9009</td>
              <td align="char" char="." rowspan="1" colspan="1">8.9895</td>
              <td align="right" rowspan="1" colspan="1">0.9600</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">C</td>
              <td align="center" rowspan="1" colspan="1">+</td>
              <td align="center" rowspan="1" colspan="1">−</td>
              <td align="center" rowspan="1" colspan="1">+</td>
              <td align="left" rowspan="1" colspan="1">Cox</td>
              <td align="char" char="." rowspan="1" colspan="1">10.54166</td>
              <td align="char" char="." rowspan="1" colspan="1">0.9127</td>
              <td align="char" char="." rowspan="1" colspan="1">6.0066</td>
              <td align="char" char="." rowspan="1" colspan="1">0.9962</td>
              <td align="char" char="." rowspan="1" colspan="1">48.9904</td>
              <td align="right" rowspan="1" colspan="1">
                <bold>0.0001</bold>
              </td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">C</td>
              <td align="center" rowspan="1" colspan="1">+</td>
              <td align="center" rowspan="1" colspan="1">−</td>
              <td align="center" rowspan="1" colspan="1">+</td>
              <td align="center" rowspan="1" colspan="1">RCox</td>
              <td align="char" char="." rowspan="1" colspan="1">7.9878</td>
              <td align="char" char="." rowspan="1" colspan="1">0.9993</td>
              <td align="char" char="." rowspan="1" colspan="1">4.1344</td>
              <td align="char" char="." rowspan="1" colspan="1">0.9997</td>
              <td align="char" char="." rowspan="1" colspan="1">4.6031</td>
              <td align="right" rowspan="1" colspan="1">0.9993</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">C</td>
              <td align="center" rowspan="1" colspan="1">+</td>
              <td align="center" rowspan="1" colspan="1">−</td>
              <td align="center" rowspan="1" colspan="1">+</td>
              <td align="right" rowspan="1" colspan="1">MTLR</td>
              <td align="char" char="." rowspan="1" colspan="1">6.5578</td>
              <td align="char" char="." rowspan="1" colspan="1">0.9933</td>
              <td align="char" char="." rowspan="1" colspan="1">8.2000</td>
              <td align="char" char="." rowspan="1" colspan="1">0.9755</td>
              <td align="char" char="." rowspan="1" colspan="1">9.2421</td>
              <td align="right" rowspan="1" colspan="1">0.9539</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">D</td>
              <td align="center" rowspan="1" colspan="1">+</td>
              <td align="center" rowspan="1" colspan="1">+</td>
              <td align="center" rowspan="1" colspan="1">+</td>
              <td align="left" rowspan="1" colspan="1">Cox</td>
              <td align="char" char="." rowspan="1" colspan="1">14.1951</td>
              <td align="char" char="." rowspan="1" colspan="1">0.7162</td>
              <td align="char" char="." rowspan="1" colspan="1">11.2333</td>
              <td align="char" char="." rowspan="1" colspan="1">0.8842</td>
              <td align="char" char="." rowspan="1" colspan="1">25.2241</td>
              <td align="right" rowspan="1" colspan="1">
                <bold>0.1189</bold>
              </td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">D</td>
              <td align="center" rowspan="1" colspan="1">+</td>
              <td align="center" rowspan="1" colspan="1">+</td>
              <td align="center" rowspan="1" colspan="1">+</td>
              <td align="center" rowspan="1" colspan="1">RCox</td>
              <td align="char" char="." rowspan="1" colspan="1">8.2420</td>
              <td align="char" char="." rowspan="1" colspan="1">0.9748</td>
              <td align="char" char="." rowspan="1" colspan="1">3.4981</td>
              <td align="char" char="." rowspan="1" colspan="1">0.9999</td>
              <td align="char" char="." rowspan="1" colspan="1">6.0813</td>
              <td align="right" rowspan="1" colspan="1">0.9959</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">D</td>
              <td align="center" rowspan="1" colspan="1">+</td>
              <td align="center" rowspan="1" colspan="1">+</td>
              <td align="center" rowspan="1" colspan="1">+</td>
              <td align="right" rowspan="1" colspan="1">MTLR</td>
              <td align="char" char="." rowspan="1" colspan="1">7.4947</td>
              <td align="char" char="." rowspan="1" colspan="1">0.9852</td>
              <td align="char" char="." rowspan="1" colspan="1">6.5158</td>
              <td align="char" char="." rowspan="1" colspan="1">0.9936</td>
              <td align="char" char="." rowspan="1" colspan="1">9.0211</td>
              <td align="right" rowspan="1" colspan="1">0.9593</td>
            </tr>
          </tbody>
        </table>
      </alternatives>
    </table-wrap>
    <sec id="sec013">
      <title>5.1 Other comparisons</title>
      <p>In 2012, Cheng <italic>et al</italic>. [<xref rid="pone.0224446.ref013" ref-type="bibr">13</xref>] won the BCC Dream Challenge (which was based on the METABRIC data) by (i) leveraging prior knowledge of cancer biology to form Meta-Genes and (ii) training an ensemble of multiple learners, fueled by the continuous insights from the challenge competitors via open sharing of code and trained models. To compare our performances with this BCC winning program, we reproduced their models (using the DreamBox7 package), then re-trained their ensemble learners on our training split of the METABRIC data and tested on the held-out test set. <xref rid="pone.0224446.t002" ref-type="table">Table 2</xref>[Row <italic>F</italic>] shows that the resulting ensemble model achieved a CI of 0.7293 on the test data. While that score is slightly better than the performance of our best model (<xref rid="pone.0224446.t002" ref-type="table">Table 2</xref>[Row <italic>E</italic>]), note that all of our tuning was performed solely on the training (n = 1586) data, while their team made major design choices for their model using the entire METABRIC cohort (all n = 1981 instances), on which it was then evaluated.</p>
      <p>Recently, Yousefi <italic>et al</italic>. [<xref rid="pone.0224446.ref031" ref-type="bibr">31</xref>] trained a deep neural network on this KIPAN data—including this gene expression data, as well as other features: Mutation, CNV and Protein. They reported concordance scores around 0.73−0.79, which are lower than our best, 0.8495.</p>
      <p>Finally, while we focused on the LDA approach, we also explored another topic modeling technique, Latent Semantic Indexing (LSI) [<xref rid="pone.0224446.ref023" ref-type="bibr">23</xref>]. Running this on both datasets (using the same discretization approach, the same <italic>t</italic>* = Enc_B encoding and the same number of c_topics, <italic>K</italic>* = 30), we found essentially the same Concordance values, and confirmed that all four claims (i) through (iv) still hold, just replacing dLDA with the “discretized LSI” (dLSI) encoding.</p>
    </sec>
  </sec>
  <sec sec-type="conclusions" id="sec014">
    <title>6 Discussion</title>
    <p>Given the growing number of gene expression datasets as part of survival analysis studies, it is clearly important to develop survival prediction models that can utilize such high-dimensional GE data. This motivated us to propose a novel survival prediction methodology that can learn predictive features from such GE data—exploring ways to learn and use c_topics as features for models that can effectively predict survival. <italic>N.b</italic>., this paper focuses exclusively on this predictive task, as this can lead to clinically relevant patient-specific information; indeed, this motivated the BCC Dream challenge, which provided the METABRIC dataset. We anticipate future work will explore the possible interpretation of these c_topics.</p>
    <p>We included Cox as one of our learning modules for this task as it is known to be effective at optimizing concordance, both empirically and theoretically [<xref rid="pone.0224446.ref032" ref-type="bibr">32</xref>]. We included RCox as this algorithm recently won Prostate Cancer Dream Challenge 9.5 [<xref rid="pone.0224446.ref012" ref-type="bibr">12</xref>]. Finally, we included the MTLR survival prediction model as its performance, there, was competitive with the best, as well as based on the empirical evidence in Haider <italic>et al</italic>. [<xref rid="pone.0224446.ref016" ref-type="bibr">16</xref>]. Our evaluations on these two datasets show that MTLR’s performance was often better than RCox and Cox. Moreover, while the basic RCox and Cox functions produce only a risk score for each patient, MTLR provides a survival distribution for each, mapping each time to a probability; see <xref ref-type="fig" rid="pone.0224446.g002">Fig 2</xref>. Such models, which produce an individual survival distribution, can be used to compute a risk score, allowing them to be used for concordance-tasks; they can also be used to predict single time probabilities (<italic>e.g</italic>., probability of a patient living at least 3 years), and also can be visualized. (We used the Kalbfleisch-Prentice approach to estimate the base hazard function, allowing Cox and RCox to similarly produce individual survival curves. Appendix B.2 describes a way to evaluate such “individual survival distribution” models, D-Calibration. Appendix C.2 then shows that, for these datasets, these models all pass this test).</p>
    <p>To summarize the main disadvantages and advantages of our approach, versus more standard approaches (<italic>e.g</italic>., PCA for dimensionality reduction, and (R)Cox for survival prediction):</p>
    <list list-type="bullet">
      <list-item>
        <p>Disadvantages:
<list list-type="bullet"><list-item><p>Topic models are not simple to describe.</p></list-item><list-item><p>This approach requires a fairly long training time (∼20 hours on a 16GB, 2.66GHz processor for a single model)—to first find the parameters (encoding, number of c_topics), then the c_topics themselves, and finally, to learn the model that has the best performance. (However, using the trained dLDA model to predict c_topic contributions for a new patient is very fast—under a second on a general purpose laptop computer.)</p></list-item></list>
</p>
      </list-item>
      <list-item>
        <p>Advantages:
<list list-type="bullet"><list-item><p>An effective process to learn representation from gene expression data, as a meaningful probability distribution over the genes.</p></list-item><list-item><p>The learned representation from the gene expression data improves survival prediction, over standard methods, in:
<list list-type="bullet"><list-item><p>Different cancer types: Breast and Kidney.</p></list-item><list-item><p>Different gene expression data types: Microarray and mRNASeq.</p></list-item><list-item><p>Different survival prediction algorithms: Cox, Regularized-Cox and MTLR.</p></list-item></list>
</p></list-item><list-item><p>Our combined approach for feature learning and survival prediction (dLDA + MTLR) archives strong concordance scores compared to standard survival models across different cancer types.</p></list-item></list>
</p>
      </list-item>
    </list>
  </sec>
  <sec sec-type="conclusions" id="sec015">
    <title>7 Conclusion</title>
    <p><xref rid="pone.0224446.t002" ref-type="table">Table 2</xref> shows that our proposed model, which uses MTLR to learn a model involving various types of derived GE features (dLDA c_topics and/or SuperPC+), has the best concordance, in two datasets representing different types of cancer, and two different gene expression platforms (micro-array and mRNAseq). That table shows that adding GE features improves survival prediction and that including both dLDA c_topics and SuperPC+ principle components gives the most improvements across held-out datasets. We also found that the “framework” that produced the best model in METABRIC, was also the best in the Pan-kidney KIPAN dataset, which shows the robustness of our proposed prediction framework. Moreover the c_topics extracted by our dLDA procedure (inspired by topic modeling) can be interpreted as collections of over-expressed or under-expressed gene sets; further analysis is needed to discover and validate the biological insights from these c_topics. Our results show that our novel survival prediction model—learning a MTLR survival model based on our derived GE features (dLDA c_topics and SuperPC+ components)—leads to survival prediction models that can be better than standard survival models. We anticipate that others will find this dLDA+MTLR approach (and code at <ext-link ext-link-type="uri" xlink:href="https://github.com/nitsanluke/GE-LDA-Survival">https://github.com/nitsanluke/GE-LDA-Survival</ext-link>) helpful for their future tasks.</p>
  </sec>
  <sec id="sec016">
    <title>A Details about the algorithms</title>
    <p>Section 4 gave a high-level overview of the important parts of the learning, and performance, systems; see also <xref ref-type="fig" rid="pone.0224446.g008">Fig 8</xref>. This appendix completes that description. In particular, it summarizes the components of the learning and performance systems—each shown as a rounded-rectangle in Figs <xref ref-type="fig" rid="pone.0224446.g003">3</xref> or <xref ref-type="fig" rid="pone.0224446.g006">6</xref>—roughly in a top-to-bottom fashion. Appendix A.1 describes the P<sc>re</sc>P<sc>rocess</sc>(⋯) routine that preprocesses the training data (both gene expression and clinical features), and the related <sc>PreProcess’</sc>(⋯) routine, used by USM, to preprocess a novel instance. Appendix A.2 then gives many details about C<sc>ompute</sc>B<sc>asis</sc><sub>[<italic>ρ</italic>=dLDA]</sub>(⋯) that computes the set of “c_topic − genes” distributions, given gene expression values (and some additional information)—extending the high-level description in routine in Section 4.1.1. Appendix A.3 describes the U<sc>se</sc>B<sc>asis</sc><sub>[<italic>ρ</italic>=dLDA]</sub> routine that uses these c_topic-genes distributions to map each patient’s gene expression profile into that patient’s specific “c_topic—distribution”; see <xref ref-type="fig" rid="pone.0224446.g005">Fig 5</xref>. Appendix A.4 presents C<sc>ompute</sc>B<sc>asis</sc><sub>[<italic>ρ</italic>=PCA]</sub> and U<sc>se</sc>B<sc>asis</sc><sub>[<italic>ρ</italic>=PCA]</sub> techniques, to deal with the other approaches for reducing the dimensionality, PCA. Finally Appendix A.5 describes two related standard survival analysis methods: Cox [<xref rid="pone.0224446.ref026" ref-type="bibr">26</xref>], and Ridge-Cox (RCox) [<xref rid="pone.0224446.ref033" ref-type="bibr">33</xref>]. (Section 2.1.1 presented another approach, based on the more recent MTLR approach to survival analysis.)</p>
    <fig id="pone.0224446.g008" orientation="portrait" position="float">
      <object-id pub-id-type="doi">10.1371/journal.pone.0224446.g008</object-id>
      <label>Fig 8</label>
      <caption>
        <title>Simplified flow diagram describing the overall prediction process, including both the learning task and the performance task.</title>
      </caption>
      <graphic xlink:href="pone.0224446.g008"/>
    </fig>
    <sec id="sec017">
      <title>A.1 P<sc>re</sc>P<sc>rocess</sc> and P<sc>re</sc>P<sc>rocess</sc>’</title>
      <p>The P<sc>re</sc>P<sc>rocess</sc> process (used by LSM in <xref ref-type="fig" rid="pone.0224446.g003">Fig 3</xref>) applies various standard “normalizations” and simple “corrections” to the training data—both raw clinical features, and gene expression values. For the clinical features <italic>X</italic><sub><italic>CF</italic></sub>, P<sc>re</sc>P<sc>rocess</sc> produces a normalized dataset without any missing values, ready for the subsequent steps in the pipeline—see the orange-lines in <xref ref-type="fig" rid="pone.0224446.g003">Fig 3</xref>. This uses the standard steps: (1) impute missing real (resp., categorical) values for a feature with the mean (resp., mode) of the observed values for that feature; and (2) binarizing each categorical variable (aka “one-hot encoding”)—<italic>e.g</italic>., we encoded the 12-valued “Histological type” using twelve bits: <italic>e.g</italic>., <italic>Invasive Tumor</italic> is [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]. For the gene expression data <italic>X</italic><sub><italic>GE</italic></sub>, P<sc>re</sc>P<sc>rocess</sc> applies the following steps: (1) As we want to deal with the log of the initial gene expression value, we first log<sub>2</sub>-transformed the data, if necessary. (Below we use “gene expression” to refer to this transformed value.) (2) Then translate all expression values into their “common z-scores”. It first computes the (common) mean and standard deviation over all the genes from the entire <italic>X</italic><sub><italic>GE</italic></sub> dataset: Let <inline-formula id="pone.0224446.e046"><alternatives><graphic xlink:href="pone.0224446.e046.jpg" id="pone.0224446.e046g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M46"><mml:msubsup><mml:mi>e</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> be the expression value of probe/gene <italic>g</italic><sub><italic>i</italic></sub> of patient <italic>j</italic>, then compute the common mean <inline-formula id="pone.0224446.e047"><alternatives><graphic xlink:href="pone.0224446.e047.jpg" id="pone.0224446.e047g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M47"><mml:mrow><mml:mover accent="true"><mml:mi>μ</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>n</mml:mi></mml:mfrac><mml:msub><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mi>e</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> (where <italic>n</italic> = 1,981×49,576 is the total number of entries for METABRIC), and the variance <inline-formula id="pone.0224446.e048"><alternatives><graphic xlink:href="pone.0224446.e048.jpg" id="pone.0224446.e048g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M48"><mml:mrow><mml:msup><mml:mover accent="true"><mml:mi>σ</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msup><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mfrac><mml:msub><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi>e</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msubsup><mml:mo>-</mml:mo><mml:mover accent="true"><mml:mi>μ</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math></alternatives></inline-formula>. We then use the Z-score transformation of each entry: <inline-formula id="pone.0224446.e049"><alternatives><graphic xlink:href="pone.0224446.e049.jpg" id="pone.0224446.e049g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M49"><mml:mrow><mml:msubsup><mml:mi>z</mml:mi><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi>e</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msubsup><mml:mo>-</mml:mo><mml:mover accent="true"><mml:mi>μ</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo>)</mml:mo></mml:mrow><mml:mover accent="true"><mml:mi>σ</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mfrac></mml:mrow></mml:math></alternatives></inline-formula>. Notes: (a) this standardization is done prior to dividing the data into train and validation sets. (b) Using z-scores based on only a single gene would not be able to identify which genes did not vary much, as (after this transform) all genes would vary the same amount. (3) P<sc>re</sc>P<sc>rocess</sc> then removes the genes that do not vary much, removing a gene <italic>i</italic> iff its <inline-formula id="pone.0224446.e050"><alternatives><graphic xlink:href="pone.0224446.e050.jpg" id="pone.0224446.e050g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M50"><mml:msubsup><mml:mi>z</mml:mi><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> values are all within the first standard deviation—<italic>i.e</italic>., if <inline-formula id="pone.0224446.e051"><alternatives><graphic xlink:href="pone.0224446.e051.jpg" id="pone.0224446.e051g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M51"><mml:mrow><mml:mo>∀</mml:mo><mml:mi>j</mml:mi><mml:mspace width="4pt"/><mml:msubsup><mml:mi>z</mml:mi><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:msubsup><mml:mo>∈</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>.</p>
      <p>This filtering process is motivated by the assumption that any gene whose expressions does not change much across multiple patients, is unlikely to be directly related to the disease, while the genes that contribute, typically have significant variations in their expression levels across patients. While this filtering procedure is unsupervised, we anticipated that it would retain the genes that have the most prognostic ability. This was confirmed as we found that this process does not eliminate any of the “top” 100 probes in the METABRIC data (these are the probes with the 100 highest concordance values); see [<xref rid="pone.0224446.ref013" ref-type="bibr">13</xref>, Table 1]. In METABRIC, this filtering procedure eliminates 27,131 of the original 49,576 probes, leaving only 22,445 probes—<italic>i.e</italic>., a ≈54.7% reduction in the number of features.</p>
      <p>Later, the performance system USM will need to apply these pre-processing steps to a novel instance—in particular, for each clinical feature, it will need to know the mean (or median) value, for imputation. Similarly, it will need to transform each gene expression values into an integer; this requires knowing the global mean <inline-formula id="pone.0224446.e052"><alternatives><graphic xlink:href="pone.0224446.e052.jpg" id="pone.0224446.e052g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M52"><mml:mover accent="true"><mml:mi>μ</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> and <inline-formula id="pone.0224446.e053"><alternatives><graphic xlink:href="pone.0224446.e053.jpg" id="pone.0224446.e053g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M53"><mml:msup><mml:mover accent="true"><mml:mi>σ</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msup></mml:math></alternatives></inline-formula> values to produce the <italic>z</italic>-values <inline-formula id="pone.0224446.e054"><alternatives><graphic xlink:href="pone.0224446.e054.jpg" id="pone.0224446.e054g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M54"><mml:mrow><mml:mo>{</mml:mo><mml:msubsup><mml:mi>z</mml:mi><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:msubsup><mml:mo>}</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> values, We include all of these values in the Ω term, which is output by the P<sc>re</sc>P<sc>rocess</sc> subroutine. This Ω is one of the inputs to the P<sc>re</sc>P<sc>rocess</sc>’ process, within USM, which applies these pre-processing steps to a novel instance encoded by its <italic>x</italic><sub><italic>GE</italic></sub> and <italic>x</italic><sub><italic>CF</italic></sub> features. Note finally that neither P<sc>re</sc>P<sc>rocess</sc> nor P<sc>re</sc>P<sc>rocess</sc>’ use the labels (survival times).</p>
    </sec>
    <sec id="sec018">
      <title>A.2 C<sc>ompute</sc>B<sc>asis</sc><sub>[<italic>ρ</italic>=dLDA]</sub></title>
      <p>As shown by the blue lines in <xref ref-type="fig" rid="pone.0224446.g003">Fig 3</xref>, the C<sc>ompute</sc>B<sc>asis</sc> process takes as input a pre-processed version of the labeled dataset that was input to LSM: the P<sc>re</sc>P<sc>rocess</sc>ed gene expression data <inline-formula id="pone.0224446.e055"><alternatives><graphic xlink:href="pone.0224446.e055.jpg" id="pone.0224446.e055g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M55"><mml:msubsup><mml:mi>X</mml:mi><mml:mrow><mml:mi>G</mml:mi><mml:mi>E</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup></mml:math></alternatives></inline-formula> and clinical features <inline-formula id="pone.0224446.e056"><alternatives><graphic xlink:href="pone.0224446.e056.jpg" id="pone.0224446.e056g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M56"><mml:msubsup><mml:mi>X</mml:mi><mml:mrow><mml:mi>C</mml:mi><mml:mi>F</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup></mml:math></alternatives></inline-formula>, with their associated labels (<italic>Lbl</italic>). This process produces the “basis” set, of type <italic>ρ</italic>. This subappendix will focus on <italic>ρ</italic> = dLDA.</p>
      <p><bold>Algorithm 1</bold> C<sc>ompute</sc>B<sc>asis</sc><sub>[<italic>ρ</italic>=dLDA]</sub> algorithm</p>
      <p specific-use="line">1: <bold>function</bold> C<sc>ompute</sc>B<sc>asis</sc><sub>[<italic>ρ</italic>=dLDA]</sub>(<inline-formula id="pone.0224446.e057"><alternatives><graphic xlink:href="pone.0224446.e057.jpg" id="pone.0224446.e057g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M57"><mml:mrow><mml:msubsup><mml:mi>X</mml:mi><mml:mrow><mml:mi>G</mml:mi><mml:mi>E</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup><mml:mo>,</mml:mo><mml:mspace width="4pt"/><mml:msubsup><mml:mi>X</mml:mi><mml:mrow><mml:mi>C</mml:mi><mml:mi>F</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup><mml:mo>,</mml:mo><mml:mspace width="4pt"/><mml:mi>L</mml:mi><mml:mi>b</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>)     ⊳ Returns a set of c_topics</p>
      <p specific-use="line">2:  <inline-formula id="pone.0224446.e058"><alternatives><graphic xlink:href="pone.0224446.e058.jpg" id="pone.0224446.e058g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M58"><mml:msubsup><mml:mi>X</mml:mi><mml:mrow><mml:mi>G</mml:mi><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mo>″</mml:mo></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> ≔ Discretize(<inline-formula id="pone.0224446.e059"><alternatives><graphic xlink:href="pone.0224446.e059.jpg" id="pone.0224446.e059g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M59"><mml:msubsup><mml:mi>X</mml:mi><mml:mrow><mml:mi>G</mml:mi><mml:mi>E</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup></mml:math></alternatives></inline-formula>)</p>
      <p specific-use="line">3:  <bold>for</bold> t in {Enc_A, Enc_B} <bold>do</bold></p>
      <p specific-use="line">4:   <italic>GE</italic><sub><italic>t</italic></sub> ≔ Encode-GE(t, <inline-formula id="pone.0224446.e060"><alternatives><graphic xlink:href="pone.0224446.e060.jpg" id="pone.0224446.e060g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M60"><mml:msubsup><mml:mi>X</mml:mi><mml:mrow><mml:mi>G</mml:mi><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mo>″</mml:mo></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>)</p>
      <p specific-use="line">5:   [<italic>GE</italic><sub><italic>t</italic>,1</sub>, <italic>GE</italic><sub><italic>t</italic>,2</sub>, …, <italic>GE</italic><sub><italic>t</italic>,5</sub>] ≔ Partition(<italic>GE</italic><sub><italic>t</italic></sub>)</p>
      <p specific-use="line">6:   % Notation: <italic>GE</italic><sub><italic>t</italic>,−<italic>i</italic></sub> = <italic>GE</italic><sub><italic>t</italic></sub> − <italic>GE</italic><sub><italic>t</italic>,<italic>i</italic></sub></p>
      <p specific-use="line">7:   % <inline-formula id="pone.0224446.e061"><alternatives><graphic xlink:href="pone.0224446.e061.jpg" id="pone.0224446.e061g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M61"><mml:msubsup><mml:mi>X</mml:mi><mml:mrow><mml:mi>C</mml:mi><mml:mi>E</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo>′</mml:mo></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> = clinical features;</p>
      <p specific-use="line">8:   <bold>for</bold> K in (5, 10, 15, …, 150) <bold>do</bold></p>
      <p specific-use="line">9:    <bold>for</bold> i = 1:5 <bold>do</bold></p>
      <p specific-use="line">10:     % Find LDA “basis set” (set of c_topics)</p>
      <p specific-use="line">11:     <inline-formula id="pone.0224446.e062"><alternatives><graphic xlink:href="pone.0224446.e062.jpg" id="pone.0224446.e062g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M62"><mml:msub><mml:mover accent="true"><mml:mi>β</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>K</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></alternatives></inline-formula> ≔ C<sc>ompute</sc>_dLDA(<italic>GE</italic><sub><italic>t</italic>,−<italic>i</italic></sub>, K)</p>
      <p specific-use="line">12:</p>
      <p specific-use="line">13:     % Project the hold-out set onto this basis set,</p>
      <p specific-use="line">14:     % encoding each patient as a K-tuple of values</p>
      <p specific-use="line">15:     <italic>GE</italic>_<italic>Topic</italic><sub><italic>t</italic>,<italic>K</italic>,<italic>i</italic></sub> ≔ U<sc>se</sc>_<sc>d</sc>LDA(<italic>GE</italic><sub><italic>t</italic>,<italic>i</italic></sub>, <inline-formula id="pone.0224446.e063"><alternatives><graphic xlink:href="pone.0224446.e063.jpg" id="pone.0224446.e063g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M63"><mml:msub><mml:mover accent="true"><mml:mi>β</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>K</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></alternatives></inline-formula>)</p>
      <p specific-use="line">16:</p>
      <p specific-use="line">17:     % Learn a Cox model for this encoding, value of <italic>K</italic>, and fold <italic>i</italic></p>
      <p specific-use="line">18:     % using both c_topics and the clinical features</p>
      <p specific-use="line">19:     % LearnCox &amp; PredictCox are based on [<xref rid="pone.0224446.ref026" ref-type="bibr">26</xref>]</p>
      <p specific-use="line">20:     <italic>w</italic><sub><italic>t</italic>,<italic>K</italic>,<italic>i</italic></sub> ≔ LearnCox(<inline-formula id="pone.0224446.e064"><alternatives><graphic xlink:href="pone.0224446.e064.jpg" id="pone.0224446.e064g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M64"><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mspace width="0.166667em"/><mml:mi>G</mml:mi><mml:mi>E</mml:mi><mml:mo>_</mml:mo><mml:mi>T</mml:mi><mml:mi>o</mml:mi><mml:mi>p</mml:mi><mml:mi>i</mml:mi><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>K</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mspace width="4pt"/><mml:msubsup><mml:mi>X</mml:mi><mml:mrow><mml:mi>C</mml:mi><mml:mi>F</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup><mml:mspace width="0.166667em"/><mml:mo>]</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mspace width="4pt"/><mml:mi>L</mml:mi><mml:mi>b</mml:mi><mml:msub><mml:mi>l</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>)</p>
      <p specific-use="line">21:</p>
      <p specific-use="line">22:     % Evaluate model on the hold out set</p>
      <p specific-use="line">23:     % Using evaluation measures concordance and likelihood</p>
      <p specific-use="line">24:     <italic>c</italic><sub><italic>t</italic>,<italic>K</italic>,<italic>i</italic></sub> ≔ Concordance(PredictCox(<inline-formula id="pone.0224446.e065"><alternatives><graphic xlink:href="pone.0224446.e065.jpg" id="pone.0224446.e065g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M65"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>K</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mspace width="4pt"/><mml:mrow><mml:mo>[</mml:mo><mml:mi>G</mml:mi><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mspace width="4pt"/><mml:msubsup><mml:mi>X</mml:mi><mml:mrow><mml:mi>C</mml:mi><mml:mi>F</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>), <italic>Lbl</italic><sub><italic>i</italic></sub>)</p>
      <p specific-use="line">25:     <italic>l</italic><sub><italic>t</italic>,<italic>K</italic>,<italic>i</italic></sub> ≔ Average{Likelihood(<inline-formula id="pone.0224446.e066"><alternatives><graphic xlink:href="pone.0224446.e066.jpg" id="pone.0224446.e066g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M66"><mml:msub><mml:mover accent="true"><mml:mi>β</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>K</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></alternatives></inline-formula>, <italic>GE</italic><sub><italic>t</italic>,<italic>i</italic></sub>)}</p>
      <p specific-use="line">26:</p>
      <p specific-use="line">27:    <inline-formula id="pone.0224446.e067"><alternatives><graphic xlink:href="pone.0224446.e067.jpg" id="pone.0224446.e067g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M67"><mml:msub><mml:mover accent="true"><mml:mi>c</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>K</mml:mi></mml:mrow></mml:msub></mml:math></alternatives></inline-formula> ≔ Average{<italic>c</italic><sub><italic>t</italic>,<italic>K</italic>,<italic>i</italic></sub>}</p>
      <p specific-use="line">28:    <inline-formula id="pone.0224446.e068"><alternatives><graphic xlink:href="pone.0224446.e068.jpg" id="pone.0224446.e068g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M68"><mml:msub><mml:mover accent="true"><mml:mi>l</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>K</mml:mi></mml:mrow></mml:msub></mml:math></alternatives></inline-formula> ≔ Average{<italic>l</italic><sub><italic>t</italic>,<italic>K</italic>,<italic>i</italic></sub>}</p>
      <p specific-use="line">29:</p>
      <p specific-use="line">30:   % Find <italic>t</italic>* (encoding scheme), with the highest concordance</p>
      <p specific-use="line">31:   <italic>t</italic>* ≔ <inline-formula id="pone.0224446.e069"><alternatives><graphic xlink:href="pone.0224446.e069.jpg" id="pone.0224446.e069g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M69"><mml:mrow><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>g</mml:mi><mml:mspace width="2pt"/><mml:msub><mml:mtext>max</mml:mtext><mml:mi>t</mml:mi></mml:msub><mml:mrow><mml:mo>{</mml:mo><mml:mspace width="4pt"/><mml:msub><mml:mover accent="true"><mml:mi>c</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>K</mml:mi></mml:mrow></mml:msub><mml:mspace width="4pt"/><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula></p>
      <p specific-use="line">32:   % Selecting <italic>K</italic>*</p>
      <p specific-use="line">33:   <inline-formula id="pone.0224446.e070"><alternatives><graphic xlink:href="pone.0224446.e070.jpg" id="pone.0224446.e070g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M70"><mml:mrow><mml:mover accent="true"><mml:mi>K</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mspace width="4pt"/><mml:mo>=</mml:mo><mml:mspace width="4pt"/><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>g</mml:mi><mml:mspace width="2pt"/><mml:msub><mml:mtext>max</mml:mtext><mml:mi>K</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>l</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mrow><mml:msup><mml:mi>t</mml:mi><mml:mo>*</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:mi>K</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula></p>
      <p specific-use="line">34:   <inline-formula id="pone.0224446.e071"><alternatives><graphic xlink:href="pone.0224446.e071.jpg" id="pone.0224446.e071g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M71"><mml:mrow><mml:msup><mml:mi>K</mml:mi><mml:mo>*</mml:mo></mml:msup><mml:mo>=</mml:mo><mml:mtext>arg</mml:mtext><mml:mspace width="2pt"/><mml:msub><mml:mtext>max</mml:mtext><mml:mrow><mml:mi>K</mml:mi><mml:mspace width="4pt"/><mml:mi>s</mml:mi><mml:mo>.</mml:mo><mml:mi>t</mml:mi><mml:mo>.</mml:mo><mml:mspace width="4pt"/><mml:msub><mml:mover accent="true"><mml:mi>l</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mrow><mml:msup><mml:mi>t</mml:mi><mml:mo>*</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mi>K</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:msub><mml:mspace width="4pt"/><mml:mo>-</mml:mo><mml:mspace width="4pt"/><mml:mover accent="true"><mml:mi>σ</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>l</mml:mi><mml:mrow><mml:msup><mml:mi>t</mml:mi><mml:mo>*</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mi>K</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mspace width="4pt"/><mml:mo>≤</mml:mo><mml:mspace width="4pt"/><mml:mspace width="4pt"/><mml:msub><mml:mover accent="true"><mml:mi>l</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mrow><mml:msup><mml:mi>t</mml:mi><mml:mo>*</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:mi>K</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mrow><mml:mo>{</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>c</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mrow><mml:msup><mml:mi>t</mml:mi><mml:mo>*</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:mi>K</mml:mi></mml:mrow></mml:msub><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> % Break ties giving priority to small K’s</p>
      <p specific-use="line">35:</p>
      <p specific-use="line">36:   <bold>return</bold> C<sc>ompute</sc>_dLDA(<italic>GE</italic><sub><italic>t</italic>*</sub>, <italic>K</italic>*)</p>
      <p>As shown at the bottom of Algorithm 4, C<sc>ompute</sc>B<sc>asis</sc> returns the results of C<sc>ompute</sc>_dLDA(<italic>GE</italic><sub><italic>t</italic>*</sub>, <italic>K</italic>*), which are a set of <italic>K</italic>* c_topic–distributions, based on its input <italic>GE</italic><sub><italic>t</italic>*</sub>, which encodes the gene expression values (<inline-formula id="pone.0224446.e072"><alternatives><graphic xlink:href="pone.0224446.e072.jpg" id="pone.0224446.e072g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M72"><mml:msubsup><mml:mi>X</mml:mi><mml:mrow><mml:mi>G</mml:mi><mml:mi>E</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup></mml:math></alternatives></inline-formula>) as non-negative integers. This means C<sc>ompute</sc>B<sc>asis</sc> must first (1) transform its input real-valued gene expression values <inline-formula id="pone.0224446.e073"><alternatives><graphic xlink:href="pone.0224446.e073.jpg" id="pone.0224446.e073g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M73"><mml:msubsup><mml:mi>X</mml:mi><mml:mrow><mml:mi>G</mml:mi><mml:mi>E</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup></mml:math></alternatives></inline-formula> into non-negative integers <italic>GE</italic><sub><italic>t</italic>*</sub>, and (2) determine the appropriate number of c_topics <inline-formula id="pone.0224446.e074"><alternatives><graphic xlink:href="pone.0224446.e074.jpg" id="pone.0224446.e074g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M74"><mml:mrow><mml:msup><mml:mi>K</mml:mi><mml:mo>*</mml:mo></mml:msup><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="script">Z</mml:mi></mml:mrow><mml:mo>+</mml:mo></mml:msup></mml:mrow></mml:math></alternatives></inline-formula>. Task (1) has two parts: (1a) Line 2 first discretizes the real-valued <italic>X</italic><sub><italic>GE</italic></sub> into (positive and negative) integers <inline-formula id="pone.0224446.e075"><alternatives><graphic xlink:href="pone.0224446.e075.jpg" id="pone.0224446.e075g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M75"><mml:mi mathvariant="script">Z</mml:mi></mml:math></alternatives></inline-formula>. (1b) The next part of the subroutine determines the best way to transform those integers into <italic>non-negative integers</italic>
<inline-formula id="pone.0224446.e076"><alternatives><graphic xlink:href="pone.0224446.e076.jpg" id="pone.0224446.e076g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M76"><mml:msup><mml:mrow><mml:mi mathvariant="script">Z</mml:mi></mml:mrow><mml:mrow><mml:mo>≥</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msup></mml:math></alternatives></inline-formula>. Below we describe these three steps, followed by (3) a description of C<sc>ompute</sc>_dLDA.</p>
      <sec id="sec019">
        <title>(1a) D<sc>iscretize</sc> subroutine</title>
        <p>Recall first that the P<sc>re</sc>P<sc>rocess</sc> routine already translated the real-valued <italic>X</italic><sub><italic>GE</italic></sub> gene expression values into z-scores <inline-formula id="pone.0224446.e077"><alternatives><graphic xlink:href="pone.0224446.e077.jpg" id="pone.0224446.e077g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M77"><mml:msubsup><mml:mi>X</mml:mi><mml:mrow><mml:mi>G</mml:mi><mml:mi>E</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup></mml:math></alternatives></inline-formula>, and excluded every genes whose values here all were in (−1, +1). To simplify the notation, view <inline-formula id="pone.0224446.e078"><alternatives><graphic xlink:href="pone.0224446.e078.jpg" id="pone.0224446.e078g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M78"><mml:mrow><mml:msubsup><mml:mi>X</mml:mi><mml:mrow><mml:mi>G</mml:mi><mml:mi>E</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:msubsup><mml:mi>z</mml:mi><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:msubsup><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>. The D<sc>iscretize</sc> routine first assigns each <inline-formula id="pone.0224446.e079"><alternatives><graphic xlink:href="pone.0224446.e079.jpg" id="pone.0224446.e079g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M79"><mml:mrow><mml:msubsup><mml:mi>z</mml:mi><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:msubsup><mml:mo>∈</mml:mo><mml:mspace width="4pt"/><mml:mrow><mml:mo>(</mml:mo><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> to 0. For the remaining “non-trivial” standardized gene expression values <inline-formula id="pone.0224446.e080"><alternatives><graphic xlink:href="pone.0224446.e080.jpg" id="pone.0224446.e080g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M80"><mml:msubsup><mml:mi>z</mml:mi><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula>’s (outside the first standard deviation) of each gene: Letting <inline-formula id="pone.0224446.e081"><alternatives><graphic xlink:href="pone.0224446.e081.jpg" id="pone.0224446.e081g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M81"><mml:mrow><mml:msubsup><mml:mi>Z</mml:mi><mml:mi>i</mml:mi><mml:mo>+</mml:mo></mml:msubsup><mml:mspace width="4pt"/><mml:mo>=</mml:mo><mml:mspace width="4pt"/><mml:mrow><mml:mo>{</mml:mo><mml:mspace width="4pt"/><mml:msubsup><mml:mi>z</mml:mi><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:msubsup><mml:mspace width="4pt"/><mml:mo>|</mml:mo><mml:mspace width="4pt"/><mml:msubsup><mml:mi>z</mml:mi><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:msubsup><mml:mo>≥</mml:mo><mml:mn>1</mml:mn><mml:mspace width="4pt"/><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> be the non-trivial positive values, we divide <inline-formula id="pone.0224446.e082"><alternatives><graphic xlink:href="pone.0224446.e082.jpg" id="pone.0224446.e082g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M82"><mml:mrow><mml:msubsup><mml:mo>Δ</mml:mo><mml:mi>i</mml:mi><mml:mo>+</mml:mo></mml:msubsup><mml:mspace width="4pt"/><mml:mo>=</mml:mo><mml:mspace width="4pt"/><mml:mtext>max</mml:mtext><mml:mrow><mml:mo>{</mml:mo><mml:msubsup><mml:mi>Z</mml:mi><mml:mi>i</mml:mi><mml:mo>+</mml:mo></mml:msubsup><mml:mo>}</mml:mo></mml:mrow><mml:mspace width="4pt"/><mml:mo>-</mml:mo><mml:mspace width="4pt"/><mml:mtext>min</mml:mtext><mml:mrow><mml:mo>{</mml:mo><mml:msubsup><mml:mi>Z</mml:mi><mml:mi>i</mml:mi><mml:mo>+</mml:mo></mml:msubsup><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> into 10 regions, of size <inline-formula id="pone.0224446.e083"><alternatives><graphic xlink:href="pone.0224446.e083.jpg" id="pone.0224446.e083g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M83"><mml:mrow><mml:msubsup><mml:mo>Δ</mml:mo><mml:mi>i</mml:mi><mml:mo>+</mml:mo></mml:msubsup><mml:mo>/</mml:mo><mml:mn>10</mml:mn></mml:mrow></mml:math></alternatives></inline-formula> each and identify each positive <inline-formula id="pone.0224446.e084"><alternatives><graphic xlink:href="pone.0224446.e084.jpg" id="pone.0224446.e084g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M84"><mml:msubsup><mml:mi>z</mml:mi><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> with the index ∈{ 1, 2, …, 10} of the appropriate bin. We similarly divide the non-trivial negative expression values <inline-formula id="pone.0224446.e085"><alternatives><graphic xlink:href="pone.0224446.e085.jpg" id="pone.0224446.e085g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M85"><mml:mrow><mml:msubsup><mml:mi>Z</mml:mi><mml:mi>i</mml:mi><mml:mo>-</mml:mo></mml:msubsup><mml:mspace width="4pt"/><mml:mo>=</mml:mo><mml:mspace width="4pt"/><mml:mrow><mml:mo>{</mml:mo><mml:msubsup><mml:mi>z</mml:mi><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:msubsup><mml:mspace width="4pt"/><mml:mo>|</mml:mo><mml:mspace width="4pt"/><mml:msubsup><mml:mi>z</mml:mi><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:msubsup><mml:mo>≤</mml:mo><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mspace width="4pt"/><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> into their 10 bins, based on <inline-formula id="pone.0224446.e086"><alternatives><graphic xlink:href="pone.0224446.e086.jpg" id="pone.0224446.e086g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M86"><mml:mrow><mml:msubsup><mml:mo>Δ</mml:mo><mml:mi>i</mml:mi><mml:mo>-</mml:mo></mml:msubsup><mml:mspace width="4pt"/><mml:mo>=</mml:mo><mml:mspace width="4pt"/><mml:mtext>max</mml:mtext><mml:mrow><mml:mo>{</mml:mo><mml:msubsup><mml:mi>Z</mml:mi><mml:mi>i</mml:mi><mml:mo>-</mml:mo></mml:msubsup><mml:mo>}</mml:mo></mml:mrow><mml:mo>-</mml:mo><mml:mo form="prefix" movablelimits="true">min</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:msubsup><mml:mi>Z</mml:mi><mml:mi>i</mml:mi><mml:mo>-</mml:mo></mml:msubsup><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> and each negative <inline-formula id="pone.0224446.e087"><alternatives><graphic xlink:href="pone.0224446.e087.jpg" id="pone.0224446.e087g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M87"><mml:msubsup><mml:mi>z</mml:mi><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> is identified with the index ∈{ -1, -2, …, -10} of the appropriate bin; see <xref ref-type="fig" rid="pone.0224446.g004">Fig 4</xref>. (Of course, the actual divisions are specific to the different genes; this figure just shows a generic split.) In general, we let <inline-formula id="pone.0224446.e088"><alternatives><graphic xlink:href="pone.0224446.e088.jpg" id="pone.0224446.e088g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M88"><mml:msubsup><mml:mi>b</mml:mi><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> be the integer bin index associated with gene <italic>g</italic><sub><italic>i</italic></sub> for subject <italic>j</italic>.</p>
        <p>Notes: (1) We initially tried to discretize the values into the bins associated with the standard deviation, in general. However, we found this did not work well. (2) C<sc>ompute</sc>B<sc>asis</sc> also returns these <inline-formula id="pone.0224446.e089"><alternatives><graphic xlink:href="pone.0224446.e089.jpg" id="pone.0224446.e089g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M89"><mml:msub><mml:mrow><mml:mo>{</mml:mo><mml:msubsup><mml:mo>Δ</mml:mo><mml:mi>i</mml:mi><mml:mo>+</mml:mo></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mo>Δ</mml:mo><mml:mi>i</mml:mi><mml:mo>-</mml:mo></mml:msubsup><mml:mo>}</mml:mo></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:math></alternatives></inline-formula> values, as part of the encoding –<italic>i.e</italic>., along with <inline-formula id="pone.0224446.e090"><alternatives><graphic xlink:href="pone.0224446.e090.jpg" id="pone.0224446.e090g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M90"><mml:msub><mml:mover accent="true"><mml:mi>β</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mrow><mml:mi>G</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msub></mml:math></alternatives></inline-formula>—and U<sc>se</sc>B<sc>asis</sc> will later use this information to discretize its real-valued gene expression input. We did not show this detail, to avoid overcluttering the text and images.</p>
      </sec>
      <sec id="sec020">
        <title>(1b) Transform to non-negative integers</title>
        <p>While D<sc>iscretize</sc> mapped each gene expression value <inline-formula id="pone.0224446.e091"><alternatives><graphic xlink:href="pone.0224446.e091.jpg" id="pone.0224446.e091g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M91"><mml:msubsup><mml:mi>z</mml:mi><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> to an integer <inline-formula id="pone.0224446.e092"><alternatives><graphic xlink:href="pone.0224446.e092.jpg" id="pone.0224446.e092g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M92"><mml:msubsup><mml:mi>b</mml:mi><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula>, the <sc>Compute</sc>_d<sc>LDA</sc> routine requires <italic>non-negative</italic> values. Section 4.1.1 discussed two ways to deal with this: using either encoding Enc_A versus Enc_B; see bottom of <xref ref-type="fig" rid="pone.0224446.g004">Fig 4</xref>. C<sc>ompute</sc>B<sc>asis</sc> uses internal cross-validation to determine which of these is best, <italic>t</italic>*, along with the number <italic>K</italic>* of c_topics; see below. (In general, we will let <italic>GE</italic><sub><italic>t</italic></sub> refer to the <italic>t</italic>-encoding of the gene expression values.)</p>
      </sec>
      <sec id="sec021">
        <title>(2) Finding optimal <italic>K</italic>*, <italic>t</italic>*</title>
        <p>As noted, the <sc>Compute</sc>_d<sc>LDA</sc> algorithm also needs to know the number of c_topics <italic>K</italic>* to produce. Rather than guess an arbitrary value, C<sc>ompute</sc>B<sc>asis</sc> instead uses (internal) cross-validation to find the best value for <italic>K</italic>, over the range <italic>K</italic> ∈ {5, 10, 15, …, 150}. For each technique <italic>t</italic> ∈ {Enc_A, Enc_B} and each of the 30 values of <italic>K</italic>, C<sc>ompute</sc>B<sc>asis</sc> first computes the dLDA model over the training set, using C<sc>ompute</sc>_dLDA (for that encoding and number of c_topics); it then used these and the (preprocessed) clinical features (<inline-formula id="pone.0224446.e093"><alternatives><graphic xlink:href="pone.0224446.e093.jpg" id="pone.0224446.e093g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M93"><mml:msubsup><mml:mi>X</mml:mi><mml:mrow><mml:mi>C</mml:mi><mml:mi>F</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup></mml:math></alternatives></inline-formula>) as covariates, along with the survival labels <italic>Lbl</italic>, to learn a Cox model [<xref rid="pone.0224446.ref026" ref-type="bibr">26</xref>]—see Algorithm 1, lines 9–20. Note it does this in-fold—using 4/5 of the training set to learn the dLDA c_topics and the Cox model, which is evaluated by computing the concordance (based on this learned model) on the remaining 1/5 (line 24).</p>
        <p>As noted above, we need to determine (1b) which is the best discretization <italic>t</italic>*, Enc_A or Enc_B, and (2) what is the appropriate <italic>K</italic>* for that technique. To answer the first question, C<sc>ompute</sc>B<sc>asis</sc> picked the encoding technique <italic>t</italic>* that gave the highest cross-validation concordance from all the (30 × 2) combinations (see Algorithm 1, line 31). Secondly, after deciding on a encoding scheme, it sets <inline-formula id="pone.0224446.e094"><alternatives><graphic xlink:href="pone.0224446.e094.jpg" id="pone.0224446.e094g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M94"><mml:mover accent="true"><mml:mi>K</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> to be the value with the largest (cross-validation) likelihood, then selects the set of <italic>K</italic>’s that are smaller than <inline-formula id="pone.0224446.e095"><alternatives><graphic xlink:href="pone.0224446.e095.jpg" id="pone.0224446.e095g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M95"><mml:mover accent="true"><mml:mi>K</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> and whose cross-validation likelihood scores are within the first standard deviation of the <inline-formula id="pone.0224446.e096"><alternatives><graphic xlink:href="pone.0224446.e096.jpg" id="pone.0224446.e096g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M96"><mml:mover accent="true"><mml:mi>K</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula>’s; see Algorithm 1, line 33. From these candidates, it selected the <italic>K</italic>* that gives essentially the highest concordance (see Algorithm 1, line 34). Empirically, we found that the internal cross-validation concordance scores was fairly flat over the critical region—<italic>e.g</italic>., <italic>K</italic> ∈ {20, ‥, 35} for METABRIC—before dipping to smaller values for larger value of K, presumably due to overfitting. This is why we are confident that the upper limit, of 150 topics, is sufficient. Once it finds the best <italic>K</italic>* and the encoding technique <italic>t</italic>*, C<sc>ompute</sc>B<sc>asis</sc> then runs <sc>Compute</sc>_d<sc>LDA</sc> on the <italic>t</italic>*-encoded (preprocessed) training gene expression data <italic>GE</italic><sub><italic>t</italic>*</sub>, seeking <italic>K</italic>* c_topics; this is <inline-formula id="pone.0224446.e097"><alternatives><graphic xlink:href="pone.0224446.e097.jpg" id="pone.0224446.e097g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M97"><mml:msub><mml:mover accent="true"><mml:mi>β</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mrow><mml:mi>G</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msub></mml:math></alternatives></inline-formula> “basis”. This routine also returns the <inline-formula id="pone.0224446.e098"><alternatives><graphic xlink:href="pone.0224446.e098.jpg" id="pone.0224446.e098g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M98"><mml:mrow><mml:mo>{</mml:mo><mml:msubsup><mml:mo>Δ</mml:mo><mml:mi>i</mml:mi><mml:mo>±</mml:mo></mml:msubsup><mml:mo>}</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> values used to produce the discretized values, <italic>GE</italic><sub><italic>t</italic></sub>.</p>
      </sec>
      <sec id="sec022">
        <title>(3) C<sc>ompute</sc>_dLDA</title>
        <p>The C<sc>ompute</sc>_dLDA(<italic>GE</italic><sub><italic>t</italic></sub>, <italic>K</italic>) process, based on Blei <italic>et al</italic>. [<xref rid="pone.0224446.ref017" ref-type="bibr">17</xref>], computes <italic>K</italic> c_topics, based on the preprocessed, discretized gene expression data <italic>GE</italic><sub><italic>t</italic></sub>, as well as the number of latent c_topics <italic>K</italic>; it then returns <italic>K</italic> c_topics–distributions, each ≈50,000-parameters of the Dirichlet distribution (for METABRIC), corresponding to a line of the <inline-formula id="pone.0224446.e099"><alternatives><graphic xlink:href="pone.0224446.e099.jpg" id="pone.0224446.e099g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M99"><mml:msub><mml:mover accent="true"><mml:mi>β</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mrow><mml:mi>G</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msub></mml:math></alternatives></inline-formula> shown in <xref ref-type="fig" rid="pone.0224446.g005">Fig 5</xref>. (Each point here corresponds to its estimate of the posterior <italic>β</italic><sub><italic>GE</italic></sub>, conditioned on the observed gene expression values.) This routine also uses the Dirichlet prior for the patient–c_topics distribution; here we used the symmetric Dirichlet(<italic>α</italic>, …, <italic>α</italic>) for some <italic>α</italic> ∈ ℜ<sup>&gt;0</sup>. (As there are <italic>K</italic> c_topics; we view this as a vector <italic>α</italic><bold>1</bold><sub><italic>K</italic></sub>.) We experimented with several values <italic>α</italic> ∈ {0.01, 0.1, 0.5, 1.0}, but found that the prior did not make much difference, since we allowed the model to estimate the prior internally. We therefore set <italic>α</italic> = 0.1.</p>
        <p>This routines also needs to set the priors for the <italic>K</italic> different c_topic–gene_expression distributions <inline-formula id="pone.0224446.e100"><alternatives><graphic xlink:href="pone.0224446.e100.jpg" id="pone.0224446.e100g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M100"><mml:mrow><mml:msubsup><mml:mi>β</mml:mi><mml:mrow><mml:mi>G</mml:mi><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mo>*</mml:mo><mml:mo>)</mml:mo></mml:mrow></mml:msubsup><mml:mrow><mml:mo>[</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mo>:</mml:mo><mml:mo>]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:msubsup><mml:mi>β</mml:mi><mml:mrow><mml:mi>G</mml:mi><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mo>*</mml:mo><mml:mo>)</mml:mo></mml:mrow></mml:msubsup><mml:mrow><mml:mo>[</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>]</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msubsup><mml:mi>β</mml:mi><mml:mrow><mml:mi>G</mml:mi><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mo>*</mml:mo><mml:mo>)</mml:mo></mml:mrow></mml:msubsup><mml:mrow><mml:mo>[</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>N</mml:mi><mml:mo>]</mml:mo></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>, for <italic>i</italic> = 1‥<italic>K</italic>, each sweeping over the <italic>N</italic> genes. Here, we use the prior <inline-formula id="pone.0224446.e101"><alternatives><graphic xlink:href="pone.0224446.e101.jpg" id="pone.0224446.e101g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M101"><mml:mrow><mml:msubsup><mml:mi>β</mml:mi><mml:mrow><mml:mi>G</mml:mi><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mo>*</mml:mo><mml:mo>)</mml:mo></mml:mrow></mml:msubsup><mml:mrow><mml:mo>[</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>]</mml:mo></mml:mrow><mml:mspace width="4pt"/><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:mo>+</mml:mo><mml:mi>δ</mml:mi></mml:mrow></mml:math></alternatives></inline-formula> where <italic>δ</italic> ∼ <italic>U</italic>[0, 1/<italic>N</italic><sup>2</sup>]—<italic>i.e</italic>., <italic>δ</italic> is sampled from the uniform distribution over the interval [0, 1/<italic>N</italic><sup>2</sup>]. This LDA learning process [<xref rid="pone.0224446.ref017" ref-type="bibr">17</xref>] uses the data in <italic>GE</italic><sub><italic>t</italic></sub> to compute the posterior distribution {<italic>β</italic><sub><italic>GE</italic></sub>[<italic>i</italic>,:]}<sub><italic>i</italic></sub> for each of these <italic>K</italic> c_topics—revealing <italic>GE</italic><sub><italic>t</italic></sub>’s intrinsic structure. Recall these are just the parameters for Dirichlet distribution; note they must be positive, but do not add up to 1. The C<sc>ompute</sc>_dLDA returns the expected values of the gene expression values drawn from this posterior distribution: <inline-formula id="pone.0224446.e102"><alternatives><graphic xlink:href="pone.0224446.e102.jpg" id="pone.0224446.e102g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M102"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>β</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mrow><mml:mi>G</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>[</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>G</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>[</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mo>∑</mml:mo><mml:msup><mml:mi>j</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:msub><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>G</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>[</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mi>j</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:math></alternatives></inline-formula>. Here, the probability values for each c_topic <inline-formula id="pone.0224446.e103"><alternatives><graphic xlink:href="pone.0224446.e103.jpg" id="pone.0224446.e103g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M103"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>β</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mrow><mml:mi>G</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>[</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mo>:</mml:mo><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> add up to 1. We will let <inline-formula id="pone.0224446.e104"><alternatives><graphic xlink:href="pone.0224446.e104.jpg" id="pone.0224446.e104g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M104"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>β</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mrow><mml:mi>G</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>β</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mrow><mml:mi>G</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>[</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mo>:</mml:mo><mml:mo>]</mml:mo></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> refer to the entire “matrix”.</p>
      </sec>
    </sec>
    <sec id="sec023">
      <title>A.3 U<sc>se</sc>B<sc>asis</sc><sub>[<italic>ρ</italic>=dLDA]</sub></title>
      <p>Once LSM has learned the c_topics (<inline-formula id="pone.0224446.e105"><alternatives><graphic xlink:href="pone.0224446.e105.jpg" id="pone.0224446.e105g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M105"><mml:msub><mml:mover accent="true"><mml:mi>β</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mrow><mml:mi>G</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msub></mml:math></alternatives></inline-formula>) for the best <italic>K</italic>* and best encoding technique <italic>t</italic>*, we can then compute the c_topic distribution for a new patient (based on her gene expression <italic>x</italic><sub><italic>GE</italic></sub>); see Figs <xref ref-type="fig" rid="pone.0224446.g003">3</xref> and <xref ref-type="fig" rid="pone.0224446.g006">6</xref>. This will call U<sc>se</sc>B<sc>asis</sc>, which in turn runs U<sc>se_d</sc>LDA (the <italic>LDA inference procedure</italic>) on the preprocessed gene expression data <inline-formula id="pone.0224446.e106"><alternatives><graphic xlink:href="pone.0224446.e106.jpg" id="pone.0224446.e106g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M106"><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>G</mml:mi><mml:mi>E</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup></mml:math></alternatives></inline-formula> of the current patient to compute the individual topic contributions for this patient [<xref rid="pone.0224446.ref017" ref-type="bibr">17</xref>]. The inference procedure determines the posterior distribution of the <bold>patient-c_topic</bold> Dirichlet distribution <inline-formula id="pone.0224446.e107"><alternatives><graphic xlink:href="pone.0224446.e107.jpg" id="pone.0224446.e107g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M107"><mml:mrow><mml:mo>Θ</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>G</mml:mi><mml:mi>E</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup><mml:mo>)</mml:mo></mml:mrow><mml:mspace width="4pt"/><mml:mo>=</mml:mo><mml:mspace width="4pt"/><mml:mrow><mml:mo>[</mml:mo><mml:mspace width="0.166667em"/><mml:msub><mml:mi>θ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>G</mml:mi><mml:mi>E</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mspace width="4pt"/><mml:msub><mml:mi>θ</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>G</mml:mi><mml:mi>E</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mspace width="4pt"/><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mspace width="4pt"/><mml:msub><mml:mi>θ</mml:mi><mml:msup><mml:mi>K</mml:mi><mml:mo>*</mml:mo></mml:msup></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>G</mml:mi><mml:mi>E</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup><mml:mo>)</mml:mo></mml:mrow><mml:mspace width="0.166667em"/><mml:mo>]</mml:mo></mml:mrow><mml:mspace width="4pt"/><mml:mo>∈</mml:mo><mml:mspace width="4pt"/><mml:msubsup><mml:mi>ℜ</mml:mi><mml:mo>+</mml:mo><mml:msup><mml:mi>K</mml:mi><mml:mo>*</mml:mo></mml:msup></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>, where each <inline-formula id="pone.0224446.e108"><alternatives><graphic xlink:href="pone.0224446.e108.jpg" id="pone.0224446.e108g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M108"><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>G</mml:mi><mml:mi>E</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup><mml:mo>)</mml:mo></mml:mrow><mml:mspace width="4pt"/><mml:mo>∈</mml:mo><mml:mspace width="4pt"/><mml:msub><mml:mi>ℜ</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> quantifies how much of this patient’s gene expression is from the <italic>j</italic><sup><italic>th</italic></sup> c_topic (using the posterior mean probabilities of the c_topics, <inline-formula id="pone.0224446.e109"><alternatives><graphic xlink:href="pone.0224446.e109.jpg" id="pone.0224446.e109g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M109"><mml:msub><mml:mover accent="true"><mml:mi>β</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mrow><mml:mi>G</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msub></mml:math></alternatives></inline-formula>).</p>
      <p>This process reduces the ≈20 000-dimension gene expression values to a very small <italic>K</italic>*-dimensional c_topics representation—<italic>e.g</italic>., <italic>L</italic>* = 30. These low-dimensional feature vectors are then used in the survival prediction algorithms to predict survival times/risk.</p>
    </sec>
    <sec id="sec024">
      <title>A.4 C<sc>ompute</sc>B<sc>asis</sc><sub>[<italic>ρ</italic>=PCA]</sub> and U<sc>se</sc>B<sc>asis</sc><sub>[<italic>ρ</italic>=PCA]</sub></title>
      <p>The previous subappendix described one way to reduce the dimensionality of the data—to transform each patient’s 20,000-tuple to a more manageable <italic>K</italic>-tuple—there based on topic modeling ideas. There have been many other feature selection methods proposed for survival prediction using gene expression data, such as hierarchical clustering, univariate gene selection, supervised PCA, penalized Cox regression and tree-based ensemble methods [<xref rid="pone.0224446.ref034" ref-type="bibr">34</xref>]. Some of these techniques first apply a procedure to reduce the dimensionality of the data, based on feature selection, feature extraction or a combination of both, while others, such as random survival forests [<xref rid="pone.0224446.ref009" ref-type="bibr">9</xref>] and L1-penalized Cox [<xref rid="pone.0224446.ref035" ref-type="bibr">35</xref>], include internal feature selection. As we wanted to compare our dLDA approach to other dimensionality reduction techniques, we chose an extension to the principle component analysis called supervised principal component analysis (SuperPC) [<xref rid="pone.0224446.ref036" ref-type="bibr">36</xref>], instead of other regularization techniques.</p>
      <p>This algorithm first calculates the univariate Cox score statistic of each individual gene against the survival time, then retains just the subset of genes whose score exceeds a threshold, determined by internal cross-validation. Then it computes PCA on the dataset containing only those selected genes, then projects each patient onto the first one (or two) components. The main disadvantage of the SuperPC algorithm is that the individual genes selected from the univariate selection process might not perform the best in a multivariate (final) model, perhaps because many of these top-ranked genes may be highly correlated with one another –<italic>i.e</italic>., it would be better having a more “diverse” set of genes [<xref rid="pone.0224446.ref034" ref-type="bibr">34</xref>, <xref rid="pone.0224446.ref037" ref-type="bibr">37</xref>]. Instead, we use a variant, called SuperPC+, that initially applies PCA on the <italic>normalized</italic> gene expression data after the constant genes are removed; see P<sc>re</sc>P<sc>rocess</sc>in Appendix A.1). The PCA transformation projects the initial “raw” features into a different space, which then can be used to select the top components based on the univariate Cox regression. Note this SuperPC+ is (still) computationally efficient, as it is based on PCA, which is efficient: Even though gene expression data is high dimensional (<italic>p</italic> ≫ <italic>n</italic>, where <italic>p</italic> is the number of genes and <italic>n</italic> is the number of instances), the rank of the GE matrix will be (at most) min{<italic>p</italic>, <italic>n</italic>} = <italic>n</italic>. Therefore, PCA can be performed without many computational restraints on the whole gene expression dataset, as here the PCA time complexity is <italic>O</italic>(<italic>n</italic><sup>3</sup>). After performing PCA on the GE dataset, we can then identify the most important principal components by computing a Cox score statistic for the univariate association between each principal component and the survival time. In our experiments, we select the threshold <italic>η</italic> for the p-value of the Cox score by internal cross-validation (wrt concordance), and retained all PCs having a p-value lower than this <italic>η</italic>—finding <italic>η</italic> = 5e-4 for the METABRIC dataset and <italic>η</italic> = 5e-2 for KIPAN. These selected PC components form the basis set <italic>B</italic><sub><italic>GE</italic></sub>[<italic>ρ</italic> = PCA].</p>
      <p>U<sc>se</sc>B<sc>asis</sc><sub>[<italic>ρ</italic>=PCA]</sub> is simply the projection of the gene expression data into the chosen PC components. This gives us a low dimensional feature representation of the original gene expression data to feed into the survival prediction algorithms.</p>
    </sec>
    <sec id="sec025">
      <title>A.5 Cox models: L<sc>earn</sc>M<sc>odel</sc><sub>[Ψ=Cox]</sub>, L<sc>earn</sc>M<sc>odel</sc><sub>[Ψ=RCox]</sub></title>
      <p>The Cox regression model’s [<xref rid="pone.0224446.ref026" ref-type="bibr">26</xref>] hazard function over time <italic>t</italic>, for an individual described by <italic>x</italic>, is the product of two components:
<disp-formula id="pone.0224446.e110"><alternatives><graphic xlink:href="pone.0224446.e110.jpg" id="pone.0224446.e110g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M110"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>h</mml:mi><mml:mi>W</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mspace width="0.166667em"/><mml:mi>t</mml:mi><mml:mspace width="0.166667em"/><mml:mo>|</mml:mo><mml:mspace width="0.166667em"/><mml:mi>x</mml:mi><mml:mspace width="0.166667em"/><mml:mo>)</mml:mo></mml:mrow><mml:mspace width="1.em"/><mml:mo>=</mml:mo><mml:mspace width="1.em"/><mml:msub><mml:mi>h</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>×</mml:mo><mml:mtext>exp</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi>x</mml:mi><mml:mi>T</mml:mi></mml:msup><mml:mi>W</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(3)</label></disp-formula>
where the baseline hazard <italic>h</italic><sub>0</sub>(<italic>t</italic>) is independent of the covariates <italic>x</italic> and the covariates are (independently) multiplicatively related to the hazard, based on a (learned) <italic>W</italic>. This formulation simplifies modeling of the hazard function by limiting the contribution of the “time” variable <italic>t</italic> to the baseline hazard <italic>h</italic><sub>0</sub>(⋅), which means the hazard ratio (HR) between two patients
<disp-formula id="pone.0224446.e111"><alternatives><graphic xlink:href="pone.0224446.e111.jpg" id="pone.0224446.e111g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M111"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mtext>HR</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mspace width="0.166667em"/><mml:msub><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mspace width="4pt"/><mml:mo>=</mml:mo><mml:mspace width="4pt"/><mml:mfrac><mml:mrow><mml:mi>h</mml:mi><mml:mo>(</mml:mo><mml:mspace width="0.166667em"/><mml:mi>t</mml:mi><mml:mspace width="0.166667em"/><mml:mo>|</mml:mo><mml:mspace width="0.166667em"/><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mspace width="0.166667em"/><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>h</mml:mi><mml:mo>(</mml:mo><mml:mspace width="0.166667em"/><mml:mi>t</mml:mi><mml:mspace width="0.166667em"/><mml:mo>|</mml:mo><mml:mspace width="0.166667em"/><mml:msub><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mspace width="0.166667em"/><mml:mo>)</mml:mo></mml:mrow></mml:mfrac><mml:mspace width="4pt"/><mml:mo>=</mml:mo><mml:mspace width="4pt"/><mml:mfrac><mml:mrow><mml:msub><mml:mi>h</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mspace width="2pt"/><mml:mtext>exp</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi>x</mml:mi><mml:mn>1</mml:mn><mml:mi>T</mml:mi></mml:msubsup><mml:mi>W</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mi>h</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mspace width="2pt"/><mml:mtext>exp</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi>x</mml:mi><mml:mn>2</mml:mn><mml:mi>T</mml:mi></mml:msubsup><mml:mi>W</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mspace width="4pt"/><mml:mo>=</mml:mo><mml:mspace width="4pt"/><mml:mtext>exp</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:mi>W</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
does not depend on time and is linear (proportional) in the exponent. To estimate the coefficients of the model, Cox [<xref rid="pone.0224446.ref026" ref-type="bibr">26</xref>] proposed a partial likelihood technique that eliminates the need to estimate the baseline hazard. This procedure allows the Cox proportional hazards model to be semi-parametric, by only using the survival times to rank the patients [<xref rid="pone.0224446.ref032" ref-type="bibr">32</xref>]. We can compute partial likelihood with all patients—both censored and uncensored:
<disp-formula id="pone.0224446.e112"><alternatives><graphic xlink:href="pone.0224446.e112.jpg" id="pone.0224446.e112g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M112"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>W</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munderover><mml:mo>∏</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:mtext>exp</mml:mtext><mml:mo>(</mml:mo><mml:msup><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:mi>W</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>∈</mml:mo><mml:mi mathvariant="script">R</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:msub><mml:mtext>exp</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:mi>W</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:msup><mml:mo>)</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:msup></mml:mrow></mml:math></alternatives><label>(4)</label></disp-formula>
<list list-type="bullet"><list-item><p><inline-formula id="pone.0224446.e113"><alternatives><graphic xlink:href="pone.0224446.e113.jpg" id="pone.0224446.e113g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M113"><mml:mrow><mml:mi mathvariant="script">R</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> is the risk set at time <italic>y</italic><sub><italic>j</italic></sub>, which are the indices of individuals who are alive and not censored before time <italic>y</italic><sub><italic>j</italic></sub></p></list-item><list-item><p>[<italic>x</italic><sub><italic>i</italic></sub>, <italic>y</italic><sub><italic>i</italic></sub>, <italic>δ</italic><sub><italic>i</italic></sub>] describes the <italic>i</italic><sup><italic>th</italic></sup> subject, where</p><p> <italic>x</italic><sub><italic>i</italic></sub> = vector of covariates</p><p> <italic>y</italic><sub><italic>i</italic></sub> = (survival or censor) time</p><p> <italic>δ</italic><sub><italic>i</italic></sub> = censor bit (0 for censored; otherwise 1)</p></list-item><list-item><p><italic>N</italic>—total number of patients in the cohort</p></list-item><list-item><p><italic>W</italic>—coefficients (to be learned)</p></list-item></list></p>
      <p>Note that only the uncensored likelihoods contribute directly, since for censored instances <italic>δ</italic><sub><italic>i</italic></sub> = 0. Therefore the censored observations are only utilized in the denominator when summed over the instances in a risk set. In essence, the partial likelihood only uses the patient’s death times to rank them in the ascending order to find the risk sets and does not use the exact times explicitly [<xref rid="pone.0224446.ref032" ref-type="bibr">32</xref>]. Hence, the coefficients estimated by maximizing the partial likelihood depend only on the ordering of the patient’s death times and the covariates, allowing for an implicit optimization for good concordance of the risk score. An in-depth study on the Cox proportional hazard model has revealed that the partial likelihood proposed by [<xref rid="pone.0224446.ref026" ref-type="bibr">26</xref>] is approximately equivalent to optimizing concordance [<xref rid="pone.0224446.ref032" ref-type="bibr">32</xref>].</p>
      <p>There are several extensions of the basic Cox proportional hazards model: some extend the initial model estimating the baseline hazard and others are based on the regularization methods imposed on the coefficients (<italic>W</italic>). Generally, regularization based on LASSO, ridge penalty or the elastic-net regularization (which allows both L1 and L2 penalties) are adopted to reduce overfitting. In our work, we use the <monospace>glmnet</monospace> R package [<xref rid="pone.0224446.ref033" ref-type="bibr">33</xref>] with ridge penalty (by setting <italic>α</italic> = 0 in the glmnet function); here called RCox. We selected ridge penalty based on the internal cross validation. We found that concordance results using models with ridge penalty were better than those having no regularization (LASSO, elastic-net).</p>
    </sec>
  </sec>
  <sec id="sec026">
    <title>B Foundations</title>
    <sec id="sec027">
      <title>B.1 Evaluation: Concordance Index (CI)</title>
      <p>This “CI” evaluation applies to any model that assigns a real number—a “risk score”—to each instance <italic>f</italic>(⋅). It considers all pairs of “comparable” instances, and determines which is predicted (by the risk model <italic>f</italic>(⋅)) to die first, and also who actually died first. CI is the proportion (probability) of these pairs of instances whose actual pair-wise survival ordering, matches the predicted ordering, with respect to <italic>f</italic>(⋅):
<disp-formula id="pone.0224446.e114"><alternatives><graphic xlink:href="pone.0224446.e114.jpg" id="pone.0224446.e114g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M114"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mtext>CI</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mi>f</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mo>|</mml:mo><mml:mo>Ψ</mml:mo><mml:mo>|</mml:mo></mml:mrow></mml:mfrac><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>)</mml:mo><mml:mo>∈</mml:mo><mml:mo>Ψ</mml:mo></mml:mrow></mml:munder><mml:mi>I</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mspace width="0.166667em"/><mml:mrow><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>&gt;</mml:mo><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mspace width="0.166667em"/><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(5)</label></disp-formula>
where <italic>I</italic>[<italic>ϕ</italic>] is the indicator function, which is 1 if the proposition <italic>ϕ</italic> is true, and 0 otherwise. A pair of patients is “comparable” if we can determine which died first –<italic>i.e</italic>., if both are uncensored, or when one patient is censored after the observed death time of the other; this corresponds to the set of ordered pairs of indices Ψ. This CI(<italic>f</italic>) score is a real value between 0 to 1, where 1 means all comparable pairs are predicted correctly. CI can be viewed as a general form of the Mann–Whitne–Wilcoxon statistic and is similar to the Area Under the ROC (Receiver Operator Curve), AUC, of classification problems [<xref rid="pone.0224446.ref032" ref-type="bibr">32</xref>].</p>
    </sec>
    <sec id="sec028">
      <title>B.2 Evaluation: D-calibration</title>
      <p>The concordance index is a discriminatory measure, which is relevant, for example, when deciding which patient with liver failure will die first without a transplant. By contrast, <italic>calibration</italic> measures the deviation between the observed and the predicted event time distributions. While this is not meaningful if we only have a risk score (<italic>e.g</italic>., as produced by the basic Cox Proportional Hazard function), this deviation can be computed for a <italic>survival distribution</italic>, like ones produced by the MTLR survival prediction tool, or the Cox+KF system—which extends the standard Cox model by using the Kalbfleisch-Prentice estimator to produce the baseline hazard function <italic>h</italic><sub>0</sub>(<italic>x</italic>) in <xref ref-type="disp-formula" rid="pone.0224446.e110">Eq 3</xref>; see [<xref rid="pone.0224446.ref011" ref-type="bibr">11</xref>]. In general, this calibration involves computing the difference between the predicted versus observed probabilities in various subgroups—<italic>e.g</italic>., if the predicted probability of surviving at least <italic>t</italic> = 2576 days is 0.75 for some subgroup, then we expect to observe around 75% of these patients to be alive at this time <italic>t</italic>.</p>
      <p>We consider a novel measure of the calibration of such survival curves, called D-calibration (“D” for “Distribution”) [<xref rid="pone.0224446.ref016" ref-type="bibr">16</xref>]. To motivate this, consider a standard Kaplan-Meier (KM) [<xref rid="pone.0224446.ref008" ref-type="bibr">8</xref>] plot shown in <xref ref-type="fig" rid="pone.0224446.g009">Fig 9</xref>, which plots the set of points (<italic>t</italic>, KM(<italic>t</italic>))—<italic>i.e</italic>., it predicts that the KM(<italic>t</italic>) fraction of patients will be alive at each time <italic>t</italic> ≥ 0. Hence, the point (6184 days, 0.50) means the median survival time of the cohort is 6184 days; see <xref ref-type="fig" rid="pone.0224446.g009">Fig 9</xref>(solid line). We will use KM<sup>−1</sup>(<italic>p</italic>) to be the time associated with the probability <italic>p</italic>—technically, KM<sup>−1</sup>(<italic>p</italic>) is the earliest time when the KM curve hits <italic>p</italic>; hence KM<sup>−1</sup>(<italic>p</italic>) (0.5) = 6184 days. If this plot is D-calibrated, then around 50% of the patients (from a hold-out set, not used to produce the KM curve) will be alive at this median time. So if we (for now) ignore censored patients, and let <italic>d</italic><sub><italic>i</italic></sub> be the time when the <italic>i</italic><sup><italic>th</italic></sup> patient died, consider the <italic>n</italic> values of {KM(<italic>d</italic><sub><italic>i</italic></sub>)}<sub><italic>i</italic>=1‥<italic>n</italic></sub>. Here, we expect KM(<italic>d</italic><sub><italic>i</italic></sub>) &gt; 0.5 for 1/2 of the patients. Similarly, as the curve includes (2576 days, 0.75) and (8941 days, 0.25), then we expect 75% to be alive at 2576 days, and 25% at 8941 days; see <xref ref-type="fig" rid="pone.0224446.g009">Fig 9</xref>. Collectively, this means we expect 25% of the patients to die between KM<sup>−1</sup> (1.0) = 0 days and KM<sup>−1</sup> (0.75) = 2576 days, and another 25% between KM<sup>−1</sup> (0.75) and KM<sup>−1</sup> (0.5), etc. These are the predictions; we can also check, to see how many people actually died in each interval: in the first quartile (between 0 and 2576 days), in the second (between 2576 and 6184 days), in the third (between 6184 and 8941 days), and the fourth (after 8941 days). If the KM plot is “correct”—<italic>i.e</italic>., is D-calibrated—then we expect 1/4 of the patients will die in each of these 4 intervals. The argument above means we expect 1/4 of the {KM(d<sub><italic>i</italic></sub>)} values to be in the interval [0, 0.25], and another quarter to be in [0.25, 0.5], etc. Stated more precisely,
<disp-formula id="pone.0224446.e115"><alternatives><graphic xlink:href="pone.0224446.e115.jpg" id="pone.0224446.e115g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M115"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mtext>the</mml:mtext><mml:mspace width="4.pt"/><mml:mtext>values</mml:mtext><mml:mspace width="4.pt"/><mml:mtext>of</mml:mtext><mml:mspace width="4.pt"/><mml:mrow><mml:mo>{</mml:mo><mml:mspace width="0.166667em"/><mml:mtext>KM</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mspace width="0.166667em"/><mml:msub><mml:mi>d</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mspace width="0.166667em"/><mml:mo>)</mml:mo></mml:mrow><mml:mspace width="0.166667em"/><mml:mo>}</mml:mo></mml:mrow><mml:mspace width="4.pt"/><mml:mtext>are</mml:mtext><mml:mspace width="4.pt"/><mml:mtext>uniformly</mml:mtext><mml:mspace width="4.pt"/><mml:mtext>distributed.</mml:mtext></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(6)</label></disp-formula></p>
      <fig id="pone.0224446.g009" orientation="portrait" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pone.0224446.g009</object-id>
        <label>Fig 9</label>
        <caption>
          <title>Kaplan–Meier survival function from METABRIC (training) data.</title>
          <p>(We only use the quartiles for pedagogic purposes.).</p>
        </caption>
        <graphic xlink:href="pone.0224446.g009"/>
      </fig>
      <p>A single KM curve is designed to represent a cohort of many patients. The MTLR system, however, computes a different survival curve for each patient—call it <italic>Pr</italic><sub><italic>i</italic></sub>(·) = <italic>Pr</italic><sub><italic>W</italic></sub> (· | <bold>x</bold><sub><italic>i</italic></sub>) (from <xref ref-type="disp-formula" rid="pone.0224446.e001">Eq 1</xref>). But the same ideas still apply: Each of these patients has a median predicted survival time—the time <inline-formula id="pone.0224446.e116"><alternatives><graphic xlink:href="pone.0224446.e116.jpg" id="pone.0224446.e116g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M116"><mml:mrow><mml:mi>P</mml:mi><mml:msubsup><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mn>0</mml:mn><mml:mo>.</mml:mo><mml:mn>5</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> where its <italic>Pr</italic><sub><italic>i</italic></sub>(⋅) curve crosses 0.50.</p>
      <p>By the same argument suggested above, we expect (for a good model <italic>W</italic>) that 1/2 of patients will die before their respective median survival time—<inline-formula id="pone.0224446.e117"><alternatives><graphic xlink:href="pone.0224446.e117.jpg" id="pone.0224446.e117g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M117"><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>≤</mml:mo><mml:mi>P</mml:mi><mml:msubsup><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mn>0</mml:mn><mml:mo>.</mml:mo><mml:mn>5</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>; that is, |{<italic>i</italic>: <italic>Pr</italic><sub><italic>i</italic></sub>(<italic>d</italic><sub><italic>i</italic></sub>) ≤ 0.5}| ≈ <italic>n</italic>/2. Continuing the arguments from above, we therefore expect the obvious analogue to <xref ref-type="disp-formula" rid="pone.0224446.e115">Eq 6</xref>:
<disp-formula id="pone.0224446.e118"><alternatives><graphic xlink:href="pone.0224446.e118.jpg" id="pone.0224446.e118g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M118"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mtext>the</mml:mtext><mml:mspace width="4.pt"/><mml:mtext>values</mml:mtext><mml:mspace width="4.pt"/><mml:mtext>of</mml:mtext><mml:mspace width="4.pt"/><mml:mrow><mml:mo>{</mml:mo><mml:mi>P</mml:mi><mml:msub><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mspace width="0.166667em"/><mml:msub><mml:mi>d</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mspace width="0.166667em"/><mml:mo>)</mml:mo></mml:mrow><mml:mo>}</mml:mo></mml:mrow><mml:mspace width="4.pt"/><mml:mtext>are</mml:mtext><mml:mspace width="4.pt"/><mml:mtext>uniform.</mml:mtext></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(7)</label></disp-formula></p>
      <p>We can now test whether a model is D-calibrated by using the Hosmer-Lemeshow (HL) [<xref rid="pone.0224446.ref030" ref-type="bibr">30</xref>] goodness-of-fit test, which compares the difference between the predicted and observed events in the event subgroups:
<disp-formula id="pone.0224446.e119"><alternatives><graphic xlink:href="pone.0224446.e119.jpg" id="pone.0224446.e119g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M119"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mtext>HL</mml:mtext><mml:mo>(</mml:mo><mml:mspace width="4pt"/><mml:mo>[</mml:mo><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mo>[</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mspace width="4pt"/><mml:msub><mml:mi>P</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mspace width="4pt"/><mml:msub><mml:mi>E</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>]</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>⋯</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mrow/><mml:mo>[</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mi>G</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mspace width="4pt"/><mml:msub><mml:mi>P</mml:mi><mml:mi>G</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mspace width="4pt"/><mml:msub><mml:mi>E</mml:mi><mml:mi>G</mml:mi></mml:msub><mml:mo>]</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable><mml:mo>]</mml:mo><mml:mo>)</mml:mo><mml:mspace width="1.em"/><mml:mo>=</mml:mo><mml:mspace width="1.em"/><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>g</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>G</mml:mi></mml:munderover><mml:mfrac><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>E</mml:mi><mml:mi>g</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mi>g</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi>g</mml:mi></mml:msub><mml:msub><mml:mi>π</mml:mi><mml:mi>g</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msub><mml:mi>π</mml:mi><mml:mi>g</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(8)</label></disp-formula>
where <italic>G</italic> is the number of subgroups (here 4), where the <italic>g</italic><sup><italic>th</italic></sup> subgroup has <inline-formula id="pone.0224446.e120"><alternatives><graphic xlink:href="pone.0224446.e120.jpg" id="pone.0224446.e120g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M120"><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi>g</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mi mathvariant="double-struck">Z</mml:mi><mml:mo>+</mml:mo></mml:msup></mml:mrow></mml:math></alternatives></inline-formula> events, with the empirical number of events <inline-formula id="pone.0224446.e121"><alternatives><graphic xlink:href="pone.0224446.e121.jpg" id="pone.0224446.e121g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M121"><mml:mrow><mml:msub><mml:mi>E</mml:mi><mml:mi>g</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mi mathvariant="double-struck">Z</mml:mi><mml:mo>+</mml:mo></mml:msup></mml:mrow></mml:math></alternatives></inline-formula> (which here is <italic>N</italic>/<italic>g</italic>, for <italic>N</italic> = ∑<sub><italic>g</italic></sub>
<italic>N</italic><sub><italic>g</italic></sub> total patients), the corresponding predicted number of events in each group <inline-formula id="pone.0224446.e122"><alternatives><graphic xlink:href="pone.0224446.e122.jpg" id="pone.0224446.e122g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M122"><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mi>g</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mi mathvariant="double-struck">Z</mml:mi><mml:mrow><mml:mo>≥</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></alternatives></inline-formula>, and <inline-formula id="pone.0224446.e123"><alternatives><graphic xlink:href="pone.0224446.e123.jpg" id="pone.0224446.e123g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M123"><mml:mrow><mml:msub><mml:mi>π</mml:mi><mml:mi>g</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:msub><mml:mi>N</mml:mi><mml:mi>g</mml:mi></mml:msub><mml:mi>N</mml:mi></mml:mfrac></mml:mrow></mml:math></alternatives></inline-formula> (which here is <inline-formula id="pone.0224446.e124"><alternatives><graphic xlink:href="pone.0224446.e124.jpg" id="pone.0224446.e124g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M124"><mml:mfrac><mml:mn>1</mml:mn><mml:mi>G</mml:mi></mml:mfrac></mml:math></alternatives></inline-formula>) is the proportion of the <italic>g</italic><sup><italic>th</italic></sup> subgroup. Under the null hypothesis (<xref ref-type="disp-formula" rid="pone.0224446.e118">Eq 7</xref>), this HL statistics follows a Chi-Square distribution with <italic>G</italic> − 2 degrees of freedom. If the predicted and empirical event rates are similar for the subgroups, the test statistic will fail to reject the null hypothesis, providing evidence that the model’s predictions are well D-calibrated—<italic>i.e</italic>., large p-values from the test statistic suggest not rejecting the null hypothesis).</p>
      <p>Notes: (1) This evaluation criterion only applies to models that produce survival distributions, which means it directly applies to the MTLR models. For the Cox and RCox models, we used the Kalbfleisch-Prentice baseline hazard estimator [<xref rid="pone.0224446.ref011" ref-type="bibr">11</xref>] to produce personalized survival curves. (2) To provide more precise evaluation, rather than using 4 bins (quantiles), we mapped the <italic>Pr</italic><sub><italic>i</italic></sub>(<italic>d</italic><sub><italic>i</italic></sub>) probabilities into 20 bins: [0, 0.05); [0.05, 0.1), …, [0.95, 1.0]. (3) This analysis deals only with uncensored data; Haider <italic>et al</italic>. [<xref rid="pone.0224446.ref016" ref-type="bibr">16</xref>] discusses how to cope with censored data.</p>
    </sec>
  </sec>
  <sec id="sec029">
    <title>C Additional results</title>
    <p>This appendix presents additional results: First, Appendix C.1 evaluates the Latent process decomposition (LPD) method, then Appendix C.2 provides D-calibration results of our various models.</p>
    <sec id="sec030">
      <title>C.1 Latent process decomposition (LPD) for microarray feature extraction</title>
      <p>Rogers <italic>et al</italic>. [<xref rid="pone.0224446.ref019" ref-type="bibr">19</xref>] introduced LPD as a topic model adaptation for microarray data. We experimented with LPD (on METABRIC data) to derive genetic features and used them along with the clinical features for comparison. We used internal cross-validation for LPD to find the optimal number of latent processes for the METABRIC data—and found that 10 was best.</p>
      <p>We then used the model based on these 10 latent process; the resulting concordance results, on the hold-out dataset, was 0.6915 (Cox), 0.6077 (RCox) and 0.6995 (MTLR). Comparing this to the “B” and “C” rows of <xref rid="pone.0224446.t002" ref-type="table">Table 2</xref>, we see that our dLDA approach performs better than this complex adaptation of the LDA model for microarray data, for the survival prediction task—<italic>i.e</italic>., dLDA produces better features from the gene expression data.</p>
      <p>There are two other reasons to prefer our dLDA-approach: (1) LPD has large time and memory requirements. (2) Moreover as our dLDA directly uses the LDA model, it can utilize all available off-the-shelf implementations, across several technology platforms with efficient and scalable implementation [<xref rid="pone.0224446.ref038" ref-type="bibr">38</xref>].</p>
    </sec>
    <sec id="sec031">
      <title>C.2 D-calibration results</title>
      <p><xref rid="pone.0224446.t003" ref-type="table">Table 3</xref> shows the D-calibration results for all of the domain-independent experiments we ran—<italic>i.e</italic>., excluding the “E” and “F” rows from <xref rid="pone.0224446.t002" ref-type="table">Table 2</xref>, which used features that were specific to breast cancer. We see that the results were D-calibrated (<italic>i.e</italic>., had a HL p-value &gt; 0.05) in all 12 situations, for METABRIC and KIPAN—for all feature groups {A, B, C, D}, and all 3 learning algorithms {Cox, RCox, MTLR}. We note that we found that Cox failed this test on other datasets, including BRCA.</p>
    </sec>
  </sec>
</body>
<back>
  <ack>
    <p>We greatly acknowledge Compute Canada for providing us with computing resources. We also thank Dream Challenges and Broad Institute for making the METABRIC and KIPAN cancer data sets publicly available.</p>
  </ack>
  <ref-list>
    <title>References</title>
    <ref id="pone.0224446.ref001">
      <label>1</label>
      <mixed-citation publication-type="other">Stewart B, Wild CP, et al. World cancer report 2014. Health. 2017.</mixed-citation>
    </ref>
    <ref id="pone.0224446.ref002">
      <label>2</label>
      <mixed-citation publication-type="journal"><name><surname>Van’t Veer</surname><given-names>LJ</given-names></name>, <name><surname>Dai</surname><given-names>H</given-names></name>, <name><surname>Van De Vijver</surname><given-names>MJ</given-names></name>, <name><surname>He</surname><given-names>YD</given-names></name>, <name><surname>Hart</surname><given-names>AA</given-names></name>, <name><surname>Mao</surname><given-names>M</given-names></name>, <etal>et al</etal><article-title>Gene expression profiling predicts clinical outcome of breast cancer</article-title>. <source>nature</source>. <year>2002</year>;<volume>415</volume>(<issue>6871</issue>):<fpage>530</fpage>–<lpage>536</lpage>. <pub-id pub-id-type="doi">10.1038/415530a</pub-id><pub-id pub-id-type="pmid">11823860</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0224446.ref003">
      <label>3</label>
      <mixed-citation publication-type="journal"><name><surname>Margolin</surname><given-names>AA</given-names></name>, <name><surname>Bilal</surname><given-names>E</given-names></name>, <name><surname>Huang</surname><given-names>E</given-names></name>, <name><surname>Norman</surname><given-names>TC</given-names></name>, <name><surname>Ottestad</surname><given-names>L</given-names></name>, <name><surname>Mecham</surname><given-names>BH</given-names></name>, <etal>et al</etal><article-title>Systematic analysis of challenge-driven improvements in molecular prognostic models for breast cancer</article-title>. <source>Science translational medicine</source>. <year>2013</year>;<volume>5</volume>(<issue>181</issue>):<fpage>181re1</fpage>–<lpage>181re1</lpage>. <pub-id pub-id-type="doi">10.1126/scitranslmed.3006112</pub-id><?supplied-pmid 23596205?><pub-id pub-id-type="pmid">23596205</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0224446.ref004">
      <label>4</label>
      <mixed-citation publication-type="journal"><name><surname>Parker</surname><given-names>JS</given-names></name>, <name><surname>Mullins</surname><given-names>M</given-names></name>, <name><surname>Cheang</surname><given-names>MC</given-names></name>, <name><surname>Leung</surname><given-names>S</given-names></name>, <name><surname>Voduc</surname><given-names>D</given-names></name>, <name><surname>Vickery</surname><given-names>T</given-names></name>, <etal>et al</etal><article-title>Supervised risk predictor of breast cancer based on intrinsic subtypes</article-title>. <source>Journal of clinical oncology</source>. <year>2009</year>;<volume>27</volume>(<issue>8</issue>):<fpage>1160</fpage>–<lpage>1167</lpage>. <pub-id pub-id-type="doi">10.1200/JCO.2008.18.1370</pub-id><?supplied-pmid 19204204?><pub-id pub-id-type="pmid">19204204</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0224446.ref005">
      <label>5</label>
      <mixed-citation publication-type="journal"><name><surname>Naderi</surname><given-names>A</given-names></name>, <name><surname>Teschendorff</surname><given-names>A</given-names></name>, <name><surname>Barbosa-Morais</surname><given-names>N</given-names></name>, <name><surname>Pinder</surname><given-names>S</given-names></name>, <name><surname>Green</surname><given-names>A</given-names></name>, <name><surname>Powe</surname><given-names>D</given-names></name>, <etal>et al</etal><article-title>A gene-expression signature to predict survival in breast cancer across independent data sets</article-title>. <source>Oncogene</source>. <year>2007</year>;<volume>26</volume>(<issue>10</issue>):<fpage>1507</fpage>–<lpage>1516</lpage>. <pub-id pub-id-type="doi">10.1038/sj.onc.1209920</pub-id><?supplied-pmid 16936776?><pub-id pub-id-type="pmid">16936776</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0224446.ref006">
      <label>6</label>
      <mixed-citation publication-type="journal"><name><surname>Beer</surname><given-names>DG</given-names></name>, <name><surname>Kardia</surname><given-names>SL</given-names></name>, <name><surname>Huang</surname><given-names>CC</given-names></name>, <name><surname>Giordano</surname><given-names>TJ</given-names></name>, <name><surname>Levin</surname><given-names>AM</given-names></name>, <name><surname>Misek</surname><given-names>DE</given-names></name>, <etal>et al</etal><article-title>Gene-expression profiles predict survival of patients with lung adenocarcinoma</article-title>. <source>Nature medicine</source>. <year>2002</year>;<volume>8</volume>(<issue>8</issue>):<fpage>816</fpage>–<lpage>824</lpage>. <pub-id pub-id-type="doi">10.1038/nm733</pub-id><?supplied-pmid 12118244?><pub-id pub-id-type="pmid">12118244</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0224446.ref007">
      <label>7</label>
      <mixed-citation publication-type="journal"><name><surname>Curtis</surname><given-names>C</given-names></name>, <name><surname>Shah</surname><given-names>SP</given-names></name>, <name><surname>Chin</surname><given-names>SF</given-names></name>, <name><surname>Turashvili</surname><given-names>G</given-names></name>, <name><surname>Rueda</surname><given-names>OM</given-names></name>, <name><surname>Dunning</surname><given-names>MJ</given-names></name>, <etal>et al</etal><article-title>The genomic and transcriptomic architecture of 2,000 breast tumours reveals novel subgroups</article-title>. <source>Nature</source>. <year>2012</year>;<volume>486</volume>(<issue>7403</issue>):<fpage>346</fpage>–<lpage>352</lpage>. <pub-id pub-id-type="doi">10.1038/nature10983</pub-id><?supplied-pmid 22522925?><pub-id pub-id-type="pmid">22522925</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0224446.ref008">
      <label>8</label>
      <mixed-citation publication-type="book"><name><surname>Altman</surname><given-names>DG</given-names></name>. <source>Practical statistics for medical research</source>. <publisher-name>CRC</publisher-name>; <year>1990</year>.</mixed-citation>
    </ref>
    <ref id="pone.0224446.ref009">
      <label>9</label>
      <mixed-citation publication-type="journal"><name><surname>Ishwaran</surname><given-names>H</given-names></name>, <name><surname>Kogalur</surname><given-names>UB</given-names></name>, <name><surname>Blackstone</surname><given-names>EH</given-names></name>, <name><surname>Lauer</surname><given-names>MS</given-names></name>. <article-title>Random Survival Forests</article-title>. <source>The Annals of Applied Statistics</source>. <year>2008</year>;<volume>2</volume>:<fpage>841</fpage>–<lpage>860</lpage>. <pub-id pub-id-type="doi">10.1214/08-AOAS169</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0224446.ref010">
      <label>10</label>
      <mixed-citation publication-type="other">Khan FM, Zubek VB. Support vector regression for censored data (SVRc): a novel tool for survival analysis. In: 2008 Eighth IEEE International Conference on Data Mining. IEEE; 2008. p. 863–868.</mixed-citation>
    </ref>
    <ref id="pone.0224446.ref011">
      <label>11</label>
      <mixed-citation publication-type="book"><name><surname>Kalbfleisch</surname><given-names>JD</given-names></name>, <name><surname>Prentice</surname><given-names>RL</given-names></name>. <source>The statistical analysis of failure time data</source>. <volume>vol. 360</volume><publisher-name>John Wiley &amp; Sons</publisher-name>; <year>2011</year>.</mixed-citation>
    </ref>
    <ref id="pone.0224446.ref012">
      <label>12</label>
      <mixed-citation publication-type="journal"><name><surname>Guinney</surname><given-names>J</given-names></name>, <name><surname>Wang</surname><given-names>T</given-names></name>, <name><surname>Laajala</surname><given-names>TD</given-names></name>, <name><surname>Winner</surname><given-names>KK</given-names></name>, <name><surname>Bare</surname><given-names>JC</given-names></name>, <name><surname>Neto</surname><given-names>EC</given-names></name>, <etal>et al</etal><article-title>Prediction of overall survival for patients with metastatic castration-resistant prostate cancer: development of a prognostic model through a crowdsourced challenge with open clinical trial data</article-title>. <source>The Lancet Oncology</source>. <year>2016</year><pub-id pub-id-type="doi">10.1016/S1470-2045(16)30560-5</pub-id><?supplied-pmid 27864015?><pub-id pub-id-type="pmid">27864015</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0224446.ref013">
      <label>13</label>
      <mixed-citation publication-type="journal"><name><surname>Cheng</surname><given-names>WY</given-names></name>, <name><surname>Yang</surname><given-names>THO</given-names></name>, <name><surname>Anastassiou</surname><given-names>D</given-names></name>. <article-title>Development of a prognostic model for breast cancer survival in an open challenge environment</article-title>. <source>Science translational medicine</source>. <year>2013</year>;<volume>5</volume>(<issue>181</issue>):<fpage>181ra50</fpage>–<lpage>181ra50</lpage>. <pub-id pub-id-type="doi">10.1126/scitranslmed.3005974</pub-id><?supplied-pmid 23596202?><pub-id pub-id-type="pmid">23596202</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0224446.ref014">
      <label>14</label>
      <mixed-citation publication-type="other">Yu CN, Greiner R, Lin HC, Baracos V. Learning Patient-Specific Cancer Survival Distributions as a Sequence of Dependent Regressors. In: Neural Information Processing Systems (NIPS); 2011. p. 1845–1853.</mixed-citation>
    </ref>
    <ref id="pone.0224446.ref015">
      <label>15</label>
      <mixed-citation publication-type="journal"><name><surname>Andres</surname><given-names>A</given-names></name>, <name><surname>Montano-Loza</surname><given-names>A</given-names></name>, <name><surname>Greiner</surname><given-names>R</given-names></name>, <name><surname>Uhlich</surname><given-names>M</given-names></name>, <name><surname>Jin</surname><given-names>P</given-names></name>, <name><surname>Hoehn</surname><given-names>B</given-names></name>, <etal>et al</etal><article-title>A novel learning algorithm to predict individual survival after liver transplantation for primary sclerosing cholangitis</article-title>. <source>PLoS One</source>. <year>2018</year><pub-id pub-id-type="doi">10.1371/journal.pone.0193523</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0224446.ref016">
      <label>16</label>
      <mixed-citation publication-type="other">Haider H, Hoehn B, Davis S, Greiner R. Effective Ways to Build and Evaluate Individual Survival Distributions. arXiv preprint arXiv:181111347. 2018.</mixed-citation>
    </ref>
    <ref id="pone.0224446.ref017">
      <label>17</label>
      <mixed-citation publication-type="journal"><name><surname>Blei</surname><given-names>DM</given-names></name>, <name><surname>Ng</surname><given-names>AY</given-names></name>, <name><surname>Jordan</surname><given-names>MI</given-names></name>. <article-title>Latent dirichlet allocation</article-title>. <source>the Journal of machine Learning research</source>. <year>2003</year>;<volume>3</volume>:<fpage>993</fpage>–<lpage>1022</lpage>.</mixed-citation>
    </ref>
    <ref id="pone.0224446.ref018">
      <label>18</label>
      <mixed-citation publication-type="journal"><name><surname>Deshwar</surname><given-names>AG</given-names></name>, <name><surname>Vembu</surname><given-names>S</given-names></name>, <name><surname>Yung</surname><given-names>CK</given-names></name>, <name><surname>Jang</surname><given-names>GH</given-names></name>, <name><surname>Stein</surname><given-names>L</given-names></name>, <name><surname>Morris</surname><given-names>Q</given-names></name>, <etal>et al</etal><article-title>PhyloWGS: reconstructing subclonal composition and evolution from whole-genome sequencing of tumors</article-title>. <source>Genome Biol</source>. <year>2015</year>;<volume>16</volume>:<fpage>35</fpage><pub-id pub-id-type="doi">10.1186/s13059-015-0602-8</pub-id><?supplied-pmid 25786235?><pub-id pub-id-type="pmid">25786235</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0224446.ref019">
      <label>19</label>
      <mixed-citation publication-type="journal"><name><surname>Rogers</surname><given-names>S</given-names></name>, <name><surname>Girolami</surname><given-names>M</given-names></name>, <name><surname>Campbell</surname><given-names>C</given-names></name>, <name><surname>Breitling</surname><given-names>R</given-names></name>. <article-title>The latent process decomposition of cDNA microarray data sets</article-title>. <source>IEEE/ACM Transactions on Computational Biology and Bioinformatics (TCBB)</source>. <year>2005</year>;<volume>2</volume>(<issue>2</issue>):<fpage>143</fpage>–<lpage>156</lpage>. <pub-id pub-id-type="doi">10.1109/TCBB.2005.29</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0224446.ref020">
      <label>20</label>
      <mixed-citation publication-type="other">Masada T, Hamada T, Shibata Y, Oguri K. Bayesian multi-topic microarray analysis with hyperparameter reestimation. In: International Conference on Advanced Data Mining and Applications. Springer; 2009. p. 253–264.</mixed-citation>
    </ref>
    <ref id="pone.0224446.ref021">
      <label>21</label>
      <mixed-citation publication-type="journal"><name><surname>Bicego</surname><given-names>M</given-names></name>, <name><surname>Lovato</surname><given-names>P</given-names></name>, <name><surname>Perina</surname><given-names>A</given-names></name>, <name><surname>Fasoli</surname><given-names>M</given-names></name>, <name><surname>Delledonne</surname><given-names>M</given-names></name>, <name><surname>Pezzotti</surname><given-names>M</given-names></name>, <etal>et al</etal><article-title>Investigating topic models’ capabilities in expression microarray data classification</article-title>. <source>IEEE/ACM Transactions on Computational Biology and Bioinformatics (TCBB)</source>. <year>2012</year>;<volume>9</volume>(<issue>6</issue>):<fpage>1831</fpage>–<lpage>1836</lpage>. <pub-id pub-id-type="doi">10.1109/TCBB.2012.121</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0224446.ref022">
      <label>22</label>
      <mixed-citation publication-type="journal"><name><surname>Liu</surname><given-names>L</given-names></name>, <name><surname>Tang</surname><given-names>L</given-names></name>, <name><surname>Dong</surname><given-names>W</given-names></name>, <name><surname>Yao</surname><given-names>S</given-names></name>, <name><surname>Zhou</surname><given-names>W</given-names></name>. <article-title>An overview of topic modeling and its current applications in bioinformatics</article-title>. <source>SpringerPlus</source>. <year>2016</year>;<volume>5</volume>(<issue>1</issue>):<fpage>1608</fpage><pub-id pub-id-type="doi">10.1186/s40064-016-3252-8</pub-id><?supplied-pmid 27652181?><pub-id pub-id-type="pmid">27652181</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0224446.ref023">
      <label>23</label>
      <mixed-citation publication-type="journal"><name><surname>Hofmann</surname><given-names>T</given-names></name>. <article-title>Unsupervised learning by probabilistic latent semantic analysis</article-title>. <source>Machine learning</source>. <year>2001</year>;<volume>42</volume>(<issue>1-2</issue>):<fpage>177</fpage>–<lpage>196</lpage>. <pub-id pub-id-type="doi">10.1023/A:1007617005950</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0224446.ref024">
      <label>24</label>
      <mixed-citation publication-type="other">Dawson JA, Kendziorski C. Survival-supervised latent Dirichlet allocation models for genomic analysis of time-to-event outcomes. arXiv preprint arXiv:12025999. 2012.</mixed-citation>
    </ref>
    <ref id="pone.0224446.ref025">
      <label>25</label>
      <mixed-citation publication-type="other">McAuliffe JD, Blei DM. Supervised topic models. In: Advances in neural information processing systems; 2008. p. 121–128.</mixed-citation>
    </ref>
    <ref id="pone.0224446.ref026">
      <label>26</label>
      <mixed-citation publication-type="journal"><name><surname>Cox</surname><given-names>DR</given-names></name>. <article-title>Regression Models and Life-Tables</article-title>. <source>Journal of the Royal Statistical Society Series B (Methodological)</source>. <year>1972</year>;<volume>34</volume>(<issue>2</issue>):<fpage>187</fpage>–<lpage>220</lpage>. <pub-id pub-id-type="doi">10.1111/j.2517-6161.1972.tb00899.x</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0224446.ref027">
      <label>27</label>
      <mixed-citation publication-type="book"><name><surname>McCullagh</surname><given-names>P</given-names></name>, <name><surname>Nelder</surname><given-names>JA</given-names></name>. <source>Generalized linear models</source>. <volume>vol. 37</volume><publisher-name>CRC</publisher-name>; <year>1989</year>.</mixed-citation>
    </ref>
    <ref id="pone.0224446.ref028">
      <label>28</label>
      <mixed-citation publication-type="journal"><name><surname>Wolfinger</surname><given-names>RD</given-names></name>, <name><surname>Gibson</surname><given-names>G</given-names></name>, <name><surname>Wolfinger</surname><given-names>ED</given-names></name>, <name><surname>Bennett</surname><given-names>L</given-names></name>, <name><surname>Hamadeh</surname><given-names>H</given-names></name>, <name><surname>Bushel</surname><given-names>P</given-names></name>, <etal>et al</etal><article-title>Assessing gene significance from cDNA microarray expression data via mixed models</article-title>. <source>Journal of computational biology</source>. <year>2001</year>;<volume>8</volume>(<issue>6</issue>):<fpage>625</fpage>–<lpage>637</lpage>. <pub-id pub-id-type="doi">10.1089/106652701753307520</pub-id><?supplied-pmid 11747616?><pub-id pub-id-type="pmid">11747616</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0224446.ref029">
      <label>29</label>
      <mixed-citation publication-type="other">Analysis Overview for Pan-kidney cohort (KICH+KIRC+KIRP) (Primary solid tumor cohort). Broad Institute TCGA Genome Data Analysis Center (2016). 28 January 2016.</mixed-citation>
    </ref>
    <ref id="pone.0224446.ref030">
      <label>30</label>
      <mixed-citation publication-type="book"><name><surname>Hosmer</surname><given-names>DW</given-names><suffix>Jr</suffix></name>, <name><surname>Lemeshow</surname><given-names>S</given-names></name>, <name><surname>Sturdivant</surname><given-names>RX</given-names></name>. <source>Applied logistic regression</source>. <volume>vol. 398</volume><publisher-name>John Wiley &amp; Sons</publisher-name>; <year>2013</year>.</mixed-citation>
    </ref>
    <ref id="pone.0224446.ref031">
      <label>31</label>
      <mixed-citation publication-type="journal"><name><surname>Yousefi</surname><given-names>S</given-names></name>, <name><surname>Amrollahi</surname><given-names>F</given-names></name>, <name><surname>Amgad</surname><given-names>M</given-names></name>, <name><surname>Dong</surname><given-names>C</given-names></name>, <name><surname>Lewis</surname><given-names>JE</given-names></name>, <name><surname>Song</surname><given-names>C</given-names></name>, <etal>et al</etal><article-title>Predicting clinical outcomes from large scale cancer genomic profiles with deep survival models</article-title>. <source>Scientific Reports</source>. <year>2017</year>;<volume>7</volume>(<issue>1</issue>):<fpage>11707</fpage><pub-id pub-id-type="doi">10.1038/s41598-017-11817-6</pub-id><?supplied-pmid 28916782?><pub-id pub-id-type="pmid">28916782</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0224446.ref032">
      <label>32</label>
      <mixed-citation publication-type="other">Steck H, Krishnapuram B, Dehing-oberije C, Lambin P, Raykar VC. On ranking in survival analysis: Bounds on the concordance index. In: Advances in neural information processing systems; 2008. p. 1209–1216.</mixed-citation>
    </ref>
    <ref id="pone.0224446.ref033">
      <label>33</label>
      <mixed-citation publication-type="journal"><name><surname>Simon</surname><given-names>N</given-names></name>, <name><surname>Friedman</surname><given-names>J</given-names></name>, <name><surname>Hastie</surname><given-names>T</given-names></name>, <name><surname>Tibshirani</surname><given-names>R</given-names></name>. <article-title>Regularization Paths for Cox’s Proportional Hazards Model via Coordinate Descent</article-title>. <source>Journal of Statistical Software</source>. <year>2011</year>;<volume>39</volume>(<issue>5</issue>):<fpage>1</fpage>–<lpage>13</lpage>. <pub-id pub-id-type="doi">10.18637/jss.v039.i05</pub-id><?supplied-pmid 27065756?><pub-id pub-id-type="pmid">27065756</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0224446.ref034">
      <label>34</label>
      <mixed-citation publication-type="journal"><name><surname>Van Wieringen</surname><given-names>WN</given-names></name>, <name><surname>Kun</surname><given-names>D</given-names></name>, <name><surname>Hampel</surname><given-names>R</given-names></name>, <name><surname>Boulesteix</surname><given-names>AL</given-names></name>. <article-title>Survival prediction using gene expression data: a review and comparison</article-title>. <source>Computational statistics &amp; data analysis</source>. <year>2009</year>;<volume>53</volume>(<issue>5</issue>):<fpage>1590</fpage>–<lpage>1603</lpage>. <pub-id pub-id-type="doi">10.1016/j.csda.2008.05.021</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0224446.ref035">
      <label>35</label>
      <mixed-citation publication-type="journal"><name><surname>Goeman</surname><given-names>JJ</given-names></name>. <article-title>L1 penalized estimation in the Cox proportional hazards model</article-title>. <source>Biometrical journal</source>. <year>2010</year>;<volume>52</volume>(<issue>1</issue>):<fpage>70</fpage>–<lpage>84</lpage>. <pub-id pub-id-type="doi">10.1002/bimj.200900028</pub-id><?supplied-pmid 19937997?><pub-id pub-id-type="pmid">19937997</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0224446.ref036">
      <label>36</label>
      <mixed-citation publication-type="journal"><name><surname>Bair</surname><given-names>E</given-names></name>, <name><surname>Tibshirani</surname><given-names>R</given-names></name>. <article-title>Semi-supervised methods to predict patient survival from gene expression data</article-title>. <source>PLoS Biol</source>. <year>2004</year>;<volume>2</volume>(<issue>4</issue>):<fpage>e108</fpage><pub-id pub-id-type="doi">10.1371/journal.pbio.0020108</pub-id><?supplied-pmid 15094809?><pub-id pub-id-type="pmid">15094809</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0224446.ref037">
      <label>37</label>
      <mixed-citation publication-type="journal"><name><surname>Ding</surname><given-names>C</given-names></name>, <name><surname>Peng</surname><given-names>H</given-names></name>. <article-title>Minimum redundancy feature selection from microarray gene expression data</article-title>. <source>Journal of bioinformatics and computational biology</source>. <year>2005</year>;<volume>3</volume>(<issue>02</issue>):<fpage>185</fpage>–<lpage>205</lpage>. <pub-id pub-id-type="doi">10.1142/S0219720005001004</pub-id><?supplied-pmid 15852500?><pub-id pub-id-type="pmid">15852500</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0224446.ref038">
      <label>38</label>
      <mixed-citation publication-type="other">Hoffman M, Bach FR, Blei DM. Online learning for latent dirichlet allocation. In: advances in neural information processing systems; 2010. p. 856–864.</mixed-citation>
    </ref>
    <ref id="pone.0224446.ref039">
      <label>39</label>
      <element-citation publication-type="other">
        <ext-link ext-link-type="uri" xlink:href="http://firebrowse.org/?cohort=KIPAN&amp;downloaddialog=true">http://firebrowse.org/?cohort=KIPAN&amp;downloaddialog=true</ext-link>
      </element-citation>
    </ref>
    <ref id="pone.0224446.ref040">
      <label>40</label>
      <element-citation publication-type="other">
        <ext-link ext-link-type="uri" xlink:href="https://www.synapse.org/#!Synapse:syn1688369/wiki/27311">https://www.synapse.org/#!Synapse:syn1688369/wiki/27311</ext-link>
      </element-citation>
    </ref>
    <ref id="pone.0224446.ref041">
      <label>41</label>
      <element-citation publication-type="other">
        <ext-link ext-link-type="uri" xlink:href="https://github.com/blei-lab/lda-c">https://github.com/blei-lab/lda-c</ext-link>
      </element-citation>
    </ref>
  </ref-list>
</back>
