<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Syst Biol</journal-id>
    <journal-id journal-id-type="iso-abbrev">Syst Biol</journal-id>
    <journal-id journal-id-type="publisher-id">sysbio</journal-id>
    <journal-title-group>
      <journal-title>Systematic Biology</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1063-5157</issn>
    <issn pub-type="epub">1076-836X</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
      <publisher-loc>US</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">10198646</article-id>
    <article-id pub-id-type="pmid">36705582</article-id>
    <article-id pub-id-type="doi">10.1093/sysbio/syad002</article-id>
    <article-id pub-id-type="publisher-id">syad002</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Software for Systematics and Evolution</subject>
      </subj-group>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI00960</subject>
        <subject>AcademicSubjects/SCI01130</subject>
        <subject>AcademicSubjects/SCI01130</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Lagrange-NG: The next generation of Lagrange</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-9130-6878</contrib-id>
        <name>
          <surname>Bettisworth</surname>
          <given-names>Ben</given-names>
        </name>
        <aff><institution>Computational Molecular Evolution Group, Heidelberg Institute for Theoretical Studies</institution>, <addr-line>Heidelberg</addr-line>, <country country="DE">Germany</country></aff>
        <xref rid="c1" ref-type="corresp"/>
        <!--ben.bettisworth@h-its.org-->
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0003-2035-9531</contrib-id>
        <name>
          <surname>Smith</surname>
          <given-names>Stephen A</given-names>
        </name>
        <aff><institution>Ecology and Evolutionary Biology, University of Michigan</institution>, <addr-line>Ann Arbor</addr-line>, <country country="US">United States</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0003-0353-0691</contrib-id>
        <name>
          <surname>Stamatakis</surname>
          <given-names>Alexandros</given-names>
        </name>
        <aff><institution>Computational Molecular Evolution Group, Heidelberg Institute for Theoretical Studies</institution>, <addr-line>Heidelberg</addr-line>, <country country="DE">Germany</country></aff>
        <aff><institution>Institute for Theoretical Informatics, Karlsruhe Institute of Technology</institution>, <addr-line>Karlsruhe</addr-line>, <country country="DE">Germany</country></aff>
      </contrib>
    </contrib-group>
    <author-notes>
      <corresp id="c1">Correspondence to be sent to: Computational Molecular Evolution Group, Heidelberg Institute for Theoretical Studies, Heidelberg, Germany; E-mail: <email>ben.bettisworth@h-its.org</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <month>1</month>
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2023-01-27">
      <day>27</day>
      <month>1</month>
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>27</day>
      <month>1</month>
      <year>2023</year>
    </pub-date>
    <volume>72</volume>
    <issue>1</issue>
    <fpage>242</fpage>
    <lpage>248</lpage>
    <history>
      <date date-type="received">
        <day>21</day>
        <month>4</month>
        <year>2022</year>
      </date>
      <date date-type="rev-recd">
        <day>09</day>
        <month>1</month>
        <year>2023</year>
      </date>
      <date date-type="accepted">
        <day>20</day>
        <month>1</month>
        <year>2023</year>
      </date>
      <date date-type="corrected-typeset">
        <day>30</day>
        <month>3</month>
        <year>2023</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2023. Published by Oxford University Press on behalf of the Society of Systematic Biologists.</copyright-statement>
      <copyright-year>2023</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbynclicense">https://creativecommons.org/licenses/by-nc/4.0/</ali:license_ref>
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution-NonCommercial License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by-nc/4.0/">https://creativecommons.org/licenses/by-nc/4.0/</ext-link>), which permits non-commercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited. For commercial re-use, please contact journals.permissions@oup.com</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="syad002.pdf"/>
    <abstract>
      <title>Abstract</title>
      <p>Computing ancestral ranges via the Dispersion Extinction and Cladogensis (DEC) model of biogeography is characterized by an exponential number of states relative to the number of regions considered. This is because the DEC model requires computing a large matrix exponential, which typically accounts for up to 80% of overall runtime. Therefore, the kinds of biogeographical analyses that can be conducted under the DEC model are limited by the number of regions under consideration. In this work, we present a completely redesigned efficient version of the popular tool Lagrange which is up to 49 times faster with multithreading enabled, and is also 26 times faster when using only one thread. We call this new version Lagrange-NG (Lagrange-Next Generation). The increased computational efficiency allows Lagrange-NG to analyze datasets with a large number of regions in a reasonable amount of time, up to 12 regions in approximately 18 min. We achieve these speedups using a relatively new method of computing the matrix exponential based on Krylov subspaces. In order to validate the correctness of Lagrange-NG, we also introduce a novel metric on range distributions for trees so that researchers can assess the difference between any two range inferences. Finally, Lagrange-NG exhibits substantially higher adherence to coding quality standards. It improves a respective software quality indicator as implemented in the SoftWipe tool from average (5.5; Lagrange) to high (7.8; Lagrange-NG). Lagrange-NG is freely available under GPL2. [Biogeography; Phylogenetics; DEC Model.]</p>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>European Union’s Horizon 2020</institution>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Marie Sklodowska-Curie</institution>
          </institution-wrap>
        </funding-source>
        <award-id>764840</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Klaus Tschira Foundation</institution>
            <institution-id institution-id-type="DOI">10.13039/501100007316</institution-id>
          </institution-wrap>
        </funding-source>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="7"/>
    </counts>
  </article-meta>
</front>
<body>
  <p>Lagrange-NG implements the DEC (Dispersion Extinction and Cladogensis) model of geographic range evolution <xref rid="CIT0010" ref-type="bibr">Ree et al. (2005)</xref>. A geographic range, in this context, describes the broadly defined distribution of the habitat of a particular species. The evolution of this range is assumed to follow the phylogeny, or the biological evolution of a species or clade. The DEC model takes, as a minimum, a phylogenetic tree, and a set of regions. The phylogenetic tree is assumed to be the true phylogeny of the included species, and the regions are the generalized areas of potential habitation for the species in question. The DEC model constructs a list of states based on the valid set of regions that a particular species could inhabit. With these components, the DEC model constructs a transition matrix between states using two parameters, an extinction parameter and a dispersion parameter. Using this transition matrix, the likelihood of the model parameters can be computed and used to optimize the model parameters. Once the optimal model parameters have been found, the most likely ancestral ranges can be found by computing the model “backwards.”</p>
  <p>However, computing likelihoods under the DEC model is computationally challenging. This is because: (i) the geographical regions are splayed into <inline-formula id="IN0001"><mml:math id="m2" display="inline" overflow="scroll"><mml:mstyle displaystyle="false"><mml:mrow><mml:msup><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo>=</mml:mo><mml:mi>s</mml:mi></mml:mstyle></mml:math></inline-formula> states (<xref rid="CIT0005" ref-type="bibr">Landis et al., 2013</xref>) as each possible range distribution is represented as a state; and (ii) the computation of the respective transition matrix is in <inline-formula id="IN0002"><mml:math id="m3" display="inline" overflow="scroll"><mml:mstyle displaystyle="false"><mml:mrow><mml:mi mathvariant="script">O</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>. Thus, computing a single likelihood of the DEC model requires <inline-formula id="IN0003"><mml:math id="m4" display="inline" overflow="scroll"><mml:mstyle displaystyle="false"><mml:mrow><mml:mi mathvariant="script">O</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="script">O</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mn>3</mml:mn><mml:mi>r</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> time. In other words, the likelihood computation is exponential with respect to the number of regions under study. Therefore, the scalability of data analyses under the DEC model is limited to the number of regions, that is, only a small number of 6 to 10 regions can be analyzed in a reasonable time (<xref rid="CIT0005" ref-type="bibr">Landis et al., 2013</xref>; <xref rid="CIT0006" ref-type="bibr">Matzke, 2013</xref>).</p>
  <p>The most expensive inference step is the computation of the transition matrix that often accounts for 80% or more of overall runtime. As in standard likelihood-based phylogenetics, the transition matrix is computed via a matrix exponential, albeit on a substantially larger matrix. Substantial research effort has been invested into finding the best way to compute the matrix exponential (<xref rid="CIT0007" ref-type="bibr">Moler and Loan, 2003</xref>), but it still remains challenging to compute efficiently as well as accurately. In addition, unlike in standard phylogenetics, the DEC model is nonreversible (i.e., uses a nonsymmetric rate matrix), which limits the number of applicable numerical methods for computing the matrix exponential, typically to less precise ones. In the following, we present the Lagrange-NG (Lagrange-Next Generation) software, an almost complete rewrite of the popular and widely used Lagrange software by <xref rid="CIT0010" ref-type="bibr">Ree et al. (2005)</xref>, and more specifically the unpublished but available to use C <inline-formula id="IN0004"><mml:math id="m5" display="inline" overflow="scroll"><mml:mstyle displaystyle="false"><mml:mo>+</mml:mo><mml:mo>+</mml:mo></mml:mstyle></mml:math></inline-formula> version of Lagrange developed by Smith which can be found on GitHub at <ext-link xlink:href="https://github.com/rhr/lagrange-cpp" ext-link-type="uri">https://github.com/rhr/lagrange-cpp</ext-link>. In this work, when we refer to the original Lagrange, we are referring not to the Python version from <xref rid="CIT0011" ref-type="bibr">Ree and Smith (2008)</xref>, but to the unpublished C <inline-formula id="IN0005"><mml:math id="m6" display="inline" overflow="scroll"><mml:mstyle displaystyle="false"><mml:mo>+</mml:mo><mml:mo>+</mml:mo></mml:mstyle></mml:math></inline-formula> version. As the primary challenge to computing the likelihood under the DEC model is to efficiently calculate the matrix exponential, Lagrange-NG relies on a relatively recent method of computing a matrix exponential based on Krylov Subspaces (<xref rid="CIT0007" ref-type="bibr">Moler and Loan, 2003</xref>) for a moderate to large number of regions (six and more) in the default mode of operation.</p>
  <p>Alongside the improvements to the matrix exponential, many so-called “micro-optimizations” (e.g., passing function arguments by reference instead of value, using more efficient data structures to store regions, or eliminating unnecessary computation) have been implemented that further accelerate computations. We have also implemented a task-based hybrid multithreading approach, which increases the rate of analyses by up to a factor of eight for datasets with exceeding 200 taxa. Furthermore, we improve upon the numerical stability compared to the original software, and fix a major bug which we discovered during development. Finally, to verify that Lagrange-NG produces analogous results as the original implementation, we devised a novel method of comparing range distribution on trees, which is based on the Earth mover’s distance metric. A similar application of the Earth mover’s distance has been successfully applied to phylogenetic placement, though this method and application is distinct (<xref rid="CIT0001" ref-type="bibr">Evans and Matsen, 2012</xref>).</p>
  <sec id="s1">
    <title>Software Description</title>
    <p>Lagrange-NG constitutes an nearly complete rewrite of the original (unpublished) C <inline-formula id="IN0006"><mml:math id="m7" display="inline" overflow="scroll"><mml:mstyle displaystyle="false"><mml:mo>+</mml:mo><mml:mo>+</mml:mo></mml:mstyle></mml:math></inline-formula> version of Lagrange. Of the 4600 lines of code present, only 5% are present from the original code base. This redesign retains the complete functionality of Lagrange, but is computationally more efficient, and implements a parallelization of DEC calculations. Lagrange-NG implements four major improvements to Lagrange. First, it supports parallelism via a hybrid task-based parallelization scheme which utilizes both coarse and fine-grained parallelism. The coarse-grained parallelism of Lagrange-NG assigns tasks to workers, which for this work can be thought of as threads for the purposes of this paper. For more details, please see the <ext-link xlink:href="http://dx.doi.org/10.5061/dryad.mw6m905zv" ext-link-type="uri">Supplementary Materials</ext-link>. Second, it deploys more efficient numerical methods and algorithms which were developed relatively recently to compute the matrix exponential, for example, an algorithm based on Krylov subspaces which we use in Lagrange-NG. Third, it introduces general improvements and optimizations, that is, micro-optimizations, which individually do not notably increase efficiency, but put together yield a substantial improvement. Finally, the fourth improvement is a substantial increase in coding standards adherence and hence, software quality, as measured by the coding standards adherence evaluation tool and benchmark SoftWipe (<xref rid="CIT0017" ref-type="bibr">Zapletal et al., 2021</xref>). The SoftWipe score of the original Lagrange software is 5.5, while our nearly complete rewrite increases this to a score of 7.8. While the original score of 5.5 is fairly average, the new score of 7.8 places Lagrange-NG 3rd in the list of 51 scientific software tools written in C or C <inline-formula id="IN0007"><mml:math id="m8" display="inline" overflow="scroll"><mml:mstyle displaystyle="false"><mml:mo>+</mml:mo><mml:mo>+</mml:mo></mml:mstyle></mml:math></inline-formula> that are contained in the SoftWipe benchmark.</p>
    <p>Importantly, during the process of improving the code quality, a potentially serious bug was discovered which, as far as the authors can determine, affects not only the C <inline-formula id="IN0008"><mml:math id="m9" display="inline" overflow="scroll"><mml:mstyle displaystyle="false"><mml:mo>+</mml:mo><mml:mo>+</mml:mo></mml:mstyle></mml:math></inline-formula> version of Lagrange but also applies to the older Python version of Lagrange which uses matrix exponentiation to compute the transition matrix. In order to correct numerical instabilities, the transition matrix was normalized such that the rows summed to 1.0 after the matrix exponential computation. During normal computation, this operation will have little effect on the results. However, if the rate matrix is sufficiently ill conditioned, the computation exhibits an extreme numerical instability such that any results produced are meaningless. If the matrix is then normalized at this point, then results produced with this matrix are made to appear sensible. Therefore, any error in the computational process is hidden from the user, and the results of the computation will be perceived as plausible. Fortunately, as long as the matrix remains unnormalized, these errors are easy to detect, as several analytical conditions are no longer met (such as the rows no longer summing to 1.0). We are not aware of any approaches to recover from these errors, but at least the user is not misled into thinking that meaningless results are plausible. This normalization error is exceedingly rare, as the authors never observed it in the thousands of datasets analyzed for this paper. Despite this, the error <italic toggle="yes">can</italic> occur, and <italic toggle="yes">will</italic> by Murphy’s law. As such, we are convinced that in the event of this bug, the user should be appropriately informed. Therefore, in this case, Lagrange-NG simply fails, and alerts the user to what occurred.</p>
    <p>In addition, we identified and corrected a configuration error in the process of building Lagrange, where important compiler optimization options were not properly utilized. Fixing this configuration error alone increased the computational efficiency of the original Lagrange by up to 10×. While this error is easy to overlook, yet trivial to fix, we assume that many past Lagrange analyses were conducted using the unoptimized code. Nonetheless, in this work when we perform benchmarks with Lagrange, we do them with this configuration error fixed.</p>
    <p>Lagrange-NG can be downloaded from GitHub at <ext-link xlink:href="https://github.com/computations/lagrange-ng" ext-link-type="uri">https://github.com/computations/lagrange-ng</ext-link> along with a tool to plot the results at <ext-link xlink:href="https://github.com/computations/lagrange-ng-plotter" ext-link-type="uri">https://github.com/computations/lagrange-ng-plotter</ext-link>. To build the software, the only requirements are a C <inline-formula id="IN0009"><mml:math id="m10" display="inline" overflow="scroll"><mml:mstyle displaystyle="false"><mml:mo>+</mml:mo><mml:mo>+</mml:mo></mml:mstyle></mml:math></inline-formula> compiler, and CMake. Optionally, Lagrange-NG can be built with the respective system versions of the <xref rid="CIT0002" ref-type="bibr">Intel Math Kernel Library (2022)</xref> (also known as MKL) and NLOpt (<xref rid="CIT0008" ref-type="bibr">Nelder and Mead, 1965</xref>; <xref rid="CIT0004" ref-type="bibr">Johnson, 2021</xref>). If a system version of MKL is not present, Lagrange-NG will build with <xref rid="CIT0009" ref-type="bibr">OpenBLAS (2022)</xref> instead.</p>
    <p>Please see the <ext-link xlink:href="http://dx.doi.org/10.5061/dryad.mw6m905zv" ext-link-type="uri">Supplementary Material</ext-link> for a more thorough description of Lagrange-NG.</p>
  </sec>
  <sec id="s2">
    <title>Performance</title>
    <p>To assess the performance of Lagrange-NG relative to the original implementation, we randomly generated a large number of synthetic datasets with a varying number of regions and executed Lagrange and Lagrange-NG to record the respective runtimes. We generated 100 random datasets with either 5, 6, or 7 regions, and all had 100 taxa, to obtain a total of 300 datasets. Furthermore, we ran an additional series of parallel performance evaluations on Lagrange-NG with eight threads assigned to coarse grained parallelization using the same datasets. The results of this performance assessment are shown in <xref rid="F1" ref-type="fig">Fig. 1</xref>. In addition, we assessed the performance of only Lagrange-NG on datasets with 8, 9, 10, 11, or 12 regions when using eight workers. For the experiments with eight regions, we generated 100 datasets, for the experiments with 9 or 10 regions, we generated 30 datasets, and for the experiments with 11 or 12 regions, we generated 10 datasets. Results from this performance assessment are shown in <xref rid="F2" ref-type="fig">Fig. 2</xref>. To assess the parallel scaling of Lagrange-NG, we generated 100 datasets with 500 taxa a six regions. Using these datasets, we measured the execution time of Lagrange-NG with 1, 4, 8, 16, and 32 cores. We took the mean runtime for each core count and used this value to compute speedups as seen in <xref rid="F3" ref-type="fig">Fig. 3</xref>.</p>
    <fig position="float" id="F1">
      <label>Figure 1.</label>
      <caption>
        <p>Comparison of runtimes between Lagrange (left) and Lagrange-NG (right) with sequential Lagrange-NG (top) and parallel Lagrange-NG using 8 cores (bot). Results were obtained by generating 100 random datasets. Note that the original Lagrange was not run with any multi-threading, as it does not support it. Instead, the data has been replicated for comparison’s sake. Times are in seconds. The figure was generated using seaborn (<xref rid="CIT0016" ref-type="bibr">Waskom, 2021</xref>).</p>
      </caption>
      <graphic xlink:href="syad002f0001" position="float"/>
    </fig>
    <fig position="float" id="F2">
      <label>Figure 2.</label>
      <caption>
        <p>Runtimes for Lagrange-NG on a larger number of regions when using 8 cores. Results were obtained by generated random datasets with 100 taxa and 8, 9, 10, 11, or 12 regions. We generated 100 random datasets for the 8 region cases; for the 9 and 10 region cases we generated 30 datasets; and for the 11 and 12 region cases we generated 10 datasets.</p>
      </caption>
      <graphic xlink:href="syad002f0002" position="float"/>
    </fig>
    <fig position="float" id="F3">
      <label>Figure 3.</label>
      <caption>
        <p>Parallel efficiency plot for a datasets with 500 taxa and 6 regions. Please notice the log-log scaling. The actual values plotted are 1.7, 1.8, 2.0, 2.1 for 4, 8, 16, and 32 cores, respectively. The ratio of the realized speedup to the optimal speedup is 0.43, 0.24, 0.13, 0.06 for 4, 8, 16, and 32 cores, respectively.</p>
      </caption>
      <graphic xlink:href="syad002f0003" position="float"/>
    </fig>
    <p>Additional performance tests are available in the <ext-link xlink:href="http://dx.doi.org/10.5061/dryad.mw6m905zv" ext-link-type="uri">Supplementary Material</ext-link>.</p>
    <sec id="s3">
      <title>Metric Performance</title>
      <p>To demonstrate the performance of the Wassserstein metric, we use a case study with three regions: A, B, and C. These three regions induce a state space with 8 states, with the states being “Empty,” “A,” “B,” “C,” “AB,” “AC,” “BC,” and “ABC.” For each of these states, we generated a “basis” distribution, which is a distribution vector containing <inline-formula id="IN0010"><mml:math id="m11" display="inline" overflow="scroll"><mml:mstyle displaystyle="false"><mml:mn>1.0</mml:mn></mml:mstyle></mml:math></inline-formula> in the entry corresponding to the state, and <inline-formula id="IN0011"><mml:math id="m12" display="inline" overflow="scroll"><mml:mstyle displaystyle="false"><mml:mn>0.0</mml:mn></mml:mstyle></mml:math></inline-formula> everywhere else. For example, the basis distribution representing “A” would be</p>
      <disp-formula id="UN0001">
        <mml:math id="M1" display="block" overflow="scroll">
          <mml:mstyle displaystyle="true">
            <mml:mtable columnalign="left" columnspacing="1">
              <mml:mtr>
                <mml:mtd>
                  <mml:mstyle displaystyle="true">
                    <mml:mrow>
                      <mml:mo>(</mml:mo>
                      <mml:mn>0.0</mml:mn>
                      <mml:mo>,</mml:mo>
                      <mml:mn>1.0</mml:mn>
                      <mml:mo>,</mml:mo>
                      <mml:mn>0.0</mml:mn>
                      <mml:mo>,</mml:mo>
                      <mml:mn>0.0</mml:mn>
                      <mml:mo>,</mml:mo>
                      <mml:mn>0.0</mml:mn>
                      <mml:mo>,</mml:mo>
                      <mml:mn>0.0</mml:mn>
                      <mml:mo>,</mml:mo>
                      <mml:mn>0.0</mml:mn>
                      <mml:mo>,</mml:mo>
                      <mml:mn>0.0</mml:mn>
                      <mml:mo>)</mml:mo>
                    </mml:mrow>
                  </mml:mstyle>
                </mml:mtd>
              </mml:mtr>
            </mml:mtable>
          </mml:mstyle>
        </mml:math>
      </disp-formula>
      <p>We then computed the pairwise distance between all of the basis vectors. The results of this computation is summarized in <xref rid="F4" ref-type="fig">Fig. 4</xref>. As it can be seen from this summary, our Wasserstein metric behaves as intended, which is to say states which have fewer regions in common with each other are farther away.</p>
      <fig position="float" id="F4">
        <label>Figure 4.</label>
        <caption>
          <p>Plot showing the pairwise Wasserstein metric between the “basis” distributions on three regions: A, B, and C. Here, the “basis” distributions are a set of distributions, one for each state, with <inline-formula id="IN0012"><mml:math id="m13" display="inline" overflow="scroll"><mml:mstyle displaystyle="false"><mml:mn>1.0</mml:mn></mml:mstyle></mml:math></inline-formula> in the corresponding entry for that state. Distributions are labeled by which entry contains the <inline-formula id="IN0013"><mml:math id="m14" display="inline" overflow="scroll"><mml:mstyle displaystyle="false"><mml:mn>1.0</mml:mn></mml:mstyle></mml:math></inline-formula>. States are ordered by a Gray code for aesthetic reasons only.</p>
        </caption>
        <graphic xlink:href="syad002f0004" position="float"/>
      </fig>
    </sec>
  </sec>
  <sec id="s4">
    <title>Validation</title>
    <p>Lagrange-NG re-implements core numerical routines of Lagrange. Such changes in numerical routines are often associated with difficult and subtle bugs as well as slight numerical deviations. We sought to ensure that Lagrange-NG and Lagrange produced the same results. To this end, we developed a pipeline to (i) generate random datasets, (ii) run both, Lagrange, and Lagrange-NG, and (iii) compare the results of the two programs. To compare results, we developed a measure to evaluate the distance between distributions of ancestral ranges on trees based on the Wasserstein metric (<xref rid="CIT0015" ref-type="bibr">Vaserstein, 1969</xref>). We provide a summary here; further details are provided in the <ext-link xlink:href="http://dx.doi.org/10.5061/dryad.mw6m905zv" ext-link-type="uri">Supplementary Material</ext-link>.</p>
    <p>To compute the distance between two ancestral range distributions on a given tree, we embed the range as a vertex weight into a hypercube graph, and then use that graph to compute the Wasserstein metric between the distributions for each node. This metric is then normalized to be between 0.0 and 1.0 by dividing by the maximum total distance, and subsequently averaged over all nodes. The intention of this metric is to better account for what the states represent in terms of range distributions in the real world. By transforming the problem into a distance through a hypercube graph, we better match the intuition that states with less regions in common are more distant.</p>
    <p>We ran this comparison for 100 iterations on datasets comprising 10, 50, and 100 taxa, and a number of regions between 2 and 6. This yielded 15 parameter sets, for a total of 1,500 tests.</p>
  </sec>
  <sec id="s5">
    <title>Biological Examples</title>
    <p>While we conducted extensive tests on simulated data, we also verify that Lagrange-NG behaves correctly on empirical datasets. To this end, we reproduced the results from a previous study on sloths from <xref rid="CIT0014" ref-type="bibr">Varela et al. (2019)</xref>. In addition, we took the opportunity to reproduce the results using the tools specified in the paper as this gave us an opportunity to compare with BioGeoBEARS (<xref rid="CIT0006" ref-type="bibr">Matzke, 2013</xref>), a similar tool.</p>
    <p>In order to reproduce results, we downloaded the supplementary data from the Dryad repository associated with the publication. To run the analyses with BioGeoBEARS and Lagrange-NG, we had to slightly modify the data. This involved correcting some taxon names so that they matched between the tree and the region data, and also removing the outgroup from the tree as there was no region data included for the outgroup. These modifications appear to be in line with what the original authors must have done, because the results from both BioGeoBEARS and Lagrange-NG match the results reported in the article. Both BioGeoBEARS and Lagrange-NG were run with the same dataset on the same computer. Despite the fact that the original study limited the number of regions to 5, we decided to also measure Lagrange-NG’s performance with no region limit, to show that Lagrange-NG can analyze large empirical datasets without a region limit.</p>
  </sec>
  <sec id="s6">
    <title>Validation</title>
    <p>The validation of Lagrange-NG with respect to Lagrange, was surprisingly successful, despite substantial modifications of nearly all critical code paths and numerical routines. Of the 1,500 tests, 0 produced results with differences over the tolerance of <inline-formula id="IN0014"><mml:math id="m15" display="inline" overflow="scroll"><mml:mstyle displaystyle="false"><mml:mn>1</mml:mn><mml:mo>×</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> when computed using our novel distance method, indicating that the results are equivalent between the two tools.</p>
    <p>The mean sequential speedup between Lagrange-NG over Lagrange on one core for 5, 6, and 7 regions is 1.54, 4.93, and 26.63, respectively. The overall time-to-solution speedup of Lagrange-NG with 8 cores over sequential Lagrange on one core for 5, 6, and 7 regions is 1.88, 7.75, and 49.2, respectively. For datasets with larger regions, Lagrange-NG analyzed these datasets with a mean time of 3.00 s, 11.12 s, 40.75 s, 217.01 s, and 1130.60 s for 8, 9, 10, 11, and 12 regions, respectively.</p>
    <p>The speedup from adding more cores when compared to the 1 core execution is 1.7, 1.8, 2.0, 2.1 for 4, 8, 16, and 32 cores, respectively, on simulated datasets with 500 taxa and 6 regions, as can be seen in <xref rid="F3" ref-type="fig">Fig. 3</xref>. The ratio between realized speedup and idealized speedup for this experiment is 0.43, 0.24, 0.13, 0.06 for 4, 8, 16, and 32 cores, respectively. Additional results for parallel speedups can be seen in the <ext-link xlink:href="http://dx.doi.org/10.5061/dryad.mw6m905zv" ext-link-type="uri">Supplemental Material</ext-link>.</p>
    <p>In addition, Lagarange-NG is substantially faster than BioGeoBEARS. On the empirical dataset, Lagrange-NG computed the result in about <inline-formula id="IN0015"><mml:math id="m16" display="inline" overflow="scroll"><mml:mstyle displaystyle="false"><mml:mn>7</mml:mn></mml:mstyle></mml:math></inline-formula> seconds using 8 cores, while BioGeoBEARS required about <inline-formula id="IN0016"><mml:math id="m17" display="inline" overflow="scroll"><mml:mstyle displaystyle="false"><mml:mn>14</mml:mn></mml:mstyle></mml:math></inline-formula> min to analyze the data using 80 cores. BioGeoBEARS and Lagrange-NG inferred different optima for model parameters, with BioGeoBEARS achieving a slightly better log-likelihood score (−216.127 vs. −224.396). It is unclear if these likelihoods are directly comparable. Nonetheless, this does not affect the respective qualitative results as BioGeoBEARS and Lagrange-NG agree on the most likely distribution for every node.</p>
    <p>The analysis of this dataset with no region limit using Lagrange-NG produced similar results to the analysis with the 5-region limit, albeit with a better likelihood (−217.023). The time for this analysis was about <inline-formula id="IN0017"><mml:math id="m18" display="inline" overflow="scroll"><mml:mstyle displaystyle="false"><mml:mn>2</mml:mn></mml:mstyle></mml:math></inline-formula> s using 8 cores.</p>
    <p>Comparing runtimes with RevBayes is difficult, as RevBayes and Lagrange-NG produce different kinds of results. RevBayes is a Bayesian analysis software, and as such produces a distribution of parameter values as the posterior. On the contrary, Lagrange-NG finds only the parameter values with the highest likelihood. Nonetheless, the limited range of available tools to compare with necessitates us to use RevBayes as a comparison. We let RevBayes run for <inline-formula id="IN0018"><mml:math id="m19" display="inline" overflow="scroll"><mml:mstyle displaystyle="false"><mml:mo>≈</mml:mo><mml:mn>7</mml:mn></mml:mstyle></mml:math></inline-formula> h on the sloth dataset, and in that time RevBayes managed to perform <inline-formula id="IN0019"><mml:math id="m20" display="inline" overflow="scroll"><mml:mstyle displaystyle="false"><mml:mo>≈</mml:mo><mml:mn>30</mml:mn></mml:mstyle></mml:math></inline-formula> iterations, which is <inline-formula id="IN0020"><mml:math id="m21" display="inline" overflow="scroll"><mml:mstyle displaystyle="false"><mml:mo>≈</mml:mo><mml:mn>14</mml:mn></mml:mstyle></mml:math></inline-formula> min per iteration. Using 3000 iterations as the default number of iterations, a number of iterations suggested by the tutorial for DEC analysis using RevBayes, the full analysis would take <inline-formula id="IN0021"><mml:math id="m22" display="inline" overflow="scroll"><mml:mstyle displaystyle="false"><mml:mo>≈</mml:mo><mml:mn>29</mml:mn></mml:mstyle></mml:math></inline-formula> d.</p>
  </sec>
  <sec id="s7">
    <title>Discussion</title>
    <p>We have shown that computation of likelihood-based biogeographical models can be greatly accelerated without sacrificing result quality. An 8-fold increase in speed over the original implementation, and a 28-fold increase in speed over BioGeoBEARS represents a step forward, especially when taking the time complexity of the matrix exponential into account. In addition, we retain this speed even on datasets with a large number of regions and no region limit, enabling for more fine grained as well as exploratory analyses of biogeographical data.</p>
    <p>Readers might wonder why the execution time for the analysis of the empirical dataset with a maximum number of regions is the slower than the analysis without a maximum number of regions. Ostensibly, a smaller number of regions should lead to a faster execution, but the runtimes shown contradict this. However, for this specific dataset, when using a maximum number of regions Lagrange-NG’s adaptive mode detected numerical issues on nearly all results involving the matrix exponential, and therefore had to fall back to the slower, but safer, method of computing results. Indeed, if we force Lagrange-NG to use the faster mode computing results using the matrix exponential, the numerical errors are so excessive that a result cannot be computed. As a happy accident, this showcases the utility of Lagrange-NG’s adaptive mode, where it was able pick the best method of computation without intervention from the user.</p>
    <p>However, the parallel efficiency of 0.5, or even lower as core counts increase, is rather sub-optimal. Yet, as detailed in the <ext-link xlink:href="http://dx.doi.org/10.5061/dryad.mw6m905zv" ext-link-type="uri">Supplementary Material</ext-link>, the parallel efficiency increases with increasing taxon and region numbers (strong scaling). This means that, as datasets become more taxon rich or as the size of the transition matrix grows, and run-times increase, Lagrange-NG will utilize its parallel computational resources more efficiently.</p>
    <p>Future work on Lagrange-NG includes extending the range of models that can be computed by the DIVA/DIVALIKE and BAYAREA family of models (<xref rid="CIT0012" ref-type="bibr">Ronquist, 1997</xref>; <xref rid="CIT0013" ref-type="bibr">Sanmartín et al., 2001</xref>; <xref rid="CIT0005" ref-type="bibr">Landis et al., 2013</xref>). In addition, the current models can be further optimized in three areas, although we expect unspectacular performance improvements.</p>
    <p>We produced a version of Lagrange-NG that utilized GPU acceleration for the matrix computations. Unfortunately, this method failed to produce acceptable speedups even for large datasets (10–11 regions). This is in line with the performance results of previous attempts to accelerate likelihood computations for phlyogenetic tree inference on GPUs (<xref rid="CIT0003" ref-type="bibr">Izquierdo-Carrasco et al., 2013</xref>). The fundamental difficulty is that the tree-based nature of the computation that induces a decreasing degree of parallelism as we approach the root, leaves many computational units starved for work, as is the case with the existing CPU-based course-grained parallization. It is possible that further development would produce better results, but we believe that by the time that datasets become large enough to observe large speedups, the analysis will simply be infeasible due to the exponential nature of the problem.</p>
    <p>For remaining improvements to the computational efficiency of Lagrange-NG, the first is to further refine the matrix exponential routine. While the current implementation is extremely fast, the implementation in Lagrange-NG has not been thoroughly optimized for this particular use case. In addition, one could further refine the work allocation for the coarse grained parallelization approach. The current method of assigning tasks is straight-forward, and can be improved upon by becoming aware of which nodes are “most blocking” of other tasks. It might be possible to devise an algorithm that can minimize the “task starved” period of computation, either as a clever assignment method, or as a so-called “work stealing” scheme.</p>
  </sec>
</body>
<back>
  <ack id="a1">
    <title>Acknowledgments</title>
    <p>We would like to thank Qihao Yuan for his work implementing the Krylov subspace-based implementation of the matrix exponential. We would also like to thank Lucas Czech for his help on the results plotting tool for Lagrange-NG.</p>
  </ack>
  <sec id="s91">
    <title>Supplementary Material</title>
    <p>Data available from the Dryad Digital Repository: <ext-link xlink:href="http://dx.doi.org/10.5061/dryad.mw6m905zv" ext-link-type="uri">http://dx.doi.org/10.5061/dryad.mw6m905zv</ext-link></p>
  </sec>
  <sec sec-type="data-availability" id="s9">
    <title>Data Availability</title>
    <p>The software, tools, and data used for this paper are available online at <ext-link xlink:href="https://github.com/computations/lagrange-ng" ext-link-type="uri">https://github.com/computations/lagrange-ng</ext-link>.</p>
  </sec>
  <sec id="s10">
    <title>Funding</title>
    <p>This project has received funding from the European Union’s Horizon 2020 research and innovation programme under the Marie Sklodowska-Curie grant agreement No 764840. In addition, this work was funded by the Klaus Tschira Foundation. The funding sources had no influence on topic choice, experimental design, analysis, or interpretation of the results in this article.</p>
  </sec>
  <ref-list id="r1">
    <title>References</title>
    <ref id="CIT0001">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Evans</surname><given-names>S.N.</given-names></string-name>, <string-name><surname>Matsen</surname><given-names>F.A.</given-names></string-name></person-group><year>2012</year>. <article-title>The phylogenetic Kantorovich–Rubinstein metric for environmental sequence samples</article-title>. <source>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</source><volume>74</volume>:<fpage>569</fpage>–<lpage>592</lpage>.<pub-id pub-id-type="pmid">22844205</pub-id></mixed-citation>
    </ref>
    <ref id="CIT0002">
      <mixed-citation publication-type="other"><collab>Intel Math Kernel Library.</collab><year>2022</year>. <article-title>Developer Reference for Intel® oneAPI Math Kernel Library - C</article-title>.</mixed-citation>
    </ref>
    <ref id="CIT0003">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Izquierdo-Carrasco</surname><given-names>F.</given-names></string-name>, <string-name><surname>Alachiotis</surname><given-names>N.</given-names></string-name>, <string-name><surname>Berger</surname><given-names>S.</given-names></string-name>, <string-name><surname>Flouri</surname><given-names>T.</given-names></string-name>, <string-name><surname>Pissis</surname><given-names>S. P.</given-names></string-name>, <string-name><surname>Stamatakis</surname><given-names>A.</given-names></string-name></person-group><year>2013</year>. <article-title>A Generic Vectorization Scheme and a GPU Kernel for the Phylogenetic Likelihood Library.</article-title> Pages <fpage>530</fpage>–<lpage>538</lpage><italic toggle="yes">in</italic> 2013 IEEE International Symposium on Parallel Distributed Processing, <publisher-name>Workshops and Phd Forum</publisher-name>.</mixed-citation>
    </ref>
    <ref id="CIT0004">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Johnson</surname><given-names>S. G.</given-names></string-name></person-group><year>2021</year>. <article-title>The nlopt nonlinear-optimization package</article-title>. <ext-link xlink:href="https://nlopt.readthedocs.io/en/latest/Citing_NLopt/" ext-link-type="uri">https://nlopt.readthedocs.io/en/latest/Citing_NLopt/</ext-link>.</mixed-citation>
    </ref>
    <ref id="CIT0005">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Landis</surname><given-names>M.J.</given-names></string-name>, <string-name><surname>Matzke</surname><given-names>N.J.</given-names></string-name>, <string-name><surname>Moore</surname><given-names>B.R.</given-names></string-name>, <string-name><surname>Huelsenbeck</surname><given-names>J.P.</given-names></string-name></person-group><year>2013</year>. <article-title>Bayesian Analysis of Biogeography when the Number of Areas is Large</article-title>. <source>Syst. Biol</source>. <volume>62</volume>:<fpage>789</fpage>–<lpage>804</lpage>.<pub-id pub-id-type="pmid">23736102</pub-id></mixed-citation>
    </ref>
    <ref id="CIT0006">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Matzke</surname><given-names>N. J.</given-names></string-name></person-group><year>2013</year>. <source>BioGeoBEARS: BioGeography with Bayesian (and Likelihood) Evolutionary Analysis in R Scripts</source>. <publisher-name>University of California</publisher-name>, <publisher-loc>Berkeley Berkeley, CA.</publisher-loc></mixed-citation>
    </ref>
    <ref id="CIT0007">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Moler</surname><given-names>C.</given-names></string-name>, <string-name><surname>Loan</surname><given-names>C.V.</given-names></string-name></person-group><year>2003</year>. <article-title>Nineteen Dubious Ways to Compute the Exponential of a Matrix, Twenty-Five Years Later</article-title>. <source>SIAM Rev</source>. <volume>45</volume>:<fpage>3</fpage>–<lpage>49</lpage>.</mixed-citation>
    </ref>
    <ref id="CIT0008">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nelder</surname><given-names>J.A.</given-names></string-name>, <string-name><surname>Mead</surname><given-names>R.</given-names></string-name></person-group><year>1965</year>. <article-title>A Simplex Method for Function Minimization</article-title>. <source>The Computer Journal</source><volume>7</volume>:<fpage>308</fpage>–<lpage>313</lpage>.</mixed-citation>
    </ref>
    <ref id="CIT0009">
      <mixed-citation publication-type="other"><collab>OpenBLAS: An optimzed BLAS library</collab>. <year>2022</year>. <article-title>OpenBLAS: An optimized BLAS library.</article-title></mixed-citation>
    </ref>
    <ref id="CIT0010">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ree</surname><given-names>R.H.</given-names></string-name>, <string-name><surname>Moore</surname><given-names>B.R.</given-names></string-name>, <string-name><surname>Webb</surname><given-names>C.O.</given-names></string-name>, <string-name><surname>Donoghue</surname><given-names>M.J.</given-names></string-name></person-group><year>2005</year>. <article-title>A Likelihood Framework for Inferring the Evolution of Geographic Range on Phylogenetic Trees</article-title>. <source>Evolution</source><volume>59</volume>:<fpage>2299</fpage>–<lpage>2311</lpage>.<pub-id pub-id-type="pmid">16396171</pub-id></mixed-citation>
    </ref>
    <ref id="CIT0011">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ree</surname><given-names>R.H.</given-names></string-name>, <string-name><surname>Smith</surname><given-names>S.A.</given-names></string-name></person-group><year>2008</year>. <article-title>Maximum Likelihood Inference of Geographic Range Evolution by Dispersal, Local Extinction, and Cladogenesis</article-title>. <source>Syst. Biol</source>. <volume>57</volume>:<fpage>4</fpage>–<lpage>14</lpage>.<pub-id pub-id-type="pmid">18253896</pub-id></mixed-citation>
    </ref>
    <ref id="CIT0012">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ronquist</surname><given-names>F.</given-names></string-name></person-group><year>1997</year>. <article-title>Dispersal-Vicariance Analysis: A New Approach to the Quantification of Historical Biogeography</article-title>. <source>Syst. Biol</source>. <volume>46</volume>:<fpage>195</fpage>–<lpage>203</lpage>.</mixed-citation>
    </ref>
    <ref id="CIT0013">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sanmartín</surname><given-names>I.</given-names></string-name>, <string-name><surname>Enghoff</surname><given-names>H.</given-names></string-name>, <string-name><surname>Ronquist</surname><given-names>F.</given-names></string-name></person-group><year>2001</year>. <article-title>Patterns of animal dispersal, vicariance and diversification in the Holarctic</article-title>. <source>Biol. J. Linn. Soc</source>. <volume>73</volume>:<fpage>345</fpage>–<lpage>390</lpage>.</mixed-citation>
    </ref>
    <ref id="CIT0014">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Varela</surname><given-names>L.</given-names></string-name>, <string-name><surname>Tambusso</surname><given-names>P.S.</given-names></string-name>, <string-name><surname>McDonald</surname><given-names>H.G.</given-names></string-name>, <string-name><surname>Fariña</surname><given-names>R.A.</given-names></string-name></person-group><year>2019</year>. <article-title>Phylogeny, Macroevolutionary Trends and Historical Biogeography of Sloths: Insights From a Bayesian Morphological Clock Analysis</article-title>. <source>Syst. Biol</source>. <volume>68</volume>:<fpage>204</fpage>–<lpage>218</lpage>.<pub-id pub-id-type="pmid">30239971</pub-id></mixed-citation>
    </ref>
    <ref id="CIT0015">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Vaserstein</surname><given-names>L.N.</given-names></string-name></person-group><year>1969</year>. <article-title>Markov Processes over Denumerable Products of Spaces, Describing Large Systems of Automata</article-title>. <source>Problemy Peredači Informacii</source><volume>5</volume>:<fpage>64</fpage>–<lpage>72</lpage>.</mixed-citation>
    </ref>
    <ref id="CIT0016">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Waskom</surname><given-names>M.L.</given-names></string-name></person-group><year>2021</year>. <article-title>seaborn: statistical data visualization</article-title>. <source>Journal of Open Source Software</source><volume>6</volume>:<fpage>3021</fpage>.</mixed-citation>
    </ref>
    <ref id="CIT0017">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zapletal</surname><given-names>A.</given-names></string-name>, <string-name><surname>Höhler</surname><given-names>D.</given-names></string-name>, <string-name><surname>Sinz</surname><given-names>C.</given-names></string-name>, <string-name><surname>Stamatakis</surname><given-names>A.</given-names></string-name></person-group><year>2021</year>. <article-title>The SoftWipe tool and benchmark for assessing coding standards adherence of scientific software</article-title>. <source>Sci. Rep</source>. <volume>11</volume>:<fpage>10015</fpage>.<pub-id pub-id-type="pmid">33976324</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
