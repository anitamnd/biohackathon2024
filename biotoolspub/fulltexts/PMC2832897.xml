<?DTDIdentifier.IdentifierValue article.dtd?>
<?DTDIdentifier.IdentifierType system?>
<?SourceDTD.DTDName article.dtd?>
<?SourceDTD.Version 1.0?>
<?ConverterInfo.XSLTName bmc2nlmx2.xsl?>
<?ConverterInfo.Version 2?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">BMC Bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>BMC Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1471-2105</issn>
    <publisher>
      <publisher-name>BioMed Central</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">2832897</article-id>
    <article-id pub-id-type="publisher-id">1471-2105-11-38</article-id>
    <article-id pub-id-type="pmid">20089148</article-id>
    <article-id pub-id-type="doi">10.1186/1471-2105-11-38</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Software</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>SeqTrim: a high-throughput pipeline for pre-processing any type of sequence read</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" id="A1">
        <name>
          <surname>Falgueras</surname>
          <given-names>Juan</given-names>
        </name>
        <xref ref-type="aff" rid="I1">1</xref>
        <email>juanfc@uma.es</email>
      </contrib>
      <contrib contrib-type="author" id="A2">
        <name>
          <surname>Lara</surname>
          <given-names>Antonio J</given-names>
        </name>
        <xref ref-type="aff" rid="I2">2</xref>
        <email>ajlara@scbi.uma.es</email>
      </contrib>
      <contrib contrib-type="author" id="A3">
        <name>
          <surname>Fernández-Pozo</surname>
          <given-names>Noé</given-names>
        </name>
        <xref ref-type="aff" rid="I3">3</xref>
        <email>noefp@uma.es</email>
      </contrib>
      <contrib contrib-type="author" id="A4">
        <name>
          <surname>Cantón</surname>
          <given-names>Francisco R</given-names>
        </name>
        <xref ref-type="aff" rid="I3">3</xref>
        <email>frcanton@uma.es</email>
      </contrib>
      <contrib contrib-type="author" id="A5">
        <name>
          <surname>Pérez-Trabado</surname>
          <given-names>Guillermo</given-names>
        </name>
        <xref ref-type="aff" rid="I2">2</xref>
        <xref ref-type="aff" rid="I4">4</xref>
        <email>guille@ac.uma.es</email>
      </contrib>
      <contrib contrib-type="author" corresp="yes" id="A6">
        <name>
          <surname>Claros</surname>
          <given-names>M  Gonzalo </given-names>
        </name>
        <xref ref-type="aff" rid="I2">2</xref>
        <xref ref-type="aff" rid="I3">3</xref>
        <email>claros@uma.es</email>
      </contrib>
    </contrib-group>
    <aff id="I1"><label>1</label>Departamento de Lenguajes y Ciencias de la Computación, Universidad de Málaga, Málaga, Spain</aff>
    <aff id="I2"><label>2</label>Plataforma Andaluza de Bioinformática, Universidad de Málaga, 29071 Málaga, Spain</aff>
    <aff id="I3"><label>3</label>Departamento de Biología Molecular y Bioquímica, Universidad de Málaga, 29071 Málaga, Spain</aff>
    <aff id="I4"><label>4</label>Departamento de Arquitectura de Computadores, Universidad de Málaga, Málaga, Spain</aff>
    <pub-date pub-type="collection">
      <year>2010</year>
    </pub-date>
    <pub-date pub-type="epub">
      <day>20</day>
      <month>1</month>
      <year>2010</year>
    </pub-date>
    <volume>11</volume>
    <fpage>38</fpage>
    <lpage>38</lpage>
    <history>
      <date date-type="received">
        <day>4</day>
        <month>6</month>
        <year>2009</year>
      </date>
      <date date-type="accepted">
        <day>20</day>
        <month>1</month>
        <year>2010</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>Copyright ©2010 Falgueras et al; licensee BioMed Central Ltd.</copyright-statement>
      <copyright-year>2010</copyright-year>
      <copyright-holder>Falgueras et al; licensee BioMed Central Ltd.</copyright-holder>
      <license license-type="open-access" xlink:href="http://creativecommons.org/licenses/by/2.0">
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/2.0">http://creativecommons.org/licenses/by/2.0</ext-link>), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="http://www.biomedcentral.com/1471-2105/11/38"/>
    <abstract>
      <sec>
        <title>Background</title>
        <p>High-throughput automated sequencing has enabled an exponential growth rate of sequencing data. This requires increasing sequence quality and reliability in order to avoid database contamination with artefactual sequences. The arrival of pyrosequencing enhances this problem and necessitates customisable pre-processing algorithms.</p>
      </sec>
      <sec>
        <title>Results</title>
        <p>SeqTrim has been implemented both as a Web and as a standalone command line application. Already-published and newly-designed algorithms have been included to identify sequence inserts, to remove low quality, vector, adaptor, low complexity and contaminant sequences, and to detect chimeric reads. The availability of several input and output formats allows its inclusion in sequence processing workflows. Due to its specific algorithms, SeqTrim outperforms other pre-processors implemented as Web services or standalone applications. It performs equally well with sequences from EST libraries, SSH libraries, genomic DNA libraries and pyrosequencing reads and does not lead to over-trimming.</p>
      </sec>
      <sec>
        <title>Conclusions</title>
        <p>SeqTrim is an efficient pipeline designed for pre-processing of any type of sequence read, including next-generation sequencing. It is easily configurable and provides a friendly interface that allows users to know what happened with sequences at every pre-processing stage, and to verify pre-processing of an individual sequence if desired. The recommended pipeline reveals more information about each sequence than previously described pre-processors and can discard more sequencing or experimental artefacts.</p>
      </sec>
    </abstract>
  </article-meta>
</front>
<body>
  <sec>
    <title>Background</title>
    <p>Sequencing projects and Expressed Sequence Tags (ESTs) are essential for gene discovery, mapping, functional genomics and for future efforts in genome annotations, which include identification of novel genes, gene location, polymorphisms and even intron-exon boundaries. The availability of high-throughput automated sequencing has enabled an exponential growth rate of sequence data, although not always with the desired quality. This exponential growth is enhanced by the so called "next-generation sequencing", and efforts have to be made in order to increase the quality and reliability of sequences incorporated into databases: up to 0.4% of sequences in nucleotide databases contain contaminant sequences [<xref ref-type="bibr" rid="B1">1</xref>,<xref ref-type="bibr" rid="B2">2</xref>]. The situation is even worse in the EST databases, where vector contamination rate reach 1.63% of sequences [<xref ref-type="bibr" rid="B3">3</xref>]. Hence, improved and user friendly bioinformatic tools are required to produce more reliable high-throughput pre-processing methods.</p>
    <p>Pre-processing includes filtering of low-quality sequences, identification of specific features (such as poly-A or poly-T tails, terminal transferase tails, and adaptors), removal of contaminant sequences (from vector to any other artefacts) and trimming the undesired segments. There are some bioinformatic tools that can accomplish individual pre-processing aspects (e.g. TrimSeq, TrimEST, VectorStrip, VecScreen, ESTPrep [<xref ref-type="bibr" rid="B4">4</xref>], crossmatch, Figaro [<xref ref-type="bibr" rid="B5">5</xref>]), and other programs that cope with the complete pre-processing pipeline such as PreGap4 [<xref ref-type="bibr" rid="B6">6</xref>] or the broadly used tools Lucy [<xref ref-type="bibr" rid="B7">7</xref>,<xref ref-type="bibr" rid="B8">8</xref>] and SeqClean [<xref ref-type="bibr" rid="B9">9</xref>]. Most of these require installation, are difficult to configure, environment-specific, or focused on specific needs (like a design only for ESTs), or require a change in implementation and design of either the program or the protocols within the laboratory itself. Moreover, it is not always possible to connect them easily with further processing tools for annotation or assembling. There are Web implementations (ESTAnnotator [<xref ref-type="bibr" rid="B10">10</xref>], ESTpass [<xref ref-type="bibr" rid="B11">11</xref>] or ESTExplorer [<xref ref-type="bibr" rid="B12">12</xref>]) that start with pre-processing and end with assembling and/or annotating ESTs, but no Web page is devoted exclusively to pre-processing. Further, these implementations are focused more on annotation than on a correct pre-processing, and tend to disregard the fact that poorly pre-processed sequences will produce effectively useless annotations.</p>
    <p>This paper describes SeqTrim, a software tool containing a flexible pipeline that successfully deals with pre-processing of any sequence read. Its performance is compared with other broadly used applications, and when using high-throughput datasets.</p>
  </sec>
  <sec>
    <title>Implementation</title>
    <p>SeqTrim has been programmed in Perl 5.8 using BioPerl libraries, can be executed as a command line tool or as a Web tool <ext-link ext-link-type="uri" xlink:href="http://www.scbi.uma.es/seqtrim">http://www.scbi.uma.es/seqtrim</ext-link>, and tasks are queued to a HP-SuperDome computer. The command line version is more suitable for automatic batch processing, workflows, or high-throughput analyses, while the Web interface is more appropriate for user interactivity. It makes use of the external programs phred [<xref ref-type="bibr" rid="B13">13</xref>,<xref ref-type="bibr" rid="B14">14</xref>] for obtaining sequence and quality values, <sc>BLAST</sc> to compare sequences, and RepeatMasker to mask repetitions and low complexity regions. This will work in any unix/linux release, including OSX.</p>
    <p>Provided that the dependencies are installed, uncompressing SeqTrim in <monospace>/usr/local</monospace> (or in any other directory defined in the $PATH) is sufficient to make it operable. Configuration parameters in the <monospace>seqtrim</monospace> directory are customisable by the user, transiently or permanently: working parameters can be permanently modified by editing the <monospace>'seqtrim.conf'</monospace>, or changed for a single run via command-line options or the Web interface. The <monospace>seqtrim</monospace> directory also contains the necessary databases, an editable file called <monospace>'RE_sites.txt'</monospace> that contains the usable restriction sites, and another editable file named <monospace>'adaptorSeqs.txt'</monospace> which contains a list of default adaptor sequences. Database modification is achieved simply by adding or removing sequences in <sc>FASTA</sc> format in the <monospace>seqtrim/DB</monospace> directory. Before each execution, SeqTrim verifies if something has been added to databases for incorporation of new sequences thereafter.</p>
    <p>The pipeline underlying SeqTrim runs through four independent and interchangeable processes (vector and other specialised features removal, quality trimming, indetermination trimming, and contamination removal) plus two optional ending steps (artefact removal, and low complexity and repeat masking) (Fig. <xref ref-type="fig" rid="F1">1</xref>). One of the main strengths of SeqTrim is that, even if a default pipeline order is provided, users can change the flow completely, or can skip one or more steps.</p>
    <fig id="F1" position="float">
      <label>Figure 1</label>
      <caption>
        <p><bold>Detailed data-flow diagram of the SeqTrim pipeline</bold>. It consists of four major steps (vector cleaning and removal of specialised features, two quality trimming steps, and contamination removal) that can be executed in any order or skipped, and two ending steps (artefact removal, and low complexity and repeat masking). The output is stored in a private area defined by an e-mail address, and can be looked up asynchronously.</p>
      </caption>
      <graphic xlink:href="1471-2105-11-38-1"/>
    </fig>
    <p>Execution time for a single sequence will depend on the complexity of the given sequence. For example, SeqTrim (without masking with RepeatMasker) takes 0.304 s/read in a 2.2 GHz Intel Core 2 duo processor and 0.477 s/read in a 1.6 GHz Itanium 2 processor when analysing 96 EST reads (a complete micro-plate) with an average length of 755 nt. When it has been tested (without the need for vector cleaning nor removal of other specialised features) with 1000 GS-FLX pyrosequencing reads with an average length of 236 nt, execution takes 0.074 s/read and 0.083 s/read, respectively, in the processors mentioned above. A true high-throughput use of SeqTrim must consider use of the command line version, since the Web interface facet becomes unsatisfactory when showing jobs with more than 10,000 reads; the browser taking 15 s to reply to a single click. However, the SeqTrim Web server is able to process up to 40,000 reads without "hanging", Safari always reacting faster than Firefox.</p>
  </sec>
  <sec>
    <title>Algorithm</title>
    <p>The recommended SeqTrim pipeline starts with vector detection using vector libraries and the removal of special features. The next step involves to trimming low quality 5'- and 3'-tails. Finally, any sequence coming from a contaminating source is removed. Two optional end steps are focused on removing any other experimental artefacts arising from molecular modifications and the masking of low complexity regions.</p>
    <sec>
      <title>Input and output</title>
      <p>SeqTrim accepts usual sequence formats: <sc>FASTA</sc> file(s) with or without the corresponding quality value file, phd format file from phred, and chromatograms, all of them with any number of sequences and optionally compressed in zip format. Text files are directly processed, but when input sequences are chromatograms, the external program phred is employed to obtain the quality value file. It must be understood that phred's low quality trimming option is disabled for such a conversion. Since the first word in the description line of every input sequence is considered its identifier, checks for sequence name duplications, as well as consistency between the sequence file and the quality value file (if provided), are performed.</p>
      <p>Several output formats (like a <sc>FASTA</sc> file containing only trimmed inserts, a text file containing user-readable information concerning the trimming events for each sequence, a text file containing the names of the rejected sequences, or a <sc>FASTA</sc> file with masked sequences) can be obtained either from the Web interface or the command line. Nucleotides whose quality value (QV) is not greater than 20 (by default) are changed to lowercase. A coloured output of each sequence can also be seen on the screen, either using the command line or the Web interface (Fig. <xref ref-type="fig" rid="F2">2</xref>), which is intended to help users in the evaluation of pre-processing results. Results will be stored for at least one month in the Web server using an e-mail address as identifier since no account is needed for SeqTrim usage.</p>
      <fig id="F2" position="float">
        <label>Figure 2</label>
        <caption>
          <p><bold>Example of sequence trimming using different sets of sequences</bold>. The upper-left frame displays the status of all executions of SeqTrim made by the user ordered by date and time of run. The upper-right frame displays the list of the sequences analysed in a single query with original length, and range and length of the trimmed sequence. Buttons for saving result files and to obtain parameters and execution order are displayed at the end of the sequence list. The bottom frame shows the original sequence coloured according to the different segments that have been removed. Legend on the right explains colour codes and a button to ask for more details are presented. Sequences to be detailed in the bottom frame are the same as listed in the upper-right frame.</p>
        </caption>
        <graphic xlink:href="1471-2105-11-38-2"/>
      </fig>
    </sec>
    <sec>
      <title>Vector cleaning and removal of specialised features</title>
      <p>The recommended first pipeline step starts by detection of cloning vector by means of NCBI's UniVec and the EMBL's emvec vector/adaptor libraries using <sc>BLAST</sc> with relaxed parameters <monospace>(q -5, G 3, E 3, F 'm D', e 1e-10)</monospace> to account for higher error rates at the beginning and end of reads. Users do not need then to specify the cloning vector. <sc>BLAST</sc> alignment is parsed to identify regions that correspond to vector sequences, even if these regions are spliced into smaller DNA fragments that match in opposite orientations. SeqTrim is designed to locate cloning restriction sites only when cloning vector was not identified. Cloning restriction sites must be entered in the parameters panel of SeqTrim.</p>
      <p>Next is location of special features [adaptors, poly-A tails (only for ESTs) and poly-T tails (only for ESTs, which indicates that the sequence is in the reverse orientation)] appearing in many sequences. Special features must be removed since they (i) provide false sequences, (ii) mislead assembling or clustering algorithms that can be further used with these sequences, and (iii) mislead researchers who use these contaminated sequences. Adaptors are located with <sc>BLAST2SEQ</sc>, customising its parameters for short sequences <monospace>(W 7, F 'F', program 'blastn')</monospace>. Poly-A and poly-T tails are detected by the function <monospace>findPolyATs</monospace> (Appendix) developed by the authors, which includes the removal of one or more A's at the 3' end of a sequence. The algorithm has been set to produce maximal sensitivity while maintaining a very strict rule for false positives: sequences that are not compliant with all necessary criteria are always rejected. In the case of ESTs, insert orientation is detected by the presence of poly-A or T tails, and chimeric inserts are determined by the concomitant presence of two of these tails in the same sequence. Poly-A or poly-T detection is skipped if input sequence does not come from a cDNA, in order to gain CPU time. In the parameters panel, users can specify adaptors, DNA source (genomic or cDNA) and orientation (if known) of inserts.</p>
    </sec>
    <sec>
      <title>Quality trimming</title>
      <p>A sequence read can contain bases of very low quality, which can mislead further processing. Therefore, the base-calling quality assessment for each nucleotide is taken into account to trim the original sequence, in order to obtain the longest sequence with the highest quality. In cases where the input sequences are in a text <sc>FASTA</sc> format and low quality nucleotides are expressed by N's (indetermination), SeqTrim can extract the largest subsequence containing less than 18% of indetermination. Values for assessing sequence quality can be changed in the parameter panel. Since not all sequences include N's, quality trimming is split into two independent steps (Fig. <xref ref-type="fig" rid="F1">1</xref>) in order to enable users to skip the useless function. Trimming by QV is automatically skipped when input sequences are not chromatograms or a quality value file is not entered. Stringency of QV trimming can also be changed by means of the parameter panel.</p>
    </sec>
    <sec>
      <title>Removal of contaminant sequences</title>
      <p>During the experimental process, cloned sequences can result from contamination sources such as DNA from the <italic>Escherichia coli </italic>genome, cloning vector, cell plasmids, organelles, viruses, yeast, or humans (due to handling). Screening of contaminant sequences is based on <sc>BLAST</sc> comparisons with trimmed sequences against a database of likely contaminants using default parameters and an expected cutoff fixed to 1e-3 and a minimal score of 60. The <sc>BLAST</sc> result is analysed by the in-house algorithm <monospace>FindContaminantSeqs</monospace> (Appendix) to establish when hits are real contaminations. Users can vary the stringency of this analysis by changing the minimal length of sequence considered as a significant contaminant in the parameter panel. SeqTrim is distributed with the genomes of <italic>E. coli</italic>, <italic>Saccharomyces cerevisiae</italic>, lambda phage and several mitochondria. More databases can be added (or removed) by the user. Length, position and identity of the contaminant sequence are returned for user information. The vector database is re-screened again at this moment, as well as adaptors, which serves to identify putative chimeras.</p>
    </sec>
    <sec>
      <title>Removal of other artefacts</title>
      <p>This optional step is intended to be performed at the end of pre-processing, since it is focused on removing any experimental artefacts introduced in the apparently cleaned insert that are owing to molecular modifications. For example, extensions introduced by the terminal transferase enzyme, the N's and/or X's at both ends, and the T's from the 5'-end and/or A's from the 3'-end are discarded here. These removals are accomplished by means of the in-house function <monospace>Look_for_artefacts</monospace> (see Appendix).</p>
    </sec>
    <sec>
      <title>Masking low complexity regions and repeats</title>
      <p>This is the last step of the SeqTrim pipeline, in which the unwanted sequence is not removed but masked, since low complexity regions and repeats are part of the real sequence, even if they can mislead further computer analysis. Low complexity regions due to simple nucleotide repeats are masked by the in-house function <monospace>LowComplexityMasking</monospace> (see Appendix). Repeats in nucleotide sequences are masked by employing RepeatMasker using species-specific repeat libraries obtained from the RepBase [<xref ref-type="bibr" rid="B15">15</xref>]. The searching algorithm for RepeatMasker has been fixed to WU-<sc>BLAST</sc> in order to reduce the time spent in one sequence analysis.</p>
    </sec>
    <sec>
      <title>Rejection criteria</title>
      <p>A pre-processed sequence is finally rejected if it complies with one the following criteria: (1) there is no insert between identified cloning vector boundaries; (2) the usable sequence is not long enough (less than 100 bp by default, which can be changed in the parameter panel); (3) there are possibly two inserts (chimeric inserts are determined by the presence of two poly-A/T tails, or detection of an internal adaptor and/or cloning restriction site); (4) the whole insert was masked. In contrast to other pre-processing algorithms, absence of cloning vector is not a reason for rejection since sometimes useful sequence starts beyond vector boundaries, or there can exist vector rearrangements that make it unrecognisable although the insert is preserved (results not shown).</p>
    </sec>
  </sec>
  <sec>
    <title>Results</title>
    <p>Developer versions of SeqTrim have been used for some years at Málaga University using actual data from various previous studies such as ESTs from xylem tissue of <italic>Pinus pinaster </italic>[<xref ref-type="bibr" rid="B16">16</xref>], ESTs from photosynthetic tissues of <italic>Pinus sylvestris </italic>(C Avila <italic>et al.</italic>, unpublished results), SSH gene libraries from pine (F.R. Cantón <italic>et al.</italic>, manuscript in preparation), or assembling BAC sequences (M. G. Claros <italic>et al.</italic>, unpublished results). Now, a collection of comparative analyses are able to demonstrate that SeqTrim outperforms other pre-processing software and that it is able to handle huge amounts of sequence.</p>
    <sec>
      <title>Comparison with other algorithms</title>
      <p>SeqTrim performance has been compared to other widely used pre-processors such as SeqClean (which acts similarly to SeqTrim), Lucy2 [<xref ref-type="bibr" rid="B8">8</xref>] (which makes use of several base caller algorithms and additional specific algorithms) and ESTPrep [<xref ref-type="bibr" rid="B4">4</xref>] (which makes use of a heuristic match function to detect sequence features, and phred to obtain quality values). Although cross-match is a restricted Smith-Waterman algorithm and has been incorporated into some EST processing packages, it has been discarded because it does not remove but masks vector-like regions, takes too much time to execute, and is not better than SeqClean or Lucy [<xref ref-type="bibr" rid="B3">3</xref>]. Since ESTs are the only kind of sequence that can be used in all programs, a collection of 576 EST chromatograms obtained in our laboratory [<xref ref-type="bibr" rid="B16">16</xref>] was used as the testing sequence set. These reads resulted in 438,550 nucleotides, of which 53.8% were considered insert by ESTPrep, 53.6% by SeqClean, 37.4% by Lucy and 31.74% by SeqTrim. The sequence reads had an average length of 761 nucleotides but, once pre-processed, the average insert size was 569 for ESTPrep, 562 for SeqClean, 490 for Lucy and 409 for SeqTrim. Both kinds of data clearly show that SeqTrim renders the shortest sequences; in fact, SeqTrim provides the shortest final sequence in 218 cases, the second-shortest in 19 cases, the third-shortest in only two cases, and never provides the longest sequence.</p>
      <p>Even with shorter sequences, SeqTrim is able to retain more information about trimmed sequences than the other programs (Fig. <xref ref-type="fig" rid="F2">2</xref>). With the default pipeline, SeqTrim is able to detect (Fig. <xref ref-type="fig" rid="F2">2</xref>) the presence of cloning vector at the 5'-end and the existence of a poly-T segment, which indicates that this sequence was cloned in reverse. Hence, SeqTrim can return a reverse complement of such a sequence in order to acquire it in the same orientation as the others. If quality trimming had been performed in the first instance, the poly-T would have been removed and the researcher would have recovered a trimmed sequence in the correct orientation. As can be seen in the details of Fig. <xref ref-type="fig" rid="F2">2</xref>, the user is informed that this sequence was reversed.</p>
      <p>With regard to the number of passed/rejected sequences (Fig. <xref ref-type="fig" rid="F3">3</xref>), ESTPrep validates 415, Lucy 335, SeqClean 418 and SeqTrim 348. Lucy is therefore the most restrictive, with SeqTrim nearly as restrictive, and SeqClean and ESTPrep each returning a similar result and being the most permissive. Equivalent outcomes were also derived when assessing the number of sequences instead of the number of nucleotides. Concordance among the algorithms was tested by assessing the number of sequences accepted and rejected. The four software programs agree in 352 sequences (113 rejected by all and 239 accepted by all, Fig. <xref ref-type="fig" rid="F3">3B</xref>), which correspond to 61.1% of sequences. If agreement is relaxed to three coincidences, the concordance rate increases to 93.4%. SeqTrim is primarily consistent with ESTPrep and SeqClean (93.4% and 95.1%, respectively, Fig. <xref ref-type="fig" rid="F3">3C</xref>), with ESTPrep and SeqClean showing only slightly less consistency between them (92.0%). SeqClean ist not as consistent with Lucy (71.5%), an Lucy disagrees similarly with ESTPrep and SeqClean (70.5% and 72.4%, respectively).</p>
      <fig id="F3" position="float">
        <label>Figure 3</label>
        <caption>
          <p><bold>Performance comparison of SeqTrim, SeqClean, Lucy and ESTPrep</bold>. A, Overview of rates of sequence acceptance and rejection by each tested algorithm. B, Degree of agreement from concordance in rejection (0:4, which means none of the four implementations accept the same sequence) to concordance in acceptance (4:0, which means that the four accept the same sequence). C, Degree of agreement of SeqTrim with respect to the other three programs.</p>
        </caption>
        <graphic xlink:href="1471-2105-11-38-3"/>
      </fig>
      <p>Agreement between the most coincident softwares (SeqTrim and SeqClean) was cross-verified. When sequences trimmed by SeqTrim were entered into SeqClean, no changes were observed, indicating that both items of software remove the same features. On the contrary, when sequences trimmed by SeqClean were entered into SeqTrim, most of them were slightly shorter mainly due to adaptor removal that SeqClean did not detect, although sometimes differences were related to low quality sequences, or chimeric sequences, that were not removed by SeqClean (results not shown).</p>
    </sec>
    <sec>
      <title>Trimming accuracy</title>
      <p>The fact that SeqTrim apparently provides the shortest sequences could be explained by over-trimming. Testing against some "gold-standards" was therefore conducted to determine trimming accuracy. A set of 100 artificially obtained sequences of 312 nt long from <italic>P. pinaster </italic>genomic DNA were enlarged with known vector and/or adaptor sequence at the 5'-end of the insert, and nothing and/or poly-A and/or adaptor and/or vector sequence at the 3'-end (headers of Table <xref ref-type="table" rid="T1">1</xref>). Overall, those datasets of artificial sequences simulate 800 DNA cloning events into <italic>Bam</italic>HI-<italic>Hin</italic>dIII cloning sites of pBlueScript-FL with or without adaptors, and having or not reached the 3' cloning vector in the sequencing process. They simulate different cloning events handled by SeqTrim with a precise knowledge of insert start and end points. Hence, accuracy of SeqTrim trimming can be examined, except trimming based on quality values (QV's).</p>
      <table-wrap id="T1" position="float">
        <label>Table 1</label>
        <caption>
          <p>SeqTrim accuracy evaluated with artificial sequences</p>
        </caption>
        <table frame="hsides" rules="groups">
          <thead>
            <tr>
              <th/>
              <th align="center" colspan="3">Vu+I</th>
              <th align="center" colspan="3">Vu+I+Vd</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td/>
              <td align="center">
                <bold>Expected</bold>
              </td>
              <td align="center">
                <bold>Obs (enz)</bold>
              </td>
              <td align="center">
                <bold>Obs (-enz)</bold>
              </td>
              <td align="center">
                <bold>Expected</bold>
              </td>
              <td align="center">
                <bold>Obs (enz)</bold>
              </td>
              <td align="center">
                <bold>Obs (-enz)</bold>
              </td>
            </tr>
            <tr>
              <td colspan="7">
                <hr/>
              </td>
            </tr>
            <tr>
              <td align="right">Sequence size</td>
              <td align="center">362</td>
              <td/>
              <td/>
              <td align="center">412</td>
              <td/>
              <td/>
            </tr>
            <tr>
              <td align="right">Insert length</td>
              <td align="center">312</td>
              <td align="center">311.71</td>
              <td align="center">311.71</td>
              <td align="center">312</td>
              <td align="center">310.7</td>
              <td align="center">311.51</td>
            </tr>
            <tr>
              <td align="right">Insert-start point</td>
              <td align="center">51</td>
              <td align="center">51.18</td>
              <td align="center">51.2</td>
              <td align="center">51</td>
              <td align="center">51.2</td>
              <td align="center">51.2</td>
            </tr>
            <tr>
              <td align="right">Insert-end point</td>
              <td align="center">362</td>
              <td align="center">361.9</td>
              <td align="center">36.91</td>
              <td align="center">362</td>
              <td align="center">360.9</td>
              <td align="center">361.71</td>
            </tr>
            <tr>
              <td align="right">Rejected</td>
              <td/>
              <td align="center">3</td>
              <td align="center">0</td>
              <td/>
              <td align="center">1</td>
              <td align="center">0</td>
            </tr>
            <tr>
              <td align="right">Mistakenly processed</td>
              <td/>
              <td align="center">9</td>
              <td align="center">0</td>
              <td/>
              <td align="center">5</td>
              <td align="center">0</td>
            </tr>
            <tr>
              <td colspan="7">
                <hr/>
              </td>
            </tr>
            <tr>
              <td/>
              <td align="center" colspan="3">
                <bold>Vu+I+pA</bold>
              </td>
              <td align="center" colspan="3">
                <bold>Vu+I+pA+Vd</bold>
              </td>
            </tr>
            <tr>
              <td colspan="7">
                <hr/>
              </td>
            </tr>
            <tr>
              <td/>
              <td align="center">
                <bold>Expected</bold>
              </td>
              <td align="center">
                <bold>Obs (enz)</bold>
              </td>
              <td align="center">
                <bold>Obs (-enz)</bold>
              </td>
              <td align="center">
                <bold>Expected</bold>
              </td>
              <td align="center">
                <bold>Obs (enz)</bold>
              </td>
              <td align="center">
                <bold>Obs (-enz)</bold>
              </td>
            </tr>
            <tr>
              <td colspan="7">
                <hr/>
              </td>
            </tr>
            <tr>
              <td align="right">Sequence size</td>
              <td align="center">392</td>
              <td/>
              <td/>
              <td align="center">442</td>
              <td/>
              <td/>
            </tr>
            <tr>
              <td align="right">Insert length</td>
              <td align="center">312</td>
              <td align="center">311.32</td>
              <td align="center">311.33</td>
              <td align="center">312</td>
              <td align="center">310.72</td>
              <td align="center">311.33</td>
            </tr>
            <tr>
              <td align="right">Insert-start point</td>
              <td align="center">51</td>
              <td align="center">51.2</td>
              <td align="center">51.2</td>
              <td align="center">51</td>
              <td align="center">51.2</td>
              <td align="center">51.2</td>
            </tr>
            <tr>
              <td align="right">Insert-end point</td>
              <td align="center">362</td>
              <td align="center">361.52</td>
              <td align="center">361.53</td>
              <td align="center">362</td>
              <td align="center">360.92</td>
              <td align="center">361.53</td>
            </tr>
            <tr>
              <td align="right">Rejected</td>
              <td/>
              <td align="center">1</td>
              <td align="center">0</td>
              <td/>
              <td align="center">1</td>
              <td align="center">0</td>
            </tr>
            <tr>
              <td align="right">Mistakenly processed</td>
              <td/>
              <td align="center">3</td>
              <td align="center">0</td>
              <td/>
              <td align="center">5</td>
              <td align="center">0</td>
            </tr>
            <tr>
              <td colspan="7">
                <hr/>
              </td>
            </tr>
            <tr>
              <td/>
              <td align="center" colspan="3">
                <bold>Vu+Au+I</bold>
              </td>
              <td align="center" colspan="3">
                <bold>Vu+Au+I+Ad+Vd</bold>
              </td>
            </tr>
            <tr>
              <td colspan="7">
                <hr/>
              </td>
            </tr>
            <tr>
              <td/>
              <td align="center">
                <bold>Expected</bold>
              </td>
              <td align="center">
                <bold>Obs (enz)</bold>
              </td>
              <td align="center">
                <bold>Obs (-enz)</bold>
              </td>
              <td align="center">
                <bold>Expected</bold>
              </td>
              <td align="center">
                <bold>Obs (enz)</bold>
              </td>
              <td align="center">
                <bold>Obs (-enz)</bold>
              </td>
            </tr>
            <tr>
              <td colspan="7">
                <hr/>
              </td>
            </tr>
            <tr>
              <td align="right">Sequence size</td>
              <td align="center">375</td>
              <td/>
              <td/>
              <td align="center">438</td>
              <td/>
              <td/>
            </tr>
            <tr>
              <td align="right">Insert length</td>
              <td align="center">312</td>
              <td align="center">311.9</td>
              <td align="center">311.91</td>
              <td align="center">312</td>
              <td align="center">311.9</td>
              <td align="center">311.91</td>
            </tr>
            <tr>
              <td align="right">Insert-start point</td>
              <td align="center">64</td>
              <td align="center">64</td>
              <td align="center">64</td>
              <td align="center">64</td>
              <td align="center">64</td>
              <td align="center">64</td>
            </tr>
            <tr>
              <td align="right">Insert-end point</td>
              <td align="center">375</td>
              <td align="center">374.9</td>
              <td align="center">374.91</td>
              <td align="center">375</td>
              <td align="center">374.9</td>
              <td align="center">374.91</td>
            </tr>
            <tr>
              <td align="right">Rejected</td>
              <td/>
              <td align="center">2</td>
              <td align="center">0</td>
              <td/>
              <td align="center">0</td>
              <td align="center">0</td>
            </tr>
            <tr>
              <td align="right">Mistakenly processed</td>
              <td/>
              <td align="center">6</td>
              <td align="center">0</td>
              <td/>
              <td align="center">0</td>
              <td align="center">0</td>
            </tr>
            <tr>
              <td colspan="7">
                <hr/>
              </td>
            </tr>
            <tr>
              <td/>
              <td align="center" colspan="3">
                <bold>Vu+Au+I+pA</bold>
              </td>
              <td align="center" colspan="3">
                <bold>Vu+Au+I+pA+Ad+Vd</bold>
              </td>
            </tr>
            <tr>
              <td colspan="7">
                <hr/>
              </td>
            </tr>
            <tr>
              <td/>
              <td align="center">
                <bold>Expected</bold>
              </td>
              <td align="center">
                <bold>Obs (enz)</bold>
              </td>
              <td align="center">
                <bold>Obs (-enz)</bold>
              </td>
              <td align="center">
                <bold>Expected</bold>
              </td>
              <td align="center">
                <bold>Obs (enz)</bold>
              </td>
              <td align="center">
                <bold>Obs (-enz)</bold>
              </td>
            </tr>
            <tr>
              <td colspan="7">
                <hr/>
              </td>
            </tr>
            <tr>
              <td align="right">Sequence size</td>
              <td align="center">405</td>
              <td/>
              <td/>
              <td align="center">468</td>
              <td/>
              <td/>
            </tr>
            <tr>
              <td align="right">Insert length</td>
              <td align="center">312</td>
              <td align="center">311.53</td>
              <td align="center">311.53</td>
              <td align="center">312</td>
              <td align="center">311.53</td>
              <td align="center">311.53</td>
            </tr>
            <tr>
              <td align="right">Insert-start point</td>
              <td align="center">64</td>
              <td align="center">64</td>
              <td align="center">64</td>
              <td align="center">64</td>
              <td align="center">64</td>
              <td align="center">64</td>
            </tr>
            <tr>
              <td align="right">Insert-end point</td>
              <td align="center">375</td>
              <td align="center">374.53</td>
              <td align="center">374.53</td>
              <td align="center">375</td>
              <td align="center">374.53</td>
              <td align="center">374.53</td>
            </tr>
            <tr>
              <td align="right">Rejected</td>
              <td/>
              <td align="center">0</td>
              <td align="center">0</td>
              <td/>
              <td align="center">0</td>
              <td align="center">0</td>
            </tr>
            <tr>
              <td align="right">Mistakenly processed</td>
              <td/>
              <td align="center">0</td>
              <td align="center">0</td>
              <td/>
              <td align="center">0</td>
              <td align="center">0</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <p>Vu, 50 nucleotides preceding the <italic>Bam</italic>HI restriction site of pBlueScript-FL. Vd, 50 nucleotides following the <italic>Hin</italic>dIII restriction site of pBlueScript-FL. I, a fragment of 312 nucleotides from <italic>Pinus pinaster </italic>genomic DNA. pA, poly-A tail of 30 A's. Au, upstream 5'-adaptor, containing the sequence GATCCGTTGCTGTCGTCG. Ad, downstream 3'-adaptor, containing the sequence CGGCCGCGTCGACAAGCT. 'Expected' corresponds to theoretical mean values for each set of artificial sequences. 'Obs (enz)' are the mean values obtained using SeqTrim with the cloning restriction sites specified. 'Obs (-enz)' are the mean values obtained using SeqTrim with no cloning restriction site specified.</p>
        </table-wrap-foot>
      </table-wrap>
      <p>Launching SeqTrim with the corresponding parameters and restriction sites provided results shown in Table <xref ref-type="table" rid="T1">1</xref>, columns 'Obs (enz)'. Rejection and incorrect processing of several sequences was not unexpected since all of these corresponded to inserts containing one of the cloning restriction sites within it. Note that a real experiment would always result in inserts without cloning sites within it, except when partially digested DNA or chimeric inserts were cloned, and in actuality, finding a cloning site within an insert is a reason to discard such an insert. As restriction site use is limited to cases where the cloning vector was not identified (see above), the same sequences were analysed without specification of restriction enzymes (columns 'Obs (-enz)' in Table <xref ref-type="table" rid="T1">1</xref>) showing that the observed mean positions and lengths were almost identical to what was expected, and that no sequence rejection occurred. A manual inspection of results revealed that the small differences found (always lesser than 2 nucleotides) corresponded to chance instances in which the first nucleotide of the insert is the same as that following the <italic>Bam</italic>HI site or preceding the <italic>Hin</italic>dIII site of the cloning vector. In the cases were the last insert nucleotide is an A, manual inspection revealed that it was removed with the poly-A tail. In conclusion, precision of SeqTrim clips is virtually guaranteed and no over-trimming is found.</p>
    </sec>
    <sec>
      <title>Performance with high-throughput reads</title>
      <p>Sequencing projects have become a true high-throughput process with the advent of next-generation sequencing. It is of interest to test if very large-scale sequencing approaches can be processed using SeqTrim with the same previously described precision. Thus, 30,893 random reads from various different organisms from the NCBI Trace Archive were selected (Fig. <xref ref-type="fig" rid="F4">4</xref>), although no information was found regarding the pre-processor used to obtain the final clips. The first remarkable finding is that SeqTrim rejected 3418 reads in the worm <italic>Caenorhabditis elegans </italic>and 1146 in the plant <italic>Arabidopsis thaliana </italic>(Fig. <xref ref-type="fig" rid="F4">4A</xref>) mainly due to the presence of two inserts in the sequence. The surprisingly high number of rejected reads in the worm is explained by the low quality sequences considered in the dataset. Since human sequences were annotated as 're-sequencing', they were treated as genomic DNA and only 534 reads were rejected; since no restriction site was defined in SeqTrim parameters because the repository does not mention it, no read will be rejected by reason of having two inserts. Another significant aspect is that some sequence reads were assessed as being too short to be useful. Only a few reads (34 in humans, 3 in the worm and 45 in the plant) contained contaminant sequences (sequences that do not belong to the nuclear material of the analysed organism). It is clear that the <italic>C. elegans </italic>reads do not have the same standard of quality as the others. It can be also inferred that SeqTrim is able to detect cloning or sequencing artefacts that would not provide useful sequence for researchers in any kind of sequencing approach.</p>
      <fig id="F4" position="float">
        <label>Figure 4</label>
        <caption>
          <p><bold>Analysis of 30,893 ESTs from three different species</bold>. 10,000 ESTs from the plant <italic>Arabidopsis thaliana</italic>, 10,244 ESTs from the worm <italic>Caenorhabditis elegans </italic>and 10,649 ESTs from human were clipped with SeqTrim. A, SeqTrim rejections grouped by rationale. B, percentage of nucleotides belonging to the four main SeqTrim classifications of trimming types. Rejected reads were excluded from calculations.</p>
        </caption>
        <graphic xlink:href="1471-2105-11-38-4"/>
      </fig>
      <p>Concerning trimmed nucleotides, Fig. <xref ref-type="fig" rid="F4">4B</xref> shows the distribution of those removed due to low QV or because they were N's, cloning vector, or a specialised feature. The reads from the three species contain a high number of nucleotides discarded for having a low QV (from 17.9% in <italic>A. thaliana </italic>to 25.5% in <italic>C. elegans</italic>). These high values can be explained by the fact that the SeqTrim QV cutoff is more stringent than that of other pre-processors, although stringency can be changed in the parameters panel (see above). Additionally, human and <italic>C. elegans </italic>reads contain very little vector sequence (3.2% and 0.7%, respectively) while those from <italic>A. thaliana </italic>contain 23.1%. The specialised features are present at significant levels in <italic>A. thaliana </italic>ESTs, but not in the other two species. Is it important to note that, although being at low numbers, only the <italic>A. thaliana </italic>reads lack N's. As a consequence of trimming, 71.2% of nucleotides correspond to insert in humans, while 40.4% are insert in <italic>C. elegans </italic>and 43.9% in <italic>A. thaliana</italic>, in contrast to figures of 74.7%, 66.7% and 48.1%, respectively, that were obtained from the provided metadata.</p>
      <p>A comparison of SeqTrim results of these sequences with the final clips reported at the NCBI was then carried out. This comparison was focused on variations of the start position and insert length since it is the only affordable comparison regarding NCBI metadata (unfortunately, only a few reads had specified which part of the sequence was removed by QV or which part is vector). The final insert in 2510 reads of <italic>A. thaliana </italic>and in 686 reads of human start at almost the same position as described in the database (below ± 5 nt), but none in the worm. The reason is that most <italic>C. elegans </italic>reads contain long stretches of cloning vector that were not removed or reported by researchers. On the other hand, 4428 reads in <italic>A. thaliana</italic>, 4699 in <italic>C. elegans </italic>and 1135 in human started in quite different positions (beyond ± 25 nt). Finally, 1916 reads in <italic>A. thaliana</italic>, 2127 in <italic>C. elegans </italic>and 8294 in human differ slightly from database reports. In any case, SeqTrim always reported shorter inserts than the database (with mean differences ranging from 1 to 318 nt). Visual inspection of the most divergent results showed that the major differences are due to more accurate localisation of the cloning vector, more stringent QV cutoff, and removal of N's. In conclusion, SeqTrim is able to analyse high-throughput Sanger sequences providing a final set of inserts of high quality and unlikely to have contaminant sequences. Moreover, it seems to outperform the software used for pre-processing the NCBI-published sequences.</p>
    </sec>
  </sec>
  <sec>
    <title>Discussion</title>
    <p>Even if there are many DNA pre-processing algorithms in the bioinformatics literature, getting them to work correctly may be very difficult, and getting them to process high-throughput data requires an extra programming effort, to enable consideration of unlikely special cases that appear when handling large amounts of sequences or when data quality are very low [<xref ref-type="bibr" rid="B7">7</xref>]. Moreover, the arrival of next-generation sequencing with new experimental approaches and slightly different output format also reinforces the requirement for new software for pre-processing in a reasonable time period. Collaboration between computer scientists and biologists for SeqTrim development has permitted successful implementation of a theoretical design for a bioinformatic solution for these types of problems, and anticipated future problems.</p>
    <p>The use of sequence pre-processors is expected to be in a pipeline with other programs [<xref ref-type="bibr" rid="B4">4</xref>,<xref ref-type="bibr" rid="B12">12</xref>,<xref ref-type="bibr" rid="B17">17</xref>,<xref ref-type="bibr" rid="B18">18</xref>]. Sometimes, constructing a pipeline is not easy, mainly due to input/output compatibility or other program peculiarities [<xref ref-type="bibr" rid="B19">19</xref>]. This has been considered in SeqTrim, since its flexibility regarding input and output formats contrasts with other sequence pre-processors that admit only one single type of sequence file: SeqClean, ESTPass or ESTPrep accept <sc>FASTA</sc> sequences while Lucy and pregap4 accept chromatograms. None accepts <sc>FASTA</sc> sequences plus qualities as SeqTrim does. Concerning the output compatibility, saving final sequences as trimmed or masked sequences enables the possibility if including SeqTrim in other known workflows such as phred/crossmatch/repeatmasker/phrap, or EST2UNI [<xref ref-type="bibr" rid="B19">19</xref>]. Moreover, most sequence pre-processors must be used only as command line programs (SeqClean, ESTPrep, TrimSeq, phred/crossmatch, Figaro), only as Web pages (VecScreen, EMBVec Query) or as command line and a GUI interface (Lucy, pregap4). No Web site is devoted exclusively to pre-processing, since they were included in more general pipelines (for example EGAssembler [<xref ref-type="bibr" rid="B18">18</xref>], ESTPass [<xref ref-type="bibr" rid="B11">11</xref>] or ESTExplorer [<xref ref-type="bibr" rid="B12">12</xref>]). However, SeqTrim usage was designed to be affordable by any type of user, by means of its Web interface or as a standalone application. Accordingly, the command line version is able to cope with high-throughput sequencing data while the Web interface is limited to a few thousand sequences, due to browser capabilities and the number of simultaneous connection. Nevertheless, taking into account that most SeqTrim users would be laboratory scientists who wish to pre-process their own data in order to determine how accurately their experiment were carried out, the coloured output for differentiation of trimmed regions in each sequence (Fig. <xref ref-type="fig" rid="F2">2</xref>) will facilitate interpretation of results as well as a comparison between cleaned and original sequences. In contrast to Lucy, original and cleaned sequences are on the same string, instead of two synchronised scrolling panels, to enable a first-look analysis.</p>
    <p>Unlike other equivalent software, installation of SeqTrim does not require special skills, because there is nothing to compile, and only requires installation of freely available NCBI-<sc>BLAST</sc>, bioperl libraries, phred (only for processing chromatograms) and RepeatMasker (optional step). Configuration files and databases provided with SeqTrim can be customised, although most parameters (except restriction sites and adaptors) will never require change. In fact, SeqTrim offers more customisation possibilities than SeqClean or ESTPrep, and nearly as many as PreGap4, but does not present more than the overwhelming forty parameters that can be modified in Lucy [<xref ref-type="bibr" rid="B8">8</xref>]. Concerning the final performance, this study clearly demonstrated that usage of SeqTrim has significantly reduced the time and complexity involved in a number of gene discovery projects while increasing reliability (Figs. <xref ref-type="fig" rid="F3">3</xref> and <xref ref-type="fig" rid="F4">4</xref>). Results with artificial and high-throughput sequences (Fig. <xref ref-type="fig" rid="F4">4</xref> and Table <xref ref-type="table" rid="T1">1</xref>) suggested that SeqTrim can handle any type of sequence read in huge numbers (considered high-throughput at least for Sanger sequencing) and provide very accurate results. Moreover, applying SeqTrim to previously published reads demonstrates that these reads should be fewer and shorter than reported (Fig. <xref ref-type="fig" rid="F4">4</xref>).</p>
    <p>SeqTrim differential behaviour can be explained as follows: (i) unlike other pre-processors, SeqTrim is designed to remove adaptor sequences as is; note that SeqClean and ESTPrep are able to remove adaptors provided that they are included in the contamination database, which is not an easy task for unskilled users. (ii) Low quality sequence removal is more restrictive to improve the subsequent assembling procedures (Fig. <xref ref-type="fig" rid="F4">4</xref>); although this makes SeqTrim able to render the shortest sequences and a high rate of rejection, trimmed sequences produce less error-prone contigs when assembled (Fernández-Pozo, unpublished results). However, parameters that affect this behaviour are configurable by users. (iii) SeqTrim is able to remove chimeric inserts (Fig. 4)--it should be noted that the only pipeline that proclaims to be able to remove double inserts is ESTPass [<xref ref-type="bibr" rid="B11">11</xref>] but, in our hands, it marks as chimeric EST sequences that are not. (iv) Inserts are located by the concurrence of vector, adaptor and restriction site sequences instead of only one criterion, usually cloning sites [<xref ref-type="bibr" rid="B4">4</xref>], that can have experimental or base-calling errors and are too short to provide certainty. Accordingly, Table <xref ref-type="table" rid="T1">1</xref> shows that the presence of vector and adaptors produces slightly more accurate results than vector alone. (v) In contrast to most pre-processing pipelines, low quality sequences are not removed in early pre-processing since location of vector, adaptor, restriction site, and poly-A/T are more reliable using crude sequences (Fig. <xref ref-type="fig" rid="F2">2</xref>). Furthermore, starting with low quality removal may obliterate key information like sequence orientation or presence of poly-A or poly-T tails. In contrast, the number of sequences rejected due to two inserts can increase, as long A or T tails can be found in low quality reads. These facts can be interpreted as concomitant poly-A and poly-T tails in the same insert, and therefore the sequence is rejected before analysing its QV, which would be the true reason for rejection. (vi) Since localisation of vector, adaptors and contaminant sequences are not dependent on perfect matches, any slippage occurring at those regions will be successfully treated, while slippage in inserts is not detected. (vii) SeqTrim is ready for handling next-generation sequencing artefacts where results are provided as sequences and qualities in independent files. Since 20,000 EST sequences will take more than one hour and since a single run of a 454 machine can generate 5 million sequences (which could take approximately 5 days to execute), future efforts for SeqTrim improvements will be focused on parallelisation and function optimisation in order to reduce execution times, as well as providing robustness for these huge numbers of sequence.</p>
  </sec>
  <sec>
    <title>Conclusions</title>
    <p>SeqTrim is the product of years of collaboration between computer scientists and biologists at the University of Málaga and is under continuous development. It scales up for pre-processing huge sets of sequences (including next-generation sequencing of bacterial artificial chromosomes one-by-one) using large-scale parallel computers (Web version), providing a time- and cost-effective solution, and its Web interface is user-friendly. Although most parameters will never require change, SeqTrim offers sufficient customisation and can cope easily with adaptors and chimeras, as well as next-generation sequencing artefacts. Input/output features provide more flexibility than other pre-processors for integration in workflows with other programs or in existing ones. The coloured output facilitates differentiation of trimmed regions in each sequence and paves the way for result interpretation as well as comparison between cleaned and original sequences, since they are on the same string. Accurateness and reliability of the final sequence clip obtained by SeqTrim have been clearly demonstrated.</p>
  </sec>
  <sec>
    <title>Availability and requirements</title>
    <p><bold>Project name </bold>SeqTrim. No license or account needed.</p>
    <p><bold>Availability </bold><ext-link ext-link-type="uri" xlink:href="http://www.scbi.uma.es/seqtrim">http://www.scbi.uma.es/seqtrim</ext-link>. Source code is directly available from the Web page. It does not include the third party software required. It also includes the vector and contaminant databases used in this work.</p>
    <p><bold>Operating systems </bold>Platform-independent (both Web and command line application).</p>
    <p><bold>Programming languages </bold>Perl for algorithm; Javascript and HTML for Web interface.</p>
    <p><bold>Other requirements </bold>Web browser supporting JavaScript (preferably Mozilla Firefox or Apple's Safari). For the command line version, the computer should have installed BioPerl <ext-link ext-link-type="uri" xlink:href="http://www.bioperl.org/wiki/Getting BioPerl">http://www.bioperl.org/wiki/Getting BioPerl</ext-link>, NCBI-Blast <ext-link ext-link-type="uri" xlink:href="http://blast.ncbi.nlm.nih.gov/Blast.cgi?CMD=Web&amp;PAGE_TYPE=BlastDocs&amp;DOC_TYPE=Download">http://blast.ncbi.nlm.nih.gov/Blast.cgi?CMD=Web&amp;PAGE_TYPE=BlastDocs&amp;DOC_TYPE=Download</ext-link>, phred <ext-link ext-link-type="uri" xlink:href="http://www.phrap.org/phredphrapconsed.html">http://www.phrap.org/phredphrapconsed.html</ext-link> only in case of using SeqTrim with chromatograms, and optionally RepeatMasker <ext-link ext-link-type="uri" xlink:href="http://www.repeatmasker.org/">http://www.repeatmasker.org/</ext-link>. Execution of RepeatMasker requires further installation of WU-Blast <ext-link ext-link-type="uri" xlink:href="http://blast.advbiocomp.com/licensing/">http://blast.advbiocomp.com/licensing/</ext-link> or cross_match <ext-link ext-link-type="uri" xlink:href="http://www.phrap.org/phredphrapconsed.html">http://www.phrap.org/phredphrapconsed.html</ext-link>.</p>
  </sec>
  <sec>
    <title>Authors' contributions</title>
    <p>JF coded in PERL the software as a command line. AJL designed and tested the Web interface. NFP tested the command line and Web interface with experimentally- and artificially-derived sequences. FRC obtained the chromatograms and next-generation sequences for testing SeqTrim, and verified by hand the output reliability. GPT connected the Web interface with super-computation capabilities at Málaga University. MGC designed the software, took into account its compatibility, and helped FRC in the manual inspection of trimmed sequences. All authors read and approved the final manuscript.</p>
  </sec>
  <sec>
    <title>Appendix</title>
    <sec>
      <title>Pseudocode of functions and algorithms developed specifically for SeqTrim</title>
      <p>   function findPolyATs(sequence, minLen, poly_type)</p>
      <p>      if found (at least minLen/2) AorT</p>
      <p>            (then [0..3] other)</p>
      <p>            (and at least minLen/2 AorT)</p>
      <p>      {</p>
      <p>         expand the region with {(at least minLen/4) AorT</p>
      <p>            (then [0..2] other)</p>
      <p>            (and at least minLen/4 AorT)}</p>
      <p>            at both sides up to 3 bases from each each end</p>
      <p>         Ns flanking the region are removed</p>
      <p>         wasThereASecondpolyTorA = Look for a second polyAorT after this one</p>
      <p>      }</p>
      <p>      return [start_point, length, wasThereASecondpolyTorA]</p>
      <p>   function FindContaminantSeqs(seq)</p>
      <p>      Run BLASTN against local contaminant database</p>
      <p>      Ignore shorter than a minimal contamination length <italic># </italic>defined by a user parameter if user gives a genus</p>
      <p>         Compare the contaminants found with the genus as it was not contaminant</p>
      <p>      Build up a list with the names of all the real contaminants</p>
      <p>      If the contaminant region is longer than admitted</p>
      <p>         the sequence is rejected.</p>
      <p>      <italic># </italic>Look for adaptors as a key for chimeric inserts</p>
      <p>      Run BLAST2SEQ against adaptors (5' and 3' ends)</p>
      <p>      if found but the distance is longer than the own adaptor length</p>
      <p>         the seq is rejected</p>
      <p>   function Look_for_artefacts(seq)</p>
      <p>      if "GCGGGG" or "CCCCGC" found at 5' or 3' end</p>
      <p>         Delete it</p>
      <p>      Clean up from extreme Ns and Xs</p>
      <p>      If is cDNA, and forward read, remove first Ts and last As (if more than 3)</p>
      <p>      If is cDNA, and backward read, remove first As and last Ts (if more than 3)</p>
      <p>   function LowComplexityMasking(s)</p>
      <p>      <italic># </italic>masking repeats</p>
      <p>      Run RepeatMasker using WU-BLAST</p>
      <p>      Analyse the result file getting [ID, beg, end, what, class]</p>
      <p>      Mask with Xs all regions found in each ID</p>
      <p>      <italic># </italic>masking dust</p>
      <p>      Look for all but Xs repeated at least 5 times</p>
      <p>      Mask them with Xs</p>
    </sec>
  </sec>
</body>
<back>
  <sec>
    <title>Acknowledgements</title>
    <p>The authors would like to acknowledge Darío Guerrero for his invaluable help concerning Web design and programming advice. This work was supported by the Spanish MICINN grants AGL2009-12139-C02-02 and BIO2009-07490, the European Union grant PLE2009-0016, and Junta de Andalucía funding to the research groups BIO-114 and TIC-113.</p>
  </sec>
  <ref-list>
    <ref id="B1">
      <mixed-citation publication-type="journal">
        <name>
          <surname>Seluja</surname>
          <given-names>GA</given-names>
        </name>
        <name>
          <surname>Farmer</surname>
          <given-names>A</given-names>
        </name>
        <name>
          <surname>McLeod</surname>
          <given-names>M</given-names>
        </name>
        <name>
          <surname>Harger</surname>
          <given-names>C</given-names>
        </name>
        <name>
          <surname>Schad</surname>
          <given-names>PA</given-names>
        </name>
        <article-title>Establishing a method of vector contamination identification in database sequences</article-title>
        <source>Bioinformatics</source>
        <year>1999</year>
        <volume>15</volume>
        <fpage>106</fpage>
        <lpage>110</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/15.2.106</pub-id>
        <pub-id pub-id-type="pmid">10089195</pub-id>
      </mixed-citation>
    </ref>
    <ref id="B2">
      <mixed-citation publication-type="journal">
        <name>
          <surname>Coker</surname>
          <given-names>JS</given-names>
        </name>
        <name>
          <surname>Davies</surname>
          <given-names>E</given-names>
        </name>
        <article-title>Identifying adaptor contamination when mining DNA sequence data</article-title>
        <source>Biotechniques</source>
        <year>2004</year>
        <volume>37</volume>
        <fpage>194</fpage>
        <lpage>198</lpage>
        <pub-id pub-id-type="pmid">15335207</pub-id>
      </mixed-citation>
    </ref>
    <ref id="B3">
      <mixed-citation publication-type="journal">
        <name>
          <surname>Chen</surname>
          <given-names>YA</given-names>
        </name>
        <name>
          <surname>Lin</surname>
          <given-names>CC</given-names>
        </name>
        <name>
          <surname>Wang</surname>
          <given-names>CD</given-names>
        </name>
        <name>
          <surname>Wu</surname>
          <given-names>HB</given-names>
        </name>
        <name>
          <surname>Hwang</surname>
          <given-names>PI</given-names>
        </name>
        <article-title>An optimized procedure greatly improves EST vector contamination removal</article-title>
        <source>BMC Genomics</source>
        <year>2007</year>
        <volume>8</volume>
        <fpage>416</fpage>
        <pub-id pub-id-type="doi">10.1186/1471-2164-8-416</pub-id>
        <pub-id pub-id-type="pmid">17997864</pub-id>
      </mixed-citation>
    </ref>
    <ref id="B4">
      <mixed-citation publication-type="journal">
        <name>
          <surname>Scheetz</surname>
          <given-names>TE</given-names>
        </name>
        <name>
          <surname>Trivedi</surname>
          <given-names>N</given-names>
        </name>
        <name>
          <surname>Roberts</surname>
          <given-names>CA</given-names>
        </name>
        <name>
          <surname>Kucaba</surname>
          <given-names>T</given-names>
        </name>
        <name>
          <surname>Berger</surname>
          <given-names>B</given-names>
        </name>
        <name>
          <surname>Robinson</surname>
          <given-names>NL</given-names>
        </name>
        <name>
          <surname>Birkett</surname>
          <given-names>CL</given-names>
        </name>
        <name>
          <surname>Gavin</surname>
          <given-names>AJ</given-names>
        </name>
        <name>
          <surname>O'Leary</surname>
          <given-names>B</given-names>
        </name>
        <name>
          <surname>Braun</surname>
          <given-names>TA</given-names>
        </name>
        <name>
          <surname>Bonaldo</surname>
          <given-names>MF</given-names>
        </name>
        <name>
          <surname>Robinson</surname>
          <given-names>JP</given-names>
        </name>
        <name>
          <surname>Sheffeld</surname>
          <given-names>VC</given-names>
        </name>
        <name>
          <surname>Casavant</surname>
          <given-names>MBSTL</given-names>
        </name>
        <article-title>ESTprep: preprocessing cDNA sequence reads</article-title>
        <source>Bioinformatics</source>
        <year>2003</year>
        <volume>19</volume>
        <fpage>1318</fpage>
        <lpage>1324</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btg159</pub-id>
        <pub-id pub-id-type="pmid">12874042</pub-id>
      </mixed-citation>
    </ref>
    <ref id="B5">
      <mixed-citation publication-type="journal">
        <name>
          <surname>White</surname>
          <given-names>JR</given-names>
        </name>
        <name>
          <surname>Roberts</surname>
          <given-names>M</given-names>
        </name>
        <name>
          <surname>Yorke</surname>
          <given-names>JA</given-names>
        </name>
        <name>
          <surname>M</surname>
          <given-names>P</given-names>
        </name>
        <article-title>Figaro: a novel statistical method for vector sequence removal</article-title>
        <source>Bioinformatics</source>
        <year>2008</year>
        <volume>24</volume>
        <fpage>462</fpage>
        <lpage>467</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btm632</pub-id>
        <pub-id pub-id-type="pmid">18202027</pub-id>
      </mixed-citation>
    </ref>
    <ref id="B6">
      <mixed-citation publication-type="journal">
        <name>
          <surname>Bonfield</surname>
          <given-names>JK</given-names>
        </name>
        <name>
          <surname>Smith</surname>
          <given-names>K</given-names>
        </name>
        <name>
          <surname>Staden</surname>
          <given-names>R</given-names>
        </name>
        <article-title>A new DNA sequence assembly program</article-title>
        <source>Nucleic Acids Res</source>
        <year>1995</year>
        <volume>23</volume>
        <fpage>4992</fpage>
        <lpage>4999</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/23.24.4992</pub-id>
        <pub-id pub-id-type="pmid">8559656</pub-id>
      </mixed-citation>
    </ref>
    <ref id="B7">
      <mixed-citation publication-type="journal">
        <name>
          <surname>Chou</surname>
          <given-names>HH</given-names>
        </name>
        <name>
          <surname>Holmes</surname>
          <given-names>MH</given-names>
        </name>
        <article-title>DNA sequence quality trimming and vector removal</article-title>
        <source>Bioinformatics</source>
        <year>2001</year>
        <volume>17</volume>
        <fpage>194</fpage>
        <lpage>198</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/17.12.1093</pub-id>
        <pub-id pub-id-type="pmid">11238078</pub-id>
      </mixed-citation>
    </ref>
    <ref id="B8">
      <mixed-citation publication-type="journal">
        <name>
          <surname>Li</surname>
          <given-names>S</given-names>
        </name>
        <name>
          <surname>Chou</surname>
          <given-names>HH</given-names>
        </name>
        <article-title>LUCY2: an interactive DNA sequence quality trimming and vector removal tool</article-title>
        <source>Bioinformatics</source>
        <year>2004</year>
        <volume>20</volume>
        <fpage>3657</fpage>
        <lpage>3665</lpage>
      </mixed-citation>
    </ref>
    <ref id="B9">
      <mixed-citation publication-type="other">
        <collab>TIGR</collab>
        <article-title>SeqClean</article-title>
        <ext-link ext-link-type="uri" xlink:href="http://compbio.dfci.harvard.edu/tgi/software/  ">http://compbio.dfci.harvard.edu/tgi/software/  </ext-link>
      </mixed-citation>
    </ref>
    <ref id="B10">
      <mixed-citation publication-type="journal">
        <name>
          <surname>Hotz-Wagenblatt</surname>
          <given-names>A</given-names>
        </name>
        <name>
          <surname>Hankeln</surname>
          <given-names>T</given-names>
        </name>
        <name>
          <surname>Ernst</surname>
          <given-names>P</given-names>
        </name>
        <name>
          <surname>Glatting</surname>
          <given-names>KH</given-names>
        </name>
        <name>
          <surname>Schmidt</surname>
          <given-names>ER</given-names>
        </name>
        <name>
          <surname>Suhai</surname>
          <given-names>S</given-names>
        </name>
        <article-title>ESTAnnotator: A tool for high throughput EST annotation</article-title>
        <source>Nucleid Acids Res</source>
        <year>2003</year>
        <volume>31</volume>
        <fpage>3716</fpage>
        <lpage>3719</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkg566</pub-id>
      </mixed-citation>
    </ref>
    <ref id="B11">
      <mixed-citation publication-type="journal">
        <name>
          <surname>Lee</surname>
          <given-names>B</given-names>
        </name>
        <name>
          <surname>Hong</surname>
          <given-names>T</given-names>
        </name>
        <name>
          <surname>Byun</surname>
          <given-names>SJ</given-names>
        </name>
        <name>
          <surname>Woo</surname>
          <given-names>T</given-names>
        </name>
        <name>
          <surname>Choi</surname>
          <given-names>YJ</given-names>
        </name>
        <article-title>ESTpass: a web-based server for processing and annotating expressed sequence tag (EST) sequences</article-title>
        <source>Nucleic Acids Res</source>
        <year>2007</year>
        <volume>35</volume>
        <fpage>W159</fpage>
        <lpage>162</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkm369</pub-id>
        <pub-id pub-id-type="pmid">17526512</pub-id>
      </mixed-citation>
    </ref>
    <ref id="B12">
      <mixed-citation publication-type="journal">
        <name>
          <surname>Nagaraj</surname>
          <given-names>SH</given-names>
        </name>
        <name>
          <surname>Deshpande</surname>
          <given-names>N</given-names>
        </name>
        <name>
          <surname>Gasser</surname>
          <given-names>RB</given-names>
        </name>
        <name>
          <surname>Ranganathan</surname>
          <given-names>S</given-names>
        </name>
        <article-title>ESTExplorer: an expressed sequence tag (EST) assembly and annotation platform</article-title>
        <source>Nucleic Acids Res</source>
        <year>2007</year>
        <volume>35</volume>
        <fpage>W143</fpage>
        <lpage>147</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkm378</pub-id>
        <pub-id pub-id-type="pmid">17545197</pub-id>
      </mixed-citation>
    </ref>
    <ref id="B13">
      <mixed-citation publication-type="journal">
        <name>
          <surname>Ewing</surname>
          <given-names>B</given-names>
        </name>
        <name>
          <surname>Hillier</surname>
          <given-names>L</given-names>
        </name>
        <name>
          <surname>Wendl</surname>
          <given-names>MC</given-names>
        </name>
        <name>
          <surname>Green</surname>
          <given-names>P</given-names>
        </name>
        <article-title>Base-calling of automated sequencer traces using phred. I. Accuracy assessment</article-title>
        <source>Genome Res</source>
        <year>1998</year>
        <volume>8</volume>
        <fpage>175</fpage>
        <lpage>185</lpage>
        <pub-id pub-id-type="pmid">9521921</pub-id>
      </mixed-citation>
    </ref>
    <ref id="B14">
      <mixed-citation publication-type="journal">
        <name>
          <surname>Ewing</surname>
          <given-names>B</given-names>
        </name>
        <name>
          <surname>Green</surname>
          <given-names>P</given-names>
        </name>
        <article-title>Base-calling of automated sequencer traces using phred. II. Error probabilities</article-title>
        <source>Genome Res</source>
        <year>1998</year>
        <volume>8</volume>
        <fpage>186</fpage>
        <lpage>194</lpage>
        <pub-id pub-id-type="pmid">9521922</pub-id>
      </mixed-citation>
    </ref>
    <ref id="B15">
      <mixed-citation publication-type="journal">
        <name>
          <surname>Jurka</surname>
          <given-names>J</given-names>
        </name>
        <article-title>Repbase Update: a database and an electronic journal of repetitive elements</article-title>
        <source>Trends Genet</source>
        <year>2000</year>
        <volume>16</volume>
        <fpage>418</fpage>
        <lpage>420</lpage>
        <pub-id pub-id-type="doi">10.1016/S0168-9525(00)02093-X</pub-id>
        <pub-id pub-id-type="pmid">10973072</pub-id>
      </mixed-citation>
    </ref>
    <ref id="B16">
      <mixed-citation publication-type="other">
        <name>
          <surname>Cantón</surname>
          <given-names>FR</given-names>
        </name>
        <name>
          <surname>Provost</surname>
          <given-names>GL</given-names>
        </name>
        <name>
          <surname>Garcia</surname>
          <given-names>V</given-names>
        </name>
        <name>
          <surname>Barré</surname>
          <given-names>A</given-names>
        </name>
        <name>
          <surname>Frigerio</surname>
          <given-names>JM</given-names>
        </name>
        <name>
          <surname>Paiva</surname>
          <given-names>J</given-names>
        </name>
        <name>
          <surname>Fevereiro</surname>
          <given-names>P</given-names>
        </name>
        <name>
          <surname>Avila</surname>
          <given-names>C</given-names>
        </name>
        <name>
          <surname>Mouret</surname>
          <given-names>JF</given-names>
        </name>
        <name>
          <surname>de Daruvar</surname>
          <given-names>A</given-names>
        </name>
        <name>
          <surname>Cánovas</surname>
          <given-names>FM</given-names>
        </name>
        <name>
          <surname>Plomion</surname>
          <given-names>C</given-names>
        </name>
        <article-title>Sustainable Forestry, Wood products and Biotechnology, </article-title>
        <source>DFA-AFA Press 2003 chap. Transcriptome analysis of wood formation in maritime pine</source>
        <fpage>333</fpage>
        <lpage>347</lpage>
      </mixed-citation>
    </ref>
    <ref id="B17">
      <mixed-citation publication-type="journal">
        <name>
          <surname>Liang</surname>
          <given-names>F</given-names>
        </name>
        <name>
          <surname>Holt</surname>
          <given-names>I</given-names>
        </name>
        <name>
          <surname>Pertea</surname>
          <given-names>G</given-names>
        </name>
        <name>
          <surname>Karamycheva</surname>
          <given-names>S</given-names>
        </name>
        <name>
          <surname>Salzberg</surname>
          <given-names>S</given-names>
        </name>
        <name>
          <surname>Quackenbush</surname>
          <given-names>J</given-names>
        </name>
        <article-title>An optimized protocol for analysis of EST sequences</article-title>
        <source>Nucleic Acids Res</source>
        <year>2000</year>
        <volume>28</volume>
        <fpage>3657</fpage>
        <lpage>3665</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/28.18.3657</pub-id>
        <pub-id pub-id-type="pmid">10982889</pub-id>
      </mixed-citation>
    </ref>
    <ref id="B18">
      <mixed-citation publication-type="journal">
        <name>
          <surname>Masoudi-Nejad</surname>
          <given-names>A</given-names>
        </name>
        <name>
          <surname>Tonomura</surname>
          <given-names>K</given-names>
        </name>
        <name>
          <surname>Kawashima</surname>
          <given-names>S</given-names>
        </name>
        <name>
          <surname>Moriya</surname>
          <given-names>Y</given-names>
        </name>
        <name>
          <surname>Suzuki</surname>
          <given-names>M</given-names>
        </name>
        <name>
          <surname>Itoh</surname>
          <given-names>M</given-names>
        </name>
        <name>
          <surname>Kanehisa</surname>
          <given-names>M</given-names>
        </name>
        <name>
          <surname>Endo</surname>
          <given-names>T</given-names>
        </name>
        <name>
          <surname>Goto</surname>
          <given-names>S</given-names>
        </name>
        <article-title>EGassembler: online bioinformatics service for large-scale processing, clustering and assembling ESTs and genomic DNA fragments</article-title>
        <source>Nucleic Acids Res</source>
        <year>2006</year>
        <volume>34</volume>
        <fpage>W459</fpage>
        <lpage>462</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkl066</pub-id>
        <pub-id pub-id-type="pmid">16845049</pub-id>
      </mixed-citation>
    </ref>
    <ref id="B19">
      <mixed-citation publication-type="journal">
        <name>
          <surname>Forment</surname>
          <given-names>J</given-names>
        </name>
        <name>
          <surname>Gilaber</surname>
          <given-names>F</given-names>
        </name>
        <name>
          <surname>Robles</surname>
          <given-names>A</given-names>
        </name>
        <name>
          <surname>Conejero</surname>
          <given-names>V</given-names>
        </name>
        <name>
          <surname>Nuez</surname>
          <given-names>F</given-names>
        </name>
        <name>
          <surname>Blanca</surname>
          <given-names>JM</given-names>
        </name>
        <article-title>EST2uni: an open, parallel tool for automated EST analysis and database creation, with a data mining web interface and microarray expression data integration</article-title>
        <source>BMC Bioinformatics</source>
        <year>2008</year>
        <volume>9</volume>
        <fpage>5</fpage>
        <pub-id pub-id-type="doi">10.1186/1471-2105-9-5</pub-id>
        <pub-id pub-id-type="pmid">18179701</pub-id>
      </mixed-citation>
    </ref>
  </ref-list>
</back>
