<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Eur Radiol</journal-id>
    <journal-id journal-id-type="iso-abbrev">Eur Radiol</journal-id>
    <journal-title-group>
      <journal-title>European Radiology</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">0938-7994</issn>
    <issn pub-type="epub">1432-1084</issn>
    <publisher>
      <publisher-name>Springer Berlin Heidelberg</publisher-name>
      <publisher-loc>Berlin/Heidelberg</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">9381634</article-id>
    <article-id pub-id-type="pmid">35368227</article-id>
    <article-id pub-id-type="publisher-id">8724</article-id>
    <article-id pub-id-type="doi">10.1007/s00330-022-08724-4</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Imaging Informatics and Artificial Intelligence</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>CardiSort: a convolutional neural network for cross vendor automated sorting of cardiac MR images</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-2842-5997</contrib-id>
        <name>
          <surname>Lim</surname>
          <given-names>Ruth P.</given-names>
        </name>
        <address>
          <email>ruthplim74@gmail.com</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff2">2</xref>
        <xref ref-type="aff" rid="Aff3">3</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Kachel</surname>
          <given-names>Stefan</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff2">2</xref>
        <xref ref-type="aff" rid="Aff4">4</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Villa</surname>
          <given-names>Adriana D. M.</given-names>
        </name>
        <xref ref-type="aff" rid="Aff5">5</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Kearney</surname>
          <given-names>Leighton</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff6">6</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Bettencourt</surname>
          <given-names>Nuno</given-names>
        </name>
        <xref ref-type="aff" rid="Aff7">7</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Young</surname>
          <given-names>Alistair A.</given-names>
        </name>
        <xref ref-type="aff" rid="Aff5">5</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Chiribiri</surname>
          <given-names>Amedeo</given-names>
        </name>
        <xref ref-type="aff" rid="Aff5">5</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Scannell</surname>
          <given-names>Cian M.</given-names>
        </name>
        <xref ref-type="aff" rid="Aff5">5</xref>
      </contrib>
      <aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="GRID">grid.410678.c</institution-id><institution-id institution-id-type="ISNI">0000 0000 9374 3516</institution-id><institution>Austin Health, </institution></institution-wrap>Melbourne, Australia </aff>
      <aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="GRID">grid.1008.9</institution-id><institution-id institution-id-type="ISNI">0000 0001 2179 088X</institution-id><institution>Departments of Radiology, </institution><institution>The University of Melbourne, </institution></institution-wrap>Melbourne, Australia </aff>
      <aff id="Aff3"><label>3</label><institution-wrap><institution-id institution-id-type="GRID">grid.1008.9</institution-id><institution-id institution-id-type="ISNI">0000 0001 2179 088X</institution-id><institution>Department of Surgery (Austin), </institution><institution>The University of Melbourne, </institution></institution-wrap>Melbourne, Australia </aff>
      <aff id="Aff4"><label>4</label><institution-wrap><institution-id institution-id-type="GRID">grid.21729.3f</institution-id><institution-id institution-id-type="ISNI">0000000419368729</institution-id><institution>Department of Radiology, </institution><institution>Columbia University, </institution></institution-wrap>New York, USA </aff>
      <aff id="Aff5"><label>5</label><institution-wrap><institution-id institution-id-type="GRID">grid.13097.3c</institution-id><institution-id institution-id-type="ISNI">0000 0001 2322 6764</institution-id><institution>School of Biomedical Engineering and Imaging Sciences, </institution><institution>Kings College London, </institution></institution-wrap>London, UK </aff>
      <aff id="Aff6"><label>6</label>I-MED Radiology, Melbourne, Australia </aff>
      <aff id="Aff7"><label>7</label><institution-wrap><institution-id institution-id-type="GRID">grid.5808.5</institution-id><institution-id institution-id-type="ISNI">0000 0001 1503 7226</institution-id><institution>Cardiovascular R &amp; D Unit, </institution><institution>University of Porto, </institution></institution-wrap>Porto, Portugal </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>4</day>
      <month>4</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>4</day>
      <month>4</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="ppub">
      <year>2022</year>
    </pub-date>
    <volume>32</volume>
    <issue>9</issue>
    <fpage>5907</fpage>
    <lpage>5920</lpage>
    <history>
      <date date-type="received">
        <day>22</day>
        <month>1</month>
        <year>2022</year>
      </date>
      <date date-type="rev-recd">
        <day>22</day>
        <month>1</month>
        <year>2022</year>
      </date>
      <date date-type="accepted">
        <day>5</day>
        <month>3</month>
        <year>2022</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2022</copyright-statement>
      <license>
        <ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>.</license-p>
      </license>
    </permissions>
    <abstract id="Abs1">
      <sec>
        <title>Objectives</title>
        <p id="Par1">To develop an image-based automatic deep learning method to classify cardiac MR images by sequence type and imaging plane for improved clinical post-processing efficiency.</p>
      </sec>
      <sec>
        <title>Methods</title>
        <p id="Par2">Multivendor cardiac MRI studies were retrospectively collected from 4 centres and 3 vendors. A two-head convolutional neural network (‘CardiSort’) was trained to classify 35 sequences by imaging sequence (<italic>n</italic> = 17) and plane (<italic>n</italic> = 10). Single vendor training (SVT) on single-centre images (<italic>n</italic> = 234 patients) and multivendor training (MVT) with multicentre images (<italic>n</italic> = 434 patients, 3 centres) were performed. Model accuracy and F1 scores on a hold-out test set were calculated, with ground truth labels by an expert radiologist. External validation of MVT (MVT<sub>external</sub>) was performed on data from 3 previously unseen magnet systems from 2 vendors (<italic>n</italic> = 80 patients).</p>
      </sec>
      <sec>
        <title>Results</title>
        <p id="Par3">Model sequence/plane/overall accuracy and F1-scores were 85.2%/93.2%/81.8% and 0.82 for SVT and 96.1%/97.9%/94.3% and 0.94 MVT on the hold-out test set. MVT<sub>external</sub> yielded sequence/plane/combined accuracy and F1-scores of 92.7%/93.0%/86.6% and 0.86. There was high accuracy for common sequences and conventional cardiac planes. Poor accuracy was observed for underrepresented classes and sequences where there was greater variability in acquisition parameters across centres, such as perfusion imaging.</p>
      </sec>
      <sec>
        <title>Conclusions</title>
        <p id="Par4">A deep learning network was developed on multivendor data to classify MRI studies into component sequences and planes, with external validation. With refinement, it has potential to improve workflow by enabling automated sequence selection, an important first step in completely automated post-processing pipelines.</p>
      </sec>
      <sec>
        <title>Key Points</title>
        <p id="Par5">
          <italic>• Deep learning can be applied for consistent and efficient classification of cardiac MR image types.</italic>
        </p>
        <p id="Par6">
          <italic>• A multicentre, multivendor study using a deep learning algorithm (CardiSort) showed high classification accuracy on a hold-out test set with good generalisation to images from previously unseen magnet systems.</italic>
        </p>
        <p id="Par7">
          <italic>• CardiSort has potential to improve clinical workflows, as a vital first step in developing fully automated post-processing pipelines.</italic>
        </p>
      </sec>
      <sec>
        <title>Supplementary Information</title>
        <p>The online version contains supplementary material available at 10.1007/s00330-022-08724-4.</p>
      </sec>
    </abstract>
    <kwd-group xml:lang="en">
      <title>Keywords</title>
      <kwd>Magnetic resonance imaging</kwd>
      <kwd>Deep learning</kwd>
      <kwd>Workflow</kwd>
      <kwd>Heart</kwd>
      <kwd>Humans</kwd>
    </kwd-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100004440</institution-id>
            <institution>Wellcome Trust</institution>
          </institution-wrap>
        </funding-source>
        <award-id>WT 203148/Z/16/Z</award-id>
        <award-id>WT 222678/Z/21/Z</award-id>
        <principal-award-recipient>
          <name>
            <surname>Scannell</surname>
            <given-names>Cian M.</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
    </funding-group>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>© European Society of Radiology 2022</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="Sec1">
    <title>Introduction</title>
    <p id="Par30">Cardiac magnetic resonance studies are commonly performed for comprehensive anatomic, functional, and quantitative assessment and are relatively complex to perform and interpret. Recently updated Society for Cardiovascular Magnetic Resonance (SCMR) guidelines advocate standardised acquisition and postprocessing to ensure study quality and reproducibility [<xref ref-type="bibr" rid="CR1">1</xref>, <xref ref-type="bibr" rid="CR2">2</xref>]. Manual post-processing is time intensive and can be prone to human error. Therefore, there are active efforts to automate a range of quantitative tasks including ventricular segmentation, myocardial tissue characterisation, and perfusion assessment [<xref ref-type="bibr" rid="CR3">3</xref>–<xref ref-type="bibr" rid="CR6">6</xref>]. If validated and made available to the clinical community, automated post-processing pipelines could aid efficiency and consistency of measurements for diagnosis, prognosis, and treatment monitoring.</p>
    <p id="Par31">Accurate identification of individual cardiac MR sequences is an important first step in directing images to the appropriate post-processing tool. In the clinic, sequence labelling currently depends upon saved scan protocols and/or real-time annotations by the scanning MR technologist, and are thus subject to large variations across centres, making standardisation difficult. Consistent automated sorting would facilitate fully automated post-processing, with a proposed clinical workflow provided in Fig. <xref rid="Fig1" ref-type="fig">1</xref>. As well as allowing for prospective automated post-processing, sequence identification can be used to automatically curate large retrospective datasets for training deep learning models. This curation has traditionally relied upon expert manual labour that is time-consuming and costly [<xref ref-type="bibr" rid="CR7">7</xref>, <xref ref-type="bibr" rid="CR8">8</xref>], and an automated means of data curation would facilitate use of larger datasets for more robust tool development and validation.
<fig id="Fig1"><label>Fig. 1</label><caption><p>Proposed streamlined clinical workflow for fully automated postprocessing, beginning with an automated cardiac sorting tool (‘CardiSort’). CardiSort would receive images directly from the scanner and classify them, then automatically direct them for further quantitative post-processing as required. Those image types not requiring advanced post-processing would be sent directly to the Picture Archiving and Communication System (PACS). Some examples of multiple automated pipelines that could follow from the initial sorting step include quantification of ventricular volume, function, mass, and myocardial strain from cine imaging; extraction of T1, T2, and T2* values and calculation of extracellular volume (ECV) from T1, T2, and T2* sequences; measurement of myocardial blood flow and myocardial perfusion reserve from stress and rest perfusion imaging, and quantification and characterisation of myocardial scar from late gadolinium-enhanced (LGE) imaging. All images and extracted metrics would then be sent automatically to PACS for image interpretation by a cardiac MR radiologist or cardiologist</p></caption><graphic xlink:href="330_2022_8724_Fig1_HTML" id="MO1"/></fig></p>
    <p id="Par32">Van der Voort et al described a convolutional neural network (CNN) approach for automated sorting of 8 brain MRI sequences, achieving greater than 98% accuracy in image labelling [<xref ref-type="bibr" rid="CR9">9</xref>]. Cardiac MR image sorting is potentially more challenging, due to patient-specific cardiac planes, and variability in sequence design and parameters, and it has not previously been studied in detail. The primary aim of this study was to develop a deep learning tool, CardiSort, to automatically classify a range of clinical cardiac MR sequences using pixel data alone, with real-world cardiac MR data obtained across three different vendors. The model is also made available as an open-source tool for use by the community.</p>
  </sec>
  <sec id="Sec2">
    <title>Materials and methods</title>
    <sec id="Sec3">
      <title>Study design and data</title>
      <p id="Par33">This was a retrospective study to create a model to classify 35 cardiac MRI sequences by sequence type and imaging plane. Anonymised cardiac MRI data was obtained from 4 centres and 3 vendors (Vendor 1, Philips; Vendor 2, Siemens; Vendor 3, General Electric) with institutional ethics approval. A total of 334 randomly sampled studies in 334 patients (224M, 110F, mean ± SD 54.8 ± 15.8 years) were obtained from Centre 1 from 2011 to 2020, with (a) 147 cases scanned at 1.5T (Ingenia, Philips Healthcare); (b) 87 cases scanned at 3T (Achieva, Philips Healthcare); and (c) additional selected sequences obtained from 100 patients on a different 1.5-T vendor system (Aera, Siemens Medical), to supplement training images for vendor 2. Centre 1 common indications for scanning were ischaemic and non-ischaemic cardiomyopathy. Ninety studies in 52 patients with aortic stenosis (31M, 21F, 72.2 ± 7.7 years) were obtained from Centre 2, scanned at 1.5T from 2013 to 2017 (Symphony, Siemens Medical), with studies performed at more than one time point in 37 patients. Forty-eight studies in 48 patients (33M, 15F, 60.0 ± 17.3 years) were obtained from centre 3, scanned at 1.5T from 2017 to 2018 (Optima MR450w, GE Healthcare) with the most common indications of non-ischaemic cardiomyopathy or arrhythmia.</p>
      <p id="Par34">Single vendor training (SVT) was first performed, utilising only data from Centre 1 (which was the largest single vendor training set), followed by multivendor training (MVT), which was retrained from scratch, utilising data from Centres 1 to 3. The final SVT and MVT models were tested on hold-out test data from Centres1 to 3.</p>
      <p id="Par35">For MVT external validation (MVT<sub>external</sub>), the model was trained on all of the internal data from Centres 1 to 3 as previously described. Testing was performed on 2 external datasets not previously seen by the model: Centre 2 data scanned in 2020 from a different vendor (Vendor 1) 3T system (Achieva, Philips, Healthcare), <italic>n</italic> = 20 patients, 14M, 6F, 58.9 ± 13.5 years; Centre 4 1.5T and 3T Vendor 2 data from 2016 to 2020 (Avanto and Skyra, Siemens Medical), <italic>n</italic> = 60 patients, 31M, 29F, 55.2 ± 14.6 years. The most common clinical indications for external data were non-ischaemic cardiomyopathy, assessment for arrhythmogenic foci, and myocarditis. Experiments performed are summarised in Fig. <xref rid="Fig2" ref-type="fig">2</xref>.
<fig id="Fig2"><label>Fig. 2</label><caption><p>Summary of experiments performed. Initially, a model was developed and trained on data from a single centre (Centre 1) and single vendor (Vendor 1), and tested on data from all 3 vendors. Subsequently, the model was trained on multi-vendor data from Centres 1–3 and tested on a hold-out test set derived from the same multivendor data. Finally, the multivendor trained model was tested on external datasets obtained from systems not used for training</p></caption><graphic xlink:href="330_2022_8724_Fig2_HTML" id="MO2"/></fig></p>
      <sec id="Sec4">
        <title>Pre-processing</title>
        <p id="Par36">All images were obtained in Digital Imaging and Communications in Medicine (DICOM) format and anonymized. Secondary capture images were removed. Slightly different pre-processing using DICOM attributes [<xref ref-type="bibr" rid="CR10">10</xref>] were required due to vendor-specific differences in the export of sequences with multiple image types, e.g. phase contrast imaging (PC), or multiple planes, e.g. cine imaging. For Vendors 1 and 3, all image types for such sequences were saved combined into a single series; series description, series instance unique identifier (series instance UID), and instance number were used for sorting. For Vendor 2, where multiple image types were saved in separate series but shared a protocol name, protocol name was also included for sorting. Data flow is summarised in Supplementary Figure <xref rid="MOESM1" ref-type="media">1</xref>, and sequence labels and final datapoints available are presented by individual magnets in Table <xref rid="Tab1" ref-type="table">1</xref>.
<table-wrap id="Tab1"><label>Table 1</label><caption><p>Sequence and plane of all data, with prevalence of datapoints presented by magnet</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="2" colspan="2"/><th colspan="5">Data used for model training</th><th colspan="3">External Validation</th></tr><tr><th colspan="3">Centre 1</th><th>Centre 2</th><th>Centre 3</th><th>Centre 2</th><th>Centre 4</th><th>Centre 4</th></tr></thead><tbody><tr><td colspan="2">Vendor</td><td><bold>Philips</bold></td><td><bold>Philips</bold></td><td><bold>Siemens</bold></td><td><bold>Siemens</bold></td><td><bold>GE</bold></td><td><bold>Philips</bold></td><td><bold>Siemens</bold></td><td><bold>Siemens</bold></td></tr><tr><td colspan="2">Field strength (T)</td><td><bold>1.5</bold></td><td><bold>3</bold></td><td><bold>1.5</bold></td><td><bold>1.5</bold></td><td><bold>1.5</bold></td><td><bold>1.5</bold></td><td><bold>1.5</bold></td><td><bold>3</bold></td></tr><tr><td>Sequence</td><td>Plane</td><td colspan="5"/><td colspan="3"/></tr><tr><td>B0 map</td><td>Axial</td><td>0</td><td>36</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>Cine bSSFP</td><td>2-Chamber</td><td>275</td><td>131</td><td>0</td><td>181</td><td>50</td><td>24</td><td>13</td><td>4</td></tr><tr><td>Cine bSSFP</td><td>3-Chamber</td><td>153</td><td>54</td><td>0</td><td>94</td><td>47</td><td>27</td><td>14</td><td>6</td></tr><tr><td>Cine bSSFP</td><td>4-Chamber</td><td>192</td><td>145</td><td>0</td><td>109</td><td>50</td><td>27</td><td>14</td><td>15</td></tr><tr><td>Cine bSSFP</td><td>LVOT</td><td>43</td><td>3</td><td>2</td><td>40</td><td>0</td><td>0</td><td>8</td><td>5</td></tr><tr><td>Cine bSSFP</td><td>RVOT</td><td>31</td><td>4</td><td>0</td><td>0</td><td>7</td><td>0</td><td>0</td><td>10</td></tr><tr><td>Cine bSSFP</td><td>Short axis</td><td>345</td><td>194</td><td>0</td><td>107</td><td>48</td><td>35</td><td>19</td><td>13</td></tr><tr><td>DBLGE</td><td>2-Chamber</td><td>127</td><td>3</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>DBLGE</td><td>3-Chamber</td><td>107</td><td>5</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>DBLGE</td><td>4-Chamber</td><td>110</td><td>4</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>DBLGE</td><td>Short Axis</td><td>129</td><td>3</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>EGE</td><td>2-Chamber</td><td>112</td><td>3</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>EGE</td><td>3-Chamber</td><td>83</td><td>3</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>EGE</td><td>4-Chamber</td><td>84</td><td>3</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>FST2</td><td>2-Chamber</td><td>26</td><td>3</td><td>25</td><td>0</td><td>0</td><td>3</td><td>3</td><td>1</td></tr><tr><td>FST2</td><td>3-Chamber</td><td>22</td><td>0</td><td>27</td><td>0</td><td>0</td><td>0</td><td>3</td><td>1</td></tr><tr><td>FST2</td><td>4-Chamber</td><td>28</td><td>3</td><td>25</td><td>0</td><td>47</td><td>2</td><td>3</td><td>1</td></tr><tr><td>FST2</td><td>Short axis</td><td>30</td><td>9</td><td>27</td><td>0</td><td>45</td><td>4</td><td>0</td><td>3</td></tr><tr><td>HASTE</td><td>Axial</td><td>137</td><td>11</td><td>0</td><td>88</td><td>47</td><td>16</td><td>45</td><td>14</td></tr><tr><td>MOLLI-</td><td>Short axis</td><td>136</td><td>66</td><td>94</td><td>0</td><td>0</td><td>0</td><td>30</td><td>0</td></tr><tr><td>MOLLI+</td><td>Short axis</td><td>141</td><td>53</td><td>113</td><td>0</td><td>0</td><td>0</td><td>29</td><td>0</td></tr><tr><td>Phase contrast</td><td>Aorta</td><td>31</td><td>7</td><td>0</td><td>103</td><td>11</td><td>0</td><td>1</td><td>12</td></tr><tr><td>Phase contrast</td><td>MPA</td><td>23</td><td>5</td><td>0</td><td>0</td><td>8</td><td>0</td><td>1</td><td>9</td></tr><tr><td>Perfusion</td><td>Short axis</td><td>60</td><td>83</td><td>0</td><td>175</td><td>0</td><td>17</td><td>0</td><td>0</td></tr><tr><td>Scout Imaging</td><td>Multiplanar</td><td>156</td><td>121</td><td>0</td><td>87</td><td>0</td><td>8</td><td>90</td><td>0</td></tr><tr><td>T2 mapping bright blood</td><td>Short axis</td><td>0</td><td>0</td><td>28</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>T2 mapping dark blood</td><td>Short axis</td><td>26</td><td>16</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>T2* mapping</td><td>Short axis</td><td>9</td><td>33</td><td>5</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>Test Perfusion (Pre contrast)</td><td>Short axis</td><td>36</td><td>55</td><td>0</td><td>93</td><td>0</td><td>15</td><td>0</td><td>0</td></tr><tr><td>TI scout</td><td>4-Chamber</td><td>30</td><td>0</td><td>5</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>TI scout</td><td>Short axis</td><td>271</td><td>55</td><td>172</td><td>90</td><td>52</td><td>18</td><td>43</td><td>12</td></tr><tr><td>WBLGE</td><td>2-Chamber</td><td>163</td><td>60</td><td>0</td><td>101</td><td>47</td><td>34</td><td>42</td><td>5</td></tr><tr><td>WBLGE</td><td>3-Chamber</td><td>141</td><td>55</td><td>0</td><td>98</td><td>47</td><td>25</td><td>33</td><td>4</td></tr><tr><td>WBLGE</td><td>4-Chamber</td><td>147</td><td>48</td><td>0</td><td>96</td><td>49</td><td>30</td><td>46</td><td>4</td></tr><tr><td>WBLGE</td><td>Short axis</td><td>221</td><td>78</td><td>0</td><td>176</td><td>47</td><td>21</td><td>50</td><td>14</td></tr><tr><td colspan="2">Total</td><td><bold>3625</bold></td><td><bold>1352</bold></td><td><bold>523</bold></td><td><bold>1638</bold></td><td><bold>604</bold></td><td><bold>306</bold></td><td><bold>487</bold></td><td><bold>133</bold></td></tr></tbody></table><table-wrap-foot><p><italic>bSSFP</italic> balanced steady-state free precession imaging; <italic>LVOT</italic> left ventricular outflow tract, perpendicular to 3-chamber plane; <italic>RVOT</italic> right ventricular outflow tract (oblique sagittal plane); <italic>DBLGE</italic> dark blood late gadolinium-enhanced images (blood pool nulled); <italic>EGE</italic> early gadolinium-enhanced images; <italic>FST2</italic> fat-suppressed T2-weighted imaging; <italic>HASTE</italic> half-Fourier acquisition single-shot turbo spin echo imaging; <italic>MOLLI+</italic> Modified Look Locker Inversion Recovery imaging post contrast; <italic>MOLLI-</italic> native Modified Look Locker Inversion Recovery imaging; <italic>MPA</italic> main pulmonary artery; <italic>TI scout</italic> inversion time scout imaging for late gadolinium-enhanced imaging; <italic>WBLGE</italic> white blood late gadolinium-enhanced images (normal myocardium nulled)</p></table-wrap-foot></table-wrap></p>
        <p id="Par37">For a unique image series, three images (first, middle, and last as sorted by position and instance number) were selected as input to the model. Three images were chosen as a fixed input size as required by the model. Although this discards images for some image series, it maintains a degree of the temporal, contrast, and spatial information within the series. This was chosen empirically to balance model performance versus model size, based on preliminary experiments. Images were resized to a 256 × 256 pixel array using bilinear interpolation, with array values normalised by the minimum and maximum values to between 0 and 1, per channel. The three images were combined to form a “3-channel” array of shape 256 × 256 × 3 as a single datapoint for model input. For MRI sequences with fewer than 3 images, the first image was repeated once or twice as required.</p>
      </sec>
    </sec>
    <sec id="Sec5">
      <title>Ground truth</title>
      <p id="Par38">Ground truth labels were semi-automatically assigned. Series descriptions for each unique extracted image series were first assigned to classes by a board-certified cardiac radiologist with 15 years’ cardiac MRI experience (SCMR Level 3 equivalent, RPL). All data were then automatically sorted into separate classes based on series description. Of the possible sequence and plane combinations, classes were included in the analysis if at least 20 unique datapoints for that class were present in the entire dataset, resulting in 35 labels incorporating both sequence type and imaging plane (Table <xref rid="Tab1" ref-type="table">1</xref>). The remaining unassigned classes were excluded from further analysis.</p>
      <p id="Par39">Labelled images were then manually reviewed for completeness, label correctness, and diagnostic quality by the same radiologist. Incorrectly labelled images were reassigned to the correct label if present, or excluded if absent. Aberrant congenital anatomy (<italic>n</italic> = 1 patient) and image sets that did not belong to one of the 35 labels, were considered non-diagnostic, or incomplete (2140/26,456 automatically extracted images, 8.1%) were excluded from further analysis. The final datasets underwent repeat review for any misclassification by the same radiologist prior to network training, at least 4 weeks after initial review.</p>
    </sec>
    <sec id="Sec6">
      <title>Data partitioning</title>
      <p id="Par40">In total, 64% of experiment data was chosen for training, 16% for validation, and 20% for testing for SVT and MVT, with MVT<sub>external</sub> trained on 80% and 20% of the internal data for training and validation respectively, and tested on all of the external data (Supplementary Table <xref rid="MOESM1" ref-type="media">1</xref>). Stratified sampling of train, validation, and test sets was performed to eliminate sampling bias, with study-level partitioning to ensure no closely related images from the training set were within validation or test sets for each given class. For MVT, 206 datapoints were excluded from the hold out test set, where data from patients with more than one study for a given class was present in the training data.</p>
    </sec>
    <sec id="Sec7">
      <title>Model</title>
      <p id="Par41">A 2D CNN, CardiSort, was iteratively developed to evaluate spatial imaging features for two-output (sequence and plane) multiclass classification. All inputs were shuffled prior to presentation to the network. An input layer and three deep convolutional layers with kernel sizes of 3 × 3 were employed for the model with 32, 32, 64, and 128 filters respectively. These were followed by two fully connected layers of 256 and 64 units respectively prior to the output layer, with separate outputs for sequence type and imaging plane (Fig. <xref rid="Fig3" ref-type="fig">3</xref>). A ReLU activation function [<xref ref-type="bibr" rid="CR11">11</xref>] was used for all layers prior to the output layer, with a softmax output used for classification [<xref ref-type="bibr" rid="CR12">12</xref>]. He-normal weight initialisation was employed [<xref ref-type="bibr" rid="CR13">13</xref>].
<fig id="Fig3"><label>Fig. 3</label><caption><p>Model architecture. Batch normalization and ReLU activation were used for all hidden layers, with Softmax activation for classification</p></caption><graphic xlink:href="330_2022_8724_Fig3_HTML" id="MO3"/></fig></p>
    </sec>
    <sec id="Sec8">
      <title>Training details</title>
      <p id="Par42">Details of training, including data augmentation, selected hyperparameters, and training platform, are provided in Supplementary Methods. Training was performed for 480 epochs, with the lowest summed validation loss observed at least 60 epochs prior to this for all experiments, using categorical cross entropy as the loss metric for both outputs.</p>
      <p id="Par43">The MVT<sub>external</sub> model is made available at <ext-link ext-link-type="uri" xlink:href="https://github.com/cianmscannell/cardisort">https://github.com/cianmscannell/cardisort</ext-link>, with accompanying code for its application to classifying non-curated data and sorting it into complete imaging series by sequence and plane label.</p>
    </sec>
    <sec id="Sec9">
      <title>Evaluation</title>
      <p id="Par44">Model performance was assessed by overall and per-class classification accuracy (true positive rate) for (a) sequence type, (b) imaging plane, and (c) combined sequence and plane accuracy (Combined). Combined weighted precision, recall, and F1-scores were also calculated. Confusion matrices and gradient-weighted class activation mapping (Grad-CAM) were employed to assess the developed models [<xref ref-type="bibr" rid="CR14">14</xref>].</p>
    </sec>
  </sec>
  <sec id="Sec10">
    <title>Results</title>
    <p id="Par45">For SVT, overall test set accuracy, precision, recall, and F1-scores of 81.2%, 0.86, 0.82, and 0.82 were achieved. Test set sequence type and plane accuracies were 85.2% and 93.2% respectively (Table <xref rid="Tab2" ref-type="table">2</xref>). Best performance for Centre 1 data was achieved compared to Centres 2 and 3, where images were acquired on different vendor systems to the training data (per-class results presented in Supplementary Table <xref rid="MOESM1" ref-type="media">2</xref>). An example of the differences (in white blood late gadolinium-enhanced images (WBLGE)) between vendors, leading to poor accuracy on unseen vendors for SVT, is shown in Fig. <xref rid="Fig4" ref-type="fig">4</xref>a.
<table-wrap id="Tab2"><label>Table 2</label><caption><p>Accuracy, weighted precision, weighted recall and weighted F1-score of the model on test data for each experiment by Centre and Vendor. Combined metrics represents data where both sequence type and plane accuracy are required for a true positive result.</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Experiment</th><th>Centre</th><th>Vendor</th><th>Sequence accuracy (%)</th><th>Plane accuracy (%)</th><th>Combined accuracy (%)</th><th>Combined<break/>Precision</th><th>Combined<break/>Recall</th><th>Combined<break/>F1-score</th></tr></thead><tbody><tr><td rowspan="4">Single vendor training*</td><td><bold>1</bold></td><td><bold>Philips</bold></td><td><p>958/1025</p><p>(93.46)</p></td><td><p>1004/1025</p><p>(97.95)</p></td><td><p>938/1025</p><p>(91.51)</p></td><td>0.93</td><td>0.92</td><td>0.91</td></tr><tr><td><bold>1 and 2</bold></td><td><bold>Siemens</bold></td><td><p>322/438</p><p>(73.52)</p></td><td><p>372/438</p><p>(84.93)</p></td><td><p>295/438</p><p>(67.35)</p></td><td>0.79</td><td>0.67</td><td>0.66</td></tr><tr><td><bold>3</bold></td><td><bold>GE</bold></td><td><p>79/133</p><p>(59.40)</p></td><td><p>112/133</p><p>(84.21)</p></td><td><p>73/133</p><p>(54.89)</p></td><td>0.78</td><td>0.55</td><td>0.53</td></tr><tr><td><bold>All</bold></td><td><bold>All</bold></td><td><p><bold>1359/1596</bold></p><p><bold>(85.15)</bold></p></td><td><p><bold>1488/1596</bold></p><p><bold>(93.23)</bold></p></td><td><p><bold>1306/1596</bold></p><p><bold>(81.83%)</bold></p></td><td><bold>0.86</bold></td><td><bold>0.82</bold></td><td><bold>0.82</bold></td></tr><tr><td rowspan="4">Multivendor training**</td><td><bold>1</bold></td><td><bold>Philips</bold></td><td><p>976/1025</p><p>(95.22)</p></td><td><p>1003/1025</p><p>(97.85)</p></td><td><p>957/1025</p><p>(93.37)</p></td><td>0.94</td><td>0.94</td><td>0.93</td></tr><tr><td><bold>1 &amp; 2</bold></td><td><bold>Siemens</bold></td><td><p>233/238</p><p>(97.90)</p></td><td><p>236/238</p><p>(99.16)</p></td><td><p>233/238</p><p>(97.90)</p></td><td>0.98</td><td>0.98</td><td>0.98</td></tr><tr><td><bold>3</bold></td><td><bold>GE</bold></td><td><p>132/133</p><p>(99.25)</p></td><td><p>128/133</p><p>(96.24)</p></td><td><p>127/133</p><p>(95.49)</p></td><td>0.99</td><td>0.95</td><td>0.95</td></tr><tr><td><bold>All</bold></td><td><bold>All</bold></td><td><p><bold>1341/1396</bold></p><p><bold>(96.06)</bold></p></td><td><p><bold>1367/1396</bold></p><p><bold>(97.92)</bold></p></td><td><p><bold>1317/1396</bold></p><p><bold>(94.34)</bold></p></td><td><bold>0.95</bold></td><td><bold>0.94</bold></td><td><bold>0.94</bold></td></tr><tr><td rowspan="3">Multivendor training – external validation</td><td><bold>2</bold></td><td><bold>Philips</bold></td><td><p>262/306</p><p>(85.62)</p></td><td><p>282/306</p><p>(92.16)</p></td><td><p>239/306</p><p>(78.10)</p></td><td>0.86</td><td>0.78</td><td>0.77</td></tr><tr><td><bold>4</bold></td><td><bold>Siemens</bold></td><td><p>596/620</p><p>(96.13)</p></td><td><p>579/620</p><p>(93.39)</p></td><td><p>563/620</p><p>(90.81)</p></td><td>0.93</td><td>0.91</td><td>0.91</td></tr><tr><td><bold>All external data</bold></td><td/><td><p><bold>858/926</bold></p><p><bold>(92.66)</bold></p></td><td><p><bold>861/926</bold></p><p><bold>(92.98)</bold></p></td><td><p><bold>802/926</bold></p><p><bold>(86.61)</bold></p></td><td><bold>0.90</bold></td><td><bold>0.87</bold></td><td><bold>0.86</bold></td></tr></tbody></table><table-wrap-foot><p>*One class (short-axis T2 bright blood mapping) was omitted from test datasets for single vendor training due to absence of this class in the training data</p><p>**Cases where patients overlapped with training data were omitted from the test set for multivendor training</p></table-wrap-foot></table-wrap><fig id="Fig4"><label>Fig. 4</label><caption><p>Error analysis. <bold>A</bold> White blood LGE short-axis imaging demonstrating differences between vendors, with 3 image types, magnitude reconstructed inversion recovery (Magnitude), phase reconstructed inversion recovery (Phase), and reference imaging to estimate background phase and surface coil field maps (Reference) images present for Vendor 1. Only the magnitude reconstructed and phase reconstructed images are present for Vendor 2, and only magnitude reconstructed images present for Vendor 3 source data. Also note that differentiation between dark and white blood LGE imaging depends upon appearance of blood and myocardium on magnitude images. <bold>B</bold> Multivendor training native modified Look-Locker Inversion Recovery (MOLLI) T1 mapping, demonstrating a correct and incorrect prediction for Vendor 1 data. In both examples, model attention is focused upon the blood within the ventricles and blood vessels, as indicated by Grad-CAM heat maps superimposed on the original images (second and fourth rows), where red represents a high degree of model attention. However, motion-related artefact is present in the incorrect example, with activation visualized over the inferoseptal segment of the left ventricle (arrows), where myocardial signal appears similar to that of the blood pool on the T1 map (arrowhead), incorrectly predicted as cine short-axis imaging. <bold>C</bold> Multivendor training fat-suppressed T2-weighted short-axis imaging demonstrating a correct and incorrect prediction. For the correct prediction, model attention is focused upon the subcutaneous fat, myocardium, and spleen (arrows), similar to structures a human reader would assess to identify the image type and plane. For the incorrect prediction, the model is focused upon banding artefact related to off-resonance effects at air/soft tissue interfaces (arrowheads). This was predicted as cine short-axis imaging, with cine imaging generally performed with balanced steady-state free precession imaging, which is most prone to banding artefact. <bold>D</bold> Multivendor training external short-axis perfusion imaging examples of a correct prediction from the validation set and incorrect prediction from the external test set. For the correct prediction, model attention is focused upon the right ventricle (arrows) and to a lesser extent the left ventricle, where large relative fluctuations in the contrast of the blood pool of the left and right ventricular chambers are present. For the incorrect prediction, the model is more focused upon the blood pool of the left ventricle (arrowheads), with similar signal within left and right ventricles observed at the mid and basal levels. Note that apical blood pool signal was variable for both training/validation and test dataset, with high signal sometimes observed secondary to flow-related “enhancement” on early perfusion imaging, prior to contrast arrival (hollow arrow)</p></caption><graphic xlink:href="330_2022_8724_Fig4a_HTML" id="d32e2506"/><graphic xlink:href="330_2022_8724_Fig4b_HTML" id="d32e2507"/><graphic xlink:href="330_2022_8724_Fig4c_HTML" id="d32e2508"/><graphic xlink:href="330_2022_8724_Fig4d_HTML" id="d32e2509"/></fig></p>
    <p id="Par46">MVT overall test set accuracy, precision, recall, and F1-scores of 94.3%, 0.95, 0.94, and 0.94 were found. Test set sequence type and plane accuracies were 96.1% and 97.9%, respectively (Table <xref rid="Tab2" ref-type="table">2</xref>). Excellent accuracy was observed for Vendor 2 data (97.9% sequence, 99.2% plane, 97.9% Combined), with near-perfect sequence accuracy for Vendor 3 data (99.3% sequence, 96.2% plane, 95.5% Combined), and stronger plane versus sequence accuracy for Vendor 1 (95.2% sequence, 97.9% plane, 93.4% Combined). The lowest sequence accuracy was observed for Vendor 1 native modified Look Locker inversion recovery (MOLLI) imaging (39.0%), most frequently predicted as cine imaging, compared to 100% sequence accuracy for native MOLLI for Vendor 2, and no Vendor 3 MOLLI data available (Supplementary Table <xref rid="MOESM1" ref-type="media">3</xref>). Grad-CAM analysis demonstrated motion-related artefact as a cause of incorrect predictions for this sequence (Fig. <xref rid="Fig4" ref-type="fig">4</xref>b). Fat-suppressed T2-weighted (FST2) weighted short axis imaging sequence accuracy was poor for Vendor 2 (4/6 datapoints, 66.7%), with failure of fat suppression and banding artefact observed (Fig. <xref rid="Fig4" ref-type="fig">4</xref>c). MVT sequence and plane confusion matrices are presented in Fig. <xref rid="Fig5" ref-type="fig">5</xref>a.
<fig id="Fig5"><label>Fig. 5</label><caption><p>Confusion matrices for multivendor training. <bold>A</bold> Hold-out test set sequence (left) and plane (right) confusion matrices; <bold>B</bold> external data sequence (left) and plane (right) confusion matrices</p></caption><graphic xlink:href="330_2022_8724_Fig5_HTML" id="MO5"/></fig></p>
    <p id="Par47">MVT<sub>external</sub> achieved overall test set accuracy, precision, recall, and F1-scores of 86.6%, 0.90, 0.87, and 0.86 on external data (Table <xref rid="Tab2" ref-type="table">2</xref>). Sequence, plane, and Combined accuracies of 85.6%, 92.2%, and 78.1% respectively for Vendor 1, and 96.1%, 93.4%, and 90.8% respectively for Vendor 2 were recorded. High F1-scores for common classes including cine imaging in multiple planes, MOLLI native and post-contrast imaging, TI scout imaging, and WBLGE imaging in all planes were found (Supplementary Table <xref rid="MOESM1" ref-type="media">4</xref>).</p>
    <p id="Par48">Excellent overall sequence accuracy of MVT<sub>external</sub> was observed for cine (94–100%), phase contrast (100%), and long-axis WBLGE (92–100%). Poorest sequence accuracy was observed for (Vendor 1) perfusion imaging (0%), most commonly misclassified as cine (10/17 datapoints) or TI scout sequences (7/17). Differences in sequence parameters, total acquisition time, and contrast protocol (dual-bolus [<xref ref-type="bibr" rid="CR15">15</xref>] for Vendor 1 training versus single bolus technique for external data), led to visually different image characteristics (Fig. <xref rid="Fig4" ref-type="fig">4</xref>d). Relatively low sequence accuracy was observed for WBLGE short axis imaging for Vendor 1 (16/21, 76.2%), classified as dark blood LGE imaging (DBLGE) in 4/21 cases. Suboptimal myocardial nulling and absence of myocardium and blood pool in the included magnitude reconstructed image when positioned distal to the left ventricular apex were observed for incorrect predictions, impacting ability to differentiate between WBLGE and DBLGE (see Fig. <xref rid="Fig4" ref-type="fig">4</xref>a, Vendor 1).</p>
    <p id="Par49">MVT<sub>external</sub> demonstrated high plane prediction accuracy for most common sequence types including cine, MOLLI, TI scout, and WBLGE imaging, strongest for 4 chamber (100%), axial (100%), and short-axis imaging (304/323, 94.1%), and high for 2-chamber (115/129, 89.1%) and 3-chamber (100/113, 88.5%) planes. Poor plane performance was observed for the main pulmonary artery (1/10, 10%), 2-chamber FST2 (4/7, 57.1%), and right ventricular outflow tract (5/10, 50%), with relatively few datapoints available for training. Poor plane performance for short axis FST2 (1/7, 14.3%) was noted, with differences in image export observed between external test (single-slice location per series) and training data (multiple-slice locations per series). Confusion matrices for sequence and plane are presented in Fig. <xref rid="Fig5" ref-type="fig">5</xref>b.</p>
  </sec>
  <sec id="Sec11">
    <title>Discussion</title>
    <p id="Par50">In this study, a multivendor deep learning model was developed and validated on external data with high accuracy and F1-scores for identifying commonly performed sequences, particularly cine and WBLGE imaging, and for standard anatomic and cardiac planes. Our work highlights the importance of training the model on a diverse, multi-institutional multivendor dataset, with SVT demonstrating high performance on hold-out test data from the same institution, but poor performance on data from other institutions and vendors, with improved accuracy with MVT on the hold-out multivendor test set.</p>
    <p id="Par51">The variability of clinically used cardiac MRI sequences is also highlighted, impacting model generalizability, exemplified in our study by the decrease in accuracy of MVT from internal test to external data. Though model performance was still very high for common image sequences, it was lower for sequences with differences in parameters and image appearance between external validation and training images, shown by our experience with perfusion imaging. Image artefacts, e.g., misregistration from motion for MOLLI, banding artefact, or failure of fat suppression, also impacted model accuracy. Differences in image export between vendors and institutions also impacted the robustness of the developed model. Vendors provide users with the option to save and export a sequence with multiple slice locations as a single or multiple series. This impacted the model’s ability to predict short-axis FST2 for MVT<sub>external</sub>, where differences in image storage existed between training and external data. Even for sequences that appear relatively uniform, subtle cross-vendor and within-vendor differences may impact model generalizability, as was observed for short axis cine imaging for automated ventricular segmentation [<xref ref-type="bibr" rid="CR16">16</xref>]. Data augmentation can aid generalizability but does not entirely solve the problem. Greater exposure to a larger variety of data and permutations of image storage for classes with multiple slice locations would likely improve accuracy.</p>
    <p id="Par52">We have made CardiSort available for the scientific community to utilise, facilitating development of fully automated pipelines by allowing automated selection of the requisite image series for processing. We have also provided our trained model weights, should other scientists wish to use transfer learning to include their own data, additional classes, or other magnet systems. Manual selection of the desired sequence is still required in automated cardiac MRI post-processing pipelines described to date [<xref ref-type="bibr" rid="CR4">4</xref>–<xref ref-type="bibr" rid="CR6">6</xref>, <xref ref-type="bibr" rid="CR17">17</xref>]. Automated extraction from non-curated data would provide a crucial first step to applying AI prospectively in the clinic, rather than retrospectively in a controlled environment. A proposed future clinical workflow would incorporate CardiSort to classify images received directly from the scanner, with sorted images then automatically sent to the appropriate post-processing pipeline for quantitative metrics, e.g. ventricular segmentation [<xref ref-type="bibr" rid="CR18">18</xref>], myocardial strain [<xref ref-type="bibr" rid="CR19">19</xref>], perfusion quantification [<xref ref-type="bibr" rid="CR5">5</xref>], and scar quantification and classification [<xref ref-type="bibr" rid="CR20">20</xref>], and results of post-processing automatically returned for image interpretation.</p>
    <p id="Par53">There are some limitations to our work. This was a relatively small dataset for a deep learning task, with data augmentation used to expose the network to a greater variety of inputs. Some classes were not available for every vendor in the training data and for external validation. We deliberately chose not to incorporate metadata within model input, which is variable between vendors/centres and may be incomplete or unavailable in publicly available datasets. While the datasets reflect real-world composition of clinical adult cardiac MRI, the model was only trained to recognise standard cardiac anatomy, with insufficient data available for congenital abnormalities.</p>
    <p id="Par54">Our approach, sampling only 3 images per sequence, likely impacted accuracy for predicting sequences that vary temporally, in image contrast or included image type throughout the acquisition, as was observed for short-axis WBLGE for MVT<sub>external</sub>. This represents a practical and efficient means of representing sequences to a model requiring data of a consistent shape for training. Cardiac MRI sequences may comprise a single image or multiple images, and a single or up to three image types, and this approach ensured representation of these. Future work might incorporate other architectures, for example, a 3-dimensional CNN with greater number of input images per sequence and/ or a recurrent neural network to incorporate more sequential information, at the expense of training efficiency.</p>
    <p id="Par55">In conclusion, we have trained a deep learning network on multi-institutional multivendor data to infer 35 unique cardiac MRI sequences by sequence type and imaging plane, with high performance for the most common image types. We have also made our work available for other scientists to use on their own non-curated datasets or to adapt to include additional sequences. Sorting of non-curated data represents a heretofore missing link in the development of efficient and fully automated processing pipelines, essential if they are to be ultimately translated from the research to the clinical domain.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Information</title>
    <sec id="Sec12">
      <p>
        <supplementary-material content-type="local-data" id="MOESM1">
          <media xlink:href="330_2022_8724_MOESM1_ESM.docx">
            <label>ESM 1</label>
            <caption>
              <p>(DOCX 609 kb)</p>
            </caption>
          </media>
        </supplementary-material>
      </p>
    </sec>
  </sec>
</body>
<back>
  <glossary>
    <title>Abbreviations</title>
    <def-list>
      <def-item>
        <term>2D</term>
        <def>
          <p id="Par8">Two-dimensional</p>
        </def>
      </def-item>
      <def-item>
        <term>bSSFP</term>
        <def>
          <p id="Par9">Balanced steady-state free precession imaging</p>
        </def>
      </def-item>
      <def-item>
        <term>CNN</term>
        <def>
          <p id="Par10">Convolutional neural network</p>
        </def>
      </def-item>
      <def-item>
        <term>DBLGE</term>
        <def>
          <p id="Par11">Dark blood late gadolinium-enhanced imaging (blood nulled)</p>
        </def>
      </def-item>
      <def-item>
        <term>DICOM</term>
        <def>
          <p id="Par12">Digital Imaging and Communications in Medicine</p>
        </def>
      </def-item>
      <def-item>
        <term>EGE </term>
        <def>
          <p id="Par13">Early gadolinium-enhanced imaging</p>
        </def>
      </def-item>
      <def-item>
        <term>FST2</term>
        <def>
          <p id="Par14">Fat-suppressed T2-weighted imaging</p>
        </def>
      </def-item>
      <def-item>
        <term>Grad-CAM</term>
        <def>
          <p id="Par15">Gradient-weighted class activation mapping</p>
        </def>
      </def-item>
      <def-item>
        <term>HASTE</term>
        <def>
          <p id="Par16">Half-Fourier acquisition single-shot turbo spin echo imaging</p>
        </def>
      </def-item>
      <def-item>
        <term>LVOT</term>
        <def>
          <p id="Par17">Left ventricular outflow tract, perpendicular to 3-chamber plane</p>
        </def>
      </def-item>
      <def-item>
        <term>MOLLI (+/-)</term>
        <def>
          <p id="Par18">Modified Look Locker inversion recovery imaging (post contrast/native)</p>
        </def>
      </def-item>
      <def-item>
        <term>MPA</term>
        <def>
          <p id="Par19">Main pulmonary artery</p>
        </def>
      </def-item>
      <def-item>
        <term>MVT</term>
        <def>
          <p id="Par20">Multivendor training</p>
        </def>
      </def-item>
      <def-item>
        <term>MVT<sub>external</sub></term>
        <def>
          <p id="Par21">Multivendor training with external test data</p>
        </def>
      </def-item>
      <def-item>
        <term>PC</term>
        <def>
          <p id="Par22">Phase contrast imaging</p>
        </def>
      </def-item>
      <def-item>
        <term>ReLU</term>
        <def>
          <p id="Par23">Rectified linear unit</p>
        </def>
      </def-item>
      <def-item>
        <term>RVOT</term>
        <def>
          <p id="Par24">Right ventricular outflow tract (oblique sagittal plane)</p>
        </def>
      </def-item>
      <def-item>
        <term>SCMR</term>
        <def>
          <p id="Par25">Society for Cardiovascular Magnetic Resonance</p>
        </def>
      </def-item>
      <def-item>
        <term>SVT </term>
        <def>
          <p id="Par26">Single vendor training</p>
        </def>
      </def-item>
      <def-item>
        <term>TI scout</term>
        <def>
          <p id="Par27">Inversion time scout imaging for late gadolinium-enhanced imaging</p>
        </def>
      </def-item>
      <def-item>
        <term>UID</term>
        <def>
          <p id="Par28">Unique identifier</p>
        </def>
      </def-item>
      <def-item>
        <term>WBLGE</term>
        <def>
          <p id="Par29">White blood late gadolinium-enhanced imaging (normal myocardium nulled)</p>
        </def>
      </def-item>
    </def-list>
  </glossary>
  <fn-group>
    <fn>
      <p>
        <bold>Publisher’s note</bold>
      </p>
      <p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
    </fn>
  </fn-group>
  <ack>
    <title>Acknowledgements</title>
    <p>The authors wish to thank Alana Malandra BAppSc (Med Rad) for her invaluable assistance with data collection.</p>
  </ack>
  <notes notes-type="funding-information">
    <title>Funding</title>
    <p>Open Access funding enabled and organised by CAUL and its Member Institutions. This work was supported by the Wellcome/ EPSRC Centre for Medical Engineering [WT 203148/Z/16/Z]; and by a Wellcome Trust Innovator Award [WT 222678/Z/21/Z].</p>
    <p>For the purpose of open access, the author has applied a CC BY public copyright licence to any Author Accepted Manuscript version arising from this submission.</p>
  </notes>
  <notes>
    <title>Declarations</title>
    <notes id="FPar1">
      <title>Guarantor</title>
      <p id="Par56">The scientific guarantor of this publication is Ruth P Lim.</p>
    </notes>
    <notes id="FPar2" notes-type="COI-statement">
      <title>Conflict of interest</title>
      <p id="Par57">The authors of this manuscript declare relationships with the following companies:</p>
      <p id="Par58">RPL: Boehringer Ingelheim (Research Grant to the author’s institution, not related to the current study)</p>
    </notes>
    <notes id="FPar3">
      <title>Statistics and biometry</title>
      <p id="Par59">No complex statistical methods were necessary for this paper.</p>
    </notes>
    <notes id="FPar4">
      <title>Informed consent</title>
      <p id="Par60">Written informed consent was waived by the Institutional Review Board.</p>
    </notes>
    <notes id="FPar5">
      <title>Ethical approval</title>
      <p id="Par61">Institutional Review Board approval was obtained.</p>
    </notes>
    <notes id="FPar6">
      <title>Methodology</title>
      <p id="Par62">• retrospective</p>
      <p id="Par63">• cross-sectional study</p>
      <p id="Par64">• multicentre study</p>
    </notes>
  </notes>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <label>1.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kramer</surname>
            <given-names>CM</given-names>
          </name>
          <name>
            <surname>Barkhausen</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Bucciarelli-Ducci</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Flamm</surname>
            <given-names>SD</given-names>
          </name>
          <name>
            <surname>Kim</surname>
            <given-names>RJ</given-names>
          </name>
          <name>
            <surname>Nagel</surname>
            <given-names>E</given-names>
          </name>
        </person-group>
        <article-title>Standardized cardiovascular magnetic resonance imaging (CMR) protocols: 2020 update</article-title>
        <source>J Cardiovasc Magn Reson</source>
        <year>2020</year>
        <volume>22</volume>
        <issue>1</issue>
        <fpage>17</fpage>
        <pub-id pub-id-type="doi">10.1186/s12968-020-00607-1</pub-id>
        <pub-id pub-id-type="pmid">32089132</pub-id>
      </element-citation>
    </ref>
    <ref id="CR2">
      <label>2.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Schulz-Menger</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Bluemke</surname>
            <given-names>DA</given-names>
          </name>
          <name>
            <surname>Bremerich</surname>
            <given-names>J</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Standardized image interpretation and post-processing in cardiovascular magnetic resonance - 2020 update : Society for Cardiovascular Magnetic Resonance (SCMR): Board of Trustees Task Force on Standardized Post-Processing</article-title>
        <source>J Cardiovasc Magn Reson</source>
        <year>2020</year>
        <volume>22</volume>
        <issue>1</issue>
        <fpage>19</fpage>
        <pub-id pub-id-type="doi">10.1186/s12968-020-00610-6</pub-id>
        <pub-id pub-id-type="pmid">32160925</pub-id>
      </element-citation>
    </ref>
    <ref id="CR3">
      <label>3.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Fahmy</surname>
            <given-names>AS</given-names>
          </name>
          <name>
            <surname>El-Rewaidy</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Nezafat</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Nakamori</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Nezafat</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>Automated analysis of cardiovascular magnetic resonance myocardial native T1 mapping images using fully convolutional neural networks</article-title>
        <source>J Cardiovasc Magn Reson</source>
        <year>2019</year>
        <volume>21</volume>
        <issue>1</issue>
        <fpage>7</fpage>
        <pub-id pub-id-type="doi">10.1186/s12968-018-0516-1</pub-id>
        <pub-id pub-id-type="pmid">30636630</pub-id>
      </element-citation>
    </ref>
    <ref id="CR4">
      <label>4.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Knott</surname>
            <given-names>KD</given-names>
          </name>
          <name>
            <surname>Seraphim</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Augusto</surname>
            <given-names>JB</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>The prognostic significance of quantitative myocardial perfusion: an artificial intelligence-based approach using perfusion mapping</article-title>
        <source>Circulation</source>
        <year>2020</year>
        <volume>141</volume>
        <issue>16</issue>
        <fpage>1282</fpage>
        <lpage>1291</lpage>
        <?supplied-pmid 32078380?>
        <pub-id pub-id-type="pmid">32078380</pub-id>
      </element-citation>
    </ref>
    <ref id="CR5">
      <label>5.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Scannell</surname>
            <given-names>CM</given-names>
          </name>
          <name>
            <surname>Veta</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Villa</surname>
            <given-names>ADM</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Deep-learning-based preprocessing for quantitative myocardial perfusion MRI</article-title>
        <source>J Magn Reson Imaging</source>
        <year>2019</year>
        <volume>51</volume>
        <fpage>1689</fpage>
        <lpage>1696</lpage>
        <pub-id pub-id-type="doi">10.1002/jmri.26983</pub-id>
        <pub-id pub-id-type="pmid">31710769</pub-id>
      </element-citation>
    </ref>
    <ref id="CR6">
      <label>6.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Tao</surname>
            <given-names>Q</given-names>
          </name>
          <name>
            <surname>Yan</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>Y</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Deep learning-based method for fully automatic quantification of left ventricle function from cine MR images: a multivendor, multicenter study</article-title>
        <source>Radiology</source>
        <year>2019</year>
        <volume>290</volume>
        <issue>1</issue>
        <fpage>81</fpage>
        <lpage>88</lpage>
        <pub-id pub-id-type="doi">10.1148/radiol.2018180513</pub-id>
        <pub-id pub-id-type="pmid">30299231</pub-id>
      </element-citation>
    </ref>
    <ref id="CR7">
      <label>7.</label>
      <mixed-citation publication-type="other">van Ooijen PMA (2019) Quality and curation of medical images and data. In: Ranschaert ER, Morozov S, Algra PR (eds) Artificial intelligence in medical imaging: opportunities, applications and risks. Springer International Publishing, pp 247–255</mixed-citation>
    </ref>
    <ref id="CR8">
      <label>8.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Willemink</surname>
            <given-names>MJ</given-names>
          </name>
          <name>
            <surname>Koszek</surname>
            <given-names>WA</given-names>
          </name>
          <name>
            <surname>Hardell</surname>
            <given-names>C</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Preparing medical imaging data for machine learning</article-title>
        <source>Radiology</source>
        <year>2020</year>
        <volume>295</volume>
        <issue>1</issue>
        <fpage>4</fpage>
        <lpage>15</lpage>
        <pub-id pub-id-type="doi">10.1148/radiol.2020192224</pub-id>
        <pub-id pub-id-type="pmid">32068507</pub-id>
      </element-citation>
    </ref>
    <ref id="CR9">
      <label>9.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>van der Voort</surname>
            <given-names>SR</given-names>
          </name>
          <name>
            <surname>Smits</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Klein</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>DeepDicomSort: an automatic sorting algorithm for brain magnetic resonance imaging data</article-title>
        <source>Neuroinformatics</source>
        <year>2021</year>
        <volume>19</volume>
        <issue>1</issue>
        <fpage>159</fpage>
        <lpage>184</lpage>
        <pub-id pub-id-type="doi">10.1007/s12021-020-09475-7</pub-id>
        <pub-id pub-id-type="pmid">32627144</pub-id>
      </element-citation>
    </ref>
    <ref id="CR10">
      <label>10.</label>
      <mixed-citation publication-type="other">NEMA PS3 / ISO 12052, Digital Imaging and Communications in Medicine (DICOM) Standard, National Electrical Manufacturers Association, Rosslyn, VA, USA. Available via <ext-link ext-link-type="uri" xlink:href="https://www.dicomstandard.org/current">https://www.dicomstandard.org/current</ext-link>. Accessed 03 Aug 2021</mixed-citation>
    </ref>
    <ref id="CR11">
      <label>11.</label>
      <mixed-citation publication-type="other">Nair V, Hinton G (2010) Rectified Linear Units improve restricted Boltzmann machines. Proceedings of the 27 th International Conference on Machine Learning, Haifa, Israel</mixed-citation>
    </ref>
    <ref id="CR12">
      <label>12.</label>
      <mixed-citation publication-type="other">Bridle JS (1990) Probabilistic interpretation of feedforward classification network outputs, with relationships to statistical pattern recognition. In: Soulié FF, Hérault J (eds) Neurocomputing. NATO ASI Series (Series F: Computer and Systems Sciences), vol 68. Springer, Berlin, Heidelberg. Available via 10.1007/978-3-642-76153-9_28. Accessed 04 Aug 2021</mixed-citation>
    </ref>
    <ref id="CR13">
      <label>13.</label>
      <mixed-citation publication-type="other">He K, Zhang X, Ren S, Sun J (2015) Delving deep into rectifiers: surpassing human level performance on ImageNet classification. Proceedings of the IEEE International Conference on Computer Vision (ICCV)</mixed-citation>
    </ref>
    <ref id="CR14">
      <label>14.</label>
      <mixed-citation publication-type="other">Chollet F (2017) Deep learning for computer vision. In: Deep learning with Python. Manning Publications, pp 119–177</mixed-citation>
    </ref>
    <ref id="CR15">
      <label>15.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ishida</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Schuster</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Morton</surname>
            <given-names>G</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Development of a universal dual-bolus injection scheme for the quantitative assessment of myocardial perfusion cardiovascular magnetic resonance</article-title>
        <source>J Cardiovasc Magn Reson</source>
        <year>2011</year>
        <volume>13</volume>
        <issue>1</issue>
        <fpage>28</fpage>
        <pub-id pub-id-type="doi">10.1186/1532-429X-13-28</pub-id>
        <pub-id pub-id-type="pmid">21609423</pub-id>
      </element-citation>
    </ref>
    <ref id="CR16">
      <label>16.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Campello</surname>
            <given-names>VM</given-names>
          </name>
          <name>
            <surname>Gkontra</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Izquierdo</surname>
            <given-names>C</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Multi-centre, multi-vendor and multi-disease cardiac segmentation: The M&amp;Ms Challenge</article-title>
        <source>IEEE Trans Med Imaging</source>
        <year>2021</year>
        <volume>40</volume>
        <issue>12</issue>
        <fpage>3543</fpage>
        <lpage>3554</lpage>
        <pub-id pub-id-type="doi">10.1109/TMI.2021.3090082</pub-id>
        <pub-id pub-id-type="pmid">34138702</pub-id>
      </element-citation>
    </ref>
    <ref id="CR17">
      <label>17.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Böttcher</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Beller</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Busse</surname>
            <given-names>A</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Fully automated quantification of left ventricular volumes and function in cardiac MRI: clinical evaluation of a deep learning-based algorithm</article-title>
        <source>Int J Cardiovasc Imaging</source>
        <year>2020</year>
        <volume>36</volume>
        <issue>11</issue>
        <fpage>2239</fpage>
        <lpage>2247</lpage>
        <pub-id pub-id-type="doi">10.1007/s10554-020-01935-0</pub-id>
        <pub-id pub-id-type="pmid">32677023</pub-id>
      </element-citation>
    </ref>
    <ref id="CR18">
      <label>18.</label>
      <mixed-citation publication-type="other">Scannell CM, Chiribiri A, Veta M (2021) Domain-adversarial learning for multi-centre, multi-vendor, and multi-disease cardiac MR image segmentation. In: Puyol AE, Pop M, Sermesant M et al (eds) Statistical atlases and computational models of the heart. M&amp;Ms and EMIDEC Challenges. STACOM 2020. Springer International Publishing, pp 228–237</mixed-citation>
    </ref>
    <ref id="CR19">
      <label>19.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ferdian</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Suinesiaputra</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Fung</surname>
            <given-names>K</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Fully automated myocardial strain estimation from cardiovascular MRI-tagged images using a deep learning framework in the UK Biobank</article-title>
        <source>Radiol Cardiothorac Imaging</source>
        <year>2020</year>
        <volume>2</volume>
        <issue>1</issue>
        <fpage>e190032</fpage>
        <pub-id pub-id-type="doi">10.1148/ryct.2020190032</pub-id>
        <pub-id pub-id-type="pmid">32715298</pub-id>
      </element-citation>
    </ref>
    <ref id="CR20">
      <label>20.</label>
      <mixed-citation publication-type="other">Lourenço A, Kerfoot E, Grigorescu I, Scannell CM, Varela M, Correia TM (2021) Automatic myocardial disease prediction from delayed-enhancement cardiac MRI and clinical information. In: Puyol AE, Pop M, Sermesant M et al (eds) Statistical atlases and computational models of the heart. M&amp;Ms and EMIDEC Challenges. STACOM 2020. Springer International Publishing, pp 334–341</mixed-citation>
    </ref>
  </ref-list>
</back>
