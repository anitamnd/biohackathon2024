<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Sci Rep</journal-id>
    <journal-id journal-id-type="iso-abbrev">Sci Rep</journal-id>
    <journal-title-group>
      <journal-title>Scientific Reports</journal-title>
    </journal-title-group>
    <issn pub-type="epub">2045-2322</issn>
    <publisher>
      <publisher-name>Nature Publishing Group UK</publisher-name>
      <publisher-loc>London</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">6754439</article-id>
    <article-id pub-id-type="publisher-id">50121</article-id>
    <article-id pub-id-type="doi">10.1038/s41598-019-50121-3</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Article</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Drug-Drug Interaction Predicting by Neural Network Using Integrated Similarity</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Rohani</surname>
          <given-names>Narjes</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Eslahchi</surname>
          <given-names>Changiz</given-names>
        </name>
        <address>
          <email>Ch-Eslahchi@sbu.ac.ir</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="GRID">grid.411600.2</institution-id><institution>Department of Computer Sciences, </institution><institution>Faculty of Mathematics, Shahid Beheshti University, G.C, </institution></institution-wrap>Tehran, 1983969411 Iran </aff>
      <aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0000 8841 7951</institution-id><institution-id institution-id-type="GRID">grid.418744.a</institution-id><institution>School of Biological Sciences, </institution><institution>Institute for Research in Fundamental Sciences (IPM), </institution></institution-wrap>Tehran, 193955746 Iran </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>20</day>
      <month>9</month>
      <year>2019</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>20</day>
      <month>9</month>
      <year>2019</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2019</year>
    </pub-date>
    <volume>9</volume>
    <elocation-id>13645</elocation-id>
    <history>
      <date date-type="received">
        <day>9</day>
        <month>5</month>
        <year>2019</year>
      </date>
      <date date-type="accepted">
        <day>6</day>
        <month>9</month>
        <year>2019</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2019</copyright-statement>
      <license license-type="OpenAccess">
        <license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. The images or other third party material in this article are included in the article’s Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this license, visit <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>.</license-p>
      </license>
    </permissions>
    <abstract id="Abs1">
      <p id="Par1">Drug-Drug Interaction (DDI) prediction is one of the most critical issues in drug development and health. Proposing appropriate computational methods for predicting unknown DDI with high precision is challenging. We proposed "NDD: Neural network-based method for drug-drug interaction prediction" for predicting unknown DDIs using various information about drugs. Multiple drug similarities based on drug substructure, target, side effect, off-label side effect, pathway, transporter, and indication data are calculated. At first, NDD uses a heuristic similarity selection process and then integrates the selected similarities with a nonlinear similarity fusion method to achieve high-level features. Afterward, it uses a neural network for interaction prediction. The similarity selection and similarity integration parts of NDD have been proposed in previous studies of other problems. Our novelty is to combine these parts with new neural network architecture and apply these approaches in the context of DDI prediction. We compared NDD with six machine learning classifiers and six state-of-the-art graph-based methods on three benchmark datasets. NDD achieved superior performance in cross-validation with AUPR ranging from 0.830 to 0.947, AUC from 0.954 to 0.994 and F-measure from 0.772 to 0.902. Moreover, cumulative evidence in case studies on numerous drug pairs, further confirm the ability of NDD to predict unknown DDIs. The evaluations corroborate that NDD is an efficient method for predicting unknown DDIs. The data and implementation of NDD are available at <ext-link ext-link-type="uri" xlink:href="https://github.com/nrohani/NDD">https://github.com/nrohani/NDD</ext-link>.</p>
    </abstract>
    <kwd-group kwd-group-type="npg-subject">
      <title>Subject terms</title>
      <kwd>Data mining</kwd>
      <kwd>Machine learning</kwd>
    </kwd-group>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>© The Author(s) 2019</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="Sec1" sec-type="introduction">
    <title>Introduction</title>
    <p id="Par2">DDIs are known as the unwanted side effects resulting from the concurrent consumption of two or more drugs<sup><xref ref-type="bibr" rid="CR1">1</xref>–<xref ref-type="bibr" rid="CR3">3</xref></sup>. When a doctor prescribes several drugs simultaneously for a patient, DDIs may cause irreparable side effects. The effects of drugs on each other may lead to other illnesses or even death. These side effects are particularly noticeable in adult people and cancer patients who take lots of drugs daily<sup><xref ref-type="bibr" rid="CR4">4</xref>,<xref ref-type="bibr" rid="CR5">5</xref></sup>.</p>
    <p id="Par3">Due to the importance of predicting DDIs in human health, industry and the economy, and the substantial amount of cost and time of traditional experimental approaches<sup><xref ref-type="bibr" rid="CR6">6</xref></sup>, accurate computational methods for predicting DDI are in need. There is a huge number of biomedical information besides the development of computational approaches. For example, DrugBank is one of the most credible databases of known DDI<sup><xref ref-type="bibr" rid="CR7">7</xref>–<xref ref-type="bibr" rid="CR9">9</xref></sup>, which contains more than 300,000 DDIs. Nevertheless, this amount of interaction data is less than 1% of the total drug pairs exist in DrugBank. In the last decade, many computational methods have been developed to address this issue and overcome these limitations<sup><xref ref-type="bibr" rid="CR10">10</xref>–<xref ref-type="bibr" rid="CR13">13</xref></sup>. Vilar <italic>et al</italic>. developed a model to predict DDIs based on Interaction Profile Fingerprint (IPF)<sup><xref ref-type="bibr" rid="CR11">11</xref></sup>. Quite simply, the interaction probability matrix was computed by multiplying the DDI matrix by the IPF matrix. Afterward, Lu <italic>et al</italic>. proposed a computational framework by applying matrix perturbation, based on the hypothesis that by removing the edges randomly from DDI network, the eigenvectors of the adjacent matrix of the network does not change<sup><xref ref-type="bibr" rid="CR14">14</xref></sup>. Unfortunately, these two methods employ no other data about drugs, except known DDIs. Assuming that similar drugs may have almost similar interactions, a new trend of similarity-based methods was followed in studies. Vilar <italic>et al</italic>.<sup><xref ref-type="bibr" rid="CR12">12</xref></sup> presented a neighbor recommender method by utilizing substructure similarity of drugs. Relying on the Vilar’s framework, Zhang <italic>et al</italic>. constructed a weighted similarity network that is labeled based on interaction with each of drugs<sup><xref ref-type="bibr" rid="CR13">13</xref></sup> and applied an integrative label propagation method via the random walk on the network to estimate the potential DDIs. However, this predicting framework only considered three types of similarities for predicting DDI via label propagation, namely substructure-based, side effect-based, and offside effect-based label propagation models<sup><xref ref-type="bibr" rid="CR13">13</xref></sup>. Concerning the hypothesis that each type of drug data may assist in disclosing the patterns of interactions, a new inclination toward ensemble methods had emerged. In this manner, Gottlieb <italic>et al</italic>.<sup><xref ref-type="bibr" rid="CR15">15</xref></sup> made use of seven drug-drug similarity measures and combined every two similarities and calculated 49 features for each drug pair and predict novel DDIs by Logistic Regression (LR). Afterward, a Heterogeneous Network-Assisted Inference (HNAI) framework was proposed<sup><xref ref-type="bibr" rid="CR16">16</xref></sup> by Chen <italic>et al</italic>., which applied five predictive models (Naive Bayes (NB), Decision Tree (DT), K-Nearest Neighbor (KNN), logistic regression, and Support Vector Machine(SVM)). In HNAI, drug pair similarities were calculated using four features: phenotypic, therapeutic, chemical, and genomic similarity. Zhang <italic>et al</italic>.<sup><xref ref-type="bibr" rid="CR17">17</xref></sup> have proposed an ensemble method that uses eight types of drug similarities and calculates six other DDI network-based drug similarities. It applies both the neighbor recommender method and the label propagation method on each of these 14 similarity type, that yields 28 models, as well as a matrix perturbation method on DDI network. At last, two ensemble methods with the weighted average ensemble rule and the classifier ensemble rule for integrating methods are adopted to aggregates these 29 models for predicting DDIs.</p>
    <p id="Par4">Liu <italic>et al</italic>.<sup><xref ref-type="bibr" rid="CR18">18</xref></sup> have proposed a Dependency-based Convolutional Neural Network (DCNN) for drug-drug interaction extraction. DCNN is a text-mining approach which predicts DDIs based on unstructured biomedical literature and the existing knowledge bases. It applies convolution layers on word sequences as well as dependency parsing trees of candidate DDIs for adjacent words. Ryu <italic>et al</italic>.<sup><xref ref-type="bibr" rid="CR19">19</xref></sup> proposed DeepDDI, which is a combination of the structural similarity profile generation pipeline and Deep Neural Network (DNN). DeepDDI predicts DDIs from chemical structures and names of drugs in pairs. It has various implications for adverse drug events such as prediction of potential causal mechanism and using them for output sentences. Lim <italic>et al</italic>.<sup><xref ref-type="bibr" rid="CR20">20</xref></sup> designed a DDI extraction model using a recursive neural network based approach which is a variation of the binary tree-LSTM model. This natural language processing model uses syntactical features of the parse tree to extract information from the DDI-related sentences. Wang <italic>et al</italic>.<sup><xref ref-type="bibr" rid="CR21">21</xref></sup> designed a DNN model to predicts the potential adverse drug reactions that take three types of features as the input: the chemical properties, biological properties, and information from the literature. This model considers drug relationships with the word-embedding method for analyzing substantial biomedical literature.</p>
    <p id="Par5">A new approach in this field is network pharmacology which identifies the synergistic interaction of drugs based on a specific disease. Li <italic>et al</italic>.<sup><xref ref-type="bibr" rid="CR22">22</xref></sup> have proposed NIMS method which constructs a disease-specific biological network between therapeutic targets. The background assumption of NIMS is that the interaction of drugs can be transferred as the interaction between targets or responsive gene products of drugs. NIMS utilizes this disease-specific network to calculate the synergistic relationship between each pair of drugs in the treatment of the disease. Guo <italic>et al</italic>.<sup><xref ref-type="bibr" rid="CR23">23</xref></sup> have shown that detecting synergistic combinations of compounds is efficient in the treatment of Inflammation-Induced Tumorigenesis (IIT). Since ITT is caused by major mutations in genes involved in proliferation, immune response, and metabolism<sup><xref ref-type="bibr" rid="CR24">24</xref></sup>, synergistic drug combinations are useful in its treatment. Guo <italic>et al</italic>.<sup><xref ref-type="bibr" rid="CR23">23</xref></sup> used synergistic modules in differential gene interaction network to predict a set of four drugs that can effectively inhibit IIT.</p>
    <p id="Par6">Although previous methods had great advances, more prediction accuracy is still needed. We developed a method to overcome this issue via similarity selection, similarity fusion, and neural network. For similarity selection, a heuristic method was proposed by Olayan <italic>et al</italic>.<sup><xref ref-type="bibr" rid="CR25">25</xref></sup> in the context of drug-target interaction prediction. This method empowers making use of a high informative subset of data. Integrating more heterogeneous data is also helpful in enhancing the prediction performance. Similarity Network Fusion (SNF)<sup><xref ref-type="bibr" rid="CR26">26</xref></sup> is a competent method to integrate various similarities which is used in numerous biological contexts<sup><xref ref-type="bibr" rid="CR25">25</xref>,<xref ref-type="bibr" rid="CR27">27</xref>,<xref ref-type="bibr" rid="CR28">28</xref></sup>. The neural network is a strongly developed approach that provides satisfactory solutions, especially for large datasets and nonlinear analyzes<sup><xref ref-type="bibr" rid="CR29">29</xref></sup> which is widely used in critical problems<sup><xref ref-type="bibr" rid="CR30">30</xref>–<xref ref-type="bibr" rid="CR32">32</xref></sup>.</p>
    <p id="Par7">In this study, we developed NDD that utilizes the neural network model along with similarity selection and fusion methods to take advantage of nonlinear analysis and professional feature extraction to improve the DDI prediction accuracy. NDD is a multi-step pipeline. In the first step, it obtains information of various drug similarities (chemical, target-based, Gene Ontology (GO), side effect, off-label side effect, pathway, Anatomical Therapeutic Chemical (ATC), ligand, transporter, indication, and Gaussian Interaction Profile (GIP) similarities) and their interaction data from different datasets. Then it selects the most informative and less redundant subset of similarity types by a heuristic process that proposed by Olayan <italic>et al</italic>.<sup><xref ref-type="bibr" rid="CR25">25</xref></sup>. In the next step, the selected similarity types are integrated by a non-linear similarity fusion method called SNF<sup><xref ref-type="bibr" rid="CR26">26</xref></sup>. Finally, the integrated similarity matrix, in addition to the interaction data is used for training the neural network. NDD can provide an accurate framework for predicting new DDIs. NDD utilizes previous methods in similarity selection and similarity fusion, but the architecture of the neural network is novel and highly tuned for this problem. Moreover, the previously proposed parts of NDD has not been used in DDI prediction context. Another novelty of this work is the combination of these steps with the neural network. All parts of NDD are described elaborately in the Materials and Methods section. We compared our method with two categories of methods, including graph-based methods and machine learning models via stratified five-fold cross-validation. To further demonstrate NDD’s ability in predicting unknown DDIs, case studies on several drugs were investigated. These results confirm that NDD is an efficient method for accurate DDI prediction.</p>
  </sec>
  <sec id="Sec2" sec-type="results">
    <title>Results</title>
    <p id="Par8">For validating the robustness of NDD, we investigated it on three datasets (DS1, DS2, and DS3). The detailed description of these datasets is provided in the Materials and Methods section. We compared our method with common machine learning classifiers such as random forest<sup><xref ref-type="bibr" rid="CR33">33</xref></sup>, logistic regression<sup><xref ref-type="bibr" rid="CR34">34</xref></sup>, adaptive boosting<sup><xref ref-type="bibr" rid="CR35">35</xref></sup>, linear discriminant analysis (LDA)<sup><xref ref-type="bibr" rid="CR36">36</xref></sup>, quadratic discriminant analysis (QDA)<sup><xref ref-type="bibr" rid="CR37">37</xref></sup>, and k-nearest neighbor<sup><xref ref-type="bibr" rid="CR38">38</xref></sup> on these datasets. Meanwhile, we also evaluated the performance of six state-of-the-art graph-based methods including Vilar’s substructure-based model<sup><xref ref-type="bibr" rid="CR11">11</xref></sup>, substructure-based label propagation model<sup><xref ref-type="bibr" rid="CR13">13</xref></sup>, side effect-based label propagation model<sup><xref ref-type="bibr" rid="CR13">13</xref></sup>, offside effect-based label propagation model<sup><xref ref-type="bibr" rid="CR13">13</xref></sup>, weighted average ensemble method<sup><xref ref-type="bibr" rid="CR17">17</xref></sup>, classifier ensemble method<sup><xref ref-type="bibr" rid="CR17">17</xref></sup> on DS1, DS2, and DS3.</p>
    <p id="Par9">The mentioned machine learning methods use just one similarity in their processes. To have a fair comparison between NDD and these methods, we applied similarity selection and fusion described in Subsections 4.4 and 4.5 on all similarity types and used the integrated similarity matrix as the inputs for machine learning methods.</p>
    <sec id="Sec3">
      <title>Evaluation criteria</title>
      <p id="Par10">In this study, we classify drug pairs to be interacting or not. So, we exploit commonly used metrics in classification, including precision, recall, F-measure, AUC, and AUPR, defined as follows.<disp-formula id="Equ1"><label>1</label><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$precision=\frac{TP}{TP+FP}$$\end{document}</tex-math><mml:math id="M2" display="block"><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:mfrac></mml:math><graphic xlink:href="41598_2019_50121_Article_Equ1.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ2"><label>2</label><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$recall=\frac{TP}{TP+FN}$$\end{document}</tex-math><mml:math id="M4" display="block"><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mfrac></mml:math><graphic xlink:href="41598_2019_50121_Article_Equ2.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ3"><label>3</label><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$F-measure=\frac{2\cdot precision\cdot recall}{precision+recall}$$\end{document}</tex-math><mml:math id="M6" display="block"><mml:mi>F</mml:mi><mml:mo>−</mml:mo><mml:mi>m</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>u</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mo>⋅</mml:mo><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo>⋅</mml:mo><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:mfrac></mml:math><graphic xlink:href="41598_2019_50121_Article_Equ3.gif" position="anchor"/></alternatives></disp-formula>Where TP, TN, FP, and FN stand for True Positive, True Negative, False Positive, and False Negative. Precision is the fraction of correct predicted interactions among all predicted interactions, while recall is the fraction of correct predicted interactions among all true interactions. Precision and recall have a trade-off; thus, improving one of them may lead to a reduction in another. Therefore, utilizing F-measure, which is the geometric mean of precision and recall, is more reasonable. The reported values for precision, recall, and F-measure of each method is based on the best value of the threshold for the output.</p>
      <p id="Par11">It should be noted that if the interaction of two drugs is assigned to zero, it denotes that no evidence of their interaction has been found yet; thus, they may interact with each other. So we cannot identify TN and FP pairs correctly. The training process requires both positive and negative samples. Therefore, some of the zero assigned pairs are considered as non-interactive pairs in the training model. So every method may have some FP in its evaluations. This leads to a reduction in calculated precision and F-measure, while the real values of precision and F-measure may be higher.</p>
      <p id="Par12">Since the values of precision, recall, and F-measure is dependent to the value of the threshold, we also evaluate methods via AUC which is the area under the receiver operating characteristic (ROC) curve, and AUPR, that is the area under the precision-recall curve. These criteria indicate the efficiency of methods independent of the threshold value. In cases that the fraction of negative samples and positive samples are not equal, AUPR is the fairer criterion for evaluation.</p>
      <p id="Par13">The assessments of method performances are conducted by stratified five-fold cross-validation. The procedure of stratified five-fold cross-validation is repeated 20 times and averaged to ensure low-variance and unbiased evaluations.</p>
    </sec>
    <sec id="Sec4">
      <title>Comparison of NDD with other methods on DS1</title>
      <p id="Par14">We first evaluated NDD on DS1 in comparison to other methods. Diverse types of machine learning classifiers such as linear, nonlinear, tree-based, kernel-based, and ensemble approaches are considered in our evaluations.</p>
      <p id="Par15">A summary of computed criteria for all methods is presented in Table <xref rid="Tab1" ref-type="table">1</xref>. It is not very surprising that the classifier ensemble method has the highest performance in terms of most criteria since it is designed and proposed for this particular dataset and this is the dataset that is compiled by the one who proposed the classifier ensemble method. Nevertheless, NDD with AUC of 0.954 (p-value = 9.105e-15, t-test), AUPR of 0.922 (p-value = 1.678e-23, t-test), F-measure of 0.835 (p-value = 1.127e-23, t-test), recall of 0.828 (p-value = 7.504e-21, t-test), and precision of 0.831 (p-value = 4.203e-21, t-test), had infinitesimal differences in all criteria compared to the classifier ensemble method. Furthermore, NDD achieved almost similar performance in comparison with the weighted average ensemble method, which is also designed specifically for DS1. Besides, NDD performs better than individual predictors (Vilar’s substructure-based model, substructure-based label propagation model, side effect-based label propagation model, and offside effect-based label propagation). Moreover, NDD outperforms machine learning classifiers (RF, LR, adaptive boosting, LDA, QDA, and KNN) in terms of all criteria. The results indicate that making use of the neural network, gives good discriminatory features and general machine learning models might not well handle to find hidden interactions.<table-wrap id="Tab1"><label>Table 1</label><caption><p>Performance comparison of all methods on DS1.</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Method</th><th>AUC</th><th>AUPR</th><th>F-measure</th><th>Recall</th><th>Precision</th></tr></thead><tbody><tr><td>Substructure-based label propagation model</td><td>0.937</td><td>0.901</td><td>0.804</td><td>0.797</td><td>0.811</td></tr><tr><td>Side-effect-based label propagation model</td><td>0.936</td><td>0.903</td><td>0.806</td><td>0.793</td><td>0.820</td></tr><tr><td>Offside-effect-based label propagation model</td><td>0.937</td><td>0.904</td><td>0.809</td><td>0.795</td><td>0.823</td></tr><tr><td>Vilar’s substructure-based model</td><td>0.936</td><td>0.902</td><td>0.804</td><td>0.797</td><td>0.812</td></tr><tr><td>Classifier ensemble method</td><td><bold>0.956</bold></td><td><bold>0.928</bold></td><td><bold>0.836</bold></td><td>0.827</td><td><bold>0.843</bold></td></tr><tr><td>Weighted average ensemble method</td><td>0.948</td><td>0.919</td><td>0.831</td><td>0.835</td><td>0.826</td></tr><tr><td>NDD</td><td>0.954</td><td>0.922</td><td>0.835</td><td>0.836</td><td>0.833</td></tr><tr><td>RF</td><td>0.830</td><td>0.693</td><td>0.666</td><td>0.738</td><td>0.607</td></tr><tr><td>LR</td><td>0.941</td><td>0.905</td><td>0.812</td><td>0.810</td><td>0.818</td></tr><tr><td>Adaptive boosting</td><td>0.722</td><td>0.587</td><td>0.558</td><td>0.572</td><td>0.546</td></tr><tr><td>LDA</td><td>0.935</td><td>0.898</td><td>0.801</td><td>0.800</td><td>0.803</td></tr><tr><td>QDA</td><td>0.857</td><td>0.802</td><td>0.751</td><td><bold>0.912</bold></td><td>0.638</td></tr><tr><td>KNN</td><td>0.730</td><td>0.134</td><td>0.080</td><td>0.062</td><td>0.098</td></tr></tbody></table><table-wrap-foot><p>The best value of each criterion is shown in bold.</p></table-wrap-foot></table-wrap></p>
      <p id="Par16">Although Vilar <italic>et al</italic>. considered only substructure similarity for predicting DDI via neighbor recommender<sup><xref ref-type="bibr" rid="CR11">11</xref></sup> and Zhang <italic>et al</italic>. considers three types of similarities for predicting DDI via label propagation<sup><xref ref-type="bibr" rid="CR13">13</xref></sup>, we further applied neighbor recommender and label propagation on other types of similarity as well as the integrated similarity matrix. The results are presented in supplementary material (see Supplementary File <xref rid="MOESM1" ref-type="media">1</xref>). One can conclude the most important similarity type for each of these methods by comparing the results.</p>
    </sec>
    <sec id="Sec5">
      <title>Comparison of NDD performance on different similarity types in DS1</title>
      <p id="Par17">To investigate the impact of different similarity types on NDD performance, we ignored the selection section 4.4 and fusion section 4.5 of NDD and just applied its neural network on the features provided with each similarity matrix.</p>
      <p id="Par18">From Table <xref rid="Tab2" ref-type="table">2</xref>, we can see that NDD has the poorest performance when it is provided with only the chemical similarity. These results are in accordance with the selected subset of similarities after applying the procedure introduced in Subsection 4.4. The subset of similarities that is selected includes all similarity types except chemical similarity since its entropy is greater than the threshold 0.6; so it is excluded from the selected list.<table-wrap id="Tab2"><label>Table 2</label><caption><p>Comparison of NDD performance on different similarity types.</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Method</th><th>Similarity</th><th>AUC</th><th>AUPR</th><th>F-measure</th><th>Recall</th><th>Precision</th></tr></thead><tbody><tr><td>NDD</td><td>chemical</td><td>0.631</td><td>0.455</td><td>0.527</td><td>0.899</td><td>0.373</td></tr><tr><td>NDD</td><td>target</td><td>0.787</td><td>0.642</td><td>0.617</td><td>0.721</td><td>0.540</td></tr><tr><td>NDD</td><td>transporter</td><td>0.682</td><td>0.568</td><td>0.519</td><td>0.945</td><td>0.358</td></tr><tr><td>NDD</td><td>enzyme</td><td>0.734</td><td>0.599</td><td>0.552</td><td>0.579</td><td>0.529</td></tr><tr><td>NDD</td><td>pathway</td><td>0.767</td><td>0.623</td><td>0.587</td><td>0.650</td><td>0.536</td></tr><tr><td>NDD</td><td>indication</td><td><bold>0.802</bold></td><td><bold>0.654</bold></td><td><bold>0.632</bold></td><td>0.740</td><td><bold>0.551</bold></td></tr><tr><td>NDD</td><td>side effect</td><td>0.778</td><td>0.601</td><td>0.619</td><td>0.748</td><td>0.528</td></tr><tr><td>NDD</td><td>offside effect</td><td>0.782</td><td>0.606</td><td>0.617</td><td><bold>0.764</bold></td><td>0.517</td></tr></tbody></table><table-wrap-foot><p>The best value of each criterion is shown in bold.</p></table-wrap-foot></table-wrap></p>
      <p id="Par19">We further compare each line of Table <xref rid="Tab2" ref-type="table">2</xref> with the seventh line of Table <xref rid="Tab1" ref-type="table">1</xref>, to evaluate the fusion process. The superiority of NDD performance on integrated similarity over its performance when provided with each of similarities, completely verify that making use of integrated similarity matrices leads to discover more discriminant features and significantly improves the prediction performance.</p>
      <p id="Par20">In addition, we repeat this evaluation for each similarity types in DS3. The results reconfirm that the integration of similarities yields more discriminant features in predicting DDIs.</p>
    </sec>
    <sec id="Sec6">
      <title>Comparison of NDD with other methods on DS2</title>
      <p id="Par21">To test the reliability and robustness of NDD, we also assessed its performance on another dataset that is compiled by Wan <italic>et al</italic>.<sup><xref ref-type="bibr" rid="CR39">39</xref></sup>. This dataset contains only the chemical similarity of drugs.</p>
      <p id="Par22">As shown in Table <xref rid="Tab3" ref-type="table">3</xref>, the highest performance in terms of all criteria is achieved by NDD. NDD outperforms both the graph-based methods (the first six rows) and machine learning methods (the last six rows). Almost all methods failed to yield promising results. The difference between NDD performance with other methods in terms of AUPR, F-measure, recall, and precision is outstanding. Even the performance of ensemble methods (the classifier ensemble method and the weighted average ensemble method), that make use of combining the results of diverse approaches, are not comparable to NDD. The striking performance of NDD on DS2, indicates the great extent of complexity of relations in this dataset; thus, NDD is very promising in extracting very discriminant features that can easily discover hidden DDIs in situations that other state-of-the-art methods do not perform well.<table-wrap id="Tab3"><label>Table 3</label><caption><p>Performance comparison of all methods on DS2.</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Method</th><th>AUC</th><th>AUPR</th><th>F-measure</th><th>Recall</th><th>Precision</th></tr></thead><tbody><tr><td>Substructure-based label propagation model</td><td>0.788</td><td>0.208</td><td>0.294</td><td>0.537</td><td>0.197</td></tr><tr><td>Vilar’s substructure-based model</td><td>0.810</td><td>0.244</td><td>0.312</td><td>0.479</td><td>0.232</td></tr><tr><td>Classifier ensemble method</td><td>0.936</td><td>0.487</td><td>0.553</td><td>0.689</td><td>0.462</td></tr><tr><td>Weighted average ensemble method</td><td>0.646</td><td>0.440</td><td>0.15</td><td>0.226</td><td>0.118</td></tr><tr><td>NDD</td><td><bold>0.994</bold></td><td><bold>0.890</bold></td><td><bold>0.825</bold></td><td><bold>0.804</bold></td><td><bold>0.847</bold></td></tr><tr><td>RF</td><td>0.982</td><td>0.812</td><td>0.747</td><td>0.713</td><td>0.785</td></tr><tr><td>LR</td><td>0.911</td><td>0.251</td><td>0.318</td><td>0.397</td><td>0.268</td></tr><tr><td>Adaptive boosting</td><td>0.904</td><td>0.185</td><td>0.266</td><td>0.359</td><td>0.211</td></tr><tr><td>LDA</td><td>0.894</td><td>0.215</td><td>0.295</td><td>0.407</td><td>0.231</td></tr><tr><td>QDA</td><td>0.926</td><td>0.466</td><td>0.174</td><td>0.875</td><td>0.096</td></tr><tr><td>KNN</td><td>0.927</td><td>0.785</td><td>0.602</td><td>0.445</td><td>0.932</td></tr></tbody></table><table-wrap-foot><p>The best value of each criterion is shown in bold.</p></table-wrap-foot></table-wrap></p>
    </sec>
    <sec id="Sec7">
      <title>Comparison of NDD with other methods on CYP interactions of DS3</title>
      <p id="Par23">For further testing the efficiency of NDD, we evaluated our proposed method on DS3. Since this dataset contains two types of interactions, the comparisons were conducted in two steps.</p>
      <p id="Par24">The computed criteria for results of algorithms in predicting CYP (the Cytochrome P450 involved DDIs) interaction are illustrated in Table <xref rid="Tab4" ref-type="table">4</xref>. It can be concluded that NDD outperforms other graph-based methods. NDD succeeded to improve AUC by 5%, and AUPR by 29%, which implicates the better structure of NDD in predicting CYP DDIs. It is noteworthy that, due to the lower proportion of positive samples in CYP interactions in comparison with NCYP (the DDIs without involving Cytochrome P450) interactions, the performance of methods declines in these types of interactions.<table-wrap id="Tab4"><label>Table 4</label><caption><p>Performance comparison of all methods on CYP interactions of DS3.</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Method</th><th>AUC</th><th>AUPR</th><th>F-measure</th><th>Recall</th><th>Precision</th></tr></thead><tbody><tr><td>Substructure-based label propagation model</td><td>0.952</td><td>0.126</td><td>0.206</td><td>0.278</td><td>0.161</td></tr><tr><td>Side-effect-based label propagation model</td><td>0.953</td><td>0.120</td><td>0.199</td><td>0.278</td><td>0.156</td></tr><tr><td>Vilar’s substructure-based model</td><td>0.953</td><td>0.126</td><td>0.196</td><td>0.279</td><td>0.152</td></tr><tr><td>Classifier ensemble method</td><td>0.990</td><td>0.541</td><td>0.553</td><td>0.566</td><td>0.546</td></tr><tr><td>Weighted average ensemble method</td><td>0.695</td><td>0.484</td><td>0.198</td><td>0.201</td><td>0.201</td></tr><tr><td>NDD</td><td><bold>0.994</bold></td><td><bold>0.830</bold></td><td><bold>0.772</bold></td><td><bold>0.770</bold></td><td><bold>0.775</bold></td></tr><tr><td>RF</td><td>0.737</td><td>0.092</td><td>0.161</td><td>0.216</td><td>0.132</td></tr><tr><td>LR</td><td>0.977</td><td>0.487</td><td>0.524</td><td>0.589</td><td>0.475</td></tr><tr><td>Adaptive boosting</td><td>0.830</td><td>0.143</td><td>0.215</td><td>0.259</td><td>0.185</td></tr><tr><td>LDA</td><td>0.953</td><td>0.327</td><td>0.388</td><td>0.363</td><td>0.425</td></tr><tr><td>QDA</td><td>0.709</td><td>0.317</td><td>0.259</td><td>0.446</td><td>0.184</td></tr><tr><td>KNN</td><td>0.590</td><td>0.064</td><td>0.039</td><td>0.008</td><td>0.190</td></tr></tbody></table><table-wrap-foot><p>The best value of each criterion is shown in bold.</p></table-wrap-foot></table-wrap></p>
    </sec>
    <sec id="Sec8">
      <title>Comparison of NDD with other methods on NCYP interactions of DS3</title>
      <p id="Par25">In this section, we investigate the method performance on NCYP interactions. Through these evaluations, which are summarized in Table <xref rid="Tab5" ref-type="table">5</xref>, the well-structured framework of NDD is verified. There is a significant improvement in AUPR, F-measure, precision, and recall by NDD method. Moreover, NDD obtained the best AUC in NCYP DDI prediction. For instance, AUPR has improved by 19%. Based on these results, we found the significant supremacy of NDD in terms of AUC as well as AUPR and F-measure, which are so consistent with the evaluations of previous sections and further confirm the capability of NDD in predicting NCYP DDIs.<table-wrap id="Tab5"><label>Table 5</label><caption><p>Performance comparison of all methods on NCYP interactions of DS3.</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Method</th><th>AUC</th><th>AUPR</th><th>F-measure</th><th>Recall</th><th>Precision</th></tr></thead><tbody><tr><td>Substructure-based label propagation model</td><td>0.890</td><td>0.159</td><td>0.216</td><td>0.379</td><td>0.153</td></tr><tr><td>Side-effect-based label propagation model</td><td>0.895</td><td>0.181</td><td>0.234</td><td>0.285</td><td>0.208</td></tr><tr><td>Vilar’s substructure-based model</td><td>0.904</td><td>0.295</td><td>0.248</td><td>0.383</td><td>0.183</td></tr><tr><td>Classifier ensemble method</td><td>0.986</td><td>0.756</td><td>0.708</td><td>0.702</td><td>0.714</td></tr><tr><td>Weighted average ensemble method</td><td>0.974</td><td>0.599</td><td>0.587</td><td>0.584</td><td>0.591</td></tr><tr><td>NDD</td><td><bold>0.992</bold></td><td><bold>0.947</bold></td><td><bold>0.902</bold></td><td><bold>0.884</bold></td><td><bold>0.918</bold></td></tr><tr><td>RF</td><td>0.889</td><td>0.167</td><td>0.242</td><td>0.411</td><td>0.168</td></tr><tr><td>LR</td><td>0.916</td><td>0.472</td><td>0.506</td><td>0.571</td><td>0.454</td></tr><tr><td>Adaptive boosting</td><td>0.709</td><td>0.150</td><td>0.193</td><td>0.358</td><td>0.141</td></tr><tr><td>LDA</td><td>0.889</td><td>0.414</td><td>0.456</td><td>0.501</td><td>0.419</td></tr><tr><td>QDA</td><td>0.536</td><td>0.260</td><td>0.132</td><td>0.080</td><td>0.387</td></tr><tr><td>KNN</td><td>0.603</td><td>0.235</td><td>0.134</td><td>0.229</td><td>0.094</td></tr></tbody></table><table-wrap-foot><p>The best value of each criterion is shown in bold.</p></table-wrap-foot></table-wrap></p>
    </sec>
    <sec id="Sec9">
      <title>Case studies</title>
      <p id="Par26">To further demonstrate NDD’s ability for predicting unknown DDIs, we investigated FPs on the DS1, in reliable databases and literature. Inspecting the FP drug pairs that obtain high probabilities of having interaction, authenticated that there is a substantial body of evidence in the valid databases and published papers for almost all of such FPs. The top ten predicted DDIs are presented in Table <xref rid="Tab6" ref-type="table">6</xref>, from which six interactions now exist in the DrugBank database, but they were labeled zero in our training samples. There is a great number of confirmations for DDIs that are newly predicted by NDD; we list numerous top predicted DDIs along with their evidence in the Supplementary File <xref rid="MOESM1" ref-type="media">2</xref>. Furthermore, a brief description of evidences for two case studies that their predicted interactions probability were above %90 is presented in Supplementary File <xref rid="MOESM1" ref-type="media">3</xref>.<table-wrap id="Tab6"><label>Table 6</label><caption><p>Top ten predicted interactions (confirmed interactions by DrugBank database is shown in bold).</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Rank</th><th>ID1</th><th>ID2</th><th>Drug Name 1</th><th>Drug Name 2</th></tr></thead><tbody><tr><td>1</td><td><bold>DB00642</bold></td><td><bold>DB01331</bold></td><td>Pemetrexed</td><td>Cefoxitin</td></tr><tr><td>2</td><td><bold>DB00642</bold></td><td><bold>DB01060</bold></td><td>Pemetrexed</td><td>Amoxicillin</td></tr><tr><td>3</td><td><bold>DB00633</bold></td><td><bold>DB01183</bold></td><td>Dexmedetomidine</td><td>Naloxone</td></tr><tr><td>4</td><td>DB00633</td><td>DB00361</td><td>Dexmedetomidine</td><td>Vinorelbine</td></tr><tr><td>5</td><td>DB00535</td><td>DB00373</td><td>Cefdinir</td><td>Timolol</td></tr><tr><td>6</td><td><bold>DB01236</bold></td><td><bold>DB01586</bold></td><td>Sevoflurane</td><td>Ursodeoxycholic acid</td></tr><tr><td>7</td><td>DB01236</td><td>DB00415</td><td>Sevoflurane</td><td>Ampicillin</td></tr><tr><td>8</td><td><bold>DB00742</bold></td><td><bold>DB00441</bold></td><td>Mannitol</td><td>Gemcitabine</td></tr><tr><td>9</td><td><bold>DB00585</bold></td><td><bold>DB01577</bold></td><td>Nizatidine</td><td>Methamphetamine</td></tr><tr><td>10</td><td>DB01136</td><td>DB00952</td><td>Carvedilol</td><td>Naratriptan</td></tr></tbody></table></table-wrap></p>
    </sec>
  </sec>
  <sec id="Sec10" sec-type="discussion">
    <title>Discussion</title>
    <p id="Par27">For predicting novel DDIs, a computational method is proposed based on similarity selection and fusion in addition to using the neural network. Its performance is very surprising, especially on datasets that had more complexity and required high-order features for eliciting hidden interactions. Its performance was significant in comparison with the graph-based and machine learning methods. Several reasons account for the high performance of NDD:<list list-type="order"><list-item><p id="Par28">It takes advantage of different types of similarity matrices; thus, it gets diverse information from different aspects of drug pairs that yield an inclusive insight about them.</p></list-item><list-item><p id="Par29">It utilizes a similarity selection approach and a fusion procedure as refinement and abstraction of whole data to avoid noise, reduce redundant information, and exclude random-like data.</p></list-item><list-item><p id="Par30">Two drugs may be considered similar due to the lack of information. This issue may occur for each type of similarities. NDD uses similarity integration method that can help to overcome this limitation.</p></list-item><list-item><p id="Par31">Neural network can automatically process the input features and elicit high-level features from them that leads to better prediction performance.</p></list-item></list></p>
    <p id="Par32">The performance of NDD was evaluated in two mechanisms: 1- comparing results of NDD with other methods and conducting t-test to test the statistical significance of NDD performance in terms of evaluation criteria scores. 2- case studies on FP predictions. There were many potential DDIs predicted by our method that has a body of evidence in the literature and credible databases. However, many other FPs are expected to be verified by reliable resources in the near future.</p>
    <p id="Par33">It should be noted that NDD needs much time to train. This is due to the fact that the number of trainable parameters of the neural network is high. Furthermore, it is difficult to list out all possible neural network architecture, and it causes the difficulty to find the optimal architecture. Running neural network-based methods needs powerful hardware. In addition to these limitations, for constructing training data, we require both interacting drug pairs and non-interacting drug pairs to train the models both with positive and negative samples and to avoid over-fitting. Nevertheless, it is almost impossible to verify that a negative drug pair is a non-interacting pair or interacting pair that is not discovered yet.</p>
    <p id="Par34">A strategy to decrease method complexity is dimension reduction; i.e. each column of the integrated similarity matrix can be considered as a feature. We applied common feature selection method Chi2<sup><xref ref-type="bibr" rid="CR40">40</xref></sup> and multiple state-of-the-art feature extraction methods such as Non-negative Matrix Factorization (NMF), Principle Component Analysis (PCA), and Stacked Auto-Encoder (SAE) with the various number of features. Moreover, we tune the hyperparameters of the neural network based on the selected features to obtain optimal results. The calculated evaluation criteria are presented in Supplementary File <xref rid="MOESM1" ref-type="media">4</xref>. By comparing these results with typical NDD performance in Table <xref rid="Tab1" ref-type="table">1</xref>, it can be concluded that none of the feature extraction methods, nor the feature selection method can improve the performance of the method. There is an interesting issue that the values of AUPR and AUC decreases as the number of (selected/extracted) features reduces. Note that these methods were applied to the columns of the integrated matrix and the integrated matrix was obtained by integrating a subset of similarity matrices with high information and less redundancy. Putting all these together, it can be inferred that reducing its dimensional leads to missing informative data and this lack of information causes poor performance.</p>
  </sec>
  <sec id="Sec11" sec-type="materials|methods">
    <title>Materials and Methods</title>
    <sec id="Sec12">
      <title>Datasets</title>
      <p id="Par35">To verify the robustness of NDD, we validate it on different benchmarks with DDI and similarity data. We used the benchmark datasets that used in previous studies<sup><xref ref-type="bibr" rid="CR15">15</xref>,<xref ref-type="bibr" rid="CR17">17</xref>,<xref ref-type="bibr" rid="CR39">39</xref></sup>.</p>
      <p id="Par36">The first benchmark (DS1) contains 548 drugs, 97168 interactions, and eight types of similarities based on substructure data, target data, enzyme data, transporter data, pathway data, indication data, side effect data, and offside effect data<sup><xref ref-type="bibr" rid="CR17">17</xref></sup>. The second benchmark (DS2) contains 707 drugs, 34412 interactions, and a chemical similarity matrix<sup><xref ref-type="bibr" rid="CR39">39</xref></sup>. The third dataset (DS3) consists of 807 drugs and seven types of similarity matrices, four of which are based on ATC, chemical similarity, ligand-based chemical similarity, and side effects. Three more similarity measures are constructed based on drug target similarities such as sequence similarity, the distance on the Protein-Protein Interaction (PPI) network and GO annotations<sup><xref ref-type="bibr" rid="CR15">15</xref></sup>. It should be noted that the third dataset contains two types of interaction: CYP and NCYP.</p>
      <p id="Par37">These data are collected from the following databases:<list list-type="bullet"><list-item><p id="Par38"><italic>DrugBank</italic><sup><xref ref-type="bibr" rid="CR7">7</xref>,<xref ref-type="bibr" rid="CR41">41</xref></sup>: A reliable database that contains information about drugs such as drug targets, drug enzymes, drug interactions, and drug transporters.</p></list-item><list-item><p id="Par39"><italic>SIDER</italic><sup><xref ref-type="bibr" rid="CR42">42</xref></sup>: A side effect database containing information of adverse drug reactions, side effect and the indication of drugs.</p></list-item><list-item><p id="Par40"><italic>KEGG</italic><sup><xref ref-type="bibr" rid="CR43">43</xref></sup>: A valid database that contains protein pathways information. This database is used to obtain drug pathways by mapping drug targets.</p></list-item><list-item><p id="Par41"><italic>PubChem</italic><sup><xref ref-type="bibr" rid="CR44">44</xref></sup>: The best reference database for drugs structures.</p></list-item><list-item><p id="Par42"><italic>OFFSIDES</italic><sup><xref ref-type="bibr" rid="CR45">45</xref></sup>: A collection of off-label side effect information about drugs.</p></list-item></list></p>
      <p id="Par43">Further details about similarities and datasets are available in Table <xref rid="Tab7" ref-type="table">7</xref> and Supplementary File 5. All similarity and interaction matrices are provided in <ext-link ext-link-type="uri" xlink:href="https://github.com/nrohani/NDD">https://github.com/nrohani/NDD</ext-link>.<table-wrap id="Tab7"><label>Table 7</label><caption><p>Details of Benchmarks.</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Benchmark Name</th><th>Reference</th><th>Number of Drugs</th><th>Number of Pairs</th><th>Number of Interactions</th><th>Number of Non-interactions</th><th>Number of Similarities</th><th>Similarity Types</th></tr></thead><tbody><tr><td>DS1</td><td>Zhang <italic>et al</italic>.<sup><xref ref-type="bibr" rid="CR17">17</xref></sup></td><td>548</td><td>300304</td><td>97168</td><td>203136</td><td>8</td><td>Chemical, Target, Transporter, Enzyme, Pathway, Indication, Side effects, Offside effect</td></tr><tr><td>DS2</td><td>Wan <italic>et al</italic>.<sup><xref ref-type="bibr" rid="CR39">39</xref></sup></td><td>707</td><td>499849</td><td>34412</td><td>465437</td><td>1</td><td>Chemical</td></tr><tr><td>DS3: CYP</td><td>Gottlieb <italic>et al</italic>.<sup><xref ref-type="bibr" rid="CR15">15</xref></sup></td><td>807</td><td>651249</td><td>10078</td><td>641171</td><td>7</td><td>GO, Target, Ligand, Chemical, PPI Distance, Side effect, ATC</td></tr><tr><td>DS3: NCYP</td><td>Gottlieb <italic>et al</italic>.<sup><xref ref-type="bibr" rid="CR15">15</xref></sup></td><td>807</td><td>651249</td><td>40904</td><td>610345</td><td>7</td><td>GO, Target, Ligand, Chemical, PPI Distance, Side effect, ATC</td></tr></tbody></table></table-wrap></p>
    </sec>
    <sec id="Sec13">
      <title>NDD overview</title>
      <p id="Par44">The steps of NDD is as follows:<list list-type="order"><list-item><p id="Par45">Calculating drug similarities and GIP for each drug pair.</p></list-item><list-item><p id="Par46">Selecting a subset of similarities with the most information and less redundancy.</p></list-item><list-item><p id="Par47">Integrating the selected similarities to obtain an integrated similarity matrix that represents all information in one matrix.</p></list-item><list-item><p id="Par48">For each drug pair, the corresponding rows of the integrated matrix are concatenated and fed to a two-layer neural network to classify. A sigmoid function is used in the output layer of the neural network to obtain the probability of the interaction between input drug pairs.</p></list-item></list></p>
      <p id="Par49">A scheme of the NDD is shown in Figure <xref rid="Fig1" ref-type="fig">1</xref>.<fig id="Fig1"><label>Figure 1</label><caption><p>The scheme of NDD workflow. (<bold>a</bold>) Selecting the best subset of similarity matrices. (<bold>b</bold>) Applying SNF, a fusion method, to integrate all selected similarities into an m*m matrix where m is the number of drugs. (<bold>c</bold>) Every row in the integrated matrix, is the feature vector of its corresponding drug. (<bold>d</bold>) For each pair of the drugs, their feature vectors are concatenated in a vector and is considered as the input of a neural network. (<bold>e</bold>) The neural network is applied to the input vector to calculate the probability of interaction between input drug pair.</p></caption><graphic xlink:href="41598_2019_50121_Fig1_HTML" id="d29e2717"/></fig></p>
    </sec>
    <sec id="Sec14">
      <title>Gaussian interaction profile</title>
      <p id="Par50">In addition to the mentioned drug similarities, we use GIP which is defined by Van <italic>et al</italic>.<sup><xref ref-type="bibr" rid="CR46">46</xref></sup>. Let matrix <italic>Y</italic> = [<italic>y</italic><sub><italic>ij</italic></sub>] be the interaction matrix that <italic>y</italic><sub><italic>ij</italic></sub>∈{0, 1} that 1 indicates the existence of interaction between drugs <italic>d</italic><sub><italic>i</italic></sub> and <italic>d</italic><sub><italic>j</italic></sub> and 0 the otherwise. The GIP, for drugs <italic>d</italic><sub><italic>i</italic></sub> and <italic>d</italic><sub><italic>j</italic></sub> is defined as:<disp-formula id="Equ4"><label>4</label><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$GI{P}_{d}({d}_{i},{d}_{j})=exp(-{\gamma }_{d}||{Y}_{i}-{Y}_{j}|{|}^{2})$$\end{document}</tex-math><mml:math id="M8" display="block"><mml:mi>G</mml:mi><mml:mi>I</mml:mi><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mspace width="-0.25em"/><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>γ</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">|</mml:mo><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">|</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:math><graphic xlink:href="41598_2019_50121_Article_Equ4.gif" position="anchor"/></alternatives></disp-formula></p>
      <p id="Par51">where <italic>Y</italic><sub><italic>i</italic></sub> is the interaction profile of drug <italic>i</italic> with all drugs; in other words, <italic>Y</italic><sub><italic>i</italic></sub> is <italic>i</italic>th column of matrix <italic>Y</italic>. The parameter <italic>γ</italic><sub><italic>d</italic></sub> controls the bandwidth. We set<disp-formula id="Equ5"><label>5</label><alternatives><tex-math id="M9">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\gamma }_{d}={\tilde{\gamma }}_{d}/(\frac{1}{n}\mathop{\sum }\limits_{i=1}^{m}\,|{Y}_{{d}_{i}}{|}^{2})$$\end{document}</tex-math><mml:math id="M10" display="block"><mml:msub><mml:mrow><mml:mi>γ</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>γ</mml:mi><mml:mo>˜</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>n</mml:mi></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>m</mml:mi></mml:munderover><mml:mspace width=".25em"/><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:msup><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:math><graphic xlink:href="41598_2019_50121_Article_Equ5.gif" position="anchor"/></alternatives></disp-formula></p>
      <p id="Par52">In order to make GIP values, independent of the size of the dataset, we normalize them via dividing to the average number of interactions per drug. Here we set <inline-formula id="IEq1"><alternatives><tex-math id="M11">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\tilde{\gamma }}_{d}=1c$$\end{document}</tex-math><mml:math id="M12"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>γ</mml:mi><mml:mo>˜</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mi>c</mml:mi></mml:math><inline-graphic xlink:href="41598_2019_50121_Article_IEq1.gif"/></alternatives></inline-formula> according to the previous research<sup><xref ref-type="bibr" rid="CR25">25</xref></sup>. It should be noted that the GIP similarity is considered only for training data and not for the test data. Because it is assumed that the interaction information is not available for test data.</p>
    </sec>
    <sec id="Sec15">
      <title>Similarity selection</title>
      <p id="Par53">NDD uses multiple similarity matrices for drugs based on various similarity types as well as GIP. Before utilizing these similarities in the neural network model, it is essential to integrate different similarities. Due to the different amount of similarity information and their dependencies, combining all of these similarity matrices is not reasonable. It also may increase the noise in the final integrated similarity. Thus, we apply an efficient approach to select a subset of these matrices that is more informative and less redundant. Then, a similarity fusion method is used to integrate the chosen similarity matrices into one final integrated similarity.</p>
      <p id="Par54">We used the similarity selection heuristic process that is introduced by Olayan <italic>et al</italic>.<sup><xref ref-type="bibr" rid="CR25">25</xref></sup>. It has several steps:<list list-type="order"><list-item><p id="Par55">Calculating entropy of each matrix</p></list-item><list-item><p id="Par56">Rank matrices based on their entropy</p></list-item><list-item><p id="Par57">Calculate the pairwise distance of matrices</p></list-item><list-item><p id="Par58">Final selection from the ranked list of matrices based on redundancy minimization</p></list-item></list></p>
      <sec id="Sec16">
        <title>Calculating entropy</title>
        <p id="Par59">The entropy of each matrix demonstrates the extent of the carried information. Let <italic>A</italic> = [<italic>a</italic><sub><italic>ij</italic></sub>]<sub><italic>m</italic>×<italic>m</italic></sub> be the similarity matrix between <italic>m</italic> drugs. The entropy <italic>E</italic><sub><italic>i</italic></sub>(<italic>A</italic>) for <italic>i</italic>th row is computed as follows:<disp-formula id="Equ6"><label>6</label><alternatives><tex-math id="M13">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${E}_{i}(A)=-\,\sum _{j}\,{p}_{ij}\,\log \,{p}_{ij}$$\end{document}</tex-math><mml:math id="M14" display="block"><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mspace width="-.25em"/><mml:munder><mml:mo>∑</mml:mo><mml:mi>j</mml:mi></mml:munder><mml:mspace width=".25em"/><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mspace width=".25em"/><mml:mi>log</mml:mi><mml:mspace width=".10em"/><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math><graphic xlink:href="41598_2019_50121_Article_Equ6.gif" position="anchor"/></alternatives></disp-formula>where<disp-formula id="Equ7"><label>7</label><alternatives><tex-math id="M15">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${p}_{ij}=\frac{{a}_{ij}}{{\sum }_{k}\,{a}_{ik}}$$\end{document}</tex-math><mml:math id="M16" display="block"><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mo>∑</mml:mo><mml:mi>k</mml:mi></mml:msub><mml:mspace width=".25em"/><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:math><graphic xlink:href="41598_2019_50121_Article_Equ7.gif" position="anchor"/></alternatives></disp-formula></p>
        <p id="Par60">The entropies of all rows are averaged to calculate the entropy of a matrix.</p>
      </sec>
      <sec id="Sec17">
        <title>Rank matrices</title>
        <p id="Par61">The matrices are ranked in ascending order based on their entropy values. The entropy value indicates the amount of random information contained in the similarity matrix. Thus, matrices with high entropy have high random information and low values of entropy indicate less random information. So the similarity matrices with entropy values greater than <italic>c</italic><sub>1</sub> log(<italic>m</italic>) are removed. Constant <italic>c</italic><sub>1</sub> manages the level of entropy in the selected matrices. We examined several numbers for <italic>c</italic><sub>1</sub> in (0, 1) and evaluated the total performance of the model with these values. The best results were obtained with <italic>c</italic><sub>1</sub> = 0.6.</p>
      </sec>
      <sec id="Sec18">
        <title>Calculate the pairwise distance</title>
        <p id="Par62">The similarity between two feature matrices <italic>A</italic> and <italic>B</italic> is defined as follows:<disp-formula id="Equ8"><label>8</label><alternatives><tex-math id="M17">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$S(A,B)=\frac{1}{1+D(A,B)}$$\end{document}</tex-math><mml:math id="M18" display="block"><mml:mi>S</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>B</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>D</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>B</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:math><graphic xlink:href="41598_2019_50121_Article_Equ8.gif" position="anchor"/></alternatives></disp-formula>where <italic>D</italic>(<italic>A</italic>, <italic>B</italic>) is the Euclidean distance between <italic>A</italic> and <italic>B</italic> matrices, which is calculated as follows:<disp-formula id="Equ9"><label>9</label><alternatives><tex-math id="M19">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$D(A,B)=\sqrt{\mathop{\sum }\limits_{i=1}^{m}\,\mathop{\sum }\limits_{j=1}^{m}\,{({a}_{ij}-{b}_{ij})}^{2}}$$\end{document}</tex-math><mml:math id="M20" display="block"><mml:mi>D</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>B</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msqrt><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>m</mml:mi></mml:munderover><mml:mspace width=".25em"/><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>m</mml:mi></mml:munderover><mml:mspace width=".25em"/><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:msqrt></mml:math><graphic xlink:href="41598_2019_50121_Article_Equ9.gif" position="anchor"/></alternatives></disp-formula>where <italic>a</italic><sub><italic>ij</italic></sub> and <italic>b</italic><sub><italic>ij</italic></sub> are the entries of <italic>A</italic> and <italic>B</italic> matrices, respectively.</p>
      </sec>
      <sec id="Sec19">
        <title>Final selection</title>
        <p id="Par63">The selected subset of matrices is obtained by an iterative procedure. Suppose there exist <italic>n</italic> similarity matrices <italic>A</italic><sub>1</sub>, <italic>A</italic><sub>2</sub>, …, <italic>A</italic><sub><italic>n</italic></sub>. In the first iteration, the set of selected matrices is empty and the set of ranked list is the one obtained by Subsection 4.4.2. In each iteration, the matrix with the least value of entropy from the ranked list <italic>C</italic> = <italic>argmin</italic><sub><italic>l</italic></sub>
<italic>E</italic>(<italic>A</italic><sub><italic>l</italic></sub>) is added to the selected set of matrices and all matrices <italic>A</italic><sub><italic>j</italic></sub> that has great similarity with <italic>C</italic>, <italic>S</italic>(<italic>C</italic>, <italic>A</italic><sub><italic>j</italic></sub>) &gt; <italic>c</italic><sub>2</sub>, are eliminated from the ranked list. This procedure is iterated with the updated ranked list. It iterates until the ranked list is empty. Constant <italic>c</italic><sub>2</sub> is a threshold for the similarity of chosen matrices, which is subjectively set to 0.6 in our work. The value of this threshold was chosen by examining several numbers in (0, 1) and evaluating the performance of the model.</p>
        <p id="Par64">Eventually, this procedure selects a subset of similarity matrices that are highly informative (due to selecting matrices with low entropy) and have low redundancy (due to eliminating matrices with high similarity).</p>
      </sec>
    </sec>
    <sec id="Sec20">
      <title>Similarity network fusion</title>
      <p id="Par65">After selecting a reasonable subset of similarity matrices, we use the SNF method proposed by Wang <italic>et al</italic>.<sup><xref ref-type="bibr" rid="CR26">26</xref></sup> to integrate the selected matrices. It combines multiple similarity measures into a single fused similarity that carry an appropriate representation of all information. SNF applies an iterative nonlinear method that updates every similarity matrix according to the other matrices via KNN.</p>
    </sec>
    <sec id="Sec21">
      <title>Neural network model selection</title>
      <p id="Par66">To obtain an accurate neural network architecture, various networks were trained on datasets with different structures by nested cross-validation<sup><xref ref-type="bibr" rid="CR47">47</xref></sup>. In nested cross-validation the hyperparameters are tuned via two cross-validations according to the following steps:<list list-type="order"><list-item><p id="Par67">Setting the hyperparameters to some values.</p></list-item><list-item><p id="Par68">Partitioning the data into three “folds” (sets).</p></list-item><list-item><p id="Par69">Training the model using two folds with the hyperparameter values.</p></list-item><list-item><p id="Par70">Testing the model on the remaining fold.</p></list-item><list-item><p id="Par71">Performing steps 3 and 4 again and again; thus, every time one of the folds is considered as the test data.</p></list-item><list-item><p id="Par72">Repeating steps 1 to 5 for all combinations of hyperparameter values.</p></list-item><list-item><p id="Par73">Returning the combination of hyperparameter values that had the best performance.</p></list-item></list></p>
      <p id="Par74">In our model, we considered the following hyperparameter sets:<list list-type="bullet"><list-item><p id="Par75">Number of hidden layers: {1, 2, …, 5}</p></list-item><list-item><p id="Par76">Number of neurons in hidden layers: {100, 200, 300, 400, 500}</p></list-item><list-item><p id="Par77">Activation functions: {Rectified linear activation function(ReLU), hyperbolic tangent (tanh), and sigmoid}</p></list-item><list-item><p id="Par78">Dropout rate: {0.3, 0.5}</p></list-item></list></p>
      <p id="Par79">The best results were obtained with two hidden layers with 300 neurons in the first and 400 neurons in the second hidden layer with Dropout rate 0.5 for both layers. We used Dropout layer<sup><xref ref-type="bibr" rid="CR48">48</xref></sup> behind each layer to prevent the over-fitting problem. The output of each neuron in a layer is a nonlinear function <italic>f</italic> of all nodes in the previous layer. <italic>f</italic> is the ReLU, which is defined as the positive part of its argument:<disp-formula id="Equ10"><label>10</label><alternatives><tex-math id="M21">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$f(x)={x}^{\ast }=\,{\rm{\max }}\,\{x,0\}$$\end{document}</tex-math><mml:math id="M22" display="block"><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo>⁎</mml:mo></mml:msup><mml:mo>=</mml:mo><mml:mspace width=".25em"/><mml:mi mathvariant="normal">max</mml:mi><mml:mspace width=".25em"/><mml:mo stretchy="false">{</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">}</mml:mo></mml:math><graphic xlink:href="41598_2019_50121_Article_Equ10.gif" position="anchor"/></alternatives></disp-formula></p>
      <p id="Par80">The final output is calculated using the sigmoid function, which is calculated as follows.<disp-formula id="Equ11"><label>11</label><alternatives><tex-math id="M23">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Sigmoid\,(x)=\frac{1}{1+{e}^{-x}}$$\end{document}</tex-math><mml:math id="M24" display="block"><mml:mi>S</mml:mi><mml:mi>i</mml:mi><mml:mi>g</mml:mi><mml:mi>m</mml:mi><mml:mi>o</mml:mi><mml:mi>i</mml:mi><mml:mi>d</mml:mi><mml:mspace width=".25em"/><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mspace width="-.25em"/><mml:mi>x</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:math><graphic xlink:href="41598_2019_50121_Article_Equ11.gif" position="anchor"/></alternatives></disp-formula></p>
      <p id="Par81">The batch size was set to 200 and the epoch number was set to 20, 50, and 50 for DS1, DS2, and DS3, respectively, because the model yielded the best performance in these setting. At first, the weights were initialized with a normal distribution with a standard deviation of 0.05, and biases were initialized with a uniform distribution in (−1,0) which is common.</p>
      <p id="Par82">Afterward, the network is trained using interaction label information and input features to update weights and biases parameters. To train the model, we use the cross-entropy loss function (<italic>C</italic>.<italic>E</italic>)<sup><xref ref-type="bibr" rid="CR49">49</xref></sup> and Stochastic Gradient Descent (SGD)<sup><xref ref-type="bibr" rid="CR50">50</xref></sup> optimization with momentum value (0.9). NDD is implemented via Keras library<sup><xref ref-type="bibr" rid="CR51">51</xref></sup> in Python3.5. More details about the implementation of methods are presented in <ext-link ext-link-type="uri" xlink:href="https://github.com/nrohani/NDD">https://github.com/nrohani/NDD</ext-link>.</p>
    </sec>
    <sec id="Sec22">
      <title>Neural network for classification</title>
      <p id="Par83">After integrating selected similarities, we assigned label ‘1’ to all known DDI (positive samples) and 0 to others for every drug pairs. Then, data were divided into training data and test data with stratified five-fold cross-validation. Stratified five-fold cross-validation randomly divides data into five equal-sized sets such that the ratio of positive and negative pairs in all sets are equal. The training data were given to a neural network for predicting the label of each pair of drugs, which indicated whether it has a connection or not. Then, for each pair of drug <italic>i</italic> and drug <italic>j</italic>, the <italic>i</italic>th row of drug similarity matrix (i.e., the similarity data between drug i and all the other drugs) is concatenated to the jth row of drug similarity matrix (similar to the previous works<sup><xref ref-type="bibr" rid="CR31">31</xref>,<xref ref-type="bibr" rid="CR32">32</xref>,<xref ref-type="bibr" rid="CR52">52</xref></sup>) and considered as a feature vector, which is fed to the neural network as an independent training sample. Then the network will be trained with the training set and the weights of the network will be updated. Once the training is accomplished, the trained neural network is implemented on test data to predict the interaction between drugs. The output is the probability of interaction between the input pairs. Two drugs that lead to a probability higher than the threshold are considered as potential interacting drugs.</p>
    </sec>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary information</title>
    <sec id="Sec23">
      <p>
        <supplementary-material content-type="local-data" id="MOESM1">
          <media xlink:href="41598_2019_50121_MOESM1_ESM.pdf">
            <caption>
              <p>Supplementary files</p>
            </caption>
          </media>
        </supplementary-material>
      </p>
    </sec>
  </sec>
</body>
<back>
  <fn-group>
    <fn>
      <p><bold>Publisher’s note</bold> Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
    </fn>
  </fn-group>
  <sec>
    <title>Supplementary information</title>
    <p><bold>Supplementary information</bold> accompanies this paper at 10.1038/s41598-019-50121-3.</p>
  </sec>
  <ack>
    <title>Acknowledgements</title>
    <p>Both authors thank Fatemeh Ahmadi Moughari for her helpful comments.</p>
  </ack>
  <notes notes-type="author-contribution">
    <title>Author Contributions</title>
    <p>N.R. and C.E. conceived of the study. N.R. implemented the study. N.R. and C.E. wrote the manuscript. Both authors have read and approved the final manuscript.</p>
  </notes>
  <notes notes-type="data-availability">
    <title>Data Availability</title>
    <p>Available at <ext-link ext-link-type="uri" xlink:href="https://github.com/nrohani/NDD">https://github.com/nrohani/NDD</ext-link>.</p>
  </notes>
  <notes notes-type="COI-statement">
    <title>Competing Interests</title>
    <p id="Par85">The authors declare no competing interests.</p>
  </notes>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <label>1.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lazarou</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Pomeranz</surname>
            <given-names>BH</given-names>
          </name>
          <name>
            <surname>Corey</surname>
            <given-names>PN</given-names>
          </name>
        </person-group>
        <article-title>Incidence of adverse drug reactions in hospitalized patients: a meta-analysis of prospective studies</article-title>
        <source>Jama</source>
        <year>1998</year>
        <volume>279</volume>
        <fpage>1200</fpage>
        <lpage>1205</lpage>
        <pub-id pub-id-type="doi">10.1001/jama.279.15.1200</pub-id>
        <pub-id pub-id-type="pmid">9555760</pub-id>
      </element-citation>
    </ref>
    <ref id="CR2">
      <label>2.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Prueksaritanont</surname>
            <given-names>T</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Drug–drug interaction studies: regulatory guidance and an industry perspective</article-title>
        <source>The AAPS journal</source>
        <year>2013</year>
        <volume>15</volume>
        <fpage>629</fpage>
        <lpage>645</lpage>
        <pub-id pub-id-type="doi">10.1208/s12248-013-9470-x</pub-id>
        <pub-id pub-id-type="pmid">23543602</pub-id>
      </element-citation>
    </ref>
    <ref id="CR3">
      <label>3.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kusuhara</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <article-title>How far should we go? Perspective of drug-drug interaction studies in drug development</article-title>
        <source>Drug metabolism pharmacokinetics</source>
        <year>2014</year>
        <volume>29</volume>
        <fpage>227</fpage>
        <lpage>228</lpage>
        <pub-id pub-id-type="doi">10.2133/dmpk.DMPK-14-PF-903</pub-id>
        <pub-id pub-id-type="pmid">24965785</pub-id>
      </element-citation>
    </ref>
    <ref id="CR4">
      <label>4.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Beijnen</surname>
            <given-names>JH</given-names>
          </name>
          <name>
            <surname>Schellens</surname>
            <given-names>JH</given-names>
          </name>
        </person-group>
        <article-title>Drug interactions in oncology</article-title>
        <source>The lancet oncology</source>
        <year>2004</year>
        <volume>5</volume>
        <fpage>489</fpage>
        <lpage>496</lpage>
        <pub-id pub-id-type="doi">10.1016/S1470-2045(04)01528-1</pub-id>
        <pub-id pub-id-type="pmid">15288238</pub-id>
      </element-citation>
    </ref>
    <ref id="CR5">
      <label>5.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Qato</surname>
            <given-names>DM</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Use of prescription and over-the-counter medications and dietary supplements among older adults in the united states</article-title>
        <source>Jama</source>
        <year>2008</year>
        <volume>300</volume>
        <fpage>2867</fpage>
        <lpage>2878</lpage>
        <pub-id pub-id-type="doi">10.1001/jama.2008.892</pub-id>
        <pub-id pub-id-type="pmid">19109115</pub-id>
      </element-citation>
    </ref>
    <ref id="CR6">
      <label>6.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hanton</surname>
            <given-names>G</given-names>
          </name>
        </person-group>
        <article-title>Preclinical cardiac safety assessment of drugs</article-title>
        <source>Drugs R &amp; D</source>
        <year>2007</year>
        <volume>8</volume>
        <fpage>213</fpage>
        <lpage>228</lpage>
        <pub-id pub-id-type="doi">10.2165/00126839-200708040-00002</pub-id>
      </element-citation>
    </ref>
    <ref id="CR7">
      <label>7.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wishart</surname>
            <given-names>DS</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Drugbank 5.0: a major update to the drugbank database for 2018</article-title>
        <source>Nucleic acids research</source>
        <year>2017</year>
        <volume>46</volume>
        <fpage>D1074</fpage>
        <lpage>D1082</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkx1037</pub-id>
      </element-citation>
    </ref>
    <ref id="CR8">
      <label>8.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Knox</surname>
            <given-names>C</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Drugbank 3.0: a comprehensive resource for omics research on drugs</article-title>
        <source>Nucleic acids research</source>
        <year>2010</year>
        <volume>39</volume>
        <fpage>D1035</fpage>
        <lpage>D1041</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkq1126</pub-id>
        <pub-id pub-id-type="pmid">21059682</pub-id>
      </element-citation>
    </ref>
    <ref id="CR9">
      <label>9.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Law</surname>
            <given-names>V</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Drugbank 4.0: shedding new light on drug metabolism</article-title>
        <source>Nucleic acids research</source>
        <year>2013</year>
        <volume>42</volume>
        <fpage>D1091</fpage>
        <lpage>D1097</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkt1068</pub-id>
        <pub-id pub-id-type="pmid">24203711</pub-id>
      </element-citation>
    </ref>
    <ref id="CR10">
      <label>10.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Vilar</surname>
            <given-names>S</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Similarity-based modeling in large-scale prediction of drug-drug interactions</article-title>
        <source>Nat. protocols</source>
        <year>2014</year>
        <volume>9</volume>
        <fpage>2147</fpage>
        <pub-id pub-id-type="doi">10.1038/nprot.2014.151</pub-id>
        <pub-id pub-id-type="pmid">25122524</pub-id>
      </element-citation>
    </ref>
    <ref id="CR11">
      <label>11.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Vilar</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Uriarte</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Santana</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Tatonetti</surname>
            <given-names>NP</given-names>
          </name>
          <name>
            <surname>Friedman</surname>
            <given-names>C</given-names>
          </name>
        </person-group>
        <article-title>Detection of drug-drug interactions by modelling interaction profile fingerprints</article-title>
        <source>PloS one</source>
        <year>2013</year>
        <volume>8</volume>
        <fpage>e58321</fpage>
        <pub-id pub-id-type="doi">10.1371/journal.pone.0058321</pub-id>
        <pub-id pub-id-type="pmid">23520498</pub-id>
      </element-citation>
    </ref>
    <ref id="CR12">
      <label>12.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Vilar</surname>
            <given-names>S</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Drug-drug interaction through molecular structure similarity analysis</article-title>
        <source>J. Am. Med. Informatics Assoc.</source>
        <year>2012</year>
        <volume>19</volume>
        <fpage>1066</fpage>
        <lpage>1074</lpage>
        <pub-id pub-id-type="doi">10.1136/amiajnl-2012-000935</pub-id>
      </element-citation>
    </ref>
    <ref id="CR13">
      <label>13.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhang</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Hu</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Sorrentino</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>Label propagation prediction of drug-drug interactions based on clinical side effects</article-title>
        <source>Sci. reports</source>
        <year>2015</year>
        <volume>5</volume>
        <fpage>12339</fpage>
        <pub-id pub-id-type="doi">10.1038/srep12339</pub-id>
      </element-citation>
    </ref>
    <ref id="CR14">
      <label>14.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lü</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Pan</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Zhou</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>Y-C</given-names>
          </name>
          <name>
            <surname>Stanley</surname>
            <given-names>HE</given-names>
          </name>
        </person-group>
        <article-title>Toward link predictability of complex networks</article-title>
        <source>Proc. Natl. Acad. Sci.</source>
        <year>2015</year>
        <volume>112</volume>
        <fpage>2325</fpage>
        <lpage>2330</lpage>
        <pub-id pub-id-type="doi">10.1073/pnas.1424644112</pub-id>
        <pub-id pub-id-type="pmid">25659742</pub-id>
      </element-citation>
    </ref>
    <ref id="CR15">
      <label>15.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Gottlieb</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Stein</surname>
            <given-names>GY</given-names>
          </name>
          <name>
            <surname>Oron</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Ruppin</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Sharan</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>Indi: a computational framework for inferring drug interactions and their associated recommendations</article-title>
        <source>Mol. systems biology</source>
        <year>2012</year>
        <volume>8</volume>
        <fpage>592</fpage>
        <pub-id pub-id-type="doi">10.1038/msb.2012.26</pub-id>
      </element-citation>
    </ref>
    <ref id="CR16">
      <label>16.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Cheng</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Zhao</surname>
            <given-names>Z</given-names>
          </name>
        </person-group>
        <article-title>Machine learning-based prediction of drug–drug interactions by integrating drug phenotypic, therapeutic, chemical, and genomic properties</article-title>
        <source>J. Am. Med. Informatics Assoc.</source>
        <year>2014</year>
        <volume>21</volume>
        <fpage>e278</fpage>
        <lpage>e286</lpage>
        <pub-id pub-id-type="doi">10.1136/amiajnl-2013-002512</pub-id>
      </element-citation>
    </ref>
    <ref id="CR17">
      <label>17.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhang</surname>
            <given-names>W</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Predicting potential drug-drug interactions by integrating chemical, biological, phenotypic and network data</article-title>
        <source>BMC bioinformatics</source>
        <year>2017</year>
        <volume>18</volume>
        <fpage>18</fpage>
        <pub-id pub-id-type="doi">10.1186/s12859-016-1415-9</pub-id>
        <pub-id pub-id-type="pmid">28056782</pub-id>
      </element-citation>
    </ref>
    <ref id="CR18">
      <label>18.</label>
      <mixed-citation publication-type="other">Liu, S., Chen, K., Chen, Q. &amp; Tang, B. Dependency-based convolutional neural network for drug-drug interaction extraction. In <italic>2016 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)</italic>, 1074–1080 (IEEE, 2016).</mixed-citation>
    </ref>
    <ref id="CR19">
      <label>19.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ryu</surname>
            <given-names>JY</given-names>
          </name>
          <name>
            <surname>Kim</surname>
            <given-names>HU</given-names>
          </name>
          <name>
            <surname>Lee</surname>
            <given-names>SY</given-names>
          </name>
        </person-group>
        <article-title>Deep learning improves prediction of drug–drug and drug–food interactions</article-title>
        <source>Proc. Natl. Acad. Sci.</source>
        <year>2018</year>
        <volume>115</volume>
        <fpage>E4304</fpage>
        <lpage>E4311</lpage>
        <pub-id pub-id-type="doi">10.1073/pnas.1803294115</pub-id>
        <pub-id pub-id-type="pmid">29666228</pub-id>
      </element-citation>
    </ref>
    <ref id="CR20">
      <label>20.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lim</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Lee</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Kang</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Drug drug interaction extraction from the literature using a recursive neural network</article-title>
        <source>PloS one</source>
        <year>2018</year>
        <volume>13</volume>
        <fpage>e0190926</fpage>
        <pub-id pub-id-type="doi">10.1371/journal.pone.0190926</pub-id>
        <pub-id pub-id-type="pmid">29373599</pub-id>
      </element-citation>
    </ref>
    <ref id="CR21">
      <label>21.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wang</surname>
            <given-names>C-S</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Detecting potential adverse drug reactions using a deep neural network model</article-title>
        <source>J. medical Internet research</source>
        <year>2019</year>
        <volume>21</volume>
        <fpage>e11016</fpage>
        <pub-id pub-id-type="doi">10.2196/11016</pub-id>
      </element-citation>
    </ref>
    <ref id="CR22">
      <label>22.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Li</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>N</given-names>
          </name>
        </person-group>
        <article-title>Network target for screening synergistic drug combinations with application to traditional chinese medicine</article-title>
        <source>BMC systems biology</source>
        <year>2011</year>
        <volume>5</volume>
        <fpage>S10</fpage>
        <pub-id pub-id-type="doi">10.1186/1752-0509-5-S1-S10</pub-id>
      </element-citation>
    </ref>
    <ref id="CR23">
      <label>23.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Guo</surname>
            <given-names>Y</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Network-based combinatorial crispr-cas9 screens identify synergistic modules in human cells</article-title>
        <source>ACS synthetic biology</source>
        <year>2019</year>
        <volume>8</volume>
        <fpage>482</fpage>
        <lpage>490</lpage>
        <pub-id pub-id-type="doi">10.1021/acssynbio.8b00237</pub-id>
        <pub-id pub-id-type="pmid">30762338</pub-id>
      </element-citation>
    </ref>
    <ref id="CR24">
      <label>24.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Guo</surname>
            <given-names>Y</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Multiscale modeling of inflammation-induced tumorigenesis reveals competing oncogenic and oncoprotective roles for inflammation</article-title>
        <source>Cancer research</source>
        <year>2017</year>
        <volume>77</volume>
        <fpage>6429</fpage>
        <lpage>6441</lpage>
        <pub-id pub-id-type="doi">10.1158/0008-5472.CAN-17-1662</pub-id>
        <pub-id pub-id-type="pmid">28951462</pub-id>
      </element-citation>
    </ref>
    <ref id="CR25">
      <label>25.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Olayan</surname>
            <given-names>RS</given-names>
          </name>
          <name>
            <surname>Ashoor</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Bajic</surname>
            <given-names>VB</given-names>
          </name>
        </person-group>
        <article-title>Ddr: efficient computational method to predict drug–target interactions using graph mining and machine learning approaches</article-title>
        <source>Bioinforma.</source>
        <year>2017</year>
        <volume>34</volume>
        <fpage>1164</fpage>
        <lpage>1173</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btx731</pub-id>
      </element-citation>
    </ref>
    <ref id="CR26">
      <label>26.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wang</surname>
            <given-names>B</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Similarity network fusion for aggregating data types on a genomic scale</article-title>
        <source>Nat. methods</source>
        <year>2014</year>
        <volume>11</volume>
        <fpage>333</fpage>
        <pub-id pub-id-type="doi">10.1038/nmeth.2810</pub-id>
        <pub-id pub-id-type="pmid">24464287</pub-id>
      </element-citation>
    </ref>
    <ref id="CR27">
      <label>27.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Tian</surname>
            <given-names>Z</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Constructing an integrated gene similarity network for the identification of disease genes</article-title>
        <source>J. biomedical semantics</source>
        <year>2017</year>
        <volume>8</volume>
        <fpage>32</fpage>
        <pub-id pub-id-type="doi">10.1186/s13326-017-0141-1</pub-id>
      </element-citation>
    </ref>
    <ref id="CR28">
      <label>28.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kim</surname>
            <given-names>Y-A</given-names>
          </name>
          <name>
            <surname>Cho</surname>
            <given-names>D-Y</given-names>
          </name>
          <name>
            <surname>Przytycka</surname>
            <given-names>TM</given-names>
          </name>
        </person-group>
        <article-title>Understanding genotype-phenotype effects in cancer via network approaches</article-title>
        <source>PLoS computational biology</source>
        <year>2016</year>
        <volume>12</volume>
        <fpage>e1004747</fpage>
        <pub-id pub-id-type="doi">10.1371/journal.pcbi.1004747</pub-id>
        <pub-id pub-id-type="pmid">26963104</pub-id>
      </element-citation>
    </ref>
    <ref id="CR29">
      <label>29.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wang</surname>
            <given-names>Y</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Predicting dna methylation state of cpg dinucleotide using genome topological features and deep networks</article-title>
        <source>Sci. reports</source>
        <year>2016</year>
        <volume>6</volume>
        <fpage>19598</fpage>
        <pub-id pub-id-type="doi">10.1038/srep19598</pub-id>
      </element-citation>
    </ref>
    <ref id="CR30">
      <label>30.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>K</given-names>
          </name>
        </person-group>
        <article-title>Xiexl. Eff. on Distributions Carbon Nitrogen a Reddish Paddy Soil Under Long-Term Differ</article-title>
        <source>Fertilization Treat. Chin. J. Soil Sci.</source>
        <year>2009</year>
        <volume>40</volume>
        <fpage>523</fpage>
        <lpage>528</lpage>
      </element-citation>
    </ref>
    <ref id="CR31">
      <label>31.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Fu</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Peng</surname>
            <given-names>Q</given-names>
          </name>
        </person-group>
        <article-title>A deep ensemble model to predict mirna-disease association</article-title>
        <source>Sci. reports</source>
        <year>2017</year>
        <volume>7</volume>
        <fpage>14482</fpage>
        <pub-id pub-id-type="doi">10.1038/s41598-017-15235-6</pub-id>
      </element-citation>
    </ref>
    <ref id="CR32">
      <label>32.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Pan</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Fan</surname>
            <given-names>Y-X</given-names>
          </name>
          <name>
            <surname>Yan</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Shen</surname>
            <given-names>H-B</given-names>
          </name>
        </person-group>
        <article-title>Ipminer: Hidden ncrna-protein interaction sequential pattern mining with stacked autoencoder for accurate computational prediction</article-title>
        <source>BMC genomics</source>
        <year>2016</year>
        <volume>17</volume>
        <fpage>582</fpage>
        <pub-id pub-id-type="doi">10.1186/s12864-016-2931-8</pub-id>
        <pub-id pub-id-type="pmid">27506469</pub-id>
      </element-citation>
    </ref>
    <ref id="CR33">
      <label>33.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Breiman</surname>
            <given-names>L</given-names>
          </name>
        </person-group>
        <article-title>Random forests</article-title>
        <source>Mach. learning</source>
        <year>2001</year>
        <volume>45</volume>
        <fpage>5</fpage>
        <lpage>32</lpage>
        <pub-id pub-id-type="doi">10.1023/A:1010933404324</pub-id>
      </element-citation>
    </ref>
    <ref id="CR34">
      <label>34.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Mitchell</surname>
            <given-names>TM</given-names>
          </name>
        </person-group>
        <article-title>Logistic regression</article-title>
        <source>Mach. learning</source>
        <year>2005</year>
        <volume>10</volume>
        <fpage>701</fpage>
      </element-citation>
    </ref>
    <ref id="CR35">
      <label>35.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Freund</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Schapire</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Abe</surname>
            <given-names>N</given-names>
          </name>
        </person-group>
        <article-title>A short introduction to boosting</article-title>
        <source>Journal-Japanese Soc. For Artif. Intell.</source>
        <year>1999</year>
        <volume>14</volume>
        <fpage>1612</fpage>
      </element-citation>
    </ref>
    <ref id="CR36">
      <label>36.</label>
      <mixed-citation publication-type="other">Izenman, A. J. Linear discriminant analysis. In <italic>Modern multivariate statistical techniques</italic>, 237–280 (Springer, 2013).</mixed-citation>
    </ref>
    <ref id="CR37">
      <label>37.</label>
      <mixed-citation publication-type="other">Lachenbruch, P. A. &amp; Goldstein, M. Discriminant analysis. <italic>Biom</italic>. 69–85 (1979).</mixed-citation>
    </ref>
    <ref id="CR38">
      <label>38.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Peterson</surname>
            <given-names>LE</given-names>
          </name>
        </person-group>
        <article-title>K-nearest neighbor</article-title>
        <source>Scholarpedia</source>
        <year>2009</year>
        <volume>4</volume>
        <fpage>1883</fpage>
        <pub-id pub-id-type="doi">10.4249/scholarpedia.1883</pub-id>
      </element-citation>
    </ref>
    <ref id="CR39">
      <label>39.</label>
      <mixed-citation publication-type="other">Wan, F., Hong, L., Xiao, A., Jiang, T. &amp; Zeng, J. Neodti: Neural integration of neighbor information from a heterogeneous network for discovering new drug-target interactions. <italic>bioRxiv</italic> 261396 (2018).</mixed-citation>
    </ref>
    <ref id="CR40">
      <label>40.</label>
      <mixed-citation publication-type="other">Liu, H. &amp; Setiono, R. Chi2: Feature selection and discretization of numeric attributes. In <italic>Proceedings of 7th IEEE International Conference on Tools with Artificial Intelligence</italic>, 388–391 (IEEE, 1995).</mixed-citation>
    </ref>
    <ref id="CR41">
      <label>41.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wishart</surname>
            <given-names>DS</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Drugbank: a comprehensive resource for in silico drug discovery and exploration</article-title>
        <source>Nucleic acids research</source>
        <year>2006</year>
        <volume>34</volume>
        <fpage>D668</fpage>
        <lpage>D672</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkj067</pub-id>
        <pub-id pub-id-type="pmid">16381955</pub-id>
      </element-citation>
    </ref>
    <ref id="CR42">
      <label>42.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kuhn</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Letunic</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Jensen</surname>
            <given-names>LJ</given-names>
          </name>
          <name>
            <surname>Bork</surname>
            <given-names>P</given-names>
          </name>
        </person-group>
        <article-title>The sider database of drugs and side effects</article-title>
        <source>Nucleic acids research</source>
        <year>2015</year>
        <volume>44</volume>
        <fpage>D1075</fpage>
        <lpage>D1079</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkv1075</pub-id>
        <pub-id pub-id-type="pmid">26481350</pub-id>
      </element-citation>
    </ref>
    <ref id="CR43">
      <label>43.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kanehisa</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Furumichi</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Tanabe</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Sato</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Morishima</surname>
            <given-names>K</given-names>
          </name>
        </person-group>
        <article-title>Kegg: new perspectives on genomes, pathways, diseases and drugs</article-title>
        <source>Nucleic acids research</source>
        <year>2016</year>
        <volume>45</volume>
        <fpage>D353</fpage>
        <lpage>D361</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkw1092</pub-id>
        <pub-id pub-id-type="pmid">27899662</pub-id>
      </element-citation>
    </ref>
    <ref id="CR44">
      <label>44.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kim</surname>
            <given-names>S</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Pubchem 2019 update: improved access to chemical data</article-title>
        <source>Nucleic acids research</source>
        <year>2018</year>
        <volume>47</volume>
        <fpage>D1102</fpage>
        <lpage>D1109</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gky1033</pub-id>
      </element-citation>
    </ref>
    <ref id="CR45">
      <label>45.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Tatonetti</surname>
            <given-names>NP</given-names>
          </name>
          <name>
            <surname>Patrick</surname>
            <given-names>PY</given-names>
          </name>
          <name>
            <surname>Daneshjou</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Altman</surname>
            <given-names>RB</given-names>
          </name>
        </person-group>
        <article-title>Data-driven prediction of drug effects and interactions</article-title>
        <source>Sci. translational medicine</source>
        <year>2012</year>
        <volume>4</volume>
        <fpage>125ra31</fpage>
        <lpage>125ra31</lpage>
        <pub-id pub-id-type="doi">10.1126/scitranslmed.3003377</pub-id>
      </element-citation>
    </ref>
    <ref id="CR46">
      <label>46.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>van Laarhoven</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Nabuurs</surname>
            <given-names>SB</given-names>
          </name>
          <name>
            <surname>Marchiori</surname>
            <given-names>E</given-names>
          </name>
        </person-group>
        <article-title>Gaussian interaction profile kernels for predicting drug–target interaction</article-title>
        <source>Bioinforma.</source>
        <year>2011</year>
        <volume>27</volume>
        <fpage>3036</fpage>
        <lpage>3043</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btr500</pub-id>
      </element-citation>
    </ref>
    <ref id="CR47">
      <label>47.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Cawley</surname>
            <given-names>GC</given-names>
          </name>
          <name>
            <surname>Talbot</surname>
            <given-names>NL</given-names>
          </name>
        </person-group>
        <article-title>On over-fitting in model selection and subsequent selection bias in performance evaluation</article-title>
        <source>J. Mach. Learn. Res.</source>
        <year>2010</year>
        <volume>11</volume>
        <fpage>2079</fpage>
        <lpage>2107</lpage>
      </element-citation>
    </ref>
    <ref id="CR48">
      <label>48.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Srivastava</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Hinton</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Krizhevsky</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Sutskever</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Salakhutdinov</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>Dropout: a simple way to prevent neural networks from overfitting</article-title>
        <source>The J. Mach. Learn. Res.</source>
        <year>2014</year>
        <volume>15</volume>
        <fpage>1929</fpage>
        <lpage>1958</lpage>
      </element-citation>
    </ref>
    <ref id="CR49">
      <label>49.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>De Boer</surname>
            <given-names>P-T</given-names>
          </name>
          <name>
            <surname>Kroese</surname>
            <given-names>DP</given-names>
          </name>
          <name>
            <surname>Mannor</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Rubinstein</surname>
            <given-names>RY</given-names>
          </name>
        </person-group>
        <article-title>A tutorial on the cross-entropy method</article-title>
        <source>Annals operations research</source>
        <year>2005</year>
        <volume>134</volume>
        <fpage>19</fpage>
        <lpage>67</lpage>
        <pub-id pub-id-type="doi">10.1007/s10479-005-5724-z</pub-id>
      </element-citation>
    </ref>
    <ref id="CR50">
      <label>50.</label>
      <mixed-citation publication-type="other">Le, Q. V. Building high-level features using large scale unsupervised learning. In <italic>Acoustics, Speech and Signal Processing (ICASSP), 2013 IEEE International Conference on</italic>, 8595–8598 (IEEE, 2013).</mixed-citation>
    </ref>
    <ref id="CR51">
      <label>51.</label>
      <mixed-citation publication-type="other">Keras <ext-link ext-link-type="uri" xlink:href="https://github.com/keras-team/keras">https://github.com/keras-team/keras</ext-link>. Accessed 22 Nov 2018.</mixed-citation>
    </ref>
    <ref id="CR52">
      <label>52.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Gong</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>D-H</given-names>
          </name>
          <name>
            <surname>You</surname>
            <given-names>Z-H</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>Z-W</given-names>
          </name>
        </person-group>
        <article-title>Drmda: deep representations-based mirna–disease association prediction</article-title>
        <source>J. cellular molecular medicine</source>
        <year>2018</year>
        <volume>22</volume>
        <fpage>472</fpage>
        <lpage>485</lpage>
        <pub-id pub-id-type="doi">10.1111/jcmm.13336</pub-id>
      </element-citation>
    </ref>
  </ref-list>
</back>
