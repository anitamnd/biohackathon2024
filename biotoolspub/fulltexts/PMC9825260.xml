<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id>
    <journal-id journal-id-type="publisher-id">bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1367-4803</issn>
    <issn pub-type="epub">1367-4811</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">9825260</article-id>
    <article-id pub-id-type="doi">10.1093/bioinformatics/btac829</article-id>
    <article-id pub-id-type="publisher-id">btac829</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Applications Note</subject>
        <subj-group subj-group-type="category-toc-heading">
          <subject>Genetic and Population Analysis</subject>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI01060</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>SIMBSIG: similarity search and clustering for biobank-scale data</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-8996-7167</contrib-id>
        <name>
          <surname>Adamer</surname>
          <given-names>Michael F</given-names>
        </name>
        <aff><institution>Department of Biosystems Science and Engineering, ETH Zurich</institution>, 4058 Basel, <country country="CH">Switzerland</country></aff>
        <aff><institution>Swiss Institute for Bioinformatics (SIB)</institution>, 1015 Lausanne, <country country="CH">Switzerland</country></aff>
        <xref rid="btac829-cor1" ref-type="corresp"/>
        <!--michael.adamer@bsse.ethz.ch-->
        <xref rid="btac829-FM1" ref-type="author-notes"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Roellin</surname>
          <given-names>Eljas</given-names>
        </name>
        <aff><institution>Department of Biosystems Science and Engineering, ETH Zurich</institution>, 4058 Basel, <country country="CH">Switzerland</country></aff>
        <xref rid="btac829-FM1" ref-type="author-notes"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Bourguignon</surname>
          <given-names>Lucie</given-names>
        </name>
        <aff><institution>Department of Health Sciences and Technology, ETH Zurich</institution>, 8008 Zurich, <country country="CH">Switzerland</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0001-7221-2393</contrib-id>
        <name>
          <surname>Borgwardt</surname>
          <given-names>Karsten</given-names>
        </name>
        <aff><institution>Department of Biosystems Science and Engineering, ETH Zurich</institution>, 4058 Basel, <country country="CH">Switzerland</country></aff>
        <aff><institution>Swiss Institute for Bioinformatics (SIB)</institution>, 1015 Lausanne, <country country="CH">Switzerland</country></aff>
      </contrib>
    </contrib-group>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Schwartz</surname>
          <given-names>Russell</given-names>
        </name>
        <role>Associate Editor</role>
      </contrib>
    </contrib-group>
    <author-notes>
      <fn id="btac829-FM1">
        <p>The authors wish it to be known that, in their opinion, Michael F Adamer and Eljas Roellin authors should be regarded as Joint First Authors.</p>
      </fn>
      <corresp id="btac829-cor1">To whom correspondence should be addressed. <email>michael.adamer@bsse.ethz.ch</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <month>1</month>
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2022-12-23">
      <day>23</day>
      <month>12</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>23</day>
      <month>12</month>
      <year>2022</year>
    </pub-date>
    <volume>39</volume>
    <issue>1</issue>
    <elocation-id>btac829</elocation-id>
    <history>
      <date date-type="received">
        <day>07</day>
        <month>7</month>
        <year>2022</year>
      </date>
      <date date-type="rev-recd">
        <day>14</day>
        <month>12</month>
        <year>2022</year>
      </date>
      <date date-type="editorial-decision">
        <day>20</day>
        <month>12</month>
        <year>2022</year>
      </date>
      <date date-type="accepted">
        <day>22</day>
        <month>12</month>
        <year>2022</year>
      </date>
      <date date-type="corrected-typeset">
        <day>04</day>
        <month>1</month>
        <year>2023</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2022. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2022</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="btac829.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Summary</title>
        <p>In many modern bioinformatics applications, such as statistical genetics, or single-cell analysis, one frequently encounters datasets which are orders of magnitude too large for conventional in-memory analysis. To tackle this challenge, we introduce SIMBSIG (<italic toggle="yes">SIM</italic>milarity <italic toggle="yes">B</italic>atched <italic toggle="yes">S</italic>earch <italic toggle="yes">I</italic>ntegrated <italic toggle="yes">G</italic>PU), a highly scalable Python package which provides a scikit-learn-like interface for out-of-core, GPU-enabled similarity searches, principal component analysis and clustering. Due to the PyTorch backend, it is highly modular and particularly tailored to many data types with a particular focus on biobank data analysis.</p>
      </sec>
      <sec id="s2">
        <title>Availability and implementation</title>
        <p>SIMBSIG is freely available from PyPI and its source code and documentation can be found on GitHub (<ext-link xlink:href="https://github.com/BorgwardtLab/simbsig" ext-link-type="uri">https://github.com/BorgwardtLab/simbsig</ext-link>) under a BSD-3 license.</p>
      </sec>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Swiss National Science Foundation</institution>
            <institution-id institution-id-type="DOI">10.13039/501100001711</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>PZ00P3_186101</award-id>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="2"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 Introduction</title>
    <p>With the ever-increasing amount of data produced, e.g. by genomics and next-generation sequencing, there is also demand for powerful computational tools to analyse such state-of-the-art datasets. In the UK Biobank alone, genotype data [800 000 single nucleotide polymorphisms (SNPs)] of half a million people are available (<xref rid="btac829-B2" ref-type="bibr">Bycroft <italic toggle="yes">et al.</italic>, 2018</xref>). This genotype dataset vastly exceeds the size of random access memory (RAM) or graphics processing units (GPU) memory of conventional computers. In general, neighbour searches in common Desktop machines can be performed in datasets up to a size of about tens of gigabytes. Therefore, algorithms and data formats, such as <monospace>hdf5</monospace> files, which allow for efficient out-of-core (ooc) computations are needed to perform any analysis or data processing. In order to tackle this issue, we introduce ‘SIMBSIG = <italic toggle="yes">SIM</italic>milarity <italic toggle="yes">B</italic>atched <italic toggle="yes">S</italic>earch <italic toggle="yes">I</italic>ntegrated <italic toggle="yes">G</italic>PU’, which can efficiently perform nearest neighbour searches, principal component analysis (PCA) and K-Means clustering on central processing units (CPUs) and GPUs, both in-core and ooc. SIMBSIG bridges the gap between the functionality and ease of use of the popular scikit-learn package and the speed of current computer hardware, particularly in the ooc scenario. Comparing with the Faiss software (<xref rid="btac829-B4" ref-type="bibr">Johnson <italic toggle="yes">et al.</italic>, 2021</xref>), a noteworthy approach related to SIMBSIG, the lack of a scikit-learn-like interface and the relatively rigid set of distance metrics make Faiss less tailored to bioinformatics applications. Nevertheless, a future version of SIMBSIG might incorporate Faiss as an alternative backend to PyTorch.</p>
  </sec>
  <sec>
    <title>2 Features</title>
    <p>SIMBSIG is a Python package which utilizes PyTorch to ensure efficient computations and provides a high-level interface mimicking scikit-learn. At its heart, SIMBSIG comprises three modules: <monospace>neighbors</monospace>, <monospace>clustering</monospace> and <monospace>decomposition</monospace>. All methods accept <monospace>numpy</monospace> arrays or <monospace>hdf5</monospace> file handles as inputs. Due to the modular structure of SIMBSIG, it will be straightforward to extend it to other data types.</p>
    <p>We chose <monospace>numpy</monospace> arrays as one of our input types for the user to have a seamless transition from scikit-learn while being able to use GPU acceleration whenever needed. The <monospace>hdf5</monospace> format is a hierarchical data format and provides many advantages over other tabular-data formats, which makes <monospace>hdf5</monospace> file objects ideal inputs to SIMBSIG. GPU usage with SIMBSIG is optional, enabling users to apply the full flexibility offered by SIMBSIG, even without access to GPUs.</p>
    <p>The <monospace>neighbors</monospace> module consists of our core routine for nearest neighbour searches in a batched, brute-force manner. This guarantees exact results with a precisely controllable memory-runtime trade-off. We implemented a batched K-Nearest Neighbour (KNN) search, where the number K of neighbours is fixed a priori, and a radius neighbour search, where all neighbours within a user-defined radius are returned. Based on this core routine, we implemented classifiers and regressors.</p>
    <p>We use a brute-force approach only due to the infeasibility of other exact methods in this scenario while retaining most other functionality of scikit-learn such as the choice of a range of metrics including all <italic toggle="yes">ℓ<sub>p</sub></italic> distances. Since, especially in genetic applications, the data are often high dimensional and subject to the curse of dimensionality, we also implemented the fractional <italic toggle="yes">ℓ<sub>p</sub></italic> distance (<xref rid="btac829-B1" ref-type="bibr">Aggarwal <italic toggle="yes">et al.</italic>, 2001</xref>). We further allow for precomputed distance matrices or user-defined functions (‘callables’). The ‘callable’ functionality is also present in scikit-learn and provides an easy way for more sophisticated (dis-)similarity functions such as kernel functions. Kernels exist, for example, for SNP data (<xref rid="btac829-B7" ref-type="bibr">Wang <italic toggle="yes">et al.</italic>, 2015</xref>) and may help obtaining more accurate results.</p>
    <p>The second core routine is batched K-Means clustering from the <monospace>clustering</monospace> module. The implementation is based on the fast K-Means algorithm by <xref rid="btac829-B6" ref-type="bibr">Sculley (2010)</xref>. Similar to the NN search, we accept <monospace>numpy</monospace> arrays or <monospace>hdf5</monospace> file handles as input, and we can cluster with respect to any <italic toggle="yes">ℓ<sub>p</sub></italic> norm, the cosine distance or a ‘callable’ distance function. We additionally implemented a heuristic stopping criterion based on the maximum relative change of any cluster centre. In practice, this stopping criterion works well for the <italic toggle="yes">ℓ<sub>p</sub></italic> distances; however, it may be lacking an analogue for more involved distance functions. In the current implementation, for any metrics that are not <italic toggle="yes">ℓ<sub>p</sub></italic>, the relative change becomes an absolute change.</p>
    <p>The third pillar of SIMBSIG is the <monospace>decomposition</monospace> module. This module provides an ooc, GPU-accelerated implementation of Halko’s approximate PCA algorithm (<xref rid="btac829-B3" ref-type="bibr">Halko <italic toggle="yes">et al.</italic>, 2011</xref>).</p>
  </sec>
  <sec>
    <title>3 Experiments</title>
    <p>To test accuracy, we designed an extensive set of unit tests, where we compare all possible input choices to the output of scikit-learn which we assume to be the ground truth. The speed of SIMBSIG was benchmarked on a large, artificial SNP dataset, where SNPs are encoded according to dominance assumption. We sampled ‘participants’ represented by a 10 000 dimensional vector with independent entries in {0, 1, 2}, representing 10 000 SNPs with probabilities <inline-formula id="IE1"><mml:math id="IM1" display="inline" overflow="scroll"><mml:mrow><mml:mo>{</mml:mo><mml:mn>0.6</mml:mn><mml:mo>,</mml:mo><mml:mn>0.2</mml:mn><mml:mo>,</mml:mo><mml:mn>0.2</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula>. In total, we sampled 500 000 such participants and stored the dataset in the <monospace>hdf5</monospace> format. We tested in-memory CPU performance against scikit-learn and benchmarked ooc scenarios. A reference GPU implementation, given by cuML (<xref rid="btac829-B5" ref-type="bibr">Raschka <italic toggle="yes">et al.</italic>, 2020</xref>), could not use the <monospace>h5py</monospace> package needed to load hdf5 files. Our results are presented in <xref rid="btac829-F1" ref-type="fig">Figure 1</xref>.</p>
    <fig position="float" id="btac829-F1">
      <label>Fig. 1.</label>
      <caption>
        <p>The runtime performance of SIMBSIG compared to the scikit-learn baseline averaged over 10 runs. We tested K-Means (<bold>a</bold>), a KNN search (<bold>b</bold>) and PCA (<bold>c</bold>). Both, in-core and ooc scenarios were computed, whereas the maximum feasible dataset size for in-core was 10<sup>5</sup> datapoints. For ooc computations, there were no memory restrictions and, therefore, a wider range of dataset sizes could be explored. The batch size was 10<sup>4</sup>. All runs were performed on an Intel i7 10700K CPU and 32GB RAM, the GPU was an Nvidia GeForce RTX3080. Stopping criteria for K-Means were set to default values</p>
      </caption>
      <graphic xlink:href="btac829f1" position="float"/>
    </fig>
  </sec>
  <sec>
    <title>4 Results</title>
    <p>As expected, in-core computations are faster for small datasets due to the decreased overhead of data loading compared to ooc computations. This is reflected in our results for datasets of fewer than 10<sup>4</sup> points in particular. In the very small dataset regime, the neighbour searches are very efficient, therefore, any computational overhead, such as converting numpy arrays to torch tensors, or moving tensors to GPU, will result in larger runtimes. For in-core computations of larger datasets, GPU-accelerated SIMBSIG neighbour searches are almost one order of magnitude faster compared to scikit-learn. In ooc, similarity searches SIMBSIG’s GPU acceleration feature offers a significant reduction in execution time for large datasets. In the K-Means and PCA algorithms, the situation is not so clear cut. While we can still see a slight performance increase in the GPU-based PCA, the CPU counterparts seem to acquire some computational overhead from the PyTorch backend. For the PCA, execution times for all in-core methods seem to converge for larger datasets. This leads us to conclude, that SIMBSIG unfolds its full power in ooc computations and GPU-based nearest neighbour searches.</p>
  </sec>
</body>
<back>
  <sec>
    <title>Funding</title>
    <p>This work was supported by the Swiss National Science Foundation [PZ00P3_186101]; and the Alfried Krupp Prize for Young University Teachers of the Alfried Krupp von Bohlen und Halbach-Stiftung to K.B.</p>
    <p><italic toggle="yes">Conflict of Interest</italic>: none declared.</p>
  </sec>
  <sec sec-type="data-availability">
    <title>Data availability</title>
    <p>All data is included in the Github repository.</p>
  </sec>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="btac829-B1">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Aggarwal</surname><given-names>C.C.</given-names></string-name></person-group><etal>et al</etal> (<year>2001</year>) On the surprising behavior of distance metrics in high dimensional space. In: <italic toggle="yes">International Conference on Database Theory 2001 Jan 4</italic>, pp. <fpage>420</fpage>–<lpage>434</lpage>. Springer, Berlin, Heidelberg.</mixed-citation>
    </ref>
    <ref id="btac829-B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bycroft</surname><given-names>C.</given-names></string-name></person-group><etal>et al</etal> (<year>2018</year>) <article-title>The UK biobank resource with deep phenotyping and genomic data</article-title>. <source>Nature</source>, <volume>562</volume>, <fpage>203</fpage>–<lpage>209</lpage>.<pub-id pub-id-type="pmid">30305743</pub-id></mixed-citation>
    </ref>
    <ref id="btac829-B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Halko</surname><given-names>N.</given-names></string-name></person-group><etal>et al</etal> (<year>2011</year>) <article-title>An algorithm for the principal component analysis of large data sets</article-title>. <source>SIAM J. Sci. Comput</source>., <volume>33</volume>, <fpage>2580</fpage>–<lpage>2594</lpage>.</mixed-citation>
    </ref>
    <ref id="btac829-B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Johnson</surname><given-names>J.</given-names></string-name></person-group><etal>et al</etal> (<year>2021</year>) <article-title>Billion-scale similarity search with GPUs</article-title>. <source>IEEE Trans. Big Data</source>, <volume>7</volume>, <fpage>535</fpage>–<lpage>547</lpage>.</mixed-citation>
    </ref>
    <ref id="btac829-B5">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Raschka</surname><given-names>S.</given-names></string-name></person-group><etal>et al</etal> (<year>2020</year>) Machine learning in python: main developments and technology trends in data science, machine learning, and artificial intelligence. <italic toggle="yes">Information,</italic><bold>11</bold>(4), 193<italic toggle="yes">.</italic></mixed-citation>
    </ref>
    <ref id="btac829-B6">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Sculley</surname><given-names>D.</given-names></string-name></person-group> (<year>2010</year>) Web-scale k-means clustering. In: <italic toggle="yes">Proceedings of the 19th International Conference on World Wide Web</italic>, pp. <fpage>1177</fpage>–<lpage>1178</lpage>.</mixed-citation>
    </ref>
    <ref id="btac829-B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname><given-names>X.</given-names></string-name></person-group><etal>et al</etal> (<year>2015</year>) <article-title>Kernel methods for large-scale genomic data analysis</article-title>. <source>Brief. Bioinform</source>., <volume>16</volume>, <fpage>183</fpage>–<lpage>192</lpage>.<pub-id pub-id-type="pmid">25053743</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
