<?DTDIdentifier.IdentifierValue -//NLM//DTD Journal Publishing DTD v2.3 20070202//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName journalpublishing.dtd?>
<?SourceDTD.Version 2.3?>
<?ConverterInfo.XSLTName nlm2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Front Neurosci</journal-id>
    <journal-id journal-id-type="iso-abbrev">Front Neurosci</journal-id>
    <journal-id journal-id-type="publisher-id">Front. Neurosci.</journal-id>
    <journal-title-group>
      <journal-title>Frontiers in Neuroscience</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1662-4548</issn>
    <issn pub-type="epub">1662-453X</issn>
    <publisher>
      <publisher-name>Frontiers Media S.A.</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">8963181</article-id>
    <article-id pub-id-type="doi">10.3389/fnins.2022.834827</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Neuroscience</subject>
        <subj-group>
          <subject>Technology and Code</subject>
        </subj-group>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>A Library for fMRI Real-Time Processing Systems in Python (RTPSpy) With Comprehensive Online Noise Reduction, Fast and Accurate Anatomical Image Processing, and Online Processing Simulation</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Misaki</surname>
          <given-names>Masaya</given-names>
        </name>
        <xref rid="c001" ref-type="corresp">
          <sup>*</sup>
        </xref>
        <uri xlink:href="http://loop.frontiersin.org/people/40848/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Bodurka</surname>
          <given-names>Jerzy</given-names>
        </name>
        <xref rid="fn001" ref-type="author-notes">
          <sup>†</sup>
        </xref>
        <uri xlink:href="http://loop.frontiersin.org/people/83975/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Paulus</surname>
          <given-names>Martin P.</given-names>
        </name>
        <uri xlink:href="http://loop.frontiersin.org/people/352/overview"/>
      </contrib>
    </contrib-group>
    <aff><institution>Laureate Institute for Brain Research</institution>, <addr-line>Tulsa, OK</addr-line>, <country>United States</country></aff>
    <author-notes>
      <fn fn-type="edited-by">
        <p>Edited by: Nikolaus Weiskopf, Max Planck Institute for Human Cognitive and Brain Sciences, Germany</p>
      </fn>
      <fn fn-type="edited-by">
        <p>Reviewed by: Stephan Heunis, Research Center Jülich, Germany; Ronald Sladky, University of Vienna, Austria; Yury Koush, Yale University, United States</p>
      </fn>
      <corresp id="c001">*Correspondence: Masaya Misaki, <email>mmisaki@laureateinstitute.org</email></corresp>
      <fn fn-type="deceased" id="fn001">
        <p><sup>†</sup>Deceased</p>
      </fn>
      <fn fn-type="other" id="fn004">
        <p>This article was submitted to Brain Imaging Methods, a section of the journal Frontiers in Neuroscience</p>
      </fn>
    </author-notes>
    <pub-date pub-type="epub">
      <day>11</day>
      <month>3</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2022</year>
    </pub-date>
    <volume>16</volume>
    <elocation-id>834827</elocation-id>
    <history>
      <date date-type="received">
        <day>13</day>
        <month>12</month>
        <year>2021</year>
      </date>
      <date date-type="accepted">
        <day>14</day>
        <month>2</month>
        <year>2022</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>Copyright © 2022 Misaki, Bodurka and Paulus.</copyright-statement>
      <copyright-year>2022</copyright-year>
      <copyright-holder>Misaki, Bodurka and Paulus</copyright-holder>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.</license-p>
      </license>
    </permissions>
    <abstract>
      <p>Real-time fMRI (rtfMRI) has enormous potential for both mechanistic brain imaging studies or treatment-oriented neuromodulation. However, the adaption of rtfMRI has been limited due to technical difficulties in implementing an efficient computational framework. Here, we introduce a python library for real-time fMRI (rtfMRI) data processing systems, Real-Time Processing System in python (RTPSpy), to provide building blocks for a custom rtfMRI application with extensive and advanced functionalities. RTPSpy is a library package including (1) a fast, comprehensive, and flexible online fMRI image processing modules comparable to offline denoising, (2) utilities for fast and accurate anatomical image processing to define an anatomical target region, (3) a simulation system of online fMRI processing to optimize a pipeline and target signal calculation, (4) simple interface to an external application for feedback presentation, and (5) a boilerplate graphical user interface (GUI) integrating operations with RTPSpy library. The fast and accurate anatomical image processing utility wraps external tools, including FastSurfer, ANTs, and AFNI, to make tissue segmentation and region of interest masks. We confirmed that the quality of the output masks was comparable with FreeSurfer, and the anatomical image processing could complete in a few minutes. The modular nature of RTPSpy provides the ability to use it for a simulation analysis to optimize a processing pipeline and target signal calculation. We present a sample script for building a real-time processing pipeline and running a simulation using RTPSpy. The library also offers a simple signal exchange mechanism with an external application using a TCP/IP socket. While the main components of the RTPSpy are the library modules, we also provide a GUI class for easy access to the RTPSpy functions. The boilerplate GUI application provided with the package allows users to develop a customized rtfMRI application with minimum scripting labor. The limitations of the package as it relates to environment-specific implementations are discussed. These library components can be customized and can be used in parts. Taken together, RTPSpy is an efficient and adaptable option for developing rtfMRI applications.</p>
      <p>
        <bold>Code available at:</bold>
        <ext-link xlink:href="https://github.com/mamisaki/RTPSpy" ext-link-type="uri">https://github.com/mamisaki/RTPSpy</ext-link>
      </p>
    </abstract>
    <kwd-group>
      <kwd>real-time fMRI</kwd>
      <kwd>neurofeedback</kwd>
      <kwd>online noise reduction</kwd>
      <kwd>python library</kwd>
      <kwd>fast segmentation</kwd>
    </kwd-group>
    <counts>
      <fig-count count="11"/>
      <table-count count="3"/>
      <equation-count count="0"/>
      <ref-count count="29"/>
      <page-count count="18"/>
      <word-count count="10432"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec sec-type="intro" id="S1">
    <title>Introduction</title>
    <p>Online evaluation of human brain activity with real-time functional magnetic resonance imaging (rtfMRI) expands the possibility of neuroimaging. Its application has been extended from on-site quality assurance (<xref rid="B3" ref-type="bibr">Cox et al., 1995</xref>), brain-computer-interface (BCI) (<xref rid="B6" ref-type="bibr">Goebel et al., 2010</xref>), brain self-regulation with neurofeedback (<xref rid="B24" ref-type="bibr">Sulzer et al., 2013</xref>), and online optimization in brain stimulation (<xref rid="B16" ref-type="bibr">Mulyana et al., 2021</xref>). Nevertheless, a complex system setup specific to an individual environment and noisy online evaluation of neural activation due to a limited real-time fMRI signal processing have hindered the utility of rtfMRI applications and reproducibility of its result (<xref rid="B25" ref-type="bibr">Thibault et al., 2018</xref>). Indeed, the significant risk of noise contamination in the neurofeedback signal has been demonstrated in recent studies (<xref rid="B27" ref-type="bibr">Weiss et al., 2020</xref>; <xref rid="B13" ref-type="bibr">Misaki and Bodurka, 2021</xref>). These issues have been addressed with a community effort releasing easy-to-use rtfMRI frameworks (<xref rid="B3" ref-type="bibr">Cox et al., 1995</xref>; <xref rid="B5" ref-type="bibr">Goebel, 2012</xref>; <xref rid="B22" ref-type="bibr">Sato et al., 2013</xref>; <xref rid="B10" ref-type="bibr">Koush et al., 2017</xref>; <xref rid="B8" ref-type="bibr">Heunis et al., 2018</xref>; <xref rid="B11" ref-type="bibr">Kumar et al., 2021</xref>; <xref rid="B12" ref-type="bibr">MacInnes et al., 2020</xref>) and consensus on reporting detailed online processing and experimental setups (<xref rid="B21" ref-type="bibr">Ros et al., 2020</xref>).</p>
    <p>As one of the contributions to such an effort, we introduce a software library for rtfMRI; fMRI Real-Time Processing System in python (RTPSpy). The goal of the RTPSpy is to provide building blocks for making a highly customized and advanced rtfMRI system. The library is not assumed to provide a complete application package but offers rtfMRI data processing components to be used as a part of a user’s custom application. We suppose that the tools of RTPSpy can also be combined with other frameworks as a part of processing modules.</p>
    <p>RTPSpy is a python library that includes a fast and comprehensive online fMRI image processing pipeline comparable to offline processing (<xref rid="B13" ref-type="bibr">Misaki and Bodurka, 2021</xref>) and an interface module for an external application to receive real-time brain activation signals <italic>via</italic> TCP/IP socket. Each online data processing component is implemented in an independent class, and a processing pipeline can be created by chaining these modules. In addition to the online fMRI signal processing modules, the library provides several utility modules, including brain anatomical image processing tools for fast and accurate tissue segmentation, and an online fMRI processing simulation system. Although these utilities may not always be required in a rtfMRI session, the fast anatomical image processing can be useful for identifying anatomically defined target regions, and the simulation analysis is vital for building an optimal processing pipeline (<xref rid="B18" ref-type="bibr">Ramot and Gonzalez-Castillo, 2019</xref>; <xref rid="B15" ref-type="bibr">Misaki et al., 2020</xref>; <xref rid="B13" ref-type="bibr">Misaki and Bodurka, 2021</xref>). We also provide a boilerplate graphical user interface (GUI) application integrating operations with RTPSpy, and a sample application of neurofeedback presentation using PsychoPy (<xref rid="B17" ref-type="bibr">Peirce, 2008</xref>) to demonstrate how the RTPSpy is implemented in an application and to interface to another external application. The GUI application is presented as just one example of library usage. However, a user may develop a custom neurofeedback application with minimum modification on this example script.</p>
    <p>The aim of this manuscript is to introduce the structure of the RTPSpy library and its usages as a part of a neurofeedback application. We hope that RTPSpy is used as a part of a user’s own custom application so that the current report focuses on how to script the RTPSpy online processing pipeline and implement it in an application. The detailed usage of the example application is presented in GitHub.<sup><xref rid="footnote1" ref-type="fn">1</xref></sup> Also, this manuscript does not provide a comprehensive evaluation of the library’s performance in detail. Such evaluations have been done in our previous report (<xref rid="B13" ref-type="bibr">Misaki and Bodurka, 2021</xref>), and only a short overview of the previous report was given in this report. Comparison with other exiting rtfMRI frameworks is also out of the scope of this manuscript. We recognize that many excellent packages are released for rtfMRI (<xref rid="B3" ref-type="bibr">Cox et al., 1995</xref>; <xref rid="B5" ref-type="bibr">Goebel, 2012</xref>; <xref rid="B22" ref-type="bibr">Sato et al., 2013</xref>; <xref rid="B10" ref-type="bibr">Koush et al., 2017</xref>; <xref rid="B8" ref-type="bibr">Heunis et al., 2018</xref>; <xref rid="B11" ref-type="bibr">Kumar et al., 2021</xref>; <xref rid="B12" ref-type="bibr">MacInnes et al., 2020</xref>), and we do not claim that RTPSpy is the best. The claim of the advanced functionality of the RTPSpy is for its own sake and not relative to other tools. RTPSpy and this manuscript aim to offer users another option for developing a custom rtfMRI application.</p>
    <p>This manuscript is organized as follows. The next section summarizes the installation and supporting system information. The third section introduces the online fMRI data processing modules in RTPSpy, the main components of the library. The issues and caveats in online fMRI data analysis and how they are addressed in RTPspy implementation are discussed here. The fourth section describes fast and accurate anatomical image processing tools. A custom processing stream was made by wrapping external tools, FastSurfer (<xref rid="B7" ref-type="bibr">Henschel et al., 2020</xref>), AFNI,<sup><xref rid="footnote2" ref-type="fn">2</xref></sup> and ANTs.<sup><xref rid="footnote3" ref-type="fn">3</xref></sup> We also evaluated the accuracy of tissue segmentation and the quality of tissue-based noise regressors made by this stream compared to FreeSurfer segmentation. The fifth and sixth sections illustrate the usage of library classes to build a processing pipeline and run a simulation analysis. An example GUI implementation is presented in the seventh section. The last section discusses the system components that are not provided with RTPSpy but are required for a complete system depending on an individual environment. The RTPSpy can be obtained from GitHub<sup><xref rid="footnote4" ref-type="fn">4</xref></sup> with GPL3 license.</p>
  </sec>
  <sec id="S2">
    <title>Installation and Supporting Systems</title>
    <p>RTPSpy is assumed to be run on a miniconda3<sup><xref rid="footnote5" ref-type="fn">5</xref></sup> or Anaconda<sup><xref rid="footnote6" ref-type="fn">6</xref></sup> environment. A yaml file for installing the required python libraries in an anaconda environment is provided with the package for easy installation. RTPSpy’s anatomical image processing depends on several external tools, AFNI (see text footnote 2), FastSurfer,<sup><xref rid="footnote7" ref-type="fn">7</xref></sup> and ANTs.<sup><xref rid="footnote8" ref-type="fn">8</xref></sup> While AFNI needs to be installed separately, FastSurfer and ANTs installation is integrated into the RTPSpy setup. Refer to the GitHub site (see text footnote 4) for further details.</p>
    <p>RTPSpy can take advantage of graphical processing unit (GPU) computation. GPU can be utilized in the online fMRI data processing and anatomical image processing with FastSurfer (see text footnote 7). To use GPU computation, a user needs a GPU compatible with NVIDIA’s CUDA toolkit<sup><xref rid="footnote9" ref-type="fn">9</xref></sup> and to install a GPU driver compatible with the CUDA. The CUDA toolkit will be installed with the yaml file. We note that GPU is not mandatory for RTPSpy. Online data processing speed in RTPSpy is fast enough for real-time fMRI even without GPU, while GPU can enhance it further (Section “Real-Time Performance”). Also, RTPSpy provides an alternative anatomical image processing stream not using FastSurfer, while the image segmentation accuracy is better with FastSurfer (Section “Evaluations for the Segmentation Masks and Noise Regressors”).</p>
    <p>RTPSpy has been developed on a Linux system (Ubuntu 20.04). It can also be run on Mac OS X and Windows with the Windows Subsystem for Linux (WSL), while GPU computation is not supported on OS X and WSL for now.</p>
  </sec>
  <sec id="S3">
    <title>RTPSpy Online fMRI Data Processing</title>
    <sec id="S3.SS1">
      <title>Overview of the Library Design</title>
      <p><xref rid="F1" ref-type="fig">Figure 1</xref> shows an overview of the modules composing an online processing pipeline. RTPSpy includes six online fMRI data processing modules; a real-time data loader (RTP_WATCH), slice-timing correction (RTP_TSHIFT), motion correction (RTP_VOLREG), spatial smoothing (RTP_SMOOTH), noise regression (RTP_REGRESS), and an application module (RTP_APP). A utility module for an external application to receive a processed signal, RTP_SERV, is also provided. RTP_WATCH is the entrance module, and RTP_APP is the terminal module of a pipeline. Other modules have common input and output interfaces so that they can be connected in any combination and order. For example, when a conventional pipeline only with a motion correction is enough, the pipeline can be made only with RTP_WATCH, RTP_VOLREG, and RTP_APP modules. If more comprehensive processing is required, all the components can be chained in a pipeline.</p>
      <fig position="float" id="F1">
        <label>FIGURE 1</label>
        <caption>
          <p>Overview of the RTPSpy module design for creating an online fMRI processing pipeline. RTP_WATCH is the entrance module, and RTP_APP is the terminal module of a pipeline. Other modules have common input and output interfaces. They can be connected in any combination and order. The modules exchange data with the Nifti1Image object of the whole-brain volume data. RTP_SERV is a utility module for an external application to receive a processed signal.</p>
        </caption>
        <graphic xlink:href="fnins-16-834827-g001" position="float"/>
      </fig>
      <p>These modules are implemented as a python class. The module’s interface method is “<monospace>do_proc</monospace>,” which receives a NiBabel<sup><xref rid="footnote10" ref-type="fn">10</xref></sup> Nifti1Image object. Its calling format is the same for all modules. The modules exchange data with the Nifti1Image object of the whole-brain volume data. The processing chain can be made by setting the “<monospace>next_proc</monospace>” property to an object of the next module. Calling the “<monospace>do_proc</monospace>” method at the head of the pipeline calls the next module’s “<monospace>do_proc</monospace>” method in the chain. This simple function interface enables the easy creation of a custom pipeline (see Section “Building a Processing Pipeline” for details).</p>
      <p>We assume that the input and output parts should be customized according to the user’s environment and an application need. For example, if a user wants to use another real-time image feeding (e.g., a dicom export feature of a scanner), RTP_WATCH can be replaced or modified in a preferred way. Also, the RTP_APP can be customized to calculate a neurofeedback signal in a user’s way. An example script for such customization is presented in Section “An Example Graphical User Interface Application Integrating the RTPSpy Modules.” We note that RTPSpy is not intended to provide a complete application for any environment. Instead, a necessary module for each environment is supposed to be developed by a user. RTPSpy offers a framework of the interface and building blocks of online fMRI data processing.</p>
    </sec>
    <sec id="S3.SS2">
      <title>Real-Time Performance</title>
      <p>Retaining the whole-brain data throughout the pipeline enables a common interface between modules. It also provides freedom of neurofeedback signal calculation (i.e., an ROI average, connectivity of multiple regions, and multi-voxel patterns in the whole brain) with various combinations of processing modules. Although this implementation seemed burdensome for real-time computation, we found that processing whole-brain volume does not significantly affect the real-time performance in RTPSpy. Our previous report (<xref rid="B13" ref-type="bibr">Misaki and Bodurka, 2021</xref>) showed that the pipeline processing was completed in less than 400 ms on a current PC equipped with a GPU. Here, we also evaluated the processing time with several PC specifications with and without GPU for a sample fMRI data (128 × 128 × 34 matrix, 203 volumes). Note that this evaluation is not a comprehensive performance test but rather a rough guide to the PC specifications required for real-time processing with RTPSpy.</p>
      <p><xref rid="T1" ref-type="table">Table 1</xref> shows the specifications of the tested PCs. “<monospace>Linux+GPU</monospace>” is the same one used in <xref rid="B13" ref-type="bibr">Misaki and Bodurka (2021)</xref>. The evaluated pipeline included all modules implemented in RTPSpy and RTP_REGRESS includes all available regressors. <xref rid="F2" ref-type="fig">Figure 2</xref> shows processing times for each module. The figure shows the results after TR = 45 since the regression waited to receive 40 volumes, excluding the initial three volumes, and the processing of the first regressed volume took a long time due to initialization and retrospective processing (see Section “Implementations of the Online fMRI Processing Algorithms,” RTP_REGRESS). The processing time of RTP_WATCH is from a file creation time to send the volume data to the next module. The processing time of RTP_APP is to extract an ROI average signal and write it in a text file.</p>
      <table-wrap position="float" id="T1">
        <label>TABLE 1</label>
        <caption>
          <p>PC specifications used for the computation time evaluation.</p>
        </caption>
        <table frame="hsides" rules="groups" cellspacing="5" cellpadding="5">
          <thead>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Name</td>
              <td valign="top" align="left" rowspan="1" colspan="1">CPU</td>
              <td valign="top" align="center" rowspan="1" colspan="1">RAM</td>
              <td valign="top" align="center" rowspan="1" colspan="1">Storage</td>
              <td valign="top" align="center" rowspan="1" colspan="1">GPU</td>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Linux + GPU</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Dual Intel Xeon Gold 6126, 2.6 GHz, 12-core</td>
              <td valign="top" align="center" rowspan="1" colspan="1">256 GB, DDR4</td>
              <td valign="top" align="center" rowspan="1" colspan="1">HDD</td>
              <td valign="top" align="center" rowspan="1" colspan="1">NVIDIA TITAN V</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Linux</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Dual Intel Xeon Gold 6126, 2.6 GHz, 12-core</td>
              <td valign="top" align="center" rowspan="1" colspan="1">256 GB, DDR4</td>
              <td valign="top" align="center" rowspan="1" colspan="1">HDD</td>
              <td valign="top" align="center" rowspan="1" colspan="1">No</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">MacBookPro1</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Intel Core i9, 2.3 GHz, 8-Core</td>
              <td valign="top" align="center" rowspan="1" colspan="1">32 GB, DDR4</td>
              <td valign="top" align="center" rowspan="1" colspan="1">SSD</td>
              <td valign="top" align="center" rowspan="1" colspan="1">No</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">MacBookPro2</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Intel Core i7, 2.7 GHz, 4-core</td>
              <td valign="top" align="center" rowspan="1" colspan="1">16 GB, DDR3</td>
              <td valign="top" align="center" rowspan="1" colspan="1">SSD</td>
              <td valign="top" align="center" rowspan="1" colspan="1">No</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Windows1</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Intel Xeon W-2245, 3.9 GHz, 8-core</td>
              <td valign="top" align="center" rowspan="1" colspan="1">32 GB, DDR4</td>
              <td valign="top" align="center" rowspan="1" colspan="1">SSD</td>
              <td valign="top" align="center" rowspan="1" colspan="1">No</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Windows2</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Intel Core i5, 2.0 GHz, 4-core</td>
              <td valign="top" align="center" rowspan="1" colspan="1">8 GB, DDR3</td>
              <td valign="top" align="center" rowspan="1" colspan="1">HDD</td>
              <td valign="top" align="center" rowspan="1" colspan="1">No</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
      <fig position="float" id="F2">
        <label>FIGURE 2</label>
        <caption>
          <p>RTPSpy online fMRI data processing times. See <xref rid="T1" ref-type="table">Table 1</xref> for the specification of the PCs. The evaluation was done with a sample fMRI data (128 × 128 × 34 matrix, 203 volumes). Processing with RTP_REGRESS included all available regressors (Legendre polynomials for high-pass filtering, 12 motion parameters, global signal, mean white matter and ventricle signals, and RETROICOR regressors).</p>
        </caption>
        <graphic xlink:href="fnins-16-834827-g002" position="float"/>
      </fig>
      <p>The results were consistent with the previous report (<xref rid="B13" ref-type="bibr">Misaki and Bodurka, 2021</xref>). The most time-consuming processing was RTP_VOLREG. RTP_REGRESS’s processing time increased with TR since cumulative GLM uses more samples in later TRs (see Section “Implementations of the Online fMRI Processing Algorithms,” RTP_REGRESS). The slope of the increase was the lowest with GPU, indicating that GPU can be beneficial when a scan has many volumes. Interestingly, however, the total processing time was not significantly different by GPU usage, and MacBookPro showed comparable performance with a high-end Linux PC, at least for the present scan length. The Windows showed relatively longer processing times regardless of the specification, which might be due to the overhead of the Windows subsystem for Linux. These results indicate that the PC requirement for RTPSpy is not high, at least for an ordinary real-time fMRI scan with a few seconds TR and less than a few hundred volumes.</p>
      <p>Even if computation time does not limit real-time fMRI processing, the limited number of sample points available online poses a challenge for online processing yet. The next section describes the details of each module functionalities and online analysis methods in RTPSpy to address this issue.</p>
    </sec>
    <sec id="S3.SS3">
      <title>Implementations of the Online fMRI Processing Algorithms</title>
      <p><xref rid="T2" ref-type="table">Table 2</xref> summarizes the functions of RTPSpy processing modules. The class files for these modules can be found in the “<monospace>rtpspy</monospace>” directory of the package. The issue of the limited number of online available sample points is critical for slice timing correction, signal scaling, and online noise regression. This section describes the methods used in the RTPSpy modules to address this issue.</p>
      <table-wrap position="float" id="T2">
        <label>TABLE 2</label>
        <caption>
          <p>Summaries of RTPSpy real-time processing modules and their differences from offline processing.</p>
        </caption>
        <table frame="hsides" rules="groups" cellspacing="5" cellpadding="5">
          <thead>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Class module (library file)</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Processing</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Difference from an offline processing</td>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">RTP_WATCH (rtp_watch.py)</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Monitoring a new fMRI volume file creation to read and convert the data as NiBabel Nifti1Image.</td>
              <td valign="top" align="left" rowspan="1" colspan="1">N/A</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">RTP_TSHIFT (rtp_tshift.py)</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Slice-timing correction with temporal interpolation and resampling time points.</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Cubic interpolation uses a pseudo future point with the same value as the present one.</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">RTP_VOLREG (rtp_volreg.py)</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Motion correction with registration to a reference volume.</td>
              <td valign="top" align="left" rowspan="1" colspan="1">None.</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">RTP_SMOOTH (rtp_smooth.py)</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Spatial smoothing by convolving a Gaussian kernel inside a brain mask.</td>
              <td valign="top" align="left" rowspan="1" colspan="1">None.</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">RTP_REGRESS (rtp_regress.py)</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Signal scaling and noise regression. Regressors include high-pass filtering, motion parameters and their temporal derivatives, global signal, mean signals in the white matter and ventricle regions, and cardiac and respiration noise models with RETROICOR (<xref rid="B4" ref-type="bibr">Glover et al., 2000</xref>).</td>
              <td valign="top" align="left" rowspan="1" colspan="1">The regression starts after acquiring enough volumes.<break/>The signal scaling uses the average signal before starting the regression.<break/>High-pass filtering and RETROICOR regressors are updated at each time (<xref rid="B13" ref-type="bibr">Misaki and Bodurka, 2021</xref>).</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">RTP_RETROTS (rtp_retrots.py)</td>
              <td valign="top" align="left" rowspan="1" colspan="1">This module is not a part of the pipeline but a supporting module for RTP_REGRESS to calculate the RETROICOR regressor.</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Although the same algorithm as offline processing is used, the online calculation of the regressors cannot be accurate (<xref rid="B13" ref-type="bibr">Misaki and Bodurka, 2021</xref>).</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">RTP_APP (rtp_app.py)</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Calculating the neurofeedback signal from the processed image to send the signal to an external application. General application controls, including anatomical image processing, are also performed.</td>
              <td valign="top" align="left" rowspan="1" colspan="1">N/A</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">RTP_SERV (rtp_serv.py)</td>
              <td valign="top" align="left" rowspan="1" colspan="1">This module is not a part of the pipeline but is to be used in an external application. The module launces a TCP/IP server in a background thread, receiving a processed signal from RTP_APP. An external application can retrieve the received signal as a property of the module.</td>
              <td valign="top" align="left" rowspan="1" colspan="1">N/A</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn>
            <p>
              <italic>N/A, Not applicable to offline processing. The library files can be found in the “<monospace>rtpspy</monospace>” directory of the RTPSpy package.</italic>
            </p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p>RTP_WATCH finds a newly created file in a watching directory in real-time, reads the data, and sends it to the next processing module. The watchdog module in python<sup><xref rid="footnote11" ref-type="fn">11</xref></sup> is used to detect a new file creation. RTP_WATCH uses the NiBabel library (see text footnote 10) to read the file. The currently supported file types are NIfTI, AFNI’s BRIK, and Siemens mosaic dicom. Technically, this module can handle all file types supported by NiBabel, so a user can easily extend the supported files as needed. The whole-brain volume data is retained in the NiBabel Nifti1Image format throughout the RTPSpy pipeline. The observer function used in RTP_WATCH (PollingObserverVFS) is system-call independent and can work with various file systems. However, polling may take a long time if many files are in the monitored directory, hindering real-time performance. If a user finds a significant delay by saving files of many runs in a single directory, it is recommended to clean or move files at each run.</p>
      <p>Although RTP_WATCH offers a simple interface to read a data file in real-time, how the MRI scanner saves the reconstructed image varies across the manufacturers and sites. RTPSpy does not provide a universal solution for that. A user may need another package to send data to the watched directory or modify the script file (rtp_watch.py) to adjust for each environment. We will discuss this limitation of the environment-specific issues in the last section.</p>
      <p>RTP_TSHIFT performs a slice-timing correction by aligning the signal sampling times in different slices to the same one with temporal interpolation. Because we cannot access the future time point in real-time, the online processing cannot be equivalent to offline. RTPSpy aligns the sampling time to the earliest slice for avoiding extrapolation. RTPSpy implements two interpolation methods, linear and cubic. The linear interpolation uses only the current and one past time point so that it is equivalent to offline processing. The cubic interpolation uses four time-points; two from the past, the present, and one future. RTPSpy puts a pseudo future point with the same value as the present one to perform the cubic interpolation. We have confirmed that this pseudo cubic method has a higher correlation with a high-order interpolation method (e.g., FFT) than a linear method (<xref rid="B14" ref-type="bibr">Misaki et al., 2015</xref>). By default, RTPSpy uses cubic interpolation.</p>
      <p>Slice-timing correction is often skipped in real-time fMRI processing, and its effect could be minor when TR is short (<xref rid="B9" ref-type="bibr">Kiebel et al., 2007</xref>; <xref rid="B23" ref-type="bibr">Sladky et al., 2011</xref>). However, some neurofeedback signal extraction methods, such as the two-point connectivity (<xref rid="B19" ref-type="bibr">Ramot et al., 2017</xref>), could be sensitive to a small timing difference between slices. The two-point method evaluates the consistency of the signal change direction (increase/decrees) at each TR, which could be sensitive to the timing of signal direction change between ROIs in different slices. The user can choose to use this module or not, and RTPSpy does not enforce the specific pipeline for the real-time fMRI processing. We also note that slice-timing correction takes no significant cost of computational time (<xref rid="F2" ref-type="fig">Figure 2</xref>).</p>
      <p>RTP_VOLREG performs motion correction by registering volumes to a reference one. The same functions as the AFNI’s 3dvolreg,<sup><xref rid="footnote12" ref-type="fn">12</xref></sup> a motion correction command in the AFNI toolkit, is implemented in RTP_VOLREG. We compiled the C source codes of 3dvolreg functions into a custom C shared library file (librtp.so in the RTPSpy package), and RTP_VOLREG accesses it <italic>via</italic> the python ctypes interface. Thus, this online processing is equivalent to the offline 3dvolreg. By default, RTP_VOLREG uses heptic (seventh order polynomial) interpolation at image reslicing, the same as the 3dvolreg default.</p>
      <p>RTP_SMOOTH performs spatial smoothing by convolving a Gaussian kernel within a masked region. Like RTP_VOLREG, RTPSpy uses the AFNI’s 3dBlurInMask<sup><xref rid="footnote13" ref-type="fn">13</xref></sup> functions compiled into a C shared library file (librtp.so), and accessed <italic>via</italic> ctypes interface in python. This process has no difference between online and offline processing.</p>
      <p>RTP_REGRESS performs a signal scaling and noise regression analysis. The regression requires at least as many data points as the number of regressors and will not commence the process until sufficient number of data points have been collected. The signal scaling is done with the average signal in this waiting period and converts a signal into percent change relative to the average in each voxel. We note that this scaling is not equivalent to the offline processing using an average of all time points in a run so that the absolute amplitude cannot be comparable between the online and offline processing. We also note that the volumes before the start of regression are processed retrospectively so that the saved data includes all volumes. Once enough volumes are received, the regression is done with an ordinary least square (OLS) approach using the PyTorch library,<sup><xref rid="footnote14" ref-type="fn">14</xref></sup> which allows a seamless switching of CPU and GPU usage according to the system equipment. The residual of regression is obtained as a denoised signal.</p>
      <p>The regressors can include high-pass filtering (Legendre polynomials), motion parameters (three shifts and three rotations), their temporal derivatives, global signal, mean signals in the white matter and ventricle regions, and cardiac and respiration noise models with RETROICOR (<xref rid="B4" ref-type="bibr">Glover et al., 2000</xref>). The order of the Legendre polynomials for high-pass filtering is adjusted according to the data length at each volume with 1 + int(d/150), where d is the scan duration in seconds (the default in AFNI). The motion parameters were received from the RTP_VOLREG module in real-time. The global signal and the mean white matter and ventricle signals are calculated from the unsmoothed data, which is also received from the RTP_VOLREG module. These regressors were made from the mask files defined in “<monospace>GS_mask</monospace>” (global signal mask), “<monospace>WM_mask</monospace>,” and “<monospace>Vent_mask</monospace>” properties of the module. As the RTP_REGRESS depends on RTP_VOLREG outputs, RTP_VOLREG must be included before RTP_REGRESS when it is used in a pipeline. A user can also include any pre-defined time-series such as a task design as a covariate in the regressors. It is up to a user to decide which regressor to use. The report in <xref rid="B13" ref-type="bibr">Misaki and Bodurka (2021)</xref> has shown which regressor was effective in reducing what noise in what brain regions and connectivity, which may help decide the noise regressor choice.</p>
      <p>RTPSpy uses cumulative GLM (cGLM), which performs regression with all samples at each time, rather than incremental GLM (iGLM), which updates only the most recent estimates based on previous estimates (<xref rid="B1" ref-type="bibr">Bagarinao et al., 2003</xref>). In <xref rid="B13" ref-type="bibr">Misaki and Bodurka (2021)</xref>, we indicated that high-pass filtering regressor, either Legendre polynomial or discrete cosine transform, filtered higher frequencies than the designed threshold at early TRs unless the regressor was adjusted at each TR. This adjustment requires a retrospective update of the regressor. Similarly, the online creation of RETROICOR regressors, made from real-time cardiac and respiration signal recordings, could not be accurate compared to the offline creation, and the error was accumulated unless retrospective correction was made (see Figures 2, 3 in <xref rid="B13" ref-type="bibr">Misaki and Bodurka, 2021</xref>). RTPSpy uses cGLM because cGLM has the advantage of being able to recalculate regressors at each volume, thereby improving the quality of regressors made online with limited samples. Although this implementation, whole-brain processing with cGLM, seemed burdensome for real-time processing, the computation time is not inhibitive to real-time performance, as shown in Section “Real-Time Performance.”</p>
      <p>RTP_RETROTS is not a pipeline component (thus, not shown in <xref rid="F1" ref-type="fig">Figure 1</xref>) but a supporting module for RTP_REGRESS to calculate the RETROICOR regressors from cardiac and respiration signals in real-time. In our environment, cardiac and respiration signals are measured using photoplethysmography and a pneumatic respiration belt, respectively. Although this hardware implementation could depend on the environment of each site (see Section “Limitations and Environment-Specific Issues”), once the signal acquisition is set up, the usage of RTP_RETROTS is simple. Its interface method (“<monospace>do_proc</monospace>”) receives respiration and cardiac signal values as one-dimensional arrays, the signals’ sampling frequency, and fMRI TR parameters. Then, the method returns the RETROICORE regressors.</p>
      <p>RTP_RETROTS implements the same functions as the AFNI’s RetroTS.py script, which are rewritten in C codes and compiled into a shared library (librtp.so). The module makes four cardiac and four respiration noise basis regressors. It is possible to also create a respiration volume per time (RVT) regressors (<xref rid="B2" ref-type="bibr">Birn et al., 2008</xref>). However, we do not recommend using them in online processing. Our previous study (<xref rid="B13" ref-type="bibr">Misaki and Bodurka, 2021</xref>) indicated that the online evaluation of RVT regressors could not be accurate, and its usage could introduce an artifactual signal fluctuation in the processed signal in an online regression.</p>
      <p>RTP_APP receives the processed image and calculates the neurofeedback signal from it. The default implementation extracts the average signal in an ROI mask, defined in the “<monospace>do_proc</monospace>” method of the rtp_app.py file. This method is provided as a prototype and can be customized according to the need for individual applications. Section “An Example Graphical User Interface Application Integrating the RTPSpy Modules” and <xref rid="F10" ref-type="fig">Figure 10</xref> show an example of a customized method. The RTPSpy noise reduction is performed for the whole-brain voxels, which is advantageous in calculating the feedback signals from multiple regions, such as the functional connectivity and decoding neurofeedback (<xref rid="B26" ref-type="bibr">Watanabe et al., 2017</xref>). The calculated signal can be sent to an external application through a network socket to the RTP_SERV module (<xref rid="F1" ref-type="fig">Figure 1</xref>; see also Section “An Example Graphical User Interface Application Integrating the RTPSpy Modules” and <xref rid="F11" ref-type="fig">Figure 11</xref>). The RTP_APP class also implements general application control methods, including anatomical image processing described in the next section and a high-level scripting interface explained in Section “Example Real-Time fMRI Session.”</p>
      <p>RTP_SERV is not a part of the image processing pipeline but offers an interface class for an external application to communicate to RTPSpy. This module is assumed to be implemented in an external application as a receiver of the processed signal. Instantiating this class launches a TCP/IP server in a background thread in an external application to receive a real-time neurofeedback signal (see Section “An Example Graphical User Interface Application Integrating the RTPSpy Modules”).</p>
    </sec>
  </sec>
  <sec id="S4">
    <title>Anatomical Image Processing With Fast and Accurate Tissue Segmentation</title>
    <p>Anatomical image processing is often required in a rtfMRI session. While there are several ways to define the target region for neurofeedback (e.g., functional localizer), if the target brain region is defined in the template brain with a group analysis, we need to warp the region mask into the participant’s brain. The noise regressions with the global signal and white matter and ventricle mean signals also require a brain mask and tissue segmentation masks on an individual brain image.</p>
    <p>Although there are many tools for brain tissue segmentation using a signal intensity, they are prone to an image bias field and often need a manual correction. Another approach for tissue segmentation uses anatomical information to segment the regions in addition to the signal intensity, such as FreeSurfer.<sup><xref rid="footnote15" ref-type="fn">15</xref></sup> FreeSurfer usually offers more accurate and robust segmentation than using only the signal intensity, but its process takes hours or longer to complete, inhibiting its use in a single visit rtfMRI session. Recently, an alternative approach of brain image segmentation using a deep neural network has been released as FastSurfer (<xref rid="B7" ref-type="bibr">Henschel et al., 2020</xref>). FastSurfer uses a U-net architecture (<xref rid="B20" ref-type="bibr">Ronneberger et al., 2015</xref>) trained to output a segmentation map equivalent to the FreeSurfer’s volume segmentation from an input of anatomical MRI image. FastSurfer can complete the segmentation in a few minutes with GPU. We made a script called FastSeg utilizing the advantage of FastSurfer to extract a brain mask (skull stripping), gray matter, white matter, and ventricle segmentation. FastSeg is implemented as part of the RTPSpy anatomical image processing pipeline and also released as an independent tool.<sup><xref rid="footnote16" ref-type="fn">16</xref></sup> The FastSurfer process in the FastSeg could take very long (about an hour) if GPU was not available. Therefore, RTPSpy also offers another processing stream that does not use FastSeg. This section describes the flow of the anatomical image processing steps and shows the evaluation results of their segmentation accuracy and noise regressor quality compared to FreeSurfer’s segmentation.</p>
    <sec id="S4.SS1">
      <title>Anatomical Image Processing Pipeline</title>
      <p>RTPspy offers a simple function interface to run a series of anatomical image processing, the “<monospace>make_masks</monospace>” method in RTP_APP class. <xref rid="F3" ref-type="fig">Figure 3</xref> shows the processing pipeline in this method. The method receives filenames of a reference function image (func_orig), anatomical image (anat_orig), template image (template, optional), and a region of interest (ROI) image in the template space (ROI_template, optional). If the alternative processing stream without FastSeg is used, white matter and ventricle masks defined in the template space (WM_template, Vent_template) can also be received. The process includes the following five steps.</p>
      <fig position="float" id="F3">
        <label>FIGURE 3</label>
        <caption>
          <p>Procedures of creating image masks in the “<monospace>make_masks</monospace>” method of RTP_APP. Two blue boxes show the procedures used in the alternative stream without using FastSeg. In the alternative stream, the first process is replaced by a blue box, and the fourth process is performed by adding the procedure in the blue box. The images below demonstrate what image processing is done at each step.</p>
        </caption>
        <graphic xlink:href="fnins-16-834827-g003" position="float"/>
      </fig>
      <list list-type="simple">
        <list-item>
          <label>(1)</label>
          <p>Extracting the brain (skull stripping), white matter, and ventricle regions using FastSeg. FastSeg uses the first stage of the FastSurfer process to make a volume segmentation map (DKTatlas+aseg.mgz). Then, all the segmented voxels are extracted as the brain mask with filling holes. The white matter mask is made with a union of the white matter and corpus callosum segmentations. The ventricle mask is made with lateral ventricle segmentation. We did not include small ventricle areas because the mask is used only for making a regressor for online fMRI denoising.</p>
        </list-item>
      </list>
      <p>In the alternative stream not using FastSeg (blue box in <xref rid="F3" ref-type="fig">Figure 3</xref>), AFNI’s 3dSkullStrip is used for brain extraction. White matter and ventricle masks are made in a later step (step 4) by warping the template masks into an individual brain.</p>
      <list list-type="simple">
        <list-item>
          <label>(2)</label>
          <p>Aligning the extracted brain image to a reference function image using AFNI align_epi_anat.py.</p>
        </list-item>
        <list-item>
          <label>(3)</label>
          <p>Aligning and resampling the brain mask into the reference function image space using the parameters made in step 2 and making a signal mask of the function image using 3dAutomask in AFNI. The union of these masks is made as a real-time processing mask (RTPmask.nii.gz), used at spatial smoothing in RTP_SMOOTH and defining the processing voxels in RTP_REGRESS. The intersect of these masks is also made as a global signal mask (GSRmask.nii.gz), used in RTP_REGRESS.</p>
        </list-item>
        <list-item>
          <label>(4)</label>
          <p>If the template image and the ROI mask on the template are provided, the template brain is warped into the participant’s anatomical brain image using the python interface of ANTs registration.<sup><xref rid="footnote17" ref-type="fn">17</xref></sup> Then, the ROI mask on the template is warped into the participant’s brain anatomy image and resampled to the reference function image to make an ROI mask in the functional image space. This mask will be used for neurofeedback signal calculation.</p>
        </list-item>
      </list>
      <p>In the alternative stream not using FastSeg (blue box in <xref rid="F3" ref-type="fig">Figure 3</xref>), white matter and ventricle masks defined in the template brain are also warped into an individual brain.</p>
      <list list-type="simple">
        <list-item>
          <label>(5)</label>
          <p>Eroding the white matter (two voxels) and ventricle (one voxel) masks and aligning them to the functional image space using the alignment parameters (affine transformation) estimated at step 2. These masks will be used for the white matter and ventricle average signal regression.</p>
        </list-item>
      </list>
      <p>These anatomical image processing could be completed in less than a few minutes. <xref rid="T3" ref-type="table">Table 3</xref> shows the processing times with and without FastSeg on the PCs listed in <xref rid="T1" ref-type="table">Table 1</xref> for one sample image (MPRAGE image with 256 × 256 × 120 matrix and 0.9 × 0.9 × 1.2 mm voxel size).</p>
      <table-wrap position="float" id="T3">
        <label>TABLE 3</label>
        <caption>
          <p>Anatomical image processing times on the PCs shown in <xref rid="T1" ref-type="table">Table 1</xref>.</p>
        </caption>
        <table frame="hsides" rules="groups" cellspacing="5" cellpadding="5">
          <thead>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">PC</td>
              <td valign="top" align="center" rowspan="1" colspan="1">Linux + GPU<xref rid="t3fns1" ref-type="table-fn">*</xref></td>
              <td valign="top" align="center" rowspan="1" colspan="1">Linux</td>
              <td valign="top" align="center" rowspan="1" colspan="1">MacBookPro1</td>
              <td valign="top" align="center" rowspan="1" colspan="1">MacBookPro2</td>
              <td valign="top" align="center" rowspan="1" colspan="1">Windows1</td>
              <td valign="top" align="center" rowspan="1" colspan="1">Windows2</td>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Processing time (s)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">89</td>
              <td valign="top" align="center" rowspan="1" colspan="1">146</td>
              <td valign="top" align="center" rowspan="1" colspan="1">197</td>
              <td valign="top" align="center" rowspan="1" colspan="1">188</td>
              <td valign="top" align="center" rowspan="1" colspan="1">241</td>
              <td valign="top" align="center" rowspan="1" colspan="1">473</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="t3fns1">
            <p>
              <italic>*FastSeg was used in Linux + GPU. The alternative stream was used for others.</italic>
            </p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
    </sec>
    <sec id="S4.SS2">
      <title>Evaluations for the Segmentation Masks and Noise Regressors</title>
      <p>Since the anatomical segmentation by FastSurfer is not exactly the same as FreeSurfer (<xref rid="B7" ref-type="bibr">Henschel et al., 2020</xref>), we evaluated the quality of white matter and ventricle masks made by the FatSeg compared to the FreeSurfer segmentation. The comparison was made for 87 healthy participants’ anatomical and resting-state fMRI images (age 18–55 years, 45 females) used in our previous study (<xref rid="B13" ref-type="bibr">Misaki and Bodurka, 2021</xref>). We also performed the same comparison for the masks made by the alternative processing stream without FastSeg.</p>
      <p><xref rid="F4" ref-type="fig">Figure 4</xref> upper panel shows the Dice coefficients of the segmentation masks with the FreeSufer segmentation in anatomical image resolution. The masks made by FastSeg had high Dice coefficients with FreeSurfer segmentation showing their good agreement, while the masks made by the alternative stream had lower agreements, especially for the white matter mask. Nevertheless, the effect of these discrepancies could be minor in creating a noise regressor at functional image resolution. The bottom panel of <xref rid="F4" ref-type="fig">Figure 4</xref> shows the correlation between the average white matter and ventricle fMRI signals created from the FastSeg (or alternative stream) and FreeSurfer masks. For the FastSeg, the correlation was nearly 1.0 (higher than 0.98 even for the minimum sample). Although a few samples had a relatively low Dice coefficient for the FastSeg ventricle mask, that was because their ventricle region was small, and minor error affected the Dice coefficient much. Indeed, the signal correlation for the sample with minimum Dice coefficient (0.77) was as high as 0.99, indicating a minor segmentation error. Thus, the effect of the segmentation difference between the FastSeg and FreeSurfer was minor on the mean white matter and ventricle signals. The noise regressors made from the FastSeg hold equal quality to those made from FreeSurfer segmentations.</p>
      <fig position="float" id="F4">
        <label>FIGURE 4</label>
        <caption>
          <p>Quality evaluations for the masks created by the RTPSpy anatomical image processing streams by comparing to FreeSurfer segmentation. The upper panel shows Dice coefficients with FreeSurfer segmentations for the white matter and ventricle masks in the anatomical image resolution. The bottom panel shows correlations of the mean signals calculated from the masks in functional images.</p>
        </caption>
        <graphic xlink:href="fnins-16-834827-g004" position="float"/>
      </fig>
      <p>For the alternative processing stream without FastSeg, the correlation was lower than the FastSeg, while they were still higher than 0.9 for most samples with the minimum of 0.89. Although the FastSeg offers a better segmentation quality, the alternative processing stream would have an acceptable quality to make a noise regressor if GPU is not available.</p>
    </sec>
  </sec>
  <sec id="S5">
    <title>RTPSpy Usage</title>
    <sec id="S5.SS1">
      <title>Building a Processing Pipeline</title>
      <sec id="S5.SS1.SSS1">
        <title>Low-Level Interface</title>
        <p><xref rid="F5" ref-type="fig">Figure 5</xref> shows a pseudo script to create an online fMRI data processing pipeline. This is presented for explaining the low-level interfaces of building an RTPSpy pipeline. A script with higher-level interfaces using RTP_APP utility methods is presented later (<xref rid="F6" ref-type="fig">Figure 6</xref>). To make a pipeline, we should create instances of each processing module (<xref rid="F5" ref-type="fig">Figure 5A</xref>), set the chaining module in the “<monospace>next_proc</monospace>” property (<xref rid="F5" ref-type="fig">Figure 5B</xref>), and the pipeline is ready. The modules’ combination and the order can be arbitrary, except that RTP_VOLREG must exist before RTP_REGRESS. The head module can be used as an interface to the pipeline (<xref rid="F5" ref-type="fig">Figure 5C</xref>).</p>
        <fig position="float" id="F5">
          <label>FIGURE 5</label>
          <caption>
            <p>A pseudo script of low-level interfaces of pipeline creation with RTPSpy. The comments with bold alphabet indicate a part of the script explained in the main text. To make a pipeline, we should create instances of each processing module <bold>(A)</bold> and set a chaining module to the “<monospace>next_proc</monospace>” property <bold>(B)</bold>. The head module can be used as an interface to the pipeline <bold>(C)</bold>. Properties of the modules in a pipeline can be directly accessed and set by the module instances <bold>(D)</bold>. Calling the “<monospace>redy_proc</monospace>” method initializes the pipeline <bold>(E)</bold>. The processing is run by feeding a NiBabel Nifti1Image object to the “<monospace>do_proc</monospace>” method of the pipeline <bold>(F)</bold>. The pipeline is closed by calling the “<monospace>end_reset</monospace>” method <bold>(G)</bold>.</p>
          </caption>
          <graphic xlink:href="fnins-16-834827-g005" position="float"/>
        </fig>
        <fig position="float" id="F6">
          <label>FIGURE 6</label>
          <caption>
            <p>A snippet of an example script to run a real-time processing pipeline using RTP_APP interfaces. The comments with bold alphabet indicate a part of the script explained in the main text. Instantiating the RTP_APP class <bold>(A)</bold> creates all processing modules inside it. If you use the “<monospace>make_masks</monospace>” method to create the mask images, call the method of the rtp_app instance <bold>(B)</bold>. This example uses dummy physiological signals <bold>(C)</bold>. The module properties can be set directly by accessing the “<monospace>rtp_app.rtp_obj</monospace>” property <bold>(C)</bold> or by feeding a property dictionary to the “<monospace>rtp_app.RTP_setup</monospace>” method <bold>(D,F)</bold>. If physiological signals are not available, you can disable RETROICOR by setting the “<monospace>phys_reg</monospace>” property of “<monospace>REGRESS</monospace>” to “<monospace>None</monospace>” <bold>(E)</bold>. Calling the “<monospace>rtp_app.ready_to_run</monospace>” initializes the pipeline <bold>(G)</bold>. The processing can be started by calling the “<monospace>manual_start</monospace>” method <bold>(H)</bold>. To close the pipeline, call the “<monospace>end_run</monospace>” method <bold>(I)</bold>.</p>
          </caption>
          <graphic xlink:href="fnins-16-834827-g006" position="float"/>
        </fig>
        <p>Properties of the modules in a pipeline can be directly accessed and set by the module instances (<xref rid="F5" ref-type="fig">Figure 5D</xref>). For example, “<monospace>volreg</monospace>” and “<monospace>mask_src_proc</monospace>” is set to rtp_regress to receive motion parameters and unsmoothed image data, which are used to create a motion regressor and an average signal regressor in a segmented mask. The “<monospace>save_proc</monospace>” property (saving the processed volume data in a NIfTI file) and “<monospace>online_saving</monospace>” property (saving is done at each volume) are also set for rtp_regress to save the processed volume image in a file. When the “<monospace>online_saving</monospace>” property is set True, the processed image at each volume is saved in real-time. The online saving is done after the downstream processing of the pipeline is completed so as not to affect the real-time performance of the pipeline processing.</p>
        <p>Calling the “<monospace>redy_proc</monospace>” method initialize the pipeline (<xref rid="F5" ref-type="fig">Figure 5E</xref>). The processing is run by feeding a NiBabel Nifti1Image object to the “<monospace>do_proc</monospace>” method of the pipeline (<xref rid="F5" ref-type="fig">Figure 5F</xref>). The pipeline is closed by calling the “<monospace>end_reset</monospace>” method (<xref rid="F5" ref-type="fig">Figure 5G</xref>), and then a concatenated image file is saved in a file. These low-level interfaces could be useful to develop custom input and output modules by users.</p>
      </sec>
      <sec id="S5.SS1.SSS2">
        <title>High-Level Interface With RTP_APP</title>
        <p>RTPSpy also offers high-level utility methods in RTP_APP. <xref rid="F6" ref-type="fig">Figure 6</xref> shows a snippet of an example script to run a real-time processing pipeline using RTP_APP interfaces. Refer also to the system check script in the package (rtpspy_system_check.py) for a complete script. Instantiating the RTP_APP class (<xref rid="F6" ref-type="fig">Figure 6A</xref>) creates all processing modules automatically inside it. The processing modules can be accessed by “<monospace>rtp_app.rtp_obj[‘TSHIFT’]</monospace>” for RTP_TSHIFT, for example. If you use the “<monospace>make_masks</monospace>” method to create the mask images, call the method of the rtp_app instance (<xref rid="F6" ref-type="fig">Figure 6B</xref>). Then, the properties of the mask files, RTP_SMOOTH.mask_file, RTP_REGRESS.mask_file, RTP_REGRESS.GS_mask (global signal mask), RTP_REGRESS.WM_mask, RTP_REGRESS. Vent_mask, and RTP_APP.ROI_mask are automatically set. The module properties can also be set directly by accessing the “<monospace>rtp_app.rtp_obj</monospace>” property (e.g., <xref rid="F6" ref-type="fig">Figure 6C</xref>) or by feeding a dictionary to the “<monospace>rtp_app.RTP_setup</monospace>” method (<xref rid="F6" ref-type="fig">Figures 6D,F</xref>). You can set a custom mask using these interfaces when you want to set a mask without using the “<monospace>make_masks</monospace>” method. The order of the pipeline cannot be modified in this interface, but you can disable a specific module by setting the “<monospace>enables</monospace>” property False (e.g., <xref rid="F8" ref-type="fig">Figure 8A</xref>). This example uses dummy physiological signals (<xref rid="F6" ref-type="fig">Figure 6C</xref>) to simulate the cardiac and respiration signal recordings. If these signals are not available, set the “<monospace>phys_reg</monospace>” property of “<monospace>REGRESS</monospace>” to “<monospace>None</monospace>” (<xref rid="F6" ref-type="fig">Figure 6E</xref>). All the properties and possible parameters are described in the script files of each module (see <xref rid="T2" ref-type="table">Table 2</xref> for the filenames). The pipeline creation is done in the “<monospace>rtp_app. RTP_setup</monospace>” method. The “<monospace>save_proc</monospace>” property of the last module (e.g., RTP_REGRESS) is automatically set True, and the RTP_APP object is connected after the last module in the “<monospace>rtp_app.RTP_setup</monospace>” method.</p>
        <p>Calling the “<monospace>rtp_app.ready_to_run</monospace>” initializes the pipeline (<xref rid="F6" ref-type="fig">Figure 6G</xref>). The processing can be started by calling the “<monospace>manual_start</monospace>” method (<xref rid="F6" ref-type="fig">Figure 6H</xref>), and then the RTP_WATCH module starts watching a new file in the watched directory. The start of the processing can also be triggered by a TTL signal implemented in the RTP_SCANONSET module (rtp_scanonset.py file). To close the pipeline, call the “<monospace>end_run</monospace>” method (<xref rid="F6" ref-type="fig">Figure 6I</xref>), then the WATCH module stops monitoring, and the online processed data is saved in a file.</p>
        <p>To customize the feedback signal calculation, you can modify the “<monospace>do_proc</monospace>” method in RTP_APP (rtp_app.py). The RTP_APP module works as a pipeline terminal, receiving the processed data, extracting the neurofeedback signal, and sending the signal to an external application. By default, it extracts the mean signal in the ROI mask, but it can be overridden according to the individual application need. An example way to make a customized application class is shown in Section “An Example Graphical User Interface Application Integrating the RTPSpy Modules,” and <xref rid="F10" ref-type="fig">Figure 10</xref>.</p>
      </sec>
    </sec>
    <sec id="S5.SS2">
      <title>Example Real-Time fMRI Session</title>
      <p><xref rid="F7" ref-type="fig">Figure 7</xref> presents an example procedure of a real-time fMRI (rtfMRI) session. Note, this is not a requirement for the library but only an example of a single-visit session and anatomically-defined neurofeedback target region. The rtfMRI session using RTPSpy could start with an anatomical image scan and a reference functional image scan to make the mask images. We usually perform a resting-state scan after an anatomical scan, and an initial image of the resting-state scan acquired in real-time is used as the reference function image. A pre-acquired anatomical image can also be used in the processing if the study is multi-visits and an anatomical image has been scanned previously. The mask creation using the “<monospace>make_masks</monospace>” method in RTP_APP can be finished during the resting-state scan so that no waiting time is required for a participant. If no resting-state scan is necessary, a short functional scan with the same imaging parameters as the neurofeedback runs can also be used. Then, you can set the RTP parameters, run the “<monospace>RTP_setup</monospace>” and “<monospace>ready_to_run</monospace>” methods, and start the neurofeedback scan.</p>
      <fig position="float" id="F7">
        <label>FIGURE 7</label>
        <caption>
          <p>Example of real-time fMRI session procedure with RTPSpy. This is an example session and not a requirement for library use.</p>
        </caption>
        <graphic xlink:href="fnins-16-834827-g007" position="float"/>
      </fig>
      <p>A critical RTP property related to the task design is the “<monospace>wait_num</monospace>” in RTP_REGRESS. This property determines how many volumes the module waits before starting the regression. The task block should start after this burn-in time. Note that this number does not include the initial volumes discarded before the fMRI signal reaches a steady state. The “<monospace>wait_num</monospace>” must be larger than the number of regressors, but the just enough number is not enough because the regression with small samples overfits the data, resulting in a very small variance in the denoised output (<xref rid="B14" ref-type="bibr">Misaki et al., 2015</xref>). The actual number of required samples depends on the number of regressors and the target region. This waiting time could limit the neurofeedback task design. However, using a noise-contaminated signal as neurofeedback has a high risk of artifactual training effect (<xref rid="B27" ref-type="bibr">Weiss et al., 2020</xref>), which may degrade the validity of an experiment. Therefore, the online image processing should include necessary noise regressors, and the task design should accept the initial burn-in time. A simulation analysis would help determine the necessary noise regressors and the optimal number of waiting TRs. Our previous report (<xref rid="B13" ref-type="bibr">Misaki and Bodurka, 2021</xref>), investigating what brain regions and connectivity were more contaminated with noises as well as the effect of each noise regressor to reduce the noise, may also help. The volumes during the burn-in time are processed at the beginning of RTP_REGRESS processing (thus, the first processing time of RTP_REGRESS could take long, as shown in Figure 4 of <xref rid="B13" ref-type="bibr">Misaki and Bodurka (2021)</xref>. These volumes can be used, for example, for the baseline calculation to scale the neurofeedback signal (<xref rid="B29" ref-type="bibr">Zotev et al., 2011</xref>; <xref rid="B28" ref-type="bibr">Young et al., 2017</xref>).</p>
    </sec>
  </sec>
  <sec id="S6">
    <title>Simulating Real-Time fMRI Processing</title>
    <p>One of the most effective ways to examine the integrity of real-time signal calculation is to simulate online processing and neurofeedback signal calculation using previously obtained fMRI data (<xref rid="B18" ref-type="bibr">Ramot and Gonzalez-Castillo, 2019</xref>; <xref rid="B15" ref-type="bibr">Misaki et al., 2020</xref>; <xref rid="B13" ref-type="bibr">Misaki and Bodurka, 2021</xref>). Assuring the integrity of online noise reduction is critical for neurofeedback training. If the noise reduction is insufficient, other factors than brain activation could confound the training effect (<xref rid="B27" ref-type="bibr">Weiss et al., 2020</xref>). Not only for the online image processing, but the feedback signal calculation also can be unique in the online analysis, for example, in the connectivity neurofeedback. The online connectivity calculation should use a short window width for a timely feedback signal reflecting the current brain state, and the optimal window width for the neurofeedback training would be specific to the target region and the task design (<xref rid="B15" ref-type="bibr">Misaki et al., 2020</xref>). In addition, simulating the signal processing is useful to evaluate the level of the actual feedback signal. For example, when the baseline level of the neurofeedback signal is adjusted by a mean signal in the preceding rest block (<xref rid="B29" ref-type="bibr">Zotev et al., 2011</xref>; <xref rid="B28" ref-type="bibr">Young et al., 2017</xref>), simulating such signal calculation could help to estimate a possible signal range to adjust a feedback presentation.</p>
    <p>The modular library design of the RTPSpy helps perform a simulation with a simple script. While the simulation can be done by copying the data volume-by-volume into the watched directory, you can also inject the data directly into the pipeline for faster simulation. An example simulation script is provided as the “<monospace>example/Simulation/rtpspy_simulation.py</monospace>” file in the package. <xref rid="F8" ref-type="fig">Figure 8</xref> shows a snippet of the example simulation script. The pipeline creation is the same as shown in <xref rid="F6" ref-type="fig">Figure 6</xref> except for disabling the RTP_WATCH module (<xref rid="F8" ref-type="fig">Figure 8A</xref>) and getting the pipeline object returned from the “<monospace>ready_to_run</monospace>” method (<xref rid="F8" ref-type="fig">Figure 8B</xref>). The simulation can proceed with feeding the Nibabel Nifti1Image object to the “<monospace>do_proc</monospace>” method of the pipeline (<xref rid="F8" ref-type="fig">Figure 8C</xref>). This method receives a volume image, image index (optional), and the end time of the previous process (optional). Calling the “<monospace>end_run</monospace>” method closes the pipeline and returns the saved filenames (<xref rid="F8" ref-type="fig">Figure 8D</xref>). The output files include the parameter log (text file), ROI signal time-series (csv file), and the denoised image saved as a NIfTI file. You can modify the neurofeedback signal calculation by overriding the do_proc method in the RTP_APP, as explained in the next section, <xref rid="F10" ref-type="fig">Figure 10</xref>.</p>
    <fig position="float" id="F8">
      <label>FIGURE 8</label>
      <caption>
        <p>A snippet of an example script of running a real-time fMRI processing simulation with RTPSpy. The comments with bold alphabet indicate a part of the script explained in the main text. The pipeline creation is the same as shown in <xref rid="F6" ref-type="fig">Figure 6</xref> except for disabling the RTP_WATCH module <bold>(A)</bold> and returning the pipeline object from the “<monospace>ready_to_run</monospace>” method <bold>(B)</bold>. The simulation can proceed with feeding the Nibabel Nifti1Image object to the “<monospace>do_proc</monospace>” method of the pipeline <bold>(C)</bold>. Calling the “<monospace>end_run</monospace>” method closes the pipeline and returns the saved filenames <bold>(D)</bold>.</p>
      </caption>
      <graphic xlink:href="fnins-16-834827-g008" position="float"/>
    </fig>
  </sec>
  <sec id="S7">
    <title>An Example Graphical User Interface Application Integrating the RTPSpy Modules</title>
    <p>RTPSpy offers a graphical user interface (GUI) class (RTP_UI, rtp_ui.py) for easy access to the module functions. The example GUI application is provided in the “<monospace>example/ROI-NF</monospace>” directory in the package. <xref rid="F9" ref-type="fig">Figure 9</xref> shows the initial window of this example application. This application is presented for demonstrating how the RTPSpy library can be used to build a custom application and as a boilerplate for making a custom application by a user. This section explains how these example scripts can be modified to make a custom application. For a step-by-step usage of this application other than scripting, please refer to GitHub (see text footnote 1).</p>
    <fig position="float" id="F9">
      <label>FIGURE 9</label>
      <caption>
        <p>A view of the example GUI application integrating the RTPSpy modules. The figure presents the “<monospace>mask creation</monospace>” tab to run the make_masks process with GUI. The example application also offers graphical interfaces to almost all parameters in RTPSpy. Detailed usage of the application is presented in GitHub (see text footnote 1).</p>
      </caption>
      <graphic xlink:href="fnins-16-834827-g009" position="float"/>
    </fig>
    <p>The application development can start with defining a user’s own application class inheriting from the RTP_APP. <xref rid="F10" ref-type="fig">Figure 10</xref> shows the code snippet from the “<monospace>roi_nf.py</monospace>” script file. In this application, ROI_NF class is defined by inheriting RTP_APP class (<xref rid="F10" ref-type="fig">Figure 10A</xref>). Neurofeedback signal extraction is performed in the “<monospace>do_proc</monospace>” method in the ROI_NF class (<xref rid="F10" ref-type="fig">Figure 10B</xref>). To customize the neurofeedback signal calculation, a user should override this method. The example script calculates the mean value within the ROI mask (<xref rid="F10" ref-type="fig">Figure 10D</xref>). The ROI mask file is defined in the “<monospace>ROI_orig</monospace>” property defined in the RTP_APP class (<xref rid="F10" ref-type="fig">Figure 10C</xref>). If an external application implements the RTP_SERV module, the signal can be sent to it using the “<monospace>send_extApp</monospace>” method (<xref rid="F10" ref-type="fig">Figure 10F</xref>) by putting a signal value in a specific format string (<xref rid="F10" ref-type="fig">Figure 10E</xref>).</p>
    <fig position="float" id="F10">
      <label>FIGURE 10</label>
      <caption>
        <p>A snippet of an example script of customized neurofeedback signal extraction and sending the signal to an external application in the “<monospace>example/ROI-NF/roi_nf.py</monospace>” file. The comments with bold alphabet indicate a part of the script explained in the main text. ROI_NF class is defined by inheriting RTP_APP class <bold>(A)</bold>. Neurofeedback signal extraction is performed in the “<monospace>do_proc</monospace>” method <bold>(B)</bold>. The example script calculates the mean value within the ROI mask <bold>(D)</bold>. The ROI mask file is defined in the “<monospace>ROI_orig</monospace>” property <bold>(C)</bold>. The signal can be sent to an external application in real-time using the “<monospace>send_extApp</monospace>” method <bold>(F)</bold> by putting it in a specific format string <bold>(E)</bold>.</p>
      </caption>
      <graphic xlink:href="fnins-16-834827-g010" position="float"/>
    </fig>
    <p><xref rid="F11" ref-type="fig">Figure 11</xref> shows the code snippet of an example external application script for neurofeedback presentation (“<monospace>example/ROI-NF/NF_psypy.py</monospace>” file). This is an independent PsychoPy<sup><xref rid="footnote18" ref-type="fn">18</xref></sup> application from RTPspy but uses the RTP_SERVE module to communicate with an RTPSpy application. Instantiating the RTP_SERVE class object starts a TCP/IP server running in another thread (<xref rid="F11" ref-type="fig">Figure 11A</xref>). This class does all the data exchange in the background. The RTP_SERVE object holds the received neurofeedback data in the pandas data frame<sup><xref rid="footnote19" ref-type="fn">19</xref></sup> (<xref rid="F11" ref-type="fig">Figure 11B</xref>). While this example script just displays the latest received value on the screen with text (<xref rid="F11" ref-type="fig">Figure 11C</xref>), users can modify this part to make a decent feedback presentation.</p>
    <fig position="float" id="F11">
      <label>FIGURE 11</label>
      <caption>
        <p>A snippet of an example script of neurofeedback presentation application in the “<monospace>example/ROI-NF/NF_psypy.py</monospace>” file. The comments with bold alphabet indicate a part of the script explained in the main text. Instantiating the RTP_SERV class object starts a TCP/IP server running in another thread <bold>(A)</bold>. The RTP_SERVE object holds the received neurofeedback data in the pandas data frame <bold>(B)</bold>. This example script displays the latest received value on the screen with text <bold>(C)</bold>.</p>
      </caption>
      <graphic xlink:href="fnins-16-834827-g011" position="float"/>
    </fig>
    <p>In this example application, the GUI operation can be done in parallel to the online image processing as the watchdog in the RTP_WATCH module runs in a separate thread, on which the processing runs. The anatomical image processing tools and a neurofeedback presentation application run on independent processes. Thus, they also run in parallel for a user to operate RTPSpy while an experiment is running. Using these example scripts, a user can develop an easy-to-use and highly customized rtfMRI application with minimum scripting labor. We also provide a full-fledged application of the left-amygdala neurofeedback session (<xref rid="B29" ref-type="bibr">Zotev et al., 2011</xref>; <xref rid="B28" ref-type="bibr">Young et al., 2017</xref>) in the “<monospace>example/LA-NF</monospace>” directory, which is explained in the <xref rid="DS1" ref-type="supplementary-material">Supplementary Material</xref>, “<monospace>LA-NF application</monospace>” and in GitHub (see text footnote 1).</p>
  </sec>
  <sec id="S8">
    <title>Limitations and Environment-Specific Issues</title>
    <p>While the RTPSpy provides general-use libraries for rtfMRI data processing, it is not a complete toolset for all environments. There could be several site-specific settings that a general library cannot support. One of the first critical settings is to obtain a reconstructed MRI image in real-time. The image format, the saved directory, and how to access the data (e.g., network mount or copying to the processing PC) could differ across manufacturers and sites. The RTP_WATCH detects a new file in the watched directory, but setting up the environment to put an fMRI file to an accessible place in real-time is not covered by the library. Specifically, our site uses AFNI’s Dimon command<sup><xref rid="footnote20" ref-type="fn">20</xref></sup> running on the scanner console computer and receives the data sent by Dimon with AFNI’s realtime plugin on a rtfMRI operation computer. This is not a part of the RTPSpy library and may not be possible for all if one cannot install additional software on the scanner console. Users may have to set up real-time access to the reconstructed image according to their environment.</p>
    <p>Another caveat of environment-specific implementation is physiological signal recording. One of the advantages of the RTPSpy is its ability to run a physiological noise regression with RETROICOR in real-time. However, the equipment for cardiac and respiration signal recording could vary across the sites and manufacturer. In our site, we measure a cardiac signal using a photoplethysmography with an infrared emitter placed under the pad of a participant’s finger and respiration using a pneumatic respiration belt. These are equipped with the MRI scanner, GE MR750, and the signal is bypassed to the processing PC <italic>via</italic> serial port. Although we developed an interface class for these signals as RTP_PHYSIO, its implementation is highly optimized for our environment. A user may need to develop a custom script to replace the RTP_PHYSIO module adjusting to the individual environment. Similarly, detection of the TTL signal of a scan start, which is defined in the custom RTP_SCANONSET class, is device-dependent and needs to be implemented by a user according to the user’s device.</p>
    <p>RTPSpy depends on several external tools for its anatomical image processing stream. Indeed, the package does not intend to provide an all-around solution by itself. Rather, RTPSpy is supposed to be used as a part of the user’s own application project. A required function specific to each application or environment should be implemented by an external tool or developed by users. We assume that the RTPSpy is used not as a complete package by itself but as a part of a custom application.</p>
  </sec>
  <sec sec-type="conclusion" id="S9">
    <title>Conclusion</title>
    <p>RTPSpy is a library for real-time fMRI processing, including comprehensive online fMRI processing, fast and accurate anatomical image processing, and a simulation system for optimizing neurofeedback signals. RTPSpy focuses on providing the building blocks to make a highly customized rtfMRI system. It also provides an example GUI application wrapped around RTPSpy modules. Although a library package requiring scripting skills may not be easy to use for everyone, we believe that RTPSpy’s modular architecture and easy-to-script interface will benefit developers who want to create customized rtfMRI applications. With its rich toolset and highly modular architecture, RTPSpy must be an attractive choice for developing optimized rtfMRI applications.</p>
  </sec>
  <sec sec-type="data-availability" id="S10">
    <title>Data Availability Statement</title>
    <p>The code and example data can be found here: <ext-link xlink:href="https://github.com/mamisaki/RTPSpy" ext-link-type="uri">https://github.com/mamisaki/RTPSpy</ext-link>.</p>
  </sec>
  <sec id="S11">
    <title>Ethics Statement</title>
    <p>The studies involving human participants were reviewed and approved by Western Institutional Review Board. The patients/participants provided their written informed consent to participate in this study.</p>
  </sec>
  <sec id="S12">
    <title>Author Contributions</title>
    <p>MM: conceptualization, data curation, formal analysis, investigation, methodology, software, writing–original draft, and writing–review and editing. JB: conceptualization, funding acquisition, investigation, methodology, software, project administration, and supervision. MP: conceptualization, funding acquisition, project administration, supervision, and writing–review and editing. All authors contributed to the article and approved the submitted version.</p>
  </sec>
  <sec sec-type="COI-statement" id="conf1">
    <title>Conflict of Interest</title>
    <p>The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p>
  </sec>
  <sec sec-type="disclaimer" id="pudiscl1">
    <title>Publisher’s Note</title>
    <p>All claims expressed in this article are solely those of the authors and do not necessarily represent those of their affiliated organizations, or those of the publisher, the editors and the reviewers. Any product that may be evaluated in this article, or claim that may be made by its manufacturer, is not guaranteed or endorsed by the publisher.</p>
  </sec>
</body>
<back>
  <sec sec-type="funding-information" id="S13">
    <title>Funding</title>
    <p>This research was supported by the Laureate Institute for Brain Research (LIBR) and the William K Warren Foundation. The funding agencies were not involved in the design of the experiment, data collection and analysis, interpretation of results, and preparation and submission of the manuscript.</p>
  </sec>
  <ack>
    <p>We dedicate this work in memory and honor of the late JB.</p>
  </ack>
  <fn-group>
    <fn id="footnote1">
      <label>1</label>
      <p>
        <ext-link xlink:href="https://github.com/mamisaki/RTPSpy/tree/main/example/ROI-NF" ext-link-type="uri">https://github.com/mamisaki/RTPSpy/tree/main/example/ROI-NF</ext-link>
      </p>
    </fn>
    <fn id="footnote2">
      <label>2</label>
      <p>
        <ext-link xlink:href="https://afni.nimh.nih.gov/" ext-link-type="uri">https://afni.nimh.nih.gov/</ext-link>
      </p>
    </fn>
    <fn id="footnote3">
      <label>3</label>
      <p>
        <ext-link xlink:href="http://stnava.github.io/ANTs/" ext-link-type="uri">http://stnava.github.io/ANTs/</ext-link>
      </p>
    </fn>
    <fn id="footnote4">
      <label>4</label>
      <p>
        <ext-link xlink:href="https://github.com/mamisaki/RTPSpy" ext-link-type="uri">https://github.com/mamisaki/RTPSpy</ext-link>
      </p>
    </fn>
    <fn id="footnote5">
      <label>5</label>
      <p>
        <ext-link xlink:href="https://docs.conda.io" ext-link-type="uri">https://docs.conda.io</ext-link>
      </p>
    </fn>
    <fn id="footnote6">
      <label>6</label>
      <p>
        <ext-link xlink:href="https://www.anaconda.com/" ext-link-type="uri">https://www.anaconda.com/</ext-link>
      </p>
    </fn>
    <fn id="footnote7">
      <label>7</label>
      <p>
        <ext-link xlink:href="https://deep-mi.org/research/fastsurfer/" ext-link-type="uri">https://deep-mi.org/research/fastsurfer/</ext-link>
      </p>
    </fn>
    <fn id="footnote8">
      <label>8</label>
      <p>
        <ext-link xlink:href="https://pypi.org/project/antspyx/" ext-link-type="uri">https://pypi.org/project/antspyx/</ext-link>
      </p>
    </fn>
    <fn id="footnote9">
      <label>9</label>
      <p>
        <ext-link xlink:href="https://developer.nvidia.com/cuda-toolkit" ext-link-type="uri">https://developer.nvidia.com/cuda-toolkit</ext-link>
      </p>
    </fn>
    <fn id="footnote10">
      <label>10</label>
      <p>
        <ext-link xlink:href="https://nipy.org/nibabel/" ext-link-type="uri">https://nipy.org/nibabel/</ext-link>
      </p>
    </fn>
    <fn id="footnote11">
      <label>11</label>
      <p>
        <ext-link xlink:href="https://pythonhosted.org/watchdog/index.html" ext-link-type="uri">https://pythonhosted.org/watchdog/index.html</ext-link>
      </p>
    </fn>
    <fn id="footnote12">
      <label>12</label>
      <p>
        <ext-link xlink:href="https://afni.nimh.nih.gov/pub/dist/doc/program_help/3dvolreg.html" ext-link-type="uri">https://afni.nimh.nih.gov/pub/dist/doc/program_help/3dvolreg.html</ext-link>
      </p>
    </fn>
    <fn id="footnote13">
      <label>13</label>
      <p>
        <ext-link xlink:href="https://afni.nimh.nih.gov/pub/dist/doc/program_help/3dBlurInMask.html" ext-link-type="uri">https://afni.nimh.nih.gov/pub/dist/doc/program_help/3dBlurInMask.html</ext-link>
      </p>
    </fn>
    <fn id="footnote14">
      <label>14</label>
      <p>
        <ext-link xlink:href="https://pytorch.org/" ext-link-type="uri">https://pytorch.org/</ext-link>
      </p>
    </fn>
    <fn id="footnote15">
      <label>15</label>
      <p>
        <ext-link xlink:href="https://freesurfer.net/" ext-link-type="uri">https://freesurfer.net/</ext-link>
      </p>
    </fn>
    <fn id="footnote16">
      <label>16</label>
      <p>
        <ext-link xlink:href="https://github.com/mamisaki/FastSeg" ext-link-type="uri">https://github.com/mamisaki/FastSeg</ext-link>
      </p>
    </fn>
    <fn id="footnote17">
      <label>17</label>
      <p>
        <ext-link xlink:href="https://github.com/ANTsX/ANTsPy" ext-link-type="uri">https://github.com/ANTsX/ANTsPy</ext-link>
      </p>
    </fn>
    <fn id="footnote18">
      <label>18</label>
      <p>
        <ext-link xlink:href="https://www.psychopy.org" ext-link-type="uri">https://www.psychopy.org</ext-link>
      </p>
    </fn>
    <fn id="footnote19">
      <label>19</label>
      <p>
        <ext-link xlink:href="https://pandas.pydata.org/" ext-link-type="uri">https://pandas.pydata.org/</ext-link>
      </p>
    </fn>
    <fn id="footnote20">
      <label>20</label>
      <p>
        <ext-link xlink:href="https://afni.nimh.nih.gov/pub/dist/doc/program_help/Dimon.html" ext-link-type="uri">https://afni.nimh.nih.gov/pub/dist/doc/program_help/Dimon.html</ext-link>
      </p>
    </fn>
  </fn-group>
  <sec sec-type="supplementary-material" id="S15">
    <title>Supplementary Material</title>
    <p>The Supplementary Material for this article can be found online at: <ext-link xlink:href="https://www.frontiersin.org/articles/10.3389/fnins.2022.834827/full#supplementary-material" ext-link-type="uri">https://www.frontiersin.org/articles/10.3389/fnins.2022.834827/full#supplementary-material</ext-link></p>
    <supplementary-material id="DS1" position="float" content-type="local-data">
      <media xlink:href="Data_Sheet_1.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
  <ref-list>
    <title>References</title>
    <ref id="B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bagarinao</surname><given-names>E.</given-names></name><name><surname>Matsuo</surname><given-names>K.</given-names></name><name><surname>Nakai</surname><given-names>T.</given-names></name><name><surname>Sato</surname><given-names>S.</given-names></name></person-group> (<year>2003</year>). <article-title>Estimation of general linear model coefficients for real-time application.</article-title>
<source><italic>Neuroimage</italic></source>
<volume>19</volume>
<fpage>422</fpage>–<lpage>429</lpage>. <pub-id pub-id-type="doi">10.1016/s1053-8119(03)00081-8</pub-id>
<?supplied-pmid 12814591?><pub-id pub-id-type="pmid">12814591</pub-id></mixed-citation>
    </ref>
    <ref id="B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Birn</surname><given-names>R. M.</given-names></name><name><surname>Smith</surname><given-names>M. A.</given-names></name><name><surname>Jones</surname><given-names>T. B.</given-names></name><name><surname>Bandettini</surname><given-names>P. A.</given-names></name></person-group> (<year>2008</year>). <article-title>The respiration response function: the temporal dynamics of fmri signal fluctuations related to changes in respiration.</article-title>
<source><italic>Neuroimage</italic></source>
<volume>40</volume>
<fpage>644</fpage>–<lpage>654</lpage>.<pub-id pub-id-type="pmid">18234517</pub-id></mixed-citation>
    </ref>
    <ref id="B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cox</surname><given-names>R. W.</given-names></name><name><surname>Jesmanowicz</surname><given-names>A.</given-names></name><name><surname>Hyde</surname><given-names>J. S.</given-names></name></person-group> (<year>1995</year>). <article-title>Real-time functional magnetic resonance imaging.</article-title>
<source><italic>Magn. Reson. Med.</italic></source>
<volume>33</volume>
<fpage>230</fpage>–<lpage>236</lpage>. <pub-id pub-id-type="doi">10.1002/mrm.1910330213</pub-id>
<?supplied-pmid 7707914?><pub-id pub-id-type="pmid">7707914</pub-id></mixed-citation>
    </ref>
    <ref id="B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Glover</surname><given-names>G. H.</given-names></name><name><surname>Li</surname><given-names>T. Q.</given-names></name><name><surname>Ress</surname><given-names>D.</given-names></name></person-group> (<year>2000</year>). <article-title>Image-based method for retrospective correction of physiological motion effects in fmri: retroicor.</article-title>
<source><italic>Magn. Reson. Med.</italic></source>
<volume>44</volume>
<fpage>162</fpage>–<lpage>167</lpage>.<pub-id pub-id-type="pmid">10893535</pub-id></mixed-citation>
    </ref>
    <ref id="B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goebel</surname><given-names>R.</given-names></name></person-group> (<year>2012</year>). <article-title>Brainvoyager–past, present, future.</article-title>
<source><italic>Neuroimage</italic></source>
<volume>62</volume>
<fpage>748</fpage>–<lpage>756</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2012.01.083</pub-id>
<?supplied-pmid 22289803?><pub-id pub-id-type="pmid">22289803</pub-id></mixed-citation>
    </ref>
    <ref id="B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goebel</surname><given-names>R.</given-names></name><name><surname>Zilverstand</surname><given-names>A.</given-names></name><name><surname>Sorger</surname><given-names>B.</given-names></name></person-group> (<year>2010</year>). <article-title>Real-time fmri-based brain-computer interfacing for neurofeedback therapy and compensation of lost motor functions.</article-title>
<source><italic>Imag. Med.</italic></source>
<volume>2</volume>
<fpage>407</fpage>–<lpage>415</lpage>. <pub-id pub-id-type="doi">10.2217/iim.10.35</pub-id></mixed-citation>
    </ref>
    <ref id="B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Henschel</surname><given-names>L.</given-names></name><name><surname>Conjeti</surname><given-names>S.</given-names></name><name><surname>Estrada</surname><given-names>S.</given-names></name><name><surname>Diers</surname><given-names>K.</given-names></name><name><surname>Fischl</surname><given-names>B.</given-names></name><name><surname>Reuter</surname><given-names>M.</given-names></name></person-group> (<year>2020</year>). <article-title>Fastsurfer - a fast and accurate deep learning based neuroimaging pipeline.</article-title>
<source><italic>Neuroimage</italic></source>
<volume>219</volume>:<issue>117012</issue>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2020.117012</pub-id>
<?supplied-pmid 32526386?><pub-id pub-id-type="pmid">32526386</pub-id></mixed-citation>
    </ref>
    <ref id="B8">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Heunis</surname><given-names>S.</given-names></name><name><surname>Besseling</surname><given-names>R.</given-names></name><name><surname>Lamerichs</surname><given-names>R.</given-names></name><name><surname>de Louw</surname><given-names>A.</given-names></name><name><surname>Breeuwer</surname><given-names>M.</given-names></name><name><surname>Aldenkamp</surname><given-names>B.</given-names></name><etal/></person-group> (<year>2018</year>). <article-title>Neu(3)Ca-Rt: a framework for real-time fmri analysis.</article-title>
<source><italic>Psychiatry Res. Neuroi.</italic></source>
<volume>282</volume>
<fpage>90</fpage>–<lpage>102</lpage>. <pub-id pub-id-type="doi">10.1016/j.pscychresns.2018.09.008</pub-id>
<?supplied-pmid 30293911?><pub-id pub-id-type="pmid">30293911</pub-id></mixed-citation>
    </ref>
    <ref id="B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kiebel</surname><given-names>S. J.</given-names></name><name><surname>Kloppel</surname><given-names>S.</given-names></name><name><surname>Weiskopf</surname><given-names>N.</given-names></name><name><surname>Friston</surname><given-names>K. J.</given-names></name></person-group> (<year>2007</year>). <article-title>Dynamic causal modeling: a generative model of slice timing in fmri.</article-title>
<source><italic>Neuroimage</italic></source>
<volume>34</volume>
<fpage>1487</fpage>–<lpage>1496</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2006.10.026</pub-id>
<?supplied-pmid 17161624?><pub-id pub-id-type="pmid">17161624</pub-id></mixed-citation>
    </ref>
    <ref id="B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Koush</surname><given-names>Y.</given-names></name><name><surname>Ashburner</surname><given-names>J.</given-names></name><name><surname>Prilepin</surname><given-names>E.</given-names></name><name><surname>Sladky</surname><given-names>R.</given-names></name><name><surname>Zeidman</surname><given-names>P.</given-names></name><name><surname>Bibikov</surname><given-names>S.</given-names></name><etal/></person-group> (<year>2017</year>). <article-title>Opennft: an open-source python/matlab framework for real-time fmri neurofeedback training based on activity.</article-title>
<source><italic>Connect. Multiv. Pattern Analy. Neuroi.</italic></source>
<volume>156</volume>
<fpage>489</fpage>–<lpage>503</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2017.06.039</pub-id>
<?supplied-pmid 28645842?><pub-id pub-id-type="pmid">28645842</pub-id></mixed-citation>
    </ref>
    <ref id="B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kumar</surname><given-names>M.</given-names></name><name><surname>Michael</surname><given-names>A.</given-names></name><name><surname>Antony</surname><given-names>J.</given-names></name><name><surname>Baldassano</surname><given-names>C.</given-names></name><name><surname>Brooks</surname><given-names>P. P.</given-names></name><name><surname>Cai</surname><given-names>M. B.</given-names></name><etal/></person-group> (<year>2021</year>). <source><italic>Brainiak: The Brain Imaging Analysis Kit. Aperture Neuro.</italic></source> Available online at: <ext-link xlink:href="https://apertureneuropub.cloud68.co/articles/42/index.html" ext-link-type="uri">https://apertureneuropub.cloud68.co/articles/42/index.html</ext-link></mixed-citation>
    </ref>
    <ref id="B12">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>MacInnes</surname><given-names>J. J.</given-names></name><name><surname>Adcock</surname><given-names>R. A.</given-names></name><name><surname>Stocco</surname><given-names>A.</given-names></name><name><surname>Prat</surname><given-names>C. S.</given-names></name><name><surname>Rao</surname><given-names>R. P. N.</given-names></name><name><surname>Dickerson</surname><given-names>K. C.</given-names></name></person-group> (<year>2020</year>). <article-title>Pyneal: open source real-time fmri software.</article-title>
<source><italic>Front. Neurosci.</italic></source>
<volume>14</volume>:<issue>900</issue>. <pub-id pub-id-type="doi">10.3389/fnins.2020.00900</pub-id>
<?supplied-pmid 33041750?><pub-id pub-id-type="pmid">33041750</pub-id></mixed-citation>
    </ref>
    <ref id="B13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Misaki</surname><given-names>M.</given-names></name><name><surname>Bodurka</surname><given-names>J.</given-names></name></person-group> (<year>2021</year>). <article-title>The impact of real-time fmri denoising on online evaluation of brain activity and functional connectivity.</article-title>
<source><italic>J. Neural. Eng.</italic></source>
<volume>18</volume>:<issue>20210701</issue>. <pub-id pub-id-type="doi">10.1088/1741-2552/ac0b33</pub-id>
<?supplied-pmid 34126595?><pub-id pub-id-type="pmid">34126595</pub-id></mixed-citation>
    </ref>
    <ref id="B14">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Misaki</surname><given-names>M.</given-names></name><name><surname>Barzigar</surname><given-names>N.</given-names></name><name><surname>Zotev</surname><given-names>V.</given-names></name><name><surname>Phillips</surname><given-names>R.</given-names></name><name><surname>Cheng</surname><given-names>S.</given-names></name><name><surname>Bodurka</surname><given-names>J.</given-names></name></person-group> (<year>2015</year>). <article-title>Real-time fmri processing with physiological noise correction - comparison with off-line analysis.</article-title>
<source><italic>J. Neurosci. Methods</italic></source>
<volume>256</volume>
<fpage>117</fpage>–<lpage>121</lpage>. <pub-id pub-id-type="doi">10.1016/j.jneumeth.2015.08.033</pub-id>
<?supplied-pmid 26343529?><pub-id pub-id-type="pmid">26343529</pub-id></mixed-citation>
    </ref>
    <ref id="B15">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Misaki</surname><given-names>M.</given-names></name><name><surname>Tsuchiyagaito</surname><given-names>A.</given-names></name><name><surname>Al Zoubi</surname><given-names>O.</given-names></name><name><surname>Paulus</surname><given-names>M.</given-names></name><name><surname>Bodurka</surname><given-names>J.</given-names></name><name><surname>Tulsa</surname><given-names>I.</given-names></name></person-group> (<year>2020</year>). <article-title>Connectome-wide search for functional connectivity locus associated with pathological rumination as a target for real-time fmri neurofeedback intervention.</article-title>
<source><italic>Neuroi. Clin.</italic></source>
<volume>26</volume>:<issue>102244</issue>. <pub-id pub-id-type="doi">10.1016/j.nicl.2020.102244</pub-id>
<?supplied-pmid 32193171?><pub-id pub-id-type="pmid">32193171</pub-id></mixed-citation>
    </ref>
    <ref id="B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mulyana</surname><given-names>B.</given-names></name><name><surname>Tsuchiyagaito</surname><given-names>A.</given-names></name><name><surname>Smith</surname><given-names>J.</given-names></name><name><surname>Misaki</surname><given-names>M.</given-names></name><name><surname>Kuplicki</surname><given-names>R.</given-names></name><name><surname>Soleimani</surname><given-names>G.</given-names></name><etal/></person-group> (<year>2021</year>). <article-title>Online closed-loop real-time tes-fmri for brain modulation: feasibility, noise/safety and pilot study.</article-title>
<source><italic>bioRxiv</italic>[preprint]</source>. <pub-id pub-id-type="doi">10.1101/2021.04.10.439268</pub-id></mixed-citation>
    </ref>
    <ref id="B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Peirce</surname><given-names>J. W.</given-names></name></person-group> (<year>2008</year>). <article-title>Generating stimuli for neuroscience using psychopy.</article-title>
<source><italic>Front. Neuroinform.</italic></source>
<volume>2</volume>:<issue>10</issue>. <pub-id pub-id-type="doi">10.3389/neuro.11.010.2008</pub-id>
<?supplied-pmid 19198666?><pub-id pub-id-type="pmid">19198666</pub-id></mixed-citation>
    </ref>
    <ref id="B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ramot</surname><given-names>M.</given-names></name><name><surname>Gonzalez-Castillo</surname><given-names>J. A.</given-names></name></person-group> (<year>2019</year>). <article-title>Framework for offline evaluation and optimization of real-time algorithms for use in neurofeedback, demonstrated on an instantaneous proxy for correlations.</article-title>
<source><italic>Neuroimage</italic></source>
<volume>188</volume>
<fpage>322</fpage>–<lpage>334</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2018.12.006</pub-id>
<?supplied-pmid 30553044?><pub-id pub-id-type="pmid">30553044</pub-id></mixed-citation>
    </ref>
    <ref id="B19">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ramot</surname><given-names>M.</given-names></name><name><surname>Kimmich</surname><given-names>S.</given-names></name><name><surname>Gonzalez-Castillo</surname><given-names>J.</given-names></name><name><surname>Roopchansingh</surname><given-names>V.</given-names></name><name><surname>Popal</surname><given-names>H.</given-names></name><name><surname>White</surname><given-names>E.</given-names></name><etal/></person-group> (<year>2017</year>). <article-title>Direct modulation of aberrant brain network connectivity through real-time neurofeedback.</article-title>
<source><italic>Elife</italic></source>
<volume>6</volume>:<issue>e28974</issue>. <pub-id pub-id-type="doi">10.7554/eLife.28974.001</pub-id></mixed-citation>
    </ref>
    <ref id="B20">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Ronneberger</surname><given-names>O.</given-names></name><name><surname>Fischer</surname><given-names>P.</given-names></name><name><surname>Brox</surname><given-names>T.</given-names></name></person-group> (<year>2015</year>). “<article-title>U-net: convolutional networks for biomedical image segmentation</article-title>,” in <source><italic>Medical Image Computing and Computer-Assisted Intervention – Miccai 2015. Lecture Notes in Computer Science</italic></source>, <role>eds</role>
<person-group person-group-type="editor"><name><surname>Navab</surname><given-names>N.</given-names></name><name><surname>Hornegger</surname><given-names>J.</given-names></name><name><surname>Wells</surname><given-names>W. M.</given-names></name><name><surname>Frangi</surname><given-names>A. F.</given-names></name></person-group> (<publisher-loc>Cham</publisher-loc>: <publisher-name>Springer International Publishing</publisher-name>), <fpage>234</fpage>–<lpage>241</lpage>.</mixed-citation>
    </ref>
    <ref id="B21">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ros</surname><given-names>T.</given-names></name><name><surname>Enriquez-Geppert</surname><given-names>S.</given-names></name><name><surname>Zotev</surname><given-names>V.</given-names></name><name><surname>Young</surname><given-names>K. D.</given-names></name><name><surname>Wood</surname><given-names>G.</given-names></name><name><surname>Whitfield-Gabrieli</surname><given-names>S.</given-names></name><etal/></person-group> (<year>2020</year>). <article-title>Consensus on the reporting and experimental design of clinical and cognitive-behavioural neurofeedback studies (cred-nf checklist).</article-title>
<source><italic>Brain</italic></source>
<volume>143</volume>
<fpage>1674</fpage>–<lpage>1685</lpage>. <pub-id pub-id-type="doi">10.1093/brain/awaa009</pub-id>
<?supplied-pmid 32176800?><pub-id pub-id-type="pmid">32176800</pub-id></mixed-citation>
    </ref>
    <ref id="B22">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sato</surname><given-names>J. R.</given-names></name><name><surname>Basilio</surname><given-names>R.</given-names></name><name><surname>Paiva</surname><given-names>F. F.</given-names></name><name><surname>Garrido</surname><given-names>G. J.</given-names></name><name><surname>Bramati</surname><given-names>I. E.</given-names></name><name><surname>Bado</surname><given-names>P.</given-names></name><etal/></person-group> (<year>2013</year>). <article-title>Real-time fmri pattern decoding and neurofeedback using friend: an fsl-integrated bci toolbox.</article-title>
<source><italic>PLoS One</italic></source>
<volume>8</volume>:<issue>e81658</issue>. <pub-id pub-id-type="doi">10.1371/journal.pone.0081658</pub-id>
<?supplied-pmid 24312569?><pub-id pub-id-type="pmid">24312569</pub-id></mixed-citation>
    </ref>
    <ref id="B23">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sladky</surname><given-names>R.</given-names></name><name><surname>Friston</surname><given-names>K. J.</given-names></name><name><surname>Trostl</surname><given-names>J.</given-names></name><name><surname>Cunnington</surname><given-names>R.</given-names></name><name><surname>Moser</surname><given-names>E.</given-names></name><name><surname>Windischberger</surname><given-names>C.</given-names></name></person-group> (<year>2011</year>). <article-title>Slice-timing effects and their correction in functional mri.</article-title>
<source><italic>Neuroimage</italic></source>
<volume>58</volume>
<fpage>588</fpage>–<lpage>594</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2011.06.078</pub-id>
<?supplied-pmid 21757015?><pub-id pub-id-type="pmid">21757015</pub-id></mixed-citation>
    </ref>
    <ref id="B24">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sulzer</surname><given-names>J.</given-names></name><name><surname>Haller</surname><given-names>S.</given-names></name><name><surname>Scharnowski</surname><given-names>F.</given-names></name><name><surname>Weiskopf</surname><given-names>N.</given-names></name><name><surname>Birbaumer</surname><given-names>N.</given-names></name><name><surname>Blefari</surname><given-names>M. L.</given-names></name><etal/></person-group> (<year>2013</year>). <article-title>Real-time fmri neurofeedback: progress and challenges.</article-title>
<source><italic>Neuroimage</italic></source>
<volume>76</volume>
<fpage>386</fpage>–<lpage>399</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.03.033</pub-id>
<?supplied-pmid 23541800?><pub-id pub-id-type="pmid">23541800</pub-id></mixed-citation>
    </ref>
    <ref id="B25">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thibault</surname><given-names>R. T.</given-names></name><name><surname>MacPherson</surname><given-names>A.</given-names></name><name><surname>Lifshitz</surname><given-names>M.</given-names></name><name><surname>Roth</surname><given-names>R. R.</given-names></name><name><surname>Raz</surname><given-names>A.</given-names></name></person-group> (<year>2018</year>). <article-title>Neurofeedback with fmri: a critical systematic review.</article-title>
<source><italic>Neuroimage</italic></source>
<volume>172</volume>
<fpage>786</fpage>–<lpage>807</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2017.12.071</pub-id>
<?supplied-pmid 29288868?><pub-id pub-id-type="pmid">29288868</pub-id></mixed-citation>
    </ref>
    <ref id="B26">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Watanabe</surname><given-names>T.</given-names></name><name><surname>Sasaki</surname><given-names>Y.</given-names></name><name><surname>Shibata</surname><given-names>K.</given-names></name><name><surname>Kawato</surname><given-names>M.</given-names></name></person-group> (<year>2017</year>). <article-title>Advances in fmri real-time neurofeedback.</article-title>
<source><italic>Trends Cogn. Sci.</italic></source>
<volume>21</volume>
<fpage>997</fpage>–<lpage>1010</lpage>. <pub-id pub-id-type="doi">10.1016/j.tics.2017.09.010</pub-id>
<?supplied-pmid 29031663?><pub-id pub-id-type="pmid">29031663</pub-id></mixed-citation>
    </ref>
    <ref id="B27">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Weiss</surname><given-names>F.</given-names></name><name><surname>Zamoscik</surname><given-names>V.</given-names></name><name><surname>Schmidt</surname><given-names>S. N. L.</given-names></name><name><surname>Halli</surname><given-names>P.</given-names></name><name><surname>Kirsch</surname><given-names>P.</given-names></name><name><surname>Gerchen</surname><given-names>M. F.</given-names></name></person-group> (<year>2020</year>). <article-title>Just a very expensive breathing training? Risk of respiratory artefacts in functional connectivity-based real-time fmri neurofeedback.</article-title>
<source><italic>Neuroimage</italic></source>
<volume>210</volume>:<issue>116580</issue>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2020.116580</pub-id>
<?supplied-pmid 31987998?><pub-id pub-id-type="pmid">31987998</pub-id></mixed-citation>
    </ref>
    <ref id="B28">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Young</surname><given-names>K. D.</given-names></name><name><surname>Siegle</surname><given-names>G. J.</given-names></name><name><surname>Zotev</surname><given-names>V.</given-names></name><name><surname>Phillips</surname><given-names>R.</given-names></name><name><surname>Misaki</surname><given-names>M.</given-names></name><name><surname>Yuan</surname><given-names>H.</given-names></name><etal/></person-group> (<year>2017</year>). <article-title>Randomized clinical trial of real-time fmri amygdala neurofeedback for major depressive disorder: effects on symptoms and autobiographical memory recall.</article-title>
<source><italic>Am. J. Psychiatry</italic></source>
<volume>174</volume>
<fpage>748</fpage>–<lpage>755</lpage>. <pub-id pub-id-type="doi">10.1176/appi.ajp.2017.16060637</pub-id>
<?supplied-pmid 28407727?><pub-id pub-id-type="pmid">28407727</pub-id></mixed-citation>
    </ref>
    <ref id="B29">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zotev</surname><given-names>V.</given-names></name><name><surname>Krueger</surname><given-names>F.</given-names></name><name><surname>Phillips</surname><given-names>R.</given-names></name><name><surname>Alvarez</surname><given-names>R. P.</given-names></name><name><surname>Simmons</surname><given-names>W. K.</given-names></name><name><surname>Bellgowan</surname><given-names>P.</given-names></name><etal/></person-group> (<year>2011</year>). <article-title>Self-regulation of amygdala activation using real-time fmri neurofeedback.</article-title>
<source><italic>PLoS One</italic></source>
<volume>6</volume>:<issue>e24522</issue>. <pub-id pub-id-type="doi">10.1371/journal.pone.0024522</pub-id>
<?supplied-pmid 21931738?><pub-id pub-id-type="pmid">21931738</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
