<?DTDIdentifier.IdentifierValue -//ES//DTD journal article DTD version 5.6.0//EN//XML?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName art560.dtd?>
<?SourceDTD.Version 5.6.0?>
<?ConverterInfo.XSLTName elsevier2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<?origin publisher?>
<?FILEmeta_CSBJ2177 xml ?>
<?FILEmain xml ?>
<?FILEmain pdf ?>
<?FILEgr1 jpg ?>
<?FILEgr2 jpg ?>
<?FILEgr3 jpg ?>
<?FILEgr4 jpg ?>
<?FILEgr5 jpg ?>
<?FILEgr6 jpg ?>
<?FILEgr7 jpg ?>
<?FILEfx1 jpg ?>
<?FILEfx2 jpg ?>
<?FILEfx3 jpg ?>
<?FILEfx4 jpg ?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Comput Struct Biotechnol J</journal-id>
    <journal-id journal-id-type="iso-abbrev">Comput Struct Biotechnol J</journal-id>
    <journal-title-group>
      <journal-title>Computational and Structural Biotechnology Journal</journal-title>
    </journal-title-group>
    <issn pub-type="epub">2001-0370</issn>
    <publisher>
      <publisher-name>Research Network of Computational and Structural Biotechnology</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">10250157</article-id>
    <article-id pub-id-type="pii">S2001-0370(23)00212-X</article-id>
    <article-id pub-id-type="doi">10.1016/j.csbj.2023.05.031</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Method Article</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>CNNSplice: Robust models for splice site prediction using convolutional neural networks</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" id="au0005">
        <name>
          <surname>Akpokiro</surname>
          <given-names>Victor</given-names>
        </name>
      </contrib>
      <contrib contrib-type="author" id="au0010">
        <name>
          <surname>Chowdhury</surname>
          <given-names>H. M. A. Mohit</given-names>
        </name>
      </contrib>
      <contrib contrib-type="author" id="au0015">
        <name>
          <surname>Olowofila</surname>
          <given-names>Samuel</given-names>
        </name>
      </contrib>
      <contrib contrib-type="author" id="au0020">
        <name>
          <surname>Nusrat</surname>
          <given-names>Raisa</given-names>
        </name>
      </contrib>
      <contrib contrib-type="author" id="au0025">
        <name>
          <surname>Oluwadare</surname>
          <given-names>Oluwatosin</given-names>
        </name>
        <email>ooluwada@uccs.edu</email>
        <xref rid="cor1" ref-type="corresp">⁎</xref>
      </contrib>
      <aff id="aff0005">Department of Computer Science, University of Colorado, Colorado Springs, CO 80918, United States</aff>
    </contrib-group>
    <author-notes>
      <corresp id="cor1"><label>⁎</label>Corresponding author. <email>ooluwada@uccs.edu</email></corresp>
    </author-notes>
    <pub-date pub-type="pmc-release">
      <day>30</day>
      <month>5</month>
      <year>2023</year>
    </pub-date>
    <!-- PMC Release delay is 0 months and 0 days and was based on <pub-date
						pub-type="epub">.-->
    <pub-date pub-type="collection">
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="epub">
      <day>30</day>
      <month>5</month>
      <year>2023</year>
    </pub-date>
    <volume>21</volume>
    <fpage>3210</fpage>
    <lpage>3223</lpage>
    <history>
      <date date-type="received">
        <day>1</day>
        <month>2</month>
        <year>2023</year>
      </date>
      <date date-type="rev-recd">
        <day>25</day>
        <month>5</month>
        <year>2023</year>
      </date>
      <date date-type="accepted">
        <day>28</day>
        <month>5</month>
        <year>2023</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© 2023 The Authors</copyright-statement>
      <copyright-year>2023</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).</license-p>
      </license>
    </permissions>
    <abstract id="ab0010">
      <p>The identification of splice site, or segments of an RNA gene where noncoding and coding sequences are connected in the 5′ and 3′ directions, is an essential post-transcriptional step for the annotation of functional genes and is required for the study and analysis of biological function in eukaryotic organisms through protein production and gene expression. Splice site detection tools have been proposed for this purpose; however, the models of these tools have a specific use case and are inefficiently or typically untransferable between organisms. Here, we present CNNSplice, a set of deep convolutional neural network models for splice site prediction. Using the five-fold cross-validation model selection technique, we explore several models based on typical machine learning applications and propose five high-performing models to efficiently predict the true and false SS in balanced and imbalanced datasets. Our evaluation results indicate that CNNSplice’s models achieve a better performance compared with existing methods across five organisms’ datasets. In addition, our generality test shows CNNSplice’s model ability to predict and annotate splice sites in new or poorly trained genome datasets indicating a broad application spectrum. CNNSplice demonstrates improved model prediction, interpretability, and generalizability on genomic datasets compared to existing splice site prediction tools. We have developed a web server for the CNNSplice algorithm which can be publicly accessed here: http://www.cnnsplice.online</p>
    </abstract>
    <kwd-group id="keys0005">
      <title>Keywords</title>
      <kwd>Splice sites (SS)</kwd>
      <kwd>Deep Learning (DL)</kwd>
      <kwd>Convolutional neural network (CNN)</kwd>
      <kwd>Dense Neural network (DNN)</kwd>
      <kwd>Feature extraction</kwd>
    </kwd-group>
  </article-meta>
</front>
<body>
  <sec id="sec0005">
    <label>1</label>
    <title>Introduction</title>
    <p id="p0010">Gene annotation is essential to understanding the biological function of the genomic sequence in living organisms <xref rid="bib1" ref-type="bibr">[1]</xref>. RNA splicing—a subtask of gene annotation—involves removing the noncoding regions (introns) and joins the protein-coding regions (exons) in the eukaryotic gene, which in turn is required for gene expression and protein synthesis comprehension. The transition points between the exons and introns are called splice sites (SS). This splicing process, which occurs during gene transcription, involves converting pre-mRNA to mRNA to extract crucial information from the nucleus and express it (translated into actual protein). RNA splicing is the term for this process. Eukaryotes have huge genome sizes and small exons that are surrounded by large introns <xref rid="bib1" ref-type="bibr">[1]</xref>. In the direction 3′ to 5′ of the intron downstream, the consensus AG dinucleotide sequence is expressed as an acceptor SS, and in the direction 5′ to 3′ of the intron upstream, the consensus GT sequence is expressed as a donor SS <xref rid="bib2" ref-type="bibr">[2]</xref>, <xref rid="bib3" ref-type="bibr">[3]</xref>, <xref rid="bib4" ref-type="bibr">[4]</xref>. Acceptor and donor SS with AG and GT dinucleotide pairings make up the salient amount of SS in a genome and are both known as canonical SS <xref rid="bib5" ref-type="bibr">[5]</xref>, with noncanonical SS also observed. The canonical sequence distribution in an SS location, as well as intron splicing, are depicted in <xref rid="fig0005" ref-type="fig">Fig. 1</xref> as a pictorial representation of the SS biochemical process. Thus, many fast and efficient computational-based approaches/algorithms have been developed for SS prediction, and these algorithms can be categorized into subgroups such as the machine learning approach <xref rid="bib6" ref-type="bibr">[6]</xref>, <xref rid="bib7" ref-type="bibr">[7]</xref>, <xref rid="bib8" ref-type="bibr">[8]</xref>, which utilizes nonlinear transformation to perform feature extraction by learning patterns from consensus AG/GT dinucleotide combination and their surrounding molecules; information gain theory <xref rid="bib9" ref-type="bibr">[9]</xref>, <xref rid="bib10" ref-type="bibr">[10]</xref>, <xref rid="bib11" ref-type="bibr">[11]</xref>, which measures the degree of mixing of classes for all samples and any position in the nucleotide sequences; probabilistic measure <xref rid="bib12" ref-type="bibr">[12]</xref>, <xref rid="bib13" ref-type="bibr">[13]</xref>, which computes the maximum likelihood from the probability of a specific SS position; and discriminant analysis approach <xref rid="bib14" ref-type="bibr">[14]</xref>, which applies the statistical measure to determine a particular position of consensus AG/GT nucleotide sequence. The extraction of features or consensus patterns from a group of nucleotide sequences to detect or create links between SS and their surrounding regions is a common element of these approaches. Of all these method subgroups, two machine learning-based algorithms—deep learning (DL) and support vector machine (SVM)—offer more optimal approaches, including shorter prediction time with increased accuracy, and have recently been a prominent approach to SS prediction. To predict SS, many SVM models use a combination of Markov models (MM) and maximum dependency decomposition (MDD) <xref rid="bib13" ref-type="bibr">[13]</xref>, <xref rid="bib15" ref-type="bibr">[15]</xref>. GeneSplicer <xref rid="bib16" ref-type="bibr">[16]</xref> integrated the MM with MDD, which was reported by Burge et al. <xref rid="bib13" ref-type="bibr">[13]</xref> to improve their SS prediction. Pashaei et al. <xref rid="bib17" ref-type="bibr">[17]</xref> investigated the effectiveness of third-order Markovian encoding models and SVMs in predicting human SS. They also proposed a novel method for SS prediction that utilizes sequence component analysis and hidden Markov model (HMM) <xref rid="bib18" ref-type="bibr">[18]</xref>, which they demonstrated to outperform existing methods in accurately predicting SS in genomic DNA.<fig id="fig0005"><label>Fig. 1</label><caption><p>Analysis of the splice sites biochemical process. This figure shows the two-stage biochemical process for splice site and sequence distribution in splice site location. The OH represent the 3′ hydroxyl group of an RNA base.</p></caption><alt-text id="at0005">Fig. 1</alt-text><graphic xlink:href="gr1"/></fig></p>
    <p id="p0015">While the sophistication of these machine learning models increased, their accuracy slowly improved. This resulted from the computational time concerns and the ineffective manual feature selection and extraction from the input variables. Hence, convolutional neural network (CNN) architectures have been used more frequently in SS prediction work using the DL approach, with varying depth, parameters, and architecture design <xref rid="bib19" ref-type="bibr">[19]</xref>, <xref rid="bib20" ref-type="bibr">[20]</xref>, <xref rid="bib21" ref-type="bibr">[21]</xref>, <xref rid="bib22" ref-type="bibr">[22]</xref>, <xref rid="bib23" ref-type="bibr">[23]</xref>. Albaradei et al. <xref rid="bib21" ref-type="bibr">[21]</xref> developed Splice2Deep, a deep CNN ensemble model that predicts SS in cross-organisms and offers the ability for new SS genome organism annotation. Similarly, Zuallaert et al. <xref rid="bib20" ref-type="bibr">[20]</xref> developed SpliceRover, a model that uses CNN to predict SS. They demonstrated the interpretability of their model by showing genomic information relevant to SS detection. Wang et al. <xref rid="bib24" ref-type="bibr">[24]</xref> developed SpliceFinder, an SS tool that predicts canonical (acceptor and donor) and noncanonical SS using a one-layer CNN. Also, Akpokiro et al. <xref rid="bib25" ref-type="bibr">[25]</xref> developed DeepSplicer, a CNN model using five-fold cross-validation and three convolutional layers of CNN architecture to predict SS in genomic organism datasets.</p>
    <p id="p0020">Although the DL-based algorithms for SS prediction have seen significant advancements, there is still a need for more performance improvements especially because many of these tools have an imbalanced performance across organisms for SS detection. Specifically, they are inflexible and not comprehensive in maintaining a consistent prediction accuracy when used for SS detection across a wide range of organisms. Also, the models of some of the existing methods are not robust to the data distribution of acceptor and donor SS made available to them for training and testing purposes, as we show in detail in our results section; thus, their detection accuracy performance varies depending on the acceptor and donor sites’ datasets ratio used for the algorithm’s training. Hence, we propose CNNSplice, a set of DL-based models, for detecting SS in organisms using robust CNN algorithm architectures. For SS prediction, CNNSplice models are trained using a preselected set of organismic datasets. The models in this study were chosen based on the cross-validation results on the datasets. According to our evaluation results, CNNSplice enhances SS detection research by producing highly effective SS detection models (Models 1, 2, 3, 4, and 5), as well as a model (Model 1) that can accurately predict or annotate newly sequenced datasets.</p>
  </sec>
  <sec id="sec0010">
    <label>2</label>
    <title>Material and methods</title>
    <sec id="sec0015">
      <label>2.1</label>
      <title>Datasets</title>
      <p id="p0025">We created a balanced and imbalanced dataset from five carefully selected datasets of organisms, namely: <italic>Homo sapiens</italic>, <italic>Oryza sativa japonica</italic>, <italic>Arabidopsis thaliana</italic>, <italic>Drosophila melanogaster</italic>, and <italic>Caenorhabditis elegans</italic>. The reference genomic sequence data for these organisms were obtained from Albaradei et al. (2020) <xref rid="bib21" ref-type="bibr">[21]</xref>, and separate acceptor and donor models were generated from each organism dataset. The outcome of this method yielded a balanced dataset consisting of confirmed true and false regions at a 1:1 ratio, totaling 10,000 entries each. Additionally, an imbalanced dataset with a confirmed true-to-false region ratio of 3:1 was generated, totaling 7500 true and 2500 false regions, with 10,000 entries in total, as detailed in <xref rid="tbl0005" ref-type="table">Table 1</xref>. For the imbalanced dataset, we also utilized an empirical sliding window program to effectively select the local flanking regions and the SS-containing region based on the sequence distribution ratio; the same applied for the balanced dataset. The relevance and justification for this dataset split is twofold, especially concerning the introduction of the imbalanced dataset. First, it was to assess the impact of the training dataset distribution on our algorithm’s performance. Second, it was to determine and develop a robust model for SS prediction across multiple organisms. This allows us to assess the strength of our models in scenarios where they are used to detect SS from datasets without knowing the data distribution, which is the case for real-life use scenarios of the SS detection tools. Hence, we propose a model that is not overly influenced by the training dataset and would perform well in extreme cases where the distribution of false or true cases is skewed.<table-wrap position="float" id="tbl0005"><label>Table 1</label><caption><p>The dataset’s sequence count.</p></caption><alt-text id="at0040">Table 1</alt-text><table frame="hsides" rules="groups"><thead><tr><th>Splice sites</th><th>Distribution</th><th>Sequence region</th><th>Distribution ratio</th></tr></thead><tbody><tr><td>Acceptor<break/>(AcSS)</td><td>Balanced</td><td>5000 (true)<break/>5000 (false)</td><td>1:1</td></tr><tr><td/><td>Imbalanced</td><td>7500 (true)<break/>2500 (false)</td><td>3:1</td></tr><tr><td>Donor<break/>(DoSS)</td><td>Balanced</td><td>5000 (true)<break/>5000 (false)</td><td>1:1</td></tr><tr><td/><td>Imbalanced</td><td>7500 (true)<break/>2500 (false)</td><td>3:1</td></tr></tbody></table><table-wrap-foot><fn><p>This shows the dataset distribution, sequence counts, and distribution ratio for balanced and imbalanced acceptor and donor sequenced organisms. The balanced datasets are evenly distributed, and the imbalanced datasets are distributed in the ratio of 3–1 (true to false).</p></fn></table-wrap-foot></table-wrap></p>
    </sec>
    <sec id="sec0020">
      <label>2.2</label>
      <title>One-hot encoding and parameter tuning</title>
      <p id="p0030">One-hot encoding, which involves converting categorical data to numerical data variables for improved machine learning algorithm prediction, is one of the aspects of data preprocessing in DL. One-hot encoding is typically applied to categorical data, whereby each category is expressed as a binary vector containing a single 1 with all other elements as 0. This encoding technique is particularly advantageous when there is no inherent order to the categories, and they are mutually exclusive. Additionally, CNNs can effectively learn to identify distinctive patterns and characteristics that correspond to each category through the use of one-hot encoded input. In this study, we utilized a binary integer variable collection to represent our input genomic nucleotide bases. Specifically, we assigned [1 0 0 0], [0 1 0 0], [0 0 1 0], and [0 0 0 1] to represent Adenine (A), Cytosine (C), Guanine (G), and Thymine (T), respectively. Additionally, we represented invalid nucleotide letters (N) with [0,0,0,0], where each nucleotide is located at the corresponding vector index containing a value of 1. Therefore, we provided the CNN architecture with a Z X 4 input matrix, where Z denotes the genomic sequence length and 4 denotes the nucleotide types (A, C, G, T). <xref rid="fig0010" ref-type="fig">Fig. 2</xref><italic>A</italic> shows a pictorial illustration of the one-hot encoding. We tuned the hyperparameters on our generated hyperparameter datasets—to avoid bias in CNN splice—during learning based on the search space shown in <xref rid="tbl0010" ref-type="table">Table 2</xref> and the selected ranges for the model generation. We fine-tuned the hyperparameters and chose the top-performing parameters based on the minimum validation loss.<fig id="fig0010"><label>Fig. 2</label><caption><p>CNNSplice architectural pipeline. This figure shows the CNNSplice pipeline with each block representing <xref rid="fig0010" ref-type="fig">Fig. 2</xref> A, <xref rid="fig0010" ref-type="fig">Fig. 2</xref>B, and <xref rid="fig0010" ref-type="fig">Fig. 2</xref> C respectively. <xref rid="fig0010" ref-type="fig">Fig. 2</xref> A shows the one-hot encoding as described in the one-hot encoding and hyper-parameter tuning section, <xref rid="fig0010" ref-type="fig">Fig. 2</xref>B depicts the convolutional layer and <xref rid="fig0010" ref-type="fig">Fig. 2</xref> C shows the output layers which includes the dense, the fully connected layer, ss denotes splice site.</p></caption><alt-text id="at0010">Fig. 2</alt-text><graphic xlink:href="gr2"/></fig><table-wrap position="float" id="tbl0010"><label>Table 2</label><caption><p>The grid search space table for the tuning of the Convolutional neural network hyperparameters.</p></caption><alt-text id="at0045">Table 2</alt-text><table frame="hsides" rules="groups"><thead><tr><th>Hyper-Parameters</th><th>Search Space</th><th>Selected Ranges</th></tr></thead><tbody><tr><td>Layers</td><td>[1, 2, 3, 4, 5]</td><td>[1, 2, 3]</td></tr><tr><td>Filter number</td><td>[50,64,100,128,150]</td><td>[5]</td></tr><tr><td>Filter size</td><td>[3,5,7,9,11]</td><td>[3, 9]</td></tr><tr><td>Stride</td><td>[1,3,5]</td><td>[1]</td></tr><tr><td>Activation function</td><td>[sigmoid, relu, softmax, tanh]</td><td>[sigmoid, relu]</td></tr><tr><td>Learning rate</td><td>[1e-3, 5e-4, 1e-4, 5e-5, 1e-5]</td><td>[1e–4]</td></tr><tr><td>Optimizers</td><td>[sgd, adam, adagrad, RMSprop, nadam]</td><td>[adam]</td></tr></tbody></table><table-wrap-foot><fn><p>This table shows different hyper-parameter lists from which the CNN architecture was tuned to select the best parameters for the model’s configuration.</p></fn></table-wrap-foot></table-wrap></p>
    </sec>
    <sec id="sec0025">
      <label>2.3</label>
      <title>Convolutional neural network model</title>
      <p id="p0035">The CNN contains the convolutional layers, which are the main building block of this neural network <xref rid="bib26" ref-type="bibr">[26]</xref>. These convolutional layers are made up of neurons that contain and perform element-wise multiplication operations between the inputs and the weights. To employ a reliable model, each CNNSplice model has different convolutional layers (<xref rid="fig0010" ref-type="fig">Fig. 2</xref><italic>B</italic>). These convolutional layers perform local and global feature extraction on the acceptor and donor genomic input sequence. Importantly, the convolutional layer consists of a complex set of learnable filters with varying filter length and depth, which enables efficient discrimination of true/false acceptor and donor SS. The best-performing model has been selected based on the average validation accuracy across the preselected organism for acceptor and donor individually. In the cross-validation section, we presented 11 architectures from which the consistent top-performing models were selected as the architecture for the convolutional layer of our pipeline.</p>
      <p id="p0040">Each model convolutional block contains a flattened layer, a fully connected layer of 100 neurons. By using all its connections to all the activations in the flatten layer, the fully connected layer increases nonlinearity expression capabilities to detect both canonical and noncanonical SS and improve CNNSplice’s generalization ability (<xref rid="fig0010" ref-type="fig">Fig. 2</xref><italic>C</italic>). Their activations may be approximated using matrix multiplication and bias offset. This layer uses the ReLU <xref rid="bib27" ref-type="bibr">[27]</xref> activation function, which uses element-wise nonlinearity. To avoid overfitting, a 30 % dropout <xref rid="bib28" ref-type="bibr">[28]</xref> layer is implemented. Finally, we used the Adam optimizer with a learning rate of 1e-4, cross-entropy for the loss function, and the Softmax activation function layer <xref rid="bib29" ref-type="bibr">[29]</xref> to transform the prediction output to normalized probability. A visual summary of the models is shown in <xref rid="fig0010" ref-type="fig">Fig. 2</xref>.</p>
    </sec>
    <sec id="sec0030">
      <label>2.4</label>
      <title>Genomic datasets sequence length selection</title>
      <p id="p0045">Statistical examination of the correlation between genomic sequence length and prediction performance has been done in the previous SS prediction research <xref rid="bib19" ref-type="bibr">[19]</xref>, <xref rid="bib21" ref-type="bibr">[21]</xref>, <xref rid="bib24" ref-type="bibr">[24]</xref> because the sequence length of the produced dataset is an important factor to consider for SS prediction. Experiments by Wang et al. <xref rid="bib24" ref-type="bibr">[24]</xref> and Du et al. <xref rid="bib19" ref-type="bibr">[19]</xref> show that the capacity of SS models to predict rises as the length of the genomic sequence increases. Though there is a favorable association between sequence length and prediction performance, a long sequence length may degrade classification performance <xref rid="bib16" ref-type="bibr">[16]</xref>, <xref rid="bib20" ref-type="bibr">[20]</xref>, <xref rid="bib21" ref-type="bibr">[21]</xref>. To maintain a good sequence length balance, and for a fair model prediction and comparison with other baseline methods, we used a sequence length of 400 of sequence region 0–399. Thus, all algorithm acceptor and donor input species datasets regions in this study have a sequence length of 400 nucleotides bases. The dataset section clearly details the source, distribution, and the true and false AcSS/DoSS regions for each dataset used in the experiment.</p>
    </sec>
    <sec id="sec0035">
      <label>2.5</label>
      <title>Evaluation metrics</title>
      <p id="p0050">We used the following metrics to evaluate the performance of our neural network models.<list list-type="simple" id="li0005"><list-item id="u0005"><label>•</label><p id="p0055">The Recall evaluates as:<disp-formula id="eqn0005"><label>(1)</label><mml:math id="M1" altimg="si0001.svg"><mml:mrow><mml:mi mathvariant="italic">Recall</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">TP</mml:mi></mml:mrow><mml:mrow><mml:mspace width="1em"/><mml:mi mathvariant="italic">TP</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="italic">FN</mml:mi><mml:mspace width="1em"/></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="M2" altimg="si0002.svg"><mml:mi mathvariant="italic">TP</mml:mi></mml:math></inline-formula> is the number of true positives, <inline-formula><mml:math id="M3" altimg="si0003.svg"><mml:mi mathvariant="italic">FN</mml:mi></mml:math></inline-formula> is the number of false negatives.</p></list-item><list-item id="u0010"><label>•</label><p id="p0060">The Precision evaluates as:<disp-formula id="eqn0010"><label>(2)</label><mml:math id="M4" altimg="si0004.svg"><mml:mrow><mml:mi mathvariant="italic">Precision</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">TP</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">TP</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="italic">FP</mml:mi><mml:mspace width="1em"/></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="M5" altimg="si0002.svg"><mml:mi mathvariant="italic">TP</mml:mi></mml:math></inline-formula> is the number of true positives, <inline-formula><mml:math id="M6" altimg="si0005.svg"><mml:mi mathvariant="italic">FP</mml:mi></mml:math></inline-formula> is the number of false positives.</p></list-item><list-item id="u0015"><label>•</label><p id="p0065">The Accuracy evaluates as:</p></list-item></list><disp-formula id="eqn0015"><label>(3)</label><mml:math id="M7" altimg="si0006.svg"><mml:mrow><mml:mi mathvariant="italic">Accuracy</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">TP</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="italic">TN</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">TP</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="italic">TN</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="italic">FP</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="italic">FN</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula></p>
    </sec>
  </sec>
  <sec id="sec0040">
    <label>3</label>
    <title>Results</title>
    <sec id="sec0045">
      <label>3.1</label>
      <title>Cross-validation</title>
      <p id="p0070">To get a smoother, less noisy, and more sustainable estimate of how well a model performs, cross-validation, which involves iterating over a K-fold validation set and determining the average across the datasets, is essential. K-1 fold is reserved for training purposes with one-fold for testing. In summary, cross-validation is used to return partitions of the dataset for training and evaluation of the model for enhanced neural network performance and statistical probability. CNNSplice splits the training dataset into five folds using K-fold cross-validation with the StratifiedKFold machine learning module <xref rid="bib19" ref-type="bibr">[19]</xref>. We reconstructed the cross-validation datasets from the source datasets <xref rid="bib21" ref-type="bibr">[21]</xref>. The training dataset, X, is split into five equally distributed subset datasets with the cross-validation computation producing a mean output of the five model accuracies and losses from five data splits. This can be represented mathematically as follows:<disp-formula id="eqn0020"><label>(4)</label><mml:math id="M8" altimg="si0007.svg"><mml:mrow><mml:mi>X</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>∪</mml:mo><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>∪</mml:mo><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mo>∪</mml:mo><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mn>4</mml:mn></mml:mrow></mml:msub><mml:mo>∪</mml:mo><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mn>5</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></disp-formula>Where X is the entire training dataset and is split into equal subsets for all <italic>i</italic> = 1, 2, 3, 4, 5. <xref rid="eqn0020" ref-type="disp-formula">Eq. 4</xref> yields five subsets from dataset X. Mathematically, the process of cross-validation is given by<disp-formula id="eqn0025"><label>(5)</label><mml:math id="M9" altimg="si0008.svg"><mml:mrow><mml:mi mathvariant="normal">|</mml:mi><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mi mathvariant="normal">|</mml:mi><mml:mo>≈</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">|</mml:mi><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mi mathvariant="normal">|</mml:mi><mml:mo>≈</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">|</mml:mi><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mi mathvariant="normal">|</mml:mi><mml:mo>≈</mml:mo><mml:mi mathvariant="normal">|</mml:mi><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mn>4</mml:mn></mml:mrow></mml:msub><mml:mi mathvariant="normal">|</mml:mi><mml:mo>≈</mml:mo><mml:mi mathvariant="normal">|</mml:mi><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mn>5</mml:mn></mml:mrow></mml:msub><mml:mi mathvariant="normal">|</mml:mi></mml:mrow></mml:math></disp-formula></p>
      <p id="p0075">As shown in <xref rid="tbl0005" ref-type="table">Table 1</xref>, we constructed 5000 true and 5000 false acceptor and donor datasets for the balanced experiments and 7500 true and 2500 false acceptor and donor datasets for the imbalanced experiment evenly. To find the best-performing convolutional layer for <xref rid="fig0010" ref-type="fig">Fig. 2</xref>B, we performed cross-validation on the list of potential architectures as follows:<list list-type="simple" id="li0010"><list-item id="u0020"><label>•</label><p id="p0080"><bold>C1</bold>: is a one-dimensional convolutional layer block.</p></list-item><list-item id="u0025"><label>•</label><p id="p0085"><bold>C11</bold>M: has a pair of one-dimensional convolutional layer and max-pooling layer.</p></list-item><list-item id="u0030"><label>•</label><p id="p0090"><bold>Model</bold> 1: contains three (3) blocks of one-dimensional convolutional layer, and a max-pooling layer for each convolutional block.</p></list-item><list-item id="u0035"><label>•</label><p id="p0095"><bold>Model</bold> 2: contains two (2) layers of a pair of one-dimensional convolutional layer and max-pooling layer.</p></list-item><list-item id="u0040"><label>•</label><p id="p0100"><bold>NPOOL1</bold>3: is similar to Model 1 and Model 3 except it has no max-pooling or average-pooling layer to each convolutional block.</p></list-item><list-item id="u0045"><label>•</label><p id="p0105"><bold>Model</bold> 3: contains three (3) blocks of a pair of one-dimensional convolutional layer and average pooling layer.</p></list-item><list-item id="u0050"><label>•</label><p id="p0110"><bold>MEANPOOL1</bold>3: is similar to NPOOL13 with a one-dimensional global average pooling layer connected in the fully connected layer.</p></list-item><list-item id="u0055"><label>•</label><p id="p0115"><bold>Model</bold> 4: averages the weight generated from Model 1 and Model 2.</p></list-item><list-item id="u0060"><label>•</label><p id="p0120"><bold>Model</bold> 5: involves weights from Model 1 and Model 3 averaged.</p></list-item><list-item id="u0065"><label>•</label><p id="p0125"><bold>NPOOL1</bold>2: is similar to Model 2 except it has no max-pooling or average-pooling layer to each convolutional block.</p></list-item><list-item id="u0070"><label>•</label><p id="p0130"><bold>AVEPOOL1</bold>2: contains two (2) layers of a pair of one-dimensional convolutional layer and average-pooling layer.</p></list-item></list></p>
      <p id="p0135">As shown in <xref rid="fig0010" ref-type="fig">Fig. 2</xref>, each of the aforementioned architectures is the variations of the architecture used in <xref rid="fig0010" ref-type="fig">Fig. 2</xref><italic>B</italic>, which accepts one-hot encoding as input. The outputs of each of these architectures, in <xref rid="fig0010" ref-type="fig">Fig. 2</xref><italic>B</italic>, serve as input to the dense and fully connected layer as seen in <xref rid="fig0010" ref-type="fig">Fig. 2</xref><italic>C</italic>. Cross-validation was performed on all the aforementioned architectures for the five organisms’ balanced and imbalanced datasets.</p>
      <p id="p0140">Our work is focused on the development of robust models that are capable of high performance on multiple organisms. Thus, to select the best-performing models, we averaged the results generated by each model across the different organisms to identify which models have a consistently high performance. We have shown the tabular results of the cross-validation experiment in <xref rid="tbl0015" ref-type="table">Table 3</xref> and <xref rid="tbl0020" ref-type="table">Table 4</xref> for the balanced and imbalanced datasets results respectively. Across the five organisms’ acceptor and donor datasets for the imbalanced and balanced datasets we created, Model 1, Model 5, and Model 3 are the top three (3) performing model architectures for balanced acceptor datasets; Model 1, Model 5, and Model 4 are the top three (3) performing model architectures for balanced donor datasets; Model 1, Model 2, and Model 5 are the top three (3) performing model architectures for imbalanced acceptor datasets; and Model 1, Model 2, and Model 4 are the top three (3) performing model architectures for imbalanced donor datasets.<table-wrap position="float" id="tbl0015"><label>Table 3</label><caption><p>The cross-validation results for the Balanced Dataset for the five organisms.</p></caption><alt-text id="at0050">Table 3</alt-text><table frame="hsides" rules="groups"><tbody><tr><td><inline-graphic xlink:href="fx1.gif"/></td></tr></tbody></table><table-wrap-foot><fn><p>This Table depicts the 5-fold Cross-validation Results, average result across the organism distribution, and average results positions for Balanced datasets across the selected organism in percent (%). With respect to validation accuracy, results highlighted shows that * represent the best result * * represents the second best, * ** represents the third. HS denotes Homo sapiens, Oryza denotes <italic>Oryza sativa japonica</italic>, AT denotes <italic>Arabidopsis thaliana</italic>, D. Mel denotes <italic>Drosophila melanogaster</italic>, and C. elegans denotes <italic>Caenorhabditis elegans</italic>.</p></fn></table-wrap-foot></table-wrap><table-wrap position="float" id="tbl0020"><label>Table 4</label><caption><p>The cross-validation results for the imbalanced dataset for the five organisms.</p></caption><alt-text id="at0055">Table 4</alt-text><table frame="hsides" rules="groups"><tbody><tr><td><inline-graphic xlink:href="fx2.gif"/></td></tr></tbody></table><table-wrap-foot><fn><p>This Table depicts the 5-fold Cross-validation Results, average result across the organism distribution, and average results positions for Imbalanced datasets across the selected organism in percent (%). With respect to validation accuracy, results highlighted shows that * represent the best result * * represents the second best, * ** represents the third. HS denotes Homo sapiens, Oryza denotes <italic>Oryza sativa japonica</italic>, AT denotes <italic>Arabidopsis thaliana</italic>, D. Mel denotes <italic>Drosophila melanogaster</italic>, and C. elegans denotes <italic>Caenorhabditis elegans</italic>.</p></fn></table-wrap-foot></table-wrap></p>
      <p id="p0145">Hence, based on the results obtained from the cross-validation experiment as shown in <xref rid="tbl0015" ref-type="table">Table 3</xref> and <xref rid="tbl0020" ref-type="table">Table 4</xref>, the architectural formation of the five best-performing models based on average accuracy across the organisms is described as follows, with a schematic representation shown in <xref rid="fig0015" ref-type="fig">Fig. 3</xref>.<list list-type="simple" id="li0015"><list-item id="u0075"><label>•</label><p id="p0150"><bold>Model 1:</bold> This model has three (3) one-dimensional convolutional layers, each with 50 kernels of size 9 and a batch size input of <italic>L X 4</italic>, the sequence length, <inline-formula><mml:math id="M10" altimg="si0009.svg"><mml:mi mathvariant="italic">where L</mml:mi></mml:math></inline-formula> is the sequence length. ReLU activation function is applied to each convolutional layer. In addition, a max-pooling layer of pool size 2 and stride 1 is applied to each individual convolutional layer.</p></list-item><list-item id="u0080"><label>•</label><p id="p0155"><bold>Model 2:</bold> This model has two (2) one-dimensional convolutional layers, each with 50 size 9 kernels and a batch size input of L X 4, <inline-formula><mml:math id="M11" altimg="si0009.svg"><mml:mi mathvariant="italic">where L</mml:mi></mml:math></inline-formula> is the sequence length. ReLU activation function is applied to each convolutional layer. In addition, a max-pooling layer of pool size 2 and stride 1 is applied to each individual convolutional layer.</p></list-item><list-item id="u0085"><label>•</label><p id="p0160"><bold>Model 3:</bold> This model has three (3) one-dimensional convolutional layers, each with 50 kernels of size 9 and a batch size input of <italic>L X 4</italic>, the sequence length, <inline-formula><mml:math id="M12" altimg="si0009.svg"><mml:mi mathvariant="italic">where L</mml:mi></mml:math></inline-formula> is the sequence length. ReLU activation function is applied to each convolutional layer. In addition, an average pooling layer of pool size 2 and stride 1 is applied to each individual convolutional layer.</p></list-item><list-item id="u0090"><label>•</label><p id="p0165"><bold>Model 4:</bold> This involves setting a new weight obtained from the mean weight across a set weight from Model 1 and Model 2 to the model.</p></list-item><list-item id="u0095"><label>•</label><p id="p0170"><bold>Model 5:</bold> This involves setting a new weight obtained from the mean weight across a set weight from Model 1 and Model 3 to the model.</p></list-item></list><fig id="fig0015"><label>Fig. 3</label><caption><p>Best performing CNNSplice model architectures. This figure shows a detailed layout of the CNNSplice models’ convolutional block architecture selected by the 5-fold cross validation process for <xref rid="fig0010" ref-type="fig">Fig. 2</xref>B of the CNNSplice pipeline illustration, <xref rid="fig0010" ref-type="fig">Fig. 2</xref>. ConvNet means the convolutional neural network layer, Max - Pool is the max-pooling layer, and the Ave - Pool is the average pooling layer. The input block denotes <xref rid="fig0010" ref-type="fig">Fig. 2</xref> A and the output block denotes <xref rid="fig0010" ref-type="fig">Fig. 2</xref> C.</p></caption><alt-text id="at0015">Fig. 3</alt-text><graphic xlink:href="gr3"/></fig></p>
    </sec>
    <sec id="sec0050">
      <label>3.2</label>
      <title>Benchmark methods for model comparison</title>
      <p id="p0175">In the context of SS prediction using the DL approach, various CNN architectures of different depths, parameters, and architecture designs have been used. Herein, we describe our benchmark cutting-edge models for comparison.</p>
      <p id="p0180"><bold>Wang, R. et al. (2019)</bold>.</p>
      <p id="p0185">Wang et al. (2019) proposed SpliceFinder <xref rid="bib24" ref-type="bibr">[24]</xref>, a CNN-based model that effectively predicts SS in various species, achieving a classification accuracy of 90.25 % in the human dataset. We chose this recent study as our baseline model because it can be applied to annotate new species without the need for retraining.</p>
      <p id="p0190"><bold>Albaradei, S. et al. (2020)</bold>.</p>
      <p id="p0195">Albaradei et al. (2020) introduced Splice2Deep <xref rid="bib21" ref-type="bibr">[21]</xref>, a high-performing SS prediction tool that uses deep CNNs and achieves high accuracy in various datasets, including <italic>Homo sapiens</italic>, <italic>Oryza sativa japonica</italic>, <italic>Arabidopsis thaliana</italic>, <italic>Drosophila melanogaster</italic>, and <italic>Caenorhabditis elegans</italic>. The authors also demonstrated the interpretability of the model by identifying important regions and motifs for SS prediction, as well as performing cross-organism validation test.</p>
      <p id="p0200"><bold>Zuallaert, J. et al. (2018)</bold>.</p>
      <p id="p0205">Zuallaert et al. (2018) proposed SpliceRover <xref rid="bib20" ref-type="bibr">[20]</xref>, a DL method that predicts SS using interpretable CNNs. The authors demonstrated the effectiveness of SpliceRover on multiple datasets and species, achieving up to 80.9 % accuracy. For benchmarking, we used their publicly available web server found at http://bioit2.irc.ugent.be/rover/splicerover.</p>
      <p id="p0210"><bold>Pertea, M. et al. (2001)</bold>.</p>
      <p id="p0215">Pertea et al. (2001) presented GeneSplicer <xref rid="bib16" ref-type="bibr">[16]</xref>, a computational approach to SS prediction that combines MM technique and MDD to identify SS in DNA sequences. The authors showed that GeneSplicer achieves high accuracy in predicting SS in various organisms, including human, mouse, and rat genomes. For benchmarking, we used their publicly available web server found at https://www.cbcb.umd.edu/software/GeneSplicer/gene_spl.shtml.</p>
      <p id="p0220"><bold>Akpokiro, V. et al. (2021)</bold>.</p>
      <p id="p0225">Finally, Akpokiro et al. (2021) proposed DeepSplicer <xref rid="bib25" ref-type="bibr">[25]</xref>, a DL-based method for predicting SS in DNA sequences. Similar to CNNSplice, DeepSplicer performed a five-fold cross-validation test and achieved high accuracy in various datasets, including <italic>Homo sapiens</italic>, <italic>Oryza sativa japonica</italic>, <italic>Arabidopsis thaliana</italic>, <italic>Drosophila melanogaster</italic>, and <italic>Caenorhabditis elegans</italic>. The data, models generated, and source code for DeepSplicer <xref rid="bib25" ref-type="bibr">[25]</xref> and SpliceFinder <xref rid="bib24" ref-type="bibr">[24]</xref> are all available in their respective GitHub repositories.</p>
    </sec>
    <sec id="sec0055">
      <label>3.3</label>
      <title>Model evaluation and performance comparison</title>
      <p id="p0230">We built separate models from our CNN algorithm architecture to reliably predict acceptor and donor SS for each of the balanced and imbalanced datasets. To improve the prediction performance of our selected models we performed feature extraction along the three regions: two local opposite genome surrounding regions (upstream and downstream) and the SS surrounding region <xref rid="bib21" ref-type="bibr">[21]</xref>. These models were selected based on peak performance from evaluating the mean prediction accuracy results across the preselected organism sequence datasets on the five-fold cross-validation results. Following feature extraction on each dataset, dinucleotides discovered on SS contain AG for acceptor sites and GT for donor sites; this AG-GT result consensus confirms previous observations in scientific literature <xref rid="bib19" ref-type="bibr">[19]</xref>, <xref rid="bib21" ref-type="bibr">[21]</xref>, <xref rid="bib25" ref-type="bibr">[25]</xref>, <xref rid="bib30" ref-type="bibr">[30]</xref>. It is crucial to highlight that we chose our models based on the outcomes of our cross-validation experiments, and we fairly compared them—as shown in <xref rid="fig0020" ref-type="fig">Fig. 4</xref><italic>a</italic>, <xref rid="fig0020" ref-type="fig">Fig. 4</xref><italic>b</italic>, <xref rid="fig0020" ref-type="fig">Fig. 4</xref><italic>c</italic>, and <xref rid="fig0020" ref-type="fig">Fig. 4</xref><italic>d</italic>—to the aforementioned state-of-the-art methods by using our test dataset with the models provided by the authors, as well as for training and testing in cases where the model was unavailable but the method architecture was available with our datasets.<fig id="fig0020"><label>Fig. 4</label><caption><p>A comparison of the performance of CNNSplice models and other models for (A) balanced acceptor, (B) balanced donor, (C) imbalanced acceptor, and (D) imbalanced donor datasets. This chart shows the CNNSplice models comparison to the models based on the performance accuracy in predicting splice sites for balanced acceptor datasets. CNNSplice m1 indicate Model 1, CNNSplice m2 indicate Model 2 CNNSplice m3 indicates Model 3, CNNSplice m4 indicate Model 4, CNNSplice m5 indicate Model 5. For this plot’s label, the Y-axis represents the accuracy in percentage (%) as the X-axis represents the name of the organisms’ datasets.</p></caption><alt-text id="at0020">Fig. 4</alt-text><graphic xlink:href="gr4"/></fig></p>
      <p id="p0235">These figures indicate that Model 1 consistently provided a high prediction accuracy across all acceptor and donor organisms for both datasets—balanced and imbalanced. In addition to Model 1, Model 3 performed well in balanced acceptor datasets (<xref rid="fig0020" ref-type="fig">Fig. 4</xref><italic>a</italic>), Model 2 and Model 5 performed better in imbalanced acceptor datasets (<xref rid="fig0020" ref-type="fig">Fig. 4</xref><italic>c</italic>), Model 1 and Model 4 performed better in balanced donor datasets (<xref rid="fig0020" ref-type="fig">Fig. 4</xref><italic>b</italic>), and Model 2 and Model 4 performed better in imbalanced donor datasets (<xref rid="fig0020" ref-type="fig">Fig. 4</xref><italic>d</italic>). In addition, we compared our models’ performance to the state-of-the-art SS prediction algorithms—Splice2Deep <xref rid="bib21" ref-type="bibr">[21]</xref>, GeneSplicer <xref rid="bib16" ref-type="bibr">[16]</xref>, SpliceRover <xref rid="bib20" ref-type="bibr">[20]</xref>, SpliceFinder <xref rid="bib24" ref-type="bibr">[24]</xref>, DeepSplicer <xref rid="bib25" ref-type="bibr">[25]</xref>—on the five organisms’ datasets: <italic>Homo sapiens</italic>, <italic>Oryza sativa japonica</italic>, <italic>Arabidopsis thaliana</italic>, <italic>Drosophila melanogaster</italic>, and <italic>Caenorhabditis elegans</italic> organisms (<xref rid="fig0020" ref-type="fig">Fig. 4</xref><italic>a</italic>–<xref rid="fig0020" ref-type="fig">Fig. 4</xref><italic>d</italic>). Model 1 achieved the highest performance accuracy compared to the other models and the state of the art for the balanced acceptor <italic>Homo sapiens</italic>, <italic>Arabidopsis thaliana</italic>, <italic>Oryza sativa japonica</italic>, and <italic>Caenorhabditis elegans</italic> organisms’ dataset with 96.94 %, 96.26 %, 96.85 %, and 97.00 % accuracy respectively (<xref rid="fig0020" ref-type="fig">Fig. 4</xref><italic>a</italic>). For the balanced donor dataset, Model 1 performed better than the other models and the Splice2Deep <xref rid="bib21" ref-type="bibr">[21]</xref>, GeneSplicer <xref rid="bib16" ref-type="bibr">[16]</xref>, and SpliceFinder <xref rid="bib24" ref-type="bibr">[24]</xref> models for <italic>Homo sapiens</italic>, <italic>Arabidopsis thaliana</italic>, <italic>Drosophila melanogaster</italic>, and <italic>Caenorhabditis elegans</italic> organisms with accuracy performance of 96.63 %, 94.10 %, 96.15 %, and 97.07 % respectively (<xref rid="fig0020" ref-type="fig">Fig. 4</xref><italic>b</italic>). Model 4 performed highest for the <italic>Oryza sativa japonica</italic> organism dataset with an accuracy of 96.35 % (<xref rid="fig0020" ref-type="fig">Fig. 4</xref><italic>b</italic>).</p>
      <p id="p0240">Also, we investigated the SS prediction potentials with imbalanced acceptor and donor organism datasets and compared our model’s performance with state-of-the-art models—SpliceFinder <xref rid="bib24" ref-type="bibr">[24]</xref> and DeepSplicer <xref rid="bib25" ref-type="bibr">[25]</xref>. It is worth noting that for this analysis, we benchmarked only with the SpliceFinder <xref rid="bib24" ref-type="bibr">[24]</xref> and DeepSplicer <xref rid="bib25" ref-type="bibr">[25]</xref> algorithms because the other state-of-the-art methods examined previously do not have available models trained with imbalanced organisms’ datasets or do not provide model architecture for model retraining with imbalanced datasets. Model 2 performed better than the DeepSplicer <xref rid="bib25" ref-type="bibr">[25]</xref> and SpliceFinder <xref rid="bib24" ref-type="bibr">[24]</xref> for imbalanced acceptor organisms’ datasets of <italic>Homo sapiens</italic> and <italic>Caenorhabditis elegans</italic> with performance accuracy of 95.82 % and 97.79 % respectively, whereas Model 1 performed better for the <italic>Arabidopsis thaliana</italic>, <italic>Oryza sativa japonica</italic>, and <italic>Drosophila melanogaster</italic> organism datasets with an accuracy of 96.02 %, 95.55 %, and 97.02 % respectively (<xref rid="fig0020" ref-type="fig">Fig. 4</xref><italic>c</italic>). For the imbalanced donor, Model 1 performed better for <italic>Drosophila melanogaster</italic> and <italic>Caenorhabditis elegans</italic> organisms with SS prediction accuracy of 96.62 % and 97.96 % respectively, Model 2 had a prediction accuracy of 96.46 % and 97.62 % for <italic>Homo sapiens</italic> and <italic>Arabidopsis thaliana</italic> respectively, and Model 4 had a prediction accuracy of 95.19 % for the <italic>Oryza sativa japonica</italic> organism dataset (<xref rid="fig0020" ref-type="fig">Fig. 4</xref><italic>d</italic>). We present tables showing the results and comparison with other methods in <xref rid="tbl0025" ref-type="table">Table 5</xref> and <xref rid="tbl0030" ref-type="table">Table 6</xref>. To show the performance evaluation metrics for CNN Splice, we show in <xref rid="tbl0035" ref-type="table">Table 7</xref> the results of the precision, recall, F1, and accuracy evaluation metrics for the Model 1 test prediction using the balanced genomic datasets. We used N/A to indicate methodologies that did not use the considered organism in their model training and situations where method architecture was not available to retrain the organism with the examined organism. The methods available for comparison in the imbalanced dataset experiment results are those with imbalanced models or model architecture provided to generate an imbalanced datasets model.<table-wrap position="float" id="tbl0025"><label>Table 5</label><caption><p>The results comparison on balanced datasets across the selected organism.</p></caption><alt-text id="at0060">Table 5</alt-text><table frame="hsides" rules="groups"><tbody><tr><td><inline-graphic xlink:href="fx3.gif"/></td></tr></tbody></table><table-wrap-foot><fn><p>This table shows the results of the Balanced SS prediction accuracy in comparison to the state of the arts for acceptor and donor genome datasets in percent (%). CNNSplice m1 indicates Model 1, CNNSplice m3 indicates Model 3, CNNSplice m4 indicates Model 4. Results highlighted in <bold>bold</bold> black color represent the best result and result highlighted in <bold>bold</bold> red represents the second-best result.</p></fn></table-wrap-foot></table-wrap><table-wrap position="float" id="tbl0030"><label>Table 6</label><caption><p>The results comparison on imbalanced datasets across the selected organism.</p></caption><alt-text id="at0065">Table 6</alt-text><table frame="hsides" rules="groups"><tbody><tr><td><inline-graphic xlink:href="fx4.gif"/></td></tr></tbody></table><table-wrap-foot><fn><p>This table shows the CNNSplice splice site prediction performance results and its comparison to other methods. We show the prediction accuracy measures, in percent (%), amongst other evaluation metrics performance results. Results highlighted in <bold>bold</bold> black color represent the best result and result highlighted in <bold>bold</bold> red represents the second-best result.</p></fn></table-wrap-foot></table-wrap><table-wrap position="float" id="tbl0035"><label>Table 7</label><caption><p>The performance evaluation metrics for the balanced dataset using model 1.</p></caption><alt-text id="at0070">Table 7</alt-text><table frame="hsides" rules="groups"><thead><tr><th>SpliceSites</th><th>Model name</th><th>Precision</th><th>F1</th><th>Recall</th><th>Accuracy</th></tr></thead><tbody><tr><td>Acceptor</td><td>Homo sapiens</td><td>94.50</td><td>94.44</td><td>94.44</td><td>94.44</td></tr><tr><td/><td>Arabidopsis thaliana</td><td>96.31</td><td>96.24</td><td>96.26</td><td>96.26</td></tr><tr><td/><td>Oryza sativa japonica</td><td>96.80</td><td>96.85</td><td>96.80</td><td>96.85</td></tr><tr><td/><td>Drosophila melanogaster</td><td>94.86</td><td>94.74</td><td>94.77</td><td>94.77</td></tr><tr><td/><td>Caenorhabditis elegans</td><td>97.29</td><td>97.00</td><td>96.69</td><td>97.00</td></tr><tr><td>  </td><td>  </td><td>  </td><td>  </td><td>  </td><td>  </td></tr><tr><td>SpliceSites</td><td>Model name</td><td>Precision</td><td>F1</td><td>Recall</td><td>Accuracy</td></tr><tr><td>Donor</td><td>Homo sapiens</td><td>96.70</td><td>96.63</td><td>96.63</td><td>96.63</td></tr><tr><td/><td>Arabidopsis thaliana</td><td>94.11</td><td>94.10</td><td>94.10</td><td>94.10</td></tr><tr><td/><td>Oryza sativa japonica</td><td>94.27</td><td>94.23</td><td>94.24</td><td>94.24</td></tr><tr><td/><td>Drosophila melanogaster</td><td>96.16</td><td>96.15</td><td>96.15</td><td>96.15</td></tr><tr><td/><td>Caenorhabditis elegans</td><td>97.10</td><td>97.04</td><td>97.07</td><td>97.07</td></tr></tbody></table><table-wrap-foot><fn><p>This table shows the CNNSplice splice site prediction performance evaluation results. We show the accuracy, precision, recall and f1 score measures in percent (%) for the balanced acceptor and donor genomic organism datasets.</p></fn></table-wrap-foot></table-wrap></p>
      <p id="p0245">In conclusion, CNNSplice presents robust DL models for improved SS prediction with comparison to the state-of-the-art methods, namely Splice2Deep <xref rid="bib21" ref-type="bibr">[21]</xref>, GeneSplicer <xref rid="bib16" ref-type="bibr">[16]</xref>, SpliceFinder <xref rid="bib24" ref-type="bibr">[24]</xref>, and DeepSplicer <xref rid="bib25" ref-type="bibr">[25]</xref> for both balanced and imbalanced acceptor and donor datasets. The plot representation of the results accuracy comparison is shown in <xref rid="fig0020" ref-type="fig">Fig. 4</xref><italic>a</italic>, <xref rid="fig0020" ref-type="fig">Fig. 4</xref><italic>b</italic>, <xref rid="fig0020" ref-type="fig">Fig. 4</xref><italic>c</italic>, and <xref rid="fig0020" ref-type="fig">Fig. 4</xref><italic>d</italic>. Based on these findings, we present models for RNA splicing detection and analysis in known or poorly annotated genomic distribution spectrums, which will aid groundbreaking research and clinical experiments. The possibility of uneven genomic dataset distribution in bioinformatics and clinical genetic testing scenarios emphasizes the importance of our imbalanced models.</p>
    </sec>
    <sec id="sec0060">
      <label>3.4</label>
      <title>P-value statistical significance test</title>
      <p id="p0250">The statistical significance of the accuracy results comparison for the balanced datasets presented in <xref rid="tbl0040" ref-type="table">Table 8</xref> was determined by employing the nonparametric Friedman test. This test was utilized to ascertain differences among several related groups, and mean ranks were employed to rank the groups. To perform the test, accuracy values were converted to ranks, where the highest accuracy value was assigned a rank of 1, and the lowest accuracy value received a rank equivalent to the number of models being compared. The mean rank for each model across all datasets and SS types was subsequently calculated.<table-wrap position="float" id="tbl0040"><label>Table 8</label><caption><p>The Friedman test results comparison on balanced datasets across the selected organism.</p></caption><alt-text id="at0075">Table 8</alt-text><table frame="hsides" rules="groups"><thead><tr><th>Algorithm</th><th>Rank</th><th>Mean rank</th></tr></thead><tbody><tr><td><bold>CNN Splice m1</bold></td><td><bold>1</bold></td><td><bold>1.33</bold></td></tr><tr><td>DeepSplicer</td><td>2</td><td>2.00</td></tr><tr><td>CNNSplice m4</td><td>3</td><td>3.17</td></tr><tr><td>Splice2deep</td><td>4</td><td>4.50</td></tr><tr><td>CNN Splice m3</td><td>5</td><td>4.67</td></tr><tr><td>SpliceFinder</td><td>6</td><td>5.33</td></tr><tr><td>GeneSplicer</td><td>7</td><td>6.67</td></tr><tr><td>SpliceRover</td><td>8</td><td>7.50</td></tr></tbody></table><table-wrap-foot><fn><p>This table shows the statistical significance of the Balanced SS prediction accuracy results in comparison to the state of the arts for acceptor and donor genome datasets. The tables show the Algorithm names, Friedman rank position and Mean rank values CNNSplice m1 indicates Model 1, CNNSplice m3 indicates Model 3, CNNSplice m4 indicates Model 4. Results highlighted in <bold>bold</bold> black color represent the best result.</p></fn></table-wrap-foot></table-wrap></p>
      <p id="p0255">Using the Friedman statistic formula:<disp-formula id="eqn0030"><label>(6)</label><mml:math id="M13" altimg="si0010.svg"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">Q</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:mfenced open="[" close="]"><mml:mrow><mml:mfrac><mml:mrow><mml:mn>12</mml:mn></mml:mrow><mml:mrow><mml:mrow><mml:mfenced open="(" close=")"><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mo>*</mml:mo><mml:mi mathvariant="normal">k</mml:mi><mml:mo>*</mml:mo><mml:mrow><mml:mfenced open="(" close=")"><mml:mrow><mml:mi mathvariant="normal">k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced></mml:mrow><mml:mo>*</mml:mo><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mfenced open="(" close=")"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:mrow><mml:mfenced open="[" close="]"><mml:mrow><mml:mfrac><mml:mrow><mml:mfenced open="(" close=")"><mml:mrow><mml:mi mathvariant="normal">k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mspace width="1em"/></mml:mrow></mml:math></disp-formula>where:</p>
      <p id="p0260">m = number of models being compared.</p>
      <p id="p0265">k = number of independent tests.</p>
      <p id="p0270">R² = mean rank of the i-th model across all the independent tests.</p>
      <p id="p0275">Based on Friedman test results shown in <xref rid="tbl0040" ref-type="table">Table 8</xref>, the statistical analysis using the Friedman test yielded a <italic>p-value</italic> less than 0.05, which signifies a significant difference among the models. The ranking based on mean ranks indicates that on average, CNNSplice model 1 performed the best, followed closely by DeepSplicer <xref rid="bib25" ref-type="bibr">[25]</xref> and CNNSplice model 4. Conversely, Splice2deep <xref rid="bib21" ref-type="bibr">[21]</xref>, CNNSplice model 3, SpliceFinder <xref rid="bib24" ref-type="bibr">[24]</xref>, GeneSplicer <xref rid="bib16" ref-type="bibr">[16]</xref>, and SpliceRover <xref rid="bib20" ref-type="bibr">[20]</xref> had lower mean ranks, indicating less consistent performance across the various datasets and SS types.</p>
    </sec>
    <sec id="sec0065">
      <label>3.5</label>
      <title>Generalizability test</title>
      <p id="p0280">To assess the generalizability of our approach, we employed an empirical sliding window program that allowed for the efficient selection of local flanking regions and the identification of the SS-containing region based on the dataset under investigation. Furthermore, we enhanced the nonlinearity expression capabilities of our model by enriching its fully connected layer and augmented the proportion of noncanonical SS in the training dataset to improve the model’s ability to detect such SS. This augmentation contributed to an improvement in the model’s generalizability. Each of the organism-generated models underwent the same procedure. For example, a <italic>Caenorhabditis elegans</italic> model was tested utilizing datasets from <italic>Homo sapiens</italic>, <italic>Oryza sativa japonica</italic>, <italic>Arabidopsis thaliana</italic>, and <italic>Drosophila melanogaster</italic>. The results are reported in <xref rid="fig0025" ref-type="fig">Fig. 5</xref> and demonstrate CNNSplice’s higher performance over other methodologies, as well as the fact that CNNSplice’s cross-organism test outperformed some other tools trained and tested on the same datasets. For example, CNNSplice balanced acceptor model, trained on <italic>Caenorhabditis elegans</italic> and tested on <italic>Drosophila melanogaster</italic>, has a prediction accuracy of 94.77 %, compared to 86.60 % and 91.97 % for SpliceFinder <xref rid="bib24" ref-type="bibr">[24]</xref> and DeepSplicer <xref rid="bib25" ref-type="bibr">[25]</xref> respectively, when trained and tested on <italic>Drosophila melanogaster</italic> balanced acceptor genome organism datasets. This result further validates CNNSplice’s capacity to predict and annotate newly introduced or previously unseen sequenced genome datasets.<fig id="fig0025"><label>Fig. 5</label><caption><p>The models’ Generalizability comparison on Balanced datasets across the selected organism. This figure shows the generalization comparison plot for CNNSplice model and other methods. This experiment is done on the selected genome organism dataset with CNNSplice model 1 and the other methods applicable models. No data or bar represent methods with no available models or model architecture for ss testing. We used the balanced dataset to effectively represent all methods involved in the generalization experiments. The Y-axis of the plots represents the prediction accuracy in percentage (%) while the X-axis represents the name of the genome organism used for the experiment.</p></caption><alt-text id="at0025">Fig. 5</alt-text><graphic xlink:href="gr5"/></fig></p>
    </sec>
    <sec id="sec0070">
      <label>3.6</label>
      <title>Understanding CNNSplice model outputs</title>
      <p id="p0285">We determined the average regional contribution and importance score to assess the impact of our feature extraction on the interpretation of our model’s prediction <xref rid="bib31" ref-type="bibr">[31]</xref>. To accomplish this, we analyzed and determined the feature that powers our model prediction by using motif extraction and visualization. A motif is a collection of subsequences related to a decision process <xref rid="bib19" ref-type="bibr">[19]</xref>. With the help of Shap <xref rid="bib32" ref-type="bibr">[32]</xref>, we were able to determine the contribution score of each feature instance inside the sequencing window and, as a result, decipher the underlying pattern of our dataset’s characteristics. Shap (SHapley Additive exPlanation) is an approximation approach to explain a machine learning model’s feature output. This tool uses the game theory approach to explain the importance of features in a model. The sequence logo is made up of the contribution score generated from the sequence patterns. WebLogo version 3.7.4 <xref rid="bib33" ref-type="bibr">[33]</xref> (available at http://weblogo.threeplusone.com/create.cgi) is used to produce the sequence logos. For both the acceptor and donor organism datasets, we randomly picked 100 sequences of each organism. Sequence positions 295–305 are represented by the magnitude of the genomic sequence characters in the motif. As shown <italic>in</italic>
<xref rid="fig0030" ref-type="fig">Fig. 6</xref> and <xref rid="fig0035" ref-type="fig">Fig. 7</xref>, AG significantly contributes to the prediction of the acceptor site for each organism dataset, as GT contributes to the prediction of the donor site.<fig id="fig0030"><label>Fig. 6</label><caption><p>Result validation for acceptor splice site organism. This Figure shows the sequence logo of <italic>the Homo sapiens, Oryza sativa japonica, Arabidopsis thaliana, Drosophila melanogaster, and Caenorhabditis elegans</italic> organisms acceptor splice sites within genomic sequence position 295 and 305. This nucleotide sequence pattern likelihood is depicted by the magnitude of the genomic sequence characters in the motif representation.</p></caption><alt-text id="at0030">Fig. 6</alt-text><graphic xlink:href="gr6"/></fig><fig id="fig0035"><label>Fig. 7</label><caption><p>Result validation for donor splice site organism. This Figure shows the sequence logo of the <italic>Homo sapiens, Oryza sativa japonica, Arabidopsis thaliana, Drosophila melanogaster, and Caenorhabditis elegans</italic> organisms donor splice sites within genomic sequence position 295 and 305. This nucleotide sequence pattern likelihood is depicted by the magnitude of the genomic sequence characters in the motif representation.</p></caption><alt-text id="at0035">Fig. 7</alt-text><graphic xlink:href="gr7"/></fig></p>
    </sec>
    <sec id="sec0075">
      <label>3.7</label>
      <title>CNNSplice webserver</title>
      <p id="p0290">We have developed a webserver accessible at <bold>http://www.cnnsplice.online</bold> for the purpose of this project. The webserver allows users to input a FASTA sequence or upload a FASTA file, following specific criteria outlined in the "About" Tab. Users must select a pre-trained model for different organisms and provide an email address for notification about a job submission and about the completion of the submission prediction. The completed job will be sent to the user via email as a text file attachment, indicating the presence or absence of a splice site for each sequence in the provided FASTA data using binary data (1 for detection, 0 for no detection). To assist users, we have included a tutorial and user guide with examples accessible through the "Tutorial/Example" Tab on the webserver.</p>
    </sec>
  </sec>
  <sec id="sec0080">
    <label>4</label>
    <title>Conclusion</title>
    <p id="p0295">In this paper, we presented CNNSplice, a powerful biological tool for predicting SS. This bioinformatics solution stems from the biological procedures of RNA splicing that are required for protein synthesis and gene expression. Our method extracts raw genomic features, maps them using one-hot encoding, and feeds them into the CNN architecture as inputs. We selected the best five models based on our five-fold cross-validation, with our model offering superior prediction performance than previous SS prediction tools for both balanced and imbalanced datasets, as stated in the results sections. Furthermore, we showed that the CNNSplice model trained on the organisms utilized in the research may be applied to another species without losing any information, demonstrating its generalizability in annotating new organisms. Based on our findings, we can conclude that CNNSplice offers the following advantages:<list list-type="simple" id="li0020"><list-item id="u0100"><label>(1)</label><p id="p0300">CNNSplice is a convenient two-class model that predicts true and false SS in both salient canonical and noncanonical SS.</p></list-item><list-item id="u0105"><label>(2)</label><p id="p0305">Our analysis shows that CNNSplice models outperform previous approaches, with our models occupying the Top-1 and Top-2 performance positions across all organisms for both balanced and imbalanced acceptor and donor datasets (<xref rid="fig0020" ref-type="fig">Fig. 4</xref>). In general, depending on the detection and the organism under consideration, each of these model architectures has its own advantages.</p></list-item><list-item id="u0110"><label>(3)</label><p id="p0310">As described in the generalization section, CNNSplice Model 1 provides a robust tool to predict and annotate poorly studied or newly sequenced genomic datasets (<xref rid="fig0025" ref-type="fig">Fig. 5</xref>). In other words, despite being trained on one genomic organism dataset and evaluated on a different organism dataset, this model yields a high SS prediction accuracy.</p></list-item></list></p>
    <p id="p0315">Our results show that CNNSplice can extract high-level features and locate SS genomic sequence patterns, which may then be used to infer gene expression information as seen in <xref rid="fig0025" ref-type="fig">Fig. 5</xref> for phenotype anomaly and diseases analysis.</p>
  </sec>
  <sec id="sec0085">
    <title>Funding</title>
    <p id="p0320">This work was supported by the start-up funding from the <funding-source id="gs1"><institution-wrap><institution-id institution-id-type="doi">10.13039/100010174</institution-id><institution>University of Colorado</institution></institution-wrap></funding-source>, Colorado Springs to O.O.</p>
  </sec>
  <sec id="sec0090">
    <title>CRediT authorship contribution statement</title>
    <p id="p0325"><bold>Victor Akpokiro:</bold> Methodology, Software, Investigation, Data curation, Analysis, Writing – original draft, Writing – review &amp; editing, Validation. <bold>H. M. A. Mohit Chowdhury:</bold> Software, Investigation, Analysis, Writing – review &amp; editing, Validation. <bold>Samuel Olowofila:</bold> Software, Writing – review &amp; editing, Validation. <bold>Raisa Nusrat:</bold> Software, Writing – review &amp; editing, Validation. <bold>Oluwatosin Oluwadare:</bold> Conceptualization, Methodology, Analysis, Writing – review &amp; editing, Supervision, Resources, Project administration, Funding acquisition.</p>
  </sec>
  <sec sec-type="COI-statement">
    <title>Declaration of Competing interest</title>
    <p id="p0330">The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.</p>
  </sec>
</body>
<back>
  <ref-list id="bibliog0005">
    <title>References</title>
    <ref id="bib1">
      <label>1</label>
      <element-citation publication-type="journal" id="sbref1">
        <person-group person-group-type="author">
          <name>
            <surname>Goel</surname>
            <given-names>N.</given-names>
          </name>
          <name>
            <surname>Singh</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Aseri</surname>
            <given-names>T.C.</given-names>
          </name>
        </person-group>
        <article-title>A review of soft computing techniques for gene prediction</article-title>
        <source>Int Sch Res Not</source>
        <year>2013</year>
        <fpage>2013</fpage>
      </element-citation>
    </ref>
    <ref id="bib2">
      <label>2</label>
      <element-citation publication-type="journal" id="sbref2">
        <person-group person-group-type="author">
          <name>
            <surname>Schellenberg</surname>
            <given-names>M.J.</given-names>
          </name>
          <name>
            <surname>Ritchie</surname>
            <given-names>D.B.</given-names>
          </name>
          <name>
            <surname>MacMillan</surname>
            <given-names>A.M.</given-names>
          </name>
        </person-group>
        <article-title>Pre-mRNA splicing: a complex picture in higher definition</article-title>
        <source>Trends Biochem Sci</source>
        <volume>33</volume>
        <issue>6</issue>
        <year>2008</year>
        <fpage>243</fpage>
        <lpage>246</lpage>
        <pub-id pub-id-type="pmid">18472266</pub-id>
      </element-citation>
    </ref>
    <ref id="bib3">
      <label>3</label>
      <element-citation publication-type="journal" id="sbref3">
        <person-group person-group-type="author">
          <name>
            <surname>Sleator</surname>
            <given-names>R.D.</given-names>
          </name>
        </person-group>
        <article-title>An overview of the current status of eukaryote gene prediction strategies</article-title>
        <source>Gene</source>
        <volume>461</volume>
        <issue>1–2</issue>
        <year>2010</year>
        <fpage>1</fpage>
        <lpage>4</lpage>
        <pub-id pub-id-type="pmid">20430068</pub-id>
      </element-citation>
    </ref>
    <ref id="bib4">
      <label>4</label>
      <element-citation publication-type="journal" id="sbref4">
        <person-group person-group-type="author">
          <name>
            <surname>Baten</surname>
            <given-names>A.K.</given-names>
          </name>
          <name>
            <surname>Halgamuge</surname>
            <given-names>S.K.</given-names>
          </name>
          <name>
            <surname>Chang</surname>
            <given-names>B.C.</given-names>
          </name>
        </person-group>
        <article-title>Fast splice site detection using information content and feature reduction</article-title>
        <source>BMC Bioinform</source>
        <volume>9</volume>
        <issue>12</issue>
        <year>2008</year>
        <fpage>1</fpage>
        <lpage>12</lpage>
      </element-citation>
    </ref>
    <ref id="bib5">
      <label>5</label>
      <element-citation publication-type="journal" id="sbref5">
        <person-group person-group-type="author">
          <name>
            <surname>Burset</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Seledtsov</surname>
            <given-names>I.A.</given-names>
          </name>
          <name>
            <surname>Solovyev</surname>
            <given-names>V.V.</given-names>
          </name>
        </person-group>
        <article-title>Analysis of canonical and non-canonical splice sites in mammalian genomes</article-title>
        <source>Nucleic Acids Res</source>
        <volume>28</volume>
        <issue>21</issue>
        <year>2000</year>
        <fpage>4364</fpage>
        <lpage>4375</lpage>
        <pub-id pub-id-type="pmid">11058137</pub-id>
      </element-citation>
    </ref>
    <ref id="bib6">
      <label>6</label>
      <mixed-citation publication-type="other" id="othref0005">Reese, M. G., Eeckman, F. H., Kulp, D., &amp; Haussler, D. Improved splice site detection in Genie. In: Proceedings of the first annual international conference on computational molecular biology; 1997, January. p. 232–40).</mixed-citation>
    </ref>
    <ref id="bib7">
      <label>7</label>
      <element-citation publication-type="journal" id="sbref6">
        <person-group person-group-type="author">
          <name>
            <surname>Zhang</surname>
            <given-names>X.H.</given-names>
          </name>
          <name>
            <surname>Heller</surname>
            <given-names>K.A.</given-names>
          </name>
          <name>
            <surname>Hefter</surname>
            <given-names>I.</given-names>
          </name>
          <name>
            <surname>Leslie</surname>
            <given-names>C.S.</given-names>
          </name>
          <name>
            <surname>Chasin</surname>
            <given-names>L.A.</given-names>
          </name>
        </person-group>
        <article-title>Sequence information for the splicing of human pre-mRNA identified by support vector machine classification</article-title>
        <source>Genome Res</source>
        <volume>13</volume>
        <issue>12</issue>
        <year>2003</year>
        <fpage>2637</fpage>
        <lpage>2650</lpage>
        <pub-id pub-id-type="pmid">14656968</pub-id>
      </element-citation>
    </ref>
    <ref id="bib8">
      <label>8</label>
      <element-citation publication-type="journal" id="sbref7">
        <person-group person-group-type="author">
          <name>
            <surname>Sun</surname>
            <given-names>Y.F.</given-names>
          </name>
          <name>
            <surname>Fan</surname>
            <given-names>X.D.</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>Y.D.</given-names>
          </name>
        </person-group>
        <article-title>Identifying splicing sites in eukaryotic RNA: support vector machine approach</article-title>
        <source>Comput Biol Med</source>
        <volume>33</volume>
        <issue>1</issue>
        <year>2003</year>
        <fpage>17</fpage>
        <lpage>29</lpage>
        <pub-id pub-id-type="pmid">12485627</pub-id>
      </element-citation>
    </ref>
    <ref id="bib9">
      <label>9</label>
      <mixed-citation publication-type="other" id="othref0010">Yeo, G., Burge, C. B. Maximum entropy modeling of short sequence motifs with applications to RNA splicing signals. In: Proceedings of the seventh annual international conference on research in computational molecular biology; 2003, April. p. 322–31).</mixed-citation>
    </ref>
    <ref id="bib10">
      <label>10</label>
      <element-citation publication-type="journal" id="sbref8">
        <person-group person-group-type="author">
          <name>
            <surname>Zhang</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Gish</surname>
            <given-names>W.</given-names>
          </name>
        </person-group>
        <article-title>Improved spliced alignment from an information theoretic approach</article-title>
        <source>Bioinformatics</source>
        <volume>22</volume>
        <issue>1</issue>
        <year>2006</year>
        <fpage>13</fpage>
        <lpage>20</lpage>
        <pub-id pub-id-type="pmid">16267086</pub-id>
      </element-citation>
    </ref>
    <ref id="bib11">
      <label>11</label>
      <element-citation publication-type="journal" id="sbref9">
        <person-group person-group-type="author">
          <name>
            <surname>Arita</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Tsuda</surname>
            <given-names>K.</given-names>
          </name>
          <name>
            <surname>Asai</surname>
            <given-names>K.</given-names>
          </name>
        </person-group>
        <article-title>Modeling splicing sites with pairwise correlations</article-title>
        <source>Bioinformatics</source>
        <volume>18</volume>
        <issue>suppl_2</issue>
        <year>2002</year>
        <fpage>S27</fpage>
        <lpage>S34</lpage>
        <pub-id pub-id-type="pmid">12385980</pub-id>
      </element-citation>
    </ref>
    <ref id="bib12">
      <label>12</label>
      <element-citation publication-type="journal" id="sbref10">
        <person-group person-group-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>T.M.</given-names>
          </name>
          <name>
            <surname>Lu</surname>
            <given-names>C.C.</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>W.H.</given-names>
          </name>
        </person-group>
        <article-title>Prediction of splice sites with dependency graphs and their expanded bayesian networks</article-title>
        <source>Bioinformatics</source>
        <volume>21</volume>
        <issue>4</issue>
        <year>2005</year>
        <fpage>471</fpage>
        <lpage>482</lpage>
        <pub-id pub-id-type="pmid">15374869</pub-id>
      </element-citation>
    </ref>
    <ref id="bib13">
      <label>13</label>
      <element-citation publication-type="journal" id="sbref11">
        <person-group person-group-type="author">
          <name>
            <surname>Burge</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Karlin</surname>
            <given-names>S.</given-names>
          </name>
        </person-group>
        <article-title>Prediction of complete gene structures in human genomic DNA</article-title>
        <source>J Mol Biol</source>
        <volume>268</volume>
        <issue>1</issue>
        <year>1997</year>
        <fpage>78</fpage>
        <lpage>94</lpage>
        <pub-id pub-id-type="pmid">9149143</pub-id>
      </element-citation>
    </ref>
    <ref id="bib14">
      <label>14</label>
      <mixed-citation publication-type="other" id="othref0015">Chuang, J. S., Roth, D. Splice site prediction using a sparse network of winnows; 2001.</mixed-citation>
    </ref>
    <ref id="bib15">
      <label>15</label>
      <element-citation publication-type="journal" id="sbref12">
        <person-group person-group-type="author">
          <name>
            <surname>Rajapakse</surname>
            <given-names>J.C.</given-names>
          </name>
          <name>
            <surname>Ho</surname>
            <given-names>L.S.</given-names>
          </name>
        </person-group>
        <article-title>Markov encoding for detecting signals in genomic sequences</article-title>
        <source>IEEE/ACM Trans Comput Biol Bioinform</source>
        <volume>2</volume>
        <issue>2</issue>
        <year>2005</year>
        <fpage>131</fpage>
        <lpage>142</lpage>
        <pub-id pub-id-type="pmid">17044178</pub-id>
      </element-citation>
    </ref>
    <ref id="bib16">
      <label>16</label>
      <element-citation publication-type="journal" id="sbref13">
        <person-group person-group-type="author">
          <name>
            <surname>Pertea</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Lin</surname>
            <given-names>X.</given-names>
          </name>
          <name>
            <surname>Salzberg</surname>
            <given-names>S.L.</given-names>
          </name>
        </person-group>
        <article-title>GeneSplicer: a new computational method for splice site prediction</article-title>
        <source>Nucleic Acids Res</source>
        <volume>29</volume>
        <issue>5</issue>
        <year>2001</year>
        <fpage>1185</fpage>
        <lpage>1190</lpage>
        <pub-id pub-id-type="pmid">11222768</pub-id>
      </element-citation>
    </ref>
    <ref id="bib17">
      <label>17</label>
      <element-citation publication-type="journal" id="sbref14">
        <person-group person-group-type="author">
          <name>
            <surname>Pashaei</surname>
            <given-names>E.</given-names>
          </name>
          <name>
            <surname>Aydin</surname>
            <given-names>N.</given-names>
          </name>
        </person-group>
        <article-title>Markovian encoding models in human splice site recognition using SVM</article-title>
        <source>Comput Biol Chem</source>
        <volume>73</volume>
        <year>2018</year>
        <fpage>159</fpage>
        <lpage>170</lpage>
        <pub-id pub-id-type="pmid">29486390</pub-id>
      </element-citation>
    </ref>
    <ref id="bib18">
      <label>18</label>
      <mixed-citation publication-type="other" id="othref0020">Pashaei, E., Yilmaz, A., Ozen, M., Aydin, N. A novel method for splice sites prediction using sequence component and hidden Markov model. In: Proceedings of the thirty eightieth annual international conference of the IEEE engineering in medicine and biology society (EMBC). IEEE; 2016, August. p. 3076–9).</mixed-citation>
    </ref>
    <ref id="bib19">
      <label>19</label>
      <element-citation publication-type="journal" id="sbref15">
        <person-group person-group-type="author">
          <name>
            <surname>Du</surname>
            <given-names>X.</given-names>
          </name>
          <name>
            <surname>Yao</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Diao</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Zhu</surname>
            <given-names>H.</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>S.</given-names>
          </name>
        </person-group>
        <article-title>Deepss: exploring splice site motif through convolutional neural network directly from dna sequence</article-title>
        <source>IEEE Access</source>
        <volume>6</volume>
        <year>2018</year>
        <fpage>32958</fpage>
        <lpage>32978</lpage>
      </element-citation>
    </ref>
    <ref id="bib20">
      <label>20</label>
      <element-citation publication-type="journal" id="sbref16">
        <person-group person-group-type="author">
          <name>
            <surname>Zuallaert</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Godin</surname>
            <given-names>F.</given-names>
          </name>
          <name>
            <surname>Kim</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Soete</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Saeys</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>De Neve</surname>
            <given-names>W.</given-names>
          </name>
        </person-group>
        <article-title>SpliceRover: interpretable convolutional neural networks for improved splice site prediction</article-title>
        <source>Bioinformatics</source>
        <volume>34</volume>
        <issue>24</issue>
        <year>2018</year>
        <fpage>4180</fpage>
        <lpage>4188</lpage>
        <pub-id pub-id-type="pmid">29931149</pub-id>
      </element-citation>
    </ref>
    <ref id="bib21">
      <label>21</label>
      <element-citation publication-type="journal" id="sbref17">
        <person-group person-group-type="author">
          <name>
            <surname>Albaradei</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Magana-Mora</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Thafar</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Uludag</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Bajic</surname>
            <given-names>V.B.</given-names>
          </name>
          <name>
            <surname>Gojobori</surname>
            <given-names>T.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Splice2Deep: an ensemble of deep convolutional neural networks for improved splice site prediction in genomic DNA</article-title>
        <source>Gene</source>
        <volume>763</volume>
        <year>2020</year>
        <object-id pub-id-type="publisher-id">100035</object-id>
      </element-citation>
    </ref>
    <ref id="bib22">
      <label>22</label>
      <element-citation publication-type="journal" id="sbref18">
        <person-group person-group-type="author">
          <name>
            <surname>Tayara</surname>
            <given-names>H.</given-names>
          </name>
          <name>
            <surname>Tahir</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Chong</surname>
            <given-names>K.T.</given-names>
          </name>
        </person-group>
        <article-title>iSS-CNN: identifying splicing sites using convolution neural network</article-title>
        <source>Chemom Intell Lab Syst</source>
        <volume>188</volume>
        <year>2019</year>
        <fpage>63</fpage>
        <lpage>69</lpage>
      </element-citation>
    </ref>
    <ref id="bib23">
      <label>23</label>
      <element-citation publication-type="journal" id="sbref19">
        <person-group person-group-type="author">
          <name>
            <surname>Jaganathan</surname>
            <given-names>K.</given-names>
          </name>
          <name>
            <surname>Panagiotopoulou</surname>
            <given-names>S.K.</given-names>
          </name>
          <name>
            <surname>McRae</surname>
            <given-names>J.F.</given-names>
          </name>
          <name>
            <surname>Darbandi</surname>
            <given-names>S.F.</given-names>
          </name>
          <name>
            <surname>Knowles</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>Y.I.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Predicting splicing from primary sequence with deep learning</article-title>
        <source>Cell</source>
        <volume>176</volume>
        <issue>3</issue>
        <year>2019</year>
        <fpage>535</fpage>
        <lpage>548</lpage>
        <pub-id pub-id-type="pmid">30661751</pub-id>
      </element-citation>
    </ref>
    <ref id="bib24">
      <label>24</label>
      <element-citation publication-type="journal" id="sbref20">
        <person-group person-group-type="author">
          <name>
            <surname>Wang</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>Z.</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>S.</given-names>
          </name>
        </person-group>
        <article-title>SpliceFinder: ab initio prediction of splice sites using convolutional neural network</article-title>
        <source>BMC Bioinform</source>
        <volume>20</volume>
        <issue>23</issue>
        <year>2019</year>
        <fpage>1</fpage>
        <lpage>13</lpage>
      </element-citation>
    </ref>
    <ref id="bib25">
      <label>25</label>
      <mixed-citation publication-type="other" id="othref0025">Akpokiro, V., Oluwadare, O., Kalita, J. DeepSplicer: an improved method of splice sites prediction using deep learning. In Proceedings of the twentieth IEEE international conference on machine learning and applications (ICMLA). IEEE; 2021, December. p. 606-9.</mixed-citation>
    </ref>
    <ref id="bib26">
      <label>26</label>
      <element-citation publication-type="journal" id="sbref21">
        <person-group person-group-type="author">
          <name>
            <surname>Ghosh</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Sufian</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Sultana</surname>
            <given-names>F.</given-names>
          </name>
          <name>
            <surname>Chakrabarti</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>De</surname>
            <given-names>D.</given-names>
          </name>
        </person-group>
        <article-title>Fundamental concepts of convolutional neural network</article-title>
        <source>Recent Trends Adv Artif Intell Internet Things</source>
        <year>2020</year>
        <fpage>519</fpage>
        <lpage>567</lpage>
      </element-citation>
    </ref>
    <ref id="bib27">
      <label>27</label>
      <mixed-citation publication-type="other" id="othref0030">Hara, K., Saito, D., Shouno, H. Analysis of function of rectified linear unit used in deep learning. In 2015 international joint conference on neural networks (IJCNN). IEEE; 2015, July. p. 1-8.</mixed-citation>
    </ref>
    <ref id="bib28">
      <label>28</label>
      <element-citation publication-type="journal" id="sbref22">
        <person-group person-group-type="author">
          <name>
            <surname>Srivastava</surname>
            <given-names>N.</given-names>
          </name>
          <name>
            <surname>Hinton</surname>
            <given-names>G.</given-names>
          </name>
          <name>
            <surname>Krizhevsky</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Sutskever</surname>
            <given-names>I.</given-names>
          </name>
          <name>
            <surname>Salakhutdinov</surname>
            <given-names>R.</given-names>
          </name>
        </person-group>
        <article-title>Dropout: a simple way to prevent neural networks from overfitting</article-title>
        <source>J Mach Learn Res</source>
        <volume>15</volume>
        <issue>1</issue>
        <year>2014</year>
        <fpage>1929</fpage>
        <lpage>1958</lpage>
      </element-citation>
    </ref>
    <ref id="bib29">
      <label>29</label>
      <element-citation publication-type="book" id="sbref23">
        <person-group person-group-type="author">
          <name>
            <surname>Bishop</surname>
            <given-names>C.M.</given-names>
          </name>
          <name>
            <surname>Nasrabadi</surname>
            <given-names>N.M.</given-names>
          </name>
        </person-group>
        <series>Pattern recognition and machine learning</series>
        <volume>4</volume>
        <year>2006</year>
        <publisher-name>Springer</publisher-name>
        <publisher-loc>New York</publisher-loc>
        <fpage>738</fpage>
      </element-citation>
    </ref>
    <ref id="bib30">
      <label>30</label>
      <element-citation publication-type="journal" id="sbref24">
        <person-group person-group-type="author">
          <name>
            <surname>Mount</surname>
            <given-names>S.M.</given-names>
          </name>
        </person-group>
        <article-title>A catalogue of splice junction sequences</article-title>
        <source>Nucleic Acids Res</source>
        <volume>10</volume>
        <issue>2</issue>
        <year>1982</year>
        <fpage>459</fpage>
        <lpage>472</lpage>
        <pub-id pub-id-type="pmid">7063411</pub-id>
      </element-citation>
    </ref>
    <ref id="bib31">
      <label>31</label>
      <element-citation publication-type="journal" id="sbref25">
        <person-group person-group-type="author">
          <name>
            <surname>Ribeiro</surname>
            <given-names>M.T.</given-names>
          </name>
          <name>
            <surname>Singh</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Guestrin</surname>
            <given-names>C.</given-names>
          </name>
        </person-group>
        <article-title>Model-agnostic interpretability of machine learning</article-title>
        <source>arXiv Prepr arXiv</source>
        <volume>1606</volume>
        <year>2016</year>
        <fpage>05386</fpage>
      </element-citation>
    </ref>
    <ref id="bib32">
      <label>32</label>
      <element-citation publication-type="journal" id="sbref26">
        <person-group person-group-type="author">
          <name>
            <surname>Lundberg</surname>
            <given-names>S.M.</given-names>
          </name>
          <name>
            <surname>Lee</surname>
            <given-names>S.I.</given-names>
          </name>
        </person-group>
        <article-title>A unified approach to interpreting model predictions</article-title>
        <source>Adv Neural Inf Process Syst</source>
        <year>2017</year>
        <fpage>30</fpage>
      </element-citation>
    </ref>
    <ref id="bib33">
      <label>33</label>
      <element-citation publication-type="journal" id="sbref27">
        <person-group person-group-type="author">
          <name>
            <surname>Crooks</surname>
            <given-names>G.E.</given-names>
          </name>
          <name>
            <surname>Hon</surname>
            <given-names>G.</given-names>
          </name>
          <name>
            <surname>Chandonia</surname>
            <given-names>J.M.</given-names>
          </name>
          <name>
            <surname>Brenner</surname>
            <given-names>S.E.</given-names>
          </name>
        </person-group>
        <article-title>WebLogo: a sequence logo generator</article-title>
        <source>Genome Res</source>
        <volume>14</volume>
        <issue>6</issue>
        <year>2004</year>
        <fpage>1188</fpage>
        <lpage>1190</lpage>
        <pub-id pub-id-type="pmid">15173120</pub-id>
      </element-citation>
    </ref>
  </ref-list>
  <sec sec-type="data-availability" id="da0005">
    <title>Data availability</title>
    <p id="p0005">CNNSplice’s data, models generated, and source code are available as an open-source software at https://github.com/OluwadareLab/CNNSplice. We have included a docker-containerized environment with all dependencies for local install and program runs in the CNNSplice repository.</p>
  </sec>
  <ack id="ack0005">
    <title>Acknowledgements</title>
    <p id="p0335">Not applicable.</p>
  </ack>
</back>
<?DTDIdentifier.IdentifierValue -//ES//DTD journal article DTD version 5.6.0//EN//XML?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName art560.dtd?>
<?SourceDTD.Version 5.6.0?>
<?ConverterInfo.XSLTName elsevier2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<?origin publisher?>
<?FILEmeta_CSBJ2177 xml ?>
<?FILEmain xml ?>
<?FILEmain pdf ?>
<?FILEgr1 jpg ?>
<?FILEgr2 jpg ?>
<?FILEgr3 jpg ?>
<?FILEgr4 jpg ?>
<?FILEgr5 jpg ?>
<?FILEgr6 jpg ?>
<?FILEgr7 jpg ?>
<?FILEfx1 jpg ?>
<?FILEfx2 jpg ?>
<?FILEfx3 jpg ?>
<?FILEfx4 jpg ?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Comput Struct Biotechnol J</journal-id>
    <journal-id journal-id-type="iso-abbrev">Comput Struct Biotechnol J</journal-id>
    <journal-title-group>
      <journal-title>Computational and Structural Biotechnology Journal</journal-title>
    </journal-title-group>
    <issn pub-type="epub">2001-0370</issn>
    <publisher>
      <publisher-name>Research Network of Computational and Structural Biotechnology</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">10250157</article-id>
    <article-id pub-id-type="pii">S2001-0370(23)00212-X</article-id>
    <article-id pub-id-type="doi">10.1016/j.csbj.2023.05.031</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Method Article</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>CNNSplice: Robust models for splice site prediction using convolutional neural networks</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" id="au0005">
        <name>
          <surname>Akpokiro</surname>
          <given-names>Victor</given-names>
        </name>
      </contrib>
      <contrib contrib-type="author" id="au0010">
        <name>
          <surname>Chowdhury</surname>
          <given-names>H. M. A. Mohit</given-names>
        </name>
      </contrib>
      <contrib contrib-type="author" id="au0015">
        <name>
          <surname>Olowofila</surname>
          <given-names>Samuel</given-names>
        </name>
      </contrib>
      <contrib contrib-type="author" id="au0020">
        <name>
          <surname>Nusrat</surname>
          <given-names>Raisa</given-names>
        </name>
      </contrib>
      <contrib contrib-type="author" id="au0025">
        <name>
          <surname>Oluwadare</surname>
          <given-names>Oluwatosin</given-names>
        </name>
        <email>ooluwada@uccs.edu</email>
        <xref rid="cor1" ref-type="corresp">⁎</xref>
      </contrib>
      <aff id="aff0005">Department of Computer Science, University of Colorado, Colorado Springs, CO 80918, United States</aff>
    </contrib-group>
    <author-notes>
      <corresp id="cor1"><label>⁎</label>Corresponding author. <email>ooluwada@uccs.edu</email></corresp>
    </author-notes>
    <pub-date pub-type="pmc-release">
      <day>30</day>
      <month>5</month>
      <year>2023</year>
    </pub-date>
    <!-- PMC Release delay is 0 months and 0 days and was based on <pub-date
						pub-type="epub">.-->
    <pub-date pub-type="collection">
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="epub">
      <day>30</day>
      <month>5</month>
      <year>2023</year>
    </pub-date>
    <volume>21</volume>
    <fpage>3210</fpage>
    <lpage>3223</lpage>
    <history>
      <date date-type="received">
        <day>1</day>
        <month>2</month>
        <year>2023</year>
      </date>
      <date date-type="rev-recd">
        <day>25</day>
        <month>5</month>
        <year>2023</year>
      </date>
      <date date-type="accepted">
        <day>28</day>
        <month>5</month>
        <year>2023</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© 2023 The Authors</copyright-statement>
      <copyright-year>2023</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).</license-p>
      </license>
    </permissions>
    <abstract id="ab0010">
      <p>The identification of splice site, or segments of an RNA gene where noncoding and coding sequences are connected in the 5′ and 3′ directions, is an essential post-transcriptional step for the annotation of functional genes and is required for the study and analysis of biological function in eukaryotic organisms through protein production and gene expression. Splice site detection tools have been proposed for this purpose; however, the models of these tools have a specific use case and are inefficiently or typically untransferable between organisms. Here, we present CNNSplice, a set of deep convolutional neural network models for splice site prediction. Using the five-fold cross-validation model selection technique, we explore several models based on typical machine learning applications and propose five high-performing models to efficiently predict the true and false SS in balanced and imbalanced datasets. Our evaluation results indicate that CNNSplice’s models achieve a better performance compared with existing methods across five organisms’ datasets. In addition, our generality test shows CNNSplice’s model ability to predict and annotate splice sites in new or poorly trained genome datasets indicating a broad application spectrum. CNNSplice demonstrates improved model prediction, interpretability, and generalizability on genomic datasets compared to existing splice site prediction tools. We have developed a web server for the CNNSplice algorithm which can be publicly accessed here: http://www.cnnsplice.online</p>
    </abstract>
    <kwd-group id="keys0005">
      <title>Keywords</title>
      <kwd>Splice sites (SS)</kwd>
      <kwd>Deep Learning (DL)</kwd>
      <kwd>Convolutional neural network (CNN)</kwd>
      <kwd>Dense Neural network (DNN)</kwd>
      <kwd>Feature extraction</kwd>
    </kwd-group>
  </article-meta>
</front>
<body>
  <sec id="sec0005">
    <label>1</label>
    <title>Introduction</title>
    <p id="p0010">Gene annotation is essential to understanding the biological function of the genomic sequence in living organisms <xref rid="bib1" ref-type="bibr">[1]</xref>. RNA splicing—a subtask of gene annotation—involves removing the noncoding regions (introns) and joins the protein-coding regions (exons) in the eukaryotic gene, which in turn is required for gene expression and protein synthesis comprehension. The transition points between the exons and introns are called splice sites (SS). This splicing process, which occurs during gene transcription, involves converting pre-mRNA to mRNA to extract crucial information from the nucleus and express it (translated into actual protein). RNA splicing is the term for this process. Eukaryotes have huge genome sizes and small exons that are surrounded by large introns <xref rid="bib1" ref-type="bibr">[1]</xref>. In the direction 3′ to 5′ of the intron downstream, the consensus AG dinucleotide sequence is expressed as an acceptor SS, and in the direction 5′ to 3′ of the intron upstream, the consensus GT sequence is expressed as a donor SS <xref rid="bib2" ref-type="bibr">[2]</xref>, <xref rid="bib3" ref-type="bibr">[3]</xref>, <xref rid="bib4" ref-type="bibr">[4]</xref>. Acceptor and donor SS with AG and GT dinucleotide pairings make up the salient amount of SS in a genome and are both known as canonical SS <xref rid="bib5" ref-type="bibr">[5]</xref>, with noncanonical SS also observed. The canonical sequence distribution in an SS location, as well as intron splicing, are depicted in <xref rid="fig0005" ref-type="fig">Fig. 1</xref> as a pictorial representation of the SS biochemical process. Thus, many fast and efficient computational-based approaches/algorithms have been developed for SS prediction, and these algorithms can be categorized into subgroups such as the machine learning approach <xref rid="bib6" ref-type="bibr">[6]</xref>, <xref rid="bib7" ref-type="bibr">[7]</xref>, <xref rid="bib8" ref-type="bibr">[8]</xref>, which utilizes nonlinear transformation to perform feature extraction by learning patterns from consensus AG/GT dinucleotide combination and their surrounding molecules; information gain theory <xref rid="bib9" ref-type="bibr">[9]</xref>, <xref rid="bib10" ref-type="bibr">[10]</xref>, <xref rid="bib11" ref-type="bibr">[11]</xref>, which measures the degree of mixing of classes for all samples and any position in the nucleotide sequences; probabilistic measure <xref rid="bib12" ref-type="bibr">[12]</xref>, <xref rid="bib13" ref-type="bibr">[13]</xref>, which computes the maximum likelihood from the probability of a specific SS position; and discriminant analysis approach <xref rid="bib14" ref-type="bibr">[14]</xref>, which applies the statistical measure to determine a particular position of consensus AG/GT nucleotide sequence. The extraction of features or consensus patterns from a group of nucleotide sequences to detect or create links between SS and their surrounding regions is a common element of these approaches. Of all these method subgroups, two machine learning-based algorithms—deep learning (DL) and support vector machine (SVM)—offer more optimal approaches, including shorter prediction time with increased accuracy, and have recently been a prominent approach to SS prediction. To predict SS, many SVM models use a combination of Markov models (MM) and maximum dependency decomposition (MDD) <xref rid="bib13" ref-type="bibr">[13]</xref>, <xref rid="bib15" ref-type="bibr">[15]</xref>. GeneSplicer <xref rid="bib16" ref-type="bibr">[16]</xref> integrated the MM with MDD, which was reported by Burge et al. <xref rid="bib13" ref-type="bibr">[13]</xref> to improve their SS prediction. Pashaei et al. <xref rid="bib17" ref-type="bibr">[17]</xref> investigated the effectiveness of third-order Markovian encoding models and SVMs in predicting human SS. They also proposed a novel method for SS prediction that utilizes sequence component analysis and hidden Markov model (HMM) <xref rid="bib18" ref-type="bibr">[18]</xref>, which they demonstrated to outperform existing methods in accurately predicting SS in genomic DNA.<fig id="fig0005"><label>Fig. 1</label><caption><p>Analysis of the splice sites biochemical process. This figure shows the two-stage biochemical process for splice site and sequence distribution in splice site location. The OH represent the 3′ hydroxyl group of an RNA base.</p></caption><alt-text id="at0005">Fig. 1</alt-text><graphic xlink:href="gr1"/></fig></p>
    <p id="p0015">While the sophistication of these machine learning models increased, their accuracy slowly improved. This resulted from the computational time concerns and the ineffective manual feature selection and extraction from the input variables. Hence, convolutional neural network (CNN) architectures have been used more frequently in SS prediction work using the DL approach, with varying depth, parameters, and architecture design <xref rid="bib19" ref-type="bibr">[19]</xref>, <xref rid="bib20" ref-type="bibr">[20]</xref>, <xref rid="bib21" ref-type="bibr">[21]</xref>, <xref rid="bib22" ref-type="bibr">[22]</xref>, <xref rid="bib23" ref-type="bibr">[23]</xref>. Albaradei et al. <xref rid="bib21" ref-type="bibr">[21]</xref> developed Splice2Deep, a deep CNN ensemble model that predicts SS in cross-organisms and offers the ability for new SS genome organism annotation. Similarly, Zuallaert et al. <xref rid="bib20" ref-type="bibr">[20]</xref> developed SpliceRover, a model that uses CNN to predict SS. They demonstrated the interpretability of their model by showing genomic information relevant to SS detection. Wang et al. <xref rid="bib24" ref-type="bibr">[24]</xref> developed SpliceFinder, an SS tool that predicts canonical (acceptor and donor) and noncanonical SS using a one-layer CNN. Also, Akpokiro et al. <xref rid="bib25" ref-type="bibr">[25]</xref> developed DeepSplicer, a CNN model using five-fold cross-validation and three convolutional layers of CNN architecture to predict SS in genomic organism datasets.</p>
    <p id="p0020">Although the DL-based algorithms for SS prediction have seen significant advancements, there is still a need for more performance improvements especially because many of these tools have an imbalanced performance across organisms for SS detection. Specifically, they are inflexible and not comprehensive in maintaining a consistent prediction accuracy when used for SS detection across a wide range of organisms. Also, the models of some of the existing methods are not robust to the data distribution of acceptor and donor SS made available to them for training and testing purposes, as we show in detail in our results section; thus, their detection accuracy performance varies depending on the acceptor and donor sites’ datasets ratio used for the algorithm’s training. Hence, we propose CNNSplice, a set of DL-based models, for detecting SS in organisms using robust CNN algorithm architectures. For SS prediction, CNNSplice models are trained using a preselected set of organismic datasets. The models in this study were chosen based on the cross-validation results on the datasets. According to our evaluation results, CNNSplice enhances SS detection research by producing highly effective SS detection models (Models 1, 2, 3, 4, and 5), as well as a model (Model 1) that can accurately predict or annotate newly sequenced datasets.</p>
  </sec>
  <sec id="sec0010">
    <label>2</label>
    <title>Material and methods</title>
    <sec id="sec0015">
      <label>2.1</label>
      <title>Datasets</title>
      <p id="p0025">We created a balanced and imbalanced dataset from five carefully selected datasets of organisms, namely: <italic>Homo sapiens</italic>, <italic>Oryza sativa japonica</italic>, <italic>Arabidopsis thaliana</italic>, <italic>Drosophila melanogaster</italic>, and <italic>Caenorhabditis elegans</italic>. The reference genomic sequence data for these organisms were obtained from Albaradei et al. (2020) <xref rid="bib21" ref-type="bibr">[21]</xref>, and separate acceptor and donor models were generated from each organism dataset. The outcome of this method yielded a balanced dataset consisting of confirmed true and false regions at a 1:1 ratio, totaling 10,000 entries each. Additionally, an imbalanced dataset with a confirmed true-to-false region ratio of 3:1 was generated, totaling 7500 true and 2500 false regions, with 10,000 entries in total, as detailed in <xref rid="tbl0005" ref-type="table">Table 1</xref>. For the imbalanced dataset, we also utilized an empirical sliding window program to effectively select the local flanking regions and the SS-containing region based on the sequence distribution ratio; the same applied for the balanced dataset. The relevance and justification for this dataset split is twofold, especially concerning the introduction of the imbalanced dataset. First, it was to assess the impact of the training dataset distribution on our algorithm’s performance. Second, it was to determine and develop a robust model for SS prediction across multiple organisms. This allows us to assess the strength of our models in scenarios where they are used to detect SS from datasets without knowing the data distribution, which is the case for real-life use scenarios of the SS detection tools. Hence, we propose a model that is not overly influenced by the training dataset and would perform well in extreme cases where the distribution of false or true cases is skewed.<table-wrap position="float" id="tbl0005"><label>Table 1</label><caption><p>The dataset’s sequence count.</p></caption><alt-text id="at0040">Table 1</alt-text><table frame="hsides" rules="groups"><thead><tr><th>Splice sites</th><th>Distribution</th><th>Sequence region</th><th>Distribution ratio</th></tr></thead><tbody><tr><td>Acceptor<break/>(AcSS)</td><td>Balanced</td><td>5000 (true)<break/>5000 (false)</td><td>1:1</td></tr><tr><td/><td>Imbalanced</td><td>7500 (true)<break/>2500 (false)</td><td>3:1</td></tr><tr><td>Donor<break/>(DoSS)</td><td>Balanced</td><td>5000 (true)<break/>5000 (false)</td><td>1:1</td></tr><tr><td/><td>Imbalanced</td><td>7500 (true)<break/>2500 (false)</td><td>3:1</td></tr></tbody></table><table-wrap-foot><fn><p>This shows the dataset distribution, sequence counts, and distribution ratio for balanced and imbalanced acceptor and donor sequenced organisms. The balanced datasets are evenly distributed, and the imbalanced datasets are distributed in the ratio of 3–1 (true to false).</p></fn></table-wrap-foot></table-wrap></p>
    </sec>
    <sec id="sec0020">
      <label>2.2</label>
      <title>One-hot encoding and parameter tuning</title>
      <p id="p0030">One-hot encoding, which involves converting categorical data to numerical data variables for improved machine learning algorithm prediction, is one of the aspects of data preprocessing in DL. One-hot encoding is typically applied to categorical data, whereby each category is expressed as a binary vector containing a single 1 with all other elements as 0. This encoding technique is particularly advantageous when there is no inherent order to the categories, and they are mutually exclusive. Additionally, CNNs can effectively learn to identify distinctive patterns and characteristics that correspond to each category through the use of one-hot encoded input. In this study, we utilized a binary integer variable collection to represent our input genomic nucleotide bases. Specifically, we assigned [1 0 0 0], [0 1 0 0], [0 0 1 0], and [0 0 0 1] to represent Adenine (A), Cytosine (C), Guanine (G), and Thymine (T), respectively. Additionally, we represented invalid nucleotide letters (N) with [0,0,0,0], where each nucleotide is located at the corresponding vector index containing a value of 1. Therefore, we provided the CNN architecture with a Z X 4 input matrix, where Z denotes the genomic sequence length and 4 denotes the nucleotide types (A, C, G, T). <xref rid="fig0010" ref-type="fig">Fig. 2</xref><italic>A</italic> shows a pictorial illustration of the one-hot encoding. We tuned the hyperparameters on our generated hyperparameter datasets—to avoid bias in CNN splice—during learning based on the search space shown in <xref rid="tbl0010" ref-type="table">Table 2</xref> and the selected ranges for the model generation. We fine-tuned the hyperparameters and chose the top-performing parameters based on the minimum validation loss.<fig id="fig0010"><label>Fig. 2</label><caption><p>CNNSplice architectural pipeline. This figure shows the CNNSplice pipeline with each block representing <xref rid="fig0010" ref-type="fig">Fig. 2</xref> A, <xref rid="fig0010" ref-type="fig">Fig. 2</xref>B, and <xref rid="fig0010" ref-type="fig">Fig. 2</xref> C respectively. <xref rid="fig0010" ref-type="fig">Fig. 2</xref> A shows the one-hot encoding as described in the one-hot encoding and hyper-parameter tuning section, <xref rid="fig0010" ref-type="fig">Fig. 2</xref>B depicts the convolutional layer and <xref rid="fig0010" ref-type="fig">Fig. 2</xref> C shows the output layers which includes the dense, the fully connected layer, ss denotes splice site.</p></caption><alt-text id="at0010">Fig. 2</alt-text><graphic xlink:href="gr2"/></fig><table-wrap position="float" id="tbl0010"><label>Table 2</label><caption><p>The grid search space table for the tuning of the Convolutional neural network hyperparameters.</p></caption><alt-text id="at0045">Table 2</alt-text><table frame="hsides" rules="groups"><thead><tr><th>Hyper-Parameters</th><th>Search Space</th><th>Selected Ranges</th></tr></thead><tbody><tr><td>Layers</td><td>[1, 2, 3, 4, 5]</td><td>[1, 2, 3]</td></tr><tr><td>Filter number</td><td>[50,64,100,128,150]</td><td>[5]</td></tr><tr><td>Filter size</td><td>[3,5,7,9,11]</td><td>[3, 9]</td></tr><tr><td>Stride</td><td>[1,3,5]</td><td>[1]</td></tr><tr><td>Activation function</td><td>[sigmoid, relu, softmax, tanh]</td><td>[sigmoid, relu]</td></tr><tr><td>Learning rate</td><td>[1e-3, 5e-4, 1e-4, 5e-5, 1e-5]</td><td>[1e–4]</td></tr><tr><td>Optimizers</td><td>[sgd, adam, adagrad, RMSprop, nadam]</td><td>[adam]</td></tr></tbody></table><table-wrap-foot><fn><p>This table shows different hyper-parameter lists from which the CNN architecture was tuned to select the best parameters for the model’s configuration.</p></fn></table-wrap-foot></table-wrap></p>
    </sec>
    <sec id="sec0025">
      <label>2.3</label>
      <title>Convolutional neural network model</title>
      <p id="p0035">The CNN contains the convolutional layers, which are the main building block of this neural network <xref rid="bib26" ref-type="bibr">[26]</xref>. These convolutional layers are made up of neurons that contain and perform element-wise multiplication operations between the inputs and the weights. To employ a reliable model, each CNNSplice model has different convolutional layers (<xref rid="fig0010" ref-type="fig">Fig. 2</xref><italic>B</italic>). These convolutional layers perform local and global feature extraction on the acceptor and donor genomic input sequence. Importantly, the convolutional layer consists of a complex set of learnable filters with varying filter length and depth, which enables efficient discrimination of true/false acceptor and donor SS. The best-performing model has been selected based on the average validation accuracy across the preselected organism for acceptor and donor individually. In the cross-validation section, we presented 11 architectures from which the consistent top-performing models were selected as the architecture for the convolutional layer of our pipeline.</p>
      <p id="p0040">Each model convolutional block contains a flattened layer, a fully connected layer of 100 neurons. By using all its connections to all the activations in the flatten layer, the fully connected layer increases nonlinearity expression capabilities to detect both canonical and noncanonical SS and improve CNNSplice’s generalization ability (<xref rid="fig0010" ref-type="fig">Fig. 2</xref><italic>C</italic>). Their activations may be approximated using matrix multiplication and bias offset. This layer uses the ReLU <xref rid="bib27" ref-type="bibr">[27]</xref> activation function, which uses element-wise nonlinearity. To avoid overfitting, a 30 % dropout <xref rid="bib28" ref-type="bibr">[28]</xref> layer is implemented. Finally, we used the Adam optimizer with a learning rate of 1e-4, cross-entropy for the loss function, and the Softmax activation function layer <xref rid="bib29" ref-type="bibr">[29]</xref> to transform the prediction output to normalized probability. A visual summary of the models is shown in <xref rid="fig0010" ref-type="fig">Fig. 2</xref>.</p>
    </sec>
    <sec id="sec0030">
      <label>2.4</label>
      <title>Genomic datasets sequence length selection</title>
      <p id="p0045">Statistical examination of the correlation between genomic sequence length and prediction performance has been done in the previous SS prediction research <xref rid="bib19" ref-type="bibr">[19]</xref>, <xref rid="bib21" ref-type="bibr">[21]</xref>, <xref rid="bib24" ref-type="bibr">[24]</xref> because the sequence length of the produced dataset is an important factor to consider for SS prediction. Experiments by Wang et al. <xref rid="bib24" ref-type="bibr">[24]</xref> and Du et al. <xref rid="bib19" ref-type="bibr">[19]</xref> show that the capacity of SS models to predict rises as the length of the genomic sequence increases. Though there is a favorable association between sequence length and prediction performance, a long sequence length may degrade classification performance <xref rid="bib16" ref-type="bibr">[16]</xref>, <xref rid="bib20" ref-type="bibr">[20]</xref>, <xref rid="bib21" ref-type="bibr">[21]</xref>. To maintain a good sequence length balance, and for a fair model prediction and comparison with other baseline methods, we used a sequence length of 400 of sequence region 0–399. Thus, all algorithm acceptor and donor input species datasets regions in this study have a sequence length of 400 nucleotides bases. The dataset section clearly details the source, distribution, and the true and false AcSS/DoSS regions for each dataset used in the experiment.</p>
    </sec>
    <sec id="sec0035">
      <label>2.5</label>
      <title>Evaluation metrics</title>
      <p id="p0050">We used the following metrics to evaluate the performance of our neural network models.<list list-type="simple" id="li0005"><list-item id="u0005"><label>•</label><p id="p0055">The Recall evaluates as:<disp-formula id="eqn0005"><label>(1)</label><mml:math id="M1" altimg="si0001.svg"><mml:mrow><mml:mi mathvariant="italic">Recall</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">TP</mml:mi></mml:mrow><mml:mrow><mml:mspace width="1em"/><mml:mi mathvariant="italic">TP</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="italic">FN</mml:mi><mml:mspace width="1em"/></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="M2" altimg="si0002.svg"><mml:mi mathvariant="italic">TP</mml:mi></mml:math></inline-formula> is the number of true positives, <inline-formula><mml:math id="M3" altimg="si0003.svg"><mml:mi mathvariant="italic">FN</mml:mi></mml:math></inline-formula> is the number of false negatives.</p></list-item><list-item id="u0010"><label>•</label><p id="p0060">The Precision evaluates as:<disp-formula id="eqn0010"><label>(2)</label><mml:math id="M4" altimg="si0004.svg"><mml:mrow><mml:mi mathvariant="italic">Precision</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">TP</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">TP</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="italic">FP</mml:mi><mml:mspace width="1em"/></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="M5" altimg="si0002.svg"><mml:mi mathvariant="italic">TP</mml:mi></mml:math></inline-formula> is the number of true positives, <inline-formula><mml:math id="M6" altimg="si0005.svg"><mml:mi mathvariant="italic">FP</mml:mi></mml:math></inline-formula> is the number of false positives.</p></list-item><list-item id="u0015"><label>•</label><p id="p0065">The Accuracy evaluates as:</p></list-item></list><disp-formula id="eqn0015"><label>(3)</label><mml:math id="M7" altimg="si0006.svg"><mml:mrow><mml:mi mathvariant="italic">Accuracy</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">TP</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="italic">TN</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">TP</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="italic">TN</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="italic">FP</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="italic">FN</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula></p>
    </sec>
  </sec>
  <sec id="sec0040">
    <label>3</label>
    <title>Results</title>
    <sec id="sec0045">
      <label>3.1</label>
      <title>Cross-validation</title>
      <p id="p0070">To get a smoother, less noisy, and more sustainable estimate of how well a model performs, cross-validation, which involves iterating over a K-fold validation set and determining the average across the datasets, is essential. K-1 fold is reserved for training purposes with one-fold for testing. In summary, cross-validation is used to return partitions of the dataset for training and evaluation of the model for enhanced neural network performance and statistical probability. CNNSplice splits the training dataset into five folds using K-fold cross-validation with the StratifiedKFold machine learning module <xref rid="bib19" ref-type="bibr">[19]</xref>. We reconstructed the cross-validation datasets from the source datasets <xref rid="bib21" ref-type="bibr">[21]</xref>. The training dataset, X, is split into five equally distributed subset datasets with the cross-validation computation producing a mean output of the five model accuracies and losses from five data splits. This can be represented mathematically as follows:<disp-formula id="eqn0020"><label>(4)</label><mml:math id="M8" altimg="si0007.svg"><mml:mrow><mml:mi>X</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>∪</mml:mo><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>∪</mml:mo><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mo>∪</mml:mo><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mn>4</mml:mn></mml:mrow></mml:msub><mml:mo>∪</mml:mo><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mn>5</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></disp-formula>Where X is the entire training dataset and is split into equal subsets for all <italic>i</italic> = 1, 2, 3, 4, 5. <xref rid="eqn0020" ref-type="disp-formula">Eq. 4</xref> yields five subsets from dataset X. Mathematically, the process of cross-validation is given by<disp-formula id="eqn0025"><label>(5)</label><mml:math id="M9" altimg="si0008.svg"><mml:mrow><mml:mi mathvariant="normal">|</mml:mi><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mi mathvariant="normal">|</mml:mi><mml:mo>≈</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">|</mml:mi><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mi mathvariant="normal">|</mml:mi><mml:mo>≈</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">|</mml:mi><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mi mathvariant="normal">|</mml:mi><mml:mo>≈</mml:mo><mml:mi mathvariant="normal">|</mml:mi><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mn>4</mml:mn></mml:mrow></mml:msub><mml:mi mathvariant="normal">|</mml:mi><mml:mo>≈</mml:mo><mml:mi mathvariant="normal">|</mml:mi><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mn>5</mml:mn></mml:mrow></mml:msub><mml:mi mathvariant="normal">|</mml:mi></mml:mrow></mml:math></disp-formula></p>
      <p id="p0075">As shown in <xref rid="tbl0005" ref-type="table">Table 1</xref>, we constructed 5000 true and 5000 false acceptor and donor datasets for the balanced experiments and 7500 true and 2500 false acceptor and donor datasets for the imbalanced experiment evenly. To find the best-performing convolutional layer for <xref rid="fig0010" ref-type="fig">Fig. 2</xref>B, we performed cross-validation on the list of potential architectures as follows:<list list-type="simple" id="li0010"><list-item id="u0020"><label>•</label><p id="p0080"><bold>C1</bold>: is a one-dimensional convolutional layer block.</p></list-item><list-item id="u0025"><label>•</label><p id="p0085"><bold>C11</bold>M: has a pair of one-dimensional convolutional layer and max-pooling layer.</p></list-item><list-item id="u0030"><label>•</label><p id="p0090"><bold>Model</bold> 1: contains three (3) blocks of one-dimensional convolutional layer, and a max-pooling layer for each convolutional block.</p></list-item><list-item id="u0035"><label>•</label><p id="p0095"><bold>Model</bold> 2: contains two (2) layers of a pair of one-dimensional convolutional layer and max-pooling layer.</p></list-item><list-item id="u0040"><label>•</label><p id="p0100"><bold>NPOOL1</bold>3: is similar to Model 1 and Model 3 except it has no max-pooling or average-pooling layer to each convolutional block.</p></list-item><list-item id="u0045"><label>•</label><p id="p0105"><bold>Model</bold> 3: contains three (3) blocks of a pair of one-dimensional convolutional layer and average pooling layer.</p></list-item><list-item id="u0050"><label>•</label><p id="p0110"><bold>MEANPOOL1</bold>3: is similar to NPOOL13 with a one-dimensional global average pooling layer connected in the fully connected layer.</p></list-item><list-item id="u0055"><label>•</label><p id="p0115"><bold>Model</bold> 4: averages the weight generated from Model 1 and Model 2.</p></list-item><list-item id="u0060"><label>•</label><p id="p0120"><bold>Model</bold> 5: involves weights from Model 1 and Model 3 averaged.</p></list-item><list-item id="u0065"><label>•</label><p id="p0125"><bold>NPOOL1</bold>2: is similar to Model 2 except it has no max-pooling or average-pooling layer to each convolutional block.</p></list-item><list-item id="u0070"><label>•</label><p id="p0130"><bold>AVEPOOL1</bold>2: contains two (2) layers of a pair of one-dimensional convolutional layer and average-pooling layer.</p></list-item></list></p>
      <p id="p0135">As shown in <xref rid="fig0010" ref-type="fig">Fig. 2</xref>, each of the aforementioned architectures is the variations of the architecture used in <xref rid="fig0010" ref-type="fig">Fig. 2</xref><italic>B</italic>, which accepts one-hot encoding as input. The outputs of each of these architectures, in <xref rid="fig0010" ref-type="fig">Fig. 2</xref><italic>B</italic>, serve as input to the dense and fully connected layer as seen in <xref rid="fig0010" ref-type="fig">Fig. 2</xref><italic>C</italic>. Cross-validation was performed on all the aforementioned architectures for the five organisms’ balanced and imbalanced datasets.</p>
      <p id="p0140">Our work is focused on the development of robust models that are capable of high performance on multiple organisms. Thus, to select the best-performing models, we averaged the results generated by each model across the different organisms to identify which models have a consistently high performance. We have shown the tabular results of the cross-validation experiment in <xref rid="tbl0015" ref-type="table">Table 3</xref> and <xref rid="tbl0020" ref-type="table">Table 4</xref> for the balanced and imbalanced datasets results respectively. Across the five organisms’ acceptor and donor datasets for the imbalanced and balanced datasets we created, Model 1, Model 5, and Model 3 are the top three (3) performing model architectures for balanced acceptor datasets; Model 1, Model 5, and Model 4 are the top three (3) performing model architectures for balanced donor datasets; Model 1, Model 2, and Model 5 are the top three (3) performing model architectures for imbalanced acceptor datasets; and Model 1, Model 2, and Model 4 are the top three (3) performing model architectures for imbalanced donor datasets.<table-wrap position="float" id="tbl0015"><label>Table 3</label><caption><p>The cross-validation results for the Balanced Dataset for the five organisms.</p></caption><alt-text id="at0050">Table 3</alt-text><table frame="hsides" rules="groups"><tbody><tr><td><inline-graphic xlink:href="fx1.gif"/></td></tr></tbody></table><table-wrap-foot><fn><p>This Table depicts the 5-fold Cross-validation Results, average result across the organism distribution, and average results positions for Balanced datasets across the selected organism in percent (%). With respect to validation accuracy, results highlighted shows that * represent the best result * * represents the second best, * ** represents the third. HS denotes Homo sapiens, Oryza denotes <italic>Oryza sativa japonica</italic>, AT denotes <italic>Arabidopsis thaliana</italic>, D. Mel denotes <italic>Drosophila melanogaster</italic>, and C. elegans denotes <italic>Caenorhabditis elegans</italic>.</p></fn></table-wrap-foot></table-wrap><table-wrap position="float" id="tbl0020"><label>Table 4</label><caption><p>The cross-validation results for the imbalanced dataset for the five organisms.</p></caption><alt-text id="at0055">Table 4</alt-text><table frame="hsides" rules="groups"><tbody><tr><td><inline-graphic xlink:href="fx2.gif"/></td></tr></tbody></table><table-wrap-foot><fn><p>This Table depicts the 5-fold Cross-validation Results, average result across the organism distribution, and average results positions for Imbalanced datasets across the selected organism in percent (%). With respect to validation accuracy, results highlighted shows that * represent the best result * * represents the second best, * ** represents the third. HS denotes Homo sapiens, Oryza denotes <italic>Oryza sativa japonica</italic>, AT denotes <italic>Arabidopsis thaliana</italic>, D. Mel denotes <italic>Drosophila melanogaster</italic>, and C. elegans denotes <italic>Caenorhabditis elegans</italic>.</p></fn></table-wrap-foot></table-wrap></p>
      <p id="p0145">Hence, based on the results obtained from the cross-validation experiment as shown in <xref rid="tbl0015" ref-type="table">Table 3</xref> and <xref rid="tbl0020" ref-type="table">Table 4</xref>, the architectural formation of the five best-performing models based on average accuracy across the organisms is described as follows, with a schematic representation shown in <xref rid="fig0015" ref-type="fig">Fig. 3</xref>.<list list-type="simple" id="li0015"><list-item id="u0075"><label>•</label><p id="p0150"><bold>Model 1:</bold> This model has three (3) one-dimensional convolutional layers, each with 50 kernels of size 9 and a batch size input of <italic>L X 4</italic>, the sequence length, <inline-formula><mml:math id="M10" altimg="si0009.svg"><mml:mi mathvariant="italic">where L</mml:mi></mml:math></inline-formula> is the sequence length. ReLU activation function is applied to each convolutional layer. In addition, a max-pooling layer of pool size 2 and stride 1 is applied to each individual convolutional layer.</p></list-item><list-item id="u0080"><label>•</label><p id="p0155"><bold>Model 2:</bold> This model has two (2) one-dimensional convolutional layers, each with 50 size 9 kernels and a batch size input of L X 4, <inline-formula><mml:math id="M11" altimg="si0009.svg"><mml:mi mathvariant="italic">where L</mml:mi></mml:math></inline-formula> is the sequence length. ReLU activation function is applied to each convolutional layer. In addition, a max-pooling layer of pool size 2 and stride 1 is applied to each individual convolutional layer.</p></list-item><list-item id="u0085"><label>•</label><p id="p0160"><bold>Model 3:</bold> This model has three (3) one-dimensional convolutional layers, each with 50 kernels of size 9 and a batch size input of <italic>L X 4</italic>, the sequence length, <inline-formula><mml:math id="M12" altimg="si0009.svg"><mml:mi mathvariant="italic">where L</mml:mi></mml:math></inline-formula> is the sequence length. ReLU activation function is applied to each convolutional layer. In addition, an average pooling layer of pool size 2 and stride 1 is applied to each individual convolutional layer.</p></list-item><list-item id="u0090"><label>•</label><p id="p0165"><bold>Model 4:</bold> This involves setting a new weight obtained from the mean weight across a set weight from Model 1 and Model 2 to the model.</p></list-item><list-item id="u0095"><label>•</label><p id="p0170"><bold>Model 5:</bold> This involves setting a new weight obtained from the mean weight across a set weight from Model 1 and Model 3 to the model.</p></list-item></list><fig id="fig0015"><label>Fig. 3</label><caption><p>Best performing CNNSplice model architectures. This figure shows a detailed layout of the CNNSplice models’ convolutional block architecture selected by the 5-fold cross validation process for <xref rid="fig0010" ref-type="fig">Fig. 2</xref>B of the CNNSplice pipeline illustration, <xref rid="fig0010" ref-type="fig">Fig. 2</xref>. ConvNet means the convolutional neural network layer, Max - Pool is the max-pooling layer, and the Ave - Pool is the average pooling layer. The input block denotes <xref rid="fig0010" ref-type="fig">Fig. 2</xref> A and the output block denotes <xref rid="fig0010" ref-type="fig">Fig. 2</xref> C.</p></caption><alt-text id="at0015">Fig. 3</alt-text><graphic xlink:href="gr3"/></fig></p>
    </sec>
    <sec id="sec0050">
      <label>3.2</label>
      <title>Benchmark methods for model comparison</title>
      <p id="p0175">In the context of SS prediction using the DL approach, various CNN architectures of different depths, parameters, and architecture designs have been used. Herein, we describe our benchmark cutting-edge models for comparison.</p>
      <p id="p0180"><bold>Wang, R. et al. (2019)</bold>.</p>
      <p id="p0185">Wang et al. (2019) proposed SpliceFinder <xref rid="bib24" ref-type="bibr">[24]</xref>, a CNN-based model that effectively predicts SS in various species, achieving a classification accuracy of 90.25 % in the human dataset. We chose this recent study as our baseline model because it can be applied to annotate new species without the need for retraining.</p>
      <p id="p0190"><bold>Albaradei, S. et al. (2020)</bold>.</p>
      <p id="p0195">Albaradei et al. (2020) introduced Splice2Deep <xref rid="bib21" ref-type="bibr">[21]</xref>, a high-performing SS prediction tool that uses deep CNNs and achieves high accuracy in various datasets, including <italic>Homo sapiens</italic>, <italic>Oryza sativa japonica</italic>, <italic>Arabidopsis thaliana</italic>, <italic>Drosophila melanogaster</italic>, and <italic>Caenorhabditis elegans</italic>. The authors also demonstrated the interpretability of the model by identifying important regions and motifs for SS prediction, as well as performing cross-organism validation test.</p>
      <p id="p0200"><bold>Zuallaert, J. et al. (2018)</bold>.</p>
      <p id="p0205">Zuallaert et al. (2018) proposed SpliceRover <xref rid="bib20" ref-type="bibr">[20]</xref>, a DL method that predicts SS using interpretable CNNs. The authors demonstrated the effectiveness of SpliceRover on multiple datasets and species, achieving up to 80.9 % accuracy. For benchmarking, we used their publicly available web server found at http://bioit2.irc.ugent.be/rover/splicerover.</p>
      <p id="p0210"><bold>Pertea, M. et al. (2001)</bold>.</p>
      <p id="p0215">Pertea et al. (2001) presented GeneSplicer <xref rid="bib16" ref-type="bibr">[16]</xref>, a computational approach to SS prediction that combines MM technique and MDD to identify SS in DNA sequences. The authors showed that GeneSplicer achieves high accuracy in predicting SS in various organisms, including human, mouse, and rat genomes. For benchmarking, we used their publicly available web server found at https://www.cbcb.umd.edu/software/GeneSplicer/gene_spl.shtml.</p>
      <p id="p0220"><bold>Akpokiro, V. et al. (2021)</bold>.</p>
      <p id="p0225">Finally, Akpokiro et al. (2021) proposed DeepSplicer <xref rid="bib25" ref-type="bibr">[25]</xref>, a DL-based method for predicting SS in DNA sequences. Similar to CNNSplice, DeepSplicer performed a five-fold cross-validation test and achieved high accuracy in various datasets, including <italic>Homo sapiens</italic>, <italic>Oryza sativa japonica</italic>, <italic>Arabidopsis thaliana</italic>, <italic>Drosophila melanogaster</italic>, and <italic>Caenorhabditis elegans</italic>. The data, models generated, and source code for DeepSplicer <xref rid="bib25" ref-type="bibr">[25]</xref> and SpliceFinder <xref rid="bib24" ref-type="bibr">[24]</xref> are all available in their respective GitHub repositories.</p>
    </sec>
    <sec id="sec0055">
      <label>3.3</label>
      <title>Model evaluation and performance comparison</title>
      <p id="p0230">We built separate models from our CNN algorithm architecture to reliably predict acceptor and donor SS for each of the balanced and imbalanced datasets. To improve the prediction performance of our selected models we performed feature extraction along the three regions: two local opposite genome surrounding regions (upstream and downstream) and the SS surrounding region <xref rid="bib21" ref-type="bibr">[21]</xref>. These models were selected based on peak performance from evaluating the mean prediction accuracy results across the preselected organism sequence datasets on the five-fold cross-validation results. Following feature extraction on each dataset, dinucleotides discovered on SS contain AG for acceptor sites and GT for donor sites; this AG-GT result consensus confirms previous observations in scientific literature <xref rid="bib19" ref-type="bibr">[19]</xref>, <xref rid="bib21" ref-type="bibr">[21]</xref>, <xref rid="bib25" ref-type="bibr">[25]</xref>, <xref rid="bib30" ref-type="bibr">[30]</xref>. It is crucial to highlight that we chose our models based on the outcomes of our cross-validation experiments, and we fairly compared them—as shown in <xref rid="fig0020" ref-type="fig">Fig. 4</xref><italic>a</italic>, <xref rid="fig0020" ref-type="fig">Fig. 4</xref><italic>b</italic>, <xref rid="fig0020" ref-type="fig">Fig. 4</xref><italic>c</italic>, and <xref rid="fig0020" ref-type="fig">Fig. 4</xref><italic>d</italic>—to the aforementioned state-of-the-art methods by using our test dataset with the models provided by the authors, as well as for training and testing in cases where the model was unavailable but the method architecture was available with our datasets.<fig id="fig0020"><label>Fig. 4</label><caption><p>A comparison of the performance of CNNSplice models and other models for (A) balanced acceptor, (B) balanced donor, (C) imbalanced acceptor, and (D) imbalanced donor datasets. This chart shows the CNNSplice models comparison to the models based on the performance accuracy in predicting splice sites for balanced acceptor datasets. CNNSplice m1 indicate Model 1, CNNSplice m2 indicate Model 2 CNNSplice m3 indicates Model 3, CNNSplice m4 indicate Model 4, CNNSplice m5 indicate Model 5. For this plot’s label, the Y-axis represents the accuracy in percentage (%) as the X-axis represents the name of the organisms’ datasets.</p></caption><alt-text id="at0020">Fig. 4</alt-text><graphic xlink:href="gr4"/></fig></p>
      <p id="p0235">These figures indicate that Model 1 consistently provided a high prediction accuracy across all acceptor and donor organisms for both datasets—balanced and imbalanced. In addition to Model 1, Model 3 performed well in balanced acceptor datasets (<xref rid="fig0020" ref-type="fig">Fig. 4</xref><italic>a</italic>), Model 2 and Model 5 performed better in imbalanced acceptor datasets (<xref rid="fig0020" ref-type="fig">Fig. 4</xref><italic>c</italic>), Model 1 and Model 4 performed better in balanced donor datasets (<xref rid="fig0020" ref-type="fig">Fig. 4</xref><italic>b</italic>), and Model 2 and Model 4 performed better in imbalanced donor datasets (<xref rid="fig0020" ref-type="fig">Fig. 4</xref><italic>d</italic>). In addition, we compared our models’ performance to the state-of-the-art SS prediction algorithms—Splice2Deep <xref rid="bib21" ref-type="bibr">[21]</xref>, GeneSplicer <xref rid="bib16" ref-type="bibr">[16]</xref>, SpliceRover <xref rid="bib20" ref-type="bibr">[20]</xref>, SpliceFinder <xref rid="bib24" ref-type="bibr">[24]</xref>, DeepSplicer <xref rid="bib25" ref-type="bibr">[25]</xref>—on the five organisms’ datasets: <italic>Homo sapiens</italic>, <italic>Oryza sativa japonica</italic>, <italic>Arabidopsis thaliana</italic>, <italic>Drosophila melanogaster</italic>, and <italic>Caenorhabditis elegans</italic> organisms (<xref rid="fig0020" ref-type="fig">Fig. 4</xref><italic>a</italic>–<xref rid="fig0020" ref-type="fig">Fig. 4</xref><italic>d</italic>). Model 1 achieved the highest performance accuracy compared to the other models and the state of the art for the balanced acceptor <italic>Homo sapiens</italic>, <italic>Arabidopsis thaliana</italic>, <italic>Oryza sativa japonica</italic>, and <italic>Caenorhabditis elegans</italic> organisms’ dataset with 96.94 %, 96.26 %, 96.85 %, and 97.00 % accuracy respectively (<xref rid="fig0020" ref-type="fig">Fig. 4</xref><italic>a</italic>). For the balanced donor dataset, Model 1 performed better than the other models and the Splice2Deep <xref rid="bib21" ref-type="bibr">[21]</xref>, GeneSplicer <xref rid="bib16" ref-type="bibr">[16]</xref>, and SpliceFinder <xref rid="bib24" ref-type="bibr">[24]</xref> models for <italic>Homo sapiens</italic>, <italic>Arabidopsis thaliana</italic>, <italic>Drosophila melanogaster</italic>, and <italic>Caenorhabditis elegans</italic> organisms with accuracy performance of 96.63 %, 94.10 %, 96.15 %, and 97.07 % respectively (<xref rid="fig0020" ref-type="fig">Fig. 4</xref><italic>b</italic>). Model 4 performed highest for the <italic>Oryza sativa japonica</italic> organism dataset with an accuracy of 96.35 % (<xref rid="fig0020" ref-type="fig">Fig. 4</xref><italic>b</italic>).</p>
      <p id="p0240">Also, we investigated the SS prediction potentials with imbalanced acceptor and donor organism datasets and compared our model’s performance with state-of-the-art models—SpliceFinder <xref rid="bib24" ref-type="bibr">[24]</xref> and DeepSplicer <xref rid="bib25" ref-type="bibr">[25]</xref>. It is worth noting that for this analysis, we benchmarked only with the SpliceFinder <xref rid="bib24" ref-type="bibr">[24]</xref> and DeepSplicer <xref rid="bib25" ref-type="bibr">[25]</xref> algorithms because the other state-of-the-art methods examined previously do not have available models trained with imbalanced organisms’ datasets or do not provide model architecture for model retraining with imbalanced datasets. Model 2 performed better than the DeepSplicer <xref rid="bib25" ref-type="bibr">[25]</xref> and SpliceFinder <xref rid="bib24" ref-type="bibr">[24]</xref> for imbalanced acceptor organisms’ datasets of <italic>Homo sapiens</italic> and <italic>Caenorhabditis elegans</italic> with performance accuracy of 95.82 % and 97.79 % respectively, whereas Model 1 performed better for the <italic>Arabidopsis thaliana</italic>, <italic>Oryza sativa japonica</italic>, and <italic>Drosophila melanogaster</italic> organism datasets with an accuracy of 96.02 %, 95.55 %, and 97.02 % respectively (<xref rid="fig0020" ref-type="fig">Fig. 4</xref><italic>c</italic>). For the imbalanced donor, Model 1 performed better for <italic>Drosophila melanogaster</italic> and <italic>Caenorhabditis elegans</italic> organisms with SS prediction accuracy of 96.62 % and 97.96 % respectively, Model 2 had a prediction accuracy of 96.46 % and 97.62 % for <italic>Homo sapiens</italic> and <italic>Arabidopsis thaliana</italic> respectively, and Model 4 had a prediction accuracy of 95.19 % for the <italic>Oryza sativa japonica</italic> organism dataset (<xref rid="fig0020" ref-type="fig">Fig. 4</xref><italic>d</italic>). We present tables showing the results and comparison with other methods in <xref rid="tbl0025" ref-type="table">Table 5</xref> and <xref rid="tbl0030" ref-type="table">Table 6</xref>. To show the performance evaluation metrics for CNN Splice, we show in <xref rid="tbl0035" ref-type="table">Table 7</xref> the results of the precision, recall, F1, and accuracy evaluation metrics for the Model 1 test prediction using the balanced genomic datasets. We used N/A to indicate methodologies that did not use the considered organism in their model training and situations where method architecture was not available to retrain the organism with the examined organism. The methods available for comparison in the imbalanced dataset experiment results are those with imbalanced models or model architecture provided to generate an imbalanced datasets model.<table-wrap position="float" id="tbl0025"><label>Table 5</label><caption><p>The results comparison on balanced datasets across the selected organism.</p></caption><alt-text id="at0060">Table 5</alt-text><table frame="hsides" rules="groups"><tbody><tr><td><inline-graphic xlink:href="fx3.gif"/></td></tr></tbody></table><table-wrap-foot><fn><p>This table shows the results of the Balanced SS prediction accuracy in comparison to the state of the arts for acceptor and donor genome datasets in percent (%). CNNSplice m1 indicates Model 1, CNNSplice m3 indicates Model 3, CNNSplice m4 indicates Model 4. Results highlighted in <bold>bold</bold> black color represent the best result and result highlighted in <bold>bold</bold> red represents the second-best result.</p></fn></table-wrap-foot></table-wrap><table-wrap position="float" id="tbl0030"><label>Table 6</label><caption><p>The results comparison on imbalanced datasets across the selected organism.</p></caption><alt-text id="at0065">Table 6</alt-text><table frame="hsides" rules="groups"><tbody><tr><td><inline-graphic xlink:href="fx4.gif"/></td></tr></tbody></table><table-wrap-foot><fn><p>This table shows the CNNSplice splice site prediction performance results and its comparison to other methods. We show the prediction accuracy measures, in percent (%), amongst other evaluation metrics performance results. Results highlighted in <bold>bold</bold> black color represent the best result and result highlighted in <bold>bold</bold> red represents the second-best result.</p></fn></table-wrap-foot></table-wrap><table-wrap position="float" id="tbl0035"><label>Table 7</label><caption><p>The performance evaluation metrics for the balanced dataset using model 1.</p></caption><alt-text id="at0070">Table 7</alt-text><table frame="hsides" rules="groups"><thead><tr><th>SpliceSites</th><th>Model name</th><th>Precision</th><th>F1</th><th>Recall</th><th>Accuracy</th></tr></thead><tbody><tr><td>Acceptor</td><td>Homo sapiens</td><td>94.50</td><td>94.44</td><td>94.44</td><td>94.44</td></tr><tr><td/><td>Arabidopsis thaliana</td><td>96.31</td><td>96.24</td><td>96.26</td><td>96.26</td></tr><tr><td/><td>Oryza sativa japonica</td><td>96.80</td><td>96.85</td><td>96.80</td><td>96.85</td></tr><tr><td/><td>Drosophila melanogaster</td><td>94.86</td><td>94.74</td><td>94.77</td><td>94.77</td></tr><tr><td/><td>Caenorhabditis elegans</td><td>97.29</td><td>97.00</td><td>96.69</td><td>97.00</td></tr><tr><td>  </td><td>  </td><td>  </td><td>  </td><td>  </td><td>  </td></tr><tr><td>SpliceSites</td><td>Model name</td><td>Precision</td><td>F1</td><td>Recall</td><td>Accuracy</td></tr><tr><td>Donor</td><td>Homo sapiens</td><td>96.70</td><td>96.63</td><td>96.63</td><td>96.63</td></tr><tr><td/><td>Arabidopsis thaliana</td><td>94.11</td><td>94.10</td><td>94.10</td><td>94.10</td></tr><tr><td/><td>Oryza sativa japonica</td><td>94.27</td><td>94.23</td><td>94.24</td><td>94.24</td></tr><tr><td/><td>Drosophila melanogaster</td><td>96.16</td><td>96.15</td><td>96.15</td><td>96.15</td></tr><tr><td/><td>Caenorhabditis elegans</td><td>97.10</td><td>97.04</td><td>97.07</td><td>97.07</td></tr></tbody></table><table-wrap-foot><fn><p>This table shows the CNNSplice splice site prediction performance evaluation results. We show the accuracy, precision, recall and f1 score measures in percent (%) for the balanced acceptor and donor genomic organism datasets.</p></fn></table-wrap-foot></table-wrap></p>
      <p id="p0245">In conclusion, CNNSplice presents robust DL models for improved SS prediction with comparison to the state-of-the-art methods, namely Splice2Deep <xref rid="bib21" ref-type="bibr">[21]</xref>, GeneSplicer <xref rid="bib16" ref-type="bibr">[16]</xref>, SpliceFinder <xref rid="bib24" ref-type="bibr">[24]</xref>, and DeepSplicer <xref rid="bib25" ref-type="bibr">[25]</xref> for both balanced and imbalanced acceptor and donor datasets. The plot representation of the results accuracy comparison is shown in <xref rid="fig0020" ref-type="fig">Fig. 4</xref><italic>a</italic>, <xref rid="fig0020" ref-type="fig">Fig. 4</xref><italic>b</italic>, <xref rid="fig0020" ref-type="fig">Fig. 4</xref><italic>c</italic>, and <xref rid="fig0020" ref-type="fig">Fig. 4</xref><italic>d</italic>. Based on these findings, we present models for RNA splicing detection and analysis in known or poorly annotated genomic distribution spectrums, which will aid groundbreaking research and clinical experiments. The possibility of uneven genomic dataset distribution in bioinformatics and clinical genetic testing scenarios emphasizes the importance of our imbalanced models.</p>
    </sec>
    <sec id="sec0060">
      <label>3.4</label>
      <title>P-value statistical significance test</title>
      <p id="p0250">The statistical significance of the accuracy results comparison for the balanced datasets presented in <xref rid="tbl0040" ref-type="table">Table 8</xref> was determined by employing the nonparametric Friedman test. This test was utilized to ascertain differences among several related groups, and mean ranks were employed to rank the groups. To perform the test, accuracy values were converted to ranks, where the highest accuracy value was assigned a rank of 1, and the lowest accuracy value received a rank equivalent to the number of models being compared. The mean rank for each model across all datasets and SS types was subsequently calculated.<table-wrap position="float" id="tbl0040"><label>Table 8</label><caption><p>The Friedman test results comparison on balanced datasets across the selected organism.</p></caption><alt-text id="at0075">Table 8</alt-text><table frame="hsides" rules="groups"><thead><tr><th>Algorithm</th><th>Rank</th><th>Mean rank</th></tr></thead><tbody><tr><td><bold>CNN Splice m1</bold></td><td><bold>1</bold></td><td><bold>1.33</bold></td></tr><tr><td>DeepSplicer</td><td>2</td><td>2.00</td></tr><tr><td>CNNSplice m4</td><td>3</td><td>3.17</td></tr><tr><td>Splice2deep</td><td>4</td><td>4.50</td></tr><tr><td>CNN Splice m3</td><td>5</td><td>4.67</td></tr><tr><td>SpliceFinder</td><td>6</td><td>5.33</td></tr><tr><td>GeneSplicer</td><td>7</td><td>6.67</td></tr><tr><td>SpliceRover</td><td>8</td><td>7.50</td></tr></tbody></table><table-wrap-foot><fn><p>This table shows the statistical significance of the Balanced SS prediction accuracy results in comparison to the state of the arts for acceptor and donor genome datasets. The tables show the Algorithm names, Friedman rank position and Mean rank values CNNSplice m1 indicates Model 1, CNNSplice m3 indicates Model 3, CNNSplice m4 indicates Model 4. Results highlighted in <bold>bold</bold> black color represent the best result.</p></fn></table-wrap-foot></table-wrap></p>
      <p id="p0255">Using the Friedman statistic formula:<disp-formula id="eqn0030"><label>(6)</label><mml:math id="M13" altimg="si0010.svg"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">Q</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:mfenced open="[" close="]"><mml:mrow><mml:mfrac><mml:mrow><mml:mn>12</mml:mn></mml:mrow><mml:mrow><mml:mrow><mml:mfenced open="(" close=")"><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mo>*</mml:mo><mml:mi mathvariant="normal">k</mml:mi><mml:mo>*</mml:mo><mml:mrow><mml:mfenced open="(" close=")"><mml:mrow><mml:mi mathvariant="normal">k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced></mml:mrow><mml:mo>*</mml:mo><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mfenced open="(" close=")"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:mrow><mml:mfenced open="[" close="]"><mml:mrow><mml:mfrac><mml:mrow><mml:mfenced open="(" close=")"><mml:mrow><mml:mi mathvariant="normal">k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mspace width="1em"/></mml:mrow></mml:math></disp-formula>where:</p>
      <p id="p0260">m = number of models being compared.</p>
      <p id="p0265">k = number of independent tests.</p>
      <p id="p0270">R² = mean rank of the i-th model across all the independent tests.</p>
      <p id="p0275">Based on Friedman test results shown in <xref rid="tbl0040" ref-type="table">Table 8</xref>, the statistical analysis using the Friedman test yielded a <italic>p-value</italic> less than 0.05, which signifies a significant difference among the models. The ranking based on mean ranks indicates that on average, CNNSplice model 1 performed the best, followed closely by DeepSplicer <xref rid="bib25" ref-type="bibr">[25]</xref> and CNNSplice model 4. Conversely, Splice2deep <xref rid="bib21" ref-type="bibr">[21]</xref>, CNNSplice model 3, SpliceFinder <xref rid="bib24" ref-type="bibr">[24]</xref>, GeneSplicer <xref rid="bib16" ref-type="bibr">[16]</xref>, and SpliceRover <xref rid="bib20" ref-type="bibr">[20]</xref> had lower mean ranks, indicating less consistent performance across the various datasets and SS types.</p>
    </sec>
    <sec id="sec0065">
      <label>3.5</label>
      <title>Generalizability test</title>
      <p id="p0280">To assess the generalizability of our approach, we employed an empirical sliding window program that allowed for the efficient selection of local flanking regions and the identification of the SS-containing region based on the dataset under investigation. Furthermore, we enhanced the nonlinearity expression capabilities of our model by enriching its fully connected layer and augmented the proportion of noncanonical SS in the training dataset to improve the model’s ability to detect such SS. This augmentation contributed to an improvement in the model’s generalizability. Each of the organism-generated models underwent the same procedure. For example, a <italic>Caenorhabditis elegans</italic> model was tested utilizing datasets from <italic>Homo sapiens</italic>, <italic>Oryza sativa japonica</italic>, <italic>Arabidopsis thaliana</italic>, and <italic>Drosophila melanogaster</italic>. The results are reported in <xref rid="fig0025" ref-type="fig">Fig. 5</xref> and demonstrate CNNSplice’s higher performance over other methodologies, as well as the fact that CNNSplice’s cross-organism test outperformed some other tools trained and tested on the same datasets. For example, CNNSplice balanced acceptor model, trained on <italic>Caenorhabditis elegans</italic> and tested on <italic>Drosophila melanogaster</italic>, has a prediction accuracy of 94.77 %, compared to 86.60 % and 91.97 % for SpliceFinder <xref rid="bib24" ref-type="bibr">[24]</xref> and DeepSplicer <xref rid="bib25" ref-type="bibr">[25]</xref> respectively, when trained and tested on <italic>Drosophila melanogaster</italic> balanced acceptor genome organism datasets. This result further validates CNNSplice’s capacity to predict and annotate newly introduced or previously unseen sequenced genome datasets.<fig id="fig0025"><label>Fig. 5</label><caption><p>The models’ Generalizability comparison on Balanced datasets across the selected organism. This figure shows the generalization comparison plot for CNNSplice model and other methods. This experiment is done on the selected genome organism dataset with CNNSplice model 1 and the other methods applicable models. No data or bar represent methods with no available models or model architecture for ss testing. We used the balanced dataset to effectively represent all methods involved in the generalization experiments. The Y-axis of the plots represents the prediction accuracy in percentage (%) while the X-axis represents the name of the genome organism used for the experiment.</p></caption><alt-text id="at0025">Fig. 5</alt-text><graphic xlink:href="gr5"/></fig></p>
    </sec>
    <sec id="sec0070">
      <label>3.6</label>
      <title>Understanding CNNSplice model outputs</title>
      <p id="p0285">We determined the average regional contribution and importance score to assess the impact of our feature extraction on the interpretation of our model’s prediction <xref rid="bib31" ref-type="bibr">[31]</xref>. To accomplish this, we analyzed and determined the feature that powers our model prediction by using motif extraction and visualization. A motif is a collection of subsequences related to a decision process <xref rid="bib19" ref-type="bibr">[19]</xref>. With the help of Shap <xref rid="bib32" ref-type="bibr">[32]</xref>, we were able to determine the contribution score of each feature instance inside the sequencing window and, as a result, decipher the underlying pattern of our dataset’s characteristics. Shap (SHapley Additive exPlanation) is an approximation approach to explain a machine learning model’s feature output. This tool uses the game theory approach to explain the importance of features in a model. The sequence logo is made up of the contribution score generated from the sequence patterns. WebLogo version 3.7.4 <xref rid="bib33" ref-type="bibr">[33]</xref> (available at http://weblogo.threeplusone.com/create.cgi) is used to produce the sequence logos. For both the acceptor and donor organism datasets, we randomly picked 100 sequences of each organism. Sequence positions 295–305 are represented by the magnitude of the genomic sequence characters in the motif. As shown <italic>in</italic>
<xref rid="fig0030" ref-type="fig">Fig. 6</xref> and <xref rid="fig0035" ref-type="fig">Fig. 7</xref>, AG significantly contributes to the prediction of the acceptor site for each organism dataset, as GT contributes to the prediction of the donor site.<fig id="fig0030"><label>Fig. 6</label><caption><p>Result validation for acceptor splice site organism. This Figure shows the sequence logo of <italic>the Homo sapiens, Oryza sativa japonica, Arabidopsis thaliana, Drosophila melanogaster, and Caenorhabditis elegans</italic> organisms acceptor splice sites within genomic sequence position 295 and 305. This nucleotide sequence pattern likelihood is depicted by the magnitude of the genomic sequence characters in the motif representation.</p></caption><alt-text id="at0030">Fig. 6</alt-text><graphic xlink:href="gr6"/></fig><fig id="fig0035"><label>Fig. 7</label><caption><p>Result validation for donor splice site organism. This Figure shows the sequence logo of the <italic>Homo sapiens, Oryza sativa japonica, Arabidopsis thaliana, Drosophila melanogaster, and Caenorhabditis elegans</italic> organisms donor splice sites within genomic sequence position 295 and 305. This nucleotide sequence pattern likelihood is depicted by the magnitude of the genomic sequence characters in the motif representation.</p></caption><alt-text id="at0035">Fig. 7</alt-text><graphic xlink:href="gr7"/></fig></p>
    </sec>
    <sec id="sec0075">
      <label>3.7</label>
      <title>CNNSplice webserver</title>
      <p id="p0290">We have developed a webserver accessible at <bold>http://www.cnnsplice.online</bold> for the purpose of this project. The webserver allows users to input a FASTA sequence or upload a FASTA file, following specific criteria outlined in the "About" Tab. Users must select a pre-trained model for different organisms and provide an email address for notification about a job submission and about the completion of the submission prediction. The completed job will be sent to the user via email as a text file attachment, indicating the presence or absence of a splice site for each sequence in the provided FASTA data using binary data (1 for detection, 0 for no detection). To assist users, we have included a tutorial and user guide with examples accessible through the "Tutorial/Example" Tab on the webserver.</p>
    </sec>
  </sec>
  <sec id="sec0080">
    <label>4</label>
    <title>Conclusion</title>
    <p id="p0295">In this paper, we presented CNNSplice, a powerful biological tool for predicting SS. This bioinformatics solution stems from the biological procedures of RNA splicing that are required for protein synthesis and gene expression. Our method extracts raw genomic features, maps them using one-hot encoding, and feeds them into the CNN architecture as inputs. We selected the best five models based on our five-fold cross-validation, with our model offering superior prediction performance than previous SS prediction tools for both balanced and imbalanced datasets, as stated in the results sections. Furthermore, we showed that the CNNSplice model trained on the organisms utilized in the research may be applied to another species without losing any information, demonstrating its generalizability in annotating new organisms. Based on our findings, we can conclude that CNNSplice offers the following advantages:<list list-type="simple" id="li0020"><list-item id="u0100"><label>(1)</label><p id="p0300">CNNSplice is a convenient two-class model that predicts true and false SS in both salient canonical and noncanonical SS.</p></list-item><list-item id="u0105"><label>(2)</label><p id="p0305">Our analysis shows that CNNSplice models outperform previous approaches, with our models occupying the Top-1 and Top-2 performance positions across all organisms for both balanced and imbalanced acceptor and donor datasets (<xref rid="fig0020" ref-type="fig">Fig. 4</xref>). In general, depending on the detection and the organism under consideration, each of these model architectures has its own advantages.</p></list-item><list-item id="u0110"><label>(3)</label><p id="p0310">As described in the generalization section, CNNSplice Model 1 provides a robust tool to predict and annotate poorly studied or newly sequenced genomic datasets (<xref rid="fig0025" ref-type="fig">Fig. 5</xref>). In other words, despite being trained on one genomic organism dataset and evaluated on a different organism dataset, this model yields a high SS prediction accuracy.</p></list-item></list></p>
    <p id="p0315">Our results show that CNNSplice can extract high-level features and locate SS genomic sequence patterns, which may then be used to infer gene expression information as seen in <xref rid="fig0025" ref-type="fig">Fig. 5</xref> for phenotype anomaly and diseases analysis.</p>
  </sec>
  <sec id="sec0085">
    <title>Funding</title>
    <p id="p0320">This work was supported by the start-up funding from the <funding-source id="gs1"><institution-wrap><institution-id institution-id-type="doi">10.13039/100010174</institution-id><institution>University of Colorado</institution></institution-wrap></funding-source>, Colorado Springs to O.O.</p>
  </sec>
  <sec id="sec0090">
    <title>CRediT authorship contribution statement</title>
    <p id="p0325"><bold>Victor Akpokiro:</bold> Methodology, Software, Investigation, Data curation, Analysis, Writing – original draft, Writing – review &amp; editing, Validation. <bold>H. M. A. Mohit Chowdhury:</bold> Software, Investigation, Analysis, Writing – review &amp; editing, Validation. <bold>Samuel Olowofila:</bold> Software, Writing – review &amp; editing, Validation. <bold>Raisa Nusrat:</bold> Software, Writing – review &amp; editing, Validation. <bold>Oluwatosin Oluwadare:</bold> Conceptualization, Methodology, Analysis, Writing – review &amp; editing, Supervision, Resources, Project administration, Funding acquisition.</p>
  </sec>
  <sec sec-type="COI-statement">
    <title>Declaration of Competing interest</title>
    <p id="p0330">The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.</p>
  </sec>
</body>
<back>
  <ref-list id="bibliog0005">
    <title>References</title>
    <ref id="bib1">
      <label>1</label>
      <element-citation publication-type="journal" id="sbref1">
        <person-group person-group-type="author">
          <name>
            <surname>Goel</surname>
            <given-names>N.</given-names>
          </name>
          <name>
            <surname>Singh</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Aseri</surname>
            <given-names>T.C.</given-names>
          </name>
        </person-group>
        <article-title>A review of soft computing techniques for gene prediction</article-title>
        <source>Int Sch Res Not</source>
        <year>2013</year>
        <fpage>2013</fpage>
      </element-citation>
    </ref>
    <ref id="bib2">
      <label>2</label>
      <element-citation publication-type="journal" id="sbref2">
        <person-group person-group-type="author">
          <name>
            <surname>Schellenberg</surname>
            <given-names>M.J.</given-names>
          </name>
          <name>
            <surname>Ritchie</surname>
            <given-names>D.B.</given-names>
          </name>
          <name>
            <surname>MacMillan</surname>
            <given-names>A.M.</given-names>
          </name>
        </person-group>
        <article-title>Pre-mRNA splicing: a complex picture in higher definition</article-title>
        <source>Trends Biochem Sci</source>
        <volume>33</volume>
        <issue>6</issue>
        <year>2008</year>
        <fpage>243</fpage>
        <lpage>246</lpage>
        <pub-id pub-id-type="pmid">18472266</pub-id>
      </element-citation>
    </ref>
    <ref id="bib3">
      <label>3</label>
      <element-citation publication-type="journal" id="sbref3">
        <person-group person-group-type="author">
          <name>
            <surname>Sleator</surname>
            <given-names>R.D.</given-names>
          </name>
        </person-group>
        <article-title>An overview of the current status of eukaryote gene prediction strategies</article-title>
        <source>Gene</source>
        <volume>461</volume>
        <issue>1–2</issue>
        <year>2010</year>
        <fpage>1</fpage>
        <lpage>4</lpage>
        <pub-id pub-id-type="pmid">20430068</pub-id>
      </element-citation>
    </ref>
    <ref id="bib4">
      <label>4</label>
      <element-citation publication-type="journal" id="sbref4">
        <person-group person-group-type="author">
          <name>
            <surname>Baten</surname>
            <given-names>A.K.</given-names>
          </name>
          <name>
            <surname>Halgamuge</surname>
            <given-names>S.K.</given-names>
          </name>
          <name>
            <surname>Chang</surname>
            <given-names>B.C.</given-names>
          </name>
        </person-group>
        <article-title>Fast splice site detection using information content and feature reduction</article-title>
        <source>BMC Bioinform</source>
        <volume>9</volume>
        <issue>12</issue>
        <year>2008</year>
        <fpage>1</fpage>
        <lpage>12</lpage>
      </element-citation>
    </ref>
    <ref id="bib5">
      <label>5</label>
      <element-citation publication-type="journal" id="sbref5">
        <person-group person-group-type="author">
          <name>
            <surname>Burset</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Seledtsov</surname>
            <given-names>I.A.</given-names>
          </name>
          <name>
            <surname>Solovyev</surname>
            <given-names>V.V.</given-names>
          </name>
        </person-group>
        <article-title>Analysis of canonical and non-canonical splice sites in mammalian genomes</article-title>
        <source>Nucleic Acids Res</source>
        <volume>28</volume>
        <issue>21</issue>
        <year>2000</year>
        <fpage>4364</fpage>
        <lpage>4375</lpage>
        <pub-id pub-id-type="pmid">11058137</pub-id>
      </element-citation>
    </ref>
    <ref id="bib6">
      <label>6</label>
      <mixed-citation publication-type="other" id="othref0005">Reese, M. G., Eeckman, F. H., Kulp, D., &amp; Haussler, D. Improved splice site detection in Genie. In: Proceedings of the first annual international conference on computational molecular biology; 1997, January. p. 232–40).</mixed-citation>
    </ref>
    <ref id="bib7">
      <label>7</label>
      <element-citation publication-type="journal" id="sbref6">
        <person-group person-group-type="author">
          <name>
            <surname>Zhang</surname>
            <given-names>X.H.</given-names>
          </name>
          <name>
            <surname>Heller</surname>
            <given-names>K.A.</given-names>
          </name>
          <name>
            <surname>Hefter</surname>
            <given-names>I.</given-names>
          </name>
          <name>
            <surname>Leslie</surname>
            <given-names>C.S.</given-names>
          </name>
          <name>
            <surname>Chasin</surname>
            <given-names>L.A.</given-names>
          </name>
        </person-group>
        <article-title>Sequence information for the splicing of human pre-mRNA identified by support vector machine classification</article-title>
        <source>Genome Res</source>
        <volume>13</volume>
        <issue>12</issue>
        <year>2003</year>
        <fpage>2637</fpage>
        <lpage>2650</lpage>
        <pub-id pub-id-type="pmid">14656968</pub-id>
      </element-citation>
    </ref>
    <ref id="bib8">
      <label>8</label>
      <element-citation publication-type="journal" id="sbref7">
        <person-group person-group-type="author">
          <name>
            <surname>Sun</surname>
            <given-names>Y.F.</given-names>
          </name>
          <name>
            <surname>Fan</surname>
            <given-names>X.D.</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>Y.D.</given-names>
          </name>
        </person-group>
        <article-title>Identifying splicing sites in eukaryotic RNA: support vector machine approach</article-title>
        <source>Comput Biol Med</source>
        <volume>33</volume>
        <issue>1</issue>
        <year>2003</year>
        <fpage>17</fpage>
        <lpage>29</lpage>
        <pub-id pub-id-type="pmid">12485627</pub-id>
      </element-citation>
    </ref>
    <ref id="bib9">
      <label>9</label>
      <mixed-citation publication-type="other" id="othref0010">Yeo, G., Burge, C. B. Maximum entropy modeling of short sequence motifs with applications to RNA splicing signals. In: Proceedings of the seventh annual international conference on research in computational molecular biology; 2003, April. p. 322–31).</mixed-citation>
    </ref>
    <ref id="bib10">
      <label>10</label>
      <element-citation publication-type="journal" id="sbref8">
        <person-group person-group-type="author">
          <name>
            <surname>Zhang</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Gish</surname>
            <given-names>W.</given-names>
          </name>
        </person-group>
        <article-title>Improved spliced alignment from an information theoretic approach</article-title>
        <source>Bioinformatics</source>
        <volume>22</volume>
        <issue>1</issue>
        <year>2006</year>
        <fpage>13</fpage>
        <lpage>20</lpage>
        <pub-id pub-id-type="pmid">16267086</pub-id>
      </element-citation>
    </ref>
    <ref id="bib11">
      <label>11</label>
      <element-citation publication-type="journal" id="sbref9">
        <person-group person-group-type="author">
          <name>
            <surname>Arita</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Tsuda</surname>
            <given-names>K.</given-names>
          </name>
          <name>
            <surname>Asai</surname>
            <given-names>K.</given-names>
          </name>
        </person-group>
        <article-title>Modeling splicing sites with pairwise correlations</article-title>
        <source>Bioinformatics</source>
        <volume>18</volume>
        <issue>suppl_2</issue>
        <year>2002</year>
        <fpage>S27</fpage>
        <lpage>S34</lpage>
        <pub-id pub-id-type="pmid">12385980</pub-id>
      </element-citation>
    </ref>
    <ref id="bib12">
      <label>12</label>
      <element-citation publication-type="journal" id="sbref10">
        <person-group person-group-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>T.M.</given-names>
          </name>
          <name>
            <surname>Lu</surname>
            <given-names>C.C.</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>W.H.</given-names>
          </name>
        </person-group>
        <article-title>Prediction of splice sites with dependency graphs and their expanded bayesian networks</article-title>
        <source>Bioinformatics</source>
        <volume>21</volume>
        <issue>4</issue>
        <year>2005</year>
        <fpage>471</fpage>
        <lpage>482</lpage>
        <pub-id pub-id-type="pmid">15374869</pub-id>
      </element-citation>
    </ref>
    <ref id="bib13">
      <label>13</label>
      <element-citation publication-type="journal" id="sbref11">
        <person-group person-group-type="author">
          <name>
            <surname>Burge</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Karlin</surname>
            <given-names>S.</given-names>
          </name>
        </person-group>
        <article-title>Prediction of complete gene structures in human genomic DNA</article-title>
        <source>J Mol Biol</source>
        <volume>268</volume>
        <issue>1</issue>
        <year>1997</year>
        <fpage>78</fpage>
        <lpage>94</lpage>
        <pub-id pub-id-type="pmid">9149143</pub-id>
      </element-citation>
    </ref>
    <ref id="bib14">
      <label>14</label>
      <mixed-citation publication-type="other" id="othref0015">Chuang, J. S., Roth, D. Splice site prediction using a sparse network of winnows; 2001.</mixed-citation>
    </ref>
    <ref id="bib15">
      <label>15</label>
      <element-citation publication-type="journal" id="sbref12">
        <person-group person-group-type="author">
          <name>
            <surname>Rajapakse</surname>
            <given-names>J.C.</given-names>
          </name>
          <name>
            <surname>Ho</surname>
            <given-names>L.S.</given-names>
          </name>
        </person-group>
        <article-title>Markov encoding for detecting signals in genomic sequences</article-title>
        <source>IEEE/ACM Trans Comput Biol Bioinform</source>
        <volume>2</volume>
        <issue>2</issue>
        <year>2005</year>
        <fpage>131</fpage>
        <lpage>142</lpage>
        <pub-id pub-id-type="pmid">17044178</pub-id>
      </element-citation>
    </ref>
    <ref id="bib16">
      <label>16</label>
      <element-citation publication-type="journal" id="sbref13">
        <person-group person-group-type="author">
          <name>
            <surname>Pertea</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Lin</surname>
            <given-names>X.</given-names>
          </name>
          <name>
            <surname>Salzberg</surname>
            <given-names>S.L.</given-names>
          </name>
        </person-group>
        <article-title>GeneSplicer: a new computational method for splice site prediction</article-title>
        <source>Nucleic Acids Res</source>
        <volume>29</volume>
        <issue>5</issue>
        <year>2001</year>
        <fpage>1185</fpage>
        <lpage>1190</lpage>
        <pub-id pub-id-type="pmid">11222768</pub-id>
      </element-citation>
    </ref>
    <ref id="bib17">
      <label>17</label>
      <element-citation publication-type="journal" id="sbref14">
        <person-group person-group-type="author">
          <name>
            <surname>Pashaei</surname>
            <given-names>E.</given-names>
          </name>
          <name>
            <surname>Aydin</surname>
            <given-names>N.</given-names>
          </name>
        </person-group>
        <article-title>Markovian encoding models in human splice site recognition using SVM</article-title>
        <source>Comput Biol Chem</source>
        <volume>73</volume>
        <year>2018</year>
        <fpage>159</fpage>
        <lpage>170</lpage>
        <pub-id pub-id-type="pmid">29486390</pub-id>
      </element-citation>
    </ref>
    <ref id="bib18">
      <label>18</label>
      <mixed-citation publication-type="other" id="othref0020">Pashaei, E., Yilmaz, A., Ozen, M., Aydin, N. A novel method for splice sites prediction using sequence component and hidden Markov model. In: Proceedings of the thirty eightieth annual international conference of the IEEE engineering in medicine and biology society (EMBC). IEEE; 2016, August. p. 3076–9).</mixed-citation>
    </ref>
    <ref id="bib19">
      <label>19</label>
      <element-citation publication-type="journal" id="sbref15">
        <person-group person-group-type="author">
          <name>
            <surname>Du</surname>
            <given-names>X.</given-names>
          </name>
          <name>
            <surname>Yao</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Diao</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Zhu</surname>
            <given-names>H.</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>S.</given-names>
          </name>
        </person-group>
        <article-title>Deepss: exploring splice site motif through convolutional neural network directly from dna sequence</article-title>
        <source>IEEE Access</source>
        <volume>6</volume>
        <year>2018</year>
        <fpage>32958</fpage>
        <lpage>32978</lpage>
      </element-citation>
    </ref>
    <ref id="bib20">
      <label>20</label>
      <element-citation publication-type="journal" id="sbref16">
        <person-group person-group-type="author">
          <name>
            <surname>Zuallaert</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Godin</surname>
            <given-names>F.</given-names>
          </name>
          <name>
            <surname>Kim</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Soete</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Saeys</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>De Neve</surname>
            <given-names>W.</given-names>
          </name>
        </person-group>
        <article-title>SpliceRover: interpretable convolutional neural networks for improved splice site prediction</article-title>
        <source>Bioinformatics</source>
        <volume>34</volume>
        <issue>24</issue>
        <year>2018</year>
        <fpage>4180</fpage>
        <lpage>4188</lpage>
        <pub-id pub-id-type="pmid">29931149</pub-id>
      </element-citation>
    </ref>
    <ref id="bib21">
      <label>21</label>
      <element-citation publication-type="journal" id="sbref17">
        <person-group person-group-type="author">
          <name>
            <surname>Albaradei</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Magana-Mora</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Thafar</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Uludag</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Bajic</surname>
            <given-names>V.B.</given-names>
          </name>
          <name>
            <surname>Gojobori</surname>
            <given-names>T.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Splice2Deep: an ensemble of deep convolutional neural networks for improved splice site prediction in genomic DNA</article-title>
        <source>Gene</source>
        <volume>763</volume>
        <year>2020</year>
        <object-id pub-id-type="publisher-id">100035</object-id>
      </element-citation>
    </ref>
    <ref id="bib22">
      <label>22</label>
      <element-citation publication-type="journal" id="sbref18">
        <person-group person-group-type="author">
          <name>
            <surname>Tayara</surname>
            <given-names>H.</given-names>
          </name>
          <name>
            <surname>Tahir</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Chong</surname>
            <given-names>K.T.</given-names>
          </name>
        </person-group>
        <article-title>iSS-CNN: identifying splicing sites using convolution neural network</article-title>
        <source>Chemom Intell Lab Syst</source>
        <volume>188</volume>
        <year>2019</year>
        <fpage>63</fpage>
        <lpage>69</lpage>
      </element-citation>
    </ref>
    <ref id="bib23">
      <label>23</label>
      <element-citation publication-type="journal" id="sbref19">
        <person-group person-group-type="author">
          <name>
            <surname>Jaganathan</surname>
            <given-names>K.</given-names>
          </name>
          <name>
            <surname>Panagiotopoulou</surname>
            <given-names>S.K.</given-names>
          </name>
          <name>
            <surname>McRae</surname>
            <given-names>J.F.</given-names>
          </name>
          <name>
            <surname>Darbandi</surname>
            <given-names>S.F.</given-names>
          </name>
          <name>
            <surname>Knowles</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>Y.I.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Predicting splicing from primary sequence with deep learning</article-title>
        <source>Cell</source>
        <volume>176</volume>
        <issue>3</issue>
        <year>2019</year>
        <fpage>535</fpage>
        <lpage>548</lpage>
        <pub-id pub-id-type="pmid">30661751</pub-id>
      </element-citation>
    </ref>
    <ref id="bib24">
      <label>24</label>
      <element-citation publication-type="journal" id="sbref20">
        <person-group person-group-type="author">
          <name>
            <surname>Wang</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>Z.</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>S.</given-names>
          </name>
        </person-group>
        <article-title>SpliceFinder: ab initio prediction of splice sites using convolutional neural network</article-title>
        <source>BMC Bioinform</source>
        <volume>20</volume>
        <issue>23</issue>
        <year>2019</year>
        <fpage>1</fpage>
        <lpage>13</lpage>
      </element-citation>
    </ref>
    <ref id="bib25">
      <label>25</label>
      <mixed-citation publication-type="other" id="othref0025">Akpokiro, V., Oluwadare, O., Kalita, J. DeepSplicer: an improved method of splice sites prediction using deep learning. In Proceedings of the twentieth IEEE international conference on machine learning and applications (ICMLA). IEEE; 2021, December. p. 606-9.</mixed-citation>
    </ref>
    <ref id="bib26">
      <label>26</label>
      <element-citation publication-type="journal" id="sbref21">
        <person-group person-group-type="author">
          <name>
            <surname>Ghosh</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Sufian</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Sultana</surname>
            <given-names>F.</given-names>
          </name>
          <name>
            <surname>Chakrabarti</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>De</surname>
            <given-names>D.</given-names>
          </name>
        </person-group>
        <article-title>Fundamental concepts of convolutional neural network</article-title>
        <source>Recent Trends Adv Artif Intell Internet Things</source>
        <year>2020</year>
        <fpage>519</fpage>
        <lpage>567</lpage>
      </element-citation>
    </ref>
    <ref id="bib27">
      <label>27</label>
      <mixed-citation publication-type="other" id="othref0030">Hara, K., Saito, D., Shouno, H. Analysis of function of rectified linear unit used in deep learning. In 2015 international joint conference on neural networks (IJCNN). IEEE; 2015, July. p. 1-8.</mixed-citation>
    </ref>
    <ref id="bib28">
      <label>28</label>
      <element-citation publication-type="journal" id="sbref22">
        <person-group person-group-type="author">
          <name>
            <surname>Srivastava</surname>
            <given-names>N.</given-names>
          </name>
          <name>
            <surname>Hinton</surname>
            <given-names>G.</given-names>
          </name>
          <name>
            <surname>Krizhevsky</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Sutskever</surname>
            <given-names>I.</given-names>
          </name>
          <name>
            <surname>Salakhutdinov</surname>
            <given-names>R.</given-names>
          </name>
        </person-group>
        <article-title>Dropout: a simple way to prevent neural networks from overfitting</article-title>
        <source>J Mach Learn Res</source>
        <volume>15</volume>
        <issue>1</issue>
        <year>2014</year>
        <fpage>1929</fpage>
        <lpage>1958</lpage>
      </element-citation>
    </ref>
    <ref id="bib29">
      <label>29</label>
      <element-citation publication-type="book" id="sbref23">
        <person-group person-group-type="author">
          <name>
            <surname>Bishop</surname>
            <given-names>C.M.</given-names>
          </name>
          <name>
            <surname>Nasrabadi</surname>
            <given-names>N.M.</given-names>
          </name>
        </person-group>
        <series>Pattern recognition and machine learning</series>
        <volume>4</volume>
        <year>2006</year>
        <publisher-name>Springer</publisher-name>
        <publisher-loc>New York</publisher-loc>
        <fpage>738</fpage>
      </element-citation>
    </ref>
    <ref id="bib30">
      <label>30</label>
      <element-citation publication-type="journal" id="sbref24">
        <person-group person-group-type="author">
          <name>
            <surname>Mount</surname>
            <given-names>S.M.</given-names>
          </name>
        </person-group>
        <article-title>A catalogue of splice junction sequences</article-title>
        <source>Nucleic Acids Res</source>
        <volume>10</volume>
        <issue>2</issue>
        <year>1982</year>
        <fpage>459</fpage>
        <lpage>472</lpage>
        <pub-id pub-id-type="pmid">7063411</pub-id>
      </element-citation>
    </ref>
    <ref id="bib31">
      <label>31</label>
      <element-citation publication-type="journal" id="sbref25">
        <person-group person-group-type="author">
          <name>
            <surname>Ribeiro</surname>
            <given-names>M.T.</given-names>
          </name>
          <name>
            <surname>Singh</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Guestrin</surname>
            <given-names>C.</given-names>
          </name>
        </person-group>
        <article-title>Model-agnostic interpretability of machine learning</article-title>
        <source>arXiv Prepr arXiv</source>
        <volume>1606</volume>
        <year>2016</year>
        <fpage>05386</fpage>
      </element-citation>
    </ref>
    <ref id="bib32">
      <label>32</label>
      <element-citation publication-type="journal" id="sbref26">
        <person-group person-group-type="author">
          <name>
            <surname>Lundberg</surname>
            <given-names>S.M.</given-names>
          </name>
          <name>
            <surname>Lee</surname>
            <given-names>S.I.</given-names>
          </name>
        </person-group>
        <article-title>A unified approach to interpreting model predictions</article-title>
        <source>Adv Neural Inf Process Syst</source>
        <year>2017</year>
        <fpage>30</fpage>
      </element-citation>
    </ref>
    <ref id="bib33">
      <label>33</label>
      <element-citation publication-type="journal" id="sbref27">
        <person-group person-group-type="author">
          <name>
            <surname>Crooks</surname>
            <given-names>G.E.</given-names>
          </name>
          <name>
            <surname>Hon</surname>
            <given-names>G.</given-names>
          </name>
          <name>
            <surname>Chandonia</surname>
            <given-names>J.M.</given-names>
          </name>
          <name>
            <surname>Brenner</surname>
            <given-names>S.E.</given-names>
          </name>
        </person-group>
        <article-title>WebLogo: a sequence logo generator</article-title>
        <source>Genome Res</source>
        <volume>14</volume>
        <issue>6</issue>
        <year>2004</year>
        <fpage>1188</fpage>
        <lpage>1190</lpage>
        <pub-id pub-id-type="pmid">15173120</pub-id>
      </element-citation>
    </ref>
  </ref-list>
  <sec sec-type="data-availability" id="da0005">
    <title>Data availability</title>
    <p id="p0005">CNNSplice’s data, models generated, and source code are available as an open-source software at https://github.com/OluwadareLab/CNNSplice. We have included a docker-containerized environment with all dependencies for local install and program runs in the CNNSplice repository.</p>
  </sec>
  <ack id="ack0005">
    <title>Acknowledgements</title>
    <p id="p0335">Not applicable.</p>
  </ack>
</back>
