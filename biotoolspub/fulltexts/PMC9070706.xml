<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1 20151215//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.1?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">J Synchrotron Radiat</journal-id>
    <journal-id journal-id-type="iso-abbrev">J Synchrotron Radiat</journal-id>
    <journal-id journal-id-type="publisher-id">J. Synchrotron Rad.</journal-id>
    <journal-title-group>
      <journal-title>Journal of Synchrotron Radiation</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">0909-0495</issn>
    <issn pub-type="epub">1600-5775</issn>
    <publisher>
      <publisher-name>International Union of Crystallography</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">9070706</article-id>
    <article-id pub-id-type="publisher-id">tv5034</article-id>
    <article-id pub-id-type="doi">10.1107/S160057752200282X</article-id>
    <article-id pub-id-type="coden">JSYRES</article-id>
    <article-id pub-id-type="pii">S160057752200282X</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Computer Programs</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title><italic toggle="yes">Tofu</italic>: a fast, versatile and user-friendly image processing toolkit for computed tomography</article-title>
      <alt-title>tofu</alt-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Faragó</surname>
          <given-names>Tomáš</given-names>
        </name>
        <xref rid="a" ref-type="aff">a</xref>
        <xref rid="cor" ref-type="corresp">*</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Gasilov</surname>
          <given-names>Sergey</given-names>
        </name>
        <xref rid="b" ref-type="aff">b</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Emslie</surname>
          <given-names>Iain</given-names>
        </name>
        <xref rid="b" ref-type="aff">b</xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0002-2429-6171</contrib-id>
        <name>
          <surname>Zuber</surname>
          <given-names>Marcus</given-names>
        </name>
        <xref rid="a" ref-type="aff">a</xref>
        <xref rid="c" ref-type="aff">c</xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0002-5243-2310</contrib-id>
        <name>
          <surname>Helfen</surname>
          <given-names>Lukas</given-names>
        </name>
        <xref rid="d" ref-type="aff">d</xref>
        <xref rid="a" ref-type="aff">a</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Vogelgesang</surname>
          <given-names>Matthias</given-names>
        </name>
        <xref rid="e" ref-type="aff">e</xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0003-1034-6876</contrib-id>
        <name>
          <surname>Baumbach</surname>
          <given-names>Tilo</given-names>
        </name>
        <xref rid="a" ref-type="aff">a</xref>
        <xref rid="c" ref-type="aff">c</xref>
      </contrib>
      <aff id="a"><label>a</label>Institute for Photon Science and Synchrotron Radiation, <institution>Karlsruhe Institute of Technology (KIT)</institution>, Herrmann-von-Helmholtz-Platz 1, 76344 Eggenstein-Leopoldshafen, <country>Germany</country></aff>
      <aff id="b"><label>b</label><institution>Canadian Light Source</institution>, 44 Innovation Blvd, Saskatoon, <country>Canada</country> S7N 2V3</aff>
      <aff id="c"><label>c</label>Laboratory for Applications of Synchrotron Radiation, <institution>Karlsruhe Institute of Technology</institution>, Kaiserstrasse 12, 76131 Karlsruhe, <country>Germany</country></aff>
      <aff id="d"><label>d</label><institution>Institut Laue-Langevin</institution>, 71 Avenue des Martyrs, CS 20156, 38042 Grenoble Cedex 9, <country>France</country></aff>
      <aff id="e"><label>e</label>Institute for Data Processing and Electronics, <institution>Karlsruhe Institute of Technology</institution>, Hermann-von-Helmholtz-Platz 1, 76344 Eggenstein-Leopoldshafen, <country>Germany</country></aff>
    </contrib-group>
    <author-notes>
      <corresp id="cor">Correspondence e-mail: <email>tomas.farago@kit.edu</email>
</corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <day>01</day>
      <month>5</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="epub">
      <day>04</day>
      <month>4</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>04</day>
      <month>4</month>
      <year>2022</year>
    </pub-date>
    <!--PMC Release delay is 0 months and 0 days and was based on the <pub-date pub-type="epub"/>.-->
    <volume>29</volume>
    <issue>Pt 3</issue>
    <issue-id pub-id-type="publisher-id">s220300</issue-id>
    <fpage>916</fpage>
    <lpage>927</lpage>
    <history>
      <date date-type="received">
        <day>26</day>
        <month>11</month>
        <year>2021</year>
      </date>
      <date date-type="accepted">
        <day>14</day>
        <month>3</month>
        <year>2022</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© Tomáš Faragó et al. 2022</copyright-statement>
      <copyright-year>2022</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution (CC-BY) Licence, which permits
unrestricted use, distribution, and reproduction in any medium, provided the original authors and source are cited.</license-p>
      </license>
      <ali:free_to_read xmlns:ali="http://www.niso.org/schemas/ali/1.0/"/>
    </permissions>
    <self-uri xlink:href="https://doi.org/10.1107/S160057752200282X">A full version of this article is available from Crystallography Journals Online.</self-uri>
    <abstract abstract-type="toc">
      <p>The versatile and user-friendly image processing toolkit <italic toggle="yes">tofu</italic>, optimized for 3D reconstruction of parallel beam, cone beam, tomography and laminography data, is presented.</p>
    </abstract>
    <abstract>
      <p><italic toggle="yes">Tofu</italic> is a toolkit for processing large amounts of images and for tomographic reconstruction. Complex image processing tasks are organized as workflows of individual processing steps. The toolkit is able to reconstruct parallel and cone beam as well as tomographic and laminographic geometries. Many pre- and post-processing algorithms needed for high-quality 3D reconstruction are available, <italic toggle="yes">e.g.</italic> phase retrieval, ring removal and de-noising. <italic toggle="yes">Tofu</italic> is optimized for stand-alone GPU workstations on which it achieves reconstruction speed comparable with costly CPU clusters. It automatically utilizes all GPUs in the system and generates 3D reconstruction code with minimal number of instructions given the input geometry (parallel/cone beam, tomography/laminography), hence yielding optimal run-time performance. In order to improve accessibility for researchers with no previous knowledge of programming, <italic toggle="yes">tofu</italic> contains graphical user interfaces for both optimization of 3D reconstruction parameters and batch processing of data with pre-configured workflows for typical computed tomography reconstruction. The toolkit is open source and extensive documentation is available for both end-users and developers. Thanks to the mentioned features, <italic toggle="yes">tofu</italic> is suitable for both expert users with specialized image processing needs (<italic toggle="yes">e.g.</italic> when dealing with data from custom-built computed tomography scanners) and for application-specific end-users who just need to reconstruct their data on off-the-shelf hardware.</p>
    </abstract>
    <kwd-group>
      <kwd>tomography</kwd>
      <kwd>laminography</kwd>
      <kwd>parallel beam</kwd>
      <kwd>cone beam</kwd>
      <kwd>3D reconstruction</kwd>
      <kwd>phase retrieval</kwd>
      <kwd>artifact removal</kwd>
      <kwd>GPU computing</kwd>
      <kwd>user interface</kwd>
      <kwd>batch processing</kwd>
      <kwd>visual programming</kwd>
    </kwd-group>
    <funding-group>
      <award-group>
        <funding-source>Bundesministerium für Bildung und Forschung</funding-source>
        <award-id>05K10CKB</award-id>
        <award-id>05K10VKE</award-id>
        <award-id>05K12CK2</award-id>
        <award-id>05K12VK2</award-id>
        <award-id>05K16VK6</award-id>
        <award-id>05K19VKE</award-id>
      </award-group>
      <award-group>
        <funding-source>Canadian Light Source</funding-source>
      </award-group>
      <award-group>
        <funding-source>Canada Foundation for Innovation</funding-source>
      </award-group>
      <award-group>
        <funding-source>Natural Sciences and Engineering Research Council of Canada</funding-source>
      </award-group>
      <award-group>
        <funding-source>National Research Council Canada</funding-source>
      </award-group>
      <award-group>
        <funding-source>Canadian Institutes of Health Research</funding-source>
      </award-group>
      <award-group>
        <funding-source>The Government of Saskatchewan</funding-source>
      </award-group>
      <award-group>
        <funding-source>University of Saskatchewan</funding-source>
      </award-group>
      <funding-statement>This work was supported by the German Federal Ministry of Education and Research (BMBF), projects UFO (05K10CKB, 05K10VKE), UFO 2 (05K12CK2, 05K12VK2), CODE-VITA (05K16VK6) and HIGH-LIFE (05K19VKE), Canadian Light Source, a national research facility of the University of Saskatchewan, which is supported by the Canada Foundation for Innovation (CFI), the Natural Sciences and Engineering Research Council (NSERC), the National Research Council (NRC), the Canadian Institutes of Health Research (CIHR), the Government of Saskatchewan, and the University of Saskatchewan.</funding-statement>
    </funding-group>
    <counts>
      <page-count count="12"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec sec-type="introduction" id="sec1">
    <label>1.</label>
    <title>Introduction</title>
    <p>X-ray microtomography (µCT) is an invaluable non-invasive imaging technique for examining the internal structure of objects and organisms. Depending on a particular geometry [parallel or cone beam, tomography or laminography (Helfen <italic toggle="yes">et al.</italic>, 2011<xref rid="bb10" ref-type="bibr"> ▸</xref>)] and source (X-ray, neutron,…), 3D reconstruction workflows may contain a lot of pre- and post-processing steps, including image normalization (Van Nieuwenhove <italic toggle="yes">et al.</italic>, 2015<xref rid="bb25" ref-type="bibr"> ▸</xref>; Jailin <italic toggle="yes">et al.</italic>, 2017<xref rid="bb12" ref-type="bibr"> ▸</xref>), phase retrieval (Paganin <italic toggle="yes">et al.</italic>, 2002<xref rid="bb19" ref-type="bibr"> ▸</xref>; Moosmann <italic toggle="yes">et al.</italic>, 2011<xref rid="bb16" ref-type="bibr"> ▸</xref>), de-noising (Buades <italic toggle="yes">et al.</italic>, 2005<xref rid="bb4" ref-type="bibr"> ▸</xref>) and artifact removal (Hsieh <italic toggle="yes">et al.</italic>, 2000<xref rid="bb11" ref-type="bibr"> ▸</xref>; Münch <italic toggle="yes">et al.</italic>, 2009<xref rid="bb17" ref-type="bibr"> ▸</xref>; Vo <italic toggle="yes">et al.</italic>, 2018<xref rid="bb27" ref-type="bibr"> ▸</xref>; Croton <italic toggle="yes">et al.</italic>, 2019<xref rid="bb5" ref-type="bibr"> ▸</xref>). The final, high-quality workflow may contain a lot of image processing algorithms and parameters which need to be adjusted for each data set separately in an iterative manner and this might become overwhelmingly difficult for inexperienced users. Moreover, such workflows may be computationally demanding, which is not an issue for large facilities because they typically have access to computer clusters, but it becomes a problem for smaller laboratories that do not have access to such equipment where scientists must process the data on their own, often on relatively inexpensive hardware.</p>
    <p>Computational speed is even more important if we consider the technological progress in imaging instrumentation. Thanks to continuous new developments in radiation sources (Raimondi, 2016<xref rid="bb21" ref-type="bibr"> ▸</xref>; Schroer <italic toggle="yes">et al.</italic>, 2018<xref rid="bb22" ref-type="bibr"> ▸</xref>), imaging detectors (Mokso <italic toggle="yes">et al.</italic>, 2017<xref rid="bb15" ref-type="bibr"> ▸</xref>), and automation (Vogelgesang <italic toggle="yes">et al.</italic>, 2016<xref rid="bb29" ref-type="bibr"> ▸</xref>; Marone <italic toggle="yes">et al.</italic>, 2017<xref rid="bb13" ref-type="bibr"> ▸</xref>; Hashem <italic toggle="yes">et al.</italic>, 2021<xref rid="bb9" ref-type="bibr"> ▸</xref>), the throughput of imaging systems is increasing. It is common that during one experimental day at a synchrotron imaging station researchers collect hundreds of data sets amounting to several terabytes of data. Even in a laboratory environment, modern µCT scanners enable data acquisition at the rate of just several tens of seconds per scan. This is highly demanded in order to capture transient processes and conduct <italic toggle="yes">in situ</italic> and <italic toggle="yes">operando</italic> studies. In this case, as well as when studying live animals under anesthesia, being able to preview and evaluate the image quality very quickly is extremely important for making a decision about repeating the scan or proceeding to the next specimen or operating point.</p>
    <p>Based on the above observations, reconstruction software should be fast, versatile, user-friendly and scalable (capable of processing large volumes of data on inexpensive, off-the-shelf hardware). Fast reconstruction immediately after the data acquisition is needed to quickly assess the measurement results. A selection of common image pre- and post-processing operations, alongside suppression of typical artifacts, must be available in order to create flexible data processing workflows. It is beneficial to avoid using several different software tools since this always slows down the reconstruction process and creates unnecessary copies of data. In addition, a simple user interface is necessary for researchers without prior experience in scripting and programming. Scalability is very important for those who do not have access to a computer cluster but still need to process large amounts of data in their home laboratories.</p>
    <p>Several open-source tomographic reconstruction tools are available. <italic toggle="yes">Astra toolbox</italic> (van Aarle <italic toggle="yes">et al.</italic>, 2016<xref rid="bb1" ref-type="bibr"> ▸</xref>) offers multiple algorithms for both parallel and cone-beam computed tomography (CT) geometries; <italic toggle="yes">PyHST2</italic> (Mirone <italic toggle="yes">et al.</italic>, 2014<xref rid="bb14" ref-type="bibr"> ▸</xref>) offers excellent run-time performance; <italic toggle="yes">Tomopy</italic> (Gürsoy <italic toggle="yes">et al.</italic>, 2014<xref rid="bb8" ref-type="bibr"> ▸</xref>), <italic toggle="yes">Savu</italic> (Atwood <italic toggle="yes">et al.</italic>, 2015<xref rid="bb2" ref-type="bibr"> ▸</xref>) and the <italic toggle="yes">Syrmep Tomo Project</italic> (Brun <italic toggle="yes">et al.</italic>, 2017<xref rid="bb3" ref-type="bibr"> ▸</xref>) provide complex capabilities by auxiliary pre- and post-processing algorithms and interfaces to other 3D reconstruction tools. They provide command line interfaces (CLI), graphical user interfaces (GUI), or both.</p>
    <p>In contrast to the flexibility of open source projects, reconstruction software supplied with laboratory scanners and commercially available reconstruction software like <italic toggle="yes">Octopus</italic> (Vlassenbroeck <italic toggle="yes">et al.</italic>, 2006<xref rid="bb26" ref-type="bibr"> ▸</xref>) or <italic toggle="yes">VG Studio Max</italic> (<ext-link xlink:href="https://www.volumegraphics.com/en/products/vgsm/ct-reconstruction-data-quality-analysis.html" ext-link-type="uri">https://www.volumegraphics.com/en/products/vgsm/ct-reconstruction-data-quality-analysis.html</ext-link>) are normally a black box, albeit with a very nice GUI, which reconstructs data following a predefined workflow. However, most of these systems cannot be modified to incorporate external algorithms into the reconstruction chain, for instance, trying a new phase-retrieval method. At the same time, there are more and more communications on custom-build laboratory systems for X-ray µCT [see Müller <italic toggle="yes">et al.</italic> (2017<xref rid="bb18" ref-type="bibr"> ▸</xref>) and references therein, and Polyakov <italic toggle="yes">et al.</italic> (2017<xref rid="bb20" ref-type="bibr"> ▸</xref>)]. Availability of user-friendly, easily extensible, and open-source software which can be used for phase-retrieval and reconstruction of cone-beam data can certainly facilitate new developments.</p>
    <p>Here, we present <italic toggle="yes">tofu</italic>, a Python software package for general image processing, but with special emphasis on tomographic reconstruction that supports parallel, cone beam, tomographic and laminographic geometries. It is user-friendly without compromising processing speed and flexibility provided by the <italic toggle="yes">ufo framework</italic> (Vogelgesang <italic toggle="yes">et al.</italic>, 2012<xref rid="bb28" ref-type="bibr"> ▸</xref>) back-end.</p>
    <p>Unlike the existing open source tools, <italic toggle="yes">tofu</italic> connects the image processing algorithms into a workflow on the <italic toggle="yes">ufo framework</italic> (OpenCL) layer. Once the data is loaded, it stays in the GPU memory as it passes through the workflow. Hence, the processing time is significantly reduced as there is no need to download intermediate results to the main memory in order to pass them to the the subsequent stages of the workflow. <italic toggle="yes">Tofu</italic> is further equipped with versatile graphical user interfaces. <italic toggle="yes">Tofu flow</italic> is a GUI for visual programming of image processing workflows. Thanks to the fast execution, one can vary the parameters and observe changes in the output <italic toggle="yes">interactively</italic>. Once the optimal combination of algorithms and parameters is found, <italic toggle="yes">tofu ez</italic> can be used to automatically reconstruct multiple tomographic data sets.</p>
    <p>In addition to the GUIs, there is a multitude of command line interface (CLI) sub-commands for experienced users, which can be embedded into scripts and other programs.</p>
    <p>Three-dimensional (3D) reconstruction in <italic toggle="yes">tofu</italic> is flexible and supports complex scanning scenarios, such as helical CT. It includes algorithms for reduction of typical artifacts, <italic toggle="yes">e.g.</italic> rings, ‘zingers’ and noise. Several phase retrieval algorithms and many general image processing filters (<italic toggle="yes">e.g.</italic> pad, crop, blur) are available as well.</p>
    <p>Scalability for 3D reconstruction is achieved by automatically splitting the data to all available GPUs in the system and by sub-dividing the final volume into several sub-volumes if needed. <italic toggle="yes">Tofu</italic> is open source with extensive documentation available online for both end-users and developers.</p>
    <p>In the next section a brief description of the software structure is presented; the most important and frequently used algorithms are listed and the implementation of filtered back projection is described in more detail. Section 3<xref rid="sec3" ref-type="sec"/> is dedicated to the user interfaces. Section 4<xref rid="sec4" ref-type="sec"/> presents several application highlights, while Section 5<xref rid="sec5" ref-type="sec"/> contains benchmarking results.</p>
  </sec>
  <sec id="sec2">
    <label>2.</label>
    <title>
Ufo framework
</title>
    <p><italic toggle="yes">Tofu</italic> is based on the open source <italic toggle="yes">ufo framework</italic> (Vogelgesang <italic toggle="yes">et al.</italic>, 2012<xref rid="bb28" ref-type="bibr"> ▸</xref>), which (1) provides a large library of image processing algorithm implementations, (2) connects them into a workflow (a directed acyclic graph), and (3) executes these workflows on a broad range of computer systems. The framework is written in C in a cross-platform and binding-friendly way, so that it can be used on different operating systems (Linux, Mac, Windows) and accessed from different programming languages (<italic toggle="yes">e.g.</italic> Python). It uses OpenCL for hardware-agnostic parallelization which allows for efficient execution on both CPUs and GPUs from various vendors, including NVIDIA, AMD and Intel. From the user perspective, there is a detailed description on how to install the prerequisites and the software itself on different operating systems and processor architectures in the manual (<ext-link xlink:href="https://ufo-core.readthedocs.io/en/latest/install/index.html" ext-link-type="uri">https://ufo-core.readthedocs.io/en/latest/install/index.html</ext-link>). Moreover, there are various Docker images available for download on Docker Hub (<ext-link xlink:href="https://hub.docker.com/r/tfarago/ufo-kit" ext-link-type="uri">https://hub.docker.com/r/tfarago/ufo-kit</ext-link>), which allows users to skip the installation step on Linux. The framework can read <italic toggle="yes">raw</italic>, <italic toggle="yes">tif</italic>, <italic toggle="yes">hdf5</italic> and <italic toggle="yes">edf</italic> file types and write <italic toggle="yes">raw</italic>, <italic toggle="yes">tif</italic>, <italic toggle="yes">hdf5</italic> and <italic toggle="yes">jpg</italic>. Table 1<xref rid="table1" ref-type="table"> ▸</xref> summarizes the components of the software stack behind <italic toggle="yes">tofu</italic>.</p>
    <p>Currently, there are over 90 image processing algorithms implemented in <italic toggle="yes">ufo-filters</italic>; here we will shortly describe the ones we implemented for obtaining high-quality 3D reconstruction.</p>
    <p><bold>2D Phase retrieval</bold> algorithms for near-field Fresnel diffraction images (also known as propagation-based phase contrast images) have been implemented, including the transport-of-intensity method (Paganin <italic toggle="yes">et al.</italic>, 2002<xref rid="bb19" ref-type="bibr"> ▸</xref>) and various contrast transfer function approaches (Moosmann <italic toggle="yes">et al.</italic>, 2011<xref rid="bb16" ref-type="bibr"> ▸</xref>). Moreover, the combination of multiple object–detector distances is supported as well (Zabler <italic toggle="yes">et al.</italic>, 2005<xref rid="bb30" ref-type="bibr"> ▸</xref>). For the case of a single object–detector distance, <italic toggle="yes">x</italic>- and <italic toggle="yes">y</italic>-direction distances can be specified separately, which is useful for processing images with non-symmetrical pixel size or various propagation distances, like in the case of Bragg magnifier imaging (Vagovič <italic toggle="yes">et al.</italic>, 2014<xref rid="bb24" ref-type="bibr"> ▸</xref>).</p>
    <p><bold>3D reconstruction</bold> is realized by the filtered back projection (FBP) algorithm for parallel beam and by the Feldkamp approach (Feldkamp <italic toggle="yes">et al.</italic>, 1984<xref rid="bb7" ref-type="bibr"> ▸</xref>) for cone beam data. Rotations of the detector, the axis of rotation and the reconstructed volume are supported for the treatment of a static setup mis­alignment, the possibility to reconstruct laminography data and the ability to rotate the reconstructed volume without the need for post-reconstruction 3D rotation. In addition, the reconstruction parameters can be specified for every projection separately to permit dynamic changes in the setup. This enables complex reconstructions without the need of data pre-processing, <italic toggle="yes">e.g.</italic> helical CT and motion-compensated reconstruction in case of vibrations or systematic drift. Fig. 1<xref rid="fig1" ref-type="fig"> ▸</xref> depicts the geometrical setup in more detail. Before the final reconstruction, it is often necessary to find the correct values of the reconstruction parameters, <italic toggle="yes">e.g.</italic> center of rotation, laminographic angle, <italic toggle="yes">etc</italic>. In order to help find these, the output of the algorithm is a 3D volume of horizontal slices where the third dimension does not need to be the vertical slice position. Instead, one can reconstruct the same horizontal slice with different values of a reconstruction parameter. Some metric, <italic toggle="yes">e.g.</italic> the standard deviation, can then be applied to such output to find the correct parameter value. Based on the specified geometry, an optimized back projection OpenCL kernel code with a minimal number of mathematical operations is generated at run-time, which leads to optimal reconstruction speed (<italic toggle="yes">e.g.</italic> coordinate transformations required for the tilted rotation axis in the case of laminography may be omitted in the case of tomography). On the top of that, only projection regions necessary for the specified reconstructed volume are read from the input data in order to minimize I/O.</p>
    <p><bold>Ring artifact removal</bold> is based on two algorithms, one for removing narrow and one for removing broad rings.</p>
    <p>Narrow rings, often stemming from noise, are removed by suppressing stripes which are close to being vertical in a sinogram (a row in a sinogram represents a projection under a certain angle), implemented by filtering the 2D Fourier transform of the sinogram.</p>
    <p>Broad rings, typical for scintillator defects, are filtered by locating the corresponding spots of extreme intensity in the projections by thresholding and region growing which yields a mask representing invalid pixels. Horizontal linear interpolation is then applied to replace erroneous intensity values.</p>
    <p>The <bold>Non-local means noise removal</bold> algorithm has been shown to significantly improve the signal-to-noise ratio of filtered images while preserving fine details (Buades <italic toggle="yes">et al.</italic>, 2005<xref rid="bb4" ref-type="bibr"> ▸</xref>). Such a filter is very desirable for the processing of low signal-to-noise ratio data, stemming from <italic toggle="yes">e.g.</italic> high-speed synchrotron experiments, high magnifications at lab sources, or neutron sources. Our current implementation supports the original algorithm and the faster version based on cumulative sums (Darbon <italic toggle="yes">et al.</italic>, 2008<xref rid="bb6" ref-type="bibr"> ▸</xref>).</p>
  </sec>
  <sec id="sec3">
    <label>3.</label>
    <title>User interfaces</title>
    <p>In this section, we will describe user interfaces (UIs) for working with the <italic toggle="yes">ufo framework</italic>. Our primary focus will be the two GUIs <italic toggle="yes">tofu flow</italic> and <italic toggle="yes">tofu ez</italic>, which enable user-friendly creation of image processing workflows and batch processing of tomographic data sets. We will also briefly describe the CLIs; Table 2<xref rid="table2" ref-type="table"> ▸</xref> contains the complete list of the user interfaces.</p>
    <p>With any of the interfaces, the 3D reconstruction produces quantitatively the following output:</p>
    <p>(i) In the case of monochromatic absorption input data, the voxel values are unitless and correspond to Δ<italic toggle="yes">x</italic>μ, where Δ<italic toggle="yes">x</italic> is the pixel size of the detector and μ the linear attenuation coefficient.</p>
    <p>(ii) In the case of phase retrieval applied on projections (and within the approximation limits of the respective retrieval algorithm), the voxels correspond to either the unitless phase shift −2πΔ<italic toggle="yes">x</italic>δ/λ or, in the case of the transport-of-intensity method and specification of the δ part of the refractive index, the Δ<italic toggle="yes">x</italic> in meters.</p>
    <p>(iii) After ring removal, the results can no longer be quantitatively interpreted.</p>
    <sec id="sec3.1">
      <label>3.1.</label>
      <title><italic toggle="yes">Tofu</italic> flow</title>
      <p><italic toggle="yes">Tofu flow</italic> is a GUI (Fig. 2<xref rid="fig2" ref-type="fig"> ▸</xref>) for visual composition of image processing workflows. Its main advantage is quick and flexible flow creation with embedded visualization of results. This combination makes the program <italic toggle="yes">interactive</italic>, which is very desirable when it comes to optimization of image processing parameters or education and training of people who are not yet familiar with tomographic image processing. It is written in Python 3 and PyQT5 (<ext-link xlink:href="https://riverbankcomputing.com/software/pyqt" ext-link-type="uri">https://riverbankcomputing.com/software/pyqt</ext-link>); the flow scene is based on <italic toggle="yes">qtpynodeeditor</italic> (<ext-link xlink:href="https://github.com/klauer/qtpynodeeditor" ext-link-type="uri">https://github.com/klauer/qtpynodeeditor</ext-link>).</p>
      <p>Algorithms from the <italic toggle="yes">ufo framework</italic> in the flow scene are represented as graphical nodes. Several nodes can be combined into one composite node in order to remove clutter. Algorithm parameters can be set directly inside nodes using standard input widgets from the Qt (<ext-link xlink:href="https://www.qt.io" ext-link-type="uri">https://www.qt.io</ext-link>) library. Moreover, parameters can be linked between nodes, <italic toggle="yes">i.e.</italic> changing one node’s parameter automatically updates another one’s, which minimizes the amount of required manual adjustments. Flow direction is defined by node connections. Starting points are nodes representing a data source and do not have input connections (<italic toggle="yes">e.g.</italic> Read node). Typical processing nodes have inputs and an output; the flow ends in sink nodes which do not have an output. Apart from write sink node, which writes the results to a disk, there is also an Image Viewer node for quick visualization of 2D images or 3D volumes.</p>
      <p>Execution of a flow in the scene, including scheduling and utilization of all GPUs in the system, is by default left to <italic toggle="yes">ufo-core</italic>. In the case of the memory-demanding 3D reconstruction, <italic toggle="yes">tofu flow</italic> creates several batches and executes them in sequence if more data than what fits into the GPU memory needs to be reconstructed. In order to provide an interactive way of working with flows, node parameters can be adjusted by a slider. Once its value has changed, a flow execution is triggered and the result in the image viewer is updated, see Fig. 3<xref rid="fig3" ref-type="fig"> ▸</xref>.</p>
    </sec>
    <sec id="sec3.2">
      <label>3.2.</label>
      <title>
Tofu ez
</title>
      <p>Writing custom scripts for batch processing of data allows one to tailor the reconstruction workflow perfectly for each particular case. However, not every research group can afford to have a person with a computer science background or an image processing specialist. To address this problem we have developed a user-friendly interface <italic toggle="yes">tofu ez</italic> which can be used to reconstruct data by scientists without substantial knowledge of the Linux command line or Python scripting skills. <italic toggle="yes">Tofu ez</italic> (Fig. 4<xref rid="fig4" ref-type="fig"> ▸</xref>) simplifies the usage of <italic toggle="yes">ufo-launch</italic> and <italic toggle="yes">tofu</italic> by exposing all important parameters in a PyQT5-based interface and automatically formatting a suitable list of commands depending on the user input. Typical applications of <italic toggle="yes">tofu ez</italic> include:</p>
      <p>(i) Optimization of reconstruction parameters.</p>
      <p>(ii) Single-click reconstruction of freshly acquired data during the experiment.</p>
      <p>(iii) Horizontal and vertical stitching of adjacent CT volumes.</p>
      <p>(iv) Batch processing of data after the experiment.</p>
      <p>(v) Data reduction and preparation for further analysis and 3D visualization.</p>
      <p>In order to start using <italic toggle="yes">tofu ez</italic> one prerequisite must be fulfilled: tomographic projections and auxiliary images required for intensity normalization (images acquired with sample moved out of the beam and detector background noise images, colloquially referred to as flats and darks) must be saved in separate directories as separate tif files or in a bigtiff container.</p>
      <p>At the beginning of a reconstruction, <italic toggle="yes">tofu ez</italic> creates a list of paths to all valid CT directories in the input directory. The names of CT directories are compared with the directory tree in the output directory (the relative path to a CT set in the input directory is preserved when results are saved in the output directory). Those CT sets whose names are not yet in the output directory will be reconstructed. If requested, <italic toggle="yes">tofu ez</italic> will automatically estimate the center of rotation parameter, which is the only unknown variable in the input of the filtered backprojection algorithm in parallel beam geometry. This information is used during the second pass, when the program creates an array of <italic toggle="yes">ufo-launch</italic> and <italic toggle="yes">tofu</italic> commands according to defined parameters and then executes them sequentially. The commands can also be printed on the screen. Fig. 5<xref rid="fig5" ref-type="fig"> ▸</xref> shows how <italic toggle="yes">tofu ez</italic> creates workflows in different situations. Metadata can be loaded from a configuration file and all parameters that could be used to re-run the reconstruction are saved automatically along with the reconstructed data.</p>
      <p>Operations belonging to the following 12 categories can be chained together to form a workflow which can be applied to multiple data sets in the input directory automatically:</p>
      <p>(i) Horizontal stitching of half acquisition mode data (see explanation in the paragraph below the list).</p>
      <p>(ii) Pre-processing with arbitrary <italic toggle="yes">ufo-launch</italic> workflow; default option is the remove-outliers filter for the suppression of ‘zinger’ artifacts.</p>
      <p>(iii) Removal of large spots which stem from defects in the scintillator crystal.</p>
      <p>(iv) Flat-field correction including dynamic intensity normalization (Van Nieuwenhove <italic toggle="yes">et al.</italic>, 2015<xref rid="bb25" ref-type="bibr"> ▸</xref>).</p>
      <p>(v) Phase-retrieval.</p>
      <p>(vi) Filtration of sinograms for the suppression of ring artifacts; fast Fourier transform based filter as well as a method which does not rely on the Fourier transform (Vo <italic toggle="yes">et al.</italic>, 2018<xref rid="bb27" ref-type="bibr"> ▸</xref>) are available.</p>
      <p>(vii) Automatic estimation of the position of the center of rotation; two different algorithms are available.</p>
      <p>(viii) Tomographic reconstruction with <italic toggle="yes">tofu reco</italic>.</p>
      <p>(ix) Crop output slices and rotate the object within the reconstructed slice.</p>
      <p>(x) Clip the histogram and convert reconstructed values to either 8 or 16 bit integers and save in the corresponding file format.</p>
      <p>(xi) Suppress noise in the reconstructed slices with the non-local means de-noising filter.</p>
      <p>(xii) Generate orthogonal slices with vertical stitching if required.</p>
      <p>An image viewer has been integrated into the <italic toggle="yes">tofu ez</italic> in order to facilitate the visual inspection of the CT slices and to clip the histogram of the reconstructed values. The advanced tab provides access to less frequently used algorithms and exposes performance optimization parameters. The fourth tab contains a number of tools for the stitching of images in case (1) the sample is larger than the beam and several local CT data sets were acquired to examine the entire volume; (2) for the preparation of the ‘half acquisition reconstruction’ (in parallel beam geometry, if a sample is rotated in the 0–360° range, two complete CT data sets are essentially acquired over the first and the second halves of rotation; if the rotation axis is shifted to the edge of the detector, the field of view can be effectively doubled).</p>
    </sec>
    <sec id="sec3.3">
      <label>3.3.</label>
      <title>Command line interfaces</title>
      <p>The generic CLI program <italic toggle="yes">ufo-launch</italic> comes with <italic toggle="yes">ufo-core</italic> and not <italic toggle="yes">tofu</italic>, but we will shortly describe it for completeness. A workflow can be created by connecting multiple algorithms with exclamation mark, similar to chaining commands on the Linux command line using the pipe symbol. For instance, the following command reads images from a disk, bins and flips them in the left-right fashion and writes the results to the disk:<xref rid="scheme1" ref-type="chem"/>
<chem-struct id="scheme1"><graphic xlink:href="s-29-00916-scheme1.jpg" position="float"/></chem-struct>
</p>
      <p>CLI-based sub-commands in <italic toggle="yes">tofu</italic> (see Table 2<xref rid="table2" ref-type="table"> ▸</xref>) contain predefined, parametrizable image processing flows. For instance, the following command performs flat field correction, fixes possible extreme values, computes the absorptivity and performs parallel beam tomographic reconstruction with the rotation axis in pixel 951, returning 200 slices around the vertical projection center with a spacing of 1 row:<xref rid="scheme2" ref-type="chem"/>
<chem-struct id="scheme2"><graphic xlink:href="s-29-00916-scheme2.jpg" position="float"/></chem-struct>
</p>
      <p>The following command performs phase retrieval based on the transport-of-intensity approach:<xref rid="scheme3" ref-type="chem"/>
<chem-struct id="scheme3"><graphic xlink:href="s-29-00916-scheme3.jpg" position="float"/></chem-struct>
</p>
      <p>Experienced users can write scripts of any complexity or integrate workflows into custom software by using <italic toggle="yes">ufo-launch</italic> or one of the <italic toggle="yes">tofu</italic> CLI sub-commands. Moreover, they can use <italic toggle="yes">tofu</italic> as a library and use the workflows in their Python programs.</p>
    </sec>
  </sec>
  <sec sec-type="cases" id="sec4">
    <label>4.</label>
    <title>Application showcases</title>
    <p>In the following sections we demonstrate the ability of <italic toggle="yes">tofu</italic> to reconstruct data of various geometries, X-ray setups and one from a neutron source. There will be four application showcases from various research fields with various imaging demands.</p>
    <sec id="sec4.1">
      <label>4.1.</label>
      <title>Parallel beam CT</title>
      <p>In this subsection, we demonstrate the capability of <italic toggle="yes">tofu</italic> to provide a high-quality 3D reconstruction of a parallel beam µCT data set acquired at a synchrotron facility, in this case the Biomedical Imaging beamline of the Canadian Light Source. In addition to the 3D reconstruction, the data processing workflow included phase retrieval and various artifact reduction algorithms. The sample was a metamorphic schist mineral held in collections of the University of Calgary; see Fig. 6<xref rid="fig6" ref-type="fig"> ▸</xref> for its projection and a slice with various pre-processing steps.</p>
      <p>For the data acquisition, we used monochromatic beam with energy of 45 keV, an effective pixel size of 1.6 µm × 1.6 µm was obtained with a PCO Edge 5.5 camera coupled to a 50 µm LuAG:Ce scintillator (Crytur) by means of an optical system (Optique Peter) with 4× magnification. The distance between the sample and the detector was set to 20 cm. Approximately one-fifth of the camera dynamic range was used and 2000 projections were acquired. A fragment of the projection is shown in Fig. 4<xref rid="fig4" ref-type="fig"> ▸</xref>(<italic toggle="yes">a</italic>). One can notice a very large spot in the center and multiple bright pixels all over the image. The former is a defect typical for single-crystal scintillators, the latter occurs when a camera sensor gets hit by X-rays directly.</p>
      <p>A CT slice from phase-retrieved projections without any additional processing [Fig. 6<xref rid="fig6" ref-type="fig"> ▸</xref>(<italic toggle="yes">b</italic>)] reconstructed at the detector row spoiled by the large spot exhibits a very intense ring artifact. It dominates the contrast and makes it almost impossible to interpret the image. Fig. 6<xref rid="fig6" ref-type="fig"> ▸</xref>(<italic toggle="yes">c</italic>) shows the same slice with various noise and artifacts suppression algorithms applied. Insets (<italic toggle="yes">d</italic>)–(<italic toggle="yes">g</italic>) in Fig. 6<xref rid="fig6" ref-type="fig"> ▸</xref> show a fragment of the slice in order to highlight the degree of improvement as more algorithms were applied before reconstruction (the automatic contrast adjustment feature of <italic toggle="yes">ImageJ</italic> was used to improve the visual presentation). In the final slice and its fragment shown in Figs. 6<xref rid="fig6" ref-type="fig"> ▸</xref>(<italic toggle="yes">c</italic>) and 6(<italic toggle="yes">g</italic>), all artifacts are suppressed so that an accurate segmentation of four distinct minerals composing the specimen becomes possible (the bright white being ilmenite and the darkest, almost black mineral is quartz as confirmed by electron probe microanalyser).</p>
    </sec>
    <sec id="sec4.2">
      <label>4.2.</label>
      <title>Correlative neutron and X-ray CT</title>
      <p>This subsection demonstrates the capability of <italic toggle="yes">tofu</italic> to provide 3D reconstructions of data from various probes, sources and imaging geometries. The experiment consisted of correlative dual-mode parallel-beam neutron and cone-beam X-ray tomography, conducted at the NeXT instrument (Tengattini <italic toggle="yes">et al.</italic>, 2020<xref rid="bb23" ref-type="bibr"> ▸</xref>) at the Institut Laue Langevin in Grenoble (France). It is one of the few instruments world-wide with an additional cone beam X-ray microfocus CT setup installed to allow one to use complementary (attenuation) contrast provided by the two probes. At NeXT, neutrons come from a cold source inside the reactor enclosure and are transported via a curved guide to the instrument where, at the sample position, a maximum continuous flux of ∼3 × 10<sup>8</sup> neutrons cm<sup>−2</sup> s<sup>−1</sup> is available.</p>
      <p>The sample was a lithium primary battery of type ‘CR1/3N’ which uses a LiMnO<sub>2</sub> chemistry with an MnO<sub>2</sub> cathode material. There is a genuine interest to investigate the different processes and phenomena during discharge of such batteries (and also during and after charging cycles of rechargeable batteries where aging processes are limiting their service lifetime) for different cell chemistries (Ziesche <italic toggle="yes">et al.</italic>, 2020<italic toggle="yes">a</italic>
<xref rid="bb31" ref-type="bibr"> ▸</xref>,<italic toggle="yes">b</italic>
<xref rid="bb32" ref-type="bibr"> ▸</xref>). Various slices and a rendering of the 3D volume combined from both probes is shown in Fig. 7<xref rid="fig7" ref-type="fig"> ▸</xref>.</p>
      <p>Neutron tomography and laminography are based on the same principles as their X-ray counterparts. Here, neutrons serve as a probe to provide information about the local attenuation of a specimen in projection images acquired from different viewing angles. Since the neutrons activate the specimen and surrounding materials (like sample environments, sample manipulator parts or the detector), radioactive decay occurs and produces secondary particles and X-ray and gamma quanta. When gamma radiation hits the detector (either the scintillator of an indirect detector system or its light-sensitive sensor chip), white spots may appear on the 2D projection images. After 3D reconstruction, these spots are visible as streak or ‘zinger’ artifacts stretching across the slice’s planes, similar to the case described before for hard X-ray imaging. These artifacts can be efficiently reduced in <italic toggle="yes">tofu</italic> by filtering out the high-intensity spots in the projection images.</p>
      <p>The indirect neutron detector was composed of a 10 µm-thick terbium-doped gadolinium oxysulfide (Gd<sub>2</sub>O<sub>2</sub>S:Tb) which was optically coupled (with slightly below 1:1 magnification) to a scientific CMOS camera (Hamamatsu ORCA-Flash4.0V2). Natively this camera has an array of 2048 × 2048 pixels of 6.5 µm pixel pitch which we used in 2 × 2-binning mode with an effective pixel size of 14.2 µm × 14.2 µm. We acquired 1600 neutron projections with 1 s exposure time in a scanning time well below 30 min which allows for time-resolved experiments during battery charging/discharging cycles.</p>
      <p>The sealed microfocus X-ray tube at the NeXT instrument with a tungsten target and a beryllium window (Hamamatsu L12161-07) was operated at 120 kV acceleration voltage with a target power of 9.6 W. We acquired 1600 X-ray projections with an amorphous-silicon-based flat-panel detector with CsI scintillator (Varex PaxScan 2530HE) and 139 µm pixel pitch. The distance between the source and the sample was 38 mm and the distance between sample and detector 462 mm, resulting in a 13.2× magnification and effective pixel size 10.5 µm × 10.5 µm.</p>
      <p>In Fig. 7<xref rid="fig7" ref-type="fig"> ▸</xref>, one can clearly see the complementary contrast obtained by the two probes. Neutrons are most sensitive to hydrogen and lithium (bright blue in the images), X-rays are mostly attenuated by heavier elements like copper, nickel and manganese, as well as the steel casing (bright red). A magenta cast occurs at locations where both X-ray and neutron attenuation is rather high, <italic toggle="yes">e.g.</italic> the MnO<sub>2</sub> cathode material.</p>
    </sec>
    <sec id="sec4.3">
      <label>4.3.</label>
      <title>Helical cone beam CT</title>
      <p>This example demonstrates the ability of <italic toggle="yes">tofu</italic> to reconstruct 3D data from complex geometries. In this case, helical cone beam CT was realized by simultaneous rotation of the sample and vertical translation of the X-ray source and the detector at the IPS X-ray imaging CL/CT-Laboratory. The sample was a tree branch, shown in Fig. 8<xref rid="fig8" ref-type="fig"> ▸</xref> together with a reconstructed slice and a 3D rendering. The reconstruction was made possible by the ability to specify the vertical source and detector positions projection-wise.</p>
      <p>An XWT-225 microfocus X-ray tube (X-RAY WorX) with a tungsten target, operated at an acceleration voltage of 160 kV with a target power of 75 W, was employed. The projection images were recorded with an XRD1612 flat-panel detector (PerkinElmer), featuring a physical pixel size of 200 µm × 200 µm with 2048 × 2048 pixels and a DRZ+ scintillator.</p>
      <p>The distance between the source and the sample was 700 mm and the distance between sample and detector 1000 mm, resulting in a 2.4× magnification and effective pixel size 82.35 µm × 82.35 µm. We acquired 7265 projections in total (each exposed for 1.5 s), 2048 projections and 15 cm vertical shift per 360°. Thus, the fully reconstructable field of view was horizontally 168.6 mm and vertically 429.6 mm and the volume size was 2048 × 2048 × 5217 pixels.</p>
    </sec>
    <sec id="sec4.4">
      <label>4.4.</label>
      <title>Cone beam laminography</title>
      <p>This example demonstrates the ability of <italic toggle="yes">tofu</italic> to reconstruct cone beam laminography data. The measurement took place at the IPS X-ray imaging CL/CT-Laboratory. The sample was a conventional DDR3 memory module with flip-chip solder bump bonds. A projection from the data set together with a reconstructed slice which shows defects (voids) in the flip-chip solder bumps is shown in Fig. 9<xref rid="fig9" ref-type="fig"> ▸</xref>.</p>
      <p>An XWT-225 microfocus X-ray tube (X-RAY WorX) with a tungsten target, operated at an acceleration voltage of 200 kV with a target power of 20 W, was employed. The projection images were recorded with an XRD1612 flat-panel detector (PerkinElmer), featuring a physical pixel size of 200 µm × 200 µm with 2048 × 2048 pixels and a DRZ+ scintillator.</p>
      <p>The distance between the source and the sample was 85.5 mm, and the distance between sample and detector 1629 mm, resulting in a 20× magnification and effective pixel size 10 µm × 10 µm. The axis of rotation was inclined by 20.91° with respect to the tomography case. In total 2048 projections were taken over an angular range of 360° and every projection was exposed for four seconds.</p>
    </sec>
  </sec>
  <sec id="sec5">
    <label>5.</label>
    <title>Performance</title>
    <p>With <italic toggle="yes">tofu</italic>, the overall throughput of systems with two or more GPUs can easily become limited by disk I/O performance instead of 3D reconstruction. Fig. 10<xref rid="fig10" ref-type="fig"> ▸</xref> provides the reconstruction performance for different types of geometries and systems. A performance comparison with respect to some other reconstruction software is shown in Table 3<xref rid="table3" ref-type="table"> ▸</xref>. Throughout this section, the term <italic toggle="yes">data set size</italic> defines both the input and output sizes, <italic toggle="yes">i.e.</italic> for data set size <italic toggle="yes">N</italic>, the input are <italic toggle="yes">N</italic> projections of size <italic toggle="yes">N</italic>
<sup>2</sup> and the output is a volume of size <italic toggle="yes">N</italic>
<sup>3</sup>.</p>
    <p>The aim of the first benchmark was to show how fast our filtered back projection implementation is for different input sizes and reconstruction geometries on various systems. We used parallel beam tomography, parallel beam laminography, cone beam tomography and cone beam laminography geometries and data set sizes 1024, 2048 and 4096. Reconstruction performance was measured on a notebook with an Intel i9-10885H processor, 32 GB of RAM and an NVIDIA RTX 2070 Super graphics card with 8 GB of RAM. The second system was a workstation with Intel i7-7820X processor, 32 GB of RAM and two NVIDIA RTX 4000 graphics cards, each with 8 GB RAM. The most powerful system was a server with two Intel Xeon Silver 4114 processors, 256 GB RAM and four GeForce RTX 2080 Ti graphics cards, each with 11 GB RAM. We measured the wall time of <italic toggle="yes">tofu reco</italic> from invocation to return and used the so-called dry-run mode, where no data is read or written to the disk. Only the creation of empty OpenCL buffers, filtered back projection and downloading of the reconstructed volume from graphics memory to main memory was performed. In this, as well as in the second benchmark below, no flat field correction or other pre- and post-processing steps were applied and the input and ouput data were in single-precision floating-point arithmetic. Fig. 10<xref rid="fig10" ref-type="fig"> ▸</xref> summarizes the performance results.</p>
    <p>The second benchmark is summarized in Table 3<xref rid="table3" ref-type="table"> ▸</xref> and compares the performance of <italic toggle="yes">tofu</italic>, <italic toggle="yes">ASTRA</italic> (van Aarle <italic toggle="yes">et al.</italic>, 2016<xref rid="bb1" ref-type="bibr"> ▸</xref>) and <italic toggle="yes">PyHST2</italic> (Mirone <italic toggle="yes">et al.</italic>, 2014<xref rid="bb14" ref-type="bibr"> ▸</xref>). We again measured the wall time and this time also included the disk I/O in order to provide a more realistic estimate of real-world reconstruction times. The disk was a RAID 0 built from two Samsung 860 EVO 500 GB SSDs with a final throughput of about 1.3 GB s<sup>−1</sup>. We used parallel beam tomographic geometry. All benchmarks were performed by using all four GPUs of the server described above and in all packages we used the filtered back projection algorithm. Opposed to slice-by-slice reconstruction, <italic toggle="yes">ASTRA</italic> does not support filtering in the volume-based reconstruction, so in that case we performed only the back projection part. Similar benchmarks on a small CPU-based cluster can be found in Marone <italic toggle="yes">et al.</italic> (2017<xref rid="bb13" ref-type="bibr"> ▸</xref>).</p>
    <p>Tomographic image processing can be massively parallelized and is thus extremely well suited for GPU implementation, which is true also for additional frequency filtering steps. For example, flat field correction and filtered back projection of a data set with size 2048 on the workstation mentioned above took <italic toggle="yes">tofu</italic> 143 s including reading from file and writing of results to disk. When we added phase retrieval based on the transport-of-intensity approach to the workflow, the processing took 159 s, which increased the total reconstruction time by only 11%.</p>
  </sec>
  <sec id="sec6">
    <label>6.</label>
    <title>Conclusion</title>
    <p>We presented <italic toggle="yes">tofu</italic>, a set of versatile high-level user interfaces for tomographic image processing including a command-line interface for efficient scripting and two graphical user interfaces for user-friendliness. It includes many pre- and post-processing algorithms, such as phase retrieval and ring-removal and supports parallel beam, cone beam, tomographic and laminographic geometries. Thus it can reconstruct data acquired with different types of light sources, setups and complicated geometries, as we have demonstrated by several use cases. The modularity makes this an ideal tool for method development platforms, where data processing workflows need to be easily adjustable.</p>
    <p>The image processing code can run on GPUs, therefore the package is not only user-friendly but also fast and, as the performance measurements show, users can obtain reconstructions in short times even by using ordinary, off-the-shelf hardware. The combination of a GUI and fast processing permits one to work with data in an interactive way, which is very useful for fine-tuning algorithm parameters and teaching people how to perform tomographic reconstruction. Once all parameters are optimized, multiple data sets acquired under the same experimental conditions can be sent to batch processing.</p>
    <p>The presented software has been used at KARA, CLS and ESRF synchrotrons and ILL neutron source for many years and received a lot of positive feedback from users. We believe that the variety of implemented algorithms, speed and cost-efficiency of GPU computing combined with simple graphical user interfaces will make the presented toolkit very attractive to a broad community of synchrotron and neutron users and researchers who need software for their custom-build laboratory-based microtomography systems.</p>
  </sec>
</body>
<back>
  <ack>
    <p>SG would like to acknowledge J. Stobbs, A. Webb, N. Zhu, A. Panahifar for participating in testing and their feedback; T. Bond for help with the stitching tools; R. Wagner for writing the Ansible script for the automatic deployment of the <italic toggle="yes">ufo framework</italic> and <italic toggle="yes">tofu</italic> on RHEL/CentOS7 computers; J. Forshaw, S. Escario, and B. Tutolo from University of Calgary for letting us to use one of their samples for demonstration purposes; Christian Schlepuetz from the Swiss Light Source for sharing the source code of their flat-field correction algorithm. We acknowledge the KIT light source, the Canadian Light Source (CLS) and the Institut Laue-Langevin (ILL) for provision of instruments needed for the experiments used in this paper. We would like to thank the Institute for Beam Physics and Technology (IBPT) for the operation of the storage ring, the Karlsruhe Research Accelerator (KARA). Open Access funding enabled and organized by Projekt DEAL.</p>
  </ack>
  <ref-list>
    <title>References</title>
    <ref id="bb1">
      <mixed-citation publication-type="other">Aarle, W. van, Palenstijn, W. J., Cant, J., Janssens, E., Bleichrodt, F., Dabravolski, A., De Beenhouwer, J., Joost Batenburg, K. &amp; Sijbers, J. (2016). <italic toggle="yes">Opt. Express</italic>, <bold>24</bold>, 25129–25147.</mixed-citation>
    </ref>
    <ref id="bb2">
      <mixed-citation publication-type="other">Atwood, R. C., Bodey, A. J., Price, S. W., Basham, M. &amp; Drakopoulos, M. (2015). <italic toggle="yes">Philos. Trans. R. Soc. A.</italic>
<bold>373</bold>, 20140398.</mixed-citation>
    </ref>
    <ref id="bb3">
      <mixed-citation publication-type="other">Brun, F., Massimi, L., Fratini, M., Dreossi, D., Billé, F., Accardo, A., Pugliese, R. &amp; Cedola, A. (2017). <italic toggle="yes">Adv Struct Chem Imag</italic>, <bold>3</bold>, 4.</mixed-citation>
    </ref>
    <ref id="bb4">
      <mixed-citation publication-type="other">Buades, A., Collect, B. &amp; Morel, J.-M. (2005). <italic toggle="yes">2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR’05)</italic>, 20–26 June 2005, San Diego, CA, USA, Vol. 2, pp. 60–65. IEEE.</mixed-citation>
    </ref>
    <ref id="bb5">
      <mixed-citation publication-type="other">Croton, L. C., Ruben, G., Morgan, K. S., Paganin, D. M. &amp; Kitchen, M. J. (2019). <italic toggle="yes">Opt. Express</italic>, <bold>27</bold>, 14231–14245.</mixed-citation>
    </ref>
    <ref id="bb6">
      <mixed-citation publication-type="other">Darbon, J., Cunha, A., Chan, T. F., Osher, S. &amp; Jensen, G. J. (2008). <italic toggle="yes">5th IEEE International Symposium on Biomedical Imaging: from Nano to Macro</italic>, 14–17 May 2008, Paris, France, pp. 1331–1334. IEEE.</mixed-citation>
    </ref>
    <ref id="bb7">
      <mixed-citation publication-type="other">Feldkamp, L. A., Davis, L. C. &amp; Kress, J. W. (1984). <italic toggle="yes">J. Opt. Soc. Am. A</italic>, <bold>1</bold>, 612.</mixed-citation>
    </ref>
    <ref id="bb8">
      <mixed-citation publication-type="other">Gürsoy, D., De Carlo, F., Xiao, X. &amp; Jacobsen, C. (2014). <italic toggle="yes">J. Synchrotron Rad.</italic>
<bold>21</bold>, 1188–1193.</mixed-citation>
    </ref>
    <ref id="bb9">
      <mixed-citation publication-type="other">Hashem, N., Pryor, M., Haas, D. &amp; Hunter, J. (2021). <italic toggle="yes">Appl. Sci.</italic>
<bold>11</bold>, 2858.</mixed-citation>
    </ref>
    <ref id="bb10">
      <mixed-citation publication-type="other">Helfen, L., Myagotin, A., Mikulík, P., Pernot, P., Voropaev, A., Elyyan, M., Di Michiel, M., Baruchel, J. &amp; Baumbach, T. (2011). <italic toggle="yes">Rev. Sci. Instrum.</italic>
<bold>82</bold>, 063702.</mixed-citation>
    </ref>
    <ref id="bb11">
      <mixed-citation publication-type="other">Hsieh, J., Molthen, R. C., Dawson, C. A. &amp; Johnson, R. H. (2000). <italic toggle="yes">Med. Phys.</italic>
<bold>27</bold>, 23–29.</mixed-citation>
    </ref>
    <ref id="bb12">
      <mixed-citation publication-type="other">Jailin, C., Buffière, J.-Y., Hild, F., Poncelet, M. &amp; Roux, S. (2017). <italic toggle="yes">J. Synchrotron Rad.</italic>
<bold>24</bold>, 220–231.</mixed-citation>
    </ref>
    <ref id="bb13">
      <mixed-citation publication-type="other">Marone, F., Studer, A., Billich, H., Sala, L. &amp; Stampanoni, M. (2017). <italic toggle="yes">Adv. Struct. Chem. Imag.</italic>
<bold>3</bold>, 1–11.</mixed-citation>
    </ref>
    <ref id="bb14">
      <mixed-citation publication-type="other">Mirone, A., Brun, E., Gouillart, E., Tafforeau, P. &amp; Kieffer, J. (2014). <italic toggle="yes">Nucl. Instrum. Methods Phys. Res. B</italic>, <bold>324</bold>, 41–48.</mixed-citation>
    </ref>
    <ref id="bb15">
      <mixed-citation publication-type="other">Mokso, R., Schlepütz, C. M., Theidel, G., Billich, H., Schmid, E., Celcer, T., Mikuljan, G., Sala, L., Marone, F., Schlumpf, N. &amp; Stampanoni, M. (2017). <italic toggle="yes">J. Synchrotron Rad.</italic>
<bold>24</bold>, 1250–1259.</mixed-citation>
    </ref>
    <ref id="bb16">
      <mixed-citation publication-type="other">Moosmann, J., Hofmann, R. &amp; Baumbach, T. (2011). <italic toggle="yes">Opt. Express</italic>, <bold>19</bold>, 12066–12073.</mixed-citation>
    </ref>
    <ref id="bb18">
      <mixed-citation publication-type="other">Müller, M., de Sena Oliveira, I., Allner, S., Ferstl, S., Bidola, P., Mechlem, K., Fehringer, A., Hehn, L., Dierolf, M., Achterhold, K., Gleich, B., Hammel, J. U., Jahn, H., Mayer, G. &amp; Pfeiffer, F. (2017). <italic toggle="yes">Proc. Natl Acad. Sci. USA</italic>, <bold>114</bold>, 12378–12383.</mixed-citation>
    </ref>
    <ref id="bb17">
      <mixed-citation publication-type="other">Münch, B., Trtik, P., Marone, F. &amp; Stampanoni, M. (2009). <italic toggle="yes">Opt. Express</italic>, <bold>17</bold>, 8567–8591.</mixed-citation>
    </ref>
    <ref id="bb19">
      <mixed-citation publication-type="other">Paganin, D., Mayo, S. C., Gureyev, T. E., Miller, P. R. &amp; Wilkins, S. W. (2002). <italic toggle="yes">J. Microsc.</italic>
<bold>206</bold>, 33–40.</mixed-citation>
    </ref>
    <ref id="bb20">
      <mixed-citation publication-type="other">Polyakov, S., Zholudev, S., Gasilov, S., Martyushov, Y., Denisov, V., Terentiev, S. &amp; Blank, V. (2017). <italic toggle="yes">Proc. SPIE</italic>, <bold>10243</bold>, 102430X.</mixed-citation>
    </ref>
    <ref id="bb21">
      <mixed-citation publication-type="other">Raimondi, P. (2016). <italic toggle="yes">Synchrotron Radiat. News</italic>, <bold>29</bold>(6), 8–15.</mixed-citation>
    </ref>
    <ref id="bb22">
      <mixed-citation publication-type="other">Schroer, C. G., Agapov, I., Brefeld, W., Brinkmann, R., Chae, Y.-C., Chao, H.-C., Eriksson, M., Keil, J., Nuel Gavaldà, X., Röhlsberger, R., Seeck, O. H., Sprung, M., Tischer, M., Wanzenberg, R. &amp; Weckert, E. (2018). <italic toggle="yes">J. Synchrotron Rad.</italic>
<bold>25</bold>, 1277–1290.</mixed-citation>
    </ref>
    <ref id="bb23">
      <mixed-citation publication-type="other">Tengattini, A., Lenoir, N., Andò, E., Giroud, B., Atkins, D., Beaucour, J. &amp; Viggiani, G. (2020). <italic toggle="yes">Nucl. Instrum. Methods Phys. Res. A</italic>, <bold>968</bold>, 163939.</mixed-citation>
    </ref>
    <ref id="bb24">
      <mixed-citation publication-type="other">Vagovič, P., Švéda, L., Cecilia, A., Hamann, E., Pelliccia, D., Gimenez, E., Korytár, D., Pavlov, K. M., Zápražný, Z., Zuber, M., Koenig, T., Olbinado, M., Yashiro, W., Momose, A., Fiederle, M. &amp; Baumbach, T. (2014). <italic toggle="yes">Opt. Express</italic>, <bold>22</bold>, 21508–21520.</mixed-citation>
    </ref>
    <ref id="bb25">
      <mixed-citation publication-type="other">Van Nieuwenhove, V., De Beenhouwer, J., De Carlo, F., Mancini, L., Marone, F. &amp; Sijbers, J. (2015). <italic toggle="yes">Opt. Express</italic>, <bold>23</bold>, 27975–27989.</mixed-citation>
    </ref>
    <ref id="bb26">
      <mixed-citation publication-type="other">Vlassenbroeck, J., Masschaele, B., Cnudde, V., Dierick, M., Pieters, K., Van Hoorebeke, L. &amp; Jacobs, P. (2006). <italic toggle="yes">Octopus 8: A High Performance Tomographic Reconstruction Package for X-ray Tube and Synchrotron micro-CT</italic>, pp. 167–173. John Wiley &amp; Sons, Ltd. https://onlinelibrary.wiley.com/doi/abs/10.1002/9780470612187.ch13.</mixed-citation>
    </ref>
    <ref id="bb27">
      <mixed-citation publication-type="other">Vo, N. T., Atwood, R. C. &amp; Drakopoulos, M. (2018). <italic toggle="yes">Opt. Express</italic>, <bold>26</bold>, 28396–28412.</mixed-citation>
    </ref>
    <ref id="bb28">
      <mixed-citation publication-type="other">Vogelgesang, M., Chilingaryan, S., dos Santos Rolo, T. &amp; Kopmann, A. (2012). <italic toggle="yes">2012 IEEE 14th International Conference on High Performance Computing and Communication &amp; 2012 IEEE 9th International Conference on Embedded Software and Systems</italic>, 25–27 June 2012, Liverpool, UK, pp. 824–829. IEEE.</mixed-citation>
    </ref>
    <ref id="bb29">
      <mixed-citation publication-type="other">Vogelgesang, M., Farago, T., Morgeneyer, T. F., Helfen, L., dos Santos Rolo, T., Myagotin, A. &amp; Baumbach, T. (2016). <italic toggle="yes">J. Synchrotron Rad.</italic>
<bold>23</bold>, 1254–1263.</mixed-citation>
    </ref>
    <ref id="bb30">
      <mixed-citation publication-type="other">Zabler, S., Cloetens, P., Guigay, J.-P., Baruchel, J. &amp; Schlenker, M. (2005). <italic toggle="yes">Rev. Sci. Instrum.</italic>
<bold>76</bold>, 073705.</mixed-citation>
    </ref>
    <ref id="bb31">
      <mixed-citation publication-type="other">Ziesche, R. F., Arlt, T., Finegan, D. P., Heenan, T. M. M., Tengattini, A., Baum, D., Kardjilov, N., Markötter, H., Manke, I., Kockelmann, W., Brett, D. J. L. &amp; Shearing, P. R. (2020<italic toggle="yes">a</italic>). <italic toggle="yes">Nat. Commun.</italic>
<bold>11</bold>, 777.</mixed-citation>
    </ref>
    <ref id="bb32">
      <mixed-citation publication-type="other">Ziesche, R. F., Robinson, J. B., Markötter, H., Bradbury, R., Tengattini, A., Lenoir, N., Helfen, L., Kockelmann, W., Kardjilov, N., Manke, I., Brett, D. J. L. &amp; Shearing, P. R. (2020<italic toggle="yes">b</italic>). <italic toggle="yes">J. Electrochem. Soc.</italic>
<bold>167</bold>, 140509.</mixed-citation>
    </ref>
  </ref-list>
</back>
<floats-group>
  <fig position="float" id="fig1">
    <label>Figure 1</label>
    <caption>
      <p>Reconstruction geometry. The center of origin is in the center of the reconstructed volume. Positions of the source and the detector are defined with respect to this point. Point (<inline-formula><inline-graphic xlink:href="s-29-00916-efi1.jpg"/></inline-formula>, <inline-formula><inline-graphic xlink:href="s-29-00916-efi2.jpg"/></inline-formula>) is the projection of the center of rotation on the detector plane. The detector, the rotation axis and the reconstructed volume can be arbitrarily oriented.</p>
    </caption>
    <graphic xlink:href="s-29-00916-fig1" position="float"/>
  </fig>
  <fig position="float" id="fig2">
    <label>Figure 2</label>
    <caption>
      <p>Main window of <italic toggle="yes">tofu flow</italic> showing tomographic reconstruction. Dark and flat field images are averaged and used to flat-field-correct the radiographs. The normalized images are padded in order to remove convolution outlier artifacts, Ram-Lak-filtered in the Fourier space, back projected and displayed.</p>
    </caption>
    <graphic xlink:href="s-29-00916-fig2" position="float"/>
  </fig>
  <fig position="float" id="fig3">
    <label>Figure 3</label>
    <caption>
      <p>An example of interactive parameter adjustment in <italic toggle="yes">tofu flow</italic>. The user gradually changes the center of rotation value from 2000 to 2048 by dragging a slider and the updated slice is immediately shown.</p>
    </caption>
    <graphic xlink:href="s-29-00916-fig3" position="float"/>
  </fig>
  <fig position="float" id="fig4">
    <label>Figure 4</label>
    <caption>
      <p>Main window of the <italic toggle="yes">tofu ez</italic> interface.</p>
    </caption>
    <graphic xlink:href="s-29-00916-fig4" position="float"/>
  </fig>
  <fig position="float" id="fig5">
    <label>Figure 5</label>
    <caption>
      <p>Block diagram of the <italic toggle="yes">tofu ez</italic> workflow generation. PR stands for phase retrieval; inpaint refers to an algorithm which removes large spots stemming from scintillator defects.</p>
    </caption>
    <graphic xlink:href="s-29-00916-fig5" position="float"/>
  </fig>
  <fig position="float" id="fig6">
    <label>Figure 6</label>
    <caption>
      <p>Reconstruction of parallel beam CT data with <italic toggle="yes">tofu ez</italic>. The sample is metamorphic schist (a piece of rock composed of four minerals). The top row shows from left to right fragments of: a raw CT projection (<italic toggle="yes">a</italic>) (dashed line indicating reconstructed row); of a slice reconstructed from phase-retrieved projections without the application of any artifact-reduction algorithms (<italic toggle="yes">b</italic>); of the same slice reconstructed with suppression of artifacts (<italic toggle="yes">c</italic>). Magnified fragments of images (<italic toggle="yes">b</italic>) and (<italic toggle="yes">c</italic>) are shown in insets (<italic toggle="yes">d</italic>) and (<italic toggle="yes">g</italic>), respectively. Images in the bottom row demonstrate progressive improvement when: only phase-retrieval was applied to data (<italic toggle="yes">d</italic>); phase-retrieval and broad ring removal (<italic toggle="yes">e</italic>); phase-retrieval, broad and narrow ring removal (<italic toggle="yes">f</italic>); all previous algorithms were applied and the outliers were removed from projections and flat-field images (<italic toggle="yes">g</italic>). Panels (<italic toggle="yes">a</italic>) and (<italic toggle="yes">d</italic>)–(<italic toggle="yes">g</italic>) have been inserted after automatic contrast adjustment was applied in <italic toggle="yes">ImageJ</italic> once to the entire image; no image correction of any kind was applied to panels (<italic toggle="yes">b</italic>, <italic toggle="yes">c</italic>). The scalebar for all images in a row is the same as shown in the heading image of that row.</p>
    </caption>
    <graphic xlink:href="s-29-00916-fig6" position="float"/>
  </fig>
  <fig position="float" id="fig7">
    <label>Figure 7</label>
    <caption>
      <p>Combined neutron and X-ray tomography of a primary cell with LiMnO<sub>2</sub> chemistry shown as a composite image. The blue channel depicts the linear neutron attenuation coefficient, the red channel the X-ray counterpart. Slices through the reconstructed volume along different directions are given in (<italic toggle="yes">a</italic>) and (<italic toggle="yes">b</italic>); a 3D rendering in (<italic toggle="yes">c</italic>). Cell diameter is 11.6 mm, voxel size 14.2 µm × 14.2 µm × 14.2 µm.</p>
    </caption>
    <graphic xlink:href="s-29-00916-fig7" position="float"/>
  </fig>
  <fig position="float" id="fig8">
    <label>Figure 8</label>
    <caption>
      <p>Helical cone beam tomography of a tree branch. Experimental setup (<italic toggle="yes">a</italic>); a slice through the reconstructed volume (<italic toggle="yes">b</italic>); 3D volume rendering (<italic toggle="yes">c</italic>). Total volume size was 2048 × 2048 × 5217 with voxel size 82.35 µm × 82.35 µm × 82.35 µm.</p>
    </caption>
    <graphic xlink:href="s-29-00916-fig8" position="float"/>
  </fig>
  <fig position="float" id="fig9">
    <label>Figure 9</label>
    <caption>
      <p>Flip-chip solder bump defects investigation in a DDR3 memory module by cone beam laminography. Projection image (<italic toggle="yes">a</italic>); reconstructed absorption slice (<italic toggle="yes">b</italic>) with a zoomed region showing some of the discovered defects.</p>
    </caption>
    <graphic xlink:href="s-29-00916-fig9" position="float"/>
  </fig>
  <fig position="float" id="fig10">
    <label>Figure 10</label>
    <caption>
      <p>Filtered back projection compute times required by <italic toggle="yes">tofu</italic> on different systems, data set sizes (1K = 1024, 2K = 2048, 4K = 4096) and geometries (P = parallel, C = cone, T = tomography, L = laminography). One hour mark is shown as a dashed horizontal line.</p>
    </caption>
    <graphic xlink:href="s-29-00916-fig10" position="float"/>
  </fig>
  <table-wrap position="float" id="table1">
    <label>Table 1</label>
    <caption>
      <title><italic toggle="yes">Tofu</italic> software stack</title>
    </caption>
    <table frame="hsides" rules="groups">
      <thead valign="top">
        <tr>
          <th style="border-bottom:1px solid black;" rowspan="1" colspan="1" align="left" charoff="50" valign="bottom">Component</th>
          <th style="border-bottom:1px solid black;" rowspan="1" colspan="1" align="left" charoff="50" valign="bottom">Description</th>
        </tr>
      </thead>
      <tbody valign="top">
        <tr>
          <td rowspan="1" colspan="1" align="left" valign="top">
            <italic toggle="yes">tofu</italic>
          </td>
          <td rowspan="1" colspan="1" align="left" valign="top">Python-based library of CLIs and GUIs for user-friendly creation of image processing workflows (<ext-link xlink:href="https://github.com/ufo-kit/tofu" ext-link-type="uri">https://github.com/ufo-kit/tofu</ext-link>, <ext-link xlink:href="https://tofu.readthedocs.io" ext-link-type="uri">https://tofu.readthedocs.io</ext-link>)</td>
        </tr>
        <tr>
          <td rowspan="1" colspan="1" align="left" valign="top">
            <italic toggle="yes">ufo-filters</italic>
          </td>
          <td rowspan="1" colspan="1" align="left" valign="top">Library of image processing algorithm implementations, including tomographic reconstruction (<ext-link xlink:href="https://github.com/ufo-kit/ufo-filters" ext-link-type="uri">https://github.com/ufo-kit/ufo-filters</ext-link>, <ext-link xlink:href="https://ufo-filters.readthedocs.io" ext-link-type="uri">https://ufo-filters.readthedocs.io</ext-link>)</td>
        </tr>
        <tr>
          <td rowspan="1" colspan="1" align="left" valign="top">
            <italic toggle="yes">ufo-core</italic>
          </td>
          <td rowspan="1" colspan="1" align="left" valign="top">GPU-enabled execution of image processing workflows on multi-GPU systems (<ext-link xlink:href="https://github.com/ufo-kit/ufo-core" ext-link-type="uri">https://github.com/ufo-kit/ufo-core</ext-link>, <ext-link xlink:href="https://ufo-core.readthedocs.io" ext-link-type="uri">https://ufo-core.readthedocs.io</ext-link>)</td>
        </tr>
      </tbody>
    </table>
  </table-wrap>
  <table-wrap position="float" id="table2">
    <label>Table 2</label>
    <caption>
      <title>User interfaces and their typical use cases</title>
    </caption>
    <table frame="hsides" rules="groups">
      <thead valign="top">
        <tr>
          <th style="border-bottom:1px solid black;" rowspan="1" colspan="1" align="left" charoff="50" valign="bottom">Program</th>
          <th style="border-bottom:1px solid black;" rowspan="1" colspan="1" align="left" charoff="50" valign="bottom">UI type</th>
          <th style="border-bottom:1px solid black;" rowspan="1" colspan="1" align="left" charoff="50" valign="bottom">Use case</th>
        </tr>
      </thead>
      <tbody valign="top">
        <tr>
          <td rowspan="1" colspan="1" align="left" valign="top">
            <italic toggle="yes">tofu flow</italic>
          </td>
          <td rowspan="1" colspan="1" align="left" valign="top">GUI</td>
          <td rowspan="1" colspan="1" align="left" valign="top">Visual workflow programming</td>
        </tr>
        <tr>
          <td rowspan="1" colspan="1" align="left" valign="top">
            <italic toggle="yes">tofu ez</italic>
          </td>
          <td rowspan="1" colspan="1" align="left" valign="top">GUI</td>
          <td rowspan="1" colspan="1" align="left" valign="top">Batch-processing of many tomographic data sets</td>
        </tr>
        <tr>
          <td rowspan="1" colspan="1" align="left" valign="top">
            <italic toggle="yes">tofu preprocess</italic>
          </td>
          <td rowspan="1" colspan="1" align="left" valign="top">CLI</td>
          <td rowspan="1" colspan="1" align="left" valign="top">Pre-processing workflows including phase retrieval</td>
        </tr>
        <tr>
          <td rowspan="1" colspan="1" align="left" valign="top">
            <italic toggle="yes">tofu find-large-spots</italic>
          </td>
          <td rowspan="1" colspan="1" align="left" valign="top">CLI</td>
          <td rowspan="1" colspan="1" align="left" valign="top">Finding spots of extreme intensity</td>
        </tr>
        <tr>
          <td rowspan="1" colspan="1" align="left" valign="top">
            <italic toggle="yes">tofu sinos</italic>
          </td>
          <td rowspan="1" colspan="1" align="left" valign="top">CLI</td>
          <td rowspan="1" colspan="1" align="left" valign="top">Sinogram generation</td>
        </tr>
        <tr>
          <td rowspan="1" colspan="1" align="left" valign="top">
            <italic toggle="yes">tofu tomo</italic>
          </td>
          <td rowspan="1" colspan="1" align="left" valign="top">CLI</td>
          <td rowspan="1" colspan="1" align="left" valign="top">Parallel beam tomographic reconstruction from sinograms</td>
        </tr>
        <tr>
          <td rowspan="1" colspan="1" align="left" valign="top">
            <italic toggle="yes">tofu reco</italic>
          </td>
          <td rowspan="1" colspan="1" align="left" valign="top">CLI</td>
          <td rowspan="1" colspan="1" align="left" valign="top">Cone/parallel tomographic/laminographic reconstruction from projections</td>
        </tr>
        <tr>
          <td rowspan="1" colspan="1" align="left" valign="top">
            <italic toggle="yes">ufo-launch</italic>
          </td>
          <td rowspan="1" colspan="1" align="left" valign="top">CLI</td>
          <td rowspan="1" colspan="1" align="left" valign="top">Creation of arbitrary workflows on the command line</td>
        </tr>
      </tbody>
    </table>
  </table-wrap>
  <table-wrap position="float" id="table3">
    <label>Table 3</label>
    <caption>
      <title>Reconstruction times of different software packages for different data set sizes</title>
      <p>The results are in form mean (standard deviation) computed from ten runs. Values in bold indicate the fastest package for a given data set size.</p>
    </caption>
    <table frame="hsides" rules="groups">
      <thead valign="top">
        <tr>
          <th rowspan="1" colspan="1" align="left" charoff="50" valign="bottom"> </th>
          <th style="border-bottom:1px solid black;" rowspan="1" colspan="3" align="left" charoff="50" valign="bottom">Data set size</th>
        </tr>
        <tr>
          <th style="border-bottom:1px solid black;" rowspan="1" colspan="1" align="left" charoff="50" valign="bottom">Package</th>
          <th style="border-bottom:1px solid black;" rowspan="1" colspan="1" align="left" charoff="50" valign="bottom">1024</th>
          <th style="border-bottom:1px solid black;" rowspan="1" colspan="1" align="left" charoff="50" valign="bottom">2048</th>
          <th style="border-bottom:1px solid black;" rowspan="1" colspan="1" align="left" charoff="50" valign="bottom">4096</th>
        </tr>
      </thead>
      <tbody valign="top">
        <tr>
          <td rowspan="1" colspan="1" align="left" valign="top">UFO</td>
          <td rowspan="1" colspan="1" align="left" valign="top"><bold>12</bold> (0.15) s</td>
          <td rowspan="1" colspan="1" align="left" valign="top"><bold>74</bold> (0.89) s</td>
          <td rowspan="1" colspan="1" align="left" valign="top">947 (12.84) s</td>
        </tr>
        <tr>
          <td rowspan="1" colspan="1" align="left" valign="top">PyHST</td>
          <td rowspan="1" colspan="1" align="left" valign="top">18 (0.12) s</td>
          <td rowspan="1" colspan="1" align="left" valign="top">93 (0.89) s</td>
          <td rowspan="1" colspan="1" align="left" valign="top"><bold>770</bold> (9.39) s</td>
        </tr>
        <tr>
          <td rowspan="1" colspan="1" align="left" valign="top">ASTRA</td>
          <td rowspan="1" colspan="1" align="left" valign="top">25 (1.39) s</td>
          <td rowspan="1" colspan="1" align="left" valign="top">189 (5.93) s</td>
          <td rowspan="1" colspan="1" align="left" valign="top">1777 (42.99) s</td>
        </tr>
      </tbody>
    </table>
  </table-wrap>
</floats-group>
