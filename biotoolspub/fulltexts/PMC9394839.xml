<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1d3 20150301//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 39.96?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?subarticle pone.0270696.r001?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">PLoS One</journal-id>
    <journal-id journal-id-type="iso-abbrev">PLoS One</journal-id>
    <journal-id journal-id-type="publisher-id">plos</journal-id>
    <journal-title-group>
      <journal-title>PLoS ONE</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1932-6203</issn>
    <publisher>
      <publisher-name>Public Library of Science</publisher-name>
      <publisher-loc>San Francisco, CA USA</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">9394839</article-id>
    <article-id pub-id-type="publisher-id">PONE-D-21-32222</article-id>
    <article-id pub-id-type="doi">10.1371/journal.pone.0270696</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Research Article</subject>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Computer and Information Sciences</subject>
        <subj-group>
          <subject>Artificial Intelligence</subject>
          <subj-group>
            <subject>Artificial Neural Networks</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Computational Biology</subject>
          <subj-group>
            <subject>Computational Neuroscience</subject>
            <subj-group>
              <subject>Artificial Neural Networks</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Neuroscience</subject>
          <subj-group>
            <subject>Computational Neuroscience</subject>
            <subj-group>
              <subject>Artificial Neural Networks</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Physiology</subject>
          <subj-group>
            <subject>Physiological Processes</subject>
            <subj-group>
              <subject>Sleep</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Research and Analysis Methods</subject>
        <subj-group>
          <subject>Bioassays and Physiological Analysis</subject>
          <subj-group>
            <subject>Electrophysiological Techniques</subject>
            <subj-group>
              <subject>Brain Electrophysiology</subject>
              <subj-group>
                <subject>Electroencephalography</subject>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Physiology</subject>
          <subj-group>
            <subject>Electrophysiology</subject>
            <subj-group>
              <subject>Neurophysiology</subject>
              <subj-group>
                <subject>Brain Electrophysiology</subject>
                <subj-group>
                  <subject>Electroencephalography</subject>
                </subj-group>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Neuroscience</subject>
          <subj-group>
            <subject>Neurophysiology</subject>
            <subj-group>
              <subject>Brain Electrophysiology</subject>
              <subj-group>
                <subject>Electroencephalography</subject>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Neuroscience</subject>
          <subj-group>
            <subject>Brain Mapping</subject>
            <subj-group>
              <subject>Electroencephalography</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Medicine and Health Sciences</subject>
        <subj-group>
          <subject>Clinical Medicine</subject>
          <subj-group>
            <subject>Clinical Neurophysiology</subject>
            <subj-group>
              <subject>Electroencephalography</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Research and Analysis Methods</subject>
        <subj-group>
          <subject>Imaging Techniques</subject>
          <subj-group>
            <subject>Neuroimaging</subject>
            <subj-group>
              <subject>Electroencephalography</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Neuroscience</subject>
          <subj-group>
            <subject>Neuroimaging</subject>
            <subj-group>
              <subject>Electroencephalography</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Engineering and Technology</subject>
        <subj-group>
          <subject>Signal Processing</subject>
          <subj-group>
            <subject>Signal Filtering</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Computer and Information Sciences</subject>
        <subj-group>
          <subject>Software Engineering</subject>
          <subj-group>
            <subject>Computer Software</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Engineering and Technology</subject>
        <subj-group>
          <subject>Software Engineering</subject>
          <subj-group>
            <subject>Computer Software</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Computer and Information Sciences</subject>
        <subj-group>
          <subject>Network Analysis</subject>
          <subj-group>
            <subject>Signaling Networks</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Medicine and Health Sciences</subject>
        <subj-group>
          <subject>Surgical and Invasive Medical Procedures</subject>
          <subj-group>
            <subject>Functional Electrical Stimulation</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Computer and Information Sciences</subject>
        <subj-group>
          <subject>Computer Architecture</subject>
          <subj-group>
            <subject>Computer Hardware</subject>
          </subj-group>
        </subj-group>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>The Portiloop: A deep learning-based open science tool for closed-loop brain stimulation</article-title>
      <alt-title alt-title-type="running-head">The Portiloop</alt-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-4439-3398</contrib-id>
        <name>
          <surname>Valenchon</surname>
          <given-names>Nicolas</given-names>
        </name>
        <role content-type="http://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role>
        <role content-type="http://credit.niso.org/contributor-roles/data-curation/">Data curation</role>
        <role content-type="http://credit.niso.org/contributor-roles/formal-analysis/">Formal analysis</role>
        <role content-type="http://credit.niso.org/contributor-roles/investigation/">Investigation</role>
        <role content-type="http://credit.niso.org/contributor-roles/methodology/">Methodology</role>
        <role content-type="http://credit.niso.org/contributor-roles/software/">Software</role>
        <role content-type="http://credit.niso.org/contributor-roles/validation/">Validation</role>
        <role content-type="http://credit.niso.org/contributor-roles/visualization/">Visualization</role>
        <role content-type="http://credit.niso.org/contributor-roles/writing-original-draft/">Writing – original draft</role>
        <role content-type="http://credit.niso.org/contributor-roles/writing-review-editing/">Writing – review &amp; editing</role>
        <xref rid="aff001" ref-type="aff">
          <sup>1</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-1390-6392</contrib-id>
        <name>
          <surname>Bouteiller</surname>
          <given-names>Yann</given-names>
        </name>
        <role content-type="http://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role>
        <role content-type="http://credit.niso.org/contributor-roles/data-curation/">Data curation</role>
        <role content-type="http://credit.niso.org/contributor-roles/formal-analysis/">Formal analysis</role>
        <role content-type="http://credit.niso.org/contributor-roles/investigation/">Investigation</role>
        <role content-type="http://credit.niso.org/contributor-roles/methodology/">Methodology</role>
        <role content-type="http://credit.niso.org/contributor-roles/software/">Software</role>
        <role content-type="http://credit.niso.org/contributor-roles/validation/">Validation</role>
        <role content-type="http://credit.niso.org/contributor-roles/visualization/">Visualization</role>
        <role content-type="http://credit.niso.org/contributor-roles/writing-original-draft/">Writing – original draft</role>
        <role content-type="http://credit.niso.org/contributor-roles/writing-review-editing/">Writing – review &amp; editing</role>
        <xref rid="aff001" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="cor001" ref-type="corresp">*</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Jourde</surname>
          <given-names>Hugo R.</given-names>
        </name>
        <role content-type="http://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role>
        <role content-type="http://credit.niso.org/contributor-roles/writing-original-draft/">Writing – original draft</role>
        <role content-type="http://credit.niso.org/contributor-roles/writing-review-editing/">Writing – review &amp; editing</role>
        <xref rid="aff002" ref-type="aff">
          <sup>2</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-5919-5397</contrib-id>
        <name>
          <surname>L’Heureux</surname>
          <given-names>Xavier</given-names>
        </name>
        <role content-type="http://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role>
        <role content-type="http://credit.niso.org/contributor-roles/methodology/">Methodology</role>
        <role content-type="http://credit.niso.org/contributor-roles/validation/">Validation</role>
        <xref rid="aff001" ref-type="aff">
          <sup>1</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-7213-5970</contrib-id>
        <name>
          <surname>Sobral</surname>
          <given-names>Milo</given-names>
        </name>
        <role content-type="http://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role>
        <role content-type="http://credit.niso.org/contributor-roles/methodology/">Methodology</role>
        <role content-type="http://credit.niso.org/contributor-roles/software/">Software</role>
        <role content-type="http://credit.niso.org/contributor-roles/validation/">Validation</role>
        <xref rid="aff001" ref-type="aff">
          <sup>1</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Coffey</surname>
          <given-names>Emily B. J.</given-names>
        </name>
        <role content-type="http://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role>
        <role content-type="http://credit.niso.org/contributor-roles/funding-acquisition/">Funding acquisition</role>
        <role content-type="http://credit.niso.org/contributor-roles/project-administration/">Project administration</role>
        <role content-type="http://credit.niso.org/contributor-roles/resources/">Resources</role>
        <role content-type="http://credit.niso.org/contributor-roles/supervision/">Supervision</role>
        <role content-type="http://credit.niso.org/contributor-roles/validation/">Validation</role>
        <role content-type="http://credit.niso.org/contributor-roles/writing-original-draft/">Writing – original draft</role>
        <role content-type="http://credit.niso.org/contributor-roles/writing-review-editing/">Writing – review &amp; editing</role>
        <xref rid="aff002" ref-type="aff">
          <sup>2</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Beltrame</surname>
          <given-names>Giovanni</given-names>
        </name>
        <role content-type="http://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role>
        <role content-type="http://credit.niso.org/contributor-roles/funding-acquisition/">Funding acquisition</role>
        <role content-type="http://credit.niso.org/contributor-roles/project-administration/">Project administration</role>
        <role content-type="http://credit.niso.org/contributor-roles/resources/">Resources</role>
        <role content-type="http://credit.niso.org/contributor-roles/supervision/">Supervision</role>
        <role content-type="http://credit.niso.org/contributor-roles/validation/">Validation</role>
        <role content-type="http://credit.niso.org/contributor-roles/writing-original-draft/">Writing – original draft</role>
        <role content-type="http://credit.niso.org/contributor-roles/writing-review-editing/">Writing – review &amp; editing</role>
        <xref rid="aff001" ref-type="aff">
          <sup>1</sup>
        </xref>
      </contrib>
    </contrib-group>
    <aff id="aff001">
      <label>1</label>
      <addr-line>MISTLab—Polytechnique, University of Montreal, Montreal, Quebec, Canada</addr-line>
    </aff>
    <aff id="aff002">
      <label>2</label>
      <addr-line>CL:ASP, Concordia University, Montreal, Quebec, Canada</addr-line>
    </aff>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Cymbalyuk</surname>
          <given-names>Gennady S.</given-names>
        </name>
        <role>Editor</role>
        <xref rid="edit1" ref-type="aff"/>
      </contrib>
    </contrib-group>
    <aff id="edit1">
      <addr-line>Georgia State University, UNITED STATES</addr-line>
    </aff>
    <author-notes>
      <fn fn-type="COI-statement" id="coi001">
        <p><bold>Competing Interests: </bold>The authors have declared that no competing interests exist.</p>
      </fn>
      <corresp id="cor001">* E-mail: <email>yann.bouteiller@polymtl.ca</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="epub">
      <day>22</day>
      <month>8</month>
      <year>2022</year>
    </pub-date>
    <volume>17</volume>
    <issue>8</issue>
    <elocation-id>e0270696</elocation-id>
    <history>
      <date date-type="received">
        <day>6</day>
        <month>10</month>
        <year>2021</year>
      </date>
      <date date-type="accepted">
        <day>15</day>
        <month>6</month>
        <year>2022</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© 2022 Valenchon et al</copyright-statement>
      <copyright-year>2022</copyright-year>
      <copyright-holder>Valenchon et al</copyright-holder>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
      </license>
    </permissions>
    <self-uri content-type="pdf" xlink:href="pone.0270696.pdf"/>
    <abstract>
      <p>Closed-loop brain stimulation refers to capturing neurophysiological measures such as electroencephalography (EEG), quickly identifying neural events of interest, and producing auditory, magnetic or electrical stimulation so as to interact with brain processes precisely. It is a promising new method for fundamental neuroscience and perhaps for clinical applications such as restoring degraded memory function; however, existing tools are expensive, cumbersome, and offer limited experimental flexibility. In this article, we propose the Portiloop, a deep learning-based, portable and low-cost closed-loop stimulation system able to target specific brain oscillations. We first document open-hardware implementations that can be constructed from commercially available components. We also provide a fast, lightweight neural network model and an exploration algorithm that automatically optimizes the model hyperparameters to the desired brain oscillation. Finally, we validate the technology on a challenging test case of real-time sleep spindle detection, with results comparable to off-line expert performance on the Massive Online Data Annotation spindle dataset (MODA; group consensus). Software and plans are available to the community as an open science initiative to encourage further development and advance closed-loop neuroscience research [<ext-link xlink:href="https://github.com/Portiloop" ext-link-type="uri">https://github.com/Portiloop</ext-link>].</p>
    </abstract>
    <funding-group>
      <award-group id="award001">
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/100008240</institution-id>
            <institution>Fonds de Recherche du Québec-Société et Culture</institution>
          </institution-wrap>
        </funding-source>
        <award-id>279561</award-id>
        <principal-award-recipient>
          <name>
            <surname>Beltrame</surname>
            <given-names>Giovanni</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
      <award-group id="award002">
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/100008240</institution-id>
            <institution>Fonds de Recherche du Québec-Société et Culture</institution>
          </institution-wrap>
        </funding-source>
        <award-id>279561</award-id>
        <principal-award-recipient>
          <name>
            <surname>Coffey</surname>
            <given-names>Emily B. J.</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
      <funding-statement>This work was supported by the AUDACE grant, awarded to G.B and E.C. by the Quebec Research Fund (FRQSC 279561 - <ext-link xlink:href="https://frq.gouv.qc.ca" ext-link-type="uri">https://frq.gouv.qc.ca</ext-link>) and approved by Polytechnique Montreal (CER-2021-39-R - <ext-link xlink:href="https://www.polymtl.ca" ext-link-type="uri">https://www.polymtl.ca</ext-link>). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
    </funding-group>
    <counts>
      <fig-count count="6"/>
      <table-count count="2"/>
      <page-count count="20"/>
    </counts>
    <custom-meta-group>
      <custom-meta id="data-availability">
        <meta-name>Data Availability</meta-name>
        <meta-value>The data underlying the results presented in this study are available from our GitHub along with our code and hardware plans: <ext-link xlink:href="https://github.com/Portiloop" ext-link-type="uri">https://github.com/Portiloop</ext-link>.</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
  <notes>
    <title>Data Availability</title>
    <p>The data underlying the results presented in this study are available from our GitHub along with our code and hardware plans: <ext-link xlink:href="https://github.com/Portiloop" ext-link-type="uri">https://github.com/Portiloop</ext-link>.</p>
  </notes>
</front>
<body>
  <sec sec-type="intro" id="sec001">
    <title>1 Introduction</title>
    <p>Electrical activity within the brain forms the basis of perception, thought and behaviour. This activity tends to be oscillatory in nature, as reciprocal connections within and between brain regions form functional circuits for processing and communicating information. Changes in electrical fields caused by synchronously firing populations of neurons can be measured on the scalp using a technique known as electroencephalography (EEG). Correlational studies have been performed for nearly a century that attempt to link specific patterns and frequency bands in EEG to cognitive functions or brain states. These approaches are informative for many types of research questions and have increased our understanding of brain processes, but they are unable to establish causal relationships. The ability to interact with brain oscillations in a precisely-timed fashion to enhance or inhibit endogenous processes—using sensory [<xref rid="pone.0270696.ref001" ref-type="bibr">1</xref>–<xref rid="pone.0270696.ref004" ref-type="bibr">4</xref>], electrical [<xref rid="pone.0270696.ref005" ref-type="bibr">5</xref>] or magnetic [<xref rid="pone.0270696.ref006" ref-type="bibr">6</xref>] stimulation—allows for their functional roles to be determined [<xref rid="pone.0270696.ref007" ref-type="bibr">7</xref>], and potentially for restoration of processes deteriorated by aging or pathology [<xref rid="pone.0270696.ref008" ref-type="bibr">8</xref>]. These so-called <italic toggle="yes">closed-loop</italic> stimulation approaches thus hold great promise for neuroscience.</p>
    <p>One of the closed-loop research areas that has progressed the fastest using non-invasive neurophysiological recordings (i.e., EEG) and brain stimulation techniques is studying memory consolidation processes in sleep [<xref rid="pone.0270696.ref001" ref-type="bibr">1</xref>, <xref rid="pone.0270696.ref009" ref-type="bibr">9</xref>–<xref rid="pone.0270696.ref011" ref-type="bibr">11</xref>]. A first target has been slow oscillations (SOs: 0.5—1.5 Hz), which are high amplitude waves that appear in non-rapid eye movement (NREM) sleep and are known to be involved in memory consolidation (i.e., the process by which recent learned experiences are transformed into long-term memory) [<xref rid="pone.0270696.ref001" ref-type="bibr">1</xref>]. Using auditory stimulation to SO up-states, when neural tissue is partly depolarized and more excitable, Ngo <italic toggle="yes">et al</italic>. enhanced the amplitude of SOs and reported an overnight improvement in memory performance, a result that has now been replicated multiple times (see [<xref rid="pone.0270696.ref012" ref-type="bibr">12</xref>–<xref rid="pone.0270696.ref014" ref-type="bibr">14</xref>] for reviews). Closed-loop stimulation has also been used in the context of preventing drowsiness [<xref rid="pone.0270696.ref002" ref-type="bibr">2</xref>], enhancing attention and engagement [<xref rid="pone.0270696.ref004" ref-type="bibr">4</xref>], and reducing central nervous system damage after strokes [<xref rid="pone.0270696.ref003" ref-type="bibr">3</xref>]. There is great potential for these closed-loop stimulation techniques in fundamental neuroscience, and potentially, for clinical applications [<xref rid="pone.0270696.ref007" ref-type="bibr">7</xref>, <xref rid="pone.0270696.ref015" ref-type="bibr">15</xref>]. However, progress is hampered by the limited portability and flexibility of available systems, as well as by their expense and by the complexity of their use.</p>
    <p>The goal of our interdisciplinary collaboration between neuroscientists, data scientists and computer engineers is to design, explore, and document the properties of a new, complete closed-loop stimulation system (i.e., hardware and software), which we call the <italic toggle="yes">Portiloop</italic>. The Portiloop is a deep learning-based, portable, battery-efficient and low-cost device that will enable the neuroscience community to collect and process EEG data in real-time, detect patterns of interest for fundamental research questions, and respond at low latency with precisely-timed stimulation. We aim to accelerate fundamental research on closed-loop stimulation in neuroscience by designing a highly functional device and offering the code and plans freely to developers and scientists in the research community.</p>
    <p>The scope of this work encompasses both neuroscience and engineering aspects, which may be of interest to audiences for different purposes. First, we describe some general background concerning the use of closed-loop stimulation in neuroscience and its potential, describe limitations in existing tools, and introduce sleep spindles, a fast neural event that is observable in EEG, as a challenging test case. Next, we discuss the real-time and portability design constraints and the (hardware) architecture of our Portiloop implementation, which is sufficiently powerful to allow us to run a neural network-based EEG detection algorithm. The hardware is not commercially available in assembled state, but it or a similar device may be constructed by readers with appropriate technical training (plans and additional information are freely available [<ext-link xlink:href="https://github.com/Portiloop" ext-link-type="uri">https://github.com/Portiloop</ext-link>]). Third, we describe a lightweight neural network architecture that can run on inexpensive, modest hardware systems such as that which we have proposed, and which can detect and react to physiological signals in real time. Most importantly, we detail our design methodology and optimization algorithm, so that the architecture can be adapted to other neural events (e.g., theta or beta-band oscillations) or types of signal (e.g., functional near-infrared spectroscopy). This latter section and associated <xref rid="pone.0270696.s001" ref-type="supplementary-material">S1 File</xref> will be of most interest to readers with a data science background who may wish to implement, use or modify the detection algorithm (all code is available). We then present data from our case study EEG event, showing that the Portiloop implementation can effectively detect sleep spindles in real time, and we describe the performance with respect to detection threshold and time delay. The latter sections may be most interesting for research users to understand the performance of the system and select appropriate parameters for its use detecting and stimulating brain oscillations. Finally, we discuss next steps and future prospects for this technology.</p>
    <p>The Portiloop is the first open-science device that is capable of closed-loop brain stimulation. Its most noteworthy contributions include:
<list list-type="bullet"><list-item><p>Two open-hardware implementations that can be constructed from commercially available components (one using the Xilinx Pynq FPGA together with the HackEEG board and one using a custom board and a Google Coral System-on-Module neural accelerator)</p></list-item><list-item><p>A fast implementation of a recurrent neural network model that can be run on inexpensive hardware to detect events in physiological signals in real time</p></list-item><list-item><p>A design-space exploration algorithm that automatically optimizes the model hyperparameters to the neural event to be detected</p></list-item><list-item><p>A real-time spindle detector with accuracy comparable to offline analysis by experts</p></list-item></list></p>
    <p>We hope that the Portiloop will increase research on closed-loop stimulation, and continue to evolve and develop as a community-supported tool.</p>
  </sec>
  <sec id="sec002">
    <title>2 General background</title>
    <sec id="sec003">
      <title>2.1 Limitations of current systems and design objectives</title>
      <p>Speed, expense, flexibility, and portability are important considerations for designing a highly functional research-focused closed-loop system. The brain’s endogenous oscillations range from about 0.1 to 150 Hz. Depending on the application and the neural event of interest, real-time constraints can vary from a few ms [<xref rid="pone.0270696.ref016" ref-type="bibr">16</xref>] to seconds [<xref rid="pone.0270696.ref004" ref-type="bibr">4</xref>]. Currently available commercial systems that are capable of slow oscillation closed-loop stimulation have difficulty accurately and precisely detecting and stimulating faster, higher frequency neural events. Devices that are fast enough and flexible enough for research purposes tend to be derived from high-end systems used for real-time computing in other applications, e.g., in aerospace and automotive industry [<xref rid="pone.0270696.ref001" ref-type="bibr">1</xref>], and are large and expensive.</p>
      <p>Various portable devices have been developed to acquire and process EEG signals. In McCrimmon et al. [<xref rid="pone.0270696.ref017" ref-type="bibr">17</xref>], the authors developed a low-cost device limited to acquisition. Other portable devices enable closed-loop stimulation [<xref rid="pone.0270696.ref002" ref-type="bibr">2</xref>–<xref rid="pone.0270696.ref004" ref-type="bibr">4</xref>], some also based on low-cost hardware [<xref rid="pone.0270696.ref009" ref-type="bibr">9</xref>], but work with simple heuristics and are generally not sufficiently powerful for complex signal detection algorithms such as those based on deep learning. Our goal is to design a closed-loop system that runs on inexpensive, portable hardware, yet is still sufficiently fast, powerful, and flexible for cutting-edge research. Another element of experimental flexibility that we incorporate into the design is the capability to change the input and output signals. Thus, although our current focus is EEG and auditory stimulation, an EEG trace could be exchanged for another physiological signal like that derived from functional near infrared spectroscopy, and detection output could be used to stimulate the brain more forcefully using transcranial electrical or magnetic stimulation. By designing the system flexibly such that it can be extended to detect and stimulate a variety of brain oscillations, we can greatly expand its application, for example to theta-band oscillations that are associated with working memory capacity and task performance [<xref rid="pone.0270696.ref018" ref-type="bibr">18</xref>], or sleep spindles. The Portiloop is designed to be the first system to provide a portable, real-time and deep learning-capable solution for multiple fundamental research applications.</p>
    </sec>
    <sec id="sec004">
      <title>2.2 Sleep spindles as a challenging test case</title>
      <p>Slow oscillations, which have been the main target for closed-loop auditory stimulation (CLAS) to date, are thought to work in concert with other faster oscillations, called <italic toggle="yes">sleep spindles</italic>, to reactivate recently learned memories and transfer them to long-term memory [<xref rid="pone.0270696.ref019" ref-type="bibr">19</xref>, <xref rid="pone.0270696.ref020" ref-type="bibr">20</xref>]. Sleep spindles are transient oscillations observed in both lighter and deeper non-rapid eye movement (NREM) sleep (<italic toggle="yes">i</italic>.<italic toggle="yes">e</italic>., sleep stages 2 and 3). Their role in memory consolidation is supported by increases in spindle density following learning (<italic toggle="yes">e</italic>.<italic toggle="yes">g</italic>., [<xref rid="pone.0270696.ref021" ref-type="bibr">21</xref>]), and the observation that age-related changes in sleep spindles are correlated with differences in overnight performance gains (<italic toggle="yes">e</italic>.<italic toggle="yes">g</italic>., [<xref rid="pone.0270696.ref022" ref-type="bibr">22</xref>, <xref rid="pone.0270696.ref023" ref-type="bibr">23</xref>]; see [<xref rid="pone.0270696.ref024" ref-type="bibr">24</xref>] for a review of spindle mechanisms and functions).</p>
      <p>If it were possible to influence spindles with sound, as it is to enhance slow oscillations, researchers could explore their functional role in healthy adults as well as characterize their involvement in cognitive aging, and even perhaps restore degraded function. Particular challenges of spindle stimulation are that each oscillatory cycle is only ∼60 ms long and the entire spindle is between 0.5 and 2.5 s, leaving little time for traditional window-based frequency analysis; there is considerable variability between the frequency, amplitude, and duration of individuals’ spindles, particularly in older populations [<xref rid="pone.0270696.ref025" ref-type="bibr">25</xref>, <xref rid="pone.0270696.ref026" ref-type="bibr">26</xref>]; and even for offline detection of spindles (which is an easier task than detecting spindles online, as the entire spindle is available and can be used in detection), agreement on spindle identification between experts themselves is limited (∼70%) [<xref rid="pone.0270696.ref027" ref-type="bibr">27</xref>, <xref rid="pone.0270696.ref028" ref-type="bibr">28</xref>]. Real-time detection of spindles is therefore a challenging test case for the Portiloop, and a working online spindle detector would be of direct interest as a research tool.</p>
    </sec>
    <sec id="sec005">
      <title>2.3 Offline sleep spindle detection for labeling and performance comparison</title>
      <p>Machine learning-based detection algorithms are powerful means of detecting subtle signals in physiological data such as EEG, but they require large sets of accurately labeled data for training and testing the algorithm’s performance. Once trained, the success of an algorithm on classifying previously unseen data can be quantified using the f1-score, which is a widely used metric to quantify an average of recall (i.e., success in detecting events) and precision (i.e., the proportion of detected events that are correct), see <xref rid="pone.0270696.s001" ref-type="supplementary-material">S1 File</xref> for equations. The consistent detection and labeling of sleep spindles is a challenging task, due to variability in their appearance and strength. Traditionally, spindles have been visually identified by multiple experts, with f1-scores computed for each scorer with respect to spindles identified by the consensus. One commonly used dataset for creating and testing spindle detection algorithms [<xref rid="pone.0270696.ref029" ref-type="bibr">29</xref>, <xref rid="pone.0270696.ref030" ref-type="bibr">30</xref>] is the Montreal Archive of Sleep Studies (MASS) [<xref rid="pone.0270696.ref031" ref-type="bibr">31</xref>], in which the sleep spindle annotations were provided by two experts. Projects using MASS for training usually take spindles identified by either expert (i.e., a logical “OR” operation). However, the MASS annotations have a low inter-rater agreement (f1-score = 0.54 [<xref rid="pone.0270696.ref028" ref-type="bibr">28</xref>]), which makes this procedure statistically naive. The Massive Online Data Annotation (MODA) [<xref rid="pone.0270696.ref028" ref-type="bibr">28</xref>] project addressed this issue by having 5 experts (on average) annotate spindles on a subset of data from MASS, and rate their confidence, in each EEG segment. The experts had an inter-rater f1-score of 0.72 with respect to the final MODA labels. This score is considerably better than the MASS equivalent, and the number of experts, the scoring and the post-processing steps enable final labels of much higher precision. We therefore adopt MODA as a basis for performance measurement, bearing in mind that even MODA does not provide a true answer about whether a spindle has occurred or not; only some degree of consensus.</p>
      <p>Several offline sleep spindle detectors have been developed and tested on MODA [<xref rid="pone.0270696.ref027" ref-type="bibr">27</xref>, <xref rid="pone.0270696.ref032" ref-type="bibr">32</xref>–<xref rid="pone.0270696.ref037" ref-type="bibr">37</xref>]. However, these generally use heuristics that compute Fourier transforms or wavelet decomposition on large portions of the signal. For real-time detection in online applications, spindles must be detected soon after their onset, if stimulation is to arrive before the spindle ends and thus be capable of influencing its evolution. Online real-time detectors therefore cannot take the same approaches that have been successful for offline detection.</p>
    </sec>
    <sec id="sec006">
      <title>2.4 Considerations for online sleep spindle detection</title>
      <p>Online detectors (<italic toggle="yes">i</italic>.<italic toggle="yes">e</italic>., detectors that act during signal acquisition) face more challenging conditions than offline detectors, due to the unavailability of “future” data points. For example, if we aim to detect and stimulate a spindle before it ends, the duration of the spindle is not yet known by definition, yet it is one of the identifying criteria for spindles commonly used by experts. Some existing heuristics filter the signal, compute power features and rely on thresholds to perform detection; however, these approaches yield relatively poor f1-scores [<xref rid="pone.0270696.ref009" ref-type="bibr">9</xref>].</p>
      <p>Deep learning can also be leveraged to perform online sleep spindle detection. This is done by first training an artificial neural network offline through supervised learning to detect sleep spindles, and then feeding the incoming signal to the trained detector. Several such models have been trained in previous work [<xref rid="pone.0270696.ref029" ref-type="bibr">29</xref>, <xref rid="pone.0270696.ref030" ref-type="bibr">30</xref>, <xref rid="pone.0270696.ref038" ref-type="bibr">38</xref>, <xref rid="pone.0270696.ref039" ref-type="bibr">39</xref>]. However, these works do not consider hardware constraints that are central for our purpose: they use large models that are often unable to run in real time even on high-end GPUs, which makes them inapplicable in embedded systems. Moreover, they are usually trained and tested on MASS [<xref rid="pone.0270696.ref031" ref-type="bibr">31</xref>] with an “OR” operation performed on the two experts’ labels, which as discussed above is not a highly precise target [<xref rid="pone.0270696.ref028" ref-type="bibr">28</xref>].</p>
      <p>In this work, we design a Pareto-optimal neural architecture that performs best on the MODA dataset [<xref rid="pone.0270696.ref028" ref-type="bibr">28</xref>] while satisfying our hardware and timing constraints. We validate our architecture against the state-of-the-art SpindleNet [<xref rid="pone.0270696.ref029" ref-type="bibr">29</xref>], initially used with the MASS dataset. When both architectures are trained and tested on MODA, ours vastly outperforms the baseline, on top of running in real time on embedded hardware.</p>
    </sec>
  </sec>
  <sec id="sec007">
    <title>3 The Portiloop system</title>
    <p>A high-level description of the Portiloop system is provided in <xref rid="pone.0270696.g001" ref-type="fig">Fig 1(a)</xref>, while a more detailed implementation scheme can be found in <xref rid="pone.0270696.g001" ref-type="fig">Fig 1(b)</xref>. Fundamentally, it is made of an EEG frontend connected to an embedded computer which reads the EEG signals, filters them, feeds the filtered signal to an Artificial Neural Network (ANN) trained to detect specific signals, and generates a stimulus when a target pattern is detected.</p>
    <p>We propose two implementations of the Portiloop that can be replicated by readers with the appropriate technical background:
<list list-type="bullet"><list-item><p>A version that can be fully built using off-the-shelf components based on a Xilinx Pynq FPGA board and an 8-channel HackEEG frontend (<xref rid="pone.0270696.g001" ref-type="fig">Fig 1(c)</xref>)</p></list-item><list-item><p>A custom printed circuit board (PCB) featuring an EEG frontend and a Google Coral neural accelerator (<xref rid="pone.0270696.g001" ref-type="fig">Fig 1(d)</xref>)</p></list-item></list></p>
    <p>The detailed hardware implementation is out of the scope of this paper, but readers can find all instructions and plans in our open-source repository.</p>
    <fig position="float" id="pone.0270696.g001">
      <object-id pub-id-type="doi">10.1371/journal.pone.0270696.g001</object-id>
      <label>Fig 1</label>
      <caption>
        <title>Portiloop implementation.</title>
        <p>(a) High-level view of the system: captured EEG data is first filtered and fed into a neural network. If a neural event is detected with sufficient confidence (&gt;threshold), a decision is made to initiate brain stimulation. The types of delays introduced by each component are denoted in parenthesis: C/V denote Constant/Variable delays, and H/S denote Hardware/Software delays. (b) A detailed implementation scheme, and two possible implementations: (c) an FPGA prototype based on off-the-shelf components, and (d) a Coral-based implementation that uses a custom printed circuit board. Plans are available on our GitHub page.</p>
      </caption>
      <graphic xlink:href="pone.0270696.g001" position="float"/>
    </fig>
    <p>Since closed-loop stimulation requires very precise timing, the Portiloop needs to detect target pattern as quickly as possible, and minimize the delay of the output stimulus. We identify two different sources of delay in the proposed system, <italic toggle="yes">hardware</italic> and <italic toggle="yes">software</italic> delays. By <italic toggle="yes">hardware delays</italic> we refer to the time it takes to retrieve the signal from the electrodes, convert it to digital, filter it, process it through the ANN, and send the resulting feedback stimulation to the subject. By <italic toggle="yes">software delays</italic> we refer to time required for our system to collect enough data to perform its functions. As an example, although the hardware operations performed by signal filters are near-instantaneous, filtering requires that a certain amount of data be collected before outputting a filtered value, introducing a constant software delay in the output signal. This delay is a trade-off related to the order of the filter. The higher the order of a filter, the more efficient it is at removing undesirable frequencies, but also the longer the software delay introduced in the signal by the filtering operation. Similarly, an ANN may need to “see” a certain portion of a signal to recognize it, introducing a (generally variable) delay on the output of the classifier. An example of such delay is illustrated in <xref rid="pone.0270696.g002" ref-type="fig">Fig 2</xref>, where the trained ANN that we latter describe in Section 6 takes a variable amount of time before correctly detecting a transient pattern in EEG signal. These hardware and software delays sum to a total delay that is the response time of the Portiloop system. They depend on the target signal and put limits on the timing constraints of the application.</p>
    <fig position="float" id="pone.0270696.g002">
      <object-id pub-id-type="doi">10.1371/journal.pone.0270696.g002</object-id>
      <label>Fig 2</label>
      <caption>
        <title>Real-time stimulation example of the Portiloop on sleep spindles.</title>
        <p>The output of the ANN (likelihood between 0 and 1, magenta) is displayed in the lower part of the Figure. When it crosses an adjustable detection threshold (horizontal grey line, here set to 0.84), the Portiloop sends a stimulus (vertical grey line). The optimal target for this stimulus is the beginning of the sleep spindle (vertical cyan line). Thus, the variable software delay is visible here between the vertical cyan and grey lines. The sections of the signal in red mark are sections wrongly detected as spindles (false positives), and the areas in black those that are not, or not yet, detected as spindles but were identified as spindles by experts (false negatives).</p>
      </caption>
      <graphic xlink:href="pone.0270696.g002" position="float"/>
    </fig>
    <p>The Portiloop GitHub includes a software for recording and visualizing the EEG signal on the device, as well as Python programming interface for the development of extensions or new applications. The Portiloop can be accessed via WiFi. A web-based Graphical User Interface (GUI) allows to configure the EEG channels, set up detection and stimulation, visualize the signals in real-time, record EEG, set up custom filters, and more. The recording can be saved either in the internal memory (32GB) or an SD card in EDF format, or streamed through the network using the Lab Streaming Layer (LSL) [<ext-link xlink:href="https://github.com/sccn/labstreaminglayer" ext-link-type="uri">https://github.com/sccn/labstreaminglayer</ext-link>], which timestamps the data stream with microsecond accuracy.</p>
  </sec>
  <sec id="sec008">
    <title>4 Neural network implementation</title>
    <p>The Portiloop is primarily designed for EEG signals, i.e. time-series of data containing oscillatory and transitory elements. In the realm of deep learning, a natural way of processing such data is to use either 1D convolutions, recurrent units, or a combination of both. The type of ANN architecture that we recommend is inspired by SpindleNet [<xref rid="pone.0270696.ref029" ref-type="bibr">29</xref>]. In essence, a sliding window over a few last data points is fed to a Convolutional Neural Network (CNN) whose purpose is to extract relevant features (<italic toggle="yes">e</italic>.<italic toggle="yes">g</italic>., frequencies) in this signal fragment. Then, these extracted features are fed to a Recurrent Neural Network (RNN) whose purpose is to keep track of the features extracted in past forward passes (where a “forward pass” is the action of computing an output from the ANN). Note that another family of architectures, called Transformers [<xref rid="pone.0270696.ref040" ref-type="bibr">40</xref>], is known for exhibiting good results with this type of data when infinite compute is available for inference. However, Transformers are memory-less and not suitable for lightweight real-time applications, because they need to process the whole signal at each forward pass. Conversely, RNNs are able to process one single data point at each forward pass and keep track of the past in memory, which makes them more applicable for the Portiloop.</p>
    <p>The Portiloop has a limited amount of available memory, so as to ensure its portability and low price. Therefore, large ANN architectures such as SpindleNet [<xref rid="pone.0270696.ref029" ref-type="bibr">29</xref>] are orders of magnitude too large to be implemented in our device. To produce networks that are suitable to our device, we rely on an automated optimization algorithm named “Parallel Model-Based Optimization” (PMBO) that allows us to trade-off accuracy and use of resources on our device (see <xref rid="pone.0270696.s001" ref-type="supplementary-material">S1 File</xref> for details).</p>
    <p>In addition, given the Portiloop’s design constraints, we sought a lightweight means of allowing our resource-restricted network to use as much signal history as possible (as do larger neural networks). Time dilation [<xref rid="pone.0270696.ref041" ref-type="bibr">41</xref>] is a technique that enables recurrent units such as Gated Recurrent Units (GRUs) to look further back in time before gradients vanish, at no computational cost. In the <xref rid="pone.0270696.s001" ref-type="supplementary-material">S1 File</xref>, we propose a version of this technique that allows us to virtually parallelize a single physical ANN into several decoupled virtual models. Our approach enables shallow recurrent neural networks to look further back in time by skipping the redundant information that is inherent to the use of a sliding window as input, while still acting as fast as possible.</p>
  </sec>
  <sec id="sec009">
    <title>5 Case study: Online sleep spindle detection</title>
    <p>We now turn our attention to a case study application of the Portiloop in neuroscience—detecting sleep spindles shortly after they start so as to be able to stimulate the brain during the spindle. The long-term goal of this application is to further clarify the role of sleep spindles in learning and memory, and to explore therapeutic interventions for memory decline (see Section 2.2). As described in Section 2.4, stimulating sleep spindles is a particularly challenging case study due to their high frequency (∼12 to 16 Hz) and rapid evolution (&lt;2.5 s), and therefore tight timing constraints, and thus serves as a demonstration of the technology’s capabilities.</p>
    <p>To the best of our knowledge, the state-of-the-art in previous work regarding online sleep spindles detection was SpindleNet [<xref rid="pone.0270696.ref029" ref-type="bibr">29</xref>]. This architecture has too many parameters to be implemented on anything but the largest graphics processing units. Moreover, it was trained and evaluated on the MASS labels (i.e., a logic “OR” on the annotations of two experts whose spindle evaluation varies considerably). Since we do not have access to the SpindleNet model, which is closed-source, we rebuilt the architecture described in [<xref rid="pone.0270696.ref029" ref-type="bibr">29</xref>] and trained it on the more difficult MODA dataset [<xref rid="pone.0270696.ref028" ref-type="bibr">28</xref>] with the same pipeline that we used to train our models, as a means of comparing the models’ performance.</p>
    <p>We draw inspiration from SpindleNet as a starting point for our ANN architecture design. In particular, we train models based on the same idea of using Convolutional Neural Networks (CNNs) followed by Recurrent Neural Networks (RNNs), and we evaluate the relevance of the three different inputs used by SpindleNet (namely, the raw signal, the signal envelope and the signal’s power features) in our setting. We then use our optimization algorithm (named PMBO) along with the MODA dataset to derive a much smaller architecture, and provide a quantitative comparison with the SpindleNet architecture on MODA. Since maximum experimental flexibility is attained by being able to stimulate anytime during the course of the spindle including with phase precision, we conduct a thorough time analysis of the proposed system, and document possible trade-offs that a researcher might use to maximize performance for a given experimental application.</p>
    <sec id="sec010">
      <title>5.1 Dataset and training</title>
      <p>We use the MODA dataset (a subset of MASS), for training our ANN, since its labels are considerably more reliable [<xref rid="pone.0270696.ref028" ref-type="bibr">28</xref>]. Ethical approval for use of the dataset was obtained from the database’s scientific committee and Concordia University’s Research Ethics Unit. This dataset is divided in two subsets. The first one, called <italic toggle="yes">phase 1</italic>, consists of 100 younger subjects, whereas the second one, <italic toggle="yes">phase 2</italic>, consists of 80 older subjects. The MODA dataset provides two types of annotations (labels) on the signal: the first is the mean score given by the group of experts for each data point; the second is a binary classification of each data point as a spindle or non-spindle, defined by a threshold on the aforementioned scores (0.2 for phase 1 and 0.35 for phase 2). Further post-processing steps were applied to obtain these binary labels: spindles that were too short (&lt;0.3 s) and too close (&lt;0.1 s) to each other were merged, then spindles that were too short (&lt;0.3 s) or too long (&gt;2.5 s) were relabeled as negative. Given this dataset, two types of ANNs are possible: classifiers and regressors. These two types of ANNs differ only by the labels and losses used to train them. Classifiers are trained on the binary labels, by optimizing the binary cross entropy loss. They directly predict whether the current signal is a spindle or not, according to the very specific definition given by these binary labels (<italic toggle="yes">i</italic>.<italic toggle="yes">e</italic>., taking into account the thresholds and post-processing applied by MODA). Regressors are trained on the score labels, by optimizing the mean square error loss. They predict the score given by the experts (before the aforementioned post-processing steps), which allows the user to select their own threshold for detection. Note that, in practice, classifiers also enable the user to select their own threshold, although in a less interpretable way. We experiment with both types of models. Finally, note that MODA is a highly unbalanced dataset as only about 5% of the signal is labeled as sleep spindles. During the course of this work, we tried different ways of balancing training for classifiers and regressors. Interestingly, we found that classifiers benefit highly from oversampling (<italic toggle="yes">i</italic>.<italic toggle="yes">e</italic>., sampling 50% of spindles and 50% of non-spindles from the dataset during training) whereas all the balancing techniques we tried for regression (including oversampling, Label Distribution Smoothing [<xref rid="pone.0270696.ref042" ref-type="bibr">42</xref>] and a custom version of the latter) actually hinder training.</p>
      <p>To evaluate against SpindleNet we compute the inputs used by this model: the signal, the envelope of the signal, and a “power feature ratio” [<xref rid="pone.0270696.ref029" ref-type="bibr">29</xref>]. The latter compares frequencies between 2 Hz and 8 Hz with frequencies between 9 Hz and 16 Hz from the Fourier transform over the last 500 ms of signal. Computing this ratio is resource-intensive in the context of the Portiloop system, and furthermore did not improve our models’ performance. Therefore, we compute this ratio offline for the sole purpose of comparison with SpindleNet, and we do not use it in our model. We set the sampling frequency to 500 Hz, which allows the Portiloop to log the raw signal at a higher resolution, and then downsample to 250 Hz. <xref rid="pone.0270696.g003" ref-type="fig">Fig 3</xref> depicts the pipeline that computes the cleaned signal and envelope.</p>
      <fig position="float" id="pone.0270696.g003">
        <object-id pub-id-type="doi">10.1371/journal.pone.0270696.g003</object-id>
        <label>Fig 3</label>
        <caption>
          <title>Portiloop signal processing pipeline for extracting relevant inputs for the ANN.</title>
          <p>The selected filters introduce an identical software delay of 40 ms in both branches. (Note that power features are computed offline only for the SpindleNet architecture and are not represented in this diagram).</p>
        </caption>
        <graphic xlink:href="pone.0270696.g003" position="float"/>
      </fig>
      <p>We filter the EEG signal in the same frequency band as used in standard sleep scoring (<italic toggle="yes">i</italic>.<italic toggle="yes">e</italic>., 0.5 Hz to 30 Hz) [<xref rid="pone.0270696.ref043" ref-type="bibr">43</xref>]. An FIR filter of order 20 works reasonably well to remove frequencies above 30 Hz, but we observed persistent power line noise in unshielded home or office recording environments. To address this issue, we apply a notch filter whose frequency depends on the geographical area (50 Hz in Europe, 60 Hz in North America). For removing low frequencies, we rely on online standardization through exponential moving average (formulas are provided in <xref rid="pone.0270696.s001" ref-type="supplementary-material">S1 File</xref>). We use a coefficient <italic toggle="yes">α</italic><sub><italic toggle="yes">μ</italic></sub> = 0.1 for our running average, which attenuates frequencies under 4 Hz. We use a smaller coefficient <italic toggle="yes">α</italic><sub><italic toggle="yes">σ</italic></sub> = 0.001 for our running variance, meaning that our estimate of the standard deviation takes a larger portion of the signal into account. We empirically found this choice of <italic toggle="yes">α</italic><sub><italic toggle="yes">μ</italic></sub> and <italic toggle="yes">α</italic><sub><italic toggle="yes">σ</italic></sub> to reveal EEG features of interest and yield acceptable standardization, by visual inspection.</p>
      <p>We apply a similar procedure to extract the envelope: first, we filter the signal with a FIR band-pass between 12 Hz and 16 Hz. Then, we standardize with <italic toggle="yes">α</italic><sub><italic toggle="yes">μ</italic></sub> = <italic toggle="yes">α</italic><sub><italic toggle="yes">σ</italic></sub> = 0.001, we square the signal, and we smooth the result by computing its moving average, this time with <italic toggle="yes">α</italic><sub><italic toggle="yes">μ</italic></sub> = 0.01. We evaluate different types of ANN architectures, using either both or only one of these preprocessed signals as input. Since FIR filters introduce software delays, we have designed both branches of the pipeline so that they introduce identical software delays to their respective outputs (<italic toggle="yes">i</italic>.<italic toggle="yes">e</italic>., 40 ms at 250 Hz sampling rate with FIR filters of order 20).</p>
      <p>The output of the ANN tells whether the model considers the current signal being a sleep spindle or not. Some further processing is necessary to ensure that we only send one stimulation per spindle. As seen in <xref rid="pone.0270696.g002" ref-type="fig">Fig 2</xref>, the detection can be noisy around the beginning or the end of a spindle, especially since we use decoupled virtual parallel networks (see <xref rid="pone.0270696.s001" ref-type="supplementary-material">S1 File</xref>). A stimulus is sent upon initial spindle detection. To avoid multiple stimuli of the same spindle, the subsequent stimulation may only occur 400 ms following the end of the spindle. If a spindle is detected again within this duration the timer is reset, and we consider it as being part of the previous spindle.</p>
    </sec>
  </sec>
  <sec id="sec011">
    <title>6 Validation and performance</title>
    <p>We report results from a thorough quantitative and qualitative study of the system, not only in terms of detection scores as generally seen in previous work (i.e, proportion of data points correctly detected to be part of a spindle), but also in terms of real-time stimulation performance. Note that all our experiments are based on the MODA dataset rather than actual nights spent wearing the Portiloop device, as we would not have ground truth labels for newly recorded data. Further validation of the final device will require reproducing the experimental setting of MASS/MODA with the Portiloop (while participants are simultaneously wearing a research-grade polysomnography system for comparison) and labelling acquired data.</p>
    <p>All results regarding online detection performance are summarized in <xref rid="pone.0270696.t001" ref-type="table">Table 1</xref>. This table shows the f1, precision and recall metrics that statistically describe how efficient different models are at detecting sleep spindles (on average over all data points). These metrics are provided separately for phase 1, which groups younger subjects, for phase 2, which groups older subjects, and for the whole cohort.</p>
    <table-wrap position="float" id="pone.0270696.t001">
      <object-id pub-id-type="doi">10.1371/journal.pone.0270696.t001</object-id>
      <label>Table 1</label>
      <caption>
        <title>Quantitative results. Our different models and ablations are compared under “Online Detection” using the nomenclature “mean (std)”, and superscripts for referencing rows in the text.</title>
        <p>In rows (4) and (5) we replace an input of our 2-input model by a copy of the other, in row (7) we remove time-dilation, in rows (8) and (9) we train our model only on phase 1 or phase 2 (i.e., young subjects or old subjects), and in row (10) we train a regressor to evaluate it as a classifier.</p>
      </caption>
      <alternatives>
        <graphic xlink:href="pone.0270696.t001" id="pone.0270696.t001g" position="float"/>
        <table frame="box" rules="all" border="0">
          <colgroup span="1">
            <col align="left" valign="middle" span="1"/>
            <col align="left" valign="middle" span="1"/>
            <col align="left" valign="middle" span="1"/>
            <col align="left" valign="middle" span="1"/>
            <col align="left" valign="middle" span="1"/>
            <col align="left" valign="middle" span="1"/>
            <col align="left" valign="middle" span="1"/>
            <col align="left" valign="middle" span="1"/>
            <col align="left" valign="middle" span="1"/>
            <col align="left" valign="middle" span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th align="left" rowspan="1" colspan="1"/>
              <th align="center" colspan="3" style="background-color:#CCCCCC" rowspan="1">(a) Phase 1 (younger)</th>
              <th align="center" colspan="3" style="background-color:#CCCCCC" rowspan="1">(b) Phase 2 (older)</th>
              <th align="center" colspan="3" style="background-color:#CCCCCC" rowspan="1">(c) Whole Cohort</th>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"/>
              <td align="center" style="background-color:#E5E5E5" rowspan="1" colspan="1">
                <italic toggle="yes">
                  <bold>Recall</bold>
                </italic>
              </td>
              <td align="center" style="background-color:#E5E5E5" rowspan="1" colspan="1">
                <italic toggle="yes">
                  <bold>Precision</bold>
                </italic>
              </td>
              <td align="center" style="background-color:#E5E5E5" rowspan="1" colspan="1">
                <italic toggle="yes">
                  <bold>f1</bold>
                </italic>
              </td>
              <td align="center" style="background-color:#E5E5E5" rowspan="1" colspan="1">
                <italic toggle="yes">
                  <bold>Recall</bold>
                </italic>
              </td>
              <td align="center" style="background-color:#E5E5E5" rowspan="1" colspan="1">
                <italic toggle="yes">
                  <bold>Precision</bold>
                </italic>
              </td>
              <td align="center" style="background-color:#E5E5E5" rowspan="1" colspan="1">
                <italic toggle="yes">
                  <bold>f1</bold>
                </italic>
              </td>
              <td align="center" style="background-color:#E5E5E5" rowspan="1" colspan="1">
                <italic toggle="yes">
                  <bold>Recall</bold>
                </italic>
              </td>
              <td align="center" style="background-color:#E5E5E5" rowspan="1" colspan="1">
                <italic toggle="yes">
                  <bold>Precision</bold>
                </italic>
              </td>
              <td align="center" style="background-color:#E5E5E5" rowspan="1" colspan="1">
                <italic toggle="yes">
                  <bold>f1</bold>
                </italic>
              </td>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td align="center" rowspan="1" colspan="1"/>
              <td align="center" colspan="9" style="background-color:#C0C0C0" rowspan="1">Experts</td>
            </tr>
            <tr>
              <td align="center" style="background-color:#CCCCCC" rowspan="1" colspan="1">
                <italic toggle="yes">Inter-rater agreement<sup>1</sup></italic>
              </td>
              <td align="center" rowspan="1" colspan="1">0.76 (0.16)</td>
              <td align="center" rowspan="1" colspan="1">0.81 (0.17)</td>
              <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">
                <bold>0.76 (0.1)</bold>
              </td>
              <td align="center" rowspan="1" colspan="1">0.66 (0.19)</td>
              <td align="center" rowspan="1" colspan="1">0.74 (0.17)</td>
              <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">
                <bold>0.65 (0.12)</bold>
              </td>
              <td align="center" rowspan="1" colspan="1">0.72 (0.18)</td>
              <td align="center" rowspan="1" colspan="1">0.78 (0.17)</td>
              <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">
                <bold>0.72 (0.12)</bold>
              </td>
            </tr>
            <tr>
              <td align="center" rowspan="1" colspan="1"/>
              <td align="center" colspan="9" style="background-color:#C0C0C0" rowspan="1">Offline Detection</td>
            </tr>
            <tr>
              <td align="center" style="background-color:#CCCCCC" rowspan="1" colspan="1"><italic toggle="yes">Ferrarelli</italic> [<xref rid="pone.0270696.ref032" ref-type="bibr">32</xref>]</td>
              <td align="center" rowspan="1" colspan="1">0.19</td>
              <td align="center" rowspan="1" colspan="1">0.83</td>
              <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">0.31</td>
              <td align="center" rowspan="1" colspan="1">0.16</td>
              <td align="center" rowspan="1" colspan="1">0.87</td>
              <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">0.27</td>
              <td align="center" rowspan="1" colspan="1">0.18</td>
              <td align="center" rowspan="1" colspan="1">0.85</td>
              <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">0.29</td>
            </tr>
            <tr>
              <td align="center" style="background-color:#CCCCCC" rowspan="1" colspan="1"><italic toggle="yes">Mölle</italic> [<xref rid="pone.0270696.ref033" ref-type="bibr">33</xref>]</td>
              <td align="center" rowspan="1" colspan="1">0.83</td>
              <td align="center" rowspan="1" colspan="1">0.47</td>
              <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">0.6</td>
              <td align="center" rowspan="1" colspan="1">0.78</td>
              <td align="center" rowspan="1" colspan="1">0.44</td>
              <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">0.56</td>
              <td align="center" rowspan="1" colspan="1">0.81</td>
              <td align="center" rowspan="1" colspan="1">0.46</td>
              <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">0.58</td>
            </tr>
            <tr>
              <td align="center" style="background-color:#CCCCCC" rowspan="1" colspan="1"><italic toggle="yes">Martin</italic> [<xref rid="pone.0270696.ref034" ref-type="bibr">34</xref>]</td>
              <td align="center" rowspan="1" colspan="1">0.61</td>
              <td align="center" rowspan="1" colspan="1">0.64</td>
              <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">0.62</td>
              <td align="center" rowspan="1" colspan="1">0.58</td>
              <td align="center" rowspan="1" colspan="1">0.56</td>
              <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">0.57</td>
              <td align="center" rowspan="1" colspan="1">0.6</td>
              <td align="center" rowspan="1" colspan="1">0.6</td>
              <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">0.6</td>
            </tr>
            <tr>
              <td align="center" style="background-color:#CCCCCC" rowspan="1" colspan="1"><italic toggle="yes">Wamsley</italic> [<xref rid="pone.0270696.ref035" ref-type="bibr">35</xref>]</td>
              <td align="center" rowspan="1" colspan="1">0.57</td>
              <td align="center" rowspan="1" colspan="1">0.69</td>
              <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">0.63</td>
              <td align="center" rowspan="1" colspan="1">0.56</td>
              <td align="center" rowspan="1" colspan="1">0.62</td>
              <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">0.59</td>
              <td align="center" rowspan="1" colspan="1">0.57</td>
              <td align="center" rowspan="1" colspan="1">0.66</td>
              <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">0.61</td>
            </tr>
            <tr>
              <td align="center" style="background-color:#CCCCCC" rowspan="1" colspan="1"><italic toggle="yes">Lacourse</italic> [<xref rid="pone.0270696.ref027" ref-type="bibr">27</xref>]</td>
              <td align="center" rowspan="1" colspan="1">0.75</td>
              <td align="center" rowspan="1" colspan="1">0.73</td>
              <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">
                <bold>0.74</bold>
              </td>
              <td align="center" rowspan="1" colspan="1">0.7</td>
              <td align="center" rowspan="1" colspan="1">0.69</td>
              <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">0.7</td>
              <td align="center" rowspan="1" colspan="1">0.73</td>
              <td align="center" rowspan="1" colspan="1">0.71</td>
              <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">
                <bold>0.72</bold>
              </td>
            </tr>
            <tr>
              <td align="center" style="background-color:#CCCCCC" rowspan="1" colspan="1"><italic toggle="yes">Ray</italic> [<xref rid="pone.0270696.ref036" ref-type="bibr">36</xref>]</td>
              <td align="center" rowspan="1" colspan="1">0.73</td>
              <td align="center" rowspan="1" colspan="1">0.47</td>
              <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">0.57</td>
              <td align="center" rowspan="1" colspan="1">0.75</td>
              <td align="center" rowspan="1" colspan="1">0.32</td>
              <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">0.45</td>
              <td align="center" rowspan="1" colspan="1">0.74</td>
              <td align="center" rowspan="1" colspan="1">0.4</td>
              <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">0.51</td>
            </tr>
            <tr>
              <td align="center" style="background-color:#CCCCCC" rowspan="1" colspan="1"><italic toggle="yes">Parekh</italic> [<xref rid="pone.0270696.ref037" ref-type="bibr">37</xref>]</td>
              <td align="center" rowspan="1" colspan="1">0.85</td>
              <td align="center" rowspan="1" colspan="1">0.61</td>
              <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">0.71</td>
              <td align="center" rowspan="1" colspan="1">0.74</td>
              <td align="center" rowspan="1" colspan="1">0.68</td>
              <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">
                <bold>0.71</bold>
              </td>
              <td align="center" rowspan="1" colspan="1">0.8</td>
              <td align="center" rowspan="1" colspan="1">0.65</td>
              <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">0.71</td>
            </tr>
            <tr>
              <td align="center" rowspan="1" colspan="1"/>
              <td align="center" colspan="9" style="background-color:#C0C0C0" rowspan="1">Online Detection</td>
            </tr>
            <tr>
              <td align="center" style="background-color:#CCCCCC" rowspan="1" colspan="1"><italic toggle="yes">Based on SpindleNet</italic> [<xref rid="pone.0270696.ref029" ref-type="bibr">29</xref>]<sup>2</sup></td>
              <td align="center" rowspan="1" colspan="1">0.92 (0.04)</td>
              <td align="center" rowspan="1" colspan="1">0.24 (0.07)</td>
              <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">0.38 (0.07)</td>
              <td align="center" rowspan="1" colspan="1">0.85 (0.06)</td>
              <td align="center" rowspan="1" colspan="1">0.19 (0.08)</td>
              <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">0.3 (0.1)</td>
              <td align="center" rowspan="1" colspan="1">0.89 (0.05)</td>
              <td align="center" rowspan="1" colspan="1">0.22 (0.07)</td>
              <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">0.35 (0.08)</td>
            </tr>
            <tr>
              <td align="center" style="background-color:#CCCCCC" rowspan="1" colspan="1">
                <bold>2-input<sup>3</sup></bold>
              </td>
              <td align="center" rowspan="1" colspan="1">0.68 (0.04)</td>
              <td align="center" rowspan="1" colspan="1">0.6 (0.06)</td>
              <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">
                <bold>0.64 (0.03)</bold>
              </td>
              <td align="center" rowspan="1" colspan="1">0.52 (0.09)</td>
              <td align="center" rowspan="1" colspan="1">0.58 (0.04)</td>
              <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">0.54 (0.05)</td>
              <td align="center" rowspan="1" colspan="1">0.62 (0.06)</td>
              <td align="center" rowspan="1" colspan="1">0.6 (0.05)</td>
              <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">
                <bold>0.61 (0.03)</bold>
              </td>
            </tr>
            <tr>
              <td align="center" style="background-color:#CCCCCC" rowspan="1" colspan="1">
                <bold>2-input ablation 1<sup>4</sup></bold>
              </td>
              <td align="center" rowspan="1" colspan="1">0.7 (0.09)</td>
              <td align="center" rowspan="1" colspan="1">0.47 (0.08)</td>
              <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">0.55 (0.04)</td>
              <td align="center" rowspan="1" colspan="1">0.56 (0.11)</td>
              <td align="center" rowspan="1" colspan="1">0.43 (0.09)</td>
              <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">0.47 (0.04)</td>
              <td align="center" rowspan="1" colspan="1">0.65 (0.1)</td>
              <td align="center" rowspan="1" colspan="1">0.46 (0.08)</td>
              <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">0.52 (0.04)</td>
            </tr>
            <tr>
              <td align="center" style="background-color:#CCCCCC" rowspan="1" colspan="1">
                <bold>2-input ablation 2<sup>5</sup></bold>
              </td>
              <td align="center" rowspan="1" colspan="1">0.72 (0.03)</td>
              <td align="center" rowspan="1" colspan="1">0.57 (0.06)</td>
              <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">
                <bold>0.64 (0.03)</bold>
              </td>
              <td align="center" rowspan="1" colspan="1">0.57 (0.08)</td>
              <td align="center" rowspan="1" colspan="1">0.53 (0.04)</td>
              <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">
                <bold>0.55 (0.04)</bold>
              </td>
              <td align="center" rowspan="1" colspan="1">0.67 (0.04)</td>
              <td align="center" rowspan="1" colspan="1">0.56 (0.05)</td>
              <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">
                <bold>0.61 (0.03)</bold>
              </td>
            </tr>
            <tr>
              <td align="center" style="background-color:#CCCCCC" rowspan="1" colspan="1">
                <bold>1-input<sup>6</sup></bold>
              </td>
              <td align="center" rowspan="1" colspan="1">0.7 (0.04)</td>
              <td align="center" rowspan="1" colspan="1">0.59 (0.05)</td>
              <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">
                <bold>0.64 (0.03)</bold>
              </td>
              <td align="center" rowspan="1" colspan="1">0.54 (0.09)</td>
              <td align="center" rowspan="1" colspan="1">0.58 (0.05)</td>
              <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">
                <bold>0.55 (0.05)</bold>
              </td>
              <td align="center" rowspan="1" colspan="1">0.64 (0.05)</td>
              <td align="center" rowspan="1" colspan="1">0.59 (0.05)</td>
              <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">
                <bold>0.61 (0.03)</bold>
              </td>
            </tr>
            <tr>
              <td align="center" style="background-color:#CCCCCC" rowspan="1" colspan="1">
                <bold>1-input ablation td<sup>7</sup></bold>
              </td>
              <td align="center" rowspan="1" colspan="1">0.47 (0.1)</td>
              <td align="center" rowspan="1" colspan="1">0.6 (0.09)</td>
              <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">0.51 (0.03)</td>
              <td align="center" rowspan="1" colspan="1">0.31 (0.12)</td>
              <td align="center" rowspan="1" colspan="1">0.59 (0.08)</td>
              <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">0.39 (0.08)</td>
              <td align="center" rowspan="1" colspan="1">0.41 (0.1)</td>
              <td align="center" rowspan="1" colspan="1">0.6 (0.09)</td>
              <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">0.47 (0.04)</td>
            </tr>
            <tr>
              <td align="center" style="background-color:#CCCCCC" rowspan="1" colspan="1">
                <bold>1-input trained on p1<sup>8</sup></bold>
              </td>
              <td align="center" rowspan="1" colspan="1">0.72 (0.05)</td>
              <td align="center" rowspan="1" colspan="1">0.56 (0.05)</td>
              <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">0.63 (0.03)</td>
              <td align="center" rowspan="1" colspan="1">0.57 (0.08)</td>
              <td align="center" rowspan="1" colspan="1">0.52 (0.07)</td>
              <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">0.54 (0.05)</td>
              <td align="center" rowspan="1" colspan="1">0.66 (0.07)</td>
              <td align="center" rowspan="1" colspan="1">0.55 (0.05)</td>
              <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">0.6 (0.03)</td>
            </tr>
            <tr>
              <td align="center" style="background-color:#CCCCCC" rowspan="1" colspan="1">
                <bold>1-input trained on p2<sup>9</sup></bold>
              </td>
              <td align="center" rowspan="1" colspan="1">0.75 (0.05)</td>
              <td align="center" rowspan="1" colspan="1">0.5 (0.05)</td>
              <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">0.6 (0.02)</td>
              <td align="center" rowspan="1" colspan="1">0.62 (0.09)</td>
              <td align="center" rowspan="1" colspan="1">0.45 (0.05)</td>
              <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">0.52 (0.03)</td>
              <td align="center" rowspan="1" colspan="1">0.7 (0.06)</td>
              <td align="center" rowspan="1" colspan="1">0.49 (0.04)</td>
              <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">0.57 (0.02)</td>
            </tr>
            <tr>
              <td align="center" style="background-color:#CCCCCC" rowspan="1" colspan="1">
                <bold>1-input regression<sup>10</sup></bold>
              </td>
              <td align="center" rowspan="1" colspan="1">0.62 (0.07)</td>
              <td align="center" rowspan="1" colspan="1">0.64 (0.06)</td>
              <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">0.63 (0.03)</td>
              <td align="center" rowspan="1" colspan="1">0.53 (0.06)</td>
              <td align="center" rowspan="1" colspan="1">0.55 (0.08)</td>
              <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">0.53 (0.04)</td>
              <td align="center" rowspan="1" colspan="1">0.58 (0.06)</td>
              <td align="center" rowspan="1" colspan="1">0.62 (0.06)</td>
              <td align="center" style="background-color:#E7E6E6" rowspan="1" colspan="1">0.6 (0.03)</td>
            </tr>
          </tbody>
        </table>
      </alternatives>
    </table-wrap>
    <p>As previously highlighted, sleep spindle detection is a difficult task and experts themselves often do not agree when annotating these offline. This disagreement is quantified by MODA [<xref rid="pone.0270696.ref028" ref-type="bibr">28</xref>] and represented in <xref rid="pone.0270696.t001" ref-type="table">Table 1</xref>, row (1) for reference. The experts annotating the MODA dataset had an average performance of 0.72 on the whole cohort in term of the f1-score of their individual annotations with respect to the final labels. They are compared to other <italic toggle="yes">offline detection</italic>, <italic toggle="yes">i</italic>.<italic toggle="yes">e</italic>., when a virtually infinite computational budget and the whole signal is available, including future data points, presented under “offline detection” in <xref rid="pone.0270696.t001" ref-type="table">Table 1</xref> (taken from [<xref rid="pone.0270696.ref028" ref-type="bibr">28</xref>]). We instead perform <italic toggle="yes">online detection</italic>, which has additional challenges: (a) computation happens in real time; (b) the future signal is not available.</p>
    <p>The MODA dataset is relatively small (∼24 h of annotated data) and heterogeneous. This adds some difficulty for training and properly assessing the performance of our models, because we choose to use only 10% of subjects as our validation set (for model selection), and another 10% of subjects as our test set (for final model evaluation). Since the results would otherwise be dependent on the assignment of subjects to the three sets, we evaluate our models through the following procedure:
<list list-type="bullet"><list-item><p>we shuffle all subjects 10 times and compute a different training/validation/test split of the dataset each time (sets are thus made of separate subjects);</p></list-item><list-item><p>for each split, we use the training set to train 3 models, the validation set being used to estimate their f1-score. We select the best of these 3 models by its best f1-score on the validation set. We then report the performance of this model in terms of its f1-score on the test set;</p></list-item><list-item><p>the above being repeated 10 times, we report the average test f1-score in <xref rid="pone.0270696.t001" ref-type="table">Table 1</xref>, with the corresponding standard deviation being indicated in parenthesis.</p></list-item></list></p>
    <p>As described previously, we use the SpindleNet [<xref rid="pone.0270696.ref029" ref-type="bibr">29</xref>] architecture as a baseline for evaluating the performance of our own models. Since SpindleNet is closed-source and trained on the MASS dataset, we retrain its architecture from scratch with the same pipeline as used to train our other classifiers. In particular, we balance training through oversampling (as opposed to the data augmentation technique used by the authors of the original paper), and we train and evaluate SpindleNet on the MODA dataset. The results of this experiment are presented in <xref rid="pone.0270696.t001" ref-type="table">Table 1</xref>, row (2). The baseline has a high recall and a poor precision; in other words it it tends to incorrectly label non-spindle events as spindles.</p>
    <p>We first derive a lightweight ANN architecture by drawing inspiration from SpindleNet. More precisely, we use our optimization algorithm PMBO to find a Pareto-optimal architecture that uses both the cleaned signal and the envelope as inputs. The resulting architecture is presented in the Supplementary Information. We measure a total duration of 40 ms for each forward pass in this model on the FPGA-based variant of the Portiloop. The detection performance of this model, reported in <xref rid="pone.0270696.t001" ref-type="table">Table 1</xref>, row (3), vastly outperforms the baseline.</p>
    <p>The idea of using the envelope along the raw signal as input to the ANN is drawn from the baseline. Since the envelope is computed from the raw signal, it should not contain any additional information that cannot be extracted by an ANN. To evaluate the relevance of this particular input, we perform the following ablation: to keep the same architecture (and thus the same model capacity), we replace one of the two inputs by a copy of the other. In <xref rid="pone.0270696.t001" ref-type="table">Table 1</xref>, row (4) both inputs are the envelope, while in row (5) both inputs are the cleaned signal. We find that the envelope input can be removed: the model in which we replace the envelope with a copy of the cleaned signal (5) has the same performance as the original model (3), and even performs marginally better on phase 2.</p>
    <p>Since we deem the use of the envelope input ineffective, we use PMBO one more time to devise our final Pareto-optimal ANN architecture, now with only the cleaned signal as input. For this matter, we run PMBO on 20 Tesla V100 GPU workers over a period of 24h. The detailed hyperparameters used in this experiment are provided in <xref rid="pone.0270696.s001" ref-type="supplementary-material">S1 File</xref>, and the results are visualized in <xref rid="pone.0270696.g004" ref-type="fig">Fig 4</xref>, which shows all the explored architectures according to their classification performance (software cost) and the use of FPGA resources (hardware cost). The red line is the Pareto front, meaning the set of configurations that are optimal for at least one of the two metrics: this means all points that are <italic toggle="yes">not</italic> on the Pareto front have at least one corresponding configuration that is better in terms of both software and hardware cost, and should therefore not be considered. We select the best model in terms of software cost (i.e. the one with the highest classification performance) irrespective of its hardware cost <italic toggle="yes">i</italic>.<italic toggle="yes">e</italic>., the model corresponding to the right-hand end of the Pareto front. This model is acceptable because it is anyway rather small, with only 25.6k parameters. We measure the execution time of this architecture to be 20 ms per forward pass on the Portiloop (vs. 40 ms for the 2-input version).</p>
    <fig position="float" id="pone.0270696.g004">
      <object-id pub-id-type="doi">10.1371/journal.pone.0270696.g004</object-id>
      <label>Fig 4</label>
      <caption>
        <title>Search space of the single-input architecture, found with PMBO.</title>
        <p>The hardware cost is the number of trainable parameters in the neural architecture, and the software cost is 1−f1- score of the fully- trained model. Black dots: non-Pareto-optimal models tested by the algorithm. Red dots: Pareto-optimal models found by the algorithm. Red line: Pareto front. The researcher would select a configuration from the Pareto front, which represents optimal trade-offs between both costs.</p>
      </caption>
      <graphic xlink:href="pone.0270696.g004" position="float"/>
    </fig>
    <p>The selected architecture is described in <xref rid="pone.0270696.g005" ref-type="fig">Fig 5</xref>, and its detection performance is summarized in <xref rid="pone.0270696.t001" ref-type="table">Table 1</xref>, row (6). Compared to our 2-input model, the single-input model exhibits the same performance, with even a marginal improvement on phase 2, while executing twice as fast (20 ms versus 40 ms). The detailed hyperparameters of this model are provided in <xref rid="pone.0270696.s001" ref-type="supplementary-material">S1 File</xref>.</p>
    <fig position="float" id="pone.0270696.g005">
      <object-id pub-id-type="doi">10.1371/journal.pone.0270696.g005</object-id>
      <label>Fig 5</label>
      <caption>
        <title>Final single-input ANN architecture.</title>
        <p>The dimensions of each layer are provided in parenthesis using the PyTorch nomenclature.</p>
      </caption>
      <graphic xlink:href="pone.0270696.g005" position="float"/>
    </fig>
    <p>To verify that the use of virtual parallelization via time-dilation (c.f. <xref rid="pone.0270696.s001" ref-type="supplementary-material">S1 File</xref>) is indeed necessary to obtain our results, we shrink the time-dilation (set to 168 ms by PMBO) to the minimum, <italic toggle="yes">i</italic>.<italic toggle="yes">e</italic>., 20 ms since this is the execution duration of the ANN per forward pass. This removes the virtual parallelization, since the same ANN must now be used for each sample. Therefore, each step of back-propagation reaches 8 times less far back in time during training. The result of this ablation is presented in <xref rid="pone.0270696.t001" ref-type="table">Table 1</xref>, row (7). The highly deteriorated results illustrate the importance of time-dilation. This hints at the relevance of looking relatively far back in time to annotate sleep spindles.</p>
    <p>Finally, to ensure the generality of our ANN, and knowing that spindles change in older adults [<xref rid="pone.0270696.ref024" ref-type="bibr">24</xref>], we compare the results using the data of MODA phase 1 (younger subjects) and the data of MODA phase 2 (older subjects). Namely, we either train the model on subjects drawn only from phase 1, or subjects drawn only from phase 2. The results of these experiments are presented in <xref rid="pone.0270696.t001" ref-type="table">Table 1</xref>, rows (8, 9). We observe that the ANN trained on phase 1 performs almost as well as the ANN trained on the whole cohort (6) on all subsets, including phase 2, whereas the ANN trained on phase 2 is noticeably worse on all subsets, even including phase 2. We hypothesize that this is because phase 2 is comprised of older adults, who have lower amplitude and fewer sleep spindles. Using phase 2 during training is still useful in terms of generalization. Indeed, the ANN trained on phase 1 only (8) has a slightly worse performance when tested on phase 1 than the ANN trained on the whole cohort (6).</p>
    <p>Note that all models presented beforehand are classifiers. We also train a regressor with the same architecture, as explained in Section 5.1. There is a subtle difference in what this model measures when compared to our classifiers: whereas classifiers predict whether the signal is a sleep spindle according to the full definition given by MODA (including post-processing), the regressor predicts the mean score given by the experts (excluding post-processing). Since we are primarily interested in classification in this article, we find the threshold that maximizes the f1-score on the binary labels, presented in <xref rid="pone.0270696.s001" ref-type="supplementary-material">S1 File</xref>. We find that the optimal threshold is 0.27 for phase 1, 0.23 for phase 2 and 0.26 for the whole cohort. We then evaluate the regressor with these thresholds on the classification task and report the results in <xref rid="pone.0270696.t001" ref-type="table">Table 1</xref>, row (10). These results are slightly weaker than those of the classifier (6). We surmise that this effect comes from the post-processing steps performed by MODA to compute the binary labels. We choose the 1-input classifier (6) for the remainder of this article.</p>
    <sec id="sec012">
      <title>6.1 Real-time stimulation</title>
      <p>The performance measured in the previous section is not entirely representative of the performance on the final task. So far, we have only measured the capability of the model to annotate each data point of the signal individually. Yet, we want the ability to send one single stimulation per sleep spindle.</p>
      <p>The ANN delays must be compounded with the other sources of delays (here reported for the FPGA version as a worst case, as they are slightly lower for the Coral version), <italic toggle="yes">i</italic>.<italic toggle="yes">e</italic>., the software delay from FIRs (40 ms), the ANN forward pass duration (20 ms) and the stimulation hardware delay, to measure our real stimulation performance. We measure an auditory stimulation delay of 4 ms when using a basic sound controller, for a total constant delay of 64 ms. The measured delays are summarized in <xref rid="pone.0270696.t002" ref-type="table">Table 2</xref>, were one can see that the most significant source of delay is the detection delay of our ANN. Training a faster model is thus a potential avenue for future work.</p>
      <table-wrap position="float" id="pone.0270696.t002">
        <object-id pub-id-type="doi">10.1371/journal.pone.0270696.t002</object-id>
        <label>Table 2</label>
        <caption>
          <title>Delays measured in the Portiloop (sleep spindle configuration).</title>
        </caption>
        <alternatives>
          <graphic xlink:href="pone.0270696.t002" id="pone.0270696.t002g" position="float"/>
          <table frame="box" rules="all" border="0">
            <colgroup span="1">
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th align="left" style="background-color:#CCCCCC" rowspan="1" colspan="1">Component</th>
                <th align="center" style="background-color:#CCCCCC" rowspan="1" colspan="1">Hardware delay</th>
                <th align="center" style="background-color:#CCCCCC" rowspan="1" colspan="1">Software delay</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="left" rowspan="1" colspan="1">Electrodes + ADC</td>
                <td align="center" rowspan="1" colspan="1">-</td>
                <td align="center" rowspan="1" colspan="1">-</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Filters</td>
                <td align="center" rowspan="1" colspan="1">-</td>
                <td align="center" rowspan="1" colspan="1">40 ms</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">ANN</td>
                <td align="center" rowspan="1" colspan="1">20 ms</td>
                <td align="center" rowspan="1" colspan="1">∼ 250 (± 100) ms</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Stimulus</td>
                <td align="center" rowspan="1" colspan="1">4 ms</td>
                <td align="center" rowspan="1" colspan="1">-</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Total: ∼ 314 ms</td>
                <td align="center" rowspan="1" colspan="1">24 ms</td>
                <td align="center" rowspan="1" colspan="1">290 (± 100) ms</td>
              </tr>
            </tbody>
          </table>
        </alternatives>
      </table-wrap>
      <p>From now on, we redefine: (a) True positive: the first stimulus sent within the duration of a spindle, taking all delays into account; (b) False positive: any other stimulus; (c) False negative: any spindle that does not receive a stimulus within its labeled duration.</p>
      <p><xref rid="pone.0270696.g006" ref-type="fig">Fig 6(a)</xref> displays the detection performance (taking all delays into account) of our final device. We compute the stimulation precision, recall and f1-score according to the aforementioned definitions of true positives, false positives and false negatives. This provides a visualization of possible trade-offs in terms of how many spindles we want to stimulate (recall) versus how sure we want to be that all stimuli are relevant (precision). In terms of f1-score, the best such trade-off is attained at a threshold of 0.84 with our model, yielding a precision and a recall of 0.71 both.</p>
      <fig position="float" id="pone.0270696.g006">
        <object-id pub-id-type="doi">10.1371/journal.pone.0270696.g006</object-id>
        <label>Fig 6</label>
        <caption>
          <title>Detection threshold trade-off.</title>
          <p>(a) Evolution of the stimulation performance with respect to the chosen detection threshold on the ANN output value. A threshold of 0.84 yields the optimal trade-off; however, researchers may wish to select different parameters according to experimental objectives. (b) Distribution of stimulation delays for a classifier with 0.5 and 0.84 thresholds, respectively. Increasing the threshold yields longer delays. Note that delays are negative when spindles are stimulated in advance of human expert annotation.</p>
        </caption>
        <graphic xlink:href="pone.0270696.g006" position="float"/>
      </fig>
      <p>The timing performance of our system can be observed in <xref rid="pone.0270696.g006" ref-type="fig">Fig 6(b)</xref>, which displays the distribution of stimulation delays, <italic toggle="yes">i</italic>.<italic toggle="yes">e</italic>., the distribution of the stimulus being closest to the beginning of each sleep spindle, all delays being taken into account. Some stimulation delays are negative, as spindles are sometimes stimulated in advance (note that we count these as false positives, which slightly harms our reported results). <xref rid="pone.0270696.g006" ref-type="fig">Fig 6(b)</xref> shows the effect of increasing the detection threshold of our model on the stimulation delays. According to <xref rid="pone.0270696.g006" ref-type="fig">Fig 6(a)</xref>, choosing a 0.84 detection threshold over the 0.5 default classification threshold in our ANN yields a better stimulation f1-score and in particular much more precise stimuli, but this comes at the price of slightly shifting the stimulation delay distribution to the right, <italic toggle="yes">i</italic>.<italic toggle="yes">e</italic>., introducing some additional delay to the stimulation, as further seen in <xref rid="pone.0270696.s001" ref-type="supplementary-material">S1 File</xref>.</p>
      <p>To further illustrate the final performance of the system, <xref rid="pone.0270696.g002" ref-type="fig">Fig 2</xref> displays an example of its real-time stimulation capability on actual EEG signal (test dataset). More examples and visual insights are provided in <xref rid="pone.0270696.s001" ref-type="supplementary-material">S1 File</xref>.</p>
      <p>Finally, we estimate the Portiloop energy efficiency by running the FPGA version continuously, powered by a fully-charged 20000 mAh battery. The battery dies out after 26 hours and 22 minutes, suggesting that our power consumption is roughly 756 mA. The Coral version runs for approximately 8 hours with a 12000 mAh battery pack suggesting a 1500 mA current draw.</p>
    </sec>
  </sec>
  <sec id="sec013">
    <title>7 Discussion and future work</title>
    <p>In this article, we introduce the Portiloop, a device that enables the real-time detection and stimulation of patterns of interest in electroencephalography signals. Our system is open-source, portable, low-cost, and can be tailored for many brain stimulation research applications. We propose a pipeline to design neural architectures that are relevant for processing EEG signals in real time. We further propose an algorithm that automates the process of finding efficient models (i.e., PMBO), using one-to-many parallel workers. We demonstrate our proposed system on the closed-loop stimulation of sleep spindles, a difficult task of high relevance for the neuroscience community. Our resulting system is the first portable device to be able to detect and stimulate sleep spindles in real time with an f1-score of 0.71, measured on MODA, a dataset renowned for the reliability of its labels. The Portiloop system can be adapted to any application of EEG closed-loop stimulation, and potentially, any other neurophysiological signal. As opposed to classical heuristics, our deep learning-based approach does not require specific knowledge of the phenomenon of interest when defining the classifier, nor does it require a way to extract the relevant information. Instead, a large dataset of annotated signals suffices to derive a high-performance model that detects complex patterns such as sleep spindles.</p>
    <p>Although we compare our architecture to a state-of-the-art sleep spindle detector (SpindleNet), we did not have access to their weights and thus we could not compare their original model with ours directly on the MODA dataset. Instead, we retrained their architecture from scratch on MODA, using our own pipeline. Contrary to the observations of Kulkarni <italic toggle="yes">et al</italic>. [<xref rid="pone.0270696.ref029" ref-type="bibr">29</xref>], we were able remove the envelope and power inputs without harming the performance of our models.</p>
    <p>Concerning PMBO, the algorithm produces high-performance lightweight architectures, but we note that the predictions of the meta-learner are often near-constant in well-performing areas of the search space, suggesting that the meta-model could not further predict the software cost. In other words, we were unable to differentiate between the best-performing configurations of the neural network. We surmise that this is due to the large variance in model performance from one training session to another. This might be further improved by additional training. In future work, techniques such as Integrated Gradients [<xref rid="pone.0270696.ref044" ref-type="bibr">44</xref>] could be used to better understand the search space, and potentially fine-tune the ANN.</p>
    <p>Explainable artificial intelligence techniques such as this may also help researchers to reveal unknown dependencies in neural activity, for example that a spindle might be preceded by another pattern of neural activity (see <xref rid="pone.0270696.s001" ref-type="supplementary-material">S1 File</xref> for an exploration of which parts of the signal are used by the neural network for classification).</p>
    <p>In addition, while the MODA dataset provides high-quality labels, training on a larger dataset of similar quality would likely further improve the performance of our models. Expanding MODA is a relevant avenue for future work, as is implementing transfer learning techniques (i.e., tools that allow a trained network to adapt to a different environment), because the EEG acquisition and signal may differ somewhat from the training data or between individuals. Transfer can be achieved with techniques such as domain randomization [<xref rid="pone.0270696.ref045" ref-type="bibr">45</xref>]. Alternatively, a dataset can be collected on the Portiloop and annotated following the same protocol as MODA.</p>
    <p>Long term, we intend to target specific portions of sleep spindles for stimulation (e.g., beginning, middle, end; or by oscillatory phase). This harder task will likely involve labeling these portions and developing more advanced RNNs/Transformers so as to consistently predict sleep spindles. Although our model does use information far back in time to make predictions, we believe that the main role currently played by the RNN is to accumulate information regarding whether the last few windows were spindles or not, rather than actually predicting the future (see <xref rid="pone.0270696.s001" ref-type="supplementary-material">S1 File</xref>). Such models will likely be more complex and computationally hungry, which is why the newer hardware implementation of the Portiloop integrates an embedded tensor processing unit (a powerful neural network accelerator). In general, finding an optimal model for a given Portiloop application involves either retraining our ANN, or re-executing PMBO to find a whole new architecture. Both activities can be done by interested practitioners using tools that accompany this work.</p>
    <p>In sum, we hope that the Portiloop will help the neuroscience community explore brain functions, such as the role of sleep spindles in memory consolidation.</p>
  </sec>
  <sec id="sec014" sec-type="supplementary-material">
    <title>Supporting information</title>
    <supplementary-material id="pone.0270696.s001" position="float" content-type="local-data">
      <label>S1 File</label>
      <caption>
        <p>(PDF)</p>
      </caption>
      <media xlink:href="pone.0270696.s001.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ack>
    <p>We thank Karine Lacourse for expert advice on spindle detection, and the MODA team for database access. <xref rid="pone.0270696.g001" ref-type="fig">Fig 1</xref> uses icons from <ext-link xlink:href="https://flaticon.com" ext-link-type="uri">https://flaticon.com</ext-link>.</p>
  </ack>
  <ref-list>
    <title>References</title>
    <ref id="pone.0270696.ref001">
      <label>1</label>
      <mixed-citation publication-type="journal"><name><surname>Ngo</surname><given-names>HVV</given-names></name>, <name><surname>Martinetz</surname><given-names>T</given-names></name>, <name><surname>Born</surname><given-names>J</given-names></name>, <name><surname>Mölle</surname><given-names>M</given-names></name>. <article-title>Auditory Closed-Loop Stimulation of the Sleep Slow Oscillation Enhances Memory</article-title>. <source>Neuron</source>. <year>2013</year>;<volume>78</volume>(<issue>3</issue>):<fpage>545</fpage>–<lpage>553</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.neuron.2013.03.006</pub-id><?supplied-pmid 23583623?><pub-id pub-id-type="pmid">23583623</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0270696.ref002">
      <label>2</label>
      <mixed-citation publication-type="other">Ha U, Yoo HJ. A Multimodal Drowsiness Monitoring Ear-Module System with Closed-Loop Real-Time Alarm. In: 2016 IEEE Biomedical Circuits and Systems Conference (BioCAS); 2016. p. 536–539.</mixed-citation>
    </ref>
    <ref id="pone.0270696.ref003">
      <label>3</label>
      <mixed-citation publication-type="other">von Lühmann A, Addesa J, Chandra S, Das A, Hayashibe M, Dutta A. Neural Interfacing Non-Invasive Brain Stimulation with NIRS-EEG Joint Imaging for Closed-Loop Control of Neuroenergetics in Ischemic Stroke. In: 2017 8th International IEEE/EMBS Conference on Neural Engineering (NER); 2017. p. 349–353.</mixed-citation>
    </ref>
    <ref id="pone.0270696.ref004">
      <label>4</label>
      <mixed-citation publication-type="journal"><name><surname>Kosmyna</surname><given-names>N</given-names></name>, <name><surname>Maes</surname><given-names>P</given-names></name>. <article-title>Attentivu: An EEG-Based Closed-Loop Biofeedback System for Real-Time Monitoring and Improvement of Engagement for Personalized Learning</article-title>. <source>Sensors</source>. <year>2019</year>;<volume>19</volume>(<issue>23</issue>). <comment>doi: </comment><pub-id pub-id-type="doi">10.3390/s19235200</pub-id><?supplied-pmid 31783646?><pub-id pub-id-type="pmid">31783646</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0270696.ref005">
      <label>5</label>
      <mixed-citation publication-type="book"><name><surname>Zarubin</surname><given-names>G</given-names></name>, <name><surname>Gundlach</surname><given-names>C</given-names></name>, <name><surname>Nikulin</surname><given-names>V</given-names></name>, <name><surname>Bogdan</surname><given-names>M</given-names></name>. <article-title>Real-Time Phase Detection for EEG-Based tACS Closed-Loop System</article-title>. In: <source>6th International Congress on Neurotechnology, Electronics and Informatics</source>. <publisher-loc>Seville, Spain</publisher-loc>; <year>2018</year>. p. <fpage>13</fpage>–<lpage>20</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.5220/0006927300130020</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0270696.ref006">
      <label>6</label>
      <mixed-citation publication-type="journal"><name><surname>Shirinpour</surname><given-names>S</given-names></name>, <name><surname>Alekseichuk</surname><given-names>I</given-names></name>, <name><surname>Mantell</surname><given-names>K</given-names></name>, <name><surname>Opitz</surname><given-names>A</given-names></name>. <article-title>Experimental Evaluation of Methods for Real-Time EEG Phase-Specific Transcranial Magnetic Stimulation</article-title>. <source>J Neural Engineering</source>. <year>2020</year>;<volume>17</volume>(<issue>4</issue>). <comment>doi: </comment><pub-id pub-id-type="doi">10.1088/1741-2552/ab9dba</pub-id><?supplied-pmid 32554882?><pub-id pub-id-type="pmid">32554882</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0270696.ref007">
      <label>7</label>
      <mixed-citation publication-type="journal"><name><surname>Zrenner</surname><given-names>C</given-names></name>, <name><surname>Belardinelli</surname><given-names>P</given-names></name>, <name><surname>Müller-Dahlhaus</surname><given-names>F</given-names></name>, <name><surname>Ziemann</surname><given-names>U</given-names></name>. <article-title>Closed-loop neuroscience and non-invasive brain stimulation: a tale of two loops</article-title>. <source>Frontiers in cellular neuroscience</source>. <year>2016</year>;<volume>10</volume>:<fpage>92</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.3389/fncel.2016.00092</pub-id><?supplied-pmid 27092055?><pub-id pub-id-type="pmid">27092055</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0270696.ref008">
      <label>8</label>
      <mixed-citation publication-type="journal"><name><surname>Vassileva</surname><given-names>A</given-names></name>, <name><surname>van Blooijs</surname><given-names>D</given-names></name>, <name><surname>Leijten</surname><given-names>F</given-names></name>, <name><surname>Huiskamp</surname><given-names>G</given-names></name>. <article-title>Neocortical electrical stimulation for epilepsy: Closed-loop versus open-loop</article-title>. <source>Epilepsy research</source>. <year>2018</year>;<volume>141</volume>:<fpage>95</fpage>–<lpage>101</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.eplepsyres.2018.02.010</pub-id><?supplied-pmid 29547789?><pub-id pub-id-type="pmid">29547789</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0270696.ref009">
      <label>9</label>
      <mixed-citation publication-type="book"><name><surname>Zotou</surname><given-names>S</given-names></name>, <name><surname>Kostopoulos</surname><given-names>GK</given-names></name>, <name><surname>Antonakopoulos</surname><given-names>TA</given-names></name>. <part-title>Real-Time Spindles Detection for Acoustic Neurofeedback</part-title>. In: <name><surname>Frasson</surname><given-names>C</given-names></name>, <name><surname>Kostopoulos</surname><given-names>G</given-names></name>, editors. <source>Brain Function Assessment in Learning. Lecture Notes in Computer Science</source>. <publisher-loc>Cham</publisher-loc>: <publisher-name>Springer International Publishing</publisher-name>; <year>2017</year>. p. <fpage>159</fpage>–<lpage>168</lpage>.</mixed-citation>
    </ref>
    <ref id="pone.0270696.ref010">
      <label>10</label>
      <mixed-citation publication-type="journal"><name><surname>Ngo</surname><given-names>HVV</given-names></name>, <name><surname>Seibold</surname><given-names>M</given-names></name>, <name><surname>Boche</surname><given-names>DC</given-names></name>, <name><surname>Mölle</surname><given-names>M</given-names></name>, <name><surname>Born</surname><given-names>J</given-names></name>. <article-title>Insights on Auditory Closed-Loop Stimulation Targeting Sleep Spindles in Slow Oscillation up-States</article-title>. <source>Journal of Neuroscience Methods</source>. <year>2019</year>;<volume>316</volume>:<fpage>117</fpage>–<lpage>124</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.jneumeth.2018.09.006</pub-id><?supplied-pmid 30194953?><pub-id pub-id-type="pmid">30194953</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0270696.ref011">
      <label>11</label>
      <mixed-citation publication-type="journal"><name><surname>Chen</surname><given-names>LL</given-names></name>, <name><surname>Madhavan</surname><given-names>R</given-names></name>, <name><surname>Rapoport</surname><given-names>BI</given-names></name>, <name><surname>Anderson</surname><given-names>WS</given-names></name>. <article-title>Real-Time Brain Oscillation Detection and Phase-Locked Stimulation Using Autoregressive Spectral Estimation and Time-Series Forward Prediction</article-title>. <source>IEEE Trans on Biomed Eng</source>. <year>2013</year>;<volume>60</volume>(<issue>3</issue>):<fpage>753</fpage>–<lpage>762</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1109/TBME.2011.2109715</pub-id><?supplied-pmid 21292589?><pub-id pub-id-type="pmid">21292589</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0270696.ref012">
      <label>12</label>
      <mixed-citation publication-type="journal"><name><surname>Fehér</surname><given-names>KD</given-names></name>, <name><surname>Wunderlin</surname><given-names>M</given-names></name>, <name><surname>Maier</surname><given-names>JG</given-names></name>, <name><surname>Hertenstein</surname><given-names>E</given-names></name>, <name><surname>Schneider</surname><given-names>C</given-names></name>, <name><surname>Mikutta</surname><given-names>C</given-names></name>, <etal>et al</etal>. <article-title>Shaping the slow waves of sleep: A systematic and integrative review of sleep slow wave modulation in humans using non-invasive brain stimulation</article-title>. <source>Sleep medicine reviews</source>. <year>2021</year>; p. <fpage>101438</fpage>. <?supplied-pmid 33582581?><pub-id pub-id-type="pmid">33582581</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0270696.ref013">
      <label>13</label>
      <mixed-citation publication-type="journal"><name><surname>Salfi</surname><given-names>F</given-names></name>, <name><surname>D’Atri</surname><given-names>A</given-names></name>, <name><surname>Tempesta</surname><given-names>D</given-names></name>, <name><surname>De Gennaro</surname><given-names>L</given-names></name>, <name><surname>Ferrara</surname><given-names>M</given-names></name>. <article-title>Boosting Slow Oscillations during Sleep to Improve Memory Function in Elderly People: A Review of the Literature</article-title>. <source>Brain Sciences</source>. <year>2020</year>;<volume>10</volume>(<issue>5</issue>):<fpage>300</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.3390/brainsci10050300</pub-id><?supplied-pmid 32429181?><pub-id pub-id-type="pmid">32429181</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0270696.ref014">
      <label>14</label>
      <mixed-citation publication-type="journal"><name><surname>Harrington</surname><given-names>MO</given-names></name>, <name><surname>Cairney</surname><given-names>SA</given-names></name>. <article-title>Sounding it out: auditory stimulation and overnight memory processing</article-title>. <source>Current Sleep Medicine Reports</source>. <year>2021</year>;. <comment>doi: </comment><pub-id pub-id-type="doi">10.1007/s40675-021-00207-0</pub-id><?supplied-pmid 34722123?><pub-id pub-id-type="pmid">34722123</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0270696.ref015">
      <label>15</label>
      <mixed-citation publication-type="journal"><name><surname>Choi</surname><given-names>J</given-names></name>, <name><surname>Kwon</surname><given-names>M</given-names></name>, <name><surname>Jun</surname><given-names>SC</given-names></name>. <article-title>A systematic review of closed-loop feedback techniques in sleep studies—related issues and future directions</article-title>. <source>Sensors</source>. <year>2020</year>;<volume>20</volume>(<issue>10</issue>):<fpage>2770</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.3390/s20102770</pub-id><?supplied-pmid 32414060?><pub-id pub-id-type="pmid">32414060</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0270696.ref016">
      <label>16</label>
      <mixed-citation publication-type="journal"><name><surname>Xu</surname><given-names>R</given-names></name>, <name><surname>Jiang</surname><given-names>N</given-names></name>, <name><surname>Lin</surname><given-names>C</given-names></name>, <name><surname>Mrachacz-Kersting</surname><given-names>N</given-names></name>, <name><surname>Dremstrup</surname><given-names>K</given-names></name>, <name><surname>Farina</surname><given-names>D</given-names></name>. <article-title>Enhanced Low-Latency Detection of Motor Intention from EEG for Closed-Loop Brain-Computer Interface Applications</article-title>. <source>IEEE Transactions on Biomedical Engineering</source>. <year>2014</year>;<volume>61</volume>(<issue>2</issue>):<fpage>288</fpage>–<lpage>296</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1109/TBME.2013.2294203</pub-id><?supplied-pmid 24448593?><pub-id pub-id-type="pmid">24448593</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0270696.ref017">
      <label>17</label>
      <mixed-citation publication-type="journal"><name><surname>McCrimmon</surname><given-names>CM</given-names></name>, <name><surname>Fu</surname><given-names>JL</given-names></name>, <name><surname>Wang</surname><given-names>M</given-names></name>, <name><surname>Lopes</surname><given-names>LS</given-names></name>, <name><surname>Wang</surname><given-names>PT</given-names></name>, <name><surname>Karimi-Bidhendi</surname><given-names>A</given-names></name>, <etal>et al</etal>. <article-title>Performance Assessment of a Custom, Portable, and Low-Cost Brain-Computer Interface Platform</article-title>. <source>IEEE Transactions on Biomedical Engineering</source>. <year>2017</year>;<volume>64</volume>(<issue>10</issue>):<fpage>2313</fpage>–<lpage>2320</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1109/TBME.2017.2667579</pub-id><?supplied-pmid 28207382?><pub-id pub-id-type="pmid">28207382</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0270696.ref018">
      <label>18</label>
      <mixed-citation publication-type="journal"><name><surname>Albouy</surname><given-names>P</given-names></name>, <name><surname>Weiss</surname><given-names>A</given-names></name>, <name><surname>Baillet</surname><given-names>S</given-names></name>, <name><surname>Zatorre</surname><given-names>RJ</given-names></name>. <article-title>Selective entrainment of theta oscillations in the dorsal stream causally enhances auditory working memory performance</article-title>. <source>Neuron</source>. <year>2017</year>;<volume>94</volume>(<issue>1</issue>):<fpage>193</fpage>–<lpage>206</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.neuron.2017.03.015</pub-id><?supplied-pmid 28343866?><pub-id pub-id-type="pmid">28343866</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0270696.ref019">
      <label>19</label>
      <mixed-citation publication-type="book"><name><surname>Bergmann</surname><given-names>TO</given-names></name>, <name><surname>Staresina</surname><given-names>BP</given-names></name>. <part-title>Neuronal oscillations and reactivation subserving memory consolidation</part-title>. In: <source>Cognitive neuroscience of memory consolidation</source>. <publisher-name>Springer</publisher-name>; <year>2017</year>. p. <fpage>185</fpage>–<lpage>207</lpage>.</mixed-citation>
    </ref>
    <ref id="pone.0270696.ref020">
      <label>20</label>
      <mixed-citation publication-type="journal"><name><surname>Rasch</surname><given-names>B</given-names></name>, <name><surname>Born</surname><given-names>J</given-names></name>. <article-title>About sleep’s role in memory</article-title>. <source>Physiological reviews</source>. <year>2013</year>;. <comment>doi: </comment><pub-id pub-id-type="doi">10.1152/physrev.00032.2012</pub-id><?supplied-pmid 23589831?><pub-id pub-id-type="pmid">23589831</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0270696.ref021">
      <label>21</label>
      <mixed-citation publication-type="journal"><name><surname>Fogel</surname><given-names>SM</given-names></name>, <name><surname>Smith</surname><given-names>CT</given-names></name>. <article-title>Learning-dependent changes in sleep spindles and Stage 2 sleep</article-title>. <source>Journal of sleep research</source>. <year>2006</year>;<volume>15</volume>(<issue>3</issue>):<fpage>250</fpage>–<lpage>255</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1111/j.1365-2869.2006.00522.x</pub-id><?supplied-pmid 16911026?><pub-id pub-id-type="pmid">16911026</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0270696.ref022">
      <label>22</label>
      <mixed-citation publication-type="journal"><name><surname>Lafortune</surname><given-names>M</given-names></name>, <name><surname>Gagnon</surname><given-names>JF</given-names></name>, <name><surname>Martin</surname><given-names>N</given-names></name>, <name><surname>Latreille</surname><given-names>V</given-names></name>, <name><surname>Dubé</surname><given-names>J</given-names></name>, <name><surname>Bouchard</surname><given-names>M</given-names></name>, <etal>et al</etal>. <article-title>Sleep spindles and rapid eye movement sleep as predictors of next morning cognitive performance in healthy middle-aged and older participants</article-title>. <source>Journal of sleep research</source>. <year>2014</year>;<volume>23</volume>(<issue>2</issue>):<fpage>159</fpage>–<lpage>167</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1111/jsr.12108</pub-id><?supplied-pmid 24245769?><pub-id pub-id-type="pmid">24245769</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0270696.ref023">
      <label>23</label>
      <mixed-citation publication-type="journal"><name><surname>Fogel</surname><given-names>S</given-names></name>, <name><surname>Vien</surname><given-names>C</given-names></name>, <name><surname>Karni</surname><given-names>A</given-names></name>, <name><surname>Benali</surname><given-names>H</given-names></name>, <name><surname>Carrier</surname><given-names>J</given-names></name>, <name><surname>Doyon</surname><given-names>J</given-names></name>. <article-title>Sleep spindles: a physiological marker of age-related changes in gray matter in brain regions supporting motor skill memory consolidation</article-title>. <source>Neurobiology of aging</source>. <year>2017</year>;<volume>49</volume>:<fpage>154</fpage>–<lpage>164</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.neurobiolaging.2016.10.009</pub-id><?supplied-pmid 27815989?><pub-id pub-id-type="pmid">27815989</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0270696.ref024">
      <label>24</label>
      <mixed-citation publication-type="journal"><name><surname>Fernandez</surname><given-names>LMJ</given-names></name>, <name><surname>Lüthi</surname><given-names>A</given-names></name>. <article-title>Sleep Spindles: Mechanisms and Functions</article-title>. <source>Physiological Reviews</source>. <year>2020</year>;<volume>100</volume>(<issue>2</issue>):<fpage>805</fpage>–<lpage>868</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1152/physrev.00042.2018</pub-id><?supplied-pmid 31804897?><pub-id pub-id-type="pmid">31804897</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0270696.ref025">
      <label>25</label>
      <mixed-citation publication-type="journal"><name><surname>Peters</surname><given-names>KR</given-names></name>, <name><surname>Ray</surname><given-names>LB</given-names></name>, <name><surname>Fogel</surname><given-names>S</given-names></name>, <name><surname>Smith</surname><given-names>V</given-names></name>, <name><surname>Smith</surname><given-names>CT</given-names></name>. <article-title>Age differences in the variability and distribution of sleep spindle and rapid eye movement densities</article-title>. <source>PloS one</source>. <year>2014</year>;<volume>9</volume>(<issue>3</issue>):<fpage>e91047</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1371/journal.pone.0091047</pub-id><?supplied-pmid 24599302?><pub-id pub-id-type="pmid">24599302</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0270696.ref026">
      <label>26</label>
      <mixed-citation publication-type="journal"><name><surname>Purcell</surname><given-names>S</given-names></name>, <name><surname>Manoach</surname><given-names>D</given-names></name>, <name><surname>Demanuele</surname><given-names>C</given-names></name>, <name><surname>Cade</surname><given-names>B</given-names></name>, <name><surname>Mariani</surname><given-names>S</given-names></name>, <name><surname>Cox</surname><given-names>R</given-names></name>, <etal>et al</etal>. <article-title>Characterizing sleep spindles in 11,630 individuals from the National Sleep Research Resource</article-title>. <source>Nature communications</source>. <year>2017</year>;<volume>8</volume>(<issue>1</issue>):<fpage>1</fpage>–<lpage>16</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/ncomms15930</pub-id><?supplied-pmid 28649997?><pub-id pub-id-type="pmid">28649997</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0270696.ref027">
      <label>27</label>
      <mixed-citation publication-type="journal"><name><surname>Lacourse</surname><given-names>K</given-names></name>, <name><surname>Delfrate</surname><given-names>J</given-names></name>, <name><surname>Beaudry</surname><given-names>J</given-names></name>, <name><surname>Peppard</surname><given-names>P</given-names></name>, <name><surname>Warby</surname><given-names>SC</given-names></name>. <article-title>A Sleep Spindle Detection Algorithm That Emulates Human Expert Spindle Scoring</article-title>. <source>J Neuroscience Methods</source>. <year>2019</year>;<volume>316</volume>:<fpage>3</fpage>–<lpage>11</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.jneumeth.2018.08.014</pub-id><?supplied-pmid 30107208?><pub-id pub-id-type="pmid">30107208</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0270696.ref028">
      <label>28</label>
      <mixed-citation publication-type="journal"><name><surname>Lacourse</surname><given-names>K</given-names></name>, <name><surname>Yetton</surname><given-names>B</given-names></name>, <name><surname>Mednick</surname><given-names>S</given-names></name>, <name><surname>Warby</surname><given-names>SC</given-names></name>. <article-title>Massive Online Data Annotation, Crowdsourcing to Generate High Quality Sleep Spindle Annotations from EEG Data</article-title>. <source>Sci Data</source>. <year>2020</year>;<volume>7</volume>(<issue>1</issue>):<fpage>190</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/s41597-020-0533-4</pub-id><?supplied-pmid 32561751?><pub-id pub-id-type="pmid">32561751</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0270696.ref029">
      <label>29</label>
      <mixed-citation publication-type="journal"><name><surname>Kulkarni</surname><given-names>PM</given-names></name>, <name><surname>Xiao</surname><given-names>Z</given-names></name>, <name><surname>Robinson</surname><given-names>EJ</given-names></name>, <name><surname>Jami</surname><given-names>AS</given-names></name>, <name><surname>Zhang</surname><given-names>J</given-names></name>, <name><surname>Zhou</surname><given-names>H</given-names></name>, <etal>et al</etal>. <article-title>A Deep Learning Approach for Real-Time Detection of Sleep Spindles</article-title>. <source>J Neural Eng</source>. <year>2019</year>;<volume>16</volume>(<issue>3</issue>):<fpage>036004</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1088/1741-2552/ab0933</pub-id><?supplied-pmid 30790769?><pub-id pub-id-type="pmid">30790769</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0270696.ref030">
      <label>30</label>
      <mixed-citation publication-type="journal"><name><surname>Tapia</surname><given-names>NI</given-names></name>, <name><surname>Estévez</surname><given-names>PA</given-names></name>. <article-title>RED: Deep Recurrent Neural Networks for Sleep EEG Event Detection</article-title>. <source>arXiv:200507795</source>. <year>2020</year>;.</mixed-citation>
    </ref>
    <ref id="pone.0270696.ref031">
      <label>31</label>
      <mixed-citation publication-type="journal"><name><surname>O’Reilly</surname><given-names>C</given-names></name>, <name><surname>Gosselin</surname><given-names>N</given-names></name>, <name><surname>Carrier</surname><given-names>J</given-names></name>, <name><surname>Nielsen</surname><given-names>T</given-names></name>. <article-title>Montreal Archive of Sleep Studies: An Open-Access Resource for Instrument Benchmarking and Exploratory Research</article-title>. <source>Journal of Sleep Research</source>. <year>2014</year>;<volume>23</volume>(<issue>6</issue>):<fpage>628</fpage>–<lpage>635</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1111/jsr.12169</pub-id><?supplied-pmid 24909981?><pub-id pub-id-type="pmid">24909981</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0270696.ref032">
      <label>32</label>
      <mixed-citation publication-type="journal"><name><surname>Ferrarelli</surname><given-names>F</given-names></name>, <name><surname>Huber</surname><given-names>R</given-names></name>, <name><surname>Peterson</surname><given-names>MJ</given-names></name>, <name><surname>Massimini</surname><given-names>M</given-names></name>, <name><surname>Murphy</surname><given-names>M</given-names></name>, <name><surname>Riedner</surname><given-names>BA</given-names></name>, <etal>et al</etal>. <article-title>Reduced Sleep Spindle Activity in Schizophrenia Patients</article-title>. <source>AJP</source>. <year>2007</year>;<volume>164</volume>(<issue>3</issue>):<fpage>483</fpage>–<lpage>492</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1176/ajp.2007.164.3.483</pub-id><?supplied-pmid 17329474?><pub-id pub-id-type="pmid">17329474</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0270696.ref033">
      <label>33</label>
      <mixed-citation publication-type="journal"><name><surname>Mölle</surname><given-names>M</given-names></name>, <name><surname>Marshall</surname><given-names>L</given-names></name>, <name><surname>Gais</surname><given-names>S</given-names></name>, <name><surname>Born</surname><given-names>J</given-names></name>. <article-title>Grouping of Spindle Activity during Slow Oscillations in Human Non-Rapid Eye Movement Sleep</article-title>. <source>J Neurosci</source>. <year>2002</year>;<volume>22</volume>(<issue>24</issue>):<fpage>10941</fpage>–<lpage>10947</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1523/JNEUROSCI.22-24-10941.2002</pub-id><?supplied-pmid 12486189?><pub-id pub-id-type="pmid">12486189</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0270696.ref034">
      <label>34</label>
      <mixed-citation publication-type="journal"><name><surname>Martin</surname><given-names>N</given-names></name>, <name><surname>Lafortune</surname><given-names>M</given-names></name>, <name><surname>Godbout</surname><given-names>J</given-names></name>, <name><surname>Barakat</surname><given-names>M</given-names></name>, <name><surname>Robillard</surname><given-names>R</given-names></name>, <name><surname>Poirier</surname><given-names>G</given-names></name>, <etal>et al</etal>. <article-title>Topography of Age-Related Changes in Sleep Spindles</article-title>. <source>Neurobiology of Aging</source>. <year>2013</year>;<volume>34</volume>(<issue>2</issue>):<fpage>468</fpage>–<lpage>476</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.neurobiolaging.2012.05.020</pub-id><?supplied-pmid 22809452?><pub-id pub-id-type="pmid">22809452</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0270696.ref035">
      <label>35</label>
      <mixed-citation publication-type="journal"><name><surname>Wamsley</surname><given-names>EJ</given-names></name>, <name><surname>Tucker</surname><given-names>MA</given-names></name>, <name><surname>Shinn</surname><given-names>AK</given-names></name>, <name><surname>Ono</surname><given-names>KE</given-names></name>, <name><surname>McKinley</surname><given-names>SK</given-names></name>, <name><surname>Ely</surname><given-names>AV</given-names></name>, <etal>et al</etal>. <article-title>Reduced Sleep Spindles and Spindle Coherence in Schizophrenia: Mechanisms of Impaired Memory Consolidation?</article-title><source>Biological Psychiatry</source>. <year>2012</year>;<volume>71</volume>(<issue>2</issue>):<fpage>154</fpage>–<lpage>161</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.biopsych.2011.08.008</pub-id><?supplied-pmid 21967958?><pub-id pub-id-type="pmid">21967958</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0270696.ref036">
      <label>36</label>
      <mixed-citation publication-type="journal"><name><surname>Ray</surname><given-names>L</given-names></name>, <name><surname>Sockeel</surname><given-names>S</given-names></name>, <name><surname>Soon</surname><given-names>M</given-names></name>, <name><surname>Bore</surname><given-names>A</given-names></name>, <name><surname>Myhr</surname><given-names>A</given-names></name>, <name><surname>Stojanoski</surname><given-names>B</given-names></name>, <etal>et al</etal>. <article-title>Expert and Crowd-Sourced Validation of an Individualized Sleep Spindle Detection Method Employing Complex Demodulation and Individualized Normalization</article-title>. <source>Front Hum Neurosci</source>. <year>2015</year>;<volume>9</volume>. <comment>doi: </comment><pub-id pub-id-type="doi">10.3389/fnhum.2015.00507</pub-id><?supplied-pmid 26441604?><pub-id pub-id-type="pmid">26441604</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0270696.ref037">
      <label>37</label>
      <mixed-citation publication-type="journal"><name><surname>Parekh</surname><given-names>A</given-names></name>, <name><surname>Selesnick</surname><given-names>IW</given-names></name>, <name><surname>Rapoport</surname><given-names>DM</given-names></name>, <name><surname>Ayappa</surname><given-names>I</given-names></name>. <article-title>Detection of K-Complexes and Sleep Spindles (DETOKS) Using Sparse Optimization</article-title>. <source>Journal of Neuroscience Methods</source>. <year>2015</year>;<volume>251</volume>:<fpage>37</fpage>–<lpage>46</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.jneumeth.2015.04.006</pub-id><?supplied-pmid 25956566?><pub-id pub-id-type="pmid">25956566</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0270696.ref038">
      <label>38</label>
      <mixed-citation publication-type="book"><name><surname>Yasuhara</surname><given-names>N</given-names></name>, <name><surname>Natori</surname><given-names>T</given-names></name>, <name><surname>Hayashi</surname><given-names>M</given-names></name>, <name><surname>Aikawa</surname><given-names>N</given-names></name>. <part-title>A Study on Automatic Detection of Sleep Spindles Using a Long Short-Term Memory Network</part-title>. In: <source>2019 IEEE 62nd International Midwest Symposium on Circuits and Systems (MWSCAS)</source>; <year>2019</year>. p. <fpage>45</fpage>–<lpage>48</lpage>.</mixed-citation>
    </ref>
    <ref id="pone.0270696.ref039">
      <label>39</label>
      <mixed-citation publication-type="book"><name><surname>Tan</surname><given-names>D</given-names></name>, <name><surname>Zhao</surname><given-names>R</given-names></name>, <name><surname>Sun</surname><given-names>J</given-names></name>, <name><surname>Qin</surname><given-names>W</given-names></name>. <part-title>Sleep Spindle Detection Using Deep Learning: A Validation Study Based on Crowdsourcing</part-title>. In: <source>37th IEEE Engineering in Medicine and Biology Conference (EMBC)</source>; <year>2015</year>. p. <fpage>2828</fpage>–<lpage>2831</lpage>.</mixed-citation>
    </ref>
    <ref id="pone.0270696.ref040">
      <label>40</label>
      <mixed-citation publication-type="book"><name><surname>Vaswani</surname><given-names>A</given-names></name>, <name><surname>Shazeer</surname><given-names>N</given-names></name>, <name><surname>Parmar</surname><given-names>N</given-names></name>, <name><surname>Uszkoreit</surname><given-names>J</given-names></name>, <name><surname>Jones</surname><given-names>L</given-names></name>, <name><surname>Gomez</surname><given-names>AN</given-names></name>, <etal>et al</etal>. <part-title>Attention is all you need</part-title>. In: <source>Advances in neural information processing systems</source>; <year>2017</year>. p. <fpage>5998</fpage>–<lpage>6008</lpage>.</mixed-citation>
    </ref>
    <ref id="pone.0270696.ref041">
      <label>41</label>
      <mixed-citation publication-type="journal"><name><surname>Chang</surname><given-names>S</given-names></name>, <name><surname>Zhang</surname><given-names>Y</given-names></name>, <name><surname>Han</surname><given-names>W</given-names></name>, <name><surname>Yu</surname><given-names>M</given-names></name>, <name><surname>Guo</surname><given-names>X</given-names></name>, <name><surname>Tan</surname><given-names>W</given-names></name>, <etal>et al</etal>. <article-title>Dilated recurrent neural networks</article-title>. <source>arXiv preprint arXiv:171002224</source>. <year>2017</year>;.</mixed-citation>
    </ref>
    <ref id="pone.0270696.ref042">
      <label>42</label>
      <mixed-citation publication-type="journal"><name><surname>Yang</surname><given-names>Y</given-names></name>, <name><surname>Zha</surname><given-names>K</given-names></name>, <name><surname>Chen</surname><given-names>YC</given-names></name>, <name><surname>Wang</surname><given-names>H</given-names></name>, <name><surname>Katabi</surname><given-names>D</given-names></name>. <article-title>Delving into Deep Imbalanced Regression</article-title>. <source>arXiv preprint arXiv:210209554</source>. <year>2021</year>;.</mixed-citation>
    </ref>
    <ref id="pone.0270696.ref043">
      <label>43</label>
      <mixed-citation publication-type="book"><name><surname>Iber</surname><given-names>C</given-names></name>, <name><surname>Ancoli-Israel</surname><given-names>S</given-names></name>, <name><surname>Chesson</surname><given-names>AL</given-names></name>, <name><surname>Quan</surname><given-names>SF</given-names></name>, <etal>et al</etal>. <source>The AASM manual for the scoring of sleep and associated events: rules, terminology and technical specifications</source>. <volume>vol. 1</volume>. <publisher-name>American academy of sleep medicine Westchester, IL</publisher-name>; <year>2007</year>.</mixed-citation>
    </ref>
    <ref id="pone.0270696.ref044">
      <label>44</label>
      <mixed-citation publication-type="other">Sundararajan M, Taly A, Yan Q. Axiomatic attribution for deep networks. In: International Conference on Machine Learning. PMLR; 2017. p. 3319–3328.</mixed-citation>
    </ref>
    <ref id="pone.0270696.ref045">
      <label>45</label>
      <mixed-citation publication-type="other">Tobin J, Fong R, Ray A, Schneider J, Zaremba W, Abbeel P. Domain randomization for transferring deep neural networks from simulation to the real world. In: International conference on intelligent robots and systems (IROS). IEEE; 2017. p. 23–30.</mixed-citation>
    </ref>
  </ref-list>
</back>
<sub-article article-type="aggregated-review-documents" id="pone.0270696.r001" specific-use="decision-letter">
  <front-stub>
    <article-id pub-id-type="doi">10.1371/journal.pone.0270696.r001</article-id>
    <title-group>
      <article-title>Decision Letter 0</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Cymbalyuk</surname>
          <given-names>Gennady S.</given-names>
        </name>
        <role>Academic Editor</role>
      </contrib>
    </contrib-group>
    <permissions>
      <copyright-statement>© 2022 Gennady S. Cymbalyuk</copyright-statement>
      <copyright-year>2022</copyright-year>
      <copyright-holder>Gennady S. Cymbalyuk</copyright-holder>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
      </license>
    </permissions>
    <related-article ext-link-type="doi" xlink:href="10.1371/journal.pone.0270696" id="rel-obj001" related-article-type="reviewed-article"/>
    <custom-meta-group>
      <custom-meta>
        <meta-name>Submission Version</meta-name>
        <meta-value>0</meta-value>
      </custom-meta>
    </custom-meta-group>
  </front-stub>
  <body>
    <p>
      <named-content content-type="letter-date">3 Jan 2022</named-content>
    </p>
    <p><!-- <div> -->PONE-D-21-32222<!-- </div> --><!-- <div> -->The Portiloop: a deep learning-based open science tool for closed-loop brain stimulation<!-- </div> --><!-- <div> -->PLOS ONE</p>
    <p>Dear Dr. Bouteiller,</p>
    <p>Thank you for submitting your manuscript to PLOS ONE. After careful consideration, we feel that it has merit but does not fully meet PLOS ONE’s publication criteria as it currently stands. Therefore, we invite you to submit a revised version of the manuscript that addresses the points raised during the review process.</p>
    <p>Please, revise manuscript for clarity, you are requested to do substantial restructuring and shortening of the manuscript. Please, clearly describe  the goal and methods of the study, and provide the details of the design and data analysis.</p>
    <p>For datasharing, please, use a scientific repository (e.g. Figshare, Harvard Dataverse,...)</p>
    <p>More than half the figures (Figures 1, 3-7, 9) only highlight processes and methods. The rest of the figures cannot be interpreted without the main text. Therefore, the scope of analyses and presentation of the results required significant improvement.</p>
    <p>Consider concatenating figures to reduce the number of figures.</p>
    <p>The potential for a toolbox is evident, but such a toolbox’s utility and functionality are not demonstrated, but rather implied. The prototypical toolbox distracts from the analyses.</p>
    <p>How could someone get one of these devices? Are readers expected to be able to build them, following your instruction (in which case the instruction would have to be much more detailed)?</p>
    <p>It would be nice to see a picture of the device and how it can be used in the lab environment.</p>
    <p>Reduced ANNs for maximizing Recall and Precision are not developed or analyzed. No reduced ANN matched SpindleNet’s Recall (% true positives). Reduced ANNs all had superior Precision (% positives found). Why? Three reduced models strike a balance between Recall and Precision with f1 scores of 0.61, but no model variations achieved the performance of expert raters. Why? All the reduced models perform essentially the same.</p>
    <p>Minor comments: Table 1. Please spell out IExp, as this term / abbreviation is not used in the text. No stimulation is actually conducted in this study. Do the Authors mean actuate?</p>
    <p>Do not use a special symbol (infinity) in the title, this will be very difficult for indexing, search engines etc.</p>
    <p>Please submit your revised manuscript by Feb 17 2022 11:59PM. If you will need more time than this to complete your revisions, please reply to this message or contact the journal office at <email>plosone@plos.org</email>. When you're ready to submit your revision, log on to <ext-link xlink:href="https://www.editorialmanager.com/pone/" ext-link-type="uri">https://www.editorialmanager.com/pone/</ext-link> and select the 'Submissions Needing Revision' folder to locate your manuscript file.</p>
    <p>Please include the following items when submitting your revised manuscript:<!-- </div> --><list list-type="bullet"><list-item><p>A rebuttal letter that responds to each point raised by the academic editor and reviewer(s). You should upload this letter as a separate file labeled 'Response to Reviewers'.</p></list-item><list-item><p>A marked-up copy of your manuscript that highlights changes made to the original version. You should upload this as a separate file labeled 'Revised Manuscript with Track Changes'.</p></list-item><list-item><p>An unmarked version of your revised paper without tracked changes. You should upload this as a separate file labeled 'Manuscript'.</p></list-item></list></p>
    <p>If you would like to make changes to your financial disclosure, please include your updated statement in your cover letter. Guidelines for resubmitting your figure files are available below the reviewer comments at the end of this letter.</p>
    <p>If applicable, we recommend that you deposit your laboratory protocols in protocols.io to enhance the reproducibility of your results. Protocols.io assigns your protocol its own identifier (DOI) so that it can be cited independently in the future. For instructions see: <ext-link xlink:href="https://journals.plos.org/plosone/s/submission-guidelines#loc-laboratory-protocols" ext-link-type="uri">https://journals.plos.org/plosone/s/submission-guidelines#loc-laboratory-protocols</ext-link>. Additionally, PLOS ONE offers an option for publishing peer-reviewed Lab Protocol articles, which describe protocols hosted on protocols.io. Read more information on sharing protocols at <ext-link xlink:href="https://plos.org/protocols?utm_medium=editorial-email&amp;utm_source=authorletters&amp;utm_campaign=protocols" ext-link-type="uri">https://plos.org/protocols?utm_medium=editorial-email&amp;utm_source=authorletters&amp;utm_campaign=protocols</ext-link>.</p>
    <p>We look forward to receiving your revised manuscript.</p>
    <p>Kind regards,</p>
    <p>Gennady S. Cymbalyuk, Ph.D.</p>
    <p>Academic Editor</p>
    <p>PLOS ONE</p>
    <p>Journal Requirements:</p>
    <p>When submitting your revision, we need you to address these additional requirements.</p>
    <p>1. Please ensure that your manuscript meets PLOS ONE's style requirements, including those for file naming. The PLOS ONE style templates can be found at </p>
    <p><ext-link xlink:href="https://journals.plos.org/plosone/s/file?id=wjVg/PLOSOne_formatting_sample_main_body.pdf" ext-link-type="uri">https://journals.plos.org/plosone/s/file?id=wjVg/PLOSOne_formatting_sample_main_body.pdf</ext-link> and </p>
    <p>
      <ext-link xlink:href="https://journals.plos.org/plosone/s/file?id=ba62/PLOSOne_formatting_sample_title_authors_affiliations.pdf" ext-link-type="uri">https://journals.plos.org/plosone/s/file?id=ba62/PLOSOne_formatting_sample_title_authors_affiliations.pdf</ext-link>
    </p>
    <p>2. Please include captions for your Supporting Information files at the end of your manuscript, and update any in-text citations to match accordingly. Please see our Supporting Information guidelines for more information: <ext-link xlink:href="http://journals.plos.org/plosone/s/supporting-information. " ext-link-type="uri">http://journals.plos.org/plosone/s/supporting-information. </ext-link></p>
    <p>[Note: HTML markup is below. Please do not edit.]</p>
    <p>Reviewers' comments:</p>
    <p>Reviewer's Responses to Questions</p>
    <p>
      <!-- <font color="black"> -->
      <bold>Comments to the Author</bold>
    </p>
    <p>1. Is the manuscript technically sound, and do the data support the conclusions?</p>
    <p>The manuscript must describe a technically sound piece of scientific research with data that supports the conclusions. Experiments must have been conducted rigorously, with appropriate controls, replication, and sample sizes. The conclusions must be drawn appropriately based on the data presented. <!-- </font> --></p>
    <p>Reviewer #1: Partly</p>
    <p>Reviewer #2: No</p>
    <p>**********</p>
    <p><!-- <font color="black"> -->2. Has the statistical analysis been performed appropriately and rigorously? <!-- </font> --></p>
    <p>Reviewer #1: I Don't Know</p>
    <p>Reviewer #2: N/A</p>
    <p>**********</p>
    <p><!-- <font color="black"> -->3. Have the authors made all data underlying the findings in their manuscript fully available?</p>
    <p>The <ext-link xlink:href="http://www.plosone.org/static/policies.action#sharing" ext-link-type="uri">PLOS Data policy</ext-link> requires authors to make all data underlying the findings described in their manuscript fully available without restriction, with rare exception (please refer to the Data Availability Statement in the manuscript PDF file). The data should be provided as part of the manuscript or its supporting information, or deposited to a public repository. For example, in addition to summary statistics, the data points behind means, medians and variance measures should be available. If there are restrictions on publicly sharing data—e.g. participant privacy or use of data from a third party—those must be specified.<!-- </font> --></p>
    <p>Reviewer #1: Yes</p>
    <p>Reviewer #2: Yes</p>
    <p>**********</p>
    <p><!-- <font color="black"> -->4. Is the manuscript presented in an intelligible fashion and written in standard English?</p>
    <p>PLOS ONE does not copyedit accepted manuscripts, so the language in submitted articles must be clear, correct, and unambiguous. Any typographical or grammatical errors should be corrected at revision, so please note any specific errors here.<!-- </font> --></p>
    <p>Reviewer #1: No</p>
    <p>Reviewer #2: Yes</p>
    <p>**********</p>
    <p><!-- <font color="black"> -->5. Review Comments to the Author</p>
    <p>Please use the space provided to explain your answers to the questions above. You may also include additional comments for the author, including concerns about dual publication, research ethics, or publication ethics. (Please upload your review as an attachment if it exceeds 20,000 characters)<!-- </font> --></p>
    <p>Reviewer #1: This is a very long and non-stringent, yet potentially very interesting manuscript. I am not able to give an in-depth review at this point, since reading the manuscript is rather confusing, and it would probably take me several days to figure out everything that you are trying to say. I would advise you to do some substantial restructuring and shortening work, then I'll be happy to provide an in-depth review. For the moment, I have some mostly technical remarks:</p>
    <p>* I would not recommend to use a special symbol (infinity) in the title, this will be very difficult for indexing, search engines etc.</p>
    <p>* Also, it is not the gold standard to share data via a private Google Drive, have you considered using a scientific repository (e.g. Figshare, Harvard Dataverse,...)</p>
    <p>* If my computer is counting correctly, the word count is ~10,000, which is clearly too long for the manuscript to be read by most people, including myself.</p>
    <p>* This manuscript should not come with 13 figures. Since most of them contain very little information, consider concatenating them to three or four figures with several subplots.</p>
    <p>* It is unclear to me what exactly you are presenting in this paper - you say it's about a new device, but at the same time you talk a lot about machine learning and software benchmarking fundamentals, and sleep physiology, which in my humble opinion is just too much for one manuscript. Please try to be concise and have a clear focus for the manuscript. For example, the best ANN architecture for spindle detection is in principle independent of any hardware implementation, and could therefore be dealt with in a separate paper (or in the Supplementary Material, if you do not deem it worth of a separate paper).</p>
    <p>* Related to this: You open-sourced the software, but how could I get one of these devices if I wanted to? I may have missed it, but I found no information on this. Was it self-built by your lab or did you have an industry partner (which I don't assume since there is on conflict of interest declared). Can I buy it from you (in which case a COI would need to be declared), or am I expected to build it myself, following your instruction (in which case the instruction would have to be much more detailed)? Without at least mentioning any prospective way that I could get hold of one of these devices in the future, I'm not sure how useful a paper describing it will be.</p>
    <p>* by the way, it would be nice to see a picture of the device and how it can be used in the lab environment.</p>
    <p>* Related to this, I did not find any information about data storage for offline analysis, and how it would integrate with existing lab infrastructures (e.g. Labstreaminglayer).</p>
    <p>To sum up, I think closed-loop stimulation is a relevant field with a lack of well-functioning and easy-to-use devices. I would therefore highly appreciate if you could bring your paper into a more digestable shape, so that your work can receive its due appreciation.</p>
    <p>Reviewer #2: Summary:</p>
    <p>The Authors developed hardware that can implement Artificial Neural Networks (ANNs) for detecting sleep spindles using FPGAs. Design constraints were imposed to make the hardware lightweight and portable for potential application in close-loop stimulation studies. This study focuses on a deep-learning, open-source toolkit for model-driven design of the FPGA ANNs, Portiloop, using a public sleep dataset (MODA) for training and testing. Such a toolkit could be useful for studies on sleep and brain stimulation, but the results are lacking. I have three concerns.</p>
    <p>Concern 1 – The potential for a toolbox is evident, but such a toolbox’s utility and functionality are not demonstrated, but rather implied. The prototypical toolbox distracts from the analyses.</p>
    <p>Concern 2 – Reduced ANNs for maximizing Recall and Precision are not developed or analyzed. No reduced ANN matched SpindleNet’s Recall (% true positives). Reduced ANNs all had superior Precision (% positives found). Why? Three reduced models strike a balance between Recall and Precision with f1 scores of 0.61, but no model variations achieved the performance of expert raters. Why? All the reduced models perform essentially the same.</p>
    <p>Concern 3 – More than half the figures (Figures 1, 3-7, 9) only highlight processes and methods. The rest of the figures cannot be interpreted without the main text. Therefore, the scope of analyses and presentation of the results required significant improvement.</p>
    <p>Minor comments:</p>
    <p>Table 1. Please spell out IExp, as this term / abbreviation is not used in the text.</p>
    <p>No stimulation is actually conducted in this study. Do the Authors mean actuate?</p>
    <p>**********</p>
    <p><!-- <font color="black"> -->6. PLOS authors have the option to publish the peer review history of their article (<ext-link xlink:href="https://journals.plos.org/plosone/s/editorial-and-peer-review-process#loc-peer-review-history" ext-link-type="uri">what does this mean?</ext-link>). If published, this will include your full peer review and any attached files.</p>
    <p>If you choose “no”, your identity will remain anonymous but your review may still be made public.</p>
    <p><bold>Do you want your identity to be public for this peer review?</bold> For information about this choice, including consent withdrawal, please see our <ext-link xlink:href="https://www.plos.org/privacy-policy" ext-link-type="uri">Privacy Policy</ext-link>.<!-- </font> --></p>
    <p>Reviewer #1: <bold>Yes: </bold>Marius Keute</p>
    <p>Reviewer #2: No</p>
    <p>[NOTE: If reviewer comments were submitted as an attachment file, they will be attached to this email and accessible via the submission site. Please log into your account, locate the manuscript record, and check for the action link "View Attachments". If this link does not appear, there are no attachment files.]</p>
    <p>While revising your submission, please upload your figure files to the Preflight Analysis and Conversion Engine (PACE) digital diagnostic tool, <ext-link xlink:href="https://pacev2.apexcovantage.com/" ext-link-type="uri">https://pacev2.apexcovantage.com/</ext-link>. PACE helps ensure that figures meet PLOS requirements. To use PACE, you must first register as a user. Registration is free. Then, login and navigate to the UPLOAD tab, where you will find detailed instructions on how to use the tool. If you encounter any issues or have any questions when using PACE, please email PLOS at <email>figures@plos.org</email>. Please note that Supporting Information files do not need this step.</p>
  </body>
</sub-article>
<sub-article article-type="author-comment" id="pone.0270696.r002">
  <front-stub>
    <article-id pub-id-type="doi">10.1371/journal.pone.0270696.r002</article-id>
    <title-group>
      <article-title>Author response to Decision Letter 0</article-title>
    </title-group>
    <related-article ext-link-type="doi" xlink:href="10.1371/journal.pone.0270696" id="rel-obj002" related-article-type="editor-report"/>
    <custom-meta-group>
      <custom-meta>
        <meta-name>Submission Version</meta-name>
        <meta-value>1</meta-value>
      </custom-meta>
    </custom-meta-group>
  </front-stub>
  <body>
    <p>
      <named-content content-type="author-response-date">7 Mar 2022</named-content>
    </p>
    <p>Please see the attached PDF : Response to Reviewers.</p>
    <p>transcript:</p>
    <p>EDITOR:</p>
    <p>---</p>
    <p>Please, revise manuscript for clarity, you are re-</p>
    <p>quested to do substantial restructuring and short-</p>
    <p>ening of the manuscript.</p>
    <p>&gt;</p>
    <p>Thank you for your suggestions. We have significantly</p>
    <p>restructured the manuscript and have moved some de-</p>
    <p>tails to Supplementary Information (please see response</p>
    <p>to reviewers for specific changes). A challenge to our in-</p>
    <p>terdisciplinary (neuroscience-engineering) work is that</p>
    <p>the portion of collaborative projects that is not specific</p>
    <p>to a reader’s discipline can be difficult for them to evalu-</p>
    <p>ate and the details are perhaps less interesting to them.</p>
    <p>However, the two parts are integral to one another: the</p>
    <p>spindle detection application and its validation is not of</p>
    <p>interest in fundamental neuroscience separately, but are</p>
    <p>necessary for neuroscientists to support the device’s use</p>
    <p>and validity in all subsequent works using it. Conversely,</p>
    <p>the hardware and software designs are not conceptually</p>
    <p>groundbreaking in isolation, but rather their adaptation</p>
    <p>and combination in the service of fundamental science</p>
    <p>is. We believe that both portions are necessary to in-</p>
    <p>clude and in some level of detail, but have made the text</p>
    <p>more readable, and have clarified how the work can be</p>
    <p>useful to audiences with different foci early in the intro-</p>
    <p>duction.</p>
    <p>---</p>
    <p>Please, clearly describe the goal and methods of</p>
    <p>the study, and provide the details of the design</p>
    <p>and data analysis.</p>
    <p>&gt;</p>
    <p>We have described the goal and approach of the study</p>
    <p>more clearly in the Introduction and in the Abstract</p>
    <p>(e.g., from the Abstract: “In this article, we propose the</p>
    <p>Portiloop, a deep learning-based, portable and low-cost</p>
    <p>closed-loop stimulation system able to target specific</p>
    <p>brain oscillations. We first document open-hardware</p>
    <p>implementations that can be constructed from commer-</p>
    <p>cially available components. We also provide a fast,</p>
    <p>lightweight neural network and an exploration algorithm</p>
    <p>that automatically optimizes the network model to the</p>
    <p>desired brain oscillation. Finally, we validate the tech-</p>
    <p>nology on a challenging test case of real-time sleep spin-</p>
    <p>dle detection, with results comparable to off-line ex-</p>
    <p>pert performance.Software and plans are available to</p>
    <p>the community as an open science initiative to encour-</p>
    <p>age further development and advance closed-loop neu-</p>
    <p>roscience research”</p>
    <p>REVIEWER 1:</p>
    <p>---</p>
    <p>I would not recommend to use a special symbol</p>
    <p>(infinity) in the title, this will be very difficult for</p>
    <p>indexing, search engines etc</p>
    <p>&gt;</p>
    <p>The infinite sign has been replaced by normal charac-</p>
    <p>ters.</p>
    <p>---</p>
    <p>Also, it is not the gold standard to share data via</p>
    <p>a private Google Drive, have you considered us-</p>
    <p>ing a scientific repository (e.g. Figshare, Harvard</p>
    <p>Dataverse,...)</p>
    <p>&gt;</p>
    <p>Our dataset, models, and all our relevant code are now</p>
    <p>provided as part of the public Portiloop GitHub repos-</p>
    <p>itory for convenience (this enables e.g. running our</p>
    <p>trained neural network out-of-the box and visualizing</p>
    <p>results in an interactive fashion). The private Google</p>
    <p>Drive link has been removed</p>
    <p>---</p>
    <p>If my computer is counting correctly, the word</p>
    <p>count is 10,000, which is clearly too long for the</p>
    <p>manuscript to be read by most people, including</p>
    <p>myself.</p>
    <p>It is unclear to me what exactly you are present-</p>
    <p>ing in this paper - you say it’s about a new device,</p>
    <p>but at the same time you talk a lot about ma-</p>
    <p>chine learning and software benchmarking funda-</p>
    <p>mentals, and sleep physiology, which in my hum-</p>
    <p>ble opinion is just too much for one manuscript.</p>
    <p>Please try to be concise and have a clear focus for</p>
    <p>the manuscript. For example, the best ANN ar-</p>
    <p>chitecture for spindle detection is in principle in-</p>
    <p>dependent of any hardware implementation, and</p>
    <p>could therefore be dealt with in a separate paper</p>
    <p>(or in the Supplementary Material, if you do not</p>
    <p>deem it worth of a separate paper).</p>
    <p>Related to this: You open-sourced the software,</p>
    <p>but how could I get one of these devices if I</p>
    <p>wanted to? I may have missed it, but I found</p>
    <p>no information on this. Was it self-built by your</p>
    <p>lab or did you have an industry partner (which I</p>
    <p>don’t assume since there is on conflict of interest</p>
    <p>declared). Can I buy it from you (in which case a</p>
    <p>COI would need to be declared), or am I expected</p>
    <p>to build it myself, following your instruction (in</p>
    <p>which case the instruction would have to be much</p>
    <p>more detailed)? Without at least mentioning any</p>
    <p>prospective way that I could get hold of one of</p>
    <p>these devices in the future, I’m not sure how use-</p>
    <p>ful a paper describing it will be.</p>
    <p>by the way, it would be nice to see a picture of</p>
    <p>the device and how it can be used in the lab en-</p>
    <p>vironment</p>
    <p>&gt;</p>
    <p>We have considerably restructured and shortened the</p>
    <p>manuscript, clarified the objectives, and have moved</p>
    <p>many of the hardware details to Supplementary Infor-</p>
    <p>mation and a Github repository. This is an interdisci-</p>
    <p>plinary work, in the sense that its focus and novelty is</p>
    <p>on the combination and adaptation of existing technolo-</p>
    <p>gies to create a research tool for neuroscience. We have</p>
    <p>provided guidance to readers to help them decide which</p>
    <p>sections to which to direct their attention, depending</p>
    <p>on their background and interests. For example, people</p>
    <p>with the necessary engineering background to build a</p>
    <p>device will be more interested in the hardware details</p>
    <p>(note that details are moved to Github), a specialist in</p>
    <p>neural networks wishing to use or adapt the network for</p>
    <p>a different neural event might be most interested in the</p>
    <p>neural network implementation, whereas neuroscientists</p>
    <p>who are more interested in evaluating the device’s re-</p>
    <p>search capabilities are likely to get more out of the case</p>
    <p>study sections (please see the paragraph in the Introduc-</p>
    <p>tion beginning with “The scope of this work is (...)”).</p>
    <p>We have also clarified what is being offered and who</p>
    <p>might be able to use it to what ends, throughout (e.g.,</p>
    <p>hardware plans, code for the PMBO algorithm and for</p>
    <p>the ANN), and we have added pictures of two Portiloop</p>
    <p>hardware implementations, as suggested.</p>
    <p>We hope our revised version is more clear about the</p>
    <p>methodological focus of the manuscript, and that you</p>
    <p>will enjoy giving it an in-depth review</p>
    <p>---</p>
    <p>Related to this, I did not find any information</p>
    <p>about data storage for offline analysis, and how it</p>
    <p>would integrate with existing lab infrastructures</p>
    <p>(e.g. Labstreaminglayer)</p>
    <p>&gt;</p>
    <p>Thank you for the suggestion; we have added the capa-</p>
    <p>bility for streaming through LSL and have added in the</p>
    <p>text, “The Portiloop comes with pre-installed software</p>
    <p>for recording and visualizing the EEG signal, as well</p>
    <p>as Python programming interface for the development</p>
    <p>of extensions or new applications. Practically, the Por-</p>
    <p>tiloop can be accessed via WiFi (it acts as a standalone</p>
    <p>access point and it can connect to an existing network)</p>
    <p>and it provides a web-based interface based on Python</p>
    <p>Notebooks that allows to configure the EEG channels,</p>
    <p>visualize the signals in real-time, start and stop EEG</p>
    <p>recording (see Figure 3). The recording can be saved</p>
    <p>either in the internal memory (32GB) or an SD card in</p>
    <p>EDF format, or streamed through the network using the</p>
    <p>Lab Streaming Layer (LSL), which guarantees synchro-</p>
    <p>nization with microsecond accuracy.”</p>
    <p>---</p>
    <p>This manuscript should not come with 13 figures.</p>
    <p>Since most of them contain very little informa-</p>
    <p>tion, consider concatenating them to three or four</p>
    <p>figures with several subplots.</p>
    <p>&gt;</p>
    <p>This manuscript should not come with 13 figures.</p>
    <p>Since most of them contain very little informa-</p>
    <p>tion, consider concatenating them to three or four</p>
    <p>figures with several subplots.</p>
    <p>---</p>
    <p>To sum up, I think closed-loop stimulation is a</p>
    <p>relevant field with a lack of well-functioning and</p>
    <p>easy-to-use devices. I would therefore highly ap-</p>
    <p>preciate if you could bring your paper into a more</p>
    <p>digestable shape, so that your work can receive its</p>
    <p>due appreciation.</p>
    <p>&gt;</p>
    <p>Thank your for your support. We hope you will find our</p>
    <p>revised version much improved, and easy to digest</p>
    <p>REVIEWER 2:</p>
    <p>---</p>
    <p>The potential for a toolbox is evident, but such a</p>
    <p>toolbox’s utility and functionality are not demon-</p>
    <p>strated, but rather implied. The prototypical</p>
    <p>toolbox distracts from the analyses.</p>
    <p>&gt;</p>
    <p>As noted also by Reviewer 1, the scope and goals of</p>
    <p>the original manuscript were not clear. We have con-</p>
    <p>siderably restructured and shortened the manuscript,</p>
    <p>clarified the objectives, and have moved many of the</p>
    <p>hardware details to Supplementary Information and a</p>
    <p>Github repository. The current work focuses on meth-</p>
    <p>ods development and proof-of-concept using a challeng-</p>
    <p>ing test case. Our neural network training pipeline,</p>
    <p>dataset and lightweight pre-trained models are now pub-</p>
    <p>licly available on the Github repository of the project.</p>
    <p>In particular, this enables comparison of our results and</p>
    <p>using trained models out-of-the box, and we hope will</p>
    <p>answer your concerns regarding utility and functional-</p>
    <p>ity, at least for the software part.</p>
    <p>The scope is now more clearly summarized in the Ab-</p>
    <p>stract (please see also Introduction): “In this article, we</p>
    <p>propose the Portiloop, a deep learning-based, portable</p>
    <p>and low-cost closed-loop stimulation system able to tar-</p>
    <p>get specific brain oscillations. We first document open-</p>
    <p>hardware implementations that can be constructed from</p>
    <p>commercially available components. We also provide a</p>
    <p>fast, lightweight neural network and an exploration algo-</p>
    <p>rithm that automatically optimizes the network model</p>
    <p>to the desired brain oscillation. Finally, we validate the</p>
    <p>technology on a challenging test case of real-time sleep</p>
    <p>spindle detection, with results comparable to off-line ex-</p>
    <p>pert performance. Software and plans are available to</p>
    <p>the community as an open science initiative to encour-</p>
    <p>age further development and advance closed-loop neu-</p>
    <p>roscience research”</p>
    <p>---</p>
    <p>Reduced ANNs for maximizing Recall and Preci-</p>
    <p>sion are not developed or analyzed. No reduced</p>
    <p>ANN matched SpindleNet’s Recall (% true posi-</p>
    <p>tives). Reduced ANNs all had superior Precision</p>
    <p>(% positives found). Why? Three reduced mod-</p>
    <p>els strike a balance between Recall and Precision</p>
    <p>with f1 scores of 0.61, but no model variations</p>
    <p>achieved the performance of expert raters. Why?</p>
    <p>All the reduced models perform essentially the</p>
    <p>same.</p>
    <p>&gt;</p>
    <p>Please note that no model can achieve the performance</p>
    <p>of expert raters for several reasons, most notably that</p>
    <p>the expert ratings are what we use as our ground truth</p>
    <p>and thus achieving their performance is statistically im-</p>
    <p>possible. But furthermore, they have a fairly low inter-</p>
    <p>rater agreement, which means that their ratings (that is</p>
    <p>the closest we have to ground truth labels) are in fact</p>
    <p>themselves pretty noisy. We have improved our expla-</p>
    <p>nation of the challenges involved in labelling spindles</p>
    <p>(see Section entitled “Offline sleep spindle detection for</p>
    <p>labeling and performance comparison”).</p>
    <p>We have also improved our explanation of the f1 score.</p>
    <p>(“Once trained, the success of an algorithm on classify-</p>
    <p>ing previously unseen data can be quantified using the</p>
    <p>f1-score, which is a widely used metric to quantify an</p>
    <p>average of recall (i.e., success in detecting events) and</p>
    <p>precision (i.e., the proportion of detected events that</p>
    <p>are correct), see Equation 1.”; a Figure 9 caption also</p>
    <p>describes the trade-off with an illustration, “This pro-</p>
    <p>vides a visualization of possible trade-offs in terms of</p>
    <p>how many spindles we want to stimulate (recall) versus</p>
    <p>how sure we want to be that all stimuli are relevant (pre-</p>
    <p>cision). In terms of f1-score, the best such trade-off is</p>
    <p>attained at a threshold of 0.84 with our model, yielding</p>
    <p>a precision and a recall of 0.71.”)</p>
    <p>Recall and Precision are meaningless metrics when con-</p>
    <p>sidered independently from each other: if we predicted</p>
    <p>that everything is a sleep spindle we would obtain a Re-</p>
    <p>call of 100%, and if we predicted that only one data</p>
    <p>point for which we are 100% sure to be in a sleep spin-</p>
    <p>dle is indeed in a sleep spindle while everything else isn’t</p>
    <p>we would obtain a Precision of 100%. The f1-score, on</p>
    <p>the other hand, is a trade-off between these two metrics,</p>
    <p>and it makes some sense to maximize it, contrary to the</p>
    <p>Recall or Precision.</p>
    <p>We do explore the optimal tradeoffs between Recall and</p>
    <p>Precision in-depth in the submission, both in terms of</p>
    <p>detection and real time stimulation (Figures 9, and in</p>
    <p>Supplementary Information show different aspects of</p>
    <p>this).</p>
    <p>Concerning the reduced models, we conduct an ablation</p>
    <p>study that shows the 1-input does indeed perform the</p>
    <p>same as the 2-input (which is why we select the reduced</p>
    <p>1-input model, see Table 1 rows (3) and (6)). Then,</p>
    <p>we perform other ablations on this model only. The</p>
    <p>reduced model trained without time-dilation performs</p>
    <p>much worse (f1=0.47, see Table 1 row (7)) than the se-</p>
    <p>lected model (f1=0.61, Table 1 row (6)). The subsequent</p>
    <p>ablation is more subtle and shows that the “younger”</p>
    <p>group (p1) contributes more to training than the “older”</p>
    <p>group (p2) (see Table 1, rows (8-10)). We have clarified</p>
    <p>these observations in the text</p>
    <p>---</p>
    <p>More than half the figures (Figures 1, 3-7, 9) only</p>
    <p>highlight processes and methods. The rest of the</p>
    <p>figures cannot be interpreted without the main</p>
    <p>text. Therefore, the scope of analyses and pre-</p>
    <p>sentation of the results required significant im-</p>
    <p>provement.</p>
    <p>&gt;</p>
    <p>Also at the suggestion of another reviewer, we have re-</p>
    <p>duced the number of figures and moved some to Supple-</p>
    <p>mentary Information. We have also adjusted the cap-</p>
    <p>tions to be clearer as to the purpose of each figure, and</p>
    <p>we believe they will be easier to interpret when placed in</p>
    <p>the context of the text with their captions (as opposed to</p>
    <p>the review format). We have considerably restructured</p>
    <p>the manuscript to clarify the scope and aims (please see</p>
    <p>Introduction, which has been largely re-written). The</p>
    <p>figures do highlight processes and methods for the most</p>
    <p>part, as these are the main advances in this interdis-</p>
    <p>ciplinary work; the spindle application is intended as</p>
    <p>a case study and validation, and to demonstrate the</p>
    <p>behaviour of the system with respect to performance</p>
    <p>trade-offs</p>
    <p>---</p>
    <p>Table 1. Please spell out IExp, as this term /</p>
    <p>abbreviation is not used in the text</p>
    <p>&gt;</p>
    <p>Thank you we have replaced it with Inter-rater agree-</p>
    <p>men</p>
    <p>---</p>
    <p>No stimulation is actually conducted in this</p>
    <p>study. Do the Authors mean actuate?</p>
    <p>&gt;</p>
    <p>We agree that “actuate” would be a more general term.</p>
    <p>However, given the proposed application in brain stim-</p>
    <p>ulation and usage in that field, we prefer to keep the</p>
    <p>stimulation terminology.</p>
    <supplementary-material id="pone.0270696.s002" position="float" content-type="local-data">
      <label>Attachment</label>
      <caption>
        <p>Submitted filename: <named-content content-type="submitted-filename">Response to Reviewers.pdf</named-content></p>
      </caption>
      <media xlink:href="pone.0270696.s002.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </body>
</sub-article>
<sub-article article-type="aggregated-review-documents" id="pone.0270696.r003" specific-use="decision-letter">
  <front-stub>
    <article-id pub-id-type="doi">10.1371/journal.pone.0270696.r003</article-id>
    <title-group>
      <article-title>Decision Letter 1</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Cymbalyuk</surname>
          <given-names>Gennady S.</given-names>
        </name>
        <role>Academic Editor</role>
      </contrib>
    </contrib-group>
    <permissions>
      <copyright-statement>© 2022 Gennady S. Cymbalyuk</copyright-statement>
      <copyright-year>2022</copyright-year>
      <copyright-holder>Gennady S. Cymbalyuk</copyright-holder>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
      </license>
    </permissions>
    <related-article ext-link-type="doi" xlink:href="10.1371/journal.pone.0270696" id="rel-obj003" related-article-type="reviewed-article"/>
    <custom-meta-group>
      <custom-meta>
        <meta-name>Submission Version</meta-name>
        <meta-value>1</meta-value>
      </custom-meta>
    </custom-meta-group>
  </front-stub>
  <body>
    <p>
      <named-content content-type="letter-date">27 Apr 2022</named-content>
    </p>
    <p><!-- <div> -->PONE-D-21-32222R1<!-- </div> --><!-- <div> -->The Portiloop: a deep learning-based open science tool for closed-loop brain stimulation<!-- </div> --><!-- <div> -->PLOS ONE</p>
    <p>Dear Dr. Bouteiller,</p>
    <p>Thank you for submitting your manuscript to PLOS ONE. After careful consideration, we feel that it has merit but does not fully meet PLOS ONE’s publication criteria as it currently stands. Therefore, we invite you to submit a revised version of the manuscript that addresses the points raised during the review process.</p>
    <p>Please, provide actual examples of the EEG and how Portiloop classifies events, in this case, sleep spindles within the time series, and how this classification compares to expert manual classification. </p>
    <p>Abstract. Please, define and mention MODA in the Abstract.</p>
    <p>Please, consider removing Figures 3.  In Figure 6, it will help to see the raw and processed signal, along with its envelope, and this could be integrated into Figure 2.</p>
    <p>Table 2. The absence of visuals to support Portiloop's performance is a concern. The only figure that shows Portiloop’s processed EEG are in Figure 2. This paper needs a figure showing how Portiloop's different variations detect spindles in EEG compared to the nominal ground truth, the MODA dataset. MODA vs. 2-input Portiloop vs. 2-3 variants of Portiloop that favor speed over classification accuracy.</p>
    <p>Table 2. Too many abbreviations and undefined terms in Row Set 2 -- on-line detection. Figures and tables should be interpretable without the main text. Therefore, the table needs a legend to describe, at a high level, what is meant by 1- and 2-inputs, ablation, td, p1, so forth.</p>
    <p>Figure 7. As is, Figure 7 is abstracted from real run / compute times. It would helpful to contrast the classification performance before and after optimization. What is the trade-off between compute time and classification with a high software and hardware cost (without PMBO), versus a low software and hardware cost (with PMBO). Show EEG output of two ANNs off and on the Pareto front.</p>
    <p>Figure 8. Figure 8 needs to be rotated clockwise 90 degrees.</p>
    <p>Figure 9. It's not clear what score and threshold mean in this figure without referencing Figure 2 and the text. Figures should be mostly interpretable in isolation. Please, show a panel (as in Fig. 2) with the EEG colored and annotated to show what are true positives, false positive, etc. for stimulation timestamps. It may also help to see an example of a delay relative to the spindle (and its duration).</p>
    <p>Please, consider whether you could bring the main text word count closer to 4000 or 5000 words and push more technical details to the Supplement or the Github repo. </p>
    <p>Please submit your revised manuscript by Jun 11 2022 11:59PM. If you will need more time than this to complete your revisions, please reply to this message or contact the journal office at <email>plosone@plos.org</email>. When you're ready to submit your revision, log on to <ext-link xlink:href="https://www.editorialmanager.com/pone/" ext-link-type="uri">https://www.editorialmanager.com/pone/</ext-link> and select the 'Submissions Needing Revision' folder to locate your manuscript file.</p>
    <p>Please include the following items when submitting your revised manuscript:<!-- </div> --><list list-type="bullet"><list-item><p>A rebuttal letter that responds to each point raised by the academic editor and reviewer(s). You should upload this letter as a separate file labeled 'Response to Reviewers'.</p></list-item><list-item><p>A marked-up copy of your manuscript that highlights changes made to the original version. You should upload this as a separate file labeled 'Revised Manuscript with Track Changes'.</p></list-item><list-item><p>An unmarked version of your revised paper without tracked changes. You should upload this as a separate file labeled 'Manuscript'.</p></list-item></list></p>
    <p>If you would like to make changes to your financial disclosure, please include your updated statement in your cover letter. Guidelines for resubmitting your figure files are available below the reviewer comments at the end of this letter.</p>
    <p>If applicable, we recommend that you deposit your laboratory protocols in protocols.io to enhance the reproducibility of your results. Protocols.io assigns your protocol its own identifier (DOI) so that it can be cited independently in the future. For instructions see: <ext-link xlink:href="https://journals.plos.org/plosone/s/submission-guidelines#loc-laboratory-protocols" ext-link-type="uri">https://journals.plos.org/plosone/s/submission-guidelines#loc-laboratory-protocols</ext-link>. Additionally, PLOS ONE offers an option for publishing peer-reviewed Lab Protocol articles, which describe protocols hosted on protocols.io. Read more information on sharing protocols at <ext-link xlink:href="https://plos.org/protocols?utm_medium=editorial-email&amp;utm_source=authorletters&amp;utm_campaign=protocols" ext-link-type="uri">https://plos.org/protocols?utm_medium=editorial-email&amp;utm_source=authorletters&amp;utm_campaign=protocols</ext-link>.</p>
    <p>We look forward to receiving your revised manuscript.</p>
    <p>Kind regards,</p>
    <p>Gennady S. Cymbalyuk, Ph.D.</p>
    <p>Academic Editor</p>
    <p>PLOS ONE</p>
    <p>[Note: HTML markup is below. Please do not edit.]</p>
    <p>Reviewers' comments:</p>
    <p>Reviewer's Responses to Questions</p>
    <p>
      <!-- <font color="black"> -->
      <bold>Comments to the Author</bold>
    </p>
    <p>1. If the authors have adequately addressed your comments raised in a previous round of review and you feel that this manuscript is now acceptable for publication, you may indicate that here to bypass the “Comments to the Author” section, enter your conflict of interest statement in the “Confidential to Editor” section, and submit your "Accept" recommendation.<!-- </font> --></p>
    <p>Reviewer #1: (No Response)</p>
    <p>Reviewer #2: (No Response)</p>
    <p>**********</p>
    <p><!-- <font color="black"> -->2. Is the manuscript technically sound, and do the data support the conclusions?</p>
    <p>The manuscript must describe a technically sound piece of scientific research with data that supports the conclusions. Experiments must have been conducted rigorously, with appropriate controls, replication, and sample sizes. The conclusions must be drawn appropriately based on the data presented. <!-- </font> --></p>
    <p>Reviewer #1: Yes</p>
    <p>Reviewer #2: Partly</p>
    <p>**********</p>
    <p><!-- <font color="black"> -->3. Has the statistical analysis been performed appropriately and rigorously? <!-- </font> --></p>
    <p>Reviewer #1: I Don't Know</p>
    <p>Reviewer #2: Yes</p>
    <p>**********</p>
    <p><!-- <font color="black"> -->4. Have the authors made all data underlying the findings in their manuscript fully available?</p>
    <p>The <ext-link xlink:href="http://www.plosone.org/static/policies.action#sharing" ext-link-type="uri">PLOS Data policy</ext-link> requires authors to make all data underlying the findings described in their manuscript fully available without restriction, with rare exception (please refer to the Data Availability Statement in the manuscript PDF file). The data should be provided as part of the manuscript or its supporting information, or deposited to a public repository. For example, in addition to summary statistics, the data points behind means, medians and variance measures should be available. If there are restrictions on publicly sharing data—e.g. participant privacy or use of data from a third party—those must be specified.<!-- </font> --></p>
    <p>Reviewer #1: Yes</p>
    <p>Reviewer #2: Yes</p>
    <p>**********</p>
    <p><!-- <font color="black"> -->5. Is the manuscript presented in an intelligible fashion and written in standard English?</p>
    <p>PLOS ONE does not copyedit accepted manuscripts, so the language in submitted articles must be clear, correct, and unambiguous. Any typographical or grammatical errors should be corrected at revision, so please note any specific errors here.<!-- </font> --></p>
    <p>Reviewer #1: No</p>
    <p>Reviewer #2: Yes</p>
    <p>**********</p>
    <p><!-- <font color="black"> -->6. Review Comments to the Author</p>
    <p>Please use the space provided to explain your answers to the questions above. You may also include additional comments for the author, including concerns about dual publication, research ethics, or publication ethics. (Please upload your review as an attachment if it exceeds 20,000 characters)<!-- </font> --></p>
    <p>Reviewer #1: The authors have done a good job with the revision. Objectives are laid out much clearer, and a number of well-made figures help the reader, and there is a comment about how to obtain such a device. There is also a My main concern with the manuscript, however, has not been adressed - it is still clearly too long to be read by a majority of the scientific community. While a part of the Methods section has been shifted to the Supplement, the word count for the main text is still between 9000 and 10000. I think the chances of having people actually read, and cite, the article would be much higher if the authors could bring the main text word count closer to 4000 or 5000 words and push more technical details to the Supplement or the Github repo. Also, the authors should be aware that the target audience are probably experimental neuroscientists more than computer scientists or electrical engineers, so a bit more information about the example study (sleep spindles) and a bit less technical detail would probably be appreciated.</p>
    <p>Reviewer #2: This design paper covers Portiloop, a closed-loop and lightweight tool for event classification in timeseries using deep learning. The paper uses detection of sleep spindles from a public dataset, MODA, as a first test case and proof of concept. The manuscript, while dense in text, adequately describes the motivation and methods for constructing Portiloop. However, the results are left mostly in text form. Nontechnical readers will benefit from seeing actual examples of the EEG and how Portiloop classifies events, in this case, sleep spindles within the time series, and how this classification compares to expert manual classification. Therefore, my remaining concerns for this manuscript are in its presentation of the results. Some figures show flow chart of methods adequately described with text alone, and some figures need to show real examples of classified EEG data. My specific comments are below:</p>
    <p>Abstract. I think it will help to define and mention MODA in the Abstract to give it a search link to a term relevant to sleep researchers.</p>
    <p>Figures 3 and 6. I agree with Reviewer 1’s previous concern of too many figures. Figures 3 and 6 appear unnecessary. However, in Figure 6, it will help to see the raw and processed signal, along with its envelope, and this could be integrated into Figure 2.</p>
    <p>Table 2. The absence of visuals to support Portiloop's performance is a concern. The only figure that shows Portiloop’s processed EEG are in Figure 2. This paper needs a figure showing how Portiloop's different variations detect spindles in EEG compared to the nominal ground truth, the MODA dataset. MODA vs. 2-input Portiloop vs. 2-3 variants of Portiloop that favor speed over classification accuracy.</p>
    <p>Table 2. Too many abbreviations and undefined terms in Row Set 2 -- on-line detection. Figures and tables should be interpretable without the main text. Therefore, the table needs a legend to describe, at a high level, what is meant by 1- and 2-inputs, ablation, td, p1, so forth.</p>
    <p>Figure 7. As is, Figure 7 is abstracted from real run / compute times. I think it would helpful to contrast the classification performance before and after optimization. What is the trade-off between compute time and classification with a high software and hardware cost (without PMBO), versus a low software and hardware cost (with PMBO). Show EEG output of two ANNs off and on the Pareto front.</p>
    <p>Figure 8. Figure 8 needs to be rotated clockwise 90 degrees.</p>
    <p>Figure 9. It's not clear what score and threshold mean in this figure without referencing Figure 2 and the text. Figures should be mostly interpretable in isolation. I recommend showing a panel (as in Fig. 2) with the EEG colored and annotated to show what are true positives, false positive, etc. for stimulation timestamps. It may also help to see an example of a delay relative to the spindle (and its duration).</p>
    <p>**********</p>
    <p><!-- <font color="black"> -->7. PLOS authors have the option to publish the peer review history of their article (<ext-link xlink:href="https://journals.plos.org/plosone/s/editorial-and-peer-review-process#loc-peer-review-history" ext-link-type="uri">what does this mean?</ext-link>). If published, this will include your full peer review and any attached files.</p>
    <p>If you choose “no”, your identity will remain anonymous but your review may still be made public.</p>
    <p><bold>Do you want your identity to be public for this peer review?</bold> For information about this choice, including consent withdrawal, please see our <ext-link xlink:href="https://www.plos.org/privacy-policy" ext-link-type="uri">Privacy Policy</ext-link>.<!-- </font> --></p>
    <p>Reviewer #1: <bold>Yes: </bold>Marius Keute</p>
    <p>Reviewer #2: No</p>
    <p>[NOTE: If reviewer comments were submitted as an attachment file, they will be attached to this email and accessible via the submission site. Please log into your account, locate the manuscript record, and check for the action link "View Attachments". If this link does not appear, there are no attachment files.]</p>
    <p>While revising your submission, please upload your figure files to the Preflight Analysis and Conversion Engine (PACE) digital diagnostic tool, <ext-link xlink:href="https://pacev2.apexcovantage.com/" ext-link-type="uri">https://pacev2.apexcovantage.com/</ext-link>. PACE helps ensure that figures meet PLOS requirements. To use PACE, you must first register as a user. Registration is free. Then, login and navigate to the UPLOAD tab, where you will find detailed instructions on how to use the tool. If you encounter any issues or have any questions when using PACE, please email PLOS at <email>figures@plos.org</email>. Please note that Supporting Information files do not need this step.</p>
  </body>
</sub-article>
<sub-article article-type="author-comment" id="pone.0270696.r004">
  <front-stub>
    <article-id pub-id-type="doi">10.1371/journal.pone.0270696.r004</article-id>
    <title-group>
      <article-title>Author response to Decision Letter 1</article-title>
    </title-group>
    <related-article ext-link-type="doi" xlink:href="10.1371/journal.pone.0270696" id="rel-obj004" related-article-type="editor-report"/>
    <custom-meta-group>
      <custom-meta>
        <meta-name>Submission Version</meta-name>
        <meta-value>2</meta-value>
      </custom-meta>
    </custom-meta-group>
  </front-stub>
  <body>
    <p>
      <named-content content-type="author-response-date">11 Jun 2022</named-content>
    </p>
    <p>The submission has been revised substantially, please see the Response to Reviewers file (at the end of the generated PDF).</p>
    <supplementary-material id="pone.0270696.s003" position="float" content-type="local-data">
      <label>Attachment</label>
      <caption>
        <p>Submitted filename: <named-content content-type="submitted-filename">answer_to_reviewers.pdf</named-content></p>
      </caption>
      <media xlink:href="pone.0270696.s003.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </body>
</sub-article>
<sub-article article-type="aggregated-review-documents" id="pone.0270696.r005" specific-use="decision-letter">
  <front-stub>
    <article-id pub-id-type="doi">10.1371/journal.pone.0270696.r005</article-id>
    <title-group>
      <article-title>Decision Letter 2</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Cymbalyuk</surname>
          <given-names>Gennady S.</given-names>
        </name>
        <role>Academic Editor</role>
      </contrib>
    </contrib-group>
    <permissions>
      <copyright-statement>© 2022 Gennady S. Cymbalyuk</copyright-statement>
      <copyright-year>2022</copyright-year>
      <copyright-holder>Gennady S. Cymbalyuk</copyright-holder>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
      </license>
    </permissions>
    <related-article ext-link-type="doi" xlink:href="10.1371/journal.pone.0270696" id="rel-obj005" related-article-type="reviewed-article"/>
    <custom-meta-group>
      <custom-meta>
        <meta-name>Submission Version</meta-name>
        <meta-value>2</meta-value>
      </custom-meta>
    </custom-meta-group>
  </front-stub>
  <body>
    <p>
      <named-content content-type="letter-date">16 Jun 2022</named-content>
    </p>
    <p>The Portiloop: a deep learning-based open science tool for closed-loop brain stimulation</p>
    <p>PONE-D-21-32222R2</p>
    <p>Dear Dr. Bouteiller,</p>
    <p>We’re pleased to inform you that your manuscript has been judged scientifically suitable for publication and will be formally accepted for publication once it meets all outstanding technical requirements.</p>
    <p>Within one week, you’ll receive an e-mail detailing the required amendments. When these have been addressed, you’ll receive a formal acceptance letter and your manuscript will be scheduled for publication.</p>
    <p>An invoice for payment will follow shortly after the formal acceptance. To ensure an efficient process, please log into Editorial Manager at <ext-link xlink:href="http://www.editorialmanager.com/pone/" ext-link-type="uri">http://www.editorialmanager.com/pone/</ext-link>, click the 'Update My Information' link at the top of the page, and double check that your user information is up-to-date. If you have any billing related questions, please contact our Author Billing department directly at <email>authorbilling@plos.org</email>.</p>
    <p>If your institution or institutions have a press office, please notify them about your upcoming paper to help maximize its impact. If they’ll be preparing press materials, please inform our press team as soon as possible -- no later than 48 hours after receiving the formal acceptance. Your manuscript will remain under strict press embargo until 2 pm Eastern Time on the date of publication. For more information, please contact <email>onepress@plos.org</email>.</p>
    <p>Kind regards,</p>
    <p>Gennady S. Cymbalyuk, Ph.D.</p>
    <p>Academic Editor</p>
    <p>PLOS ONE</p>
    <p>Additional Editor Comments (optional):</p>
    <p>Reviewers' comments:</p>
    <p>Reviewer's Responses to Questions</p>
    <p>
      <!-- <font color="black"> -->
      <bold>Comments to the Author</bold>
    </p>
    <p>1. If the authors have adequately addressed your comments raised in a previous round of review and you feel that this manuscript is now acceptable for publication, you may indicate that here to bypass the “Comments to the Author” section, enter your conflict of interest statement in the “Confidential to Editor” section, and submit your "Accept" recommendation.<!-- </font> --></p>
    <p>Reviewer #1: All comments have been addressed</p>
    <p>Reviewer #2: All comments have been addressed</p>
    <p>**********</p>
    <p><!-- <font color="black"> -->2. Is the manuscript technically sound, and do the data support the conclusions?</p>
    <p>The manuscript must describe a technically sound piece of scientific research with data that supports the conclusions. Experiments must have been conducted rigorously, with appropriate controls, replication, and sample sizes. The conclusions must be drawn appropriately based on the data presented. <!-- </font> --></p>
    <p>Reviewer #1: Yes</p>
    <p>Reviewer #2: Yes</p>
    <p>**********</p>
    <p><!-- <font color="black"> -->3. Has the statistical analysis been performed appropriately and rigorously? <!-- </font> --></p>
    <p>Reviewer #1: Yes</p>
    <p>Reviewer #2: Yes</p>
    <p>**********</p>
    <p><!-- <font color="black"> -->4. Have the authors made all data underlying the findings in their manuscript fully available?</p>
    <p>The <ext-link xlink:href="http://www.plosone.org/static/policies.action#sharing" ext-link-type="uri">PLOS Data policy</ext-link> requires authors to make all data underlying the findings described in their manuscript fully available without restriction, with rare exception (please refer to the Data Availability Statement in the manuscript PDF file). The data should be provided as part of the manuscript or its supporting information, or deposited to a public repository. For example, in addition to summary statistics, the data points behind means, medians and variance measures should be available. If there are restrictions on publicly sharing data—e.g. participant privacy or use of data from a third party—those must be specified.<!-- </font> --></p>
    <p>Reviewer #1: Yes</p>
    <p>Reviewer #2: Yes</p>
    <p>**********</p>
    <p><!-- <font color="black"> -->5. Is the manuscript presented in an intelligible fashion and written in standard English?</p>
    <p>PLOS ONE does not copyedit accepted manuscripts, so the language in submitted articles must be clear, correct, and unambiguous. Any typographical or grammatical errors should be corrected at revision, so please note any specific errors here.<!-- </font> --></p>
    <p>Reviewer #1: Yes</p>
    <p>Reviewer #2: Yes</p>
    <p>**********</p>
    <p><!-- <font color="black"> -->6. Review Comments to the Author</p>
    <p>Please use the space provided to explain your answers to the questions above. You may also include additional comments for the author, including concerns about dual publication, research ethics, or publication ethics. (Please upload your review as an attachment if it exceeds 20,000 characters)<!-- </font> --></p>
    <p>Reviewer #1: I still think it is quite long, but otherwise I have no further complaints. I recommend to accept this paper.</p>
    <p>Reviewer #2: While I feel it would have helped to show non-technical readers the explicit performance and tradeoffs between the different ANNs (e.g., examples of spindle detection on time series with maximal recall vs. maximal precision vs. maximal f1 vs. maximal hardware costs vs. optimal tradeoff in software and hardware costs etc.), this is stylistic and not essential. Thank you for addressing my technical concerns, and I have no further comments.</p>
    <p>**********</p>
    <p><!-- <font color="black"> -->7. PLOS authors have the option to publish the peer review history of their article (<ext-link xlink:href="https://journals.plos.org/plosone/s/editorial-and-peer-review-process#loc-peer-review-history" ext-link-type="uri">what does this mean?</ext-link>). If published, this will include your full peer review and any attached files.</p>
    <p>If you choose “no”, your identity will remain anonymous but your review may still be made public.</p>
    <p><bold>Do you want your identity to be public for this peer review?</bold> For information about this choice, including consent withdrawal, please see our <ext-link xlink:href="https://www.plos.org/privacy-policy" ext-link-type="uri">Privacy Policy</ext-link>.<!-- </font> --></p>
    <p>Reviewer #1: <bold>Yes: </bold>Marius Keute</p>
    <p>Reviewer #2: No</p>
    <p>**********</p>
  </body>
</sub-article>
<sub-article article-type="editor-report" id="pone.0270696.r006" specific-use="acceptance-letter">
  <front-stub>
    <article-id pub-id-type="doi">10.1371/journal.pone.0270696.r006</article-id>
    <title-group>
      <article-title>Acceptance letter</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Cymbalyuk</surname>
          <given-names>Gennady S.</given-names>
        </name>
        <role>Academic Editor</role>
      </contrib>
    </contrib-group>
    <permissions>
      <copyright-statement>© 2022 Gennady S. Cymbalyuk</copyright-statement>
      <copyright-year>2022</copyright-year>
      <copyright-holder>Gennady S. Cymbalyuk</copyright-holder>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
      </license>
    </permissions>
    <related-article ext-link-type="doi" xlink:href="10.1371/journal.pone.0270696" id="rel-obj006" related-article-type="reviewed-article"/>
  </front-stub>
  <body>
    <p>
      <named-content content-type="letter-date">12 Aug 2022</named-content>
    </p>
    <p>PONE-D-21-32222R2 </p>
    <p>The Portiloop: a deep learning-based open science tool for closed-loop brain stimulation </p>
    <p>Dear Dr. Bouteiller:</p>
    <p>I'm pleased to inform you that your manuscript has been deemed suitable for publication in PLOS ONE. Congratulations! Your manuscript is now with our production department. </p>
    <p>If your institution or institutions have a press office, please let them know about your upcoming paper now to help maximize its impact. If they'll be preparing press materials, please inform our press team within the next 48 hours. Your manuscript will remain under strict press embargo until 2 pm Eastern Time on the date of publication. For more information please contact <email>onepress@plos.org</email>.</p>
    <p>If we can help with anything else, please email us at <email>plosone@plos.org</email>. </p>
    <p>Thank you for submitting your work to PLOS ONE and supporting open access. </p>
    <p>Kind regards, </p>
    <p>PLOS ONE Editorial Office Staff</p>
    <p>on behalf of</p>
    <p>Dr. Gennady S. Cymbalyuk </p>
    <p>Academic Editor</p>
    <p>PLOS ONE</p>
  </body>
</sub-article>
