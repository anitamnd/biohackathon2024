<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id>
    <journal-id journal-id-type="publisher-id">bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1367-4803</issn>
    <issn pub-type="epub">1367-4811</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">8058777</article-id>
    <article-id pub-id-type="pmid">32780838</article-id>
    <article-id pub-id-type="doi">10.1093/bioinformatics/btaa714</article-id>
    <article-id pub-id-type="publisher-id">btaa714</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Original Papers</subject>
        <subj-group subj-group-type="category-toc-heading">
          <subject>Structural Bioinformatics</subject>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI01060</subject>
      </subj-group>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI01060</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>GraphQA: protein model quality assessment using graph convolutional networks</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0001-8152-767X</contrib-id>
        <name>
          <surname>Baldassarre</surname>
          <given-names>Federico</given-names>
        </name>
        <aff><institution>Division of Robotics, Perception and Learning (RPL), KTH – Royal Institute of Technology</institution>, 10044 Stockholm, <country country="SE">Sweden</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Menéndez Hurtado</surname>
          <given-names>David</given-names>
        </name>
        <aff><institution>Department of Intelligent Systems, Science for Life Laboratory, Stockholm University</institution>, Box 1031, 17121 Solna, <country country="SE">Sweden</country></aff>
        <aff><institution>Department of Biochemistry and Biophysics, school of Electrical Engineering and Computer Science (EECS), Stockholm University</institution>, 10691 Stockholm, <country country="SE">Sweden</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Elofsson</surname>
          <given-names>Arne</given-names>
        </name>
        <aff><institution>Department of Intelligent Systems, Science for Life Laboratory, Stockholm University</institution>, Box 1031, 17121 Solna, <country country="SE">Sweden</country></aff>
        <aff><institution>Department of Biochemistry and Biophysics, school of Electrical Engineering and Computer Science (EECS), Stockholm University</institution>, 10691 Stockholm, <country country="SE">Sweden</country></aff>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Azizpour</surname>
          <given-names>Hossein</given-names>
        </name>
        <xref rid="btaa714-cor1" ref-type="corresp"/>
        <aff><institution>Division of Robotics, Perception and Learning (RPL), KTH – Royal Institute of Technology</institution>, 10044 Stockholm, <country country="SE">Sweden</country></aff>
        <!--azizpour@kth.se-->
      </contrib>
    </contrib-group>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Ponty</surname>
          <given-names>Yann</given-names>
        </name>
        <role>Associate Editor</role>
      </contrib>
    </contrib-group>
    <author-notes>
      <corresp id="btaa714-cor1">To whom correspondence should be addressed. <email>azizpour@kth.se</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <day>01</day>
      <month>2</month>
      <year>2021</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2020-08-11">
      <day>11</day>
      <month>8</month>
      <year>2020</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>11</day>
      <month>8</month>
      <year>2020</year>
    </pub-date>
    <volume>37</volume>
    <issue>3</issue>
    <fpage>360</fpage>
    <lpage>366</lpage>
    <history>
      <date date-type="received">
        <day>18</day>
        <month>1</month>
        <year>2020</year>
      </date>
      <date date-type="rev-recd">
        <day>03</day>
        <month>7</month>
        <year>2020</year>
      </date>
      <date date-type="editorial-decision">
        <day>25</day>
        <month>7</month>
        <year>2020</year>
      </date>
      <date date-type="accepted">
        <day>05</day>
        <month>8</month>
        <year>2020</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2020. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2020</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="btaa714.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Motivation</title>
        <p>Proteins are ubiquitous molecules whose function in biological processes is determined by their 3D structure. Experimental identification of a protein’s structure can be time-consuming, prohibitively expensive and not always possible. Alternatively, protein folding can be modeled using computational methods, which however are not guaranteed to always produce optimal results. GraphQA is a graph-based method to estimate the quality of protein models, that possesses favorable properties such as representation learning, explicit modeling of both sequential and 3D structure, geometric invariance and computational efficiency.</p>
      </sec>
      <sec id="s2">
        <title>Results</title>
        <p>GraphQA performs similarly to state-of-the-art methods despite using a relatively low number of input features. In addition, the graph network structure provides an improvement over the architecture used in ProQ4 operating on the same input features. Finally, the individual contributions of GraphQA components are carefully evaluated.</p>
      </sec>
      <sec id="s3">
        <title>Availability and implementation</title>
        <p>PyTorch implementation, datasets, experiments and link to an evaluation server are available through this GitHub repository: github.com/baldassarreFe/graphqa.</p>
      </sec>
      <sec id="s5">
        <title>Supplementary information</title>
        <p><xref rid="sup1" ref-type="supplementary-material">Supplementary data</xref> are available at <italic toggle="yes">Bioinformatics</italic> online.</p>
      </sec>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Swedish E-science Research Council</institution>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Swedish National Infrastructure for Computing</institution>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Swedish Research Council</institution>
            <institution-id institution-id-type="DOI">10.13039/501100004359</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>2017-04609</award-id>
        <award-id>2016-03798</award-id>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="7"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 Introduction</title>
    <p>Protein molecules are predominantly present in biological forms, where they are responsible for most cellular functions. Therefore, understanding, predicting and modifying proteins in biological processes are essential for medical, pharmaceutical and genetic research. Such studies strongly depend on discovering mechanical and chemical properties of proteins through the determination of their structure.</p>
    <p>At the high level, a protein molecule is a chain of hundreds of smaller molecules called amino acids. Identifying a protein’s amino-acid sequence is nowadays straightforward. However, the function of a protein is primarily determined by its 3D structure. Spatial folding can be determined experimentally, but the existing procedures are time consuming, prohibitively expensive and not always possible. Thus, several computational techniques were developed for protein structure prediction (<xref rid="btaa714-B3" ref-type="bibr">Arnold <italic toggle="yes">et al.</italic>, 2006</xref>; <xref rid="btaa714-B48" ref-type="bibr">Wang <italic toggle="yes">et al.</italic>, 2017</xref>; <xref rid="btaa714-B50" ref-type="bibr">Xu, 2019</xref>). So far, no single method is always best, e.g. some proteins are best modeled by some specific method, also, computational methods often produce multiple outputs. Thus, candidate generation is generally followed by an evaluation step. This work focuses on quality assessment (QA) of computationally derived protein models (<xref rid="btaa714-B29" ref-type="bibr">Lundstrom <italic toggle="yes">et al.</italic>, 2001</xref>; <xref rid="btaa714-B49" ref-type="bibr">Won <italic toggle="yes">et al.</italic>, 2019</xref>).</p>
    <p>Protein QA, also referred to as the estimation of model accuracy, estimates the quality of computational protein models in terms of divergence from their native structure. The downstream goal of QA is twofold: to find the best model in a pool of models and to refine a model based on its estimated local quality.</p>
    <p>Computational protein folding and design have recently received attention from the machine learning community (<xref rid="btaa714-B1" ref-type="bibr">AlQuraishi, 2019</xref>; <xref rid="btaa714-B2" ref-type="bibr">Anand and Huang, 2018</xref>; <xref rid="btaa714-B11" ref-type="bibr">Evans <italic toggle="yes">et al.</italic>, 2018</xref>; <xref rid="btaa714-B21" ref-type="bibr">Jones and Kandathil, 2018</xref>; <xref rid="btaa714-B19" ref-type="bibr">Ingraham <italic toggle="yes">et al.</italic>, 2019b</xref>; <xref rid="btaa714-B48" ref-type="bibr">Wang <italic toggle="yes">et al.</italic>, 2017</xref>; <xref rid="btaa714-B50" ref-type="bibr">Xu, 2019</xref>), while QA has yet to follow. This is despite the importance of QA for structural biology and the availability of standard datasets to benchmark machine learning techniques, such as the biannual CASP event (<xref rid="btaa714-B34" ref-type="bibr">Moult <italic toggle="yes">et al.</italic>, 1999</xref>). The field of bioinformatics, on the other hand, has witnessed noticeable progress in QA for more than a decade: from earlier works using artificial neural networks (<xref rid="btaa714-B47" ref-type="bibr">Wallner and Elofsson, 2006</xref>) or support vector machines (<xref rid="btaa714-B39" ref-type="bibr">Ray <italic toggle="yes">et al.</italic>, 2012</xref>; <xref rid="btaa714-B43" ref-type="bibr">Uziela <italic toggle="yes">et al.</italic>, 2016</xref>) to more recent works including MULTICOM (<xref rid="btaa714-B16" ref-type="bibr">Hou <italic toggle="yes">et al.</italic>, 2019</xref>), SARTclust (submitted as group UOSHAN in CASP13) (<xref rid="btaa714-B6" ref-type="bibr">Cheng <italic toggle="yes">et al.</italic>, 2019</xref>), ModFOLD7 (<xref rid="btaa714-B32" ref-type="bibr">McGuffin <italic toggle="yes">et al.</italic>, 2019b</xref>), FaeNNz (<xref rid="btaa714-B42" ref-type="bibr">Studer <italic toggle="yes">et al.</italic>, 2020</xref>) and those using deep learning techniques, such as 1D-CNNs, 3D-CNNs and LSTMs (<xref rid="btaa714-B7" ref-type="bibr">Conover <italic toggle="yes">et al.</italic>, 2019</xref>; <xref rid="btaa714-B9" ref-type="bibr">Derevyanko <italic toggle="yes">et al.</italic>, 2018</xref>; <xref rid="btaa714-B17" ref-type="bibr">Hurtado <italic toggle="yes">et al.</italic>, 2018</xref>; <xref rid="btaa714-B38" ref-type="bibr">Pagès <italic toggle="yes">et al.</italic>, 2018</xref>).</p>
    <p>In this work, we tackle QA with graph convolutional networks (GCNs), which offer several desirable properties over previous methods. Through extensive experiments, we show GraphQA performs similarly to the state-of-the-art methods despite using a relatively low number of features. Particularly, in comparison to ProQ4 which uses the same set of input features, it provides a clear improvement in performance.</p>
    <sec>
      <title>1.1 Related works</title>
      <p><bold>Protein quality assessment</bold> methods are evaluated in CASP (<xref rid="btaa714-B33" ref-type="bibr">Moult <italic toggle="yes">et al.</italic>, 1995</xref>) since CASP7 (<xref rid="btaa714-B8" ref-type="bibr">Cozzetto <italic toggle="yes">et al.</italic>, 2007</xref>). Current techniques can be divided into two categories: single-model methods which operate on a single protein model to estimate its quality (<xref rid="btaa714-B46" ref-type="bibr">Wallner and Elofsson, 2003</xref>), and consensus methods that use consistency between several candidates to estimate their quality (<xref rid="btaa714-B29" ref-type="bibr">Lundstrom <italic toggle="yes">et al.</italic>, 2001</xref>). Single-model methods are applicable to a single protein in isolation and in the recent CASP13 performed comparably to or better than consensus methods for the first time (<xref rid="btaa714-B6" ref-type="bibr">Cheng <italic toggle="yes">et al.</italic>, 2019</xref>). Several recent single-model QA works are based on deep learning: 3DCNN and Ornate adopt a volumetric representation of proteins (<xref rid="btaa714-B9" ref-type="bibr">Derevyanko <italic toggle="yes">et al.</italic>, 2018</xref>). Ornate improves 3DCNN by defining a canonical orientation (<xref rid="btaa714-B38" ref-type="bibr">Pagès <italic toggle="yes">et al.</italic>, 2018</xref>). ProQ3D (<xref rid="btaa714-B44" ref-type="bibr">Uziela <italic toggle="yes">et al.</italic>, 2017</xref>) uses a multilayer perceptron with carefully optimized residue descriptors from ProQ3 (<xref rid="btaa714-B43" ref-type="bibr">Uziela <italic toggle="yes">et al.</italic>, 2016</xref>) as inputs. MULTICOM-NOVEL (<xref rid="btaa714-B16" ref-type="bibr">Hou <italic toggle="yes">et al.</italic>, 2019</xref>) trains a 1DCNN with multitask learning to predict local and global scores. ProQ4 adopts a pretrained 1D-CNN that is fine-tuned in a Siamese configuration with a rank loss (<xref rid="btaa714-B17" ref-type="bibr">Hurtado <italic toggle="yes">et al.</italic>, 2018</xref>) using exactly the same protein descriptors as used in this work. Other recent methods not based on deep learning include SBROD that uses ridge regression (<xref rid="btaa714-B23" ref-type="bibr">Karasikov <italic toggle="yes">et al.</italic>, 2019</xref>), QMEANDisCo (<xref rid="btaa714-B42" ref-type="bibr">Studer <italic toggle="yes">et al.</italic>, 2020</xref>) and VoroMQA that takes a statistical approach on atom-level contact area (<xref rid="btaa714-B37" ref-type="bibr">Olechnovič <italic toggle="yes">et al.</italic>, 2013</xref>). VoroMQA and ProQ3D are among the top-performing methods of CASP13 (<xref rid="btaa714-B49" ref-type="bibr">Won <italic toggle="yes">et al.</italic>, 2019</xref>) together with MULTICOM, ModFOLD7 (<xref rid="btaa714-B31" ref-type="bibr">McGuffin <italic toggle="yes">et al.</italic>, 2019a</xref>) and SART (<xref rid="btaa714-B6" ref-type="bibr">Cheng <italic toggle="yes">et al.</italic>, 2019</xref>), which use a large combination of protein predictors as inputs to the machine learning algorithm .
</p>
      <fig position="float" id="btaa714-F1">
        <label>Fig. 1.</label>
        <caption>
          <p>Protein QA. GraphQA predicts local and global scores from a protein’s graph using message passing between chemically bonded or spatially close residues. CASP QA algorithms score protein models by comparison with experimentally determined conformations</p>
        </caption>
        <graphic xlink:href="btaa714f1" position="float"/>
      </fig>
      <p><bold>Graph convolutional networks</bold> bring the representation learning power of CNNs to graph data, and have been recently applied with success to multiple domains, e.g. physics (<xref rid="btaa714-B15" ref-type="bibr">Gonzalez <italic toggle="yes">et al.</italic>, 2018</xref>), visual scene understanding (<xref rid="btaa714-B35" ref-type="bibr">Narasimhan <italic toggle="yes">et al.</italic>, 2018</xref>) and natural language understanding (<xref rid="btaa714-B25" ref-type="bibr">Kipf and Welling, 2017</xref>). In the chemistry domain, molecules can be naturally represented as graphs, and GCNs have been proven effective in several related tasks, including molecular representation learning (<xref rid="btaa714-B10" ref-type="bibr">Duvenaud <italic toggle="yes">et al.</italic>, 2015</xref>), protein interface prediction (<xref rid="btaa714-B12" ref-type="bibr">Fout <italic toggle="yes">et al.</italic>, 2017</xref>), chemical property prediction (<xref rid="btaa714-B14" ref-type="bibr">Gilmer <italic toggle="yes">et al.</italic>, 2017</xref>; <xref rid="btaa714-B26" ref-type="bibr">Li <italic toggle="yes">et al.</italic>, 2018a</xref>; <xref rid="btaa714-B36" ref-type="bibr">Niepert <italic toggle="yes">et al.</italic>, 2016</xref>), drug–drug interaction (<xref rid="btaa714-B54" ref-type="bibr">Zitnik <italic toggle="yes">et al.</italic>, 2018</xref>), drug–target interaction (<xref rid="btaa714-B13" ref-type="bibr">Gao <italic toggle="yes">et al.</italic>, 2018</xref>), molecular optimization (<xref rid="btaa714-B20" ref-type="bibr">Jin <italic toggle="yes">et al.</italic>, 2019</xref>) and generation of proteins, molecules and drugs (<xref rid="btaa714-B18" ref-type="bibr">Ingraham <italic toggle="yes">et al.</italic>, 2019a</xref>; <xref rid="btaa714-B27" ref-type="bibr">Li <italic toggle="yes">et al.</italic>, 2018b</xref>; <xref rid="btaa714-B28" ref-type="bibr">Liu <italic toggle="yes">et al.</italic>, 2018</xref>; <xref rid="btaa714-B41" ref-type="bibr">Simonovsky and Komodakis, 2018</xref>; <xref rid="btaa714-B51" ref-type="bibr">You <italic toggle="yes">et al.</italic>, 2018</xref>). However, to the best of our knowledge, when we started this work, GCNs have never been applied to the problem of protein QA.</p>
    </sec>
    <sec>
      <title>1.2 Contributions</title>
      <list list-type="bullet">
        <list-item>
          <p>This work is the first to tackle QA with GCNs which bring several desirable properties over previous methods, including representation learning (3DCNN, Ornate), geometric invariance (VoroMQA, Ornate), sequence learning (ProQ4, AngularQA), explicit modeling of 3D structure (3DCNN, Ornate, VoroMQA) and computational efficiency.</p>
        </list-item>
        <list-item>
          <p>Thanks to these properties, a simple GCN setup performs similarly to state-of-the-art methods while using a relatively low number of features. Also, the graph network structure provides an improvement over the architecture used in ProQ4. This is demonstrated through extensive experiments on multiple datasets and scoring regimes.</p>
        </list-item>
        <list-item>
          <p>Novel representation techniques are used to explicitly reflect the sequential (residue separation) and 3D structure (angles, spatial distance and secondary structure) of proteins.</p>
        </list-item>
        <list-item>
          <p>Enabled by the use of GCN, we combine the optimization of local and global predictions for QA, improving over the performance of global-only or local-only scoring methods.</p>
        </list-item>
        <list-item>
          <p>Through an extensive set of ablation studies, the significance of different components of the method, including architecture, loss and features, are carefully analyzed.</p>
        </list-item>
      </list>
    </sec>
  </sec>
  <sec>
    <title>2 Materials and methods</title>
    <p>We start describing our method by arguing for the representation of protein molecules as graphs in learning tasks, then we define the problem of protein QA, and finally, we introduce the GraphQA architecture.</p>
    <sec>
      <title>2.1 Protein representation as graphs</title>
      <p>Proteins are large molecular structures that perform vital functions in all living organisms. At the chemical level, a protein consists of one or more chains of smaller molecules, which we interchangeably refer to as <bold>residues</bold> for their role in the chain, or as <bold>amino acids</bold> for their chemical composition. The sequence of residues <inline-formula id="IE1"><mml:math id="IM1" display="inline" overflow="scroll"><mml:mrow><mml:mi>S</mml:mi><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> that composes a protein represents its <italic toggle="yes">primary structure</italic>, where <italic toggle="yes">a<sub>i</sub></italic> is one of the 22 amino acid types (20 natural ones, plus Selenocysteine and Pyrrolysine). The interactions between neighboring residues and the environment dictate how the chain will fold into complex spatial structures that represent the protein’s <italic toggle="yes">secondary structure</italic> and <italic toggle="yes">tertiary structure</italic>.</p>
      <p>Therefore, a suitable representation for any learning task should reflect both the identity and sequence of the residues, i.e. the primary structure, and geometric information about the protein’s arrangement in space, i.e. its tertiary structure (<xref rid="btaa714-F2" ref-type="fig">Fig. 2</xref>). Some works use RNN or 1D-CNN to model proteins as a flat sequence of residues with the spatial structure potentially embedded in the handcrafted residue features (<xref rid="btaa714-B7" ref-type="bibr">Conover <italic toggle="yes">et al.</italic>, 2019</xref>; <xref rid="btaa714-B17" ref-type="bibr">Hurtado <italic toggle="yes">et al.</italic>, 2018</xref>). Other works model proteins’ spatial structure using volumes of atomic densities and 3D-CNNs, but do not explicitly use the sequential information contained in the residue chain (<xref rid="btaa714-B9" ref-type="bibr">Derevyanko <italic toggle="yes">et al.</italic>, 2018</xref>; <xref rid="btaa714-B38" ref-type="bibr">Pagès <italic toggle="yes">et al.</italic>, 2018</xref>). We argue that graph-based learning can explicitly model both the sequential and geometric structures of proteins. Moreover, it accommodates proteins of different lengths and spatial extent and is invariant to rotations and translations.
</p>
      <fig position="float" id="btaa714-F2">
        <label>Fig. 2.</label>
        <caption>
          <p>Protein representations for learning. Sequential representations for LSTM or 1D-CNN fail to represent spatial proximity of non-consecutive residues. Volumetric representations for 3D-CNN fail instead to capture sequence information and are not rotation invariant. Protein graphs explicitly represent both sequential and spatial structure, and are geometrically invariant by design</p>
        </caption>
        <graphic xlink:href="btaa714f2" position="float"/>
      </fig>
      <p>In the simplest form, a protein can be represented as a linear graph, where nodes represent amino acids and edges connect consecutive residues according to the primary structure. This set of edges, which represent the covalent <bold>bonds</bold> that form the protein backbone, can be extended to include the interactions between non-consecutive residues, e.g. through Van der Waals forces or hydrogen bonds, commonly denoted as <bold>contacts</bold>. By forming an edge between all pairs of residues that are within a chemically reasonable distance of each other, the graph becomes a rich representation of both the sequential and geometric structure of the protein (<xref rid="btaa714-F2" ref-type="fig">Fig. 2</xref>). To spatially locate residues and measure distances, we consider the coordinates of alpha carbons. We refer to this representation, composed of residues, bonds and contacts, as the <bold>protein graph</bold>:
<disp-formula id="E1"><mml:math id="M1" display="block" overflow="scroll"><mml:mrow><mml:mi mathvariant="script">P</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mo>{</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">v</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>}</mml:mo><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mo>{</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">e</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mtext>bond</mml:mtext></mml:mrow></mml:msubsup><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:mi>i</mml:mi><mml:mo>−</mml:mo><mml:mi>j</mml:mi><mml:mo>|</mml:mo><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>}</mml:mo><mml:mo>∪</mml:mo><mml:mo>{</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">e</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mtext>contact</mml:mtext></mml:mrow></mml:msubsup><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:mi>i</mml:mi><mml:mo>−</mml:mo><mml:mi>j</mml:mi><mml:mo>|</mml:mo><mml:mo>&gt;</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mrow><mml:mo>‖</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>‖</mml:mo></mml:mrow><mml:mo>≤</mml:mo><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mtext>max</mml:mtext></mml:mrow></mml:msub><mml:mo>}</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where <inline-formula id="IE2"><mml:math id="IM2" display="inline" overflow="scroll"><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mo>|</mml:mo><mml:mi>S</mml:mi><mml:mo>|</mml:mo></mml:mrow></mml:math></inline-formula> are residue indices, <inline-formula id="IE3"><mml:math id="IM3" display="inline" overflow="scroll"><mml:mrow><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mi>z</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> are the coordinates of each residue’s alpha carbon, representing the protein’s <bold>conformation</bold>, and <inline-formula id="IE4"><mml:math id="IM4" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mtext>max</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> is a cutoff distance for contacts.</p>
      <p>With the protein’s structure encoded in the graph, additional residue and relationship features can be encoded as nodes and edges attributes, <inline-formula id="IE5"><mml:math id="IM5" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">v</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE6"><mml:math id="IM6" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">e</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> respectively. Section 3.2 describes, in detail, an attribution that preserves the sequence information and 3D geometry while remaining invariant to rotation.</p>
    </sec>
    <sec>
      <title>2.2 Protein quality assessment</title>
      <p>Experimental identification of a protein’s <bold>native structure</bold> can be time consuming and prohibitively expensive. Alternatively, computational folding methods are used to generate <bold>decoy</bold> conformations for a specific <bold>target</bold> protein. Since no single method is consistently best, a QA step is used to identify the conformations <italic toggle="yes">C<sup>d</sup></italic> that most correctly represent the native structure.</p>
      <p>If the native structure <inline-formula id="IE7"><mml:math id="IM7" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mtext>native</mml:mtext></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> is experimentally determined, the quality of a decoy can be measured by comparing the decoy with the native structure. In the CASP challenge, decoys submitted for a target are scored against the unreleased native structure. Some QA methods compute global (per decoy) scores, which can be used for ranking and represent the principal factor for CASP, while others produce local (per residue) scores which help identify incorrect parts of a decoy (<xref rid="btaa714-B45" ref-type="bibr">Uziela <italic toggle="yes">et al.</italic>, 2018</xref>).</p>
      <p>In most scenarios, however, the native structure is not available, and quality must be estimated based on physical and chemical properties of the decoy, e.g. in drug development, it would be unpractical to synthesize samples of novel proteins and researchers rely on computational folding and QA instead.</p>
      <p>Here, we introduce GraphQA, a graph-based neural network that learns to predict global and local QA scores, with a relatively low number of features and minimal model engineering, using existing datasets of scored proteins. At the residue level, GraphQA is trained to output the Local Distance Difference Test (<xref rid="btaa714-B30" ref-type="bibr">Mariani <italic toggle="yes">et al.</italic>, 2013</xref>) and the Contact Area Difference (<xref rid="btaa714-B37" ref-type="bibr">Olechnovič <italic toggle="yes">et al.</italic>, 2013</xref>) scores. For a residue <italic toggle="yes">i</italic>, we denote them as: <inline-formula id="IE8"><mml:math id="IM8" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mi>i</mml:mi><mml:mi>ℓ</mml:mi></mml:msubsup><mml:mo>:</mml:mo><mml:mo>=</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mtext>LDDT</mml:mtext></mml:mrow></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mtext>CAD</mml:mtext></mml:mrow></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></inline-formula>.</p>
      <p>At the decoy level, GraphQA is trained to output widely used scores: Global Distance Test Total Score, which is the official CASP score for protein-level QA, Global Distance Test High Accuracy (<xref rid="btaa714-B52" ref-type="bibr">Zemla, 2003</xref>), TM-score (<xref rid="btaa714-B53" ref-type="bibr">Zhang and Skolnick, 2004</xref>) and the global versions of LDDT and CAD. Together, we denote them as: <inline-formula id="IE9"><mml:math id="IM9" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mi>g</mml:mi></mml:msup><mml:mo>:</mml:mo><mml:mo>=</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mtext>GDT</mml:mtext><mml:mo>_</mml:mo><mml:mtext>TS</mml:mtext><mml:mo>,</mml:mo><mml:mtext>GDT</mml:mtext><mml:mo>_</mml:mo><mml:mtext>HA</mml:mtext><mml:mo>,</mml:mo><mml:mtext>TM</mml:mtext><mml:mo>,</mml:mo><mml:mtext>LDDT</mml:mtext><mml:mo>,</mml:mo><mml:mtext>CAD</mml:mtext><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></inline-formula>.</p>
      <p>With <inline-formula id="IE10"><mml:math id="IM10" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mtext>GraphQA</mml:mtext></mml:mrow></mml:mrow><mml:mi>i</mml:mi><mml:mi>ℓ</mml:mi></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="script">P</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE11"><mml:math id="IM11" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mtext>GraphQA</mml:mtext></mml:mrow></mml:mrow><mml:mi>g</mml:mi></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="script">P</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> denoting the network’s local and global predictions for an input <inline-formula id="IE12"><mml:math id="IM12" display="inline" overflow="scroll"><mml:mi mathvariant="script">P</mml:mi></mml:math></inline-formula>, the learning objective is to minimize the following Mean Squared Error (MSE) losses:
<disp-formula id="E2"><label>(1)</label><mml:math id="M2" display="block" overflow="scroll"><mml:mrow><mml:mtable><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow/></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow><mml:mi>ℓ</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mi>i</mml:mi><mml:mrow><mml:mo>|</mml:mo><mml:mi>S</mml:mi><mml:mo>|</mml:mo></mml:mrow></mml:munderover><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mtext>GraphQA</mml:mtext></mml:mrow></mml:mrow><mml:mi>i</mml:mi><mml:mi>ℓ</mml:mi></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="script">P</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msubsup><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mi>i</mml:mi><mml:mi>ℓ</mml:mi></mml:msubsup></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow/></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow><mml:mi>g</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mtext>GraphQA</mml:mtext></mml:mrow></mml:mrow><mml:mi>g</mml:mi></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="script">P</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mi>g</mml:mi></mml:msup></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p>
      <p>Note that, for the sole purpose of sorting decoy according to ground-truth quality, training with a ranking loss would be sufficient (<xref rid="btaa714-B9" ref-type="bibr">Derevyanko <italic toggle="yes">et al.</italic>, 2018</xref>). Instead, MSE forces the output to match the quality score, which is a harder objective, but results in a network can be more easily inspected and possibly used to improve existing folding methods in an end-to-end fashion (Section 4.3).</p>
    </sec>
    <sec>
      <title>2.3 GraphQA architecture</title>
      <p>GraphQA is a GCN that operates on protein graphs using the message-passing algorithm described by <xref rid="btaa714-B5" ref-type="bibr">Battaglia <italic toggle="yes">et al.</italic> (2018)</xref>. The building block of GraphQA, a graph layer, takes a protein graph as input (with an additional global feature <inline-formula id="IE13"><mml:math id="IM13" display="inline" overflow="scroll"><mml:mi mathvariant="bold-italic">u</mml:mi></mml:math></inline-formula>), and performs the following propagation steps to output a graph with updated node/edge/global features and unchanged structure:
<disp-formula id="E3"><mml:math id="M3" display="block" overflow="scroll"><mml:mtable columnalign="left"><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mi mathvariant="bold-italic">e</mml:mi><mml:msub><mml:mrow><mml:mo>′</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mi>ϕ</mml:mi></mml:mrow><mml:mi>e</mml:mi></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">e</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">v</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">v</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">u</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mtext>Update edges</mml:mtext></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold-italic">e</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:msub><mml:mrow><mml:mo>′</mml:mo></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>e</mml:mi><mml:mo>→</mml:mo><mml:mi>v</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mi mathvariant="bold-italic">e</mml:mi><mml:msub><mml:mrow><mml:mo>′</mml:mo></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>}</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mtext>Aggregate edges</mml:mtext></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mi mathvariant="bold-italic">v</mml:mi><mml:msub><mml:mrow><mml:mo>′</mml:mo></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mi>ϕ</mml:mi></mml:mrow><mml:mi>v</mml:mi></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold-italic">e</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:msub><mml:mrow><mml:mo>′</mml:mo></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">v</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">u</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mtext>Update nodes</mml:mtext></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold-italic">e</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mo>′</mml:mo><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>e</mml:mi><mml:mo>→</mml:mo><mml:mi>u</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mi mathvariant="bold-italic">e</mml:mi><mml:msub><mml:mrow><mml:mo>′</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>}</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mtext>Aggregate all edges</mml:mtext></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold-italic">v</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mo>′</mml:mo><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>v</mml:mi><mml:mo>→</mml:mo><mml:mi>u</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mi mathvariant="bold-italic">v</mml:mi><mml:msub><mml:mrow><mml:mo>′</mml:mo></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>}</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mtext>Aggregate all nodes</mml:mtext></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mo>′</mml:mo><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mi>ϕ</mml:mi></mml:mrow><mml:mi>u</mml:mi></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold-italic">e</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mo>′</mml:mo><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mi mathvariant="bold-italic">v</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mo>′</mml:mo><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">u</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mtext>Update global features</mml:mtext></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>where <inline-formula id="IE14"><mml:math id="IM14" display="inline" overflow="scroll"><mml:mo>ϕ</mml:mo></mml:math></inline-formula> represent three update functions that transform nodes/edges/global features (e.g. a MLP), and <italic toggle="yes">ρ</italic> represent three pooling functions that aggregate features at various levels (e.g. sum or mean).</p>
      <p>Similarly to CNNs, multiple graph layers are stacked to propagate local information to increasingly larger neighborhoods, i.e. receptive field. This enables the network to learn quality-related features at multiple scales: secondary structures in the first layers, e.g. <italic toggle="yes">α</italic>-helices and <italic toggle="yes">β</italic>-sheets, and larger structures in deeper layers e.g. domain structures and arrangements.</p>
      <p>The GraphQA architecture is conceptually divided into three stages (<xref rid="btaa714-F1" ref-type="fig">Fig. 1</xref>). At the input, the <bold>encoder</bold> increases the node and edge features’ dimensions through <inline-formula id="IE15"><mml:math id="IM15" display="inline" overflow="scroll"><mml:mrow><mml:mn>2</mml:mn><mml:mo>×</mml:mo></mml:mrow></mml:math></inline-formula> (Linear-Dropout-ReLU) transformation and adds a global bias. Then, at its core, <italic toggle="yes">L</italic> <bold>message-passing</bold> layers operate on the encoded graph, leveraging its structure to propagate and aggregate information. The update functions <inline-formula id="IE16"><mml:math id="IM16" display="inline" overflow="scroll"><mml:mo>ϕ</mml:mo></mml:math></inline-formula> consist of Linear-Dropout-ReLU transformations, with the size of the linear layers progressively decreasing. We use average pooling for the aggregation functions <italic toggle="yes">ρ</italic>, since preliminary experiments with max/sum pooling performed poorly. Finally, the <bold>readout</bold> layer outputs local and global quality scores by applying a Linear-Sigmoid operation to the latest node and global features, respectively.</p>
    </sec>
  </sec>
  <sec>
    <title>3 Experiments</title>
    <sec>
      <title>3.1 Datasets</title>
      <p>Following the common practice in QA, we use the data from past years’ editions of CASP, encompassing several targets with multiple scored decoys each. From CASP 9–12, we assemble a dataset of 85k decoys <inline-formula id="IE17"><mml:math id="IM17" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="script">P</mml:mi><mml:mo>,</mml:mo><mml:mo>{</mml:mo><mml:msubsup><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mi>i</mml:mi><mml:mi>ℓ</mml:mi></mml:msubsup><mml:mo>}</mml:mo><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mi>g</mml:mi></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>, which we randomly split into a training set (∼270 targets) and a validation set for hyperparameter optimization (∼50 targets). These targets are also used for the extensive ablation studies described in Section 4.2 and in <xref rid="sup1" ref-type="supplementary-material">Supplementary Appendix</xref> S4. To compare GraphQA against other top-scoring methods, we collect the ∼14k stage-2 decoys across 72 targets of CASP 13 as a test set. We obtain ground-truth scores for training and evaluation by comparing each decoy with the released native structure. Further details on data collection and processing are available in <xref rid="sup1" ref-type="supplementary-material">Supplementary Appendix</xref> S2.1.</p>
    </sec>
    <sec>
      <title>3.2 Features</title>
      <p><bold>Node features</bold> The node attributes <inline-formula id="IE18"><mml:math id="IM18" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">v</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> of a protein graph <inline-formula id="IE19"><mml:math id="IM19" display="inline" overflow="scroll"><mml:mi mathvariant="script">P</mml:mi></mml:math></inline-formula> represent the identity, statistical and structural features of the <italic toggle="yes">i</italic>th residue. We encode the residue identity using a one-of-22 encoding of the corresponding amino acid. Following <xref rid="btaa714-B17" ref-type="bibr">Hurtado <italic toggle="yes">et al.</italic> (2018)</xref>, we also add residue-level statistics computed using Multiple Sequence Alignment (MSA) (<xref rid="btaa714-B40" ref-type="bibr">Rost <italic toggle="yes">et al.</italic>, 1994</xref>), namely <italic toggle="yes">self-information</italic> and <italic toggle="yes">partial entropy</italic>, each described by a 23-dimensional vector. Finally, we add a 14-dimensional vector of spatial features including the dihedral angles, surface accessibility and secondary structure type as determined by DSSP (<xref rid="btaa714-B22" ref-type="bibr">Kabsch and Sander, 1983</xref>).</p>
      <p><bold>Edge features</bold> An edge represents either a contact or a bond between two residues <italic toggle="yes">i</italic> and <italic toggle="yes">j</italic> w.r.t. to the conformation <inline-formula id="IE20"><mml:math id="IM20" display="inline" overflow="scroll"><mml:mrow><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mi>z</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula>. An edge always exists between two consecutive residues, while non-consecutive residues are only connected if <inline-formula id="IE21"><mml:math id="IM21" display="inline" overflow="scroll"><mml:mrow><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:mo>&lt;</mml:mo><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mtext>max</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, with <inline-formula id="IE22"><mml:math id="IM22" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mtext>max</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> optimized on the validation set. We further enrich this connectivity structure by encoding spatial and sequential distances as an 8D feature vector <inline-formula id="IE23"><mml:math id="IM23" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">e</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>. Spatial distance is encoded using a radial basis function <inline-formula id="IE24"><mml:math id="IM24" display="inline" overflow="scroll"><mml:mrow><mml:mtext>exp</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mo>−</mml:mo><mml:msubsup><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mo>/</mml:mo><mml:mo>σ</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, with <italic toggle="yes">σ</italic> determined on the validation set. Sequential distance is defined as the number of amino acids between the two residues in the sequence and expressed using a <bold>separation encoding</bold>, i.e. a one-hot encoding of the separation <inline-formula id="IE25"><mml:math id="IM25" display="inline" overflow="scroll"><mml:mrow><mml:mo>|</mml:mo><mml:mi>i</mml:mi><mml:mo>−</mml:mo><mml:mi>j</mml:mi><mml:mo>|</mml:mo></mml:mrow></mml:math></inline-formula> according to the classes <inline-formula id="IE26"><mml:math id="IM26" display="inline" overflow="scroll"><mml:mrow><mml:mo>{</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>3</mml:mn><mml:mo>,</mml:mo><mml:mn>4</mml:mn><mml:mo>,</mml:mo><mml:mn>5</mml:mn><mml:mo>:</mml:mo><mml:mn>10</mml:mn><mml:mo>,</mml:mo><mml:mo>&gt;</mml:mo><mml:mn>10</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula>.</p>
    </sec>
    <sec>
      <title>3.3 Optimization and hyperparameter search</title>
      <p>The MSE losses in <xref rid="E2" ref-type="disp-formula">Equation 1</xref> are weighted as <inline-formula id="IE27"><mml:math id="IM27" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">tot</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mi>ℓ</mml:mi></mml:msub><mml:msub><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow><mml:mi>ℓ</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mi>g</mml:mi></mml:msub><mml:msub><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow><mml:mi>g</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and minimized using Adam Optimizer (<xref rid="btaa714-B24" ref-type="bibr">Kingma and Ba, 2014</xref>) with <italic toggle="yes">L</italic><sub>2</sub> regularization. GraphQA is significantly faster to train than LSTM or 3D-CNN methods, e.g. 35 epochs take <inline-formula id="IE28"><mml:math id="IM28" display="inline" overflow="scroll"><mml:mrow><mml:mo>∼</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula> hours on one NVIDIA 2080Ti GPU with batches of 200 graphs, thus allowing for an extensive hyperparameter search. <xref rid="sup1" ref-type="supplementary-material">Supplementary Appendix</xref> S3.2 reports search space, optimization procedure and the parameters of the model with highest <inline-formula id="IE29"><mml:math id="IM29" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mtext>target</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> on the validation set.</p>
    </sec>
  </sec>
  <sec>
    <title>4 Evaluation</title>
    <p>We compare GraphQA with other single-model methods which are top-performing in CASP13 and/or represent a relevant approach for QA. ProQ3D computes fixed-size statistical descriptions of the decoys in CASP 9-10, including Rosetta energy terms, which are then used to train a Multilayer Perceptron on quality scores (<xref rid="btaa714-B44" ref-type="bibr">Uziela <italic toggle="yes">et al.</italic>, 2017</xref>). In ProQ4, a 1D-CNN is trained to predict LDDT scores from a vectorized representation of protein sequences, a global score is then obtained by averaging over all residues (<xref rid="btaa714-B17" ref-type="bibr">Hurtado <italic toggle="yes">et al.</italic>, 2018</xref>). ProQ4 is pretrained on a large dataset of protein secondary structures and then fine-tuned on CASP 9-10 using a Siamese configuration to improve ranking performances. 3DCNN (group name: LamoureuxLab) trains a CNN on a three-dimensional representation of atomic densities to rank the decoys in CASP 7–10 according to their GDT_TS scores (<xref rid="btaa714-B9" ref-type="bibr">Derevyanko <italic toggle="yes">et al.</italic>, 2018</xref>). Notably, no additional feature is used other than atomic structure and type, however, the fixed-size volumetric representation of this method is sensitive to rotations and does not scale well with protein size. Ornate (group name: 3DCNN) applies a similar 3D approach to predict local CAD scores and achieves rotation invariance by specifying a canonical residue-centered orientation (<xref rid="btaa714-B38" ref-type="bibr">Pagès <italic toggle="yes">et al.</italic>, 2018</xref>). Although optimized for local scoring, the average of the predicted scores is shown to correlate well with GDT_TS. AngularQA, feeds a sequence-like representation of the protein structures from 3DRobot and CASP 9–12 to an LSTM to predict GDT_TS scores (<xref rid="btaa714-B7" ref-type="bibr">Conover <italic toggle="yes">et al.</italic>, 2019</xref>). VoroMQA is a statistical potential method that represents an alternative to the other machine learning-based methods (<xref rid="btaa714-B37" ref-type="bibr">Olechnovič <italic toggle="yes">et al.</italic>, 2013</xref>). SART (group name: SASHAN) combines statistical- and consistency-based terms to predict global and local scores (<xref rid="btaa714-B6" ref-type="bibr">Cheng <italic toggle="yes">et al.</italic>, 2019</xref>).</p>
    <sec>
      <title>4.1 Results</title>
      <p>We evaluate all methods on a common subset of 72 CASP13 targets for which official submissions are publicly available (list in <xref rid="sup1" ref-type="supplementary-material">Supplementary Appendix</xref> S6).</p>
      <p><bold>Global metrics</bold> For the main experiments, we restrict the evaluation of global performances to GDT_TS, since it is the official score for CASP and all participants are expected to submit predictions for GDT_TS. Further results for GDT_HA and TM-score are available in the <xref rid="sup1" ref-type="supplementary-material">Supplementary Material</xref>. For each QA method, we consider the predicted and ground-truth scores and compute: Root Mean Squared Error (RMSE), Pearson correlation coefficient computed across all decoys of all targets (<italic toggle="yes">R</italic>), Pearson correlation coefficient computed on a per-target basis and then averaged over all targets (<inline-formula id="IE30"><mml:math id="IM30" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mtext>target</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>), <italic toggle="yes">z</italic>-score of the top-scoring decoy of each target and averaged across targets (<italic toggle="yes">z</italic>), and the minimum difference between the true score of the best decoy and the true scores of the five highest-ranking decoys for each target averaged over targets (<inline-formula id="IE31"><mml:math id="IM31" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mtext>FRL</mml:mtext></mml:mrow></mml:mrow><mml:mn>5</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>).</p>
      <p><bold>Local metrics</bold> GraphQA predicts LDDT and CAD scores, to enable a valid comparison with the local scores predicted by other methods, we compute the absolute Spearman correlation coefficient between predicted and ground-truth scores. Specifically, we compute: Spearman correlation coefficient across all residues of all decoys of all targets (<italic toggle="yes">ρ</italic>), and Spearman correlation coefficient on a per-decoy basis and then averaged over all decoys of all targets (<inline-formula id="IE32"><mml:math id="IM32" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mo>ρ</mml:mo></mml:mrow><mml:mrow><mml:mtext>decoy</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>). Of these, we focus on <inline-formula id="IE33"><mml:math id="IM33" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mtext>target</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE34"><mml:math id="IM34" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mo>ρ</mml:mo></mml:mrow><mml:mrow><mml:mtext>decoy</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, which, respectively, measure the ability to rank decoys by quality and to distinguish the correctly predicted parts of a model from those that need improvement. See <xref rid="sup1" ref-type="supplementary-material">Supplementary Appendix</xref> S5 for more details and definitions.</p>
      <p><xref rid="btaa714-T1" ref-type="table">Table 1</xref> compares the performances of GraphQA and other state-of-the-art single-model methods on GDT_TS predictions for CASP13, while <xref rid="btaa714-F3" ref-type="fig">Figure 3</xref> contains a graphical representation of true versus predicted GDT_TS and LDDT scores for all targets in CASP13. At the global level, a noticeably higher <inline-formula id="IE35"><mml:math id="IM35" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mtext>target</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> metric indicates that GraphQA is more capable than other state-of-the-art single-model QA methods at ranking decoys of a target based on their overall quality. The 95% confidence interval for <inline-formula id="IE36"><mml:math id="IM36" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mtext>target</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> computed using the Fisher <italic toggle="yes">r</italic>-to-<italic toggle="yes">z</italic> method is <inline-formula id="IE37"><mml:math id="IM37" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mn>.772</mml:mn><mml:mo>,</mml:mo><mml:mn>.786</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></inline-formula>. Additional results for our method are reported in <xref rid="sup1" ref-type="supplementary-material">Supplementary Appendix</xref> S6.
</p>
      <fig position="float" id="btaa714-F3">
        <label>Fig. 3.</label>
        <caption>
          <p>Joint plots of LDDT and GDT_TS scores on CASP13. The marginal plots show the distribution of true versus predicted scores</p>
        </caption>
        <graphic xlink:href="btaa714f3" position="float"/>
      </fig>
      <table-wrap position="float" id="btaa714-T1">
        <label>Table 1.</label>
        <caption>
          <p>CASP13 global quality assessment</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1">Method</th>
              <th rowspan="1" colspan="1">RMSE ↓</th>
              <th rowspan="1" colspan="1">
                <inline-formula id="IE38">
                  <mml:math id="IM38" display="inline" overflow="scroll">
                    <mml:mrow>
                      <mml:mi>R</mml:mi>
                      <mml:mo>↑</mml:mo>
                    </mml:mrow>
                  </mml:math>
                </inline-formula>
              </th>
              <th rowspan="1" colspan="1">
                <inline-formula id="IE39">
                  <mml:math id="IM39" display="inline" overflow="scroll">
                    <mml:mrow>
                      <mml:msub>
                        <mml:mrow>
                          <mml:mi>R</mml:mi>
                        </mml:mrow>
                        <mml:mrow>
                          <mml:mtext>target</mml:mtext>
                        </mml:mrow>
                      </mml:msub>
                      <mml:mo>↑</mml:mo>
                    </mml:mrow>
                  </mml:math>
                </inline-formula>
              </th>
              <th rowspan="1" colspan="1"><italic toggle="yes">z</italic> ↑</th>
              <th rowspan="1" colspan="1">
                <inline-formula id="IE40">
                  <mml:math id="IM40" display="inline" overflow="scroll">
                    <mml:mrow>
                      <mml:msub>
                        <mml:mrow>
                          <mml:mrow>
                            <mml:mtext>FRL</mml:mtext>
                          </mml:mrow>
                        </mml:mrow>
                        <mml:mn>5</mml:mn>
                      </mml:msub>
                      <mml:mo>↓</mml:mo>
                    </mml:mrow>
                  </mml:math>
                </inline-formula>
              </th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">
                <bold>GraphQA</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.130</bold>
              </td>
              <td rowspan="1" colspan="1">0.855</td>
              <td rowspan="1" colspan="1">
                <bold>0.779</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>1.274</bold>
              </td>
              <td rowspan="1" colspan="1">0.030</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">ModFOLD7_rank</td>
              <td rowspan="1" colspan="1">0.156</td>
              <td rowspan="1" colspan="1">
                <bold>0.872</bold>
              </td>
              <td rowspan="1" colspan="1">0.742</td>
              <td rowspan="1" colspan="1">1.063</td>
              <td rowspan="1" colspan="1">
                <bold>0.023</bold>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">
                <bold>GraphQA-RAW</bold>
              </td>
              <td rowspan="1" colspan="1">0.158</td>
              <td rowspan="1" colspan="1">0.769</td>
              <td rowspan="1" colspan="1">0.720</td>
              <td rowspan="1" colspan="1">0.962</td>
              <td rowspan="1" colspan="1">0.051</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">ProQ4</td>
              <td rowspan="1" colspan="1">0.176</td>
              <td rowspan="1" colspan="1">0.698</td>
              <td rowspan="1" colspan="1">0.664</td>
              <td rowspan="1" colspan="1">0.870</td>
              <td rowspan="1" colspan="1">0.028</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">FaeNNz</td>
              <td rowspan="1" colspan="1">0.141</td>
              <td rowspan="1" colspan="1">0.803</td>
              <td rowspan="1" colspan="1">0.661</td>
              <td rowspan="1" colspan="1">0.865</td>
              <td rowspan="1" colspan="1">0.032</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">ProQ3D</td>
              <td rowspan="1" colspan="1">0.146</td>
              <td rowspan="1" colspan="1">0.802</td>
              <td rowspan="1" colspan="1">0.637</td>
              <td rowspan="1" colspan="1">0.815</td>
              <td rowspan="1" colspan="1">0.024</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">VoroMQA-A</td>
              <td rowspan="1" colspan="1">0.208</td>
              <td rowspan="1" colspan="1">0.657</td>
              <td rowspan="1" colspan="1">0.555</td>
              <td rowspan="1" colspan="1">0.755</td>
              <td rowspan="1" colspan="1">0.041</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Ornate</td>
              <td rowspan="1" colspan="1">0.205</td>
              <td rowspan="1" colspan="1">0.478</td>
              <td rowspan="1" colspan="1">0.490</td>
              <td rowspan="1" colspan="1">0.535</td>
              <td rowspan="1" colspan="1">0.058</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">PLU-AngularQA</td>
              <td rowspan="1" colspan="1">0.193</td>
              <td rowspan="1" colspan="1">0.574</td>
              <td rowspan="1" colspan="1">0.421</td>
              <td rowspan="1" colspan="1">0.425</td>
              <td rowspan="1" colspan="1">0.049</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">MULTICOM_CLUSTER</td>
              <td rowspan="1" colspan="1">0.103</td>
              <td rowspan="1" colspan="1">0.908</td>
              <td rowspan="1" colspan="1">0.839</td>
              <td rowspan="1" colspan="1">1.112</td>
              <td rowspan="1" colspan="1">0.025</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">UOSHAN</td>
              <td rowspan="1" colspan="1">0.090</td>
              <td rowspan="1" colspan="1">0.925</td>
              <td rowspan="1" colspan="1">0.865</td>
              <td rowspan="1" colspan="1">1.122</td>
              <td rowspan="1" colspan="1">0.030</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn1">
            <p><italic toggle="yes">Note</italic>: RMSE, Pearson corr., <italic toggle="yes">z</italic>-score and top-5 rank loss w.r.t. GDT_TS scores (normalized in [0,1]). Top: single-models methods sorted by <inline-formula id="IE41"><mml:math id="IM41" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mtext>target</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>. At the bottom: consensus methods for context. Best results in bold.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p>Evaluation metrics for local quality predictions w.r.t. ground-truth CAD and LDDT scores are reported in <xref rid="btaa714-T2" ref-type="table">Table 2</xref>. At the local level, our method proves to be on a par with best-performing methods, demonstrating the ability to evaluate quality at the residue level and distinguishing correctly predicted parts of the protein chain. Interestingly, GraphQA and ProQ4 use the same input features and they both co-optimize for local and global predictions, but the former achieves much better performances than the latter. We argue that the graph-based architecture allows GraphQA to capture more complex and long-range dependencies between residues than the Siamese 1D-CNN used in ProQ4 (<xref rid="btaa714-F6" ref-type="fig">Fig. 6</xref>).
</p>
      <table-wrap position="float" id="btaa714-T2">
        <label>Table 2.</label>
        <caption>
          <p>CASP13 local quality assessment</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1"/>
              <th colspan="2" rowspan="1">CAD<hr/></th>
              <th colspan="2" rowspan="1">LDDT<hr/></th>
            </tr>
            <tr>
              <th rowspan="1" colspan="1">Method</th>
              <th rowspan="1" colspan="1">
                <inline-formula id="IE42">
                  <mml:math id="IM42" display="inline" overflow="scroll">
                    <mml:mrow>
                      <mml:mo>|</mml:mo>
                      <mml:mo>ρ</mml:mo>
                      <mml:mo>|</mml:mo>
                      <mml:mo>↑</mml:mo>
                    </mml:mrow>
                  </mml:math>
                </inline-formula>
              </th>
              <th rowspan="1" colspan="1">
                <inline-formula id="IE43">
                  <mml:math id="IM43" display="inline" overflow="scroll">
                    <mml:mrow>
                      <mml:mo>|</mml:mo>
                      <mml:msub>
                        <mml:mrow>
                          <mml:mo>ρ</mml:mo>
                        </mml:mrow>
                        <mml:mrow>
                          <mml:mtext>decoy</mml:mtext>
                        </mml:mrow>
                      </mml:msub>
                      <mml:mo>|</mml:mo>
                      <mml:mo>↑</mml:mo>
                    </mml:mrow>
                  </mml:math>
                </inline-formula>
              </th>
              <th rowspan="1" colspan="1">
                <inline-formula id="IE44">
                  <mml:math id="IM44" display="inline" overflow="scroll">
                    <mml:mrow>
                      <mml:mo>|</mml:mo>
                      <mml:mo>ρ</mml:mo>
                      <mml:mo>|</mml:mo>
                      <mml:mo>↑</mml:mo>
                    </mml:mrow>
                  </mml:math>
                </inline-formula>
              </th>
              <th rowspan="1" colspan="1">
                <inline-formula id="IE45">
                  <mml:math id="IM45" display="inline" overflow="scroll">
                    <mml:mrow>
                      <mml:mo>|</mml:mo>
                      <mml:msub>
                        <mml:mrow>
                          <mml:mi>ρ</mml:mi>
                        </mml:mrow>
                        <mml:mrow>
                          <mml:mtext>decoy</mml:mtext>
                        </mml:mrow>
                      </mml:msub>
                      <mml:mo>|</mml:mo>
                      <mml:mo>↑</mml:mo>
                    </mml:mrow>
                  </mml:math>
                </inline-formula>
              </th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">ProQ3D-lDDT</td>
              <td rowspan="1" colspan="1">0.611</td>
              <td rowspan="1" colspan="1">0.380</td>
              <td rowspan="1" colspan="1">0.754</td>
              <td rowspan="1" colspan="1">
                <bold>0.543</bold>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">
                <bold>GraphQA</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.664</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.423</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.797</bold>
              </td>
              <td rowspan="1" colspan="1">0.527</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">FaeNNz</td>
              <td rowspan="1" colspan="1">0.648</td>
              <td rowspan="1" colspan="1">0.361</td>
              <td rowspan="1" colspan="1">0.794</td>
              <td rowspan="1" colspan="1">0.523</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">ModFOLD7</td>
              <td rowspan="1" colspan="1">0.523</td>
              <td rowspan="1" colspan="1">0.336</td>
              <td rowspan="1" colspan="1">0.678</td>
              <td rowspan="1" colspan="1">0.501</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">ProQ3D-CAD</td>
              <td rowspan="1" colspan="1">0.638</td>
              <td rowspan="1" colspan="1">0.415</td>
              <td rowspan="1" colspan="1">0.728</td>
              <td rowspan="1" colspan="1">0.499</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">
                <bold>GraphQA-RAW</bold>
              </td>
              <td rowspan="1" colspan="1">0.613</td>
              <td rowspan="1" colspan="1">0.385</td>
              <td rowspan="1" colspan="1">0.730</td>
              <td rowspan="1" colspan="1">0.497</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">ProQ4</td>
              <td rowspan="1" colspan="1">0.549</td>
              <td rowspan="1" colspan="1">0.326</td>
              <td rowspan="1" colspan="1">0.677</td>
              <td rowspan="1" colspan="1">0.474</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">3DCNN</td>
              <td rowspan="1" colspan="1">0.539</td>
              <td rowspan="1" colspan="1">0.298</td>
              <td rowspan="1" colspan="1">0.688</td>
              <td rowspan="1" colspan="1">0.431</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">VoroMQA-A</td>
              <td rowspan="1" colspan="1">0.499</td>
              <td rowspan="1" colspan="1">0.285</td>
              <td rowspan="1" colspan="1">0.600</td>
              <td rowspan="1" colspan="1">0.412</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Ornate</td>
              <td rowspan="1" colspan="1">0.415</td>
              <td rowspan="1" colspan="1">0.286</td>
              <td rowspan="1" colspan="1">0.462</td>
              <td rowspan="1" colspan="1">0.373</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">UOSHAN</td>
              <td rowspan="1" colspan="1">0.517</td>
              <td rowspan="1" colspan="1">0.317</td>
              <td rowspan="1" colspan="1">0.688</td>
              <td rowspan="1" colspan="1">0.488</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">ModFOLDclust2</td>
              <td rowspan="1" colspan="1">0.486</td>
              <td rowspan="1" colspan="1">0.338</td>
              <td rowspan="1" colspan="1">0.641</td>
              <td rowspan="1" colspan="1">0.512</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn2">
            <p><italic toggle="yes">Note</italic>: Global and per-decoy absolute Spearman corr. are reported w.r.t. ground-truth CAD and LDDT. Above the line: single-models methods sorted by LDDT <inline-formula id="IE46"><mml:math id="IM46" display="inline" overflow="scroll"><mml:mrow><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mtext>decoy</mml:mtext></mml:mrow></mml:msub><mml:mo>|</mml:mo></mml:mrow></mml:math></inline-formula>, consensus methods below. Best results</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p>As shown in our ablation studies, hand-engineered features like MSA and DSSP contribute to the performances of GraphQA (<xref rid="btaa714-F5" ref-type="fig">Fig. 5</xref>), yet we wish to prove that our method can learn directly from raw data. GraphQA-RAW is a variant that relies uniquely on the one-hot encoding of amino acid identity, similarly to how 3D-CNN and Ornate use atomic features only. The results for GraphQA-RAW show that the graph representation and the GCN architecture are effective at automatically extracting features that are almost as expressive as the hand-engineered features used by the full GraphQA.</p>
    </sec>
    <sec>
      <title>4.2 Ablation studies</title>
      <p>Here, we analyze how various components of GraphQA contribute to the final performance, ranging from optimization and architectural choices to protein feature selection. Unless stated otherwise, all ablation studies follow the training procedure described in Section 3.3 for a lower number of epochs. We report results on CASP 11 as mean and std dev of 10 runs.</p>
      <p><bold>Local and global co-optimization</bold> We investigate the interplay between local and global predictions, specifically whether co-optimizing for both is beneficial or detrimental. At the global level, models trained to predict only global scores achieve a global RMSE of <inline-formula id="IE47"><mml:math id="IM47" display="inline" overflow="scroll"><mml:mrow><mml:mn>0.129</mml:mn><mml:mo>±</mml:mo><mml:mn>.007</mml:mn></mml:mrow></mml:math></inline-formula>, whereas models trained to predict both local and global scores obtain <inline-formula id="IE48"><mml:math id="IM48" display="inline" overflow="scroll"><mml:mrow><mml:mn>0.117</mml:mn><mml:mo>±</mml:mo><mml:mn>.006</mml:mn></mml:mrow></mml:math></inline-formula>, suggesting that local scores can provide additional information and help the assessment of global quality. At the local level instead, co-optimization does not seem to improve performances: models trained uniquely on local scores achieve a local RMSE of <inline-formula id="IE49"><mml:math id="IM49" display="inline" overflow="scroll"><mml:mrow><mml:mn>0.121</mml:mn><mml:mo>±</mml:mo><mml:mn>.002</mml:mn></mml:mrow></mml:math></inline-formula>, while models trained to predict both obtain <inline-formula id="IE50"><mml:math id="IM50" display="inline" overflow="scroll"><mml:mrow><mml:mn>0.123</mml:mn><mml:mo>±</mml:mo><mml:mn>.004</mml:mn></mml:mrow></mml:math></inline-formula>.</p>
      <p><bold>Connectivity and architecture</bold> In this study, we test the combined effects of the depth of the network <italic toggle="yes">L</italic> and the cutoff value <inline-formula id="IE51"><mml:math id="IM51" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mtext>max</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>. Every additional message-passing layer allows to aggregate information from a larger neighborhood, effectively extending the receptive field at the readout. Also, the num. of included contacts affects graph connectivity and message propagation: low <inline-formula id="IE52"><mml:math id="IM52" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mtext>max</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> correspond to low average degree and long shortest paths between any two residues, and vice versa (<xref rid="sup1" ref-type="supplementary-material">Supplementary Appendix</xref> S2.2).</p>
      <p>Thus, an architecture that operates on sparsely connected graphs will require more message-passing layers to achieve the same holistic view of a shallow network operating on denser representations. However, this trade-off is only properly exposed if <inline-formula id="IE53"><mml:math id="IM53" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mo>ϕ</mml:mo></mml:mrow><mml:mi>u</mml:mi></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mo>ρ</mml:mo></mml:mrow><mml:mi>u</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula> are removed from the architecture. In fact, a global pathway creates a shortcut that connects all nodes in the graph and sidesteps the limitations of shallow networks. With the global pathway disabled, global predictions are computed in the readout layer by aggregating node features from the last MP layer.</p>
      <p><xref rid="btaa714-F4" ref-type="fig">Figure 4</xref> reports the RMSE obtained by networks of different depths with no global path, operating on protein graphs constructed with different cutoff values. As expected, the shallow 3-layer architecture requires more densely connected inputs to achieve the same performances of the 9-layer network. Surprisingly, local predictions seem to be more affected by these factors than global predictions, suggesting that a large receptive field is important even for local scores.
</p>
      <fig position="float" id="btaa714-F4">
        <label>Fig. 4.</label>
        <caption>
          <p>Trade-off between the number of message-passing layers and the connectivity of the protein graph (CASP11)</p>
        </caption>
        <graphic xlink:href="btaa714f4" position="float"/>
      </fig>
      <p><bold>Node and edge features</bold> We evaluate the impact of node and edge features on the overall prediction performances (<xref rid="btaa714-F5" ref-type="fig">Fig. 5</xref>). For the nodes, we use the amino acid identity as a minimal representation and combine it with: (i) DSSP features, (ii) partial entropy, (iii) self-information, (iv) both DSSP and MSA features. All features improve both local and global scoring, with DSSP features being marginally more relevant for LDDT. For the edges, we evaluate the effect of having either: (i) a binary indicator of bond/contact, (ii) geometric features, i.e. the Euclidean distance between residues, (iii) sequential features, i.e. the categorical encoding of the separation between residues, (iv) both distance and separation encoding. Progressively richer edge features seem to be benefit LDDT predictions, while little improvement can be seen at the global level.
</p>
      <fig position="float" id="btaa714-F5">
        <label>Fig. 5.</label>
        <caption>
          <p>Ablation study of node (top) and edge (bottom) features (validation results on CASP 11). All node features improve both local and global scoring. DSSP features are marginally more relevant for LDDT. Richer edge features benefit LDDT predictions the most, while bringing little improvement to GDT_TS</p>
        </caption>
        <graphic xlink:href="btaa714f5" position="float"/>
      </fig>
    </sec>
    <sec>
      <title>4.3 Visualization and explainability</title>
      <p>Since GraphQA is fully differentiable, the trained model can be used to explain the factors that influenced a low score and thereby provide potentially useful feedback for protein structure refinement. A simple approach for explaining predictions of a differentiable function <inline-formula id="IE54"><mml:math id="IM54" display="inline" overflow="scroll"><mml:mrow><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> is Sensitivity Analysis (<xref rid="btaa714-B4" ref-type="bibr">Baehrens <italic toggle="yes">et al.</italic>, 2010</xref>), which uses <inline-formula id="IE55"><mml:math id="IM55" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>‖</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mo>∇</mml:mo></mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:msub><mml:mi>f</mml:mi></mml:mrow><mml:mo>‖</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> to measure how variations in the input affect the output. In <xref rid="btaa714-F6" ref-type="fig">Figure 6</xref>, we consider the LDDT score predicted for two different residues and compute the magnitude of the gradients w.r.t. the edges of the graph. Thanks to its GCN architecture, GraphQA is able to capture quality-related dependencies not only in the neighborhood of the selected residues, but also further apart in the sequence.
</p>
      <fig position="float" id="btaa714-F6">
        <label>Fig. 6.</label>
        <caption>
          <p>Gradient magnitude of predicted LDDT score w.r.t. the edges of the input graph (T0773). In the edge matrix, a darker red indicates a higher magnitude. The attributions for residue 20 (left) and 60 (right) reveal the long-range dependencies between residues captured by GraphQA</p>
        </caption>
        <graphic xlink:href="btaa714f6" position="float"/>
      </fig>
      <p>We further probe the feasibility of structure refinement with a simple experiment and leave elaborate experiments as future work. If the network has learned a meaningful scoring function, then the gradient of the score w.r.t. the contact distances should aim in the direction of the native structure. Considering all decoys of all targets in CASP 11, we obtain an average cosine similarity <inline-formula id="IE56"><mml:math id="IM56" display="inline" overflow="scroll"><mml:mrow><mml:mtext>cos</mml:mtext><mml:mo> </mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>∂</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mtext>GraphQA</mml:mtext></mml:mrow></mml:mrow><mml:mi>g</mml:mi></mml:msup><mml:mo>/</mml:mo><mml:mo>∂</mml:mo><mml:mi mathvariant="bold-italic">d</mml:mi><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">d</mml:mi></mml:mrow><mml:mrow><mml:mtext>decoy</mml:mtext></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">d</mml:mi></mml:mrow><mml:mrow><mml:mtext>native</mml:mtext></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> of <inline-formula id="IE57"><mml:math id="IM57" display="inline" overflow="scroll"><mml:mrow><mml:mn>0.14</mml:mn><mml:mo>±</mml:mo><mml:mn>.08</mml:mn></mml:mrow></mml:math></inline-formula>, which suggests that gradients can be used as a coarse feedback for end-to-end protein structure prediction.</p>
    </sec>
  </sec>
  <sec>
    <title>5 Conclusion</title>
    <p>We applied GCNs to the important problem of protein QA. Since proteins are naturally represented as graphs, GCN allowed us to collect the individual benefits of the previous QA methods including representation learning, geometric invariance, explicit modeling of sequential and 3D structure, simultaneous local and global scoring, and computational efficiency. Thanks to these benefits, and through an extensive set of experiments, we demonstrated similar performance levels compared to the state-of-the-art in single-model QA using various metrics and datasets. This is achieved using relatively low number of features. We further analyzed the results via thorough ablation and qualitative studies. It is important to note that our tests were conducted offline while the other methods’ performance are taken from the blind test of CASP13 challenge. Thus, a fair comparison will only be possible when the results of CASP14 become available.</p>
    <p>Finally, we believe that richer geometric representations, e.g. including relative rotations, and atom-level graphs could represent an interesting future direction for learning-based QA.</p>
  </sec>
  <sec>
    <title>Funding</title>
    <p>This work was supported by Swedish E-science Research Council, the Swedish National Infrastructure for Computing, and the Swedish Research Council (Vetenskapsrådet). Project 2017-04609 to HA and 2016-03798 to AE.</p>
    <p><italic toggle="yes">Conflict of Interest</italic>: none declared.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material id="sup1" position="float" content-type="local-data">
      <label>btaa714_Supplementary_Data</label>
      <media xlink:href="btaa714_supplementary_data.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="btaa714-B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>AlQuraishi</surname><given-names>M.</given-names></string-name></person-group> (<year>2019</year>) 
<article-title>End-to-end differentiable learning of protein structure</article-title>. <source>Cell Syst</source>., <volume>8</volume>, <fpage>292</fpage>–<lpage>301</lpage>.<pub-id pub-id-type="pmid">31005579</pub-id></mixed-citation>
    </ref>
    <ref id="btaa714-B2">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Anand</surname><given-names>N.</given-names></string-name>, <string-name><surname>Huang</surname><given-names>P.</given-names></string-name></person-group> (<year>2018</year>) Generative modeling for protein structures. In: Bengio,S. <italic toggle="yes">et al</italic>. (eds), Advances in Neural Information Processing Systems 31, Curran Associates, pp. 7494–7505<italic toggle="yes">.</italic></mixed-citation>
    </ref>
    <ref id="btaa714-B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Arnold</surname><given-names>K.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2006</year>) 
<article-title>The SWISS-MODEL workspace: a web-based environment for protein structure homology modelling</article-title>. <source>Bioinformatics</source>, <volume>22</volume>, <fpage>195</fpage>–<lpage>201</lpage>.<pub-id pub-id-type="pmid">16301204</pub-id></mixed-citation>
    </ref>
    <ref id="btaa714-B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Baehrens</surname><given-names>D.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2010</year>) 
<article-title>How to explain individual classification decisions</article-title>. <source>J. Mach. Learn. Res</source>., <volume>11</volume>, <fpage>1803</fpage>–<lpage>1831</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa714-B5">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Battaglia</surname><given-names>P.W.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2018</year>) Relational inductive biases, deep learning, and graph networks. <italic toggle="yes">arXiv preprint arXiv : 1806.01261</italic>.</mixed-citation>
    </ref>
    <ref id="btaa714-B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cheng</surname><given-names>J.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2019</year>) 
<article-title>Estimation of model accuracy in CASP13</article-title>. <source>Proteins</source>, <volume>87</volume>, <fpage>1361</fpage>–<lpage>1377</lpage>.<pub-id pub-id-type="pmid">31265154</pub-id></mixed-citation>
    </ref>
    <ref id="btaa714-B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Conover</surname><given-names>M.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2019</year>) 
<article-title>AngularQA: protein model quality assessment with LSTM networks</article-title>. <source>Comput. Math. Biophys</source>., <volume>7</volume>, <fpage>1</fpage>–<lpage>9</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa714-B8">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cozzetto</surname><given-names>D.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2007</year>) 
<article-title>Assessment of predictions in the model quality assessment category</article-title>. <source>Proteins</source>, <volume>69</volume>, <fpage>175</fpage>–<lpage>183</lpage>.<pub-id pub-id-type="pmid">17680695</pub-id></mixed-citation>
    </ref>
    <ref id="btaa714-B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Derevyanko</surname><given-names>G.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2018</year>) 
<article-title>Deep convolutional networks for quality assessment of protein folds</article-title>. <source>Bioinformatics (Oxford, England)</source>, <volume>34</volume>, <fpage>4046</fpage>–<lpage>4053</lpage>.<pub-id pub-id-type="pmid">29931128</pub-id></mixed-citation>
    </ref>
    <ref id="btaa714-B10">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Duvenaud</surname><given-names>D.K.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2015</year>) Convolutional networks on graphs for learning molecular fingerprints. In: Cortes,C. <italic toggle="yes">et al.</italic> (eds), Advances in Neural Information Processing Systems 28, Curran Associates, Inc. pp. <fpage>2224</fpage>–<lpage>2232</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa714-B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Evans</surname><given-names>R.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2018</year>) 
<article-title>De novo structure prediction with deeplearning based scoring</article-title>. <source>Annu. Rev. Biochem</source>., <volume>77</volume>, <fpage>6</fpage>.</mixed-citation>
    </ref>
    <ref id="btaa714-B12">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Fout</surname><given-names>A.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2017</year>) Protein interface prediction using graph convolutional networks. In: <italic toggle="yes">NeurIPS</italic>, Curran Associates Inc., Red Hook, NY, USA, pp. <fpage>6530</fpage>–<lpage>6539</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa714-B13">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Gao</surname><given-names>K.Y.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2018</year>) Interpretable drug target prediction using deep neural representation. In: <italic toggle="yes">IJCAI</italic>, AAAI Press, pp. <fpage>3371</fpage>–<lpage>3377</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa714-B14">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Gilmer</surname><given-names>J.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2017</year>) Neural message passing for quantum chemistry. In: <italic toggle="yes">Proceedings of the 34th International Conference on Machine Learning. Sydney, NSW, Australia,</italic> Vol. 70, pp. 1263–1272.</mixed-citation>
    </ref>
    <ref id="btaa714-B15">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Gonzalez</surname><given-names>A.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2018</year>) Graph networks as learnable physics engines for inference and control. In: Jennifer,D. <italic toggle="yes">et al.</italic> (eds), Proceedings of Machine Learning Research, Stockholmsmässan, Stockholm Sweden, pp. 4470–4479, PMLR<italic toggle="yes">.</italic></mixed-citation>
    </ref>
    <ref id="btaa714-B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hou</surname><given-names>J.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2019</year>) 
<article-title>Protein tertiary structure modeling driven by deep learning and contact distance prediction in casp13</article-title>. <source>Proteins Struct. Funct. Bioinf</source>., <volume>87</volume>, <fpage>1165</fpage>–<lpage>1178</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa714-B17">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Hurtado</surname><given-names>D.M.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2018</year>) Deep transfer learning in the assessment of the quality of protein models. <italic toggle="yes">arXiv preprint arXiv : 1804.06281.</italic></mixed-citation>
    </ref>
    <ref id="btaa714-B18">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Ingraham</surname><given-names>J.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2019</year>a) Generative models for graph-based protein design. In: Advances in Neural InfAdvances in Neural Information Processing Systems, pp. 15820--15831.</mixed-citation>
    </ref>
    <ref id="btaa714-B19">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Ingraham</surname><given-names>J.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2019</year>b) Learning protein structure with a differentiable simulator. In: <italic toggle="yes">ICLR.</italic></mixed-citation>
    </ref>
    <ref id="btaa714-B20">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Jin</surname><given-names>W.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2019</year>) Learning multimodal graph-to-graph translation for molecular optimization. In: <italic toggle="yes">ICLR. arXiv preprint arXiv:1812.01070.</italic></mixed-citation>
    </ref>
    <ref id="btaa714-B21">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jones</surname><given-names>D.</given-names></string-name>, <string-name><surname>Kandathil</surname><given-names>S.</given-names></string-name></person-group> (<year>2018</year>) 
<article-title>High precision in protein contact prediction using fully convolutional neural networks and minimal sequence features</article-title>. <source>Bioinformatics</source>, <volume>34</volume>, <fpage>3308</fpage>–<lpage>3315</lpage>.<pub-id pub-id-type="pmid">29718112</pub-id></mixed-citation>
    </ref>
    <ref id="btaa714-B22">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kabsch</surname><given-names>W.</given-names></string-name>, <string-name><surname>Sander</surname><given-names>C.</given-names></string-name></person-group> (<year>1983</year>) 
<article-title>Dictionary of protein secondary structure: pattern recognition of hydrogen-bonded and geometrical features</article-title>. <source>Biopolym. Orig. Res. Biomol</source>., <volume>22</volume>, <fpage>2577</fpage>–<lpage>2637</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa714-B23">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Karasikov</surname><given-names>M.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2019</year>) 
<article-title>Smooth orientation-dependent scoring function for coarse-grained protein quality assessment</article-title>. <source>Bioinformatics</source>, <volume>35</volume>, <fpage>2801</fpage>–<lpage>2808</lpage>.<pub-id pub-id-type="pmid">30590384</pub-id></mixed-citation>
    </ref>
    <ref id="btaa714-B24">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Kingma</surname><given-names>D.P.</given-names></string-name>, <string-name><surname>Ba</surname><given-names>J.</given-names></string-name></person-group> (<year>2014</year>) Adam: a method for stochastic optimization. In: Yoshua,B.<italic toggle="yes"> et al</italic>. (eds), <italic toggle="yes">3rd International Conference on Learning Representations, {ICLR} 2015, San Diego, CA, USA, May 7–9, 2015</italic>, Conference Track Proceedings<italic toggle="yes">.</italic></mixed-citation>
    </ref>
    <ref id="btaa714-B25">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Kipf</surname><given-names>T.N.</given-names></string-name>, <string-name><surname>Welling</surname><given-names>M.</given-names></string-name></person-group> (<year>2017</year>) Semi-supervised classification with graph convolutional networks. In: <italic toggle="yes"> 5th International Conference on Learning Representations, {ICLR} 2017, Toulon, France, April 24–26, 2017, Conference Track Proceedings, OpenReview.net.</italic></mixed-citation>
    </ref>
    <ref id="btaa714-B26">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Li</surname><given-names>R.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2018</year>a) Adaptive graph convolutional neural networks. In: <italic toggle="yes">Thirty-Second AAAI Conference on Artificial Intelligence. New Orleans, Louisiana, USA, February 2–7, 2018, pp. 3546--3553.</italic></mixed-citation>
    </ref>
    <ref id="btaa714-B27">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Li</surname><given-names>Y.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2018</year>b) Learning deep generative models of graphs. Learning Deep Generative Models of Graphs.</mixed-citation>
    </ref>
    <ref id="btaa714-B28">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Liu</surname><given-names>Q.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2018</year>) Constrained graph variational autoencoders for molecule design. In: Advances in neural information processing systems, pp. <fpage>7795</fpage>–<lpage>7804</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa714-B29">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lundstrom</surname><given-names>J.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2001</year>) 
<article-title>Pcons: a neural-network-based consensus predictor that improves fold recognition</article-title>. <source>Protein Sci</source>., <volume>10, 2354–2362</volume>.</mixed-citation>
    </ref>
    <ref id="btaa714-B30">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mariani</surname><given-names>V.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2013</year>) 
<article-title>LDDT: a local superposition-free score for comparing protein structures and models using distance difference tests</article-title>. <source>Bioinformatics</source>, <volume>29</volume>, <fpage>2722</fpage>–<lpage>2728</lpage>.<pub-id pub-id-type="pmid">23986568</pub-id></mixed-citation>
    </ref>
    <ref id="btaa714-B31">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>McGuffin</surname><given-names>L.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2019</year>a) 
<article-title>IntFOLD: an integrated web resource for high performance protein structure and function prediction</article-title>. <source>Nucleic Acids Res</source>., <volume>47</volume>, <fpage>W408</fpage>–<lpage>W413</lpage>.<pub-id pub-id-type="pmid">31045208</pub-id></mixed-citation>
    </ref>
    <ref id="btaa714-B32">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>McGuffin</surname><given-names>L.J.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2019</year>b) 
<article-title>IntFOLD: an integrated web resource for high performance protein structure and function prediction</article-title>. <source>Nucleic Acids Res</source>., <volume>47</volume>, <fpage>W408</fpage>–<lpage>W413</lpage>.<pub-id pub-id-type="pmid">31045208</pub-id></mixed-citation>
    </ref>
    <ref id="btaa714-B33">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Moult</surname><given-names>J.</given-names></string-name></person-group>  <etal>et al</etal> (<year>1995</year>) 
<article-title>A large-scale experiment to assess protein structure prediction methods</article-title>. <source>Proteins</source>, <volume>23</volume>, <fpage>ii</fpage>–<lpage>iv</lpage>.<pub-id pub-id-type="pmid">8710822</pub-id></mixed-citation>
    </ref>
    <ref id="btaa714-B34">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Moult</surname><given-names>J.</given-names></string-name></person-group>  <etal>et al</etal> (<year>1999</year>) 
<article-title>Critical assessment of methods of protein structure predictions (CASP): round III</article-title>. <source>Proteins</source>, <volume>3</volume>, <fpage>2</fpage>–<lpage>6</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa714-B35">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Narasimhan</surname><given-names>M.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2018</year>) Out of the box: reasoning with graph convolution nets for factual visual question answering. In: Advances in neural information processing systems, pp. 2654--2665.</mixed-citation>
    </ref>
    <ref id="btaa714-B36">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Niepert</surname><given-names>M.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2016</year>) Learning convolutional neural networks for graphs. In: <italic toggle="yes">International Conference on Machine Learning.</italic> pp. 2014--2023.</mixed-citation>
    </ref>
    <ref id="btaa714-B37">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Olechnovič</surname><given-names>K.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2013</year>) 
<article-title>CAD-score: a new contact area difference-based function for evaluation of protein structural models</article-title>. <source>Proteins Struct. Funct. Bioinf</source>., <volume>81</volume>, <fpage>149</fpage>–<lpage>162</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa714-B38">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Pagès</surname><given-names>G.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2018</year>) Protein model quality assessment using 3D oriented convolutional neural networks. pp. 3313–3319.</mixed-citation>
    </ref>
    <ref id="btaa714-B39">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ray</surname><given-names>A.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2012</year>) 
<article-title>Improved model quality assessment using ProQ2</article-title>. <source>BMC Bioinformatics</source>, <volume>13</volume>, <fpage>224</fpage>.<pub-id pub-id-type="pmid">22963006</pub-id></mixed-citation>
    </ref>
    <ref id="btaa714-B40">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rost</surname><given-names>B.</given-names></string-name></person-group>  <etal>et al</etal> (<year>1994</year>) 
<article-title>Redefining the goals of protein secondary structure prediction</article-title>. <source>J. Mol. Biol</source>., <volume>235</volume>, <fpage>13</fpage>–<lpage>26</lpage>.<pub-id pub-id-type="pmid">8289237</pub-id></mixed-citation>
    </ref>
    <ref id="btaa714-B41">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Simonovsky</surname><given-names>M.</given-names></string-name>, <string-name><surname>Komodakis</surname><given-names>N.</given-names></string-name></person-group> (<year>2018</year>) Graphvae: Towards generation of small graphs using variational autoencoders. In: <italic toggle="yes">International Conference on Artificial Neural Networks</italic>, Cham, pp. 412-422
.</mixed-citation>
    </ref>
    <ref id="btaa714-B42">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Studer</surname><given-names>G.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2020</year>) 
<article-title>Qmeandisco-distance constraints applied on model quality estimation</article-title>. <source>Bioinformatics (Oxford, England)</source>, <volume>36</volume>, <fpage>1765</fpage>–<lpage>1771</lpage>.<pub-id pub-id-type="pmid">31697312</pub-id></mixed-citation>
    </ref>
    <ref id="btaa714-B43">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Uziela</surname><given-names>K.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2016</year>) 
<article-title>ProQ3: improved model quality assessments using Rosetta energy terms</article-title>. <source>Sci. Rep</source>., <volume>6</volume>, <fpage>33509</fpage>.<pub-id pub-id-type="pmid">27698390</pub-id></mixed-citation>
    </ref>
    <ref id="btaa714-B44">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Uziela</surname><given-names>K.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2017</year>) 
<article-title>ProQ3D: improved model quality assessments using deep learning</article-title>. <source>Bioinformatics (Oxford, England)</source>, <volume>33</volume>, <fpage>1578</fpage>.<pub-id pub-id-type="pmid">28052925</pub-id></mixed-citation>
    </ref>
    <ref id="btaa714-B45">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Uziela</surname><given-names>K.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2018</year>) 
<article-title>Improved protein model quality assessments by changing the target function</article-title>. <source>Proteins Struct. Funct. Bioinf</source>., <volume>86</volume>, <fpage>654</fpage>–<lpage>663</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa714-B46">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wallner</surname><given-names>B.</given-names></string-name>, <string-name><surname>Elofsson</surname><given-names>A.</given-names></string-name></person-group> (<year>2003</year>) 
<article-title>Can correct protein models be identified?</article-title>  <source>Protein Sci</source>., <volume>12, 1073--1086</volume>.</mixed-citation>
    </ref>
    <ref id="btaa714-B47">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wallner</surname><given-names>B.</given-names></string-name>, <string-name><surname>Elofsson</surname><given-names>A.</given-names></string-name></person-group> (<year>2006</year>) 
<article-title>Can correct regions in protein models be identified</article-title>. <source>Protein Sci</source>., <volume>15</volume>, <fpage>900</fpage>–<lpage>913</lpage>.<pub-id pub-id-type="pmid">16522791</pub-id></mixed-citation>
    </ref>
    <ref id="btaa714-B48">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname><given-names>S.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2017</year>) 
<article-title>Accurate de novo prediction of protein contact map by ultra-deep learning model</article-title>. <source>PLoS Comput. Biol</source>., <volume>13</volume>, <fpage>e1005324</fpage>.<pub-id pub-id-type="pmid">28056090</pub-id></mixed-citation>
    </ref>
    <ref id="btaa714-B49">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Won</surname><given-names>J.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2019</year>) 
<article-title>Assessment of protein model structure accuracy estimation in casp13: challenges in the era of deep learning</article-title>. <source>Proteins Struct. Funct. Bioinf</source>., <volume>87</volume>, <fpage>1351</fpage>–<lpage>1360</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa714-B50">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Xu</surname><given-names>J.</given-names></string-name></person-group> (<year>2019</year>) 
<article-title>Distance-based protein folding powered by deep learning</article-title>. <source>Proc. Natl. Acad. Sci. USA</source>, <volume>116</volume>, <fpage>16856</fpage>–<lpage>16865</lpage>.<pub-id pub-id-type="pmid">31399549</pub-id></mixed-citation>
    </ref>
    <ref id="btaa714-B51">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>You</surname><given-names>J.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2018</year>) Graph convolutional policy network for goal-directed molecular graph generation. In: Bengio,S. <italic toggle="yes">et al.</italic> (eds.) Advances in neural information processing systems, pp. 6410–6421<italic toggle="yes">.</italic></mixed-citation>
    </ref>
    <ref id="btaa714-B52">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zemla</surname><given-names>A.</given-names></string-name></person-group> (<year>2003</year>) 
<article-title>LGA: a method for finding 3D similarities in protein structures</article-title>. <source>Nucleic Acids Res</source>., <volume>31</volume>, <fpage>3370</fpage>–<lpage>3374</lpage>.<pub-id pub-id-type="pmid">12824330</pub-id></mixed-citation>
    </ref>
    <ref id="btaa714-B53">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname><given-names>Y.</given-names></string-name>, <string-name><surname>Skolnick</surname><given-names>J.</given-names></string-name></person-group> (<year>2004</year>) 
<article-title>Scoring function for automated assessment of protein structure template quality</article-title>. <source>Proteins Struct. Funct. Bioinf</source>., <volume>57</volume>, <fpage>702</fpage>–<lpage>710</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa714-B54">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zitnik</surname><given-names>M.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2018</year>) 
<article-title>Modeling polypharmacy side effects with graph convolutional networks</article-title>. <source>Bioinformatics</source>, <volume>34</volume>, <fpage>i457</fpage>–<lpage>i466</lpage>.<pub-id pub-id-type="pmid">29949996</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
