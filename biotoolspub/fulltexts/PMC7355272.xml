<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1 20151215//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.1?>
<?ConverterInfo.XSLTName jp2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id>
    <journal-id journal-id-type="publisher-id">bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1367-4803</issn>
    <issn pub-type="epub">1367-4811</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">7355272</article-id>
    <article-id pub-id-type="doi">10.1093/bioinformatics/btaa408</article-id>
    <article-id pub-id-type="publisher-id">btaa408</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Macromolecular Sequence, Structure, and Function</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Hopper: a mathematically optimal algorithm for sketching biological data</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>DeMeo</surname>
          <given-names>Benjamin</given-names>
        </name>
        <xref ref-type="aff" rid="btaa408-aff1">b1</xref>
        <xref ref-type="aff" rid="btaa408-aff2">b2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Berger</surname>
          <given-names>Bonnie</given-names>
        </name>
        <xref ref-type="aff" rid="btaa408-aff2">b2</xref>
        <xref ref-type="aff" rid="btaa408-aff3">b3</xref>
        <xref ref-type="corresp" rid="btaa408-cor1"/>
        <!--<email>bab@csail.mit.edu</email>-->
      </contrib>
    </contrib-group>
    <aff id="btaa408-aff1"><label>b1</label><institution>Department of Bioinformatics, Harvard University</institution>, Cambridge, MA 02138, <country country="US">USA</country></aff>
    <aff id="btaa408-aff2">
      <label>b2</label>
      <institution>Computer Science and Artificial Intelligence Laboratory</institution>
    </aff>
    <aff id="btaa408-aff3"><label>b3</label>Department of Mathematics, <institution>Massachusetts Institute of Technology</institution>, Cambridge, MA 02139, <country country="US">USA</country></aff>
    <author-notes>
      <corresp id="btaa408-cor1">To whom correspondence should be addressed. E-mail: <email>bab@csail.mit.edu</email></corresp>
    </author-notes>
    <pub-date pub-type="ppub">
      <month>7</month>
      <year>2020</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2020-07-13">
      <day>13</day>
      <month>7</month>
      <year>2020</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>13</day>
      <month>7</month>
      <year>2020</year>
    </pub-date>
    <!-- PMC Release delay is 0 months and 0 days and was based on the <pub-date pub-type="epub"/>. -->
    <volume>36</volume>
    <issue>Suppl 1</issue>
    <issue-title>ISMB 2020 Proceedings</issue-title>
    <fpage>i236</fpage>
    <lpage>i241</lpage>
    <permissions>
      <copyright-statement>© The Author(s) 2020. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2020</copyright-year>
      <license license-type="cc-by-nc" xlink:href="http://creativecommons.org/licenses/by-nc/4.0/">
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by-nc/4.0/">http://creativecommons.org/licenses/by-nc/4.0/</ext-link>), which permits non-commercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited. For commercial re-use, please contact journals.permissions@oup.com</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="btaa408.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Motivation</title>
        <p>Single-cell RNA-sequencing has grown massively in scale since its inception, presenting substantial analytic and computational challenges. Even simple downstream analyses, such as dimensionality reduction and clustering, require days of runtime and hundreds of gigabytes of memory for today’s largest datasets. In addition, current methods often favor common cell types, and miss salient biological features captured by small cell populations.</p>
      </sec>
      <sec id="s2">
        <title>Results</title>
        <p>Here we present Hopper, a single-cell toolkit that both speeds up the analysis of single-cell datasets and highlights their transcriptional diversity by intelligent subsampling, or <italic>sketching</italic>. Hopper realizes the optimal polynomial-time approximation of the Hausdorff distance between the full and downsampled dataset, ensuring that each cell is well-represented by some cell in the sample. Unlike prior sketching methods, Hopper adds points iteratively and allows for additional sampling from regions of interest, enabling fast and targeted multi-resolution analyses. In a dataset of over 1.3 million mouse brain cells, Hopper detects a cluster of just 64 macrophages expressing inflammatory genes (0.004% of the full dataset) from a Hopper sketch containing just 5000 cells, and several other small but biologically interesting immune cell populations invisible to analysis of the full data. On an even larger dataset consisting of ∼2 million developing mouse organ cells, we show Hopper’s even representation of important cell types in small sketches, in contrast with prior sketching methods. We also introduce Treehopper, which uses spatial partitioning to speed up Hopper by orders of magnitude with minimal loss in performance. By condensing transcriptional information encoded in large datasets, Hopper and Treehopper grant the individual user with a laptop the analytic capabilities of a large consortium.</p>
      </sec>
      <sec id="s3">
        <title>Availability and implementation</title>
        <p>The code for Hopper is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/bendemeo/hopper">https://github.com/bendemeo/hopper</ext-link>. In addition, we have provided sketches of many of the largest single-cell datasets, available at <ext-link ext-link-type="uri" xlink:href="http://hopper.csail.mit.edu">http://hopper.csail.mit.edu</ext-link>.</p>
      </sec>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>National Institutes of Health</institution>
            <institution-id institution-id-type="DOI">10.13039/100000002</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>R01GM081871</award-id>
        <award-id>R01GM108348</award-id>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="6"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 Introduction</title>
    <p>Recent improvements in single-cell technologies have enabled high-throughput profiling of individual cells, allowing fine-grained analyses of biological tissues. Droplet-based technologies have enabled profiling of millions of cells in a single experiment. Even larger datasets, containing tens or hundreds of millions or even billions of cells, are imminent (<xref rid="btaa408-B1" ref-type="bibr">Angerer <italic>et al.</italic>, 2017</xref>). For example, the Human Cell Atlas project aims to characterize and classify all cells in the human body (<xref rid="btaa408-B13" ref-type="bibr">Rozenblatt-Rosen <italic>et al.</italic>, 2017</xref>).</p>
    <p>While these large-scale assays have enormous scientific and therapeutic potential, they also present significant computational and analytic challenges. Even the most basic exploratory analyses—visualization, clustering and removal of batch effects—become intractable for more than tens of thousands of cells. Clinically or scientifically relevant cells are often far outnumbered by common cell types (<xref rid="btaa408-B7" ref-type="bibr">Hie <italic>et al.</italic>, 2019</xref>). Thus, there is a pressing need to produce <italic>sketches</italic> that reduce the size of single-cell datasets while preserving their transcriptional diversity.</p>
    <p>There are several recent methods with this aim. Dropclust (<xref rid="btaa408-B15" ref-type="bibr">Sinha <italic>et al.</italic>, 2018</xref>) performs Louvain clustering on an approximate nearest-neighbor network (<xref rid="btaa408-B2" ref-type="bibr">Blondel <italic>et al.</italic>, 2008</xref>), and uses the resulting clusters as points of reference for downsampling. However, clustering itself is a very difficult and computationally expensive task, with the quality of the resulting sketches depending entirely on the clustering algorithm. The recently introduced Geometric Sketching (<xref rid="btaa408-B7" ref-type="bibr">Hie <italic>et al.</italic>, 2019</xref>) samples evenly across transcriptional space by covering the Principal component-reduced dataset with a gapped grid of disjoint axis-aligned hypercubes of uniform size, and sampling a point at random from each. Geometric Sketching is very fast; yet, as we shall show, the fixed gridding axis can lead to artificial clusters near the grid intersections, potentially negatively affecting downstream analyses. Moreover, neither of these methods provides mathematical guarantees as to the approximation quality of the output sketches.</p>
    <p>To address these challenges, we introduce Hopper, a novel toolkit that produces sketches with mathematical optimality guarantees on the distance from a point in the original data to the nearest point in the sketch. It achieves this result by implementing <italic>farthest-first traversal</italic>, a provably optimal polynomial-time approximation to the <italic>k</italic>-center problem.</p>
    <p>Intuitively, this means that every point in the full dataset <italic>X</italic> is very close to some point in the sketch <italic>S</italic>. Compared to Geometric Sketching, the current state of the art, Hopper dramatically improves the quality of sketches as measured by the Hausdorff distance, and better represents low-dimensional substructures without artifacts introduced by gridding. Unlike all prior methods, Hopper allows fast insertion and removal of cells from the sketch, whilst preserving strong mathematical guarantees. This enables fast multi-resolution analyses of large datasets.</p>
    <p>Hopper uses the triangle inequality to speed up farthest-first traversal, yielding feasible runtimes on today’s largest datasets. However, producing large sketches of large datasets is slow compared to Geometric Sketching (<xref ref-type="fig" rid="btaa408-F1">Fig. 1</xref>). To address this issue, we introduce Treehopper, which leverages spatial partitioning to reduce the runtime by orders of magnitude without significant loss in performance. In particular, Treehopper yields lower Hausdorff distances than any prior approach, with speed comparable to or faster than Geometric Sketching (<xref ref-type="fig" rid="btaa408-F1">Fig. 1</xref>). We thus recommend Treehopper as the state of the art for sketching large datasets.
</p>
    <fig id="btaa408-F1" orientation="portrait" position="float">
      <label>Fig. 1.</label>
      <caption>
        <p>Hausdorff distances and runtimes for various Hopper and Treehopper routines, with Geometric Sketching for comparison, on ∼1.3 million mouse neurons (<bold>a</bold>, <bold>b</bold>) and ∼2 million developing organ cells (<bold>c</bold>, <bold>d</bold>). For the Treehopper tests, the number of partitions <italic>d</italic> is indicated parenthetically in the legends. The basic Hopper routine produces the lowest Hausdorff distance obtainable in polynomial time, with our faster Treehopper routines nearly realizing the optimum. All significantly outperform Geometric Sketching, and show more consistent Hausdorff performance. Both Hopper and Treehopper take time linear in the sketch size, with slope depending on the overall dataset size and the degree of pre-partitioning. Geometric Sketching performs variably depending on the dataset’s geometry</p>
      </caption>
      <graphic xlink:href="btaa408f1"/>
    </fig>
    <p>The code for Hopper and Treehopper is freely available at <ext-link ext-link-type="uri" xlink:href="https://github.com/bendemeo/hopper">https://github.com/bendemeo/hopper</ext-link>. In addition, we have provided pre-computed sketches of many of the largest single-cell datasets, available at <ext-link ext-link-type="uri" xlink:href="http://hopper.csail.mit.edu">http://hopper.csail.mit.edu</ext-link>.</p>
  </sec>
  <sec>
    <title>2 Algorithm</title>
    <sec>
      <title>2.1 Overview of Hopper</title>
      <p>At the core of Hopper is the <italic>farthest-first traversal</italic>, an elegant greedy approximation to the <italic>k</italic>-center problem. Here the goal is to minimize, for some sample <italic>S</italic> of size <italic>k</italic> from a ground set <italic>X</italic>, the <italic>Hausdorff distance</italic><disp-formula id="E1"><mml:math id="M1"><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mi mathvariant="normal">H</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>S</mml:mi><mml:mo>,</mml:mo><mml:mi>X</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>max</mml:mi><mml:mo>⁡</mml:mo></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mo>∈</mml:mo><mml:mi>X</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>min</mml:mi><mml:mo>⁡</mml:mo></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mo>∈</mml:mo><mml:mi>S</mml:mi></mml:mrow></mml:msub><mml:mi>d</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></disp-formula>where <italic>d</italic> is a metric of choice (in our experiments, we use the Euclidean metric).</p>
      <p>The algorithm works by sampling an initial point from <italic>X</italic> at random, and repeatedly adding to the sample the point <italic>p</italic> that is furthest from any of the previously sampled points:
<disp-formula id="E2"><label>(1)</label><mml:math id="M2"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mtext>arg</mml:mtext><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mtext>max</mml:mtext></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mo>∈</mml:mo><mml:mi>X</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>min</mml:mi><mml:mo>⁡</mml:mo></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mo>∈</mml:mo><mml:mi>S</mml:mi></mml:mrow></mml:msub><mml:mi>d</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p>
      <p>Intuitively, we repeatedly add to <italic>S</italic> the point of <italic>X</italic> that is least well-represented by <italic>S</italic>. We call this <italic>hopping</italic>, and implement it in the "hop" function of the Hopper module.</p>
      <p>By design, this method is guaranteed to strictly decrease the Hausdorff distance <inline-formula id="IE1"><mml:math id="IM1"><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mi mathvariant="normal">H</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:mi>S</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> after each step, assuming that the maximum is realized by only one point. In fact, one can show the following:<statement id="mthst1"><p><sc>Theorem</sc> 1. <italic>Suppose that S is a k-step farthest traversal of X. Then</italic>,
<disp-formula id="E3"><mml:math id="M3"><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mi mathvariant="normal">H</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:mi>S</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>≤</mml:mo><mml:mn>2</mml:mn><mml:msubsup><mml:mi>d</mml:mi><mml:mi mathvariant="normal">H</mml:mi><mml:mrow><mml:mtext>opt</mml:mtext></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></disp-formula><italic>where</italic> <inline-formula id="IE2"><mml:math id="IM2"><mml:mrow><mml:msubsup><mml:mi>d</mml:mi><mml:mi mathvariant="normal">H</mml:mi><mml:mrow><mml:mtext>opt</mml:mtext></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula><italic>is the optimal Hausdorff distance realized by any subset of size k.</italic></p><p>Thus, farthest-first traversal realizes a 2-approximation to the optimal Hausdorff distance. The proof of this Theorem is found in the study by <xref rid="btaa408-B4" ref-type="bibr">Gonzalez (1985)</xref>. The following theorem, due to <xref rid="btaa408-B8" ref-type="bibr">Hochba (1997)</xref>, shows that we cannot reasonably hope to do any better:</p></statement><statement id="mthst2"><p><sc>Theorem</sc> 2. <italic>Let</italic> <inline-formula id="IE3"><mml:math id="IM3"><mml:mrow><mml:mo>α</mml:mo><mml:mo>&lt;</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula><italic>. Then, unless P = NP, there is no polynomial time algorithm for producing a set S satisfying</italic><disp-formula id="E4"><mml:math id="M4"><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mi mathvariant="normal">H</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:mi>S</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>≤</mml:mo><mml:mo>α</mml:mo><mml:mo>·</mml:mo><mml:msubsup><mml:mi>d</mml:mi><mml:mi mathvariant="normal">H</mml:mi><mml:mrow><mml:mtext>opt</mml:mtext></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Thus, Hopper provides a gold-standard for sketching in the sense that no algorithm can reliably obtain a better Hausdorff distance, unless <italic>P</italic> = <italic>NP</italic>. The output of Hopper is an ordered collection of <inline-formula id="IE4"><mml:math id="IM4"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> of cells from <italic>X</italic>, such that for any <inline-formula id="IE5"><mml:math id="IM5"><mml:mrow><mml:mo>ℓ</mml:mo><mml:mo>≤</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:math></inline-formula>, the subset <inline-formula id="IE6"><mml:math id="IM6"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mo>ℓ</mml:mo></mml:msub></mml:mrow></mml:math></inline-formula> reaches within a factor of two of the lowest possible Hausdorff distance for any sketch of size <inline-formula id="IE7"><mml:math id="IM7"><mml:mo>ℓ</mml:mo></mml:math></inline-formula>.</p></statement></p>
      <sec>
        <title>2.1.1 Geometric speedups</title>
        <p>The most computationally expensive aspect of farthest-first traversals is identifying the point <italic>p</italic> from <xref ref-type="disp-formula" rid="E2">Equation 1</xref>. To do so, one must maintain for each <inline-formula id="IE8"><mml:math id="IM8"><mml:mrow><mml:mi>x</mml:mi><mml:mo>∈</mml:mo><mml:mi>X</mml:mi></mml:mrow></mml:math></inline-formula>, the distance to the nearest point in <italic>S</italic>. Each time a point is added to <italic>S</italic>, these distances must be updated. A naïve approach computes the distance from every <inline-formula id="IE9"><mml:math id="IM9"><mml:mrow><mml:mi>x</mml:mi><mml:mo>∈</mml:mo><mml:mi>X</mml:mi></mml:mrow></mml:math></inline-formula> to the newly added <italic>p</italic>, and updates the minimum distances accordingly. This requires <italic>O</italic>(<italic>n</italic>) time for each point addition, where <italic>n</italic> is the size of <italic>X</italic>. Producing a sketch of size <italic>k</italic> thus takes <italic>O</italic>(<italic>nk</italic>) time, which can be prohibitive for large sketches of large datasets.</p>
        <p>Various speedups have been proposed in the theoretical computer science community (e.g. <xref rid="btaa408-B6" ref-type="bibr">Har-Peled and Mendel, 2006</xref>), but all scale poorly with the dimensionality of the dataset. Instead, Hopper implements two simple geometric speedups using the triangle inequality. First, if the newly added point <italic>p</italic> has distance <italic>r</italic> to its nearest representative in <italic>S</italic>, then by the triangle inequality,
<disp-formula id="E5"><mml:math id="M5"><mml:mrow><mml:mi>r</mml:mi><mml:mo>≤</mml:mo><mml:mi>d</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>≤</mml:mo><mml:mi>d</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>d</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></disp-formula>for any <inline-formula id="IE10"><mml:math id="IM10"><mml:mrow><mml:mi>s</mml:mi><mml:mo>∈</mml:mo><mml:mi>S</mml:mi></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE11"><mml:math id="IM11"><mml:mrow><mml:mi>x</mml:mi><mml:mo>∈</mml:mo><mml:mi>X</mml:mi></mml:mrow></mml:math></inline-formula>. In particular, if <inline-formula id="IE12"><mml:math id="IM12"><mml:mrow><mml:mi>d</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>≤</mml:mo><mml:mi>d</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, then we must have <inline-formula id="IE13"><mml:math id="IM13"><mml:mrow><mml:mi>d</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>≥</mml:mo><mml:mfrac><mml:mi>r</mml:mi><mml:mn>2</mml:mn></mml:mfrac></mml:mrow></mml:math></inline-formula>. Thus, we need only examine those points in <italic>X</italic> with distance <inline-formula id="IE14"><mml:math id="IM14"><mml:mrow><mml:mo>≥</mml:mo><mml:mfrac><mml:mi>r</mml:mi><mml:mn>2</mml:mn></mml:mfrac></mml:mrow></mml:math></inline-formula> to their nearest point in <italic>S</italic>. To quickly find these points, the points <italic>X</italic> are sorted by their distance to the nearest point of <italic>S</italic>. Second, for <inline-formula id="IE15"><mml:math id="IM15"><mml:mrow><mml:mi>s</mml:mi><mml:mo>∈</mml:mo><mml:mi>S</mml:mi></mml:mrow></mml:math></inline-formula>, if <inline-formula id="IE16"><mml:math id="IM16"><mml:mrow><mml:mi>d</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>≥</mml:mo><mml:mn>2</mml:mn><mml:mi>r</mml:mi></mml:mrow></mml:math></inline-formula>, then if <inline-formula id="IE17"><mml:math id="IM17"><mml:mrow><mml:mi>x</mml:mi><mml:mo>∈</mml:mo><mml:mi>X</mml:mi></mml:mrow></mml:math></inline-formula> is closest to <italic>s</italic>, the triangle inequality gives:
<disp-formula id="E6"><mml:math id="M6"><mml:mrow><mml:mi>d</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>≥</mml:mo><mml:mi>d</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mi>d</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>≥</mml:mo><mml:mi>r</mml:mi></mml:mrow></mml:math></disp-formula>so there is no need to update any of the points associated to <italic>s</italic>. These two observations often allow significantly fewer than <italic>n</italic> points to be examined at each iteration. The exact runtime depends on the dimensionality and geometry of the dataset (<xref rid="btaa408-B19" ref-type="bibr">Yu <italic>et al.</italic>, 2015</xref>), but in practice the speedup is noticeable, especially for the first few thousand cells (<xref ref-type="fig" rid="btaa408-F1">Fig. 1</xref>).</p>
      </sec>
    </sec>
    <sec>
      <title>2.2 Overview of Treehopper</title>
      <p>In spite of the speedups discussed above, Hopper may still be prohibitively slow on very large datasets (<xref ref-type="fig" rid="btaa408-F1">Fig. 1</xref>). We therefore introduce Treehopper, a derivative of Hopper which newly uses spatial partitioning to drastically speed up sketch generation, with little loss in performance. The dataset <italic>X</italic> is first divided into disjoint subsets <inline-formula id="IE18"><mml:math id="IM18"><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>d</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> using Principal Component Trees (PC-trees), which hierarchically split the data into equal halves along the leading principal component (<xref rid="btaa408-B16" ref-type="bibr">Verma <italic>et al.</italic>, 2009</xref>). A Hopper <italic>H<sub>i</sub></italic> is instantiated in each partition <italic>X<sub>i</sub></italic>, beginning a farthest-first traversal <italic>S<sub>i</sub></italic> of <italic>X<sub>i</sub></italic>. These Hoppers are sorted according to their Hausdorff distance <inline-formula id="IE19"><mml:math id="IM19"><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mi mathvariant="normal">H</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>. At each step, the Hopper with highest Hausdorff distance hops, adding a point to <italic>S<sub>i</sub></italic>, and adjusting its position in the sorted list of Hoppers. The final sketch is the union of all the sub-traversals <italic>S<sub>i</sub></italic>.</p>
      <p>Treehopper is inspired in part by Geometric Sketching, which demonstrates the utility of spatial partitioning for rapid sketch generation. However, in contrast with Geometric Sketching, where the partitions are all hypercubes of the same size and a point is drawn from each, Treehopper allows partitions to occupy variable-sized regions of transcriptional space, and draws variable numbers of points from the partitions according to their individual geometries. Thus, Treehopper bridges the gap between the fast partition-and-sample approach and the slower, but mathematically optimal, farthest-first traversal approach. We thus recommend Treehopper, and incorporate it into Hopper as the method of choice.</p>
      <p>Using a fast heap implementation, Treehopper achieves an average hop time of <inline-formula id="IE20"><mml:math id="IM20"><mml:mrow><mml:mi>O</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo>/</mml:mo><mml:mi>d</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> instead of <italic>O</italic>(<italic>n</italic>). Within each partition, the traversals <italic>S<sub>i</sub></italic> realize the optimality bound of Theorem 1, but this bound may not be achieved globally. This tradeoff between time and performance is fully tunable. If <italic>d </italic>=<italic> </italic>1, we achieve optimal polynomial-time performance in <italic>O</italic>(<italic>nk</italic>) worst-case time. On the other extreme, if <italic>d </italic>=<italic> n</italic>, a random subsample is produced in <italic>O</italic>(<italic>k</italic>) time. For <italic>d</italic>-values in the tens to hundreds, these methods produce drastic speedups with little loss in accuracy, sketching today’s largest datasets with very low Hausdorff distance in a matter of minutes (<xref ref-type="fig" rid="btaa408-F1">Fig. 1</xref>). Thus, Treehopper improves the state of the art in both time and sketch quality.</p>
    </sec>
  </sec>
  <sec>
    <title>3 Experimental results</title>
    <sec>
      <title>3.1 Hopper better approximates biological datasets</title>
      <p>We assessed our method’s performance on two of the largest published single-cell RNA-seq experiments: A set of 1.3 million mouse neurons from 10X Genomics, and a set of ∼2 million mammalian organogenesis cells (<xref rid="btaa408-B3" ref-type="bibr">Cao <italic>et al.</italic>, 2019</xref>). Each dataset underwent standard normalization and feature selection protocols, and was projected to its first 100 independent components. Consistent with our mathematical guarantees, Hopper obtained Hausdorff distances significantly lower than any prior sketching technique, showing empirically that all cells in the dataset are better-represented (<xref ref-type="fig" rid="btaa408-F1">Fig. 1a, c</xref>). These improvements remained significant even when Treehopper was used with as many as 256 pre-partitions, suggesting that pre-partitioning does not substantially reduce performance. In contrast with Geometric Sketching, Hausdorff distance decreases smoothly as the number of points increases, likely because Hopper and Treehopper are highly sensitive to individual outliers. Hopper, Treehopper and Geometric Sketching all require memory approximately equal to the size of the input dataset (data not shown).</p>
      <p>As expected, Hopper and Treehopper run approximately linearly in the dataset size, with slopes depending on the number of pre-partitions (<xref ref-type="fig" rid="btaa408-F1">Fig. 1</xref>). Geometric Sketching shows variable time performance between the two tested datasets. We suspect that because Geometric Sketching relies on a binary search to select the correct grid size, runtime is heavily impacted by the number of search iterations needed, which depends rather unpredictably on the starting grid size and on the dataset’s geometry. Because even small sketch sizes may require several iterations, this leads to slower performance for small sketch sizes. On the other hand, the runtime may be faster for larger sketches (<xref ref-type="fig" rid="btaa408-F1">Fig. 1b, d</xref>).</p>
    </sec>
    <sec>
      <title>3.2 Hopper reveals novel clusters of immune cells in mouse brain data</title>
      <p>Clustering is a key step in the analysis of single-cell data, allowing identification of known cell types, and discovery of new cell types, in a sample. Hopper facilitates better clustering by representing rare clusters even with small sketches. To demonstrate this, we used Hopper to order the first 5000 cells (about 0.4%) of the 1.3 million neuron dataset, and clustered the resulting cells using Louvain community detection (<xref rid="btaa408-B2" ref-type="bibr">Blondel <italic>et al.</italic>, 2008</xref>). These cluster labels were then propagated to the full dataset via nearest-neighbor classification. The detected clusters, plotted and annotated in <xref ref-type="fig" rid="btaa408-F2">Figure 2(a)</xref>, reveal several small but interesting cellular populations. For example one of the clusters, consisting of a mere 64 cells, showed elevated expression of the <italic>Cd5l</italic> gene, which is expressed by macrophages in inflamed tissues (<xref rid="btaa408-B14" ref-type="bibr">Sanjurjo <italic>et al.</italic>, 2015</xref>) (<xref ref-type="fig" rid="btaa408-F2">Fig. 2a</xref>). Another cluster consisted of just 114 cells with elevated expression of <italic>Pf4</italic> and <italic>F13a1</italic>, marker genes for activated platelets (<xref rid="btaa408-B12" ref-type="bibr">Newman and Chong, 2000</xref>) (<xref ref-type="fig" rid="btaa408-F2">Fig. 2a, c</xref>). Another, consisting of just 221 cells, showed elevated expression the Interferon-<italic>β</italic> gene <italic>Ifnb1</italic>, expressed in fibroblasts and monocytes in response to viral infection (<xref rid="btaa408-B9" ref-type="bibr">Hu <italic>et al.</italic>, 2007</xref>). Clusters 2–4 express canonical microglial markers, highlighting the transcriptional diversity of this group (<xref rid="btaa408-B5" ref-type="bibr">Hammond <italic>et al.</italic>, 2019</xref>; <xref rid="btaa408-B11" ref-type="bibr">Lee <italic>et al.</italic>, 2008</xref>). <xref ref-type="fig" rid="btaa408-F2">Figure 2(c)</xref> shows expression heatmaps for each of these genes. Considering the role of the immune system in modulating disease states, these clusters are likely clinically important despite their small size.
</p>
      <fig id="btaa408-F2" orientation="portrait" position="float">
        <label>Fig. 2.</label>
        <caption>
          <p>(<bold>a</bold>) Louvain clustering on the 5000-cell Hopper sketch of the 1.3 million-cell mouse brain dataset. Each cluster is numbered, and biologically interesting clusters are annotated with their inferred identity. (<bold>b</bold>) Table showing the cell counts per cluster after nearest-neighbor classification on the whole dataset, and the top differentially expressed genes in each cluster. (<bold>c</bold>) Heat maps showing the expression of four different marker genes in a Hopper sketch of 5000 mouse brain cells out of 1.3 million. Elevated CD68 expression in the top half suggests a diverse population of immune cells. (<bold>d</bold>) Louvain clusters computed on the entire dataset fail to distinguish any of the cell subtypes identified by clustering on the sketch (see main text)</p>
        </caption>
        <graphic xlink:href="btaa408f2"/>
      </fig>
      <p><xref ref-type="fig" rid="btaa408-F2">Figure 2(b)</xref> lists all clusters, together with their sizes and differentially expressed genes relative to the total. Remarkably, almost all of the clusters computed from the Hopper sketch are extremely small relative to the full dataset size, indicating that miniscule populations can account for a large proportion of the dataset’s transcriptional diversity. These populations are completely invisible to any analysis of the full dataset. For example the Louvain clustering produced by scanpy (<xref rid="btaa408-B18" ref-type="bibr">Wolf <italic>et al.</italic>, 2018</xref>) on the full dataset lumps all of the immune cell clusters into a single relatively small cluster of 8856 cells, obscuring their true diversity (<xref ref-type="fig" rid="btaa408-F2">Fig. 2d</xref>). This reflects a fundamental limitation of all modularity-based approaches, as documented in <xref rid="btaa408-B10" ref-type="bibr">Kumpula <italic>et al.</italic> (2007)</xref>: as the size of a dataset increases, so does the size of the smallest community that can be detected by modularity optimization. This has serious implications for single-cell pipelines: it is mathematically impossible to detect sufficiently small populations of cells via Louvain clustering, which remains the most popular method. Hopper and Treehopper circumvent this limitation by reducing the overall dataset size whilst retaining rare cell types, thus increasing the proportion of rare cells in the overall sample to the point where Louvain clustering can uncover them. Thus, our sketched datasets are not only more computationally manageable, but allow finer-grained detection of cellular populations as compared to the full data.</p>
    </sec>
    <sec>
      <title>3.3 Hopper samples smoothly across low-dimensional substructures</title>
      <p>Geometric Sketching, the prior state of the art, covers the data with a gapped grid of axis-aligned boxes and samples a point from each box. This is a well-motivated approach that works well on many datasets. However, we have observed that axis-aligned grid hypercubes do not always represent the data evenly, especially where the local low-dimensional structure of the data aligns poorly with the gridding axis (<xref rid="btaa408-B19" ref-type="bibr">Yu <italic>et al.</italic>, 2015</xref>). As demonstrated schematically in <xref ref-type="fig" rid="btaa408-F3">Figure 3(a)</xref>, this results in more points near the grid square intersections. This effect is compounded as the ambient dimension <italic>D</italic> increases, since as many as <inline-formula id="IE21"><mml:math id="IM21"><mml:mrow><mml:msup><mml:mn>2</mml:mn><mml:mi>D</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula> hypercubes may meet. As a result, we observe clumping even when the underlying data are Gaussian (<xref ref-type="fig" rid="btaa408-F3">Fig. 3b</xref>). On the mouse organogenesis dataset, this manifests as additional clusters not present in the Hopper sketches (<xref ref-type="fig" rid="btaa408-F3">Fig. 3d</xref>).
</p>
      <fig id="btaa408-F3" orientation="portrait" position="float">
        <label>Fig. 3.</label>
        <caption>
          <p>Grid-based sketches clump at grid intersections. (<bold>a</bold>) Schematic diagram, assuming the data lies near a one-dimensional line (red) in two-dimensional space. Where the line meets the grid intersection, four points are sampled, causing an artificial clump (circled). This effect is compounded in higher dimensions. (<bold>b</bold>) A sample geometric sketch on 2-D Gaussian data randomly embedded into 100-dimensional space. The 100 sampled points are shown in white, with the remaining points colored by grid cell. The grids partition the data erratically, and regions near grid intersections are preferentially sampled. (<bold>c</bold>) Hopper sketch of the same data, with 100 points colored according to their closest sampled point. The data are smoothly represented. (<bold>d</bold>) UMAP visualizations of sketches produced by Hopper, Geometric Sketching and by Treehopper with 32 partitions, coloured by cell type. Geometric Sketching generates additional clusters at grid intersections. Hopper and Treehopper avoid this issue</p>
        </caption>
        <graphic xlink:href="btaa408f3"/>
      </fig>
      <p>Hopper avoids this issue entirely by not relying on any axis, ensuring that all low-dimensional substructures are smoothly represented regardless of spatial orientation (<xref ref-type="fig" rid="btaa408-F3">Fig. 3c, d</xref>). Sketches produced with Treehopper closely resemble those of Hopper, even with partition sizes less than 5% of the total sample size (<xref ref-type="fig" rid="btaa408-F3">Fig. 3d</xref>).</p>
      <p>We note that the pure-partitioning approach taken by Geometric Sketching does allow remarkably fast runtimes, and the artificial clumping effect does not occur on all datasets; indeed, geometric sketches of the 1.3 million mouse neuron dataset closely resemble Hopper sketches (data not shown). We suspect that the observed defect emerges primarily when the data have high intrinsic dimensionality, i.e. lie on a high-dimensional manifold, because this allows for more high-dimensional intersections between occupied grid hypercubes.</p>
    </sec>
  </sec>
  <sec>
    <title>4 Discussion</title>
    <p>Hopper leverages the mathematical power of farthest-first traversal to produce sketches that preserve a sample’s transcriptional diversity and biological meaning. These sketches are mathematically guaranteed to represent the original data as well as any polynomial-time algorithm, thus providing a much-needed gold standard. By incorporating the powerful partition-and-sample approach implemented in Treehopper, we allow tunable scaling to massive-scale single-cell datasets without excessive computational burden.</p>
    <p>We have provided the first 50 000 cells in the far traversal of two super-massive single-cell RNA-seq datasets. This data require only a few megabytes of storage, but allow immediate production of mathematically optimal sketches of any size smaller than 50 000. This allows the researcher immediate access both to small sketches, which may isolate the rare cell types, and larger sketches, which may be more comprehensive at the expense of obscuring rare cell types. Indeed, the position of a cell in the far traversal produced by Hopper may prove a valuable input to other downstream analyses. For example, one could modify the Louvain community detection algorithm by weighting vertices according to their traversal positions, and modifying the modularity-detection step to ensure that both rare and common clusters are represented.</p>
    <p>The experiments in this article exclusively use Euclidean distance as a measure of dissimilarity, but Hopper also generalizes to arbitrary dissimilarity measures, provided that they satisfy the triangle inequality (e.g. Manhattan distance, Minkowski distance, etc.) Unlike other methods, an explicit embedding of the cells is not required—only a method of determining distance. As demonstrated by kernel support vector machines, this is a highly desirable property. There are several existing machine algorithms for learning discriminative metrics from single cell datasets, which can be directly fed into the Hopper framework. For example SIMLR (<xref rid="btaa408-B17" ref-type="bibr">Wang <italic>et al.</italic>, 2017</xref>) uses machine learning to jointly predict the clustering and the distance measure. Other possibilities abound, from established kernels (e.g. polynomial kernels or radial basis functions) to custom-designed kernels which may incorporate prior knowledge about the relevant factors shaping a dataset’s diversity. Because the distance function can be user-specified, inputting such custom kernels into the Hopper framework is very straightforward.</p>
    <p>Hopper offers a flexible, scalable and mathematically principled workflow for distilling the essence of a single-cell dataset. As these datasets grow, such methods will become increasingly vital for enabling the advanced and computationally expensive downstream workflows that the future of single-cell data undoubtedly holds.</p>
  </sec>
</body>
<back>
  <ack id="ack1">
    <title>Acknowledgements</title>
    <p>The authors are grateful to Brian Hie, Hoon Cho, Ashwin Narayan, Rohit Singh and other members of the Berger lab for valuable feedback and input. We especially thank Brian Hie for his help in producing the sketched datasets available online. The authors also thank Bryan Bryson for his expert help in biologically interpreting the Louvain clusters of the mouse brain data, outlined in <xref ref-type="fig" rid="btaa408-F2">Figure 2(a)</xref>.</p>
    <sec>
      <title>Funding</title>
      <p>This work was supported by the National Institutes of Health [R01GM081871 and R01GM108348 to B.B.].</p>
      <p><italic>Conflict of Interest</italic>: none declared.</p>
    </sec>
  </ack>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="btaa408-B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Angerer</surname><given-names>P.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) 
<article-title>Single cells make big data: new challenges and opportunities in transcriptomics</article-title>. <source>Curr. Opin. Syst. Biol</source>., <volume>4</volume>, <fpage>85</fpage>–<lpage>91</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa408-B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Blondel</surname><given-names>V.D.</given-names></name></person-group><etal>et al</etal> (<year>2008</year>) 
<article-title>Fast unfolding of communities in large networks</article-title>. <source>J. Stat. Mech. Theory Exp</source>., <volume>2008</volume>, <fpage>P10008</fpage>.</mixed-citation>
    </ref>
    <ref id="btaa408-B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Cao</surname><given-names>J.</given-names></name></person-group><etal>et al</etal> (<year>2019</year>) 
<article-title>The single-cell transcriptional landscape of mammalian organogenesis</article-title>. <source>Nature</source>, <volume>566</volume>, <fpage>496</fpage>–<lpage>502</lpage>.<pub-id pub-id-type="pmid">30787437</pub-id></mixed-citation>
    </ref>
    <ref id="btaa408-B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Gonzalez</surname><given-names>T.F.</given-names></name></person-group> (<year>1985</year>) 
<article-title>Clustering to minimize the maximum intercluster distance</article-title>. <source>Theor. Comput. Sci</source>., <volume>38</volume>, <fpage>293</fpage>–<lpage>306</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa408-B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Hammond</surname><given-names>T.R.</given-names></name></person-group><etal>et al</etal> (<year>2019</year>) 
<article-title>Single-cell RNA sequencing of microglia throughout the mouse lifespan and in the injured brain reveals complex cell-state changes</article-title>. <source>Immunity</source>, <volume>50</volume>, <fpage>253</fpage>–<lpage>271</lpage>.<pub-id pub-id-type="pmid">30471926</pub-id></mixed-citation>
    </ref>
    <ref id="btaa408-B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Har-Peled</surname><given-names>S.</given-names></name>, <name name-style="western"><surname>Mendel</surname><given-names>M.</given-names></name></person-group> (<year>2006</year>) 
<article-title>Fast construction of nets in low-dimensional metrics and their applications</article-title>. <source>SIAM J. Comput</source>., <volume>35</volume>, <fpage>1148</fpage>–<lpage>1184</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa408-B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Hie</surname><given-names>B.</given-names></name></person-group><etal>et al</etal> (<year>2019</year>) 
<article-title>Geometric sketching compactly summarizes the single-cell transcriptomic landscape</article-title>. <source>Cell Syst</source>., <volume>8</volume>, <fpage>483</fpage>–<lpage>493.e7</lpage><pub-id pub-id-type="pmid">31176620</pub-id></mixed-citation>
    </ref>
    <ref id="btaa408-B8">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Hochba</surname><given-names>D.S.</given-names></name></person-group> (<year>1997</year>) 
<article-title>Approximation algorithms for NP-hard problems</article-title>. <source>ACM SIGACT News</source>, <volume>28</volume>, <fpage>40</fpage>–<lpage>52</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa408-B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Hu</surname><given-names>J.</given-names></name></person-group><etal>et al</etal> (<year>2007</year>) 
<article-title>Chromosome-specific and noisy IFNB1 transcription in individual virus-infected human primary dendritic cells</article-title>. <source>Nucleic Acids Res</source>., <volume>35</volume>, <fpage>5232</fpage>–<lpage>5241</lpage>.<pub-id pub-id-type="pmid">17675303</pub-id></mixed-citation>
    </ref>
    <ref id="btaa408-B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Kumpula</surname><given-names>J.M.</given-names></name></person-group><etal>et al</etal> (<year>2007</year>) 
<article-title>Limited resolution in complex network community detection with Potts model approach</article-title>. <source>Eur. Phys. J. B</source>, <volume>56</volume>, <fpage>41</fpage>–<lpage>45</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa408-B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Lee</surname><given-names>J.-K.</given-names></name></person-group><etal>et al</etal> (<year>2008</year>) 
<article-title>Regulator of G-protein signaling 10 promotes dopaminergic neuron survival via regulation of the microglial inflammatory response</article-title>. <source>J. Neurosci</source>., <volume>28</volume>, <fpage>8517</fpage>–<lpage>8528</lpage>.<pub-id pub-id-type="pmid">18716210</pub-id></mixed-citation>
    </ref>
    <ref id="btaa408-B12">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Newman</surname><given-names>P.M.</given-names></name>, <name name-style="western"><surname>Chong</surname><given-names>B.H.</given-names></name></person-group> (<year>2000</year>) 
<article-title>Heparin-induced thrombocytopenia: new evidence for the dynamic binding of purified anti-PF4–heparin antibodies to platelets and the resultant platelet activation</article-title>. <source>Blood</source>, <volume>96</volume>, <fpage>182</fpage>–<lpage>187</lpage>.<pub-id pub-id-type="pmid">10891449</pub-id></mixed-citation>
    </ref>
    <ref id="btaa408-B13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Rozenblatt-Rosen</surname><given-names>O.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) 
<article-title>The human cell atlas: from vision to reality</article-title>. <source>Nat. News</source>, <volume>550</volume>, <fpage>451</fpage>–<lpage>453</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa408-B14">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Sanjurjo</surname><given-names>L.</given-names></name></person-group><etal>et al</etal> (<year>2015</year>) 
<article-title>AIM/CD5L: a key protein in the control of immune homeostasis and inflammatory disease</article-title>. <source>J. Leukocyte Biol</source>., <volume>98</volume>, <fpage>173</fpage>–<lpage>184</lpage>.<pub-id pub-id-type="pmid">26048980</pub-id></mixed-citation>
    </ref>
    <ref id="btaa408-B15">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Sinha</surname><given-names>D.</given-names></name></person-group><etal>et al</etal> (<year>2018</year>) 
<article-title>dropClust: efficient clustering of ultra-large scRNA-seq data</article-title>. <source>Nucleic Acids Res</source>., <volume>46</volume>, <fpage>e36</fpage>–<lpage>e36</lpage>.<pub-id pub-id-type="pmid">29361178</pub-id></mixed-citation>
    </ref>
    <ref id="btaa408-B16">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Verma</surname><given-names>N.</given-names></name></person-group><etal>et al</etal> (<year>2009</year>) <chapter-title>Which spatial partition trees are adaptive to intrinsic dimension</chapter-title>? In <source>Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence</source>. 
<publisher-name>AUAI Press</publisher-name>, Montreal, Canada, pp. <fpage>565</fpage>–<lpage>574</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa408-B17">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Wang</surname><given-names>B.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>). Visualization and analysis of single-cell RNA-seq data by kernel-based similarity learning. <italic>Nat. Methods</italic>, <bold>14</bold>, 414--416.</mixed-citation>
    </ref>
    <ref id="btaa408-B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Wolf</surname><given-names>F.A.</given-names></name></person-group><etal>et al</etal> (<year>2018</year>) 
<article-title>SCANPY: large-scale single-cell gene expression data analysis</article-title>. <source>Genome Biol</source>., <volume>19</volume>, <fpage>15</fpage>.<pub-id pub-id-type="pmid">29409532</pub-id></mixed-citation>
    </ref>
    <ref id="btaa408-B19">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Yu</surname><given-names>Y.W.</given-names></name></person-group><etal>et al</etal> (<year>2015</year>) 
<article-title>Entropy-scaling search of massive biological data</article-title>. <source>Cell Syst</source>., <volume>1</volume>, <fpage>130</fpage>–<lpage>140</lpage>.<pub-id pub-id-type="pmid">26436140</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
