<?DTDIdentifier.IdentifierValue -//NPG//DTD XML Article//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName NPG_XML_Article.dtd?>
<?SourceDTD.Version 2.7.10?>
<?ConverterInfo.XSLTName nature2nlmx2.xsl?>
<?ConverterInfo.Version 2?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Nat Commun</journal-id>
    <journal-id journal-id-type="iso-abbrev">Nat Commun</journal-id>
    <journal-title-group>
      <journal-title>Nature Communications</journal-title>
    </journal-title-group>
    <issn pub-type="epub">2041-1723</issn>
    <publisher>
      <publisher-name>Nature Pub. Group</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">4354266</article-id>
    <article-id pub-id-type="pii">ncomms6825</article-id>
    <article-id pub-id-type="doi">10.1038/ncomms6825</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Article</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Visualizing cellular imaging data using PhenoPlot</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Sailem</surname>
          <given-names>Heba Z.</given-names>
        </name>
        <xref ref-type="aff" rid="a1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Sero</surname>
          <given-names>Julia E.</given-names>
        </name>
        <xref ref-type="aff" rid="a1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Bakal</surname>
          <given-names>Chris</given-names>
        </name>
        <xref ref-type="corresp" rid="c1">a</xref>
        <xref ref-type="aff" rid="a1">1</xref>
      </contrib>
      <aff id="a1"><label>1</label><institution>Dynamical Cell Systems, Division of Cancer Biology, Institute of Cancer Research</institution>, 237 Fulham Road, London SW3 6JB, <country>UK</country></aff>
    </contrib-group>
    <author-notes>
      <corresp id="c1">
        <label>a</label>
        <email>cbakal@icr.ac.uk</email>
      </corresp>
    </author-notes>
    <pub-date pub-type="epub">
      <day>08</day>
      <month>01</month>
      <year>2015</year>
    </pub-date>
    <volume>6</volume>
    <elocation-id>5825</elocation-id>
    <history>
      <date date-type="received">
        <day>15</day>
        <month>10</month>
        <year>2014</year>
      </date>
      <date date-type="accepted">
        <day>11</day>
        <month>11</month>
        <year>2014</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>Copyright © 2015, Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.</copyright-statement>
      <copyright-year>2015</copyright-year>
      <copyright-holder>Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.</copyright-holder>
      <license xmlns:xlink="http://www.w3.org/1999/xlink" license-type="open-access" xlink:href="http://creativecommons.org/licenses/by/4.0/">
        <!--author-paid-->
        <license-p>This work is licensed under a Creative Commons Attribution 4.0 International License. The images or other third party material in this article are included in the article’s Creative Commons license, unless indicated otherwise in the credit line; if the material is not included under the Creative Commons license, users will need to obtain permission from the license holder to reproduce the material. To view a copy of this license, visit <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link></license-p>
      </license>
    </permissions>
    <abstract>
      <p>Visualization is essential for data interpretation, hypothesis formulation and communication of results. However, there is a paucity of visualization methods for image-derived data sets generated by high-content analysis in which complex cellular phenotypes are described as high-dimensional vectors of features. Here we present a visualization tool, PhenoPlot, which represents quantitative high-content imaging data as easily interpretable glyphs, and we illustrate how PhenoPlot can be used to improve the exploration and interpretation of complex breast cancer cell phenotypes.</p>
    </abstract>
    <abstract abstract-type="web-summary">
      <p><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="i1" xlink:href="ncomms6825-i1.jpg"/>Cellular imaging studies can generate large volumes of complex phenotypic data; however, presenting this information in a form that quickly conveys trends in the data set remains a challenge. Sailem <italic>et al.</italic> present a tool which translates such data into easily interpretable cell-like glyphs.</p>
    </abstract>
  </article-meta>
</front>
<body>
  <p>Using microscopy and computer vision methods, researchers can now quantify cellular and subcellular phenotypes, signalling states, and the spatial organization of single cells<xref ref-type="bibr" rid="b1">1</xref><xref ref-type="bibr" rid="b2">2</xref>. Detecting and describing the similarities and differences between cellular phenotypes becomes increasingly difficult as the number of cell images increases, even when the images and the quantification of these images are available. For example, while the manual examination of raw images can often detect subtle differences in phenotypes, human beings are prone to bias and such differences may or may not exist numerically. This means that a disparity may exist between what the observer believes to be the phenotype, and the quantitative phenotype itself. Conversely, an experimentalist may not be able to see some of the phenotypic differences that are detected by computational analysis in raw images, as humans cannot easily discern aspects such as pixel intensities, ‘texture’ (distribution of pixel intensities) and subtle changes in label localization<xref ref-type="bibr" rid="b3">3</xref>. Moreover, many images may be acquired across different channels, which increases the number of dimensions the analyst needs to work with. Finally, it is difficult for observers to appreciate how different features, such as area, shape and the intensity of different labels are quantitatively related to each other. Thus, the success of any image-based study relies heavily on the ability of the experimentalist to relate images with numerical data.</p>
  <p>Visualization can greatly facilitate data analysis and interpretation, which are still major bottlenecks in gaining biologically meaningful knowledge from imaging data. Coordinate-based graphs and heatmaps<xref ref-type="bibr" rid="b4">4</xref> are the most frequently used methods for representing imaging measurements, but they have a number of drawbacks. Coordinate-based graphs such as bar charts and scatter plots are restricted to three dimensions, while parallel coordinates can represent many dimensions but may suffer from occlusion between data points<xref ref-type="bibr" rid="b5">5</xref>. On the other hand, heatmaps use coloured objects (typically boxes) to represent many dimensions<xref ref-type="bibr" rid="b4">4</xref>, but it can be difficult for humans to discern the extent to which different hues reflect differences in phenotypes<xref ref-type="bibr" rid="b6">6</xref>. Critically in the context of image-based data sets, neither coordinate-based graphs nor heatmaps are intuitive representations of cellular phenotypes, as they do not use pictorial representations of individual features. It may therefore be difficult for experimentalists to understand what any given cell or population looks like, or to relate numbers to images, using heatmaps or scatter plots.</p>
  <p>Glyph-based methods use a collection of visual elements such as size, colour, texture and/or orientation to depict multidimensional data<xref ref-type="bibr" rid="b7">7</xref>. For example, star glyphs use radial bars with length proportional to variable values<xref ref-type="bibr" rid="b8">8</xref>. Another example is the facial glyphs proposed by Chernoff <italic>et al.</italic><xref ref-type="bibr" rid="b8">8</xref><xref ref-type="bibr" rid="b9">9</xref> to represent around 20 variables. Chernoff faces exploit humans’ ability to detect differences between faces and allow quick identification of which samples are different from one another. However, facial glyphs are rarely used to represent cellular data because they imply emotional expressions that might not be relevant to the represented data<xref ref-type="bibr" rid="b8">8</xref><xref ref-type="bibr" rid="b10">10</xref>. Like other visualization methods, the available glyph-based methods are not intuitive representations of cellular phenotypes and do not address the question of how samples differ in terms of their visual phenotypes.</p>
  <p>We design and develop PhenoPlot, a glyph-based approach, to represent multidimensional cellular measurements in an intuitive manner. PhenoPlot is a free and open source Matlab toolbox that comes with a graphical user interface (GUI). Currently, PhenoPlot allows the visualization of up to 21 variables. We illustrate the utility of PhenoPlot in profiling the morphology of breast cancer cell lines and show how PhenoPlot can be a useful tool in understanding and interpreting multidimensional cellular imaging data.</p>
  <sec disp-level="1" sec-type="results">
    <title>Results</title>
    <sec disp-level="2">
      <title>PhenoPlot design</title>
      <p>PhenoPlot employs many visual elements, such as differently sized, coloured and structured objects, to represent multiple dimensions independently of XY coordinates. <xref ref-type="supplementary-material" rid="S1">Supplementary Table 1</xref> lists all PhenoPlot elements that the user can choose for plotting depending on the features measured. Like other visualization tools, such as heatmaps and star and facial glyphs, data scaling is required in PhenoPlot. In the example shown (<xref ref-type="fig" rid="f1">Fig. 1a</xref>), the cell body, nucleus, and perinuclear regions are represented using ellipses. The length and width of each of these objects are represented as the major and minor dimension of the ellipse, respectively. Dimensional variables (that is, length and width) should be scaled together to a 0.1–1 interval to maintain the aspect ratio between different dimensions and implicitly represent additional dimensions (for example, cell width-to-length ratio). In <xref ref-type="fig" rid="f1">Fig. 1a</xref>, the number of nuclei is plotted as subcircles within the nuclear ellipse. The relative area of cell protrusions, such as lamellipodia, is represented on the top of the cell as a half-ellipse whose major dimension is proportional to the relative protrusion area (<xref ref-type="fig" rid="f1">Fig. 1a</xref>). Intensities of the cell, nucleus and perinuclear regions are represented by mapping average intensity values of fluorescent markers to different colour hues.</p>
      <p>To increase the number of dimensions that can be represented in PhenoPlot, we devised the concept of ‘Proportional Filling’ that exploits the principle of visual closure where humans can easily perceive the value of partially filled object<xref ref-type="bibr" rid="b11">11</xref>. Given a variable scaled between 0 and 1, we represent the feature using a glyph and the value by filling part of the glyph in proportion to the variable value with a specified symbol or colour. For example, if we measure the neighbour fraction (NF), that is, the fraction of the cell border that is in contact with other cells, then we can represent NF as the fraction of cell ellipse border that is thickened or overlaid by a symbol (<xref ref-type="fig" rid="f1">Fig. 1a</xref>). Other representations include the proportion of the cell ellipse that is filled with a symbol, which can be used to represent cellular texture, the number of mitochondria or the number of vesicles (<xref ref-type="fig" rid="f1">Fig. 1a</xref>). Similarly, the proportion of the nucleus ellipse filled with a symbol can be used to represent nuclear texture. We also added three organelle glyphs (ellipse, rectangle and line), where the height of the filled portion of the organelle is proportional to the variable value (<xref ref-type="fig" rid="f1">Fig. 1a,b</xref>). These organelle glyphs can be used to represent an organelle intensity, quantity or texture. In total, eight features are provided that exploit proportional filling.</p>
      <p>PhenoPlot allows the customization of different element colours and line styles and the specification of cell positions in a two-dimensional plane. Importantly, many PhenoPlot elements are colour independent, which increases its usability. A figure legend will be drawn automatically using the user input for feature names. <xref ref-type="fig" rid="f1">Figure 1b</xref> shows the appearance of PhenoPlot elements representing different values for 15 variables (<xref ref-type="supplementary-material" rid="S1">Supplementary Table 2</xref>). Unlike other visualization methods such as bar charts (<xref ref-type="supplementary-material" rid="S1">Supplementary Fig. 1a</xref>), heatmaps (<xref ref-type="supplementary-material" rid="S1">Supplementary Fig. 1b</xref>), star glyphs (<xref ref-type="supplementary-material" rid="S1">Supplementary Fig. 1c</xref> and <xref ref-type="supplementary-material" rid="S1">Supplementary Table 3</xref>) and Chernoff faces (<xref ref-type="supplementary-material" rid="S1">Supplementary Fig. 1d</xref> and <xref ref-type="supplementary-material" rid="S1">Supplementary Table 3</xref>), PhenoPlot represents particular cellular features intuitively (for example, cell shape, texture features or nuclear morphology).</p>
    </sec>
    <sec disp-level="2">
      <title>Profiling breast cancer cell lines morphology with PhenoPlot</title>
      <p>To demonstrate the utility of PhenoPlot, we generated PhenoPlots to describe the phenotypes of 19 breast cell lines, which are predominantly derived from human tumours (<xref ref-type="supplementary-material" rid="S1">Supplementary Table 4</xref>). For each cell line, nuclear and cell bodies were fluorescently labelled, fixed, and imaged by confocal microscopy (Methods). Nine features were plotted for each cell including the length and the width of the cells and nuclei; the area of cellular protrusions; NF, which measures the fraction of cell border in contact with other cells; cellular ruffliness, which reflects the irregularity of the cell border; and the cellular and nuclear textures, which describe the distribution of pixel intensity in these regions (see Methods). Hierarchical clustering was used to group cell lines with similar morphologies into five clusters (<xref ref-type="supplementary-material" rid="S1">Supplementary Fig. 2</xref>). We used PhenoPlot to visualize the average measurements for each cluster and produce intuitive representations based on the measurements of 155,811 cells (<xref ref-type="fig" rid="f2">Fig. 2a</xref>, top row). Using PhenoPlot, we are able to better visualize aspects of cell morphology that are otherwise difficult for the human observer to appreciate. For example, the PhenoPlot of cells in cluster 1 shows that they are round, poorly spread, have high NF, low nuclear texture index and do not form protrusions (<xref ref-type="fig" rid="f2">Fig. 2a</xref>). In contrast, the PhenoPlot of cells in cluster 2 shows that cells have extensive ruffles, low NF and high values of cellular and nuclear texture index. On the basis of the high value of protrusiveness, ruffliness and texture, we infer that the cells in cluster 2 are likely to be highly motile. This notion is consistent with the fact that hs578T and MDA-MB-157 cells are derived from metastatic breast cancer and are known to be invasive<xref ref-type="bibr" rid="b12">12</xref>. PhenoPlot shows that cells in cluster 3 are far less ruffly and textured and have higher NF than cells in cluster 2, suggesting that they are less motile. On the basis of their PhenoPlots, cells in cluster 4 appear to have an intermediate phenotype between clusters 1 and 2, while cells in cluster 5 seem to be similar to cells in cluster 3, but less spread. Thus, PhenoPlots provide effective and intuitive pictorial representations of cellular phenotypes that allow the interpretation of quantitative results and their relation to cellular images.</p>
      <p>Discriminating between phenotypes of different clusters and making inferences regarding underlying biological process is challenging when using either images of a ‘representative cell’ (which is a cell with features closest to the average of all cells in the cluster), or images containing many cells (<xref ref-type="fig" rid="f2">Fig. 2a</xref> middle and bottom rows and <xref ref-type="supplementary-material" rid="S1">Supplementary Fig. 3</xref>). For example, cells in clusters 2 and 3 appear to have similar large, spread, flat shapes as determined by raw images (<xref ref-type="supplementary-material" rid="S1">Supplementary Fig. 3</xref>), even though cells in cluster 2 exhibit far more ruffles than cells in cluster 3 (<xref ref-type="fig" rid="f2">Fig. 2a</xref> top and b,c). Moreover, it is difficult for humans to appreciate from raw images that cluster 4 cells are the most ‘textured’ of all cells in the data set (<xref ref-type="supplementary-material" rid="S1">Supplementary Fig. 3</xref>). It is also difficult for humans to appreciate the relationships between variables using raw images. For example, cluster 2 and 3 cells are both spread, but the ratio of ruffles to protrusiveness is very different (<xref ref-type="fig" rid="f2">Fig. 2a</xref> top).</p>
      <p>By comparison, typical visualization methods such as heatmaps or bar charts are not intuitive representations of phenotypes and are not easy to relate to cell images. For example, heatmaps represent the variables using colour shades of boxes (<xref ref-type="fig" rid="f2">Fig. 2b</xref>), but these boxes do not reflect the visual appearance of the feature. Thus, it is difficult to picture how cells look from a heatmap, especially when many dimensions are displayed. Although bar charts are effective in identifying differences between the values of a few variables, it is difficult for the analyst to interpret a biological phenotype from this representation (<xref ref-type="fig" rid="f2">Fig. 2c</xref>). Furthermore, it is difficult to understand the relationship between variables using heatmaps or bar charts, because features are compared individually.</p>
    </sec>
    <sec disp-level="2">
      <title>PhenoPlot is a flexible visualization method</title>
      <p>Like other glyph-based approaches, PhenoPlots are independent of XY coordinates. This makes PhenoPlot a flexible tool that can be combined with other visualization methods. Furthermore, extra dimensions can be visualized using the position of PhenoPlots in a two-dimensional plane. For example, projecting PhenoPlots of average measurements for the different breast cell lines in the first two principal components (PCs) of the data facilitates the identification of phenotypic similarities and differences between cell lines (<xref ref-type="fig" rid="f3">Fig. 3a</xref>). <xref ref-type="fig" rid="f3">Figure 3a</xref> shows that cell lines on the left-hand side have epithelial-like shapes (low protrusiveness, less spread, and high NF), cells on the right-hand side have mesenchymal-like shapes (highly protrusive and ruffly, more spread, and low NF), while cell lines with intermediate morphologies are in the middle. Moreover, interesting relationships can be easily identified from this representation. For example, mesenchymal-like cell lines have higher nuclear texture than epithelial-like cell lines except for MCF10A and SUM159, and some of the cell lines with intermediate morphology have increased nuclear texture values. This observation can trigger further experiments to investigate the nature of nuclear texture differences between epithelial and mesenchymal phenotypes. Conversely, a typical scatter plot provides no information on the nature of differences between cell lines (<xref ref-type="fig" rid="f3">Fig. 3b</xref>). Thus, PhenoPlot is a flexible method that can assist data analysis and identification of new hypotheses and complement other analysis and visualization techniques.</p>
    </sec>
  </sec>
  <sec disp-level="1" sec-type="discussion">
    <title>Discussion</title>
    <p>Visualization is essential for understanding and interpreting complex data extracted from cellular images. The currently available general-purpose visualization tools, such as heatmaps or parallel coordinates, are difficult to relate to biological phenomena. These methods are usually accompanied by qualitative examination of cellular images to identify cells representative of the quantitative phenotypes<xref ref-type="bibr" rid="b13">13</xref><xref ref-type="bibr" rid="b14">14</xref>, which is a tedious task that requires biological expertise, and is prone to bias. Many examples in the literature employ pictorial representations to explain biological phenotypes, but these examples are usually drawn manually and are generally not quantitative<xref ref-type="bibr" rid="b15">15</xref><xref ref-type="bibr" rid="b16">16</xref><xref ref-type="bibr" rid="b17">17</xref>. PhenoPlot formalizes a general pictorial representation of cells using various visual encodings and novel visualization techniques to concisely and quantitatively represent high-content data. PhenoPlot is available as a Matlab toolbox, which allows the integration of the visualization step with data exploration and data analysis steps. To increase PhenoPlot usability, we developed a simple GUI that can be easily used by biologists. We propose that PhenoPlot can facilitate exploration, understanding, memory and communication of cellular imaging data.</p>
    <p>To maximize the effectiveness of PhenoPlot in communicating research results, visualization principles should be considered. These include the use of colour to make the most relevant features to the biological question more salient<xref ref-type="bibr" rid="b18">18</xref>, the application of the Gestalt principle of proximity<xref ref-type="bibr" rid="b11">11</xref> by plotting cells in PC space and the removal of dimensions that do not convey information to the reader<xref ref-type="bibr" rid="b19">19</xref>.</p>
    <p>‘An image is worth a thousand words’, but the challenge in high-content imaging is to summarize thousands of images in a few figures. To our knowledge, PhenoPlot is the first method that is specifically designed to represent cellular imaging data in an intuitive way so that it can be easily linked to the biological phenotype. This allows the effective visualization of multiple dimensions, which can reveal complex relationships that might otherwise be missed. Furthermore, PhenoPlot can aid the understanding and interpretation of quantitative results. Importantly, extensive biological expertise is not required to understand the visual elements in PhenoPlot, which make it a useful tool in science communication.</p>
  </sec>
  <sec disp-level="1" sec-type="methods">
    <title>Methods</title>
    <sec disp-level="2">
      <title>Implementation</title>
      <p>The PhenoPlot toolbox was developed using Matlab 2012a. PhenoPlot includes a GUI. The source code of PhenoPlot, demo files and the data sets used in this manuscript are provided in the Supplementary Software at <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="uri" xlink:href="http://www.icr.ac.uk/our-research/researchers-and-teams/dr-chris-bakal/resources">http://www.icr.ac.uk/our-research/researchers-and-teams/dr-chris-bakal/resources</ext-link>.</p>
    </sec>
    <sec disp-level="2">
      <title>Experimental methods for breast cancer lines data set</title>
      <p>MCF10A breast epithelial and AU565 breast tumour cells were obtained from ATCC (LCG Standards). MDAMB231, HCC70, HCC1143, HCC1954, MCF7, T47D, BT474, CAMA1, MDAMB453 and hs578T breast tumour and MCF12A non-tumour cells were obtained from the laboratory of Alan Ashworth (Breakthrough Breast Cancer, ICR). SUM149, SUM159, MDAMB157, JIMT1, SKBR3 and ZR75.1 breast tumour cells were obtained from the laboratory of Jorge Reis-Filho (Breakthrough Breast Cancer, ICR).</p>
      <p>All cell lines were cultured in DMEM:F12 Glutamax medium supplemented with 5% heat-inactivated fetal bovine serum, unless otherwise indicated.</p>
      <p>Cells were seeded in 384-well plates at concentrations ranging from 1,000 to 3,000 cells per well, depending on the size and proliferation rate of the cell line. Cells were fixed on day 3 after plating. Before fixation, 10 μM dihydroethidium (2-hydroethidium, dihydroethidium (DHE); Invitrogen) was added to all wells. Cells were fixed with 4% formaldehyde at room temperature for 10 min, washed with PBS and permeabilized with PBS/0.1% Triton-X-100 for 10 min at room temperature. Nuclear DNA was stained with 4′,6-diamino-2-phenylindole (DAPI; Sigma). Sequential image acquisition was performed with a × 20 air objective using an automated spinning disc confocal microscope, the Opera HCS (PerkinElmer). Fourteen wells and 12 fields per well were imaged per condition.</p>
    </sec>
    <sec disp-level="2">
      <title>Image processing</title>
      <p>Customized image analysis scripts were developed and applied using Acapella Studio 2.7 (PerkinElmer).</p>
      <p>Nuclei were detected using the DAPI channel, and the cytoplasm was detected based on the DHE channel using the nucleus object as a seed. Cell and nucleus length, width and area and NF were extracted using Acapella functions. Twenty texture features (eight SER, eight Gabor<xref ref-type="bibr" rid="b20">20</xref> and four Haralick<xref ref-type="bibr" rid="b21">21</xref>) were calculated for both the DAPI channel in the nuclei region and the DHE channel in the cell core region. Protrusions were calculated as follows. For each cell, the average pixel intensity in the DHE channel was calculated and the largest subobject with more than 70% of the cell average intensity was selected as the cell core and the rest of the cell was selected as protrusion area. Ruffliness was calculated as an SER Edge texture feature in the cell membrane divided by the cell form factor, which we found to be representative of cell edge ruffling. In total, 52 features were extracted. Mitotic cells (cells with high DAPI intensity judged on experiment and cell line bases), small objects and border objects were filtered out.</p>
    </sec>
    <sec disp-level="2">
      <title>Computational analysis</title>
      <p>All computational analysis steps were performed using Matlab.</p>
    </sec>
    <sec disp-level="2">
      <title>Feature transformation</title>
      <p>To obtain a texture features index, we scaled texture features and then applied PCA to the nucleus and cell texture features individually. We used the first PC from each set as compressed texture index.</p>
      <p>For the hierarchical clustering and PCA, standard normalization was used so that all features were on the same scale. Euclidean distance and average linkage were used for the hierarchical clustering.</p>
      <p>To generate the PhenoPlots in <xref ref-type="fig" rid="f2">Figs 2a</xref> and <xref ref-type="fig" rid="f3">3a</xref>, dimensional features (cell length and width, and nucleus length and width) were scaled together to a 0.1–1 interval (to maintain aspect ratio) by subtracting the minimum of all dimensional features and dividing by the range of all dimensional features, and then multiplying the result by 0.9 and adding 0.1. The scaling for dimensional features start at 0.1 to avoid losing an object when it has relatively the lowest length or width. All other features were scaled between 0 and 1. <xref ref-type="supplementary-material" rid="S1">Supplementary Table 5</xref> lists the features used for the represented elements.</p>
    </sec>
  </sec>
  <sec disp-level="1">
    <title>Author contributions</title>
    <p>H.S. conceived the study, designed and developed the tool and performed the image and data analysis. J.E.S. performed the breast cell lines experiment. H.S. and C.B. wrote the manuscript.</p>
  </sec>
  <sec disp-level="1">
    <title>Additional information</title>
    <p><bold>How to cite this article:</bold> Sailem, H. <italic>et al.</italic> Visualizing cellular imaging data using PhenoPlot. <italic>Nat. Commun.</italic> 6:5825 doi: 10.1038/ncomms6825 (2015).</p>
  </sec>
  <sec sec-type="supplementary-material" id="S1">
    <title>Supplementary Material</title>
    <supplementary-material id="d33e18" content-type="local-data">
      <caption>
        <title>Supplementary Figures, Supplementary Tables and Supplementary Software</title>
        <p>Supplementary Figures 1-3 and Supplementary Tables 1-5</p>
      </caption>
      <media xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="ncomms6825-s1.pdf"/>
    </supplementary-material>
    <supplementary-material id="d33e24" content-type="local-data">
      <caption>
        <title>Supplementary Software</title>
        <p>PhenoPlot is a Matlab toolbox with an interactive Graphical User Interface (GUI) that generates cell-like glyphs from imaging data. The software requires Matlab 2012 and is best-used with data extracted from cellular images, but can be used to represent any numerical data. A guide on using the software both from the command line, and using the GUI, is provided in the file PhenoPlot_manual.pdf.</p>
      </caption>
      <media xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="ncomms6825-s2.zip"/>
    </supplementary-material>
  </sec>
</body>
<back>
  <ack>
    <p>We would like to acknowledge C. Isacke, F. Markowetz, Y. Yuan, M. Sanchez-Alvarez, A.R. Barr and L. Evans for useful comments on the manuscript. This work was funded by grants from the BBSRC (BB/J017183/1) and CRUK (C37275/A13478). C.B. is a Research Career Development Fellow of the Wellcome Trust.</p>
  </ack>
  <ref-list>
    <ref id="b1">
      <mixed-citation publication-type="journal"><name><surname>Danuser</surname><given-names>G.</given-names></name><article-title>Computer vision in cell biology</article-title>. <source>Cell</source><volume>147</volume>, <fpage>973</fpage>–<lpage>978</lpage> (<year>2011</year>).<pub-id pub-id-type="pmid">22118455</pub-id></mixed-citation>
    </ref>
    <ref id="b2">
      <mixed-citation publication-type="journal"><name><surname>Shariff</surname><given-names>A.</given-names></name>, <name><surname>Kangas</surname><given-names>J.</given-names></name>, <name><surname>Coelho</surname><given-names>L. P.</given-names></name>, <name><surname>Quinn</surname><given-names>S.</given-names></name> &amp; <name><surname>Murphy</surname><given-names>R. F.</given-names></name>
<article-title>Automated image analysis for high-content screening and analysis</article-title>. <source>J. Biomol. Screen.</source>
<volume>15</volume>, <fpage>726</fpage>–<lpage>734</lpage> (<year>2010</year>).<pub-id pub-id-type="pmid">20488979</pub-id></mixed-citation>
    </ref>
    <ref id="b3">
      <mixed-citation publication-type="journal"><name><surname>Glory</surname><given-names>E.</given-names></name> &amp; <name><surname>Murphy</surname><given-names>R. F.</given-names></name>
<article-title>Automated subcellular location determination and high-throughput microscopy</article-title>. <source>Dev. Cell</source>
<volume>12</volume>, <fpage>7</fpage>–<lpage>16</lpage> (<year>2007</year>).<pub-id pub-id-type="pmid">17199037</pub-id></mixed-citation>
    </ref>
    <ref id="b4">
      <mixed-citation publication-type="journal"><name><surname>Gehlenborg</surname><given-names>N.</given-names></name> &amp; <name><surname>Wong</surname><given-names>B.</given-names></name>
<article-title>Points of view: heat maps</article-title>. <source>Nat. Methods</source>
<volume>9</volume>, <fpage>213</fpage>–<lpage>213</lpage> (<year>2012</year>).</mixed-citation>
    </ref>
    <ref id="b5">
      <mixed-citation publication-type="journal"><name><surname>Gehlenborg</surname><given-names>N.</given-names></name> &amp; <name><surname>Wong</surname><given-names>B.</given-names></name>
<article-title>Points of view: Into the third dimension</article-title>. <source>Nat. Methods</source>
<volume>9</volume>, <fpage>851</fpage>–<lpage>851</lpage> (<year>2012</year>).<pub-id pub-id-type="pmid">23097778</pub-id></mixed-citation>
    </ref>
    <ref id="b6">
      <mixed-citation publication-type="journal"><name><surname>Wong</surname><given-names>B.</given-names></name><article-title>Points of view: avoiding color</article-title>. <source>Nat. Methods</source><volume>8</volume>, <fpage>525</fpage>–<lpage>525</lpage> (<year>2011</year>).<pub-id pub-id-type="pmid">21850730</pub-id></mixed-citation>
    </ref>
    <ref id="b7">
      <mixed-citation publication-type="journal"><name><surname>Borgo</surname><given-names>R.</given-names></name><italic>et al.</italic><article-title>Glyph-based visualization: foundations, design guidelines, techniques and applications</article-title>. <source>Eurographics State of the Art Reports</source><fpage>39</fpage>–<lpage>63</lpage> (<year>2013</year>).</mixed-citation>
    </ref>
    <ref id="b8">
      <mixed-citation publication-type="journal"><name><surname>Lee</surname><given-names>M. D.</given-names></name>, <name><surname>Reilly</surname><given-names>R. E.</given-names></name> &amp; <name><surname>Butavicius</surname><given-names>M. A.</given-names></name>
<article-title>Visualizations of binary data: A comparative evaluation</article-title>. <source>Int. J. Hum. Comput. Stud.</source>
<volume>59</volume>, <fpage>569</fpage>–<lpage>602</lpage> (<year>2003</year>).</mixed-citation>
    </ref>
    <ref id="b9">
      <mixed-citation publication-type="journal"><name><surname>Chernoff</surname><given-names>H.</given-names></name>, <name><surname>Association</surname><given-names>S.</given-names></name> &amp; <name><surname>Jun</surname><given-names>N.</given-names></name>
<article-title>The use of faces to represent points in k-dimensional space graphically</article-title>. <source>J. Am. Stat. Assoc.</source>
<volume>68</volume>, <fpage>361</fpage>–<lpage>368</lpage> (<year>1973</year>).</mixed-citation>
    </ref>
    <ref id="b10">
      <mixed-citation publication-type="journal"><name><surname>Morris</surname><given-names>C. J.</given-names></name>, <name><surname>Ebert</surname><given-names>D. S.</given-names></name> &amp; <name><surname>Rheingans</surname><given-names>P. L.</given-names></name> in<source>Proc. 28th AIPR Work. 3D Vis. Data Explor. Decis. Mak</source> (ed. Oliver W. R. )<volume>3905</volume>, <fpage>12</fpage>–<lpage>17</lpage>SPIE (<year>2000</year>).</mixed-citation>
    </ref>
    <ref id="b11">
      <mixed-citation publication-type="journal"><name><surname>Wong</surname><given-names>B.</given-names></name><article-title>Points of view: Gestalt principles (Part 2)</article-title>. <source>Nat. Methods</source><volume>7</volume>, <fpage>941</fpage>–<lpage>941</lpage> (<year>2010</year>).</mixed-citation>
    </ref>
    <ref id="b12">
      <mixed-citation publication-type="journal"><name><surname>Pishvaian</surname><given-names>M. J.</given-names></name><italic>et al.</italic><article-title>Cadherin-11 is expressed in invasive breast cancer cell lines</article-title>. <source>Cancer Res.</source><volume>59</volume>, <fpage>947</fpage>–<lpage>952</lpage> (<year>1999</year>).<pub-id pub-id-type="pmid">10029089</pub-id></mixed-citation>
    </ref>
    <ref id="b13">
      <mixed-citation publication-type="journal"><name><surname>Bakal</surname><given-names>C.</given-names></name>, <name><surname>Aach</surname><given-names>J.</given-names></name>, <name><surname>Church</surname><given-names>G.</given-names></name> &amp; <name><surname>Perrimon</surname><given-names>N.</given-names></name>
<article-title>Quantitative morphological signatures define local signaling networks regulating cell morphology</article-title>. <source>Science</source>
<volume>316</volume>, <fpage>1753</fpage>–<lpage>1756</lpage> (<year>2007</year>).<pub-id pub-id-type="pmid">17588932</pub-id></mixed-citation>
    </ref>
    <ref id="b14">
      <mixed-citation publication-type="journal"><name><surname>Neumann</surname><given-names>B.</given-names></name><italic>et al.</italic><article-title>Phenotypic profiling of the human genome by time-lapse microscopy reveals cell division genes</article-title>. <source>Nature</source><volume>464</volume>, <fpage>721</fpage>–<lpage>727</lpage> (<year>2010</year>).<pub-id pub-id-type="pmid">20360735</pub-id></mixed-citation>
    </ref>
    <ref id="b15">
      <mixed-citation publication-type="journal"><name><surname>Tufte</surname><given-names>E. R.</given-names></name><source>The Visual Display of Quantitative Information</source> Graphics Press LLC (<year>2001</year>).</mixed-citation>
    </ref>
    <ref id="b16">
      <mixed-citation publication-type="journal"><name><surname>McCandless</surname><given-names>D.</given-names></name><source>Information is Beautiful</source> Collins (<year>2012</year>).</mixed-citation>
    </ref>
    <ref id="b17">
      <mixed-citation publication-type="journal"><name><surname>Boon</surname><given-names>K.</given-names></name><italic>et al.</italic><article-title>An anatomy of normal and malignant gene expression</article-title>. <source>Proc. Natl Acad. Sci. USA</source><volume>99</volume>, <fpage>11287</fpage>–<lpage>11292</lpage> (<year>2002</year>).<pub-id pub-id-type="pmid">12119410</pub-id></mixed-citation>
    </ref>
    <ref id="b18">
      <mixed-citation publication-type="journal"><name><surname>Wong</surname><given-names>B.</given-names></name><article-title>Points of view: salience to relevance</article-title>. <source>Nat. Methods</source><volume>8</volume>, <fpage>889</fpage>–<lpage>889</lpage> (<year>2011</year>).<pub-id pub-id-type="pmid">22148153</pub-id></mixed-citation>
    </ref>
    <ref id="b19">
      <mixed-citation publication-type="journal"><name><surname>Shoresh</surname><given-names>N.</given-names></name> &amp; <name><surname>Wong</surname><given-names>B.</given-names></name>
<article-title>Points of view: data exploration</article-title>. <source>Nat. Methods</source>
<volume>9</volume>, <fpage>5</fpage>–<lpage>5</lpage> (<year>2011</year>).<pub-id pub-id-type="pmid">22312636</pub-id></mixed-citation>
    </ref>
    <ref id="b20">
      <mixed-citation publication-type="journal"><name><surname>Turner</surname><given-names>M. R.</given-names></name><article-title>Texture discrimination by Gabor functions</article-title>. <source>Biol. Cybern.</source><volume>55</volume>, <fpage>71</fpage>–<lpage>82</lpage> (<year>1986</year>).<pub-id pub-id-type="pmid">3801538</pub-id></mixed-citation>
    </ref>
    <ref id="b21">
      <mixed-citation publication-type="journal"><name><surname>Haralick</surname><given-names>R. M.</given-names></name><article-title>Statistical and structural approaches to texture</article-title>. <source>Proc. IEEE</source><volume>67</volume>, <fpage>786</fpage>–<lpage>804</lpage> (<year>1979</year>).</mixed-citation>
    </ref>
  </ref-list>
</back>
<floats-group>
  <fig id="f1">
    <label>Figure 1</label>
    <caption>
      <title>PhenoPlot design.</title>
      <p>(<bold>a</bold>) Illustration of the main visualization elements in PhenoPlot. Each element can represent a feature quantified from raw image data. Examples of the features that these elements can represent are shown in parentheses. (<bold>b</bold>) PhenoPlots of 15 variables. The PhenoPlot elements used here are main ellipse (length and width), main ellipse filling, inner sub-ellipse (length and width), inner sub-ellipse filling, inner sub-ellipse colour, relative protrusion area, spikes (fraction and height), membrane process, line organelle, ellipse organelle and rectangle organelle as detailed in <xref ref-type="supplementary-material" rid="S1">Supplementary Table 2</xref>.</p>
    </caption>
    <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="ncomms6825-f1"/>
  </fig>
  <fig id="f2">
    <label>Figure 2</label>
    <caption>
      <title>Visualization of morphological clusters of 19 breast cell lines.</title>
      <p>(<bold>a</bold>) Top row: PhenoPlot of the average of nine morphological features for each cluster. Middle row: representative image of a single cell from each cluster outlined in white and red, where red indicates the cell border in contact with other cells (NF). Scale bars, 50 μm. Bottom row: selected raw cell image from each cluster. Scale bars, 50 μm. (<bold>b</bold>) Heatmap of the average of nine morphological features for each cluster. (<bold>c</bold>) Bar chart of the average of nine morphological features for each cluster.</p>
    </caption>
    <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="ncomms6825-f2"/>
  </fig>
  <fig id="f3">
    <label>Figure 3</label>
    <caption>
      <title>PhenoPlots projected in the first two PCs.</title>
      <p>(<bold>a</bold>) PhenoPlots of the average morphological measurements for 19 breast cell lines where the cell position in the two-dimensional plane is based on the first two PCs (PCA is applied to the same morphological measurements in <xref ref-type="supplementary-material" rid="S1">Supplementary Fig. 2</xref>). (<bold>b</bold>) Average measurements of breast cell line morphology projected in the first two PCs.</p>
    </caption>
    <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="ncomms6825-f3"/>
  </fig>
</floats-group>
