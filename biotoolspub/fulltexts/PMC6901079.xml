<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1 20151215//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.1?>
<?ConverterInfo.XSLTName jp2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id>
    <journal-id journal-id-type="publisher-id">bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1367-4803</issn>
    <issn pub-type="epub">1367-4811</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">6901079</article-id>
    <article-id pub-id-type="doi">10.1093/bioinformatics/btz357</article-id>
    <article-id pub-id-type="publisher-id">btz357</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Original Papers</subject>
        <subj-group subj-group-type="category-toc-heading">
          <subject>Gene Expression</subject>
        </subj-group>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Exact hypothesis testing for shrinkage-based Gaussian graphical models</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Bernal</surname>
          <given-names>Victor</given-names>
        </name>
        <xref ref-type="aff" rid="btz357-aff1">1</xref>
        <xref ref-type="aff" rid="btz357-aff2">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Bischoff</surname>
          <given-names>Rainer</given-names>
        </name>
        <xref ref-type="aff" rid="btz357-aff2">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Guryev</surname>
          <given-names>Victor</given-names>
        </name>
        <xref ref-type="aff" rid="btz357-aff3">3</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Grzegorczyk</surname>
          <given-names>Marco</given-names>
        </name>
        <xref ref-type="aff" rid="btz357-aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0003-2218-1140</contrib-id>
        <name>
          <surname>Horvatovich</surname>
          <given-names>Peter</given-names>
        </name>
        <xref ref-type="aff" rid="btz357-aff2">2</xref>
        <xref ref-type="corresp" rid="btz357-cor1"/>
        <!--<email>p.l.horvatovich@rug.nl</email>-->
      </contrib>
    </contrib-group>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Birol</surname>
          <given-names>Inanc</given-names>
        </name>
        <role>Associate Editor</role>
      </contrib>
    </contrib-group>
    <aff id="btz357-aff1"><label>1</label><institution>Bernoulli Institute, University of Groningen</institution>, Groningen AG, <country country="NL">The Netherlands</country></aff>
    <aff id="btz357-aff2">
      <label>2</label>
      <institution>Department of Analytical Biochemistry, Groningen Research Institute of Pharmacy</institution>
    </aff>
    <aff id="btz357-aff3"><label>3</label><institution>European Research Institute for the Biology of Ageing, University Medical Center Groningen, University of Groningen</institution>, Groningen AV, <country country="NL">The Netherlands</country></aff>
    <author-notes>
      <corresp id="btz357-cor1">To whom correspondence should be addressed. Email: <email>p.l.horvatovich@rug.nl</email></corresp>
    </author-notes>
    <pub-date pub-type="ppub">
      <day>01</day>
      <month>12</month>
      <year>2019</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2019-05-11">
      <day>11</day>
      <month>5</month>
      <year>2019</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>11</day>
      <month>5</month>
      <year>2019</year>
    </pub-date>
    <!-- PMC Release delay is 0 months and 0 days and was based on the <pub-date pub-type="epub"/>. -->
    <volume>35</volume>
    <issue>23</issue>
    <fpage>5011</fpage>
    <lpage>5017</lpage>
    <history>
      <date date-type="received">
        <day>15</day>
        <month>11</month>
        <year>2018</year>
      </date>
      <date date-type="rev-recd">
        <day>8</day>
        <month>3</month>
        <year>2019</year>
      </date>
      <date date-type="accepted">
        <day>26</day>
        <month>4</month>
        <year>2019</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2019. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2019</copyright-year>
      <license license-type="cc-by-nc" xlink:href="http://creativecommons.org/licenses/by-nc/4.0/">
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by-nc/4.0/">http://creativecommons.org/licenses/by-nc/4.0/</ext-link>), which permits non-commercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited. For commercial re-use, please contact journals.permissions@oup.com</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="btz357.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Motivation</title>
        <p>One of the main goals in systems biology is to learn molecular regulatory networks from quantitative profile data. In particular, Gaussian graphical models (GGMs) are widely used network models in bioinformatics where variables (e.g. transcripts, metabolites or proteins) are represented by nodes, and pairs of nodes are connected with an edge according to their partial correlation. Reconstructing a GGM from data is a challenging task when the sample size is smaller than the number of variables. The main problem consists in finding the inverse of the covariance estimator which is ill-conditioned in this case. Shrinkage-based covariance estimators are a popular approach, producing an invertible ‘shrunk’ covariance. However, a proper significance test for the ‘shrunk’ partial correlation (i.e. the GGM edges) is an open challenge as a probability density including the shrinkage is unknown. In this article, we present (i) a geometric reformulation of the shrinkage-based GGM, and (ii) a probability density that naturally includes the shrinkage parameter.</p>
      </sec>
      <sec id="s2">
        <title>Results</title>
        <p>Our results show that the inference using this new ‘shrunk’ probability density is as accurate as Monte Carlo estimation (an unbiased non-parametric method) for any shrinkage value, while being computationally more efficient. We show on synthetic data how the novel test for significance allows an accurate control of the Type I error and outperforms the network reconstruction obtained by the widely used R package <italic>GeneNet</italic>. This is further highlighted in two gene expression datasets from stress response in <italic>Eschericha coli</italic>, and the effect of influenza infection in <italic>Mus musculus</italic>.</p>
      </sec>
      <sec id="s3">
        <title>Availability and implementation</title>
        <p>
          <ext-link ext-link-type="uri" xlink:href="https://github.com/V-Bernal/GGM-Shrinkage">https://github.com/V-Bernal/GGM-Shrinkage</ext-link>
        </p>
      </sec>
      <sec id="s4">
        <title>Supplementary information</title>
        <p><xref ref-type="supplementary-material" rid="sup1">Supplementary data</xref> are available at <italic>Bioinformatics</italic> online.</p>
      </sec>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <named-content content-type="funder-name">Data Science and System Complexity Centre</named-content>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <named-content content-type="funder-name">DSSC</named-content>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <named-content content-type="funder-name">University of Groningen</named-content>
          <named-content content-type="funder-identifier">10.13039/501100001721</named-content>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <named-content content-type="funder-name">European Cooperation in Science and Technology</named-content>
          <named-content content-type="funder-identifier">10.13039/501100000921</named-content>
        </funding-source>
        <award-id>CA15109</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <named-content content-type="funder-name">European Cooperation for Statistics of Network Data Science (COSTNET)</named-content>
        </funding-source>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="7"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 Introduction</title>
    <p>In systems biology and bioinformatics an important objective is to explore molecular associations (e.g. gene regulatory or protein interaction networks) based on molecular profiles. Among the most popular statistical models for biological networks are Relevance networks (RNs) (<xref rid="btz357-B4" ref-type="bibr">Butte and Kohane, 2003</xref>), Gaussian graphical models (GGMs) (<xref rid="btz357-B5" ref-type="bibr">Edwards, 2000</xref>) and Bayesian networks (BNs) (<xref rid="btz357-B13" ref-type="bibr">Friedman <italic>et al.</italic>, 2000</xref>).</p>
    <p>GGMs are widely used for network learning because, unlike RNs, they measure the strengths of direct relationships (avoiding indirect, spurious associations). When compared with BNs, GGMs are computationally feasible (even for large networks) and have similar statistical performance (<xref rid="btz357-B31" ref-type="bibr">Werhli <italic>et al.</italic>, 2006</xref>). In particular, GGMs employ partial correlations to represent probabilistic dependences (e.g. relationships among genes, proteins or metabolites) by measuring linear relationships between pairs of variables while conditioning over the remaining ones (i.e. the effects from all other variables are adjusted, resulting in a measure of direct relationships). In this way, a GGM’s structure consists of nodes representing the random variables with an edge connecting a pair of nodes according to its partial correlation (e.g. whether it is statistically significant).</p>
    <p>The reconstruction of a GGM requires the inverse of the covariance matrix. It is therefore important that the covariance estimator is (i) invertible and (ii) well-conditioned (i.e. that the inversion does not magnify estimation errors). For the sample covariance estimator <inline-formula id="IE1"><mml:math id="IM1"><mml:msup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold">C</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>SM</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> with <inline-formula id="IE2"><mml:math id="IM2"><mml:mi>p</mml:mi></mml:math></inline-formula> variables and sample size <inline-formula id="IE3"><mml:math id="IM3"><mml:mi>n</mml:mi></mml:math></inline-formula>, three main cases can be identified (<xref rid="btz357-B16" ref-type="bibr">Ledoit and Wolf, 2004</xref>): it is invertible and well-conditioned if <inline-formula id="IE4"><mml:math id="IM4"><mml:mi>n</mml:mi><mml:mo>≫</mml:mo><mml:mi>p</mml:mi></mml:math></inline-formula>, it is invertible but ill-conditioned if <inline-formula id="IE5"><mml:math id="IM5"><mml:mi>n</mml:mi></mml:math></inline-formula> is comparable to <inline-formula id="IE6"><mml:math id="IM6"><mml:mi>p</mml:mi></mml:math></inline-formula>, and it is not invertible if <inline-formula id="IE7"><mml:math id="IM7"><mml:mi>n</mml:mi><mml:mo>≪</mml:mo><mml:mi>p</mml:mi></mml:math></inline-formula>. This set up is referred to as a high-dimensional problem, ‘<italic>small n, large p</italic>’ or just as ‘<inline-formula id="IE8"><mml:math id="IM8"><mml:mi>n</mml:mi><mml:mo>≪</mml:mo><mml:mi>p</mml:mi></mml:math></inline-formula>’. The analysis of molecular profiles in biology usually involves a large set of variables (e.g. genes, proteins and metabolites) and a relatively small sample size (e.g. biological replicates or time points). In this case, there are two popular frameworks for learning GGMs from quantitative molecular profile data. On one hand, <italic>Glasso</italic> (<xref rid="btz357-B12" ref-type="bibr">Friedman <italic>et al.</italic>, 2008</xref>) is based on estimating the covariance’s inverse using a <inline-formula id="IE9"><mml:math id="IM9"><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> penalty (i.e. some of the matrix entries are estimated as zero), and is complemented with model selection strategies. On the other hand, <italic>GeneNet</italic> (<xref rid="btz357-B24" ref-type="bibr">Schäfer and Strimmer, 2005a)</xref> estimates a modified covariance matrix by using an (invertible) estimator based on shrinkage (<xref rid="btz357-B16" ref-type="bibr">Ledoit and Wolf, 2004</xref>). The latter has the advantage of providing <italic>P</italic>-values (<xref rid="btz357-B28" ref-type="bibr">Strimmer, 2008a</xref>, <xref rid="btz357-B29" ref-type="bibr">b</xref>) and this article will focus on this approach.</p>
    <p>Covariance estimators based on shrinkage are useful in the high-dimensional case as they produce a more stable (but biased) estimator. They consist of a convex linear combination of the (unbiased) sample covariance estimator <inline-formula id="IE10"><mml:math id="IM10"><mml:msup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold">C</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi mathvariant="normal">SM</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> with a target estimator <inline-formula id="IE11"><mml:math id="IM11"><mml:mi mathvariant="bold">T</mml:mi></mml:math></inline-formula> (e.g. a diagonal matrix). The result is a well-conditioned estimator, and its inverse can be used to compute the ‘shrunk’ partial correlations. Over the last decade, the shrinkage approach to reconstruct GGMs has had a considerable use in biological/medical research (<xref rid="btz357-B2" ref-type="bibr">Beerenwinkel <italic>et al.</italic>, 2007</xref>; <xref rid="btz357-B3" ref-type="bibr">Benedetti et al., 2017</xref>; <xref rid="btz357-B15" ref-type="bibr">Keller et al., 2008</xref>; <xref rid="btz357-B19" ref-type="bibr">Ma et al., 2007</xref>; <xref rid="btz357-B23" ref-type="bibr">Saha <italic>et al.</italic>, 2017</xref>). In particular, the widely used R package <italic>GeneNet</italic> received more than 1200 citations to date (<xref ref-type="supplementary-material" rid="sup1">Supplementary Fig. S1</xref>), and methodologically is one of the most important GGM approaches in system biology (<xref rid="btz357-B9" ref-type="bibr">Faust and Raes, 2012</xref>; <xref rid="btz357-B18" ref-type="bibr">Lemm <italic>et al.</italic>, 2011</xref>; <xref rid="btz357-B20" ref-type="bibr">Markowetz and Spang, 2007</xref>).</p>
    <p>However, a proper significance test of the ‘shrunk’ partial correlations requires the inclusion of the shrinkage value in an analytical form, which is an open and challenging task not addressed so far. The importance of an accurate test becomes greater for large networks, since a GGM with <inline-formula id="IE12"><mml:math id="IM12"><mml:mi>p</mml:mi></mml:math></inline-formula> variables implies testing <inline-formula id="IE13"><mml:math id="IM13"><mml:mi>p</mml:mi><mml:mo>(</mml:mo><mml:mi>p</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:math></inline-formula> edges, the reconstruction becomes a multiple testing problem. Thus, even a slight bias in the test translates into an error that is repeated systematically. Moreover, if the bias is not independent of <inline-formula id="IE14"><mml:math id="IM14"><mml:mi>n</mml:mi></mml:math></inline-formula> or <inline-formula id="IE15"><mml:math id="IM15"><mml:mi>p</mml:mi></mml:math></inline-formula>, studies performed under different conditions are not comparable. For example, in <xref rid="btz357-B25" ref-type="bibr">Schäfer and Strimmer (2005b)</xref>, the authors employed the standard density of the partial correlation, and reported that for small number of samples (e.g. <italic>n</italic>&lt;30) the test has a low power. In addition, a recent study (<xref rid="btz357-B22" ref-type="bibr">Omranian <italic>et al.</italic>, 2016</xref>) found that the method returns a rather small fraction of true positives.</p>
    <p>To overcome the above-mentioned limitations, we aim to obtain a probability density that includes the shrinkage effects. The new test of significance must be valid for any shrinkage value, providing a proper control of the false positives (FPs) and the use of multiple testing corrections.</p>
  </sec>
  <sec>
    <title>2 Materials and methods</title>
    <p>This section introduces some background theory about GGMs, as well as the shrinkage approach for covariance estimation. This is followed by a description of how the test of significance is performed in <italic>GeneNet</italic>, together with its shortcomings. Next, to overcome the aforementioned pitfalls, the inference problem is translated under a geometrical perspective. This is achieved by using some seminal ideas that go back to the work of R.A. Fisher in the early 1900s. Finally, it is shown how these ideas permit the inclusion of the shrinkage into the inference in the form of a ‘shrunk’ probability density.</p>
    <p>As part of the notation throughout the text capital letters are used to represent random variables (e.g. <italic>X</italic>), uppercase bold letters for matrices (e.g. <bold>C</bold>), and lowercase bold letters for vectors (e.g. <inline-formula id="IE16"><mml:math id="IM16"><mml:mrow><mml:mstyle displaystyle="true"><mml:mover><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover></mml:mstyle></mml:mrow></mml:math></inline-formula>). We use the lowercase <inline-formula id="IE17"><mml:math id="IM17"><mml:mo>ρ</mml:mo></mml:math></inline-formula> for the partial correlation coefficient, and the uppercase <bold>P</bold> for the matrix of partial correlations.</p>
    <sec>
      <title>2.1 Gaussian graphical models</title>
      <p>A GGM is an undirected graphical model represented by a matrix <bold>P</bold> of partial correlation coefficients (<xref rid="btz357-B32" ref-type="bibr">Whittaker, 1990</xref>). The partial correlation is a measure of the linear relationships between pairs of variables that corrects the effect coming from all the others (i.e. it measures full-conditional relationships). In this way, the coefficient <inline-formula id="IE20"><mml:math id="IM18"><mml:msub><mml:mrow><mml:mi mathvariant="bold">P</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">ij</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> stands for the partial correlation between variables <inline-formula id="IE21"><mml:math id="IM19"><mml:mi>i</mml:mi></mml:math></inline-formula> and<inline-formula id="IE22"><mml:math id="IM20"><mml:mo> </mml:mo><mml:mi>j</mml:mi></mml:math></inline-formula>, and can be written as
<disp-formula id="E1"><label>(1)</label><mml:math id="M1"><mml:msub><mml:mrow><mml:mi mathvariant="bold">P</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>-</mml:mo><mml:mi mathvariant="normal"> </mml:mi><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">Ω</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msqrt><mml:msub><mml:mrow><mml:mi mathvariant="bold">Ω</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">ii</mml:mi></mml:mrow></mml:msub></mml:msqrt><mml:msqrt><mml:msub><mml:mrow><mml:mi mathvariant="bold">Ω</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">jj</mml:mi></mml:mrow></mml:msub></mml:msqrt></mml:mrow></mml:mfrac></mml:math></disp-formula>where <inline-formula id="IE23"><mml:math id="IM21"><mml:mi mathvariant="bold">Ω</mml:mi></mml:math></inline-formula> is the inverse of the <inline-formula id="IE24"><mml:math id="IM22"><mml:mi>p</mml:mi><mml:mo>×</mml:mo><mml:mi>p</mml:mi></mml:math></inline-formula> covariance matrix <inline-formula id="IE25"><mml:math id="IM23"><mml:mi mathvariant="bold">C</mml:mi></mml:math></inline-formula> (<xref rid="btz357-B5" ref-type="bibr">Edwards, 2000</xref>). However, estimating <inline-formula id="IE26"><mml:math id="IM24"><mml:mi mathvariant="bold">C</mml:mi></mml:math></inline-formula> from data is not trivial when the sample size <inline-formula id="IE27"><mml:math id="IM25"><mml:mi>n</mml:mi></mml:math></inline-formula> is smaller than the number of variables <inline-formula id="IE28"><mml:math id="IM26"><mml:mi>p</mml:mi></mml:math></inline-formula>. For example, let <inline-formula id="IE29"><mml:math id="IM27"><mml:mi mathvariant="bold">D</mml:mi></mml:math></inline-formula> be a<inline-formula id="IE30"><mml:math id="IM28"><mml:mo> </mml:mo><mml:mi>p</mml:mi><mml:mo>×</mml:mo><mml:mi>n</mml:mi></mml:math></inline-formula> data matrix with the observations arranged in columns. The maximum likelihood estimator <inline-formula id="IE31"><mml:math id="IM29"><mml:msup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold">C</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi mathvariant="normal">ML</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> is given by
<disp-formula id="E2"><label>(2)</label><mml:math id="M2"><mml:msup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold">C</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi mathvariant="normal">ML</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mfrac><mml:msub><mml:mrow><mml:mi mathvariant="bold">D</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold">c</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">D</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold">c</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi mathvariant="bold">t</mml:mi></mml:mrow></mml:msup></mml:math></disp-formula>where <inline-formula id="IE32"><mml:math id="IM30"><mml:msub><mml:mrow><mml:mi mathvariant="bold">D</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold">c</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is the <inline-formula id="IE33"><mml:math id="IM31"><mml:mi>p</mml:mi><mml:mo>×</mml:mo><mml:mi>p</mml:mi></mml:math></inline-formula> centered matrix obtained by subtracting from each row/variable of <inline-formula id="IE34"><mml:math id="IM32"><mml:mi mathvariant="bold">D</mml:mi></mml:math></inline-formula> its mean value, and the superscript t refers to the transpose. In this case, neither <inline-formula id="IE36"><mml:math id="IM33"><mml:msup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold">C</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi mathvariant="normal">ML</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula>, nor the unbiased estimator <inline-formula id="IE37"><mml:math id="IM34"><mml:msup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold">C</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi mathvariant="normal">SM</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mfrac bevelled="true"><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfrac><mml:msup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold">C</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi mathvariant="normal">ML</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> (i.e. the sample covariance) are positive definite. As some of the eigenvalues can be zero these estimators are not necessarily invertible.</p>
      <p><xref rid="btz357-B16" ref-type="bibr">Ledoit and Wolf (2003</xref>, <xref rid="btz357-B17" ref-type="bibr">2004</xref>) proposed a shrinkage-based estimator which consists of a convex combination of the form
<disp-formula id="E3"><label>(3)</label><mml:math id="M3"><mml:msup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold">C</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi mathvariant="bold">λ</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mfenced separators="|"><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mo>λ</mml:mo></mml:mrow></mml:mfenced><mml:msup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold">C</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>SM</mml:mi></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mo>λ</mml:mo><mml:mi mathvariant="bold">T</mml:mi></mml:math></disp-formula>where<inline-formula id="IE38"><mml:math id="IM35"><mml:mi mathvariant="normal"> </mml:mi><mml:mi mathvariant="bold">T</mml:mi></mml:math></inline-formula> is a target estimator (e.g. a diagonal matrix of variances), and <inline-formula id="IE39"><mml:math id="IM36"><mml:mo>λ</mml:mo></mml:math></inline-formula> is the shrinkage value, which is between 0 and 1. The authors choose <inline-formula id="IE40"><mml:math id="IM37"><mml:mo>λ</mml:mo></mml:math></inline-formula> to minimize the mean square error (MSE) (i.e. to optimize the tradeoff between the variance coming from <inline-formula id="IE41"><mml:math id="IM38"><mml:msup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold">C</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi mathvariant="normal">SM</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> and the bias from <inline-formula id="IE42"><mml:math id="IM39"><mml:mi mathvariant="bold">T</mml:mi></mml:math></inline-formula>). A short overview on shrinking toward different target matrices can be found in <xref rid="btz357-B24" ref-type="bibr">Schäfer and Strimmer (2005a)</xref>. In this sense it is guaranteed that <inline-formula id="IE43"><mml:math id="IM40"><mml:msup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold">C</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi mathvariant="bold">λ</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula>, as defined in <xref ref-type="disp-formula" rid="E3">Equation (3)</xref>, is well-conditioned in the ‘<italic>small n, large p</italic>’ scenario, and its inverse can be used to compute the ‘shrunk’ partial correlations. However it has the disadvantage that the shrinkage effect (i.e. <inline-formula id="IE44"><mml:math id="IM41"><mml:mo>λ</mml:mo></mml:math></inline-formula>) propagates to the partial correlations via <xref ref-type="disp-formula" rid="E1">Equation (1)</xref>. Although <inline-formula id="IE45"><mml:math id="IM42"><mml:msup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold">C</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi mathvariant="bold">λ</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> is a less variable (but biased) estimator with respect to <inline-formula id="IE46"><mml:math id="IM43"><mml:msup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold">C</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi mathvariant="normal">SM</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula>, the ‘shrunk’ partial correlation is distorted in a non-trivial manner.</p>
    </sec>
    <sec>
      <title>2.2 Empirical null fitting—parametric test in <italic>GeneNet</italic></title>
      <p><italic>GeneNet</italic> (<xref rid="btz357-B24" ref-type="bibr">Schäfer and Strimmer, 2005a)</xref> is a state of the art approach for inferring shrinkage-based GGMs. It estimates <inline-formula id="IE47"><mml:math id="IM44"><mml:msup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold">C</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi mathvariant="bold">λ</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> with an analytical expression for <inline-formula id="IE48"><mml:math id="IM45"><mml:mo>λ</mml:mo></mml:math></inline-formula> that minimizes the MSE, as explained in Section 2.1. The partial correlations obtained by <xref ref-type="disp-formula" rid="E1">Equation (1)</xref> with <inline-formula id="IE49"><mml:math id="IM46"><mml:msup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold">C</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi mathvariant="bold">λ</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> consist of a mixture of edges from the null and real effects. Following the notation in (<xref rid="btz357-B24" ref-type="bibr">Schäfer and Strimmer, 2005a)</xref> the distribution across edges <inline-formula id="IE50"><mml:math id="IM47"><mml:mi>f</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mo>ρ</mml:mo></mml:mrow></mml:mfenced></mml:math></inline-formula> is assumed to be a mixture density of the form <inline-formula id="IE51"><mml:math id="IM48"><mml:mi>f</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mo>ρ</mml:mo></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mo>π</mml:mo></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mo>ρ</mml:mo></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:mfenced separators="|"><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mo>π</mml:mo></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mo>ρ</mml:mo></mml:mrow></mml:mfenced></mml:math></inline-formula>, where <inline-formula id="IE52"><mml:math id="IM49"><mml:msub><mml:mrow><mml:mo>π</mml:mo></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> is the proportion of the null edges, <inline-formula id="IE53"><mml:math id="IM50"><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mo>ρ</mml:mo></mml:mrow></mml:mfenced></mml:math></inline-formula> is the probability density for <inline-formula id="IE54"><mml:math id="IM51"><mml:mo>ρ</mml:mo><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:math></inline-formula>, and <inline-formula id="IE55"><mml:math id="IM52"><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mo>ρ</mml:mo></mml:mrow></mml:mfenced></mml:math></inline-formula> the probability density for the real effects (<inline-formula id="IE56"><mml:math id="IM53"><mml:mo>ρ</mml:mo><mml:mo>≠</mml:mo><mml:mn>0</mml:mn></mml:math></inline-formula>). Next, the inference is carried out by empirical null fitting (ENF).</p>
      <p>ENF aims to correct for implicit ‘imperfections’ in experimental setups by identifying an empirical <inline-formula id="IE57"><mml:math id="IM54"><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mo>ρ</mml:mo></mml:mrow></mml:mfenced></mml:math></inline-formula>. For this, it is necessary to find a region where <inline-formula id="IE58"><mml:math id="IM55"><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mo>ρ</mml:mo></mml:mrow></mml:mfenced></mml:math></inline-formula> dominates over <inline-formula id="IE59"><mml:math id="IM56"><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mo>ρ</mml:mo></mml:mrow></mml:mfenced></mml:math></inline-formula>. A necessary condition known as the <italic>zero assumption</italic>, is that <inline-formula id="IE60"><mml:math id="IM57"><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mo>ρ</mml:mo></mml:mrow></mml:mfenced></mml:math></inline-formula> should vanish near to <inline-formula id="IE61"><mml:math id="IM58"><mml:mo>ρ</mml:mo><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:math></inline-formula>, which holds when <inline-formula id="IE62"><mml:math id="IM59"><mml:msub><mml:mrow><mml:mo>π</mml:mo></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>≥</mml:mo><mml:mn>0.90</mml:mn></mml:math></inline-formula> (<xref rid="btz357-B6" ref-type="bibr">Efron, 2012</xref>). This constrains ENF to the case of sparse networks. Despite its advantages, ENF is susceptible to errors due to the difficulty in choosing a ‘non-contaminated’ region. For more details about ENF we refer the reader to <xref rid="btz357-B7" ref-type="bibr">Efron (2004</xref>, <xref rid="btz357-B8" ref-type="bibr">2005</xref>).</p>
      <p>The test for significance exploits the fact that under simulation studies (for small λ) the distribution of the ‘shrunk’ partial correlation is close to the standard partial correlation (i.e. without shrinkage) given by <xref rid="btz357-B11" ref-type="bibr">Fisher (1924)</xref> as
<disp-formula id="E4"><label>(4)</label><mml:math id="M4"><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mo>ρ</mml:mo></mml:mrow></mml:mfenced><mml:mi mathvariant="normal"> </mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi mathvariant="normal">Beta</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac><mml:mo>,</mml:mo><mml:mfrac><mml:mrow><mml:mi>k</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced></mml:mrow></mml:mfrac><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msup><mml:mrow><mml:mo>ρ</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>k</mml:mi><mml:mo>-</mml:mo><mml:mn>3</mml:mn><mml:mo>)</mml:mo><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></disp-formula></p>
      <p>The authors use it as a substitute of the unknown ‘shrunk’ density. In this way, <inline-formula id="IE63"><mml:math id="IM60"><mml:mi>k</mml:mi></mml:math></inline-formula> is found by maximizing the (truncated) likelihood over a domain where presumably the <italic>zero assumption</italic> holds. However, as the shrinkage effects are not included, the <italic>P</italic>-values are suboptimal.</p>
      <p>In particular, inferring a GGM of <inline-formula id="IE64"><mml:math id="IM61"><mml:mi>p</mml:mi></mml:math></inline-formula> variables implies a multiple testing problem as <inline-formula id="IE65"><mml:math id="IM62"><mml:mi>p</mml:mi><mml:mo>(</mml:mo><mml:mi>p</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:math></inline-formula> tests have to be performed. This becomes more important when modeling biological networks with hundreds or thousands of variables. Thus, the use of a probability density including the distortion from <inline-formula id="IE66"><mml:math id="IM63"><mml:mo>λ</mml:mo></mml:math></inline-formula> becomes crucial. Otherwise, even a slight deviation from it would translate in a bias that is repeated systematically when computing the <italic>P</italic>-values and the corresponding multiple testing correction.</p>
    </sec>
    <sec>
      <title>2.3 The geometry of partial correlation</title>
      <p>In this subsection, we show how the shrinkage value <inline-formula id="IE67"><mml:math id="IM64"><mml:mo>λ</mml:mo></mml:math></inline-formula> can be taken into account. To this end, we make use of geometrical considerations and the concept of subject space. Subject space is a scheme where random variables are represented as vectors in a coordinate system with one axis per observation/experiment (<xref rid="btz357-B33" ref-type="bibr">Wickens, 2014</xref>). In this way, <inline-formula id="IE68"><mml:math id="IM65"><mml:mi>p</mml:mi></mml:math></inline-formula> random variables with <inline-formula id="IE69"><mml:math id="IM66"><mml:mi>n</mml:mi></mml:math></inline-formula> samples translate into <inline-formula id="IE70"><mml:math id="IM67"><mml:mi>p</mml:mi></mml:math></inline-formula> vectors in an <inline-formula id="IE71"><mml:math id="IM68"><mml:mi>n</mml:mi></mml:math></inline-formula>-dimensional space. Under this scheme, probabilistic relationships (e.g. correlations) can be interpreted geometrically.</p>
      <p>For the purpose of illustration consider three random variables <inline-formula id="IE72"><mml:math id="IM69"><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mi>Y</mml:mi></mml:math></inline-formula>, and <inline-formula id="IE73"><mml:math id="IM70"><mml:mi>Z</mml:mi></mml:math></inline-formula> with expectation zero (<inline-formula id="IE74"><mml:math id="IM71"><mml:mi>E</mml:mi><mml:mfenced open="[" close="]" separators="|"><mml:mrow><mml:mi>X</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mi>E</mml:mi><mml:mo>[</mml:mo><mml:mi>Y</mml:mi><mml:mo>]</mml:mo><mml:mo>=</mml:mo><mml:mi>E</mml:mi><mml:mo>[</mml:mo><mml:mi>Z</mml:mi><mml:mo>]</mml:mo><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:math></inline-formula>). Their respective vector representations are denoted by <inline-formula id="IE75"><mml:math id="IM72"><mml:mrow><mml:mstyle displaystyle="true"><mml:mover><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover></mml:mstyle></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mstyle displaystyle="true"><mml:mover><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover></mml:mstyle></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mstyle displaystyle="true"><mml:mover><mml:mrow><mml:mi mathvariant="bold-italic">z</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover></mml:mstyle></mml:mrow></mml:math></inline-formula>. The correlation <inline-formula id="IE76"><mml:math id="IM73"><mml:mi>r</mml:mi></mml:math></inline-formula> between <inline-formula id="IE77"><mml:math id="IM74"><mml:mi>X</mml:mi></mml:math></inline-formula> and <inline-formula id="IE78"><mml:math id="IM75"><mml:mi>Y</mml:mi></mml:math></inline-formula> (a measure of linear dependence) is related to the angle between the vectors (see <xref ref-type="fig" rid="btz357-F1">Fig. 1a</xref>), and can be written as
<disp-formula id="E5"><label>(5)</label><mml:math id="M5"><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">XY</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:munderover><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:mrow><mml:mstyle displaystyle="true"><mml:mover><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo>-</mml:mo></mml:mover></mml:mstyle></mml:mrow></mml:mrow></mml:mfenced><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:mrow><mml:mstyle displaystyle="true"><mml:mover><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>-</mml:mo></mml:mover></mml:mstyle></mml:mrow></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:msqrt><mml:msup><mml:mrow><mml:mrow><mml:munderover><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:mrow><mml:mstyle displaystyle="true"><mml:mover><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo>-</mml:mo></mml:mover></mml:mstyle></mml:mrow></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:msqrt><mml:msqrt><mml:msup><mml:mrow><mml:mrow><mml:munderover><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:mrow><mml:mstyle displaystyle="true"><mml:mover><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>-</mml:mo></mml:mover></mml:mstyle></mml:mrow></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:msqrt></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mstyle displaystyle="true"><mml:mover><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover></mml:mstyle><mml:mo>·</mml:mo><mml:mrow><mml:mstyle displaystyle="true"><mml:mover><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover></mml:mstyle></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>‖</mml:mo><mml:mrow><mml:mstyle displaystyle="true"><mml:mover><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover></mml:mstyle></mml:mrow><mml:mo>‖</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mo>‖</mml:mo><mml:mrow><mml:mstyle displaystyle="true"><mml:mover><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover></mml:mstyle></mml:mrow><mml:mo>‖</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo> </mml:mo></mml:math></disp-formula>where <inline-formula id="IE79"><mml:math id="IM76"><mml:mrow><mml:msub><mml:mrow><mml:mo>‖</mml:mo><mml:mrow><mml:mstyle displaystyle="true"><mml:mover><mml:mrow><mml:mi mathvariant="bold-italic">*</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover></mml:mstyle></mml:mrow><mml:mo>‖</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> denotes the usual Euclidean norm, and <inline-formula id="IE80"><mml:math id="IM77"><mml:mrow><mml:mstyle displaystyle="true"><mml:mover><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover></mml:mstyle></mml:mrow><mml:mo>·</mml:mo><mml:mrow><mml:mstyle displaystyle="true"><mml:mover><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover></mml:mstyle></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mo>‖</mml:mo><mml:mrow><mml:mstyle displaystyle="true"><mml:mover><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover></mml:mstyle></mml:mrow><mml:mo>‖</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mo>‖</mml:mo><mml:mrow><mml:mstyle displaystyle="true"><mml:mover><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover></mml:mstyle></mml:mrow><mml:mo>‖</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mi mathvariant="normal">cos</mml:mi><mml:mo>(</mml:mo><mml:mo>∠</mml:mo><mml:mrow><mml:mstyle displaystyle="true"><mml:mover><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover></mml:mstyle></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mstyle displaystyle="true"><mml:mover><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover></mml:mstyle></mml:mrow><mml:mo>)</mml:mo><mml:mo> </mml:mo></mml:math></inline-formula>and <inline-formula id="IE81"><mml:math id="IM78"><mml:mo>∠</mml:mo><mml:mrow><mml:mstyle displaystyle="true"><mml:mover><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover></mml:mstyle></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mstyle displaystyle="true"><mml:mover><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover></mml:mstyle></mml:mrow></mml:math></inline-formula> stands for the angle between <inline-formula id="IE82"><mml:math id="IM79"><mml:mrow><mml:mstyle displaystyle="true"><mml:mover><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover></mml:mstyle></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE83"><mml:math id="IM80"><mml:mrow><mml:mstyle displaystyle="true"><mml:mover><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover></mml:mstyle></mml:mrow></mml:math></inline-formula>. In the multivariate case, the pairwise correlations can be arranged in a symmetric matrix (i.e. the correlation matrix). This matrix is the covariance matrix of the standardized random variables, and its pairwise association are in <inline-formula id="IE84"><mml:math id="IM81"><mml:mo>[</mml:mo><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>]</mml:mo></mml:math></inline-formula>.
</p>
      <fig id="btz357-F1" orientation="portrait" position="float">
        <label>Fig. 1.</label>
        <caption>
          <p>Geometry of the partial correlation. The vectors <inline-formula id="IE85"><mml:math id="IM82"><mml:mrow><mml:mstyle displaystyle="true"><mml:mover><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover></mml:mstyle></mml:mrow></mml:math></inline-formula>, <inline-formula id="IE86"><mml:math id="IM83"><mml:mrow><mml:mstyle displaystyle="true"><mml:mover><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover></mml:mstyle></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE87"><mml:math id="IM84"><mml:mrow><mml:mstyle displaystyle="true"><mml:mover><mml:mrow><mml:mi mathvariant="bold-italic">z</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover></mml:mstyle></mml:mrow></mml:math></inline-formula> represent the random variables <italic>X, Y</italic> and <italic>Z</italic>  in subject space. In Panel (<bold>a</bold>), the correlation <inline-formula id="IE88"><mml:math id="IM85"><mml:mi mathvariant="bold-italic">r</mml:mi></mml:math></inline-formula> between <italic>X</italic> and <italic>Y</italic> is the cosine of <inline-formula id="IE89"><mml:math id="IM86"><mml:mo>α</mml:mo></mml:math></inline-formula>. In Panel (<bold>b</bold>), the partial correlation between <italic>X</italic> and <italic>Y</italic> can be interpreted as the cosine of the angle <inline-formula id="IE90"><mml:math id="IM87"><mml:mo>β</mml:mo></mml:math></inline-formula>. That is the cosine between the projection of <inline-formula id="IE91"><mml:math id="IM88"><mml:mrow><mml:mstyle displaystyle="true"><mml:mover><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover></mml:mstyle></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE92"><mml:math id="IM89"><mml:mrow><mml:mstyle displaystyle="true"><mml:mover><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover></mml:mstyle></mml:mrow></mml:math></inline-formula> onto a plane orthogonal to <inline-formula id="IE93"><mml:math id="IM90"><mml:mrow><mml:mstyle displaystyle="true"><mml:mover><mml:mrow><mml:mi mathvariant="bold-italic">z</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover></mml:mstyle></mml:mrow></mml:math></inline-formula>. The shrinkage effect consists in that the vectors <inline-formula id="IE94"><mml:math id="IM91"><mml:mrow><mml:mstyle displaystyle="true"><mml:mover><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover></mml:mstyle></mml:mrow></mml:math></inline-formula>, <inline-formula id="IE95"><mml:math id="IM92"><mml:mrow><mml:mstyle displaystyle="true"><mml:mover><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover></mml:mstyle></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE96"><mml:math id="IM93"><mml:mrow><mml:mstyle displaystyle="true"><mml:mover><mml:mrow><mml:mi mathvariant="bold-italic">z</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover></mml:mstyle></mml:mrow><mml:mo> </mml:mo></mml:math></inline-formula>are transformed to <inline-formula id="IE97"><mml:math id="IM94"><mml:mrow><mml:mstyle displaystyle="true"><mml:mover><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">λ</mml:mi></mml:mrow></mml:msup><mml:mo>→</mml:mo></mml:mover></mml:mstyle></mml:mrow><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mrow><mml:mstyle displaystyle="true"><mml:mover><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">λ</mml:mi></mml:mrow></mml:msup><mml:mo>→</mml:mo></mml:mover></mml:mstyle></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE98"><mml:math id="IM95"><mml:mrow><mml:mstyle displaystyle="true"><mml:mover><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">z</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">λ</mml:mi></mml:mrow></mml:msup><mml:mo>→</mml:mo></mml:mover></mml:mstyle></mml:mrow></mml:math></inline-formula> such that their lengths remain 1, and only the angles between each other change. In other words, the transformed vectors become less correlated. In Panel (<bold>c</bold>), the geometrical effect of the shrinkage consists in changing the projection plane <inline-formula id="IE99"><mml:math id="IM96"><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">v</mml:mi></mml:mrow><mml:mrow><mml:mo>⊥</mml:mo><mml:mi mathvariant="bold-italic">z</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> to <inline-formula id="IE100"><mml:math id="IM97"><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">v</mml:mi></mml:mrow><mml:mrow><mml:mo>⊥</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">z</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">λ</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:msup></mml:math></inline-formula>. In Panel (<bold>d</bold>), the ‘shrunk’ partial correlation <inline-formula id="IE101"><mml:math id="IM98"><mml:msup><mml:mrow><mml:mo>ρ</mml:mo></mml:mrow><mml:mrow><mml:mo>λ</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> between <italic>X</italic> and <italic>Y</italic> is the cosine of the angle <inline-formula id="IE102"><mml:math id="IM99"><mml:msup><mml:mrow><mml:mo>β</mml:mo></mml:mrow><mml:mrow><mml:mo>λ</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula>. That is the cosine between the projections of <inline-formula id="IE103"><mml:math id="IM100"><mml:mrow><mml:mstyle displaystyle="true"><mml:mover><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">λ</mml:mi></mml:mrow></mml:msup><mml:mo>→</mml:mo></mml:mover></mml:mstyle></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE104"><mml:math id="IM101"><mml:mrow><mml:mstyle displaystyle="true"><mml:mover><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">λ</mml:mi></mml:mrow></mml:msup><mml:mo>→</mml:mo></mml:mover></mml:mstyle></mml:mrow></mml:math></inline-formula> onto <inline-formula id="IE105"><mml:math id="IM102"><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">v</mml:mi></mml:mrow><mml:mrow><mml:mo>⊥</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">z</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">λ</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:msup></mml:math></inline-formula></p>
        </caption>
        <graphic xlink:href="btz357f1"/>
      </fig>
      <p>Whenever the target matrix <inline-formula id="IE106"><mml:math id="IM103"><mml:mi mathvariant="bold">T</mml:mi></mml:math></inline-formula> in <xref ref-type="disp-formula" rid="E3">Equation (3)</xref> is chosen as the diagonal matrix of variances, it results in scaling the <italic>off-diagonal</italic> elements of <inline-formula id="IE107"><mml:math id="IM104"><mml:msup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold">C</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi mathvariant="normal">SM</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> by a constant factor <inline-formula id="IE108"><mml:math id="IM105"><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mo>λ</mml:mo><mml:mo>)</mml:mo></mml:math></inline-formula>, while the diagonal remains unchanged. This applies as well to the correlation matrix with a shrinkage towards the identity matrix; symbolically <inline-formula id="IE109"><mml:math id="IM106"><mml:msub><mml:mrow><mml:msup><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mo>λ</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfenced separators="|"><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mo>λ</mml:mo></mml:mrow></mml:mfenced><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow></mml:msub><mml:mo> </mml:mo><mml:mo>∀</mml:mo><mml:mo> </mml:mo><mml:mi>i</mml:mi><mml:mo>≠</mml:mo><mml:mi>j</mml:mi></mml:math></inline-formula>, and 1 otherwise. In this case, the maximal correlation is <inline-formula id="IE110"><mml:math id="IM107"><mml:mo>±</mml:mo><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mo>λ</mml:mo><mml:mo>)</mml:mo></mml:math></inline-formula>, and (near) multi-collinearity is avoided. In subject space, this decorrelation means that the angles between the vectors increase while their lengths remain equal to one, generating the new <inline-formula id="IE111"><mml:math id="IM108"><mml:mrow><mml:mstyle displaystyle="true"><mml:mover><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">λ</mml:mi></mml:mrow></mml:msup><mml:mo>→</mml:mo></mml:mover></mml:mstyle></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mstyle displaystyle="true"><mml:mover><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">λ</mml:mi></mml:mrow></mml:msup><mml:mo>→</mml:mo></mml:mover></mml:mstyle></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mstyle displaystyle="true"><mml:mover><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">z</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">λ</mml:mi></mml:mrow></mml:msup><mml:mo>→</mml:mo></mml:mover></mml:mstyle></mml:mrow></mml:math></inline-formula>.</p>
      <p>On the other hand, the (standard) partial correlation <inline-formula id="IE112"><mml:math id="IM109"><mml:mo>ρ</mml:mo></mml:math></inline-formula> is a measure of linear dependence between two random variables after conditioning over all others. Geometrically, conditioning <inline-formula id="IE113"><mml:math id="IM110"><mml:mi>X</mml:mi></mml:math></inline-formula> (and <inline-formula id="IE114"><mml:math id="IM111"><mml:mi>Y</mml:mi></mml:math></inline-formula>) over the variable <inline-formula id="IE115"><mml:math id="IM112"><mml:mi>Z</mml:mi></mml:math></inline-formula> is equivalent to projecting the vector <inline-formula id="IE116"><mml:math id="IM113"><mml:mrow><mml:mstyle displaystyle="true"><mml:mover><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover></mml:mstyle></mml:mrow></mml:math></inline-formula> (and <inline-formula id="IE117"><mml:math id="IM114"><mml:mrow><mml:mstyle displaystyle="true"><mml:mover><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover></mml:mstyle></mml:mrow></mml:math></inline-formula>) onto a plane <inline-formula id="IE118"><mml:math id="IM115"><mml:msup><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mo>⊥</mml:mo><mml:mi>Z</mml:mi></mml:mrow></mml:msup><mml:mo> </mml:mo></mml:math></inline-formula>orthogonal to <inline-formula id="IE119"><mml:math id="IM116"><mml:mrow><mml:mstyle displaystyle="true"><mml:mover><mml:mrow><mml:mi mathvariant="bold-italic">z</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover></mml:mstyle></mml:mrow></mml:math></inline-formula>. Therefore, <inline-formula id="IE120"><mml:math id="IM117"><mml:mo>ρ</mml:mo></mml:math></inline-formula> is the cosine of the angle between the projected vectors on <inline-formula id="IE121"><mml:math id="IM118"><mml:msup><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mo>⊥</mml:mo><mml:mi>Z</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> as shown in <xref ref-type="fig" rid="btz357-F1">Figure 1b</xref>. The new vectors (i.e. <inline-formula id="IE122"><mml:math id="IM119"><mml:mrow><mml:mstyle displaystyle="true"><mml:mover><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">λ</mml:mi></mml:mrow></mml:msup><mml:mo>→</mml:mo></mml:mover></mml:mstyle></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mstyle displaystyle="true"><mml:mover><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">λ</mml:mi></mml:mrow></mml:msup><mml:mo>→</mml:mo></mml:mover></mml:mstyle></mml:mrow></mml:math></inline-formula>) are now projected onto a new plane (i.e. <inline-formula id="IE123"><mml:math id="IM120"><mml:msup><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mo>⊥</mml:mo><mml:msup><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mo>λ</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:msup></mml:math></inline-formula>), propagating the shrinkage effects as shown in <xref ref-type="fig" rid="btz357-F1">Figure 1c and d</xref>. At this point we recognize that the same geometric arguments used in <xref rid="btz357-B11" ref-type="bibr">Fisher (1924)</xref> to obtain the distribution of the (standard) partial correlation hold. From here on we will adapt that reasoning to our context.</p>
      <p>We start by highlighting that <inline-formula id="IE124"><mml:math id="IM121"><mml:msup><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mo>λ</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> =<inline-formula id="IE125"><mml:math id="IM122"><mml:mfenced separators="|"><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mo>λ</mml:mo></mml:mrow></mml:mfenced><mml:mi>r</mml:mi></mml:math></inline-formula> is invariant under rotations of the axes (like <inline-formula id="IE126"><mml:math id="IM123"><mml:mi>r</mml:mi></mml:math></inline-formula>). In other words, given a rotation of the coordinates, the shrunk (and standard) correlation remains unchanged. Now, suppose that the coordinate system rotates making one of its axes coincides with <inline-formula id="IE127"><mml:math id="IM124"><mml:mrow><mml:mstyle displaystyle="true"><mml:mover><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">z</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">λ</mml:mi></mml:mrow></mml:msup><mml:mo>→</mml:mo></mml:mover></mml:mstyle></mml:mrow></mml:math></inline-formula> (the new conditioning variable). Then, conditioning over <inline-formula id="IE128"><mml:math id="IM125"><mml:msup><mml:mrow><mml:mi>Z</mml:mi></mml:mrow><mml:mrow><mml:mo>λ</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> becomes equivalent to removing (from <inline-formula id="IE129"><mml:math id="IM126"><mml:mrow><mml:mstyle displaystyle="true"><mml:mover><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">λ</mml:mi></mml:mrow></mml:msup><mml:mo>→</mml:mo></mml:mover></mml:mstyle></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE130"><mml:math id="IM127"><mml:mrow><mml:mstyle displaystyle="true"><mml:mover><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">λ</mml:mi></mml:mrow></mml:msup><mml:mo>→</mml:mo></mml:mover></mml:mstyle></mml:mrow></mml:math></inline-formula>) the component in the <inline-formula id="IE131"><mml:math id="IM128"><mml:mrow><mml:mstyle displaystyle="true"><mml:mover><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">z</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">λ</mml:mi></mml:mrow></mml:msup><mml:mo>→</mml:mo></mml:mover></mml:mstyle></mml:mrow></mml:math></inline-formula> direction. Thus, the vectors are projected onto a plane <inline-formula id="IE132"><mml:math id="IM129"><mml:msup><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mo>⊥</mml:mo><mml:msup><mml:mrow><mml:mi>Z</mml:mi></mml:mrow><mml:mrow><mml:mo>λ</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:msup></mml:math></inline-formula> that is orthogonal to <inline-formula id="IE133"><mml:math id="IM130"><mml:mrow><mml:mstyle displaystyle="true"><mml:mover><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">z</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">λ</mml:mi></mml:mrow></mml:msup><mml:mo>→</mml:mo></mml:mover></mml:mstyle></mml:mrow></mml:math></inline-formula>. Consequently, <inline-formula id="IE134"><mml:math id="IM131"><mml:msup><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mo>λ</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> is modified when it is conditioned over <inline-formula id="IE135"><mml:math id="IM132"><mml:msup><mml:mrow><mml:mi>Z</mml:mi></mml:mrow><mml:mrow><mml:mo>λ</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> to give the ‘shrunk’ partial correlation <inline-formula id="IE136"><mml:math id="IM133"><mml:msup><mml:mrow><mml:mo>ρ</mml:mo></mml:mrow><mml:mrow><mml:mo>λ</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula>; symbolically <inline-formula id="IE137"><mml:math id="IM134"><mml:msup><mml:mrow><mml:mo>ρ</mml:mo></mml:mrow><mml:mrow><mml:mo>λ</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mo>λ</mml:mo></mml:mrow></mml:msup><mml:mo>|</mml:mo><mml:msup><mml:mrow><mml:mi>Z</mml:mi></mml:mrow><mml:mrow><mml:mo>λ</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula>. The distribution of <inline-formula id="IE138"><mml:math id="IM135"><mml:msup><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mo>λ</mml:mo></mml:mrow></mml:msup><mml:mo>|</mml:mo><mml:msup><mml:mrow><mml:mi>Z</mml:mi></mml:mrow><mml:mrow><mml:mo>λ</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> is the distribution of <inline-formula id="IE139"><mml:math id="IM136"><mml:msup><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mo>λ</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> obtained by removing one sample (decreasing its degrees of freedom by one). This process can be repeated by rotating the axes once more to condition over the next variable, and the argument is generalizable by replacing <inline-formula id="IE140"><mml:math id="IM137"><mml:mi>Z</mml:mi></mml:math></inline-formula> with a set of <inline-formula id="IE141"><mml:math id="IM138"><mml:mi>p</mml:mi><mml:mo>-</mml:mo><mml:mn>2</mml:mn></mml:math></inline-formula> variables <inline-formula id="IE142"><mml:math id="IM139"><mml:mo>{</mml:mo><mml:msub><mml:mrow><mml:mi>Z</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>Z</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>.</mml:mo><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mi>Z</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>-</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>}</mml:mo></mml:math></inline-formula>. Finally, the vectors have been conditioned over the <inline-formula id="IE143"><mml:math id="IM140"><mml:mi>p</mml:mi><mml:mo>-</mml:mo><mml:mn>2</mml:mn></mml:math></inline-formula> other variables, and <inline-formula id="IE144"><mml:math id="IM141"><mml:msup><mml:mrow><mml:mo>ρ</mml:mo></mml:mrow><mml:mrow><mml:mo>λ</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mo>λ</mml:mo></mml:mrow></mml:msup><mml:mo>|</mml:mo><mml:mo>{</mml:mo><mml:msub><mml:mrow><mml:mi>Z</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>Z</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>.</mml:mo><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mi>Z</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>-</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>}</mml:mo></mml:math></inline-formula> follows the distribution of <inline-formula id="IE145"><mml:math id="IM142"><mml:msup><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mo>λ</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> obtained after removing <inline-formula id="IE146"><mml:math id="IM143"><mml:mi>p</mml:mi><mml:mo>-</mml:mo><mml:mn>2</mml:mn></mml:math></inline-formula> samples.</p>
      <p>The distribution for <inline-formula id="IE147"><mml:math id="IM144"><mml:msup><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mo>λ</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> is found via the transformation <inline-formula id="IE148"><mml:math id="IM145"><mml:msup><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mo>λ</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mo>λ</mml:mo><mml:mo>)</mml:mo><mml:mi>r</mml:mi></mml:math></inline-formula> over <xref ref-type="disp-formula" rid="E4">Equation (4)</xref> leading to
<disp-formula id="E6"><label>(6)</label><mml:math id="M6"><mml:mrow><mml:msubsup><mml:mo stretchy="false">∫</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mrow><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:mfenced><mml:mi>d</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:msubsup><mml:mo stretchy="false">∫</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mfenced separators="|"><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mo>λ</mml:mo></mml:mrow></mml:mfenced><mml:mo> </mml:mo></mml:mrow><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mo>λ</mml:mo></mml:mrow></mml:mfenced><mml:mo> </mml:mo></mml:mrow></mml:msubsup><mml:mrow><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mo>λ</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mo>λ</mml:mo></mml:mrow></mml:mfenced><mml:mo> </mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msup><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mo>λ</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mo>λ</mml:mo></mml:mrow></mml:mfenced><mml:mo> </mml:mo></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:math></disp-formula></p>
      <p>and is naturally defined in <inline-formula id="IE149"><mml:math id="IM146"><mml:mo>[</mml:mo><mml:mo>-</mml:mo><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mo>λ</mml:mo><mml:mo>)</mml:mo><mml:mo>,</mml:mo><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mo>λ</mml:mo><mml:mo>)</mml:mo><mml:mo>]</mml:mo></mml:math></inline-formula> with the form
<disp-formula id="E7"><label>(7)</label><mml:math id="M7"><mml:msup><mml:mrow><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mo>λ</mml:mo></mml:mrow></mml:msup><mml:mfenced separators="|"><mml:mrow><mml:msup><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mo>λ</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:msup><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mo>λ</mml:mo></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>-</mml:mo><mml:msup><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:msup><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mo>λ</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>k</mml:mi><mml:mo>-</mml:mo><mml:mn>3</mml:mn><mml:mo>)</mml:mo><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mi mathvariant="italic">Beta</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac><mml:mo>,</mml:mo><mml:mfrac><mml:mrow><mml:mi>k</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced><mml:msup><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mo>λ</mml:mo></mml:mrow></mml:mfenced><mml:mo> </mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>k</mml:mi><mml:mo>-</mml:mo><mml:mn>2</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mo> </mml:mo></mml:math></disp-formula></p>
      <p>The expectation is <inline-formula id="IE150"><mml:math id="IM147"><mml:mi mathvariant="double-struck">E</mml:mi><mml:mfenced open="[" close="]" separators="|"><mml:mrow><mml:msup><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mo>λ</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mfenced separators="|"><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mo>λ</mml:mo></mml:mrow></mml:mfenced><mml:mi mathvariant="double-struck">E</mml:mi><mml:mfenced open="[" close="]" separators="|"><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula>, and its variance <inline-formula id="IE151"><mml:math id="IM148"><mml:mi mathvariant="normal">var</mml:mi><mml:mfenced open="[" close="]" separators="|"><mml:mrow><mml:msup><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mo>λ</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mo>λ</mml:mo></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mi mathvariant="normal">v</mml:mi><mml:mi mathvariant="normal">ar</mml:mi><mml:mfenced open="[" close="]" separators="|"><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula> is reduced as <inline-formula id="IE152"><mml:math id="IM149"><mml:msup><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mo>λ</mml:mo></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>≤</mml:mo><mml:mn>1</mml:mn></mml:math></inline-formula>. As a consequence of the geometric arguments above the density for the ‘shrunk’ partial correlation<inline-formula id="IE153"><mml:math id="IM150"><mml:mo> </mml:mo><mml:msup><mml:mrow><mml:mo>ρ</mml:mo></mml:mrow><mml:mrow><mml:mo>λ</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mo>λ</mml:mo></mml:mrow></mml:msup><mml:mo>|</mml:mo><mml:mi mathvariant="normal"> </mml:mi><mml:mo>{</mml:mo><mml:msub><mml:mrow><mml:mi>Z</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>Z</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>.</mml:mo><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mi>Z</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>-</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>}</mml:mo></mml:math></inline-formula> in the well posed case <inline-formula id="IE154"><mml:math id="IM151"><mml:mi>n</mml:mi><mml:mo>≫</mml:mo><mml:mi>p</mml:mi></mml:math></inline-formula> is also described by <xref ref-type="disp-formula" rid="E7">Equation (7)</xref> with <inline-formula id="IE155"><mml:math id="IM152"><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mi>n</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mo>(</mml:mo><mml:mi>p</mml:mi><mml:mo>-</mml:mo><mml:mn>2</mml:mn><mml:mo>)</mml:mo></mml:math></inline-formula>. In the ill-posed case <inline-formula id="IE156"><mml:math id="IM153"><mml:mi>n</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>p</mml:mi></mml:math></inline-formula>, <inline-formula id="IE157"><mml:math id="IM154"><mml:mi>k</mml:mi></mml:math></inline-formula> can be estimated via maximum likelihood estimation (MLE) (<xref ref-type="supplementary-material" rid="sup1">Supplementary Section S2</xref>) as it has no clear geometrical meaning. Some examples of the shrinkage effect are provided in the <xref ref-type="supplementary-material" rid="sup1">Supplementary Section S1</xref>. Further mathematical details can be found in <xref rid="btz357-B10" ref-type="bibr">Fisher (1915)</xref> and <xref rid="btz357-B14" ref-type="bibr">Hotelling (1953)</xref>.</p>
    </sec>
  </sec>
  <sec>
    <title>3 Implementation</title>
    <p>In what follows we will compare two inference methods. First, ENF with <xref ref-type="disp-formula" rid="E4">Equation (4)</xref> currently implemented in <italic>GeneNet</italic> version 1.2.13 (see Section 2.2). Second, the parametric approach proposed here, to which we will refer as Shrunk MLE (see <xref ref-type="supplementary-material" rid="sup1">Supplementary Section S2</xref>). We will employ as the gold standard a computationally expensive estimation of <italic>P</italic>-values based on Monte Carlo (MC) (see <xref ref-type="supplementary-material" rid="sup1">Supplementary Section S3</xref>). MC estimation is a non-parametric and unbiased method; however, for large networks it is time costly which limits its use in many applications.</p>
    <sec>
      <title>3.1 Synthetic data</title>
      <p>Simulations are performed with R version 3.4.0, and <italic>GeneNet</italic> version 1.2.13. The later allows to generate GGMs with a fixed percentage of partial correlations (<xref rid="btz357-B24" ref-type="bibr">Schäfer and Strimmer, 2005a)</xref>.</p>
    </sec>
    <sec>
      <title>3.2 Stress response in <italic>Escherichia coli</italic></title>
      <p>This dataset consists of <italic>E.coli</italic> microarray gene-expression from <xref rid="btz357-B26" ref-type="bibr">Schmidt-Heck et al. (2004)</xref>. The authors studied the stress temporal response after the expression of recombinant human superoxide dismutase (SOD) at 8, 15, 22, 45, 68, 90, 150 and 180 min. SOD expression was induced by isopropyl β-D-1-thiogalactopyranoside (IPTG), which is a lactose analog inducer of the lac operon. In the original study the authors identified 102 out of 4289 protein coding genes as differentially expressed at transcript level in one or more samples after induction. Data pre-processing included log<sub>2</sub>-ratio transformation with respect to the first time point. The final dataset consists of expression values for transcripts corresponding to 102 genes with 9 time points, and was obtained from the R package <italic>GeneNet</italic> version 1.2.13.</p>
    </sec>
    <sec>
      <title>3.3 Infection response in <italic>Mus musculus</italic></title>
      <p>The following dataset comes from a study of transcript interactions in a mouse (<italic>M.musculus</italic>) model of influenza infection (<xref rid="btz357-B27" ref-type="bibr">Steed et al., 2017</xref>). It is available at <ext-link ext-link-type="uri" xlink:href="https://www.ebi.ac.uk/arrayexpress/experiments/E-MTAB-5337">https://www.ebi.ac.uk/arrayexpress/experiments/E-MTAB-5337</ext-link>, and consists of RNA-seq transcript expression data of mouse lungs. The study focuses on the role of the <italic>Irgm1</italic> gene in mice of 8–12 weeks of age with samples at four time points (0, 3, 6, and 10 days after infection). We pre-processed it by filtering out probes with low counts (i.e. fractions per million (FPM) &lt; 1). From the duplicate probes we kept the one with the highest FPM. A total of 539 genes were differentially expressed at the 10% level false discovery rate (FDR) and their expression values were log<sub>2</sub>-transformed.</p>
    </sec>
  </sec>
  <sec>
    <title>4 Results</title>
    <sec>
      <title>4.1 Analysis of simulated data</title>
      <p>In this section, we demonstrate the superior performance of the improved approach Shrunk MLE by comparing it to: (i) ENF, and (ii) MC <italic>P</italic>-value estimation. A total of 4574 datasets were simulated (see <xref ref-type="supplementary-material" rid="sup1">Supplementary Table S1</xref>). First, we perform a qualitative study under the null hypothesis <inline-formula id="IE158"><mml:math id="IM155"><mml:msub><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>:</mml:mo><mml:mo>ρ</mml:mo><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:math></inline-formula>. Second, we cross compare the reconstruction for sparse networks (i.e. small percentage of true positives) in terms of the FPs, and the positive predictive value (PPV). Third, two real quantitative molecular profile datasets are used to examine the results from a biological point of view. <xref ref-type="supplementary-material" rid="sup1">Supplementary Table S2</xref> gives an overview of definitions used in the evaluation.</p>
      <p><xref ref-type="fig" rid="btz357-F2">Figure 2a and b</xref> display the <italic>average</italic> histograms for the <italic>P</italic>-values retrieved by each method. <xref ref-type="fig" rid="btz357-F2">Figure 2c and d</xref> show the two null-densities<inline-formula id="IE159"><mml:math id="IM156"><mml:mi mathvariant="normal"> </mml:mi><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:msup><mml:mrow><mml:mo>ρ</mml:mo></mml:mrow><mml:mrow><mml:mo>λ</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mfenced></mml:math></inline-formula> and <inline-formula id="IE160"><mml:math id="IM157"><mml:msup><mml:mrow><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mo>λ</mml:mo></mml:mrow></mml:msup><mml:mfenced separators="|"><mml:mrow><mml:msup><mml:mrow><mml:mo>ρ</mml:mo></mml:mrow><mml:mrow><mml:mo>λ</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mfenced><mml:mi mathvariant="normal"> </mml:mi></mml:math></inline-formula>presented as <xref ref-type="disp-formula" rid="E4">Equations (4)</xref> and <xref ref-type="disp-formula" rid="E7">(7)</xref>. In the first case, the degrees of freedom <inline-formula id="IE161"><mml:math id="IM158"><mml:mi>k</mml:mi></mml:math></inline-formula> was obtained via MLE under simulated <inline-formula id="IE162"><mml:math id="IM159"><mml:msub><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula>, in the second case via ENF. Here it can be observed that <inline-formula id="IE163"><mml:math id="IM160"><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:msup><mml:mrow><mml:mo>ρ</mml:mo></mml:mrow><mml:mrow><mml:mo>λ</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mfenced></mml:math></inline-formula> has larger tails than <inline-formula id="IE164"><mml:math id="IM161"><mml:msup><mml:mrow><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mo>λ</mml:mo></mml:mrow></mml:msup><mml:mfenced separators="|"><mml:mrow><mml:msup><mml:mrow><mml:mo>ρ</mml:mo></mml:mrow><mml:mrow><mml:mo>λ</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mfenced></mml:math></inline-formula>. This is further illustrated by Q-Q plots in <xref ref-type="supplementary-material" rid="sup1">Supplementary Figure S2</xref>, where the <italic>P</italic>-values’ quantiles are expected to be on the diagonal line if they agree with the theoretical quantiles (from a uniform distribution in <inline-formula id="IE165"><mml:math id="IM162"><mml:mo>[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>]</mml:mo></mml:math></inline-formula>). <xref ref-type="fig" rid="btz357-F3">Figure 3</xref> shows the number of significant partial correlations obtained by each method while varying the sample size <inline-formula id="IE166"><mml:math id="IM163"><mml:mi>n</mml:mi></mml:math></inline-formula>. <xref ref-type="fig" rid="btz357-F3">Figure 3a and b</xref> show the results using (un-adjusted) <italic>P</italic>-values under <inline-formula id="IE167"><mml:math id="IM164"><mml:msub><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> at <inline-formula id="IE168"><mml:math id="IM165"><mml:mo>α</mml:mo><mml:mo>=</mml:mo><mml:mn>0.05</mml:mn></mml:math></inline-formula> and <inline-formula id="IE169"><mml:math id="IM166"><mml:mo>α</mml:mo><mml:mo>=</mml:mo><mml:mn>0.01</mml:mn></mml:math></inline-formula> respectively. It can be observed that ENF does not recover the proportion of <italic>expected</italic> FPs. <xref ref-type="fig" rid="btz357-F3">Figure 3c and d</xref> show the FPs for different ratios <inline-formula id="IE170"><mml:math id="IM167"><mml:mi>p</mml:mi><mml:mo>/</mml:mo><mml:mi>n</mml:mi></mml:math></inline-formula> in sparse networks. In this scenario, ENF learns considerably more FPs than the other methods. In <xref ref-type="fig" rid="btz357-F4">Figure 4</xref>, we compare the false positive rate (FPR) with respect to the gold standard in a grid of <inline-formula id="IE171"><mml:math id="IM168"><mml:mi>p</mml:mi></mml:math></inline-formula> and <inline-formula id="IE172"><mml:math id="IM169"><mml:mi>n</mml:mi></mml:math></inline-formula>. For Shrunk MLE the performance is equivalent to MC when <inline-formula id="IE173"><mml:math id="IM170"><mml:mi>n</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>10</mml:mn></mml:math></inline-formula> and <inline-formula id="IE174"><mml:math id="IM171"><mml:mi>p</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>40</mml:mn></mml:math></inline-formula>, while ENF differs in almost every case. The PPV for different <inline-formula id="IE175"><mml:math id="IM172"><mml:mi>n</mml:mi></mml:math></inline-formula> is presented in <xref ref-type="fig" rid="btz357-F5">Figure 5</xref> for adjusted <italic>P</italic>-values (<xref rid="btz357-B114" ref-type="bibr">Benjamini and Hochberg, 1995</xref>). See <xref ref-type="supplementary-material" rid="sup1">Supplementary Figures S3 and S4</xref> for the PPV with unadjusted <italic>P</italic>-values, and an additional Type I error plot. In general, a relatively low PPV is expected as <inline-formula id="IE176"><mml:math id="IM173"><mml:mo>δ</mml:mo></mml:math></inline-formula> is small (i.e. there are few positives compared with the number of tests). We observe that the performance of Shrunk MLE is similar to the gold standard MC even for very large <inline-formula id="IE177"><mml:math id="IM174"><mml:mo>λ</mml:mo></mml:math></inline-formula>. Additionally, Shrunk MLE requires a much shorter computational time, as can be seen in the <xref ref-type="supplementary-material" rid="sup1">Supplementary Table S3</xref>.
</p>
      <fig id="btz357-F2" orientation="portrait" position="float">
        <label>Fig. 2.</label>
        <caption>
          <p>Probability densities and <italic>P</italic>-values under<inline-formula id="IE178"><mml:math id="IM175"><mml:mi mathvariant="normal"> </mml:mi><mml:msub><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula>. This figure shows a comparison of the standard <inline-formula id="IE179"><mml:math id="IM176"><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:msup><mml:mrow><mml:mo>ρ</mml:mo></mml:mrow><mml:mrow><mml:mo>λ</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mfenced></mml:math></inline-formula> and ‘shrunk’ <inline-formula id="IE180"><mml:math id="IM177"><mml:msup><mml:mrow><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mo>λ</mml:mo></mml:mrow></mml:msup><mml:mfenced separators="|"><mml:mrow><mml:msup><mml:mrow><mml:mo>ρ</mml:mo></mml:mrow><mml:mrow><mml:mo>λ</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mfenced></mml:math></inline-formula> densities, and their <italic>P</italic>-values under <inline-formula id="IE181"><mml:math id="IM178"><mml:msub><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula>. Here Standard MLE denotes <inline-formula id="IE182"><mml:math id="IM179"><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:msup><mml:mrow><mml:mo>ρ</mml:mo></mml:mrow><mml:mrow><mml:mo>λ</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mfenced></mml:math></inline-formula> (i.e. <xref ref-type="disp-formula" rid="E4">Equation 4</xref>) with <italic>k</italic> obtained via MLE (as in Shrunk MLE). Panel (<bold>a</bold>) shows the average histogram of <italic>P</italic>-values obtained with (i) Standard MLE (dark grey), (ii) Shrunk MLE (light grey) and (iii) MC (white) with 15 iterations. Panel (<bold>b</bold>) replaces Standard MLE by ENF to estimate <inline-formula id="IE183"><mml:math id="IM180"><mml:mi>k</mml:mi></mml:math></inline-formula> in <inline-formula id="IE184"><mml:math id="IM181"><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:msup><mml:mrow><mml:mo>ρ</mml:mo></mml:mrow><mml:mrow><mml:mo>λ</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mfenced></mml:math></inline-formula> (currently used in <italic>GeneNet</italic>). The bin’s width is set to 0.05; therefore, the first bin represents the amount of significant coefficients at the 5% level. The bin’s height corresponds to the mean over 25 simulations, and the error bars (for ENF) to ±2 SE. It can be seen that the <italic>P</italic>-values from ENF (dark grey) are not uniformly distributed in [0, 1] under <inline-formula id="IE185"><mml:math id="IM182"><mml:msub><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula>. Panels (<bold>c</bold>) and (<bold>d</bold>) show the difference <inline-formula id="IE186"><mml:math id="IM183"><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:msup><mml:mrow><mml:mo>ρ</mml:mo></mml:mrow><mml:mrow><mml:mo>λ</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mfenced><mml:mo>-</mml:mo><mml:msup><mml:mrow><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mo>λ</mml:mo></mml:mrow></mml:msup><mml:mfenced separators="|"><mml:mrow><mml:msup><mml:mrow><mml:mo>ρ</mml:mo></mml:mrow><mml:mrow><mml:mo>λ</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mfenced></mml:math></inline-formula> when <inline-formula id="IE187"><mml:math id="IM184"><mml:mi>k</mml:mi></mml:math></inline-formula> is found via MLE or via ENF, respectively (see Section 2.1). Data were simulated with <inline-formula id="IE188"><mml:math id="IM185"><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>100</mml:mn></mml:math></inline-formula>, <inline-formula id="IE189"><mml:math id="IM186"><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>20</mml:mn></mml:math></inline-formula> and <inline-formula id="IE190"><mml:math id="IM187"><mml:mo>λ</mml:mo><mml:mo>=</mml:mo></mml:math></inline-formula>0.94. The critical value at <inline-formula id="IE191"><mml:math id="IM188"><mml:mo>α</mml:mo><mml:mo>=</mml:mo><mml:mn>0.05</mml:mn></mml:math></inline-formula> (in dashed grey) is estimated by MC (with 100 iterations). It can be seen that <inline-formula id="IE192"><mml:math id="IM189"><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:msup><mml:mrow><mml:mo>ρ</mml:mo></mml:mrow><mml:mrow><mml:mo>λ</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mfenced></mml:math></inline-formula> has larger tails than <inline-formula id="IE193"><mml:math id="IM190"><mml:msup><mml:mrow><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mo>λ</mml:mo></mml:mrow></mml:msup><mml:mfenced separators="|"><mml:mrow><mml:msup><mml:mrow><mml:mo>ρ</mml:mo></mml:mrow><mml:mrow><mml:mo>λ</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mfenced></mml:math></inline-formula></p>
        </caption>
        <graphic xlink:href="btz357f2"/>
      </fig>
      <fig id="btz357-F3" orientation="portrait" position="float">
        <label>Fig. 3.</label>
        <caption>
          <p>False positives. This figure shows the number of FPs obtained with different sample size <inline-formula id="IE194"><mml:math id="IM191"><mml:mi>n</mml:mi></mml:math></inline-formula>. The number of FPs are shown in Panels (<bold>a</bold>) and (<bold>b</bold>) under <inline-formula id="IE195"><mml:math id="IM192"><mml:msub><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula>: no partial correlation (i.e. the percentages of true correlations <inline-formula id="IE196"><mml:math id="IM193"><mml:mo>δ</mml:mo></mml:math></inline-formula> is zero). Inference is carried out from simulated data for <inline-formula id="IE197"><mml:math id="IM194"><mml:mi>p</mml:mi></mml:math></inline-formula> = 100 and <inline-formula id="IE198"><mml:math id="IM195"><mml:mi>n</mml:mi></mml:math></inline-formula> ranging from 10 to 150 in steps of size 10. The black horizontal line represents the <italic>expected</italic> number of FPs under<inline-formula id="IE199"><mml:math id="IM196"><mml:mi mathvariant="normal"> </mml:mi><mml:msub><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula>, tested at <inline-formula id="IE200"><mml:math id="IM197"><mml:mo>α</mml:mo></mml:math></inline-formula> = 0.05 and<inline-formula id="IE201"><mml:math id="IM198"><mml:mi mathvariant="normal"> </mml:mi><mml:mn>0.01</mml:mn></mml:math></inline-formula> respectively (i.e. 247.5 for <inline-formula id="IE202"><mml:math id="IM199"><mml:mo>α</mml:mo></mml:math></inline-formula> = 0.05 and 49.5 for <inline-formula id="IE203"><mml:math id="IM200"><mml:mo>α</mml:mo></mml:math></inline-formula>=0.01). Panels (<bold>c</bold>) and (<bold>d</bold>) show the number of FPs for different proportions <inline-formula id="IE204"><mml:math id="IM201"><mml:mi>p</mml:mi><mml:mo>/</mml:mo><mml:mi>n</mml:mi></mml:math></inline-formula> when the percentages of non-zero correlations is <inline-formula id="IE205"><mml:math id="IM202"><mml:mo>δ</mml:mo></mml:math></inline-formula> = 0.01. Here <inline-formula id="IE206"><mml:math id="IM203"><mml:mi>p</mml:mi></mml:math></inline-formula> = 50, 100, 150, 200 and <inline-formula id="IE207"><mml:math id="IM204"><mml:mi>n</mml:mi><mml:mo> </mml:mo></mml:math></inline-formula> = 20. Three approaches are compared: ENF (dot with dashed line), Shrunk MLE (square with dotted line), and MC with 15 iterations (triangle with continuous line). Symbols (and bars) represent the average (±2 SE) over 25 repeated simulations. The upper horizontal axis shows the average shrinkage intensity <inline-formula id="IE208"><mml:math id="IM205"><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="normal">λ</mml:mi></mml:mrow><mml:mrow/></mml:mover></mml:mrow></mml:math></inline-formula> rounded to two digits</p>
        </caption>
        <graphic xlink:href="btz357f3"/>
      </fig>
      <fig id="btz357-F4" orientation="portrait" position="float">
        <label>Fig. 4.</label>
        <caption>
          <p>FPR cross-comparison. This figure shows a heatmap for the difference in FPR under <inline-formula id="IE209"><mml:math id="IM206"><mml:msub><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula>: no partial correlation with respect to the gold standard (MC). The number of variables <inline-formula id="IE210"><mml:math id="IM207"><mml:mi>p</mml:mi></mml:math></inline-formula> range from 10 to 400, and the sample size <inline-formula id="IE211"><mml:math id="IM208"><mml:mi>n</mml:mi></mml:math></inline-formula> from 3 to 100. Panel (<bold>a</bold>) shows the heatmap for the FPR for ENF minus the FPR for MC, averaged over 10 simulations (rounded to two decimals). Panel (<bold>b</bold>) show the respective results for Shrunk MLE. The test is carried out at <inline-formula id="IE212"><mml:math id="IM209"><mml:mo>α</mml:mo></mml:math></inline-formula> = 0.05 with a shrinkage value fixed to <inline-formula id="IE213"><mml:math id="IM210"><mml:mo>λ</mml:mo></mml:math></inline-formula> = 0.3. The color scale represents the FPR differences in the <inline-formula id="IE214"><mml:math id="IM211"><mml:mi>p</mml:mi></mml:math></inline-formula> – <inline-formula id="IE215"><mml:math id="IM212"><mml:mi>n</mml:mi></mml:math></inline-formula> grid, where the larger the FPR difference the darker is the corresponding grid cell. In general, Shrunk MLE outperforms ENF, and it is in close agreement with MC for <inline-formula id="IE216"><mml:math id="IM213"><mml:mi>p</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>40</mml:mn></mml:math></inline-formula> and <inline-formula id="IE217"><mml:math id="IM214"><mml:mi>n</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>10</mml:mn></mml:math></inline-formula></p>
        </caption>
        <graphic xlink:href="btz357f4"/>
      </fig>
      <fig id="btz357-F5" orientation="portrait" position="float">
        <label>Fig. 5.</label>
        <caption>
          <p>Positive predictive value. This figure shows the PPV (<inline-formula id="IE218"><mml:math id="IM215"><mml:mi mathvariant="italic">PPV</mml:mi><mml:mo>=</mml:mo><mml:mi mathvariant="italic">TP</mml:mi><mml:mo>/</mml:mo><mml:mi mathvariant="italic">P</mml:mi></mml:math></inline-formula>) obtained with different sample sizes. The inference is carried out from simulated data for <inline-formula id="IE219"><mml:math id="IM216"><mml:mi>p</mml:mi><mml:mo> </mml:mo></mml:math></inline-formula> =100 with <inline-formula id="IE220"><mml:math id="IM217"><mml:mi>n</mml:mi></mml:math></inline-formula> ranging from 10 to 150 in steps of size 10, tested at <inline-formula id="IE221"><mml:math id="IM218"><mml:mo>α</mml:mo></mml:math></inline-formula> = 0.05. The Panels (<bold>a</bold>) and (<bold>b</bold>) show the PPV using Benjamini-Hochberg (BH)-adjusted <italic>P</italic>-values for multiple testing with <inline-formula id="IE222"><mml:math id="IM219"><mml:mo> </mml:mo><mml:mo>δ</mml:mo></mml:math></inline-formula> = 0.01 (or 49 correlations) and <inline-formula id="IE223"><mml:math id="IM220"><mml:mo>δ</mml:mo></mml:math></inline-formula> = 0.03 (or 148 correlations). Three approaches are compared: ENF (dot with dashed line), Shrunk MLE (square with dotted line), and MC with 15 iterations (triangle with continuous line). Symbols (and bars) represent the average (±2 SEs) over 25 repeated simulations. The upper horizontal axis shows the average shrinkage intensity <inline-formula id="IE224"><mml:math id="IM221"><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="normal">λ</mml:mi></mml:mrow><mml:mo>¯</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> rounded to two digits</p>
        </caption>
        <graphic xlink:href="btz357f5"/>
      </fig>
    </sec>
    <sec>
      <title>4.2 Analysis of experimental data</title>
      <sec>
        <title>4.2.1 Effects of human SOD protein expression on transcript expression in <italic>E.coli</italic></title>
        <p>Here we employ our new approach to analyze <italic>E.coli</italic> microarray gene-expression data from <xref rid="btz357-B26" ref-type="bibr">Schmidt-Heck et al. (2004)</xref>. The final data consist of transcripts corresponding to 102 genes with 9 time points. We treated the data as static (ignoring its temporal nature) following the original analysis (<xref rid="btz357-B24" ref-type="bibr">Schäfer and Strimmer, 2005a)</xref>. <xref ref-type="fig" rid="btz357-F6">Figure 6</xref> shows that MC, and our approach (Shrunk MLE) learn nearly the same amount of edges using <italic>P</italic>-values, differing in 20 out of 258 connections (∼7.75%).
</p>
        <fig id="btz357-F6" orientation="portrait" position="float">
          <label>Fig. 6.</label>
          <caption>
            <p>Amount of significant edges related to the induced expression of SOD in <italic>E.coli</italic>. Analysis of <italic>E.coli</italic> gene microarray expression data upon response to induced SOD expression. The dataset includes 102 genes (<xref rid="btz357-B26" ref-type="bibr">Schmidt-Heck <italic>et al.</italic>, 2004</xref>). The estimator produces an optimal shrinkage <inline-formula id="IE225"><mml:math id="IM222"><mml:mo>λ</mml:mo></mml:math></inline-formula> = 0.18. Three methods are compared at <inline-formula id="IE226"><mml:math id="IM223"><mml:mo>α</mml:mo></mml:math></inline-formula> = 0.05: ENF, Shrunk MLE, MC with 40 iterations. Panel (<bold>a</bold>) Venn diagram of significant partial correlations (i.e. edges in the GGM) recovered by each method with un-adjusted <italic>P</italic>-values. Panel (<bold>b</bold>) Venn diagram of significant partial correlations recovered by each method with BH-adjusted <italic>P</italic>-values</p>
          </caption>
          <graphic xlink:href="btz357f6"/>
        </fig>
        <p>ENF learns 220 additional edges (∼85.3% more than MC). We observe that after BH adjustment the amount of edges in Shrunk MLE is too low to make any conclusion due to the small sample size (see <xref ref-type="fig" rid="btz357-F3">Figs 3–5</xref>). Therefore, the analysis is continued with un-adjusted <italic>P</italic>-values. For every method the most significant connections were <italic>lacA-lacZ, lacY-lacZ</italic> and <italic>lacA-lacY</italic>. The lac operon involves precisely these three genes induced by IPTG. Shrunk MLE and MC retrieve 74 connected genes, and ENF 88 at <inline-formula id="IE227"><mml:math id="IM224"><mml:mo>α</mml:mo><mml:mo>=</mml:mo><mml:mn>0.05</mml:mn></mml:math></inline-formula>. These genes were assessed for gene ontology (GO) enrichment using PANTHER Classification System (<ext-link ext-link-type="uri" xlink:href="http://geneontology.org/">http://geneontology.org/</ext-link>) (<xref rid="btz357-B1" ref-type="bibr">Ashburner <italic>et al.</italic>, 2000</xref>; <xref rid="btz357-B21" ref-type="bibr">Mi <italic>et al.</italic>, 2017</xref>) with a FDR &lt; 0.05. The result shows that our method identifies a significant enrichment of stress response (GO: 0006950, fold enrichment = 2.57, FDR = 3.87 10<sup>−</sup><sup>2</sup>). In contrast, this GO term is not significant for ENF (fold enrichment = 9.81, FDR = 1.27 10<sup>−1</sup>) suggesting that the enrichment of the genes related to the treatment stimulus was diluted. The most significant GOs obtained with Shrunk MLE, ENF, as well as the hubs present in the network structures are reported in <xref ref-type="supplementary-material" rid="sup1">Supplementary Table S4a</xref>–c, respectively. The GGM structure can be seen in <xref ref-type="supplementary-material" rid="sup1">Supplementary Figure S5</xref>.</p>
      </sec>
      <sec>
        <title>4.2.2 Effects of infection with the influenza virus on gene expression in <italic>M.musculus</italic></title>
        <p>Here we study transcript interactions in a public RNA-seq data from a mouse (<italic>M.musculus</italic>) model of influenza infection (<xref rid="btz357-B27" ref-type="bibr">Steed et al., 2017</xref>). The final data consists of 539 genes and 2<inline-formula id="IE228"><mml:math id="IM225"><mml:mn>4</mml:mn></mml:math></inline-formula> samples. <xref ref-type="fig" rid="btz357-F7">Figure 7</xref> shows that MC (considered as the gold standard), and Shrunk MLE learn nearly the same number of edges using <italic>P</italic>-values, differing only in 37 out of 11 870 connections (∼0.312%). It also shows that the agreement using BH-adjusted <italic>P</italic>-values is ∼76.53%. This illustrates the fact that even small discrepancies in the <italic>P</italic>-values might become large for the adjusted <italic>P</italic>-values, and can be observed by comparing the PPVs in <xref ref-type="fig" rid="btz357-F5">Figure 5</xref> and <xref ref-type="supplementary-material" rid="sup1">Supplementary Figure S3</xref>.
</p>
        <fig id="btz357-F7" orientation="portrait" position="float">
          <label>Fig. 7.</label>
          <caption>
            <p>Amount of significant edges related to lung samples’ expression in <italic>M.musculus</italic>. Analysis of <italic>M.musculus</italic> RNA-seq expression data from lung samples (<xref rid="btz357-B27" ref-type="bibr">Steed <italic>et al.</italic>, 2017</xref>). The estimator produces an optimal shrinkage <inline-formula id="IE229"><mml:math id="IM226"><mml:mo>λ</mml:mo><mml:mo>≈</mml:mo></mml:math></inline-formula>0.11. Three methods are compared at <inline-formula id="IE230"><mml:math id="IM227"><mml:mo>α</mml:mo><mml:mo>=</mml:mo><mml:mn>0.10</mml:mn></mml:math></inline-formula>; ENF, Shrunk MLE and MC (with 40 iterations). Panel (<bold>a</bold>) Venn diagram of significant partial correlations (i.e. edges in the GGM) recovered by each method with un-adjusted <italic>P</italic>-values. Panel (<bold>b</bold>) Venn diagram of significant partial correlations recovered by each method with BH-adjusted <italic>P</italic>-values</p>
          </caption>
          <graphic xlink:href="btz357f7"/>
        </fig>
        <p>ENF learns considerably more edges (∼200%) compared with MC or to our method. As the large number of genes is uninformative for GO enrichment analysis the edges were assessed in terms of true positive rate (TPR) and FPR by using as ground truth the protein-protein interaction STRING database (<ext-link ext-link-type="uri" xlink:href="https://string-db.org/">https://string-db.org/</ext-link>) (<xref rid="btz357-B30" ref-type="bibr">Szklarczyk <italic>et al.</italic>, 2017</xref>) (see <xref ref-type="supplementary-material" rid="sup1">Supplementary Table S5a</xref>). We observe that while the TPR for Shrunk MLE and ENF are similar, the FPR is lower for Shrunk MLE. Moreover, not a single additional connection found exclusively by ENF is reported in the STRING database. The most significant GOs found with Shrunk MLE, and ENF are reported in <xref ref-type="supplementary-material" rid="sup1">Supplementary Table S5b</xref> and c, and the GGM structure in <xref ref-type="supplementary-material" rid="sup1">Supplementary Figure S6</xref>.</p>
      </sec>
    </sec>
  </sec>
  <sec>
    <title>5 Discussion</title>
    <p>GGMs assess linear relationships between pairs of variables (partial correlations) from multivariate normal data. Some pitfalls inherent to the model are that non-linear associations are not necessarily captured, and that the partial correlation is not a robust statistics (i.e. it is susceptible to outliers), which becomes important when the sample size is small. The motivation for this work has been to improve the inference of GGMs from quantitative molecular profile data when sample size is small (e.g. 10–20), and there is large number of variables (100–10 000). Inferring a GGM structure demands the inverse of the covariance matrix, which is ill-conditioned in the high-dimensional scenario. Covariance estimators based on shrinkage are broadly employed in these cases, resulting in an invertible matrix. Previously, a parametric tests for GGMs was designed that calibrates the <italic>P</italic>-values in a approximated way, using the standard density and ENF. The inference becomes suboptimal because the shrinkage effects are not included in the test density. Moreover, ENF is known to be susceptible to errors as the selection of a non-contaminated region is difficult (i.e. it is restricted to sparse networks). An accurate ‘shrunk’ test is needed to complement the estimation with a proper control of the Type I error (i.e. FPR), and multiple testing corrections. In this way, experiments performed with different sample sizes and/or number of compounds (nodes) become comparable.</p>
    <p>Our empirical results support the idea that the standard density has larger tails than the new ‘shrunk’ density. As a consequence (i) under<inline-formula id="IE231"><mml:math id="IM228"><mml:mi mathvariant="normal"> </mml:mi><mml:msub><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mi mathvariant="normal"> </mml:mi></mml:math></inline-formula>the <italic>P</italic>-values deviate from <inline-formula id="IE232"><mml:math id="IM229"><mml:mi>U</mml:mi><mml:mo>[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>]</mml:mo></mml:math></inline-formula>, and (ii) the FPs cannot be controlled efficiently by multiple testing procedures. When it comes to its biological interpretation the excessive number of FPs might dilute the GO enrichment related to the treatment stimulus (see <italic>E.coli</italic> example) thus obscuring the targeted effect of the analysis.</p>
    <p>To resolve this situation, we have derived the null distribution of the ‘shrunk’ (i.e. regularized) partial correlation. In this sense, our work represents an improvement over the parametric tests described in <xref rid="btz357-B24" ref-type="bibr">Schäfer and Strimmer (2005a</xref>,<xref rid="btz357-B29" ref-type="bibr">b</xref>). To our knowledge, this is the only approach with a theoretical test of significance that includes the shrinkage effect. This was achieved by recalling some the geometrical ideas about the partial correlation coefficient from the seminal work of <xref rid="btz357-B11" ref-type="bibr">Fisher (1924)</xref>. The improved approach presented here (i.e. Shrunk MLE) is independent of the aforementioned drawbacks because it naturally includes the shrinkage, and the degrees of freedom are estimated independently of the real mixture. We have shown how the test with Shrunk MLE (i) allows the inference for any shrinkage value with accurate multiple testing corrections (e.g. control of the FDR), (ii) it is as accurate as MC <italic>P</italic>-value estimation (a non-parametric approach considered to be the gold standard) while computationally faster and (iii) it is not limited to sparse networks. The assessment was carried out in terms of the number of learnt edges, and the PPV (with and without adjustment). Particularly, for <inline-formula id="IE233"><mml:math id="IM230"><mml:mi>p</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>40</mml:mn></mml:math></inline-formula> and <inline-formula id="IE234"><mml:math id="IM231"><mml:mi>n</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>10</mml:mn></mml:math></inline-formula> the FPR is as accurate as MC (see <xref ref-type="fig" rid="btz357-F4">Fig. 4</xref>). However, for dataset with too small sample size (e.g. <inline-formula id="IE235"><mml:math id="IM232"><mml:mi>n</mml:mi></mml:math></inline-formula> = 5 and <inline-formula id="IE236"><mml:math id="IM233"><mml:mi>p</mml:mi></mml:math></inline-formula> = 20 in <xref ref-type="fig" rid="btz357-F4">Fig. 4</xref>) the estimation should be performed with MC.</p>
    <p>Ideally, an analysis should include both the coefficient and its <italic>P</italic>-value. However, without considering <inline-formula id="IE237"><mml:math id="IM234"><mml:mo>λ</mml:mo></mml:math></inline-formula>, it is not trivial to conclude by the ‘shrunk’ coefficient whether an association is strong or not. Further studies are required to address this issue.</p>
  </sec>
  <sec>
    <title>Funding</title>
    <p>This work was supported by the Data Science and System Complexity Centre (DSSC) of the University of Groningen. M.G. is supported by the European Cooperation in Science and Technology (COST) [COST Action CA15109 European Cooperation for Statistics of Network Data Science (COSTNET)].</p>
    <p><italic>Conflict of Interest</italic>: none declared.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material content-type="local-data" id="sup1">
      <label>btz357_Supplementary_Data</label>
      <media xlink:href="btz357_supplementary_data.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="btz357-B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Ashburner</surname><given-names>M.</given-names></name></person-group><etal>et al</etal> (<year>2000</year>) 
<article-title>Gene ontology: tool for the unification of biology</article-title>. <source>Nat. Genet</source>., <volume>25</volume>, <fpage>25.</fpage><pub-id pub-id-type="pmid">10802651</pub-id></mixed-citation>
    </ref>
    <ref id="btz357-B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Beerenwinkel</surname><given-names>N.</given-names></name></person-group><etal>et al</etal> (<year>2007</year>) 
<article-title>Genetic progression and the waiting time to cancer</article-title>. <source>PLoS Comput. Biol</source>., <volume>3</volume>, <fpage>e225.</fpage><pub-id pub-id-type="pmid">17997597</pub-id></mixed-citation>
    </ref>
    <ref id="btz357-B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Benedetti</surname><given-names>E.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) 
<article-title>Network inference from glycoproteomics data reveals new reactions in the IgG glycosylation pathway</article-title>. <source>Nat. Commun</source>., <volume>8</volume>, <fpage>1483</fpage>.<pub-id pub-id-type="pmid">29133956</pub-id></mixed-citation>
    </ref>
    <ref id="btz357-B114">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Benjamini</surname><given-names>Y.</given-names></name>, <name name-style="western"><surname>Yosef</surname><given-names>H.</given-names></name></person-group> (<year>1995</year>) 
<article-title>Controlling the false discovery rate: a practical and powerful approach to multiple testing</article-title>. <source>J R Stat Soc Series B Stat Methodol</source>., <volume>57</volume>, <fpage>289</fpage>–<lpage>300</lpage>.</mixed-citation>
    </ref>
    <ref id="btz357-B4">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Butte</surname><given-names>A.J.</given-names></name>, <name name-style="western"><surname>Kohane</surname><given-names>I.S.</given-names></name></person-group> (<year>2003</year>) <chapter-title>Relevance networks: a first step toward finding genetic regulatory networks within microarray data</chapter-title> In: <person-group person-group-type="editor"><name name-style="western"><surname>Parmigiani</surname><given-names>G.</given-names></name></person-group><etal>et al</etal> (ed.) <source>The Analysis of Gene Expression Data</source>. 
<publisher-name>Springer</publisher-name>, 
<publisher-loc>New York, NY</publisher-loc>, pp. <fpage>428</fpage>–<lpage>446</lpage>.</mixed-citation>
    </ref>
    <ref id="btz357-B5">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Edwards</surname><given-names>D.</given-names></name></person-group> (<year>2000</year>) <source>Introduction to Graphical Modelling</source>, <edition>2</edition>nd edn. 
<publisher-name>Springer Science &amp; Business Media, Springer-Verlag</publisher-name>
<publisher-loc>New York</publisher-loc>.</mixed-citation>
    </ref>
    <ref id="btz357-B6">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Efron</surname><given-names>B.</given-names></name></person-group> (<year>2012</year>) <source>Large-Scale Inference: Empirical Bayes Methods for Estimation, Testing, and Prediction</source>. 
<publisher-name>Cambridge University Press</publisher-name>, New York.</mixed-citation>
    </ref>
    <ref id="btz357-B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Efron</surname><given-names>B.</given-names></name></person-group> (<year>2004</year>) 
<article-title>Large-scale simultaneous hypothesis testing: the choice of a null hypothesis</article-title>. <source>J. Am. Stat. Assoc</source>., <volume>99</volume>, <fpage>96</fpage>–<lpage>104</lpage>.</mixed-citation>
    </ref>
    <ref id="btz357-B8">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Efron</surname><given-names>B.</given-names></name></person-group> (<year>2005</year>) Local false discovery rates. Stanford University.</mixed-citation>
    </ref>
    <ref id="btz357-B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Faust</surname><given-names>K.</given-names></name>, <name name-style="western"><surname>Raes</surname><given-names>J.</given-names></name></person-group> (<year>2012</year>) 
<article-title>Microbial interactions: from networks to models</article-title>. <source>Nat. Rev. Microbiol</source>., <volume>10</volume>, <fpage>538.</fpage><pub-id pub-id-type="pmid">22796884</pub-id></mixed-citation>
    </ref>
    <ref id="btz357-B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Fisher</surname><given-names>R.A.</given-names></name></person-group> (<year>1915</year>) 
<article-title>Frequency distribution of the values of the correlation coefficient in samples from an indefinitely large population</article-title>. <source>Biometrika</source>, <volume>10</volume>, <fpage>507</fpage>–<lpage>521</lpage>.</mixed-citation>
    </ref>
    <ref id="btz357-B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Fisher</surname><given-names>R.A.</given-names></name></person-group> (<year>1924</year>) 
<article-title>The distribution of the partial correlation coefficient</article-title>. <source>Metron</source>, <volume>3</volume>, <fpage>329</fpage>–<lpage>332</lpage>.</mixed-citation>
    </ref>
    <ref id="btz357-B12">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Friedman</surname><given-names>J.</given-names></name></person-group><etal>et al</etal> (<year>2008</year>) 
<article-title>Sparse inverse covariance estimation with the graphical lasso</article-title>. <source>Biostatistics</source>, <volume>9</volume>, <fpage>432</fpage>–<lpage>441</lpage>.<pub-id pub-id-type="pmid">18079126</pub-id></mixed-citation>
    </ref>
    <ref id="btz357-B13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Friedman</surname><given-names>N.</given-names></name></person-group><etal>et al</etal> (<year>2000</year>) 
<article-title>Using Bayesian networks to analyze expression data</article-title>. <source>J. Comput. Biol</source>., <volume>7</volume>, <fpage>601</fpage>–<lpage>620</lpage>.<pub-id pub-id-type="pmid">11108481</pub-id></mixed-citation>
    </ref>
    <ref id="btz357-B14">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Hotelling</surname><given-names>H.</given-names></name></person-group> (<year>1953</year>) 
<article-title>New light on the correlation coefficient and its transforms</article-title>. <source>J. R. Stat. Soc. Ser. B</source>, <volume>15</volume>, <fpage>193</fpage>–<lpage>232</lpage>.</mixed-citation>
    </ref>
    <ref id="btz357-B15">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Keller</surname><given-names>M.P.</given-names></name></person-group><etal>et al</etal> (<year>2008</year>) 
<article-title>A gene expression network model of type 2 diabetes links cell cycle regulation in islets with diabetes susceptibility</article-title>. <source>Genome Res</source>., <volume>18</volume>, <fpage>706</fpage>–<lpage>716</lpage>.<pub-id pub-id-type="pmid">18347327</pub-id></mixed-citation>
    </ref>
    <ref id="btz357-B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Ledoit</surname><given-names>O.</given-names></name>, <name name-style="western"><surname>Wolf</surname><given-names>M.</given-names></name></person-group> (<year>2004</year>) 
<article-title>A well-conditioned estimator for large-dimensional covariance matrices</article-title>. <source>J. Multivar. Anal</source>., <volume>88</volume>, <fpage>365</fpage>–<lpage>411</lpage>.</mixed-citation>
    </ref>
    <ref id="btz357-B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Ledoit</surname><given-names>O.</given-names></name>, <name name-style="western"><surname>Wolf</surname><given-names>M.</given-names></name></person-group> (<year>2003</year>) 
<article-title>Improved estimation of the covariance matrix of stock returns with an application to portfolio selection</article-title>. <source>J. Empir. Financ</source>., <volume>10</volume>, <fpage>603</fpage>–<lpage>621</lpage>.</mixed-citation>
    </ref>
    <ref id="btz357-B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Lemm</surname><given-names>S.</given-names></name></person-group><etal>et al</etal> (<year>2011</year>) 
<article-title>Introduction to machine learning for brain imaging</article-title>. <source>Neuroimage</source>, <volume>56</volume>, <fpage>387</fpage>–<lpage>399</lpage>.<pub-id pub-id-type="pmid">21172442</pub-id></mixed-citation>
    </ref>
    <ref id="btz357-B19">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Ma</surname><given-names>S.</given-names></name></person-group><etal>et al</etal> (<year>2007</year>) 
<article-title>An <italic>Arabidopsis</italic> gene network based on the graphical Gaussian model</article-title>. <source>Genome Res</source>., <volume>17</volume>, <fpage>1614</fpage>–<lpage>1625</lpage>.<pub-id pub-id-type="pmid">17921353</pub-id></mixed-citation>
    </ref>
    <ref id="btz357-B20">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Markowetz</surname><given-names>F.</given-names></name>, <name name-style="western"><surname>Spang</surname><given-names>R.</given-names></name></person-group> (<year>2007</year>) 
<article-title>Inferring cellular networks - a review</article-title>. <source>BMC Bioinformatics</source>, <volume>8</volume>, <fpage>S5</fpage>.</mixed-citation>
    </ref>
    <ref id="btz357-B21">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Mi</surname><given-names>H.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) 
<article-title>PANTHER version 11: expanded annotation data from Gene Ontology and Reactome pathways, and data analysis tool enhancements</article-title>. <source>Nucleic Acids Res</source>., <volume>45</volume>, <fpage>D183</fpage>–<lpage>D189</lpage>.<pub-id pub-id-type="pmid">27899595</pub-id></mixed-citation>
    </ref>
    <ref id="btz357-B22">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Omranian</surname><given-names>N.</given-names></name></person-group><etal>et al</etal> (<year>2016</year>) 
<article-title>Gene regulatory network inference using fused LASSO on multiple data sets</article-title>. <source>Sci. Rep</source>., <volume>6</volume>, <fpage>20533.</fpage><pub-id pub-id-type="pmid">26864687</pub-id></mixed-citation>
    </ref>
    <ref id="btz357-B23">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Saha</surname><given-names>A.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) 
<article-title>Co-expression networks reveal the tissue-specific regulation of transcription and splicing</article-title>. <source>Genome Res</source>., <volume>11</volume>, <fpage>1843</fpage>–<lpage>1858</lpage>.</mixed-citation>
    </ref>
    <ref id="btz357-B24">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Schäfer</surname><given-names>J.</given-names></name>, <name name-style="western"><surname>Strimmer</surname><given-names>K.</given-names></name></person-group> (<year>2005a</year>) 
<article-title>A shrinkage approach to large-scale covariance matrix estimation and implications for functional genomics</article-title>. <source>Stat. Appl. Genet. Mol. Biol</source>., <volume>4</volume>, <fpage>1175</fpage>–<lpage>1189</lpage>.</mixed-citation>
    </ref>
    <ref id="btz357-B25">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Schäfer</surname><given-names>J.</given-names></name>, <name name-style="western"><surname>Strimmer</surname><given-names>K.</given-names></name></person-group> (<year>2005b</year>) 
<article-title>An empirical Bayes approach to inferring large-scale gene association networks</article-title>. <source>Bioinformatics</source>, <volume>21</volume>, <fpage>754</fpage>–<lpage>764</lpage>.<pub-id pub-id-type="pmid">15479708</pub-id></mixed-citation>
    </ref>
    <ref id="btz357-B26">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Schmidt-Heck</surname><given-names>W.</given-names></name></person-group><etal>et al</etal> (<year>2004</year>) 
<article-title>Reverse engineering of the stress response during expression of a recombinant protein</article-title>. In: <source>Proceedings of the EUNITE Symposium</source>, <italic>10–12 June 2004, Aachen, Germany</italic>
<fpage>pp. 407</fpage>–<lpage>412</lpage>. Verlag Mainz.</mixed-citation>
    </ref>
    <ref id="btz357-B27">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Steed</surname><given-names>A.L.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) 
<article-title>The microbial metabolite desaminotyrosine protects from influenza through type I interferon</article-title>. <source>Science</source>, <volume>357</volume>, <fpage>498</fpage>–<lpage>502</lpage>.<pub-id pub-id-type="pmid">28774928</pub-id></mixed-citation>
    </ref>
    <ref id="btz357-B28">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Strimmer</surname><given-names>K.</given-names></name></person-group> (<year>2008a</year>) 
<article-title>A unified approach to false discovery rate estimation</article-title>. <source>BMC Bioinformatics</source>, <volume>9</volume>, <fpage>303.</fpage><pub-id pub-id-type="pmid">18613966</pub-id></mixed-citation>
    </ref>
    <ref id="btz357-B29">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Strimmer</surname><given-names>K.</given-names></name></person-group> (<year>2008b</year>) 
<article-title>fdrtool: a versatile R package for estimating local and tail area-based false discovery rates</article-title>. <source>Bioinformatics</source>, <volume>24</volume>, <fpage>1461</fpage>–<lpage>1462</lpage>.<pub-id pub-id-type="pmid">18441000</pub-id></mixed-citation>
    </ref>
    <ref id="btz357-B30">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Szklarczyk</surname><given-names>D.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) 
<article-title>The STRING database in 2017: quality-controlled protein-protein association networks, made broadly accessible</article-title>. <source>Nucleic Acids Res.</source>, <volume>45</volume>, <fpage>D362</fpage>–<lpage>D368</lpage>.<pub-id pub-id-type="pmid">27924014</pub-id></mixed-citation>
    </ref>
    <ref id="btz357-B31">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Werhli</surname><given-names>A.V.</given-names></name></person-group><etal>et al</etal> (<year>2006</year>) 
<article-title>Comparative evaluation of reverse engineering gene regulatory networks with relevance networks, graphical Gaussian models and Bayesian networks</article-title>. <source>Bioinformatics</source>, <volume>22</volume>, <fpage>2523</fpage>–<lpage>2531</lpage>.<pub-id pub-id-type="pmid">16844710</pub-id></mixed-citation>
    </ref>
    <ref id="btz357-B32">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Whittaker</surname><given-names>J.</given-names></name></person-group> (<year>1990</year>) <source>Graphical Models in Applied Multivariate Statistics</source>. 
<publisher-name>Wiley Publishing</publisher-name>, 
<publisher-loc>NY</publisher-loc>.</mixed-citation>
    </ref>
    <ref id="btz357-B33">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Wickens</surname><given-names>T.D.</given-names></name></person-group> (<year>2014</year>) <source>The Geometry of Multivariate Statistics</source>. 
<publisher-name>Psychology Press</publisher-name>, New York.</mixed-citation>
    </ref>
  </ref-list>
</back>
