<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">BMC Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">BMC Bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>BMC Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1471-2105</issn>
    <publisher>
      <publisher-name>BioMed Central</publisher-name>
      <publisher-loc>London</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">7672824</article-id>
    <article-id pub-id-type="publisher-id">3556</article-id>
    <article-id pub-id-type="doi">10.1186/s12859-020-03556-9</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Research</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>GODoc: high-throughput protein function prediction using novel <italic>k</italic>-nearest-neighbor and voting algorithms</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Liu</surname>
          <given-names>Yi-Wei</given-names>
        </name>
        <address>
          <email>blueswen.tw@gmail.com</email>
        </address>
        <xref ref-type="aff" rid="Aff1"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Hsu</surname>
          <given-names>Tz-Wei</given-names>
        </name>
        <address>
          <email>eric0330eric@gmail.com</email>
        </address>
        <xref ref-type="aff" rid="Aff1"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Chang</surname>
          <given-names>Che-Yu</given-names>
        </name>
        <address>
          <email>a0952072007@gmail.com</email>
        </address>
        <xref ref-type="aff" rid="Aff1"/>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Liao</surname>
          <given-names>Wen-Hung</given-names>
        </name>
        <address>
          <email>whliao@gmail.com</email>
        </address>
        <xref ref-type="aff" rid="Aff1"/>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-6711-1739</contrib-id>
        <name>
          <surname>Chang</surname>
          <given-names>Jia-Ming</given-names>
        </name>
        <address>
          <email>chang.jiaming@gmail.com</email>
        </address>
        <xref ref-type="aff" rid="Aff1"/>
      </contrib>
      <aff id="Aff1"><institution-wrap><institution-id institution-id-type="GRID">grid.412042.1</institution-id><institution-id institution-id-type="ISNI">0000 0001 2106 6277</institution-id><institution>Department of Computer Science, </institution><institution>National Chengchi University, </institution></institution-wrap>11605 Taipei, Taiwan </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>18</day>
      <month>11</month>
      <year>2020</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>18</day>
      <month>11</month>
      <year>2020</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2020</year>
    </pub-date>
    <volume>21</volume>
    <issue>Suppl 6</issue>
    <issue-sponsor>Publication of this supplement has not been supported by sponsorship. Information about the source of funding for publication charges can be found in the individual articles. The articles have undergone the journal's standard peer review process for supplements. The Supplement Editors declare that they have no competing interests.</issue-sponsor>
    <elocation-id>276</elocation-id>
    <history>
      <date date-type="received">
        <day>21</day>
        <month>5</month>
        <year>2020</year>
      </date>
      <date date-type="accepted">
        <day>25</day>
        <month>5</month>
        <year>2020</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2020</copyright-statement>
      <license license-type="OpenAccess">
        <license-p><bold>Open Access</bold>This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>. The Creative Commons Public Domain Dedication waiver (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/publicdomain/zero/1.0/">http://creativecommons.org/publicdomain/zero/1.0/</ext-link>) applies to the data made available in this article, unless otherwise stated in a credit line to the data.</license-p>
      </license>
    </permissions>
    <abstract id="Abs1">
      <sec>
        <title>Background</title>
        <p id="Par1">Biological data has grown explosively with the advance of next-generation sequencing. However, annotating protein function with wet lab experiments is time-consuming. Fortunately, computational function prediction can help wet labs formulate biological hypotheses and prioritize experiments. Gene Ontology (GO) is a framework for unifying the representation of protein function in a hierarchical tree composed of GO terms.</p>
      </sec>
      <sec>
        <title>Results</title>
        <p id="Par2">We propose GODoc, a general protein GO prediction framework based on sequence information which combines feature engineering, feature reduction, and a novel ​<italic>k</italic>​-nearest-neighbor algorithm to resolve the multiple GO prediction problem. Comprehensive evaluation on CAFA2 shows that GODoc performs better than two baseline models. In the CAFA3 competition (68 teams), GODoc ranks 10th in Cellular Component Ontology. Regarding the species-specific task, the proposed method ranks 10th and 8th in the eukaryotic Cellular Component Ontology and the prokaryotic Molecular Function Ontology, respectively. In the term-centric task, GODoc performs third and is tied for first for the biofilm formation of <italic>Pseudomonas aeruginosa</italic> and the long-term memory of <italic>Drosophila melanogaster</italic>, respectively.</p>
      </sec>
      <sec>
        <title>Conclusions</title>
        <p id="Par3">We have developed a novel and effective strategy to incorporate a training procedure into the <italic>k</italic>-nearest neighbor algorithm (instance-based learning) which is capable of solving the Gene Ontology multiple-label prediction problem, which is especially notable given the thousands of Gene Ontology terms.</p>
      </sec>
    </abstract>
    <kwd-group xml:lang="en">
      <title>Keywords</title>
      <kwd>Protein function prediction</kwd>
      <kwd>Machine learning</kwd>
      <kwd>Gene ontology</kwd>
      <kwd>Homology extension</kwd>
      <kwd>Data science</kwd>
    </kwd-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100004663</institution-id>
            <institution>Ministry of Science and Technology, Taiwan</institution>
          </institution-wrap>
        </funding-source>
        <award-id>106-2221-E-004-011-MY2</award-id>
        <principal-award-recipient>
          <name>
            <surname>Chang</surname>
            <given-names>Jia-Ming</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
    </funding-group>
    <conference xlink:href="http://alan.cs.gsu.edu/isbra19/">
      <conf-name>15th International Symposium on Bioinformatics Research and Applications (ISBRA'19)</conf-name>
      <conf-acronym>ISBRA'19</conf-acronym>
      <conf-loc>Barcelona, Spain</conf-loc>
      <conf-date>3-6 June 2019</conf-date>
    </conference>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>© The Author(s) 2020</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="Sec1">
    <title>Background</title>
    <p id="Par9">Proteins are important macromolecules in living organisms because they carry essential functions to ensure the survival of creatures. If we know what function a protein carries, we can understand life at the molecular level and the molecular mechanisms of disease. Gene Ontology (GO) is the main framework for unifying the representation of protein function, initiated by the GO Consortium in 1998. GO classifies functions into three domains: Biological Process Ontology (BPO), Cellular Component Ontology (CCO), and Molecular Function Ontology (MFO). BPO describes the biological process in which the gene product participates, CCO specifies the location of the gene product, and MFO indicates what the gene product can do or its ability. GO terms are linked to each other with a hierarchical directed tree structure. The relationship and terms can be graphed as directed edges and nodes, respectively (an example can be found on page 26, [<xref ref-type="bibr" rid="CR1">1</xref>]). GO is annotated to a protein by either biological experiments or computational prediction. Therefore, each GO annotation is associated with an evidence code to indicate the method employed to generate the annotation [<xref ref-type="bibr" rid="CR2">2</xref>].</p>
    <p id="Par10">Compared with the growth of protein sequence data, the speed of protein function annotation from wet lab experiments is slow. Fortunately, computational function prediction can help wet labs formulate biological hypotheses and prioritize experiments. In this research, we seek to use information about a protein sequence to predict its GOs, a multiple-label classification problem. This task is different from traditional multiple-label classification, as GO labels are hierarchical. There exist both computational and biological challenges. Computational speaking, the number of annotated proteins is relatively small compared with the number of GO terms. There are about 40,000 unique GO terms, but only 66,841 experimentally annotated sequences in Swiss-Prot, as of September 2016. Biologically, annotations might not be perfectly reproduced due to budgetary or ethical reasons. In addition, some experiments are performed in vitro and may not reflect a protein’s activity in vivo.</p>
    <p id="Par11">Predicting the function of a target protein from its homologs is the most common approach. Homologs between two proteins may indicate a common ancestry; thus they may have the same function. As a result, the available GOs of the homologs are prediction candidates for a target protein. The Basic Local Alignment Search Tool (BLAST) and Position-Specific Iterated BLAST (PSI-BLAST) [<xref ref-type="bibr" rid="CR3">3</xref>] are two standard tools for searching homologous sequences. PSLDoc uses the information from PSI-BLAST, the position-specific scoring matrix (PSSM), to build a TFPSSM (Term Frequency based on PSSM) feature to find homologous proteins [<xref ref-type="bibr" rid="CR4">4</xref>], and PSLDoc is used to predict protein subcellular localization, which can be considered as a subset of CCO. In addition to sequence-similarity-based approach, there exist some databases or computational methods to characterize proteins to individual domains or motifs, which are useful for function prediction. For example, CATH-Gene3D clusters proteins into functional families (FunFam), which implies similar sequences, structures, and GOs [<xref ref-type="bibr" rid="CR5">5</xref>]. The CATH FunFHMMer web server identifies FunFams for an unknown target such that FunFam associated GOs are good prediction candidates [<xref ref-type="bibr" rid="CR6">6</xref>].</p>
    <p id="Par12">The Critical Assessment of Functional Annotation (CAFA) aims to evaluate prediction methods in an unbiased way. It was established by the Function Special Interest Group (Function-SIG). CAFA1, CAFA2, CAFA3 and CAFA <italic>π</italic> (3.14), the first four challenges, were organized and carried out during 2010–2011 [<xref ref-type="bibr" rid="CR7">7</xref>], 2013–2014 [<xref ref-type="bibr" rid="CR8">8</xref>], 2016–2017 [<xref ref-type="bibr" rid="CR9">9</xref>], and 2017–2018 [<xref ref-type="bibr" rid="CR9">9</xref>], respectively. The competitions are conducted in a time-delayed format with a <italic>prediction</italic> phase, an <italic>annotation growth</italic> phase, and an <italic>evaluation</italic> phase (Fig. 12, [<xref ref-type="bibr" rid="CR9">9</xref>]). At the beginning, the organization provides a large number of protein sequences with unknown function for the participants to predict (<italic>t</italic><sub>− 1</sub> in Fig. 12, [<xref ref-type="bibr" rid="CR9">9</xref>]). During the <italic>prediction</italic> phase, the predictor submits their predicted annotations of these target proteins. When the <italic>prediction</italic> phase ends (<italic>t</italic><sub>0</sub> in Fig. 12, [<xref ref-type="bibr" rid="CR9">9</xref>]), the challenge moves on to the <italic>annotation growth</italic> phase (<italic>t</italic><sub>1</sub> in Fig. 12, [<xref ref-type="bibr" rid="CR9">9</xref>]), in which some protein function of target proteins might be annotated through experiment. Entering the <italic>evaluation</italic> phase, those proteins with annotations are selected as a benchmark to evaluate each method’s prediction performance.</p>
    <p id="Par13">We propose GODoc, an effective GO prediction framework [<xref ref-type="bibr" rid="CR10">10</xref>] extended from PSLDoc [<xref ref-type="bibr" rid="CR4">4</xref>] and PSLDoc2 [<xref ref-type="bibr" rid="CR11">11</xref>], which has demonstrated excellent performance in predicting protein subcellular localization. We design three novel voting strategies based on the <italic>k-nearest-neighbor</italic> algorithm by incorporating a training procedure to solve the multiple-label prediction problem, as the number of GO terms is much larger than the number of localization sites (Section: Data sets). GODoc is evaluated on the CAFA2 and CAFA3 data sets and yields significantly better results than the two baseline models. In the CAFA3 competition, GODoc ranks 3rd and 5th among 67 and 59 methods in full and partial modes, respectively. According to the minimum normalized semantic distance metric in BPO, and for CCO, it achieves a score of 0.592, which ranks among the top 10% in 67 methods based on Fmax.</p>
  </sec>
  <sec id="Sec2">
    <title>Results</title>
    <sec id="Sec3">
      <title>Experiment 1: PCA</title>
      <p id="Par14">The Fmax of two baseline models and TFPSSM 1NN with different PCA parameters are summarized in Fig. <xref rid="Fig1" ref-type="fig">1</xref>. TFPSSM 1NN demonstrates better performance than the two baseline models on both the CAFA2-Swiss (Fig. <xref rid="Fig1" ref-type="fig">1</xref>a) and CAFA3-Swiss (Fig. <xref rid="Fig1" ref-type="fig">1</xref>b) datasets. TFPSSM extracts homology information from BLAST search, which has been shown to be efficient against a non-redundant database without losing prediction performance [<xref ref-type="bibr" rid="CR11">11</xref>]. This has also been confirmed by our experiment because the dashed (original) and solid (non-redundant) lines of the same color are almost identical (compatible Fmax), which shows that the TFPSSM 1NN algorithm effectively picks out neighbors by keeping one representative of redundant sequences (non-redundant dataset). During feature reduction, whitening pre-processing (green versus yellow/orange) yields the best explained ratios of around 96%. These parameter settings are used in further experiments.
<fig id="Fig1"><label>Fig. 1</label><caption><p>Fmax of TFPSSM 1NN on CAFA2-Swiss (<bold>a</bold>) and CAFA3-Swiss (<bold>b</bold>) with different PCA parameters, where the explained ratio ranges from 90 to 98.5% with a step size of 0.5%</p></caption><graphic xlink:href="12859_2020_3556_Fig1_HTML" id="MO1"/></fig></p>
    </sec>
    <sec id="Sec4">
      <title>Experiment 2: <italic>k</italic>-nearest-neighbor algorithm and weighted voting</title>
      <p id="Par15">In the Fixed-KNN experiment, we set <italic>k</italic> from 1 to 10 and voted with Sum and Max propagation functions using three different weight assignment rules (Fig. <xref rid="Fig2" ref-type="fig">2</xref>). We observe that better performance can be obtained by setting <italic>k</italic> larger than 1 in BPO and CCO. However, the benefit decreases for <italic>k</italic> larger than 3 in MFO. Among the three weight schemes, <italic>Inverse</italic> is more reliable than the other two methods. As a result, we employ the <italic>Inverse</italic> approach in further experiments. The results also reveal that Sum propagation is better than Max.
<fig id="Fig2"><label>Fig. 2</label><caption><p>Fmax of Fixed-KNN on CAFA2-Swiss (<bold>a</bold>) and CAFA3-Swiss (<bold>b</bold>) with different <italic>k</italic>, voting schemes, and propagations, in which Sum-* and Max-* denote the Sum and Max propagation function, respectively</p></caption><graphic xlink:href="12859_2020_3556_Fig2_HTML" id="MO2"/></fig></p>
      <p id="Par16">Figure <xref rid="Fig3" ref-type="fig">3</xref> presents Fmax of Dynamic-KNN under different distance thresholds and propagation functions. Using the 2nd quartile (Q2) as the threshold not only yields the best performance on the three ontologies, but also contains half of the test data (Q2, <italic>Inverse</italic> in Table <xref rid="Tab1" ref-type="table">1</xref>). In this experiment, we also find the Sum-propagated function to be an effective way to address our problem. Given the previous two experiments (Figs. <xref rid="Fig2" ref-type="fig">2</xref> and <xref rid="Fig3" ref-type="fig">3</xref>), we conclude that <italic>Sum</italic> propagation is better than <italic>Max</italic>; hence in the following experiments, to reduce training complexity, we consider only <italic>Sum</italic> propagation. The comparison between the <italic>Inverse</italic> and <italic>FunOverlap</italic> voting weight schemes is shown in Fig. <xref rid="Fig4" ref-type="fig">4</xref>. Although FunOverlap outperforms Inverse, it predicts fewer proteins (# of preds and % in Table <xref rid="Tab1" ref-type="table">1</xref>).
<fig id="Fig3"><label>Fig. 3</label><caption><p>Fmax of Dynamic-KNN on CAFA2-Swiss (<bold>a</bold>) and CAFA3-Swiss (<bold>b</bold>) with different dynamic threshold and propagation functions under partial evaluation mode</p></caption><graphic xlink:href="12859_2020_3556_Fig3_HTML" id="MO3"/></fig><table-wrap id="Tab1"><label>Table 1</label><caption><p>Dynamic-KNN coverage in partial model with respect to different distance thresholds and voting weight schemes in the cross-validation validation data set. <italic># of seqs</italic>: total number of proteins in the set. <italic>Distance</italic>: distance threshold used in Dynamic-KNN. <italic># of preds</italic>: number of predicted proteins and its corresponding proportion in %</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="2">Type</th><th rowspan="2">Dataset</th><th rowspan="2"># of seqs</th><th rowspan="2">Distance</th><th colspan="2">    <italic>Inverse</italic></th><th colspan="2"><italic>   FunOverlap</italic></th></tr><tr><th># of preds</th><th> %</th><th># of preds</th><th> %</th></tr></thead><tbody><tr><td rowspan="6">BPO</td><td rowspan="3">CAFA2-Swiss</td><td rowspan="3">8146</td><td>Q1</td><td> 2046</td><td>25.12</td><td> 1882</td><td>23.10</td></tr><tr><td>Q2</td><td> 4095</td><td>50.27</td><td> 3654</td><td>44.86</td></tr><tr><td>Q3</td><td> 6112</td><td>75.03</td><td> 5167</td><td>64.43</td></tr><tr><td rowspan="3">CAFA3-Swiss</td><td rowspan="3">10,163</td><td>Q1</td><td> 2562</td><td>25.21</td><td> 2309</td><td>22.72</td></tr><tr><td>Q2</td><td> 5095</td><td>50.13</td><td> 4470</td><td>43.98</td></tr><tr><td>Q3</td><td> 7601</td><td>74.79</td><td> 6333</td><td>62.32</td></tr><tr><td rowspan="6">CCO</td><td rowspan="3">CAFA2-Swiss</td><td rowspan="3">8114</td><td>Q1</td><td> 2039</td><td>25.13</td><td> 1855</td><td>22.86</td></tr><tr><td>Q2</td><td> 4034</td><td>49.72</td><td> 3540</td><td>43.63</td></tr><tr><td>Q3</td><td> 6042</td><td>74.46</td><td> 4898</td><td>60.36</td></tr><tr><td rowspan="3">CAFA3-Swiss</td><td rowspan="3">9866</td><td>Q1</td><td> 2548</td><td>24.91</td><td> 2204</td><td>22.34</td></tr><tr><td>Q2</td><td> 4922</td><td>49.89</td><td> 4261</td><td>43.19</td></tr><tr><td>Q3</td><td> 7357</td><td>74.57</td><td> 5912</td><td>59.92</td></tr><tr><td rowspan="6">MFO</td><td rowspan="3">CAFA2-Swiss</td><td rowspan="3">5211</td><td>Q1</td><td> 1291</td><td>24.77</td><td> 1204</td><td>23.11</td></tr><tr><td>Q2</td><td> 2593</td><td>49.76</td><td> 2366</td><td>45.40</td></tr><tr><td>Q3</td><td> 3902</td><td>74.88</td><td> 3405</td><td>65.35</td></tr><tr><td rowspan="3">CAFA3-Swiss</td><td rowspan="3">7017</td><td>Q1</td><td> 1756</td><td>25.02</td><td> 1630</td><td>23.23</td></tr><tr><td>Q2</td><td> 3518</td><td>50.14</td><td> 3185</td><td>45.39</td></tr><tr><td>Q3</td><td> 5278</td><td>75.22</td><td> 4573</td><td>65.17</td></tr></tbody></table></table-wrap><fig id="Fig4"><label>Fig. 4</label><caption><p>Fmax of Dynamic-KNN on CAFA2-Swiss (<bold>a</bold>) and CAFA3-Swiss (<bold>b</bold>) with different dynamic threshold and voting weight schemes under partial evaluation mode</p></caption><graphic xlink:href="12859_2020_3556_Fig4_HTML" id="MO4"/></fig></p>
      <p id="Par17">In the Hybrid-KNN experiment, we seek to study the effects of combining Fixed-KNN and Dynamic-KNN. We examine the combination of fixed <italic>k</italic> from 1 to 10 and the 2nd quartile as a dynamic threshold with <italic>Inverse</italic> voting weight and <italic>Sum</italic> propagation (Fig. <xref rid="Fig5" ref-type="fig">5</xref>). We observe no clear benefit in Fmax from the combination of Fixed-KNN and Dynamic-KNN.
<fig id="Fig5"><label>Fig. 5</label><caption><p>Fmax of Hybrid-KNN and Fixed-kNN on CAFA2-Swiss (<bold>a</bold>) and CAFA3-Swiss (<bold>b</bold>)</p></caption><graphic xlink:href="12859_2020_3556_Fig5_HTML" id="MO5"/></fig></p>
    </sec>
    <sec id="Sec5">
      <title>Summary of experimental results</title>
      <p id="Par18">As determined in the previous experiments, the optimal parameter combination used for CAFA2-Swiss is listed in Table <xref rid="Tab2" ref-type="table">2</xref>. All TFPSSM features are extracted using PCA with <italic>whitening</italic> preprocessing, SVD from the <italic>non-redundant</italic> training dataset, and <italic>Sum</italic> propagation.
<table-wrap id="Tab2"><label>Table 2</label><caption><p>The best parameter combination trained from CAFA2-Swiss is utilized in the CAFA2-Benchmark</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Type</th><th>PCA dims</th><th>Exp. ratio (%)</th><th>Method</th><th>Voting weight</th><th><italic>k</italic> or <italic>dynamic</italic></th></tr></thead><tbody><tr><td rowspan="4">BPO</td><td char="." align="char" rowspan="4">107</td><td char="." align="char" rowspan="4">96.0</td><td>1NN</td><td>–</td><td>1</td></tr><tr><td>Fixed-KNN</td><td>inverse</td><td>7</td></tr><tr><td>Dynamic-KNN</td><td>inverse</td><td>Q2</td></tr><tr><td>Hybrid-KNN</td><td>inverse</td><td>4 + Q2</td></tr><tr><td rowspan="4">CCO</td><td char="." align="char" rowspan="4">51</td><td char="." align="char" rowspan="4">95.0</td><td>1NN</td><td>–</td><td>1</td></tr><tr><td>Fixed-KNN</td><td>inverse</td><td>9</td></tr><tr><td>Dynamic-KNN</td><td>inverse</td><td>Q2</td></tr><tr><td>Hybrid-KNN</td><td>inverse</td><td>7 + Q2</td></tr><tr><td rowspan="4">MFO</td><td char="." align="char" rowspan="4">121</td><td char="." align="char" rowspan="4">96.5</td><td>1NN</td><td>–</td><td>1</td></tr><tr><td>Fixed-KNN</td><td>inverse</td><td>3</td></tr><tr><td>Dynamic-KNN</td><td>inverse</td><td>Q2</td></tr><tr><td>Hybrid-KNN</td><td>inverse</td><td>3 + Q2</td></tr></tbody></table></table-wrap></p>
      <p id="Par19">Figure <xref rid="Fig6" ref-type="fig">6</xref> shows the Fmax (a) and precision-recall curve (b) of 1NN, Fixed-KNN, and Hybrid-KNN under full evaluation mode and Dynamic-KNN under partial evaluation mode. Although Dynamic-KNN with <italic>Inverse</italic> weighting performs best among the three Ontologies, it only predicts less than half of the proteins (0.38–0.43). For the full mode, Fixed-KNN and Hybird-KNN show compatible performance, which is better than 1NN. Most of the proposed <italic>k</italic>-nearest-neighbor voting algorithms (green bars) perform better than the two baseline methods, especially in BPO and MFO. The exceptional performance of the Naive method in CCO is biased because the benchmark proteins were annotated with more general terms than the (training) proteins previously deposited in the UniProt database [<xref ref-type="bibr" rid="CR8">8</xref>].
<fig id="Fig6"><label>Fig. 6</label><caption><p>Fmax (<bold>a</bold>) and precision-recall curve (<bold>b</bold>) of each method on CAFA2-benchmark trained on CAFA2-Swiss, where Fixed, Dyn.Inverse, Dyn.FunOverlap, and Hybrid represent Fixed-KNN, Dynamic-KNN with Inverse voting weight, Dynamic-KNN with FunOverlap voting weight, and Hybrid-KNN, respectively. The number inside the bar shows the predicted proportion, in particular for Dynamic-KNN in partial mode</p></caption><graphic xlink:href="12859_2020_3556_Fig6_HTML" id="MO6"/></fig></p>
    </sec>
  </sec>
  <sec id="Sec6">
    <title>Discussion</title>
    <p id="Par20">We participated in the CAFA3 competition as the NCCUCS team. The manuscript summarizing our CAFA3 results was published in Genome Biology and bioRxiv [<xref ref-type="bibr" rid="CR9">9</xref>, <xref ref-type="bibr" rid="CR12">12</xref>]. We submitted three models: 1NN, Fynamic-KNN with Inverse, and Dynamic-KNN with FunOverlap. According to the official evaluation, our methods performed quite well among the 68 teams (Fig. 12 in [<xref ref-type="bibr" rid="CR12">12</xref>]). In the protein-centric evaluation, it ranks 3rd and 5th in full and partial modes, respectively, according to the minimum normalized semantic distance metric in the BPO ontology (Supplemental Table S<xref rid="MOESM1" ref-type="media">1</xref>). For the CCO ontology, GODoc (NCCUCS) ranks 10th based on the Fmax metric (Fig. 3c in [<xref ref-type="bibr" rid="CR9">9</xref>]) and the precision-recall curve (Fig. 3F in [<xref ref-type="bibr" rid="CR9">9</xref>]). Since different methods sometimes perform differently on different species [<xref ref-type="bibr" rid="CR9">9</xref>], the benchmarks are further divided into eukaryotic- and prokaryotic-species categories. GODoc ranks 10th and 8th in eukaryotic CCO and prokaryotic MFO Fmax, respectively (Fig. 5c, d in [<xref ref-type="bibr" rid="CR9">9</xref>]). In addition to the protein-centric task, predicting which proteins are associated with a given function (term-centric, binary classification) is also evaluated in CAFA3. For biofilm formation (GO:0042710) of the bacterium <italic>Pseudomonas aeruginosa</italic>, the proposed method ranks third in AUC (Fig. 9b in [<xref ref-type="bibr" rid="CR9">9</xref>]). For long-term memory (GO:0007616) of <italic>Drosophila melanogaster</italic>, our method ranks first (tied with other two methods) in AUC (Fig. 10 in [<xref ref-type="bibr" rid="CR9">9</xref>]).</p>
  </sec>
  <sec id="Sec7">
    <title>Conclusions</title>
    <p id="Par21">We propose a framework for protein function prediction that utilizes TFPSSM features. We propose three different methods, namely, TFPSSM 1NN, TFPSSM Vote (Fixed-KNN, Dynamic-KNN, and Hybrid-KNN), and TFPSSM CATH (Dynamic-KNN with FunOverlap) to enhance prediction accuracy. The advantage of traditional KNN lies in its interpretability. Its performance, however, is inferior to other machine learning methods since no actual training takes place. Here we demonstrate that variants of KNN with extra training procedures (dynamic + voting scheme) can outperform baseline methods.</p>
    <p id="Par22">As a newly developed framework, there are still a wide range of ideas worth investigating in the future (i.e., combining hydrophobe with TFPSSM). In addition, as we have demonstrated the ability of the proposed framework to predict protein subcellular localization and protein function, we expect it to perform effectively on other protein prediction problems as well.</p>
  </sec>
  <sec id="Sec8">
    <title>Methods</title>
    <p id="Par23">Firstly, each protein is represented by TFPSSM, a feature vector based on the frequency of the gapped-dipeptides [<xref ref-type="bibr" rid="CR4">4</xref>] in the position-specific scoring matrix (PSSM). Then, principal component analysis (PCA) is employed to reduce the TFPSSM features to a lower number of dimensions. Finally, we combine variance <italic>k</italic>-nearest-neighbor algorithms with CATH FunFam information to predict GOs. The details of feature extraction, dimensionality reduction, CATH information, and the voting scheme are described in the following sections.</p>
    <sec id="Sec9">
      <title>Feature representation by TFPSSM</title>
      <p id="Par24">When considering proteins as documents, <italic>n</italic>-peptide is a general term representation [<xref ref-type="bibr" rid="CR13">13</xref>]: a peptide of length <italic>n</italic> without gaps (bi-gram for <italic>n</italic> = 2). However, as using <italic>n</italic>-peptides to capture long-distance amino acid information results in a high-dimensional vector, the new protein representation <italic>gapped amino acid pair</italic> was proposed [<xref ref-type="bibr" rid="CR14">14</xref>], later followed by <italic>amino acid-coupling patterns</italic> [<xref ref-type="bibr" rid="CR15">15</xref>]. In PSLDoc, Chang et al. modify amino acid-coupling patterns to <italic>gapped-dipeptide</italic> [<xref ref-type="bibr" rid="CR4">4</xref>], in which <italic>XdY</italic> denotes the amino acid coupling pattern of amino acid types <italic>X</italic> and <italic>Y</italic> separated by <italic>d</italic> amino acids (Fig. <xref rid="Fig7" ref-type="fig">7</xref>). The vector size is controlled by <italic>l</italic>, where <italic>XdY</italic> for 0 ≤ <italic>d</italic> ≤ <italic>l</italic>. The dimension of gapped-dipeptide is 20 × (<italic>l</italic> + 1) × 20. Taking <italic>l</italic> = 13 as an example, a protein is represented by a gapped-dipeptide feature vector of 5600 (=20 × 14 × 20) dimensions [<xref ref-type="bibr" rid="CR4">4</xref>].
<fig id="Fig7"><label>Fig. 7</label><caption><p>An example of amino acid-coupling pattern representation. Given the protein sequence “MPLDLYNTLT”, it contains amino acid-coupling patterns M0P, M1L, M2D, M3L, and so on. Its corresponding amino acid-coupling pattern is shown in the bottom part</p></caption><graphic xlink:href="12859_2020_3556_Fig7_HTML" id="MO7"/></fig></p>
      <p id="Par25">The PSSM is evolutionary information generated by PSI-BLAST. For a protein sequence <italic>S</italic> of length <italic>n</italic>, the PSSM of <italic>S</italic> is represented by an <italic>n</italic> × 20 matrix, in which the <italic>n</italic> rows correspond to the amino acid sequence of <italic>S</italic> and the columns correspond to the 20 distinct amino acids. In predicting protein localization, Chang et al. propose TFPSSM to combine gapped-dipeptide representation with the PSSM [<xref ref-type="bibr" rid="CR4">4</xref>]. That is, the frequency of the gapped di-peptides is calculated based on the PSSM. The fast (insensitive) PSI-BLAST parameter setting is used to reduce running times (−matrix BLOSUM80 –evalue 1e-5 –gapopen 9 –gapextend 2 –threshold 999 –seq yes –soft_masking true –numter_iteration 2) [<xref ref-type="bibr" rid="CR11">11</xref>].</p>
    </sec>
    <sec id="Sec10">
      <title>Dimensionality reduction by principal component analysis</title>
      <p id="Par26">PCA is a useful statistical procedure to decompose high dimension datasets into low dimension ones with a set of successive orthogonal components that explain the maximum variance of the data. Therefore, we use PCA to reduce TFPSSM’s feature dimension.</p>
      <p id="Par27">In our study, the orthogonal components are computed from the training data and applied on both training data and test data using the <italic>Scikit-learn</italic> v0.19.0 module. The size of the reduced dimensions can be chosen to reflect different explained variance ratios. Accordingly, we conducted a series of experiments to determine the appropriate variance ratios based on five-fold cross-validation of CAFA2-Swiss and CAFA3-Swiss (detailed in the Evaluation section, Experimental design, Experiment1). Finally, the distance between two proteins is defined as the Euclidean distance of the two corresponding vectors in PCA projected space.</p>
    </sec>
    <sec id="Sec11">
      <title>Novel <italic>k</italic>-nearest-neighbor algorithms</title>
      <p id="Par28">We propose three strategies to apply the <italic>k</italic>-nearest-neighbor (KNN) algorithm to select candidate proteins. The predicted GOs of the target are determined by voting for results from GOs of the candidate proteins. We use a weighted voting strategy, that is, the greater the similarity to the target, the higher the voting weight. The voting result represents the likelihood of the predicted GOs, which are summarized as <italic>confidence scores</italic>.
<list list-type="order"><list-item><p id="Par29">TFPSSM 1NN: The GOs of the query protein are predicted as the same GOs of its nearest neighbors with a confidence score of 1.00 (Fig. <xref rid="Fig8" ref-type="fig">8</xref>a).</p></list-item><list-item><p id="Par30">TFPSSM vote: We propose three ways to choose <italic>k</italic> instead of 1NN.
<list list-type="alpha-lower"><list-item><p id="Par31">Fixed-KNN: <italic>k</italic> is fixed and chosen based on training data. Figure <xref rid="Fig8" ref-type="fig">8</xref>b depicts an example in which <italic>k</italic> is set to 3. <italic>k</italic> is determined based on five-fold cross-validation of CAFA2-Swiss and CAFA3-Swiss (detailed in the Evaluation section, Experimental design, Experiment2).</p></list-item><list-item><p id="Par32">Dynamic-KNN: We calculate the distance distribution of each protein’s nearest neighbors such that we are able to use the 1st, 2nd, or 3rd quartile (Q1, Q2 or Q3) as a distance threshold to select neighbors instead of a fixed <italic>k</italic>, that is, training proteins are selected as neighbors when their distances to the query protein are smaller than the threshold. Figure <xref rid="Fig8" ref-type="fig">8</xref>.c shows an example for the threshold as <italic>d</italic>. Dynamic-KNN is not applicable to those query proteins when no neighbor is closer than the given distance threshold. The evaluation of Dynamic-KNN is done following the process of the partial model in CAFA3, involving only benchmarking predicted queries.</p></list-item><list-item><p id="Par33">Hybrid-KNN: if a protein cannot be predicted by Dynamic-KNN, we apply fixed-KNN to select the <italic>k</italic>-nearest neighbors ignoring the distance threshold. This is considered the combined prediction of Fixed-KNN and Dynamic-KNN.</p></list-item></list><fig id="Fig8"><label>Fig. 8</label><caption><p>An illustration showing 1NN, Fixed-KNN, and Dynamic-KNN. A query protein is colored in gray. There are two GOs for training data (colored in green and orange) where the neighbor proteins picked are indicated with a solid circle. <bold>a</bold> 1NN: the nearest training protein is selected. <bold>b</bold> Fixed-KNN: three training proteins are picked for <italic>K</italic> = 3. <bold>c</bold> Dynamic-KNN: five proteins are selected, as their distances to the query are smaller than the threshold <italic>d</italic></p></caption><graphic xlink:href="12859_2020_3556_Fig8_HTML" id="MO8"/></fig></p></list-item></list></p>
    </sec>
    <sec id="Sec12">
      <title>Voting weight schemes</title>
      <p id="Par34">When neighbor proteins are selected, their voting weights are determined as follows: (1) <italic>Equal</italic>: all weights are equal to 1; (2) <italic>Inverse</italic>: inverse of the Euclidean distance, <italic>d</italic>, between the query protein and the neighbor protein, 1/<italic>d</italic>; (3) <italic>Sqrt-Inverse</italic>: square root of the above inverse weight, <inline-formula id="IEq1"><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \sqrt{1/d} $$\end{document}</tex-math><mml:math id="M2" display="inline"><mml:msqrt><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msqrt></mml:math><inline-graphic xlink:href="12859_2020_3556_Article_IEq1.gif"/></alternatives></inline-formula>, which aims to constrain the range of voting weights to prevent extremely large weights; (4) <italic>FunOverlap</italic>: In addition to the above voting schemes concerning sequence feature space, <italic>FunOverlap</italic> is incorporated to integrate information from protein domains. The domain-based approach has been shown to be useful in predicting protein function [<xref ref-type="bibr" rid="CR16">16</xref>], where proteins are classified into FunFam. We adopt the HMMer model of FunFams released on the CATH-Gene3D server to predict the FunFams of the query and neighbor proteins with an <italic>E</italic>-value threshold of 10<sup>−5</sup> [<xref ref-type="bibr" rid="CR17">17</xref>]. Then, the voting weight of the neighboring protein is set to the overlap proportion between its predicted FunFams and those of the query. The <italic>FunOverlap</italic> item is applicable if there is no FunFam below the <italic>E</italic>-value threshold (10<sup>− 5</sup>) or when the overlap proportion is zero Therefore, <italic>FunOverlap</italic> is only used in Dynamic-KNN.</p>
    </sec>
    <sec id="Sec13">
      <title>GO propagate step</title>
      <p id="Par35">Because GO is a hierarchical structure, GO prediction of the node is propagated to its parent node. There are two approaches to merge propagated voting weights from child nodes: <italic>Max</italic> and <italic>Sum</italic> (Fig. <xref rid="Fig9" ref-type="fig">9</xref>). The former uses the maximum weight of the child nodes as a weight (Fig. <xref rid="Fig9" ref-type="fig">9</xref>a), and the latter uses the sum of the children weights as a weight (Fig. <xref rid="Fig9" ref-type="fig">9</xref>b). After the propagation step is finished, the score of each candidate GO is normalized between 0 and 1 by dividing it by the maximum score.
<fig id="Fig9"><label>Fig. 9</label><caption><p>An illustration showing two functions for merging propagated voting weights from child nodes. Given three proteins selected as neighbors by 3-NN, their corresponding GOs and voting weights are shown in the top. <bold>a</bold>
<italic>Max</italic>: The voting weight of the parent is the maximum weight of the child nodes. For example, the weight of GO:2 is 2.3, the maximum of 2.3 and 1.2. <bold>b</bold>
<italic>Sum</italic>: The voting weight of the parent is the sum weight of the child nodes. For example, the weight of GO:2 is 3.5, the sum of 2.3 and 1.2</p></caption><graphic xlink:href="12859_2020_3556_Fig9_HTML" id="MO9"/></fig></p>
      <p id="Par36">The overall system architecture of the GODoc is shown in Fig. <xref rid="Fig10" ref-type="fig">10</xref>. It extends PSLDoc2 (blue and green parts) with the afore-mentioned novel voting designs and weighting schemes (red part).
<fig id="Fig10"><label>Fig. 10</label><caption><p>System architecture of GODoc for protein GO prediction, which contains three parts: PSSM homologous extension (blue), TFPSSM feature representation (green), and the proposed voting algorithms (red). The former two parts are based on PSLDoc2 with updated databases. The last part combines a novel <italic>k</italic>-nearest-neighbor algorithm and weighting schemes</p></caption><graphic xlink:href="12859_2020_3556_Fig10_HTML" id="MO10"/></fig></p>
    </sec>
    <sec id="Sec14">
      <title>Evaluation</title>
      <p id="Par37">To compare with other methods and validate the reproducibility of our experiments, we followed the evaluation measures and the dataset used in CAFA2. In this section we discuss the dataset, the cross-validation procedure for training the model, the evaluation measures, the baseline models, and the experimental design.</p>
    </sec>
    <sec id="Sec15">
      <title>Data sets</title>
      <p id="Par38">We used data from CAFA2 and CAFA3. The training data of CAFA2 includes three databases: GO Consortium, UniProt-GOA, and Swiss-Prot. As the annotation evidence codes of Swiss-Prot were more reliable than the other two, only the data from Swiss-Prot was included in our training dataset, referred to as CAFA2-Swiss. Additionally, we used the training data from CAFA3 (provides only Swiss-Prot, is referred to as CAFA3-Swiss). Regarding the test data, the benchmark dataset from CAFA2 originally was used to evaluate submitted methods, referred to as CAFA2-Benchmark. Table <xref rid="Tab3" ref-type="table">3</xref> gives a short summary of each dataset, including the number of protein sequences, the number of GO, and the median GO numbers of each protein in BPO, CCO, and MFO.
<table-wrap id="Tab3"><label>Table 3</label><caption><p>Training and test dataset statistics</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Dataset</th><th>Ontology</th><th># of seqs</th><th># of GOs</th><th>Median # of GOs</th></tr></thead><tbody><tr><td rowspan="3">CAFA2-Swiss</td><td>BPO</td><td>40,728</td><td>15,838</td><td>25</td></tr><tr><td>CCO</td><td>40,571</td><td>1892</td><td>9</td></tr><tr><td>MFO</td><td>26,056</td><td>5480</td><td>8</td></tr><tr><td rowspan="3">CAFA3-Swiss</td><td>BPO</td><td>50,813</td><td>19,682</td><td>29</td></tr><tr><td>CCO</td><td>49,328</td><td>2426</td><td>10</td></tr><tr><td>MFO</td><td>35,086</td><td>6366</td><td>8</td></tr><tr><td rowspan="3">CAFA2-Benchmark</td><td>BPO</td><td>860</td><td>6540</td><td>29</td></tr><tr><td>CCO</td><td>1259</td><td>833</td><td>11</td></tr><tr><td>MFO</td><td>421</td><td>1501</td><td>8</td></tr></tbody></table></table-wrap></p>
    </sec>
    <sec id="Sec16">
      <title>Five-fold cross-validation</title>
      <p id="Par39">We used five-fold cross-validation to examine the stability of the proposed method on the training dataset, which was split into five partitions. For each round, one fold was considered validation data and the other four folds were used to train the model. We repeated this for five rounds, each of which used different folds as the training and validation data. By using cross-validation to fit model parameters, we reduced the probability of model overfitting.</p>
      <p id="Par40">To avoid bias from duplicates in cross-validation, non-redundant data was generated by applying ultra-fast sequence analysis (USERACH) [<xref ref-type="bibr" rid="CR18">18</xref>] to cluster 50% identical sequences. The size of data was reduced to around 30% (Table <xref rid="Tab4" ref-type="table">4</xref>).
<table-wrap id="Tab4"><label>Table 4</label><caption><p>Average protein amount of training data in cross-validation (80% of the total amount) for redundant and non-redundant datasets in different ontologies</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Type</th><th>Dataset</th><th># of redundant</th><th># of non-redundant</th><th>Reduction ratio (%)</th></tr></thead><tbody><tr><td rowspan="2">BPO</td><td>CAFA2-Swiss</td><td>  32,582</td><td>  22,231</td><td>  31.77</td></tr><tr><td>CAFA3-Swiss</td><td>  40,650</td><td>  27,158</td><td>  33.19</td></tr><tr><td rowspan="2">CCO</td><td>CAFA2-Swiss</td><td>  32,457</td><td>  22,521</td><td>  30.61</td></tr><tr><td>CAFA3-Swiss</td><td>  39,462</td><td>  26,631</td><td>  32.51</td></tr><tr><td rowspan="2">MFO</td><td>CAFA2-Swiss</td><td>  20,845</td><td>  14,711</td><td>  29.43</td></tr><tr><td>CAFA3-Swiss</td><td>  28,267</td><td>  19,254</td><td>  31.89</td></tr></tbody></table></table-wrap></p>
    </sec>
    <sec id="Sec17">
      <title>Evaluation metrics</title>
      <p id="Par41">The prediction result for each term included a confidence score between 0 and 1. Thus, a decision threshold <italic>τ</italic> was applied to determine the set of predicted GO terms, <italic>P</italic> (<italic>τ</italic>). Similarly, a set of experimentally determined GO terms was denoted as <italic>T</italic>. We focused on protein-centric evaluation, that is, an object function is calculated between <italic>P</italic> (<italic>τ</italic>) and <italic>T</italic> for each protein <italic>i</italic> and threshold <italic>τ</italic>. We define its precision and recall as
<disp-formula id="Equ1"><label>1</label><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ {pr}_i\left(\tau \right)=\frac{\sum \limits_{v\in O}I\left(v\in {P}_i\left(\tau \right)\bullet v\in {T}_i\right)}{\sum \limits_{v\in O}I\left(v\in {P}_i\left(\tau \right)\right)} $$\end{document}</tex-math><mml:math id="M4" display="block"><mml:msub><mml:mi mathvariant="italic">pr</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mfenced close=")" open="("><mml:mi>τ</mml:mi></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>v</mml:mi><mml:mo>∈</mml:mo><mml:mi>O</mml:mi></mml:mrow></mml:munder><mml:mi>I</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:mi>v</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mfenced close=")" open="("><mml:mi>τ</mml:mi></mml:mfenced><mml:mo>∙</mml:mo><mml:mi>v</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mi>T</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>v</mml:mi><mml:mo>∈</mml:mo><mml:mi>O</mml:mi></mml:mrow></mml:munder><mml:mi>I</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:mi>v</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mfenced close=")" open="("><mml:mi>τ</mml:mi></mml:mfenced></mml:mrow></mml:mfenced></mml:mrow></mml:mfrac></mml:math><graphic xlink:href="12859_2020_3556_Article_Equ1.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ2"><label>2</label><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ {rc}_i\left(\tau \right)=\frac{\sum \limits_{v\in O}I\left(v\in {P}_i\left(\tau \right)\bullet v\in {T}_i\right)}{\sum \limits_{v\in O}I\left(v\in {T}_i\right)} $$\end{document}</tex-math><mml:math id="M6" display="block"><mml:msub><mml:mi mathvariant="italic">rc</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mfenced close=")" open="("><mml:mi>τ</mml:mi></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>v</mml:mi><mml:mo>∈</mml:mo><mml:mi>O</mml:mi></mml:mrow></mml:munder><mml:mi>I</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:mi>v</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mfenced close=")" open="("><mml:mi>τ</mml:mi></mml:mfenced><mml:mo>∙</mml:mo><mml:mi>v</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mi>T</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>v</mml:mi><mml:mo>∈</mml:mo><mml:mi>O</mml:mi></mml:mrow></mml:munder><mml:mi>I</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:mi>v</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mi>T</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mfrac></mml:math><graphic xlink:href="12859_2020_3556_Article_Equ2.gif" position="anchor"/></alternatives></disp-formula>where <italic>I</italic>(·) is an indicator function. Overall precision and recall are defined as
<disp-formula id="Equ3"><label>3</label><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ pr\left(\tau \right)=\frac{1}{m\left(\tau \right)}\bullet \sum \limits_{i=1}^{m\left(\tau \right)}{pr}_i\left(\tau \right) $$\end{document}</tex-math><mml:math id="M8" display="block"><mml:mi mathvariant="italic">pr</mml:mi><mml:mfenced close=")" open="("><mml:mi>τ</mml:mi></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>m</mml:mi><mml:mfenced close=")" open="("><mml:mi>τ</mml:mi></mml:mfenced></mml:mrow></mml:mfrac><mml:mo>∙</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mfenced close=")" open="("><mml:mi>τ</mml:mi></mml:mfenced></mml:mrow></mml:munderover><mml:msub><mml:mi mathvariant="italic">pr</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mfenced close=")" open="("><mml:mi>τ</mml:mi></mml:mfenced></mml:math><graphic xlink:href="12859_2020_3556_Article_Equ3.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ4"><label>4</label><alternatives><tex-math id="M9">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ rc\left(\tau \right)=\frac{1}{n_e}\bullet \sum \limits_{i=1}^{n_e}{rc}_i\left(\tau \right) $$\end{document}</tex-math><mml:math id="M10" display="block"><mml:mi mathvariant="italic">rc</mml:mi><mml:mfenced close=")" open="("><mml:mi>τ</mml:mi></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:msub><mml:mi>n</mml:mi><mml:mi>e</mml:mi></mml:msub></mml:mfrac><mml:mo>∙</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mi>e</mml:mi></mml:msub></mml:munderover><mml:msub><mml:mi mathvariant="italic">rc</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mfenced close=")" open="("><mml:mi>τ</mml:mi></mml:mfenced></mml:math><graphic xlink:href="12859_2020_3556_Article_Equ4.gif" position="anchor"/></alternatives></disp-formula>where <italic>m</italic>(<italic>τ</italic>) denotes a set of proteins with prediction confidence above threshold <italic>τ</italic>. As a method might predict only part of targets, an evaluation can be done under full mode (<italic>n</italic><sub><italic>e</italic></sub> = all dataset) or partial mode (<italic>n</italic><sub><italic>e</italic></sub> = <italic>m</italic>(0)). To provide a single evaluation metric, the maximum <italic>F</italic>-measure was used:
<disp-formula id="Equ5"><label>5</label><alternatives><tex-math id="M11">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ {F}_{max}=\underset{\tau }{\max}\left\{\frac{2\bullet pr\left(\tau \right)\bullet rc\left(\tau \right)}{pr\left(\tau \right)+ rc\left(\tau \right)}\right\} $$\end{document}</tex-math><mml:math id="M12" display="block"><mml:msub><mml:mi>F</mml:mi><mml:mi mathvariant="italic">max</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:munder><mml:mo>max</mml:mo><mml:mi>τ</mml:mi></mml:munder><mml:mfenced close="}" open="{"><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mo>∙</mml:mo><mml:mi mathvariant="italic">pr</mml:mi><mml:mfenced close=")" open="("><mml:mi>τ</mml:mi></mml:mfenced><mml:mo>∙</mml:mo><mml:mi mathvariant="italic">rc</mml:mi><mml:mfenced close=")" open="("><mml:mi>τ</mml:mi></mml:mfenced></mml:mrow><mml:mrow><mml:mi mathvariant="italic">pr</mml:mi><mml:mfenced close=")" open="("><mml:mi>τ</mml:mi></mml:mfenced><mml:mo>+</mml:mo><mml:mi mathvariant="italic">rc</mml:mi><mml:mfenced close=")" open="("><mml:mi>τ</mml:mi></mml:mfenced></mml:mrow></mml:mfrac></mml:mfenced></mml:math><graphic xlink:href="12859_2020_3556_Article_Equ5.gif" position="anchor"/></alternatives></disp-formula></p>
    </sec>
    <sec id="Sec18">
      <title>Baseline models</title>
      <p id="Par42">In order to investigate the bottom line performance, we used two baseline models: Naive and BLAST. Their implementations were adopted from the Matlab code in the CAFA2 experiment [<xref ref-type="bibr" rid="CR8">8</xref>].
<list list-type="bullet"><list-item><p id="Par43">The Naive method always predicts each GO scored by its normalized frequency among the training data. As a result, query proteins are predicted with the same result.</p></list-item><list-item><p id="Par44">The BLAST method predicts GOs based on BLAST searching against the training data. We extract proteins showing local alignment identity with the query protein. The GOs of the query are predicted by assembling the GOs of similar proteins; their confidence scores are converted from the BLAST <italic>E</italic>-values.</p></list-item></list></p>
    </sec>
    <sec id="Sec19">
      <title>Experimental design</title>
      <p id="Par45">We conducted the following experiments to evaluate the performance of each step in the proposed framework on the CAFA2-Swiss and CAFA3-Swiss training data. The training procedure was conducted based on five-fold cross-validation (detailed in the section on Five-fold cross-validation).
<list list-type="bullet"><list-item><p id="Par46">Experiment 1: Three factors of PCA reduction were evaluated, simplifying the process by using only TFPSSM 1NN: 1) the size of reduced dimensions with different explained variance ratios, 2) carried out on redundant or non-redundant training data, 3) the benefit of whitening, a preprocessing step that scales each component to the unit variance.</p></list-item><list-item><p id="Par47">Experiment 2: We sought to identify the interaction between the voting algorithm (<italic>k</italic> and <italic>Q</italic>), the weighting scheme, and propagate step for the TFPSSM vote architecture. First, <italic>k</italic> of Fixed-KNN (1 to 10) and the weighting scheme (<italic>Equal</italic>, <italic>Inverse</italic>, <italic>Sqrt</italic>) were investigated under <italic>Max</italic> or <italic>Sum</italic> propagation. After selecting the best weighting scheme, <italic>Q</italic> of Dynamic KNN (Q1, Q2, Q3) was investigated in the same way. The benefit of incorporating protein domain information was judged by a comparison between <italic>FunOverlap</italic> and the selected weighting scheme. Last, the performance of Hybird-KNN was evaluated.</p></list-item></list></p>
      <p id="Par48">Finally, a model was trained according to the best setting learned from the previous experiments. Then, it was evaluated on the CAFA2-benchmark so it could be compared with other methods reported in CAFA2 on the same basis.</p>
    </sec>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary information</title>
    <sec id="Sec20">
      <p>
        <supplementary-material content-type="local-data" id="MOESM1">
          <media xlink:href="12859_2020_3556_MOESM1_ESM.xlsx">
            <caption>
              <p><bold>Additional file 1: Table S1.</bold> The performance of the submitted Model 1 based on minimum normalized semantic distance metric adapted from CAFA3 Results Release.</p>
            </caption>
          </media>
        </supplementary-material>
      </p>
    </sec>
  </sec>
</body>
<back>
  <glossary>
    <title>Abbreviations</title>
    <def-list>
      <def-item>
        <term>CAFA</term>
        <def>
          <p id="Par4">Critical Assessment of Functional Annotation</p>
        </def>
      </def-item>
      <def-item>
        <term>GO</term>
        <def>
          <p id="Par5">Gene Ontology</p>
        </def>
      </def-item>
      <def-item>
        <term>GODoc</term>
        <def>
          <p id="Par6">Gene Ontology prediction based on Document classification method</p>
        </def>
      </def-item>
      <def-item>
        <term>FunFam</term>
        <def>
          <p id="Par7">Functional Family</p>
        </def>
      </def-item>
      <def-item>
        <term>KNN</term>
        <def>
          <p id="Par8">K-nearest-neighbor</p>
        </def>
      </def-item>
    </def-list>
  </glossary>
  <fn-group>
    <fn>
      <p>
        <bold>Publisher’s Note</bold>
      </p>
      <p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
    </fn>
  </fn-group>
  <sec>
    <title>Supplementary information</title>
    <p><bold>Supplementary information</bold> accompanies this paper at 10.1186/s12859-020-03556-9.</p>
  </sec>
  <ack>
    <title>Acknowledgements</title>
    <p>We would like to acknowledge Dr. Aaron Heidel for his assistance in polishing the manuscript. The authors acknowledge the anonymous reviewers for their suggestions, which improved the quality of the manuscript.</p>
    <sec id="FPar1">
      <title>About this supplement</title>
      <p id="Par49">This article has been published as part of BMC Bioinformatics Volume 21 Supplement 6, 2020: Selected articles from the 15th International Symposium on Bioinformatics Research and Applications (ISBRA-19): bioinformatics. The full contents of the supplement are available online at <ext-link ext-link-type="uri" xlink:href="https://bmcbioinformatics.biomedcentral.com/articles/supplements/volume-21-supplement-6">https://bmcbioinformatics.biomedcentral.com/articles/supplements/volume-21-supplement-6</ext-link>.</p>
    </sec>
  </ack>
  <notes notes-type="author-contribution">
    <title>Authors’ contributions</title>
    <p>YWL, WHL, and JMC conceived the study. YWL implemented the method and performed the experiments. TWH and CYC implemented the web service of the method. YWL drafted the manuscript and then WHL and JMC finalized it. All authors have read and approved the final manuscript.</p>
  </notes>
  <notes notes-type="funding-information">
    <title>Funding</title>
    <p>This work was supported by the Taiwan Ministry of Science and Technology [106–2221-E-004-011-MY2 to J.-M.C.] and “The Human Project from Mind, Brain and Learning” of NCCU from the Higher Education Sprout Project by the Ministry of Education in Taiwan. We are grateful to the National Center for High-performance Computing for computer time and facilities. Publication costs are funded by the Taiwan Ministry of Science and Technology.</p>
  </notes>
  <notes notes-type="data-availability">
    <title>Availability of data and materials</title>
    <p>The GODoc method is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/changlabtw/GODoc">https://github.com/changlabtw/GODoc</ext-link>.</p>
  </notes>
  <notes id="FPar2">
    <title>Ethics approval and consent to participate</title>
    <p id="Par50">Not applicable.</p>
  </notes>
  <notes id="FPar3">
    <title>Consent for publication</title>
    <p id="Par51">Not applicable.</p>
  </notes>
  <notes id="FPar4" notes-type="COI-statement">
    <title>Competing interests</title>
    <p id="Par52">The authors declare that they have no competing interests.</p>
  </notes>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <label>1.</label>
      <mixed-citation publication-type="other">Dessimoz, Christophe, Nives Škunca, editors. The Gene Ontology Handbook. Vol. 1446. New York: Humana Press; 2017. 10.1007/978-1-4939-3743-1.</mixed-citation>
    </ref>
    <ref id="CR2">
      <label>2.</label>
      <mixed-citation publication-type="other">The Gene Ontology Consortium. <ext-link ext-link-type="uri" xlink:href="http://geneontology.org/docs/guide-go-evidence-codes/">http://geneontology.org/docs/guide-go-evidence-codes/</ext-link>. Accessed 22 July 2019.</mixed-citation>
    </ref>
    <ref id="CR3">
      <label>3.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Altschul</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Madden</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Schäffer</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Miller</surname>
            <given-names>W</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Gapped BLAST and PSI-BLAST: a new generation of protein database search programs</article-title>
        <source>Nucleic Acids Res</source>
        <year>1997</year>
        <volume>25</volume>
        <fpage>3389</fpage>
        <lpage>3402</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/25.17.3389</pub-id>
        <pub-id pub-id-type="pmid">9254694</pub-id>
      </element-citation>
    </ref>
    <ref id="CR4">
      <label>4.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chang</surname>
            <given-names>J-M</given-names>
          </name>
          <name>
            <surname>Su</surname>
            <given-names>EC</given-names>
          </name>
          <name>
            <surname>Lo</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Chiu</surname>
            <given-names>H-SS</given-names>
          </name>
          <name>
            <surname>Sung</surname>
            <given-names>T-YY</given-names>
          </name>
          <name>
            <surname>Hsu</surname>
            <given-names>W-LL</given-names>
          </name>
        </person-group>
        <article-title>PSLDoc: protein subcellular localization prediction based on gapped-dipeptides and probabilistic latent semantic analysis</article-title>
        <source>Proteins.</source>
        <year>2008</year>
        <volume>72</volume>
        <fpage>693</fpage>
        <lpage>710</lpage>
        <pub-id pub-id-type="doi">10.1002/prot.21944</pub-id>
        <pub-id pub-id-type="pmid">18260102</pub-id>
      </element-citation>
    </ref>
    <ref id="CR5">
      <label>5.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Dawson</surname>
            <given-names>NL</given-names>
          </name>
          <name>
            <surname>Sillitoe</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Lees</surname>
            <given-names>JG</given-names>
          </name>
          <name>
            <surname>Lam</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Orengo</surname>
            <given-names>CA</given-names>
          </name>
        </person-group>
        <article-title>Protein bioinformatics, from protein modifications and networks to proteomics</article-title>
        <source>Methods Mol Biology Clifton N J</source>
        <year>2017</year>
        <volume>1558</volume>
        <fpage>79</fpage>
        <lpage>110</lpage>
        <pub-id pub-id-type="doi">10.1007/978-1-4939-6783-4_4</pub-id>
      </element-citation>
    </ref>
    <ref id="CR6">
      <label>6.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Das</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Sillitoe</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Lee</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Lees</surname>
            <given-names>JG</given-names>
          </name>
          <name>
            <surname>Dawson</surname>
            <given-names>NL</given-names>
          </name>
          <name>
            <surname>Ward</surname>
            <given-names>J</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>CATH FunFHMMer web server: protein functional annotations using functional family assignments</article-title>
        <source>Nucleic Acids Res</source>
        <year>2015</year>
        <volume>43</volume>
        <fpage>W148</fpage>
        <lpage>W153</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkv488</pub-id>
        <pub-id pub-id-type="pmid">25964299</pub-id>
      </element-citation>
    </ref>
    <ref id="CR7">
      <label>7.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Radivojac</surname>
            <given-names>P</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>A large-scale evaluation of computational protein function prediction</article-title>
        <source>Nat Methods</source>
        <year>2013</year>
        <volume>10</volume>
        <fpage>221</fpage>
        <lpage>227</lpage>
        <pub-id pub-id-type="doi">10.1038/nmeth.2340</pub-id>
        <pub-id pub-id-type="pmid">23353650</pub-id>
      </element-citation>
    </ref>
    <ref id="CR8">
      <label>8.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Jiang</surname>
            <given-names>Y</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>An expanded evaluation of protein function prediction methods shows an improvement in accuracy</article-title>
        <source>Genome Biol</source>
        <year>2016</year>
        <volume>17</volume>
        <fpage>184</fpage>
        <pub-id pub-id-type="doi">10.1186/s13059-016-1037-6</pub-id>
        <pub-id pub-id-type="pmid">27604469</pub-id>
      </element-citation>
    </ref>
    <ref id="CR9">
      <label>9.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhou</surname>
            <given-names>N</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>The CAFA challenge reports improved protein function prediction and new functional annotations for hundreds of genes through experimental screens</article-title>
        <source>Genome Biol</source>
        <year>2019</year>
        <volume>20</volume>
        <fpage>244</fpage>
        <pub-id pub-id-type="doi">10.1186/s13059-019-1835-8</pub-id>
        <pub-id pub-id-type="pmid">31744546</pub-id>
      </element-citation>
    </ref>
    <ref id="CR10">
      <label>10.</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Liu</surname>
            <given-names>Y-W</given-names>
          </name>
        </person-group>
        <source>Applying data science to high-throughput protein function prediction, master thesis, National Chengchi University</source>
        <year>2017</year>
      </element-citation>
    </ref>
    <ref id="CR11">
      <label>11.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chang</surname>
            <given-names>J-MM</given-names>
          </name>
          <name>
            <surname>Taly</surname>
            <given-names>J-FF</given-names>
          </name>
          <name>
            <surname>Erb</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Sung</surname>
            <given-names>T-YY</given-names>
          </name>
          <name>
            <surname>Hsu</surname>
            <given-names>W-LL</given-names>
          </name>
          <name>
            <surname>Tang</surname>
            <given-names>CY</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Efficient and interpretable prediction of protein functional classes by correspondence analysis and compact set relations</article-title>
        <source>PLoS One</source>
        <year>2013</year>
        <volume>8</volume>
        <fpage>e75542</fpage>
        <pub-id pub-id-type="doi">10.1371/journal.pone.0075542</pub-id>
        <pub-id pub-id-type="pmid">24146760</pub-id>
      </element-citation>
    </ref>
    <ref id="CR12">
      <label>12.</label>
      <mixed-citation publication-type="other">Zhou N, et al. The CAFA challenge reports improved protein function prediction and new functional annotations for hundreds of genes through experimental screens. bioRxiv. 2019:653105. 10.1101/653105.</mixed-citation>
    </ref>
    <ref id="CR13">
      <label>13.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Yu</surname>
            <given-names>C-SS</given-names>
          </name>
          <name>
            <surname>Lin</surname>
            <given-names>C-JJ</given-names>
          </name>
          <name>
            <surname>Hwang</surname>
            <given-names>J-KK</given-names>
          </name>
        </person-group>
        <article-title>Predicting subcellular localization of proteins for gram-negative bacteria by support vector machines based on n-peptide compositions</article-title>
        <source>Protein Sci</source>
        <year>2004</year>
        <volume>13</volume>
        <fpage>1402</fpage>
        <lpage>1406</lpage>
        <pub-id pub-id-type="doi">10.1110/ps.03479604</pub-id>
        <pub-id pub-id-type="pmid">15096640</pub-id>
      </element-citation>
    </ref>
    <ref id="CR14">
      <label>14.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Park</surname>
            <given-names>K-JJ</given-names>
          </name>
          <name>
            <surname>Kanehisa</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>Prediction of protein subcellular locations by support vector machines using compositions of amino acids and amino acid pairs</article-title>
        <source>Bioinformatics (Oxford, England)</source>
        <year>2003</year>
        <volume>19</volume>
        <fpage>1656</fpage>
        <lpage>1663</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btg222</pub-id>
      </element-citation>
    </ref>
    <ref id="CR15">
      <label>15.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Liang</surname>
            <given-names>H-KK</given-names>
          </name>
          <name>
            <surname>Huang</surname>
            <given-names>C-MM</given-names>
          </name>
          <name>
            <surname>Ko</surname>
            <given-names>M-TT</given-names>
          </name>
          <name>
            <surname>Hwang</surname>
            <given-names>J-KK</given-names>
          </name>
        </person-group>
        <article-title>Amino acid coupling patterns in thermophilic proteins</article-title>
        <source>Proteins.</source>
        <year>2005</year>
        <volume>59</volume>
        <fpage>58</fpage>
        <lpage>63</lpage>
        <pub-id pub-id-type="doi">10.1002/prot.20386</pub-id>
        <pub-id pub-id-type="pmid">15688447</pub-id>
      </element-citation>
    </ref>
    <ref id="CR16">
      <label>16.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Das</surname>
            <given-names>S</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Functional classification of CATH superfamilies: a domain-based approach for protein function annotation</article-title>
        <source>Bioinformatics</source>
        <year>2015</year>
        <volume>31</volume>
        <issue>21</issue>
        <fpage>3460</fpage>
        <lpage>3467</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btv398</pub-id>
        <pub-id pub-id-type="pmid">26139634</pub-id>
      </element-citation>
    </ref>
    <ref id="CR17">
      <label>17.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Sillitoe</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Lewis</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Orengo</surname>
            <given-names>C</given-names>
          </name>
        </person-group>
        <article-title>Using CATH-Gene3D to analyze the sequence, structure, and function of proteins</article-title>
        <source>Curr Protoc Bioinformatics</source>
        <year>2015</year>
        <volume>50</volume>
        <fpage>1.28.1</fpage>
        <lpage>1.2821</lpage>
        <pub-id pub-id-type="doi">10.1002/0471250953.bi0128s50</pub-id>
      </element-citation>
    </ref>
    <ref id="CR18">
      <label>18.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Edgar</surname>
            <given-names>RC</given-names>
          </name>
        </person-group>
        <article-title>Search and clustering orders of magnitude faster than BLAST</article-title>
        <source>Bioinformatics (Oxford, England)</source>
        <year>2010</year>
        <volume>26</volume>
        <fpage>2460</fpage>
        <lpage>2461</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btq461</pub-id>
      </element-citation>
    </ref>
  </ref-list>
</back>
