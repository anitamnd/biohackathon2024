<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-archivearticle1.dtd?>
<?SourceDTD.Version 1.1?>
<?ConverterInfo.XSLTName jp2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Biomed Res Int</journal-id>
    <journal-id journal-id-type="iso-abbrev">Biomed Res Int</journal-id>
    <journal-id journal-id-type="publisher-id">BMRI</journal-id>
    <journal-title-group>
      <journal-title>BioMed Research International</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">2314-6133</issn>
    <issn pub-type="epub">2314-6141</issn>
    <publisher>
      <publisher-name>Hindawi Publishing Corporation</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">4164313</article-id>
    <article-id pub-id-type="doi">10.1155/2014/213656</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Review Article</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>A Review of Feature Extraction Software for Microarray Gene Expression Data</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Tan</surname>
          <given-names>Ching Siang</given-names>
        </name>
        <xref ref-type="aff" rid="I1"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Ting</surname>
          <given-names>Wai Soon</given-names>
        </name>
        <xref ref-type="aff" rid="I1"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Mohamad</surname>
          <given-names>Mohd Saberi</given-names>
        </name>
        <xref ref-type="aff" rid="I1"/>
        <xref ref-type="corresp" rid="cor1">*</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Chan</surname>
          <given-names>Weng Howe</given-names>
        </name>
        <xref ref-type="aff" rid="I1"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Deris</surname>
          <given-names>Safaai</given-names>
        </name>
        <xref ref-type="aff" rid="I1"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Ali Shah</surname>
          <given-names>Zuraini</given-names>
        </name>
        <xref ref-type="aff" rid="I1"/>
      </contrib>
    </contrib-group>
    <aff id="I1">Artificial Intelligence and Bioinformatics Research Group, Faculty of Computing, Universiti Teknologi Malaysia, 81310 Skudai, Johor, Malaysia</aff>
    <author-notes>
      <corresp id="cor1">*Mohd Saberi Mohamad: <email>saberi@utm.my</email></corresp>
      <fn fn-type="other">
        <p>Academic Editor: Dongchun Liang</p>
      </fn>
    </author-notes>
    <pub-date pub-type="ppub">
      <year>2014</year>
    </pub-date>
    <pub-date pub-type="epub">
      <day>31</day>
      <month>8</month>
      <year>2014</year>
    </pub-date>
    <volume>2014</volume>
    <elocation-id>213656</elocation-id>
    <history>
      <date date-type="received">
        <day>23</day>
        <month>4</month>
        <year>2014</year>
      </date>
      <date date-type="rev-recd">
        <day>24</day>
        <month>7</month>
        <year>2014</year>
      </date>
      <date date-type="accepted">
        <day>24</day>
        <month>7</month>
        <year>2014</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>Copyright © 2014 Ching Siang Tan et al.</copyright-statement>
      <copyright-year>2014</copyright-year>
      <license xlink:href="https://creativecommons.org/licenses/by/3.0/">
        <license-p>This is an open access article distributed under the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <abstract>
      <p>When gene expression data are too large to be processed, they are transformed into a reduced representation set of genes. Transforming large-scale gene expression data into a set of genes is called feature extraction. If the genes extracted are carefully chosen, this gene set can extract the relevant information from the large-scale gene expression data, allowing further analysis by using this reduced representation instead of the full size data. In this paper, we review numerous software applications that can be used for feature extraction. The software reviewed is mainly for Principal Component Analysis (PCA), Independent Component Analysis (ICA), Partial Least Squares (PLS), and Local Linear Embedding (LLE). A summary and sources of the software are provided in the last section for each feature extraction method.</p>
    </abstract>
  </article-meta>
</front>
<body>
  <sec id="sec1">
    <title>1. Introduction</title>
    <p>The advances of microarray technology allow the expression levels of thousands of genes to be measured simultaneously [<xref rid="B56" ref-type="bibr">1</xref>]. This technology has caused an explosion in the amount of microarray gene expression data. However, the gene expression data generated are high-dimensional, containing a huge number of genes and small number of samples. This is called the “large <italic>p</italic> small <italic>n</italic> problem” [<xref rid="B38" ref-type="bibr">2</xref>]. The high-dimensional data are the main problem when analysing the data. As a result, instead of using gene selection methods, feature extraction methods are also important in order to reduce the dimensionality of high-dimensional data. Instead of eliminating irrelevant genes, feature extraction methods work by transforming the original data into a new representation. Feature extraction is usually better than gene selection in terms of causing less information loss. As a result, the high-dimensionality problem can be solved using feature extraction.</p>
    <p>Software is a set of machine readable instructions that direct a computer's processor to perform specific operations. With increases in the volume of data generated by modern biomedical studies, software is required to facilitate and ease the understanding of biological processes. Bioinformatics has emerged as a discipline in which emphasis is placed on easily understanding biological processes. Gheorghe and Mitrana [<xref rid="B20" ref-type="bibr">3</xref>] relate bioinformatics to computational biology and natural computing. Higgs and Attwood [<xref rid="B25" ref-type="bibr">4</xref>] believe that bioinformatics is important in the context of evolutionary biology.</p>
    <p>In this paper, the software applications that can be used for feature extraction are reviewed. The software reviewed is mainly for Principal Component Analysis (PCA), Independent Component Analysis (ICA), Partial Least Squares (PLS), and Local Linear Embedding (LLE). In the last section for each feature extraction method, a summary and sources are provided.</p>
  </sec>
  <sec id="sec2">
    <title>2. Software for Principal Component Analysis (PCA)</title>
    <p>In the domain of dimension reduction, PCA is one of the renowned techniques. The fundamental concept of PCA is to decrease the dimensionality of a given data set, whilst maintaining as plentiful as possible the variation existing in the initial predictor variables. This is attained by transforming the <italic>p</italic> initial variables <italic>X</italic> = [<italic>x</italic>
<sub>1</sub>, <italic>x</italic>
<sub>2</sub>,…, <italic>x</italic>
<sub><italic>p</italic></sub>] to a latest set of <italic>q</italic> predictor variables. Linear amalgamation of the initial variables is <italic>T</italic> = [<italic>t</italic>
<sub>1</sub>, <italic>t</italic>
<sub>2</sub>,…, <italic>t</italic>
<sub><italic>q</italic></sub>]. In mathematical domain, PCA successively optimizes the variance of a linear amalgamation of the initial predictor variables:
<disp-formula id="EEq1"><label>(1)</label><mml:math id="M1"><mml:mtable><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>q</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mtext>argmax</mml:mtext></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>Var</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>X</mml:mi><mml:mi>u</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msup><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msup><mml:mi>u</mml:mi><mml:mo>=</mml:mo><mml:mn mathvariant="normal">1</mml:mn></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>
conditional upon the constraint <italic>u</italic>
<sub><italic>i</italic></sub>
<sup><italic>T</italic></sup>
<italic>S</italic>
<sub><italic>X</italic></sub>
<italic>u</italic>
<sub><italic>j</italic></sub> = 0, for every 1 ≤ <italic>i</italic> ≤ <italic>j</italic>. The orthogonal constraint makes sure that the linear combinations are uncorrelated; that is, Cov(<italic>Xu</italic>
<sub><italic>i</italic></sub>, <italic>Xu</italic>
<sub><italic>j</italic></sub>) = 0, <italic>i</italic> ≠ <italic>j</italic>. These linear combinations are denoted as the principle components (PCs):
<disp-formula id="EEq2"><label>(2)</label><mml:math id="M2"><mml:mtable><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>X</mml:mi><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>
The projection vectors (or known as the weighting vectors) <italic>u</italic> can be attained by eigenvalue decomposition on the covariance matrix <italic>S</italic>
<sub><italic>X</italic></sub>:
<disp-formula id="EEq3"><label>(3)</label><mml:math id="M3"><mml:mtable><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>γ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>
where <italic>γ</italic>
<sub><italic>i</italic></sub> is the <italic>i</italic>th eigenvalue in the decreasing order, for <italic>i</italic> = 1,…, <italic>q</italic>, and <italic>u</italic>
<sub><italic>i</italic></sub> is the resultant eigenvector. The eigenvalue <italic>γ</italic>
<sub><italic>i</italic></sub> calculates the variance of the <italic>i</italic>th PC and the eigenvector <italic>u</italic>
<sub><italic>i</italic></sub> gives the weights for the linear transformation (projection).</p>
    <sec id="sec2.1">
      <title>2.1. FactoMineR</title>
      <p>FactoMineR is an R package that provides various functions for the analysis of multivariate data [<xref rid="B37" ref-type="bibr">5</xref>]. The newest version of this package is maintained by Hussen et al. [<xref rid="B27" ref-type="bibr">6</xref>]. There are a few main features provided by this package; for example, different types of variables, data structures, and supplementary information can be taken into account. Besides that, it offers dimension reduction methods such as Principal Component Analysis (PCA), Multiple Correspondence Analysis (MCA), and Correspondence Analysis (CA). The steps in implementing PCA are described in Lê et al. [<xref rid="B37" ref-type="bibr">5</xref>] and Hoffmann [<xref rid="B26" ref-type="bibr">7</xref>]. For PCA, there are three main functions for performing the PCA, plotting it, and printing its results. This package is mainly for Windows, MacOS, and Linux.</p>
    </sec>
    <sec id="sec2.2">
      <title>2.2. ExPosition</title>
      <p>ExPosition is an R package for the multivariate analysis of quantitative and qualitative data. ExPosition stands for Exploratory Analysis with the Singular Value Decomposition. The newest version of this package is maintained by Beaton et al. [<xref rid="B6" ref-type="bibr">8</xref>]. A variety of multivariate methods are provided in this package such as PCA, multidimensional scaling (MDS), and Generalized PCA. All of these methods can be performed by using the<italic> corePCA</italic> function in this package. Another function,<italic> epPCA</italic>, can be applied to implement PCA. Besides that, Generalized PCA can be implemented using the function<italic> epGPCA</italic> as well. All of these methods are used to analyse quantitative data. A plotting function is also offered by this package in order to plot the results of the analysis. This package can be installed on Windows, Linux, and MacOS.</p>
    </sec>
    <sec id="sec2.3">
      <title>2.3. amap</title>
      <p>The R package “amap” was developed for clustering as well as PCA for both parallelized functions and robust methods. It is an R package for multidimensional analysis. The newest version is maintained by Lucas [<xref rid="B40" ref-type="bibr">9</xref>]. Three different types of PCA are provided by this package. The methods are PCA, Generalized PCA, and Robust PCA. PCA methods can be implemented using the functions<italic> acp</italic> and<italic> pca</italic> for PCA,<italic> acpgen</italic> for Generalized PCA, and<italic> acprob</italic> for Robust PCA. This package also allows the implementation of correspondence factorial analysis through the function<italic> afc</italic>. Besides that, a plotting function is also provided for plotting the results of PCA as a graphical representation. The clustering methods offered by this package are<italic> k</italic>-means and hierarchical clustering. The dissimilarity matrix and distance matrix can be computed using this package as well. This package is mainly for Windows, Linux, and MacOS.</p>
    </sec>
    <sec id="sec2.4">
      <title>2.4. ADE-4</title>
      <p>ADE-4 was originally developed by Thioulouse et al. [<xref rid="B49" ref-type="bibr">10</xref>] as software for analyzing multivariate data and displaying graphics. This software includes a variety of methods such as PCA, CA, Principal Component Regression, PLS, Canonical Correspondence Analysis, Discriminant Analysis, and others. Besides that, this software is implemented in an R environment as an R package, “ade4.” The newest version of this package is maintained by Penel [<xref rid="B54" ref-type="bibr">37</xref>]. In this package, PCA can be performed by using the<italic> dudi.pca</italic> function. A visualization function is also provided in order to visualize the results as a graphical representation. In previous studies, this package was implemented by Dray and Dufour [<xref rid="B18" ref-type="bibr">38</xref>] to identify and understand ecological community structures. This package is mainly for Linux, Windows, and MacOS.</p>
    </sec>
    <sec id="sec2.5">
      <title>2.5. MADE4</title>
      <p>MADE4 (microarray ade4) was developed by Culhane et al. [<xref rid="B15" ref-type="bibr">11</xref>] for multivariate analysis of gene expression data based on the R package “ade4.” Basically, it is the extensions of the R package “ade4” for microarray data. The purpose of writing this software was to help users in the analysis of microarray data using multivariate analysis methods. This software is able to handle a variety of gene expression data formats, and new visualization software has been added to the package in order to facilitate the visualization of microarray data. Other extra features such as data preprocessing and gene filtering are included as well. However, this package was further improved by the addition of the LLSimpute algorithm to handle the missing values in the microarray data by Moorthy et al. [<xref rid="B45" ref-type="bibr">39</xref>]. It is implemented in an R environment. The advance of this package is that multiple datasets can be integrated to carry out analysis of microarray data. The newest version is maintained by Culhane [<xref rid="B14" ref-type="bibr">40</xref>]. This package can be installed on Linux, Windows, and MacOS.</p>
    </sec>
    <sec id="sec2.6">
      <title>2.6. XLMiner</title>
      <p>XLMiner is add-in software for Microsoft Excel that offers numerous data mining methods for analysing data [<xref rid="B62" ref-type="bibr">12</xref>]. It offers a quick start in the use of a variety of data mining methods for analysing data. This software can be used for data reduction using PCA, classification using Neural Networks or Decision Trees [<xref rid="B59" ref-type="bibr">41</xref>, <xref rid="B31" ref-type="bibr">42</xref>], class prediction, data exploration, affinity analysis, and clustering. In this software, PCA can be implemented using the Principle Component tab [<xref rid="B3" ref-type="bibr">43</xref>]. This software is implemented in Excel. As a result, the dataset should be in an Excel spreadsheet. In order to start the implementation of XLMiner, the dataset needs to be manually partitioned into training, validation, and test sets. Please see <ext-link ext-link-type="uri" xlink:href="http://www.solver.com/xlminer-data-mining">http://www.solver.com/xlminer-data-mining</ext-link> for further details. This software can be installed on Windows and MacOS.</p>
    </sec>
    <sec id="sec2.7">
      <title>2.7. ViSta</title>
      <p>ViSta stands for Visual Statistics System and can be used for multivariate data analysis and visualization in order to provide a better understanding of the data [<xref rid="B63" ref-type="bibr">13</xref>]. This software is based on the Lisp-Stat system [<xref rid="B50" ref-type="bibr">44</xref>]. It is an open source system that can be freely distributed for multivariate analysis and visualization. PCA and multiple and simple CA are provided in this software. Its main advance is that the data analysis is guided in a visualization environment in order to generate more reliable and accurate results. The four state-of-the-art visualization methods offered by this software are GuideMaps [<xref rid="B64" ref-type="bibr">45</xref>], WorkMaps [<xref rid="B65" ref-type="bibr">46</xref>], Dynamic Statistical Visualization [<xref rid="B66" ref-type="bibr">47</xref>], and Statistical Re-Vision [<xref rid="B44" ref-type="bibr">48</xref>]. The plug-ins for PCA can be downloaded from <ext-link ext-link-type="uri" xlink:href="http://www.mdp.edu.ar/psicologia/vista/vista.htm">http://www.mdp.edu.ar/psicologia/vista/vista.htm</ext-link>. An example of implementation of the analysis using PCA can be viewed in Valero-Mora and Ledesma [<xref rid="B61" ref-type="bibr">49</xref>]. This software can be installed on Windows, Unix, and Macintosh.</p>
    </sec>
    <sec id="sec2.8">
      <title>2.8. imDEV</title>
      <p>Interactive Modules for Data Exploration and Visualization (imDEV) [<xref rid="B22" ref-type="bibr">14</xref>] is an application of RExcel that integrates R and Excel for the analysis, visualization, and exploration of multivariate data. It is used in Microsoft Excel as add-ins by using an R package. Basically, it is implemented in Visual Basic and R. In this software, numerous dimension reduction methods are provided such as PCA, ICA, PLS regression, and Discriminant Analysis. Besides that, this software also offers clustering, imputing of missing values, feature selection, and data visualization. The 2 × 3 visualization methods are offered such as dendrograms, distribution plots, biplots, and correlation networks. This software is compatible with a few versions of Microsoft Excel such as Excel 2007 and 2010.</p>
    </sec>
    <sec id="sec2.9">
      <title>2.9. Statistics Toolbox</title>
      <p>Statistical Toolbox offers a variety of algorithms and tools for data modelling and data analysis. Multivariate data analysis methods are offered by this toolbox. The methods include PCA, clustering, dimension reduction, factor analysis, visualization, and others. In the statistical toolbox of MATLAB, several PCA functions are provided for multivariate analysis, for example,<italic> pcacov</italic>,<italic> princomp</italic>, and<italic> pcares</italic> (MathWorks). Most of these functions are used for dimensional reduction.<italic> pcacov</italic> is used for covariance matrices,<italic> princomp</italic> for raw data matrices, and<italic> pcares</italic> for residuals from PCA. All of these functions are implemented in MATLAB.</p>
    </sec>
    <sec id="sec2.10">
      <title>2.10. Weka</title>
      <p>Weka [<xref rid="B24" ref-type="bibr">16</xref>] is data mining software that provides a variety of machine learning algorithms. This software offers feature selection, data preprocessing, regression, classification, and clustering methods [<xref rid="B19" ref-type="bibr">50</xref>]. This software is implemented in a Java environment. PCA is used as a dimension reduction method in Weka to reduce the dimensionality of complex data through transformation. However, not all of the datasets are complete. Prabhume and Sathe [<xref rid="B52" ref-type="bibr">51</xref>] introduced a new filter PCA for Weka in order to solve the problem of incomplete datasets. It works by estimating the complete dataset from the incomplete dataset. This software is mainly for Windows, Linux, and MacOS.</p>
    </sec>
    <sec id="sec2.11">
      <title>2.11. NAG Library</title>
      <p>In NAG Library, the function of PCA is provided as the g03aa routine [<xref rid="B46" ref-type="bibr">17</xref>] in both C and Fortran. This routine performs PCA on data matrices. This software was developed by the Numerical Algorithms Group. In the NAG Library, more than 1700 algorithms are offered for mathematical and statistical analysis. For PCA, it is suitable for multivariate methods, G03. Other methods provided are correlation analysis, wavelet transforms, and partial differential equations. Please refer to <ext-link ext-link-type="uri" xlink:href="http://www.nag.com/numeric/MB/manual_22_1/pdf/G03/g03aa.pdf">http://www.nag.com/numeric/MB/manual_22_1/pdf/G03/</ext-link>
<ext-link ext-link-type="uri" xlink:href="http://www.nag.com/numeric/MB/manual_22_1/pdf/G03/g03aa.pdf">g03aa.pdf</ext-link> for further details about the g03aaa routine. This software can be installed on Windows, Linux, MacOS, AIX, HP UX, and Solaris.</p>
    </sec>
    <sec id="sec2.12">
      <title>2.12. Case Study</title>
      <p>In this section, we will discuss the implementation of coinertia analysis (CIA) to cross-platform visualization in<italic> MADE4</italic> and<italic> ADE4</italic> to perform multivariate analysis of microarray datasets. To demonstrate, PCA was applied on 4 childhood tumors (NB, BL-NHL, EWS, and RMS) from a microarray gene expression profiling study [<xref rid="B34" ref-type="bibr">52</xref>]. From these data, a subset (<italic>khan$train</italic>, 206 genes × 64 cases), each case's factor denoting the respective class (<italic>khan$train</italic> classes, length = 64), and a gene annotation's data frame are accessible in aforementioned dataset in MADE4:<list list-type="simple"><list-item><label> </label><p><italic>&lt; library (made4)</italic></p></list-item><list-item><label> </label><p><italic>&lt; data (khan)</italic></p></list-item><list-item><label> </label><p><italic>&lt; dataset = khan$train</italic></p></list-item><list-item><label> </label><p><italic>&lt; fac = khan$train.classes</italic></p></list-item><list-item><label> </label><p><italic>&lt; geneSym = khan$annotation$Symbol</italic></p></list-item><list-item><label> </label><p><italic>&lt; results.coa &lt;- ord (dataset, type = “coa”)</italic></p></list-item><list-item><label> </label><p><italic>&lt; par (mfrow = c (1, 2))</italic></p></list-item><list-item><label> </label><p><italic>&lt; plotarrays (results.coa, classvec = fac)</italic></p></list-item><list-item><label> </label><p><italic>&lt; plotgenes (results.coa, genelabels = geneSym).</italic></p></list-item></list>
<xref ref-type="fig" rid="fig1">Figure 1</xref> shows the PCA of a 306-gene subset. As origin as the point of reference, the more advanced gene and case are projected in the similar direction, the stronger the association between involved gene and case is (gene is upregulated in that array sample).</p>
    </sec>
    <sec id="sec2.13">
      <title>2.13. Summary of PCA Software</title>
      <p>Tables <xref ref-type="table" rid="tab1">1</xref> and <xref ref-type="table" rid="tab2">2</xref> show the summary and sources of PCA software, respectively. <xref ref-type="table" rid="tab3"> Table 3</xref> discusses the related work of this software.</p>
    </sec>
  </sec>
  <sec id="sec3">
    <title>3. Software for Independent Component Analysis (ICA)</title>
    <p>ICA is considered as a valuable extension of PCA that has been established considering the blind separation of independent sources from their linear combination [<xref rid="B68" ref-type="bibr">53</xref>]. In a way, the initial point of ICA is the property of uncorrelation of general PCA. Based on <italic>n</italic> × <italic>p</italic> data matrix <italic>X</italic>, whose rows <italic>r</italic>
<sub><italic>i</italic></sub>  (<italic>j</italic> = 1,…, <italic>n</italic>) tally to observational variables and whose columns <italic>c</italic>
<sub><italic>j</italic></sub>  (<italic>j</italic> = 1,…, <italic>p</italic>) are the individuals of the corresponding variables, the ICA model of <italic>X</italic> can be written as
<disp-formula id="EEq4"><label>(4)</label><mml:math id="M4"><mml:mtable><mml:mtr><mml:mtd><mml:mi>X</mml:mi><mml:mo>=</mml:mo><mml:mi>A</mml:mi><mml:mi>S</mml:mi><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>
With generality intact, <italic>A</italic> is a <italic>n</italic> × <italic>n</italic> mixing matrix, whereas <italic>S</italic> is a <italic>n</italic> × <italic>p</italic> source matrix under the necessity of <italic>S</italic> being statistically independent as possible. “Independent components” are the new variables confined in the rows of <italic>S</italic>, to wit, the variables observed are linearly collected independent components. Mutual information <italic>I</italic> = ∑<sub><italic>k</italic></sub>
<italic>H</italic>(<italic>S</italic>
<sub><italic>k</italic></sub>) − <italic>H</italic>(<italic>S</italic>), where <italic>H</italic>(<italic>S</italic>
<sub><italic>k</italic></sub>) = −∫<italic>p</italic>(<italic>S</italic>
<sub><italic>k</italic></sub>)log⁡⁡<italic>p</italic>(<italic>S</italic>
<sub><italic>k</italic></sub>)<italic>ds</italic>
<sub><italic>k</italic></sub> is the marginal entropy of the variables <italic>S</italic>
<sub><italic>k</italic></sub>, <italic>p</italic>(<italic>S</italic>
<sub><italic>k</italic></sub>) is the probabilistic density function, and <italic>H</italic>(<italic>S</italic>) is the joint entropy [<xref rid="B28" ref-type="bibr">54</xref>]. Value the independent components able to be attained by discovering the correct linear mixtures of the observational variables, since mixing can be inverted as
<disp-formula id="EEq5"><label>(5)</label><mml:math id="M5"><mml:mtable><mml:mtr><mml:mtd><mml:mi>U</mml:mi><mml:mo>=</mml:mo><mml:mi>S</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn mathvariant="normal">1</mml:mn></mml:mrow></mml:msup><mml:mi>X</mml:mi><mml:mo>=</mml:mo><mml:mi>W</mml:mi><mml:mi>X</mml:mi><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>
</p>
    <sec id="sec3.1">
      <title>3.1. FastICA</title>
      <p>FastICA is the most widely used method of ICA [<xref rid="B67" ref-type="bibr">55</xref>]. It is implemented in an R environment as the R package “FastICA” for performing ICA and Projection Pursuit by using the FastICA algorithm. FastICA was first introduced by Hyvärinen [<xref rid="B28" ref-type="bibr">54</xref>] for single and multiple component extraction. The FastICA algorithm is based on a fixed-point iteration scheme maximizing non-Gaussianity as a measure of statistical independence. This package is maintained by Marchini et al. [<xref rid="B41" ref-type="bibr">18</xref>]. ICA is used to extract the informative features through a transformation of the observed multidimensional random vectors into independent components. This package is mainly for Windows, Linux, and MacOS. FastICA is also implemented in MATLAB. In MATLAB, FastICA implements a fast fixed-point algorithm for ICA as well as projection pursuit. It provides a simple user interface and also a powerful algorithm for computation.</p>
    </sec>
    <sec id="sec3.2">
      <title>3.2. JADE</title>
      <p>JADE is an R package that provides a function for implementing ICA. This package is maintained by Nordhausen et al. [<xref rid="B47" ref-type="bibr">19</xref>]. In this package, Cardoso's JADE algorithm [<xref rid="B11" ref-type="bibr">56</xref>] is provided for ICA. Instead of the JADE algorithm, other Blind Source Separation (BSS) methods such as the SOBI [<xref rid="B7" ref-type="bibr">57</xref>] and AMUSE [<xref rid="B51" ref-type="bibr">58</xref>] methods are offered. Both of these methods are mainly used for solving second order BSS problems. Amari error [<xref rid="B2" ref-type="bibr">59</xref>] is offered to evaluate the performance of the ICA algorithm. This package can be installed on Linux, Windows, and MacOS.</p>
    </sec>
    <sec id="sec3.3">
      <title>3.3. High Performance Signal Analysis Tools (HiPerSAT)</title>
      <p>HiPerSAT is written in C++ for processing electroencephalography (EEG) data with whitening of data and ICA [<xref rid="B33" ref-type="bibr">20</xref>]. MPI and OpenMP are used to perform parallel analysis of ICA. Basically, this software is used to analyse EEG data in order to understand the neurological components of brain activity. In this software, FastICA, SOBI, and Informax algorithms are offered. HiPerSAT is integrated into MATLAB and EEGLAB [<xref rid="B16" ref-type="bibr">60</xref>]. EEGLAB is MATLAB-based software that is used for analysing EEG data. However, the advantage of HiPerSAT is that it can handle larger datasets compared to MATLAB. In comparison to EEGLAB, HiPerSAT is able to handle large datasets without partitioning but EEGLAB requires data partitioning. Data whitening is performed before implementing the algorithms. This software can be installed on all platforms.</p>
    </sec>
    <sec id="sec3.4">
      <title>3.4. MineICA</title>
      <p>MineICA is an R package that supplies the implementation of ICA on transcriptomic data [<xref rid="B10" ref-type="bibr">21</xref>]. The main purpose of MineICA is to provide an easier way of interpreting the decomposition results from ICA. Besides that, this software also provides a correlation-based graph for comparing the components from different datasets. The newest version of this package is maintained by Biton [<xref rid="B9" ref-type="bibr">61</xref>]. This package provides some features such as storage of ICA results, annotation of features, and visualization of the results of ICA. This package can be installed on Linux, MacOS, and Windows.</p>
    </sec>
    <sec id="sec3.5">
      <title>3.5. Pearson Independent Component Analysis</title>
      <p>Karnanen [<xref rid="B32" ref-type="bibr">22</xref>] developed an R package for a feature extraction technique based on the Pearson ICA algorithm. This is a mutual information-based blind source separation approach which applies the Pearson system as a parametric model. In order to extract the independent components using the ICA algorithm, the mutual information of the components has to be minimized. However minimization of mutual information is required to use a score function. The Pearson system was used to model the score function. The parameters of the Pearson system are estimated by the method of moments. In order to speed up the algorithm, tanh nonlinearity is used when the distribution is far from Gaussian.</p>
    </sec>
    <sec id="sec3.6">
      <title>3.6. Maximum Likelihood Independent Component Analysis</title>
      <p>Teschenforff [<xref rid="B48" ref-type="bibr">23</xref>] developed an R package for ICA by using maximum likelihood estimation. This method was first introduced by Hyvaerinen et al. [<xref rid="B29" ref-type="bibr">62</xref>]. This method uses a fixed-point algorithm as the Maximum Likelihood estimation. For a fixed set of data and underlying statistical model, Maximum Likelihood selects the set of values of the model parameters that maximizes the likelihood function. Maximum Likelihood estimation gives a unified approach to estimation, which is well-defined in the case of normal distribution. By using a maximum likelihood framework and controlling the number of algorithm runs, this fixed-point algorithm provides a very fast implementation for maximization of likelihood.</p>
    </sec>
    <sec id="sec3.7">
      <title>3.7. Sample Case Study</title>
      <p>In this section, we utilize<italic> MineICA</italic> for microarray-based gene expression data of 200 breast cancer tumors kept in the package<italic> breastCancerMAINZ</italic> [<xref rid="B58" ref-type="bibr">63</xref>] based on a study done by Biton et al. [<xref rid="B10" ref-type="bibr">21</xref>]. In this study, we focused on how<italic> MineICA</italic> can be utilized to study an ICA-based decomposition. Pseudo code for this case study is as follows:<list list-type="order"><list-item><p>Loading the library and the data</p></list-item><list-item><p>Creation of an<italic> IcaSet</italic> object</p><p><list list-type="simple"><list-item><label>(2.1)</label><p>Load an example of expression data</p></list-item><list-item><label>(2.2)</label><p>Run ICA</p></list-item><list-item><label>(2.3)</label><p>Create a<italic> MineICAParams</italic> object, function<italic> buildMineICAParams</italic>
</p></list-item><list-item><label>(2.4)</label><p>Create an<italic> IcaSet</italic> instance, function<italic> buildIcaSet</italic>
</p></list-item><list-item><label>(2.5)</label><p><italic>IcaSet</italic> basics</p></list-item></list></p></list-item><list-item><p>Run global analysis</p></list-item><list-item><p>Run analysis by calling individual functions</p><p><list list-type="simple"><list-item><label>(4.1)</label><p>Write description of contributing genes or features, function<italic> writeProjByComp</italic>
</p></list-item><list-item><label>(4.2)</label><p>Plot heatmaps of the contributing elements, function<italic> plot_heatmapsOnSel</italic>
</p></list-item><list-item><label>(4.3)</label><p>Gene enrichment analysis, function<italic> runEnrich</italic>
</p></list-item><list-item><label>(4.4)</label><p>Association with sample variables</p></list-item><list-item><label>(4.5)</label><p>Clustering of the samples according to each component</p></list-item><list-item><label>(4.6)</label><p>Comparison of<italic> IcaSet</italic> objects, function<italic> runCompareIcaSets.</italic>
</p></list-item></list></p></list-item></list>
<xref ref-type="fig" rid="fig2">Figure 2</xref> explains the correlation based graph denoting relationship between independent components (IC) attained on four breast cancer samples' microarray data. Every node represents an IC and respective colors denote the origin of dataset. Thickness of edge represents the extent of correlation among the linked ICs. Black edges represent reciprocal nodes.</p>
    </sec>
    <sec id="sec3.8">
      <title>3.8. Summary of ICA Software</title>
      <p>Tables <xref ref-type="table" rid="tab4">4</xref> and <xref ref-type="table" rid="tab5">5</xref> show the summary and sources of ICA software, respectively.</p>
    </sec>
  </sec>
  <sec id="sec4">
    <title>4. Software for Partial Least Squares (PLS)</title>
    <p>The fundamental hypothesis of PLS is that the experimental information is created by a framework or methodology which is determined by a small number of latent characteristics. Thusly, PLS goes for discovering uncorrelated linear transformation of the initial indicator characteristics which have high covariance with the reaction characteristics. In light of these latent components, PLS predicts reaction characteristics <italic>y</italic>, the assignment of regression, and reproduce initial matrix <italic>X</italic>, the undertaking of data modelling, in the meantime. The purpose of building components in PS is to optimize the covariance among the variable <italic>y</italic> and the initial predictor variables <italic>X</italic>:
<disp-formula id="EEq6"><label>(6)</label><mml:math id="M6"><mml:mtable><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>q</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mtext>argmax</mml:mtext></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtext>Cov</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msup><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mi>w</mml:mi><mml:mo>=</mml:mo><mml:mn mathvariant="normal">1</mml:mn><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>
Restricted to constraint <italic>w</italic>
<sub><italic>i</italic></sub>
<sup><italic>T</italic></sup>
<italic>S</italic>
<sub><italic>x</italic></sub>
<italic>w</italic>
<sub><italic>j</italic></sub> = 0, for all 1 ≤ <italic>i</italic> &lt; <italic>j</italic>. The crucial assignment of PLS is to attain the vectors of maximum weights <italic>w</italic>
<sub><italic>i</italic></sub>  (<italic>i</italic> = 1,…, <italic>q</italic>) to build a small number of components, while PCA is an “unsupervised” method that utilizes the <italic>X</italic> data only. To develop the components, [<italic>t</italic>
<sub>1</sub>, <italic>t</italic>
<sub>2</sub>,…, <italic>t</italic>
<sub><italic>q</italic></sub>], PLS decomposes <italic>X</italic> and <italic>y</italic> to yield a bilinear denotation of the data [<xref rid="B69" ref-type="bibr">64</xref>]:
<disp-formula id="EEq7"><label>(7)</label><mml:math id="M7"><mml:mtable><mml:mtr><mml:mtd><mml:mi>X</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mn mathvariant="normal">1</mml:mn></mml:mrow></mml:msub><mml:msubsup><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mn mathvariant="normal">1</mml:mn></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mn mathvariant="normal">2</mml:mn></mml:mrow></mml:msub><mml:msubsup><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mn mathvariant="normal">2</mml:mn></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mo>⋯</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>q</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mi>e</mml:mi><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mn mathvariant="normal">1</mml:mn></mml:mrow></mml:msub><mml:msubsup><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mn mathvariant="normal">1</mml:mn></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mn mathvariant="normal">2</mml:mn></mml:mrow></mml:msub><mml:msubsup><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mn mathvariant="normal">2</mml:mn></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mo>⋯</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mi>f</mml:mi><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>
where <italic>w</italic>'s are vectors of weights for building the PLS components <italic>t</italic> = <italic>X</italic>
<sub><italic>w</italic></sub>, <italic>v</italic>'s are scalars, and <italic>e</italic> and <italic>f</italic> are the residuals. The concept of PLS is to assume <italic>w</italic> and <italic>v</italic> by regression.</p>
    <sec id="sec4.1">
      <title>4.1. Partial Least Squares Discriminant Analysis</title>
      <p>Barker and Rayens [<xref rid="B4" ref-type="bibr">24</xref>] developed a PLS for discriminant analysis. However the original PLS was not designed for discriminant purposes. PLS Discriminant Analysis is used to find a linear regression model by projecting the dependent features and the independent features to a new space. Then the fundamental relations can be extracted from the latent variables. This method was developed for software called Unscrambler, which was first developed by Martens and Naes [<xref rid="B42" ref-type="bibr">65</xref>]. Unscrambler is a commercial software product for multivariate data analysis. Unscrambler is used for analysing large and complex datasets quickly and easily using the power of multivariate analysis. Moreover this multivariate data analysis also offers exceptional data visualization.</p>
    </sec>
    <sec id="sec4.2">
      <title>4.2. Least Squares: Partial Least Squares</title>
      <p>Jørgensen et al. [<xref rid="B30" ref-type="bibr">25</xref>] proposed a method of using an iterative combination of PLS and ordinary least squares to extract the relationship between the predictor variable and the responses. This method is based on a combination of least squares estimates for the design variables and PLS regression on the spectra. The PLS scores were incorporated into the ordinary least squares equation on the spectra. The idea is to separate the information from the spectral and design matrices in a nice way. However this method is able to extract the information even when fewer components are used. In addition, this method is insensitive to the relative scaling of the spectra and the process. Moreover this combination method is also less biased than the individual PLS technique.</p>
    </sec>
    <sec id="sec4.3">
      <title>4.3. Powered Partial Least Squares Discriminant Analysis</title>
      <p>Liland and Indahl [<xref rid="B39" ref-type="bibr">26</xref>] extended the Powered PLS to Powered PLS Discriminant Analysis to overcome the extraction of information for the multivariate classification problem. This method can construct more efficient group separation and generate more interpretive outcomes than the ordinary Partial Least Square Discriminant Analysis technique. The features extracted by the Powered PLS can contribute to revealing the relevance of particular predictors and often requires smaller and simpler components than ordinary PLS. Moreover the optimization task is equivalent to maximizing the correlation between the transformed predictors and the groups. This makes it possible to discard the influence of less important predictors. This method was also developed by the authors for availability in an R package.</p>
    </sec>
    <sec id="sec4.4">
      <title>4.4. Penalized Partial Least Squares</title>
      <p>
Krämer et al. [<xref rid="B35" ref-type="bibr">27</xref>] proposed a combination of the feature extraction technique PLS with a penalization framework. This method is an extension of PLS regression using a penalization technique. Ordinary PLS is suited for regression problems by minimizing a quadratic loss function iteratively. In addition, the representation in terms of kernel matrices provides an intuitive geometric interpretation of the penalty term. The penalty terms control the roughness of the estimated functions. With the incorporation of penalization into this framework, the research direction became more promising. This method is used to extract relevant information for high-dimensional regression problems and also for noisy data. This method was also developed by the Krämer and her colleagues colleagues [<xref rid="B70" ref-type="bibr">66</xref>] for availability in an R package.</p>
    </sec>
    <sec id="sec4.5">
      <title>4.5. SlimPLS</title>
      <p>Gutkin et al. [<xref rid="B23" ref-type="bibr">33</xref>] proposed a feature extraction method based on PLS called SlimPLS. Ranking-based filters usually utilize a univariate method when selecting features. The filter methods can produce reasonable feature sets especially when the original feature sets are uncorrelated. However the chosen feature set will be suboptimal when the features of the original set are dependent. Some of the features will add little discriminative power on top of previously selected features. SlimPLS is a multivariate feature extraction method which incorporates feature dependencies into calculation. This multivariate property is constructed by combining the highly predictive feature with some less predictive but correlated features. This is because the added features will provide more information on the behaviour of the samples.</p>
    </sec>
    <sec id="sec4.6">
      <title>4.6. Sparse Partial Least Squares Discriminant Analysis and Sparse Generalized Partial Least Squares</title>
      <p>Chung and Keles [<xref rid="B13" ref-type="bibr">28</xref>] proposed two extension feature extraction approaches based on Sparse PLS. These approaches are Sparse PLS Discriminant Analysis and Sparse Generalized PLS for high-dimensional datasets. These two approaches improved ordinary PLS by employing feature extraction and dimension reduction simultaneously. These two approaches perform well even with unbalanced sample sizes of the classes. Sparse PLS Discrimination Analysis is computationally efficient because it only requires computational time for one run of Sparse PLS and a classifier. Moreover, Sparse Generalized PLS extends Sparse PLS to the generalized linear model framework. These methods were also developed by Chung and Keles for availability in an R package.</p>
    </sec>
    <sec id="sec4.7">
      <title>4.7. Degrees of Freedom of Partial Least Squares</title>
      <p>Kramer and Sugiyama [<xref rid="B36" ref-type="bibr">29</xref>] proposed a method of unbiased estimation of the degrees of freedom for PLS regression. The authors stated that the construction of latent components from the independent variable also depended on the dependent variable. However for PLS regression, the optimal number of components needs to be determined first. One of the ways of determining the optimal number of components is through the degrees of freedom for the complexity of fitted models. Moreover the degrees of freedom estimate can be used for the comparison of different regression methods. Furthermore, the two implementations for the degrees of freedom utilize the connection between PLS regression and numerical linear methods from numerical linear. The authors also developed an R package for this unbiased estimation of the degrees of freedom of PLS.</p>
    </sec>
    <sec id="sec4.8">
      <title>4.8. Surrogate Variable Analysis Partial Least Squares</title>
      <p>
Chakraborty and Datta [<xref rid="B12" ref-type="bibr">30</xref>] proposed a surrogate variable analysis method based on PLS. In differential gene expression analysis, one of the important issues is to avoid the hidden confounders in the dataset. The hidden confounders of gene expression are caused by different environmental conditions of the samples. However this problem cannot be simply overcome by modifying the gene expression data by using a normalizing technique. This method can extract the informative features by identifying the hidden effects of the underlying latent factors using ordinary PLS and applying analysis of covariance (ANCOVA). ANCOVA is applied with the PLS signatures of these hidden effects as covariates in order to identify the genes that are truly differentially expressed. This method was also developed by the authors for availability in an R package.</p>
    </sec>
    <sec id="sec4.9">
      <title>4.9. Partial Least Squares Path Modelling</title>
      <p>Sanchez and Trinchera [<xref rid="B57" ref-type="bibr">31</xref>] developed an R package for Partial Least Squares Path Modelling (PLS-PM). PLS-PM was first introduced by Wold [<xref rid="B43" ref-type="bibr">67</xref>] and is also known as Structural Equation Modelling (SEM). It can be used as a composite-based alternative to factor-based SEM. PLS-PM can be used when the distributions are highly skewed. Moreover, PLS-PM can also be used to estimate relationships between latent variables with several indicators even though the sample size is small. Basically, PLS-PM consists of two sets of linear equations: the inner model and the outer model. The inner model specifies the relations between latent variables, while the outer model specifies the relations between a latent variable and its observed indicator. PLS-PM is a multivariate feature extraction analysis technique based on the cause-effect relationships of the unobserved and observed features.</p>
    </sec>
    <sec id="sec4.10">
      <title>4.10. Partial Least Squares Regression for Generalized Linear Models</title>
      <p>Bertrand et al. [<xref rid="B8" ref-type="bibr">32</xref>] developed a software application of PLS regression for generalized linear models. Generalized linear models are important to allow the response features to have a distribution other than normal. Generalized linear models can be viewed as a case of generalized linear models with an identity link. From the perspective of generalized linear models, however, it is useful to suppose that the distribution function is the normal distribution with constant variance and the link function is the identity, which is the canonical link if the variance is known. However, the generalized linear models preserve all the predictive power of the features where the predicted means are not assumed to be normally distributed. PLS regression is used to extract the predictive features from the generalized linear models.</p>
    </sec>
    <sec id="sec4.11">
      <title>4.11. Case Study</title>
      <p>In this section, we will discuss the R package consists of svpls. This function will call fitModel function in order to appropriate a number of ANCOVA models that are identified by pmax to the data and opt for the best model by looking the minimum value of the Akaike's information Criterion (AIC) [<xref rid="B1" ref-type="bibr">68</xref>]. Subsequently, this model is utilized to forecast the real pattern of genes' differential expression. The command lines in R are as follows:<list list-type="simple"><list-item><label> </label><p>&gt; ## Fitting the optimal ANCOVA model to the data gives:</p></list-item><list-item><label> </label><p>&gt; fit &lt;-svpls (10, 10, hidden_fac.dat, pmax = 5, fdr = 0.05)</p></list-item><list-item><label> </label><p>&gt; ## The optimal ANCOVA model, its AIC value and the positive genes detected</p></list-item><list-item><label> </label><p>&gt; ## from it are givenL</p></list-item><list-item><label> </label><p>&gt; fit$opt.model [1]</p></list-item><list-item><label> </label><p>&gt; fit$AIC.opt [1]</p></list-item><list-item><label> </label><p>&gt; fit$genes</p></list-item><list-item><label> </label><p>&gt; ## The corrected gene expression matrix obtained after removing the effects of the hidden variability is given by:</p></list-item><list-item><label> </label><p>&gt; Y.corrected &lt;- fit$Y.corr</p></list-item><list-item><label> </label><p>&gt; pval.adj &lt;-fit$pvalues.adj.</p></list-item></list>For instance, we study the efficacy of svapls on ALL/AML preprocessed dataset [<xref rid="B21" ref-type="bibr">69</xref>]. This data consists of expression levels of 7129 genes that have been log-transformed over two samples of patients. These two sets of 47 patients and 25 patients reported to suffer from Acute lymphoblastic Leukemia (ALL) and Acute Myeloid Leukemia (AML), respectively. By using svpls function, we yielded initial 1000 genes with corrected expression matrix. Random samples' distribution from four sources in the abovementioned matrix removes the extra effects owing to reported batch specific clustering in the initial data. In this context svapls performed equally efficient relative to another popular R package ber for removing batch effects in microarray data as shown in <xref ref-type="fig" rid="fig3">Figure 3</xref>.</p>
    </sec>
    <sec id="sec4.12">
      <title>4.12. Summary of PLS Software</title>
      <p>
Tables <xref ref-type="table" rid="tab6">6</xref> and <xref ref-type="table" rid="tab7">7</xref> show the summary and sources of PLS software, respectively. <xref ref-type="table" rid="tab8"> Table 8</xref> shows the related works on discussed software.</p>
    </sec>
  </sec>
  <sec id="sec5">
    <title>5. Software for Local Linear Embedding (LLE)</title>
    <p>Straightforward geometric intuitions are the basis for LLE algorithm. Assume that given data comprise of <italic>N</italic> real-valued vectors <italic>X</italic>
<sub><italic>i</italic></sub>, for each <italic>D</italic> dimensionality, tested by some core manifold. Given that there is adequate data, every data point and their neighbors are expected to be situated on or near to a locally linear patch of the manifold. Abovementioned patches are described by linear coefficients that rebuild every data point from respective neighbors. Equation (<xref ref-type="disp-formula" rid="EEq9">8</xref>) is the cost function used to calculate reconstruction errors which sums the squared distances between all the data points and their reconstructions. The weights <italic>W</italic>
<sub><italic>ij</italic></sub> summarize the contribution of the <italic>j</italic>th data point to the <italic>i</italic>th reconstruction. The optimal weights <italic>W</italic>
<sub><italic>ij</italic></sub> are found by solving a least-squares problem [<xref rid="B71" ref-type="bibr">70</xref>]:
<disp-formula id="EEq9"><label>(8)</label><mml:math id="M8"><mml:mtable><mml:mtr><mml:mtd><mml:mi>ϵ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:munderover><mml:mstyle displaystyle="true"><mml:mo stretchy="false">∑</mml:mo></mml:mstyle><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn mathvariant="normal">1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mrow><mml:munderover><mml:mstyle displaystyle="true"><mml:mo stretchy="false">∑</mml:mo></mml:mstyle><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn mathvariant="normal">1</mml:mn></mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mn mathvariant="normal">2</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:munder><mml:mstyle displaystyle="true"><mml:mo stretchy="false">∑</mml:mo></mml:mstyle><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn mathvariant="normal">1</mml:mn></mml:mrow></mml:munder><mml:mrow><mml:msup><mml:mrow><mml:mi>ϵ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>
<disp-formula id="EEq10"><label>(9)</label><mml:math id="EEq10EBAAAFBCA"><mml:mtable><mml:mtr><mml:mtd><mml:msup><mml:mrow><mml:mi>ϵ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:mrow><mml:munderover><mml:mstyle displaystyle="true"><mml:mo stretchy="false">∑</mml:mo></mml:mstyle><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn mathvariant="normal">1</mml:mn></mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:msubsup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:munderover><mml:mstyle displaystyle="true"><mml:mo stretchy="false">∑</mml:mo></mml:mstyle><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn mathvariant="normal">1</mml:mn></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:mo> </mml:mo><mml:mrow><mml:munderover><mml:mstyle displaystyle="true"><mml:mo stretchy="false">∑</mml:mo></mml:mstyle><mml:mrow><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mn mathvariant="normal">1</mml:mn></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:msubsup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>
<disp-formula id="EEq11"><label>(10)</label><mml:math id="EEq11EAAAAFBCA"><mml:mtable><mml:mtr><mml:mtd><mml:msubsup><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>
</p>
    <sec id="sec5.1">
      <title>5.1. lle</title>
      <p>An R package “lle” has been developed in order to implement LLE for feature extraction. This package provides the algorithm of LLE in order to transform high-dimensional data into low-dimensional data. The newest version of this package is maintained by Diedrich and Abel [<xref rid="B17" ref-type="bibr">34</xref>]. The main functions of this package allow users to perform LLE and also to plot the results of LLE. The implementation of LLE is based on the idea of Ridder and Duin [<xref rid="B55" ref-type="bibr">71</xref>]. Besides that, some enhancements such as selection of the subset and calculation of the intrinsic dimension are offered. This package can be installed on Windows, Linux, and MacOS.</p>
    </sec>
    <sec id="sec5.2">
      <title>5.2. RDRToolbox</title>
      <p>RDRToolbox is an R package developed for nonlinear dimension reduction with LLE and Isomap. The package is maintained by Bartenhagen [<xref rid="B5" ref-type="bibr">35</xref>]. It offers the transformation of high-dimensional to low-dimensional data by using either LLE or Isomap. Besides that, a plotting function is provided to plot the results. In addition, the Davis-Bouldin Index is provided for the purposes of validating clusters. It is mainly for Linux, MacOS, and Windows.</p>
    </sec>
    <sec id="sec5.3">
      <title>5.3. Scikit-Learn</title>
      <p>Scikit-learn is software implemented in Python by integrating machine learning algorithms [<xref rid="B53" ref-type="bibr">36</xref>]. It is a simple-to-use software that allows users to implement a variety of machine learning algorithms. The machine learning algorithms include classification, clustering, feature extraction, model selection, manifold learning, and other methods. Isomap, LLE, and Local Tangent Space Alignment (LTSA) are provided by this software. Please see <ext-link ext-link-type="uri" xlink:href="http://scikit-learn.org/stable/">http://scikit-learn.org/stable/</ext-link> for further details. This software can be installed on a variety of platforms such as Windows and Ubuntu.</p>
    </sec>
    <sec id="sec5.4">
      <title>5.4. Case Study</title>
      <p>This section demonstrates the dimension reduction workflow for the publicly available the Golub et al. leukemia dataset (see <xref ref-type="fig" rid="fig5">Figure 5</xref>). The data is available as R package and can be downloaded and loaded via<list list-type="simple"><list-item><label> </label><p>&gt; source (“<ext-link ext-link-type="uri" xlink:href="http://bioconductor.org/biocLite.R">http://bioconductor.org/biocLite.R</ext-link>”)</p></list-item><list-item><label> </label><p>&gt; biocLite (“golubEsets”)</p></list-item><list-item><label> </label><p>&gt; library (golubEsets)</p></list-item><list-item><label> </label><p>&gt; data (Golub_Merge).</p></list-item></list>The dataset consists of 72 samples, divided into 47 ALL and 25 AML patients, and 7129 expression values. In this example, we compute a two-dimensional LLE and Isomap embedding and plot the results. At first, we extract the features and class labels:<list list-type="simple"><list-item><label> </label><p>&gt; golubExprs = t (exprs (Golub_Merge))</p></list-item><list-item><label> </label><p>&gt; labels = pData (Golub_Merge)$ALL.AML</p></list-item><list-item><label> </label><p>&gt; dim (golubExprs).</p></list-item></list>The residual variance of Isomap can be used to estimate the intrinsic dimension of the dataset:<list list-type="simple"><list-item><label> </label><p>&gt; Isomap (data = golubExprs, dims = 1 : 10, plotResiduals = TRUE, <italic>k</italic> = 5).</p></list-item></list>Based on <xref ref-type="fig" rid="fig4">Figure 4</xref>, regarding the dimensions for which the residual variances stop to decrease significantly, we can expect a low intrinsic dimension of two or three and, therefore, visualization true to the structure of the original data. Next, we compute the LLE and Isomap embedding for two target dimensions:<list list-type="simple"><list-item><label> </label><p>&gt; golubIsomap = Isomap (data = golubExprs, dims = 2, <italic>k</italic> = 5)</p></list-item><list-item><label> </label><p>&gt; golubLLE = LLE(data = golubExprs, dim = 2, <italic>k</italic> = 5).</p></list-item></list>The Davis-Bouldin-Index shows that the ALL and AML patients are well separated into two clusters:<list list-type="simple"><list-item><label> </label><p>&gt; DBIndex(data = golubIsomap$dim2, labels = labels)</p></list-item><list-item><label> </label><p>&gt; DBIndex(data = golubLLE, labels = labels).</p></list-item></list>Finally, we use plotDR to plot the two-dimensional data:<list list-type="simple"><list-item><label> </label><p>&gt; plotDR(data = golubIsomap$dim2, labels = labels, axesLabels = c(“”, “”), legend = TRUE)</p></list-item><list-item><label> </label><p>&gt; title (main = “Isomap”)</p></list-item><list-item><label> </label><p>&gt; plotDR (data = golubLLE, labels = labels, axesLabels = c(“”,“”), legend = TRUE)</p></list-item><list-item><label> </label><p>&gt; title (main = “LLE”).</p></list-item></list>Both visualizations, using either Isomap or LLE, show distinct clusters of ALL and AML patients, although the cluster overlaps less in the Isomap embedding. This is consistent with the DB-Index, which is very low for both methods, but slightly higher for LLE. A three-dimensional visualization can be generated in the same manner and is best analyzed interactively within R.</p>
    </sec>
    <sec id="sec5.5">
      <title>5.5. Summary of LLE Software</title>
      <p>Tables <xref ref-type="table" rid="tab9">9</xref> and <xref ref-type="table" rid="tab10">10</xref> show the summary and sources of LLE software, respectively. <xref ref-type="table" rid="tab11"> Table 11</xref> shows the related works in discussed software.</p>
    </sec>
  </sec>
  <sec id="sec6">
    <title>6. Conclusion</title>
    <p>Nowadays, numerous software applications have been developed to help users implement feature extraction of gene expression data. In this paper, we present a comprehensive review of software for feature extraction methods. The methods are PCA, ICA, PLS, and LLE. These software applications have some limitations in terms of statistical aspects as well as computational performance. In conclusion, there is a need for the development of better software.</p>
  </sec>
</body>
<back>
  <ack>
    <title>Acknowledgments</title>
    <p>The authors would like to thank Universiti Teknologi Malaysia for funding this research by Research University Grants (Grant nos. J130000.2628.08J80 and J130000.2507.05H50). The authors would also like to thank Research Management Centre (RMC), Universiti Teknologi Malaysia, for supporting this research.</p>
  </ack>
  <sec sec-type="conflict">
    <title>Conflict of Interests</title>
    <p>The authors declare that there is no conflict of interests regarding the publication of this paper.</p>
  </sec>
  <ref-list>
    <ref id="B56">
      <label>1</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Van Sanden</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Lin</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Burzykowski</surname>
            <given-names>T</given-names>
          </name>
        </person-group>
        <article-title>Performance of gene selection and classification methods in a microarray setting: a simulation study</article-title>
        <source>
          <italic>Communications in Statistics. Simulation and Computation</italic>
        </source>
        <year>2008</year>
        <volume>37</volume>
        <issue>1-2</issue>
        <fpage>409</fpage>
        <lpage>424</lpage>
        <pub-id pub-id-type="other">MR2422897</pub-id>
        <pub-id pub-id-type="other">ZBL1138.62362</pub-id>
        <pub-id pub-id-type="other">2-s2.0-38949117303</pub-id>
      </element-citation>
    </ref>
    <ref id="B38">
      <label>2</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Liu</surname>
            <given-names>Q</given-names>
          </name>
          <name>
            <surname>Sung</surname>
            <given-names>AH</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>Z</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Gene selection and classification for cancer microarray data based on machine learning and similarity measures</article-title>
        <source>
          <italic>BMC Genomics</italic>
        </source>
        <year>2011</year>
        <volume>12</volume>
        <issue>supplement 5, article S1</issue>
        <pub-id pub-id-type="other">2-s2.0-84255194463</pub-id>
      </element-citation>
    </ref>
    <ref id="B20">
      <label>3</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Gheorghe</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Mitrana</surname>
            <given-names>V</given-names>
          </name>
        </person-group>
        <article-title>A formal language-based approach in biology</article-title>
        <source>
          <italic>Comparative and Functional Genomics</italic>
        </source>
        <year>2004</year>
        <volume>5</volume>
        <issue>1</issue>
        <fpage>91</fpage>
        <lpage>94</lpage>
        <pub-id pub-id-type="other">2-s2.0-2942567941</pub-id>
        <pub-id pub-id-type="pmid">18629037</pub-id>
      </element-citation>
    </ref>
    <ref id="B25">
      <label>4</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Higgs</surname>
            <given-names>PG</given-names>
          </name>
          <name>
            <surname>Attwood</surname>
            <given-names>T</given-names>
          </name>
        </person-group>
        <article-title>Bioinformatics and molecular evolution</article-title>
        <source>
          <italic>Comparative and Functional Genomics</italic>
        </source>
        <year>2005</year>
        <volume>6</volume>
        <fpage>317</fpage>
        <lpage>319</lpage>
      </element-citation>
    </ref>
    <ref id="B37">
      <label>5</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lê</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Josse</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Husson</surname>
            <given-names>F</given-names>
          </name>
        </person-group>
        <article-title>FactoMineR: an R package for multivariate analysis</article-title>
        <source>
          <italic>Journal of Statistical Software</italic>
        </source>
        <year>2008</year>
        <volume>25</volume>
        <issue>1</issue>
        <fpage>1</fpage>
        <lpage>18</lpage>
        <pub-id pub-id-type="other">2-s2.0-46749110034</pub-id>
      </element-citation>
    </ref>
    <ref id="B27">
      <label>6</label>
      <element-citation publication-type="other">
        <person-group person-group-type="author">
          <name>
            <surname>Hussen</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Josse</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Le</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Mazet</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Package ‘FactoMineR’</article-title>
        <comment>2013, <ext-link ext-link-type="uri" xlink:href="http://cran.r-project.org/web/packages/FactoMineR/FactoMineR.pdf">http://cran.r-project.org/web/packages/FactoMineR/FactoMineR.pdf</ext-link></comment>
      </element-citation>
    </ref>
    <ref id="B26">
      <label>7</label>
      <element-citation publication-type="other">
        <person-group person-group-type="author">
          <name>
            <surname>Hoffmann</surname>
            <given-names>I</given-names>
          </name>
        </person-group>
        <article-title>Principal Component Analysis with FactoMineR</article-title>
        <comment>2010, <ext-link ext-link-type="uri" xlink:href="http://www.statistik.tuwien.ac.at/public/filz/students/seminar/ws1011/hoffmann_ausarbeitung.pdf">http://www.statistik.tuwien.ac.at/public/filz/students/seminar/ws1011/hoffmann_ausarbeitung.pdf</ext-link></comment>
      </element-citation>
    </ref>
    <ref id="B6">
      <label>8</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Beaton</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Fatt</surname>
            <given-names>CRC</given-names>
          </name>
          <name>
            <surname>Abdi</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <source>
          <italic>Package 'ExPosition'</italic>
        </source>
        <year>2013</year>
        <comment>
          <ext-link ext-link-type="uri" xlink:href="http://cran.r-project.org/web/packages/ExPosition/ExPosition.pdf">http://cran.r-project.org/web/packages/ExPosition/ExPosition.pdf</ext-link>
        </comment>
      </element-citation>
    </ref>
    <ref id="B40">
      <label>9</label>
      <element-citation publication-type="other">
        <person-group person-group-type="author">
          <name>
            <surname>Lucas</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Package ‘amap’</article-title>
        <comment>2013, <ext-link ext-link-type="uri" xlink:href="http://cran.r-project.org/web/packages/amap/vignettes/amap.pdf">http://cran.r-project.org/web/packages/amap/vignettes/amap.pdf</ext-link></comment>
      </element-citation>
    </ref>
    <ref id="B49">
      <label>10</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Thioulouse</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Chessel</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Dolédec</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Olivier</surname>
            <given-names>J-M</given-names>
          </name>
        </person-group>
        <article-title>ADE-4: a multivariate analysis and graphical display software</article-title>
        <source>
          <italic>Journal of Statistics and Computing</italic>
        </source>
        <year>1997</year>
        <volume>7</volume>
        <issue>1</issue>
        <fpage>75</fpage>
        <lpage>83</lpage>
        <pub-id pub-id-type="other">2-s2.0-0001878986</pub-id>
      </element-citation>
    </ref>
    <ref id="B15">
      <label>11</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Culhane</surname>
            <given-names>AC</given-names>
          </name>
          <name>
            <surname>Thioulouse</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Perriere</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Higgins</surname>
            <given-names>DG</given-names>
          </name>
        </person-group>
        <article-title>MADE4: an R package for multivariate analysis of gene expression data</article-title>
        <source>
          <italic>Bioinformatics</italic>
        </source>
        <year>2005</year>
        <volume>21</volume>
        <issue>11</issue>
        <fpage>2789</fpage>
        <lpage>2790</lpage>
        <pub-id pub-id-type="pmid">15797915</pub-id>
      </element-citation>
    </ref>
    <ref id="B62">
      <label>12</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Witten</surname>
            <given-names>IH</given-names>
          </name>
          <name>
            <surname>Frank</surname>
            <given-names>E</given-names>
          </name>
        </person-group>
        <source>
          <italic>Data Mining: Practical Machine Learning Tools and Techniques</italic>
        </source>
        <year>2005</year>
        <edition>2nd edition</edition>
        <publisher-name>Elsevier</publisher-name>
      </element-citation>
    </ref>
    <ref id="B63">
      <label>13</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Young</surname>
            <given-names>FW</given-names>
          </name>
          <name>
            <surname>Bann</surname>
            <given-names>CM</given-names>
          </name>
        </person-group>
        <person-group person-group-type="editor">
          <name>
            <surname>Stine</surname>
            <given-names>RA</given-names>
          </name>
          <name>
            <surname>Fox</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>ViSta: a visual statistics system</article-title>
        <source>
          <italic>Statistical Computing Environments for Social Research</italic>
        </source>
        <year>1992</year>
        <publisher-name>Sage</publisher-name>
        <fpage>207</fpage>
        <lpage>235</lpage>
      </element-citation>
    </ref>
    <ref id="B22">
      <label>14</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Grapov</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Newman</surname>
            <given-names>JW</given-names>
          </name>
        </person-group>
        <article-title>imDEV: a graphical user interface to R multivariate analysis tools in Microsoft Excel</article-title>
        <source>
          <italic>Bioinformatics</italic>
        </source>
        <year>2012</year>
        <volume>28</volume>
        <issue>17</issue>
        <fpage>2288</fpage>
        <lpage>2290</lpage>
        <pub-id pub-id-type="publisher-id">bts439</pub-id>
        <pub-id pub-id-type="other">2-s2.0-84865552798</pub-id>
        <pub-id pub-id-type="pmid">22815358</pub-id>
      </element-citation>
    </ref>
    <ref id="B60">
      <label>15</label>
      <element-citation publication-type="book">
        <collab>The MathWorks</collab>
        <source>
          <italic>Statistics Toolbox for Use with MATLAB, User Guide Version 4</italic>
        </source>
        <year>2003</year>
        <comment>
          <ext-link ext-link-type="uri" xlink:href="http://www.pi.ingv.it/~longo/CorsoMatlab/OriginalManuals/stats.pdf">http://www.pi.ingv.it/~longo/CorsoMatlab/OriginalManuals/stats.pdf</ext-link>
        </comment>
      </element-citation>
    </ref>
    <ref id="B24">
      <label>16</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hall</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Frank</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Holmes</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Pfahringer</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Reutemann</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Witten</surname>
            <given-names>IH</given-names>
          </name>
        </person-group>
        <article-title>The WEKA data mining software: an update</article-title>
        <source>
          <italic>ACM SIGKDD Explorations Newsletter</italic>
        </source>
        <year>2009</year>
        <volume>11</volume>
        <issue>1</issue>
        <fpage>10</fpage>
        <lpage>18</lpage>
      </element-citation>
    </ref>
    <ref id="B46">
      <label>17</label>
      <element-citation publication-type="other">
        <comment>NAG Toolbox for Matlab: g03aa, G03-Multivariate Methods, <ext-link ext-link-type="uri" xlink:href="http://www.nag.com/numeric/MB/manual_22_1/pdf/G03/g03aa.pdf">http://www.nag.com/numeric/MB/manual_22_1/pdf/G03/g03aa.pdf</ext-link></comment>
      </element-citation>
    </ref>
    <ref id="B41">
      <label>18</label>
      <element-citation publication-type="other">
        <person-group person-group-type="author">
          <name>
            <surname>Marchini</surname>
            <given-names>JL</given-names>
          </name>
          <name>
            <surname>Heaton</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Ripley</surname>
            <given-names>BD</given-names>
          </name>
        </person-group>
        <article-title>Package ‘fastICA’</article-title>
        <comment>
          <ext-link ext-link-type="uri" xlink:href="http://cran.r-project.org/web/packages/fastICA/fastICA.pdf">http://cran.r-project.org/web/packages/fastICA/fastICA.pdf</ext-link>
        </comment>
      </element-citation>
    </ref>
    <ref id="B47">
      <label>19</label>
      <element-citation publication-type="other">
        <person-group person-group-type="author">
          <name>
            <surname>Nordhausen</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Cardoso</surname>
            <given-names>J-F</given-names>
          </name>
          <name>
            <surname>Miettinen</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Oja</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Ollila</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Taskinen</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>Package ‘JADE’</article-title>
        <comment>
          <ext-link ext-link-type="uri" xlink:href="http://cran.r-project.org/web/packages/JADE/JADE.pdf">http://cran.r-project.org/web/packages/JADE/JADE.pdf</ext-link>
        </comment>
      </element-citation>
    </ref>
    <ref id="B33">
      <label>20</label>
      <element-citation publication-type="other">
        <person-group person-group-type="author">
          <name>
            <surname>Keith</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Hoge</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Frank</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Malony</surname>
            <given-names>AD</given-names>
          </name>
        </person-group>
        <comment>HiPerSAT Technical Report, 2005, <ext-link ext-link-type="uri" xlink:href="http://nic.uoregon.edu/docs/reports/HiPerSATTechReport.pdf">http://nic.uoregon.edu/docs/reports/HiPerSATTechReport.pdf</ext-link></comment>
      </element-citation>
    </ref>
    <ref id="B10">
      <label>21</label>
      <element-citation publication-type="other">
        <person-group person-group-type="author">
          <name>
            <surname>Biton</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Zinovyev</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Barillot</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Radvanyi</surname>
            <given-names>F</given-names>
          </name>
        </person-group>
        <article-title>MineICA: independent component analysis of transcriptomic data</article-title>
        <comment>2013, <ext-link ext-link-type="uri" xlink:href="http://www.bioconductor.org/packages/2.13/bioc/vignettes/MineICA/inst/doc/MineICA.pdf">http://www.bioconductor.org/packages/2.13/bioc/vignettes/MineICA/inst/doc/MineICA.pdf</ext-link></comment>
      </element-citation>
    </ref>
    <ref id="B32">
      <label>22</label>
      <element-citation publication-type="other">
        <person-group person-group-type="author">
          <name>
            <surname>Karnanen</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Independent component analysis using score functions from the Pearson system</article-title>
        <comment>2006, <ext-link ext-link-type="uri" xlink:href="http://cran.r-project.org/web/packages/PearsonICA/PearsonICA.pdf">http://cran.r-project.org/web/packages/PearsonICA/PearsonICA.pdf</ext-link></comment>
      </element-citation>
    </ref>
    <ref id="B48">
      <label>23</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Teschenforff</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <source>
          <italic>Independent Component Analysis Using Maximum Likelihood</italic>
        </source>
        <year>2012</year>
        <comment>
          <ext-link ext-link-type="uri" xlink:href="http://cran.r-project.org/web/packages/mlica2/mlica2.pdf">http://cran.r-project.org/web/packages/mlica2/mlica2.pdf</ext-link>
        </comment>
      </element-citation>
    </ref>
    <ref id="B4">
      <label>24</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Barker</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Rayens</surname>
            <given-names>W</given-names>
          </name>
        </person-group>
        <article-title>Partial least squares for discrimination</article-title>
        <source>
          <italic>Journal of Chemometrics</italic>
        </source>
        <year>2003</year>
        <volume>17</volume>
        <issue>3</issue>
        <fpage>166</fpage>
        <lpage>173</lpage>
        <pub-id pub-id-type="other">2-s2.0-0037350844</pub-id>
      </element-citation>
    </ref>
    <ref id="B30">
      <label>25</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Jørgensen</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Segtnan</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Thyholt</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Næs</surname>
            <given-names>T</given-names>
          </name>
        </person-group>
        <article-title>A comparison of methods for analysing regression models with both spectral and designed variables</article-title>
        <source>
          <italic>Journal of Chemometrics</italic>
        </source>
        <year>2004</year>
        <volume>18</volume>
        <issue>10</issue>
        <fpage>451</fpage>
        <lpage>464</lpage>
        <pub-id pub-id-type="other">2-s2.0-24944465238</pub-id>
      </element-citation>
    </ref>
    <ref id="B39">
      <label>26</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Liland</surname>
            <given-names>KH</given-names>
          </name>
          <name>
            <surname>Indahl</surname>
            <given-names>UG</given-names>
          </name>
        </person-group>
        <article-title>Powered partial least squares discriminant analysis</article-title>
        <source>
          <italic>Journal of Chemometrics</italic>
        </source>
        <year>2009</year>
        <volume>23</volume>
        <issue>1</issue>
        <fpage>7</fpage>
        <lpage>18</lpage>
        <pub-id pub-id-type="other">2-s2.0-58549098908</pub-id>
      </element-citation>
    </ref>
    <ref id="B35">
      <label>27</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Krämer</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Boulesteix</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Tutz</surname>
            <given-names>G</given-names>
          </name>
        </person-group>
        <article-title>Penalized Partial Least Squares with applications to B-spline transformations and functional data</article-title>
        <source>
          <italic>Chemometrics and Intelligent Laboratory Systems</italic>
        </source>
        <year>2008</year>
        <volume>94</volume>
        <issue>1</issue>
        <fpage>60</fpage>
        <lpage>69</lpage>
        <pub-id pub-id-type="other">2-s2.0-50249088015</pub-id>
      </element-citation>
    </ref>
    <ref id="B13">
      <label>28</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chung</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Keles</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>Sparse partial least squares classification for high dimensional data</article-title>
        <source>
          <italic>Statistical Applications in Genetics and Molecular Biology</italic>
        </source>
        <year>2010</year>
        <volume>9</volume>
        <issue>1</issue>
        <pub-id pub-id-type="other">MR2721697</pub-id>
        <pub-id pub-id-type="other">2-s2.0-77950530973</pub-id>
      </element-citation>
    </ref>
    <ref id="B36">
      <label>29</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kramer</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Sugiyama</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>The degrees of freedom of partial least squares regression</article-title>
        <source>
          <italic>Journal of the American Statistical Association</italic>
        </source>
        <year>2011</year>
        <volume>106</volume>
        <issue>494</issue>
        <fpage>697</fpage>
        <lpage>705</lpage>
        <pub-id pub-id-type="other">MR2847952</pub-id>
        <pub-id pub-id-type="other">2-s2.0-79960116378</pub-id>
      </element-citation>
    </ref>
    <ref id="B12">
      <label>30</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chakraborty</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Datta</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>Surrogate variable analysis using partial least squares (SVA-PLS) in gene expression studies</article-title>
        <source>
          <italic>Bioinformatics</italic>
        </source>
        <year>2012</year>
        <volume>28</volume>
        <issue>6</issue>
        <fpage>799</fpage>
        <lpage>806</lpage>
        <pub-id pub-id-type="other">2-s2.0-84859095468</pub-id>
        <pub-id pub-id-type="pmid">22238271</pub-id>
      </element-citation>
    </ref>
    <ref id="B57">
      <label>31</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Sanchez</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Trinchera</surname>
            <given-names>L</given-names>
          </name>
        </person-group>
        <source>
          <italic>Tools for Partial Least Squares Path Modeling</italic>
        </source>
        <year>2013</year>
        <comment>
          <ext-link ext-link-type="uri" xlink:href="http://cran.r-project.org/web/packages/plspm/plspm.pdf">http://cran.r-project.org/web/packages/plspm/plspm.pdf</ext-link>
        </comment>
      </element-citation>
    </ref>
    <ref id="B8">
      <label>32</label>
      <element-citation publication-type="other">
        <person-group person-group-type="author">
          <name>
            <surname>Bertrand</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Meyer</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Bertrand</surname>
            <given-names>MM</given-names>
          </name>
        </person-group>
        <article-title>Partial Least Squares Regression for generalized linear models</article-title>
        <comment>
          <ext-link ext-link-type="uri" xlink:href="http://cran.r-project.org/web/packages/plsRglm/plsRglm.pdf">http://cran.r-project.org/web/packages/plsRglm/plsRglm.pdf</ext-link>
        </comment>
      </element-citation>
    </ref>
    <ref id="B23">
      <label>33</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Gutkin</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Shamir</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Dror</surname>
            <given-names>G</given-names>
          </name>
        </person-group>
        <article-title>SlimPLS: a method for feature selection in gene expression-based disease classification</article-title>
        <source>
          <italic>PLoS ONE</italic>
        </source>
        <year>2009</year>
        <volume>4</volume>
        <issue>7</issue>
        <pub-id pub-id-type="publisher-id">e6416</pub-id>
        <pub-id pub-id-type="other">2-s2.0-68149171307</pub-id>
      </element-citation>
    </ref>
    <ref id="B17">
      <label>34</label>
      <element-citation publication-type="other">
        <person-group person-group-type="author">
          <name>
            <surname>Diedrich</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Abel</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>Package ‘lle’</article-title>
        <comment>
          <ext-link ext-link-type="uri" xlink:href="http://cran.r-project.org/web/packages/lle/lle.pdf">http://cran.r-project.org/web/packages/lle/lle.pdf</ext-link>
        </comment>
      </element-citation>
    </ref>
    <ref id="B5">
      <label>35</label>
      <element-citation publication-type="other">
        <person-group person-group-type="author">
          <name>
            <surname>Bartenhagen</surname>
            <given-names>C</given-names>
          </name>
        </person-group>
        <article-title>RDRToolbox: a package for nonlinear dimension reduction with Isomap and LLE</article-title>
        <comment>2013, <ext-link ext-link-type="uri" xlink:href="http://bioconductor.org/packages/2.13/bioc/vignettes/RDRToolbox/inst/doc/vignette.pdf">http://bioconductor.org/packages/2.13/bioc/vignettes/RDRToolbox/inst/doc/vignette.pdf</ext-link></comment>
      </element-citation>
    </ref>
    <ref id="B53">
      <label>36</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Pedregosa</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Varoquaux</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Gramfort</surname>
            <given-names>A</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Scikit-learn: machine learning in Python</article-title>
        <source>
          <italic>Journal of Machine Learning Research</italic>
        </source>
        <year>2011</year>
        <volume>12</volume>
        <fpage>2825</fpage>
        <lpage>2830</lpage>
      </element-citation>
    </ref>
    <ref id="B54">
      <label>37</label>
      <element-citation publication-type="other">
        <person-group person-group-type="author">
          <name>
            <surname>Penel</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <comment>Package “ade4”, 2013, <ext-link ext-link-type="uri" xlink:href="http://cran.r-project.org/web/packages/ade4/ade4.pdf">http://cran.r-project.org/web/packages/ade4/ade4.pdf</ext-link></comment>
      </element-citation>
    </ref>
    <ref id="B18">
      <label>38</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Dray</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Dufour</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>The ade4 package: implementing the duality diagram for ecologists</article-title>
        <source>
          <italic>Journal of Statistical Software</italic>
        </source>
        <year>2007</year>
        <volume>22</volume>
        <issue>4</issue>
        <fpage>1</fpage>
        <lpage>20</lpage>
        <pub-id pub-id-type="other">2-s2.0-37649024043</pub-id>
      </element-citation>
    </ref>
    <ref id="B45">
      <label>39</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Moorthy</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Mohamad</surname>
            <given-names>MS</given-names>
          </name>
          <name>
            <surname>Deris</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Ibrahim</surname>
            <given-names>Z</given-names>
          </name>
        </person-group>
        <article-title>Multivariate analysis of gene expression data and missing value imputation based on llsimpute algorithm</article-title>
        <source>
          <italic>International Journal of Innovative Computing, Information and Control</italic>
        </source>
        <year>2012</year>
        <volume>6</volume>
        <issue>5</issue>
        <fpage>1335</fpage>
        <lpage>1339</lpage>
        <pub-id pub-id-type="other">2-s2.0-84859222236</pub-id>
      </element-citation>
    </ref>
    <ref id="B14">
      <label>40</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Culhane</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <source>
          <italic>Package ‘made4’</italic>
        </source>
        <year>2013</year>
        <comment>
          <ext-link ext-link-type="uri" xlink:href="http://bioconductor.org/packages/release/bioc/manuals/made4/man/made4.pdf">http://bioconductor.org/packages/release/bioc/manuals/made4/man/made4.pdf</ext-link>
        </comment>
      </element-citation>
    </ref>
    <ref id="B59">
      <label>41</label>
      <element-citation publication-type="confproc">
        <person-group person-group-type="author">
          <name>
            <surname>Subbulakshmi</surname>
            <given-names>CV</given-names>
          </name>
          <name>
            <surname>Deepa</surname>
            <given-names>SN</given-names>
          </name>
          <name>
            <surname>Malathi</surname>
            <given-names>N</given-names>
          </name>
        </person-group>
        <article-title>Comparative analysis of XLMiner and WEKA for pattern classification</article-title>
        <conf-name>Proceedings of the IEEE International Conference on Advanced Communication Control and Computing Technologies (ICACCCT '12)</conf-name>
        <conf-date>August 2012</conf-date>
        <conf-loc>Ramanathapuram Tamil Nadu, India</conf-loc>
        <fpage>453</fpage>
        <lpage>457</lpage>
        <pub-id pub-id-type="other">2-s2.0-84869383573</pub-id>
      </element-citation>
    </ref>
    <ref id="B31">
      <label>42</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Jothi</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Anita</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>Data mining classification techniques applied for cancer disease—a case study using Xlminer</article-title>
        <source>
          <italic>International Journal of Engineering Research &amp; Technology</italic>
        </source>
        <year>2012</year>
        <volume>1</volume>
        <issue>8</issue>
      </element-citation>
    </ref>
    <ref id="B3">
      <label>43</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Anh</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Magi</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <source>
          <italic>Principal Component Analysis: Final Paper in Financial Pricing</italic>
        </source>
        <year>2009</year>
        <publisher-name>National Cheng Kung University</publisher-name>
      </element-citation>
    </ref>
    <ref id="B50">
      <label>44</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Tierney</surname>
            <given-names>L</given-names>
          </name>
        </person-group>
        <source>
          <italic>Lisp-Stat: An Object-Oriented Environment for Statistical Computing &amp; Dynamic Graphics</italic>
        </source>
        <year>1990</year>
        <publisher-loc>Reading, Mass, USA</publisher-loc>
        <publisher-name>Addison-Wesley</publisher-name>
      </element-citation>
    </ref>
    <ref id="B64">
      <label>45</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Young</surname>
            <given-names>FW</given-names>
          </name>
          <name>
            <surname>Lubinsky</surname>
            <given-names>DJ</given-names>
          </name>
        </person-group>
        <article-title>Guiding data analysis with visual statistical strategies</article-title>
        <source>
          <italic>Journal of Computational and Graphical Statistics</italic>
        </source>
        <year>1995</year>
        <volume>4</volume>
        <fpage>229</fpage>
        <lpage>250</lpage>
      </element-citation>
    </ref>
    <ref id="B65">
      <label>46</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Young</surname>
            <given-names>FW</given-names>
          </name>
          <name>
            <surname>Smith</surname>
            <given-names>JB</given-names>
          </name>
        </person-group>
        <person-group person-group-type="editor">
          <name>
            <surname>Buja</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Tukey</surname>
            <given-names>PA</given-names>
          </name>
        </person-group>
        <article-title>Towards a structured data analysis environment: a cognition-based design</article-title>
        <source>
          <italic>Computing and Graphics in Statistics</italic>
        </source>
        <year>1991</year>
        <volume>36</volume>
        <publisher-loc>New York, NY, USA</publisher-loc>
        <publisher-name>Springer</publisher-name>
        <fpage>253</fpage>
        <lpage>279</lpage>
      </element-citation>
    </ref>
    <ref id="B66">
      <label>47</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Young</surname>
            <given-names>FW</given-names>
          </name>
          <name>
            <surname>Faldowski</surname>
            <given-names>RA</given-names>
          </name>
          <name>
            <surname>McFarlane</surname>
            <given-names>MM</given-names>
          </name>
        </person-group>
        <person-group person-group-type="editor">
          <name>
            <surname>Rao</surname>
            <given-names>CR</given-names>
          </name>
        </person-group>
        <article-title>Multivariate statistical visualization</article-title>
        <source>
          <italic>Handbook of Statistics</italic>
        </source>
        <year>1993</year>
        <fpage>958</fpage>
        <lpage>998</lpage>
      </element-citation>
    </ref>
    <ref id="B44">
      <label>48</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>McFarlane</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Young</surname>
            <given-names>FW</given-names>
          </name>
        </person-group>
        <article-title>Graphical sensitivity analysis for multidimensional scaling</article-title>
        <source>
          <italic>Journal of Computational and Graphical Statistics</italic>
        </source>
        <year>1994</year>
        <volume>3</volume>
        <issue>1</issue>
        <fpage>23</fpage>
        <lpage>34</lpage>
      </element-citation>
    </ref>
    <ref id="B61">
      <label>49</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Valero-Mora</surname>
            <given-names>PM</given-names>
          </name>
          <name>
            <surname>Ledesma</surname>
            <given-names>RD</given-names>
          </name>
        </person-group>
        <article-title>Using interactive graphics to teach multivariate data analysis to psychology students</article-title>
        <source>
          <italic>Journal of Statistics Education</italic>
        </source>
        <year>2011</year>
        <volume>19</volume>
        <issue>1</issue>
        <pub-id pub-id-type="other">2-s2.0-79954568283</pub-id>
      </element-citation>
    </ref>
    <ref id="B19">
      <label>50</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Frank</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Hall</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Holmes</surname>
            <given-names>G</given-names>
          </name>
          <etal/>
        </person-group>
        <person-group person-group-type="editor">
          <name>
            <surname>Maimon</surname>
            <given-names>O</given-names>
          </name>
          <name>
            <surname>Rokach</surname>
            <given-names>L</given-names>
          </name>
        </person-group>
        <article-title>Weka—a machine learning workbench for data mining</article-title>
        <source>
          <italic>Data Mining and Knowledge Discovery Handbook</italic>
        </source>
        <year>2010</year>
        <fpage>1269</fpage>
        <lpage>1277</lpage>
      </element-citation>
    </ref>
    <ref id="B52">
      <label>51</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Prabhume</surname>
            <given-names>SS</given-names>
          </name>
          <name>
            <surname>Sathe</surname>
            <given-names>SR</given-names>
          </name>
        </person-group>
        <article-title>Reconstruction of a complete dataset from an incomplete dataset by PCA (principal component analysis) technique: some results</article-title>
        <source>
          <italic>International Journal of Computer Science and Network Security</italic>
        </source>
        <year>2010</year>
        <volume>10</volume>
        <issue>12</issue>
        <fpage>195</fpage>
        <lpage>199</lpage>
      </element-citation>
    </ref>
    <ref id="B34">
      <label>52</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Khan</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Wei</surname>
            <given-names>JS</given-names>
          </name>
          <name>
            <surname>Ringnér</surname>
            <given-names>M</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Classification and diagnostic prediction of cancers using gene expression profiling and artificial neural networks</article-title>
        <source>
          <italic>Nature Medicine</italic>
        </source>
        <year>2001</year>
        <volume>7</volume>
        <issue>6</issue>
        <fpage>673</fpage>
        <lpage>679</lpage>
        <pub-id pub-id-type="other">2-s2.0-0034954414</pub-id>
      </element-citation>
    </ref>
    <ref id="B68">
      <label>53</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Comon</surname>
            <given-names>P</given-names>
          </name>
        </person-group>
        <article-title>Independent component analysis, a new concept?</article-title>
        <source>
          <italic>Signal Processing</italic>
        </source>
        <year>1994</year>
        <volume>36</volume>
        <issue>3</issue>
        <fpage>287</fpage>
        <lpage>314</lpage>
        <pub-id pub-id-type="other">2-s2.0-0028416938</pub-id>
      </element-citation>
    </ref>
    <ref id="B28">
      <label>54</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hyvärinen</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Fast and robust fixed-point algorithms for independent component analysis</article-title>
        <source>
          <italic>IEEE Transactions on Neural Networks</italic>
        </source>
        <year>1999</year>
        <volume>10</volume>
        <issue>3</issue>
        <fpage>626</fpage>
        <lpage>634</lpage>
        <pub-id pub-id-type="other">2-s2.0-0032629347</pub-id>
        <pub-id pub-id-type="pmid">18252563</pub-id>
      </element-citation>
    </ref>
    <ref id="B67">
      <label>55</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Zarzoso</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Comon</surname>
            <given-names>P</given-names>
          </name>
        </person-group>
        <person-group person-group-type="editor">
          <name>
            <surname>Davies</surname>
            <given-names>ME</given-names>
          </name>
          <name>
            <surname>James</surname>
            <given-names>CJ</given-names>
          </name>
          <name>
            <surname>Abdallah</surname>
            <given-names>SA</given-names>
          </name>
          <name>
            <surname>Plumbley</surname>
            <given-names>MD</given-names>
          </name>
        </person-group>
        <article-title>Comparative speed analysis of FastICA</article-title>
        <source>
          <italic>Independent Component Analysis and Signal Separation</italic>
        </source>
        <year>2007</year>
        <volume>4666</volume>
        <publisher-loc>Berlin, Germany</publisher-loc>
        <publisher-name>Springer</publisher-name>
        <fpage>293</fpage>
        <lpage>300</lpage>
        <series>Lecture Notes in Computer Science</series>
      </element-citation>
    </ref>
    <ref id="B11">
      <label>56</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Cardoso</surname>
            <given-names>JF</given-names>
          </name>
          <name>
            <surname>Souloumiac</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Blind beamforming for non-Gaussian signals</article-title>
        <source>
          <italic>IEE Proceedings, Part F: Radar and Signal Processing</italic>
        </source>
        <year>1993</year>
        <volume>140</volume>
        <issue>6</issue>
        <fpage>362</fpage>
        <lpage>370</lpage>
        <pub-id pub-id-type="other">2-s2.0-0027812550</pub-id>
      </element-citation>
    </ref>
    <ref id="B7">
      <label>57</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Belouchrani</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Abed-Meraim</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Cardoso</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Moulines</surname>
            <given-names>E</given-names>
          </name>
        </person-group>
        <article-title>A blind source separation technique using second-order statistics</article-title>
        <source>
          <italic>IEEE Transactions on Signal Processing</italic>
        </source>
        <year>1997</year>
        <volume>45</volume>
        <issue>2</issue>
        <fpage>434</fpage>
        <lpage>444</lpage>
        <pub-id pub-id-type="other">2-s2.0-0031078854</pub-id>
      </element-citation>
    </ref>
    <ref id="B51">
      <label>58</label>
      <element-citation publication-type="confproc">
        <person-group person-group-type="author">
          <name>
            <surname>Tong</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Soon</surname>
            <given-names>VC</given-names>
          </name>
          <name>
            <surname>Huang</surname>
            <given-names>YF</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>AMUSE: a new blind identification algorithm</article-title>
        <conf-name>Proceedings of the IEEE International Symposium on Circuits and Systems</conf-name>
        <conf-date>May 1990</conf-date>
        <fpage>1784</fpage>
        <lpage>1787</lpage>
        <pub-id pub-id-type="other">2-s2.0-0025594816</pub-id>
      </element-citation>
    </ref>
    <ref id="B2">
      <label>59</label>
      <element-citation publication-type="confproc">
        <person-group person-group-type="author">
          <name>
            <surname>Amari</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Cichocki</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>HH</given-names>
          </name>
        </person-group>
        <article-title>A new learning algorithm for blind signal separation</article-title>
        <conf-name>Proceedings of the Advances in Neural Information Processing Systems Conference</conf-name>
        <conf-date>1996</conf-date>
        <fpage>757</fpage>
        <lpage>763</lpage>
      </element-citation>
    </ref>
    <ref id="B16">
      <label>60</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Delorme</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Makeig</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>EEGLAB: an open source toolbox for analysis of single-trial EEG dynamics including independent component analysis</article-title>
        <source>
          <italic>Journal of Neuroscience Methods</italic>
        </source>
        <year>2004</year>
        <volume>134</volume>
        <issue>1</issue>
        <fpage>9</fpage>
        <lpage>21</lpage>
        <pub-id pub-id-type="other">2-s2.0-1242283941</pub-id>
        <pub-id pub-id-type="pmid">15102499</pub-id>
      </element-citation>
    </ref>
    <ref id="B9">
      <label>61</label>
      <element-citation publication-type="other">
        <person-group person-group-type="author">
          <name>
            <surname>Biton</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Package ‘MineICA’</article-title>
        <comment>2013, <ext-link ext-link-type="uri" xlink:href="http://www.bioconductor.org/packages/2.13/bioc/manuals/MineICA/man/MineICA.pdf">http://www.bioconductor.org/packages/2.13/bioc/manuals/MineICA/man/MineICA.pdf</ext-link></comment>
      </element-citation>
    </ref>
    <ref id="B29">
      <label>62</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Hyvaerinen</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Karhunen</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Oja</surname>
            <given-names>E</given-names>
          </name>
        </person-group>
        <source>
          <italic>Independent Component Analysis</italic>
        </source>
        <year>2001</year>
        <publisher-loc>New York, NY, USA</publisher-loc>
        <publisher-name>John Wiley &amp; Sons</publisher-name>
      </element-citation>
    </ref>
    <ref id="B58">
      <label>63</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Schmidt</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Böhm</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>von Törne</surname>
            <given-names>C</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>The humoral immune system has a key prognostic impact in node-negative breast cancer</article-title>
        <source>
          <italic>Cancer Research</italic>
        </source>
        <year>2008</year>
        <volume>68</volume>
        <issue>13</issue>
        <fpage>5405</fpage>
        <lpage>5413</lpage>
        <pub-id pub-id-type="other">2-s2.0-44849101184</pub-id>
        <pub-id pub-id-type="pmid">18593943</pub-id>
      </element-citation>
    </ref>
    <ref id="B69">
      <label>64</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Helland</surname>
            <given-names>IS</given-names>
          </name>
        </person-group>
        <article-title>On the structure of partial least squares regression</article-title>
        <source>
          <italic>Communications in Statistics. Simulation and Computation</italic>
        </source>
        <year>1988</year>
        <volume>17</volume>
        <issue>2</issue>
        <fpage>581</fpage>
        <lpage>607</lpage>
        <pub-id pub-id-type="other">MR955342</pub-id>
        <pub-id pub-id-type="other">ZBL0695.62167</pub-id>
      </element-citation>
    </ref>
    <ref id="B42">
      <label>65</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Martens</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Naes</surname>
            <given-names>T</given-names>
          </name>
        </person-group>
        <source>
          <italic>Multivariate calibration</italic>
        </source>
        <year>1989</year>
        <publisher-loc>London, UK</publisher-loc>
        <publisher-name>John Wiley &amp; Sons</publisher-name>
        <pub-id pub-id-type="other">MR1029523</pub-id>
      </element-citation>
    </ref>
    <ref id="B70">
      <label>66</label>
      <element-citation publication-type="other">
        <person-group person-group-type="author">
          <name>
            <surname>Krämer</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Boulesteix</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Package “ppls”</article-title>
        <comment>2013, <ext-link ext-link-type="uri" xlink:href="http://cran.rproject.org/web/packages/ppls/ppls.pdf">http://cran.rproject. org/web/packages/ppls/ppls.pdf</ext-link></comment>
      </element-citation>
    </ref>
    <ref id="B43">
      <label>67</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Wold</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <person-group person-group-type="editor">
          <name>
            <surname>Joreskog</surname>
            <given-names>KG</given-names>
          </name>
          <name>
            <surname>Wold</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <article-title>Soft modeling: the basic design and some extensions</article-title>
        <source>
          <italic>Systems under Indirect Observations: Causality, Structure, Prediction</italic>
        </source>
        <year>1982</year>
        <publisher-loc>Amsterdam, The Netherlands</publisher-loc>
        <publisher-name>North-Holland</publisher-name>
        <fpage>1</fpage>
        <lpage>54</lpage>
        <series>Part 2</series>
      </element-citation>
    </ref>
    <ref id="B1">
      <label>68</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Akaike</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <article-title>Likelihood and the Bayes procedure</article-title>
        <source>
          <italic>Trabajos de Estadística y de Investigación Operativa</italic>
        </source>
        <year>1980</year>
        <volume>31</volume>
        <issue>1</issue>
        <fpage>143</fpage>
        <lpage>166</lpage>
      </element-citation>
    </ref>
    <ref id="B21">
      <label>69</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Golub</surname>
            <given-names>TR</given-names>
          </name>
          <name>
            <surname>Slonim</surname>
            <given-names>DK</given-names>
          </name>
          <name>
            <surname>Tamayo</surname>
            <given-names>P</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Molecular classification of cancer: class discovery and class prediction by gene expression monitoring</article-title>
        <source>
          <italic>Science</italic>
        </source>
        <year>1999</year>
        <volume>286</volume>
        <issue>5439</issue>
        <fpage>531</fpage>
        <lpage>537</lpage>
        <pub-id pub-id-type="other">2-s2.0-0033569406</pub-id>
        <pub-id pub-id-type="pmid">10521349</pub-id>
      </element-citation>
    </ref>
    <ref id="B71">
      <label>70</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Roweis</surname>
            <given-names>ST</given-names>
          </name>
          <name>
            <surname>Saul</surname>
            <given-names>LK</given-names>
          </name>
        </person-group>
        <article-title>Nonlinear dimensionality reduction linear embedding</article-title>
        <source>
          <italic>Science</italic>
        </source>
        <year>2000</year>
        <volume>290</volume>
        <issue>5500</issue>
        <fpage>2323</fpage>
        <lpage>2326</lpage>
        <pub-id pub-id-type="other">2-s2.0-0034704222</pub-id>
        <pub-id pub-id-type="pmid">11125150</pub-id>
      </element-citation>
    </ref>
    <ref id="B55">
      <label>71</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Ridder</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Duin</surname>
            <given-names>RPW</given-names>
          </name>
        </person-group>
        <source>
          <italic>Locally Linear Embedding</italic>
        </source>
        <year>2002</year>
        <publisher-loc>Delft, The Netherlands</publisher-loc>
        <publisher-name>University of Technology</publisher-name>
      </element-citation>
    </ref>
  </ref-list>
</back>
<floats-group>
  <fig id="fig1" orientation="portrait" position="float">
    <label>Figure 1</label>
    <caption>
      <p>Plot of genes.</p>
    </caption>
    <graphic xlink:href="BMRI2014-213656.001"/>
  </fig>
  <fig id="fig2" orientation="portrait" position="float">
    <label>Figure 2</label>
    <caption>
      <p>Correlation-based graph.</p>
    </caption>
    <graphic xlink:href="BMRI2014-213656.002"/>
  </fig>
  <fig id="fig3" orientation="portrait" position="float">
    <label>Figure 3</label>
    <caption>
      <p>(a, b, and c) Heatmaps showing the original and corrected expression levels for the first 1000 genes in the Golub data. (a) Heatmap for the first 1000 genes in the original Golub expression data. (b) Heatmap for the first 1000 genes in the adjusted Golub expression data obtained by use of the R package ber. (c) Heatmap for the first 1000 genes in the adjusted Golub expression data obtained by the use of our R package svapls.</p>
    </caption>
    <graphic xlink:href="BMRI2014-213656.003"/>
  </fig>
  <fig id="fig4" orientation="portrait" position="float">
    <label>Figure 4</label>
    <caption>
      <p>Plot of dimension versus residual variance.</p>
    </caption>
    <graphic xlink:href="BMRI2014-213656.004"/>
  </fig>
  <fig id="fig5" orientation="portrait" position="float">
    <label>Figure 5</label>
    <caption>
      <p>Two-dimensional embedding of the Golub et al. [<xref rid="B21" ref-type="bibr">69</xref>] leukemia dataset (top: Isomap; bottom: LLE).</p>
    </caption>
    <graphic xlink:href="BMRI2014-213656.005"/>
  </fig>
  <table-wrap id="tab1" orientation="portrait" position="float">
    <label>Table 1</label>
    <caption>
      <p>A summary for PCA software.</p>
    </caption>
    <table frame="hsides" rules="groups">
      <thead>
        <tr>
          <th align="left" rowspan="1" colspan="1">Number</th>
          <th align="left" rowspan="1" colspan="1">Software</th>
          <th align="left" rowspan="1" colspan="1">Author/year</th>
          <th align="left" rowspan="1" colspan="1">Language</th>
          <th align="left" rowspan="1" colspan="1">Features</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td align="left" rowspan="1" colspan="1">1</td>
          <td align="left" rowspan="1" colspan="1">FactoMineR</td>
          <td align="left" rowspan="1" colspan="1">
Lê et al. [<xref rid="B37" ref-type="bibr">5</xref>]</td>
          <td align="left" rowspan="1" colspan="1">R</td>
          <td align="left" rowspan="1" colspan="1">(i) Various dimension reduction methods such as PCA, CA, and MCA<break/>(ii) Different types of variables, data structures, and supplementary information are considered <break/>(iii) The PCA function can handle missing values</td>
        </tr>
        <tr>
          <td align="center" colspan="5" rowspan="1">
            <hr/>
          </td>
        </tr>
        <tr>
          <td align="left" rowspan="1" colspan="1">2</td>
          <td align="left" rowspan="1" colspan="1">ExPosition</td>
          <td align="left" rowspan="1" colspan="1">Beaton et al. [<xref rid="B6" ref-type="bibr">8</xref>]</td>
          <td align="left" rowspan="1" colspan="1">R</td>
          <td align="left" rowspan="1" colspan="1">(i) Numerous multivariate analysis methods such as PCA and Generalized Principal Component Analysis (GPCA)<break/>(ii) Can be applied to quantitative and qualitative data<break/>(iii) Implementation of Singular Value Decomposition</td>
        </tr>
        <tr>
          <td align="center" colspan="5" rowspan="1">
            <hr/>
          </td>
        </tr>
        <tr>
          <td align="left" rowspan="1" colspan="1">3</td>
          <td align="left" rowspan="1" colspan="1">amap</td>
          <td align="left" rowspan="1" colspan="1">Lucas [<xref rid="B40" ref-type="bibr">9</xref>]</td>
          <td align="left" rowspan="1" colspan="1">R</td>
          <td align="left" rowspan="1" colspan="1">(i) Different types of PCA are provided: PCA, Generalized PCA, and Robust PCA<break/>(ii) Clustering methods are provided such as hierarchical clustering and <italic>k</italic>-means clustering<break/>(iii) Plotting function for PCA<break/>(iv) Computing distance and dissimilarity matrices </td>
        </tr>
        <tr>
          <td align="center" colspan="5" rowspan="1">
            <hr/>
          </td>
        </tr>
        <tr>
          <td align="left" rowspan="1" colspan="1">4</td>
          <td align="left" rowspan="1" colspan="1">ADE-4</td>
          <td align="left" rowspan="1" colspan="1">Thioulouse et al. [<xref rid="B49" ref-type="bibr">10</xref>]</td>
          <td align="left" rowspan="1" colspan="1">R</td>
          <td align="left" rowspan="1" colspan="1">A variety of methods such as PCA, CA, Principal Analysis Regression, PLS, and others are offered</td>
        </tr>
        <tr>
          <td align="center" colspan="5" rowspan="1">
            <hr/>
          </td>
        </tr>
        <tr>
          <td align="left" rowspan="1" colspan="1">5</td>
          <td align="left" rowspan="1" colspan="1">MADE4</td>
          <td align="left" rowspan="1" colspan="1">
Culhane et al. [<xref rid="B15" ref-type="bibr">11</xref>]</td>
          <td align="left" rowspan="1" colspan="1">R</td>
          <td align="left" rowspan="1" colspan="1">(i) Functions provided by ADE-4<break/>(ii) Integration of multiple datasets for multivariate analysis<break/>(iii) Functions for visualizing and plotting the results of analysis, including 3D plots<break/>(iv) Addition of LLSimpute algorithm for imputation of missing values</td>
        </tr>
        <tr>
          <td align="center" colspan="5" rowspan="1">
            <hr/>
          </td>
        </tr>
        <tr>
          <td align="left" rowspan="1" colspan="1">6</td>
          <td align="left" rowspan="1" colspan="1">XLMiner</td>
          <td align="left" rowspan="1" colspan="1">Witten and Frank [<xref rid="B62" ref-type="bibr">12</xref>]</td>
          <td align="left" rowspan="1" colspan="1">Implemented in Excel</td>
          <td align="left" rowspan="1" colspan="1">(i) Provision of data reduction methods such as PCA<break/>(ii) Can be used for classification, clustering, data preprocessing, data normalization, and others</td>
        </tr>
        <tr>
          <td align="center" colspan="5" rowspan="1">
            <hr/>
          </td>
        </tr>
        <tr>
          <td align="left" rowspan="1" colspan="1">7</td>
          <td align="left" rowspan="1" colspan="1">ViSta</td>
          <td align="left" rowspan="1" colspan="1">
Young et al. [<xref rid="B63" ref-type="bibr">13</xref>]</td>
          <td align="left" rowspan="1" colspan="1">C++, Fortran, XLisp, and ViDAL</td>
          <td align="left" rowspan="1" colspan="1">(i) Multivariate analysis methods are offered such as PCA, Interactive Cluster Analysis, and Parallel Boxplots<break/>(ii) Provision of dynamic and high-interaction visualization for displaying multiple views of data</td>
        </tr>
        <tr>
          <td align="center" colspan="5" rowspan="1">
            <hr/>
          </td>
        </tr>
        <tr>
          <td align="left" rowspan="1" colspan="1">8</td>
          <td align="left" rowspan="1" colspan="1">imDEV</td>
          <td align="left" rowspan="1" colspan="1">Grapov and Newman [<xref rid="B22" ref-type="bibr">14</xref>]</td>
          <td align="left" rowspan="1" colspan="1">Visual Basic and R</td>
          <td align="left" rowspan="1" colspan="1">(i) Data preprocessing: missing values imputation and data transformations<break/>(ii) Clustering methods are offered<break/>(iii) Dimension reduction methods: PCA and ICA<break/>(iv) Feature selection methods<break/>(v) Visualization of data dependencies</td>
        </tr>
        <tr>
          <td align="center" colspan="5" rowspan="1">
            <hr/>
          </td>
        </tr>
        <tr>
          <td align="left" rowspan="1" colspan="1">9</td>
          <td align="left" rowspan="1" colspan="1">Statistics Toolbox</td>
          <td align="left" rowspan="1" colspan="1">The MathWorks [<xref rid="B60" ref-type="bibr">15</xref>]</td>
          <td align="left" rowspan="1" colspan="1">MATLAB</td>
          <td align="left" rowspan="1" colspan="1">(i) Multivariate statistics such as PCA, clustering, and others<break/>(ii) Statistical plots, probability distributions, linear models, nonlinear models for regression, and others are provided</td>
        </tr>
        <tr>
          <td align="center" colspan="5" rowspan="1">
            <hr/>
          </td>
        </tr>
        <tr>
          <td align="left" rowspan="1" colspan="1">10</td>
          <td align="left" rowspan="1" colspan="1">Weka</td>
          <td align="left" rowspan="1" colspan="1">Hall et al. [<xref rid="B24" ref-type="bibr">16</xref>]</td>
          <td align="left" rowspan="1" colspan="1">Java</td>
          <td align="left" rowspan="1" colspan="1">A variety of machine learning algorithms are provided such as feature selection, data preprocessing, regression, dimension reduction, classification, and clustering methods</td>
        </tr>
        <tr>
          <td align="center" colspan="5" rowspan="1">
            <hr/>
          </td>
        </tr>
        <tr>
          <td align="left" rowspan="1" colspan="1">11</td>
          <td align="left" rowspan="1" colspan="1">NAG Library</td>
          <td align="left" rowspan="1" colspan="1">NAG Toolbox for MATLAB<break/>[<xref rid="B46" ref-type="bibr">17</xref>]</td>
          <td align="left" rowspan="1" colspan="1">Fortran and C</td>
          <td align="left" rowspan="1" colspan="1">(i) Provision of more than 1700 mathematical and statistical algorithms<break/>(ii) Multivariate analysis using PCA can be implemented using the g03aa routine</td>
        </tr>
      </tbody>
    </table>
  </table-wrap>
  <table-wrap id="tab2" orientation="portrait" position="float">
    <label>Table 2</label>
    <caption>
      <p>Sources of PCA software.</p>
    </caption>
    <table frame="hsides" rules="groups">
      <thead>
        <tr>
          <th align="left" rowspan="1" colspan="1">Number</th>
          <th align="left" rowspan="1" colspan="1">Software</th>
          <th align="left" rowspan="1" colspan="1">Sources</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td align="left" rowspan="1" colspan="1">1</td>
          <td align="left" rowspan="1" colspan="1">FactoMineR</td>
          <td align="left" rowspan="1" colspan="1">
            <ext-link ext-link-type="uri" xlink:href="http://cran.r-project.org/web/packages/FactoMineR/index.html">http://cran.r-project.org/web/packages/FactoMineR/index.html</ext-link>
          </td>
        </tr>
        <tr>
          <td align="left" rowspan="1" colspan="1">2</td>
          <td align="left" rowspan="1" colspan="1">ExPosition</td>
          <td align="left" rowspan="1" colspan="1">
            <ext-link ext-link-type="uri" xlink:href="http://cran.r-project.org/web/packages/ExPosition/index.html">http://cran.r-project.org/web/packages/ExPosition/index.html</ext-link>
          </td>
        </tr>
        <tr>
          <td align="left" rowspan="1" colspan="1">3</td>
          <td align="left" rowspan="1" colspan="1">Amap</td>
          <td align="left" rowspan="1" colspan="1">
            <ext-link ext-link-type="uri" xlink:href="http://cran.r-project.org/web/packages/amap/index.html">http://cran.r-project.org/web/packages/amap/index.html</ext-link>
          </td>
        </tr>
        <tr>
          <td align="left" rowspan="1" colspan="1">4</td>
          <td align="left" rowspan="1" colspan="1">ADE-4</td>
          <td align="left" rowspan="1" colspan="1">
            <ext-link ext-link-type="uri" xlink:href="http://cran.r-project.org/web/packages/ade4/index.html">http://cran.r-project.org/web/packages/ade4/index.html</ext-link>
          </td>
        </tr>
        <tr>
          <td align="left" rowspan="1" colspan="1">5</td>
          <td align="left" rowspan="1" colspan="1">MADE4</td>
          <td align="left" rowspan="1" colspan="1">
            <ext-link ext-link-type="uri" xlink:href="http://www.bioconductor.org/packages/2.11/bioc/html/made4.html">http://www.bioconductor.org/packages/2.11/bioc/html/made4.html</ext-link>
          </td>
        </tr>
        <tr>
          <td align="left" rowspan="1" colspan="1">6</td>
          <td align="left" rowspan="1" colspan="1">XLMiner</td>
          <td align="left" rowspan="1" colspan="1">
            <ext-link ext-link-type="uri" xlink:href="http://www.solver.com/xlminer-data-mining">http://www.solver.com/xlminer-data-mining</ext-link>
          </td>
        </tr>
        <tr>
          <td align="left" rowspan="1" colspan="1">7</td>
          <td align="left" rowspan="1" colspan="1">ViSta</td>
          <td align="left" rowspan="1" colspan="1">
            <ext-link ext-link-type="uri" xlink:href="http://www.visualstats.org/">http://www.visualstats.org/</ext-link>
            <break/>
            <ext-link ext-link-type="uri" xlink:href="http://www.mdp.edu.ar/psicologia/vista/vista.htm">http://www.mdp.edu.ar/psicologia/vista/vista.htm</ext-link>
          </td>
        </tr>
        <tr>
          <td align="left" rowspan="1" colspan="1">8</td>
          <td align="left" rowspan="1" colspan="1">imDEV</td>
          <td align="left" rowspan="1" colspan="1">
            <ext-link ext-link-type="uri" xlink:href="http://sourceforge.net/projects/imdev/">http://sourceforge.net/projects/imdev/</ext-link>
          </td>
        </tr>
        <tr>
          <td align="left" rowspan="1" colspan="1">9</td>
          <td align="left" rowspan="1" colspan="1">Statistics Toolbox</td>
          <td align="left" rowspan="1" colspan="1">
            <ext-link ext-link-type="uri" xlink:href="http://www.mathworks.com/matlabcentral/fileexchange/30792-pca-principal-component-analysis">http://www.mathworks.com/matlabcentral/fileexchange/30792-pca-principal-component-analysis</ext-link>
          </td>
        </tr>
        <tr>
          <td align="left" rowspan="1" colspan="1">10</td>
          <td align="left" rowspan="1" colspan="1">Weka</td>
          <td align="left" rowspan="1" colspan="1">
            <ext-link ext-link-type="uri" xlink:href="http://www.cs.waikato.ac.nz/ml/weka/downloading.html">http://www.cs.waikato.ac.nz/ml/weka/downloading.html</ext-link>
          </td>
        </tr>
        <tr>
          <td align="left" rowspan="1" colspan="1">11</td>
          <td align="left" rowspan="1" colspan="1">NAG Library</td>
          <td align="left" rowspan="1" colspan="1">
            <ext-link ext-link-type="uri" xlink:href="http://www.nag.com/downloads/cldownloads.asp">http://www.nag.com/downloads/cldownloads.asp</ext-link>
          </td>
        </tr>
      </tbody>
    </table>
  </table-wrap>
  <table-wrap id="tab3" orientation="portrait" position="float">
    <label>Table 3</label>
    <caption>
      <p>Related work.</p>
    </caption>
    <table frame="hsides" rules="groups">
      <thead>
        <tr>
          <th align="left" rowspan="1" colspan="1">Software</th>
          <th align="left" rowspan="1" colspan="1">Author</th>
          <th align="left" rowspan="1" colspan="1">Motivation</th>
          <th align="left" rowspan="1" colspan="1">Advantage</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td align="left" rowspan="1" colspan="1">FactoMineR</td>
          <td align="left" rowspan="1" colspan="1">
Lê et al. (2009) [<xref rid="B37" ref-type="bibr">5</xref>]</td>
          <td align="left" rowspan="1" colspan="1">(i) Providing a multivariate data analytic technique for applications in biological systems<break/>(ii) To combine “Omics” data structured into groups <break/>(iii) To help on their functional interpretations.</td>
          <td align="left" rowspan="1" colspan="1">(i) It provides a geometrical point of view and a lot of graphical outputs<break/>(ii) It can take into account a structure on the data<break/>(iii) A GUI is available.</td>
        </tr>
        <tr>
          <td align="center" colspan="4" rowspan="1">
            <hr/>
          </td>
        </tr>
        <tr>
          <td align="left" rowspan="1" colspan="1">MADE4</td>
          <td align="left" rowspan="1" colspan="1">Culhane et al. [<xref rid="B15" ref-type="bibr">11</xref>]</td>
          <td align="left" rowspan="1" colspan="1">To provide a simple-to-use tool for multivariate analysis of microarray data</td>
          <td align="left" rowspan="1" colspan="1">(i) Accepts a wide variety of gene-expression data input formats<break/>(ii) No additional data processing is required</td>
        </tr>
        <tr>
          <td align="center" colspan="4" rowspan="1">
            <hr/>
          </td>
        </tr>
        <tr>
          <td align="left" rowspan="1" colspan="1">Statistic toolbox</td>
          <td align="left" rowspan="1" colspan="1">
The MathWorks [<xref rid="B60" ref-type="bibr">15</xref>]</td>
          <td align="left" rowspan="1" colspan="1">High-dimensional and complex microarray data need automatic/computer aided tools for analysis</td>
          <td align="left" rowspan="1" colspan="1">Elegant matrix support; visualization</td>
        </tr>
        <tr>
          <td align="center" colspan="4" rowspan="1">
            <hr/>
          </td>
        </tr>
        <tr>
          <td align="left" rowspan="1" colspan="1">imDev</td>
          <td align="left" rowspan="1" colspan="1">Grapov and Newman, 2012 [<xref rid="B22" ref-type="bibr">14</xref>]</td>
          <td align="left" rowspan="1" colspan="1">Omics experiments generate complex high-dimensional data requiring multivariate analyses</td>
          <td align="left" rowspan="1" colspan="1">(i) User-friendly graphical interface <break/>(ii) Visualizations can be exported directly from the R plotting interface in a variety of file formats<break/>(iii) Dynamic loading of R objects between analyses sessions</td>
        </tr>
      </tbody>
    </table>
  </table-wrap>
  <table-wrap id="tab4" orientation="portrait" position="float">
    <label>Table 4</label>
    <caption>
      <p>Summary of ICA software.</p>
    </caption>
    <table frame="hsides" rules="groups">
      <thead>
        <tr>
          <th align="left" rowspan="1" colspan="1">Number</th>
          <th align="left" rowspan="1" colspan="1">Software</th>
          <th align="left" rowspan="1" colspan="1">Author/year</th>
          <th align="left" rowspan="1" colspan="1">Language</th>
          <th align="left" rowspan="1" colspan="1">Features</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td align="left" rowspan="1" colspan="1">1</td>
          <td align="left" rowspan="1" colspan="1">FastICA</td>
          <td align="left" rowspan="1" colspan="1">
Marchini et al. [<xref rid="B41" ref-type="bibr">18</xref>]</td>
          <td align="left" rowspan="1" colspan="1">R and MATLAB</td>
          <td align="left" rowspan="1" colspan="1">ICA algorithm is provided for implementing the analysis using ICA</td>
        </tr>
        <tr>
          <td align="center" colspan="5" rowspan="1">
            <hr/>
          </td>
        </tr>
        <tr>
          <td align="left" rowspan="1" colspan="1">2</td>
          <td align="left" rowspan="1" colspan="1">JADE</td>
          <td align="left" rowspan="1" colspan="1">Nordhausen et al. [<xref rid="B47" ref-type="bibr">19</xref>]</td>
          <td align="left" rowspan="1" colspan="1">R</td>
          <td align="left" rowspan="1" colspan="1">(i) JADE algorithm is provided for ICA<break/>(ii) Other BSS methods such as AMUSE and SOBI are offered</td>
        </tr>
        <tr>
          <td align="center" colspan="5" rowspan="1">
            <hr/>
          </td>
        </tr>
        <tr>
          <td align="left" rowspan="1" colspan="1">3</td>
          <td align="left" rowspan="1" colspan="1">HiPerSAT</td>
          <td align="left" rowspan="1" colspan="1">Keith et al. [<xref rid="B33" ref-type="bibr">20</xref>]</td>
          <td align="left" rowspan="1" colspan="1">C++, MATLAB, and EEGLAB</td>
          <td align="left" rowspan="1" colspan="1">(i) Integration of FastICA, Informax, and SOBI algorithms<break/>(ii) Data whitening is provided</td>
        </tr>
        <tr>
          <td align="center" colspan="5" rowspan="1">
            <hr/>
          </td>
        </tr>
        <tr>
          <td align="left" rowspan="1" colspan="1">4</td>
          <td align="left" rowspan="1" colspan="1">MineICA</td>
          <td align="left" rowspan="1" colspan="1">Biton et al. [<xref rid="B10" ref-type="bibr">21</xref>]</td>
          <td align="left" rowspan="1" colspan="1">R</td>
          <td align="left" rowspan="1" colspan="1">(i) Storage and visualization of ICA results<break/>(ii) Annotation of features</td>
        </tr>
        <tr>
          <td align="center" colspan="5" rowspan="1">
            <hr/>
          </td>
        </tr>
        <tr>
          <td align="left" rowspan="1" colspan="1">5</td>
          <td align="left" rowspan="1" colspan="1">Pearson ICA</td>
          <td align="left" rowspan="1" colspan="1">Karnanen [<xref rid="B32" ref-type="bibr">22</xref>]</td>
          <td align="left" rowspan="1" colspan="1">R</td>
          <td align="left" rowspan="1" colspan="1">Extraction of the independent components using the minimization of mutual information from the Pearson system</td>
        </tr>
        <tr>
          <td align="center" colspan="5" rowspan="1">
            <hr/>
          </td>
        </tr>
        <tr>
          <td align="left" rowspan="1" colspan="1">6</td>
          <td align="left" rowspan="1" colspan="1">Maximum Likelihood ICA</td>
          <td align="left" rowspan="1" colspan="1">Teschenforff [<xref rid="B48" ref-type="bibr">23</xref>]</td>
          <td align="left" rowspan="1" colspan="1">R</td>
          <td align="left" rowspan="1" colspan="1">Implementation of the Maximum Likelihood and fixed-point algorithm into ICA</td>
        </tr>
      </tbody>
    </table>
  </table-wrap>
  <table-wrap id="tab5" orientation="portrait" position="float">
    <label>Table 5</label>
    <caption>
      <p>Sources of ICA software.</p>
    </caption>
    <table frame="hsides" rules="groups">
      <thead>
        <tr>
          <th align="left" rowspan="1" colspan="1">Number</th>
          <th align="left" rowspan="1" colspan="1">Software</th>
          <th align="left" rowspan="1" colspan="1">Sources</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td align="left" rowspan="2" colspan="1">1</td>
          <td align="left" rowspan="2" colspan="1">FastICA</td>
          <td align="left" rowspan="1" colspan="1">R: <ext-link ext-link-type="uri" xlink:href="http://cran.r-project.org/web/packages/fastICA/index.html">http://cran.r-project.org/web/packages/fastICA/index.html</ext-link>
</td>
        </tr>
        <tr>
          <td align="left" rowspan="1" colspan="1">MATLAB: <ext-link ext-link-type="uri" xlink:href="http://research.ics.aalto.fi/ica/fastica/">http://research.ics.aalto.fi/ica/fastica/</ext-link>
</td>
        </tr>
        <tr>
          <td align="left" rowspan="1" colspan="1">2</td>
          <td align="left" rowspan="1" colspan="1">JADE</td>
          <td align="left" rowspan="1" colspan="1">
            <ext-link ext-link-type="uri" xlink:href="http://cran.r-project.org/web/packages/JADE/index.html">http://cran.r-project.org/web/packages/JADE/index.html</ext-link>
          </td>
        </tr>
        <tr>
          <td align="left" rowspan="1" colspan="1">3</td>
          <td align="left" rowspan="1" colspan="1">HiPerSAT</td>
          <td align="left" rowspan="1" colspan="1">
            <ext-link ext-link-type="uri" xlink:href="http://nic.uoregon.edu/projects/hipersat/index.php">http://nic.uoregon.edu/projects/hipersat/index.php</ext-link>
          </td>
        </tr>
        <tr>
          <td align="left" rowspan="1" colspan="1">4</td>
          <td align="left" rowspan="1" colspan="1">MineICA</td>
          <td align="left" rowspan="1" colspan="1">
            <ext-link ext-link-type="uri" xlink:href="http://www.bioconductor.org/packages/2.12/bioc/html/MineICA.html">http://www.bioconductor.org/packages/2.12/bioc/html/MineICA.html</ext-link>
          </td>
        </tr>
        <tr>
          <td align="left" rowspan="1" colspan="1">5</td>
          <td align="left" rowspan="1" colspan="1">Pearson ICA</td>
          <td align="left" rowspan="1" colspan="1">
            <ext-link ext-link-type="uri" xlink:href="http://cran.r-project.org/web/packages/PearsonICA/index.html">http://cran.r-project.org/web/packages/PearsonICA/index.html</ext-link>
          </td>
        </tr>
        <tr>
          <td align="left" rowspan="1" colspan="1">6</td>
          <td align="left" rowspan="1" colspan="1">Maximum Likelihood ICA</td>
          <td align="left" rowspan="1" colspan="1">
            <ext-link ext-link-type="uri" xlink:href="http://cran.r-project.org/web/packages/mlica2/index.html">http://cran.r-project.org/web/packages/mlica2/index.html</ext-link>
          </td>
        </tr>
      </tbody>
    </table>
  </table-wrap>
  <table-wrap id="tab6" orientation="portrait" position="float">
    <label>Table 6</label>
    <caption>
      <p>A summary of PLS software.</p>
    </caption>
    <table frame="hsides" rules="groups">
      <thead>
        <tr>
          <th align="left" rowspan="1" colspan="1">Number</th>
          <th align="left" rowspan="1" colspan="1">Software</th>
          <th align="left" rowspan="1" colspan="1">Author/year</th>
          <th align="left" rowspan="1" colspan="1">Language</th>
          <th align="left" rowspan="1" colspan="1">Features</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td align="left" rowspan="1" colspan="1">1</td>
          <td align="left" rowspan="1" colspan="1">PLS Discriminant Analysis</td>
          <td align="left" rowspan="1" colspan="1">
Barker and Rayens [<xref rid="B4" ref-type="bibr">24</xref>]</td>
          <td align="left" rowspan="1" colspan="1">C/C++, Visual Basic</td>
          <td align="left" rowspan="1" colspan="1">PLS for discriminant analysis</td>
        </tr>
        <tr>
          <td align="center" colspan="5" rowspan="1">
            <hr/>
          </td>
        </tr>
        <tr>
          <td align="left" rowspan="1" colspan="1">2</td>
          <td align="left" rowspan="1" colspan="1">Least Squares–PLS</td>
          <td align="left" rowspan="1" colspan="1">
Jørgensen et al. [<xref rid="B30" ref-type="bibr">25</xref>]</td>
          <td align="left" rowspan="1" colspan="1">R </td>
          <td align="left" rowspan="1" colspan="1">Implementation combining PLS and ordinary least squares</td>
        </tr>
        <tr>
          <td align="center" colspan="5" rowspan="1">
            <hr/>
          </td>
        </tr>
        <tr>
          <td align="left" rowspan="1" colspan="1">3</td>
          <td align="left" rowspan="1" colspan="1">Powered PLS Discriminant Analysis</td>
          <td align="left" rowspan="1" colspan="1">Liland and Indahl [<xref rid="B39" ref-type="bibr">26</xref>]</td>
          <td align="left" rowspan="1" colspan="1">R</td>
          <td align="left" rowspan="1" colspan="1">Extraction of information for multivariate classification problems</td>
        </tr>
        <tr>
          <td align="center" colspan="5" rowspan="1">
            <hr/>
          </td>
        </tr>
        <tr>
          <td align="left" rowspan="1" colspan="1">4</td>
          <td align="left" rowspan="1" colspan="1">Penalized PLS</td>
          <td align="left" rowspan="1" colspan="1">
Kr<inline-formula><mml:math id="M9"><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mtext>a</mml:mtext></mml:mrow><mml:mo mathvariant="normal">¨</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula>mer et al. (2008) [<xref rid="B35" ref-type="bibr">27</xref>]</td>
          <td align="left" rowspan="1" colspan="1">R</td>
          <td align="left" rowspan="1" colspan="1">Extension of PLS regression using penalization technique</td>
        </tr>
        <tr>
          <td align="center" colspan="5" rowspan="1">
            <hr/>
          </td>
        </tr>
        <tr>
          <td align="left" rowspan="1" colspan="1">5</td>
          <td align="left" rowspan="1" colspan="1">SlimPLS</td>
          <td align="left" rowspan="1" colspan="1">Gutkin et al. [<xref rid="B32" ref-type="bibr">22</xref>]</td>
          <td align="left" rowspan="1" colspan="1">R</td>
          <td align="left" rowspan="1" colspan="1">Multivariate feature extraction method which incorporates feature dependencies</td>
        </tr>
        <tr>
          <td align="center" colspan="5" rowspan="1">
            <hr/>
          </td>
        </tr>
        <tr>
          <td align="left" rowspan="1" colspan="1">6</td>
          <td align="left" rowspan="1" colspan="1">Sparse PLS Discriminant Analysis, Sparse Generalized PLS</td>
          <td align="left" rowspan="1" colspan="1">Chung and Keles [<xref rid="B13" ref-type="bibr">28</xref>]</td>
          <td align="left" rowspan="1" colspan="1">R</td>
          <td align="left" rowspan="1" colspan="1">Sparse version techniques employing feature extraction and dimension reduction simultaneously</td>
        </tr>
        <tr>
          <td align="center" colspan="5" rowspan="1">
            <hr/>
          </td>
        </tr>
        <tr>
          <td align="left" rowspan="1" colspan="1">7</td>
          <td align="left" rowspan="1" colspan="1">PLS Degrees of Freedom</td>
          <td align="left" rowspan="1" colspan="1">Kramer and Sugiyama [<xref rid="B36" ref-type="bibr">29</xref>]</td>
          <td align="left" rowspan="1" colspan="1">R</td>
          <td align="left" rowspan="1" colspan="1">Using an unbiased estimation of the degrees of freedom for PLS regression</td>
        </tr>
        <tr>
          <td align="center" colspan="5" rowspan="1">
            <hr/>
          </td>
        </tr>
        <tr>
          <td align="left" rowspan="1" colspan="1">8</td>
          <td align="left" rowspan="1" colspan="1">Surrogate Variable Analysis PLS</td>
          <td align="left" rowspan="1" colspan="1">
Chakraborty and Datta [<xref rid="B12" ref-type="bibr">30</xref>]</td>
          <td align="left" rowspan="1" colspan="1">R</td>
          <td align="left" rowspan="1" colspan="1">Extraction of the informative features with hidden confounders which are unaccounted for</td>
        </tr>
        <tr>
          <td align="center" colspan="5" rowspan="1">
            <hr/>
          </td>
        </tr>
        <tr>
          <td align="left" rowspan="1" colspan="1">9</td>
          <td align="left" rowspan="1" colspan="1">PLS Path Modelling</td>
          <td align="left" rowspan="1" colspan="1">Sanchez and Trinchera [<xref rid="B57" ref-type="bibr">31</xref>]</td>
          <td align="left" rowspan="1" colspan="1">R</td>
          <td align="left" rowspan="1" colspan="1">A multivariate feature extraction analysis technique based on the cause-effect relationships of the unobserved and observed features</td>
        </tr>
        <tr>
          <td align="center" colspan="5" rowspan="1">
            <hr/>
          </td>
        </tr>
        <tr>
          <td align="left" rowspan="1" colspan="1">10</td>
          <td align="left" rowspan="1" colspan="1">PLS Regression for Generalized Linear Models</td>
          <td align="left" rowspan="1" colspan="1">
Bertrand et al. (2013) [<xref rid="B8" ref-type="bibr">32</xref>]</td>
          <td align="left" rowspan="1" colspan="1">R</td>
          <td align="left" rowspan="1" colspan="1">PLS regression is used to extract the predictive features from the generalized linear models</td>
        </tr>
      </tbody>
    </table>
  </table-wrap>
  <table-wrap id="tab7" orientation="portrait" position="float">
    <label>Table 7</label>
    <caption>
      <p>Sources of PLS software.</p>
    </caption>
    <table frame="hsides" rules="groups">
      <thead>
        <tr>
          <th align="left" rowspan="1" colspan="1">Number</th>
          <th align="left" rowspan="1" colspan="1">Software</th>
          <th align="left" rowspan="1" colspan="1">Sources</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td align="left" rowspan="1" colspan="1">1</td>
          <td align="left" rowspan="1" colspan="1">PLS Discriminant Analysis</td>
          <td align="left" rowspan="1" colspan="1">
            <ext-link ext-link-type="uri" xlink:href="http://www.camo.com/downloads/sample-data.html">http://www.camo.com/downloads/sample-data.html</ext-link>
          </td>
        </tr>
        <tr>
          <td align="left" rowspan="1" colspan="1">2</td>
          <td align="left" rowspan="1" colspan="1">Least Squares–PLS</td>
          <td align="left" rowspan="1" colspan="1">
            <ext-link ext-link-type="uri" xlink:href="http://cran.r-project.org/web/packages/lspls/index.html">http://cran.r-project.org/web/packages/lspls/index.html</ext-link>
          </td>
        </tr>
        <tr>
          <td align="left" rowspan="1" colspan="1">3</td>
          <td align="left" rowspan="1" colspan="1">Powered PLS Discriminant Analysis</td>
          <td align="left" rowspan="1" colspan="1">
            <ext-link ext-link-type="uri" xlink:href="http://cran.r-project.org/web/packages/pls/index.html">http://cran.r-project.org/web/packages/pls/index.html</ext-link>
          </td>
        </tr>
        <tr>
          <td align="left" rowspan="1" colspan="1">4</td>
          <td align="left" rowspan="1" colspan="1">Penalized PLS</td>
          <td align="left" rowspan="1" colspan="1">
            <ext-link ext-link-type="uri" xlink:href="http://cran.r-project.org/web/packages/ppls/index.html">http://cran.r-project.org/web/packages/ppls/index.html</ext-link>
          </td>
        </tr>
        <tr>
          <td align="left" rowspan="1" colspan="1">5</td>
          <td align="left" rowspan="1" colspan="1">SlimPLS</td>
          <td align="left" rowspan="1" colspan="1">
            <ext-link ext-link-type="uri" xlink:href="http://cran.r-project.org/web/packages/SlimPLS/index.html">http://cran.r-project.org/web/packages/SlimPLS/index.html</ext-link>
          </td>
        </tr>
        <tr>
          <td align="left" rowspan="1" colspan="1">6</td>
          <td align="left" rowspan="1" colspan="1">Sparse PLS Discriminant Analysis, Sparse Generalized PLS</td>
          <td align="left" rowspan="1" colspan="1">
            <ext-link ext-link-type="uri" xlink:href="http://cran.r-project.org/web/packages/spls/index.html">http://cran.r-project.org/web/packages/spls/index.html</ext-link>
          </td>
        </tr>
        <tr>
          <td align="left" rowspan="1" colspan="1">7</td>
          <td align="left" rowspan="1" colspan="1">Degrees of Freedom of PLS</td>
          <td align="left" rowspan="1" colspan="1">
            <ext-link ext-link-type="uri" xlink:href="http://cran.r-project.org/web/packages/plsdof/index.html">http://cran.r-project.org/web/packages/plsdof/index.html</ext-link>
          </td>
        </tr>
        <tr>
          <td align="left" rowspan="1" colspan="1">8</td>
          <td align="left" rowspan="1" colspan="1">Surrogate Variable Analysis PLS</td>
          <td align="left" rowspan="1" colspan="1">
            <ext-link ext-link-type="uri" xlink:href="http://cran.r-project.org/web/packages/svapls/index.html">http://cran.r-project.org/web/packages/svapls/index.html</ext-link>
          </td>
        </tr>
        <tr>
          <td align="left" rowspan="1" colspan="1">9</td>
          <td align="left" rowspan="1" colspan="1">PLS Path Modelling</td>
          <td align="left" rowspan="1" colspan="1">
            <ext-link ext-link-type="uri" xlink:href="http://cran.r-project.org/web/packages/plspm/index.html">http://cran.r-project.org/web/packages/plspm/index.html</ext-link>
          </td>
        </tr>
        <tr>
          <td align="left" rowspan="1" colspan="1">10</td>
          <td align="left" rowspan="1" colspan="1">PLS Regression for Generalized Linear Models</td>
          <td align="left" rowspan="1" colspan="1">
            <ext-link ext-link-type="uri" xlink:href="http://cran.r-project.org/web/packages/plsRglm/index.html">http://cran.r-project.org/web/packages/plsRglm/index.html</ext-link>
          </td>
        </tr>
      </tbody>
    </table>
  </table-wrap>
  <table-wrap id="tab8" orientation="portrait" position="float">
    <label>Table 8</label>
    <caption>
      <p>Related work.</p>
    </caption>
    <table frame="hsides" rules="groups">
      <thead>
        <tr>
          <th align="left" rowspan="1" colspan="1">Software</th>
          <th align="left" rowspan="1" colspan="1">Author</th>
          <th align="left" rowspan="1" colspan="1">Motivation</th>
          <th align="left" rowspan="1" colspan="1">Advantage</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td align="left" rowspan="1" colspan="1">plsRglm (R package)</td>
          <td align="left" rowspan="1" colspan="1">
Bertrand et al. (2010) [<xref rid="B8" ref-type="bibr">32</xref>]</td>
          <td align="left" rowspan="1" colspan="1">(i) To deal with incomplete datasets using cross-validation<break/>(ii) To extend PLS regression to generalized linear models</td>
          <td align="left" rowspan="1" colspan="1">(i) Provides formula support<break/>(ii) Several new classes and their generics<break/>(iii) Custom GLR models and graphics to assess the bootstrap based significance of the predictors</td>
        </tr>
        <tr>
          <td align="center" colspan="4" rowspan="1">
            <hr/>
          </td>
        </tr>
        <tr>
          <td align="left" rowspan="1" colspan="1">SVA-PLS</td>
          <td align="left" rowspan="1" colspan="1">
Chakraborty and Datta [<xref rid="B12" ref-type="bibr">30</xref>]</td>
          <td align="left" rowspan="1" colspan="1">(i) To identify the genes that are differentially expressed between the samples from two different tissue types<break/>(ii) To identify the hidden effects of the underlying latent factors in a gene expression profiling study</td>
          <td align="left" rowspan="1" colspan="1">(i) Relatively better at discovering a higher proportion of the truly significant genes<break/>(ii) Low error rate<break/>(iii) High sensitivity and specificity</td>
        </tr>
        <tr>
          <td align="center" colspan="4" rowspan="1">
            <hr/>
          </td>
        </tr>
        <tr>
          <td align="left" rowspan="1" colspan="1">SlimPLS</td>
          <td align="left" rowspan="1" colspan="1">Gutkin et al. [<xref rid="B23" ref-type="bibr">33</xref>]</td>
          <td align="left" rowspan="1" colspan="1">To obtain a low dimensional approximation of a matrix that is “as close as possible” to a given vector</td>
          <td align="left" rowspan="1" colspan="1">(i) Focuses solely on feature selection<break/>(ii) Can be used as a pre-processing stage with different classifiers</td>
        </tr>
      </tbody>
    </table>
  </table-wrap>
  <table-wrap id="tab9" orientation="portrait" position="float">
    <label>Table 9</label>
    <caption>
      <p>A summary of LLE software.</p>
    </caption>
    <table frame="hsides" rules="groups">
      <thead>
        <tr>
          <th align="left" rowspan="1" colspan="1">Number</th>
          <th align="left" rowspan="1" colspan="1">Software</th>
          <th align="left" rowspan="1" colspan="1">Author/year</th>
          <th align="left" rowspan="1" colspan="1">Language</th>
          <th align="left" rowspan="1" colspan="1">Features</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td align="left" rowspan="1" colspan="1">1</td>
          <td align="left" rowspan="1" colspan="1">lle</td>
          <td align="left" rowspan="1" colspan="1">Diedrich and Abel [<xref rid="B17" ref-type="bibr">34</xref>]</td>
          <td align="left" rowspan="1" colspan="1">R</td>
          <td align="left" rowspan="1" colspan="1">(i) LLE algorithm is provided for transforming high-dimensional data into low-dimensional data <break/>(ii) Selection of subset and calculation of the intrinsic dimension are provided</td>
        </tr>
        <tr>
          <td align="center" colspan="5" rowspan="1">
            <hr/>
          </td>
        </tr>
        <tr>
          <td align="left" rowspan="1" colspan="1">2</td>
          <td align="left" rowspan="1" colspan="1">RDRToolbox</td>
          <td align="left" rowspan="1" colspan="1">Bartenhagen [<xref rid="B5" ref-type="bibr">35</xref>]</td>
          <td align="left" rowspan="1" colspan="1">R</td>
          <td align="left" rowspan="1" colspan="1">(i) LLE and Isomap for feature extraction<break/>(ii) Davis-Bouldin Index for the purpose of validating clusters</td>
        </tr>
        <tr>
          <td align="center" colspan="5" rowspan="1">
            <hr/>
          </td>
        </tr>
        <tr>
          <td align="left" rowspan="1" colspan="1">3</td>
          <td align="left" rowspan="1" colspan="1">Scikit-learn</td>
          <td align="left" rowspan="1" colspan="1">Pedregosa et al. [<xref rid="B53" ref-type="bibr">36</xref>]</td>
          <td align="left" rowspan="1" colspan="1">Python</td>
          <td align="left" rowspan="1" colspan="1">(i) Classification, manifold learning, feature extraction, clustering, and other methods are offered<break/>(ii) LLE, Isomap, and LTSA are provided</td>
        </tr>
      </tbody>
    </table>
  </table-wrap>
  <table-wrap id="tab10" orientation="portrait" position="float">
    <label>Table 10</label>
    <caption>
      <p>Sources of LLE software.</p>
    </caption>
    <table frame="hsides" rules="groups">
      <thead>
        <tr>
          <th align="left" rowspan="1" colspan="1">Number</th>
          <th align="left" rowspan="1" colspan="1">Software</th>
          <th align="left" rowspan="1" colspan="1">Sources</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td align="left" rowspan="1" colspan="1">1</td>
          <td align="left" rowspan="1" colspan="1">lle</td>
          <td align="left" rowspan="1" colspan="1">
            <ext-link ext-link-type="uri" xlink:href="http://cran.r-project.org/web/packages/lle/index.html">http://cran.r-project.org/web/packages/lle/index.html</ext-link>
          </td>
        </tr>
        <tr>
          <td align="left" rowspan="1" colspan="1">2</td>
          <td align="left" rowspan="1" colspan="1">RDRToolbox</td>
          <td align="left" rowspan="1" colspan="1">
            <ext-link ext-link-type="uri" xlink:href="http://www.bioconductor.org/packages/2.12/bioc/html/RDRToolbox.html">http://www.bioconductor.org/packages/2.12/bioc/html/RDRToolbox.html</ext-link>
          </td>
        </tr>
        <tr>
          <td align="left" rowspan="1" colspan="1">3</td>
          <td align="left" rowspan="1" colspan="1">Scikit-learn</td>
          <td align="left" rowspan="1" colspan="1">
            <ext-link ext-link-type="uri" xlink:href="http://scikit-learn.org/dev/install.html">http://scikit-learn.org/dev/install.html</ext-link>
          </td>
        </tr>
      </tbody>
    </table>
  </table-wrap>
  <table-wrap id="tab11" orientation="portrait" position="float">
    <label>Table 11</label>
    <caption>
      <p>Related work.</p>
    </caption>
    <table frame="hsides" rules="groups">
      <thead>
        <tr>
          <th align="left" rowspan="1" colspan="1">Software</th>
          <th align="left" rowspan="1" colspan="1">Author</th>
          <th align="left" rowspan="1" colspan="1">Motivation</th>
          <th align="left" rowspan="1" colspan="1">Advantage</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td align="left" rowspan="1" colspan="1">RDRToolbox</td>
          <td align="left" rowspan="1" colspan="1">Bartenhagen [<xref rid="B5" ref-type="bibr">35</xref>]</td>
          <td align="left" rowspan="1" colspan="1">(i) To reduce high dimensionality microarray data <break/>(ii) To preserve most of the significant information and generate data with similar characteristics like the high-dimensional original</td>
          <td align="left" rowspan="1" colspan="1">(i) Combine information from all features<break/>(ii) Suited for low-dimensional representations of the whole data</td>
        </tr>
        <tr>
          <td align="center" colspan="4" rowspan="1">
            <hr/>
          </td>
        </tr>
        <tr>
          <td align="left" rowspan="1" colspan="1">Scikit-learn</td>
          <td align="left" rowspan="1" colspan="1">
Pedregosa et al. [<xref rid="B53" ref-type="bibr">36</xref>]</td>
          <td align="left" rowspan="1" colspan="1">To calculate activity index parameters through clustering</td>
          <td align="left" rowspan="1" colspan="1">(i) Easy-to-use interface<break/>(ii) Can easily be integrated into applications outside the traditional range of statistical data analysis</td>
        </tr>
        <tr>
          <td align="center" colspan="4" rowspan="1">
            <hr/>
          </td>
        </tr>
        <tr>
          <td align="left" rowspan="1" colspan="1">lle</td>
          <td align="left" rowspan="1" colspan="1">
Diedrich and Abel [<xref rid="B17" ref-type="bibr">34</xref>]</td>
          <td align="left" rowspan="1" colspan="1">Currently available data dimension reduction methods are either supervised, where data need to be labeled, or computational complex</td>
          <td align="left" rowspan="1" colspan="1">(i) Fast<break/>(ii) Purely unsupervised</td>
        </tr>
      </tbody>
    </table>
  </table-wrap>
</floats-group>
