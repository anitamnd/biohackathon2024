<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Nat Commun</journal-id>
    <journal-id journal-id-type="iso-abbrev">Nat Commun</journal-id>
    <journal-title-group>
      <journal-title>Nature Communications</journal-title>
    </journal-title-group>
    <issn pub-type="epub">2041-1723</issn>
    <publisher>
      <publisher-name>Nature Publishing Group UK</publisher-name>
      <publisher-loc>London</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">8121839</article-id>
    <article-id pub-id-type="publisher-id">23196</article-id>
    <article-id pub-id-type="doi">10.1038/s41467-021-23196-8</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Article</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Hierarchical progressive learning of cell identities in single-cell data</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-4615-1309</contrib-id>
        <name>
          <surname>Michielsen</surname>
          <given-names>Lieke</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff2">2</xref>
        <xref ref-type="aff" rid="Aff3">3</xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-1148-1562</contrib-id>
        <name>
          <surname>Reinders</surname>
          <given-names>Marcel J. T.</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff2">2</xref>
        <xref ref-type="aff" rid="Aff3">3</xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-8601-2149</contrib-id>
        <name>
          <surname>Mahfouz</surname>
          <given-names>Ahmed</given-names>
        </name>
        <address>
          <email>a.mahfouz@lumc.nl</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff2">2</xref>
        <xref ref-type="aff" rid="Aff3">3</xref>
      </contrib>
      <aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="GRID">grid.10419.3d</institution-id><institution-id institution-id-type="ISNI">0000000089452978</institution-id><institution>Department of Human Genetics, </institution><institution>Leiden University Medical Center, </institution></institution-wrap>Leiden, The Netherlands </aff>
      <aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="GRID">grid.10419.3d</institution-id><institution-id institution-id-type="ISNI">0000000089452978</institution-id><institution>Leiden Computational Biology Center, Leiden University Medical Center, </institution></institution-wrap>Leiden, The Netherlands </aff>
      <aff id="Aff3"><label>3</label><institution-wrap><institution-id institution-id-type="GRID">grid.5292.c</institution-id><institution-id institution-id-type="ISNI">0000 0001 2097 4740</institution-id><institution>Delft Bioinformatics Lab, Delft University of Technology, </institution></institution-wrap>Delft, The Netherlands </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>14</day>
      <month>5</month>
      <year>2021</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>14</day>
      <month>5</month>
      <year>2021</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2021</year>
    </pub-date>
    <volume>12</volume>
    <elocation-id>2799</elocation-id>
    <history>
      <date date-type="received">
        <day>26</day>
        <month>8</month>
        <year>2020</year>
      </date>
      <date date-type="accepted">
        <day>16</day>
        <month>4</month>
        <year>2021</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2021</copyright-statement>
      <license>
        <ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. The images or other third party material in this article are included in the article’s Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this license, visit <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>.</license-p>
      </license>
    </permissions>
    <abstract id="Abs1">
      <p id="Par1">Supervised methods are increasingly used to identify cell populations in single-cell data. Yet, current methods are limited in their ability to learn from multiple datasets simultaneously, are hampered by the annotation of datasets at different resolutions, and do not preserve annotations when retrained on new datasets. The latter point is especially important as researchers cannot rely on downstream analysis performed using earlier versions of the dataset. Here, we present scHPL, a hierarchical progressive learning method which allows continuous learning from single-cell data by leveraging the different resolutions of annotations across multiple datasets to learn and continuously update a classification tree. We evaluate the classification and tree learning performance using simulated as well as real datasets and show that scHPL can successfully learn known cellular hierarchies from multiple datasets while preserving the original annotations. scHPL is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/lcmmichielsen/hierarchicalprogressivelearning">https://github.com/lcmmichielsen/scHPL</ext-link>.</p>
    </abstract>
    <abstract id="Abs2" abstract-type="web-summary">
      <p id="Par2">Classification methods for scRNA-seq data are limited in their ability to learn from multiple datasets simultaneously. Here the authors present scHPL, a hierarchical progressive learning method that automatically finds relationships between cell populations across multiple datasets and constructs a classification tree.</p>
    </abstract>
    <kwd-group kwd-group-type="npg-subject">
      <title>Subject terms</title>
      <kwd>Data processing</kwd>
      <kwd>Machine learning</kwd>
      <kwd>Gene expression</kwd>
    </kwd-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">https://doi.org/10.13039/501100003246</institution-id>
            <institution>Nederlandse Organisatie voor Wetenschappelijk Onderzoek (Netherlands Organisation for Scientific Research)</institution>
          </institution-wrap>
        </funding-source>
        <award-id>024.004.012</award-id>
        <principal-award-recipient>
          <name>
            <surname>Michielsen</surname>
            <given-names>Lieke</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
    </funding-group>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>© The Author(s) 2021</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="Sec1" sec-type="introduction">
    <title>Introduction</title>
    <p id="Par3">Cell identification is an essential step in single-cell studies with profound effects on downstream analysis. For example, in order to compare cell-population-specific eQTL findings across studies, cell identities should be consistent<sup><xref ref-type="bibr" rid="CR1">1</xref></sup>. Currently, cells in single-cell RNA-sequencing (scRNA-seq) datasets are primarily annotated using clustering and visual exploration techniques, i.e., cells are first clustered into populations that are subsequently named based on the expression of marker genes. This is not only time-consuming but also subjective<sup><xref ref-type="bibr" rid="CR2">2</xref></sup>. The number of cell populations identified in a dataset, for example, is strongly correlated with the number of cells analyzed, which results in inconsistency across datasets<sup><xref ref-type="bibr" rid="CR3">3</xref>–<xref ref-type="bibr" rid="CR5">5</xref></sup>.</p>
    <p id="Par4">Recently, many supervised methods have been developed to replace unsupervised techniques. The underlying principles of these methods vary greatly. Some methods, for instance, rely on prior knowledge and assume that for each cell population marker genes can be defined (e.g., SCINA<sup><xref ref-type="bibr" rid="CR6">6</xref></sup> and Garnett<sup><xref ref-type="bibr" rid="CR7">7</xref></sup>), while others search for similar cells in a reference database (e.g., scmap<sup><xref ref-type="bibr" rid="CR8">8</xref></sup> and Cell-BLAST<sup><xref ref-type="bibr" rid="CR9">9</xref></sup>), or train a classifier using a reference atlas or a labeled dataset (e.g., scPred<sup><xref ref-type="bibr" rid="CR10">10</xref></sup> and CHETAH<sup><xref ref-type="bibr" rid="CR11">11</xref></sup>).</p>
    <p id="Par5">Supervised methods rely either on a reference atlas or labeled dataset. Ideally, we would use a reference atlas containing all possible cell populations to train a classifier. Such an atlas, however, does not exist yet and might never be fully complete. In particular, aberrant cell populations might be missing as a huge number of diseases exist and mutations could result in new cell populations. To overcome these limitations, some methods (e.g., OnClass) rely on the Cell Ontology to identify cell populations that are missing from the training data but do exist in the Cell Ontology database<sup><xref ref-type="bibr" rid="CR12">12</xref></sup>. These Cell Ontologies, however, were not developed for scRNA-seq data specifically. As a consequence, many newly identified (sub)populations are missing and relationships between cell populations might be inaccurate. A striking example of this inadequacy is neuronal cell populations. Recent single-cell studies have identified hundreds of populations<sup><xref ref-type="bibr" rid="CR4">4</xref>,<xref ref-type="bibr" rid="CR13">13</xref>,<xref ref-type="bibr" rid="CR14">14</xref></sup>, including seven subtypes and 92 cell populations in one study only<sup><xref ref-type="bibr" rid="CR5">5</xref></sup>. In contrast, the Cell Ontology currently includes only one glutamatergic neuronal cell population without any subtypes.</p>
    <p id="Par6">Since no complete reference atlas is available, a classifier should ideally be able to combine the information of multiple annotated datasets and continue learning. Each time a new cell population is found in a dataset, it should be added to the knowledge of the classifier. We advocate that this can be realized with progressive learning, a learning strategy inspired by humans. Human learning is a continuous process that never ends<sup><xref ref-type="bibr" rid="CR15">15</xref></sup>. Using progressive learning, the task complexity is gradually increased, for instance, by adding more classes, but it is essential that the knowledge of the previous classes is preserved<sup><xref ref-type="bibr" rid="CR16">16</xref>,<xref ref-type="bibr" rid="CR17">17</xref></sup>. This strategy allows combining information of multiple existing datasets and retaining the possibility to add more datasets afterward. However, it cannot be simply applied to scRNA-seq datasets as a constant terminology to describe cell populations is missing, which eliminates straightforward identification of new cell populations based on their names. For example, the recently discovered neuronal populations are typically identified using clustering and named based on the expression of marker genes. A standardized nomenclature for these clusters is missing<sup><xref ref-type="bibr" rid="CR18">18</xref></sup>, so the relationship between cell populations defined in different datasets is often unknown.</p>
    <p id="Par7">Moreover, the level of detail (resolution) at which datasets are annotated highly depends on the number of cells analyzed<sup><xref ref-type="bibr" rid="CR19">19</xref></sup>. For instance, if a dataset is annotated at a low resolution, it might contain T cells, while a dataset at a higher resolution can include subpopulations of T cells, such as CD4+ and CD8+ T cells. We need to consider this hierarchy of cell populations in our representation, which can be done with a hierarchical classifier. This has the advantage that cell population definitions of multiple datasets can be combined, ensuring consistency. A hierarchical classifier has additional advantages in comparison to a classifier that does not exploit this hierarchy between classes (here denoted as “flat classifier”). One of these advantages is that the classification problem is divided into smaller sub-problems, while a flat classifier needs to distinguish between many classes simultaneously. Another advantage is that if we are not sure about the annotation of an unlabeled cell at the highest resolution, we can always label it as an intermediate cell population (i.e., at a lower resolution).</p>
    <p id="Par8">Currently, some classifiers, such as Garnett, CHETAH, and Moana, already exploit this hierarchy between classes<sup><xref ref-type="bibr" rid="CR7">7</xref>,<xref ref-type="bibr" rid="CR11">11</xref>,<xref ref-type="bibr" rid="CR20">20</xref></sup>. Garnett and Moana both depend on prior knowledge in the form of marker genes for the different classes. Especially for deeper annotated datasets, it can be difficult to define marker genes for each cell population that are robust across scRNA-seq datasets<sup><xref ref-type="bibr" rid="CR21">21</xref>,<xref ref-type="bibr" rid="CR22">22</xref></sup>. Moreover, we have previously shown that adding prior knowledge is not beneficial<sup><xref ref-type="bibr" rid="CR23">23</xref></sup>. CHETAH, on the contrary, constructs a classification tree based on one dataset by hierarchically clustering the reference profiles of the cell populations and classifies new cells based on the similarity to the reference profile of that cell population. However, simple flat classifiers outperform CHETAH<sup><xref ref-type="bibr" rid="CR23">23</xref></sup>, indicating that a successful strategy to exploit this hierarchy is still missing. Furthermore, these hierarchical classifiers cannot exploit the different resolutions of multiple datasets as this requires adaptation of the hierarchical representation.</p>
    <p id="Par9">Even if multiple datasets are combined into a hierarchy, there might be unseen populations in an unlabeled dataset. Identifying these cells as a new population is a challenging problem. Although some classifiers have implemented an option to reject cells, they usually fail when being tested in a realistic scenario<sup><xref ref-type="bibr" rid="CR23">23</xref></sup>. In most cases, the rejection option is implemented by setting a threshold on the posterior probability<sup><xref ref-type="bibr" rid="CR7">7</xref>,<xref ref-type="bibr" rid="CR10">10</xref>,<xref ref-type="bibr" rid="CR23">23</xref>,<xref ref-type="bibr" rid="CR24">24</xref></sup>. If the highest posterior probability does not exceed a threshold, the cell is rejected. By looking at the posterior, the actual similarity between a cell and the cell population is ignored.</p>
    <p id="Par10">In this work, we propose a hierarchical progressive learning approach to overcome these challenges. To summarize our contributions: (i) we exploit the hierarchical relationships between cell populations to be able to classify data sets at different resolutions, (ii) we propose a progressive learning approach that updates the hierarchical relationships dynamically and consistently, and (iii) we adopt an advanced rejection procedure including a one-class classifier to be able to discover new cell (sub)populations.</p>
  </sec>
  <sec id="Sec2" sec-type="results">
    <title>Results</title>
    <sec id="Sec3">
      <title>Hierarchical progressive learning of cell identities</title>
      <p id="Par11">We developed scHPL, a hierarchical progressive learning approach to learn a classification tree using multiple labeled datasets (Fig. <xref rid="Fig1" ref-type="fig">1A</xref>) and use this tree to predict the labels of a new, unlabeled dataset (Fig. <xref rid="Fig1" ref-type="fig">1B</xref>). The tree is learned using multiple iterations (Methods). First, we match the labels of two datasets by training a flat classifier for each dataset and predicting the labels of the other dataset. Based on these predictions we create a matching matrix (<italic>X</italic>) and match the cell populations of the two datasets. In the matching process, we separate different biological scenarios, such as a perfect match, merging or splitting cell populations, as well as creating a new population (Fig. <xref rid="Fig2" ref-type="fig">2</xref>, Supplementary Table <xref rid="MOESM1" ref-type="media">1</xref>). In the following iterations, we add one labeled dataset at a time by training a flat classifier on this new dataset and training the previously learned tree on all pre-existing datasets. Similar to the previous iteration, the tree is updated after cross-prediction and matching of the labels. It could happen that datasets are inconsistently labeled and the labels cannot be matched (Supplementary Note <xref rid="MOESM1" ref-type="media">1</xref>). In this case, one of the populations might be missing from the tree.<fig id="Fig1"><label>Fig. 1</label><caption><title>Schematic overview of scHPL.</title><p><bold>a</bold> Overview of the training phase. In the first iteration, we start with two labeled datasets. The colored areas represent the different cell populations. For both datasets a flat classifier (FC1 and FC2) is constructed. Using this tree and the corresponding dataset, a classifier is trained for each node in the tree except for the root. We use the trained classification tree of one dataset to predict the labels of the other. The decision boundaries of the classifiers are indicated with the contour lines. We compare the predicted labels to the cluster labels to find matches between the labels of the two datasets. The tree belonging to the first dataset is updated according to these matches, which results in a hierarchical classifier (HC1). In dataset 2, for example, subpopulations of population “1” of dataset 1 are found. Therefore, these cell populations, “A” and “B”, are added as children to the “1” population. In iteration 2, a new labeled dataset is added. Again a flat classifier (FC3) is trained for this dataset and HC1 is trained on datasets 1 and 2, combined. After cross-prediction and matching the labels, we update the tree which is then trained on all datasets 1–3 (HC2). <bold>b</bold> The final classifier can be used to annotate a new unlabeled dataset. If this dataset contains unknown cell populations, these will be rejected.</p></caption><graphic xlink:href="41467_2021_23196_Fig1_HTML" id="d32e418"/></fig><fig id="Fig2"><label>Fig. 2</label><caption><title>Schematic examples of different matching scenarios.</title><p><bold>a</bold> Perfect match, <bold>b</bold> splitting, <bold>c</bold> merging, and <bold>d</bold> new population. The first two columns represent a schematic representation of two datasets. After cross-predictions, the matching matrix (<italic>X</italic>) is constructed using the confusion matrices (Methods). We update the tree based on <italic>X</italic>.</p></caption><graphic xlink:href="41467_2021_23196_Fig2_HTML" id="d32e446"/></fig></p>
      <p id="Par12">Either during tree learning or prediction, there can be unseen populations. Therefore, an efficient rejection option is needed, which we do in two steps. First, we reject cells by thresholding the reconstruction error of a cell when applying a PCA-based dimension reduction: a new, unknown, population is not used to learn the PCA transformation, and consequently will not be properly represented by the selected PCs, leading to a high reconstruction error (Methods). Second, to accommodate rejections when the new population is within the selected PCA domain, scHPL adopts two alternatives to classify cells: a linear and a one-class support vector machine (SVM). The linear SVM has shown high performance in a benchmark of scRNA-seq classifiers<sup><xref ref-type="bibr" rid="CR23">23</xref></sup> but has a limited rejection option. Whereas, the one-class SVM solves this as only positive training samples are used to fit a tight decision boundary<sup><xref ref-type="bibr" rid="CR25">25</xref></sup>.</p>
    </sec>
    <sec id="Sec4">
      <title>Linear SVM has a higher classification accuracy than one-class SVM</title>
      <p id="Par13">We tested our hierarchical classification scheme by measuring the classification performance of the one-class SVM and linear SVM on simulated, PBMC (PBMC-FACS) and brain (Allen Mouse Brain (AMB)) data using 10-, 10-, and 5-fold cross-validation respectively (Methods). The simulated dataset was constructed using Splatter<sup><xref ref-type="bibr" rid="CR26">26</xref></sup> and consists of 8839 cells, 9000 genes, and 6 different cell populations (Supplementary Fig. <xref rid="MOESM1" ref-type="media">1</xref>). PBMC-FACS is the downsampled FACS-sorted PBMC dataset from Zheng et al.<sup><xref ref-type="bibr" rid="CR27">27</xref></sup> and consists of 20,000 cells and 10 cell populations. The AMB dataset is challenging as it has deep annotation levels<sup><xref ref-type="bibr" rid="CR5">5</xref></sup>, containing 92 different cell populations ranging in size from 11 to 1348 cells. In these experiments, the classifiers were trained on predefined trees (Supplementary Figs. <xref rid="MOESM1" ref-type="media">1</xref>–<xref rid="MOESM1" ref-type="media">3</xref>).</p>
      <p id="Par14">On all datasets, the linear SVM performs better than the one-class SVM (Fig. <xref rid="Fig3" ref-type="fig">3A–D</xref>). The simulated dataset is relatively easy since the cell populations are widely separated (Supplementary Fig. <xref rid="MOESM1" ref-type="media">1C</xref>). The linear SVM shows an almost perfect performance: only 0.9% of the cells are rejected (based on the reconstruction error only), which is in line with the adopted threshold resulting in 1% false negatives. The one-class SVM labels 92.9% of the cells correctly, the rest is labeled as an internal node (2.3%) or rejected (4.8%), which results in a median Hierarchical F1-score (HF1-score) of 0.973, where HF1 is an F1-score that considers class importance across the hierarchy (Methods).<fig id="Fig3"><label>Fig. 3</label><caption><title>Classification performance.</title><p><bold>a–c</bold> Boxplots showing the HF1-score of the one-class and linear SVM during <italic>n</italic>-fold cross-validation on the <bold>a</bold> simulated (<italic>n</italic> = 10), <bold>b</bold> PBMC-FACS (<italic>n</italic> = 10), and <bold>c</bold> AMB (<italic>n</italic> = 5) dataset. In the boxplots, the middle (orange) line represents the median, the lower and upper hinge represents the first and third quartiles, and the lower and upper whiskers represent the values no further than 1.5 interquartile range away from the lower and upper hinge, respectively. <bold>d</bold> Barplot showing the percentage of true positives (TP), false negatives (FN), and false positives (FP) per classifier on the AMB dataset. For the TPs a distinction is made between correctly predicted leaf nodes and internal nodes. <bold>e</bold> Heatmap showing the percentage of unlabeled cells per classifier during the different rejection experiments. <bold>f</bold> Heatmap showing the F1-score per classifier per cell population on the AMB dataset. Gray indicates that a classifier never predicted a cell to be of that population.</p></caption><graphic xlink:href="41467_2021_23196_Fig3_HTML" id="d32e535"/></fig></p>
      <p id="Par15">As expected, the performance of the classifiers on real data drops, but the HF1-scores remain higher than 0.9. On both the PBMC-FACS and AMB dataset, the performance of the linear SVM is higher than the one-class SVM (Fig. <xref rid="Fig3" ref-type="fig">3B–D</xref>). For the AMB dataset, we used the same cross-validation folds as in Abdelaal et al.<sup><xref ref-type="bibr" rid="CR23">23</xref></sup>, which enables us to compare our results. When comparing to CHETAH, which allows hierarchical classification, we notice that the linear SVM performs better based on the median F1-score (0.94 vs. 0.83). The one-class SVM has a slightly lower median F1-score (0.80 vs. 0.83), but it has more correctly predicted cells and less wrongly predicted cells (Fig. <xref rid="Fig3" ref-type="fig">3D</xref>).</p>
      <p id="Par16">The linear (hierarchical) SVM also shows a better performance compared to SVM<sub>rejection</sub>, which is a flat linear SVM with a rejection option based on the posterior probability and was the best classifier for this data<sup><xref ref-type="bibr" rid="CR23">23</xref></sup>. SVM<sub>rejection</sub>, however, has a slightly higher median F1-score (0.98 vs. 0.94). This is mainly because it makes almost no mistakes, only 1.7% of the cells are wrongly labeled (Fig. <xref rid="Fig3" ref-type="fig">3D</xref>). The number of rejected cells, on the other hand, is not considered when calculating the median F1-score. This number is relatively high for SVM<sub>rejection</sub> (19.8%). The linear SVM, on the contrary, has almost no rejected cells, which is also reflected in a higher HF1-score (Fig. <xref rid="Fig3" ref-type="fig">3C</xref>). Because of this large amount of rejections of SVM<sub>rejection</sub>, the one-class SVM also has a higher HF1-score.</p>
      <p id="Par17">On the AMB dataset, we observe that the performance of all classifiers decreases when the number of cells per cell population becomes smaller. The performance of the one-class SVM is affected more than the others (Fig. <xref rid="Fig3" ref-type="fig">3F</xref>). The one-class SVM, for instance, never predicts the “Astro Aqp4” cells correctly, while this population is relatively different from the rest as it is the only non-neuronal population. This cell population, however, only consists of eleven cells.</p>
      <p id="Par18">In the previous experiments, we used all genes to train the classifiers. Since the selection of highly variable genes (HVGs) is common in scRNA-seq analysis pipelines, we tested the effect of selecting HVGs on the classification performance of the PBMC-FACS dataset. We noted that using all genes results in the highest HF1-score for both the linear and one-class SVM (Supplementary Fig. <xref rid="MOESM1" ref-type="media">4</xref>).</p>
    </sec>
    <sec id="Sec5">
      <title>One-class SVM detects new cells better than linear SVM</title>
      <p id="Par19">Besides a high accuracy, the classifiers should be able to reject unseen cell populations. First, we evaluated the rejection option on the simulated data. In this dataset, the cell populations are distinct, so we expect that this is a relatively easy task. We removed one cell population, “Group 3”, from the training set and used this population as a test set. The one-class SVM outperforms the linear SVM as it correctly rejects all these cells, while the linear SVM rejects only 38.9% of them.</p>
      <p id="Par20">Next, we tested the rejection option on the AMB dataset. Here, we did four experiments and each time removed a node, including all its subpopulations, from the predefined tree (Supplementary Fig. <xref rid="MOESM1" ref-type="media">3</xref>). We removed the “L6 IT” and “Lamp5” cell populations from the second layer of the tree, and the “L6 IT VISp Penk Col27a1” and “Lamp5 Lsp1” from the third layer. When a node is removed from the second layer of the tree, the linear SVM clearly rejects these cells better than the one-class SVM (Fig. <xref rid="Fig3" ref-type="fig">3E</xref>). On the contrary, the one-class SVM rejects leaf node cells better.</p>
    </sec>
    <sec id="Sec6">
      <title>scHPL accurately learns cellular hierarchies</title>
      <p id="Par21">Next, we tested if we could learn the classification trees for the simulated and PBMC-FACS data using scHPL. In both experiments, we performed 10-fold cross-validation and split the training set into three different batches, Batches 1–3, to simulate the idea of different datasets. To obtain different annotation levels in these batches, multiple cell populations were merged into one population in some batches, or cell populations were removed from certain batches (Tables <xref rid="MOESM1" ref-type="media">S2</xref> and <xref rid="MOESM1" ref-type="media">S3</xref>). Batch 1 contains the lowest resolution and Batch 3 the highest. When learning the trees, we try all (six) different orders of the batches to see whether this affects tree learning. Combining this with the 10-fold cross-validation, 60 trees were learned in total by each classifier. To summarize the results, we constructed a final tree in which the thickness of an edge indicates how often it appeared in the 60 learned trees.</p>
      <p id="Par22">The linear and one-class SVM showed stable results during both experiments; all 60 trees—except for two trees learned by the one-class SVM on the PBMC data—look identical (Fig. <xref rid="Fig4" ref-type="fig">4A–D</xref>). The final tree for the simulated data looks as expected, but the tree for the PBMC data looks slightly different from the predefined hematopoietic tree (Supplementary Fig. <xref rid="MOESM1" ref-type="media">2A</xref>). In the learned trees, CD4+ memory T cells are a subpopulation of CD8+ instead of CD4+ T cells. The correlation between the centroids of CD4+ memory T cells and CD8+ T cells (<italic>r</italic> = 0.985 ± 0.003) is also slightly higher than the correlation to CD4+ T cells (<italic>r</italic> = 0.975 ± 0.002) (Supplementary Fig. <xref rid="MOESM1" ref-type="media">5</xref>). Using the learned tree instead of the predefined hematopoietic tree improves the classification performance of the linear SVM slightly (HF1-score = 0.990 vs. 0.985). Moreover, when relying on the predefined hematopoietic tree, CD4+ memory T cells, CD8+ T cells, and CD8+ naive T cells were also often confused, further highlighting the difficulty in distinguishing these populations based on their transcriptomic profiles alone (Tables <xref rid="MOESM1" ref-type="media">S4</xref> and <xref rid="MOESM1" ref-type="media">5</xref>).<fig id="Fig4"><label>Fig. 4</label><caption><title>Tree learning evaluation.</title><p>Classification trees learned when using a <bold>a</bold>, <bold>c</bold>, <bold>e</bold> linear SVM or <bold>b</bold>, <bold>d</bold>, <bold>f</bold> one-class SVM during the <bold>a</bold>, <bold>b</bold> simulated, <bold>c</bold>, <bold>d</bold> PBMC-FACS, and <bold>e</bold>, <bold>f</bold> simulated rejection experiment. The line pattern of the links indicates how often that link was learned during the 60 training runs. <bold>d</bold> In 2/60 trees, the link between the CD8+ T cells and the CD8+ naive and CD4+ memory T cells is missing. In those trees, the CD8+ T cells and CD8+ naive T cells have a perfect match and the CD4+ memory T cells are missing from the tree. <bold>f</bold> In 20/60 trees, the link between “Group456” and “Group5” is missing. In those trees, these two populations are a perfect match.</p></caption><graphic xlink:href="41467_2021_23196_Fig4_HTML" id="d32e685"/></fig></p>
      <p id="Par23">Next, we tested the effect of the matching threshold (default = 0.25) on the tree construction by varying this to 0.1 and 0.5. For the linear SVM, changing the threshold had no effect. For the one-class SVM, we noticed a small difference when changing the threshold to 0.1. The two trees that were different using the default threshold (Fig. <xref rid="Fig4" ref-type="fig">4D</xref>), were now constructed as the other 58 trees. In general, scHPL is robust to settings of the matching threshold due to its reliance on reciprocal classification.</p>
    </sec>
    <sec id="Sec7">
      <title>Missing populations affect tree construction with linear SVM</title>
      <p id="Par24">We tested whether new or missing cell populations in the training set could influence tree learning. We mimicked this scenario using the simulated dataset and the same batches as in the previous tree learning experiment. In the previous experiment, “Group5” and “Group6” were merged into “Group56” in Batch 2, but now we removed “Group5” completely from this batch (Supplementary Table <xref rid="MOESM1" ref-type="media">6</xref>). In this setup, the linear SVM mis-constructs all trees (Fig. <xref rid="Fig4" ref-type="fig">4E</xref>). If “Group5” is present in one batch and absent in another, the “Group5” cells are not rejected, but labeled as “Group6”. Consequently, “Group6” is added as a parent node to “Group5” and “Group6”. On the other hand, the one-class SVM suffers less than the linear SVM from these missing populations and correctly learns the expected tree in two-third of the cases (Fig. <xref rid="Fig4" ref-type="fig">4F</xref>). In the remaining third (20 trees), “Group5” matched perfectly with “Group456” and was thus not added to the tree. This occurs only if we have the following order: Batch 1–Batch 3–Batch 2 or Batch 3–Batch 1–Batch 2. Adding batches in increasing or decreasing resolution consequently resulted in the correct tree.</p>
    </sec>
    <sec id="Sec8">
      <title>Linear SVM can learn the classification tree during an inter-dataset experiment</title>
      <p id="Par25">Finally, we tested scHPL in a realistic scenario by using three PBMC datasets (PBMC-eQTL, PBMC-Bench10Xv2, and PBMC-FACS) to learn a classification tree and using this tree to predict the labels of a fourth PBMC dataset (PBMC-Bench10Xv3) (Table <xref rid="Tab1" ref-type="table">1</xref>). Before applying scHPL, we aligned the datasets using Seurat<sup><xref ref-type="bibr" rid="CR28">28</xref></sup>. We constructed an expected classification tree based on the names of the cell populations in the datasets (Fig. <xref rid="Fig5" ref-type="fig">5A</xref>). Note that matching based on names might result in an erroneous tree since every dataset was labeled using different clustering techniques, marker genes, and their own naming conventions.<table-wrap id="Tab1"><label>Table 1</label><caption><p>Number of cells per cell population in the different training datasets (batches) and test dataset. Subpopulations are indicated using an indent.</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Cell population</th><th>Batch 1 eQTL</th><th>Batch 2 Bench-10Xv2</th><th>Batch 3 FACS</th><th>Test dataset Bench-10Xv3</th></tr></thead><tbody><tr><td>CD19+ B</td><td>812</td><td>676</td><td>2000</td><td>346</td></tr><tr><td>CD34+</td><td/><td/><td>2000</td><td/></tr><tr><td>Monocytes (MC)</td><td/><td>1194</td><td/><td/></tr><tr><td>     CD14+</td><td>2081</td><td/><td>2000</td><td>354</td></tr><tr><td>     CD16+</td><td>274</td><td/><td/><td>98</td></tr><tr><td>CD4+ T</td><td>13,523</td><td>1458</td><td/><td>960</td></tr><tr><td>     Reg.</td><td/><td/><td>2000</td><td/></tr><tr><td>     Naive</td><td/><td/><td>2000</td><td/></tr><tr><td>     Memory</td><td/><td/><td>2000</td><td/></tr><tr><td>CD8+ T</td><td>4195</td><td>2128</td><td/><td>962</td></tr><tr><td>     Naive</td><td/><td/><td>2000</td><td/></tr><tr><td>Megakaryocyte (MK)</td><td>142</td><td>433</td><td/><td>270</td></tr><tr><td>NK cell</td><td/><td>429</td><td>2000</td><td>194</td></tr><tr><td>     CD56+ bright</td><td>355</td><td/><td/><td/></tr><tr><td>     CD56+ dim</td><td>2415</td><td/><td/><td/></tr><tr><td>Dendritic</td><td/><td/><td/><td>35</td></tr><tr><td>     Plasmacytoid (pDC)</td><td>101</td><td/><td/><td/></tr><tr><td>     Myeloid (mDC)</td><td>455</td><td/><td/><td/></tr></tbody></table></table-wrap><fig id="Fig5"><label>Fig. 5</label><caption><title>PBMC inter-dataset evaluation.</title><p><bold>a</bold> Expected and <bold>b</bold> learned classification tree when using a linear SVM on the PBMC datasets. The color of a node represents the agreement between dataset(s) regarding that cell population. <bold>c</bold> Confusion matrix when using the learned classification tree to predict the labels of PBMC-Bench10Xv3. The dark boundaries indicate the hierarchy of the constructed classification tree.</p></caption><graphic xlink:href="41467_2021_23196_Fig5_HTML" id="d32e978"/></fig></p>
      <p id="Par26">When comparing the tree learned using the linear SVM to the expected tree, we notice five differences (Fig. <xref rid="Fig5" ref-type="fig">5A, B</xref>). Some of these differences are minor, such as the matching of monocytes from the Bench10Xv2 dataset to myeloid dendritic cells (mDC), CD14+ monocytes, and the CD16+ monocytes. Monocytes can differentiate into mDC which can explain their transcriptomic similarity<sup><xref ref-type="bibr" rid="CR29">29</xref></sup>. Other differences between the reconstructed and the expected tree are likely the result of (partly) mislabeled cell populations in the original datasets (Supplementary Figs. <xref rid="MOESM1" ref-type="media">6</xref>–<xref rid="MOESM1" ref-type="media">15</xref>). (i) According to the expression of <italic>FCER1A</italic> (a marker for mDC) and <italic>FCGR3A</italic> (CD16+ monocytes), the labels of the mDC and the CD16+ monocytes in the eQTL dataset are reversed (Supplementary Figs. <xref rid="MOESM1" ref-type="media">6</xref>–<xref rid="MOESM1" ref-type="media">8</xref>). (ii) Part of the CD14+ monocytes in the FACS dataset express <italic>FCER1A</italic>, which is a marker for mDC (Supplementary Figs. <xref rid="MOESM1" ref-type="media">6</xref>, <xref rid="MOESM1" ref-type="media">8</xref>, and <xref rid="MOESM1" ref-type="media">9</xref>). The CD14+ monocytes in the FACS dataset are thus partly mDCs, which explains the match with the mDC from the eQTL dataset. (iii) Part of the CD4+ T cells from the eQTL and Bench10Xv2 dataset should be relabeled as CD8+ T cells (Supplementary Figs. <xref rid="MOESM1" ref-type="media">6</xref>, and <xref rid="MOESM1" ref-type="media">10</xref>–<xref rid="MOESM1" ref-type="media">13</xref>). In these datasets, the cells labeled as the CD8+ T cells only contain cytotoxic CD8+ T cells, while naive CD8+ T cells are all labeled as CD4+ T cells. This mislabeling explains why the CD8+ naive T cells are a subpopulation of the CD4+ T cells. (iv) Part of the CD34+ cells in the FACS dataset should be relabeled as pDC (Supplementary Figs. <xref rid="MOESM1" ref-type="media">6</xref>, <xref rid="MOESM1" ref-type="media">14</xref>, and <xref rid="MOESM1" ref-type="media">15</xref>), which explains why the pDC are a subpopulation of the CD34+ cells. In the FACS dataset, the labels were obtained using sorting, which would indicate that these labels are correct. The purity of the CD34+ cells, however, was significantly low (45%) compared to other cell populations (92–100%)<sup><xref ref-type="bibr" rid="CR27">27</xref></sup>. There is only one difference, however, that cannot be explained by mislabeling. The NK cells from the FACS dataset do not only match the NK cells from the eQTL dataset, but also the CD8+ T cells.</p>
      <p id="Par27">Most cells of the Bench10Xv3 dataset can be correctly annotated using the learned classification tree (Fig. <xref rid="Fig5" ref-type="fig">5E</xref>). Interestingly, we notice that the CD16+ monocytes are predicted to be mDCs and vice versa, which could be explained by the fact that the labels of the mDCs and the CD16+ monocytes were flipped in the eQTL dataset. Furthermore, part of the CD4+ T cells are predicted to be CD8+ naïve T cells. In the Bench10Xv3, we noticed the same mislabeling of part of the CD4+ T cells as in the eQTL and Bench10Xv2 datasets, which supports our predictions (Supplementary Figs. <xref rid="MOESM1" ref-type="media">6</xref> and <xref rid="MOESM1" ref-type="media">10</xref>–<xref rid="MOESM1" ref-type="media">13</xref>).</p>
      <p id="Par28">The tree constructed using the one-class SVM differs slightly compared to the linear SVM (Supplementary Fig. <xref rid="MOESM1" ref-type="media">16A</xref>). Here, the monocytes from the Bench10Xv2 match the CD14+ monocytes and mDC (which are actually CD16+ monocytes) as we would expect. Next, the CD14+ monocytes from the FACS dataset merge the CD16+ monocytes (which are actually mDC) and the monocytes. Using the one-class SVM the CD8+ T cells and NK cells from the Bench10Xv2 dataset are missing since there was a complex scenario. The NK cells are a relatively small population in this dataset which made it difficult to train a classifier for this population.</p>
      <p id="Par29">In the previous experiments, we used the default setting of Seurat to align the datasets (using 2000 genes). We tested whether changing the number of genes to 1000 and 5000 affects the performance. When using the one-class SVM, the number of genes does not affect tree construction. For the linear SVM, we notice one small difference when using 1000 genes: the CD8+ T cells from the Bench10Xv2 dataset are a subpopulation of the CD8+ T cells from the eQTL dataset instead of a perfect match.</p>
      <p id="Par30">The predicted labels of the Bench10Xv3 dataset change slightly when using a different number of genes (Supplementary Fig. <xref rid="MOESM1" ref-type="media">17</xref>). Whether more genes improve the prediction, differs per cell population. The labels of the megakaryocytes, for instance, are better predicted when more genes are used, but for the dendritic cells we observe the reverse pattern.</p>
    </sec>
    <sec id="Sec9">
      <title>Mapping brain cell populations using scHPL</title>
      <p id="Par31">Next, we applied scHPL to construct a tree that maps the relationships between brain cell populations. This is a considerably more challenging task compared to PBMCs given the large number of cell populations as well as the fact that brain cell types are not consistently annotated. First, we combined two datasets from the primary visual cortex of the mouse brain, AMB2016 and AMB2018<sup><xref ref-type="bibr" rid="CR4">4</xref>,<xref ref-type="bibr" rid="CR5">5</xref></sup>. AMB2018 contains more cells (12,771 vs. 1298) and is clustered at a higher resolution (92 cell populations vs. 41) compared to AMB2016. Before applying scHPL, we aligned the datasets using Seurat<sup><xref ref-type="bibr" rid="CR28">28</xref></sup>. Using scHPL with the linear SVM results in an almost perfect tree (Fig. <xref rid="Fig6" ref-type="fig">6</xref>). We verified these results by comparing our constructed tree to cluster correspondences in Extended Data Fig. 6 from Tasic et al.<sup><xref ref-type="bibr" rid="CR5">5</xref></sup>. Since AMB2018 is clustered at a higher resolution, most populations are subpopulations of AMB2016, which are all correctly identified by scHPL. Conversely, three L4 populations from AMB2016 were merged into one population (L4 IT VISp Rspo1) from AMB2018<sup><xref ref-type="bibr" rid="CR5">5</xref></sup>, forming a continuous spectrum. This relation was also automatically identified using scHPL (Fig. <xref rid="Fig6" ref-type="fig">6</xref>). Compared to the results from Tasic et al.<sup><xref ref-type="bibr" rid="CR5">5</xref></sup>, one cell population from AMB2018 is attached to a different parent node. scHPL assigned “L6b VISp Col8a1 Rprm” as a subpopulation of “L6a Sla” instead of “L6b Rgs12”. This population, however, does not express <italic>Rgs12</italic>, but does express <italic>Sla</italic> (Supplementary Fig. <xref rid="MOESM1" ref-type="media">18</xref>), supporting the matching identified by scHPL. Three cell populations could not be added to the tree due to complex scenarios. According to Extended Data Fig. 6 from Tasic et al.<sup><xref ref-type="bibr" rid="CR5">5</xref></sup>, these AMB2018 populations are a subpopulation of multiple AMB2016 subpopulations.<fig id="Fig6"><label>Fig. 6</label><caption><title>Constructed hierarchy for the AMB datasets.</title><p>Learned classification tree after applying scHPL with a linear SVM on the AMB2016 and AMB2018 datasets. A green node indicates that a population from the AMB2016 and AMB2018 datasets had a perfect match. Three populations from the AMB2018 dataset are missing from the tree: “Pvalb Sema3e Kank4”, “Sst Hpse Sema3c”, and “Sst Tac1 Tacr3”.</p></caption><graphic xlink:href="41467_2021_23196_Fig6_HTML" id="d32e1128"/></fig></p>
      <p id="Par32">The AMB2016 and AMB2018 datasets were generated and analyzed by the same group and hence the cluster matching is certainly easier than a real-life scenario. Therefore, we tested scHPL also on a complicated scenario with brain datasets that are sequenced using different protocols and by different labs (Supplementary Table <xref rid="MOESM1" ref-type="media">7</xref>, Supplementary Fig. <xref rid="MOESM1" ref-type="media">19</xref>). We used three datasets (Zeisel, Tabula Muris, and Saunders) to construct the tree (Fig. <xref rid="Fig7" ref-type="fig">7A–D</xref>)<sup><xref ref-type="bibr" rid="CR2">2</xref>,<xref ref-type="bibr" rid="CR30">30</xref>,<xref ref-type="bibr" rid="CR31">31</xref></sup>. Before applying scHPL, we aligned the datasets using Seurat<sup><xref ref-type="bibr" rid="CR28">28</xref></sup>. The Zeisel dataset is annotated at two resolutions. First, we constructed a tree using a linear SVM based on the low resolution of Zeisel. We started with the Saunders dataset and added Zeisel (Fig. <xref rid="Fig7" ref-type="fig">7E</xref>). This is a clear illustration of the possible scenarios scHPL can manage. Some populations are a perfect match between the two datasets (e.g., neurons), some populations from Saunders are split (e.g., astrocytes), some are merged (e.g., macrophages and microglia), and some populations from Zeisel have no match (e.g., Ttr). Next, we updated the tree by adding the Tabula Muris dataset (Fig. <xref rid="Fig7" ref-type="fig">7F</xref>). Here, we found matches that would not have been possible to identify by relying on the assigned cell type labels to map cell types. For example, mural cells from Saunders are a perfect match with the brain pericytes from the Tabula Muris. The results of scHPL with the one-class SVM were almost identical to the linear SVM (Supplementary Fig. <xref rid="MOESM1" ref-type="media">20A</xref>).<fig id="Fig7"><label>Fig. 7</label><caption><title>Brain inter-dataset evaluation.</title><p><bold>a</bold>–<bold>d</bold> UMAP embeddings of the datasets after alignment using Seurat v3. <bold>e</bold> Learned hierarchy when starting with the Saunders dataset and adding Zeisel with linear SVM. <bold>f</bold> Updated tree when the Tabula Muris dataset is added. <bold>g</bold> Confusion matrix when using the learned classification tree to predict the labels of Rosenberg. The dark boundaries indicate the hierarchy of the classification tree.</p></caption><graphic xlink:href="41467_2021_23196_Fig7_HTML" id="d32e1188"/></fig></p>
      <p id="Par33">Next, we used the resulting tree to predict the labels of a fourth independent dataset (Rosenberg)<sup><xref ref-type="bibr" rid="CR32">32</xref></sup>. The predictions from the linear and the one-class SVM are very similar (Figs. <xref rid="Fig7" ref-type="fig">7G</xref> and S<xref rid="MOESM1" ref-type="media">20B</xref>). The only difference is that the linear SVM correctly predicts some progenitor or precursor neuronal populations from Rosenberg to be “neurogenesis” while the one-class SVM rejects these populations.</p>
      <p id="Par34">To assess the effect of the annotation resolution, we repeated the analysis using the higher resolution annotation from the Zeisel dataset (Supplementary Figs. <xref rid="MOESM1" ref-type="media">21</xref>–<xref rid="MOESM1" ref-type="media">23</xref>). Here, we noticed that the “brain pericytes (TM)” and “pericytes (Zeisel)”—two populations one would easily match based on the names only—are not in the same subtree. “Brain pericyte (TM)” forms a perfect match with “mural (Saunders)” and “vascular smooth muscle cells (Zeisel)”, while “pericytes (Zeisel)” is a subpopulation of “endothelial stalk (Saunders)” and “endothelial cell (TM)” (Supplementary Figs. <xref rid="MOESM1" ref-type="media">22</xref> and <xref rid="MOESM1" ref-type="media">23</xref>). In the UMAP embedding of the integrated datasets, the “pericytes” and “brain pericyte” are at different locations, but they do overlap with the cell populations they were matched with (Supplementary Fig. <xref rid="MOESM1" ref-type="media">21</xref>). This highlights the power of scHPL matching rather than name-based matching.</p>
    </sec>
  </sec>
  <sec id="Sec10" sec-type="discussion">
    <title>Discussion</title>
    <p id="Par35">In this study, we showed that scHPL can learn cell identities progressively from multiple reference datasets. We showed that using our approach the labels of two AMB datasets can successfully be matched to create a hierarchy containing mainly neuronal cell populations and that we can combine three other brain datasets to create a hierarchy containing mainly non-neuronal cell populations. In both experiments, we discovered new relationships between cell populations, such as the mapping of “L6b VISp Col8a1 Rprm” as a subpopulation of “L6b Sla” instead of “L6b Rgs12”. This observation would not be possible to make by manually matching populations based on the assigned labels, highlighting the power of automatically constructing cellular hierarchies. In this case, the Cell Ontology database could also not be used to verify this relationship since many brain cell populations are missing. Most of these populations have recently been annotated using scRNA-seq and there is a wide lack of consistency in population annotation and matching between studies<sup><xref ref-type="bibr" rid="CR18">18</xref></sup>. scHPL can potentially be used to map these relations, irrespective of the assigned labels, and improve the Cell Ontology database.</p>
    <p id="Par36">When combining multiple datasets to construct a tree, we expect that cell populations are annotated correctly. However, in the PBMC inter-dataset experiment, this was not the case. At first sight, the constructed tree looked erroneous, but the expression of marker genes revealed that (parts of) several cell populations were mislabeled. Here, we could use the constructed tree as a warning that there was something wrong with the original annotations.</p>
    <p id="Par37">In general, scHPL is robust to sampling differences between datasets or varying parameters such as the matching threshold or the number of genes used. The brain datasets used to construct the tree, for instance, varied greatly in population sizes, which did not cause any difficulties. This is mainly because we rely on reciprocal classification. A match between cell populations that is missed when training a classifier on one dataset to predict labels of the other, can still be captured by the classifier trained on the other dataset.</p>
    <p id="Par38">Since batch effects are inevitable when combining datasets, we require datasets to be aligned before running scHPL. In all inter-dataset experiments in this manuscript, we used Seurat V3<sup><xref ref-type="bibr" rid="CR28">28</xref></sup> for the alignment, but we would like to emphasize that scHPL is not dependent on Seurat and can be combined with any batch correction tool, such as more computationally efficient methods like Harmony<sup><xref ref-type="bibr" rid="CR33">33</xref></sup>. A current limitation of these tools is that when a new dataset is added, the alignment—and consequently also scHPL—has to be rerun. An interesting alternative would be to project the new dataset to a latent space learned using reference dataset(s), using scArches<sup><xref ref-type="bibr" rid="CR34">34</xref></sup> for example. In that case, scHPL does not have to be rerun but can be progressively updated.</p>
    <p id="Par39">The batch effects between the datasets make it more difficult to troubleshoot errors. Generally, it will be hard to resolve whether mistakes in the constructed tree are caused by the erroneous alignment of datasets or by mismatches created by scHPL.</p>
    <p id="Par40">We would like to note though that there are inherent limitations to the assumption that cell populations have hierarchical relationships. While this assumption is widely adopted in single-cell studies as well as the Cell Ontology, there are indeed situations in which a tree is not adequate. For instance, situations in which cells dedifferentiate into other cell types, such as beta to alpha cell conversions in type2 diabetes<sup><xref ref-type="bibr" rid="CR35">35</xref>,<xref ref-type="bibr" rid="CR36">36</xref></sup>.</p>
    <p id="Par41">Considering the classification performance, we showed that using a hierarchical approach outperforms flat classification. On the AMB dataset, the linear SVM outperformed SVM<sub>rejection</sub>, which was the best performing classifier on this dataset<sup><xref ref-type="bibr" rid="CR23">23</xref></sup>. In contrast to SVM<sub>rejection</sub>, the linear SVM did not reject any of the cells but labeled them as an intermediate cell population. During this experiment, there were no cells of unknown populations. Correct intermediate predictions instead of rejection are therefore beneficial since it provides the user with at least some information. When comparing the linear SVM and one-class SVM, we noticed that the accuracy of the linear SVM is equal to or higher than the one-class SVM on all datasets. For both classifiers, we saw a decrease in performance on populations with a small number of cells, but for the one-class SVM this effect was more apparent.</p>
    <p id="Par42">Since the one-class SVM has a low performance on small cell populations, it also cannot be used to combine datasets that consist of small populations. If the classification performance is low, it will also not be possible to construct the correct tree. On the other hand, the performance of the linear SVM seems to be robust to small populations throughout our experiments. This classifier can thus better be used when combining multiple datasets with small populations.</p>
    <p id="Par43">When testing the rejection option, the one-class SVM clearly outperforms the linear SVM by showing a perfect performance on the simulated dataset. Moreover, when cell populations are missing from the simulated data, the linear SVM cannot learn the correct tree anymore, in contrast to the one-class SVM. This suggests that the one-class SVM is preferred when cell populations are missing, although, on the AMB dataset, the rejection option of both classifiers was not perfect.</p>
    <p id="Par44">In summary, we present a hierarchical progressive learning approach to automatically identify cell identities based on multiple datasets with various levels of subpopulations. We show that we can accurately learn cell identities and learn hierarchical relations between cell populations. Our results indicate that choosing between a one-class and a linear SVM is a trade-off between achieving higher accuracy and the ability to discover new cell populations. Our approach can be beneficial in single-cell studies where a comprehensive reference atlas is not present, for instance, to annotate datasets consistently during a cohort study. The first available annotated datasets can be used to build the hierarchical tree, which could subsequently be used to annotate cells in the other datasets.</p>
  </sec>
  <sec id="Sec11">
    <title>Methods</title>
    <sec id="Sec12">
      <title>Hierarchical progressive learning</title>
      <p id="Par45">Within scHPL, we use a hierarchical classifier instead of a flat classifier. A flat classifier is a classifier that does not consider a hierarchy and distinguishes between all cell populations simultaneously. For the AMB dataset, a flat classifier will have to learn the decision boundaries between all 92 cell populations in one go. Alternatively, a hierarchical classifier divides the problem into smaller subproblems. First, it learns the difference between the three broad classes: e.g., GABAergic neurons, glutamatergic neurons, and nonneuronal cells. Next, it learns the decision boundaries between the six subtypes of GABAergic neurons and the eight subtypes of glutamatergic neurons, separately. Finally, it will learn the decision boundaries between the different cell populations within each subtype separately.</p>
    </sec>
    <sec id="Sec13">
      <title>Training the hierarchical classifier</title>
      <p id="Par46">The training procedure of the hierarchical classifier is the same for every tree: we train a local classifier for each node except the root. This local classifier is either a one-class SVM or a linear SVM. We used the one-class SVM (svm.OneClassSVM(nu = 0.05)) from the scikit-learn library in Python<sup><xref ref-type="bibr" rid="CR37">37</xref></sup>. A one-class classifier only uses positive training samples. Positive training samples include cells from the node itself and all its child nodes. To avoid overfitting, we select the first 100 principal components (PCs) of the training data. Next, we select informative PCs for each node separately using a two-sided two-sample <italic>t</italic> test between the positive and negative samples of a node (<italic>α</italic> &lt; 0.05, Bonferroni corrected). Negative samples are selected using the siblings policy<sup><xref ref-type="bibr" rid="CR38">38</xref></sup>, i.e., sibling nodes include all nodes that have the same ancestor, excluding the ancestor itself. If a node has no siblings, cells labeled as the parent node, but not the node itself are considered negative samples. In some rare cases, the Bonferroni correction was too strict and no PCs were selected. In those cases, the five PCs with the smallest <italic>p</italic> values were selected. For the linear SVM, we used the svm.LinearSVC() function from the scikit-learn library. This classifier is trained using positive and negative samples. The linear SVM applies L2-regularization by default, so no extra measures to prevent overtraining were necessary.</p>
    </sec>
    <sec id="Sec14">
      <title>The reconstruction error</title>
      <p id="Par47">The reconstruction error is used to reject unknown cell populations. We use the training data to learn a suitable threshold that can be used to reject cells by doing nested fivefold cross-validation. A PCA (n_components = 100) is learned on the training data. The test data is then reconstructed by first mapping the data to the selected PCA domain, and then mapping the data back to the original space using the inverse transformation (hence the data lies within the plane spanned by the selected PCs). The reconstruction error is the difference between the original data and the reconstructed data (in other words, the distance of the original data to the PC plane). The median of the <italic>q</italic>th (default <italic>q</italic> = 0.99) percentile of the errors across the test data is used as a threshold. By increasing or decreasing this parameter, the number of false negatives can be controlled. Finally, we apply a PCA (n_components = 100) to the whole dataset to learn the transformation that can be applied to new unlabeled data later.</p>
    </sec>
    <sec id="Sec15">
      <title>Predicting the labels</title>
      <p id="Par48">First, we look at the reconstruction error of a new cell to determine whether it should be rejected. If the reconstruction error is higher than the threshold determined on the training data, the cell is rejected. If not, we continue with predicting its label. We start at the root node, which we denote as the parent node, and use the local classifiers of its children to predict the label of the cell using the predict() function, and score it using the decision_function(), both from the scikit-learn package. These scores represent the signed distance of a cell to the decision boundary. When comparing the results of the local classifiers, we distinguish three scenarios:<list list-type="order"><list-item><p id="Par49">All child nodes label the cell negative. If the parent node is the root, the new cell is rejected. Otherwise, we have an internal node prediction and the new cell is labeled with the name of the parent node.</p></list-item><list-item><p id="Par50">One child node labels the cell positive. If this child node is a leaf node, the sample is labeled with the name of this node. Otherwise, this node becomes the new parent and we continue with its children.</p></list-item><list-item><p id="Par51">Multiple child nodes label the cell positive. We only consider the child node with the highest score and continue as in scenario two.</p></list-item></list></p>
    </sec>
    <sec id="Sec16">
      <title>Reciprocal matching labels and updating the tree</title>
      <p id="Par52">Starting with two datasets, <italic>D1</italic> and <italic>D2</italic>, and the two corresponding classification trees (which can be either hierarchical or flat), we would like to match the labels of the datasets and merge the classification trees accordingly into a new classification tree while being consistent with both input classification trees (Fig. <xref rid="Fig1" ref-type="fig">1</xref>). We do this in two steps: first matching the labels between the two datasets and then updating the tree.</p>
      <p id="Par53">Reciprocal matching labels: We first cross-predict the labels of the datasets: we use the classifier trained on <italic>D1</italic> to predict the labels of <italic>D2</italic> and vice versa. We construct confusion matrices, <italic>C1</italic> and <italic>C2</italic>, for <italic>D1</italic> and <italic>D2</italic>, respectively. Here, <italic>C1</italic><sub><italic>ij</italic></sub> indicates how many cells of population <italic>i</italic> of <italic>D1</italic> are predicted to be population <italic>j</italic> of <italic>D2</italic>. This prediction can be either a leaf node, internal node, or a rejection. As the values in <italic>C1</italic> and <italic>C2</italic> are highly dependent on the size of a cell population, we normalize the rows such that the sum of every row is one, now indicating the fraction of cells of population <italic>i</italic> in <italic>D1</italic> that has been assigned to population <italic>j</italic> in <italic>D2</italic><disp-formula id="Equ1"><label>1</label><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$NC{1}_{ij}=\frac{C{1}_{ij}}{{\sum }_{\forall j}C{1}_{ij}}$$\end{document}</tex-math><mml:math id="M2"><mml:mi>N</mml:mi><mml:mi>C</mml:mi><mml:msub><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>C</mml:mi><mml:msub><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo mathsize="big">∑</mml:mo></mml:mrow><mml:mrow><mml:mo>∀</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mi>C</mml:mi><mml:msub><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:math><graphic xlink:href="41467_2021_23196_Article_Equ1.gif" position="anchor"/></alternatives></disp-formula>Clearly, a high fraction is indicative of matching population <italic>i</italic> in <italic>D1</italic> with population <italic>j</italic> in <italic>D2</italic>. Due to splitting, merging, or new populations between both datasets, multiple relatively high fractions can occur (e.g., if a population <italic>i</italic> is split in two populations <italic>j</italic><sub>1</sub> and <italic>j</italic><sub>2</sub> due to <italic>D2</italic> being of a higher resolution, both fractions <italic>NC</italic><sub><italic>ij</italic>1</sub> and <italic>NC</italic><sub><italic>ij</italic>2</sub> will be approximately 0.5). To accommodate for these operations, we allow multiple matches per population.</p>
      <p id="Par54">To convert these fractions into matches, <italic>NC1</italic> and <italic>NC2</italic> are converted into binary confusion matrices, <italic>BC1</italic> and <italic>BC2</italic>, where a 1 indicates a match between a population in <italic>D1</italic> with a population in <italic>D2</italic>, and vice versa. To determine a match, we take the value of the fraction as well as the difference with the other fractions into account. This is done for each row (population) of <italic>NC1</italic> and <italic>NC2</italic> separately. When considering row <italic>i</italic> from <italic>NC1</italic>, we first rank all fractions, then the highest fraction will be set to 1 in <italic>BC1</italic>, after which all fractions for which the difference with the preceding (higher) fraction is less than a predefined threshold (default = 0.25) will also be set to 1 in <italic>BC1</italic>.</p>
      <p id="Par55">To arrive at reciprocal matching between <italic>D1</italic> and <italic>D2</italic>, we combine <italic>BC1</italic> and <italic>BC2</italic> into matching matrix <italic>X</italic> (Fig. <xref rid="Fig2" ref-type="fig">2</xref>)<disp-formula id="Equ2"><label>2</label><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$X={BC}{1}^{T}+{BC}2$$\end{document}</tex-math><mml:math id="M4"><mml:mi>X</mml:mi><mml:mo>=</mml:mo><mml:mi>B</mml:mi><mml:mi>C</mml:mi><mml:msup><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mi>B</mml:mi><mml:mi>C</mml:mi><mml:mn>2</mml:mn></mml:math><graphic xlink:href="41467_2021_23196_Article_Equ2.gif" position="anchor"/></alternatives></disp-formula>The columns in <italic>X</italic> represent the cell populations of <italic>D1</italic> and the rows represent the cell populations of <italic>D2</italic>. If <italic>X</italic><sub><italic>ij</italic></sub> = 2, this indicates a reciprocal match between cell population <italic>i</italic> from <italic>D2</italic> and cell populations <italic>j</italic> from <italic>D1</italic>. <italic>X</italic><sub><italic>ij</italic></sub> = 1 indicates a one-sided match, and <italic>X</italic><sub><italic>ij</italic></sub> = 0 represents no match.</p>
      <p id="Par56">Tree updating: Using the reciprocal matches between <italic>D1</italic> and <italic>D2</italic> represented in <italic>X</italic>, we update the hierarchical tree belonging to <italic>D1</italic> to incorporate the labels and tree structure of <italic>D2</italic>. We do that by handling the correspondences in <italic>X</italic> elementwise. For a nonzero value in <italic>X</italic>, we check whether there are other nonzero values in the corresponding row and column to identify which tree operation we need to take (such as split/merge/create). As an example, if we encounter a split for population <italic>i</italic> in <italic>D1</italic> into <italic>j</italic><sub>1</sub> and <italic>j</italic><sub>2</sub>, we will create new nodes for <italic>j</italic><sub>1</sub> and <italic>j</italic><sub>2</sub> as child nodes of node <italic>i</italic> in the hierarchical tree of <italic>D1</italic>. Figure <xref rid="Fig2" ref-type="fig">2</xref> and Supplementary Table <xref rid="MOESM1" ref-type="media">1</xref> explain the four most common scenarios: a perfect match, splitting nodes, merging nodes, and a new population. All other scenarios are explained in Supplementary Note 1. After an update, the corresponding values in <italic>X</italic> are set to zero and we continue with the next nonzero element of <italic>X</italic>. If the matching is impossible, the corresponding values in <italic>X</italic> are thus not set to zero. If we have evaluated all elements of <italic>X</italic>, and there are still non-zero values, we will change <italic>X</italic> into a strict matrix, i.e., we further only consider reciprocal matches, so all “1”s are turned into a “0” with some exceptions (Supplementary Note <xref rid="MOESM1" ref-type="media">2</xref>). We then again evaluate <italic>X</italic> element-wise once more.</p>
    </sec>
    <sec id="Sec17">
      <title>Evaluation</title>
      <sec id="Sec18">
        <title>Hierarchical F1-score</title>
        <p id="Par57">We use the hierarchical F1-score (HF1-score) to evaluate the performance of the classifiers<sup><xref ref-type="bibr" rid="CR39">39</xref></sup>. We first calculate the hierarchical precision (<italic>hP</italic>) and recall (<italic>hR</italic>)<disp-formula id="Equ3"><label>3</label><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$hP=\frac{{\sum }_{i}{P}_{i}\cap {T}_{i}}{{\sum }_{i}{P}_{i}}$$\end{document}</tex-math><mml:math id="M6"><mml:mi>h</mml:mi><mml:mi>P</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mo mathsize="big">∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>∩</mml:mo><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo mathsize="big">∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:math><graphic xlink:href="41467_2021_23196_Article_Equ3.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ4"><label>4</label><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$hR=\frac{{\sum }_{i}{P}_{i}\cap {T}_{i}}{{\sum }_{i}{T}_{i}}$$\end{document}</tex-math><mml:math id="M8"><mml:mi>h</mml:mi><mml:mi>R</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mo mathsize="big">∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>∩</mml:mo><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo mathsize="big">∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:math><graphic xlink:href="41467_2021_23196_Article_Equ4.gif" position="anchor"/></alternatives></disp-formula>Here, <inline-formula id="IEq1"><alternatives><tex-math id="M9">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${P}_{{i}}$$\end{document}</tex-math><mml:math id="M10"><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2021_23196_Article_IEq1.gif"/></alternatives></inline-formula> is a set that contains the predicted cell population for a cell <italic>i</italic> and all the ancestors of that node, <inline-formula id="IEq2"><alternatives><tex-math id="M11">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${T}_{{i}}$$\end{document}</tex-math><mml:math id="M12"><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2021_23196_Article_IEq2.gif"/></alternatives></inline-formula> contains the true cell population and all its ancestors, and <inline-formula id="IEq3"><alternatives><tex-math id="M13">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${P}_{i}\cap {T}_{i}$$\end{document}</tex-math><mml:math id="M14"><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>∩</mml:mo><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2021_23196_Article_IEq3.gif"/></alternatives></inline-formula> is the overlap between these two sets. The HF1-score is the harmonic mean of <italic>hP</italic> and <italic>hR</italic><disp-formula id="Equ5"><label>5</label><alternatives><tex-math id="M15">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\rm{HF}}1=\frac{2{hP}* {\rm{}}{hR}}{{hP}+{hR}}$$\end{document}</tex-math><mml:math id="M16"><mml:mi mathvariant="normal">HF</mml:mi><mml:mn>1</mml:mn><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mi>h</mml:mi><mml:mi>P</mml:mi><mml:mo>*</mml:mo><mml:mi mathvariant="normal"/><mml:mi>h</mml:mi><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>h</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>h</mml:mi><mml:mi>R</mml:mi></mml:mrow></mml:mfrac></mml:math><graphic xlink:href="41467_2021_23196_Article_Equ5.gif" position="anchor"/></alternatives></disp-formula></p>
      </sec>
      <sec id="Sec19">
        <title>Median F1-score</title>
        <p id="Par58">We use the median F1-score to compare the classification performance to other methods. The F1-score is calculated for each cell population in the dataset and afterward the median of these scores is taken. Rejected cells and internal predictions are not considered when calculating this score.</p>
      </sec>
    </sec>
    <sec id="Sec20">
      <title>Datasets</title>
      <sec id="Sec21">
        <title>Simulated data</title>
        <p id="Par59">We used the R-package Splatter (V 1.6.1) to simulate a hierarchical scRNA-seq dataset that consists of 8839 cells and 9000 genes and represents the tree shown in Supplementary Fig. <xref rid="MOESM1" ref-type="media">1A</xref> (Supplementary Note <xref rid="MOESM1" ref-type="media">3</xref>)<sup><xref ref-type="bibr" rid="CR26">26</xref></sup>. We chose this low number of genes to speed up the computation time. In total there are 6 different cell populations of approximately 1500 cells each. As a preprocessing step, we log-transformed the count matrix (log<sub>2</sub>(count+1)). A UMAP embedding of the simulated dataset shows it indeed represents the desired hierarchy (Supplementary Fig. <xref rid="MOESM1" ref-type="media">1C</xref>).</p>
      </sec>
      <sec id="Sec22">
        <title>Peripheral blood mononuclear cells (PBMC) scRNA-seq datasets</title>
        <p id="Par60">We used four different PBMC datasets: PBMC-FACS, PBMC-Bench10Xv2, PBMC-Bench10Xv3, and PBMC-eQTL. The PBMC-FACS dataset is the downsampled FACS-sorted PBMC dataset from Zheng et al.<sup><xref ref-type="bibr" rid="CR27">27</xref></sup>. Cells were first FACS-sorted into ten different cell populations (CD14+ monocytes, CD19+ B cells, CD34+ cells, CD4+ helper T cells, CD4+/CD25+ regulatory T cells, CD4+/CD45RA+/CD25− naive T cells, CD4+/CD45RO+ memory T cells, CD56+ natural killer cells, CD8+ cytotoxic T cells, CD8+/CD45RA+ naive cytotoxic T cells) and sequenced using 10× chromium<sup><xref ref-type="bibr" rid="CR27">27</xref></sup>. Each cell population consists of 2000 cells. The total dataset consists of 20,000 cells and 21,952 genes. During the cross-validation on the PBMC-FACS dataset, we tested the effect of selecting HVG. We used the “seurat_v3” flavor of scanpy to select 500, 1000, 2000, and 5000 HVG on the training set<sup><xref ref-type="bibr" rid="CR28">28</xref>,<xref ref-type="bibr" rid="CR40">40</xref></sup>. The PBMC-Bench10Xv2 and PBMC-Bench10Xv3 datasets are the PbmcBench pbmc1.10Xv2 and pbmc1.10Xv3 datasets from Ding et al.<sup><xref ref-type="bibr" rid="CR41">41</xref></sup>. These datasets consist of 6444 and 3222 cells respectively, 22,280 genes, and nine different cell populations. Originally the PBMC-Bench10Xv2 dataset contained CD14+ and CD16+ monocytes. We merged these into one population called monocytes to introduce a different annotation level compared to the other PBMC datasets. The PBMC-eQTL dataset was sequenced using 10× Chromium and consists of 24,439 cells, 22,229 genes, and eleven different cell populations<sup><xref ref-type="bibr" rid="CR42">42</xref></sup>.</p>
      </sec>
      <sec id="Sec23">
        <title>Brain scRNA-seq datasets</title>
        <p id="Par61">We used two datasets from the mouse brain, AMB2016, and AMB2018, to look at different resolutions of cell populations in the primary mouse visual cortex. The AMB2016 dataset was sequenced using SMARTer<sup><xref ref-type="bibr" rid="CR4">4</xref></sup>, downloaded from <ext-link ext-link-type="uri" xlink:href="https://portal.brain-map.org/atlases-and-data/rnaseq/data-files-2018">https://portal.brain-map.org/atlases-and-data/rnaseq/data-files-2018</ext-link>. AMB2016 consists of 1298 cells and 21,413 genes. The AMB2018 dataset, which was sequenced using SMART-Seq V4<sup><xref ref-type="bibr" rid="CR5">5</xref></sup>, downloaded from <ext-link ext-link-type="uri" xlink:href="https://portal.brain-map.org/atlases-and-data/rnaseq/mouse-v1-and-alm-smart-seq">https://portal.brain-map.org/atlases-and-data/rnaseq/mouse-v1-and-alm-smart-seq</ext-link>, consists of 12,771 cells and 42,625 genes. In addition, we used four other brain datasets: Zeisel<sup><xref ref-type="bibr" rid="CR2">2</xref></sup>, Tabula Muris<sup><xref ref-type="bibr" rid="CR30">30</xref></sup>, Rosenberg<sup><xref ref-type="bibr" rid="CR32">32</xref></sup>, and Saunders<sup><xref ref-type="bibr" rid="CR31">31</xref></sup>. These were downloaded from the scArches “data” Google Drive (“mouse_brain_regions.h5ad” from <ext-link ext-link-type="uri" xlink:href="https://drive.google.com/drive/folders/1QQXDuUjKG8CTnwWW_u83MDtdrBXr8Kpq">https://drive.google.com/drive/folders/1QQXDuUjKG8CTnwWW_u83MDtdrBXr8Kpq</ext-link>)<sup><xref ref-type="bibr" rid="CR34">34</xref></sup>. We downsampled each dataset such that at the highest resolution each cell population consisted of up to 5000 cells to reduce the computational time for the alignment (Supplementary Table <xref rid="MOESM1" ref-type="media">7</xref>).</p>
      </sec>
      <sec id="Sec24">
        <title>Preprocessing scRNA-seq datasets</title>
        <p id="Par62">All datasets were preprocessed as described in Abdelaal et al.<sup><xref ref-type="bibr" rid="CR23">23</xref></sup>. Briefly, we removed cells labeled in the original studies as doublets, debris or unlabeled cells, cells from cell populations with less than ten cells, and genes that were not expressed. Next, we calculated the median number of detected genes per cell, and from that, we obtained the median absolute deviation (MAD) across all cells in the log scale. We removed cells when the total number of detected genes was below three MAD from the median number of detected genes per cell. During the intra-dataset experiments, we log-transformed the count matrices (log<sub>2</sub>(count + 1)).</p>
      </sec>
      <sec id="Sec25">
        <title>Aligning scRNA-seq datasets</title>
        <p id="Par63">During the inter-dataset experiments, we aligned the datasets using Seurat V3<sup><xref ref-type="bibr" rid="CR28">28</xref></sup> based on the joint set of genes expressed in all datasets. In the PBMC, AMB, and brain inter-dataset experiment respectively 17,573, 19,197, and 14,858 genes remained. For the PBMC inter-dataset experiment, we also removed cell populations that consisted of less than 100 cells from the datasets used for constructing and training the classification tree (PBMC-eQTL, FACS, Bench10Xv2). To test the effect of the number of genes on scHPL, we integrated this data using 1000, 2000 (default), and 5000 HVGs.</p>
      </sec>
    </sec>
    <sec id="Sec26">
      <title>Reporting summary</title>
      <p id="Par64">Further information on research design is available in the <xref rid="MOESM3" ref-type="media">Nature Research Reporting Summary</xref> linked to this article.</p>
    </sec>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary information</title>
    <sec id="Sec27">
      <supplementary-material content-type="local-data" id="MOESM1">
        <media xlink:href="41467_2021_23196_MOESM1_ESM.pdf">
          <caption>
            <p>Supplementary Information</p>
          </caption>
        </media>
      </supplementary-material>
      <supplementary-material content-type="local-data" id="MOESM2">
        <media xlink:href="41467_2021_23196_MOESM2_ESM.pdf">
          <caption>
            <p>Peer Review File</p>
          </caption>
        </media>
      </supplementary-material>
      <supplementary-material content-type="local-data" id="MOESM3">
        <media xlink:href="41467_2021_23196_MOESM3_ESM.pdf">
          <caption>
            <p>Reporting Summary</p>
          </caption>
        </media>
      </supplementary-material>
    </sec>
  </sec>
</body>
<back>
  <fn-group>
    <fn>
      <p><bold>Peer review information</bold><italic>Nature Communications</italic> thanks the anonymous reviewer(s) for their contribution to the peer review of this work. Peer reviewer reports are available.</p>
    </fn>
    <fn>
      <p><bold>Publisher’s note</bold> Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
    </fn>
  </fn-group>
  <sec>
    <title>Supplementary information</title>
    <p>The online version contains supplementary material available at 10.1038/s41467-021-23196-8.</p>
  </sec>
  <ack>
    <title>Acknowledgements</title>
    <p>This research was supported by an NWO Gravitation project: BRAINSCAPES: A Roadmap from Neurogenetics to Neurobiology (NWO: 024.004.012) and the European Union’s Horizon 2020 research and innovation program under the Marie Skłodowska-Curie grant agreement No. 861190 (PAVE).</p>
  </ack>
  <notes notes-type="author-contribution">
    <title>Author contributions</title>
    <p>L.M., M.J.T.R., and A.M. conceived the study and designed the experiments. L.M. performed all the experiments and wrote the paper. L.M., M.J.T.R., and A.M. reviewed and approved the paper.</p>
  </notes>
  <notes notes-type="data-availability">
    <title>Data availability</title>
    <p>The filtered PBMC-FACS and AMB2018 datasets can be downloaded from Zenodo (10.5281/zenodo.3357167). The simulated dataset and the aligned datasets used during the inter-dataset experiment can be downloaded from Zenodo (10.5281/zenodo.3736493). Accession numbers or links to the raw data: AMB2016<sup><xref ref-type="bibr" rid="CR4">4</xref></sup> (<ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE71585">GSE71585</ext-link>), AMB2018<sup><xref ref-type="bibr" rid="CR5">5</xref></sup> (<ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE115746">GSE115746</ext-link>), PBMC-FACS<sup><xref ref-type="bibr" rid="CR27">27</xref></sup> (SRP073767, <ext-link ext-link-type="uri" xlink:href="https://support.10xgenomics.com/single-cell-gene-expression/datasets">https://support.10xgenomics.com/single-cell-gene-expression/datasets</ext-link>), PBMC-eQTL<sup><xref ref-type="bibr" rid="CR42">42</xref></sup> (<ext-link ext-link-type="uri" xlink:href="https://ega-archive.org/studies/EGAS00001002560">EGAS00001002560</ext-link>), PBMC-Bench10Xv2 and PBMC-Bench10Xv3<sup><xref ref-type="bibr" rid="CR41">41</xref></sup> (<ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE132044">GSE132044</ext-link>), Rosenberg<sup><xref ref-type="bibr" rid="CR32">32</xref></sup> (<ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE110823">GSE110823</ext-link>), Zeisel<sup><xref ref-type="bibr" rid="CR2">2</xref></sup> (<ext-link ext-link-type="uri" xlink:href="http://mousebrain.org">http://mousebrain.org</ext-link>, file name L5_all.loom, downloaded on 9/9/2019), Saunders<sup><xref ref-type="bibr" rid="CR31">31</xref></sup> (<ext-link ext-link-type="uri" xlink:href="http://dropviz.org">http://dropviz.org</ext-link>, DGE by Region section, downloaded on 30/8/2019), Tabula Muris<sup><xref ref-type="bibr" rid="CR30">30</xref></sup> (<ext-link ext-link-type="uri" xlink:href="https://figshare.com/projects/Tabula_Muris_Transcriptomic_characterization_of_20_organs_and_tissues_from_Mus_musculus_at_single_cell_resolution/27733">https://figshare.com/projects/Tabula_Muris_Transcriptomic_characterization_of_20_organs_and_tissues_from_Mus_musculus_at_single_cell_resolution/27733</ext-link>, downloaded on 14/2/2019).</p>
  </notes>
  <notes notes-type="data-availability">
    <title>Code availability</title>
    <p>The source code for scHPL is available as a python package that is installable through the PyPI repository (<ext-link ext-link-type="uri" xlink:href="https://github.com/lcmmichielsen/hierarchicalprogressivelearning">https://github.com/lcmmichielsen/scHPL</ext-link>)<sup><xref ref-type="bibr" rid="CR43">43</xref></sup>.</p>
  </notes>
  <notes id="FPar1" notes-type="COI-statement">
    <title>Competing interests</title>
    <p id="Par65">The authors declare no competing interests.</p>
  </notes>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <label>1.</label>
      <mixed-citation publication-type="other">van der Wijst, M. G. et al. The single-cell eQTLGen consortium. <italic>Elife</italic><bold>9</bold>, e52155 (2020).</mixed-citation>
    </ref>
    <ref id="CR2">
      <label>2.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zeisel</surname>
            <given-names>A</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Molecular architecture of the mouse nervous system</article-title>
        <source>Cell</source>
        <year>2018</year>
        <volume>174</volume>
        <fpage>999</fpage>
        <lpage>1014.e22</lpage>
        <pub-id pub-id-type="doi">10.1016/j.cell.2018.06.021</pub-id>
        <pub-id pub-id-type="pmid">30096314</pub-id>
      </element-citation>
    </ref>
    <ref id="CR3">
      <label>3.</label>
      <mixed-citation publication-type="other">Svensson, V., da Veiga Beltrame, E. &amp; Pachter, L. A curated database reveals trends in single-cell transcriptomics. <italic>Database</italic><bold>2020</bold> (2020).</mixed-citation>
    </ref>
    <ref id="CR4">
      <label>4.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Tasic</surname>
            <given-names>B</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Adult mouse cortical cell taxonomy revealed by single cell transcriptomics</article-title>
        <source>Nat. Neurosci.</source>
        <year>2016</year>
        <volume>19</volume>
        <fpage>335</fpage>
        <lpage>346</lpage>
        <pub-id pub-id-type="doi">10.1038/nn.4216</pub-id>
        <pub-id pub-id-type="pmid">26727548</pub-id>
      </element-citation>
    </ref>
    <ref id="CR5">
      <label>5.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Tasic</surname>
            <given-names>B</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Shared and distinct transcriptomic cell types across neocortical areas</article-title>
        <source>Nature</source>
        <year>2018</year>
        <volume>563</volume>
        <fpage>72</fpage>
        <lpage>78</lpage>
        <pub-id pub-id-type="doi">10.1038/s41586-018-0654-5</pub-id>
        <pub-id pub-id-type="pmid">30382198</pub-id>
      </element-citation>
    </ref>
    <ref id="CR6">
      <label>6.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhang</surname>
            <given-names>Z</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>SCINA: semi-supervised analysis of single cells in silico</article-title>
        <source>Genes</source>
        <year>2019</year>
        <volume>10</volume>
        <fpage>531</fpage>
        <pub-id pub-id-type="doi">10.3390/genes10070531</pub-id>
      </element-citation>
    </ref>
    <ref id="CR7">
      <label>7.</label>
      <mixed-citation publication-type="other">Pliner, H. A., Shendure, J. &amp; Trapnell, C. Supervised classification enables rapid annotation of cell atlases. <italic>Nat. Methods</italic>10.1038/s41592-019-0535-3 (2019).</mixed-citation>
    </ref>
    <ref id="CR8">
      <label>8.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kiselev</surname>
            <given-names>VY</given-names>
          </name>
          <name>
            <surname>Yiu</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Hemberg</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>scmap: projection of single-cell RNA-seq data across data sets</article-title>
        <source>Nat. Methods</source>
        <year>2018</year>
        <volume>15</volume>
        <fpage>359</fpage>
        <pub-id pub-id-type="doi">10.1038/nmeth.4644</pub-id>
        <pub-id pub-id-type="pmid">29608555</pub-id>
      </element-citation>
    </ref>
    <ref id="CR9">
      <label>9.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Cao</surname>
            <given-names>Z-J</given-names>
          </name>
          <name>
            <surname>Wei</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Lu</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>D-C</given-names>
          </name>
          <name>
            <surname>Gao</surname>
            <given-names>G</given-names>
          </name>
        </person-group>
        <article-title>Searching large-scale scRNA-seq databases via unbiased cell embedding with Cell BLAST</article-title>
        <source>Nat. Commun.</source>
        <year>2020</year>
        <volume>11</volume>
        <fpage>3458</fpage>
        <pub-id pub-id-type="doi">10.1038/s41467-020-17281-7</pub-id>
        <pub-id pub-id-type="pmid">32651388</pub-id>
      </element-citation>
    </ref>
    <ref id="CR10">
      <label>10.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Alquicira-Hernandez</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Sathe</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Ji</surname>
            <given-names>HP</given-names>
          </name>
          <name>
            <surname>Nguyen</surname>
            <given-names>Q</given-names>
          </name>
          <name>
            <surname>Powell</surname>
            <given-names>JE</given-names>
          </name>
        </person-group>
        <article-title>ScPred: accurate supervised method for cell-type classification from single-cell RNA-seq data</article-title>
        <source>Genome Biol.</source>
        <year>2019</year>
        <volume>20</volume>
        <fpage>264</fpage>
        <pub-id pub-id-type="doi">10.1186/s13059-019-1862-5</pub-id>
        <pub-id pub-id-type="pmid">31829268</pub-id>
      </element-citation>
    </ref>
    <ref id="CR11">
      <label>11.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>de Kanter</surname>
            <given-names>JK</given-names>
          </name>
          <name>
            <surname>Lijnzaad</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Candelli</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Margaritis</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Holstege</surname>
            <given-names>FCP</given-names>
          </name>
        </person-group>
        <article-title>CHETAH: a selective, hierarchical cell type identification method for single-cell RNA sequencing</article-title>
        <source>Nucleic Acids Res.</source>
        <year>2019</year>
        <volume>47</volume>
        <fpage>e95</fpage>
        <lpage>e95</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkz543</pub-id>
        <pub-id pub-id-type="pmid">31226206</pub-id>
      </element-citation>
    </ref>
    <ref id="CR12">
      <label>12.</label>
      <mixed-citation publication-type="other">Wang, S. et al. Unifying single-cell annotations based on the cell ontology. <italic>bioRxiv</italic>10.1101/810234 (2019).</mixed-citation>
    </ref>
    <ref id="CR13">
      <label>13.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zeisel</surname>
            <given-names>A</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Brain structure. Cell types in the mouse cortex and hippocampus revealed by single-cell RNA-seq</article-title>
        <source>Science</source>
        <year>2015</year>
        <volume>347</volume>
        <fpage>1138</fpage>
        <lpage>1142</lpage>
        <pub-id pub-id-type="doi">10.1126/science.aaa1934</pub-id>
        <pub-id pub-id-type="pmid">25700174</pub-id>
      </element-citation>
    </ref>
    <ref id="CR14">
      <label>14.</label>
      <mixed-citation publication-type="other">Hodge, R. D. et al. Conserved cell types with divergent features in human versus mouse cortex. <italic>Nature</italic>10.1038/s41586-019-1506-7 (2019).</mixed-citation>
    </ref>
    <ref id="CR15">
      <label>15.</label>
      <mixed-citation publication-type="other">Jarvis, P. <italic>Towards a Comprehensive Theory of Human Learning</italic>. (Taylor &amp; Francis Ltd., 2006).</mixed-citation>
    </ref>
    <ref id="CR16">
      <label>16.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Yang</surname>
            <given-names>BH</given-names>
          </name>
          <name>
            <surname>Asada</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <article-title>Progressive learning and its application to robot impedance learning</article-title>
        <source>IEEE Trans. Neural Netw.</source>
        <year>1996</year>
        <volume>7</volume>
        <fpage>941</fpage>
        <lpage>952</lpage>
        <pub-id pub-id-type="doi">10.1109/72.508937</pub-id>
        <pub-id pub-id-type="pmid">18263489</pub-id>
      </element-citation>
    </ref>
    <ref id="CR17">
      <label>17.</label>
      <mixed-citation publication-type="other">Fayek, H. M. <italic>Continual Deep Learning via Progressive Learning</italic>. (RMIT University, 2019).</mixed-citation>
    </ref>
    <ref id="CR18">
      <label>18.</label>
      <mixed-citation publication-type="other">Yuste, R. et al. A community-based transcriptomics classification and nomenclature of neocortical cell types. <italic>Nat. Neurosci.</italic>10.1038/s41593-020-0685-8 (2020).</mixed-citation>
    </ref>
    <ref id="CR19">
      <label>19.</label>
      <mixed-citation publication-type="other">Svensson, V. &amp; da Veiga Beltrame, E. A curated database reveals trends in single cell transcriptomics. <italic>bioRxiv</italic>10.1101/742304 (2019).</mixed-citation>
    </ref>
    <ref id="CR20">
      <label>20.</label>
      <mixed-citation publication-type="other">Wagner, F. &amp; Yanai, I. Moana: a robust and scalable cell type classification framework for single-cell RNA-Seq data. <italic>bioRxiv</italic>10.1101/456129 (2018).</mixed-citation>
    </ref>
    <ref id="CR21">
      <label>21.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Bakken</surname>
            <given-names>TE</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Single-nucleus and single-cell transcriptomes compared in matched cortical cell types</article-title>
        <source>PLoS ONE</source>
        <year>2018</year>
        <volume>13</volume>
        <fpage>e0209648</fpage>
        <pub-id pub-id-type="doi">10.1371/journal.pone.0209648</pub-id>
        <pub-id pub-id-type="pmid">30586455</pub-id>
      </element-citation>
    </ref>
    <ref id="CR22">
      <label>22.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Aevermann</surname>
            <given-names>BD</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Cell type discovery using single-cell transcriptomics: implications for ontological representation</article-title>
        <source>Hum. Mol. Genet.</source>
        <year>2018</year>
        <volume>27</volume>
        <fpage>R40</fpage>
        <lpage>R47</lpage>
        <pub-id pub-id-type="doi">10.1093/hmg/ddy100</pub-id>
        <pub-id pub-id-type="pmid">29590361</pub-id>
      </element-citation>
    </ref>
    <ref id="CR23">
      <label>23.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Abdelaal</surname>
            <given-names>T</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>A comparison of automatic cell identification methods for single-cell RNA sequencing data</article-title>
        <source>Genome Biol.</source>
        <year>2019</year>
        <volume>20</volume>
        <fpage>194</fpage>
        <pub-id pub-id-type="doi">10.1186/s13059-019-1795-z</pub-id>
        <pub-id pub-id-type="pmid">31500660</pub-id>
      </element-citation>
    </ref>
    <ref id="CR24">
      <label>24.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Boufea</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Seth</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Batada</surname>
            <given-names>N</given-names>
          </name>
        </person-group>
        <article-title>SCID uses discriminant analysis to identify transcriptionally equivalent cell types across single-cell RNA-Seq data with batch effect</article-title>
        <source>iScience</source>
        <year>2020</year>
        <volume>23</volume>
        <fpage>100914</fpage>
        <pub-id pub-id-type="doi">10.1016/j.isci.2020.100914</pub-id>
        <pub-id pub-id-type="pmid">32151972</pub-id>
      </element-citation>
    </ref>
    <ref id="CR25">
      <label>25.</label>
      <mixed-citation publication-type="other">Tax, D. <italic>One-Class Classification Concept-Learning in the Absence of Counter-Examples</italic>. (TU Delft, 2001).</mixed-citation>
    </ref>
    <ref id="CR26">
      <label>26.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zappia</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Phipson</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Oshlack</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Splatter: simulation of single-cell RNA sequencing data</article-title>
        <source>Genome Biol.</source>
        <year>2017</year>
        <volume>18</volume>
        <fpage>174</fpage>
        <pub-id pub-id-type="doi">10.1186/s13059-017-1305-0</pub-id>
        <pub-id pub-id-type="pmid">28899397</pub-id>
      </element-citation>
    </ref>
    <ref id="CR27">
      <label>27.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zheng</surname>
            <given-names>GXY</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Massively parallel digital transcriptional profiling of single cells</article-title>
        <source>Nat. Commun.</source>
        <year>2017</year>
        <volume>8</volume>
        <fpage>14049</fpage>
        <pub-id pub-id-type="doi">10.1038/ncomms14049</pub-id>
        <pub-id pub-id-type="pmid">28091601</pub-id>
      </element-citation>
    </ref>
    <ref id="CR28">
      <label>28.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Stuart</surname>
            <given-names>T</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Comprehensive integration of single-cell data</article-title>
        <source>Cell</source>
        <year>2019</year>
        <volume>177</volume>
        <fpage>1888</fpage>
        <lpage>1902.e21</lpage>
        <pub-id pub-id-type="doi">10.1016/j.cell.2019.05.031</pub-id>
        <pub-id pub-id-type="pmid">31178118</pub-id>
      </element-citation>
    </ref>
    <ref id="CR29">
      <label>29.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>León</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>López-Bravo</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Ardavín</surname>
            <given-names>C</given-names>
          </name>
        </person-group>
        <article-title>Monocyte-derived dendritic cells</article-title>
        <source>Semin. Immunol.</source>
        <year>2005</year>
        <volume>17</volume>
        <fpage>313</fpage>
        <lpage>318</lpage>
        <pub-id pub-id-type="doi">10.1016/j.smim.2005.05.013</pub-id>
        <pub-id pub-id-type="pmid">15955712</pub-id>
      </element-citation>
    </ref>
    <ref id="CR30">
      <label>30.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Schaum</surname>
            <given-names>N</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Single-cell transcriptomics of 20 mouse organs creates a Tabula Muris</article-title>
        <source>Nature</source>
        <year>2018</year>
        <volume>562</volume>
        <fpage>367</fpage>
        <lpage>372</lpage>
        <pub-id pub-id-type="doi">10.1038/s41586-018-0590-4</pub-id>
        <pub-id pub-id-type="pmid">30283141</pub-id>
      </element-citation>
    </ref>
    <ref id="CR31">
      <label>31.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Saunders</surname>
            <given-names>A</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Molecular diversity and specializations among the cells of the adult mouse brain</article-title>
        <source>Cell</source>
        <year>2018</year>
        <volume>174</volume>
        <fpage>1015</fpage>
        <lpage>1030.e16</lpage>
        <pub-id pub-id-type="doi">10.1016/j.cell.2018.07.028</pub-id>
        <pub-id pub-id-type="pmid">30096299</pub-id>
      </element-citation>
    </ref>
    <ref id="CR32">
      <label>32.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Rosenberg</surname>
            <given-names>AB</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Single-cell profiling of the developing mouse brain and spinal cord with split-pool barcoding</article-title>
        <source>Science</source>
        <year>2018</year>
        <volume>360</volume>
        <fpage>176</fpage>
        <lpage>182</lpage>
        <pub-id pub-id-type="doi">10.1126/science.aam8999</pub-id>
        <pub-id pub-id-type="pmid">29545511</pub-id>
      </element-citation>
    </ref>
    <ref id="CR33">
      <label>33.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Korsunsky</surname>
            <given-names>I</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Fast, sensitive and accurate integration of single-cell data with Harmony</article-title>
        <source>Nat. Methods</source>
        <year>2019</year>
        <volume>16</volume>
        <fpage>1289</fpage>
        <lpage>1296</lpage>
        <pub-id pub-id-type="doi">10.1038/s41592-019-0619-0</pub-id>
        <pub-id pub-id-type="pmid">31740819</pub-id>
      </element-citation>
    </ref>
    <ref id="CR34">
      <label>34.</label>
      <mixed-citation publication-type="other">Lotfollahi, M. et al. Query to reference single-cell integration with transfer learning. <italic>bioRxiv</italic>10.1101/2020.07.16.205997 (2020).</mixed-citation>
    </ref>
    <ref id="CR35">
      <label>35.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Cinti</surname>
            <given-names>F</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Evidence of β-cell dedifferentiation in human type 2 diabetes</article-title>
        <source>J. Clin. Endocrinol. Metab.</source>
        <year>2016</year>
        <volume>101</volume>
        <fpage>1044</fpage>
        <lpage>1054</lpage>
        <pub-id pub-id-type="doi">10.1210/jc.2015-2860</pub-id>
        <pub-id pub-id-type="pmid">26713822</pub-id>
      </element-citation>
    </ref>
    <ref id="CR36">
      <label>36.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hunter</surname>
            <given-names>CS</given-names>
          </name>
          <name>
            <surname>Stein</surname>
            <given-names>RW</given-names>
          </name>
        </person-group>
        <article-title>Evidence for loss in identity, de-differentiation, and trans-differentiation of islet β-cells in type 2 diabetes</article-title>
        <source>Front. Genet.</source>
        <year>2017</year>
        <volume>8</volume>
        <fpage>35</fpage>
        <pub-id pub-id-type="doi">10.3389/fgene.2017.00035</pub-id>
        <pub-id pub-id-type="pmid">28424732</pub-id>
      </element-citation>
    </ref>
    <ref id="CR37">
      <label>37.</label>
      <mixed-citation publication-type="other">Pedregosa, F. et al. <italic>Scikit-learn: Machine Learning in Python</italic>. <ext-link ext-link-type="uri" xlink:href="http://scikit-learn.sourceforge.net">http://scikit-learn.sourceforge.net</ext-link> (2011).</mixed-citation>
    </ref>
    <ref id="CR38">
      <label>38.</label>
      <mixed-citation publication-type="other">Fagni, T. &amp; Sebastiani, F. On the selection of negative examples for hierarchical text categorization. in <italic>Proceedings of the 3rd language technology conference</italic> 24–28 (2007).</mixed-citation>
    </ref>
    <ref id="CR39">
      <label>39.</label>
      <mixed-citation publication-type="other">Kiritchenko, S. &amp; Famili, F. Functional annotation of genes using hierarchical text categorization. <italic>Proceedings of BioLink SIG, ISMB</italic> (2005).</mixed-citation>
    </ref>
    <ref id="CR40">
      <label>40.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wolf</surname>
            <given-names>FA</given-names>
          </name>
          <name>
            <surname>Angerer</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Theis</surname>
            <given-names>FJ</given-names>
          </name>
        </person-group>
        <article-title>SCANPY: large-scale single-cell gene expression data analysis</article-title>
        <source>Genome Biol.</source>
        <year>2018</year>
        <volume>19</volume>
        <fpage>15</fpage>
        <pub-id pub-id-type="doi">10.1186/s13059-017-1382-0</pub-id>
        <pub-id pub-id-type="pmid">29409532</pub-id>
      </element-citation>
    </ref>
    <ref id="CR41">
      <label>41.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ding</surname>
            <given-names>J</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Systematic comparison of single-cell and single-nucleus RNA-sequencing methods</article-title>
        <source>Nat. Biotechnol.</source>
        <year>2020</year>
        <volume>38</volume>
        <fpage>737</fpage>
        <lpage>746</lpage>
        <pub-id pub-id-type="doi">10.1038/s41587-020-0465-8</pub-id>
        <pub-id pub-id-type="pmid">32341560</pub-id>
      </element-citation>
    </ref>
    <ref id="CR42">
      <label>42.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Van Der Wijst</surname>
            <given-names>MGP</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Single-cell RNA sequencing identifies celltype-specific cis-eQTLs and co-expression QTLs</article-title>
        <source>Nat. Genet.</source>
        <year>2018</year>
        <volume>50</volume>
        <fpage>493</fpage>
        <lpage>497</lpage>
        <pub-id pub-id-type="doi">10.1038/s41588-018-0089-9</pub-id>
        <pub-id pub-id-type="pmid">29610479</pub-id>
      </element-citation>
    </ref>
    <ref id="CR43">
      <label>43.</label>
      <mixed-citation publication-type="other">Michielsen, L. C. M., Reinders, M. J. T. &amp; Mahfouz, A. <italic>Hierarchical Progressive Learning of Cell Identities in Single-Cell Data</italic>. 10.5281/zenodo.4644285 (2021).</mixed-citation>
    </ref>
  </ref-list>
</back>
