<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//NLM//DTD Journal Publishing DTD v2.3 20070202//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName journalpublishing.dtd?>
<?SourceDTD.Version 2.3?>
<?ConverterInfo.XSLTName jp2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Front Genet</journal-id>
    <journal-id journal-id-type="iso-abbrev">Front Genet</journal-id>
    <journal-id journal-id-type="publisher-id">Front. Genet.</journal-id>
    <journal-title-group>
      <journal-title>Frontiers in Genetics</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1664-8021</issn>
    <publisher>
      <publisher-name>Frontiers Media S.A.</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">7169426</article-id>
    <article-id pub-id-type="doi">10.3389/fgene.2020.00247</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Genetics</subject>
        <subj-group>
          <subject>Original Research</subject>
        </subj-group>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>sigFeature: Novel Significant Feature Selection Method for Classification of Gene Expression Data Using Support Vector Machine and <italic>t</italic> Statistic</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Das</surname>
          <given-names>Pijush</given-names>
        </name>
        <xref ref-type="aff" rid="aff1">
          <sup>1</sup>
        </xref>
        <xref ref-type="corresp" rid="c001">
          <sup>*</sup>
        </xref>
        <uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/166615/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Roychowdhury</surname>
          <given-names>Anirban</given-names>
        </name>
        <xref ref-type="aff" rid="aff2">
          <sup>2</sup>
        </xref>
        <uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/934557/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Das</surname>
          <given-names>Subhadeep</given-names>
        </name>
        <xref ref-type="aff" rid="aff1">
          <sup>1</sup>
        </xref>
        <uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/934923/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Roychoudhury</surname>
          <given-names>Susanta</given-names>
        </name>
        <xref ref-type="aff" rid="aff3">
          <sup>3</sup>
        </xref>
        <uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/197078/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Tripathy</surname>
          <given-names>Sucheta</given-names>
        </name>
        <xref ref-type="aff" rid="aff1">
          <sup>1</sup>
        </xref>
        <xref ref-type="aff" rid="aff4">
          <sup>4</sup>
        </xref>
        <xref ref-type="corresp" rid="c002">
          <sup>*</sup>
        </xref>
        <uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/289360/overview"/>
      </contrib>
    </contrib-group>
    <aff id="aff1"><sup>1</sup><institution>Computational Genomics lab, Structural Biology and Bioinformatics Division, CSIR- Indian Institute of Chemical Biology</institution>, <addr-line>Kolkata</addr-line>, <country>India</country></aff>
    <aff id="aff2"><sup>2</sup><institution>Department of Oncogene Regulation, Chittaranjan National Cancer Institute</institution>, <addr-line>Kolkata</addr-line>, <country>India</country></aff>
    <aff id="aff3"><sup>3</sup><institution>Saroj Gupta Cancer Centre and Research Institute</institution>, <addr-line>Kolkata</addr-line>, <country>India</country></aff>
    <aff id="aff4"><sup>4</sup><institution>Academy of Scientific and Innovative Research</institution>, <addr-line>New Delhi</addr-line>, <country>India</country></aff>
    <author-notes>
      <fn fn-type="edited-by">
        <p>Edited by: Alfredo Pulvirenti, University of Catania, Italy</p>
      </fn>
      <fn fn-type="edited-by">
        <p>Reviewed by: Sanga Mitra, National Institutes of Health (NIH), United States; Abhijit Das, University of Southern California, United States</p>
      </fn>
      <corresp id="c001">*Correspondence: Pijush Das <email>topijush@gmail.com</email></corresp>
      <corresp id="c002">Sucheta Tripathy <email>tsucheta@iicb.res.in</email></corresp>
      <fn fn-type="other" id="fn001">
        <p>This article was submitted to Bioinformatics and Computational Biology, a section of the journal Frontiers in Genetics</p>
      </fn>
    </author-notes>
    <pub-date pub-type="epub">
      <day>03</day>
      <month>4</month>
      <year>2020</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2020</year>
    </pub-date>
    <volume>11</volume>
    <elocation-id>247</elocation-id>
    <history>
      <date date-type="received">
        <day>26</day>
        <month>8</month>
        <year>2019</year>
      </date>
      <date date-type="accepted">
        <day>02</day>
        <month>3</month>
        <year>2020</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>Copyright © 2020 Das, Roychowdhury, Das, Roychoudhury and Tripathy.</copyright-statement>
      <copyright-year>2020</copyright-year>
      <copyright-holder>Das, Roychowdhury, Das, Roychoudhury and Tripathy</copyright-holder>
      <license xlink:href="http://creativecommons.org/licenses/by/4.0/">
        <license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.</license-p>
      </license>
    </permissions>
    <abstract>
      <p>Biological data are accumulating at a faster rate, but interpreting them still remains a problem. Classifying biological data into distinct groups is the first step in understanding them. Data classification in response to a certain treatment is an extremely important aspect for differentially expressed genes in making present/absent calls. Many feature selection algorithms have been developed including the support vector machine recursive feature elimination procedure (SVM-RFE) and its variants. Support vector machine RFEs are greedy methods that attempt to find superlative possible combinations leading to binary classification, which may not be biologically significant. To overcome this limitation of SVM-RFE, we propose a novel feature selection algorithm, termed as “sigFeature” (<ext-link ext-link-type="uri" xlink:href="https://bioconductor.org/packages/sigFeature/">https://bioconductor.org/packages/sigFeature/</ext-link>), based on SVM and <italic>t</italic> statistic to discover the differentially significant features along with good performance in classification. The “sigFeature” R package is centered around a function called “sigFeature,” which provides automatic selection of features for the binary classification. Using six publicly available microarray data sets (downloaded from Gene Expression Omnibus) with different biological attributes, we further compared the performance of “sigFeature” to three other feature selection algorithms. A small number of selected features (by “sigFeature”) also show higher classification accuracy. For further downstream evaluation of its biological signature, we conducted gene set enrichment analysis with the selected features (genes) from “sigFeature” and compared it with the outputs of other algorithms. We observed that “sigFeature” is able to predict the signature of four out of six microarray data sets accurately, whereas the other algorithms predict less data set signatures. Thus, “sigFeature” is considerably better than related algorithms in discovering differentially significant features from microarray data sets.</p>
    </abstract>
    <kwd-group>
      <kwd>feature selection</kwd>
      <kwd>machine learning</kwd>
      <kwd>support vector machine</kwd>
      <kwd>microaaray</kwd>
      <kwd>cancer</kwd>
      <kwd>RNA-Seq</kwd>
      <kwd>bootstrap</kwd>
      <kwd>GSEA</kwd>
    </kwd-group>
    <funding-group>
      <award-group>
        <funding-source id="cn001">CSIR - Indian Institute of Chemical Biology<named-content content-type="fundref-id">10.13039/501100012323</named-content></funding-source>
      </award-group>
    </funding-group>
    <counts>
      <fig-count count="7"/>
      <table-count count="2"/>
      <equation-count count="10"/>
      <ref-count count="43"/>
      <page-count count="12"/>
      <word-count count="7854"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec sec-type="intro" id="s1">
    <title>Introduction</title>
    <p>Feature selection is described as a process in which a subset of relevant features is selected from a larger data set. These features are used for model construction. On the basis of the model created, one can separate or classify the classes present in a data set (James et al., <xref rid="B19" ref-type="bibr">2013</xref>). Based on the combination of selection algorithms and model building, feature selection methods are normally classified into three classes such as Filter methods, Wrapper methods, and Embedded methods. All the feature selection algorithms used in this article belong to Wrapper methods. A subset of features is used in Wrapper methods, and a model is trained with those features. The user then decided to add or remove features from the subset based on the inferences from the previous model. Generally, microarray data sets are high-dimensional in nature. It is obvious that not all the features contribute to the prediction variable. Removing low-importance features will not only increase the accuracy but also reduce the complexity of the model and its overfitting. Therefore, the training time for the very large data sets can also be reduced. Usually, the feature selection algorithms (Allison et al., <xref rid="B3" ref-type="bibr">2006</xref>) are used for different tasks such as classification, clustering, and regression analysis (Jović et al., <xref rid="B20" ref-type="bibr">2015</xref>). Feature selection algorithm is widely used in analyzing different types of biological data set, for example, whole-genome expression data set (Ramaswamy et al., <xref rid="B29" ref-type="bibr">2001</xref>; Frank et al., <xref rid="B13" ref-type="bibr">2006</xref>; Zheng et al., <xref rid="B42" ref-type="bibr">2006</xref>), protein mass spectra data set (Hilario et al., <xref rid="B18" ref-type="bibr">2006</xref>), whole-genome sequencing data set (Das et al., <xref rid="B10" ref-type="bibr">2006</xref>), and so on.</p>
    <p>Differential expression analysis technologies on different data sets such as RNAseq and microarrays provide a great opportunity for the researchers to quantify the expression levels of thousands of cellular genes concurrently. This advantage led to its rampant use in clinical settings. A general approach is to employ <italic>t</italic> statistic (along with multiple hypothesis tests) on microarray data sets to obtain the statistically significant differentially expressed genes (DEGs). However, the DEGs produced by most of the methods often contain biologically irrelevant data lacking discriminatory power to classify the groups present in the data set. This is also the same with the clinical data. It is therefore essential to develop an appropriate algorithm to identify biologically significant DEGs together with excellent classification precision in a tumor versus normal tissue contrast (Galland et al., <xref rid="B14" ref-type="bibr">2010</xref>) or in distinct tumor subtypes (Bonome et al., <xref rid="B7" ref-type="bibr">2008</xref>).</p>
    <p>Over the past few years, many feature selection algorithms have been developed for microarray data analysis. However, most of the binary (two-class) feature selection algorithms focus mostly on classification accuracy of the selected features, which often fails to be biologically relevant leading to inaccurate downstream data analysis (Golub et al., <xref rid="B16" ref-type="bibr">1999</xref>; Guyon et al., <xref rid="B17" ref-type="bibr">2002</xref>; Lee et al., <xref rid="B22" ref-type="bibr">2003</xref>; Zhang et al., <xref rid="B40" ref-type="bibr">2006a</xref>,<xref rid="B41" ref-type="bibr">b</xref>; Zhou and Mao, <xref rid="B43" ref-type="bibr">2005</xref>; Li et al., <xref rid="B23" ref-type="bibr">2012</xref>; Mishra and Mishra, <xref rid="B26" ref-type="bibr">2015</xref>). So, a better classifier that has the ability to select features with greater discriminatory power and more biological insight is required for clinical practice (Roepman et al., <xref rid="B33" ref-type="bibr">2005</xref>, <xref rid="B32" ref-type="bibr">2006</xref>). We have used expression values of different cancer types [e.g., breast cancer (GSE3744), oral cancer (GSE25099), ovarian cancer (GSE26712), squamous cell carcinoma (GSE2280), lung cancer (GSE7670), and brain cancer (GSE4290)] to test and compare “sigFeature” algorithm with other algorithms.</p>
    <p>In this study, we have created a novel feature selection algorithm “sigFeature” that is based on support vector machine (SVM) and <italic>t</italic> statistic. Our algorithm not only selects features with higher classification accuracy but also determines the differentially expressed features (genes) seamlessly. After comparing “sigFeature” with three selection algorithms such as “SVM-RFE,” “SVM-T-RFE,” and “SVM-BT-RFE” (<xref ref-type="supplementary-material" rid="SM1">Supplementary Data Sheet 1</xref>) using the aforementioned data sets, “sigFeature” stands apart in terms of feature classification, as well as differentially expressed features in almost all the classes studied. We further tested “sigFeature” for determining its ability to predict the biological signatures of the example data sets. It was found that when gene set enrichment analysis (GSEA) analysis (Subramanian et al., <xref rid="B36" ref-type="bibr">2005</xref>) was done on the output of “sigFeature,” the biological features of the samples were predicted accurately. “sigFeature” is proven to be better than other algorithms when tested with GSEA with the selected features.</p>
  </sec>
  <sec sec-type="materials and methods" id="s2">
    <title>Materials and Methods</title>
    <p>We have chosen six publicly available microarray data sets randomly for testing and comparison with our tool. All the feature selection algorithms are applied precisely for cancer classification. In addition to most feature selection methods embedded with an estimation of the classifier, “sigFeature” is inherently a multivariate method. “sigFeature” evaluates the relevance of several features considered together. A univariate method, on the other hand, assesses the significance of each feature individually. The latter is often computationally easier, but the former is more sophisticated from the data analysis point of view, as genes are known to communicate in many respects and are often coregulated. We also used the selection approach of the ensemble feature that relies on various subsamples of the original data to create different signatures. Using GSEA analysis, the selected robust signatures are finally analyzed to determine its biological signature.</p>
    <sec>
      <title>Microarray Data Sets</title>
      <p><xref rid="T1" ref-type="table">Table 1</xref> summarizes the main characteristics of the microarray data sets downloaded from GEO (Gene Expression Omnibus). The data sets share common characteristics such as very low samples/dimensions (or features) ratio.</p>
      <table-wrap id="T1" position="float">
        <label>Table 1</label>
        <caption>
          <p>Description of the data sets.</p>
        </caption>
        <table frame="hsides" rules="groups">
          <thead>
            <tr>
              <th valign="top" align="left" rowspan="1" colspan="1">
                <bold>Data set</bold>
              </th>
              <th valign="top" align="center" rowspan="1" colspan="1">
                <bold>Samples</bold>
              </th>
              <th valign="top" align="center" rowspan="1" colspan="1">
                <bold>Probes</bold>
              </th>
              <th valign="top" align="center" rowspan="1" colspan="1">
                <bold>Classes</bold>
              </th>
              <th valign="top" align="left" rowspan="1" colspan="1">
                <bold>SDR</bold>
              </th>
              <th valign="top" align="left" rowspan="1" colspan="1">
                <bold>Types</bold>
              </th>
              <th valign="top" align="left" rowspan="1" colspan="1">
                <bold>Reference</bold>
              </th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">GSE3744</td>
              <td valign="top" align="center" rowspan="1" colspan="1">47</td>
              <td valign="top" align="center" rowspan="1" colspan="1">54675</td>
              <td valign="top" align="center" rowspan="1" colspan="1">2</td>
              <td valign="top" align="left" rowspan="1" colspan="1">0.00086</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Breast cancer</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Richardson et al., <xref rid="B30" ref-type="bibr">2006</xref></td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">GSE25099</td>
              <td valign="top" align="center" rowspan="1" colspan="1">79</td>
              <td valign="top" align="center" rowspan="1" colspan="1">17881</td>
              <td valign="top" align="center" rowspan="1" colspan="1">2</td>
              <td valign="top" align="left" rowspan="1" colspan="1">0.00441</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Oral cancer</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Peng et al., <xref rid="B28" ref-type="bibr">2011</xref></td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">GSE26712</td>
              <td valign="top" align="center" rowspan="1" colspan="1">195</td>
              <td valign="top" align="center" rowspan="1" colspan="1">22283</td>
              <td valign="top" align="center" rowspan="1" colspan="1">2</td>
              <td valign="top" align="left" rowspan="1" colspan="1">0.00875</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Ovarian cancer</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Bonome et al., <xref rid="B7" ref-type="bibr">2008</xref></td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">GSE2280</td>
              <td valign="top" align="center" rowspan="1" colspan="1">27</td>
              <td valign="top" align="center" rowspan="1" colspan="1">22283</td>
              <td valign="top" align="center" rowspan="1" colspan="1">2</td>
              <td valign="top" align="left" rowspan="1" colspan="1">0.00121</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Squamous cell carcinoma</td>
              <td valign="top" align="left" rowspan="1" colspan="1">O'Donnell et al., <xref rid="B27" ref-type="bibr">2005</xref></td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">GSE7670</td>
              <td valign="top" align="center" rowspan="1" colspan="1">66 (54<xref ref-type="table-fn" rid="TN1"><sup>*</sup></xref>)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">22283</td>
              <td valign="top" align="center" rowspan="1" colspan="1">2</td>
              <td valign="top" align="left" rowspan="1" colspan="1">0.00296</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Lung cancer</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Su et al., <xref rid="B35" ref-type="bibr">2007</xref></td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">GSE4290</td>
              <td valign="top" align="center" rowspan="1" colspan="1">180</td>
              <td valign="top" align="center" rowspan="1" colspan="1">54613</td>
              <td valign="top" align="center" rowspan="1" colspan="1">2</td>
              <td valign="top" align="left" rowspan="1" colspan="1">0.00329</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Brain cancer</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Sun et al., <xref rid="B37" ref-type="bibr">2006</xref></td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="TN1">
            <label>*</label>
            <p>Total 27 paired samples are used in this example.</p>
          </fn>
          <p><italic>Samples/dimensions ratio (SDR) refers to the ratio between the number of samples and the number of dimensions (or features)</italic>.</p>
        </table-wrap-foot>
      </table-wrap>
      <p>All these data sets are preprocessed using the following procedures.</p>
    </sec>
    <sec>
      <title>Data Normalization</title>
      <p>The purpose of data normalization is to minimize the variation in data due to various non-biological factors and make them comparable in one scale. These data sets are normalized by “quantile” normalization method using the “Bioconductor” package “Limma” (Ritchie et al., <xref rid="B31" ref-type="bibr">2015</xref>). The goal of the “quantile” normalization method (Bolstad et al., <xref rid="B6" ref-type="bibr">2003</xref>) is to make the distribution of sample intensities equal for each array in a set of arrays.</p>
    </sec>
    <sec>
      <title>Support Vector Machines</title>
      <p>Generally, SVMs are used for classification and regression analysis as supervised learning methods. Support vector machines are also used for selecting features from a data set [e.g., SVM recursive feature elimination (SVM-RFE)]. For feature selection, we have used SVM in “sigFeature,” with some modification to obtain the desired weight values for each feature. In this section, we have explained how SVM effectively operates, because our algorithm is built upon the basic principle of SVM.</p>
      <p>Support vector machine uses kernel functions to perform classification efficiently on non-linear data. It implements implicit mapping in the high-dimensional input feature vectors into high-dimensional spaces. This produces a linear hyperplane, which can separate two groups of data meaningfully (Butte, <xref rid="B8" ref-type="bibr">2002</xref>). The hyperplane in higher dimensional spaces is chosen to be maximally distant from both groups so that examples from separate classes are separated as much as possible. New examples are then classified based on their orientation to the hyperplane. The hyperplane can be expressed as a vector (Equation 1, linear SVM) that acts as a reference frame to map the position of each sample in higher dimensional spaces and is summed to yield a discriminate score, which is used to classify the sample into one of the two groups.
<disp-formula id="E1"><label>(1)</label><mml:math id="M1"><mml:mtable class="eqnarray" columnalign="right center left"><mml:mtr><mml:mtd><mml:mi>f</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:munderover accentunder="false" accent="false"><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:munderover></mml:mstyle><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>b</mml:mi></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>
Assuming a training data set {(<italic>x</italic>1, <italic>y</italic>1), …, (<italic>xn, yn</italic>), <inline-formula><mml:math id="M2"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi>ℜ</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula>, <italic>y</italic><sub><italic>i</italic></sub> ∈ (−1, 1)}, where <italic>x</italic> = (<italic>x</italic><sub>1</sub>, …, <italic>x</italic><sub><italic>d</italic></sub>) is a <italic>d-</italic>dimensional input vector, and <italic>y</italic> is the class label, and <italic>w</italic> = (<italic>w</italic><sub>1</sub>, …, <italic>w</italic><sub><italic>d</italic></sub>) are coefficients of the hyperplane, and <italic>b</italic> represents the intercept of the hyperplane. Support vector machines are used in different feature selection algorithms, for example, “SVM-RFE,” “SVM-T-RFE,” and “SVM-BT-RFE.” A detailed description of those algorithms is given in the <xref ref-type="supplementary-material" rid="SM1">Supplementary Data Sheet 1</xref>.</p>
    </sec>
    <sec>
      <title>Support Vector Machine–Recursive Feature Elimination</title>
      <p>In 2002, Guyon et al. (<xref rid="B17" ref-type="bibr">2002</xref>) introduced a feature selection method known as SVM-RFE for classification of cancer. The “SVM-RFE” is a weight-based method. The weight vector coefficients of a linear SVM are applied at each stage as a feature ranking criterion. The most informative features are those that correspond to the largest weight. Thus, a sequential backward feature elimination procedure is used by “SVM-RFE” for selecting the feature with the smallest weight that is subsequently stored into a stack. This iteration process is continued until the last feature variable remains. The “SVM-RFE” algorithm and our newly developed feature selection algorithm both belong to the Wrapper method, and both algorithms select the feature by eliminating feature recursively. The main difference is there in calculating the ranking score for the <italic>i</italic>th feature.</p>
    </sec>
    <sec>
      <title>Significant Feature Selection (sigFeature)</title>
      <p>“SVM-RFE” (Guyon et al., <xref rid="B17" ref-type="bibr">2002</xref>) algorithm was originally written for selecting features in binary classification problem. Some researchers (Li et al., <xref rid="B23" ref-type="bibr">2012</xref>; Mishra and Mishra, <xref rid="B26" ref-type="bibr">2015</xref>) enhanced “SVM-RFE” for further betterment of the feature selection process. Li et al. (<xref rid="B23" ref-type="bibr">2012</xref>) and Mishra and Mishra (<xref rid="B26" ref-type="bibr">2015</xref>) used different mathematical equitation in their algorithms to calculate the ranking score for the <italic>i</italic>th feature. For more information, see <xref ref-type="supplementary-material" rid="SM1">Supplementary Data Sheet 1</xref>.</p>
      <p>Generally, the expression data set contains a large number of probes sets and a small number of sample sizes. It is observed that the number of samples in each class is unequal in the data set. In our approach, the features to be selected for classification need to contain maximum discriminatory power between the classes. Considering the imbalance in sample size (no. of samples class 1 ≠ class 2) into consideration, we characterize the accompanying measure as below (Equation 2):
<disp-formula id="E2"><label>(2)</label><mml:math id="M3"><mml:mtable class="eqnarray" columnalign="right center left"><mml:mtr><mml:mtd><mml:mo>Δ</mml:mo><mml:mi>δ</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mstyle displaystyle="true"><mml:munder class="msub"><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msup><mml:mo>∈</mml:mo><mml:mi>c</mml:mi><mml:mi>l</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:munder></mml:mstyle><mml:mi>f</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mstyle displaystyle="true"><mml:munder class="msub"><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo></mml:mrow></mml:msup><mml:mo>∈</mml:mo><mml:mi>c</mml:mi><mml:mi>l</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:munder></mml:mstyle><mml:mi>f</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>
In class +1 and −1, the total number of samples is considered as <italic>n</italic><sup>+</sup> and <italic>n</italic><sup>−</sup>, respectively. The value Δδ denotes the separation between the two classes. The larger the value of Δδ, the better is the separation between the two classes. Considering equation (2) and denoting the difference of the <italic>j</italic>th feature of the two classes such as <inline-formula><mml:math id="M4"><mml:mo>|</mml:mo><mml:msubsup><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msubsup><mml:mo>|</mml:mo></mml:math></inline-formula> and <inline-formula><mml:math id="M5"><mml:mo>|</mml:mo><mml:msubsup><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo></mml:mrow></mml:msubsup><mml:mo>|</mml:mo></mml:math></inline-formula>, we get Equation 3:
<disp-formula id="E3"><label>(3)</label><mml:math id="M6"><mml:mtable class="eqnarray" columnalign="right center left"><mml:mtr><mml:mtd><mml:mo>Δ</mml:mo><mml:mi>δ</mml:mi><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:munderover accentunder="false" accent="false"><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:munderover></mml:mstyle><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:msubsup><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msubsup><mml:mo>|</mml:mo><mml:mo>-</mml:mo><mml:mstyle displaystyle="true"><mml:munderover accentunder="false" accent="false"><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:munderover></mml:mstyle><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:msubsup><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo></mml:mrow></mml:msubsup><mml:mo>|</mml:mo><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:munderover accentunder="false" accent="false"><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:munderover></mml:mstyle><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mo>|</mml:mo><mml:msubsup><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msubsup><mml:mo>|</mml:mo><mml:mo>-</mml:mo><mml:mo>|</mml:mo><mml:msubsup><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo></mml:mrow></mml:msubsup><mml:mo>|</mml:mo></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>
The <italic>j</italic>th element of <italic>w</italic> (weight vector) is considered, as <italic>w</italic><sub><italic>j</italic></sub> and <italic>d</italic> is the total number of features. In special cases, where one class has only one sample, and the other class has more than one sample, <bold><italic>t</italic></bold>, the significant differences between the two classes can be calculated by using standard single sample <italic>t</italic> statistic where <inline-formula><mml:math id="M7"><mml:mo>|</mml:mo><mml:msubsup><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msubsup><mml:mo>|</mml:mo></mml:math></inline-formula> stands for class +1 and <inline-formula><mml:math id="M8"><mml:mo>|</mml:mo><mml:msubsup><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo></mml:mrow></mml:msubsup><mml:mo>|</mml:mo></mml:math></inline-formula> stands for class −1.
<disp-formula id="E4"><label>(4)</label><mml:math id="M9"><mml:mtable class="eqnarray" columnalign="right center left"><mml:mtr><mml:mtd><mml:mtext>where</mml:mtext><mml:mo>|</mml:mo><mml:msubsup><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msubsup><mml:mo>|</mml:mo><mml:mo>=</mml:mo><mml:mo>|</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo>¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msup><mml:mo>-</mml:mo><mml:msubsup><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msqrt><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>/</mml:mo><mml:msup><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:msqrt></mml:mrow></mml:mfrac><mml:mo>|</mml:mo><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi><mml:mo>|</mml:mo><mml:msubsup><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo></mml:mrow></mml:msubsup><mml:mo>|</mml:mo><mml:mo>=</mml:mo><mml:mo>|</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo>¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo></mml:mrow></mml:msubsup><mml:mo>-</mml:mo><mml:msubsup><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msqrt><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>/</mml:mo><mml:msup><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:msqrt></mml:mrow></mml:mfrac><mml:mo>|</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>
where <inline-formula><mml:math id="M10"><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo>¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msubsup></mml:math></inline-formula> and <inline-formula><mml:math id="M11"><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo>¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo></mml:mrow></mml:msubsup></mml:math></inline-formula> stands for mean, <inline-formula><mml:math id="M12"><mml:msubsup><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msubsup></mml:math></inline-formula> and <inline-formula><mml:math id="M13"><mml:msubsup><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo></mml:mrow></mml:msubsup></mml:math></inline-formula> are standard deviation, <inline-formula><mml:math id="M14"><mml:msubsup><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msubsup></mml:math></inline-formula> and<inline-formula><mml:math id="M15"><mml:msubsup><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo></mml:mrow></mml:msubsup></mml:math></inline-formula> stand for the specified population mean of the <italic>j</italic>th feature, and <italic>n</italic><sup>+</sup> and <italic>n</italic><sup>−</sup> are the number of samples present in each class (+1 class and −1 class), respectively.
<disp-formula id="E5"><label>(5)</label><mml:math id="M16"><mml:mtable class="eqnarray" columnalign="right center left"><mml:mtr><mml:mtd><mml:mo>Δ</mml:mo><mml:mi>δ</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>*</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mo>|</mml:mo><mml:msubsup><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msubsup><mml:mo>|</mml:mo><mml:mo>-</mml:mo><mml:mo>|</mml:mo><mml:msubsup><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo></mml:mrow></mml:msubsup><mml:mo>|</mml:mo></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p>
      <p><inline-formula><mml:math id="M17"><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> If both classes have more than one sample, then the separation value Δδ can be calculated by the equation as below:
<disp-formula id="E6"><label>(6)</label><mml:math id="M18"><mml:mtable class="eqnarray" columnalign="right center left"><mml:mtr><mml:mtd><mml:mo>Δ</mml:mo><mml:mi>δ</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>*</mml:mo><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo>¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msubsup><mml:mo>-</mml:mo><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo>¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msqrt><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>/</mml:mo><mml:msup><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>/</mml:mo><mml:msup><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:msqrt></mml:mrow></mml:mfrac></mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>
From the above equation, the maximum separation would be affected when the expression values of an individual feature in both classes reject the null hypothesis <bold>Ho</bold> and move on in the direction of a specified alternative hypothesis <bold>Ha</bold>.
<disp-formula id="E7"><label>(7)</label><mml:math id="M19"><mml:mtable class="eqnarray" columnalign="right center left"><mml:mtr><mml:mtd><mml:mo>Δ</mml:mo><mml:mi>δ</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>*</mml:mo><mml:mi>P</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>&lt;</mml:mo><mml:mo>-</mml:mo><mml:mo>|</mml:mo><mml:mi>u</mml:mi><mml:mo>|</mml:mo><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>&gt;</mml:mo><mml:mo>|</mml:mo><mml:mi>u</mml:mi><mml:mo>|</mml:mo></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>
where <bold><italic>v</italic></bold> is the level of flexibility parameter for the corresponding reference distribution, and <bold><italic>u</italic></bold> is the observed (positive) estimation of the test statistic on the basis of the level of flexibility <bold><italic>v</italic></bold>. Unlike “SVM-RFE,” in “sigFeature” we select important features by incorporating the product of weights and the corresponding differences between the classes. The pseudo code of the algorithm is given as below.</p>
      <table-wrap id="d35e1713" position="float">
        <label>Algorithm 1</label>
        <caption>
          <p>sigFeature</p>
        </caption>
        <table frame="hsides" rules="groups">
          <tbody>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Inputs:<break/>      Training examples <inline-formula><mml:math id="M20"><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula><break/>      Class labels <inline-formula><mml:math id="M21"><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula><break/> Initialize:<break/> Subset of existing features <italic>s</italic> = [1, 2, …<italic>n</italic>]<break/> Feature ranked list <italic>r</italic> = []<break/> Repeat until <italic>s</italic> = []<break/>           Confine training examples to good feature inventories<break/>          <italic>X</italic> = <italic>X</italic><sub>0</sub>(:, <italic>s</italic>)<break/>          Train the classifier (training data set)<break/>          α = <italic>SVM</italic> − <italic>train</italic> (<italic>X, y</italic>)<break/>          Enumerate the weight vector of dimension length(s)<break/>          <inline-formula><mml:math id="M22"><mml:mi>W</mml:mi><mml:mo>=</mml:mo><mml:munder class="msub"><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula><break/>          Enumerate the ranking criteria (for all <italic>i</italic>)<break/>          <italic>c</italic><sub><italic>i</italic></sub> = <italic>w</italic><sub><italic>i</italic></sub>*<italic>P</italic>[<italic>t</italic><sub><italic>i</italic></sub>(<italic>v</italic>) &lt; −|<italic>u</italic>|<italic>ort</italic><sub><italic>i</italic></sub>(<italic>v</italic>) &gt; |<italic>u</italic>|]<break/>          Find the feature with the negligible ranking criterion<break/>          <italic>f</italic> = <italic>sort</italic>(<italic>c</italic>)<break/>          Reform feature ranked list:<break/>          <italic>r</italic> = [<italic>s</italic>(<italic>f</italic>), <italic>r</italic>]<break/>          Remove the feature with the smallest ranking criterion<break/>          <italic>s</italic> = <italic>s</italic>(1:<italic>f</italic> − 1, <italic>f</italic> + 1:<italic>length</italic>(<italic>s</italic>))<break/> Output:<break/> Feature ranked list <italic>r</italic>.</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
    </sec>
    <sec>
      <title>Robust Selection of Features Using the Ensemble Selection Procedure</title>
      <p>We have further embedded the recent concept of ensemble feature selection techniques to improve the stability of feature selection algorithms (Abeel et al., <xref rid="B2" ref-type="bibr">2010</xref>). Like ensemble learning for classification, the technique of selection of features uses the same idea. A number of different selectors of features are used in this method (ensemble), and finally, the output of these separate selectors is aggregated and returned as the final result. Using our newly developed algorithm “sigFeature,” we focus on the analysis of ensemble feature selection technique to select robust features. The other feature selection algorithms (“SVM-RFE,” “SVM-T-RFE,” and “SVM-BT-RFE”) included in this work for performance comparison with “sigFeature” select robust features in a similar way.</p>
      <p>We chose our training set with 40 subsampling sets consisting of 90% of the original data set. The remaining 10% of the data can be used to evaluate classification performance as an independent validation set. The main motto behind this is to generate a variety of feature selection protocols using “sigFeature” algorithm. Because the “sigFeature” algorithm is deterministic, performing it on different training samples is the only way to generate diversity in selection. To this end, we use the bootstrapping method, a well-established statistical technique for reducing variance (Efron, <xref rid="B12" ref-type="bibr">1992</xref>). In statistics, bootstrap is a method that relies on random sampling with replacement. Within each layer, a simple random sample is selected from the n−1 clusters within the n clusters of the layer. The process can be repeated “N” times by producing N new samples. Bootstrap weights are generated in each layer for infinite populations (“with replacement” sampling) by sampling with replacement from the primary sampling unites. The weights of the bootstrap are used to measure values of “N” that are used to determine the variance. By drawing different bootstrap samples of the training data (with replacement), we can apply “sigFeature” algorithm to each of these bootstrap samples and thus obtain a variety of feature rankings. Then, we have an ensemble (Ensemble feature selection) composed of <italic>t</italic> feature selectors, EFS = <italic>{F1,F2,…Ft}</italic>, so we assume that each <italic>Fi</italic> gives the ranking feature, <inline-formula><mml:math id="M23"><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="M24"><mml:msubsup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula> indicates the rank of feature <italic>j</italic> in bootstrap <italic>i</italic>. Rank 1 is assigned for the best feature, and the worst is ranked N. In order to aggregate the various rankings obtained by bootstrapping the training data, we have chosen a complete linear aggregation (CLA) in a final signature. A general formula obtained by summing the ranks over all bootstrap samples for the ensemble ranking <italic>f</italic> is as follows:
<disp-formula id="E8"><label>(8)</label><mml:math id="M25"><mml:mtable class="eqnarray" columnalign="right center left"><mml:mtr><mml:mtd><mml:mi>f</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mstyle displaystyle="true"><mml:munderover accentunder="false" accent="false"><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:munderover></mml:mstyle><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>,</mml:mo><mml:mstyle displaystyle="true"><mml:munderover accentunder="false" accent="false"><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:munderover></mml:mstyle><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>
where <italic>w</italic><sub><italic>i</italic></sub> denotes a bootstrap-dependent weight.</p>
      <p>Then, the ensemble ranking <italic>f</italic> is obtained by simply summing the ranks above all samples of the bootstrap.</p>
      <p>The <italic>s</italic> features with the highest summed rank are selected from <italic>f</italic> to select the final set of features for a size <italic>s</italic> signature.</p>
    </sec>
    <sec>
      <title>Stability Measurement of the Selected Features</title>
      <p>Stability measurement is an essential part of the classification performance. It is therefore necessary to incorporate stability, else any feature selection algorithm may always return the same features regardless of any input sample combinations. We used Kuncheva index (KI) statistical analysis described below to measure stability of the selected features.</p>
      <p>Let us consider a data set <italic>X</italic> = {<italic>x</italic><sub>1</sub>, …., <italic>x</italic><sub><italic>M</italic></sub>} with M samples and N features. After that, the sample set is subsampled randomly with <italic>k</italic> times of size [<italic>xM</italic>](0 &lt; <italic>x</italic> &lt; 1). We randomly selected <italic>k</italic> = 40 in our data analysis and <italic>x</italic> = 0.9. Consequently, on each of the k subsamplings, feature selection is performed, and a marker set of a given size is selected, further referred to as a signature. The relative stability <italic>S</italic><sub><italic>tot</italic></sub> can then be defined as the average of all pair-like comparisons between all the signatures on the <italic>k</italic> subsamplings.
<disp-formula id="E9"><label>(9)</label><mml:math id="M26"><mml:mtable class="eqnarray" columnalign="right center left"><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>o</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:msubsup><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msubsup><mml:mi>K</mml:mi><mml:mi>I</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>
where <italic>f</italic><sub><italic>i</italic></sub> is the signature obtained by the subsampling method <italic>i</italic>(1 ≤ <italic>i</italic> ≤ <italic>k</italic>). <italic>KI</italic>(<italic>f</italic><sub><italic>i</italic></sub>, <italic>f</italic><sub><italic>j</italic></sub>) denotes the KI. A stability index defined as follows between <italic>f</italic><sub><italic>i</italic></sub> and <italic>f</italic><sub><italic>j</italic></sub> (Kuncheva, <xref rid="B21" ref-type="bibr">2007</xref>).
<disp-formula id="E10"><label>(10)</label><mml:math id="M27"><mml:mtable class="eqnarray" columnalign="right center left"><mml:mtr><mml:mtd><mml:mi>K</mml:mi><mml:mi>I</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>r</mml:mi><mml:mi>N</mml:mi><mml:mo>-</mml:mo><mml:msup><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mo>.</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>N</mml:mi><mml:mo>-</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>r</mml:mi><mml:mo>-</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>/</mml:mo><mml:mi>N</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mo>-</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>/</mml:mo><mml:mi>N</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>
where <italic>s</italic> = |<italic>f</italic><sub><italic>i</italic></sub>| = |<italic>f</italic><sub><italic>j</italic></sub>| refers to the signature size, and <italic>r</italic> = |<italic>f</italic><sub><italic>i</italic></sub>⋂<italic>f</italic><sub><italic>j</italic></sub>| refers to the number of common elements in both signatures. The KI meets −1 &lt; <italic>KI</italic>(<italic>f</italic><sub><italic>i</italic></sub>, <italic>f</italic><sub><italic>j</italic></sub>) ≤ 1, and the higher its value, the greater the number of features commonly selected in both signatures. In this index, the <italic>s</italic><sup>2</sup>/<italic>N</italic> term corrects a bias due to the chance to select common features between two randomly selected signatures.</p>
    </sec>
    <sec>
      <title>Classification Performance (Cross-Validation)</title>
      <p>In 2002, Ambroise and McLachlan (<xref rid="B4" ref-type="bibr">2002</xref>) introduced a new cross-validation technique for evaluation of feature (gene) selection algorithms. In this technique, the feature selection is performed on a subset of samples, which are obtained from the total sample sets, and the validation is performed on the other subsample set to acquire an impartial execution test. In this research work, we recruited external 10-fold cross-validation data set to assess the performance of the selected features.</p>
    </sec>
    <sec>
      <title>GSEA for Prediction of Biological Signature in the Test Data Sets</title>
      <p>An important attribute of a selected feature is its potential to predict the biological signature of any data set. In GSEA, we used the Molecular Signatures Database (MSigDB V 7.0) to compare selected features using the aforementioned algorithms for further downstream evaluation. MSigDB V 7.0 is a compilation of annotated gene sets. For this analysis, Cancer Gene Neighborhoods (CGN), Cancer modules (CM), and Oncogenic signatures (C6) gene sets were used during GSEA (Subramanian et al., <xref rid="B36" ref-type="bibr">2005</xref>), with the first 500 selected features generated by each of the algorithms including “sigFeature.” Briefly, CGN is a collection of gene sets defined by expression neighborhoods centered on 380 cancer associated genes, whereas CM is an assemblage of 456 gene set “modules” observed to significantly change during various oncogenic conditions (Segal et al., <xref rid="B34" ref-type="bibr">2004</xref>), and finally, C6 is a collection of gene sets (oncogenic signatures, 189 gene sets) that represent signatures of biological pathways that are generally deregulated in carcinogenesis.</p>
    </sec>
    <sec>
      <title>Implementation and Availability</title>
      <p>All the algorithms (“sigFeature,” “SVM-RFE,” “SVM-T-RFE,” and “SVM-BT-RFE”) are implemented in R script. The “sigFeature” package is available in Bioconductor and GitHub repository (<ext-link ext-link-type="uri" xlink:href="https://bioconductor.org/packages/sigFeature">https://bioconductor.org/packages/sigFeature</ext-link>). We use SVM by using a CRAN package named “e1071” (Meyer et al., <xref rid="B25" ref-type="bibr">2018</xref>). The R script for the algorithm “SVM-RFE” (Guyon et al., <xref rid="B17" ref-type="bibr">2002</xref>) is publicly available. Because there are no fast implementations of “SVM-T-RFE” and “SVM-BT-RFE” accessible so far, we used the “e1071” package to implement these two algorithms in R.</p>
    </sec>
  </sec>
  <sec sec-type="results" id="s3">
    <title>Results</title>
    <p>The experimental evaluations on the six different types of cancer microarray data sets have been reported here. We also analyzed the RNA-Seq data set (Canine mammary gland tumors, GSE119810) for reestablishing the robustness of the newly developed algorithm (detailed results are available in <xref ref-type="supplementary-material" rid="SM3">Supplementary Data Sheet 3</xref>). Finding a robust feature list (Roepman et al., <xref rid="B33" ref-type="bibr">2005</xref>) from a large sample pool without any sample biasness is a very tedious work. In order to compare the list of features produced by “sigFeature” algorithm with the features obtained from other algorithms discussed (e.g., “SVM-RFE,” “SVM-T-RFE,” “SVM-BT-RFE”), a comparable model for the selection method needs to be followed. We resampled 90% of the total data using bootstrap method (with replacement), and the resampling was done 40 times (bootstrapping graphics is shown in <xref ref-type="fig" rid="F1">Figure 1</xref>). The remaining 10% samples are used to evaluate the features selected. For the assessment of the combined significance of marker sets, the latest classification performance has already been provided. The results show that both stability and accuracy of the classification are quite significant on the data set compared to stability measurement and classification of the selected features of other algorithms such as “SVM-RFE,” “SVM-T-RFE,” and “SVM-BT-RFE.” The results of the variance in pairwise stability between two signatures are also discussed. The complementary performance of the various feature selection algorithms of consensus building from different individual signatures is carefully evaluated. We performed the <italic>t</italic>-test of the selected features individually between the classes in the data set to see the significant difference of the groups. The features that are more distinctly different will assist further downstream assessment. Thus, the GSEA is used to observe the contribution by using these robust features in discovering the cancer signature.</p>
    <fig id="F1" position="float">
      <label>Figure 1</label>
      <caption>
        <p>Bootstrap distribution plot and normal Q-Q plot for the data set GSE2280. We used 40 bootstraps (with replacement) with 90% of the total samples (GSE2280) to randomize the array of subsamples.</p>
      </caption>
      <graphic xlink:href="fgene-11-00247-g0001"/>
    </fig>
    <sec>
      <title>Stability of the Selected Features</title>
      <p>We compared the feature of each of the algorithms and analyzed the stability of each of the six cancer data sets used in this study. <xref ref-type="fig" rid="F1">Figure 1</xref> shows the results of the data set GSE2280 using a default configuration with the bootstrap number of 40, and all feature selection algorithms have been applied, with <italic>E</italic> = 1% at each iteration. Results of the other data sets are represented in Supplementary Figures (Figure 2.1 to Figure 6.4.2 in <xref ref-type="supplementary-material" rid="SM2">Supplementary Data Sheet 2</xref>). To minimize the execution time taken by each algorithm, the default configuration is used. The KI measures the robustness of the selected signatures (marker sets), and the external cross-validation error is used to measure the classification performance (<xref ref-type="fig" rid="F2">Figure 2</xref>). Kuncheva index is generally calculated between two feature vectors. The more the KI is closer to 1, the more the vectors are similar. It can be observed in the literature (Kuncheva, <xref rid="B21" ref-type="bibr">2007</xref>) that the CLA methods significantly improve the baseline (only SVM-RFE) in terms of both stability and classification performance. Methods of ensemble are better able to eliminate noisy and irrelevant dimensions. So we chose to produce the robust feature using the CLA method in our present study. One important issue in stable feature selection is how to measure the “stability” of feature selection algorithms, that is, how to qualify selection sensitivity for training set variations. The measure of stability can be used in various contexts. On the one hand, evaluation of various algorithms in performance comparison is indispensable. On the other hand, in feature selection algorithms, which take stability into account, it can be used for internal validation. We have chosen a feature list as a reference list in our steady measurement experiment, and the remaining feature lists are measured based on the reference feature list. Finally, the stability value of pairwise experiment is represented as a plot of histogram (<xref ref-type="fig" rid="F3">Figure 3</xref>).</p>
      <fig id="F2" position="float">
        <label>Figure 2</label>
        <caption>
          <p>Kuncheva index plot for the data set GSE2280. The stability of the features is measured based on CLA methods for different feature selection algorithms. We used 40 bootstraps (with replacement) and eliminated <italic>E</italic> = 1% features.</p>
        </caption>
        <graphic xlink:href="fgene-11-00247-g0002"/>
      </fig>
      <fig id="F3" position="float">
        <label>Figure 3</label>
        <caption>
          <p>Histogram plots for pairwise stability comparison of the features. Distribution plots of the pairwise stabilities for the data set GSE2280 where different algorithms produce the feature lists. In each iteration of the algorithms, we used 40 bootstraps, eliminated <italic>E</italic> = 1% features, used a signature size of 10%, and selected the CLA aggregation model.</p>
        </caption>
        <graphic xlink:href="fgene-11-00247-g0003"/>
      </fig>
    </sec>
    <sec>
      <title>Classification Performance Results</title>
      <p>The results of the classification of the GSE2280 microarray data set are illustrated here, and outputs for other data sets are included in <xref ref-type="supplementary-material" rid="SM2">Supplementary Data Sheet 2</xref>. We used different publicly available algorithms (“SVM-RFE,” “SVM-T-RFE,” and “SVM-BT-RFE”) to compare the performance of the selected feature with “sigFeature” for this data set. From the 90% of the total data set, the feature lists are selected, and the 10% of samples are used for testing the selected feature. We also subsampled by iterating 40 times the 90% of the total samples using the bootstrapping (with replacement) method to remove the sample biasness. After that, we use the improved ensemble selection method (“CLA”) to find out the robust feature list. Using the feature list, the classification performance is tested on the test sample set. The graphical representation of the result is shown in <xref ref-type="fig" rid="F4">Figure 4</xref>. In order to find the best classification accuracy, we have adjusted the parameters cost and gamma (<xref ref-type="fig" rid="F5">Figure 5</xref>). The gamma parameter intuitively defines the extent to which the influence of a single example of training reaches, with low values meaning “far” and high values meaning “close.” The cost parameter offers proper classification of training examples to maximize the decision function margin. The “SVM-BT-RFE,” an individual ranking method, performs more badly than other algorithms evaluated in this study because this algorithm selects many redundant features, which give minimal preferential power to the classification issue. The classification performance here depends on many conditions. The major factors are the number of samples in a data set and the numeric values corresponding to the expression of each gene in that data set.</p>
      <fig id="F4" position="float">
        <label>Figure 4</label>
        <caption>
          <p>Tenfold external cross-validation error plot. The classification performances of the top features are shown here, which are selected by different feature selection algorithms. We used 40 bootstraps and eliminated <italic>E</italic> = 1% features.</p>
        </caption>
        <graphic xlink:href="fgene-11-00247-g0004"/>
      </fig>
      <fig id="F5" position="float">
        <label>Figure 5</label>
        <caption>
          <p>Three-dimensional representation of cost, gamma, and classification accuracy. The Cost and gamma values are selected to determine the best performance in the classification of features selected (top 1,000 features by CLA) by different selection algorithms.</p>
        </caption>
        <graphic xlink:href="fgene-11-00247-g0005"/>
      </fig>
    </sec>
    <sec>
      <title>Differentially Significant Features</title>
      <p>In order to obtain a meaningful biological insight, the selected features must have a significant difference between the sample groups present in the data sets. In this experiment, we compare the characteristics (significant difference between the groups) of the features produced by “sigFeature” with other algorithms. Thus, we compare the <italic>p</italic>-values of each feature (top <italic>n</italic> = 1,000), which are produced by the different algorithms. Although individual feature lists are produced by each subset (40 bootstraps), we average the <italic>p</italic>-value by its position in the feature list. In each data set, it may not create an equal number of sample size in both classes. We use default <italic>t</italic>-test (two-sided) using an R function named <italic>t</italic>-test()and computed the unadjusted <italic>p</italic>-values. Then the unadjusted <italic>p</italic>-values produced are used to plot a histogram, depicted in <xref ref-type="fig" rid="F6">Figure 6</xref> to observe the frequency of the unadjusted <italic>p</italic>-values associated with the rank feature. The histogram plot shows the area proportional to the unadjusted <italic>p</italic>-value frequency.</p>
      <fig id="F6" position="float">
        <label>Figure 6</label>
        <caption>
          <p>Histogram plots of unadjusted <italic>p</italic>-values. The comparison of the average unadjusted <italic>p</italic>-values is shown, which are calculated individually using the top 1,000 features between classes. The list of features is made using 40 bootstrap subsets where the feature selection algorithms remove <italic>E</italic> = 1% features at each iteration.</p>
        </caption>
        <graphic xlink:href="fgene-11-00247-g0006"/>
      </fig>
    </sec>
    <sec>
      <title>GSEA Results</title>
      <p>The features identified by newly developed “sigFeature” (top five hundred features by CLA) and other three algorithms SVM-RFE, SVM-T-RFE, and SVM-BT-RFE were analyzed by the aforementioned workflow to check whether they are able to predict the biological attribute of the six microarray data sets from which they were derived.</p>
      <p>The first data set GSE2280 is a critical data set as it originates from oral cancer patients with lymphatic metastasis. Interestingly, “sigFeature” was able to significantly (<italic>p</italic> ≤ 0.05) predict two gene sets “Neighborhood of RAP1A” and “Neighborhood of UBE2N.” Both genes were strongly involved in regulation of tumor metastasis. The monomeric G protein, RAP1A, acts as a switch during transduction of cellular signaling and generally regulated by its binding to either guanosine triphosphate (GTP) or guanosine diphosphate. It functions to regulate the function of cell adhesions and junction proteins and mediate cellular migration and polarization to promote metastasis in prostrate tumors, ovarian tumors, melanoma, lung cancer, glioma, bladder cancer, leukemia, and also oral cavity (Bailey et al., <xref rid="B5" ref-type="bibr">2009</xref>; Chen et al., <xref rid="B9" ref-type="bibr">2013</xref>; Lu et al., <xref rid="B24" ref-type="bibr">2016</xref>; Yi-Lei et al., <xref rid="B39" ref-type="bibr">2017</xref>). Moreover, UBE2N encodes a protein that is a member of the E2 ubiquitin–conjugating enzyme family and helps to catalyze the synthesis of non-canonical “Lys-63”-linked polyubiquitin chains leading to transcriptional activation of genes involved in tumor proliferation and metastasis (Gallo et al., <xref rid="B15" ref-type="bibr">2017</xref>; Vallabhaneni et al., <xref rid="B38" ref-type="bibr">2017</xref>). Among the other algorithms, SVM-RFE only enriched the term “Neighborhood of RAN” that is related to signature of cancer metastasis. RAN is also a GTPase, which regulates the nucleocytoplasmic import and export of proteins and RNAs, and reported to be involved in the metastasis of renal cell carcinoma and pancreatic cancer (Abe et al., <xref rid="B1" ref-type="bibr">2008</xref>; Deng et al., <xref rid="B11" ref-type="bibr">2014</xref>). No other algorithms were able to identify such intricate aspect in the given data set.</p>
      <p>Data set GSE4290 is derived from glioma patients. The feature identified by “sigFeature” was able to enrich computational gene sets “Genes in the cancer module 83” and “Genes in the cancer module 151.” Interestingly, these modules were composed mostly of data sets derived from primary neuro tumors and related cell lines. Hence, it appears that “sigFeature” is able to partially identify its biological attributes correctly compared to other algorithms that failed to do so.</p>
      <p>In case of data set GSE7670, expression of genes was obtained from lung cancer samples and cell lines. Feature selected by only SVM-T-RFE was not able to predict its biological nature. Other algorithms along with “sigFeature” are able to predict its true biological origin by enrichment of oncogenic signature (C6) “Module_5 Lung genes.”</p>
      <p>Data set GSE26712 is based on ovarian cancer. Feature selected by “sigFeature” also predicted its biological origin with the enrichment of oncogenic signature (C6) “Module_1 Ovary genes.” Among the other algorithms, only SVM-RFE–derived feature was able to predict that the data set is of ovarian origin by enrichment of the same module.</p>
      <p>Data set GSE3744 is composed of breast carcinoma samples. Only SVM-BT-RFE was able to partially predict the true biological nature of the data set. The feature enriched the term oncogenic signature (C6) “KRAS.600.LUNG.BREAST_UP.V1_UP” that comprised the genes that were up-regulated in epithelial lung and breast cancer cell lines overexpressing an oncogenic form of KRAS gene. The “sigFeature” and other given algorithms could not predict the biological nature of the data set. We needed further in-depth inquiry to define the appropriate reason why those algorithms were unable to detect the cancer signature.</p>
      <p>Next, data set GSE25099 has the characteristic of oral squamous cell carcinoma. In this case, “sigFeature” and the other algorithms could not identify the biological signature, as they could not enrich any gene set containing features related to oral cancer. For further clarification, a differential expression analysis was performed between case and control samples, and a signature list was generated using a cutoff value of <italic>p</italic> &lt; 0.05 and a fold change of ±1.5. This list of signatures was also unable to predict the cancer signature in the GSEA assessment.</p>
      <p>Overall, the analysis revealed that “sigFeature” is able to predict the signature of three out of six data sets with absolute precision, whereas the fourth one partially (<xref rid="T2" ref-type="table">Table 2</xref>). Comparable proficiency was observed only with SVM-RFE (three of six). Support vector machine BT-RFE could get one out of six right and partially correct about the other, whereas SVM-T-RFE failed in case of all the data sets. Thus, it appears from the comparative analysis that selection of biologically relevant feature is a crucial achievement of the newly developed “sigFeature.”</p>
      <table-wrap id="T2" position="float">
        <label>Table 2</label>
        <caption>
          <p>Results of GSEA.</p>
        </caption>
        <table frame="hsides" rules="groups">
          <thead>
            <tr>
              <th rowspan="1" colspan="1"/>
              <th valign="top" align="center" rowspan="1" colspan="1">
                <bold>Final score (out of 6)</bold>
              </th>
              <th valign="top" align="left" rowspan="1" colspan="1">
                <bold>GSE3744</bold>
              </th>
              <th valign="top" align="left" rowspan="1" colspan="1">
                <bold>GSE25099</bold>
              </th>
              <th valign="top" align="left" rowspan="1" colspan="1">
                <bold>GSE26712</bold>
              </th>
              <th valign="top" align="left" rowspan="1" colspan="1">
                <bold>GSE2280</bold>
              </th>
              <th valign="top" align="left" rowspan="1" colspan="1">
                <bold>GSE7670</bold>
              </th>
              <th valign="top" align="left" rowspan="1" colspan="1">
                <bold>GSE4290</bold>
              </th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">sigFeature</td>
              <td valign="top" align="center" rowspan="1" colspan="1">4</td>
              <td valign="top" align="left" rowspan="1" colspan="1">No</td>
              <td valign="top" align="left" rowspan="1" colspan="1">No</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Yes</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Yes</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Yes</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Yes (partially)</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">SVM-RFE</td>
              <td valign="top" align="center" rowspan="1" colspan="1">3</td>
              <td valign="top" align="left" rowspan="1" colspan="1">No</td>
              <td valign="top" align="left" rowspan="1" colspan="1">No</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Yes</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Yes</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Yes</td>
              <td valign="top" align="left" rowspan="1" colspan="1">No</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">SVM-BT-RFE</td>
              <td valign="top" align="center" rowspan="1" colspan="1">2</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Yes (partially)</td>
              <td valign="top" align="left" rowspan="1" colspan="1">No</td>
              <td valign="top" align="left" rowspan="1" colspan="1">No</td>
              <td valign="top" align="left" rowspan="1" colspan="1">No</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Yes</td>
              <td valign="top" align="left" rowspan="1" colspan="1">No</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">SVM-T-RFE</td>
              <td valign="top" align="center" rowspan="1" colspan="1">1</td>
              <td valign="top" align="left" rowspan="1" colspan="1">No</td>
              <td valign="top" align="left" rowspan="1" colspan="1">No</td>
              <td valign="top" align="left" rowspan="1" colspan="1">No</td>
              <td valign="top" align="left" rowspan="1" colspan="1">No</td>
              <td valign="top" align="left" rowspan="1" colspan="1">No</td>
              <td valign="top" align="left" rowspan="1" colspan="1">No</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
      <p>Next, we have tested the same <italic>t</italic>-test with robust list of features produced in each algorithm of selection. The <italic>p</italic>-values are graphically displayed below in <xref ref-type="fig" rid="F7">Figure 7</xref>. The average unadjusted <italic>p</italic>-value generated by the top characteristics (<italic>n</italic> = 1,000) selected by the “sigFeature” algorithm is much more significant than the unadjusted <italic>p</italic>-value generated by the other selection algorithm. Also for the robust feature lists, the similar result is found.</p>
      <fig id="F7" position="float">
        <label>Figure 7</label>
        <caption>
          <p>Histogram plots of unadjusted <italic>p</italic>-values (using top 1,000 robust features). The comparison of unadjusted <italic>p</italic>-values is shown, which are calculated by using the top 1,000 features (from the robust feature list) individually between the classes.</p>
        </caption>
        <graphic xlink:href="fgene-11-00247-g0007"/>
      </fig>
    </sec>
  </sec>
  <sec sec-type="discussion" id="s4">
    <title>Discussion</title>
    <p>In this article, we proposed a novel feature selection algorithm using “SVM-RFE” and <italic>t</italic> statistic (called “sigFeature”) to select significant features. We also tested the “sigFeature” algorithm on six publicly available microarray data sets, containing different biological attributes, and compared it with already existing similar type of algorithms (such as “SVM-RFE,” “SVM-T-RFE,” and “SVM-BT-RFE”). The plots show that the sigFeature algorithm's initial goal of selecting significant feature along with excellent classification accuracy is being met. The top features chosen by the sigFeature algorithm are very considerably distinct from those chosen by other feature selection algorithms used in this research work. Thus, the average <italic>p</italic>-value plot indicates significant results for the features chosen by our algorithm. We compared the <italic>p</italic>-value produced by the top 1,000 features using those algorithms; it shows that more significant <italic>p</italic>-value s are generated by the features that are selected by “sigFeature” algorithm than others.</p>
    <p>We could also predict robust biomarkers with a concrete focus on microarray studies on six cancer diagnosis data sets using sigFeature algorithm. The stability of the markers is appropriate for both reproducibility and biological validation. However, stability alone is not a nice performance measure, as it is easy to improve stability by considering some fixed sets of features. Moreover, the ensuing predictive model is probably poor in the classification of new samples. The CLA technique is an experimental methodology for evaluating the strength of biomarker lists in combination with the predictive results of classification designs based on them. This CLA protocol repeatedly considers some samples for selecting markers as well as estimating classifiers from autonomous samples used to assess the efficiency of classification. The external 10-fold cross-validation error is more convenient to evaluate the predictive performance of data sets with unbalanced class proportions, a common situation for microarray experiments. “sigFeature” shows promising performance compared to other feature selection algorithms.</p>
    <p>Finally, performing GSEA analysis using specified cancer gene sets of MSigDB, we obtained a concrete evidence to show that features selected by “sigFeature” have the potential to identify biological attributes of data sets more accurately. Here, “sigFeature” was able to predict the signature of three out of six data sets with complete accuracy, whereas the fourth one partially. Comparable expertise was observed with SVM-RFE, whereas the rest have put up a comparatively poor show.</p>
    <p>Thus, we can conclude that the proposed algorithm identifies features leading to more accurate classification and generation of differentially significant features.</p>
  </sec>
  <sec sec-type="data-availability" id="s5">
    <title>Data Availability Statement</title>
    <p>Publicly available datasets were analyzed in this study. This data can be found here: GSE3744, GSE25099, GSE26712, GSE2280, GSE7670, and GSE4290.</p>
  </sec>
  <sec id="s6">
    <title>Ethics Statement</title>
    <p>Ethical review and approval was not required for the study on human participants in accordance with the local legislation and institutional requirements. The ethics committee waived the requirement of written informed consent for participation.</p>
  </sec>
  <sec id="s7">
    <title>Author Contributions</title>
    <p>PD developed the method and implemented the sigFeature algorithms, under the supervision of ST and SR. All authors (PD, AR, SD, SR, and ST) added to composing the content, read and affirmed the final version of the manuscript.</p>
    <sec>
      <title>Conflict of Interest</title>
      <p>The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p>
    </sec>
  </sec>
</body>
<back>
  <ack>
    <p>We thank the CSIR-Indian Institute of Chemical Biology for offering the study infrastructure. We would like to thank the Council of Scientific &amp; Industrial Research for giving the fellowship to PD. We thank Mr Shoumik Roychoudhury, Department of Computer and Information Sciences, Temple University, Philadelphia, PA, USA, for his precious remarks.</p>
  </ack>
  <sec sec-type="supplementary-material" id="s8">
    <title>Supplementary Material</title>
    <p>The Supplementary Material for this article can be found online at: <ext-link ext-link-type="uri" xlink:href="https://www.frontiersin.org/articles/10.3389/fgene.2020.00247/full#supplementary-material">https://www.frontiersin.org/articles/10.3389/fgene.2020.00247/full#supplementary-material</ext-link></p>
    <supplementary-material content-type="local-data" id="SM1">
      <label>Supplementary Data Sheet 1</label>
      <caption>
        <p>It contains overview of different feature selection algorithms used in this research work.</p>
      </caption>
      <media xlink:href="Data_Sheet_1.docx">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material content-type="local-data" id="SM2">
      <label>Supplementary Data Sheet 2</label>
      <caption>
        <p>It contains experimental results of different data sets.</p>
      </caption>
      <media xlink:href="Data_Sheet_2.docx">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material content-type="local-data" id="SM3">
      <label>Supplementary Data Sheet 3</label>
      <caption>
        <p>It contains experimental results on RNA-Seq data set.</p>
      </caption>
      <media xlink:href="Data_Sheet_3.docx">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
  <ref-list>
    <title>References</title>
    <ref id="B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Abe</surname><given-names>H.</given-names></name><name><surname>Kamai</surname><given-names>T.</given-names></name><name><surname>Shirataki</surname><given-names>H.</given-names></name><name><surname>Oyama</surname><given-names>T.</given-names></name><name><surname>Arai</surname><given-names>K.</given-names></name><name><surname>Yoshida</surname><given-names>K.</given-names></name></person-group> (<year>2008</year>). <article-title>High expression of Ran GTPase is associated with local invasion and metastasis of human clear cell renal cell carcinoma</article-title>. <source>Int. J. Cancer</source>
<volume>122</volume>, <fpage>2391</fpage>–<lpage>2397</lpage>. <pub-id pub-id-type="doi">10.1002/ijc.23400</pub-id><?supplied-pmid 18241036?><pub-id pub-id-type="pmid">18241036</pub-id></mixed-citation>
    </ref>
    <ref id="B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Abeel</surname><given-names>T.</given-names></name><name><surname>Helleputte</surname><given-names>T.</given-names></name><name><surname>Van de Peer</surname><given-names>Y.</given-names></name><name><surname>Dupont</surname><given-names>P.</given-names></name><name><surname>Saeys</surname><given-names>Y.</given-names></name></person-group> (<year>2010</year>). <article-title>Robust biomarker identification for cancer diagnosis with ensemble feature selection methods</article-title>. <source>Bioinformatics</source>
<volume>26</volume>, <fpage>392</fpage>–<lpage>398</lpage>. <pub-id pub-id-type="doi">10.1093/bioinformatics/btp630</pub-id><?supplied-pmid 19942583?><pub-id pub-id-type="pmid">19942583</pub-id></mixed-citation>
    </ref>
    <ref id="B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Allison</surname><given-names>D. B.</given-names></name><name><surname>Cui</surname><given-names>X.</given-names></name><name><surname>Page</surname><given-names>G. P.</given-names></name><name><surname>Sabripour</surname><given-names>M.</given-names></name></person-group> (<year>2006</year>). <article-title>Microarray data analysis: from disarray to consolidation and consensus</article-title>. <source>Nat. Rev. Genet.</source>
<volume>7</volume>, <fpage>55</fpage>–<lpage>65</lpage>. <pub-id pub-id-type="doi">10.1038/nrg1749</pub-id><?supplied-pmid 16369572?><pub-id pub-id-type="pmid">16369572</pub-id></mixed-citation>
    </ref>
    <ref id="B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ambroise</surname><given-names>C.</given-names></name><name><surname>McLachlan</surname><given-names>G. J.</given-names></name></person-group> (<year>2002</year>). <article-title>Selection bias in gene extraction on the basis of microarray gene-expression data</article-title>. <source>Proc. Natl. Acad. Sci. U.S.A</source>. <volume>99</volume>, <fpage>6562</fpage>–<lpage>6566</lpage>. <pub-id pub-id-type="doi">10.1073/pnas.102102699</pub-id><?supplied-pmid 11983868?><pub-id pub-id-type="pmid">11983868</pub-id></mixed-citation>
    </ref>
    <ref id="B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bailey</surname><given-names>C. L.</given-names></name><name><surname>Kelly</surname><given-names>P.</given-names></name><name><surname>Casey</surname><given-names>P. J.</given-names></name></person-group> (<year>2009</year>). <article-title>Activation of Rap1 promotes prostate cancer metastasis</article-title>. <source>Cancer Res.</source>
<volume>69</volume>, <fpage>4962</fpage>–<lpage>4968</lpage>. <pub-id pub-id-type="doi">10.1158/0008-5472.CAN-08-4269</pub-id><?supplied-pmid 19470770?><pub-id pub-id-type="pmid">19470770</pub-id></mixed-citation>
    </ref>
    <ref id="B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bolstad</surname><given-names>B. M.</given-names></name><name><surname>Irizarry</surname><given-names>R.</given-names></name><name><surname>Astrand</surname><given-names>M.</given-names></name><name><surname>Speed</surname><given-names>T. P.</given-names></name></person-group> (<year>2003</year>). <article-title>A comparison of normalization methods for high density oligonucleotide array data based on variance and bias</article-title>. <source>Bioinformatics</source>
<volume>19</volume>, <fpage>185</fpage>–<lpage>193</lpage>. <pub-id pub-id-type="doi">10.1093/bioinformatics/19.2.185</pub-id><?supplied-pmid 12538238?><pub-id pub-id-type="pmid">12538238</pub-id></mixed-citation>
    </ref>
    <ref id="B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bonome</surname><given-names>T.</given-names></name><name><surname>Levine</surname><given-names>D. A.</given-names></name><name><surname>Shih</surname><given-names>J.</given-names></name><name><surname>Randonovich</surname><given-names>M.</given-names></name><name><surname>Pise-Masison</surname><given-names>C. A.</given-names></name><name><surname>Bogomolniy</surname><given-names>F.</given-names></name><etal/></person-group>. (<year>2008</year>). <article-title>A gene signature predicting for survival in suboptimally debulked patients with ovarian cancer</article-title>. <source>Cancer Res.</source><volume>68</volume>, <fpage>5478</fpage>–<lpage>5486</lpage>. <pub-id pub-id-type="doi">10.1158/0008-5472.CAN-07-6595</pub-id><?supplied-pmid 18593951?><pub-id pub-id-type="pmid">18593951</pub-id></mixed-citation>
    </ref>
    <ref id="B8">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Butte</surname><given-names>A.</given-names></name></person-group> (<year>2002</year>). <article-title>The use and analysis of microarray data</article-title>. <source>Nat. Rev. Drug Discov.</source>
<volume>1</volume>, <fpage>951</fpage>–<lpage>960</lpage>. <pub-id pub-id-type="doi">10.1038/nrd961</pub-id><?supplied-pmid 12461517?><pub-id pub-id-type="pmid">12461517</pub-id></mixed-citation>
    </ref>
    <ref id="B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>C.-H.</given-names></name><name><surname>Chuang</surname><given-names>H.-C.</given-names></name><name><surname>Huang</surname><given-names>C.-C.</given-names></name><name><surname>Fang</surname><given-names>F.-M.</given-names></name><name><surname>Huang</surname><given-names>H.-Y.</given-names></name><name><surname>Tsai</surname><given-names>H.-T.</given-names></name><etal/></person-group>. (<year>2013</year>). <article-title>Overexpression of Rap-1A indicates a poor prognosis for oral cavity squamous cell carcinoma and promotes tumor cell invasion via Aurora-A modulation</article-title>. <source>Am. J. Pathol.</source><volume>182</volume>, <fpage>516</fpage>–<lpage>528</lpage>. <pub-id pub-id-type="doi">10.1016/j.ajpath.2012.10.023</pub-id><?supplied-pmid 23219753?><pub-id pub-id-type="pmid">23219753</pub-id></mixed-citation>
    </ref>
    <ref id="B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Das</surname><given-names>R.</given-names></name><name><surname>Dimitrova</surname><given-names>N.</given-names></name><name><surname>Xuan</surname><given-names>Z.</given-names></name><name><surname>Rollins</surname><given-names>R. A.</given-names></name><name><surname>Haghighi</surname><given-names>F.</given-names></name><name><surname>Edwards</surname><given-names>J. R.</given-names></name><etal/></person-group>. (<year>2006</year>). <article-title>Computational prediction of methylation status in human genomic sequences</article-title>. <source>Proc. Natl. Acad. Sci. U.S.A</source>. <volume>103</volume>, <fpage>10713</fpage>–<lpage>10716</lpage>. <pub-id pub-id-type="doi">10.1073/pnas.0602949103</pub-id><?supplied-pmid 16818882?><pub-id pub-id-type="pmid">16818882</pub-id></mixed-citation>
    </ref>
    <ref id="B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Deng</surname><given-names>L.</given-names></name><name><surname>Shang</surname><given-names>Y.</given-names></name><name><surname>Guo</surname><given-names>S.</given-names></name><name><surname>Liu</surname><given-names>C.</given-names></name><name><surname>Zhou</surname><given-names>L.</given-names></name><name><surname>Sun</surname><given-names>Y.</given-names></name><etal/></person-group>. (<year>2014</year>). <article-title>Ran GTPase protein promotes metastasis and invasion in pancreatic cancer by deregulating the expression of AR and CXCR4</article-title>. <source>Cancer Biol. Ther.</source><volume>15</volume>, <fpage>1087</fpage>–<lpage>1093</lpage>. <pub-id pub-id-type="doi">10.4161/cbt.29217</pub-id><?supplied-pmid 24840182?><pub-id pub-id-type="pmid">24840182</pub-id></mixed-citation>
    </ref>
    <ref id="B12">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Efron</surname><given-names>B.</given-names></name></person-group> (<year>1992</year>). <article-title>Bootstrap methods: another look at the jackknife</article-title>, in <source>Breakthroughs in Statistics</source> (<publisher-loc>New York, NY</publisher-loc>: <publisher-name>Springer</publisher-name>), <fpage>569</fpage>–<lpage>593</lpage>. <pub-id pub-id-type="doi">10.1007/978-1-4612-4380-9_41</pub-id></mixed-citation>
    </ref>
    <ref id="B13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Frank</surname><given-names>O.</given-names></name><name><surname>Brors</surname><given-names>B.</given-names></name><name><surname>Fabarius</surname><given-names>A.</given-names></name><name><surname>Li</surname><given-names>L.</given-names></name><name><surname>Haak</surname><given-names>M.</given-names></name><name><surname>Merk</surname><given-names>S.</given-names></name><etal/></person-group>. (<year>2006</year>). <article-title>Gene expression signature of primary imatinib-resistant chronic myeloid leukemia patients</article-title>. <source>Leukemia</source><volume>20</volume>, <fpage>1400</fpage>–<lpage>1407</lpage>. <pub-id pub-id-type="doi">10.1038/sj.leu.2404270</pub-id><?supplied-pmid 16728981?><pub-id pub-id-type="pmid">16728981</pub-id></mixed-citation>
    </ref>
    <ref id="B14">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Galland</surname><given-names>F.</given-names></name><name><surname>Lacroix</surname><given-names>L.</given-names></name><name><surname>Saulnier</surname><given-names>P.</given-names></name><name><surname>Dessen</surname><given-names>P.</given-names></name><name><surname>Meduri</surname><given-names>G.</given-names></name><name><surname>Bernier</surname><given-names>M.</given-names></name><etal/></person-group>. (<year>2010</year>). <article-title>Differential gene expression profiles of invasive and non-invasive non-functioning pituitary adenomas based on microarray analysis</article-title>. <source>Endocr. Relat. Cancer</source><volume>17</volume>, <fpage>361</fpage>–<lpage>371</lpage>. <pub-id pub-id-type="doi">10.1677/ERC-10-0018</pub-id><?supplied-pmid 20228124?><pub-id pub-id-type="pmid">20228124</pub-id></mixed-citation>
    </ref>
    <ref id="B15">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gallo</surname><given-names>L. H.</given-names></name><name><surname>Ko</surname><given-names>J.</given-names></name><name><surname>Donoghue</surname><given-names>D. J.</given-names></name></person-group> (<year>2017</year>). <article-title>The importance of regulatory ubiquitination in cancer and metastasis</article-title>. <source>Cell Cycle</source>
<volume>16</volume>, <fpage>634</fpage>–<lpage>648</lpage>. <pub-id pub-id-type="doi">10.1080/15384101.2017.1288326</pub-id><?supplied-pmid 28166483?><pub-id pub-id-type="pmid">28166483</pub-id></mixed-citation>
    </ref>
    <ref id="B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Golub</surname><given-names>T. R.</given-names></name><name><surname>Slonim</surname><given-names>D. K.</given-names></name><name><surname>Tamayo</surname><given-names>P.</given-names></name><name><surname>Huard</surname><given-names>C.</given-names></name><name><surname>Gaasenbeek</surname><given-names>M.</given-names></name><name><surname>Mesirov</surname><given-names>J. P.</given-names></name><etal/></person-group>. (<year>1999</year>). <article-title>Molecular classification of cancer: class discovery and class prediction by gene expression monitoring</article-title>. <source>Science</source><volume>286</volume>, <fpage>531</fpage>–<lpage>537</lpage>. <pub-id pub-id-type="doi">10.1126/science.286.5439.531</pub-id><?supplied-pmid 10521349?><pub-id pub-id-type="pmid">10521349</pub-id></mixed-citation>
    </ref>
    <ref id="B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Guyon</surname><given-names>I.</given-names></name><name><surname>Weston</surname><given-names>J.</given-names></name><name><surname>Barnhill</surname><given-names>S.</given-names></name><name><surname>Vapnik</surname><given-names>V.</given-names></name></person-group> (<year>2002</year>). <article-title>Gene selection for cancer classification using support vector machines</article-title>. <source>Mach. Learn.</source>
<volume>46</volume>, <fpage>389</fpage>–<lpage>422</lpage>. <pub-id pub-id-type="doi">10.1023/A:1012487302797</pub-id></mixed-citation>
    </ref>
    <ref id="B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hilario</surname><given-names>M.</given-names></name><name><surname>Kalousis</surname><given-names>A.</given-names></name><name><surname>Pellegrini</surname><given-names>C.</given-names></name><name><surname>Müller</surname><given-names>M.</given-names></name></person-group> (<year>2006</year>). <article-title>Processing and classification of protein mass spectra</article-title>. <source>Mass Spectrom. Rev.</source>
<volume>25</volume>, <fpage>409</fpage>–<lpage>449</lpage>. <pub-id pub-id-type="doi">10.1002/mas.20072</pub-id><?supplied-pmid 16463283?><pub-id pub-id-type="pmid">16463283</pub-id></mixed-citation>
    </ref>
    <ref id="B19">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>James</surname><given-names>G.</given-names></name><name><surname>Witten</surname><given-names>D.</given-names></name><name><surname>Hastie</surname><given-names>T.</given-names></name><name><surname>Tibshirani</surname><given-names>R.</given-names></name></person-group> (<year>2013</year>). <source>An Introduction to Statistical Learning</source>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Springer</publisher-name>
<pub-id pub-id-type="doi">10.1007/978-1-4614-7138-7</pub-id></mixed-citation>
    </ref>
    <ref id="B20">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Jović</surname><given-names>A.</given-names></name><name><surname>Brkić</surname><given-names>K.</given-names></name><name><surname>Bogunović</surname><given-names>N.</given-names></name></person-group> (<year>2015</year>). <article-title>A review of feature selection methods with applications</article-title>, in <source>2015 38th International Convention on Information and Communication Technology, Electronics and Microelectronics (MIPRO)</source> (<publisher-name>IEEE</publisher-name>), <fpage>1200</fpage>–<lpage>1205</lpage>. <pub-id pub-id-type="doi">10.1109/MIPRO.2015.7160458</pub-id></mixed-citation>
    </ref>
    <ref id="B21">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kuncheva</surname><given-names>L. I.</given-names></name></person-group> (<year>2007</year>). <article-title>A stability index for feature selection</article-title>, in <source>Artificial Intelligence and Applications</source>, <fpage>421</fpage>–<lpage>427</lpage>.</mixed-citation>
    </ref>
    <ref id="B22">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>K. E.</given-names></name><name><surname>Sha</surname><given-names>N.</given-names></name><name><surname>Dougherty</surname><given-names>E. R.</given-names></name><name><surname>Vannucci</surname><given-names>M.</given-names></name><name><surname>Mallick</surname><given-names>B. K.</given-names></name></person-group> (<year>2003</year>). <article-title>Gene selection: a bayesian variable selection approach</article-title>. <source>Bioinformatics</source>
<volume>19</volume>, <fpage>90</fpage>–<lpage>97</lpage>. <pub-id pub-id-type="doi">10.1093/bioinformatics/19.1.90</pub-id><?supplied-pmid 12499298?><pub-id pub-id-type="pmid">12499298</pub-id></mixed-citation>
    </ref>
    <ref id="B23">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>X.</given-names></name><name><surname>Peng</surname><given-names>S.</given-names></name><name><surname>Chen</surname><given-names>J.</given-names></name><name><surname>Lü</surname><given-names>B.</given-names></name><name><surname>Zhang</surname><given-names>H.</given-names></name><name><surname>Lai</surname><given-names>M.</given-names></name></person-group> (<year>2012</year>). <article-title>SVM–T-RFE: a novel gene selection algorithm for identifying metastasis-related genes in colorectal cancer using gene expression profiles</article-title>. <source>Biochem. Biophys. Res. Commun.</source>
<volume>419</volume>, <fpage>148</fpage>–<lpage>153</lpage>. <pub-id pub-id-type="doi">10.1016/j.bbrc.2012.01.087</pub-id><?supplied-pmid 22306013?><pub-id pub-id-type="pmid">22306013</pub-id></mixed-citation>
    </ref>
    <ref id="B24">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lu</surname><given-names>L.</given-names></name><name><surname>Wang</surname><given-names>J.</given-names></name><name><surname>Wu</surname><given-names>Y.</given-names></name><name><surname>Wan</surname><given-names>P.</given-names></name><name><surname>Yang</surname><given-names>G.</given-names></name></person-group> (<year>2016</year>). <article-title>Rap1A promotes ovarian cancer metastasis via activation of ERK/p38 and notch signaling</article-title>. <source>Cancer Med.</source>
<volume>5</volume>, <fpage>3544</fpage>–<lpage>3554</lpage>. <pub-id pub-id-type="doi">10.1002/cam4.946</pub-id><?supplied-pmid 27925454?><pub-id pub-id-type="pmid">27925454</pub-id></mixed-citation>
    </ref>
    <ref id="B25">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Meyer</surname><given-names>D.</given-names></name><name><surname>Dimitriadou</surname><given-names>E.</given-names></name><name><surname>Hornik</surname><given-names>K.</given-names></name><name><surname>Weingessel</surname><given-names>A.</given-names></name><name><surname>Leisch</surname><given-names>F.</given-names></name></person-group> (<year>2018</year>). <source>e1071: Misc Functions of the Department of Statistics, Probability Theory Group (Formerly: E1071), TU Wien</source>. R Packag. version 1.</mixed-citation>
    </ref>
    <ref id="B26">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mishra</surname><given-names>S.</given-names></name><name><surname>Mishra</surname><given-names>D.</given-names></name></person-group> (<year>2015</year>). <article-title>SVM-BT-RFE: an improved gene selection framework using Bayesian T-test embedded in support vector machine (recursive feature elimination) algorithm</article-title>. <source>Karbala Int. J. Mod. Sci.</source>
<volume>1</volume>, <fpage>86</fpage>–<lpage>96</lpage>. <pub-id pub-id-type="doi">10.1016/j.kijoms.2015.10.002</pub-id></mixed-citation>
    </ref>
    <ref id="B27">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O'Donnell</surname><given-names>R. K.</given-names></name><name><surname>Kupferman</surname><given-names>M.</given-names></name><name><surname>Wei</surname><given-names>S. J.</given-names></name><name><surname>Singhal</surname><given-names>S.</given-names></name><name><surname>Weber</surname><given-names>R.</given-names></name><name><surname>O'Malley</surname><given-names>B.</given-names></name><etal/></person-group>. (<year>2005</year>). <article-title>Gene expression signature predicts lymphatic metastasis in squamous cell carcinoma of the oral cavity</article-title>. <source>Oncogene</source><volume>24</volume>, <fpage>1244</fpage>–<lpage>1251</lpage>. <pub-id pub-id-type="doi">10.1038/sj.onc.1208285</pub-id><?supplied-pmid 15558013?><pub-id pub-id-type="pmid">15558013</pub-id></mixed-citation>
    </ref>
    <ref id="B28">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Peng</surname><given-names>C.-H.</given-names></name><name><surname>Liao</surname><given-names>C.-T.</given-names></name><name><surname>Peng</surname><given-names>S.-C.</given-names></name><name><surname>Chen</surname><given-names>Y.-J.</given-names></name><name><surname>Cheng</surname><given-names>A.-J.</given-names></name><name><surname>Juang</surname><given-names>J.-L.</given-names></name><etal/></person-group>. (<year>2011</year>). <article-title>A novel molecular signature identified by systems genetics approach predicts prognosis in oral squamous cell carcinoma</article-title>. <source>PLoS ONE</source><volume>6</volume>:<fpage>e23452</fpage>. <pub-id pub-id-type="doi">10.1371/journal.pone.0023452</pub-id><?supplied-pmid 21853135?><pub-id pub-id-type="pmid">21853135</pub-id></mixed-citation>
    </ref>
    <ref id="B29">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ramaswamy</surname><given-names>S.</given-names></name><name><surname>Tamayo</surname><given-names>P.</given-names></name><name><surname>Rifkin</surname><given-names>R.</given-names></name><name><surname>Mukherjee</surname><given-names>S.</given-names></name><name><surname>Yeang</surname><given-names>C.-H.</given-names></name><name><surname>Angelo</surname><given-names>M.</given-names></name><etal/></person-group>. (<year>2001</year>). <article-title>Multiclass cancer diagnosis using tumor gene expression signatures</article-title>. <source>Proc. Natl. Acad. Sci. U.S.A.</source><volume>98</volume>, <fpage>15149</fpage>–<lpage>15154</lpage>. <pub-id pub-id-type="doi">10.1073/pnas.211566398</pub-id><?supplied-pmid 11742071?><pub-id pub-id-type="pmid">11742071</pub-id></mixed-citation>
    </ref>
    <ref id="B30">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Richardson</surname><given-names>A. L.</given-names></name><name><surname>Wang</surname><given-names>Z. C.</given-names></name><name><surname>De Nicolo</surname><given-names>A.</given-names></name><name><surname>Lu</surname><given-names>X.</given-names></name><name><surname>Brown</surname><given-names>M.</given-names></name><name><surname>Miron</surname><given-names>A.</given-names></name><etal/></person-group>. (<year>2006</year>). <article-title>X chromosomal abnormalities in basal-like human breast cancer</article-title>. <source>Cancer Cell</source><volume>9</volume>, <fpage>121</fpage>–<lpage>132</lpage>. <pub-id pub-id-type="doi">10.1016/j.ccr.2006.01.013</pub-id><?supplied-pmid 16473279?><pub-id pub-id-type="pmid">16473279</pub-id></mixed-citation>
    </ref>
    <ref id="B31">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ritchie</surname><given-names>M. E.</given-names></name><name><surname>Phipson</surname><given-names>B.</given-names></name><name><surname>Wu</surname><given-names>D.</given-names></name><name><surname>Hu</surname><given-names>Y.</given-names></name><name><surname>Law</surname><given-names>C. W.</given-names></name><name><surname>Shi</surname><given-names>W.</given-names></name><etal/></person-group>. (<year>2015</year>). <article-title>limma powers differential expression analyses for RNA-sequencing and microarray studies</article-title>. <source>Nucleic Acids Res.</source><volume>43</volume>, <fpage>e47</fpage>–<lpage>e47</lpage>. <pub-id pub-id-type="doi">10.1093/nar/gkv007</pub-id><?supplied-pmid 25605792?><pub-id pub-id-type="pmid">25605792</pub-id></mixed-citation>
    </ref>
    <ref id="B32">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Roepman</surname><given-names>P.</given-names></name><name><surname>de Jager</surname><given-names>A.</given-names></name><name><surname>Groot Koerkamp</surname><given-names>M. J. A.</given-names></name><name><surname>Kummer</surname><given-names>J. A.</given-names></name><name><surname>Slootweg</surname><given-names>P. J.</given-names></name><name><surname>Holstege</surname><given-names>F. C. P.</given-names></name></person-group> (<year>2006</year>). <article-title>Maintenance of head and neck tumor gene expression profiles upon lymph node metastasis</article-title>. <source>Cancer Res.</source>
<volume>66</volume>, <fpage>11110</fpage>–<lpage>11114</lpage>. <pub-id pub-id-type="doi">10.1158/0008-5472.CAN-06-3161</pub-id><?supplied-pmid 17145852?><pub-id pub-id-type="pmid">17145852</pub-id></mixed-citation>
    </ref>
    <ref id="B33">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Roepman</surname><given-names>P.</given-names></name><name><surname>Wessels</surname><given-names>L. F. A.</given-names></name><name><surname>Kettelarij</surname><given-names>N.</given-names></name><name><surname>Kemmeren</surname><given-names>P.</given-names></name><name><surname>Miles</surname><given-names>A. J.</given-names></name><name><surname>Lijnzaad</surname><given-names>P.</given-names></name><etal/></person-group>. (<year>2005</year>). <article-title>An expression profile for diagnosis of lymph node metastases from primary head and neck squamous cell carcinomas</article-title>. <source>Nat. Genet.</source><volume>37</volume>, <fpage>182</fpage>–<lpage>186</lpage>. <pub-id pub-id-type="doi">10.1038/ng1502</pub-id><?supplied-pmid 15640797?><pub-id pub-id-type="pmid">15640797</pub-id></mixed-citation>
    </ref>
    <ref id="B34">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Segal</surname><given-names>E.</given-names></name><name><surname>Friedman</surname><given-names>N.</given-names></name><name><surname>Koller</surname><given-names>D.</given-names></name><name><surname>Regev</surname><given-names>A.</given-names></name></person-group> (<year>2004</year>). <article-title>A module map showing conditional activity of expression modules in cancer</article-title>. <source>Nat. Genet.</source>
<volume>36</volume>, <fpage>1090</fpage>–<lpage>1098</lpage>. <pub-id pub-id-type="doi">10.1038/ng1434</pub-id><?supplied-pmid 15448693?><pub-id pub-id-type="pmid">15448693</pub-id></mixed-citation>
    </ref>
    <ref id="B35">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Su</surname><given-names>L.-J.</given-names></name><name><surname>Chang</surname><given-names>C.-W.</given-names></name><name><surname>Wu</surname><given-names>Y.-C.</given-names></name><name><surname>Chen</surname><given-names>K.-C.</given-names></name><name><surname>Lin</surname><given-names>C.-J.</given-names></name><name><surname>Liang</surname><given-names>S.-C.</given-names></name><etal/></person-group>. (<year>2007</year>). <article-title>Selection of DDX5 as a novel internal control for Q-RT-PCR from microarray data using a block bootstrap re-sampling scheme</article-title>. <source>BMC Genomics</source><volume>8</volume>, <fpage>140</fpage>. <pub-id pub-id-type="doi">10.1186/1471-2164-8-140</pub-id><?supplied-pmid 17540040?><pub-id pub-id-type="pmid">17540040</pub-id></mixed-citation>
    </ref>
    <ref id="B36">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Subramanian</surname><given-names>A.</given-names></name><name><surname>Tamayo</surname><given-names>P.</given-names></name><name><surname>Mootha</surname><given-names>V. K.</given-names></name><name><surname>Mukherjee</surname><given-names>S.</given-names></name><name><surname>Ebert</surname><given-names>B. L.</given-names></name><name><surname>Gillette</surname><given-names>M. A.</given-names></name><etal/></person-group>. (<year>2005</year>). <article-title>Gene set enrichment analysis: a knowledge-based approach for interpreting genome-wide expression profiles</article-title>. <source>Proc. Natl. Acad. Sci. U.S.A.</source><volume>102</volume>, <fpage>15545</fpage>–<lpage>15550</lpage>. <pub-id pub-id-type="doi">10.1073/pnas.0506580102</pub-id><?supplied-pmid 16199517?><pub-id pub-id-type="pmid">16199517</pub-id></mixed-citation>
    </ref>
    <ref id="B37">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sun</surname><given-names>L.</given-names></name><name><surname>Hui</surname><given-names>A.-M.</given-names></name><name><surname>Su</surname><given-names>Q.</given-names></name><name><surname>Vortmeyer</surname><given-names>A.</given-names></name><name><surname>Kotliarov</surname><given-names>Y.</given-names></name><name><surname>Pastorino</surname><given-names>S.</given-names></name><etal/></person-group>. (<year>2006</year>). <article-title>Neuronal and glioma-derived stem cell factor induces angiogenesis within the brain</article-title>. <source>Cancer Cell</source><volume>9</volume>, <fpage>287</fpage>–<lpage>300</lpage>. <pub-id pub-id-type="doi">10.1016/j.ccr.2006.03.003</pub-id><?supplied-pmid 16616334?><pub-id pub-id-type="pmid">16616334</pub-id></mixed-citation>
    </ref>
    <ref id="B38">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vallabhaneni</surname><given-names>K. C.</given-names></name><name><surname>Penfornis</surname><given-names>P.</given-names></name><name><surname>Xing</surname><given-names>F.</given-names></name><name><surname>Hassler</surname><given-names>Y.</given-names></name><name><surname>Adams</surname><given-names>K. V.</given-names></name><name><surname>Mo</surname><given-names>Y.-Y.</given-names></name><etal/></person-group>. (<year>2017</year>). <article-title>Stromal cell extracellular vesicular cargo mediated regulation of breast cancer cell metastasis via ubiquitin conjugating enzyme E2 N pathway</article-title>. <source>Oncotarget</source><volume>8</volume>:<fpage>109861</fpage>. <pub-id pub-id-type="doi">10.18632/oncotarget.22371</pub-id><?supplied-pmid 29299114?><pub-id pub-id-type="pmid">29299114</pub-id></mixed-citation>
    </ref>
    <ref id="B39">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yi-Lei</surname><given-names>Z.</given-names></name><name><surname>Ruo-Chen</surname><given-names>W.</given-names></name><name><surname>Ken</surname><given-names>C.</given-names></name><name><surname>Brian</surname><given-names>Z. R.</given-names></name><name><surname>Li</surname><given-names>S.</given-names></name><etal/></person-group>. (<year>2017</year>). <article-title>Roles of Rap1 signaling in tumor cell migration and invasion</article-title>. <source>Cancer Biol. Med.</source><volume>14</volume>, <fpage>90</fpage>–<lpage>99</lpage>. <pub-id pub-id-type="doi">10.20892/j.issn.2095-3941.2016.0086</pub-id><?supplied-pmid 28443208?><pub-id pub-id-type="pmid">28443208</pub-id></mixed-citation>
    </ref>
    <ref id="B40">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>H. H.</given-names></name><name><surname>Ahn</surname><given-names>J.</given-names></name><name><surname>Lin</surname><given-names>X.</given-names></name><name><surname>Park</surname><given-names>C.</given-names></name></person-group> (<year>2006a</year>). <article-title>Gene selection using support vector machines with non-convex penalty</article-title>. <source>Bioinformatics</source>
<volume>22</volume>, <fpage>88</fpage>–<lpage>95</lpage>. <pub-id pub-id-type="doi">10.1093/bioinformatics/bti736</pub-id><?supplied-pmid 16249260?><pub-id pub-id-type="pmid">16249260</pub-id></mixed-citation>
    </ref>
    <ref id="B41">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>X.</given-names></name><name><surname>Lu</surname><given-names>X.</given-names></name><name><surname>Shi</surname><given-names>Q.</given-names></name><name><surname>Xu</surname><given-names>X.</given-names></name><name><surname>Leung</surname><given-names>H. E.</given-names></name><name><surname>Harris</surname><given-names>L. N.</given-names></name><etal/></person-group>. (<year>2006b</year>). <article-title>Recursive SVM feature selection and sample classification for mass-spectrometry and microarray data</article-title>. <source>BMC Bioinformatics</source><volume>7</volume>, <fpage>197</fpage>. <pub-id pub-id-type="doi">10.1186/1471-2105-7-197</pub-id><?supplied-pmid 16606446?><pub-id pub-id-type="pmid">16606446</pub-id></mixed-citation>
    </ref>
    <ref id="B42">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zheng</surname><given-names>C.</given-names></name><name><surname>Li</surname><given-names>L.</given-names></name><name><surname>Haak</surname><given-names>M.</given-names></name><name><surname>Brors</surname><given-names>B.</given-names></name><name><surname>Frank</surname><given-names>O.</given-names></name><name><surname>Giehl</surname><given-names>M.</given-names></name><etal/></person-group>. (<year>2006</year>). <article-title>Gene expression profiling of CD34+ cells identifies a molecular signature of chronic myeloid leukemia blast crisis</article-title>. <source>Leukemia</source><volume>20</volume>, <fpage>1028</fpage>–<lpage>1034</lpage>. <pub-id pub-id-type="doi">10.1038/sj.leu.2404227</pub-id><?supplied-pmid 16617318?><pub-id pub-id-type="pmid">16617318</pub-id></mixed-citation>
    </ref>
    <ref id="B43">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Zhou</surname><given-names>X.</given-names></name><name><surname>Mao</surname><given-names>K.</given-names></name></person-group> (<year>2005</year>). <article-title>Gene Selection of DNA Microarray Data Based on Regularization Networks</article-title>, in <source>International Conference on Intelligent Data Engineering and Automated Learning</source> (<publisher-loc>Berlin; Heidelberg</publisher-loc>: <publisher-name>Springer</publisher-name>), <fpage>414</fpage>–<lpage>421</lpage>. <pub-id pub-id-type="doi">10.1007/11508069_54</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
