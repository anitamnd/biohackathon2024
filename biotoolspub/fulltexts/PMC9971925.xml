<?DTDIdentifier.IdentifierValue -//NLM//DTD Journal Publishing DTD v2.3 20070202//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName journalpublishing.dtd?>
<?SourceDTD.Version 2.3?>
<?ConverterInfo.XSLTName nlm2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Front Bioinform</journal-id>
    <journal-id journal-id-type="iso-abbrev">Front Bioinform</journal-id>
    <journal-id journal-id-type="publisher-id">Front. Bioinform.</journal-id>
    <journal-title-group>
      <journal-title>Frontiers in Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="epub">2673-7647</issn>
    <publisher>
      <publisher-name>Frontiers Media S.A.</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">9971925</article-id>
    <article-id pub-id-type="publisher-id">1107467</article-id>
    <article-id pub-id-type="doi">10.3389/fbinf.2023.1107467</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Bioinformatics</subject>
        <subj-group>
          <subject>Original Research</subject>
        </subj-group>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>CASBERT: BERT-based retrieval for compositely annotated biosimulation model entities</article-title>
      <alt-title alt-title-type="left-running-head">Munarko et al.</alt-title>
      <alt-title alt-title-type="right-running-head">
        <ext-link xlink:href="https://doi.org/10.3389/fbinf.2023.1107467" ext-link-type="uri">10.3389/fbinf.2023.1107467</ext-link>
      </alt-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Munarko</surname>
          <given-names>Yuda</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="c001" ref-type="corresp">*</xref>
        <uri xlink:href="https://loop.frontiersin.org/people/1322868/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Rampadarath</surname>
          <given-names>Anand</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="aff2" ref-type="aff">
          <sup>2</sup>
        </xref>
        <uri xlink:href="https://loop.frontiersin.org/people/2144391/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Nickerson</surname>
          <given-names>David P.</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
        <uri xlink:href="https://loop.frontiersin.org/people/34505/overview"/>
      </contrib>
    </contrib-group>
    <aff id="aff1"><sup>1</sup><institution>Auckland Bioengineering Institute</institution>, <institution>University of Auckland</institution>, <addr-line>Auckland</addr-line>, <country>New Zealand</country></aff>
    <aff id="aff2"><sup>2</sup><institution>The New Zealand Institute for Plant &amp; Food Research Ltd.</institution>, <addr-line>Auckland</addr-line>, <country>New Zealand</country></aff>
    <author-notes>
      <fn fn-type="edited-by">
        <p><bold>Edited by:</bold><ext-link xlink:href="https://loop.frontiersin.org/people/1204262/overview" ext-link-type="uri">Livia Perfetto</ext-link>, Sapienza University of Rome, Italy</p>
      </fn>
      <fn fn-type="edited-by">
        <p><bold>Reviewed by:</bold><ext-link xlink:href="https://loop.frontiersin.org/people/1057540/overview" ext-link-type="uri">Anna Bernasconi</ext-link>, Politecnico di Milano, Italy</p>
        <p><ext-link xlink:href="https://loop.frontiersin.org/people/1724674/overview" ext-link-type="uri">Ivo Siekmann</ext-link>, Liverpool John Moores University, United Kingdom</p>
      </fn>
      <corresp id="c001">*Correspondence: Yuda Munarko, <email>ymun794@aucklanduni.ac.nz</email>
</corresp>
      <fn fn-type="other">
        <p>This article was submitted to Network Bioinformatics, a section of the journal Frontiers in Bioinformatics</p>
      </fn>
    </author-notes>
    <pub-date pub-type="epub">
      <day>14</day>
      <month>2</month>
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2023</year>
    </pub-date>
    <volume>3</volume>
    <elocation-id>1107467</elocation-id>
    <history>
      <date date-type="received">
        <day>24</day>
        <month>11</month>
        <year>2022</year>
      </date>
      <date date-type="accepted">
        <day>31</day>
        <month>1</month>
        <year>2023</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>Copyright © 2023 Munarko, Rampadarath and Nickerson.</copyright-statement>
      <copyright-year>2023</copyright-year>
      <copyright-holder>Munarko, Rampadarath and Nickerson</copyright-holder>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.</license-p>
      </license>
    </permissions>
    <abstract>
      <p>Maximising FAIRness of biosimulation models requires a comprehensive description of model entities such as reactions, variables, and components. The COmputational Modeling in BIology NEtwork (COMBINE) community encourages the use of Resource Description Framework with composite annotations that semantically involve ontologies to ensure completeness and accuracy. These annotations facilitate scientists to find models or detailed information to inform further reuse, such as model composition, reproduction, and curation. SPARQL has been recommended as a key standard to access semantic annotation with RDF, which helps get entities precisely. However, SPARQL is unsuitable for most repository users who explore biosimulation models freely without adequate knowledge of ontologies, RDF structure, and SPARQL syntax. We propose here a text-based information retrieval approach, CASBERT, that is easy to use and can present candidates of relevant entities from models across a repository’s contents. CASBERT adapts Bidirectional Encoder Representations from Transformers (BERT), where each composite annotation about an entity is converted into an entity embedding for subsequent storage in a list of entity embeddings. For entity lookup, a query is transformed to a query embedding and compared to the entity embeddings, and then the entities are displayed in order based on their similarity. The list structure makes it possible to implement CASBERT as an efficient search engine product, with inexpensive addition, modification, and insertion of entity embedding. To demonstrate and test CASBERT, we created a dataset for testing from the Physiome Model Repository and a static export of the BioModels database consisting of query-entities pairs. Measured using Mean Average Precision and Mean Reciprocal Rank, we found that our approach can perform better than the traditional bag-of-words method.</p>
    </abstract>
    <kwd-group>
      <kwd>BERT</kwd>
      <kwd>sentence-BERT</kwd>
      <kwd>information retrieval</kwd>
      <kwd>composite annotation embedding</kwd>
      <kwd>RDF</kwd>
      <kwd>ontology</kwd>
      <kwd>biomodels</kwd>
      <kwd>physiome model repository (PMR)</kwd>
    </kwd-group>
    <funding-group>
      <funding-statement>The authors acknowledge financial support by the Aotearoa Foundation, Auckland Bioengineering Institute, and the National Institutes of Health (grant P41 GM109824).</funding-statement>
    </funding-group>
  </article-meta>
</front>
<body>
  <sec id="s1">
    <title>1 Introduction</title>
    <p>In developing a biosimulation model, it is essential to provide a comprehensive description of the entities of the model related to processes, reactions, variables, mathematical equations and parameters. Formally, the COmputational Modeling in BIology NEtwork (COMBINE) community recommended the description in the form of semantic annotations using the Resource Description Framework (RDF) technology (<xref rid="B19" ref-type="bibr">Neal et al., 2019</xref>). With semantic annotations, complete and precise description is constructed in a composite manner involving various knowledge source terms and their relationships in a structured form (<xref rid="B15" ref-type="bibr">Gennari et al., 2011</xref>). Further, composite annotations are used as a community standard to encourage platform interoperability and sharing and collaboration between modellers (<xref rid="B14" ref-type="bibr">Gennari et al., 2021</xref>; <xref rid="B33" ref-type="bibr">Welsh et al., 2021</xref>). This work supports this recommendation and goes beyond the composite annotation structure to provide an entity retrieval method with a simple data structure that is easy to deploy. Moreover, the method should be general enough so it can be implemented for different domains with composite annotations.</p>
    <p>This complete and precise description is beneficial for understanding the model and subsequently becomes the key to rediscovery for verification and possible reuse. Verification that includes model curation ensures experimental results’ validity, reproducibility and consistency. Scientists can then confidently compare models or evaluate their proposed approaches. More comprehensive usability will enable model composition, creating larger-scale models, which is an essential aspect of modelling human physiology as a whole (<xref rid="B2" ref-type="bibr">Bassingthwaighte, 2000</xref>) and understanding the human body (<xref rid="B17" ref-type="bibr">Hunter et al., 2002</xref>).</p>
    <p>The standard technology to locate and manipulate data stored in RDF format is SPARQL Protocol and RDF Query Language (SPARQL). SPARQL is powerful for retrieving data specifically and precisely (<xref rid="B21" ref-type="bibr">Pérez et al., 2009</xref>), although it requires a rigid syntax query. This rigidity becomes a barrier for most users even if they already have enough knowledge regarding the RDF triple and ontologies to explore RDF. For expert users, their queries still may fail caused by misspellings, capitalisation, and ontology term variation. Therefore, text-based queries that can be composed freely, as in commercial search engines, are preferred, although the results are less precise.</p>
    <p>The current state-of-the-art approaches offer a workaround by converting text-based queries to SPARQL by leveraging deep learning. Most of the works are for question-and-answer tasks on general knowledge, for example, about an object’s location and public figures’ achievements; hence, they do not explicitly support the search of entities annotated compositely. The knowledge base used is generic RDF triple graphs such as DBPedia<xref rid="fn1" ref-type="fn"><sup>1</sup></xref>, Yet Another Great Ontology (YAGO)<xref rid="fn2" ref-type="fn"><sup>2</sup></xref>, and Wikidata<xref rid="fn3" ref-type="fn"><sup>3</sup></xref>. These graphs maintain a massive amount of information about entities and their facts, extracted from various sources such as Wikipedia and GeoName. The community and users manually validate information, so the level of accuracy is relatively high. <xref rid="B28" ref-type="bibr">Soru et al. (2020)</xref> and <xref rid="B36" ref-type="bibr">Yin et al. (2021)</xref> have considered the conversion as a language translation problem where SPARQL is the foreign language. <xref rid="B28" ref-type="bibr">Soru et al. (2020)</xref> implemented Long Short-Term Memory (LSTM) architecture to build sequence-to-sequence models and train the model over a dataset extracted from DBPedia. Then, <xref rid="B36" ref-type="bibr">Yin et al. (2021)</xref> extended the work by investigating the use of eight Neural Machine Translation (NMT) methods built using Convolutional Neural Network (CNN), Recurrent Neural Network (RNN), and Transformer. CNN-based method (<xref rid="B13" ref-type="bibr">Gehring et al., 2017</xref>) performed the best within these methods, followed by Transformer-based (<xref rid="B31" ref-type="bibr">Vaswani et al., 2017</xref>). However, in the context of natural language translation, the use of Transformer is prospective to improve performance since it is not as mature as RNN and CNN. With the popularity of Bidirectional Encoder Representations from Transformers (BERT) (<xref rid="B11" ref-type="bibr">Devlin et al., 2018</xref>), <xref rid="B30" ref-type="bibr">Tran et al. (2021)</xref> created SPBERT, a Transformer-based model pre-trained using a large DBPedia dataset for natural language to SPARQL and query results verbalisation tasks, and proved that the Transformer-based approach could surpass RNN and CNN. Adapting the created model for a new model is efficient by finetuning the existing model with less training data while keeping the property of the original model. Nevertheless, the text converted in these approaches must be in the natural language templates as formatted in the dataset. They cannot accommodate properly unstructured queries using keywords such as those used on commercial search engines.</p>
    <p>Working well with structured and unstructured text-based queries, Natural Language Interface for Model Entity Discovery (NLIMED) provides an interface to retrieve entities annotated compositely (<xref rid="B18" ref-type="bibr">Munarko et al., 2022</xref>). It identifies phrases in the query associated with the physiological domain and links them to possible ontology classes and predicates. The link results are then composed as SPARQL and executed at the SPARQL endpoint to retrieve entities. A similar tool was developed by <xref rid="B26" ref-type="bibr">Sarwar et al. (2019)</xref>, Model Annotation and Discovery (MAD), with the same domain but limited to entities in epithelial models. This limitation relates to template-based methods whose templates are customised for a particular topic, so adding topic coverage requires new templates.</p>
    <p>This paper presents CASBERT, a method to retrieve entities in biosimulation models that are annotated compositely. We apply the information retrieval paradigm and leave the complexity of SPARQL providing a more expressive query composition while maximising the advantages of BERT. By adopting Sentence-BERT (<xref rid="B22" ref-type="bibr">Reimers and Gurevych, 2019</xref>), composite annotations describing entities are pre-calculated into entity embeddings and stored into a list of entity embeddings. With the entity embeddings, a query that is also converted into a query embedding is compared using a similarity formula; then, the ranked results are displayed.</p>
    <p>With CASBERT, researchers can now explore information about entities in biosimulation models stored in a repository. They can find and access information quickly and adequately, including parameter values, variable units, variable types, and mathematical equations. CASBERT allows users to create expressive queries as keywords or natural language, such as ‘concentration of triose phosphate in astrocytes’. This convenience accelerates model validation, reproduction and reuse, directly supporting the principles of FAIR (Findability, Accessibility, Interoperability and Reusability) data.</p>
    <p>Recently, the biosimulation model formats in the two largest repositories, the Physiome Model Repository (PMR) (<xref rid="B37" ref-type="bibr">Yu et al., 2011</xref>) and the BioModels Database (<xref rid="B5" ref-type="bibr">Chelliah et al., 2015</xref>), have used RDF to describe their entities. Composite annotations are largely used to describe models in CellML (<xref rid="B9" ref-type="bibr">Cuellar et al., 2003</xref>) and SBML (<xref rid="B16" ref-type="bibr">Hucka et al., 2003</xref>) formats, detailing entities with terms in ontologies such as anatomical location, chemical compound, physics of biology, gene, and protein. We generated test data from these repositories in query and entity pairs. CASBERT performance was measured using Mean Average Precision and Mean Reciprocal Rank, and compared to the traditional bag-of-words method, the score was significantly higher. In addition, entity embeddings stored as a list are easy to manage, allowing for efficient addition, subtraction, and replacement processes, making them suitable for search engine implementations. CASBERT can also be implemented for composite annotation search in various domains such as chemistry, pharmacy, and medicine. Our implementation, dataset, and experiment setup are publicly available<xref rid="fn4" ref-type="fn"><sup>4</sup></xref>.</p>
  </sec>
  <sec sec-type="materials|methods" id="s2">
    <title>2 Materials and methods</title>
    <p>CASBERT provides an approach to converting composite annotations defining entities and queries to embeddings. Entity embeddings are pre-calculated and stored in a list of entity embeddings, whereas query embeddings are created on the fly when a request is made. Entities are then presented from the most relevant by initially calculating the similarity values between query embedding and entity embeddings.</p>
    <p>The conversion to embedding methods are based on Bidirectional Encoder Representations from Transformers (BERT) (<xref rid="B11" ref-type="bibr">Devlin et al., 2018</xref>) by implementing Sentence-BERT (<xref rid="B22" ref-type="bibr">Reimers and Gurevych, 2019</xref>). For the experiment, we created a dataset by collecting composite annotations from biosimulation models from the PMR and the BioModels database. These conversion methods are described in the following subsections, starting with the dataset used.</p>
    <sec id="s2-1">
      <title>2.1 Biosimulation model - Composite Annotation Query (BM-CAQ) dataset</title>
      <p>We constructed the dataset for the experiment by extracting compositely annotated entities in the PMR (<xref rid="B37" ref-type="bibr">Yu et al., 2011</xref>) and the BioModels database (<xref rid="B5" ref-type="bibr">Chelliah et al., 2015</xref>). The PMR is a repository storing biosimulation models initiated by the Physiome Project (<xref rid="B17" ref-type="bibr">Hunter et al., 2002</xref>). Most models are written using the CellML standard and annotated using the RDF standard. The models usually are equipped with human-readable information that can be loaded as web pages. We can further simulate and analyse physiological processes by running models using tools such as OpenCOR (<xref rid="B12" ref-type="bibr">Garny and Hunter, 2015</xref>). Like the PMR, the BioModels database manages biosimulation models in more significant numbers. The models deposited in this repository are mostly written using SBML standard (<xref rid="B16" ref-type="bibr">Hucka et al., 2003</xref>).</p>
      <p><xref rid="T1" ref-type="table">Table 1</xref> presents the example entities described compositely using the RDF standard in the PMR. These entities are variables of the brain energy metabolism model (<xref rid="B6" ref-type="bibr">Cloutier et al., 2009</xref>) whose CellML model is available in the PMR<xref rid="fn5" ref-type="fn"><sup>5</sup></xref>. An entity is described by at least one or, ideally, more ontology classes to provide detailed and precise descriptions. In the examples, <italic>GAPg</italic>/<italic>GAPg</italic> is annotated with OPB:00340, CHEBI:17138, and FMA:54537, whereas <italic>dAMP</italic>_<italic>dATPn.ATPn</italic> is annotated with OPB:00340, CHEBI: 15422, and FMA:54527, where these ontology classes are concepts available in Ontology of Physics for Biology (OPB) (<xref rid="B8" ref-type="bibr">Cook et al., 2008</xref>), Foundational Model of Anatomy (FMA) (<xref rid="B24" ref-type="bibr">Rosse and Mejino, 2008</xref>), and Chemical Entities of Biological Interest (ChEBI) (<xref rid="B10" ref-type="bibr">Degtyarenko et al., 2008</xref>), respectively. Additionally, the relationship between an entity and ontology classes is specified using predicates where in the example, there are ‘bqbiol:isPropertyOf’, ‘bqbiol:isPartOf’, ‘bqbiol:isVersionOf’ and ‘bqbiol:is’. As a complement, although not mandatory, an entity may be provided with a literal description marked with the ‘dcterms:description’ predicate, for example, ‘Rate of change in the concentration of glyceraldehyde-3-phosphate in the astrocyte’ on <italic>GAPg</italic>/<italic>GAPg</italic> entity.</p>
      <table-wrap position="float" id="T1">
        <label>TABLE 1</label>
        <caption>
          <p>The example of compositely annotated entities written using the RDF standard in the PMR. These entities are variables of the brain energy metabolism model, GAPg/GAPg and dAMP_dATPn.ATPn (<xref rid="B6" ref-type="bibr">Cloutier et al., 2009</xref>). They are described by ontology classes such as OPB_00340, CHEBI:17138, and FMA:54527; and predicates such as ‘bqbiol:isVersionOf’ and ‘bqbiol:is’. There are also literal descriptions marked by the dcterms:description predicate, although not all entities have one.</p>
        </caption>
        <table frame="hsides" rules="groups">
          <thead valign="top">
            <tr>
              <th align="center" rowspan="1" colspan="1">Variable</th>
              <th align="center" rowspan="1" colspan="1">Annotation using RDF</th>
            </tr>
          </thead>
          <tbody valign="top">
            <tr>
              <td align="left" rowspan="1" colspan="1">GAPg/GAPg</td>
              <td align="left" rowspan="1" colspan="1">&lt;rdf:Description rdf:about = “./cloutier_2009.cellml#<bold>GAPg_GAPg</bold>”&gt;</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"/>
              <td align="left" rowspan="1" colspan="1">&lt;bqbiol:isPropertyOf rdf:resource = “./cloutier_2009.cellml#entity_1”/&gt;</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"/>
              <td align="left" rowspan="1" colspan="1">&lt;<bold>bqbiol:isVersionOf</bold> rdf:resource = “<ext-link xlink:href="https://identifiers.org/opb/OPB_00340" ext-link-type="uri"><bold>https://identifiers.org/opb/OPB_00340</bold></ext-link>”/&gt;</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"/>
              <td align="left" rowspan="1" colspan="1">&lt;<bold>dcterms:description</bold>&gt;</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"/>
              <td align="left" rowspan="1" colspan="1">
                <bold>Rate of change in the concentration of glyceraldehyde-3-phosphate in the astrocyte</bold>
              </td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"/>
              <td align="left" rowspan="1" colspan="1">&lt;/dcterms:description&gt;</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"/>
              <td align="left" rowspan="1" colspan="1">&lt;/rdf:Description&gt;</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"/>
              <td align="left" rowspan="1" colspan="1">&lt;rdf:Description rdf:about = “./cloutier_2009.cellml#entity_1”&gt;</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"/>
              <td align="left" rowspan="1" colspan="1">&lt;bqbiol:isPartOf rdf:resource = “./cloutier_2009.cellml#entity_2”/&gt;</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"/>
              <td align="left" rowspan="1" colspan="1">&lt;<bold>bqbiol:is</bold> rdf:resource = “<ext-link xlink:href="http://identifiers.org/chebi/CHEBI:17138" ext-link-type="uri"><bold>http://identifiers.org/chebi/CHEBI:17138</bold></ext-link>”/&gt;</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"/>
              <td align="left" rowspan="1" colspan="1">&lt;/rdf:Description&gt;</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"/>
              <td align="left" rowspan="1" colspan="1">&lt;rdf:Description rdf:about = “./cloutier_2009.cellml#entity_2”&gt;</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"/>
              <td align="left" rowspan="1" colspan="1">&lt;<bold>bqbiol:is</bold> rdf:resource = “<ext-link xlink:href="http://identifiers.org/fma/FMA:54537" ext-link-type="uri"><bold>http://identifiers.org/fma/FMA:54537</bold></ext-link>”/&gt;</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"/>
              <td align="left" rowspan="1" colspan="1">&lt;/rdf:Description&gt;</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">dAMP_dATPn.ATPn</td>
              <td align="left" rowspan="1" colspan="1">&lt;rdf:Description rdf:about = “./cloutier_2009.cellml#<bold>dAMP_dATPn.ATPn</bold>”&gt;</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"/>
              <td align="left" rowspan="1" colspan="1">&lt;bqbiol:isPropertyOf rdf:resource = “./cloutier_2009.cellml#entity_15”/&gt;</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"/>
              <td align="left" rowspan="1" colspan="1">&lt;<bold>bqbiol:isVersionOf</bold> rdf:resource = “<ext-link xlink:href="https://identifiers.org/opb/OPB_00340" ext-link-type="uri"><bold>https://identifiers.org/opb/OPB_00340</bold></ext-link>”/&gt;</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"/>
              <td align="left" rowspan="1" colspan="1">&lt;<bold>dcterms:description</bold>&gt;</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"/>
              <td align="left" rowspan="1" colspan="1">
                <bold>Rate of change in the concentration of adenosine triphosphate in the neuron of the brain</bold>
              </td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"/>
              <td align="left" rowspan="1" colspan="1">&lt;/dcterms:description&gt;</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"/>
              <td align="left" rowspan="1" colspan="1">&lt;/rdf:Description&gt;</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"/>
              <td align="left" rowspan="1" colspan="1">&lt;rdf:Description rdf:about = “./cloutier_2009.cellml#entity_15”&gt;</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"/>
              <td align="left" rowspan="1" colspan="1">&lt;bqbiol:isPartOf rdf:resource = “./cloutier_2009.cellml#entity_1”/&gt;</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"/>
              <td align="left" rowspan="1" colspan="1">&lt;<bold>bqbiol:is</bold> rdf:resource = “<ext-link xlink:href="http://identifiers.org/chebi/CHEBI:15422" ext-link-type="uri"><bold>http://identifiers.org/chebi/CHEBI:15422</bold></ext-link>”/&gt;</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"/>
              <td align="left" rowspan="1" colspan="1">&lt;/rdf:Description&gt;</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"/>
              <td align="left" rowspan="1" colspan="1">&lt;rdf:Description rdf:about = “./cloutier_2009.cellml#entity_1”&gt;</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"/>
              <td align="left" rowspan="1" colspan="1">&lt;<bold>bqbiol:is</bold> rdf:resource = “<ext-link xlink:href="http://identifiers.org/fma/FMA:54527" ext-link-type="uri"><bold>http://identifiers.org/fma/FMA:54527</bold></ext-link>”/&gt;</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"/>
              <td align="left" rowspan="1" colspan="1">&lt;/rdf:Description&gt;</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn>
            <p>Text in bold are the main terms for the composite annotation, which are the ontology classes, variable description, and variable name whose relationship is described by the predicates.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p>There are 13,360 entities<xref rid="fn6" ref-type="fn"><sup>6</sup></xref> in the RDF and CellML files in the PMR, and 4,652 have literal descriptions. These literal descriptions usually accurately summarise the composite annotations of entities, although some are not. We assume that an accurate literal description can be used as a query representation for testing CASBERT and can reflect future user queries. Therefore, our test data includes all accurate literal descriptions as valid queries and the related entities as relevant search objects. Altogether, there are 338 unique queries, each relating to one or many entities. Then, we will refer to this set of query-entity pairs as <italic>noPredicate</italic> because most queries do not explicitly have an RDF predicate term.</p>
      <p>However, we anticipate that queries for specific entity searches mimicking SPARQL will include predicate terms. Therefore, we created the second set of query-entity pairs by inserting the terms in the predicates to the queries in <italic>noPredicate</italic>. Terms were chosen randomly based on a series of predicates determining the relationship between ontology classes and entities. For example, the GAPg in <xref rid="T1" ref-type="table">Table 1</xref> and CHEBI:17138 (glyceraldehyde-3-phosphate) are linked by ‘bqbiol:isPropertyOf’ and ‘bqbiol:is’ so that the insert can use the ‘is property of’ and ‘is’. If ‘is property of’ is selected, the new query becomes ‘Rate of change in the concentration of is property of glyceraldehyde-3-phosphate in the astrocyte’. We got 534 additional query-entity pairs and name this set as <italic>withPredicate</italic>’.</p>
      <p>We applied the same strategy to extract queries from the BioModels database, which returned 834 <italic>noPredicate</italic> and 1,541 <italic>withPredicate</italic> queries. In its entirety, this dataset is named Biosimulation Model - Composite Annotation Query (BM-CAQ) and sample data are shown in <xref rid="s11" ref-type="sec">Supplementary Tables S1–S4</xref>. The source code for creating this dataset and testing CASBERT is available online<xref rid="fn7" ref-type="fn"><sup>7</sup></xref>.</p>
    </sec>
    <sec id="s2-2">
      <title>2.2 Composite annotation search using BERT (CASBERT)</title>
      <p>We used Sentence-BERT (<xref rid="B22" ref-type="bibr">Reimers and Gurevych, 2019</xref>), a BERT-based sentence encoder, to convert queries and composite annotations to embeddings and to classify the query to be compared to the appropriate entity embedding list. BERT provides pre-training models built based on massive corpora that can be fine-tuned with a smaller corpus to maximise performance for domain-specific uses (<xref rid="B11" ref-type="bibr">Devlin et al., 2018</xref>). A sentence is converted into embedding by splitting to tokens and then calculating each token’s embedding unique to the context, such as the surrounding tokens and position. Therefore, the same token in different sentences will have a different embedding. This attention to context correlates with high reliability in several natural language processing tasks, such as named entity recognition, concept extraction, and sentiment analysis, and is relatively better than non-context embedding (<xref rid="B1" ref-type="bibr">Arora et al., 2020</xref>; <xref rid="B29" ref-type="bibr">Taillé et al., 2020</xref>). In addition, the form of the token, which is part of the sentence, makes BERT more adaptive to typographical errors and variations of word writing.</p>
      <p>The most straightforward approach to create a sentence embedding is by averaging the token embeddings; however, this often leads to poor performance (<xref rid="B22" ref-type="bibr">Reimers and Gurevych, 2019</xref>). Resolving this issue, Sentence-BERT offers a better concatenation method optimised for Semantic Textual Similarity (STS) by applying Siamese (<xref rid="B3" ref-type="bibr">Bromley et al., 1993</xref>) and Triplet loss (<xref rid="B32" ref-type="bibr">Weinberger and Saul, 2009</xref>) networks.</p>
      <p>In the following, we describe the CASBERT mechanism for transforming composite annotations to entity embeddings and queries to query embeddings.</p>
      <sec id="s2-2-1">
        <title>2.2.1 Entity embedding</title>
        <p>An entity embedding represents an entity as a dense vector whose dimensions match the sentence transformer model used. CASBERT generates this presentation by converting composite annotations to embedding. The annotation comprises triples which are subject, predicate and object expressions. These triples form a tree where the root is the entity’s name, the leaves are the ontology classes (objects), and the edges are the predicates. The predicates link the root and the leaves to form paths. The entity embedding is the average of all path embeddings, where the ontology class embedding and the predicate embeddings determine the path embedding.</p>
        <p>Here we describe the process of converting composite annotations to entity embeddings. We use the <italic>GAPg</italic>/<italic>GAPg</italic> variable in <xref rid="T1" ref-type="table">Table 1</xref> as a running example where all other composite annotations are processed similarly to become entity embeddings. <xref rid="F1" ref-type="fig">Figure 1A</xref> shows the composite annotation regarding the concentration (OPB:00340) of glyceraldehyde 3-phosphate (CHEBI:17138) in an Astrocyte (FMA:54537). There are five triples with the subject and objects: root (<italic>GAPg</italic>/<italic>GAPg</italic>), ontology classes (OPB:00340, CHEBI:17138, FMA:54537), and intermediate subjects/objects (entity_1, entity_2). <xref rid="F1" ref-type="fig">Figure 1B</xref> presents interconnected triples creating paths that display a clear relationship between root and ontology classes. The terms referred to as intermediate subject/object are usually generic and are similar across all composite annotations, so they cannot be used as a differentiator; therefore, we ignore them (<xref rid="F1" ref-type="fig">Figure 1C</xref>). Next, we remove predicates that directly connect intermediate subjects, e.g. ‘is’, and ontology classes, because these only describe the intermediate subjects/objects, not the entity. We remove the prefix of the predicate term; for example, rather than ‘bqbiol:isPropertyOf’, we use ‘isPropertyOf’ as a predicate term.</p>
        <fig position="float" id="F1">
          <label>FIGURE 1</label>
          <caption>
            <p>The example of an entity compositely annotated using RDF and its representation for further conversion to embedding. <bold>(A)</bold> The composite annotation of <italic>GAPg</italic>/<italic>GAPg</italic> entity by three ontology classes. <bold>(B)</bold> Paths consist of predicates connecting the entity to ontology classes. <bold>(C)</bold> The representation of the entity before converted to entity embedding.</p>
          </caption>
          <graphic xlink:href="fbinf-03-1107467-g001" position="float"/>
        </fig>
        <p><xref rid="F2" ref-type="fig">Figure 2</xref> illustrates the translation to the entity embedding process. Initially, CASBERT calculates the embedding of each path <italic>e</italic>
<sub><italic>pt</italic></sub> by combining its ontology class embedding <italic>e</italic>
<sub><italic>c</italic></sub> and the average of predicate embeddings <italic>e</italic>
<sub><italic>p</italic></sub> using Eq. <xref rid="e2" ref-type="disp-formula">2</xref>; where <italic>e</italic>
<sub><italic>c</italic></sub> and <italic>e</italic>
<sub><italic>p</italic></sub> are calculated using Eq. <xref rid="e1" ref-type="disp-formula">(1)</xref>. <italic>e</italic>
<sub><italic>c</italic></sub> is the average of ontology class feature embeddings; for example, FMA:54537 has a preferred label feature of ‘Astrocyte’ and a synonym feature of ‘Astrocytus’. There are other features, such as parent labels and definitions, but using the selected two features only can give a higher performance (<xref rid="B18" ref-type="bibr">Munarko et al., 2022</xref>). For <italic>e</italic>
<sub><italic>p</italic></sub> calculation, predicate terms in camelCase format are normalised to phrases in lowercase before converting to embeddings. For example, ‘isVersionOf’ and ‘isPartOf’ are changed to ‘is version of’ and ‘is part of’. Then, we limit the role of <italic>e</italic>
<sub><italic>p</italic></sub> with <italic>w</italic>
<sub><italic>p</italic></sub> between 0 and 1, which makes it lower than the role of the ontology class embedding. Finally, all path embeddings are averaged to get entity embedding <italic>e</italic>
<sub><italic>e</italic></sub> as presented by Eq. <xref rid="e3" ref-type="disp-formula">(3)</xref>.<disp-formula id="e1"><mml:math id="m1" overflow="scroll"><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mfrac><mml:munderover accentunder="false" accent="true"><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mspace width="1em"/><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">d</mml:mi><mml:mspace width="1em"/><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mfrac><mml:munderover accentunder="false" accent="true"><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math><label>(1)</label></disp-formula>
<disp-formula id="e2"><mml:math id="m2" overflow="scroll"><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mo>.</mml:mo><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:math><label>(2)</label></disp-formula>
<disp-formula id="e3"><mml:math id="m3" overflow="scroll"><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>e</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:mfrac><mml:munderover accentunder="false" accent="true"><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mrow><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math><label>(3)</label></disp-formula>
</p>
        <fig position="float" id="F2">
          <label>FIGURE 2</label>
          <caption>
            <p>The conversion of entities to entity embeddings. For each entity, ontology classes and predicates are encoded into embeddings. Embeddings of ontology classes and predicates in one path are combined to form path embedding. Finally, all path embeddings are combined using the average function, creating an entity embedding.</p>
          </caption>
          <graphic xlink:href="fbinf-03-1107467-g002" position="float"/>
        </fig>
      </sec>
      <sec id="s2-2-2">
        <title>2.2.2 Query embedding</title>
        <p>Users create queries using keywords or natural language to search for entities. CASBERT represents these queries into query embeddings, so they are comparable to entity embeddings.</p>
        <p>To explain the process of converting queries to query embeddings, we use ‘triose phosphate concentration in astrocytes’ as a running query example (see <xref rid="F3" ref-type="fig">Figure 3</xref>). This query is intended to search for the <italic>GAPg</italic>/<italic>GAPg</italic> variable as in <xref rid="T1" ref-type="table">Table 1</xref> where ‘triose phosphate’ is a synonym for ‘glyceraldehyde 3-phosphate’. A query can be assumed to be a composite annotation summary containing phrases about physiological and biochemical terms. CASBERT uses off-the-shelf natural language processing (NLP) method, SciSpacy (<xref rid="B20" ref-type="bibr">Neumann et al., 2019</xref>) with the ‘en_core_sci_scibert’ as Named Entity Recognition (NER) model, to identify these phrases; where for the query example, there are ‘concentration’, ‘triose phosphate’, and ‘astrocyte’. These phrases are converted to embeddings and combined by averaging (Eq. <xref rid="e4" ref-type="disp-formula">4</xref>). We assume that these phrases correlate with ontology classes to some degree; therefore, the combined embedding <italic>e</italic>
<sub><italic>ph</italic></sub> is normalised by <italic>w</italic>
<sub><italic>ph</italic></sub>, which is the average of the maximum similarity of each phrase in <italic>p</italic> to ontology classes <italic>c</italic>. After converting into embeddings, the similarity between <italic>p</italic>
<sub><italic>i</italic></sub> and <italic>c</italic>
<sub><italic>j</italic></sub> follows Eq. <xref rid="e6" ref-type="disp-formula">6</xref>.<disp-formula id="e4"><mml:math id="m4" overflow="scroll"><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mfrac><mml:munderover accentunder="false" accent="true"><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mspace width="1em"/><mml:mi mathvariant="normal">w</mml:mi><mml:mi mathvariant="normal">h</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mspace width="1em"/><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mfrac><mml:munderover accentunder="false" accent="true"><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:mi mathvariant="italic">max</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:mi>S</mml:mi><mml:mi>i</mml:mi><mml:msubsup><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msubsup><mml:mfenced open="(" close=")"><mml:mrow><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:math><label>(4)</label></disp-formula>
<disp-formula id="e5"><mml:math id="m5" overflow="scroll"><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>q</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>e</mml:mi></mml:mrow></mml:msub><mml:mi>e</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msub></mml:math><label>(5)</label></disp-formula>
<disp-formula id="e6"><mml:math id="m6" overflow="scroll"><mml:mi>S</mml:mi><mml:mi>i</mml:mi><mml:mi>m</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>q</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>e</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>q</mml:mi></mml:mrow></mml:msub><mml:mo>.</mml:mo><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>e</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mfenced open="‖" close="‖"><mml:mrow><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>q</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mfenced open="‖" close="‖"><mml:mrow><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>e</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mrow><mml:mo movablelimits="false" form="prefix">∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msubsup><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>.</mml:mo><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msqrt><mml:mrow><mml:msubsup><mml:mrow><mml:mo movablelimits="false" form="prefix">∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:msqrt><mml:msqrt><mml:mrow><mml:msubsup><mml:mrow><mml:mo movablelimits="false" form="prefix">∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:msqrt></mml:mrow></mml:mfrac></mml:math><label>(6)</label></disp-formula>
</p>
        <fig position="float" id="F3">
          <label>FIGURE 3</label>
          <caption>
            <p>The conversion of a query to a query embedding. Phrases related to physiology and biochemical terms are identified using NER method, and then converted into embeddings using Sentence-BERT. These phrase embeddings are then averaged and combined with the entire query text embedding.</p>
          </caption>
          <graphic xlink:href="fbinf-03-1107467-g003" position="float"/>
        </fig>
        <p>Furthermore, we take into account the relationship between phrases. This relationship is encoded explicitly or implicitly as conjunctions, prepositions, and the order of words. We capture this relationship by accounting for the overall query as an embedding <italic>e</italic>. The query embedding is then the addition of <italic>e</italic>
<sub><italic>ph</italic></sub> and <italic>e</italic>, where <italic>e</italic> is multiplied with the empirically decided multiplier <italic>m</italic>
<sub><italic>e</italic></sub> (see Eq. <xref rid="e5" ref-type="disp-formula">5</xref>).</p>
        <p>A few phrases may not have physiological or biochemical meaning and only complement other phrases. Therefore, their embeddings should be weighted lower and merged with the complemented phrase embedding. We use the <italic>w</italic>
<sub><italic>p</italic></sub> value for experiment purposes, the same weight used in Eq. <xref rid="e2" ref-type="disp-formula">(2)</xref>, to weight these phrase embeddings.</p>
      </sec>
      <sec id="s2-2-3">
        <title>2.2.3 Entity retrieval</title>
        <p>With the availability of the entity embedding list and query embedding, we can now calculate their similarities and present the relevant entities sorted from the most similar, as illustrated in <xref rid="F4" ref-type="fig">Figure 4</xref>.</p>
        <fig position="float" id="F4">
          <label>FIGURE 4</label>
          <caption>
            <p>Entity search process using CASBERT. CASBERT provides entity embedding lists to choose from in the retrieval process according to the query type. Lists are distinguished by different <italic>w</italic>
<sub><italic>p</italic></sub> values, for example, <italic>L</italic>
<sub>1</sub> with a value of 0 and <italic>L</italic>
<sub>2</sub> with a value of 0.22. At first, the query is converted to an embedding. Then, the embedding becomes the input of the Query Classifier (QC) model to select the correct entity embedding list. The entity results are then taken from the chosen entity embedding list and presented in a sorted order based on cosine similarity values.</p>
          </caption>
          <graphic xlink:href="fbinf-03-1107467-g004" position="float"/>
        </fig>
        <sec id="s2-2-3-1">
          <title>2.2.3.1 Query - Entity Similarity</title>
          <p>We implemented Cosine Similarity (CS) (<xref rid="B25" ref-type="bibr">Salton and McGill, 1983</xref>) to calculate the similarity value between a query embedding <italic>e</italic>
<sub><italic>q</italic></sub> and an entity embedding <italic>e</italic>
<sub><italic>e</italic></sub>. CS of two embeddings is the dot product of both embeddings divided by the multiplication of the magnitude of both embeddings (Eq. <xref rid="e6" ref-type="disp-formula">(6)</xref>). Thus, CS ignores the magnitude of each embedding, making it suitable for the high dimensionality nature of embedding. Additionally, ‘multi-qa-MiniLM-L6-cos-v1’ pre-trained sentence transformer model (<xref rid="B22" ref-type="bibr">Reimers and Gurevych, 2019</xref>) used to convert a sentence to an embedding in CASBERT is optimised with CS. This calculated value is later used to display the retrieval results from the highest to the lowest.</p>
        </sec>
        <sec id="s2-2-3-2">
          <title>2.2.3.2 Query Classification</title>
          <p>Considering that we can create multiple lists of entity embeddings with different <italic>w</italic>
<sub><italic>p</italic></sub> (see Eq. <xref rid="e2" ref-type="disp-formula">(2)</xref>), we found that some queries can retrieve best when compared to a list with <italic>w</italic>
<sub><italic>p</italic></sub> = 0, while others to a list with <italic>w</italic>
<sub><italic>p</italic></sub> &gt; 0. As an experiment, we created two lists, <italic>L</italic>
<sub>1</sub> with <italic>w</italic>
<sub><italic>p</italic></sub> = 0 and <italic>L</italic>
<sub>2</sub> with <italic>w</italic>
<sub><italic>p</italic></sub> = 0.22. Then we created the Query Classification (QC) model to classify queries to <italic>L</italic>
<sub>1</sub> or <italic>L</italic>
<sub>2</sub>, where these classes are associated with the embedding list used for entity retrieval. The training data was extracted from partially combined query-entity sets in BM-CAQ. We calculated the value of <italic>mAP@</italic>10 (see Eq. <xref rid="e8" ref-type="disp-formula">(8)</xref>) of the selected query pairs to perform searches to <italic>L</italic>
<sub>1</sub> and <italic>L</italic>
<sub>2</sub>. The highest value determines pair labelling to <italic>L</italic>
<sub>1</sub> or <italic>L</italic>
<sub>2</sub>. The QC model was trained using Transformers (<xref rid="B34" ref-type="bibr">Wolf et al., 2020</xref>) and the ‘bert-base-uncased’ pre-trained model where the training data was initially augmented using nlpaug<xref rid="fn8" ref-type="fn"><sup>8</sup></xref> to increase its size and diversity. The training process in more detail is presented in <xref rid="s11" ref-type="sec">Supplementary Figure S1</xref>.</p>
        </sec>
      </sec>
    </sec>
  </sec>
  <sec id="s3">
    <title>3 Experiments and results</title>
    <sec id="s3-1">
      <title>3.1 Experiment setup</title>
      <p>We conducted experiments to measure CASBERT’s performance in searching for entities in the biosimulation models in the PMR and the BioModels database. <xref rid="T2" ref-type="table">Table 2</xref> displays query-entity pair sets and retrieval methods used in this experiment. The data used is the BM-CAQ dataset, including <italic>noPredicate</italic> and <italic>withPredicate</italic> sets. Additionally, we combined the two sets into <italic>combine</italic> and used 60% of it for training and validation of the QC model and the remaining 40% for additional test data.</p>
      <table-wrap position="float" id="T2">
        <label>TABLE 2</label>
        <caption>
          <p>The strategies to measure CASBERT performance. There are three query sets and eight retrieval methods including BM25 as the gold standard.</p>
        </caption>
        <table frame="hsides" rules="groups">
          <thead valign="top">
            <tr>
              <th rowspan="2" align="left" colspan="1">Q-E type</th>
              <th colspan="2" align="center" rowspan="1"># Of query-entities</th>
              <th rowspan="2" align="left" colspan="1">Description</th>
            </tr>
            <tr>
              <th align="center" rowspan="1" colspan="1">PMR-CA</th>
              <th align="center" rowspan="1" colspan="1">BioModels-CA</th>
            </tr>
          </thead>
          <tbody valign="top">
            <tr>
              <td align="left" rowspan="1" colspan="1">
                <italic>noPredicate</italic>
              </td>
              <td align="center" rowspan="1" colspan="1">338</td>
              <td align="center" rowspan="1" colspan="1">834</td>
              <td align="left" rowspan="1" colspan="1">The original query-entity pairs extracted from the PMR and the BioModels-CA.</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">
                <italic>withPredicate</italic>
              </td>
              <td align="center" rowspan="1" colspan="1">534</td>
              <td align="center" rowspan="1" colspan="1">1541</td>
              <td align="left" rowspan="1" colspan="1">The expanded <italic>noPredicate</italic> set by randomly adding terms in composite annotation predicate to the associated existing query terms</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">
                <italic>combine</italic>
              </td>
              <td align="center" rowspan="1" colspan="1">509</td>
              <td align="center" rowspan="1" colspan="1">1777</td>
              <td align="left" rowspan="1" colspan="1">Combination of <italic>noPredicate</italic> and <italic>withPredicate</italic> where the data used for QC model training is removed</td>
            </tr>
          </tbody>
        </table>
        <table frame="hsides" rules="groups">
          <thead>
            <tr>
              <th align="left" rowspan="1" colspan="1">Retrieval method</th>
              <th colspan="2" align="left" rowspan="1">Terms used to generate query embedding</th>
              <th align="left" rowspan="1" colspan="1">List of entity embeddings used</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td align="left" rowspan="1" colspan="1">
                <italic>macro</italic>
              </td>
              <td colspan="2" align="left" rowspan="1">whole query terms</td>
              <td align="left" rowspan="1" colspan="1"><italic>E</italic><sub>1</sub>(<italic>w</italic><sub><italic>p</italic></sub> = 0)</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">
                <italic>macroWP</italic>
              </td>
              <td colspan="2" align="left" rowspan="1">whole query terms</td>
              <td align="left" rowspan="1" colspan="1"><italic>E</italic><sub>2</sub>(0 &lt; <italic>w</italic>
<sub><italic>p</italic></sub> &lt; 1)</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">
                <italic>micro</italic>
              </td>
              <td colspan="2" align="left" rowspan="1">ontology class concept phrase</td>
              <td align="left" rowspan="1" colspan="1"><italic>E</italic><sub>1</sub>(<italic>w</italic><sub><italic>p</italic></sub> = 0)</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">
                <italic>microWP</italic>
              </td>
              <td colspan="2" align="left" rowspan="1">ontology class concept phrase</td>
              <td align="left" rowspan="1" colspan="1"><italic>E</italic><sub>2</sub>(0 &lt; <italic>w</italic>
<sub><italic>p</italic></sub> &lt; 1)</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">
                <italic>mixed</italic>
              </td>
              <td colspan="2" align="left" rowspan="1">whole query terms &amp; ontology class concept phrases</td>
              <td align="left" rowspan="1" colspan="1"><italic>E</italic><sub>1</sub>(<italic>w</italic><sub><italic>p</italic></sub> = 0)</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">
                <italic>mixedWP</italic>
              </td>
              <td colspan="2" align="left" rowspan="1">whole query terms &amp; ontology class concept phrases</td>
              <td align="left" rowspan="1" colspan="1"><italic>E</italic><sub>2</sub>(0 &lt; <italic>w</italic>
<sub><italic>p</italic></sub> &lt; 1)</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">
                <italic>mixedCl</italic>
              </td>
              <td colspan="2" align="left" rowspan="1">whole query terms &amp; ontology class concept phrases</td>
              <td align="left" rowspan="1" colspan="1">select between <italic>L</italic>
<sub>1</sub> or <italic>L</italic>
<sub>2</sub>
</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">BM25</td>
              <td colspan="2" align="left" rowspan="1">Retrieval uses a bag-of-words method, BM25</td>
              <td align="left" rowspan="1" colspan="1"/>
            </tr>
          </tbody>
        </table>
      </table-wrap>
      <p><italic>w</italic><sub><italic>p</italic></sub> is a variable that defines the role of the predicate embedding, which is ideally lower than the role of the ontology class embedding. In this experiment, we want to demonstrate the difference in performance between retrieval methods using entity lists without predicates and entity lists with predicates. Therefore, we first created two entity embedding lists, <italic>L</italic>
<sub>1</sub> with <italic>w</italic>
<sub><italic>p</italic></sub> = 0 and <italic>L</italic>
<sub>2</sub> with 0 &lt; <italic>w</italic>
<sub><italic>p</italic></sub> &lt; 1. The <italic>w</italic>
<sub><italic>p</italic></sub> value for <italic>L</italic>
<sub>2</sub> can be any arbitrary number as long as still in the correct range. Here, we choose 0.22 because it is small compared to the ontology class embedding weight, which is 1, and sufficient to represent the existence of predicates.</p>
      <p>We tested three retrieval scenarios that yielded seven methods combined with entity embedding lists <italic>L</italic>
<sub>1</sub> and <italic>L</italic>
<sub>2</sub>. We also measured the performance of BM25 (<xref rid="B23" ref-type="bibr">Robertson and Walker, 1994</xref>), a bag-of-words method, as the gold standard. The first scenario calculates the query embedding based on the query text only without identifying the phrases; when used to retrieve entities from <italic>L</italic>
<sub>1</sub> is named <italic>macro</italic> while from <italic>L</italic>
<sub>2</sub> is called <italic>macroWP</italic>. The following scenario uses phrases related to physiological and biochemical terms to generate query embeddings; when retrieving from <italic>L</italic>
<sub>1</sub>, the method is called <italic>micro</italic>. The phrases are detected using the NER method, converted to embedding and combined using the averaging function. The additional use of non-physiological and biochemical phrases with this method, along with the retrieval from <italic>L</italic>
<sub>2</sub>, is called <italic>microWP</italic>. Next, the third scenario combines the two initial scenarios using Eqs<xref rid="e4" ref-type="disp-formula">s (4)</xref>, <xref rid="e5" ref-type="disp-formula">(5</xref>), where the application for <italic>L</italic>
<sub>1</sub> and <italic>L</italic>
<sub>2</sub> are <italic>mixed</italic> and <italic>mixedWP</italic> consecutively. Here we set <italic>m</italic>
<sub><italic>e</italic></sub> = 1.9, which again is determined empirically by the logic that the query term as a whole is good enough to represent the query while the phrases within it can enhance the quality of the query representation as an embedding; therefore, <italic>m</italic>
<sub><italic>e</italic></sub> is more significant than <italic>w</italic>
<sub><italic>ph</italic></sub>. Finally, we apply <italic>L</italic>
<sub>1</sub> and <italic>L</italic>
<sub>2</sub> selection using the QC model with the third scenario as <italic>mixedCl</italic>.</p>
    </sec>
    <sec id="s3-2">
      <title>3.2 Evaluation metric</title>
      <p>We measured CASBERT performance for each set of query-entity pairs <italic>Q</italic> in the BM-CAQ dataset using Mean Average Precision for the top k results (<italic>mAP@k</italic>), Eq. <xref rid="e8" ref-type="disp-formula">(8)</xref>. <italic>mAP@k</italic> is based on Average Precision at k (<italic>AP@k</italic>) as shown by Equation <xref rid="e7" ref-type="disp-formula">7</xref>, where <italic>R</italic> is the number of relevant entities in the results, <italic>P@i</italic> is the proportion of relevant entities in the top <italic>i</italic> results, and <italic>r@i</italic> is a relevance function that returns 0 or 1 for the irrelevance or relevance of the entity at position <italic>i</italic>, respectively. Suppose there is a query-entity pair (<italic>q</italic>, <italic>es</italic>) in <italic>Q</italic>, where the number of <italic>es</italic> is at least one; then, with the query <italic>q</italic>, a retrieval method should be able to retrieve entities in <italic>es</italic> only. The number of search results that match this <italic>es</italic> is <italic>R</italic>. Furthermore, we set the value of <italic>k</italic> to 10 because search results are usually arranged in pages of 10 entities, and users are generally only interested in the first page.<disp-formula id="e7"><mml:math id="m7" overflow="scroll"><mml:mi>A</mml:mi><mml:mi>P</mml:mi><mml:mi>@</mml:mi><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:mfrac><mml:munderover accentunder="false" accent="true"><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:munderover><mml:mi>P</mml:mi><mml:mi>@</mml:mi><mml:mi>i</mml:mi><mml:mo>×</mml:mo><mml:mi>r</mml:mi><mml:mi>@</mml:mi><mml:mi>i</mml:mi></mml:math><label>(7)</label></disp-formula>
<disp-formula id="e8"><mml:math id="m8" overflow="scroll"><mml:mi>m</mml:mi><mml:mi>A</mml:mi><mml:mi>P</mml:mi><mml:mi>@</mml:mi><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mfenced open="|" close="|"><mml:mrow><mml:mi>Q</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mfrac><mml:munderover accentunder="false" accent="true"><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mfenced open="|" close="|"><mml:mrow><mml:mi>Q</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:munderover><mml:mi>A</mml:mi><mml:mi>P</mml:mi><mml:mi>@</mml:mi><mml:msub><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math><label>(8)</label></disp-formula>
</p>
      <p>Moreover, we also use Mean Reciprocal Rank (<italic>mRR</italic>) with Eq. <xref rid="e9" ref-type="disp-formula">(9)</xref> measuring the mean of the multiplicative inverse of the first entity in the retrieval results found to be relevant (<italic>ranks</italic>
<sub><italic>i</italic></sub>). For example, given the query <italic>q</italic>, a retrieval method returns entities of <italic>k</italic> = 5 displayed in order of rank and relevance, 0 or 1, as {<italic>1</italic>: <italic>0</italic>,<italic>2</italic>: <italic>1</italic>,<italic>3</italic>: <italic>0</italic>,<italic>4</italic>: <italic>0</italic>,<italic>5</italic>: <italic>1</italic>}. Then the Reciprocal Rank calculation (<italic>RR</italic>) only considers the ranking of the first relevant entity, {<italic>2</italic>: <italic>1</italic>}, so the value of <italic>RR</italic> for <italic>q</italic> is 0.5. Then the value of <italic>mRR</italic> is calculated and averaged for all queries in <italic>Q</italic>.<disp-formula id="e9"><mml:math id="m9" overflow="scroll"><mml:mi>m</mml:mi><mml:mi>R</mml:mi><mml:mi>R</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mfenced open="|" close="|"><mml:mrow><mml:mi>Q</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mfrac><mml:munderover accentunder="false" accent="true"><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mfenced open="|" close="|"><mml:mrow><mml:mi>Q</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:munderover><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>k</mml:mi><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:math><label>(9)</label></disp-formula>
</p>
    </sec>
    <sec id="s3-3">
      <title>3.3 Results</title>
      <p>From <xref rid="T3" ref-type="table">Table 3</xref>, we can see that all of the methods used in CASBERT have higher <italic>mAP@</italic>10 and <italic>mRR</italic> than the gold standard BM25. The <italic>macro</italic> and <italic>macroWP</italic> perform reasonably well for all query-entity pair sets in the BM-CAQ. These methods are the most efficient because there is only one conversion to embedding for each query, so the retrieval process is faster. Meanwhile, the <italic>micro</italic> and <italic>microWP</italic>, which incorporate embeddings of phrases in the query, have the lowest measurement results among all the proposed methods. Using phrases alone overrides the relational information between phrases, resulting in lower performance. Strategies that combine embeddings of the whole query terms and phrases related to the concept of ontology classes (<italic>mixed</italic>, <italic>mixedWP</italic>, <italic>mixedCl</italic>) perform best (indicated by bold values in <xref rid="T3" ref-type="table">Table 3</xref>). These results show that the query text as a whole is sufficient to be converted into an embedding representing the query while embedding phrases helps increase the quality of query embedding. Moreover, in the <italic>mixedWP</italic>, using the QC model can slightly improve the retrieval quality and make it the best method. The QC model classifies queries for further retrieval from the appropriate entity embedding list, although the performance gains are modest.</p>
      <table-wrap position="float" id="T3">
        <label>TABLE 3</label>
        <caption>
          <p>CASBERT performance over three query-entity pair sets and seven searching methods compared to the bag-of-words method (BM25) measured using <italic>mAP@</italic>10 and <italic>mRR</italic>. The numbers of entities in the PMR and the BioModels are 4,652 and 54,456 respectively.</p>
        </caption>
        <table frame="hsides" rules="groups">
          <thead valign="top">
            <tr>
              <th rowspan="2" align="center" colspan="1">Method</th>
              <th colspan="2" align="center" rowspan="1">
                <italic>noPredicate</italic>
              </th>
              <th colspan="2" align="center" rowspan="1">
                <italic>withPredicate</italic>
              </th>
              <th colspan="2" align="center" rowspan="1">Combine</th>
            </tr>
            <tr>
              <th align="left" rowspan="1" colspan="1">mAP@10</th>
              <th align="center" rowspan="1" colspan="1">mRR</th>
              <th align="left" rowspan="1" colspan="1">mAP@10</th>
              <th align="center" rowspan="1" colspan="1">mRR</th>
              <th align="left" rowspan="1" colspan="1">mAP@10</th>
              <th align="center" rowspan="1" colspan="1">mRR</th>
            </tr>
          </thead>
          <tbody valign="top">
            <tr>
              <td colspan="7" align="left" rowspan="1">PMR-CA</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"> <italic>macro</italic>
</td>
              <td align="char" char="." rowspan="1" colspan="1">0.645216</td>
              <td align="center" rowspan="1" colspan="1">0.643424</td>
              <td align="char" char="." rowspan="1" colspan="1">0.572291</td>
              <td align="center" rowspan="1" colspan="1">0.597649</td>
              <td align="char" char="." rowspan="1" colspan="1">0.601406</td>
              <td align="center" rowspan="1" colspan="1">0.602604</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"> <italic>macroWP</italic>
</td>
              <td align="char" char="." rowspan="1" colspan="1">0.626565</td>
              <td align="center" rowspan="1" colspan="1">0.624992</td>
              <td align="char" char="." rowspan="1" colspan="1">0.585014</td>
              <td align="center" rowspan="1" colspan="1">0.606947</td>
              <td align="char" char="." rowspan="1" colspan="1">0.604012</td>
              <td align="center" rowspan="1" colspan="1">0.608011</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"> <italic>micro</italic>
</td>
              <td align="char" char="." rowspan="1" colspan="1">0.619483</td>
              <td align="center" rowspan="1" colspan="1">0.617890</td>
              <td align="char" char="." rowspan="1" colspan="1">0.534427</td>
              <td align="center" rowspan="1" colspan="1">0.549304</td>
              <td align="char" char="." rowspan="1" colspan="1">0.592228</td>
              <td align="center" rowspan="1" colspan="1">0.595516</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"> <italic>microWP</italic>
</td>
              <td align="char" char="." rowspan="1" colspan="1">0.606255</td>
              <td align="center" rowspan="1" colspan="1">0.608560</td>
              <td align="char" char="." rowspan="1" colspan="1">0.504055</td>
              <td align="center" rowspan="1" colspan="1">0.515426</td>
              <td align="char" char="." rowspan="1" colspan="1">0.574869</td>
              <td align="center" rowspan="1" colspan="1">0.579472</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"> <italic>mixed</italic>
</td>
              <td align="char" char="." rowspan="1" colspan="1">0.656636</td>
              <td align="center" rowspan="1" colspan="1">0.656326</td>
              <td align="char" char="." rowspan="1" colspan="1">0.572109</td>
              <td align="center" rowspan="1" colspan="1">0.583003</td>
              <td align="char" char="." rowspan="1" colspan="1">0.623287</td>
              <td align="center" rowspan="1" colspan="1">0.624638</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"> <italic>mixedWP</italic>
</td>
              <td align="char" char="." rowspan="1" colspan="1">0.641843</td>
              <td align="center" rowspan="1" colspan="1">0.641940</td>
              <td align="char" char="." rowspan="1" colspan="1">0.585494</td>
              <td align="center" rowspan="1" colspan="1">0.612151</td>
              <td align="char" char="." rowspan="1" colspan="1">0.615885</td>
              <td align="center" rowspan="1" colspan="1">0.621419</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"> <italic>mixedCl</italic>
</td>
              <td align="char" char="." rowspan="1" colspan="1">
                <bold>0.660346</bold>
              </td>
              <td align="center" rowspan="1" colspan="1">
                <bold>0.659399</bold>
              </td>
              <td align="char" char="." rowspan="1" colspan="1">
                <bold>0.589960</bold>
              </td>
              <td align="center" rowspan="1" colspan="1">
                <bold>0.615694</bold>
              </td>
              <td align="char" char="." rowspan="1" colspan="1">
                <bold>0.626420</bold>
              </td>
              <td align="center" rowspan="1" colspan="1">
                <bold>0.631739</bold>
              </td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"> BM25</td>
              <td align="char" char="." rowspan="1" colspan="1">0.459375</td>
              <td align="center" rowspan="1" colspan="1">0.443034</td>
              <td align="char" char="." rowspan="1" colspan="1">0.464496</td>
              <td align="center" rowspan="1" colspan="1">0.487373</td>
              <td align="char" char="." rowspan="1" colspan="1">0.456505</td>
              <td align="center" rowspan="1" colspan="1">0.457420</td>
            </tr>
            <tr>
              <td colspan="7" align="left" rowspan="1">BioModels-CA</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"> <italic>macro</italic>
</td>
              <td align="char" char="." rowspan="1" colspan="1">0.345486</td>
              <td align="center" rowspan="1" colspan="1">0.340106</td>
              <td align="char" char="." rowspan="1" colspan="1">0.310285</td>
              <td align="center" rowspan="1" colspan="1">0.302129</td>
              <td align="char" char="." rowspan="1" colspan="1">0.356034</td>
              <td align="center" rowspan="1" colspan="1">0.347905</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"> <italic>macroWP</italic>
</td>
              <td align="char" char="." rowspan="1" colspan="1">0.330100</td>
              <td align="center" rowspan="1" colspan="1">0.326029</td>
              <td align="char" char="." rowspan="1" colspan="1">0.326831</td>
              <td align="center" rowspan="1" colspan="1">0.325134</td>
              <td align="char" char="." rowspan="1" colspan="1">0.365903</td>
              <td align="center" rowspan="1" colspan="1">0.362892</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"> <italic>micro</italic>
</td>
              <td align="char" char="." rowspan="1" colspan="1">0.294353</td>
              <td align="center" rowspan="1" colspan="1">0.291914</td>
              <td align="char" char="." rowspan="1" colspan="1">0.283026</td>
              <td align="center" rowspan="1" colspan="1">0.283291</td>
              <td align="char" char="." rowspan="1" colspan="1">0.312949</td>
              <td align="center" rowspan="1" colspan="1">0.309471</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"> <italic>microWP</italic>
</td>
              <td align="char" char="." rowspan="1" colspan="1">0.301564</td>
              <td align="center" rowspan="1" colspan="1">0.296179</td>
              <td align="char" char="." rowspan="1" colspan="1">0.274491</td>
              <td align="center" rowspan="1" colspan="1">0.271451</td>
              <td align="char" char="." rowspan="1" colspan="1">0.314506</td>
              <td align="center" rowspan="1" colspan="1">0.309211</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"> <italic>mixed</italic>
</td>
              <td align="char" char="." rowspan="1" colspan="1">0.347681</td>
              <td align="center" rowspan="1" colspan="1">0.345045</td>
              <td align="char" char="." rowspan="1" colspan="1">0.326664</td>
              <td align="center" rowspan="1" colspan="1">0.323393</td>
              <td align="char" char="." rowspan="1" colspan="1">0.370148</td>
              <td align="center" rowspan="1" colspan="1">0.365433</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"> <italic>mixedWP</italic>
</td>
              <td align="char" char="." rowspan="1" colspan="1">0.335051</td>
              <td align="center" rowspan="1" colspan="1">0.331222</td>
              <td align="char" char="." rowspan="1" colspan="1">0.<bold>344296</bold>
</td>
              <td align="center" rowspan="1" colspan="1">
                <bold>0.344932</bold>
              </td>
              <td align="char" char="." rowspan="1" colspan="1">0.379058</td>
              <td align="center" rowspan="1" colspan="1">
                <bold>0.377573</bold>
              </td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"> <italic>mixedCl</italic>
</td>
              <td align="char" char="." rowspan="1" colspan="1">
                <bold>0.348054</bold>
              </td>
              <td align="center" rowspan="1" colspan="1">
                <bold>0.344794</bold>
              </td>
              <td align="char" char="." rowspan="1" colspan="1">0.343567</td>
              <td align="center" rowspan="1" colspan="1">0.344058</td>
              <td align="char" char="." rowspan="1" colspan="1">
                <bold>0.379351</bold>
              </td>
              <td align="center" rowspan="1" colspan="1">0.377557</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"> BM25</td>
              <td align="char" char="." rowspan="1" colspan="1">0.240671</td>
              <td align="center" rowspan="1" colspan="1">0.231515</td>
              <td align="char" char="." rowspan="1" colspan="1">0.294758</td>
              <td align="center" rowspan="1" colspan="1">0.294779</td>
              <td align="char" char="." rowspan="1" colspan="1">0.280370</td>
              <td align="center" rowspan="1" colspan="1">0.277879</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn>
            <p>The values in bold are maximum performance measured on three sets of query-entity pairs using mAP@10 and mRR values.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p>Based on the type of data for testing, the retrieval results from the PMR are better than those from the BioModels database. This difference is due to the more significant number of biosimulation models in the BioModels database, about twice the PMR, but their entities need to be annotated with more precision. By limiting the search to entities that are considered fully annotated, the performance is almost the same, as shown in the <xref rid="s11" ref-type="sec">Supplementary Table S5</xref>.</p>
      <p>Illustrating the effect of different <italic>mAP@</italic>10 and <italic>mRR</italic> values, <xref rid="F5" ref-type="fig">Figure 5</xref> shows the top 10 retrievals of entities for three query examples retrieved using <italic>mixedCl</italic> and BM25. Search results are organised in order from the left-hand side to the right-hand side based on the similarity values between queries and entity results, starting from the highest one. Three query-entity pairs are used in the <italic>noPredicate</italic> set. For the first and the third queries, <italic>mixedCl</italic> and BM25 retrieve the same number of relevant entities, indicated by blue boxes; however, the <italic>mixedCl</italic> presents the relevant entities earlier than BM25. Measured using <italic>AP@</italic>10 and <italic>RR</italic>, <italic>mixedCl</italic> raises higher values with a large margin. For the second example, <italic>mixedCl</italic> can retrieve more relevant entities and rank better. Overall, the <italic>mAP@</italic>10 and <italic>mRR</italic> of <italic>mixedCl</italic> is higher than BM25. A higher <italic>mAP@</italic>10 and <italic>mRR</italic> provide a better search experience with relevant entities served earlier or more.</p>
      <fig position="float" id="F5">
        <label>FIGURE 5</label>
        <caption>
          <p>The presentation of search results differentiated by <italic>mAP@</italic>10 and <italic>mRR</italic> towards values. Blue boxes are relevant entities, while white boxes are irrelevant entities. <italic>mAP@</italic>10 and <italic>mRR</italic> are calculated from the results of the <italic>mixedCl</italic> and BM25 methods on the <italic>noPredicate</italic> query-entity pair set. Results are sorted in which entities with the higher similarity to the query are placed on the left-hand side. The results of the first and third queries are similar for both methods, but the use of <italic>mixedCl</italic>, with higher <italic>mAP@</italic>10 and <italic>mRR</italic>, can show relevant entities earlier than BM25.</p>
        </caption>
        <graphic xlink:href="fbinf-03-1107467-g005" position="float"/>
      </fig>
    </sec>
  </sec>
  <sec sec-type="discussion" id="s4">
    <title>4 Discussion</title>
    <p>We have demonstrated that the adaptation of BERT-based embedding to encode entities’ composite annotations and queries in CASBERT can surpass the performance of the standard bag-of-words methods. This better performance is closely related to how BERT tokenises an input sentence and converts the token into embedding. BERT implements WordPiece tokeniser (<xref rid="B35" ref-type="bibr">Wu et al., 2016</xref>), a subword-based tokenisation algorithm. This algorithm can adequately accommodate wording variations, spelling errors, and missing white space issues. Therefore, unique words in specific domains, such as biology, can be segmented into appropriate tokens. These tokens are then converted into embeddings. For the token embedding to be unique to the position and sentence sequence, the representation of a token as an embedding is combined with the positional embedding and sentence sequence embedding. Hence, this combination can appropriately represent a sentence. Moreover, this way of embedding contributes to the generation of similar embeddings for sentences with synonymy meanings.</p>
    <p>In the following subsections, we discuss CASBERT improvements, analysed based on different embedding generation methods. Then the discussion is followed by the possibility of implementing CASBERT in various domains and complementing SPARQL. Finally, we present our recommendations and future works.</p>
    <sec id="s4-1">
      <title>4.1 Performance increase</title>
      <p>As presented in <xref rid="T3" ref-type="table">Table 3</xref>, our proposed methods are quite effective in converting the entities’ composite annotations and queries to embeddings and retrieving relevant entities based on the provided query. The analysis of those methods and performance based on the similarity value between query and composite annotation is described below.</p>
      <sec id="s4-1-1">
        <title>4.1.1 Entity’s composite annotation to embedding methods</title>
        <p>We have experimented with creating entity embedding by considering predicates (0 &lt; <italic>w</italic>
<sub><italic>p</italic></sub> &lt; 1) and not (<italic>w</italic>
<sub><italic>p</italic></sub> = 0). Entity embeddings considering predicates are primarily suitable for queries containing the predicate terms or their synonyms; conversely, the ones without predicates usually are suitable for queries without predicate terms. This pattern is shown by the consecutive good measurement results of the <italic>mixedWP</italic> method on <italic>withPredicate</italic> set and the <italic>mixed</italic> method on <italic>noPredicate</italic> set. Intuitively, for high-performance retrieval, the entity embedding list selected should match the presence of predicate terms in the query. However, this approach will not outperform the <italic>mixedCl</italic> method since the average results of the stated evidence are lower than the average results of the <italic>mixedCl</italic> method on the same sets. This lower performance may be because the terms identified as predicates are unrelated to either the predicate or the ontology class. On the other hand, predicates that are not phrases, but are conjunctions and prepositions, cannot be detected, eliminating the possibility of selecting the proper entity embedding list. The <italic>mixedCl</italic> method uses the QC model to determine the query embedding list based on the overall query terms. The application of a BERT-based classifier for classification is proven to have better accuracy. Overall, <italic>mixedCl</italic> is best on nine measurements of <italic>mAP@</italic>10 and <italic>mRR</italic> and only slightly lower than the best of the other three (<xref rid="T3" ref-type="table">Table 3</xref>, bold values).</p>
        <p>While only two <italic>w</italic>
<sub><italic>p</italic></sub> values, 0 and 0.22, are used in this experiment, we predict that <italic>w</italic>
<sub><italic>p</italic></sub> should be adaptive to the query, so in the future, we recommend specifying <italic>w</italic>
<sub><italic>p</italic></sub> automatically. However, this adaptive <italic>w</italic>
<sub><italic>p</italic></sub> approach will sacrifice the simplicity of the current entity’s composite annotation list because ontology class and predicate embeddings should be separately managed, and there should be a mechanism to create entity embedding with given <italic>w</italic>
<sub><italic>p</italic></sub> value effectively.</p>
      </sec>
      <sec id="s4-1-2">
        <title>4.1.2 Query to embedding methods</title>
        <p>The empirical results show that the mixed scenario performs best, followed by macro and micro scenarios consecutively. The micro scenario is intended to detect phrases related to physiology and biochemical terms in a query and generate a query embedding by combining all phrase embeddings. However, the detection accuracy depends on the NER method’s performance in identifying the phrases and the query created by the user.</p>
        <p>The macro scenario is better than the micro scenario. This higher performance could be related to encoding whole query terms containing all phrases related to physiology and biochemical terms, including their relationship in a single embedding unit. However, individual phrases are not considered, allowing slight entity detection inaccuracies. Overall, this scenario is the most efficient because it only performs a one-step conversion from query to embedding, in contrast with the other scenarios that identify multiple phrases and convert to embeddings and then combine them.</p>
        <p>The mixed scenario can slightly increase <italic>mAP@</italic>10 and <italic>mRR</italic>. As expected, this merge takes good account of the <italic>macro</italic> scenarios’s advantages and emphasises the critical phrases provided in the query. To avoid the decisive role of the phrases related to physiology and biochemical terms, delimiting with <italic>w</italic>
<sub><italic>ph</italic></sub> (Eq. <xref rid="e4" ref-type="disp-formula">4</xref>) can give adequate proportion. Although this scenario is not the most efficient, its computational cost is linearly increased depending on the identified phrases. Due to its highest effectiveness, we recommend the mixed scenario to be implemented for composite annotation search.</p>
      </sec>
      <sec id="s4-1-3">
        <title>4.1.3 Performance analysis based on the similarity of query and Entity’s composite annotation</title>
        <p><xref rid="F6" ref-type="fig">Figure 6</xref> shows CASBERT’s ability in retrieving entities for various queries differentiated by their similarity to relevant entities for PMR-CA. We calculated the similarity directly using the query embedding generated with the <italic>macro</italic> method against the entity embedding. CASBERT performance is higher than BM25 when the similarity value is more than 0.3 and achieves the highest margin for similarity from 0.5 to 0.9, covering about 96% of the total test data. This pattern indicates CASBERT benefits because most user queries fall within this range. For very low query-entity similarity, 0.1 to 0.2, BM25 is better because a limited number of the same terms, one or two, can direct the query to relevant entities. In contrast, embedding in CASBERT may lead the query to entities with different terms but having the same context. Unfortunately, the combination of a low similarity value and the absence of a common term results in lower performance. Furthermore, we found a similar pattern for BioModels-CA, although we do not measure performance for low query-entity similarity values (see <xref rid="s11" ref-type="sec">Supplementary Figure S2</xref> and <xref rid="s11" ref-type="sec">Supplementary Table S5</xref>).</p>
        <fig position="float" id="F6">
          <label>FIGURE 6</label>
          <caption>
            <p>The relationship between the similarity of terms in the query with those in the entity to <italic>mAP@</italic>10 for PMR-CA. The number of entities is 4,652 and the number of test data is 509. Generally CASBERT is better than BM25 when the similarity value is 0.3 and above.</p>
          </caption>
          <graphic xlink:href="fbinf-03-1107467-g006" position="float"/>
        </fig>
      </sec>
    </sec>
    <sec id="s4-2">
      <title>4.2 Recommendations and future works</title>
      <sec id="s4-2-1">
        <title>4.2.1 Other domain implementation</title>
        <p>We have shown CASBERT can well represent compositely annotated entities as embeddings. Although the data we use come from a repository of biosimulation models, implementation in other domains such as chemistry, pharmacy or medicine is possible as long as they are annotated using RDF and have ontology dictionaries. The entity retrieval process is started by modifying the input query to embedding using the <italic>mixed</italic> method or <italic>macro</italic> method for more straightforward implementation and then measuring query-entity similarity using cosine similarity. Moreover, most of the BERT models we used are pre-trained models without further fine tuning, except query classification modes; therefore, the implementation in other domains with no training data is still accessible.</p>
      </sec>
      <sec id="s4-2-2">
        <title>4.2.2 Search engine implementation</title>
        <p>The embeddings representing entities now can be managed in a list of embeddings. The list is more straightforward than the standard indexing technique in search retrieval systems such as the inverted index. New embeddings can be easily attached to the list; even deletion, insertion, and replacement require only a minimum effort; therefore, overall maintenance will be cheaper. More importantly, we can avoid traditional search engine complexities, including preprocessing (stemming, case folding, stop word removal, spelling corrections, and lemmatisation), synonyms and abbreviations handlings.</p>
      </sec>
      <sec id="s4-2-3">
        <title>4.2.3 Cross repositories search</title>
        <p>We estimate that it is possible to find similar information from different repositories with the same domain. <xref rid="T4" ref-type="table">Table 4</xref> shows the example of two queries with their results from the PMR and the BioModels database. The query ‘concentration of triose phosphate in astrocyte’, ‘triose phosphate’ is correctly mapped to CHEBI:17138 in entities from both repositories, whereas ‘concentration’ and ‘astrocyte’ are mapped to different entities but with interrelated properties. Furthermore, the query ‘ammonium in cytoplasm’ also gives similar results with the mapping of ‘ammonium’ in entities from both queries was CHEBI:28938, while ‘cytoplasm’ as FMA:66836 (Portion of cytosol) in the PMR and GO:0005737 (cytoplasm) at the BioModels database. These results suggest that multiple repositories can be combined in a single search system to complement each other and be used for possible confirmation and reuse of models across repositories.</p>
        <table-wrap position="float" id="T4">
          <label>TABLE 4</label>
          <caption>
            <p>The example of entities retrieved from different repositories, the PMR and the BioModels database. Those entities have similarities in the ontology classes related to the queries.</p>
          </caption>
          <table frame="hsides" rules="groups">
            <thead valign="top">
              <tr>
                <th rowspan="2" align="center" colspan="1">
                  <bold>Query</bold>
                </th>
                <th colspan="2" align="center" rowspan="1">
                  <bold>Result</bold>
                </th>
              </tr>
              <tr>
                <th align="center" rowspan="1" colspan="1">
                  <bold>PMR</bold>
                </th>
                <th align="center" rowspan="1" colspan="1">
                  <bold>BioModels database</bold>
                </th>
              </tr>
            </thead>
            <tbody valign="top">
              <tr>
                <td align="left" rowspan="1" colspan="1">concentration of triose phosphate in astrocyte</td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>cloutier_2009.cellml#GAPg_GAPg</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>BIOMD0000000565.rdf#metaid_40</bold>
                </td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1"/>
                <td align="left" rowspan="1" colspan="1">FMA:54537 Astrocyte</td>
                <td align="left" rowspan="1" colspan="1">OPB:00592 Chemical molar flow rate</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1"/>
                <td align="left" rowspan="1" colspan="1">OPB:00340 Concentration of chemical</td>
                <td align="left" rowspan="1" colspan="1">CHEBI:32816 pyruvic acid</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1"/>
                <td align="left" rowspan="1" colspan="1">CHEBI:17138 glyceraldehyde 3-phosphate</td>
                <td align="left" rowspan="1" colspan="1">CHEBI:17138 glyceraldehyde 3-phosphate</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1"/>
                <td align="left" rowspan="1" colspan="1"/>
                <td align="left" rowspan="1" colspan="1">GO:0005829 cytosol</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">ammonium in cytoplasm</td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>weinstein_1995.cellml#Concentrations.C_int_NH4</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>BIOMD0000000470.rdf#metaid_1155</bold>
                </td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1"/>
                <td align="left" rowspan="1" colspan="1">OPB:00340 Concentration of chemical</td>
                <td align="left" rowspan="1" colspan="1">OPB:00592 Chemical molar flow rate</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1"/>
                <td align="left" rowspan="1" colspan="1">CHEBI:28938 ammonium</td>
                <td align="left" rowspan="1" colspan="1">CHEBI:28938 ammonium</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1"/>
                <td align="left" rowspan="1" colspan="1">FMA:66836 Portion of cytosol</td>
                <td align="left" rowspan="1" colspan="1">GO:0005576 extracellular region</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1"/>
                <td align="left" rowspan="1" colspan="1"/>
                <td align="left" rowspan="1" colspan="1">GO:0005737 cytoplasm</td>
              </tr>
            </tbody>
          </table>
          <table-wrap-foot>
            <fn>
              <p>The text in bold are the variable names obtained from the PMR and the BioModel database using the two queries given.</p>
            </fn>
          </table-wrap-foot>
        </table-wrap>
      </sec>
      <sec id="s4-2-4">
        <title>4.2.4 CASBERT for SPARQL</title>
        <p>SPARQL and CASBERT have a similar intent to get information from RDF documents. SPARQL is rigid and can extract precise details as long as the information about the ontology and structure of the RDF document is known. In comparison, CASBERT is relaxed in exploring information freely where ontology knowledge is not mandatory. Therefore, both methods are not interchangeable, but CASBERT can supplement SPARQL to understand the structure of the RDF document and the ontology classes involved.</p>
      </sec>
      <sec id="s4-2-5">
        <title>4.2.5 Future works</title>
        <p>We account for composite annotation structure and combine ontology class and predicate embeddings to calculate entity embedding. This combination involves two variables, <italic>m</italic>
<sub><italic>e</italic></sub> and <italic>w</italic>
<sub><italic>p</italic></sub>, whose values adjust the search object and possibly the query type for maximum performance. We have currently prototyped a search engine<xref rid="fn9" ref-type="fn"><sup>9</sup></xref> that, once deployed, can collect query logs containing user activities in searching. Using these logs, we can analyse user behaviour and the relationship between the query and the relevant entity. We thought that by leveraging this relation and applying a grid search, CASBERT could automatically determine the value combinations of <italic>m</italic>
<sub><italic>e</italic></sub> and <italic>w</italic>
<sub><italic>p</italic></sub>.</p>
        <p>We are leveraging a Transformers-based method, Sentence-BERT, to convert text into embeddings. As an alternative, there is InferSent (<xref rid="B7" ref-type="bibr">Conneau et al., 2017</xref>), based on Bi-LSTM, and universal Sentence Encoder (USE) (<xref rid="B4" ref-type="bibr">Cer et al., 2018</xref>), based on Deep Averaging Network (DAN) and Transformers. Sentence-BERT is superior for sentiment analysis tasks but inferior to USE for TREC data for query classification tasks (<xref rid="B22" ref-type="bibr">Reimers and Gurevych, 2019</xref>). For our purposes, we believe Sentence-BERT is better than other methods because of its better understanding of context. The tokens used are WordPieces (<xref rid="B27" ref-type="bibr">Schuster and Nakajima, 2012</xref>) rather than words, so they can more precisely represent unique words in the biosimulation modelling domain and are more resistant to typos. In comparison, the method using Bi-LSTM combines the two-way conversion results, from left to right and <italic>vice versa</italic>, which are calculated separately. However, we will implement some text-to-embedding conversion methods as an option, as LSTM-based methods may be better for performance in other small data and systems with CPU only. Moreover, we will compare their performance for various purposes using CASBERT.</p>
        <p>Further study in cross-repositories retrieval also needs to be considered; hence, it can promote reusability between repositories.</p>
      </sec>
    </sec>
  </sec>
  <sec sec-type="conclusion" id="s5">
    <title>5 Conclusion</title>
    <p>The increasing availability of composite annotation to describe entities in biosimulation models requires a simple tool to access information inside by ordinary users. We propose CASBERT, a BERT based method providing keyword-based searching that effectively manages composite annotations and retrieves entities using a text query. This effectiveness is achieved by converting the entities’ composite annotations to embeddings and organising them in a list; therefore, adding, deleting, inserting, and modifying embedding is cheaper. Getting relevant entities using a previously converted query to an embedding is straightforward with this structure. Using query-entities pairs test data extracted from the PMR and the BioModels database, empirically, CASBERT can retrieve better than bag-of-words methods such as BM25. It can potentially give a better user experience than the traditional approach. In the future, we are interested in developing a cross-repositories search engine to encourage biosimulation model reuse between different repositories.</p>
  </sec>
</body>
<back>
  <fn-group>
    <fn id="fn1">
      <label>1</label>
      <p><ext-link xlink:href="https://www.dbpedia.org/" ext-link-type="uri">https://www.dbpedia.org/</ext-link>.</p>
    </fn>
    <fn id="fn2">
      <label>2</label>
      <p><ext-link xlink:href="https://yago-knowledge.org" ext-link-type="uri">https://yago-knowledge.org</ext-link>.</p>
    </fn>
    <fn id="fn3">
      <label>3</label>
      <p><ext-link xlink:href="https://www.wikidata.org/" ext-link-type="uri">https://www.wikidata.org/</ext-link>.</p>
    </fn>
    <fn id="fn4">
      <label>4</label>
      <p><ext-link xlink:href="https://github.com/napakalas/casbert/" ext-link-type="uri">https://github.com/napakalas/casbert/</ext-link>.</p>
    </fn>
    <fn id="fn5">
      <label>5</label>
      <p><ext-link xlink:href="https://models.physiomeproject.org/workspace/5af/" ext-link-type="uri">https://models.physiomeproject.org/workspace/5af/</ext-link>.</p>
    </fn>
    <fn id="fn6">
      <label>6</label>
      <p>as of July 2020.</p>
    </fn>
    <fn id="fn7">
      <label>7</label>
      <p><ext-link xlink:href="https://github.com/napakalas/casbert-experiment/" ext-link-type="uri">https://github.com/napakalas/casbert-experiment/</ext-link>.</p>
    </fn>
    <fn id="fn8">
      <label>8</label>
      <p><ext-link xlink:href="https://github.com/makcedward/nlpaug" ext-link-type="uri">https://github.com/makcedward/nlpaug</ext-link>.</p>
    </fn>
    <fn id="fn9">
      <label>9</label>
      <p><ext-link xlink:href="https://github.com/napakalas/bmse/" ext-link-type="uri">https://github.com/napakalas/bmse/</ext-link>.</p>
    </fn>
  </fn-group>
  <sec sec-type="data-availability" id="s6">
    <title>Data availability statement</title>
    <p>Publicly available datasets were analyzed in this study. This data can be found here: <ext-link xlink:href="https://github.com/napakalas/casbert" ext-link-type="uri">https://github.com/napakalas/casbert</ext-link>.</p>
  </sec>
  <sec id="s7">
    <title>Author contributions</title>
    <p>YM, AR, and DN contributed to the conception and design of the study. YM implemented CASBERT, performed the analysis and wrote the first draft of the manuscript. All authors contributed to the testing and evaluation of CASBERT and wrote sections of the manuscript. All authors contributed to the manuscript revision, read and approved the submitted version.</p>
  </sec>
  <sec sec-type="COI-statement" id="s9">
    <title>Conflict of interest</title>
    <p>Author AR is employed by The New Zealand Institute for Plant &amp; Food Research Ltd.</p>
    <p>The remaining authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p>
  </sec>
  <sec sec-type="disclaimer" id="s10">
    <title>Publisher’s note</title>
    <p>All claims expressed in this article are solely those of the authors and do not necessarily represent those of their affiliated organizations, or those of the publisher, the editors and the reviewers. Any product that may be evaluated in this article, or claim that may be made by its manufacturer, is not guaranteed or endorsed by the publisher.</p>
  </sec>
  <sec id="s11">
    <title>Supplementary material</title>
    <p>The Supplementary Material for this article can be found online at: <ext-link xlink:href="https://www.frontiersin.org/articles/10.3389/fbinf.2023.1107467/full#supplementary-material" ext-link-type="uri">https://www.frontiersin.org/articles/10.3389/fbinf.2023.1107467/full#supplementary-material</ext-link>
</p>
    <supplementary-material id="SM1" position="float" content-type="local-data">
      <media xlink:href="DataSheet1.PDF">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
  <ref-list>
    <title>References</title>
    <ref id="B1">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Arora</surname><given-names>S.</given-names></name><name><surname>May</surname><given-names>A.</given-names></name><name><surname>Zhang</surname><given-names>J.</given-names></name><name><surname>Ré</surname><given-names>C.</given-names></name></person-group> (<year>2020</year>). <source>Contextual embeddings: When are they worth it?</source>
<comment><italic>arXiv:2005.09117 [cs]</italic></comment>. <comment>ArXiv:2005.09117 [cs]</comment>. <pub-id pub-id-type="doi">10.48550/arXiv.2005.09117</pub-id>
</mixed-citation>
    </ref>
    <ref id="B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bassingthwaighte</surname><given-names>J. B.</given-names></name></person-group> (<year>2000</year>). <article-title>Strategies for the physiome project</article-title>. <source>Ann. Biomed. Eng.</source>
<volume>28</volume>, <fpage>1043</fpage>–<lpage>1058</lpage>. <pub-id pub-id-type="doi">10.1114/1.1313771</pub-id>
<pub-id pub-id-type="pmid">11144666</pub-id></mixed-citation>
    </ref>
    <ref id="B3">
      <mixed-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Bromley</surname><given-names>J.</given-names></name><name><surname>Guyon</surname><given-names>I.</given-names></name><name><surname>LeCun</surname><given-names>Y.</given-names></name><name><surname>Säckinger</surname><given-names>E.</given-names></name><name><surname>Shah</surname><given-names>R.</given-names></name></person-group> (<year>1993</year>). “<article-title>Signature verification using a ”Siamese” time delay neural network</article-title>,” in <conf-name>NIPS’93: Proceedings of the 6th International Conference on Neural Information Processing Systems</conf-name> (<publisher-loc>San Francisco, CA, USA</publisher-loc>: <publisher-name>Morgan Kaufmann Publishers Inc.</publisher-name>), <fpage>737</fpage>–<lpage>744</lpage>.</mixed-citation>
    </ref>
    <ref id="B4">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Cer</surname><given-names>D.</given-names></name><name><surname>Yang</surname><given-names>Y.</given-names></name><name><surname>Kong</surname><given-names>S. Y.</given-names></name><name><surname>Hua</surname><given-names>N.</given-names></name><name><surname>Limtiaco</surname><given-names>N.</given-names></name><name><surname>John</surname><given-names>R. S.</given-names></name><etal/></person-group> (<year>2018</year>). <source>Universal sentence encoder</source>. <comment>ArXiv:1803.11175 [cs]</comment>. <pub-id pub-id-type="doi">10.48550/arXiv.1803.11175</pub-id>
</mixed-citation>
    </ref>
    <ref id="B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chelliah</surname><given-names>V.</given-names></name><name><surname>Juty</surname><given-names>N.</given-names></name><name><surname>Ajmera</surname><given-names>I.</given-names></name><name><surname>Ali</surname><given-names>R.</given-names></name><name><surname>Dumousseau</surname><given-names>M.</given-names></name><name><surname>Glont</surname><given-names>M.</given-names></name><etal/></person-group> (<year>2015</year>). <article-title>BioModels: Ten-year anniversary</article-title>. <source>Nucleic Acids Res.</source>
<volume>43</volume>, <fpage>D542</fpage>–<lpage>D548</lpage>. <pub-id pub-id-type="doi">10.1093/nar/gku1181</pub-id>
<pub-id pub-id-type="pmid">25414348</pub-id></mixed-citation>
    </ref>
    <ref id="B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cloutier</surname><given-names>M.</given-names></name><name><surname>Bolger</surname><given-names>F. B.</given-names></name><name><surname>Lowry</surname><given-names>J. P.</given-names></name><name><surname>Wellstead</surname><given-names>P.</given-names></name></person-group> (<year>2009</year>). <article-title>An integrative dynamic model of brain energy metabolism using <italic>in vivo</italic> neurochemical measurements</article-title>. <source>J. Comput. Neurosci.</source>
<volume>27</volume>, <fpage>391</fpage>–<lpage>414</lpage>. <pub-id pub-id-type="doi">10.1007/s10827-009-0152-8</pub-id>
<pub-id pub-id-type="pmid">19396534</pub-id></mixed-citation>
    </ref>
    <ref id="B7">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Conneau</surname><given-names>A.</given-names></name><name><surname>Kiela</surname><given-names>D.</given-names></name><name><surname>Schwenk</surname><given-names>H.</given-names></name><name><surname>Barrault</surname><given-names>L.</given-names></name><name><surname>Bordes</surname><given-names>A.</given-names></name></person-group> (<year>2017</year>). <source>Supervised learning of universal sentence representations from natural language inference data</source>. <comment><italic>arXiv preprint arXiv:1705.02364</italic></comment>.</mixed-citation>
    </ref>
    <ref id="B8">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cook</surname><given-names>D. L.</given-names></name><name><surname>Mejino</surname><given-names>J. L. V.</given-names></name><name><surname>Neal</surname><given-names>M. L.</given-names></name><name><surname>Gennari</surname><given-names>J. H.</given-names></name></person-group> (<year>2008</year>). <article-title>Bridging biological ontologies and biosimulation: The ontology of physics for biology</article-title>. <source>AMIA Annu. Symp. Proc.</source>
<volume>2008</volume>, <fpage>136</fpage>–<lpage>140</lpage>.<pub-id pub-id-type="pmid">18999003</pub-id></mixed-citation>
    </ref>
    <ref id="B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cuellar</surname><given-names>A. A.</given-names></name><name><surname>Lloyd</surname><given-names>C. M.</given-names></name><name><surname>Nielsen</surname><given-names>P. F.</given-names></name><name><surname>Bullivant</surname><given-names>D. P.</given-names></name><name><surname>Nickerson</surname><given-names>D. P.</given-names></name><name><surname>Hunter</surname><given-names>P. J.</given-names></name></person-group> (<year>2003</year>). <article-title>An overview of CellML 1.1, a biological model description language</article-title>. <source>Simulation</source>
<volume>79</volume>, <fpage>740</fpage>–<lpage>747</lpage>. <pub-id pub-id-type="doi">10.1177/0037549703040939</pub-id>
</mixed-citation>
    </ref>
    <ref id="B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Degtyarenko</surname><given-names>K.</given-names></name><name><surname>de Matos</surname><given-names>P.</given-names></name><name><surname>Ennis</surname><given-names>M.</given-names></name><name><surname>Hastings</surname><given-names>J.</given-names></name><name><surname>Zbinden</surname><given-names>M.</given-names></name><name><surname>McNaught</surname><given-names>A.</given-names></name><etal/></person-group> (<year>2008</year>). <article-title>ChEBI: A database and ontology for chemical entities of biological interest</article-title>. <source>Nucleic Acids Res.</source>
<volume>36</volume>, <fpage>D344</fpage>–<lpage>D350</lpage>. <pub-id pub-id-type="doi">10.1093/nar/gkm791</pub-id>
<pub-id pub-id-type="pmid">17932057</pub-id></mixed-citation>
    </ref>
    <ref id="B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Devlin</surname><given-names>J.</given-names></name><name><surname>Chang</surname><given-names>M. W.</given-names></name><name><surname>Lee</surname><given-names>K.</given-names></name><name><surname>Toutanova</surname><given-names>K.</given-names></name></person-group> (<year>2018</year>). <article-title>Bert: Pre-training of deep bidirectional transformers for language understanding</article-title>. <comment><italic>arXiv preprint arXiv:1810.04805</italic> Tex.ids= devlin_bert_2019 arXiv: 1810.04805</comment>
</mixed-citation>
    </ref>
    <ref id="B12">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Garny</surname><given-names>A.</given-names></name><name><surname>Hunter</surname><given-names>P. J.</given-names></name></person-group> (<year>2015</year>). <article-title>OpenCOR: A modular and interoperable approach to computational biology</article-title>. <source>Front. Physiology</source>
<volume>6</volume>, <fpage>26</fpage>. <pub-id pub-id-type="doi">10.3389/fphys.2015.00026</pub-id>
</mixed-citation>
    </ref>
    <ref id="B13">
      <mixed-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Gehring</surname><given-names>J.</given-names></name><name><surname>Auli</surname><given-names>M.</given-names></name><name><surname>Grangier</surname><given-names>D.</given-names></name><name><surname>Yarats</surname><given-names>D.</given-names></name><name><surname>Dauphin</surname><given-names>Y. N.</given-names></name></person-group> (<year>2017</year>). “<article-title>Convolutional sequence to sequence learning</article-title>,” in <conf-name>Proceedings of the 34th International Conference on Machine Learning (PMLR)</conf-name>, <conf-loc>Sydney, Australia</conf-loc>, <fpage>1243</fpage>–<lpage>1252</lpage>. <comment>ISSN: 2640-3498</comment>.</mixed-citation>
    </ref>
    <ref id="B14">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gennari</surname><given-names>J. H.</given-names></name><name><surname>König</surname><given-names>M.</given-names></name><name><surname>Misirli</surname><given-names>G.</given-names></name><name><surname>Neal</surname><given-names>M. L.</given-names></name><name><surname>Nickerson</surname><given-names>D. P.</given-names></name><name><surname>Waltemath</surname><given-names>D.</given-names></name></person-group> (<year>2021</year>). <article-title>OMEX metadata specification (version 1.2)</article-title>. <source>J. Integr. Bioinforma.</source>
<volume>18</volume>, <fpage>20210020</fpage>. <pub-id pub-id-type="doi">10.1515/jib-2021-0020</pub-id>
</mixed-citation>
    </ref>
    <ref id="B15">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gennari</surname><given-names>J. H.</given-names></name><name><surname>Neal</surname><given-names>M. L.</given-names></name><name><surname>Galdzicki</surname><given-names>M.</given-names></name><name><surname>Cook</surname><given-names>D. L.</given-names></name></person-group> (<year>2011</year>). <article-title>Multiple ontologies in action: Composite annotations for biosimulation models</article-title>. <source>J. Biomed. Inf.</source>
<volume>44</volume>, <fpage>146</fpage>–<lpage>154</lpage>. <pub-id pub-id-type="doi">10.1016/j.jbi.2010.06.007</pub-id>
</mixed-citation>
    </ref>
    <ref id="B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hucka</surname><given-names>M.</given-names></name><name><surname>Finney</surname><given-names>A.</given-names></name><name><surname>Sauro</surname><given-names>H. M.</given-names></name><name><surname>Bolouri</surname><given-names>H.</given-names></name><name><surname>Doyle</surname><given-names>J. C.</given-names></name><name><surname>Kitano</surname><given-names>H.</given-names></name><etal/></person-group> (<year>2003</year>). <article-title>The systems biology markup language (SBML): A medium for representation and exchange of biochemical network models</article-title>. <source>Bioinformatics</source>
<volume>19</volume>, <fpage>524</fpage>–<lpage>531</lpage>. <pub-id pub-id-type="doi">10.1093/bioinformatics/btg015</pub-id>
<pub-id pub-id-type="pmid">12611808</pub-id></mixed-citation>
    </ref>
    <ref id="B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hunter</surname><given-names>P.</given-names></name><name><surname>Robbins</surname><given-names>P.</given-names></name><name><surname>Noble</surname><given-names>D.</given-names></name></person-group> (<year>2002</year>). <article-title>The IUPS human physiome project</article-title>. <source>Pflügers Arch.</source>
<volume>445</volume>, <fpage>1</fpage>–<lpage>9</lpage>. <pub-id pub-id-type="doi">10.1007/s00424-002-0890-1</pub-id>
<pub-id pub-id-type="pmid">12397380</pub-id></mixed-citation>
    </ref>
    <ref id="B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Munarko</surname><given-names>Y.</given-names></name><name><surname>Sarwar</surname><given-names>D. M.</given-names></name><name><surname>Rampadarath</surname><given-names>A.</given-names></name><name><surname>Atalag</surname><given-names>K.</given-names></name><name><surname>Gennari</surname><given-names>J. H.</given-names></name><name><surname>Neal</surname><given-names>M. L.</given-names></name><etal/></person-group> (<year>2022</year>). <article-title>NLIMED: Natural Language Interface for model entity discovery in biosimulation model repositories</article-title>. <source>Front. Physiology</source>
<volume>13</volume>, <fpage>820683</fpage>. <pub-id pub-id-type="doi">10.3389/fphys.2022.820683</pub-id>
</mixed-citation>
    </ref>
    <ref id="B19">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Neal</surname><given-names>M. L.</given-names></name><name><surname>König</surname><given-names>M.</given-names></name><name><surname>Nickerson</surname><given-names>D.</given-names></name><name><surname>Mısırlı</surname><given-names>G.</given-names></name><name><surname>Kalbasi</surname><given-names>R.</given-names></name><name><surname>Dräger</surname><given-names>A.</given-names></name><etal/></person-group> (<year>2019</year>). <article-title>Harmonizing semantic annotations for computational models in biology</article-title>. <source>Briefings Bioinforma.</source>
<volume>20</volume>, <fpage>540</fpage>–<lpage>550</lpage>. <pub-id pub-id-type="doi">10.1093/bib/bby087</pub-id>
</mixed-citation>
    </ref>
    <ref id="B20">
      <mixed-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Neumann</surname><given-names>M.</given-names></name><name><surname>King</surname><given-names>D.</given-names></name><name><surname>Beltagy</surname><given-names>I.</given-names></name><name><surname>Ammar</surname><given-names>W.</given-names></name></person-group> (<year>2019</year>). “<article-title>ScispaCy: Fast and robust models for biomedical Natural Language processing</article-title>,” in <conf-name>Proceedings of the 18th BioNLP Workshop and Shared Task</conf-name> (<publisher-loc>Florence, Italy</publisher-loc>: <publisher-name>Association for Computational Linguistics</publisher-name>), <fpage>319</fpage>–<lpage>327</lpage>. <comment>ArXiv: 1902.07669</comment>. <pub-id pub-id-type="doi">10.18653/v1/W19-5034</pub-id>
</mixed-citation>
    </ref>
    <ref id="B21">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pérez</surname><given-names>J.</given-names></name><name><surname>Arenas</surname><given-names>M.</given-names></name><name><surname>Gutierrez</surname><given-names>C.</given-names></name></person-group> (<year>2009</year>). <article-title>Semantics and complexity of SPARQL</article-title>. <source>ACM Trans. Database Syst.</source>
<volume>34</volume>, <fpage>1:1</fpage>–<lpage>16:45</lpage>. <pub-id pub-id-type="doi">10.1145/1567274.1567278</pub-id>
</mixed-citation>
    </ref>
    <ref id="B22">
      <mixed-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Reimers</surname><given-names>N.</given-names></name><name><surname>Gurevych</surname><given-names>I.</given-names></name></person-group> (<year>2019</year>). “<article-title>Sentence-BERT: Sentence embeddings using siamese BERT-networks</article-title>,” in <conf-name>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing</conf-name> (<publisher-loc>Florence, Italy</publisher-loc>: <publisher-name>Association for Computational Linguistics</publisher-name>).</mixed-citation>
    </ref>
    <ref id="B23">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Robertson</surname><given-names>S. E.</given-names></name><name><surname>Walker</surname><given-names>S.</given-names></name></person-group> (<year>1994</year>). “<article-title>Some simple effective approximations to the 2-Poisson model for probabilistic weighted retrieval</article-title>,” in <source>SIGIR ’94</source>. Editors <person-group person-group-type="editor"><name><surname>Croft,</surname><given-names>B. W.</given-names></name><name><surname>van Rijsbergen</surname><given-names>C. J.</given-names></name></person-group> (<publisher-loc>London</publisher-loc>: <publisher-name>Springer</publisher-name>), <fpage>232</fpage>–<lpage>241</lpage>.</mixed-citation>
    </ref>
    <ref id="B24">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Rosse</surname><given-names>C.</given-names></name><name><surname>Mejino</surname><given-names>J. L. V.</given-names></name></person-group> (<year>2008</year>). “<article-title>The foundational model of anatomy ontology</article-title>,” in <source>Anatomy ontologies for Bioinformatics: Principles and practice</source>. <source>Computational biology</source>. Editors <person-group person-group-type="editor"><name><surname>Burger</surname><given-names>A.</given-names></name><name><surname>Davidson</surname><given-names>D.</given-names></name><name><surname>Baldock</surname><given-names>R.</given-names></name></person-group> (<publisher-loc>London</publisher-loc>: <publisher-name>Springer</publisher-name>), <fpage>59</fpage>–<lpage>117</lpage>. <pub-id pub-id-type="doi">10.1007/978-1-84628-885-2_4</pub-id>
</mixed-citation>
    </ref>
    <ref id="B25">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Salton</surname><given-names>G.</given-names></name><name><surname>McGill</surname><given-names>M. J.</given-names></name></person-group> (<year>1983</year>). <source>Introduction to modern information retrieval</source>. <publisher-loc>New York, NY, USA</publisher-loc>: <publisher-name>McGraw-Hill</publisher-name>.</mixed-citation>
    </ref>
    <ref id="B26">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sarwar</surname><given-names>D. M.</given-names></name><name><surname>Kalbasi</surname><given-names>R.</given-names></name><name><surname>Gennari</surname><given-names>J. H.</given-names></name><name><surname>Carlson</surname><given-names>B. E.</given-names></name><name><surname>Neal</surname><given-names>M. L.</given-names></name><name><surname>Bono</surname><given-names>B. d.</given-names></name><etal/></person-group> (<year>2019</year>). <article-title>Model annotation and discovery with the physiome model repository</article-title>. <source>BMC Bioinforma.</source>
<volume>20</volume>, <fpage>457</fpage>. <pub-id pub-id-type="doi">10.1186/s12859-019-2987-y</pub-id>
</mixed-citation>
    </ref>
    <ref id="B27">
      <mixed-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Schuster</surname><given-names>M.</given-names></name><name><surname>Nakajima</surname><given-names>K.</given-names></name></person-group> (<year>2012</year>). “<article-title>Japanese and Korean voice search</article-title>,” in <conf-name>2012 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</conf-name> (<publisher-loc>Kyoto, Japan</publisher-loc>: <publisher-name>IEEE</publisher-name>), <fpage>5149</fpage>–<lpage>5152</lpage>. <comment>ISSN: 2379-190X</comment>. <pub-id pub-id-type="doi">10.1109/ICASSP.2012.6289079</pub-id>
</mixed-citation>
    </ref>
    <ref id="B28">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Soru</surname><given-names>T.</given-names></name><name><surname>Marx</surname><given-names>E.</given-names></name><name><surname>Moussallem</surname><given-names>D.</given-names></name><name><surname>Publio</surname><given-names>G.</given-names></name><name><surname>Valdestilhas</surname><given-names>A.</given-names></name><name><surname>Esteves</surname><given-names>D.</given-names></name><etal/></person-group> (<year>2020</year>). <source>SPARQL as a foreign language</source>. <comment><italic>arXiv:1708.07624 [cs]</italic> ArXiv: 1708.07624</comment>.</mixed-citation>
    </ref>
    <ref id="B29">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Taillé</surname><given-names>B.</given-names></name><name><surname>Guigue</surname><given-names>V.</given-names></name><name><surname>Gallinari</surname><given-names>P.</given-names></name></person-group> (<year>2020</year>). “<article-title>Contextualized embeddings in named-entity recognition: An empirical study on generalization</article-title>,” in <source>Advances in information retrieval</source> (<publisher-loc>Cham</publisher-loc>: <publisher-name>Springer</publisher-name>), <fpage>383</fpage>–<lpage>391</lpage>. <pub-id pub-id-type="doi">10.1007/978-3-030-45442-5_48</pub-id>
</mixed-citation>
    </ref>
    <ref id="B30">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Tran</surname><given-names>H.</given-names></name><name><surname>Phan</surname><given-names>L.</given-names></name><name><surname>Anibal</surname><given-names>J.</given-names></name><name><surname>Nguyen</surname><given-names>B. T.</given-names></name><name><surname>Nguyen</surname><given-names>T.-S.</given-names></name></person-group> (<year>2021</year>). “<article-title>SPBERT: An efficient pre-training BERT on SPARQL queries for question answering over knowledge graphs</article-title>,” in <source>Neural information processing</source>. <source>Lecture notes in computer science</source>. Editors <person-group person-group-type="editor"><name><surname>Mantoro</surname><given-names>T.</given-names></name><name><surname>Lee</surname><given-names>M.</given-names></name><name><surname>Ayu</surname><given-names>M. A.</given-names></name><name><surname>Wong</surname><given-names>K. W.</given-names></name><name><surname>Hidayanto</surname><given-names>A. N.</given-names></name></person-group> (<publisher-loc>Cham</publisher-loc>: <publisher-name>Springer International Publishing</publisher-name>), <fpage>512</fpage>–<lpage>523</lpage>. <pub-id pub-id-type="doi">10.1007/978-3-030-92185-9_42</pub-id>
</mixed-citation>
    </ref>
    <ref id="B31">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Vaswani</surname><given-names>A.</given-names></name><name><surname>Shazeer</surname><given-names>N.</given-names></name><name><surname>Parmar</surname><given-names>N.</given-names></name><name><surname>Uszkoreit</surname><given-names>J.</given-names></name><name><surname>Jones</surname><given-names>L.</given-names></name><name><surname>Gomez</surname><given-names>A. N.</given-names></name><etal/></person-group> (<year>2017</year>). “<article-title>Attention is all you need</article-title>,” in <source>Advances in neural information processing systems</source> (<publisher-loc>Red Hook, NY, USA</publisher-loc>: <publisher-name>Curran Associates, Inc.</publisher-name>), <volume>Vol. 30</volume>.</mixed-citation>
    </ref>
    <ref id="B32">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Weinberger</surname><given-names>K. Q.</given-names></name><name><surname>Saul</surname><given-names>L. K.</given-names></name></person-group> (<year>2009</year>). <article-title>Distance metric learning for large margin nearest neighbor classification</article-title>. <source>J. Mach. Learn. Res.</source>
<volume>10</volume>, <fpage>207</fpage>–<lpage>244</lpage>.</mixed-citation>
    </ref>
    <ref id="B33">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Welsh</surname><given-names>C.</given-names></name><name><surname>Nickerson</surname><given-names>D. P.</given-names></name><name><surname>Rampadarath</surname><given-names>A.</given-names></name><name><surname>Neal</surname><given-names>M. L.</given-names></name><name><surname>Sauro</surname><given-names>H. M.</given-names></name><name><surname>Gennari</surname><given-names>J. H.</given-names></name></person-group> (<year>2021</year>). <article-title>libOmexMeta: enabling semantic annotation of models to support FAIR principles</article-title>. <source>Bioinformatics</source>
<volume>37</volume>, <fpage>4898</fpage>–<lpage>4900</lpage>. <pub-id pub-id-type="doi">10.1093/bioinformatics/btab445</pub-id>
<pub-id pub-id-type="pmid">34132740</pub-id></mixed-citation>
    </ref>
    <ref id="B34">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Wolf</surname><given-names>T.</given-names></name><name><surname>Debut</surname><given-names>L.</given-names></name><name><surname>Sanh</surname><given-names>V.</given-names></name><name><surname>Chaumond</surname><given-names>J.</given-names></name><name><surname>Delangue</surname><given-names>C.</given-names></name><name><surname>Moi</surname><given-names>A.</given-names></name><etal/></person-group> (<year>2020</year>). <source>HuggingFace’s transformers: State-of-the-art Natural Language processing</source>. <comment><italic>arXiv:1910.03771 [cs]</italic> ArXiv: 1910.03771</comment>.</mixed-citation>
    </ref>
    <ref id="B35">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Wu</surname><given-names>Y.</given-names></name><name><surname>Schuster</surname><given-names>M.</given-names></name><name><surname>Chen</surname><given-names>Z.</given-names></name><name><surname>Le</surname><given-names>Q. V.</given-names></name><name><surname>Norouzi</surname><given-names>M.</given-names></name><name><surname>Macherey</surname><given-names>W.</given-names></name><etal/></person-group> (<year>2016</year>). <source>Google’s neural machine translation system: Bridging the gap between human and machine translation</source>. <comment><italic>arXiv:1609.08144 [cs]</italic> ArXiv: 1609.08144</comment>.</mixed-citation>
    </ref>
    <ref id="B36">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yin</surname><given-names>X.</given-names></name><name><surname>Gromann</surname><given-names>D.</given-names></name><name><surname>Rudolph</surname><given-names>S.</given-names></name></person-group> (<year>2021</year>). <article-title>Neural machine translating from natural language to SPARQL</article-title>. <source>Future Gener. Comput. Syst.</source>
<volume>117</volume>, <fpage>510</fpage>–<lpage>519</lpage>. <pub-id pub-id-type="doi">10.1016/j.future.2020.12.013</pub-id>
</mixed-citation>
    </ref>
    <ref id="B37">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yu</surname><given-names>T.</given-names></name><name><surname>Lloyd</surname><given-names>C. M.</given-names></name><name><surname>Nickerson</surname><given-names>D. P.</given-names></name><name><surname>Cooling</surname><given-names>M. T.</given-names></name><name><surname>Miller</surname><given-names>A. K.</given-names></name><name><surname>Garny</surname><given-names>A.</given-names></name><etal/></person-group> (<year>2011</year>). <article-title>The physiome model repository 2</article-title>. <source>Bioinformatics</source>
<volume>27</volume>, <fpage>743</fpage>–<lpage>744</lpage>. <pub-id pub-id-type="doi">10.1093/bioinformatics/btq723</pub-id>
<pub-id pub-id-type="pmid">21216774</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
