<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 2?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">BMC Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">BMC Bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>BMC Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1471-2105</issn>
    <publisher>
      <publisher-name>BioMed Central</publisher-name>
      <publisher-loc>London</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">5053080</article-id>
    <article-id pub-id-type="publisher-id">1287</article-id>
    <article-id pub-id-type="doi">10.1186/s12859-016-1287-z</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Methodology Article</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Boolean regulatory network reconstruction using literature based knowledge with a genetic algorithm optimization method</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-6717-2451</contrib-id>
        <name>
          <surname>Dorier</surname>
          <given-names>Julien</given-names>
        </name>
        <address>
          <email>julien.dorier@sib.swiss</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Crespo</surname>
          <given-names>Isaac</given-names>
        </name>
        <address>
          <email>isaac.crespo@sib.swiss</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Niknejad</surname>
          <given-names>Anne</given-names>
        </name>
        <address>
          <email>Anne.Niknejad@sib.swiss</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Liechti</surname>
          <given-names>Robin</given-names>
        </name>
        <address>
          <email>Robin.Liechti@sib.swiss</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Ebeling</surname>
          <given-names>Martin</given-names>
        </name>
        <address>
          <email>martin.ebeling@roche.com</email>
        </address>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Xenarios</surname>
          <given-names>Ioannis</given-names>
        </name>
        <address>
          <email>ioannis.xenarios@sib.swiss</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <aff id="Aff1"><label>1</label>Vital-IT, Systems biology and medicine department, SIB Swiss Institute of Bioinformatics, 1015 Lausanne, Switzerland </aff>
      <aff id="Aff2"><label>2</label>Pharmaceutical Sciences/Translational Technologies and Bioinformatics, Roche Innovation Center Basel, 124 Grenzacherstrasse, 4070 Basel, Switzerland </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>6</day>
      <month>10</month>
      <year>2016</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>6</day>
      <month>10</month>
      <year>2016</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2016</year>
    </pub-date>
    <volume>17</volume>
    <elocation-id>410</elocation-id>
    <history>
      <date date-type="received">
        <day>16</day>
        <month>3</month>
        <year>2016</year>
      </date>
      <date date-type="accepted">
        <day>29</day>
        <month>9</month>
        <year>2016</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s). 2016</copyright-statement>
      <license license-type="OpenAccess">
        <license-p><bold>Open Access</bold>This article is distributed under the terms of the Creative Commons Attribution 4.0 International License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted use, distribution, and reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/publicdomain/zero/1.0/">http://creativecommons.org/publicdomain/zero/1.0/</ext-link>) applies to the data made available in this article, unless otherwise stated.</license-p>
      </license>
    </permissions>
    <abstract id="Abs1">
      <sec>
        <title>Background</title>
        <p>Prior knowledge networks (PKNs) provide a framework for the development of computational biological models, including Boolean models of regulatory networks which are the focus of this work. PKNs are created by a painstaking process of literature curation, and generally describe all relevant regulatory interactions identified using a variety of experimental conditions and systems, such as specific cell types or tissues. Certain of these regulatory interactions may not occur in all biological contexts of interest, and their presence may dramatically change the dynamical behaviour of the resulting computational model, hindering the elucidation of the underlying mechanisms and reducing the usefulness of model predictions. Methods are therefore required to generate optimized contextual network models from generic PKNs.</p>
      </sec>
      <sec>
        <title>Results</title>
        <p>We developed a new approach to generate and optimize Boolean networks, based on a given PKN. Using a genetic algorithm, a model network is built as a sub-network of the PKN and trained against experimental data to reproduce the experimentally observed behaviour in terms of attractors and the transitions that occur between them under specific perturbations. The resulting model network is therefore contextualized to the experimental conditions and constitutes a dynamical Boolean model closer to the observed biological process used to train the model than the original PKN. Such a model can then be interrogated to simulate response under perturbation, to detect stable states and their properties, to get insights into the underlying mechanisms and to generate new testable hypotheses.</p>
      </sec>
      <sec>
        <title>Conclusions</title>
        <p>Generic PKNs attempt to synthesize knowledge of all interactions occurring in a biological process of interest, irrespective of the specific biological context. This limits their usefulness as a basis for the development of context-specific, predictive dynamical Boolean models. The optimization method presented in this article produces specific, contextualized models from generic PKNs. These contextualized models have improved utility for hypothesis generation and experimental design. The general applicability of this methodological approach makes it suitable for a variety of biological systems and of general interest for biological and medical research. Our method was implemented in the software optimusqual, available online at <ext-link ext-link-type="uri" xlink:href="http://www.vital-it.ch/software/optimusqual/">http://www.vital-it.ch/software/optimusqual/</ext-link>.</p>
      </sec>
      <sec>
        <title>Electronic supplementary material</title>
        <p>The online version of this article (doi:10.1186/s12859-016-1287-z) contains supplementary material, which is available to authorized users.</p>
      </sec>
    </abstract>
    <kwd-group xml:lang="en">
      <title>Keywords</title>
      <kwd>Boolean regulatory networks</kwd>
      <kwd>Qualitative modeling</kwd>
      <kwd>Network inference</kwd>
      <kwd>Optimization</kwd>
      <kwd>Genetic algorithm</kwd>
      <kwd>Prior knowledge network</kwd>
    </kwd-group>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>© The Author(s) 2016</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="Sec1" sec-type="introduction">
    <title>Background</title>
    <p>High-throughput technologies in different areas of biomedical research provide massive amounts of data that are difficult to organize and interpret. Network-based representations of biological systems have become a popular way to structure and analyse this information. Networks can be inferred directly from experimental data or created from prior knowledge – Prior Knowledge Networks (PKN). Both strategies have their advantages and disadvantages. PKNs are normally not context-specific, as they usually include all regulatory interactions relevant to the process under study, and may be biased towards biological entities and interactions that are intensively studied, or merge interactions measured under different experimental conditions, including different cell types or tissues. Networks inferred exclusively from high-throughput data (such as transcriptomic or proteomic data) may be more comprehensive and more contextualized to the experimental conditions of interest, but they do not provide direct information about causal relationships, i.e., directionality, as they are usually based on the statistical co-occurrence of biological events (for example, co-expression of two genes). The underlying causality can be elucidated only for a reduced number of cases by costly perturbation experiments or time series data.</p>
    <p>In an attempt to overcome the drawbacks of these two network construction strategies, several methods combining both prior knowledge and experimental data have been developed during the last years. Among these methods, we distinguish those that exhaustively explore the search space in order to identify an optimal configuration that explains the experimental data - combinatorial optimization methods - from those based on a heuristic approach. Combinatorial optimization methods include those based on integer programming [<xref ref-type="bibr" rid="CR1">1</xref>–<xref ref-type="bibr" rid="CR4">4</xref>] or answer set programming [<xref ref-type="bibr" rid="CR5">5</xref>]. Their computational complexity grows exponentially with the network size, limiting their applicability to small systems. Heuristic approaches that attempt to overcome these limitations can be divided into those that focus on describing the response of the system to perturbations and those that focus on describing the stable states of the system. Heuristic contextualization methods that focus on describing the response of the system to perturbations require multiple perturbation experiments to train the PKN. Saez-Rodriguez et al. [<xref ref-type="bibr" rid="CR6">6</xref>] proposed discrete logic modelling to curate and expand canonical signalling pathways using information from perturbation experiments to train the model. Irit Gat-Viks et al. [<xref ref-type="bibr" rid="CR7">7</xref>] developed a similar method to construct discrete dynamical models from a PKN that include feedback loops, transforming the original graph into multiple acyclic graphs starting from multiple perturbed nodes, for which perturbation experiment data should be available.</p>
    <p>Heuristic contextualization methods that focus on describing the stable states of the system require less experimental information but the resulting models are strongly contextualized to the stable states. Examples include the methods proposed by Layek et al. [<xref ref-type="bibr" rid="CR8">8</xref>], Crespo et al. [<xref ref-type="bibr" rid="CR9">9</xref>] and Rodriguez et al. [<xref ref-type="bibr" rid="CR10">10</xref>]. The main limitation of these methods is that, given that they are trained to describe correctly the stable states, they may fail to describe other dynamical behaviours, such as the transitions between stable states under specific perturbations. In a specific example, Rodriguez et al. [<xref ref-type="bibr" rid="CR10">10</xref>] showed in a model of the T-helper differentiation process how only a fraction of the alternative optimized models successfully described a known transdifferentiation between phenotypes Th1 and Th2 under the stimulation of GATA3.</p>
    <p>Here we propose a new heuristic method for the contextualization of PKNs that specifically addresses the above-mentioned limitations. It consists in a heuristic network training approach that considers not only the stable states of the system but also the reachability of those states under specific perturbations. The method takes as input a PKN and experimental information about the stable states and transitions between them upon perturbation. A genetic algorithm is used to explore the search space of Boolean networks with asynchronous updates and to find networks that best describe the experimental data, using only edges present in the PKN. We demonstrate the ability of our algorithm to reconstruct a previously published cell-fate decision model [<xref ref-type="bibr" rid="CR11">11</xref>] used as gold standard, by comparing the networks reconstructed by our algorithm to the original cell-fate decision model. The results demonstrate the utility of the approach to reconstruct reliable dynamical Boolean models based on the integration of PKN and experimental data. Such models can be interrogated to predict network response under perturbation, stability properties and robustness of the network, with potential application to guide experimental approaches including hypothesis generation.</p>
  </sec>
  <sec id="Sec2" sec-type="materials|methods">
    <title>Methods</title>
    <p>This section is divided in two main parts. Part 1 describes our network optimization method (Fig. <xref rid="Fig1" ref-type="fig">1</xref>). This takes as input a PKN and a set of experiments (training set) and uses a genetic algorithm to train model networks to reproduce as closely as possible the experimental data provided in the training set, with the constraint that all edges must be taken from the PKN. The output of the method is a set of model networks. Part 2 describes our method to assess the quality of network optimization. This uses an <italic>in silico</italic> gold standard network to generate PKNs and training sets, which are taken as input for the optimization method. The resulting model networks are then compared to the original <italic>in silico</italic> gold standard network and the result of this comparison is taken as a measure of our network optimization method quality.<fig id="Fig1"><label>Fig. 1</label><caption><p>Optimization method. Our network optimization method takes as input a PKN and a training set and uses a genetic algorithm to find sub-graphs of the PKN which reproduce as well as possible all experiments in the training set. For each run of the optimization method, only the best network is kept as optimized network. To increase the chances to obtain good solutions, multiple independent runs of the optimization method are usually started in parallel, and only a fraction of optimized networks is kept as model networks</p></caption><graphic xlink:href="12859_2016_1287_Fig1_HTML" id="MO1"/></fig>
</p>
    <sec id="Sec3">
      <title>Description of the network optimization method</title>
      <sec id="Sec4">
        <title>Definitions</title>
        <sec id="FPar1">
          <title>Model network</title>
          <p>A model network is a Boolean network, used to model a given biological process. Ideally, the model network obtained after the optimization procedure should behave like the biological system. In this work we consider asynchronous Boolean networks, as defined by Garg and co-authors [<xref ref-type="bibr" rid="CR12">12</xref>]. Each node corresponds to a gene or a protein and its state is given by a Boolean variable, which can represent node expression or activity. Edges correspond to interactions between nodes and can be positive (activators) or negative (inhibitors). The dynamical behaviour of a Boolean network can be measured by performing <italic>in silico</italic> experiments. In this work, an <italic>in silico</italic> experiment consists of a set of perturbations (over-expression/knock-out of one or any combination of nodes) and a set of transitions between them. For each transition from a perturbation P<sub>1</sub> to a perturbation P<sub>2</sub>, the output of the <italic>in silico</italic> experiment is an attractor reachability graph (see Fig. <xref rid="Fig2" ref-type="fig">2</xref>) whose nodes are attractors obtained with each perturbation and edges denote reachability between attractors. More precisely, an edge will connect an attractor obtained with perturbation P<sub>1</sub> to an attractor obtained with perturbation P<sub>2</sub> if and only if the states of the first attractor are connected to the states of the second attractor by at least one path in the asynchronous state transition graph of the network with perturbation P<sub>2</sub>.<fig id="Fig2"><label>Fig. 2</label><caption><p>In silico experiments and attractor reachability graph. Example of attractor reachability graph for the transition from unperturbed network to over-expression of TNF on the cell-fate decision model [<xref ref-type="bibr" rid="CR11">11</xref>]. The unperturbed network has four attractors, each shown as a network with <italic>red nodes</italic> corresponding to active nodes and <italic>blue nodes</italic> corresponding to inactive nodes. These attractors are labelled A<sub>1,1</sub>, A<sub>1,2</sub>, A<sub>1,3</sub>, and A<sub>1,4</sub>. Attractor A<sub>1,3</sub> corresponds to the physiological state used by Calzone and co-authors [<xref ref-type="bibr" rid="CR11">11</xref>] as initial state. The perturbed network (TNF fixed to 1) has only three attractors (denoted A<sub>2,1</sub>, A<sub>2,2</sub> and A<sub>2,3</sub>), interpreted as the three cell fates: non-apoptotic cell death, survival, and apoptosis. After TNF over-expression, each attractor of the unperturbed network will stabilize into at least one attractor of the perturbed network (<italic>grey arrows</italic>). For example, the physiological state A<sub>1,3</sub> will stabilize into either of the three cell fates A<sub>2,1</sub>, A<sub>2,2</sub> and A<sub>2,3</sub>. Note that this figure presents only the transition from unperturbed network to over-expression of TNF, and not the reverse transition. Therefore no information is shown on the reachability from attractors obtained with over-expression of TNF to attractors of the unperturbed network</p></caption><graphic xlink:href="12859_2016_1287_Fig2_HTML" id="MO2"/></fig>
</p>
          <p>To perform <italic>in silico</italic> experiments, two methods were used in this work. The first method is boolSim, a software developed by Garg and co-authors [<xref ref-type="bibr" rid="CR12">12</xref>], which uses an implicit method based on reduced ordered binary decision diagrams to evaluate the attractor reachability graph of a network. This method is exact and exhaustively finds all attractors but quickly becomes too computationally expensive for large networks. The second method we used was a simple algorithm based on a stochastic exploration of the state transition graph (see Additional file <xref rid="MOESM1" ref-type="media">1</xref> for details). This stochastic approach scales better than boolSim as network size increases, but there is no guarantee that all attractors will be found. In this work, the stochastic method was used to evaluate attractor reachability graphs in our implementation of the optimization method, while boolSim was used to assess the quality of the final optimization results.</p>
        </sec>
        <sec id="FPar2">
          <title>Prior knowledge network (PKN)</title>
          <p>The PKN is a network that summarizes known interactions between genes and/or proteins of interest, usually obtained from the literature by a biocurator or by automatic text mining methods. Note that although this network can contain direct interactions, most of the interactions are usually indirect.</p>
        </sec>
        <sec id="FPar3">
          <title>Training set</title>
          <p>The training set is a set of known experimental results that the final model network should be able to reproduce. In this work, the training set consists of stable phenotypes measured in different conditions and transitions between them. It is given in the form of a transition graph. Each node of the training set graph is defined by a perturbation and an observation. A perturbation can involve the over-expression (node always set to 1) and/or knock-out (node always set to 0) of any subset of nodes in the network. An observation is a list of nodes and their corresponding state measured at equilibrium after the perturbation. Node states should be either 0 or 1. Edges in the training set graph correspond to transitions between stable phenotypes. An edge from perturbation P<sub>1</sub> with observation O<sub>1</sub> to perturbation P<sub>2</sub> with observation O<sub>2</sub> means that under perturbation P<sub>1</sub> the system exhibits a stable phenotype characterized by observation O<sub>1</sub> and after perturbation P<sub>2</sub> the system will stabilize into a phenotype characterized by observation O<sub>2</sub>. Note that P<sub>1</sub> = P<sub>2</sub> is allowed, as well as O<sub>1</sub> = O<sub>2</sub>.</p>
          <p>Intuitively, a Boolean network reproduces a training set if for each perturbation/observation in the training set, the network can stabilize into an attractor compatible with the observation when applying the corresponding perturbation. In addition, attractors matched to perturbation/observation nodes linked by an edge in the training set graph should be connected by “time” evolution of the network, i.e. connected by an edge in the attractor reachability graph. Finally, each node of the training set graph should correspond to a unique attractor in the attractor reachability graph. For instance, the following training set graph (P<sub>1</sub>,O<sub>1</sub>) → (P<sub>2</sub>,O<sub>2</sub>) → (P<sub>3</sub>,O<sub>3</sub>) means that the model network should have at least one attractor A<sub>1</sub> with node states corresponding to observation O<sub>1</sub> when perturbed by P<sub>1</sub>, as well as attractors A<sub>2</sub> and A<sub>3</sub> with node states corresponding to observations O<sub>2</sub> and O<sub>3</sub> when perturbed by P<sub>2</sub> and P<sub>3</sub> respectively. In addition, A<sub>1</sub> should be connected to A<sub>2</sub> and the same attractor A<sub>2</sub> should be connected to A<sub>3</sub> in the attractor reachability graph.</p>
          <p>This definition of training set is flexible enough to accommodate complex experimental scenarios such as the (long term) responses to drugs in specific mutational backgrounds, but also time-dependent processes such as cellular differentiation in response to various combinations of stimuli. Multiple scenarios can even be combined into a unique training set (e.g. training set 1 in Additional file <xref rid="MOESM2" ref-type="media">2</xref>).</p>
        </sec>
      </sec>
      <sec id="Sec5">
        <title>Problem formulation</title>
        <p>Given a PKN and a training set, find the model network that reproduces as well as possible all experiments in the training set, under the constraint that the model network must be a sub-graph of the PKN (all edges and nodes in the model network must exist in the PKN).</p>
        <p>We also enforced the following properties of the model network, given in decreasing order of importance. (i) It should include a user-defined set of essential nodes. Typically, this set will contain nodes that are known to play an important role in the modelled biological process, or that represent key experimental readouts. (ii) It should be as small as possible in terms of number of nodes. Since the prior knowledge network can be very large, it can be challenging to evaluate its attractors, therefore having a model network that is as simple as possible should reduce the computational effort. (iii) Given a set of nodes, the model network should contain as many edges (connecting these nodes) from the PKN as possible. The idea here is to force the model network to be as close as possible to the PKN, removing only edges that are in contradiction with the training set.</p>
        <p>To optimize all these properties simultaneously, we used a standard multi-objective optimization approach, based on a multi-dimensional fitness function, defined for each network as<disp-formula id="Equa"><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \mathbf{F}=\left({f}_T,-{N}_{ess. nodes},{N}_{nodes},-{N}_{edges}\right) $$\end{document}</tex-math><mml:math id="M2"><mml:mi mathvariant="bold">F</mml:mi><mml:mo>=</mml:mo><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mi>T</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>s</mml:mi><mml:mo>.</mml:mo><mml:mi mathvariant="italic">nodes</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mi mathvariant="italic">nodes</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mi mathvariant="italic">edges</mml:mi></mml:msub></mml:mrow></mml:mfenced></mml:math><graphic xlink:href="12859_2016_1287_Article_Equa.gif" position="anchor"/></alternatives></disp-formula>where <italic>f</italic>
<sub><italic>T</italic></sub> measures how well the network reproduce the experiments given in the training set, <italic>N</italic>
<sub><italic>ess. nodes</italic></sub> is the number of essential nodes appearing in the network, <italic>N</italic>
<sub><italic>nodes</italic></sub> is its number of nodes and <italic>N</italic>
<sub><italic>edges</italic></sub> its number of edges. Multi-dimensional fitness functions are compared using lexicographical ordering, which means that optimization of <italic>f</italic>
<sub><italic>T</italic></sub> is considered as most important, followed by <italic>N</italic>
<sub><italic>ess. nodes</italic></sub>, <italic>N</italic>
<sub><italic>nodes</italic></sub> and finally <italic>N</italic>
<sub><italic>edges</italic></sub>. Note that the component responsible for maximization of the number of edges (<italic>N</italic>
<sub><italic>edges</italic></sub>) appears only after the number of nodes (<italic>N</italic>
<sub><italic>nodes</italic></sub>). As a consequence, networks with same <italic>f</italic>
<sub><italic>T</italic></sub> and <italic>N</italic>
<sub><italic>ess. nodes</italic></sub> are first compared according to their number of nodes. Only if they have the same number of nodes, their number of edges is taken into account in the comparison. The first component <italic>f</italic>
<sub><italic>T</italic></sub> (defined in Additional file <xref rid="MOESM1" ref-type="media">1</xref>) measures the average distance between observations contained in the training set and attractors of the network, with the following constraints on the chosen attractors: (1) if two observations are connected by an edge in the training set graph then the corresponding attractors must be connected in the attractor reachability graph and (2) each observation in the training set graph must correspond to a unique attractor. Among all attractors satisfying these two constraints, only the ones that minimize <italic>f</italic>
<sub><italic>T</italic></sub> are taken into account. Approximately, <italic>f</italic>
<sub><italic>T</italic></sub> can be considered as the fraction of observations in the training set that are not reproduced correctly by the network.</p>
        <p>With these definitions, the challenge becomes a non-linear discrete optimization problem: the model network corresponds to the sub-graph of the PKN that minimizes the multi-dimensional fitness function <bold>F</bold>. For a PKN with <italic>M</italic> edges, the number of possible model networks is 2<sup><italic>M</italic></sup>. As a consequence, except for a very small PKN, brute force testing of all possible networks is not possible, and a numerical optimization method is required. Here we use a genetic algorithm (more details are available in Additional file <xref rid="MOESM1" ref-type="media">1</xref>), a well-established heuristic optimization method, which can be easily implemented and is known to give reasonably good results with non-linear discrete optimization problems. Heuristic optimization algorithms, like the genetic algorithm, are designed to seek good solutions, at a reasonable computational cost, but without guarantee of optimality or completeness. It is worth noting that this problem is neither linear nor convex, and therefore more efficient linear or convex optimization methods cannot be used here. Indeed, contrary to the case where the training set contains only information on steady states (attractors with only one state) or successive states in the state transition graph, which can be reformulated as a linear or convex optimization problem [<xref ref-type="bibr" rid="CR3">3</xref>, <xref ref-type="bibr" rid="CR4">4</xref>], the more general form of our training set, which contains information on attractors but also reachability between them, prevents this reformulation.</p>
        <p>Except for very large training sets, this optimization problem will in general not be completely specified. Indeed, several different networks may be able to reproduce the training set equally well (minimize <italic>f</italic>
<sub><italic>T</italic></sub>). Although adding more components to the fitness function (<italic>N</italic>
<sub><italic>ess. nodes</italic></sub>, <italic>N</italic>
<sub><italic>nodes</italic></sub> and <italic>N</italic>
<sub><italic>edges</italic></sub>) should help to reduce the number of networks that are solutions of the optimization problem, it may not be sufficient to reduce the solution to a unique network. Therefore, the solution to the optimization problem should not be considered as a unique network, but as a collection of different networks which are all equally good candidate models. This is not a limitation of the chosen optimization method (genetic algorithm), but a consequence of the lack of knowledge on the biological system. To reduce the number of solutions, an obvious solution consists in increasing the training set size. Alternatively, carefully building the PKN without unnecessary edges will help to decrease the dimension of the search space as well as the number of solutions.</p>
        <p>The bottleneck with this approach in terms of performance is the evaluation of attractor reachability graphs. As a consequence, this method should be used with networks having on the order of hundreds of nodes. This limit on the network size is not strict, since the computational cost will depend on the number of nodes, connectivity and topology of the optimized networks, which are governed by the corresponding properties of the PKN as well as the number of essential nodes.</p>
      </sec>
    </sec>
    <sec id="Sec6">
      <title>Evaluation of the network optimization method</title>
      <p>To evaluate the network optimization method, we used a gold standard model to generate <italic>in silico</italic> PKNs and training sets, which were then used as input for our network optimization method. The resulting model networks were then compared to the original gold standard network, and the result of this comparison was taken as a proxy for the quality of the optimization method.</p>
      <p>As gold standard, we used a cell-fate decision model proposed by Calzone and co-authors [<xref ref-type="bibr" rid="CR11">11</xref>] (Fig. <xref rid="Fig3" ref-type="fig">3a</xref>). Note that it is outside the scope of the present paper to discuss whether this model correctly describes the underlying biological process. A toy model completely unrelated to any biological process could also have been used as a gold standard.<fig id="Fig3"><label>Fig. 3</label><caption><p>Cell-fate decision model. <bold>a</bold> Cell-fate decision model [<xref ref-type="bibr" rid="CR11">11</xref>] used as gold standard. Essential nodes are shown with <italic>grey</italic> background. <bold>b</bold> List of transitions, starting from each of the 4 unperturbed network’s attractors to attractors reached after single node perturbations of the cell-fate decision model. Each line corresponds to an edge in the attractor reachability graph. Only the first lines are shown, the full table is given in Additional file <xref rid="MOESM3" ref-type="media">3</xref>. <bold>c</bold> PKN obtained from (<bold>b</bold>) by adding edges from perturbed nodes to observed nodes whose state (absolute value) change by more than 0.5 (highlighted in <italic>yellow</italic>). Edges are positive if perturbation and variation of observed node state have same sign, and negative if they have opposite sign. For example, line 3 in table (<bold>b</bold>) will generate seven positive edges from Apoptosome to Apoptosis, BAX, CASP3, CASP8, Cyt_c, MOMP and SMAC as well as one negative edge from Apoptosome to cIAP. The complete list of interactions in the PKN is given in Additional file <xref rid="MOESM4" ref-type="media">4</xref> (PKN 1)</p></caption><graphic xlink:href="12859_2016_1287_Fig3_HTML" id="MO3"/></fig>
</p>
      <p>To illustrate the simplification of the network obtained by minimizing the number of nodes, we decided to use training sets containing information for only a fraction of all nodes in the gold standard model, namely the 14 nodes chosen by Calzone and co-authors for their reduced cell-fate decision model [<xref ref-type="bibr" rid="CR11">11</xref>] (grey nodes in Fig. <xref rid="Fig3" ref-type="fig">3a</xref>).</p>
      <sec id="Sec7">
        <title>Generating input data</title>
        <sec id="FPar4">
          <title>In silico PKN</title>
          <p>BoolSim was used to perform every possible single node perturbation experiment on the gold standard network, starting from the unperturbed network. The resulting attractor reachability graphs were used to build a list of attractor transitions (see Fig. <xref rid="Fig3" ref-type="fig">3b</xref> and Additional file <xref rid="MOESM3" ref-type="media">3</xref>), with each line corresponding to one edge in the attractor reachability graph. If an attractor had more than one state, it was replaced by the average of all its states. Assuming that each line in the list transitions (Fig. <xref rid="Fig3" ref-type="fig">3b</xref> and Additional file <xref rid="MOESM3" ref-type="media">3</xref>) corresponded to a transition that could be observed experimentally and reported in an article, an <italic>in silico</italic> PKN was built by linking perturbed nodes to observed nodes whose states changed significantly (Fig. <xref rid="Fig3" ref-type="fig">3c</xref> and PKN 1 in Additional file <xref rid="MOESM4" ref-type="media">4</xref>). That is, each line in Fig. <xref rid="Fig3" ref-type="fig">3b</xref> generates edges from the perturbed node to each observed node whose state changes by more than 0.5 (absolute value). Edges are positive if perturbation and variation of observed node state have the same sign, and negative if they have opposite signs. Finally all edges of the gold standard network also are added to the PKN.</p>
          <p>In addition to this ideal PKN, we also generated five PKNs with increasing fractions of noise (10, 20, 30, 40 and 50 % noise). To generate a PKN with noise fraction <italic>q</italic>, we randomly replaced a fraction <italic>q</italic> of all edges in the ideal PKN by the same number of edges randomly chosen in the set of edges of the form <italic>n</italic>
<sub>1</sub> → <italic>n</italic>
<sub>2</sub> and <italic>n</italic>
<sub>1</sub> ⊣ <italic>n</italic>
<sub>2</sub> that were not in the ideal PKN (<italic>n</italic>
<sub>1</sub>, <italic>n</italic>
<sub>2</sub> are nodes of the ideal PKN). The lists of interactions in each of these PKNs are given in Additional file <xref rid="MOESM4" ref-type="media">4</xref> (PKN 2 to 6).</p>
        </sec>
        <sec id="FPar5">
          <title>Essential nodes</title>
          <p>We used the 14 nodes of the reduced cell-fate decision model proposed by Calzone and co-authors [<xref ref-type="bibr" rid="CR11">11</xref>]: ATP, Apoptosis, CASP3, CASP8, cIAP, FASL, MOMP, MPT, NFkB, NonACD, RIP1, ROS, Survival and TNF (grey nodes in Fig. <xref rid="Fig3" ref-type="fig">3a</xref>; i.e., all nodes for which experimental data was assumed to be available).</p>
        </sec>
        <sec id="FPar6">
          <title>In silico training sets</title>
          <p>We built a training set based on the response to TNF and FASL perturbations by mutant versions of the cell-fate decision model discussed by Calzone and co-authors [<xref ref-type="bibr" rid="CR11">11</xref>]. We considered seven mutant versions: wild-type, CASP3 knock-out, CASP8 knock-out, cIAP knock-out, NFkB knock-out, RIP1 knock-out and simultaneous knock-out of CASP3, CASP8 and RIP1. For each mutant, we measured the response of the gold standard network to TNF over-expression, FASL over-expression and simultaneous over-expression of TNF and FASL, starting from the physiological state (all nodes inactive except ATP and cIAP) described by Calzone and co-authors [<xref ref-type="bibr" rid="CR11">11</xref>]. For each attractor obtained, an observation was added to the training set, using the measured states of all essential nodes in the attractor. For each attractor reached after perturbation of TNF, FASL or TNF and FASL together, we added to the training set a transition from the initial attractor (physiological state) to the reached attractor. The resulting training set is given in Additional file <xref rid="MOESM2" ref-type="media">2</xref>, training set 1. Note that for a given mutant, all perturbations are linked to the same initial observation obtained with the unperturbed network, which means that during the optimization, only transitions starting from the same initial attractor will be used to evaluate the fitness function.</p>
          <p>In addition to this training set, we also built two smaller training sets obtained by keeping only transitions for the wild-type mutant (training set 2 in Additional file <xref rid="MOESM2" ref-type="media">2</xref>), and keeping only the initial physiological attractor (training set 3 in Additional file <xref rid="MOESM2" ref-type="media">2</xref>).</p>
          <p>To study the effect of errors in training sets on the optimization method, we also generated five training sets with increasing fractions of errors (10, 20, 30, 40 and 50 %) by randomly reversing the corresponding fraction of all node states appearing in training set 1 (training sets 1 with 10 to 50 % error in Additional file <xref rid="MOESM2" ref-type="media">2</xref>).</p>
        </sec>
      </sec>
      <sec id="Sec8">
        <title>Comparing a model network to the gold standard</title>
        <p>Given a model network, obtained by using the network optimization method with an <italic>in silico</italic> PKN and training set generated from the gold standard network, we measured how close this model network was to the gold standard network. Various metrics could be used here, but we considered that the most important characteristic of a model network was its ability to correctly predict the behaviour of the underlying biological system (in the present case, the gold standard model). To compare predictions from the model network and gold standard network we defined a score (denoted <italic>s</italic>
<sub><italic>all</italic></sub>) which measures the similarity between the average states reached by the model network and gold standard network after all possible single node perturbations of essential nodes, starting from each attractor of the unperturbed gold standard network. More precisely, for each perturbation and initial state, the average state reached by a network is a vector of dimension <italic>N</italic>
<sub><italic>ess. nodes</italic></sub> whose n-th component is obtained as the average state of the n-th essential node over all attractors reached after the perturbation, starting from the given initial state. The <italic>s</italic>
<sub><italic>all</italic></sub> score is then defined as <italic>s</italic>
<sub><italic>all</italic></sub> = 1 − <italic>Δ</italic>/<italic>N</italic>
<sub><italic>ess. nodes</italic></sub>, where <italic>Δ</italic> denotes the average over all perturbations and initial states of the Manhattan distance between average states reached by the model network and gold standard network (for a detailed definition see Additional file <xref rid="MOESM1" ref-type="media">1</xref>). We decided to consider not only the best attractor (as during the optimization process) but to consider all attractors reached, thus penalizing those situations where only part of the attractors reached by the model correspond to the attractors reached by the gold standard network.</p>
        <p>The <italic>s</italic>
<sub><italic>all</italic></sub> score defined in this way has a value of 1 when the average predictions of both networks consistently agree for all perturbations and initial states, and a value of 0 when both networks consistently predict opposite states. Since the evaluation of the <italic>s</italic>
<sub><italic>all</italic></sub> score is based on experiments that are not part of the training set, it can be interpreted as a measure of the predictive power of the model network.</p>
      </sec>
      <sec id="Sec9">
        <title>Evaluation of the optimization method: workflow</title>
        <p>An important question in the context of network optimization is whether a network is able to correctly predict the outcome of experiments that are not part of the training set against which it was optimized. To answer this question and to assess the quality of the network optimization method, we proceeded in the following way (see Fig. <xref rid="Fig4" ref-type="fig">4</xref>):<list list-type="order"><list-item><p>As described above, the gold standard network (Fig. <xref rid="Fig4" ref-type="fig">4a</xref>) was used to generate an <italic>in silico</italic> PKN (Fig. <xref rid="Fig4" ref-type="fig">4b</xref>) and an <italic>in silico</italic> training set (Fig. <xref rid="Fig4" ref-type="fig">4c</xref>).</p></list-item><list-item><p>Multiple independent runs (500 if not otherwise specified) of the network optimization method were performed, each with the same <italic>in silico</italic> PKN and training set as input (Fig. <xref rid="Fig4" ref-type="fig">4d</xref>), using a population of 50 replicas for the genetic algorithm. Each run was halted if the best value of the fitness function did not decrease during more than 10 iterations, and the network with the best fitness function obtained during the run was retained. Among the 500 networks generated in this way only the best 50 networks (according to fitness function) were kept as model networks (Fig. <xref rid="Fig4" ref-type="fig">4e</xref>).</p></list-item><list-item><p>For each model network and the gold standard network we performed <italic>in silico</italic> experiments to find the attractors reached after all possible single node perturbations of essential nodes, starting from each attractor of the unperturbed gold standard network (Fig. <xref rid="Fig4" ref-type="fig">4f and g</xref>).</p></list-item><list-item><p>The predictions for each model network were then compared to the gold standard network predictions by measuring the <italic>s</italic>
<sub><italic>all</italic></sub> score defined previously (Fig. <xref rid="Fig4" ref-type="fig">4h</xref>). These scores, which measure the predictive power of the model networks, were then interpreted as a measure of the optimization method quality.</p></list-item></list>
<fig id="Fig4"><label>Fig. 4</label><caption><p>Evaluation of the optimization method: Workflow. To evaluate our optimization method, we used a gold standard network, interpreted as the true underlying biological system’s network (<bold>a</bold>). An <italic>in silico</italic> PKN (<bold>b</bold>) and a training set (<bold>c</bold>) containing a limited amount of information were generated by performing <italic>in silico</italic> experiments on the gold standard network. Using the PKN and training set as input, we started 500 independent runs of our network optimization (<bold>d</bold>), and kept the best network (with minimal value of the fitness function) obtained with each run. Among these 500 networks, the 50 best networks (according to fitness function) were kept as model networks (<bold>e</bold>). The predictive power of each model network was then evaluated by comparing its average predictions for all single node perturbations (<bold>f</bold>) to the corresponding gold standard network predictions (<bold>g</bold>). The resulting <italic>s</italic>
<sub><italic>all</italic></sub> scores (<bold>h</bold>) measure how close model networks and gold standard network predictions are and were taken as a proxy for the quality of the optimization method</p></caption><graphic xlink:href="12859_2016_1287_Fig4_HTML" id="MO4"/></fig>
</p>
        <p>This procedure was repeated with different training sets and PKNs to study the behaviour of the network optimization method in different conditions.</p>
      </sec>
      <sec id="Sec10">
        <title>Random networks</title>
        <p>The distribution of <italic>s</italic>
<sub><italic>all</italic></sub> scores indicates how close the model networks predictions are to the gold standard network predictions. Another important question is whether a score <italic>s</italic>
<sub><italic>all</italic></sub> obtained with a given model network is significantly better than a score obtained with a random network, i.e. is the optimization method better than a random network generator? To answer this question, random sub-networks of the PKN were generated by randomly keeping (with probability 0.5) each interaction in the PKN. The randomized network <italic>s</italic>
<sub><italic>all</italic></sub> scores were then evaluated and compared to the model network <italic>s</italic>
<sub><italic>all</italic></sub> score.</p>
      </sec>
    </sec>
  </sec>
  <sec id="Sec11" sec-type="results">
    <title>Results and discussion</title>
    <sec id="Sec12">
      <title>Network optimization: applied example</title>
      <p>We illustrate how our optimization method behaves by following its evolution when applied on a sample data set. We performed 500 independent runs of the optimization method using training set 1 (Additional file <xref rid="MOESM2" ref-type="media">2</xref>), PKN 1 (Additional file <xref rid="MOESM4" ref-type="media">4</xref>) and the 14 essential nodes discussed in the method section (grey nodes in Fig. <xref rid="Fig3" ref-type="fig">3</xref>).</p>
      <p>Figure <xref rid="Fig5" ref-type="fig">5a</xref> illustrates how the individual components of the fitness function <bold>F</bold> = (<italic>f</italic>
<sub><italic>T</italic></sub>, − <italic>N</italic>
<sub><italic>ess. nodes</italic></sub>, <italic>N</italic>
<sub><italic>nodes</italic></sub>, − <italic>N</italic>
<sub><italic>edges</italic></sub>) evolve during the run giving the network with the minimal fitness function value. Following an initialization of all replicas to the empty network, the optimization process starts with an initial phase where <italic>f</italic>
<sub><italic>T</italic></sub> decreases while <italic>N</italic>
<sub><italic>ess. nodes</italic></sub>, <italic>N</italic>
<sub><italic>nodes</italic></sub> and <italic>N</italic>
<sub><italic>edges</italic></sub> all increase as the networks are populated with nodes and edges. The number of nodes and edges is large enough to include all essential nodes (<italic>N</italic>
<sub><italic>ess. nodes</italic></sub> = 14) for most networks after the 50th iteration, and when <italic>N</italic>
<sub><italic>ess. nodes</italic></sub> saturates the number of nodes starts to decrease. The number of edges tends to increase steadily from the first to the last iteration, but increases faster whenever the number of nodes increases or saturates. This is a consequence of the lexicographical ordering of multi-dimensional fitness functions. The optimization is stopped when the best value of the fitness function fails to decrease during 10 consecutive iterations, and the network with best value of the fitness function is retained as the output of this optimization run.<fig id="Fig5"><label>Fig. 5</label><caption><p>Example of network optimization: best run. <bold>a</bold> Evolution of the fitness function <bold>F</bold> = (<italic>f</italic>
<sub><italic>T</italic></sub>, − <italic>N</italic>
<sub><italic>ess. nodes</italic></sub>, <italic>N</italic>
<sub><italic>nodes</italic></sub>, − <italic>N</italic>
<sub><italic>edges</italic></sub>) during one run of the optimization method using the training set 1 given in Additional file <xref rid="MOESM2" ref-type="media">2</xref>, the PKN given in Additional file <xref rid="MOESM4" ref-type="media">4</xref> (PKN 1) and the 14 essential nodes from the reduced cell-fate decision model proposed by Calzone and co-authors [<xref ref-type="bibr" rid="CR11">11</xref>]. For each given iteration, <italic>blue dots</italic> correspond to individual replicas and <italic>black dot</italic> to the replica with best value of the fitness function. <bold>b</bold> Network with best value of the fitness function obtained during this run. The run shown in this figure is the one that produced the network with minimal value of the fitness function among 500 independent runs</p></caption><graphic xlink:href="12859_2016_1287_Fig5_HTML" id="MO5"/></fig>
</p>
      <p>Figure <xref rid="Fig5" ref-type="fig">5b</xref> presents the best network obtained during this optimization run. It has a first fitness function component <italic>f</italic>
<sub><italic>T</italic></sub> = 0, which means that it perfectly reproduces all the experiments in the training set. The second component (<italic>N</italic>
<sub><italic>ess. nodes</italic></sub> = 14) is also optimal. The third component <italic>N</italic>
<sub><italic>nodes</italic></sub> = 15 is very close to the minimal value 14. Although it may not be optimal, the fact that no network was found with <italic>N</italic>
<sub><italic>nodes</italic></sub> = 14 and <italic>f</italic>
<sub><italic>T</italic></sub> = 0 in any of the 500 runs suggest that <italic>N</italic>
<sub><italic>nodes</italic></sub> = 15 is the minimum number of nodes compatible with <italic>f</italic>
<sub><italic>T</italic></sub> = 0. It is not clear whether the fourth component (<italic>N</italic>
<sub><italic>edges</italic></sub> = 58) is optimal since it is much smaller than the 99 edges from the PKN connecting the 15 nodes of this network. Therefore, while this network may not be an exact global minimum of the fitness function, it seems to be very close, which suggests that our implementation of the genetic algorithm is appropriate to handle this minimization problem.</p>
      <p>The goal of our network optimization method is not only to find networks that can reproduce all experiments in the training set (<italic>f</italic>
<sub><italic>T</italic></sub> = 0), but also, and most importantly to find networks that can predict the outcome of experiments against which they were not trained. Since the gold standard network used to generate the PKN and the training set is known, this can be quantified by evaluating the <italic>s</italic>
<sub><italic>all</italic></sub> score (defined in the <xref rid="Sec2" ref-type="sec">Methods</xref> section) which measures the similarity between the average attractors reached by the model network and the average attractors reached by the gold standard network after all possible single node perturbations. Note that contrary to <italic>f</italic>
<sub><italic>T</italic></sub>, which only takes into account a subset of the attractors that best match the training set, the <italic>s</italic>
<sub><italic>all</italic></sub> score takes into account all attractors reached after perturbation, thus penalizing the situation where only a subset of attractors behave properly. For the model network given in Fig. <xref rid="Fig5" ref-type="fig">5b</xref>, <italic>s</italic>
<sub><italic>all</italic></sub> ≃ 0.974, so approximately 97.4 % of the predicted node states are correct following single node perturbations. Although only one attractor of the unperturbed gold standard network was part of the training set, the model network nevertheless recovered the same 4 attractors as the gold standard network, with only one error (node CASP8 = 1 instead of 0 in one attractor).</p>
      <p>We next examined the diversity of model networks that can be obtained by running the optimization method multiple times. For each of the 500 independent runs we selected the single best network, and from these 500 optimized networks then selected the 50 networks with the lowest fitness function, which were retained as model networks. While none of these networks necessarily represents an exact global minimum of the fitness function, all networks had optimal values for the first and second components (<italic>f</italic>
<sub><italic>T</italic></sub> = 0 and <italic>N</italic>
<sub><italic>ess. nodes</italic></sub> = 14). The best 50 model networks were compared to the gold standard model by measuring the <italic>s</italic>
<sub><italic>all</italic></sub> scores and the resulting distribution of <italic>s</italic>
<sub><italic>all</italic></sub> scores is shown in Fig. <xref rid="Fig6" ref-type="fig">6</xref> (dark blue) along with the score for the best network (red). The median <italic>s</italic>
<sub><italic>all</italic></sub> of the 50 best networks is high, with about 97 % of node states correctly predicted after all single node perturbations, and significantly higher than the distribution of <italic>s</italic>
<sub><italic>all</italic></sub> scores for all the 500 networks (light blue). This shows that at least for this sample input data set, networks with small values of the fitness function tend to have high <italic>s</italic>
<sub><italic>all</italic></sub> scores, i.e. their predictions are close to the gold standard network predictions.<fig id="Fig6"><label>Fig. 6</label><caption><p>Example of network optimization: <italic>s</italic>
<sub><italic>all</italic></sub> scores distribution. Distribution of <italic>s</italic>
<sub><italic>all</italic></sub> scores obtained with 500 independent runs of the optimization method using the same input data as in Fig. <xref rid="Fig5" ref-type="fig">5</xref>. For each run, only the network with minimal value of the fitness function was kept. This figure shows the <italic>s</italic>
<sub><italic>all</italic></sub> scores for the best network (<italic>red line</italic>), for the 50 best networks (<italic>dark blue boxplot</italic>) and for all 500 networks (<italic>light blue boxplot</italic>). In addition, <italic>s</italic>
<sub><italic>all</italic></sub> scores for the PKN (<italic>black line</italic>) and 350 random sub-networks of the PKN (<italic>grey boxplot</italic>) are shown</p></caption><graphic xlink:href="12859_2016_1287_Fig6_HTML" id="MO6"/></fig>
</p>
      <p>To check that the good scores obtained by the model networks were not only due to a very informative PKN, which by construction contains all the functional interactions of the gold standard network, we also measured the <italic>s</italic>
<sub><italic>all</italic></sub> score of the PKN (black line in Fig. <xref rid="Fig6" ref-type="fig">6</xref>). As shown in Fig. <xref rid="Fig6" ref-type="fig">6</xref>, scores of the best 50 model networks (dark blue) are significantly higher than the score of the PKN (black), indicating that the optimization method indeed generates models with much improved predictive power compared to the PKN used as input. The <italic>s</italic>
<sub><italic>all</italic></sub> scores for random sub-networks of the PKN (shown in grey) are also significantly lower than those for the 50 model networks. This result is not entirely trivial, since these random networks are built with edges of the PKN that correspond to functional interactions of the gold standard network.</p>
    </sec>
    <sec id="Sec13">
      <title>Genetic algorithm</title>
      <p>The quality of the optimization method, as measured by the <italic>s</italic>
<sub><italic>all</italic></sub> score, is determined by the combination of the optimization algorithm (genetic algorithm) and the choice of fitness function. In the previous section, we showed that the optimization method was able to generate model networks with good predictive power (high <italic>s</italic>
<sub><italic>all</italic></sub> scores). This result strongly suggests that the choice of fitness function was adequate and that the optimization algorithm was able to find sufficiently good solutions to the minimization problem. However, it does not say anything about the efficiency of the optimization algorithm, and indeed a simple random network generator could also produce optimal solutions in principle, simply by generating a sufficiently large number of networks.</p>
      <p>To evaluate our implementation of the genetic algorithm, we compared the evolution of best fitness function values obtained by our algorithm to best fitness function values obtained on a population of random networks. We started 200 independent runs of the optimization method, using the same input as in the previous section (training set 1 in Additional file <xref rid="MOESM2" ref-type="media">2</xref>, PKN 1 in Additional file <xref rid="MOESM4" ref-type="media">4</xref> and 14 grey nodes in Fig. <xref rid="Fig3" ref-type="fig">3</xref> as essential nodes). During each run, the fitness function value and <italic>s</italic>
<sub><italic>all</italic></sub> score of the best network (i.e. with minimal fitness function value) obtained were stored for each iteration of the genetic algorithm (black dots in Fig. <xref rid="Fig5" ref-type="fig">5a</xref>). The resulting distributions of best fitness function values and corresponding <italic>s</italic>
<sub><italic>all</italic></sub> scores obtained with the 200 runs are shown in Fig. <xref rid="Fig7" ref-type="fig">7</xref> (blue boxplots, left panel) as a function of the number of iterations of the genetic algorithm. In parallel, for each run of the optimization method, a corresponding “random run” was created by generating, for each iteration, exactly the same number of random networks (random sub-networks of the PKN) as the number of networks generated by the genetic algorithm. For each iteration of the random run, we stored the fitness function value and <italic>s</italic>
<sub><italic>all</italic></sub> score of the best random network (i.e. with minimal fitness function value) obtained since the beginning of the run. The resulting distributions of best fitness function values and corresponding <italic>s</italic>
<sub><italic>all</italic></sub> scores obtained with the 200 “random runs” are shown in Fig. <xref rid="Fig7" ref-type="fig">7</xref> (grey boxplots, left panel) as a function of the number of iterations. Note that although Fig. <xref rid="Fig7" ref-type="fig">7</xref> presents data for iterations up to 285, the average run length was 171 iterations. Missing values from the end of each run until iteration 285 were replaced by the fitness function value and <italic>s</italic>
<sub><italic>all</italic></sub> score obtained in the last iteration of the run.<fig id="Fig7"><label>Fig. 7</label><caption><p>Genetic algorithm evaluation. <italic>Left panel</italic>: evolution of fitness function <bold>F</bold> = (<italic>f</italic>
<sub><italic>T</italic></sub>, − <italic>N</italic>
<sub><italic>ess. nodes</italic></sub>, <italic>N</italic>
<sub><italic>nodes</italic></sub>, − <italic>N</italic>
<sub><italic>edges</italic></sub>) and <italic>s</italic>
<sub><italic>all</italic></sub> score for the best network (i.e. with minimal fitness function) obtained during a run of the optimization method using the same input data as in Fig. <xref rid="Fig5" ref-type="fig">5</xref>. <italic>Blue boxplots</italic> summarize values obtained with 200 independent runs of the optimization method. <italic>Grey boxplots</italic> show corresponding results obtained with 200 “random runs”. Note that each <italic>box</italic> summarizes values obtained during 10 iterations (2000 data points). <italic>Right panel</italic>: fitness function and <italic>s</italic>
<sub><italic>all</italic></sub> score for the best network (according to the fitness function) obtained after a specified number of runs (horizontal axis). Each <italic>box</italic> summarizes 500 values, obtained by randomly sampling the given number of runs among 200 independent runs of the optimization method</p></caption><graphic xlink:href="12859_2016_1287_Fig7_HTML" id="MO7"/></fig>
</p>
      <p>When comparing results obtained with the genetic algorithm (blue) and random runs (grey), it is clear that the genetic algorithm is much more efficient at generating networks with low values of the fitness function. This is particularly apparent for the first component of the fitness function (<italic>f</italic>
<sub><italic>T</italic></sub> in upper left panel of Fig. <xref rid="Fig7" ref-type="fig">7</xref>), where optimized networks reach a median value <italic>f</italic>
<sub><italic>T</italic></sub> ≃ 0.020, while random runs reach only a median <italic>f</italic>
<sub><italic>T</italic></sub> ≃ 0.236. In addition, while the other components of the fitness function (<italic>N</italic>
<sub><italic>ess. nodes</italic></sub>, <italic>N</italic>
<sub><italic>nodes</italic></sub> and <italic>N</italic>
<sub><italic>edges</italic></sub>) tend to approach their optimal values in a similar way as in Fig. <xref rid="Fig5" ref-type="fig">5a</xref> using the genetic algorithm, this is not the case for the random runs. More importantly, the <italic>s</italic>
<sub><italic>all</italic></sub> score (lower left panel) increases quickly for optimized networks (blue) to reach a median value <italic>s</italic>
<sub><italic>all</italic></sub> ≃ 0.938, while it only marginally increases for random runs to reach a median <italic>s</italic>
<sub><italic>all</italic></sub> ≃ 0.788.</p>
      <p>In addition to the distribution of best fitness function values obtained during one run discussed above, we also characterized the distribution of best fitness function values obtained after multiple runs (right panel of Fig. <xref rid="Fig7" ref-type="fig">7</xref>). This is particularly relevant in the context of optimization based on genetic algorithms, where it is common practice to start multiple independent runs in parallel. We randomly sampled the specified number of runs (horizontal axis) among the 200 runs, storing the fitness function value and <italic>s</italic>
<sub><italic>all</italic></sub> score of the best network (according to the fitness function) found in the sampled runs. This process was repeated 500 times for each number of runs, so that each boxplot summarizes 500 values. Using multiple runs has a dramatic impact on the best value of the fitness function obtained with the genetic algorithm (blue boxes): the median value of the first component (<italic>f</italic>
<sub><italic>T</italic></sub> in upper right panel) decreases from <italic>f</italic>
<sub><italic>T</italic></sub> ≃ 0.020 with one run to <italic>f</italic>
<sub><italic>T</italic></sub> = 0 with 20 runs, while its dispersion strongly reduces, with an interquartile range that decreases from 0.052 with one run to 0 with 20 runs. Similarly, while the median <italic>s</italic>
<sub><italic>all</italic></sub> score increases from <italic>s</italic>
<sub><italic>all</italic></sub> ≃ 0.938 with one run to <italic>s</italic>
<sub><italic>all</italic></sub> ≃ 0.970 with 20 runs (lower right panel), its dispersion is reduced, with an interquartile range that decreases from 0.034 to 0.017. The other components of the fitness function (<italic>N</italic>
<sub><italic>ess. nodes</italic></sub>, <italic>N</italic>
<sub><italic>nodes</italic></sub> and <italic>N</italic>
<sub><italic>edges</italic></sub>) are only marginally improved by increasing the number of runs.</p>
      <p>The best value of the fitness function obtained with random runs (upper panel, grey boxes) also improves when increasing the number of runs, but it is still far from the best values obtained with the genetic algorithm. The <italic>s</italic>
<sub><italic>all</italic></sub> score obtained with random runs (lower panel, grey boxes) only slightly increases from <italic>s</italic>
<sub><italic>all</italic></sub> ≃ 0.788 with one run to <italic>s</italic>
<sub><italic>all</italic></sub> ≃ 0.797 with 20 runs.</p>
      <p>To summarize, Fig. <xref rid="Fig7" ref-type="fig">7</xref> shows that our implementation of the genetic algorithm is significantly more efficient than random sampling in finding solutions to the fitness function minimization problem.</p>
    </sec>
    <sec id="Sec14">
      <title>PKN quality</title>
      <p>In the previous sections we used an ideal PKN which contained only (direct or indirect) interactions observed after <italic>in silico</italic> perturbation experiments of the gold standard network. However, a PKN built from the literature will usually not be perfect; it may contain “noise” in the form of interactions that are not relevant to the particular biological context under study, while some relevant interactions may also be missing.</p>
      <p>To investigate the effect of noise in the PKN on the optimization method, we generated five PKNs (PKN 2 to 6 in Additional file <xref rid="MOESM4" ref-type="media">4</xref>) by adding 10, 20, 30, 40, and 50 % of noise to the ideal PKN, as defined in <xref rid="Sec2" ref-type="sec">Methods</xref> section. For each PKN, we started 500 independent runs of the optimization method and kept the best network (with minimal value of the fitness function) obtained with each run. Among the 500 resulting networks, only the 50 with minimal values of the fitness function were kept as model networks. The left panel of Fig. <xref rid="Fig8" ref-type="fig">8</xref> presents the distribution of fitness function values and <italic>s</italic>
<sub><italic>all</italic></sub> scores as a function of the PKN used as input (horizontal axis) for the resulting model networks (blue boxes), for random sub-networks of the PKNs used as input (grey boxes) and for the PKNs (black lines). The values of the fitness function obtained with model networks increase (worsen) as the fraction of noise in the PKN increases, with the median <italic>f</italic>
<sub><italic>T</italic></sub> reaching <italic>f</italic>
<sub><italic>T</italic></sub> ≃ 0.015 with 50 % noise. The number of nodes and edges also increases with noise, suggesting that it is not possible to find simple networks that are able to reproduce training set experiments when too many interactions are missing in the PKN.<fig id="Fig8"><label>Fig. 8</label><caption><p>PKN quality and training set size. Fitness function <bold>F</bold> = (<italic>f</italic>
<sub><italic>T</italic></sub>, − <italic>N</italic>
<sub><italic>ess. nodes</italic></sub>, <italic>N</italic>
<sub><italic>nodes</italic></sub>, − <italic>N</italic>
<sub><italic>edges</italic></sub>) and <italic>s</italic>
<sub><italic>all</italic></sub> score for model networks (<italic>blue boxplots</italic>), random sub-networks of the PKN (<italic>grey boxplots</italic>) and PKN (<italic>black line</italic>) as a function of noise in the input PKN (<italic>left panel</italic>), errors in the training set (<italic>centre panel</italic>) and size of the training set (<italic>right panel</italic>). <italic>Left panel</italic>: results based on the training set 1 given in Additional file <xref rid="MOESM4" ref-type="media">4</xref> and PKNs 1 to 6 (Additional file <xref rid="MOESM3" ref-type="media">3</xref>). <italic>Centre panel</italic>: results based on training set 1 with 0 to 50 % error (Additional file <xref rid="MOESM2" ref-type="media">2</xref>) and PKN 1 (Additional file <xref rid="MOESM4" ref-type="media">4</xref>). <italic>Right panel</italic>: results based on training sets 1, 2 and 3 (Additional file <xref rid="MOESM2" ref-type="media">2</xref>) and PKN 1 (Additional file <xref rid="MOESM4" ref-type="media">4</xref>). Each <italic>blue boxplot</italic> summarizes measurements on 50 model networks obtained out of 500 independent runs of the optimization method (more details in main text). Each <italic>grey boxplot</italic> summarizes measurements on 350 random sub-networks of the PKN used as input for the optimization method. Component <italic>N</italic>
<sub><italic>ess. nodes</italic></sub> of the fitness function was always optimal (<italic>N</italic>
<sub><italic>ess. nodes</italic></sub> = 14) and is not shown in this figure</p></caption><graphic xlink:href="12859_2016_1287_Fig8_HTML" id="MO8"/></fig>
</p>
      <p>As expected, the predictive power of model networks (<italic>s</italic>
<sub><italic>all</italic></sub> score, lower left panel) decreases with increasing noise in the PKN. However, the median <italic>s</italic>
<sub><italic>all</italic></sub> score is always above 0.798 even with 50 % noise in the PKN. In addition, the distribution of <italic>s</italic>
<sub><italic>all</italic></sub> scores is always significantly higher for model networks (blue) than for random networks (grey) and PKN (black). The decrease of <italic>s</italic>
<sub><italic>all</italic></sub> scores with increasing PKN noise suggests that our method makes good use of the information contained in the PKN, and that a carefully constructed PKN can increase the quality of the resulting model networks. The fact that model networks always have better <italic>s</italic>
<sub><italic>all</italic></sub> scores than PKNs also shows that our method is rather tolerant to errors in the PKN. Indeed, even with 50 % noise in the PKN, our method is able to output model networks that have more predictive power than the input PKN. However, if the PKN is known to be very noisy, it could be worth considering other methods which are not based on prior knowledge.</p>
    </sec>
    <sec id="Sec15">
      <title>Training set quality</title>
      <p>In the previous section we used an ideal training set obtained by measuring the response of the gold standard network to perturbations. To evaluate the robustness of the optimization method to errors in the training set, we generated five training sets by adding 10, 20, 30, 40, and 50 % of errors to the ideal training set (training sets 1 with 10 to 50 % error in Additional file <xref rid="MOESM2" ref-type="media">2</xref>), as described in the <xref rid="Sec2" ref-type="sec">Methods</xref> section.</p>
      <p>For each training set, we generated 50 model networks from 500 independent runs by following the procedure described in the previous sections. The centre panel of Fig. <xref rid="Fig8" ref-type="fig">8</xref> presents the distribution of fitness function values and <italic>s</italic>
<sub><italic>all</italic></sub> scores as a function of the fraction of errors in the input training set for the resulting model networks (blue boxes), for random sub-networks of the PKN (grey boxes) and for the PKN (black lines).</p>
      <p>The values of the fitness function dramatically increase (worsen) when the number of errors in the training set is increased. In particular, while model networks obtained with the ideal training set always perfectly reproduce all experiments in the training set (<italic>f</italic>
<sub><italic>T</italic></sub> = 0), about 9.9 % of the training set cannot be reproduced by model networks when the training set contains 10 % of errors (median <italic>f</italic>
<sub><italic>T</italic></sub> ≃ 0.099). When the training set contains 50 % of errors, <italic>f</italic>
<sub><italic>T</italic></sub> reaches a median value of 0.327, which means that model networks fail to reproduce about 33 % of the training set. This suggests that it is not possible to find a model network, built as a sub-graph of the PKN, which is able to reproduce all errors in our training set.</p>
      <p>As expected, the predictive power of model networks (<italic>s</italic>
<sub><italic>all</italic></sub> score, lower centre panel) decreases when increasing the fraction of errors in the training set, but this decrease is moderate. For instance, <italic>s</italic>
<sub><italic>all</italic></sub> scores are not significantly lower with 10 % of errors in the training set (median <italic>s</italic>
<sub><italic>all</italic></sub> ≃ 0.969) than with the ideal training set (median <italic>s</italic>
<sub><italic>all</italic></sub> ≃ 0.970). Moreover, for all training sets with up to 30 % of errors, <italic>s</italic>
<sub><italic>all</italic></sub> is clearly higher for model networks (blue) than for random sub-networks of the PKN (grey) and for the PKN (black). Only when the training set contains 50 % of errors does the median <italic>s</italic>
<sub><italic>all</italic></sub> score of model networks become lower than the <italic>s</italic>
<sub><italic>all</italic></sub> score of the PKN. However, even in this case, the median predictive power of model networks is still above 80 %. The moderate decrease of predictive power, together with the rapid increase of fitness function values when the number of errors in the training set increases, suggest that our optimization method is not greatly affected by overfitting. The use of a PKN contributes greatly to this result by drastically reducing the number of parameters in the model.</p>
    </sec>
    <sec id="Sec16">
      <title>Training set size</title>
      <p>In the previous experiments we used a comprehensive training set that included the states of all 14 essential nodes measured before and after over-expression of TNF, FASL or the combination of TNF and FASL, for seven mutant versions of the gold standard network (training set 1 in Additional file <xref rid="MOESM2" ref-type="media">2</xref>). To study the effect of reducing the training set coverage on the optimization method, we generated two smaller training sets (see <xref rid="Sec2" ref-type="sec">Methods</xref> section): a “medium” training set, which contains data for the wild-type mutant only (training set 2 in Additional file <xref rid="MOESM2" ref-type="media">2</xref>) and a “small” training set, containing only the initial physiological state (training set 3 in Additional file <xref rid="MOESM2" ref-type="media">2</xref>). Clearly, the small training set does not contain enough information to properly infer a model network, and it was used to study the behaviour of the optimization method in this limit. Following the same procedure as in the previous sections, for each training set we used the optimization method to generate 50 model networks out of 500 independent runs. The resulting distributions of fitness function values and <italic>s</italic>
<sub><italic>all</italic></sub> scores are shown in the right panel of Fig. <xref rid="Fig8" ref-type="fig">8</xref> (blue boxes) as a function of the training set used as input (horizontal axis), together with fitness function values and <italic>s</italic>
<sub><italic>all</italic></sub> scores measured on random sub-networks of the PKN (grey boxes) and directly on the PKN (black lines). Although model networks always perfectly reproduce all experiments in the training sets (<italic>f</italic>
<sub><italic>T</italic></sub> = 0, upper right panel), other components of the fitness function tend to improve when the size of the training set decreases. In particular, the number of nodes reaches its optimal value (<italic>N</italic>
<sub><italic>nodes</italic></sub> = 14) for medium and small training sets, while networks obtained with the small training set have more edges than networks obtained with large training set. This is due to the smaller training sets imposing fewer constraints on the networks than larger training sets, which leave more freedom to optimize the remaining components of the fitness function.</p>
      <p>Although the predictive power of model networks decreases with training set size (<italic>s</italic>
<sub><italic>all</italic></sub> score, lower right panel), it remains significantly higher than that of random sub-networks of the PKN (grey) and the complete PKN (black) for all training sets. Interestingly, while the small training set contains only the states of 14 essential nodes in one attractor of the unperturbed gold standard network, the resulting model networks still have a median <italic>s</italic>
<sub><italic>all</italic></sub> of 0.937, which means that approximately 94 % of the 1624 nodes states measured after all single nodes perturbations are predicted correctly.</p>
      <p>To summarize, although the predictive power of model networks decreases with the quantity of information contained in the training set, our optimization method was still able to produce networks with significantly improved predictive power compared to the input PKN and random sub-networks of the PKN when using reduced training sets.</p>
    </sec>
    <sec id="Sec17">
      <title>Fitness function: maximizing versus minimizing number of edges</title>
      <p>The choice of fitness function is an essential ingredient of network optimization methods. While the first two components of our fitness function (<italic>f</italic>
<sub><italic>T</italic></sub> and <italic>N</italic>
<sub><italic>ess. nodes</italic></sub>) can be easily understood, our choice of third and fourth components (<italic>N</italic>
<sub><italic>nodes</italic></sub> and <italic>N</italic>
<sub><italic>edges</italic></sub>) may not be so obvious. Indeed, these last two components were chosen to first minimize the number of nodes and then maximize the number of edges (among networks with same number of nodes), whereas a more usual choice of regularization consists in minimizing the number of edges.</p>
      <p>To motivate our choice of fitness function, we used our optimization method with the modified fitness function <bold>F</bold> = (<italic>f</italic>
<sub><italic>T</italic></sub>, − <italic>N</italic>
<sub><italic>ess. nodes</italic></sub>, <italic>N</italic>
<sub><italic>edges</italic></sub>) which minimizes the number of edges and does not constrain the number of nodes. For each input data set discussed in the previous sections, 50 model networks were generated out of 500 independent runs. Due to slower convergence of the genetic algorithm with this fitness function, we had to use 100 replicas instead of 50 to obtain model networks with comparable fitness function values. The resulting distributions of <italic>s</italic>
<sub><italic>all</italic></sub> scores are shown in Fig. <xref rid="Fig9" ref-type="fig">9</xref> (red boxes), together with <italic>s</italic>
<sub><italic>all</italic></sub> scores obtained previously by minimizing number of nodes and maximizing number of edges (blue boxes). In addition, <italic>s</italic>
<sub><italic>all</italic></sub> scores measured on random sub-networks of the PKN (grey boxes) and directly on the PKN (black lines) are also shown for comparison. In the following, we will abbreviate the approach of “maximizing the number of edges while minimizing the number of nodes” as simply “maximizing the number of edges”. The additional constraint on the node number has to be kept in mind.<fig id="Fig9"><label>Fig. 9</label><caption><p>Fitness function: maximizing versus minimizing number of edges. Comparison of predictive power (<italic>s</italic>
<sub><italic>all</italic></sub> score) of model networks obtained with the fitness function <bold>F</bold> = (<italic>f</italic>
<sub><italic>T</italic></sub>, − <italic>N</italic>
<sub><italic>ess. nodes</italic></sub>, <italic>N</italic>
<sub><italic>nodes</italic></sub>, − <italic>N</italic>
<sub><italic>edges</italic></sub>) which minimize number of nodes and subsequently maximize number of edges (<italic>blue boxplots</italic>), and fitness function <bold>F</bold> = (<italic>f</italic>
<sub><italic>T</italic></sub>, − <italic>N</italic>
<sub><italic>ess. nodes</italic></sub>, <italic>N</italic>
<sub><italic>edges</italic></sub>) which minimize number of edges (<italic>red boxplots</italic>). Except for <italic>s</italic>
<sub><italic>all</italic></sub> scores obtained by minimizing the number of edges (<italic>red</italic>), all results were taken from Fig. <xref rid="Fig8" ref-type="fig">8</xref>. Model networks optimized with minimization of the number of edges (<italic>red</italic>) used the same input data sets and the optimization procedure as in Fig. <xref rid="Fig8" ref-type="fig">8</xref>, except for the change of fitness function, and the use of 100 instead of 50 replicas</p></caption><graphic xlink:href="12859_2016_1287_Fig9_HTML" id="MO9"/></fig>
</p>
      <p>Clearly, the predictive power of model networks obtained by minimizing the number of edges is less sensitive to noise in the PKN used as input (left panel). With no or low noise, maximizing the number of edges is clearly a good strategy, as the <italic>s</italic>
<sub><italic>all</italic></sub> scores are significantly lower when minimizing the number of edges. When PKN noise increases, both approaches give comparable results, with slightly better, although not significantly, <italic>s</italic>
<sub><italic>all</italic></sub> scores obtained by minimizing number of edges with 30 and 40 % noise.</p>
      <p>Similarly, when the training set contain errors (centre panel), model networks obtained by maximizing the number of edges tend to have higher predictive power. Although the difference is more pronounced for low fractions of errors in training sets, median <italic>s</italic>
<sub><italic>all</italic></sub> scores obtained by maximizing the number of edges are always higher than scores obtained by minimizing the number of edges.</p>
      <p>The advantage of maximizing the number of edges becomes more striking when decreasing the size of the training set used as input (right panel). Indeed, while networks obtained by maximizing the number of edges have a median <italic>s</italic>
<sub><italic>all</italic></sub> score that slowly decreases from 0.970 to 0.937, networks obtained by minimizing the number of edges always have significantly lower <italic>s</italic>
<sub><italic>all</italic></sub> scores, reaching a median of 0.778 with small training set. More importantly, although networks obtained by minimizing the number of edges are significantly better than random sub-networks of the PKN and the PKN itself when using a large training set, they are not much better than the PKN when using a medium training set, and significantly worse than the PKN when using a small training set, with a median <italic>s</italic>
<sub><italic>all</italic></sub> score 0.778 barely better than the median <italic>s</italic>
<sub><italic>all</italic></sub> score 0.774 of random sub-networks of the PKN.</p>
      <p>These results can be understood by realizing that maximizing the number of edges generates networks which are as close as possible to the PKN, only removing edges that are in contradiction with the training set, and therefore use a maximum of information contained in the PKN. This is particularly interesting in the limit of small training sets, when the information contained in the training set is not sufficient to properly infer a model network. In this limit, in addition to the training set, our method heavily uses the information contained in the PKN, and therefore generates model networks with reasonably good predictive power. By contrast, minimizing the number of edges within the limit of small training sets results in over-simplified model networks that are not able to properly predict anything else than what they were trained for.</p>
      <p>This reasoning also explains why maximizing the number of edges is a better strategy when the quality of PKN is good, and becomes less attractive in the limit of very noisy PKN. What is interesting, and somewhat unexpected, is the fact that maximizing edges does not give significantly worse results than minimizing edges in the limit of very noisy PKNs.</p>
      <p>The main motivation behind minimizing the number of edges is usually based on Occam’s razor, i.e. the principle of parsimony. However, this approach can lead to oversimplification of the resulting model, for instance by removing alternative pathways that are necessary to ensure the known robustness of regulatory networks. The idea behind maximizing the number of edges is to keep this robustness and to reflect the complexity of biological networks. For a node with various documented biological functions, it seems artificial to reduce that node to only one of them, assuming that the input PKN was built carefully.</p>
    </sec>
    <sec id="Sec18">
      <title>Combined predictions</title>
      <p>In general, one should not expect the optimization problem discussed here to have a unique solution (network). If the training set does not contain enough information to completely constrain the problem then multiple solutions may be possible. If essential interactions are missing from the PKN then no sub-network of the PKN (model network) may be able to exactly reproduce all experiments in the training set (<italic>f</italic>
<sub><italic>T</italic></sub> = 0) and a potentially large number of solutions with equally good <italic>f</italic>
<sub><italic>T</italic></sub> &gt; 0 may be possible. Even when the optimization problem does have a unique optimal solution, heuristic optimization methods, like the genetic algorithm that we use, might be unable to find it, and instead output multiple sub-optimal networks with similar fitness function values. For all these reasons, a large set of model networks may be equally good solutions to the optimization problem.</p>
      <p>This multiplicity of model networks is not in contradiction with a unique network describing the underlying biological system (in this work: the gold standard network), but only reflects our lack of knowledge on the system. To summarize all these solutions, a common practice is to generate an average network as the union of all models networks, with a weight attached to each edge, such as the number of model networks in which it appears. However, unless all model networks are very similar, this consensus network is of limited interest since it does not retain the topology (feed-back loops, connectivity), and more importantly, the dynamical behaviour (attractor reachability graph) of the original model networks. Instead, we propose to summarize our results at the level of the predictions by measuring averages but also variability of node states predicted by all model networks. Intuitively, if a node state prediction varies a lot across networks, this could be due to a lack of information in the PKN and training set, and therefore could be correlated to prediction errors.</p>
      <p>To check whether prediction variability was correlated to prediction errors, we summarized the predictions of the 50 model networks obtained previously with each input data set (PKN and training set). We used the same predictions that were used to measure the <italic>s</italic>
<sub><italic>all</italic></sub> score (see <xref rid="Sec2" ref-type="sec">Methods</xref> section), i.e. the average states reached by a network after each single node perturbation of essential nodes, starting from each attractor of the gold standard network. For each input data set (PKN and training set), single node perturbation and initial state (gold standard network attractor), we evaluated the average and variance of the 50 average states predicted by the 50 model networks. We also evaluated the corresponding prediction error by measuring the absolute difference between average model networks’ predictions and average states reached by the gold standard network. This procedure led to 21,112 error versus variance measurements, one for each of the 14 essential nodes, with 29 single node perturbations (unperturbed, 14 nodes forced to 1, 14 nodes forced to 0), 4 attractors of the gold standard network and 13 input data sets (more details on this procedure are given in Additional file <xref rid="MOESM1" ref-type="media">1</xref>).</p>
      <p>The resulting distribution of error versus variance is shown in Fig. <xref rid="Fig10" ref-type="fig">10</xref>. This figure shows a strong correlation between error and variance, confirmed by a Spearman’s rank correlation coefficient of ≃ 0.96. This result suggests that the prediction error, which is usually unknown, can be (approximately) estimated by measuring the prediction variance provided that not only one, but multiple model networks are kept as solutions of the optimization problem.<fig id="Fig10"><label>Fig. 10</label><caption><p>Combined predictions: error versus variance. Distribution of errors as a function variance obtained by summarizing the predictions of the 50 model networks obtained which each input data set (more details in main text). The number <italic>N</italic> above each <italic>boxplot</italic> denotes the number of measurements in the boxplot</p></caption><graphic xlink:href="12859_2016_1287_Fig10_HTML" id="MO10"/></fig>
</p>
      <p>Ideally, variance should be estimated based on the full population of networks which are solutions of our optimization problem, or at least on a uniformly sampled subset of the solutions. However, due to the heuristic approach used here, our optimization method should in principle be unable to generate an exhaustive list of solutions, or to uniformly sample the set of solutions. The strong correlation observed in Fig. <xref rid="Fig10" ref-type="fig">10</xref> is therefore an interesting and non-trivial result, which shows that despite these limitations, our optimization method is able to sample sufficiently well the space of solutions.</p>
    </sec>
    <sec id="Sec19">
      <title>Related work</title>
      <p>A large amount of methods focusing on the problem of Boolean network inference have been published. In the following we will consider only methods that are similar to our method in the sense that they combine the use of experimental data against which Boolean networks are trained, together with prior knowledge to reduce the size of the search space. These methods are classified according to the type of data used in the training set.</p>
      <p>Several methods require training sets in the form of time series of experimental measurements. REACT [<xref ref-type="bibr" rid="CR13">13</xref>] and CellNopt [<xref ref-type="bibr" rid="CR14">14</xref>] use evolutionary algorithms to train networks against time series obtained with various network perturbations. Both methods only consider networks with synchronous dynamics. By assuming that the consecutive measurements in the time series corresponds to successive states of the network with synchronous dynamics, Breindl et al. [<xref ref-type="bibr" rid="CR4">4</xref>] can use linear programming to solve the network optimization problem. BoolNet [<xref ref-type="bibr" rid="CR15">15</xref>] implements the Best-Fit Extension [<xref ref-type="bibr" rid="CR16">16</xref>] and REVEAL [<xref ref-type="bibr" rid="CR17">17</xref>] algorithms to reconstruct networks from time series obtained with various network perturbations, and can use synchronous as well as asynchronous dynamics. RE:IN [<xref ref-type="bibr" rid="CR18">18</xref>] uses a Satisfiability Modulo Theories (SMT) solver to exhaustively find all networks that can exactly reproduce the training set, which consists of time series obtained under various network perturbations. Only synchronous dynamics is implemented in this method.</p>
      <p>Other methods focus on early responses to perturbations and only consider a small subset of two time points in each time series. Only the initial measurement and a second carefully chosen time point reflecting the initial response to the perturbation are kept in the training set. In addition to time series discussed above, CellNopt [<xref ref-type="bibr" rid="CR14">14</xref>] also implements a method based on a genetic algorithm to train networks on the early response to perturbations, assuming synchronous dynamics of the networks. Guziolowski et al. [<xref ref-type="bibr" rid="CR19">19</xref>] and Videla et al. [<xref ref-type="bibr" rid="CR5">5</xref>] use answer set programming to enumerate all networks that exactly reproduce the initial response to perturbations using synchronous dynamics, but also all suboptimal networks within a user defined tolerance.</p>
      <p>Another popular approach is to use a training set containing stable phenotypes assumed to be steady states (attractors with one state) of the network. These training sets contain only equilibrium properties of the network and lack information on the dynamics of the network. XPRED [<xref ref-type="bibr" rid="CR9">9</xref>] and PRUNET [<xref ref-type="bibr" rid="CR10">10</xref>] use evolutionary algorithms to find networks that have steady states as close as possible to the phenotypes given in the training set. Knapp and Kaderali [<xref ref-type="bibr" rid="CR3">3</xref>] reformulated the problem of finding networks with specific steady states obtained under various perturbations as a linear programming problem. A runtime comparison with these methods is given in Additional file <xref rid="MOESM5" ref-type="media">5</xref>.</p>
      <p>Our optimization method contrasts with the aforementioned approaches in a number of ways. First, our method combines information on both the dynamics (time series) and equilibrium properties (steady states) of the networks, while the aforementioned approaches use only one of these types of information. Indeed our training set can contain measurements performed on stable phenotypes that are assumed to correspond to attractors of the networks, together with measurements on their reachability upon perturbation of the network. Second, our method uses asynchronous dynamics, which is usually considered as more relevant for the description of biological networks than synchronous dynamics [<xref ref-type="bibr" rid="CR20">20</xref>]. By contrast, all methods discussed above, except BoolNet, use synchronous dynamics. Finally, our method attempts to maximize the number of edges in order to be as close as possible to the input PKN, while only Videla et al. [<xref ref-type="bibr" rid="CR9">9</xref>] suggest that minimizing the number of edges may not be the optimal approach.</p>
    </sec>
  </sec>
  <sec id="Sec20" sec-type="conclusion">
    <title>Conclusions</title>
    <p>Within the last years the wealth of experimental data from high-throughput technologies in different areas of biology has popularized the construction of a PKN to summarize and visualize the knowledge derived from this data. Unfortunately, although it is technically possible to directly transform such a network as a dynamical Boolean model, it may not behave as expected for a specific biological process because it usually includes interactions described in different biological contexts and/or experimental conditions, some of which could be absent in the biological process under study. The presence of these “wrong” or “inactive” interactions in the model may dramatically change its dynamical behaviour with consequent lack of reliability of its predictions.</p>
    <p>Here we propose a method to generate and optimize dynamical Boolean models by training a given PKN against experimental data describing either stable states or response to perturbation or both. The output of our method is a set of sub-networks of the PKN contextualized to the experimental conditions used to train the model. Simulations performed on such a network should yield more reliable predictions, helping researchers in hypothesis generation and experimental design. The general applicability of the method in a variety of biological contexts will make this approach of interest to biological and medical researchers.</p>
    <p>Future developments will include the implementation of the same strategy on a multi-valued discrete system (i.e. non-Boolean), which should allow a more precise description of gene activities and network dynamics. The current method could also be adapted to deal with the cyclic behaviour and time series of oscillatory processes.</p>
  </sec>
</body>
<back>
  <app-group>
    <app id="App1">
      <sec id="Sec21">
        <title>Additional files</title>
        <p>
          <media position="anchor" xlink:href="12859_2016_1287_MOESM1_ESM.pdf" id="MOESM1">
            <label>Additional file 1:</label>
            <caption>
              <p>Methods. Detailed description of the methods. (PDF 1329 kb)</p>
            </caption>
          </media>
          <media position="anchor" xlink:href="12859_2016_1287_MOESM2_ESM.pdf" id="MOESM2">
            <label>Additional file 2:</label>
            <caption>
              <p>Cell-fate decision model: <italic>in silico</italic> training sets. Training sets used to evaluate the optimization method. Each training set is given in the form of a transition graph, where each node contains a perturbation with the corresponding observation (stable phenotype) and edges denote a transition between stable phenotype upon change of condition (perturbation). Perturbations are specified using a combination of node names prefixed by – or + sign to specify knock-out (node state fixed to 0) or over-expression (node state fixed to 1). When multiple edges connect the same source node to different target nodes, it means that all transitions start from the same phenotype (same attractor of the network). Node states that were intentionally reversed to generate errors in training sets are shown in red. (PDF 9015 kb)</p>
            </caption>
          </media>
          <media position="anchor" xlink:href="12859_2016_1287_MOESM3_ESM.pdf" id="MOESM3">
            <label>Additional file 3:</label>
            <caption>
              <p>Cell-fate decision model: single node perturbations. List of transitions between attractors from unperturbed to single node perturbations. Each line corresponds to one edge in the attractor reachability graph. Attractors with more than one state are replaced by the average over all states in the attractor. (PDF 63 kb)</p>
            </caption>
          </media>
          <media position="anchor" xlink:href="12859_2016_1287_MOESM4_ESM.pdf" id="MOESM4">
            <label>Additional file 4:</label>
            <caption>
              <p>Cell-fate decision model: <italic>in silico</italic> PKNs. In silico PKNs for the cell-fate decision model. For each PKN, a graphical representation as well as the list of interactions is given. Interactions that were changed to introduce noise in the PKNs are shown in blue in the list of interactions. In the graphical representation, interactions that were changed to introduce noise in the PKNs are shown in magenta (negative interactions) and cyan (positive interactions). (PDF 314 kb)</p>
            </caption>
          </media>
          <media position="anchor" xlink:href="12859_2016_1287_MOESM5_ESM.pdf" id="MOESM5">
            <label>Additional file 5:</label>
            <caption>
              <p>Comparison with related methods. Runtime comparison between our implementation of the method (optimusqual) and related methods. (PDF 1190 kb)</p>
            </caption>
          </media>
        </p>
      </sec>
    </app>
  </app-group>
  <ack>
    <title>Acknowledgements</title>
    <p>We thank Alan Bridge for proofreading and critical reviewing of the manuscript. We thank Frédéric Schütz, Anastasia Chasapi and Nikolaos Berntenis for fruitful discussions.</p>
    <p>The computations were performed at the Vital-IT (<ext-link ext-link-type="uri" xlink:href="http://www.vital-it.ch/">http://www.vital-it.ch</ext-link>) Center for high-performance computing of the SIB Swiss Institute of Bioinformatics. Figures were produced with graphviz [<xref ref-type="bibr" rid="CR21">21</xref>, <xref ref-type="bibr" rid="CR22">22</xref>] (<ext-link ext-link-type="uri" xlink:href="http://www.graphviz.org/">http://www.graphviz.org</ext-link>) and the R package ggplot2 [<xref ref-type="bibr" rid="CR22">22</xref>, <xref ref-type="bibr" rid="CR23">23</xref>]. Libraries CUDD [<xref ref-type="bibr" rid="CR24">24</xref>], TRNG [<xref ref-type="bibr" rid="CR25">25</xref>] and boost [<xref ref-type="bibr" rid="CR26">26</xref>] were used in our implementation of the method (optimusqual).</p>
    <sec id="FPar7">
      <title>Funding</title>
      <p>JD was supported by the Roche Postdoc Fellowship (RPF) Program and by the SystemsX.ch project MoDeLoMX.</p>
    </sec>
    <sec id="FPar8">
      <title>Availability of data and material</title>
      <p>The optimization method was implemented in the software optimusqual. Executable binaries are available for download on the project home page.</p>
      <p><bold>Project name</bold>: optimusqual</p>
      <p><bold>Version</bold>: 1.0.5</p>
      <p><bold>Project home page</bold>: <ext-link ext-link-type="uri" xlink:href="http://www.vital-it.ch/software/optimusqual/">http://www.vital-it.ch/software/optimusqual/</ext-link></p>
      <p><bold>Programming language</bold>: C++</p>
      <p><bold>Operating system(s):</bold> Linux (64-bit)</p>
      <p>To use optimusqual, three input files are required: (1) a training set in xml format, (2) a prior knowledge network in boolSim network format [<xref ref-type="bibr" rid="CR12">12</xref>] and (3) a list of essential nodes (text file with one node per line). More details are given in the documention distributed with optimusqual.</p>
    </sec>
    <sec id="FPar9">
      <title>Authors’ contributions</title>
      <p>IX and ME helped to design the method and the study. JD designed and implemented the method, analyzed the data and helped to draft the manuscript. IC critically assessed the method and helped to draft the manuscript. AN and RL helped to design the method. All of the authors have read and approved the final manuscript.</p>
    </sec>
    <sec id="FPar10">
      <title>Competing interests</title>
      <p>The authors declare that they have no competing interests.</p>
    </sec>
    <sec id="FPar11">
      <title>Consent for publication</title>
      <p>Not applicable.</p>
    </sec>
    <sec id="FPar12">
      <title>Ethics approval and consent to participate</title>
      <p>Not applicable.</p>
    </sec>
  </ack>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <label>1.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ourfali</surname>
            <given-names>O</given-names>
          </name>
          <name>
            <surname>Shlomi</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Ideker</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Ruppin</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Sharan</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>SPINE: a framework for signaling-regulatory pathway inference from cause-effect experiments</article-title>
        <source>Bioinformatics (Oxford, England)</source>
        <year>2007</year>
        <volume>23</volume>
        <fpage>i359</fpage>
        <lpage>i366</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btm170</pub-id>
      </element-citation>
    </ref>
    <ref id="CR2">
      <label>2.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lan</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Smoly</surname>
            <given-names>IY</given-names>
          </name>
          <name>
            <surname>Rapaport</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Lindquist</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Fraenkel</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Yeger-Lotem</surname>
            <given-names>E</given-names>
          </name>
        </person-group>
        <article-title>ResponseNet: revealing signaling and regulatory networks linking genetic and transcriptomic screening data</article-title>
        <source>Nucleic Acids Res</source>
        <year>2011</year>
        <volume>39</volume>
        <fpage>W424</fpage>
        <lpage>W429</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkr359</pub-id>
        <?supplied-pmid 21576238?>
        <pub-id pub-id-type="pmid">21576238</pub-id>
      </element-citation>
    </ref>
    <ref id="CR3">
      <label>3.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Knapp</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Kaderali</surname>
            <given-names>L</given-names>
          </name>
        </person-group>
        <article-title>Reconstruction of cellular signal transduction networks using perturbation assays and linear programming</article-title>
        <source>PLoS One</source>
        <year>2013</year>
        <volume>8</volume>
        <fpage>e69220</fpage>
        <pub-id pub-id-type="doi">10.1371/journal.pone.0069220</pub-id>
        <?supplied-pmid 23935958?>
        <pub-id pub-id-type="pmid">23935958</pub-id>
      </element-citation>
    </ref>
    <ref id="CR4">
      <label>4.</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Breindl</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Chaves</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Allgower</surname>
            <given-names>F</given-names>
          </name>
        </person-group>
        <article-title>A linear reformulation of Boolean optimization problems and structure identification of gene regulation networks</article-title>
        <source>52nd IEEE Conference on Decision and Control. IEEE</source>
        <year>2013</year>
        <fpage>733</fpage>
        <lpage>738</lpage>
      </element-citation>
    </ref>
    <ref id="CR5">
      <label>5.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Videla</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Guziolowski</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Eduati</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Thiele</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Gebser</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Nicolas</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Saez-Rodriguez</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Schaub</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Siegel</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Learning Boolean logic models of signaling networks with ASP</article-title>
        <source>Theor Comput Sci</source>
        <year>2015</year>
        <volume>599</volume>
        <fpage>79</fpage>
        <lpage>101</lpage>
        <pub-id pub-id-type="doi">10.1016/j.tcs.2014.06.022</pub-id>
      </element-citation>
    </ref>
    <ref id="CR6">
      <label>6.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Saez-Rodriguez</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Alexopoulos</surname>
            <given-names>LG</given-names>
          </name>
          <name>
            <surname>Epperlein</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Samaga</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Lauffenburger</surname>
            <given-names>DA</given-names>
          </name>
          <name>
            <surname>Klamt</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Sorger</surname>
            <given-names>PK</given-names>
          </name>
        </person-group>
        <article-title>Discrete logic modelling as a means to link protein signalling networks with functional analysis of mammalian signal transduction</article-title>
        <source>Mol Syst Biol</source>
        <year>2009</year>
        <volume>5</volume>
        <fpage>331</fpage>
        <pub-id pub-id-type="doi">10.1038/msb.2009.87</pub-id>
        <?supplied-pmid 19953085?>
        <pub-id pub-id-type="pmid">19953085</pub-id>
      </element-citation>
    </ref>
    <ref id="CR7">
      <label>7.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Gat-Viks</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Tanay</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Shamir</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>Modeling and analysis of heterogeneous regulation in biological networks</article-title>
        <source>J Comput Biol</source>
        <year>2004</year>
        <volume>11</volume>
        <fpage>1034</fpage>
        <lpage>1049</lpage>
        <pub-id pub-id-type="doi">10.1089/cmb.2004.11.1034</pub-id>
        <?supplied-pmid 15662196?>
        <pub-id pub-id-type="pmid">15662196</pub-id>
      </element-citation>
    </ref>
    <ref id="CR8">
      <label>8.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Layek</surname>
            <given-names>RK</given-names>
          </name>
          <name>
            <surname>Datta</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Dougherty</surname>
            <given-names>ER</given-names>
          </name>
        </person-group>
        <article-title>From biological pathways to regulatory networks</article-title>
        <source>Mol BioSyst</source>
        <year>2011</year>
        <volume>7</volume>
        <fpage>843</fpage>
        <lpage>851</lpage>
        <pub-id pub-id-type="doi">10.1039/C0MB00263A</pub-id>
        <?supplied-pmid 21161088?>
        <pub-id pub-id-type="pmid">21161088</pub-id>
      </element-citation>
    </ref>
    <ref id="CR9">
      <label>9.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Crespo</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Krishna</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Le Béchec</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>del Sol</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Predicting missing expression values in gene regulatory networks using a discrete logic modeling optimization guided by network stable states</article-title>
        <source>Nucleic Acids Res</source>
        <year>2013</year>
        <volume>41</volume>
        <fpage>e8</fpage>
        <pub-id pub-id-type="doi">10.1093/nar/gks785</pub-id>
        <?supplied-pmid 22941654?>
        <pub-id pub-id-type="pmid">22941654</pub-id>
      </element-citation>
    </ref>
    <ref id="CR10">
      <label>10.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Rodriguez</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Crespo</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Androsova</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>del Sol</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Discrete logic modelling optimization to contextualize prior knowledge networks using PRUNET</article-title>
        <source>PLoS One</source>
        <year>2015</year>
        <volume>10</volume>
        <issue>6</issue>
        <fpage>e0127216</fpage>
        <pub-id pub-id-type="doi">10.1371/journal.pone.0127216</pub-id>
        <?supplied-pmid 26058016?>
        <pub-id pub-id-type="pmid">26058016</pub-id>
      </element-citation>
    </ref>
    <ref id="CR11">
      <label>11.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Calzone</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Tournier</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Fourquet</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Thieffry</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Zhivotovsky</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Barillot</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Zinovyev</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Mathematical modelling of cell-fate decision in response to death receptor engagement</article-title>
        <source>PLoS Comput Biol</source>
        <year>2010</year>
        <volume>6</volume>
        <fpage>e1000702</fpage>
        <pub-id pub-id-type="doi">10.1371/journal.pcbi.1000702</pub-id>
        <?supplied-pmid 20221256?>
        <pub-id pub-id-type="pmid">20221256</pub-id>
      </element-citation>
    </ref>
    <ref id="CR12">
      <label>12.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Garg</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Di Cara</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Xenarios</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Mendoza</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>De Micheli</surname>
            <given-names>G</given-names>
          </name>
        </person-group>
        <article-title>Synchronous versus asynchronous modeling of gene regulatory networks</article-title>
        <source>Bioinformatics (Oxford, England)</source>
        <year>2008</year>
        <volume>24</volume>
        <fpage>1917</fpage>
        <lpage>1925</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btn336</pub-id>
      </element-citation>
    </ref>
    <ref id="CR13">
      <label>13.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Vera-Licona</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Jarrah</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Garcia-Puente</surname>
            <given-names>LD</given-names>
          </name>
          <name>
            <surname>McGee</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Laubenbacher</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>An algebra-based method for inferring gene regulatory networks</article-title>
        <source>BMC Syst Biol</source>
        <year>2014</year>
        <volume>8</volume>
        <fpage>37</fpage>
        <pub-id pub-id-type="doi">10.1186/1752-0509-8-37</pub-id>
        <?supplied-pmid 24669835?>
        <pub-id pub-id-type="pmid">24669835</pub-id>
      </element-citation>
    </ref>
    <ref id="CR14">
      <label>14.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Terfve</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Cokelaer</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Henriques</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>MacNamara</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Goncalves</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Morris</surname>
            <given-names>MK</given-names>
          </name>
          <name>
            <surname>van Iersel</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Lauffenburger</surname>
            <given-names>DA</given-names>
          </name>
          <name>
            <surname>Saez-Rodriguez</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>CellNOptR: a flexible toolkit to train protein signaling networks to data using multiple logic formalisms</article-title>
        <source>BMC Syst Biol</source>
        <year>2012</year>
        <volume>6</volume>
        <fpage>133</fpage>
        <pub-id pub-id-type="doi">10.1186/1752-0509-6-133</pub-id>
        <?supplied-pmid 23079107?>
        <pub-id pub-id-type="pmid">23079107</pub-id>
      </element-citation>
    </ref>
    <ref id="CR15">
      <label>15.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Müssel</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Hopfensitz</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Kestler</surname>
            <given-names>HA</given-names>
          </name>
        </person-group>
        <article-title>BoolNet-an R package for generation, reconstruction and analysis of Boolean networks</article-title>
        <source>Bioinformatics</source>
        <year>2010</year>
        <volume>26</volume>
        <fpage>1378</fpage>
        <lpage>1380</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btq124</pub-id>
        <?supplied-pmid 20378558?>
        <pub-id pub-id-type="pmid">20378558</pub-id>
      </element-citation>
    </ref>
    <ref id="CR16">
      <label>16.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lähdesmäki</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Shmulevich</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Yli-harja</surname>
            <given-names>O</given-names>
          </name>
        </person-group>
        <article-title>On learning gene regulatory networks under the boolean network model</article-title>
        <source>Mach Learn</source>
        <year>2003</year>
        <volume>52</volume>
        <fpage>147</fpage>
        <lpage>167</lpage>
        <pub-id pub-id-type="doi">10.1023/A:1023905711304</pub-id>
      </element-citation>
    </ref>
    <ref id="CR17">
      <label>17.</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Liang</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Fuhrman</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Somogyi</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>REVEAL, a general reverse engineering algorithm for inference of genetic network architecture</article-title>
        <source>Pacific Symposium on Biocomputing</source>
        <year>1998</year>
        <fpage>18</fpage>
        <lpage>29</lpage>
      </element-citation>
    </ref>
    <ref id="CR18">
      <label>18.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Dunn</surname>
            <given-names>S-J</given-names>
          </name>
          <name>
            <surname>Martello</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Yordanov</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Emmott</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Smith</surname>
            <given-names>AG</given-names>
          </name>
        </person-group>
        <article-title>Defining an essential transcription factor program for naïve pluripotency</article-title>
        <source>Science (New York, NY)</source>
        <year>2014</year>
        <volume>344</volume>
        <fpage>1156</fpage>
        <lpage>1160</lpage>
        <pub-id pub-id-type="doi">10.1126/science.1248882</pub-id>
      </element-citation>
    </ref>
    <ref id="CR19">
      <label>19.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Guziolowski</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Videla</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Eduati</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Thiele</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Cokelaer</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Siegel</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Saez-Rodriguez</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Exhaustively characterizing feasible logic models of a signaling network using Answer Set Programming</article-title>
        <source>Bioinformatics (Oxford, England)</source>
        <year>2013</year>
        <volume>29</volume>
        <fpage>2320</fpage>
        <lpage>2326</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btt393</pub-id>
      </element-citation>
    </ref>
    <ref id="CR20">
      <label>20.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Saadatpour</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Albert</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Albert</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>Attractor analysis of asynchronous Boolean models of signal transduction networks</article-title>
        <source>J Theor Biol</source>
        <year>2010</year>
        <volume>266</volume>
        <fpage>641</fpage>
        <lpage>656</lpage>
        <pub-id pub-id-type="doi">10.1016/j.jtbi.2010.07.022</pub-id>
        <?supplied-pmid 20659480?>
        <pub-id pub-id-type="pmid">20659480</pub-id>
      </element-citation>
    </ref>
    <ref id="CR21">
      <label>21.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Gansner</surname>
            <given-names>ER</given-names>
          </name>
          <name>
            <surname>North</surname>
            <given-names>SC</given-names>
          </name>
        </person-group>
        <article-title>Open graph visualization system and its applications to software engineering</article-title>
        <source>Software - Practice and Experience</source>
        <year>2000</year>
        <volume>30</volume>
        <fpage>1203</fpage>
        <lpage>1233</lpage>
        <pub-id pub-id-type="doi">10.1002/1097-024X(200009)30:11&lt;1203::AID-SPE338&gt;3.0.CO;2-N</pub-id>
      </element-citation>
    </ref>
    <ref id="CR22">
      <label>22.</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <collab>R Core Team</collab>
        </person-group>
        <source>R: a language and environment for statistical computing</source>
        <year>2015</year>
        <publisher-loc>Vienna</publisher-loc>
        <publisher-name>R Foundation for Statistical Computing</publisher-name>
      </element-citation>
    </ref>
    <ref id="CR23">
      <label>23.</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Wickham</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <source>ggplot2: elegant graphics for data analysis</source>
        <year>2009</year>
        <publisher-loc>New York</publisher-loc>
        <publisher-name>Springer</publisher-name>
      </element-citation>
    </ref>
    <ref id="CR24">
      <label>24.</label>
      <mixed-citation publication-type="other">CUDD: CU Decision Diagram Package [<ext-link ext-link-type="uri" xlink:href="http://vlsi.colorado.edu/personal/fabio/">http://vlsi.colorado.edu/personal/fabio/</ext-link>]</mixed-citation>
    </ref>
    <ref id="CR25">
      <label>25.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Bauke</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Mertens</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>Random numbers for large-scale distributed Monte Carlo simulations</article-title>
        <source>Phys Rev E</source>
        <year>2007</year>
        <volume>75</volume>
        <fpage>066701</fpage>
        <pub-id pub-id-type="doi">10.1103/PhysRevE.75.066701</pub-id>
      </element-citation>
    </ref>
    <ref id="CR26">
      <label>26.</label>
      <mixed-citation publication-type="other">Boost C++ libraries [<ext-link ext-link-type="uri" xlink:href="http://www.boost.org/">http://www.boost.org</ext-link>]</mixed-citation>
    </ref>
  </ref-list>
</back>
