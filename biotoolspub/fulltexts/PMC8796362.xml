<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id>
    <journal-id journal-id-type="publisher-id">bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1367-4803</issn>
    <issn pub-type="epub">1367-4811</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">8796362</article-id>
    <article-id pub-id-type="pmid">34849583</article-id>
    <article-id pub-id-type="doi">10.1093/bioinformatics/btab786</article-id>
    <article-id pub-id-type="publisher-id">btab786</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Original Papers</subject>
        <subj-group subj-group-type="category-toc-heading">
          <subject>Genome Analysis</subject>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI01060</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>PIntMF: Penalized Integrative Matrix Factorization method for multi-omics data</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-9133-780X</contrib-id>
        <name>
          <surname>Pierre-Jean</surname>
          <given-names>Morgane</given-names>
        </name>
        <xref rid="btab786-cor1" ref-type="corresp"/>
        <aff><institution>Centre National de Recherche en Génomique Humaine, CEA, Université de Paris-Saclay</institution>, Evry, <country country="FR">France</country></aff>
        <!--mpierrejean.pro@gmail.com-->
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Mauger</surname>
          <given-names>Florence</given-names>
        </name>
        <aff><institution>Centre National de Recherche en Génomique Humaine, CEA, Université de Paris-Saclay</institution>, Evry, <country country="FR">France</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-5358-4463</contrib-id>
        <name>
          <surname>Deleuze</surname>
          <given-names>Jean-François</given-names>
        </name>
        <aff><institution>Centre National de Recherche en Génomique Humaine, CEA, Université de Paris-Saclay</institution>, Evry, <country country="FR">France</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Le Floch</surname>
          <given-names>Edith</given-names>
        </name>
        <aff><institution>Centre National de Recherche en Génomique Humaine, CEA, Université de Paris-Saclay</institution>, Evry, <country country="FR">France</country></aff>
      </contrib>
    </contrib-group>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Marschall</surname>
          <given-names>Tobias</given-names>
        </name>
        <role>Associate Editor</role>
      </contrib>
    </contrib-group>
    <author-notes>
      <corresp id="btab786-cor1">To whom correspondence should be addressed. <email>mpierrejean.pro@gmail.com</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <day>15</day>
      <month>2</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2021-11-26">
      <day>26</day>
      <month>11</month>
      <year>2021</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>26</day>
      <month>11</month>
      <year>2021</year>
    </pub-date>
    <volume>38</volume>
    <issue>4</issue>
    <fpage>900</fpage>
    <lpage>907</lpage>
    <history>
      <date date-type="received">
        <day>11</day>
        <month>3</month>
        <year>2021</year>
      </date>
      <date date-type="rev-recd">
        <day>30</day>
        <month>9</month>
        <year>2021</year>
      </date>
      <date date-type="editorial-decision">
        <day>11</day>
        <month>11</month>
        <year>2021</year>
      </date>
      <date date-type="accepted">
        <day>11</day>
        <month>11</month>
        <year>2021</year>
      </date>
      <date date-type="corrected-typeset">
        <day>03</day>
        <month>12</month>
        <year>2021</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2021. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2021</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbynclicense">https://creativecommons.org/licenses/by-nc/4.0/</ali:license_ref>
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution-NonCommercial License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by-nc/4.0/">https://creativecommons.org/licenses/by-nc/4.0/</ext-link>), which permits non-commercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited. For commercial re-use, please contact journals.permissions@oup.com</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="btab786.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Motivation</title>
        <p>It is more and more common to perform multi-omics analyses to explore the genome at diverse levels and not only at a single level. Through integrative statistical methods, multi-omics data have the power to reveal new biological processes, potential biomarkers and subgroups in a cohort. Matrix factorization (MF) is an unsupervised statistical method that allows a clustering of individuals, but also reveals relevant omics variables from the various blocks.</p>
      </sec>
      <sec id="s2">
        <title>Results</title>
        <p>Here, we present PIntMF (Penalized Integrative Matrix Factorization), an MF model with sparsity, positivity and equality constraints. To induce sparsity in the model, we used a classical Lasso penalization on variable and individual matrices. For the matrix of samples, sparsity helps in the clustering, while normalization (matching an equality constraint) of inferred coefficients is added to improve interpretation. Moreover, we added an automatic tuning of the sparsity parameters using the famous glmnet package. We also proposed three criteria to help the user to choose the number of latent variables. PIntMF was compared with other state-of-the-art integrative methods including feature selection techniques in both synthetic and real data. PIntMF succeeds in finding relevant clusters as well as variables in two types of simulated data (correlated and uncorrelated). Next, PIntMF was applied to two real datasets (Diet and cancer), and it revealed interpretable clusters linked to available clinical data. Our method outperforms the existing ones on two criteria (clustering and variable selection). We show that PIntMF is an easy, fast and powerful tool to extract patterns and cluster samples from multi-omics data.</p>
      </sec>
      <sec id="s3">
        <title>Availability and implementation</title>
        <p>An R package is available at <ext-link xlink:href="https://github.com/mpierrejean/pintmf" ext-link-type="uri">https://github.com/mpierrejean/pintmf</ext-link>.</p>
      </sec>
      <sec id="s5">
        <title>Supplementary information</title>
        <p><xref rid="sup1" ref-type="supplementary-material">Supplementary data</xref> are available at <italic toggle="yes">Bioinformatics</italic> online.</p>
      </sec>
    </abstract>
    <counts>
      <page-count count="8"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec id="S1">
    <title>1 Introduction</title>
    <p>The improvement of high-throughput biological technologies enables the production of various omics data such as genomic, transcriptomic, epigenomic, proteomic and metabolomic data (<xref rid="btab786-B27" ref-type="bibr">Ritchie <italic toggle="yes">et al.</italic>, 2015</xref>; <xref rid="btab786-B47" ref-type="bibr">Yugi <italic toggle="yes">et al.</italic>, 2016</xref>). The generation of these data allows investigating biological processes in cancer or complex diseases. For example, The Cancer Genome Atlas [TCGA (<xref rid="btab786-B21" ref-type="bibr">Network <italic toggle="yes">et al.</italic>, 2012</xref>)] has already produced numerous omics data for a set of 32 cancer types (<xref rid="btab786-B41" ref-type="bibr">Vasaikar <italic toggle="yes">et al.</italic>, 2018</xref>). Recently, other multi-omics studies on complex diseases and single-cell data have been published (<xref rid="btab786-B2" ref-type="bibr">Bock <italic toggle="yes">et al.</italic>, 2016</xref>; <xref rid="btab786-B29" ref-type="bibr">Rowlands <italic toggle="yes">et al.</italic>, 2014</xref>; <xref rid="btab786-B46" ref-type="bibr">Yang, 2020</xref>).</p>
    <p>However, integrating omics data addresses several statistical challenges, such as dealing with a large number of variables, few samples and data heterogeneity (<xref rid="btab786-B1" ref-type="bibr">Bersanelli <italic toggle="yes">et al.</italic>, 2016</xref>). Indeed, the statistical distributions of omics data are very heterogeneous. For instance, mutations can be modeled by a binary distribution, while RNAseq data can be modeled by a Negative Binomial distribution and metabolomic data by a Gaussian distribution. In addition, the omic block sizes could vary from one hundred to one billion variables. Furthermore, collecting several types of omics data from a single sample could be difficult due to the cost and access to the biological material.</p>
    <p>Over the past decade, unsupervised integrative methods have been developed to analyze multi-omics datasets and to identify potential biomarkers and new classifications in complex diseases (<xref rid="btab786-B5" ref-type="bibr">Cantini <italic toggle="yes">et al.</italic>, 2020</xref>; <xref rid="btab786-B8" ref-type="bibr">Chauvel <italic toggle="yes">et al.</italic>, 2020</xref>; <xref rid="btab786-B13" ref-type="bibr">Huang <italic toggle="yes">et al.</italic>, 2017</xref>; <xref rid="btab786-B23" ref-type="bibr">Pierre-Jean <italic toggle="yes">et al.</italic>, 2020</xref>; <xref rid="btab786-B40" ref-type="bibr">Tini <italic toggle="yes">et al.</italic>, 2019</xref>). Blocks of omics data can be seen as matrices, and relevant information can be extracted using dimension reduction methods, particularly, matrix factorization (MF) methods (<xref rid="btab786-B30" ref-type="bibr">Sastry <italic toggle="yes">et al.</italic>, 2020</xref>) and canonical correlation analysis (CCA) (<xref rid="btab786-B37" ref-type="bibr">Tenenhaus and Tenenhaus, 2011</xref>).</p>
    <p>CCA methods are used to integrate multi-omics data and aim to maximize the correlation between omics datasets under certain constraints (<xref rid="btab786-B28" ref-type="bibr">Rodosthenous <italic toggle="yes">et al.</italic>, 2020</xref>; <xref rid="btab786-B38" ref-type="bibr">Tenenhaus <italic toggle="yes">et al.</italic>, 2014</xref>; <xref rid="btab786-B37" ref-type="bibr">Tenenhaus and Tenenhaus, 2011</xref>).</p>
    <p>Then, MF techniques infer two matrices when applied to a single omic dataset: the first one describes the structure between variables (e.g. genes, probes, regions) and the second one describes the structure between samples.</p>
    <p>One famous MF method is the Non-Negative Matrix Factorization [NMF (<xref rid="btab786-B17" ref-type="bibr">Lee and Seung, 1999</xref>)]. This method implements non-negativity constraints on the two inferred matrices. NMF provides a way to explain the structure of data by providing variable profiles (dictionary for each dimension). NMF also enables a classification of the samples thanks to the second matrix. The NMF is a commonly applied method used for a single omic block to identify disease subtypes in gene expression data (<xref rid="btab786-B4" ref-type="bibr">Burstein <italic toggle="yes">et al.</italic>, 2015</xref>) or recently, in DNA methylation data (<xref rid="btab786-B26" ref-type="bibr">Reilly <italic toggle="yes">et al.</italic>, 2019</xref>).</p>
    <p>More recently, extensions of MF have been developed to perform integrative analysis (<xref rid="btab786-B7" ref-type="bibr">Chalise <italic toggle="yes">et al.</italic>, 2014</xref>; <xref rid="btab786-B9" ref-type="bibr">Chen and Zhang, 2018</xref>; <xref rid="btab786-B20" ref-type="bibr">Mo <italic toggle="yes">et al.</italic>, 2013</xref>). MF extensions need to infer more than two matrices: one matrix for each omic block is computed and one matrix for samples.</p>
    <p>MF showed that it is a powerful technique to integrate heterogeneous data (<xref rid="btab786-B5" ref-type="bibr">Cantini <italic toggle="yes">et al.</italic>, 2020</xref>; <xref rid="btab786-B8" ref-type="bibr">Chauvel <italic toggle="yes">et al.</italic>, 2020</xref>; <xref rid="btab786-B23" ref-type="bibr">Pierre-Jean <italic toggle="yes">et al.</italic>, 2020</xref>). In our article, we propose a Penalized Integrative Matrix Factorization method called PIntMF, to discover new patterns and a new classification of a cohort. First, to add sparsity on the first inferred matrix (corresponding to the variable blocks), we used a common regularization technique: the Least Absolute Shrinkage and Selection Operator [LASSO (<xref rid="btab786-B39" ref-type="bibr">Tibshirani, 1996</xref>)]. Moreover, the sparsity on the variable block helps to the interpretation of patterns that drive the clustering of the samples. Then, sparsity, non-negativity and equality constraints are added to the second matrix (corresponding to the samples) to improve the interpretability of the clustering. The originality is the mix of the constraints for the clustering of the samples and the discovery of potential biomarkers.</p>
    <p>In addition, we propose criteria to choose the number of latent variables and to properly initialize the algorithm.</p>
    <p>The performance of this new unsupervised model was evaluated on both simulated and real data. First, we applied PIntMF on a simulated framework introduced by our group in <xref rid="btab786-B23" ref-type="bibr">Pierre-Jean <italic toggle="yes">et al.</italic> (2020)</xref> and on a simulated framework from <xref rid="btab786-B10" ref-type="bibr">Chung and Kang (2019)</xref>. We compared our method to several existing unsupervised methods that perform both variable selection and clustering: intNMF (<xref rid="btab786-B6" ref-type="bibr">Chalise and Fridley, 2017</xref>), SGCCA (<xref rid="btab786-B38" ref-type="bibr">Tenenhaus <italic toggle="yes">et al.</italic>, 2014</xref>), MoCluster (<xref rid="btab786-B18" ref-type="bibr">Meng <italic toggle="yes">et al.</italic>, 2016</xref>), CIMLR (<xref rid="btab786-B24" ref-type="bibr">Ramazzotti <italic toggle="yes">et al.</italic>, 2018</xref>) and iClusterPlus (<xref rid="btab786-B19" ref-type="bibr">Mo and Shen, 2018</xref>). Then, we applied the model on a murine liver dataset (<xref rid="btab786-B45" ref-type="bibr">Williams <italic toggle="yes">et al.</italic>, 2016</xref>) and glioblastoma cancer data from TCGA already used in <xref rid="btab786-B32" ref-type="bibr">Shen <italic toggle="yes">et al.</italic> (2012)</xref>.</p>
  </sec>
  <sec id="S2">
    <title>2 Materials and methods</title>
    <sec id="S3">
      <title>2.1 Model description</title>
      <p>In the following, <bold>A</bold> denotes a matrix, <bold>a</bold> is a vector and <italic toggle="yes">a</italic> is a scalar. We consider <italic toggle="yes">K</italic> matrices <inline-formula id="IE1"><mml:math id="IM1" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mi>K</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> as the input of each method. Each matrix <inline-formula id="IE2"><mml:math id="IM2" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is of size <inline-formula id="IE3"><mml:math id="IM3" display="inline" overflow="scroll"><mml:mrow><mml:mi>n</mml:mi><mml:mo>×</mml:mo><mml:msub><mml:mrow><mml:mi>J</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> (<italic toggle="yes">n</italic> is the number of samples and <italic toggle="yes">J<sub>k</sub></italic> the number of variables for the block <italic toggle="yes">k</italic>). In this article, we propose a model based on the matrix factorization method, i.e.:
<disp-formula id="E1"><label>(1)</label><mml:math id="M1" display="block" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msup><mml:mo>≈</mml:mo><mml:mi mathvariant="bold">W</mml:mi><mml:msup><mml:mrow><mml:mi mathvariant="bold">H</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msup></mml:mrow></mml:math></disp-formula>where <bold>W</bold> denotes a common basis matrix and <inline-formula id="IE4"><mml:math id="IM4" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">H</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula> a specific coefficient matrix associated with the block <italic toggle="yes">k</italic>. <bold>W</bold> is of size <italic toggle="yes">n </italic>×<italic toggle="yes"> P</italic> and <inline-formula id="IE5"><mml:math id="IM5" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">H</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula> is of size <inline-formula id="IE6"><mml:math id="IM6" display="inline" overflow="scroll"><mml:mrow><mml:mi>P</mml:mi><mml:mo>×</mml:mo><mml:msub><mml:mrow><mml:mi>J</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>. Therefore, the variable <italic toggle="yes">P</italic> is the number of latent variables in the model.</p>
      <p>To ensure identifiability and improve interpretation of the model, non-negativity and sparsity constraints are imposed on <bold>W</bold> [as in intNMF model described in <xref rid="btab786-B6" ref-type="bibr">Chalise and Fridley (2017)</xref>]. <bold>W</bold> will be used to cluster samples simultaneously across the <italic toggle="yes">K</italic> omics blocks. On <inline-formula id="IE7"><mml:math id="IM7" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">H</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula>, a sparsity constraint is imposed to perform variable selection simultaneously to the clustering of samples. Sparsity ensures a better interpretation of the variables that drive the clustering of samples. The model 1 can be extended to the following optimization problem:
<disp-formula id="E2"><label>(2)</label><mml:math id="M2" display="block" overflow="scroll"><mml:mtable><mml:mtr><mml:mtd><mml:munder><mml:mrow><mml:mi>min</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold">W</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">H</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">H</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msup></mml:mrow></mml:munder><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:munderover><mml:mrow><mml:mo>|</mml:mo><mml:mo>|</mml:mo></mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msup><mml:mo>−</mml:mo><mml:mi mathvariant="bold">W</mml:mi><mml:msup><mml:mrow><mml:mi mathvariant="bold">H</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msup><mml:mo>|</mml:mo><mml:msubsup><mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mi>F</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mi>k</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">H</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msup><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo>+</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:mrow><mml:msub><mml:mrow><mml:mo>μ</mml:mo></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">w</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>•</mml:mo></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo> </mml:mo><mml:mi mathvariant="normal">s</mml:mi><mml:mo>.</mml:mo><mml:mi mathvariant="normal">t</mml:mi><mml:mo>.</mml:mo><mml:mo> </mml:mo><mml:mi mathvariant="bold">W</mml:mi><mml:mo>≥</mml:mo><mml:mn>0</mml:mn></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>where <inline-formula id="IE8"><mml:math id="IM8" display="inline" overflow="scroll"><mml:mrow><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">H</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msup><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>P</mml:mi></mml:munderover><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>J</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:munderover><mml:mo>|</mml:mo></mml:mrow><mml:msubsup><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msubsup><mml:mo>|</mml:mo></mml:mrow></mml:math></inline-formula>.</p>
    </sec>
    <sec id="S4">
      <title>2.2 Solving equation</title>
      <p>The optimization problem 2 is not convex on <inline-formula id="IE9"><mml:math id="IM9" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold">W</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">H</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">H</mml:mi></mml:mrow><mml:mi>K</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula>, but is convex separately on each matrix. Consequently, it can be solved alternatively on <inline-formula id="IE10"><mml:math id="IM10" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold">W</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">H</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">H</mml:mi></mml:mrow><mml:mi>K</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula> until convergence.</p>
      <p><italic toggle="yes">Solve on</italic> <bold>W</bold>: In this step, each <inline-formula id="IE11"><mml:math id="IM11" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">H</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula> is fixed and the problem 3 is solved on <bold>W</bold>.
<disp-formula id="E3"><label>(3)</label><mml:math id="M3" display="block" overflow="scroll"><mml:mrow><mml:munder><mml:mrow><mml:mi>min</mml:mi></mml:mrow><mml:mi mathvariant="bold">W</mml:mi></mml:munder><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:munderover><mml:mrow><mml:mo>|</mml:mo><mml:mo>|</mml:mo></mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msup><mml:mo>−</mml:mo><mml:mi mathvariant="bold">W</mml:mi><mml:msup><mml:mrow><mml:mi mathvariant="bold">H</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msup><mml:mo>|</mml:mo><mml:msubsup><mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mi>F</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>+</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:mrow><mml:msub><mml:mrow><mml:mo>μ</mml:mo></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">w</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>•</mml:mo></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo> </mml:mo><mml:mtext>st</mml:mtext><mml:mo>.</mml:mo><mml:mo> </mml:mo><mml:mi mathvariant="bold">W</mml:mi><mml:mo>≥</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></disp-formula></p>
      <p>All individuals are independent for the weights <bold>W</bold> when <inline-formula id="IE12"><mml:math id="IM12" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">H</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula> are fixed. The problem for an individual <italic toggle="yes">i</italic> can be written as follows:
<disp-formula id="E4"><label>(4)</label><mml:math id="M4" display="block" overflow="scroll"><mml:mrow><mml:munder><mml:mrow><mml:mi>min</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">w</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>•</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:munder><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:munderover><mml:mrow><mml:mo>|</mml:mo><mml:mo>|</mml:mo></mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>•</mml:mo></mml:mrow><mml:mi>k</mml:mi></mml:msubsup><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">w</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>•</mml:mo></mml:mrow></mml:msub><mml:msup><mml:mrow><mml:mi mathvariant="bold">H</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msup><mml:mo>|</mml:mo><mml:msup><mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mo>μ</mml:mo></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">w</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>•</mml:mo></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo> </mml:mo><mml:mtext>st</mml:mtext><mml:mo>.</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">w</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>•</mml:mo></mml:mrow></mml:msub><mml:mo>≥</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></disp-formula></p>
      <p><xref rid="E4" ref-type="disp-formula">Equation 4</xref> is equivalent to
<disp-formula id="E5"><label>(5)</label><mml:math id="M5" display="block" overflow="scroll"><mml:mrow><mml:munder><mml:mrow><mml:mi>min</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">w</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>•</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:munder><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:munderover><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>J</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:munderover><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msubsup><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">w</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>•</mml:mo></mml:mrow></mml:msub><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">h</mml:mi></mml:mrow><mml:mrow><mml:mo>•</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mo>μ</mml:mo></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">w</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>•</mml:mo></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo> </mml:mo><mml:mtext>st</mml:mtext><mml:mo>.</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">w</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>•</mml:mo></mml:mrow></mml:msub><mml:mo>≥</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></disp-formula></p>
      <p>The optimization problem described by 5 is a classical lasso problem with a positivity constraint. It can be easily and fastly solved by glmnet R package (<xref rid="btab786-B16" ref-type="bibr">Jerome <italic toggle="yes">et al.</italic>, 2010</xref>).</p>
      <p><italic toggle="yes">Solve on</italic> <inline-formula id="IE13"><mml:math id="IM13" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">H</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula>: When <bold>W</bold> is fixed, each <inline-formula id="IE14"><mml:math id="IM14" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">H</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula> can be solved independently. In this section, to be more readable, the index <italic toggle="yes">k</italic> is removed from the equations.
<disp-formula id="E6"><label>(6)</label><mml:math id="M6" display="block" overflow="scroll"><mml:mrow><mml:munder><mml:mrow><mml:mi>min</mml:mi></mml:mrow><mml:mi mathvariant="bold">H</mml:mi></mml:munder><mml:mi>Q</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">H</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:munder><mml:mrow><mml:mi>min</mml:mi></mml:mrow><mml:mi mathvariant="bold">H</mml:mi></mml:munder><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:mi mathvariant="bold">X</mml:mi><mml:mo>−</mml:mo><mml:mi mathvariant="bold">W</mml:mi><mml:mi mathvariant="bold">H</mml:mi><mml:mo>|</mml:mo><mml:msubsup><mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mi>F</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>+</mml:mo><mml:mo>λ</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>P</mml:mi></mml:munderover><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>J</mml:mi></mml:munderover><mml:mo>|</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>|</mml:mo></mml:mrow></mml:math></disp-formula>
 <disp-formula id="E7"><mml:math id="M7" display="block" overflow="scroll"><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mi>Q</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">H</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mtext>Trace</mml:mtext><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">X</mml:mi><mml:mo>−</mml:mo><mml:mi mathvariant="bold">W</mml:mi><mml:mi mathvariant="bold">H</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">X</mml:mi><mml:mo>−</mml:mo><mml:mi mathvariant="bold">W</mml:mi><mml:mi mathvariant="bold">H</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mi>T</mml:mi></mml:msup></mml:mrow><mml:mo>}</mml:mo></mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mo>λ</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>P</mml:mi></mml:munderover><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>J</mml:mi></mml:munderover><mml:mo>|</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>|</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mo>=</mml:mo><mml:mi mathvariant="italic">vec</mml:mi><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">X</mml:mi><mml:mo>−</mml:mo><mml:mi mathvariant="bold">W</mml:mi><mml:mi mathvariant="bold">H</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:mi>v</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">X</mml:mi><mml:mo>−</mml:mo><mml:mi mathvariant="bold">W</mml:mi><mml:mi mathvariant="bold">H</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mo>λ</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>P</mml:mi></mml:munderover><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>J</mml:mi></mml:munderover><mml:mo>|</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>|</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p>
      <p>We denote
<disp-formula id="E8"><mml:math id="M8" display="block" overflow="scroll"><mml:mi mathvariant="bold">h</mml:mi><mml:mo>=</mml:mo><mml:mi mathvariant="italic">vec</mml:mi><mml:mo>(</mml:mo><mml:mi mathvariant="bold">H</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mtable><mml:mtr><mml:mtd><mml:msub><mml:mi mathvariant="bold">H</mml:mi><mml:mn>11</mml:mn></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>⋮</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi mathvariant="bold">H</mml:mi><mml:mrow><mml:mi>P</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>⋮</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi mathvariant="bold">H</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mi>J</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>⋮</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi mathvariant="bold">H</mml:mi><mml:mrow><mml:mi>P</mml:mi><mml:mi>J</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr></mml:mtable><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo> </mml:mo><mml:mi>and</mml:mi><mml:mo> </mml:mo><mml:mi mathvariant="bold">x</mml:mi><mml:mo>=</mml:mo><mml:mi mathvariant="italic">vec</mml:mi><mml:mo>(</mml:mo><mml:mi mathvariant="bold">X</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mtable><mml:mtr><mml:mtd><mml:msub><mml:mi mathvariant="bold">X</mml:mi><mml:mn>11</mml:mn></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>⋮</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi mathvariant="bold">X</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>⋮</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi mathvariant="bold">X</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mi>J</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>⋮</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi mathvariant="bold">X</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mi>J</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr></mml:mtable><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:math></disp-formula>
 <disp-formula id="E9"><mml:math id="M9" display="block" overflow="scroll"><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mi>Q</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">H</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo> =</mml:mo></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">x</mml:mi><mml:mo>−</mml:mo><mml:mi mathvariant="italic">vec</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">W</mml:mi><mml:mi mathvariant="bold">H</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">x</mml:mi><mml:mo>−</mml:mo><mml:mi mathvariant="italic">vec</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">W</mml:mi><mml:mi mathvariant="bold">H</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mo>λ</mml:mo><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:mi mathvariant="bold">h</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>   =</mml:mo></mml:mtd><mml:mtd><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">x</mml:mi><mml:mo>−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="double-struck">I</mml:mi></mml:mrow><mml:mi>J</mml:mi></mml:msub><mml:mo>⊗</mml:mo><mml:mi mathvariant="bold">W</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi mathvariant="italic">vec</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">H</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">x</mml:mi><mml:mo>−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="double-struck">I</mml:mi></mml:mrow><mml:mi>J</mml:mi></mml:msub><mml:mo>⊗</mml:mo><mml:mi mathvariant="bold">W</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi mathvariant="italic">vec</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">H</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow/></mml:mtd><mml:mtd><mml:mrow><mml:mo>+</mml:mo><mml:mo>λ</mml:mo><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:mi mathvariant="bold">h</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>   =</mml:mo></mml:mtd><mml:mtd><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">x</mml:mi><mml:mo>−</mml:mo><mml:mover accent="true"><mml:mi mathvariant="bold">W</mml:mi><mml:mo stretchy="false">˜</mml:mo></mml:mover><mml:mi mathvariant="bold">h</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">x</mml:mi><mml:mo>−</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">W</mml:mi><mml:mo stretchy="false">˜</mml:mo></mml:mover></mml:mrow><mml:mi mathvariant="bold">h</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mo>λ</mml:mo><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:mi mathvariant="bold">h</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula>where <inline-formula id="IE15"><mml:math id="IM15" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="double-struck">I</mml:mi></mml:mrow><mml:mi>J</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is the identity matrix of size <italic toggle="yes">J</italic> and <inline-formula id="IE16"><mml:math id="IM16" display="inline" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">W</mml:mi><mml:mo stretchy="false">˜</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="double-struck">I</mml:mi></mml:mrow><mml:mi>J</mml:mi></mml:msub><mml:mo>⊗</mml:mo><mml:mi mathvariant="bold">W</mml:mi></mml:mrow></mml:math></inline-formula></p>
      <p>We can reformulate the problem as LASSO:
<disp-formula id="E10"><mml:math id="M10" display="block" overflow="scroll"><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mi>Q</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">H</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:mi mathvariant="bold">x</mml:mi><mml:mo>−</mml:mo><mml:mover accent="true"><mml:mi mathvariant="bold">W</mml:mi><mml:mo stretchy="false">˜</mml:mo></mml:mover><mml:mi mathvariant="bold">h</mml:mi><mml:mo>|</mml:mo><mml:msup><mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:mo>λ</mml:mo><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:mi mathvariant="bold">h</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p>
      <p><bold><italic toggle="yes">λ</italic></bold> will be optimized for each block <inline-formula id="IE17"><mml:math id="IM17" display="inline" overflow="scroll"><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>K</mml:mi></mml:mrow></mml:math></inline-formula>.</p>
      <p>As for <bold>W</bold>, we used the glmnet package to solve this problem.</p>
      <p><italic toggle="yes">Normalization</italic> We would like to consider <bold>W</bold> as a weight matrix. To avoid problems of convergence or non-identifiability, the normalization by the sum of weights for each row of <bold>W</bold> is added after computing the matrix, i.e. each row is divided by its sum after each step:
<disp-formula id="E11"><label>(7)</label><mml:math id="M11" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">w</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>•</mml:mo></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">w</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>•</mml:mo></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>P</mml:mi></mml:munderover><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">w</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>p</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula></p>
      <p>Therefore, the normalization corresponds to an equality constraint.</p>
    </sec>
    <sec id="S5">
      <title>2.3 Stopping criteria</title>
      <p>The stopping criterion of the model is determined by the convergence of the matrix <bold>W</bold>. The stability of the similarity of matrix <bold>W</bold> between two iterations means that the model has converged therefore we stop the algorithm. The similarity between <inline-formula id="IE18"><mml:math id="IM18" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">W</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE19"><mml:math id="IM19" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">W</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula> is measured with the Adjusted Rand Index (ARI). The users have also the possibility to define a maximum number of iterations to limit the computing time of the algorithm.</p>
    </sec>
    <sec id="S6">
      <title>2.4 Automatic tuning of sparsity parameters</title>
      <p>For each block <inline-formula id="IE20"><mml:math id="IM20" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">H</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula> and <bold>W</bold>, we need to calibrate the sparsity parameter <italic toggle="yes">λ<sub>k</sub></italic> and <italic toggle="yes">μ<sub>i</sub></italic>. The main advantage of glmnet package is the speed (see <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S9</xref>), and, it implements a cross validation technique to choose the best <italic toggle="yes">λ</italic> or <italic toggle="yes">μ</italic>. PIntMF takes advantage of glmnet to calibrate the penalty on each block. We use CV at each step to find the optimal values for <italic toggle="yes">λ</italic> and <italic toggle="yes">μ</italic>. However, all <italic toggle="yes">μ<sub>i</sub></italic> have been set to 1 in the following experiments (simulations and applications) to save computational time since the results were very similar.</p>
      <p>Therefore, the only parameter that the user needs to tune is the number of latent variables <italic toggle="yes">P</italic>.</p>
    </sec>
    <sec id="S7">
      <title>2.5 Optimization of the algorithm</title>
      <p><bold>Initialization</bold>: Often in NMF algorithms (<xref rid="btab786-B17" ref-type="bibr">Lee and Seung, 1999</xref>), the matrices are initialized by non-negative random values. We assess four kinds of initialization for PIntMF (hierarchical clustering, random, Similarity Network Fusion and Singular Values Decomposition).</p>
      <p>The best initialization is based on the SNF algorithm (<xref rid="btab786-B43" ref-type="bibr">Wang <italic toggle="yes">et al.</italic>, 2014</xref>) (<xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S1</xref>). This initialization has the advantage to take into account simultaneously the <italic toggle="yes">K</italic> blocks of the analysis. Therefore, for all the following analyses, SNF initialization was used.</p>
      <p><bold>Computing optimization of H</bold>: Several algorithms to solve the Lasso problem on <inline-formula id="IE21"><mml:math id="IM21" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">H</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula> were tested. glmnet is the fastest package among them (<xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S9</xref>).</p>
    </sec>
    <sec id="S8">
      <title>2.6 Clustering</title>
      <p>In this article, all clusterings are obtained by applying a hierarchical clustering with the ward distance (<xref rid="btab786-B44" ref-type="bibr">Ward Jr, 1963</xref>) on matrix <bold>W</bold>. For the optimal number of clusters, <italic toggle="yes">P</italic> is chosen.</p>
    </sec>
    <sec id="S9">
      <title>2.7 Criteria to choose the best model</title>
      <p>In this section, we present three different criteria to choose the appropriate number of latent variables (<italic toggle="yes">P</italic>).</p>
      <p><bold>Mean square error</bold>: The number of latent variables can be optimized by looking at the curve of the Mean Square Error (MSE). In this context, the mean square error (MSE) for each dataset <italic toggle="yes">k</italic> is defined by:
<disp-formula id="E12"><label>(8)</label><mml:math id="M12" display="block" overflow="scroll"><mml:mrow><mml:mi>M</mml:mi><mml:mi>S</mml:mi><mml:msubsup><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mi>P</mml:mi><mml:mi>k</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msup><mml:mo>−</mml:mo><mml:mi mathvariant="bold">W</mml:mi><mml:msup><mml:mrow><mml:mi mathvariant="bold">H</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msup><mml:mo>|</mml:mo><mml:msubsup><mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mi>F</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>×</mml:mo><mml:msub><mml:mrow><mml:mi>J</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula></p>
      <p>Then, the total MSE is then defined by averaging the different <inline-formula id="IE22"><mml:math id="IM22" display="inline" overflow="scroll"><mml:mrow><mml:mi>M</mml:mi><mml:mi>S</mml:mi><mml:msubsup><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mi>P</mml:mi><mml:mi>k</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula>:
<disp-formula id="E13"><label>(9)</label><mml:math id="M13" display="block" overflow="scroll"><mml:mrow><mml:mi>M</mml:mi><mml:mi>S</mml:mi><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mi>P</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mi>k</mml:mi></mml:munder><mml:mi>M</mml:mi><mml:mi>S</mml:mi><mml:msubsup><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mi>P</mml:mi><mml:mi>k</mml:mi></mml:msubsup><mml:mo>/</mml:mo><mml:mi>K</mml:mi></mml:mrow></mml:math></disp-formula></p>
      <p><bold>Percentage of variation explained (PVE)</bold>: To measure the performance of the method, we computed the Percentage of Variation Explained (<xref rid="btab786-B22" ref-type="bibr">Nowak <italic toggle="yes">et al.</italic>, 2011</xref>) defined by the following formula:
<disp-formula id="E14"><label>(10)</label><mml:math id="M14" display="block" overflow="scroll"><mml:mrow><mml:mi mathvariant="italic">PVE</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">W</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">H</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msup><mml:mo>−</mml:mo><mml:mi mathvariant="bold">W</mml:mi><mml:msup><mml:mrow><mml:mi mathvariant="bold">H</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msup><mml:mo>|</mml:mo><mml:msubsup><mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mi>F</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msup><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">X</mml:mi><mml:mo stretchy="true">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mi>k</mml:mi></mml:msup><mml:msub><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>J</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:msubsup><mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mi>F</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula>where <inline-formula id="IE23"><mml:math id="IM23" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">X</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mi>k</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula> is a vector containing the average profile of each individual:</p>
      <p><inline-formula id="IE24"><mml:math id="IM24" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">X</mml:mi><mml:mo stretchy="true">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mi>i</mml:mi><mml:mi>k</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mi>j</mml:mi></mml:munder><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>J</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:math></inline-formula>, and <inline-formula id="IE25"><mml:math id="IM25" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>J</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> is a row-vector of size <italic toggle="yes">J<sub>k</sub></italic>.</p>
      <p>Then, we computed the global PVE as the mean of the PVE on the <italic toggle="yes">K</italic> blocks, i.e.:
<disp-formula id="E15"><label>(11)</label><mml:math id="M15" display="block" overflow="scroll"><mml:mrow><mml:mi mathvariant="italic">PVE</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>K</mml:mi></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:munderover><mml:mi>P</mml:mi><mml:mi>V</mml:mi><mml:mi>E</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">W</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">H</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></disp-formula></p>
      <p><bold>Cophenetic distance</bold>: We were inspired by <xref rid="btab786-B11" ref-type="bibr">Gaujoux and Seoighe (2010)</xref> for the last criterion.</p>
      <p>We wanted to assess if the distances in the tree (after hierarchical clustering on <bold>W</bold>) accurately reflect the original distances.</p>
      <p>One way is to compute the correlation between the cophenetic distances and the original distance data generated by the dist() function on <bold>W</bold> (<xref rid="btab786-B35" ref-type="bibr">Sokal and Rohlf, 1962</xref>). The clustering is valid, if the correlation between the two quantities is high. Note that, we use the cophenetic function defined by <xref rid="btab786-B34" ref-type="bibr">Sneath <italic toggle="yes">et al.</italic> (1973)</xref>.</p>
      <p>The cophenetic correlation usually decreases with the increase of <italic toggle="yes">P</italic> values. <xref rid="btab786-B3" ref-type="bibr">Brunet <italic toggle="yes">et al.</italic> (2004)</xref> suggested choosing the smallest value of <italic toggle="yes">P</italic> for which this coefficient starts decreasing.</p>
    </sec>
  </sec>
  <sec id="S10">
    <title>3 Performance criteria</title>
    <p>Two criteria are used to assess the performance of our method and to compare it with others.</p>
    <sec id="S11">
      <title>3.1 Adjusted Rand Index</title>
      <p>On a simulated dataset and on well-known real datasets, it is possible to compute the similarity between the true and the inferred classifications. We use the ARI as a criterion to evaluate the performance of our method. The ARI (<xref rid="btab786-B25" ref-type="bibr">Rand, 1971</xref>) is equal to one when the two classifications that are compared are totally similar and zero or even negative if the classifications are completely different.</p>
    </sec>
    <sec id="S12">
      <title>3.2 Area under the ROC curve</title>
      <p>On a simulated dataset, the variables that drive the subgroups are known, and it is easy to compute false-positive and true-positive rates. First, variables are ordered by their standard deviation (from the highest to the lowest) computed on the <bold>H</bold> matrix to highlight the largest differences between the <italic toggle="yes">P</italic> components and therefore the most contributory to the clusters. To summarize the information of these two quantities, we compute the area under the TPR-FPR curve [area under the roc curve (AUROC)]. An AUROC equal to one means that the method selects the variables with no error. An AUROC under 0.50 means that false-positive variables are selected before the true positive ones.</p>
    </sec>
  </sec>
  <sec id="S13">
    <title>4 Results</title>
    <sec id="S14">
      <title>4.1 Performance on simulated datasets</title>
      <p>We assess the performance of PIntMF in two simulated frameworks described below.</p>
      <sec id="S15">
        <label>4.1.1</label>
        <title>Simulations on independent datasets (non-correlated blocks)</title>
        <p>The performance of PIntMF to cluster samples and to select relevant variables was evaluated on simulated data described by <xref rid="btab786-B23" ref-type="bibr">Pierre-Jean <italic toggle="yes">et al.</italic> (2020)</xref>. The framework of these simulations is composed of three blocks with three different types of distribution (Binary, Beta-like and Gaussian) to simulate the heterogeneity of the integrative omics data studies. Indeed, a binary distribution could match a mutation (equal to 1 if the gene is mutated and 0 otherwise); a Beta-like distribution could match DNA methylation data, and a Gaussian distribution could match gene expression values.</p>
        <p>Four unbalanced clusters (composed of 25, 20, 5 and 10 individuals) have been simulated (Benchmarks 1–5). Datasets with 2, 3 and 4 balanced clusters have also been simulated (Benchmarks 6–8). Each benchmark is simulated 50 times.</p>
        <p>PIntMF was compared with several integrative unsupervised methods (<xref rid="btab786-B23" ref-type="bibr">Pierre-Jean <italic toggle="yes">et al.</italic>, 2020</xref>) that perform both clustering and variable selection namely: intNMF (<xref rid="btab786-B7" ref-type="bibr">Chalise <italic toggle="yes">et al.</italic>, 2014</xref>), SGCCA (<xref rid="btab786-B38" ref-type="bibr">Tenenhaus <italic toggle="yes">et al.</italic>, 2014</xref>), MoCluster (<xref rid="btab786-B18" ref-type="bibr">Meng <italic toggle="yes">et al.</italic>, 2016</xref>), iClusterPlus (<xref rid="btab786-B20" ref-type="bibr">Mo <italic toggle="yes">et al.</italic>, 2013</xref>) and CIMLR (<xref rid="btab786-B24" ref-type="bibr">Ramazzotti <italic toggle="yes">et al.</italic>, 2018</xref>).</p>
        <p>Clustering performance was evaluated using the ARI on simulated data (see Section 3.1).</p>
        <p>On the eight simulated benchmarks with various levels of signal-to-noise ratio, PIntMF and MoCluster outperform the other methods with an ARI equal to 1 in most cases (<xref rid="btab786-F1" ref-type="fig">Fig.  1</xref>). </p>
        <fig position="float" id="btab786-F1">
          <label>Fig. 1.</label>
          <caption>
            <p>ARI of PIntMF, intNMF, SGCCA, MoCluster, iClusterPlus and CIMLR methods on simulated datasets. B1: Reference, B2: More Gaussian noise, B3: More Gaussian noise and more Binary noise, B4: More Beta noise and more Binary noise, B5: More Relevant variables, B6: 2 balanced clusters, B7: 3 balanced clusters, B8: 4 balanced clusters</p>
          </caption>
          <graphic xlink:href="btab786f1" position="float"/>
        </fig>
        <p>The performance of variable selection is assessed using the AUROCs after computing False Positive Rates (FPR) and True Positive Rates (TPR) (see Section 3.2). The computation of the AUROC shows that PIntMF performs as well as MoCluster on the three types of data (<xref rid="sup1" ref-type="supplementary-material">Supplementary Table S2</xref>). Indeed, PIntMF reaches either the first or the second-best AUROC for these simulations. Moreover, the lowest AUROC is equal to 0.88, which means that the method is both sensitive and specific.</p>
      </sec>
      <sec id="S16">
        <label>4.1.2</label>
        <title>Simulation based on real data (correlated blocks)</title>
        <p>We evaluate the performance of PIntMF on a simulated framework based on real cancer data developed by <xref rid="btab786-B10" ref-type="bibr">Chung and Kang (2019)</xref>. Indeed, the previous simulated framework does not simulate any correlation between omics blocks.</p>
        <p>OmicsSIMLA is a simulation tool for generating multi-omics data with disease status. The tool simulates CpGs with methylation proportions, RNA-seq read counts and normalized protein expression levels. Here, we simulated 50 datasets containing 50 cases (i.e. short-term survival) and 50 controls (i.e. long-term survival), and three omics blocks (RNAseq, DNA methylation and proteins). We aimed to recover the two groups but also the different features that drive overall survival using the simulated DNA methylation, expression and protein data. For two of the three blocks (expression and DNA methylation), the variables simulated with a differential expression or methylation between the two groups are known. The simulated data are described in <xref rid="sup1" ref-type="supplementary-material">Supplementary Materials</xref> (<xref rid="sup1" ref-type="supplementary-material">Supplementary Section S6</xref>).</p>
        <p>In these simulations, we also compared the performance of PIntMF to other methods in terms of clustering and variable selection. First, CIMLR does not give any results on these simulations (the algorithm does not converge). For all the other methods, the ARI is equal to 1 (maximum value) for all 50 datasets.</p>
        <p>Then, we compared the variable selection performance of PIntMF, intNMF, iClusterPlus, MoCluster and SGCCA by computing the AUROC on expression and DNA methylation blocks only (the protein block does not contain any variable simulated with differential abundance, more details are given in <xref rid="sup1" ref-type="supplementary-material">Supplementary Section S6</xref>).</p>
        <p><bold>DNA Methylation dataset:</bold> PIntMF and iclusterPlus outperform the others with similar performances but the AUROC of iclusterPlus is significantly higher. However, the AUROC of PIntMF is significantly higher than for MoCluster, SGCCA and intNMF (<xref rid="btab786-F2" ref-type="fig">Fig.  2</xref>).</p>
        <fig position="float" id="btab786-F2">
          <label>Fig. 2.</label>
          <caption>
            <p>AUROC of PIntMF, MoCluster, SGCCA, iClusterPlus and intNMF for OmicsSIMLA simulations on (<bold>a</bold>) DNA methylation and (<bold>b</bold>) Gene expression blocks</p>
          </caption>
          <graphic xlink:href="btab786f2" position="float"/>
        </fig>
        <p><bold>Expression dataset:</bold> PIntMF is the best method with an AUROC significantly higher than the other methods. However, all methods achieve an AUROC higher than 0.92 (<xref rid="btab786-F2" ref-type="fig">Fig.  2</xref>).</p>
        <p>On these simulations, PIntMF gives similar results to iClusterPlus, but with automatic tuning of parameters. Moreover, the algorithm of PIntMF is faster than iClusterPlus.</p>
      </sec>
      <sec id="S17">
        <label>4.1.3</label>
        <title>Stability selection</title>
        <p>Jackknife was performed to evaluate the stability of variable selection. To perform this technique, we run the model PIntMF on the data without one sample at each step. Therefore, we obtain <italic toggle="yes">n</italic> datasets containing <italic toggle="yes">n−</italic>1 individuals on which we apply the method.</p>
        <p>The stability of the selected variables for Binary, Gaussian, methylation and expression datasets seems to be strong (<xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S10</xref>). For proteins and for beta-like data, the bootstrap reveals that some selected variables are not stable, even though it was expected for proteins since they were not simulated with a differential expression between clusters. In the case where the selection is not stable, the solution could be using jackknife to remove potential false-positive variables.</p>
      </sec>
      <sec id="S18">
        <label>4.1.4</label>
        <title>Summary</title>
        <p>Our method PIntMF provides satisfying clustering and variable selection both on correlated blocks (Simulation Framework 2) and on non-correlated blocks (Simulation Framework 1). PIntMF is the only method that performs well on all simulated settings. We conclude on these two frameworks of simulated data that PIntMF is a fast and flexible tool.</p>
      </sec>
    </sec>
    <sec id="S19">
      <title>4.2 Applications</title>
      <p>In this section, we assess the performance of the PIntMF method on real data by considering two applications. The first one is a dataset from murine liver (<xref rid="btab786-B45" ref-type="bibr">Williams <italic toggle="yes">et al.</italic>, 2016</xref>) under two different diets already used in two previous comparison articles (<xref rid="btab786-B23" ref-type="bibr">Pierre-Jean <italic toggle="yes">et al.</italic>, 2020</xref>; <xref rid="btab786-B40" ref-type="bibr">Tini <italic toggle="yes">et al.</italic>, 2019</xref>), and the objective is to recover the diets of the mice (fat diet or chow diet). The second one is a glioblastoma dataset from TCGA used by <xref rid="btab786-B32" ref-type="bibr">Shen <italic toggle="yes">et al.</italic> (2012)</xref> and the goal is to find the tumor subtypes.</p>
      <sec id="S20">
        <label>4.2.1</label>
        <title>PIntMF highlights variables linked to phenotypes of samples</title>
        <p>We analyzed the BXD cohort (composed of 64 samples) (<xref rid="btab786-B45" ref-type="bibr">Williams <italic toggle="yes">et al.</italic>, 2016</xref>); the mice were divided into two different environmental conditions of diet: chow diet (CD) (6% kcal of fat) or high-fat diet (HFD) (60% kcal of fat). Measurements have been made in the livers of the entire population at the transcriptome (35 554 variables), the proteome (21 547 variables) and the metabolome (956 variables) levels.</p>
        <p>Therefore, we applied PIntMF to this dataset as well as intNMF, MoCluster, SGCCA, iClusterPlus and CIMLR (<xref rid="sup1" ref-type="supplementary-material">Supplementary Table S4</xref>).</p>
        <p>PIntMF produces a perfect classification of the individuals for this real dataset.</p>
        <p>For this dataset, all criteria for the model selection were computed (<xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S6</xref>), and two groups were selected for further analysis.</p>
        <p>PIntMF highlights interesting variables that seem to have different abundance between the two groups CD and HFD (<xref rid="btab786-F3" ref-type="fig">Fig.  3</xref>): Vitamin E (C<sub>29</sub>H<sub>50</sub>O<sub>2</sub>), Cholesteryl (C<sub>36</sub>H<sub>62</sub>O<sub>5</sub>), Mustard Oil (C<sub>4</sub>H<sub>5</sub>NS). Saa2 gene that codes for a protein involved in the HDL complex seems to be differentially expressed between the two groups. Then, the Cidea gene that is involved in the metabolism of lipids and lipoproteins has a slightly different level of expression between the two groups. Finally, Cyp2b9 oxides steroids, fatty acids and xenobiotics are less expressed in the high-fat diet group. To conclude, PIntMF succeeds well into recovering the correct classification and relevant markers in all datasets.</p>
        <fig position="float" id="btab786-F3">
          <label>Fig. 3.</label>
          <caption>
            <p>BXD cohort results: Top 10 selected variables with PIntMF of each dataset (Metabolites, Proteins and RNA), the clustering given by PIntMF and the true clustering are on the right</p>
          </caption>
          <graphic xlink:href="btab786f3" position="float"/>
        </fig>
      </sec>
      <sec id="S21">
        <label>4.2.</label>
        <title>2 PIntMF reveals a new classification of non-annotated samples on TCGA dataset</title>
        <p>In addition, we analyzed a subset of the glioblastoma dataset from the cancer genome atlas (TCGA): the Glioblastoma study (2009) used in (<xref rid="btab786-B32" ref-type="bibr">Shen <italic toggle="yes">et al.</italic>, 2012</xref>). The dataset contains three matrices: copy number variation (1599 regions), DNA methylation (1515 CpGs) and mRNA expression (1740 genes) in 55 samples. GBM samples were classified into four subtypes (Classical: CL, Mesenchymal: MES, Neural: NL and Proneural: PN). In addition, there are samples with no subtype (NA). Using the PIntMF method, we highlight samples with no classification close to labeled samples. Looking at the three criteria, the best number of latent variables seems to be five (<xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S7</xref>). For example, the green cluster from PIntMF matches a part of the CL subtype, and one sample labeled as NA is in this green cluster. Then, the purple cluster from PIntMF matches the PN subtype, and one sample labeled as NA can be classified within the PN subtype (<xref rid="btab786-F4" ref-type="fig">Fig.  4a</xref>). Clusters 1 (red) and 2 (blue) are more heterogenous. However, the red one is composed of NL and NA labeled samples. The blue one is close to samples labeled as PN.</p>
        <fig position="float" id="btab786-F4">
          <label>Fig. 4.</label>
          <caption>
            <p>(<bold>a</bold>) Heatmap of <bold>W</bold>. The clustering of PIntMF was compared to glioblastoma subtypes. (<bold>b</bold>) Survival curves with <italic toggle="yes">P</italic>-value of log-rank test. (<bold>c–e</bold>) <bold>H</bold> matrix for the three considered omics blocks on glioblastoma dataset</p>
          </caption>
          <graphic xlink:href="btab786f4" position="float"/>
        </fig>
        <p>We performed a survival analysis to identify a relation between groups found by PIntMF and the survival rate (<xref rid="btab786-F4" ref-type="fig">Fig.  4b</xref>). The survival test gives a significant <italic toggle="yes">P</italic>-value at 5% (<italic toggle="yes">P</italic>-value = 0.00013 with log-rank test). The prognosis for the purple (4) group is better than those of the red and green (1 and 3) groups and even better than the orange and blue (2 and 5) groups. Note that, the PN subtype is split into two groups (purple and blue) that have two very different survival curves.</p>
        <p>The previous study (<xref rid="btab786-B32" ref-type="bibr">Shen <italic toggle="yes">et al.</italic>, 2012</xref>) performed with the iCluster method (<xref rid="btab786-B31" ref-type="bibr">Shen <italic toggle="yes">et al.</italic>, 2009</xref>) identified 3 subgroups with a less significant <italic toggle="yes">P</italic>-value (0.01) than PIntMF for the survival differences between subgroups. Their Cluster 1 matches the PN group, Cluster 2 matches the CL group and Cluster 3 is mostly composed of the MES subtype. Authors do not give any information about the samples with no subtypes.</p>
        <p><bold>H</bold> matrices exhibit various types of genomic profiles according to the clusters (<xref rid="btab786-F4" ref-type="fig">Fig.  4</xref>). For instance, the orange cluster (5) shows few alterations at the copy number variation level (<xref rid="btab786-F4" ref-type="fig">Fig.  4c</xref>) but a particular profile for DNA methylation and gene expression data (<xref rid="btab786-F4" ref-type="fig">Fig.  4e</xref>). The blue cluster (2) has a distinct pattern of expression (<xref rid="btab786-F4" ref-type="fig">Fig.  4d</xref>).</p>
      </sec>
    </sec>
  </sec>
  <sec id="S22">
    <title>5 Discussion</title>
    <p>Here, we present the PIntMF model that is capable of discovering new subgroups from a cohort and potential new biomarkers from several types of omics data. PIntMF is a matrix factorization model with positivity and sparsity constraints (Lasso) on inferred matrices. The method and all the scripts of this article are available in an R package entitled PIntMF.</p>
    <p>The main advantage of this method is the automatic tuning of the lasso penalties for both variable and sample matrices. To optimize the computational time of the algorithm (<xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S9</xref>), we tried several algorithms to infer matrices <inline-formula id="IE26"><mml:math id="IM26" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">H</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula>. <monospace>glmnet</monospace> is very fast compared with the other widely used algorithms (ncvreg, quadrupen and biglasso), therefore it was retained for all the analyses. We also optimized the algorithm initialization using the SNF algorithm (<xref rid="btab786-B43" ref-type="bibr">Wang <italic toggle="yes">et al.</italic>, 2014</xref>). This initialization enables the algorithm to provide the best clustering and the best percentage of explained variation (<xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S1</xref>). Moreover, this initialization is performed at the integrative level rather than on each individual data block.</p>
    <p>PIntMF automatically tunes the penalties on matrices <inline-formula id="IE27"><mml:math id="IM27" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">H</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula> and <bold>W</bold>, without any user intervention, and we noticed that all the matrices are quite sparse on real datasets (<xref rid="btab786-F4" ref-type="fig">Fig.  4</xref>). The user needs to choose only one parameter that is the number of latent variables. The last parameter can be chosen by looking at the MSE, cophenetic coefficient and the PVE (<xref rid="sup1" ref-type="supplementary-material">Supplementary Figs S2–S6</xref>). All these criteria are implemented in the R package. For non-correlated data simulations, only the cophenetic coefficient and the PVE allow selecting the correct number of latent variables.</p>
    <p>It is still difficult to evaluate the performance of an integrative method on simulations (<xref rid="btab786-B5" ref-type="bibr">Cantini <italic toggle="yes">et al.</italic>, 2020</xref>). The relationships between blocks of omics data are complex, often not well-known, and the modeling of these links is complicated. To our knowledge, there does not exist any reference dataset to assess performances in terms of clustering and variable selection. Therefore, we evaluated the algorithm on two different simulation frameworks (completely simulated and based on real-data) and two real datasets. Furthermore, we compared it with several other state-of-the-art integrative methods. We demonstrated, on the first simulated dataset (non-correlated blocks), that PIntMF outperforms the other methods on both clustering and variable selection. Indeed, on simulated data, the clustering from PIntMF makes few classification errors. PIntMF is also more robust to heterogeneous data compared with the others: the method performs as well on gaussian distributions as on binary or beta distributions for the variable selection. On another simulated framework based on real data (correlated blocks), we observed good clustering performances (perfect classification) and variable selection levels (AUROC upper than 90%). When applying the algorithm on two real datasets (BXD and TCGA data, Section 4.2), we demonstrated that the method could deal with real datasets. In particular, we found relevant subgroups but also interesting variables linked to the clinical phenotypes (diet and overall survival).</p>
    <p>A weakness of the model is that the convergence of the algorithm to an optimal solution is not mathematically justified. Furthermore, a significance test for each selected variable is not given due to the use of the LASSO regression (<xref rid="btab786-B15" ref-type="bibr">Jain and Xu, 2021</xref>). Jackknife could provide an idea of the confidence in the selected variables (<xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S10</xref>). However, this approach is very time-consuming when applied on large datasets.</p>
    <p>The method could be further improved by dealing with missing values. Missing values could be inside a block for a few variables. These missing values could be imputed using the average of the other correlated variables, by the values of the nearest neighbor or by more complex methods as proposed by <xref rid="btab786-B42" ref-type="bibr">Voillet <italic toggle="yes">et al.</italic> (2016</xref>), <xref rid="btab786-B12" ref-type="bibr">González <italic toggle="yes">et al.</italic> (2009</xref>), <xref rid="btab786-B14" ref-type="bibr">Husson and Josse (2013</xref>) and <xref rid="btab786-B36" ref-type="bibr">Song <italic toggle="yes">et al.</italic> (2020)</xref>. Commonly, a whole block can also be missing for an individual. In this case, the matrix <bold>W</bold> could be computed only on the blocks that are present for this individual. Thanks to the <bold>W</bold> matrix, we could deduce a new profile for this patient from the <inline-formula id="IE28"><mml:math id="IM28" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">H</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula> matrix inferred with the other individuals.</p>
    <p>We could also extend the scope of PIntMF by including prior information such as the genome structure. For instance, we could force the algorithm to select the same genes in the DNA methylation block and the expression block. A group Lasso penalty (<xref rid="btab786-B33" ref-type="bibr">Simon <italic toggle="yes">et al.</italic>, 2013</xref>) could be added to the proposed model to include such a prior.</p>
    <p>To conclude, PIntMF is an easy and flexible method to integrate omics data. It implements an original mixture of constraints on matrices to cluster samples and discover new biomarkers. PIntMF exhibits good performance in terms of classification or variable selection in both simulation cases (correlated blocks or non-correlated blocks). It outperforms the other tested methods since it is the only one that works well in all our simulated frameworks. PIntMF is fast and automatically tunes the penalty for each block to select an appropriate number of variables (sparse matrices). Moreover, it provides a sparse matrix <bold>W</bold> to facilitate the clustering of samples. Finally, we also provide three criteria namely MSE, PVE and cophenetic coefficient to choose the best number of latent variables.</p>
    <p>The integration of several types of omics data using our method could help in discovering potential new biomarkers even with a small number of patients. Finally, it could also help to classify patients with unknown phenotypes.</p>
  </sec>
  <sec sec-type="data-availability" id="S23">
    <title>Data availability</title>
    <p>An R package named PIntMF can be used to reproduce all simulations and figures and is available online at <ext-link xlink:href="https://github.com/mpierrejean/" ext-link-type="uri">https://github.com/mpierrejean/pintmf</ext-link>. </p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material id="sup1" position="float" content-type="local-data">
      <label>btab786_supplementary_data</label>
      <media xlink:href="btab786_supplementary_data.zip">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ack id="ack1">
    <title>Acknowledgement</title>
    <p>The authors thank Steven McGinn for English language editing. </p>
    <p><italic toggle="yes">Financial Support</italic>: none declared. </p>
    <p><italic toggle="yes">Conflict of Interest</italic>: none declared.</p>
  </ack>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="btab786-B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bersanelli</surname><given-names>M.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2016</year>) <article-title>Methods for the integration of multi-omics data: mathematical aspects</article-title>. <source>BMC Bioinformatics</source>, <volume>17</volume>, <fpage>15</fpage>.<pub-id pub-id-type="pmid">26821531</pub-id></mixed-citation>
    </ref>
    <ref id="btab786-B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bock</surname><given-names>C.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2016</year>) <article-title>Multi-omics of single cells: strategies and applications</article-title>. <source>Trends Biotechnol</source>., <volume>34</volume>, <fpage>605</fpage>–<lpage>608</lpage>.<pub-id pub-id-type="pmid">27212022</pub-id></mixed-citation>
    </ref>
    <ref id="btab786-B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Brunet</surname><given-names>J.-P.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2004</year>) <article-title>Metagenes and molecular pattern discovery using matrix factorization</article-title>. <source>Proc. Nat. Acad. Sci. USA</source>, <volume>101</volume>, <fpage>4164</fpage>–<lpage>4169</lpage>.<pub-id pub-id-type="pmid">15016911</pub-id></mixed-citation>
    </ref>
    <ref id="btab786-B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Burstein</surname><given-names>M.D.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2015</year>) <article-title>Comprehensive genomic analysis identifies novel subtypes and targets of triple-negative breast cancer</article-title>. <source>Clin. Cancer Res</source>., <volume>21</volume>, <fpage>1688</fpage>–<lpage>1698</lpage>.<pub-id pub-id-type="pmid">25208879</pub-id></mixed-citation>
    </ref>
    <ref id="btab786-B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cantini</surname><given-names>L.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2020</year>) <article-title>Benchmarking joint multi-omics dimensionality reduction approaches for cancer study</article-title>. <source>Nat. Commun</source>., <volume>2</volume>, <fpage>124</fpage>.</mixed-citation>
    </ref>
    <ref id="btab786-B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chalise</surname><given-names>P.</given-names></string-name>, <string-name><surname>Fridley</surname><given-names>B.L.</given-names></string-name></person-group> (<year>2017</year>) <article-title>Integrative clustering of multi-level omic data based on non-negative matrix factorization algorithm</article-title>. <source>PLoS One</source>, <volume>12</volume>, <fpage>e0176278</fpage>.<pub-id pub-id-type="pmid">28459819</pub-id></mixed-citation>
    </ref>
    <ref id="btab786-B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chalise</surname><given-names>P.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2014</year>) <article-title>Integrative clustering methods for high-dimensional molecular data</article-title>. <source>Transl. Cancer Res</source>., <volume>3</volume>, <fpage>202</fpage>–<lpage>216</lpage>.<pub-id pub-id-type="pmid">25243110</pub-id></mixed-citation>
    </ref>
    <ref id="btab786-B8">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chauvel</surname><given-names>C.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2020</year>) <article-title>Evaluation of integrative clustering methods for the analysis of multi-omics data</article-title>. <source>Brief. Bioinf</source>., <volume>21</volume>, <fpage>541</fpage>–<lpage>552</lpage>. [CrossRef][<italic toggle="yes">10.1093/bib/bbz015</italic>]</mixed-citation>
    </ref>
    <ref id="btab786-B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chen</surname><given-names>J.</given-names></string-name>, <string-name><surname>Zhang</surname><given-names>S.</given-names></string-name></person-group> (<year>2018</year>) <article-title>Discovery of two-level modular organization from matched genomic data via joint matrix tri-factorization</article-title>. <source>Nucleic Acids Res</source>., <volume>46</volume>, <fpage>5967</fpage>–<lpage>5976</lpage>.<pub-id pub-id-type="pmid">29878151</pub-id></mixed-citation>
    </ref>
    <ref id="btab786-B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chung</surname><given-names>R.-H.</given-names></string-name>, <string-name><surname>Kang</surname><given-names>C.-Y.</given-names></string-name></person-group> (<year>2019</year>) <article-title>A multi-omics data simulator for complex disease studies and its application to evaluate multi-omics data analysis methods for disease classification</article-title>. <source>GigaScience</source>, <volume>8</volume>, <fpage>giz045</fpage>.<pub-id pub-id-type="pmid">31029063</pub-id></mixed-citation>
    </ref>
    <ref id="btab786-B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gaujoux</surname><given-names>R.</given-names></string-name>, <string-name><surname>Seoighe</surname><given-names>C.</given-names></string-name></person-group> (<year>2010</year>) <article-title>A flexible r package for nonnegative matrix factorization</article-title>. <source>BMC Bioinformatics</source>, <volume>11</volume>, <fpage>367</fpage>.<pub-id pub-id-type="pmid">20598126</pub-id></mixed-citation>
    </ref>
    <ref id="btab786-B12">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>González</surname><given-names>I.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2009</year>) <article-title>Highlighting relationships between heterogeneous biological data through graphical displays based on regularized canonical correlation analysis</article-title>. <source>J. Biol. Syst</source>., <volume>17</volume>, <fpage>173</fpage>–<lpage>199</lpage>.</mixed-citation>
    </ref>
    <ref id="btab786-B13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Huang</surname><given-names>S.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2017</year>) <article-title>More is better: recent progress in multi-omics data integration methods</article-title>. <source>Front. Genet</source>., <volume>8</volume>, <fpage>84</fpage>.<pub-id pub-id-type="pmid">28670325</pub-id></mixed-citation>
    </ref>
    <ref id="btab786-B14">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Husson</surname><given-names>F.</given-names></string-name>, <string-name><surname>Josse</surname><given-names>J.</given-names></string-name></person-group> (<year>2013</year>) <article-title>Handling missing values in multiple factor analysis</article-title>. <source>Food Qual. Preference</source>, <volume>30</volume>, <fpage>77</fpage>–<lpage>85</lpage>.</mixed-citation>
    </ref>
    <ref id="btab786-B15">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jain</surname><given-names>R.</given-names></string-name>, <string-name><surname>Xu</surname><given-names>W.</given-names></string-name></person-group> (<year>2021</year>) <article-title>Hdsi: high dimensional selection with interactions algorithm on feature selection and testing</article-title>. <source>PLoS One</source>, <volume>16</volume>, <fpage>e0246159</fpage>.<pub-id pub-id-type="pmid">33592034</pub-id></mixed-citation>
    </ref>
    <ref id="btab786-B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jerome</surname><given-names>F.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2010</year>) <article-title>Regularization paths for generalized linear models via coordinate descent</article-title>. <source>J. Stat. Softw</source>., <volume>33</volume>, <fpage>1</fpage>–<lpage>22</lpage>.<pub-id pub-id-type="pmid">20808728</pub-id></mixed-citation>
    </ref>
    <ref id="btab786-B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lee</surname><given-names>D.D.</given-names></string-name>, <string-name><surname>Seung</surname><given-names>H.S.</given-names></string-name></person-group> (<year>1999</year>) <article-title>Learning the parts of objects by non-negative matrix factorization</article-title>. <source>Nature</source>, <volume>401</volume>, <fpage>788</fpage>–<lpage>791</lpage>.<pub-id pub-id-type="pmid">10548103</pub-id></mixed-citation>
    </ref>
    <ref id="btab786-B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Meng</surname><given-names>C.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2016</year>) <article-title>mocluster: identifying joint patterns across multiple omics data sets</article-title>. <source>J. Proteome Res</source>., <volume>15</volume>, <fpage>755</fpage>–<lpage>765</lpage>.<pub-id pub-id-type="pmid">26653205</pub-id></mixed-citation>
    </ref>
    <ref id="btab786-B19">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Mo</surname><given-names>Q.</given-names></string-name>, <string-name><surname>Shen</surname><given-names>R.</given-names></string-name></person-group> (<year>2018</year>) <italic toggle="yes">iClusterPlus: Integrative Clustering of Multi-Type Genomic Data. Bioconductor R package version 1.18.0</italic>.</mixed-citation>
    </ref>
    <ref id="btab786-B20">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mo</surname><given-names>Q.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2013</year>) <article-title>Pattern discovery and cancer gene identification in integrated cancer genomic data</article-title>. <source>Proc. Natl. Acad. Sci. USA</source>, <volume>110</volume>, <fpage>4245</fpage>–<lpage>4250</lpage>.<pub-id pub-id-type="pmid">23431203</pub-id></mixed-citation>
    </ref>
    <ref id="btab786-B21">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Network</surname><given-names>C.G.A.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2012</year>) <article-title>Comprehensive molecular portraits of human breast tumours</article-title>. <source>Nature</source>, <volume>490</volume>, <fpage>61</fpage>.<pub-id pub-id-type="pmid">23000897</pub-id></mixed-citation>
    </ref>
    <ref id="btab786-B22">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nowak</surname><given-names>G.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2011</year>) <article-title>A fused lasso latent feature model for analyzing multi-sample ACGH data</article-title>. <source>Biostatistics</source>, <volume>12</volume>, <fpage>776</fpage>–<lpage>791</lpage>.<pub-id pub-id-type="pmid">21642389</pub-id></mixed-citation>
    </ref>
    <ref id="btab786-B23">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pierre-Jean</surname><given-names>M.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2020</year>) <article-title>Clustering and variable selection evaluation of 13 unsupervised methods for multi-omics data integration</article-title>. <source>Brief. Bioinf</source>., <volume>21</volume>, <fpage>2011</fpage>–<lpage>2030</lpage>. [CrossRef<italic toggle="yes">]</italic>[<italic toggle="yes">10.1093/bib/bbz138</italic>]</mixed-citation>
    </ref>
    <ref id="btab786-B24">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ramazzotti</surname><given-names>D.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2018</year>) <article-title>Multi-omic tumor data reveal diversity of molecular mechanisms that correlate with survival</article-title>. <source>Nat. Commun</source>., <volume>9</volume>, <fpage>4453</fpage>.<pub-id pub-id-type="pmid">30367051</pub-id></mixed-citation>
    </ref>
    <ref id="btab786-B25">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rand</surname><given-names>W.M.</given-names></string-name></person-group> (<year>1971</year>) <article-title>Objective criteria for the evaluation of clustering methods</article-title>. <source>J. Am. Stat. Assoc</source>., <volume>66</volume>, <fpage>846</fpage>–<lpage>850</lpage>.</mixed-citation>
    </ref>
    <ref id="btab786-B26">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Reilly</surname><given-names>B.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2019</year>) <article-title>DNA methylation identifies genetically and prognostically distinct subtypes of myelodysplastic syndromes</article-title>. <source>Blood Adv</source>., <volume>3</volume>, <fpage>2845</fpage>–<lpage>2858</lpage>.<pub-id pub-id-type="pmid">31582393</pub-id></mixed-citation>
    </ref>
    <ref id="btab786-B27">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ritchie</surname><given-names>M.D.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2015</year>) <article-title>Methods of integrating data to uncover genotype–phenotype interactions</article-title>. <source>Nat. Rev. Genet</source>., <volume>16</volume>, <fpage>85</fpage>–<lpage>97</lpage>.<pub-id pub-id-type="pmid">25582081</pub-id></mixed-citation>
    </ref>
    <ref id="btab786-B28">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rodosthenous</surname><given-names>T.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2020</year>) <article-title>Integrating multi-omics data through sparse canonical correlation analysis for the prediction of complex traits: a comparison study</article-title>. <source>Bioinformatics</source>, <volume>36</volume>, <fpage>4616</fpage>–<lpage>4625</lpage>. [CrossRef<italic toggle="yes">]</italic>[<italic toggle="yes">10.1093/bioinformatics/btaa530]</italic><pub-id pub-id-type="pmid">32437529</pub-id></mixed-citation>
    </ref>
    <ref id="btab786-B29">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rowlands</surname><given-names>D.S.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2014</year>) <article-title>Multi-omic integrated networks connect DNA methylation and miRNA with skeletal muscle plasticity to chronic exercise in type 2 diabetic obesity</article-title>. <source>Physiol. Genomics</source>, <volume>46</volume>, <fpage>747</fpage>–<lpage>765</lpage>.<pub-id pub-id-type="pmid">25138607</pub-id></mixed-citation>
    </ref>
    <ref id="btab786-B30">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Sastry</surname><given-names>A.V.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2020</year>) Matrix factorization recovers consistent regulatory signals from disparate datasets. <italic toggle="yes">BioRxiv</italic>.</mixed-citation>
    </ref>
    <ref id="btab786-B31">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Shen</surname><given-names>R.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2009</year>) <article-title>Integrative clustering of multiple genomic data types using a joint latent variable model with application to breast and lung cancer subtype analysis</article-title>. <source>Bioinformatics</source>, <volume>25</volume>, <fpage>2906</fpage>–<lpage>2912</lpage>.<pub-id pub-id-type="pmid">19759197</pub-id></mixed-citation>
    </ref>
    <ref id="btab786-B32">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Shen</surname><given-names>R.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2012</year>) <article-title>Integrative subtype discovery in glioblastoma using icluster</article-title>. <source>PLoS One</source>, <volume>7</volume>, <fpage>e35236</fpage>.<pub-id pub-id-type="pmid">22539962</pub-id></mixed-citation>
    </ref>
    <ref id="btab786-B33">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Simon</surname><given-names>N.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2013</year>) <article-title>A sparse-group lasso</article-title>. <source>J. Comput. Graph. Stat</source>., <volume>22</volume>, <fpage>231</fpage>–<lpage>245</lpage>.</mixed-citation>
    </ref>
    <ref id="btab786-B34">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Sneath</surname><given-names>P.H.</given-names></string-name></person-group>  <etal>et al</etal> (<year>1973</year>) <italic toggle="yes">Numerical Taxonomy. The Principles and Practice of Numerical Classification</italic>.W. H. Freeman, San Francisco.</mixed-citation>
    </ref>
    <ref id="btab786-B35">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sokal</surname><given-names>R.R.</given-names></string-name>, <string-name><surname>Rohlf</surname><given-names>F.J.</given-names></string-name></person-group> (<year>1962</year>) <article-title>The comparison of dendrograms by objective methods</article-title>. <source>Taxon</source>, <volume>11</volume>, <fpage>33</fpage>–<lpage>40</lpage>.</mixed-citation>
    </ref>
    <ref id="btab786-B36">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Song</surname><given-names>M.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2020</year>) <article-title>A review of integrative imputation for multi-omics datasets</article-title>. <source>Front. Genet</source>., <volume>11</volume>, <fpage>570255</fpage>.<pub-id pub-id-type="pmid">33193667</pub-id></mixed-citation>
    </ref>
    <ref id="btab786-B37">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tenenhaus</surname><given-names>A.</given-names></string-name>, <string-name><surname>Tenenhaus</surname><given-names>M.</given-names></string-name></person-group> (<year>2011</year>) <article-title>Regularized generalized canonical correlation analysis</article-title>. <source>Psychometrika</source>, <volume>76</volume>, <fpage>257</fpage>–<lpage>284</lpage>.</mixed-citation>
    </ref>
    <ref id="btab786-B38">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tenenhaus</surname><given-names>A.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2014</year>) <article-title>Variable selection for generalized canonical correlation analysis</article-title>. <source>Biostatistics</source>, <volume>15</volume>, <fpage>569</fpage>–<lpage>583</lpage>.<pub-id pub-id-type="pmid">24550197</pub-id></mixed-citation>
    </ref>
    <ref id="btab786-B39">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tibshirani</surname><given-names>R.</given-names></string-name></person-group> (<year>1996</year>) <article-title>Regression shrinkage and selection via the lasso</article-title>. <source>J. R. Stat. Soc. Ser. B (Methodological)</source>, <volume>58</volume>, pages <fpage>267</fpage>–<lpage>288</lpage>.</mixed-citation>
    </ref>
    <ref id="btab786-B40">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tini</surname><given-names>G.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2019</year>) <article-title>Multi-omics integration - a comparison of unsupervised clustering methodologies</article-title>. <source>Brief. Bioinf</source>., <volume>20</volume>, <fpage>1269</fpage>–<lpage>1279</lpage>. [CrossRef<italic toggle="yes">]</italic>[<italic toggle="yes">10.1093/bib/bbx167</italic>]</mixed-citation>
    </ref>
    <ref id="btab786-B41">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Vasaikar</surname><given-names>S.V.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2018</year>) <article-title>Linkedomics: analyzing multi-omics data within and across 32 cancer types</article-title>. <source>Nucleic Acids Res</source>., <volume>46</volume>, <fpage>D956</fpage>–<lpage>D963</lpage>.<pub-id pub-id-type="pmid">29136207</pub-id></mixed-citation>
    </ref>
    <ref id="btab786-B42">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Voillet</surname><given-names>V.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2016</year>) <article-title>Handling missing rows in multi-omics data integration: multiple imputation in multiple factor analysis framework</article-title>. <source>BMC Bioinformatics</source>, <volume>17</volume>, <fpage>1</fpage>–<lpage>16</lpage>.<pub-id pub-id-type="pmid">26817711</pub-id></mixed-citation>
    </ref>
    <ref id="btab786-B43">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname><given-names>B.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2014</year>) <article-title>Similarity network fusion for aggregating data types on a genomic scale</article-title>. <source>Nat. Methods</source>, <volume>11</volume>, <fpage>333</fpage>–<lpage>337</lpage>.<pub-id pub-id-type="pmid">24464287</pub-id></mixed-citation>
    </ref>
    <ref id="btab786-B44">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ward Jr</surname><given-names>J.H.</given-names></string-name></person-group> (<year>1963</year>) <article-title>Hierarchical grouping to optimize an objective function</article-title>. <source>J. Am. Stat. Assoc</source>., <volume>58</volume>, <fpage>236</fpage>–<lpage>244</lpage>.</mixed-citation>
    </ref>
    <ref id="btab786-B45">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Williams</surname><given-names>E.G.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2016</year>) <article-title>Systems proteomics of liver mitochondria function</article-title>. <source>Science</source>, <volume>352</volume>, <fpage>aad0189</fpage>.<pub-id pub-id-type="pmid">27284200</pub-id></mixed-citation>
    </ref>
    <ref id="btab786-B46">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yang</surname><given-names>X.</given-names></string-name></person-group> (<year>2020</year>) <article-title>Multitissue multiomics systems biology to dissect complex diseases</article-title>. <source>Trends Mol. Med</source>., <volume>26</volume>, <fpage>718</fpage>–<lpage>728</lpage>. [CrossRef<italic toggle="yes">]</italic>[<italic toggle="yes">10.1016/j.molmed.2020.04.006]</italic><pub-id pub-id-type="pmid">32439301</pub-id></mixed-citation>
    </ref>
    <ref id="btab786-B47">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yugi</surname><given-names>K.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2016</year>) <article-title>Trans-omics: how to reconstruct biochemical networks across multiple omic layers</article-title>. <source>Trends Biotechnol</source>., <volume>34</volume>, <fpage>276</fpage>–<lpage>290</lpage>.<pub-id pub-id-type="pmid">26806111</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
