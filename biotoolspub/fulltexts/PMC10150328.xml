<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">NAR Genom Bioinform</journal-id>
    <journal-id journal-id-type="iso-abbrev">NAR Genom Bioinform</journal-id>
    <journal-id journal-id-type="publisher-id">nargab</journal-id>
    <journal-title-group>
      <journal-title>NAR Genomics and Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="epub">2631-9268</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">10150328</article-id>
    <article-id pub-id-type="doi">10.1093/nargab/lqad041</article-id>
    <article-id pub-id-type="publisher-id">lqad041</article-id>
    <article-categories>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI00030</subject>
        <subject>AcademicSubjects/SCI00980</subject>
        <subject>AcademicSubjects/SCI01060</subject>
        <subject>AcademicSubjects/SCI01140</subject>
        <subject>AcademicSubjects/SCI01180</subject>
      </subj-group>
      <subj-group subj-group-type="heading">
        <subject>Standard Article</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>ADOPT: intrinsic protein disorder prediction through deep bidirectional transformers</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Redl</surname>
          <given-names>Istvan</given-names>
        </name>
        <aff><institution>Peptone Ltd</institution>, 370 Grays Inn Road, London WC1X 8BB, <country country="GB">UK</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Fisicaro</surname>
          <given-names>Carlo</given-names>
        </name>
        <aff><institution>Peptone Ltd</institution>, 370 Grays Inn Road, London WC1X 8BB, <country country="GB">UK</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Dutton</surname>
          <given-names>Oliver</given-names>
        </name>
        <aff><institution>Peptone Ltd</institution>, 370 Grays Inn Road, London WC1X 8BB, <country country="GB">UK</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Hoffmann</surname>
          <given-names>Falk</given-names>
        </name>
        <aff><institution>Peptone Ltd</institution>, 370 Grays Inn Road, London WC1X 8BB, <country country="GB">UK</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Henderson</surname>
          <given-names>Louie</given-names>
        </name>
        <aff><institution>Peptone Ltd</institution>, 370 Grays Inn Road, London WC1X 8BB, <country country="GB">UK</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Owens</surname>
          <given-names>Benjamin M J</given-names>
        </name>
        <aff><institution>Peptone Ltd</institution>, 370 Grays Inn Road, London WC1X 8BB, <country country="GB">UK</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Heberling</surname>
          <given-names>Matthew</given-names>
        </name>
        <aff><institution>Peptone Ltd</institution>, 370 Grays Inn Road, London WC1X 8BB, <country country="GB">UK</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Paci</surname>
          <given-names>Emanuele</given-names>
        </name>
        <aff><institution>Peptone Ltd</institution>, 370 Grays Inn Road, London WC1X 8BB, <country country="GB">UK</country></aff>
        <aff><institution>Department of Physics and Astronomy ‘Augusto Righi’, University of Bologna</institution>, 40127 Bologna, <country country="IT">Italy</country></aff>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0003-0829-0615</contrib-id>
        <name>
          <surname>Tamiola</surname>
          <given-names>Kamil</given-names>
        </name>
        <!--kamil@peptone.io-->
        <aff><institution>Peptone Ltd</institution>, 370 Grays Inn Road, London WC1X 8BB, <country country="GB">UK</country></aff>
        <xref rid="COR1" ref-type="corresp"/>
      </contrib>
    </contrib-group>
    <author-notes>
      <corresp id="COR1">To whom correspondence should be addressed. Tel: +41 79 609 7333; Email: <email>kamil@peptone.io</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <month>6</month>
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2023-05-01">
      <day>01</day>
      <month>5</month>
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>01</day>
      <month>5</month>
      <year>2023</year>
    </pub-date>
    <volume>5</volume>
    <issue>2</issue>
    <elocation-id>lqad041</elocation-id>
    <history>
      <date date-type="received">
        <day>10</day>
        <month>8</month>
        <year>2022</year>
      </date>
      <date date-type="rev-recd">
        <day>07</day>
        <month>2</month>
        <year>2023</year>
      </date>
      <date date-type="accepted">
        <day>17</day>
        <month>4</month>
        <year>2023</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2023. Published by Oxford University Press on behalf of NAR Genomics and Bioinformatics.</copyright-statement>
      <copyright-year>2023</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbynclicense">https://creativecommons.org/licenses/by-nc/4.0/</ali:license_ref>
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution-NonCommercial License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by-nc/4.0/">https://creativecommons.org/licenses/by-nc/4.0/</ext-link>), which permits non-commercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited. For commercial re-use, please contact <email>journals.permissions@oup.com</email></license-p>
      </license>
    </permissions>
    <self-uri xlink:href="lqad041.pdf"/>
    <abstract>
      <title>Abstract</title>
      <p>Intrinsically disordered proteins (IDPs) are important for a broad range of biological functions and are involved in many diseases. An understanding of intrinsic disorder is key to develop compounds that target IDPs. Experimental characterization of IDPs is hindered by the very fact that they are highly dynamic. Computational methods that predict disorder from the amino acid sequence have been proposed. Here, we present ADOPT (Attention DisOrder PredicTor), a new predictor of protein disorder. ADOPT is composed of a self-supervised encoder and a supervised disorder predictor. The former is based on a deep bidirectional transformer, which extracts dense residue-level representations from Facebook’s Evolutionary Scale Modeling library. The latter uses a database of nuclear magnetic resonance chemical shifts, constructed to ensure balanced amounts of disordered and ordered residues, as a training and a test dataset for protein disorder. ADOPT predicts whether a protein or a specific region is disordered with better performance than the best existing predictors and faster than most other proposed methods (a few seconds per sequence). We identify the features that are relevant for the prediction performance and show that good performance can already be gained with &lt;100 features. ADOPT is available as a stand-alone package at <ext-link xlink:href="https://github.com/PeptoneLtd/ADOPT" ext-link-type="uri">https://github.com/PeptoneLtd/ADOPT</ext-link> and as a web server at <ext-link xlink:href="https://adopt.peptone.io" ext-link-type="uri">https://adopt.peptone.io/</ext-link>.</p>
    </abstract>
    <counts>
      <page-count count="14"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec sec-type="intro" id="SEC1">
    <title>INTRODUCTION</title>
    <p>Modern biochemistry is based on the assumption that proteins fold into a three-dimensional structure, which defines their biological function (<xref rid="B1" ref-type="bibr">1</xref>). However, in the past 20 years a novel class of biologically active polypeptides was identified that defies the structure–function paradigm. Intrinsically disordered proteins (IDPs) constitute a broad class that encompasses proteins that do not fold into a defined three-dimensional structure, undergo transitions between multiple unstructured or partially structured conformations or fold upon binding (<xref rid="B2" ref-type="bibr">2</xref>). IDPs play a fundamental role in biological processes such as cell signalling and regulation (<xref rid="B3" ref-type="bibr">3</xref>) and were implicated in numerous debilitating human disorders, including various cancers (<xref rid="B4" ref-type="bibr">4</xref>), diabetes (<xref rid="B5" ref-type="bibr">5</xref>), cardiovascular diseases (<xref rid="B6" ref-type="bibr">6</xref>) and neurodegenerative conditions such as Alzheimer’s or Parkinson’s disease (<xref rid="B7" ref-type="bibr">7</xref>). Consequently, IDPs are considered prime targets for drug development, yet very limited success of IDP-targeting compounds has been reported to date (<xref rid="B8" ref-type="bibr">8</xref>). The development of therapeutic molecules that target full-length IDPs or unstructured regions of folded proteins (IDRs) is particularly challenging because unfolded regions are depleted in hydrophobic residues, which stabilize druggable protein regions. Instead, IDPs contain many charged and polar residues, whose repulsive interactions drive intrinsic protein disorder. Thus, amino acid sequence composition of IDPs holds key to precise prediction and assessment of structural disorder in high-value and unmet medical targets. The rational design of IDP-targeting compounds is hindered by the lack of a well-defined structure and by the challenges posed by the experimental characterization of the broad conformational ensembles they populate. The big amount of potential IDP drug targets is presently not approachable with traditional structure-based drug design tools and needs the development of new methods. Experimental techniques used to characterize intrinsic disorder include X-ray crystallography, nuclear magnetic resonance (NMR) spectroscopy, small-angle X-ray scattering, circular dichroism and Förster resonance energy transfer. The resolution of the information and nature itself of the disorder probed depend on the experimental technique used to characterize it. NMR chemical shifts depend uniquely on the local environment and provide a probe, at single amino acid level, of the structure and dynamics of IDPs.</p>
    <p>Since the first disorder predictor was proposed in 1997 (<xref rid="B9" ref-type="bibr">9</xref>), numerous protein disorder predictors have been developed. In general, they can be divided into four categories: physicochemical predictors, machine learning (ML)-based predictors, template-based predictors and meta predictors. Physicochemical property-based predictors (<xref rid="B10" ref-type="bibr">10–15</xref>) utilize chemical features of amino acids, especially hydrophobicity and net charge, to predict whether a residue belongs to an ordered or a disordered region. Disorder predictions can be straightforwardly interpreted in terms of physical properties of underlying amino acid sequence. However, the accuracy and sensitivity of such predictors are limited to the features they use to differentiate between order and disorder. ML-based predictors (<xref rid="B16" ref-type="bibr">16–30</xref>) use positive and negative samples to distinguish between ordered and disordered regions. They can be used to search for the most important among many features. In comparison to physicochemical predictors, ML-based predictors are more flexible in their search of features, yet may suffer from poor ‘explainability’ of extracted features and their relevance for disorder. Template-based predictors (<xref rid="B31" ref-type="bibr">31–33</xref>) search for homologous structures (templates) and use these to distinguish between structured and unstructured regions in proteins. Their results can be easily interpreted, but homologous structures might not be found or their disorder prediction might not be transferable to the query protein. Finally, meta predictors (<xref rid="B33" ref-type="bibr">33</xref>) aggregate the output of multiple other disorder prediction tools and report a composite disorder score. In general, this leads to a better prediction accuracy than individual predictors, but at the cost of an increased computational effort, which in turn may hamper their effectiveness against proteome-size surveys.</p>
    <p>Despite the progress in disorder prediction in the last 25 years, a systematic assessment of the different predictors did not exist until a few years ago. Recently, two comparisons have been established. The critical assessment of protein intrinsic disorder prediction (CAID) (<xref rid="B34" ref-type="bibr">34</xref>) is a community-based blind test of state-of-the-art prediction of intrinsically disordered regions based on 643 proteins from DisProt (<xref rid="B35" ref-type="bibr">35</xref>). DisProt, the most comprehensive database of disordered proteins, provides manually curated annotations of currently ∼2400 IDPs and IDRs of at least 10 residues likely to be associated with a biological function. The data are based on multiple experimental measurements, but not all IDRs of a protein are contained in DisProt. Furthermore, the annotations in the DisProt database are binary; e.g. they do not report on the strength of disorder of a specific residue in the protein.</p>
    <p>CheZOD is a small database (<xref rid="B36" ref-type="bibr">36</xref>) of 117 proteins known to contain disorder for which NMR chemical shifts are available from the BMRB database (<xref rid="B37" ref-type="bibr">37</xref>). The CheZOD <italic toggle="yes">Z</italic>-score (referred to as <italic toggle="yes">Z</italic>-score below), based on secondary chemical shifts and defined in (<xref rid="B36" ref-type="bibr">36</xref>), quantifies the degree of local disorder on a continuous scale. Secondary chemical shifts, e.g. differences in chemical shifts of nuclei between the actual structure and a random coil structure, are a precise indicator of local protein disorder (<xref rid="B38" ref-type="bibr">38</xref>). It was demonstrated that the <italic toggle="yes">Z</italic>-score scale, besides being a reliable measure of disorder, also agrees well with other measures of disorder. The histogram of all <italic toggle="yes">Z</italic>-scores calculated for an expanded CheZOD database (<xref rid="B39" ref-type="bibr">39</xref>) containing 1325 proteins and constructed in a way to ensure balanced amounts of disordered and ordered residues fits a bimodal distribution; residues with <italic toggle="yes">Z</italic>-scores &lt;3.0 can be considered fully disordered, whereas 3.0 &lt; <italic toggle="yes">Z</italic> &lt; 8.0 corresponds to cases with fractional formation of local, ordered structure.</p>
    <p>A systematic comparison of 43 predictors in CAID (<xref rid="B34" ref-type="bibr">34</xref>) and 27 predictors on <italic toggle="yes">Z</italic>-scores (<xref rid="B39" ref-type="bibr">39</xref>) showed that deep learning techniques clearly outperform physicochemical methods. For example, SPOT-Disorder (<xref rid="B27" ref-type="bibr">27</xref>,<xref rid="B40" ref-type="bibr">40</xref>) was the second best predictor in both competitions, slightly beaten by flDPnn (<xref rid="B30" ref-type="bibr">30</xref>) in CAID and by ODiNPred (<xref rid="B39" ref-type="bibr">39</xref>) on <italic toggle="yes">Z</italic>-scores. All three predictors use deep neural networks to predict protein disorder.</p>
    <p>The elucidation of information from protein sequences is one of the most formidable challenges in modern biology. A comparable task in artificial intelligence (AI) research is natural language processing (NLP), in which ML and linguistic models are used to study how properties of language, including semantics, phonetics, phonology, morphology, syntax, lexicon and pragmatics, arise and interact. To accomplish this, NLP models must be able to find common patterns in variable length and non-linear correlations in language constituents as letters, words and sentences (<xref rid="B41" ref-type="bibr">41</xref>). The final goal of NLP is to find regularities of natural language and universal language creation rules.</p>
    <p>Supervised learning, a rapidly emerging branch of AI research, is of particularly high importance to computational biology where vast and well-annotated data repositories are available. Its more sophisticated variant, self-supervised learning, enables AI systems to learn from orders of magnitude more data than supervised ones, which is important for recognizing and understanding patterns of more subtle and less common representations. Self-supervised neural models such as the transformer (<xref rid="B42" ref-type="bibr">42</xref>) have recently proven to be especially effective for these tasks, e.g. vastly improving language modelling and next sentence prediction in BERT (<xref rid="B43" ref-type="bibr">43</xref>) or generating high-quality human-like text in GPT (<xref rid="B44" ref-type="bibr">44</xref>).</p>
    <p>Motivated by recent developments in self-supervised learning and its application to protein language models (<xref rid="B45" ref-type="bibr">45</xref>,<xref rid="B46" ref-type="bibr">46</xref>), we developed a novel structural disorder predictor that benefits from the transformer architecture. We demonstrate here the relative benefit of ADOPT (Attention DisOrder PredicTor) software on the expanded version of the CheZOD database. ADOPT outperforms the state-of-the-art tools, ODiNPred, SPOT-Disorder and Metapredict v2, in a number of benchmarks. Finally, we provide an analysis of the residue-level representations used in the development of ADOPT and discuss in detail the features that contribute to an accurate prediction of protein disorder from sequence alone.</p>
  </sec>
  <sec sec-type="materials|methods" id="SEC2">
    <title>MATERIALS AND METHODS</title>
    <p>ADOPT is composed of two blocks: a self-supervised encoder and a supervised disorder predictor. The encoder takes a protein input sequence and uses information from a large database of sequences to generate feature information for every residue in the sequence. The decoder uses this information and predicts a disorder score. We used Facebook’s Evolutionary Scale Modeling (ESM) library to extract dense amino acid residue-level representations, which feed into the supervised ML-based predictor. The ESM library exploits a set of deep transformer encoder models (<xref rid="B42" ref-type="bibr">42</xref>,<xref rid="B43" ref-type="bibr">43</xref>), which processes character sequences of amino acids as inputs. A high-level representation of the ADOPT architecture is shown in Figure <xref rid="F1" ref-type="fig">1</xref>.</p>
    <fig position="float" id="F1">
      <label>Figure 1.</label>
      <caption>
        <p>Schematic view of the ADOPT architecture. A protein sequence is fed into the transformer encoder block that generates a residue-level representation of the input. The embedding vector serves as an input to the disorder predictor block that predicts the level of disorder of each residue, given in terms of <italic toggle="yes">Z</italic>-scores.</p>
      </caption>
      <graphic xlink:href="lqad041fig1" position="float"/>
    </fig>
    <p>The encoder maps each element <italic toggle="yes">x</italic><sub><italic toggle="yes">i</italic></sub> ∈ <italic toggle="yes">V</italic> of an input sequence of symbol representations <bold>x</bold> = (<italic toggle="yes">x</italic><sub>1</sub>, …, <italic toggle="yes">x</italic><sub><italic toggle="yes">n</italic></sub>) to a dense vector <bold>z</bold><sub><italic toggle="yes">i</italic></sub>, where <inline-formula><tex-math id="M0001" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}${\bf z}_i \in \mathbb {R}^{d_{{\rm mod}}}$\end{document}</tex-math></inline-formula>. This means that the context of every residue within the input sequence is encoded in a vector with <italic toggle="yes">d</italic><sub>mod</sub> features . Here, <inline-formula><tex-math id="M0001a" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$d_{{\rm mod}} \in \mathbb {N}^+$\end{document}</tex-math></inline-formula> is the <italic toggle="yes">embedding dimension</italic> that is set at training time, <inline-formula><tex-math id="M0002" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$n \in \mathbb {N}^*$\end{document}</tex-math></inline-formula> is the length of the protein <italic toggle="yes">p</italic> represented by <bold>x</bold> and</p>
    <disp-formula>
      <tex-math id="M0003" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$$\begin{eqnarray*} V&amp;=&amp;\lbrace 'L ', 'A ', 'G ', 'V ', 'S ', 'E ', 'R ', 'T ', 'I ', 'D ', \\ &amp;&amp; 'P ', 'K ', 'Q ', 'N ', 'F ', 'Y ', 'M ', 'H ', 'W ', 'C ', \\ &amp;&amp; 'X ', 'B ', 'U ', 'Z ', 'O ', '\text{--} '\rbrace \end{eqnarray*}$$\end{document}</tex-math>
    </disp-formula>
    <p>represents the vocabulary, where '<italic toggle="yes">X</italic>’ stands for unknown amino acid and ‘−’ is the gap symbol in the event of a multi-sequence aligned input. Furthermore, ‘<italic toggle="yes">B</italic> and <italic toggle="yes">Z</italic>’ are ambiguous and ‘<italic toggle="yes">U</italic> and <italic toggle="yes">O</italic>’ are non-natural amino acids, and the remaining 20 are standard ones. Therefore, a protein <italic toggle="yes">p</italic>, represented by the sequence vector <bold>x</bold>, will be encoded on an embedding matrix <inline-formula><tex-math id="M0004" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$Z \in \mathbb {R}^{n \times d_{{\rm mod}}}$\end{document}</tex-math></inline-formula> obtained by stacking <bold>z</bold><sub><italic toggle="yes">i</italic></sub> for <italic toggle="yes">i</italic> = 1, 2, …, <italic toggle="yes">n</italic>.</p>
    <p>ADOPT computes residue-level <italic toggle="yes">Z</italic>-scores (<xref rid="B36" ref-type="bibr">36</xref>), which quantify the degree of local disorder related to each residue, on a continuous scale, based on NMR secondary chemical shifts (<xref rid="B47" ref-type="bibr">47</xref>). The input of the disorder predictor is given by the dense representations (embeddings) <italic toggle="yes">Z</italic> of each protein sequence <bold>x</bold>, whereas the output is the predicted <italic toggle="yes">Z</italic>-score of each element <italic toggle="yes">x</italic><sub><italic toggle="yes">i</italic></sub> of <bold>x</bold>.</p>
    <p>In order to strike a balance between readability and details, while keeping the paper self-contained, we provide more details on the transformer block, including the attention mechanism (see Supplementary Figure S1).</p>
    <sec id="SEC2-1">
      <title>Datasets</title>
      <sec id="SEC2-1-1">
        <title>Pre-training datasets</title>
        <p>Pre-training datasets were based on UniRef (<xref rid="B48" ref-type="bibr">48</xref>). UniRef50 and UniRef90 were extracted from UniParc (<xref rid="B49" ref-type="bibr">49</xref>) by clustering at 50% and 90% sequence identity, respectively. The UR90/S dataset represents a high-diversity and sparse subset of UniRef90 dated March 2020 and contains 98 million proteins, while the UR50/S dataset represents a high-diversity and sparse subset of UniRef50 representative sequences from March 2018 with 27.1 million proteins. The MSA-UR50 dataset was generated with multiple sequence alignment (MSA) to each UniRef50 sequence by searching the UniClust30 (<xref rid="B50" ref-type="bibr">50</xref>) database in October 2017 with HHblits 3.1.0 (<xref rid="B51" ref-type="bibr">51</xref>) and contained 26 million MSAs. Default settings were used for HHblits except for the number of search iterations (<monospace>-n</monospace>), which was set to 3. Sequences longer than 1024 residues were removed and the average depth of the MSAs was 1192.</p>
      </sec>
      <sec id="SEC2-1-2">
        <title>Disorder prediction datasets</title>
        <p>The disorder prediction datasets were the CheZOD ‘1325’ and the CheZOD ‘117’ databases (<xref rid="B39" ref-type="bibr">39</xref>) containing 1325 and 117 sequences, respectively, together with their residue-level <italic toggle="yes">Z</italic>-scores. Note that throughout this paper we refer to the ‘1325’ and ‘117’ sets as <italic toggle="yes">base</italic> and <italic toggle="yes">validation</italic> sets, respectively.</p>
        <p>Although <italic toggle="yes">Z</italic>-scores can be transformed into probabilities of disorder that report on the likelihood of a residue being disordered, we decided to adhere to <italic toggle="yes">Z</italic>-scores primarily reported in ODiNPred (<xref rid="B39" ref-type="bibr">39</xref>).</p>
      </sec>
    </sec>
    <sec id="SEC2-2">
      <title>Pre-trained transformer models</title>
      <p>ADOPT utilizes three different pre-trained transformers: <italic toggle="yes">ESM-1b</italic>, <italic toggle="yes">ESM-1v</italic> and <italic toggle="yes">ESM-MSA</italic>. The architectures of <italic toggle="yes">ESM-1b</italic> and <italic toggle="yes">ESM-1v</italic> were described earlier and pre-trained on UR50/S and UR90/S, respectively. A complete review of <italic toggle="yes">ESM-MSA</italic> architecture is given in (<xref rid="B52" ref-type="bibr">52</xref>). The aforementioned transformer was pre-trained on MSA-UR50 (see Table <xref rid="tbl1" ref-type="table">1</xref>).</p>
      <table-wrap position="float" id="tbl1">
        <label>Table 1.</label>
        <caption>
          <p>Hyperparameters, dataset and number of parameters related to each ESM model employed</p>
        </caption>
        <table frame="hsides" rules="groups">
          <thead>
            <tr>
              <th rowspan="1" colspan="1">Transformer</th>
              <th rowspan="1" colspan="1">Dataset</th>
              <th rowspan="1" colspan="1">
                <italic toggle="yes">l</italic>
              </th>
              <th rowspan="1" colspan="1">
                <italic toggle="yes">d</italic>
                <sub>mod</sub>
              </th>
              <th rowspan="1" colspan="1">
                <italic toggle="yes">h</italic>
              </th>
              <th rowspan="1" colspan="1">Parameters</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">
                <italic toggle="yes">ESM-1v</italic>
              </td>
              <td rowspan="1" colspan="1">UR90/S</td>
              <td rowspan="1" colspan="1">33</td>
              <td rowspan="1" colspan="1">1280</td>
              <td rowspan="1" colspan="1">20</td>
              <td rowspan="1" colspan="1">650 M</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">
                <italic toggle="yes">ESM-1b</italic>
              </td>
              <td rowspan="1" colspan="1">UR50/S</td>
              <td rowspan="1" colspan="1">33</td>
              <td rowspan="1" colspan="1">1280</td>
              <td rowspan="1" colspan="1">20</td>
              <td rowspan="1" colspan="1">650 M</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">
                <italic toggle="yes">ESM-MSA</italic>
              </td>
              <td rowspan="1" colspan="1">MSA-UR50</td>
              <td rowspan="1" colspan="1">12</td>
              <td rowspan="1" colspan="1">768</td>
              <td rowspan="1" colspan="1">12</td>
              <td rowspan="1" colspan="1">100 M</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
    </sec>
    <sec id="SEC2-3">
      <title>Disorder predictors</title>
      <p>We built four different variants of ADOPT, which differed in the underlying ESM model. We used <italic toggle="yes">ESM-1v</italic>, <italic toggle="yes">ESM-1b</italic>, <italic toggle="yes">ESM-MSA</italic> and <italic toggle="yes">ESM-combined</italic>, where the last one referred to the concatenation of the representations given by <italic toggle="yes">ESM-1v</italic> and <italic toggle="yes">ESM-1b</italic>. The input dimension <italic toggle="yes">d</italic><sub>mod</sub>, which was equivalent to the dimension of the residue-level representation, was dependent on the ESM transformer used (Table <xref rid="tbl1" ref-type="table">1</xref>), e.g. <italic toggle="yes">d</italic><sub>mod</sub> = 2560 for <italic toggle="yes">ESM-combined</italic> and <italic toggle="yes">d</italic><sub>mod</sub> = 1280 for <italic toggle="yes">ESM-1b</italic>. Note that <italic toggle="yes">ESM-combined</italic> is an artificial concept and just a label that does not represent a stand-alone transformer model. In fact, it is only a reference to the concatenated outputs extracted from the two pre-trained transformers <italic toggle="yes">ESM-1v</italic> and <italic toggle="yes">ESM-1b</italic>.</p>
      <p>Not all four predictors were tested in every benchmark exercise due to the fact that some of them, e.g. <italic toggle="yes">ESM-1v</italic> and <italic toggle="yes">ESM-1b</italic>, have similar performances. We indicate in each result discussed which predictor is used.</p>
      <p>To predict <italic toggle="yes">Z</italic>-scores using the residue-level representations, we used a simple Lasso regression model with shrinkage parameter <italic toggle="yes">λ</italic> = 0.0001, which is considered a well-known, standard technique; see e.g. Chapter 3 in (<xref rid="B53" ref-type="bibr">53</xref>). The optimal value for <italic toggle="yes">λ</italic> was found experimentally by a search across the interval [0.0001, 0.5].</p>
      <p>In the binary case, i.e. predicting <italic toggle="yes">order/disorder</italic> only, we used a simple logistic regression with a <italic toggle="yes">L</italic><sub>2</sub> penalty term; for details, see Chapter 4 in (<xref rid="B53" ref-type="bibr">53</xref>).</p>
      <p>As a benchmark with AlphaFold2, we correlated rolling averages of the predicted local distance difference test (pLDDT) and solvent accessible surface area (SASA), defined in the ‘Benchmark on order/disorder classification’ section, with <italic toggle="yes">Z</italic>-scores. In both metrics, the window lengths were ranging from 5 to 30 in steps of 5. In the three cases of sequences containing unknown amino acids, the unknown amino acid was replaced with glycine. SASA was calculated using FreeSASA 2.0.3 (<ext-link xlink:href="https://freesasa.github.io/" ext-link-type="uri">https://freesasa.github.io/</ext-link>) with default parameters, with the total relative per residue used for correlations.</p>
    </sec>
    <sec id="SEC2-4">
      <title>Supervised training and evaluation</title>
      <p>Our predictors were trained on a reduced part of <italic toggle="yes">base</italic> dataset. We filtered out all sequences from the base set that showed 20% or higher pairwise sequence similarity with the sequences in the test set, i.e. the 117 CheZOD dataset. These sequences were identified with the tool <monospace>MMSeqs2</monospace> [<monospace>mmseqs search</monospace> was used with sensitivity <monospace>-s 7.5</monospace> and number of iteration 3; <monospace>fident</monospace> (fraction of identical matches) was used as a pairwise similarity metric]; see (<xref rid="B54" ref-type="bibr">54</xref>) and <ext-link xlink:href="https://github.com/soedinglab/MMseqs2" ext-link-type="uri">https://github.com/soedinglab/MMseqs2</ext-link>. We further reduced our training set and kept only those sequences that appeared in the training set of Ilzhoefer <italic toggle="yes">et al.</italic> (<xref rid="B55" ref-type="bibr">55</xref>), which also used the CheZOD dataset to develop a disorder predictor (after the original release of our work in a bioRxiv manuscript on 26 May 2022). This means that there were 1159 sequences in our final training set. We used the validation set containing 117 sequences as the test set. The performance of our regression models was measured by Spearman correlation (<inline-formula><tex-math id="M0005" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\rho _{\texttt {Spearman}}$\end{document}</tex-math></inline-formula>) between predicted and experimental <italic toggle="yes">Z</italic>-scores. To further assess model performance, we also provided mean absolute errors (MAEs) and average prediction errors. Where relevant, we also added <italic toggle="yes">P</italic>-values. However, given that these were consistently 0.0, i.e. detecting e.g. correlation falsely had zero probability, we omitted them from most tables.</p>
      <p>Following the cross-validation settings used in (<xref rid="B39" ref-type="bibr">39</xref>), we performed a similar 10-fold cross-validation (CV), separately, using only a filtered version of the base dataset, i.e. 1325 sequences. We removed sequences that showed pairwise identity ≥50%. This time, similarity was computed <italic toggle="yes">only within</italic> the base set, and we used the same setting as described earlier, i.e. <monospace>mmseqs search</monospace> routine with sensitivity <monospace>-s 7.5</monospace> and number of iterations 3; similarity was assessed using <monospace>fident</monospace>. This procedure resulted in a set with 1168 sequences, which we will refer to as a <italic toggle="yes">cross-validation set</italic>. Note that the overlap between this set, which we used for all subsequent cross-validation exercises, and the training set described in the above paragraph is only 1069 sequences. As per standard practice, in a fold 9/10th of the base dataset was used as the training set, where model was fitted, and the remaining 1/10th as the test set. We used randomized 10-fold CV; that is, the folds were selected randomly. A new regression was trained for each fold and we report the average correlation <inline-formula><tex-math id="M0006" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\rho _{\texttt {Spearman}}$\end{document}</tex-math></inline-formula>, average MAE and average prediction errors, together with standard deviations, taken across the folds. For the regression task, we performed two cross-validation exercises: one based on <italic toggle="yes">residue-level</italic> and another on <italic toggle="yes">sequence-level</italic> fold selection. In the former case, whether a residue was in the training or test set was decided on amino acid level. The latter meant that training and test sets were assembled by sequences; i.e. all residues in a sequence were either in the training or in the test set. Note that despite mentioning some of the results from the related ODiNPred paper (<xref rid="B39" ref-type="bibr">39</xref>), we omit any direct comparison between the cross-validation tasks presented here and those appearing in the ODiNPred, due to differences in the datasets used.</p>
      <p>In the order/disorder classification tasks, we used the area under the receiver operating characteristic curve (ROC AUC) and Matthews correlation coefficient (MCC) as standard evaluation metrics. Furthermore, we provided precision scores, whereby ordered residues were treated as ‘positives’ (<italic toggle="yes">Z</italic>-scores &gt;8.0). Our classifiers were evaluated in two settings: a residue-level 10-fold CV on the cross-validation set, and a training using the filtered base set and testing on the validation set.</p>
    </sec>
    <sec id="SEC2-5">
      <title>Feature selection</title>
      <p>Two methods were used to identify a subset of relevant coordinates or features of the residue-level representation vectors, as shown in Figure <xref rid="F5" ref-type="fig">5</xref>. Recall that we used Lasso regression as our disorder predictor.</p>
      <fig position="float" id="F2">
        <label>Figure 2.</label>
        <caption>
          <p>Reliability study on ADOPT predictions. Spearman correlations and disordered regions’ prediction recall computed on trimmed and randomly mutated sequences are shown in panels (<bold>A</bold>) and (<bold>B</bold>), respectively. MAEs computed on trimmed and randomly mutated sequences are shown in panels (<bold>C</bold>) and (<bold>D</bold>), respectively.</p>
        </caption>
        <graphic xlink:href="lqad041fig2" position="float"/>
      </fig>
      <fig position="float" id="F3">
        <label>Figure 3.</label>
        <caption>
          <p>Contour plots showing the density levels of experimental versus predicted <italic toggle="yes">Z</italic>-scores for the validation set containing 117 sequences: panel (<bold>A</bold>) shows results obtained with ESM transformer-based predictor (here <italic toggle="yes">ESM-1b</italic> was used) and panel (<bold>B</bold>) shows the results obtained with ODiNPred. Diagonal reference lines indicate the idealized ‘perfect’ prediction; i.e. predicted values are equal to the experimental values. As the probability mass around the reference line is tighter for the ESM-based predictor on the left, its accuracy is better than that of ODiNPred. This is further supported by the average prediction error and MAE for the two predictors (see Table <xref rid="tbl2" ref-type="table">2</xref>). <italic toggle="yes">Z</italic>-scores predicted by ODiNPred were retrieved via the publicly available web service referenced in (<xref rid="B39" ref-type="bibr">39</xref>). Note that using these predicted <italic toggle="yes">Z</italic>-scores a slightly higher Spearman correlation of 0.671 was found, rather than 0.649 as reported in (<xref rid="B39" ref-type="bibr">39</xref>). Recall that the Spearman correlation for <italic toggle="yes">ESM-1b</italic> was 0.686. Note that the difference between correlation coefficients 0.671 and 0.686 was found to be significant (one-sided <italic toggle="yes">P</italic>-value = 0.0122) based on the Fisher <italic toggle="yes">r</italic>-to-<italic toggle="yes">Z</italic> transformation.</p>
        </caption>
        <graphic xlink:href="lqad041fig3" position="float"/>
      </fig>
      <fig position="float" id="F4">
        <label>Figure 4.</label>
        <caption>
          <p>Residue-level comparison of Spearman correlations between actual and predicted <italic toggle="yes">Z</italic>-scores for the validation set containing 117 sequences. Two of the ESM transformer-based predictors were used, <italic toggle="yes">ESM-1b</italic> and <italic toggle="yes">ESM-combined</italic>, which is based on the concatenated representations of <italic toggle="yes">ESM-1v</italic> and <italic toggle="yes">ESM-1b</italic>. The dotted reference line indicates the overall Spearman correlation of 0.649 obtained by ODiNPred as reported in (<xref rid="B39" ref-type="bibr">39</xref>).</p>
        </caption>
        <graphic xlink:href="lqad041fig4" position="float"/>
      </fig>
      <fig position="float" id="F5">
        <label>Figure 5.</label>
        <caption>
          <p>Predictive power of the residue-level representation vectors as a function of the number of their coordinates used in the regression. Here, the transformer <italic toggle="yes">ESM-1b</italic> was used, and the predictive power was quantified in terms of <inline-formula><tex-math id="M0007" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\rho _{\texttt {Spearman}}$\end{document}</tex-math></inline-formula> between actual and predicted <italic toggle="yes">Z</italic>-scores on the validation set containing 117 sequences. <italic toggle="yes">Naive selection</italic> (blue line) is based on the magnitude of the regression coefficients and <italic toggle="yes">stability selection</italic> (red line) is a more robust technique based on resampling; more details are provided in the ‘Discussion’ section.</p>
        </caption>
        <graphic xlink:href="lqad041fig5" position="float"/>
      </fig>
      <p>In <italic toggle="yes">naive selection</italic>, we selected only those coordinates whose coefficients were above a certain threshold in terms of their absolute value; that is, the subset <italic toggle="yes">S</italic> ⊂ {1, 2, …, 1280} was given by</p>
      <disp-formula>
        <tex-math id="M0008" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$$\begin{eqnarray*} |\beta _{s}| &gt;{\rm cut\hbox{-}off} \quad \Longleftrightarrow \quad s \in S, \end{eqnarray*}$$\end{document}</tex-math>
      </disp-formula>
      <p>where <italic toggle="yes">β</italic><sub><italic toggle="yes">i</italic></sub> for <italic toggle="yes">i</italic> ∈ {1, 2, …, 1280} are the Lasso coefficients for the fixed shrinkage parameter <italic toggle="yes">λ</italic> = 0.0001. We fitted a new linear regression (Lasso with the same parameter <italic toggle="yes">λ</italic> = 0.0001) on the reduced set of features and reported the correlation <italic toggle="yes">ρ</italic><sub>Spearman</sub> between predicted and actual <italic toggle="yes">Z</italic>-scores on the test set. We repeated this procedure for 10 different <italic toggle="yes">cut-off</italic> values, equally spaced ranging from 0.5 to 0.2. This selection method is called naive, as it throws away coordinates whose coefficients are below the cut-off in absolute terms, which may still be relevant, and the set of selected features may contain a fair amount of noise. As an alternative method, we used <italic toggle="yes">stability selection</italic> to identify relevant subsets of the representation vector coordinates. We defined 30 different shrinkage parameters <italic toggle="yes">λ</italic>. These were equally spaced points of the interval [5 × 10<sup>−5</sup>, 0.1], endpoints included. For each <italic toggle="yes">λ</italic>, we carried out the following procedure. From the initial test set, we chose a random subset, whose size was half of the original one. We fitted a Lasso regression and recorded the features, whose coefficients were non-zero. We repeated this 500 times and for each vector coordinate <italic toggle="yes">i</italic> ∈ {1, 2, …, 1280} we estimated the selection probability Π<sub><italic toggle="yes">i</italic></sub>(<italic toggle="yes">λ</italic>) by the number of times the coordinate got selected divided by 500.</p>
      <p>In order to arrive at the relevant subsets, we applied cut-off values at two different stages. First, we put a threshold <italic toggle="yes">c</italic><sub>p</sub> on the selection probabilities. Second, we counted for how many <italic toggle="yes">λ</italic> values this particular threshold <italic toggle="yes">c</italic><sub>p</sub> has been exceeded. We refer to the latter quantity as frequency cut-off and denote it by <italic toggle="yes">c</italic><sub>f</sub>. We used the following values:</p>
      <disp-formula>
        <tex-math id="M0009" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$$\begin{eqnarray*} c_{{\rm p}} \in [0.6, 0.7, 0.8, 0.9], \quad c_{{\rm f}} \in [10, 15, 20]. \end{eqnarray*}$$\end{document}</tex-math>
      </disp-formula>
      <p>As an example, for <italic toggle="yes">c</italic><sub>p</sub> = 0.6 and <italic toggle="yes">c</italic><sub>f</sub> = 15, a representation vector coordinate <italic toggle="yes">i</italic> was deemed relevant if the selection probability Π<sub><italic toggle="yes">i</italic></sub>(<italic toggle="yes">λ</italic>) &gt; 0.6 for at least 15 different <italic toggle="yes">λ</italic> values. The estimated probabilities Π<sub><italic toggle="yes">i</italic></sub>(<italic toggle="yes">λ</italic>) as a function of <italic toggle="yes">λ</italic> ∈ Λ can be depicted as paths. We use the term <italic toggle="yes">stability paths</italic> to describe those that pass the aforementioned two thresholds <italic toggle="yes">c</italic><sub>p</sub> and <italic toggle="yes">c</italic><sub>f</sub>, as shown in Figure <xref rid="F6" ref-type="fig">6</xref>. For more details and discussions on stability selection in general, we refer to (<xref rid="B56" ref-type="bibr">56</xref>).</p>
      <fig position="float" id="F6">
        <label>Figure 6.</label>
        <caption>
          <p>Stability path examples given by <italic toggle="yes">stability selection</italic>, as described in the ‘Materials and Methods’ section; see the ‘Feature selection’ subsection. Here, we used the transformer <italic toggle="yes">ESM-1b</italic> and applied the probability and frequency cut-offs <italic toggle="yes">c</italic><sub>p</sub> = 0.9 and <italic toggle="yes">c</italic><sub>f</sub> = 20, respectively. A particular line represents one coordinate or feature of the representation vector and shows the selection probability Π<sub><italic toggle="yes">i</italic></sub>(<italic toggle="yes">λ</italic>) (on the <italic toggle="yes">y</italic>-axis) as a function of the shrinkage parameter <italic toggle="yes">λ</italic> (on the <italic toggle="yes">x</italic>-axis). The red, solid lines represent the coordinates that made the final subset selection and the black, dashed lines represent all remaining coordinates. In this particular example, there are 78 red lines. Interestingly, there is one red line (coordinate) buried in the black lines in the region of lower shrinkage values <italic toggle="yes">λ</italic>. This means that even though more coordinates were selected in Lasso for a lower <italic toggle="yes">λ</italic>, this particular coordinate, which typically was picked for higher <italic toggle="yes">λ</italic>, was not selected.</p>
        </caption>
        <graphic xlink:href="lqad041fig6" position="float"/>
      </fig>
    </sec>
    <sec id="SEC2-6">
      <title>Implementation</title>
      <p>ADOPT is available as a command-line utility at <ext-link xlink:href="https://github.com/PeptoneLtd/ADOPT" ext-link-type="uri">https://github.com/PeptoneLtd/ADOPT</ext-link>. The software uses Facebook’s ESM 0.4 (<ext-link xlink:href="https://github.com/facebookresearch/esm" ext-link-type="uri">https://github.com/facebookresearch/esm</ext-link>) for the pre-training phase, Sklearn 1.0 (<ext-link xlink:href="https://scikit-learn.org/stable/" ext-link-type="uri">https://scikit-learn.org/stable/</ext-link>) for the disorder predictor, BertViz 1.2 (<ext-link xlink:href="https://github.com/jessevig/bertviz" ext-link-type="uri">https://github.com/jessevig/bertviz</ext-link>) for the multi-head attention visualization, HHblits 3.1.0 (<ext-link xlink:href="https://github.com/soedinglab/hh-suite" ext-link-type="uri">https://github.com/soedinglab/hh-suite</ext-link>) for extracting the MSAs and ONNX 1.10.2 (<ext-link xlink:href="https://onnx.ai/" ext-link-type="uri">https://onnx.ai/</ext-link>) for the inference phase. The embedding representations were extracted in bulk with the ESM command-line utility specifying the <monospace>--include per_tok</monospace> option from both CheZOD ‘1325’ and CheZOD ‘117’ FASTA files. The embedding vectors’ extraction and tool development (training and inference) were performed on a single Nvidia DGX A100.</p>
    </sec>
  </sec>
  <sec sec-type="results" id="SEC3">
    <title>RESULTS</title>
    <sec id="SEC3-1">
      <title>Disorder predictor developed using the CheZOD datasets</title>
      <p>In order to compare ADOPT to the current state-of-the-art disorder predictor ODiNPred, we adopted the benchmarking protocol found in (<xref rid="B39" ref-type="bibr">39</xref>). The CheZOD database was split into two parts, a <italic toggle="yes">base</italic> and a <italic toggle="yes">validation</italic> set, containing 1325 and 117 sequences, respectively, with their residue-level <italic toggle="yes">Z</italic>-scores, which are NMR-based measures of disorder. We used <italic toggle="yes">Z</italic>-scores to compute the probability of disorder <inline-formula><tex-math id="M00010" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\mathbb {P}_{\texttt {disorder}}$\end{document}</tex-math></inline-formula> at residual level. A probability close to 1 indicates that the residue is likely disordered. Throughout this paper, we are only considering <italic toggle="yes">Z</italic>-scores as a measure of disorder and omit any further quantification of probabilities of disorder. Furthermore, for classification tasks residues with <italic toggle="yes">Z</italic>-scores below/above 8 were assumed to be disordered/ordered, respectively.</p>
    </sec>
    <sec id="SEC3-2">
      <title>Training on the base set and performance evaluation on the validation set</title>
      <p>We evaluated the variants of ADOPT on four different representations obtained from ESM transformers: <italic toggle="yes">ESM-1b</italic>, <italic toggle="yes">ESM-1v</italic>, <italic toggle="yes">ESM-MSA</italic> and also an <italic toggle="yes">ESM-combined</italic> that used the concatenated representations from <italic toggle="yes">ESM-1b</italic> and <italic toggle="yes">ESM-1v</italic>. Note that the choice of the transformer model changes the input of our disorder predictor and therefore influences its performance. The reduced base and validation sets consisted of 1236 and 117 sequences, respectively. Here, sequences that are part of both sets of the CheZOD database were removed from the <italic toggle="yes">base</italic> set. We found that disorder predictors had a tendency to overestimate the experimental <italic toggle="yes">Z</italic>-scores, which was a phenomenon universally observed across the whole spectrum of predictors (<xref rid="B39" ref-type="bibr">39</xref>). On the validation set, ODiNPred e.g. displayed an average prediction error of −2.723, meaning that it typically predicted higher <italic toggle="yes">Z</italic>-scores and an MAE of 3.735. Although our ESM-based predictors also overestimated <italic toggle="yes">Z</italic>-scores, their prediction errors were considerably lower; e.g. for <italic toggle="yes">ESM-1b</italic> the average prediction error and MAE were −2.179 and 3.417, respectively. Spearman correlation coefficients (<inline-formula><tex-math id="M00011" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\rho _{\texttt {Spearman}}$\end{document}</tex-math></inline-formula>) between the predicted and actual <italic toggle="yes">Z</italic>-scores were used to benchmark performance against ODiNPred. Our ESM transformer-based predictors showed the following Spearman correlation coefficients between predicted and experimental <italic toggle="yes">Z</italic>-scores: 0.686 (<italic toggle="yes">ESM-1b</italic>), 0.677 (<italic toggle="yes">ESM-1v</italic>), 0.604 (<italic toggle="yes">ESM-MSA</italic>) and 0.688 (<italic toggle="yes">ESM-combined</italic>), compared to the reported Spearman correlation coefficient of 0.649 for ODiNPred and 0.64 for SPOT-Disorder given the same prediction task (<xref rid="B39" ref-type="bibr">39</xref>) (see Table <xref rid="tbl2" ref-type="table">2</xref>). We note that these results have been reproduced by Ilzhoefer <italic toggle="yes">et al.</italic> (<xref rid="B55" ref-type="bibr">55</xref>) after the original release of our work in a bioRxiv manuscript on 26 May 2022. Note that the difference between correlation coefficients of <italic toggle="yes">ESM-1b</italic> and ODiNPred was found to be significant (one-sided <italic toggle="yes">P</italic>-value = 0.0122, compared to ODiNPred’s 0.671) by using Fisher <italic toggle="yes">r</italic>-to-<italic toggle="yes">Z</italic> transformation. At the same time, the difference between the correlations of <italic toggle="yes">ESM-1b</italic> and <italic toggle="yes">ESM-1v</italic> is less significant (one-sided <italic toggle="yes">P</italic>-value = 0.0869). We also performed the same benchmark test on a recent disorder predictor, Metapredict v2 (<xref rid="B57" ref-type="bibr">57</xref>). Metapredict v2 was generated by training a neural network on the disorder scores of a hybrid version of the original Metapredict disorder predictor (<xref rid="B58" ref-type="bibr">58</xref>) and predicted pLDDT scores. While the original predictor was highly competitive in the last CAID competition, the successor clearly outperforms the performance of the original predictor with faster execution time. The Spearman correlation coefficient between predicted disorder scores from Metapredict v2 and experimentally derived scores was 0.6581, slightly better than ODiNPred and SPOT-Disorder, but worse than ADOPT. In summary, ADOPT predicted protein disorder more accurately than current state-of-the-art predictors and the overestimation of experimental <italic toggle="yes">Z</italic>-scores observed across all the tested disordered predictors indicates that these ML-based algorithms display high sensitivity to sequence patterns present in ordered regions.</p>
      <table-wrap position="float" id="tbl2">
        <label>Table 2.</label>
        <caption>
          <p>Spearman correlations between actual <italic toggle="yes">Z</italic>-scores and predicted pLDDT<sub>5</sub> scores along with actual <italic toggle="yes">Z</italic>-scores and predicted SASA<sub>15</sub> scores, obtained by AlphaFold2</p>
        </caption>
        <table frame="hsides" rules="groups">
          <thead>
            <tr>
              <th rowspan="1" colspan="1">Disorder predictor</th>
              <th rowspan="1" colspan="1">Spearman correlation coefficient (<inline-formula><tex-math id="M00012" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\rho _{\texttt {Spearman}}$\end{document}</tex-math></inline-formula>)</th>
              <th rowspan="1" colspan="1">Average prediction error</th>
              <th rowspan="1" colspan="1">MAE</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">AlphaFold2, pLDDT<sub>5</sub></td>
              <td rowspan="1" colspan="1">0.555</td>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1"/>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">AlphaFold2, SASA<sub>15</sub></td>
              <td rowspan="1" colspan="1">0.630</td>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1"/>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Metapredict v2</td>
              <td rowspan="1" colspan="1">0.658</td>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1"/>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">ODiNPred</td>
              <td rowspan="1" colspan="1">0.649</td>
              <td rowspan="1" colspan="1">−2.723 ± 3.95</td>
              <td rowspan="1" colspan="1">3.735 ± 3.01</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">
                <italic toggle="yes">ESM-1v</italic>
              </td>
              <td rowspan="1" colspan="1">0.677</td>
              <td rowspan="1" colspan="1">−2.377 ± 3.94</td>
              <td rowspan="1" colspan="1">3.559 ± 2.93</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">
                <italic toggle="yes">ESM-1b</italic>
              </td>
              <td rowspan="1" colspan="1">0.686</td>
              <td rowspan="1" colspan="1">−<bold>2.179</bold> ± 3.85</td>
              <td rowspan="1" colspan="1"><bold>3.417</bold> ± 2.81</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">
                <italic toggle="yes">ESM-MSA</italic>
              </td>
              <td rowspan="1" colspan="1">0.604</td>
              <td rowspan="1" colspan="1">−2.973 ± 4.16</td>
              <td rowspan="1" colspan="1">4.035 ± 3.14</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">
                <italic toggle="yes">ESM-combined</italic>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.688</bold>
              </td>
              <td rowspan="1" colspan="1">−2.189 ± 3.91</td>
              <td rowspan="1" colspan="1">3.442 ± 2.86</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="T2TFN1">
            <p>Spearman correlations between actual and predicted <italic toggle="yes">Z</italic>-scores, average prediction error (actual − predicted) and MAE obtained by ODiNPred and our ESM transformer-based predictors. These correlations have been collected for the task linked to the model evaluated on the validation set consisting of 117 sequences. Given that the <italic toggle="yes">P</italic>-values in all cases were 0.0, we omitted them.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p>The prediction of local disorder in a residue is dependent on the neighbourhood of this residue. In order to estimate whether our predictor is able to correctly identify disordered regions, we computed the disordered regions’ prediction recall score, i.e. the fraction of correctly predicted disordered regions from all disordered regions in the dataset. First, the <italic toggle="yes">Z</italic>-score related to each residue in all proteins of the <italic toggle="yes">validation</italic> set has been predicted with the <italic toggle="yes">ESM-1b</italic> model as upstream task. After converting the <italic toggle="yes">Z</italic>-scores of both, the ground truth and the predicted ones, into a binary class, i.e. <italic toggle="yes">Z</italic> &lt; 8 for a residue belonging to a disordered region and <italic toggle="yes">Z</italic> ≥ 8 for a residue in an ordered region (<xref rid="B39" ref-type="bibr">39</xref>), we identify for each sequence the related disordered regions defined as those areas where the number of consecutive disordered residues is ≥3 in the ground truth and 70% of the residues in those areas are disordered in the prediction. The recall computed over the binary class of disordered regions is 66%. This means that the ADOPT disorder predictor trained on the <italic toggle="yes">ESM-1b</italic> transformer is able to correctly find most disordered regions.</p>
      <p>Furthermore, we test the robustness of our methods. Therefore, we introduce two small changes in the sequence and measure the change in disorder prediction. First, we predict how the termini of a protein sequence that are less structured and more flexible influence our predictions. We trim between 1 and 10 residues at both termini of each sequence and measure the difference between predicted and actual <italic toggle="yes">Z</italic>-scores for the rest of the protein. Second, we randomly mutated up to 10 residues in the <italic toggle="yes">validation</italic> dataset. In both cases, we report the differences in terms of MAE and Spearman correlation computed on the related ground truth and predicted <italic toggle="yes">Z</italic>-scores as well as recall score computed over disordered regions’ binary class. The results in Figure <xref rid="F2" ref-type="fig">2</xref> show that the accuracy of ADOPT is not influenced by the inclusion of random residues and changes in the number of termini residues showing that ADOPT is robust upon small changes in the given input protein sequence.</p>
      <p>In order to understand the origin of improvement observed in ADOPT, we compared the performance of one of our ESM transformer-based predictors <italic toggle="yes">ESM-1b</italic> against ODiNPred by visualizing the contour plots of the 2D density of actual versus predicted <italic toggle="yes">Z</italic>-scores (see Figure <xref rid="F3" ref-type="fig">3</xref>). Here, the reference lines indicate the idealized case, where predicted values are equal to the actual values. The more probability mass lies closer to these reference lines, the better the accuracy of the predictor. Figure <xref rid="F3" ref-type="fig">3</xref> demonstrates that both predictors identify correctly the bimodal <italic toggle="yes">Z</italic>-score distribution of ordered and disordered regions. This distribution has been chosen in the development of the CheZOD database in order to have a good mixture of both protein classes. The average mass is above the reference line in both regions and for both predictors, which shows that the bias to ordered regions is not limited to a specific strength of protein disorder. The contour lines are tighter around the reference line for the ESM transformer-based predictor (on the left), than for ODiNPred (on the right). The data for ODiNPred were obtained via the publicly available web service (<ext-link xlink:href="https://st-protein.chem.au.dk/odinpred" ext-link-type="uri">https://st-protein.chem.au.dk/odinpred</ext-link>). Note that using these predicted <italic toggle="yes">Z</italic>-scores a slightly higher Spearman correlation coefficient of 0.671 was found for ODiNPred, than 0.649 as reported in the paper (<xref rid="B39" ref-type="bibr">39</xref>). The result shows that the ESM transformer produces less outliers in comparison to ODiNPred. While the prediction of the ESM transformer is far from perfect, the probability of returning a bad <italic toggle="yes">Z</italic>-score prediction, defined by a difference of Δ<italic toggle="yes">Z</italic> = 5 from the experimental <italic toggle="yes">Z</italic>-score, is significantly lower than that for ODiNPred (see Figure <xref rid="F3" ref-type="fig">3</xref>).</p>
      <p>Our amino acid level analysis reveals further details about the biophysical origin of the prediction accuracy. We compared two of our proposed disorder predictors, <italic toggle="yes">ESM-1b</italic> and <italic toggle="yes">ESM-combined</italic>, to ODiNPred (Figure <xref rid="F4" ref-type="fig">4</xref>). Keeping the same setting as described earlier, i.e. <inline-formula><tex-math id="M00013" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\rho _{\texttt {Spearman}}$\end{document}</tex-math></inline-formula> between the predicted and experimental <italic toggle="yes">Z</italic>-scores for the validation set, we observed that the ESM transformer-based predictors displayed better than or similar correlation levels to that of ODiNPred for most amino acids. Some notable exceptions were histidine and methionine. In these cases, ODiNPred was significantly weaker with correlation coefficients <inline-formula><tex-math id="M00014" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\rho _{\texttt {Spearman}}=0.584$\end{document}</tex-math></inline-formula> and <inline-formula><tex-math id="M00015" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\rho _{\texttt {Spearman}}=0.560$\end{document}</tex-math></inline-formula> compared to e.g. <italic toggle="yes">ESM-1b</italic> with <inline-formula><tex-math id="M00016" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\rho _{\texttt {Spearman}}=0.643$\end{document}</tex-math></inline-formula> and <inline-formula><tex-math id="M00017" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\rho _{\texttt {Spearman}}=0.660$\end{document}</tex-math></inline-formula> for histidine and methionine, respectively. Curiously, all three predictors had considerable difficulties with glycine, cysteine and proline. In fact, for glycine, ODiNPred’s <inline-formula><tex-math id="M00018" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\rho _{\texttt {Spearman}}=0.610$\end{document}</tex-math></inline-formula> outperformed both ESM transformer-based predictors by ∼0.03 (see Figure <xref rid="F4" ref-type="fig">4</xref>). The distribution of <italic toggle="yes">Z</italic>-scores for these amino acids (<xref rid="sup1" ref-type="supplementary-material">Supplementary Figures S2 and S3</xref>) demonstrates that especially the <italic toggle="yes">Z</italic>-scores of ordered glycine and proline residues are shifted to higher <italic toggle="yes">Z</italic>-scores in the predictions of <italic toggle="yes">ESM-1b</italic> and ODiNPred in comparison to the actual values. While this trend is observed for all residues, it has a more pronounced effect on the correlation coefficient of glycine and proline because these amino acids are under-represented in ordered regions. The distribution of <italic toggle="yes">Z</italic>-scores from cysteine (see <xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S3</xref>) is clearly different from the distribution of the other amino acids with a higher relative amount of cysteines with intermediate <italic toggle="yes">Z</italic>-scores around 8. ODiNPred and <italic toggle="yes">ESM-1b</italic>, however, predict a much higher amount of ordered cysteine residues. Glycine, cysteine and proline are structurally different from the other 17 naturally occurring amino acids. Proline is the only amino acid with a secondary α amino group. Glycine is the smallest and most flexible amino acid, i.e. the only residue that has no chiral C<sup>α</sup> atom. Both amino acids are commonly referred to as α-helix breakers and thus are crucial for a correct prediction of disordered protein regions (<xref rid="B59" ref-type="bibr">59</xref>). Cysteine has a thiol group and is therefore the only residue that is able to form disulfide bonds within the protein over long distances in sequence. Disulfide bonds are particularly important for the stability of proteins (<xref rid="B60" ref-type="bibr">60</xref>). The forming or breaking of disulfide bonds depends on the oxidation state of the protein. This renders a correct prediction of its disorder state particularly challenging because the data we use to learn from and train on do not explicitly include the effect of oxidation. Moreover, the prediction of protein disorder remains especially challenging for amino acids that are important for the breaking of ordered regions. The newly developed ESM transformer improves the prediction of disordered segments for 19 out of 20 amino acids. This shows that the improvement of the ESM transformer is not limited to amino acid-specific biophysical properties.</p>
    </sec>
    <sec id="SEC3-3">
      <title>Performance of the ESM transformer-based disorder predictors assessed by 10-fold CV</title>
      <p>To gain further insights into the performance of our predictors, we carried out two different 10-fold CV following the protocol proposed in (<xref rid="B39" ref-type="bibr">39</xref>); a detailed description of these tests is provided in the ‘Materials and Methods’ section. Cross-validation gives information on how the predictor generalizes to an independent dataset by resampling the validation set in different portions to avoid overfitting or selection bias. In the <italic toggle="yes">residue-level 10-fold CV</italic>, the Spearman correlations averaged across the 10 folds were as follows: 0.746 (<italic toggle="yes">ESM-1b</italic>), 0.745 (<italic toggle="yes">ESM-1v</italic>) and 0.719 (<italic toggle="yes">ESM-MSA</italic>). The same correlations for the <italic toggle="yes">sequence-level 10-fold CV</italic> showed slightly lower values: 0.718 (<italic toggle="yes">ESM-1b</italic>), 0.717 (<italic toggle="yes">ESM-1v</italic>) and 0.702 (<italic toggle="yes">ESM-MSA</italic>). Even though a similar 10-fold CV was reported by ODiNPred to have a correlation of 0.6904 [see (<xref rid="B39" ref-type="bibr">39</xref>)], we highlight again that due to differences in datasets we used for CV and the one used by ODiNPred, we omit direct comparisons. These results are summarized in Tables <xref rid="tbl3" ref-type="table">3</xref> (residue level) and <xref rid="tbl4" ref-type="table">4</xref> (sequence level) and show that our predictor does not suffer from selection bias, e.g. from the specific choice of the <italic toggle="yes">validation set</italic>, but rather gives an overall balanced performance independent of the constitution of the <italic toggle="yes">validation set</italic>.</p>
      <table-wrap position="float" id="tbl3">
        <label>Table 3.</label>
        <caption>
          <p>Spearman correlations, MAE and average prediction error between predicted and actual <italic toggle="yes">Z</italic>-scores obtained by our ESM transformer-based predictors for the <italic toggle="yes">residue-level</italic> 10-fold CV on the <italic toggle="yes">cross-validation set</italic> consisting of 1168 sequences only</p>
        </caption>
        <table frame="hsides" rules="groups">
          <thead>
            <tr>
              <th colspan="4" align="center" rowspan="1"><italic toggle="yes">Residue-level</italic> 10-fold CV</th>
            </tr>
            <tr>
              <th rowspan="1" colspan="1">Disorder predictor</th>
              <th rowspan="1" colspan="1">
                <inline-formula>
                  <tex-math id="M00019" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\rho _{\texttt {Spearman}}$\end{document}</tex-math>
                </inline-formula>
              </th>
              <th rowspan="1" colspan="1">MAE</th>
              <th rowspan="1" colspan="1">Average prediction error</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">
                <italic toggle="yes">ESM-1v</italic>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.746</bold>
              </td>
              <td align="center" rowspan="1" colspan="1"><bold>2.285</bold> ± 0.012</td>
              <td align="center" rowspan="1" colspan="1"><bold>0.0001</bold> ± 0.029</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">
                <italic toggle="yes">ESM-1b</italic>
              </td>
              <td rowspan="1" colspan="1">0.745</td>
              <td align="center" rowspan="1" colspan="1">2.292 ± 0.019</td>
              <td align="center" rowspan="1" colspan="1">0.0001 ± 0.016</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">
                <italic toggle="yes">ESM-MSA</italic>
              </td>
              <td rowspan="1" colspan="1">0.719</td>
              <td align="center" rowspan="1" colspan="1">2.62 ± 0.023</td>
              <td align="center" rowspan="1" colspan="1">−0.0004 ± 0.034</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
      <table-wrap position="float" id="tbl4">
        <label>Table 4.</label>
        <caption>
          <p>Spearman correlations, MAE and average prediction error between predicted and actual <italic toggle="yes">Z</italic>-scores obtained by our ESM transformer-based predictors for the <italic toggle="yes">sequence-level</italic> 10-fold CV on the <italic toggle="yes">cross-validation set</italic> consisting of 1168 sequences only</p>
        </caption>
        <table frame="hsides" rules="groups">
          <thead>
            <tr>
              <th colspan="4" align="center" rowspan="1"><italic toggle="yes">Sequence-level</italic> 10-fold CV</th>
            </tr>
            <tr>
              <th rowspan="1" colspan="1">Disorder predictor</th>
              <th rowspan="1" colspan="1">
                <inline-formula>
                  <tex-math id="M00020" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\rho _{\texttt {Spearman}}$\end{document}</tex-math>
                </inline-formula>
              </th>
              <th rowspan="1" colspan="1">MAE</th>
              <th rowspan="1" colspan="1">Average prediction error</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">
                <italic toggle="yes">ESM-1v</italic>
              </td>
              <td rowspan="1" colspan="1">0.717</td>
              <td align="center" rowspan="1" colspan="1">2.438 ± 0.076</td>
              <td align="center" rowspan="1" colspan="1">0.0004 ± 0.168</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">
                <italic toggle="yes">ESM-1b</italic>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.718</bold>
              </td>
              <td align="center" rowspan="1" colspan="1"><bold>2.428</bold> ± 0.081</td>
              <td align="center" rowspan="1" colspan="1"><bold>0.004</bold> ± 0.151</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">
                <italic toggle="yes">ESM-MSA</italic>
              </td>
              <td rowspan="1" colspan="1">0.702</td>
              <td align="center" rowspan="1" colspan="1">2.716 ± 0.111</td>
              <td align="center" rowspan="1" colspan="1">−0.012 ± 0.268</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
    </sec>
    <sec id="SEC3-4">
      <title>Benchmark on order/disorder classification</title>
      <p>Experimental <italic toggle="yes">Z</italic>-scores from the sequences in the CheZOD database exhibit traits of a bimodal distribution, as shown in Figure <xref rid="F3" ref-type="fig">3</xref>. In (<xref rid="B39" ref-type="bibr">39</xref>), a mixture of two skew-normal distributions was fitted to the distribution of observed <italic toggle="yes">Z</italic>-scores with a reasonably high accuracy quantified by a Hellinger distance of 0.00367. This means that the distribution of <italic toggle="yes">Z</italic>-scores of all sequences in the CheZOD database can be approximated by two distributions that are separated in <italic toggle="yes">Z</italic>-score. This motivates a binary classification task, where a <italic toggle="yes">Z</italic>-score below/above 8 is interpreted as disorder/order, respectively. To remain aligned with (<xref rid="B39" ref-type="bibr">39</xref>), a 10-fold CV was performed on the cross-validation set. Accuracy was measured using standard metrics: the ROC AUC and the MCC that measure dependence between binary outcomes. Here, a simple logistic regression was used on the representations extracted from the ESM transformers. The ROC AUC/MCC averaged across the 10-folds were as follows: 0.964/0.798 (<italic toggle="yes">ESM-1b</italic>), 0.964/0.799 (<italic toggle="yes">ESM-1v</italic>) and 0.947/0.765 (<italic toggle="yes">ESM-MSA</italic>) (see Table <xref rid="tbl5" ref-type="table">5</xref>). Although these results clearly exceed the values of ROC AUC = 0.914 and MCC = 0.690 ODiNPred reported for the same task in (<xref rid="B39" ref-type="bibr">39</xref>), we omit any direct comparison for this task, given that the cross-validation set we used is different from that of ODiNPred. In the aforementioned table, we also present precision scores for disorder for ESM-based predictors. Given that we labelled disordered residues with 0 (i.e. treated as ‘negatives’), precision in this case means the percentage of the correctly predicted disordered residues. Our predictors are able to predict ∼88% of disordered residues. Note that considering a majority-based random classifier, which takes the most frequent class from the training set and uses that as prediction in a test set, in this 10-fold CV the majority class is always ordered (∼70%); accordingly, its prediction on the test fold will be ordered, which amounts to an ROC AUC value of 0.5. This can be compared to an ROC AUC value of 0.94 of the ESM-based predictors.</p>
      <table-wrap position="float" id="tbl5">
        <label>Table 5.</label>
        <caption>
          <p>ROC AUC, MCC and precision for disorder by our ESM transformer-based predictors for order/disorder classification given by the <italic toggle="yes">residue-level</italic> 10-fold CV on the <italic toggle="yes">cross-validation set</italic> consisting of 1168 sequences only</p>
        </caption>
        <table frame="hsides" rules="groups">
          <thead>
            <tr>
              <th rowspan="1" colspan="1"/>
              <th colspan="3" align="center" rowspan="1"><italic toggle="yes">Residue-level</italic> 10-fold CV</th>
            </tr>
            <tr>
              <th rowspan="1" colspan="1">Disorder predictor</th>
              <th rowspan="1" colspan="1">ROC AUC</th>
              <th rowspan="1" colspan="1">MCC</th>
              <th rowspan="1" colspan="1">Precision</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">
                <italic toggle="yes">ESM-1v</italic>
              </td>
              <td rowspan="1" colspan="1">0.964</td>
              <td rowspan="1" colspan="1">
                <bold>0.799</bold>
              </td>
              <td rowspan="1" colspan="1">0.880 ± 0.005</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">
                <italic toggle="yes">ESM-1b</italic>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.964</bold>
              </td>
              <td rowspan="1" colspan="1">0.798</td>
              <td rowspan="1" colspan="1"><bold>0.881</bold> ± 0.007</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">
                <italic toggle="yes">ESM-MSA</italic>
              </td>
              <td rowspan="1" colspan="1">0.947</td>
              <td rowspan="1" colspan="1">0.765</td>
              <td rowspan="1" colspan="1">0.865 ± 0.007</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
      <p>In order to support these results further, a similar logistic regression was fitted to the filtered base dataset. As described earlier, this dataset contains 1159 sequences. The performance of the ESM transformer-based (here <italic toggle="yes">ESM-1b</italic>) order/disorder classifier was evaluated on the validation set containing 117 sequences. The results of ROC AUC = 0.895 and MCC = 0.610 obtained on this task can still be considered strong. Our analysis demonstrates that the ESM transformer not only predicts better <italic toggle="yes">Z</italic>-scores than ODiNPred, but also performs better on a binary classification of ordered and disordered regions, a topic that is very relevant in biology. This result is further reinforced by the lower mass of the ESM transformer in comparison to ODiNPred in the intermediate region with <italic toggle="yes">Z</italic>-scores around 8 in Figure <xref rid="F3" ref-type="fig">3</xref>.</p>
      <p>Additionally, it is worth mentioning that there are well-known frameworks, e.g. CASP10, for disorder prediction assessment. As described in (<xref rid="B39" ref-type="bibr">39</xref>), the datasets in CASP10 were heavily imbalanced and &lt;10% of the residues were disordered. To put this in context, in the overall CheZOD dataset, this percentage was 36.3%. The authors in (<xref rid="B39" ref-type="bibr">39</xref>) make two further observations. ODiNPred was not the best-performing predictor in the CASP10 dataset, which may be due to the over-representation of ordered residues. Second, other disorder predictors overall performed much better on the CheZOD dataset.</p>
      <p>The scientific community has shown great interest in AlphaFold2. Recent work has demonstrated that the pLDDT (<xref rid="B61" ref-type="bibr">61</xref>), a per-residue metric of local confidence of the prediction, is correlated with disorder, outperforming IUPred2 (<xref rid="B62" ref-type="bibr">62</xref>), SPOT-Disorder2 (<xref rid="B63" ref-type="bibr">63</xref>) and other disorder predictors (<xref rid="B64" ref-type="bibr">64</xref>,<xref rid="B65" ref-type="bibr">65</xref>). Further work has proved that the SASA per residue of models produced by AlphaFold2 shows better correlation to protein disorder than the pLDDT and that using a smoothing window improves accuracy further (<xref rid="B62" ref-type="bibr">62</xref>). To benchmark performance, AlphaFold2 structural models were predicted for the validation set of 117 proteins using the full database. For the rolling averages of pLDDT and of SASA, we observed that the largest correlations (0.5546 and 0.6299) were given by window sizes 5 and 15, respectively, as reported in Table <xref rid="tbl2" ref-type="table">2</xref>. We note that predicting the structure from pre-calculated features derived from the MSAs took ∼40 h on one NVIDIA A100 GPU in total. It is worth highlighting that AlphaFold2 is a template-based predictor; that is, it uses templates as ingredients in making predictions. Hence, it is more nuanced than pure sequence-based methods. Curiously, for disordered proteins finding a suitable template is problematic. Broadly speaking, this may also be the reason why pLDDT correlates reasonably well with disorder; i.e. where AlphaFold2 is less certain about a well-defined structure, there will likely be disorder.</p>
    </sec>
    <sec id="SEC3-5">
      <title>A fast inference tool</title>
      <p>From an end user perspective, obtaining accurate disorder predictions quickly and easily is important. In this aspect, ADOPT offers unmatched performance. We demonstrate this through comparisons with two other tools. ODiNPred currently is available through the web service (<ext-link xlink:href="https://st-protein.chem.au.dk/odinpred" ext-link-type="uri">https://st-protein.chem.au.dk/odinpred</ext-link>). Querying 117 proteins took overnight. We also made an attempt to use SPOT-Disorder2 (<ext-link xlink:href="https://sparks-lab.org/server/spot-disorder2/" ext-link-type="uri">https://sparks-lab.org/server/spot-disorder2/</ext-link>), which is considered at least as accurate as ODiNPred. However, a maximum of 10 sequences can be submitted at a time and the output is returned in 12 h in the best case. In contrast, ADOPT, with a single command line, takes a few seconds to produce disorder predictions for 117 sequences and there is no cap on the number of sequences used in inference.</p>
      <p>To prove that the ADOPT performance is the best in class not only in terms of disorder prediction but even in terms of inference time, we used the ADOPT to predict the <italic toggle="yes">Z</italic>-scores of the 20 600 unique protein-coding genes from the reference <italic toggle="yes">human proteome</italic> (<ext-link xlink:href="https://www.uniprot.org/proteomes/UP000005640" ext-link-type="uri">https://www.uniprot.org/proteomes/UP000005640</ext-link>) that encode for 79 038 protein transcript variants. The protein sequences longer than 1024 units were split into two subsequences, due to the ESM context window length constraint mentioned earlier. The whole procedure takes roughly 15 min to be completed on a single NVIDIA DGX A100, which demonstrates that the ADOPT inference phase is three orders of magnitude faster than those of ODiNPred and AlphaFold2. However, this comparison is limited taking advantage of the fact that ADOPT runs as a fast command-line tool, while ODiNPred and SPOT-Disorder2 have been used as a web service. To give a fairer comparison, we repeated the speed benchmark with Metapredict v2 on one CPU core, which reflects the standard usage of an end user of this predictor. Running the <italic toggle="yes">human proteome</italic> took 15 and 46 min on an Apple M1 chip and on a Colab instance, respectively, and is therefore of comparable speed to ADOPT using a GPU. Note that Metapredict v2 has been generated to reproduce the pre-calculated results of another disorder predictor, Metapredict hybrid, for 363 265 protein sequences from 21 proteomes in order to increase its speed. Performing a similar task, e.g. training a neural network on pre-predicted protein sequences from ADOPT, could be an opportunity to increase the speed of our predictor. Both on a single NVIDIA DGX and on an Apple M1 chip, I/O time represents ∼15% of the inference time and computation time constitutes the remaining ∼85%.</p>
      <p>We believe that these aspects—accuracy and ease of use—will not just appeal to a wider audience, but also facilitate disorder-related research projects that were previously not possible due to scale.</p>
    </sec>
  </sec>
  <sec sec-type="discussion" id="SEC4">
    <title>DISCUSSION</title>
    <sec id="SEC4-1">
      <title>Remarks on the residue-level representations produced by ESM transformers</title>
      <p>There is a set of questions that naturally and frequently arise in the domain of NLP and recently in language models in biological applications: How much information is encoded in these representations? What exactly do they encode? Are bigger representations always better? In general, how do we make sense of them?</p>
      <p>To motivate these questions, recall that ODiNPred uses 157 hand-engineered biophysical features as inputs in its prediction model (<xref rid="B39" ref-type="bibr">39</xref>). By design, these input features are straightforward to interpret and there is sound rationale as to why they may help predict disorder. In contrast, the input of our ESM-based predictor is much bigger, 1280, which is the size of the representation vectors given by e.g. <italic toggle="yes">ESM-1b</italic>, and its features are, albeit real numbers, abstract, and they are hard to make sense of in physical terms, e.g. residue interaction entropy or net charge.</p>
      <p>Answers to the above questions also depend on the downstream task the representations are used for, e.g. predicting fluorescence, contact maps, disorder, sequence/amino acid level classification, etc. This implies a dependence on the prediction model too. In the case of disorder prediction, we use Lasso regression, which is a linear method (<xref rid="B53" ref-type="bibr">53</xref>). It is a continuous feature selection technique that means that varying the <italic toggle="yes">shrinkage</italic> parameter <italic toggle="yes">λ</italic> will influence the number of non-zero coefficients. The higher the <italic toggle="yes">λ</italic>, the greater the <italic toggle="yes">L</italic><sub>1</sub> penalty term, and hence, the number of non-zero coefficients decreases. In a fitted model with a given <italic toggle="yes">λ</italic>, only those features are used that have non-zero coefficients. In other words, these features are the ones that carry significant information. Therefore, Lasso can help us understand <italic toggle="yes">which coordinates of the representation vectors are relevant</italic>.</p>
      <p>Are all the 1280 coordinates, e.g. in the case of <italic toggle="yes">ESM-1b</italic>, needed? We used two different approaches to address this question. The first one was a <italic toggle="yes">naive selection</italic>, whereby only those features are considered whose coefficients were above a certain threshold in absolute terms. This analysis showed that e.g. with 141 coordinates a correlation of <italic toggle="yes">ρ</italic><sub>Spearman</sub> = 0.643 could be achieved, as shown in Figure <xref rid="F5" ref-type="fig">5</xref>.</p>
      <p>A better, yet computationally more demanding approach is <italic toggle="yes">stability selection</italic>, which uses resampling and in this aspect is similar to bootstrapping (<xref rid="B56" ref-type="bibr">56</xref>). Using this more robust technique, we found that choosing only 84 coordinates of the representation vectors and using those to predict <italic toggle="yes">Z</italic>-scores already showed an acceptable correlation <inline-formula><tex-math id="M00021" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\rho _{\texttt {Spearman}}=0.625$\end{document}</tex-math></inline-formula> on the validation set containing 117 sequences. The predictive power of the representation vectors could be further enhanced by taking additional coordinates, e.g. 114, which yielded a correlation <inline-formula><tex-math id="M00022" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\rho _{\texttt {Spearman}}=0.636$\end{document}</tex-math></inline-formula>, as depicted by the markers on the red line in Figure <xref rid="F6" ref-type="fig">6</xref>. Interestingly, this method identified 167 coordinates, which gave a correlation of <inline-formula><tex-math id="M00023" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\rho _{\texttt {Spearman}}=0.656$\end{document}</tex-math></inline-formula>, which is markedly better than the subset of the same size selected by the naive approach. In comparison to ODiNPred that relies on 157 biophysical features and achieves a correlation of <inline-formula><tex-math id="M00024" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\rho _{\texttt {Spearman}}=0.649$\end{document}</tex-math></inline-formula> (<xref rid="B39" ref-type="bibr">39</xref>), already a subset of 114 coordinates of the <italic toggle="yes">ESM-1b</italic> representations could offer a very similar performance.</p>
      <p>This analysis answers, at least partly, the question whether bigger representations are necessarily better. The <italic toggle="yes">ESM-MSA</italic>-based predictor, which uses smaller sized representations, 768, performs relatively poorly with a correlation <inline-formula><tex-math id="M00025" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\rho _{\texttt {Spearman}}=0.604$\end{document}</tex-math></inline-formula> (see Table <xref rid="tbl2" ref-type="table">2</xref>), compared to all of the alternatives based on the reduced <italic toggle="yes">ESM-1b</italic> representations presented earlier. This clearly suggests that, at least regarding disorder prediction, the quality of the representations given by <italic toggle="yes">ESM-1b</italic> is genuinely better not purely because of the size of the representation. This is because we could select a subset of coordinates from the <italic toggle="yes">ESM-1b</italic> representations that was much smaller in size than the <italic toggle="yes">ESM-MSA</italic> representations (768), and yet had better prediction power than <italic toggle="yes">ESM-MSA</italic>.</p>
    </sec>
    <sec id="SEC4-2">
      <title>Remarks on the current state of protein disorder predictions</title>
      <p>Protein disorder prediction is a challenging task. Even with the methodological advancements of ADOPT, Spearman rank correlation coefficients (<inline-formula><tex-math id="M00026" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\rho _{\texttt {Spearman}}$\end{document}</tex-math></inline-formula>) of up to 0.7 demonstrate that there is still a significant room for further improvement. Besides their different architectures, the most performant protein disorder predictors use deep neural networks to predict the disorder of a residue within a sequence. While these tools identify the features important for disorder prediction, they do not necessarily give a direct indication about the connection of these features to the biophysical origin of protein disorder. Here, we compared two state-of-the-art predictors, ODiNPred (<xref rid="B39" ref-type="bibr">39</xref>) and our new ESM transformer, and found several similarities in their ability to predict certain biophysical features. For example, we could show that both predictors could accurately separate ordered from disordered residues, whose definition is based on the simple observation that experimental <italic toggle="yes">Z</italic>-scores follow a bimodal distribution. While such a classification performance is promising, applying the predictors to a more diverse dataset, as e.g. used in CAID (<xref rid="B34" ref-type="bibr">34</xref>), is more challenging.</p>
      <p>We observed that both predictors predict slightly too ordered <italic toggle="yes">Z</italic>-scores. Interestingly, this observation is independent of the actual <italic toggle="yes">Z</italic>-score; e.g. ordered and disordered regions are both predicted, on average, to be too ordered. This indicates that there might be a general feature that contributes to the ‘orderness’ of a residue, which is not completely learned by either of the predictors. Our amino acid analysis reveals that especially the <italic toggle="yes">Z</italic>-scores of these amino acids, which are known as breakers or stoppers of ordered regions like α helices or β sheets, e.g. glycine and proline, are less accurately predicted than the other amino acids (Figure <xref rid="F4" ref-type="fig">4</xref> and <xref rid="sup1" ref-type="supplementary-material">Supplementary Figures S2 and S3</xref>). This suggests that the prediction of protein disorder might be enhanced if the predictors are trained on well-labelled data of these residues as their occurrence within a protein sequence plays an important role in the formation of ordered regions.</p>
      <p>Furthermore, we observe that it is particularly difficult to predict cysteine residues. Long-range contacts formed from disulfide bridges hold proteins together and are therefore of tremendous importance for the formation of the hydrophobic core of folded proteins. This observation is in line with the analysis of the 157 biophysical features from ODiNPred (<xref rid="B39" ref-type="bibr">39</xref>). They observed that the most important features for protein disorder prediction are hydrophobic clusters, the predicted secondary structure and the evolutionary relationship. While the last one was used to extract the features in this study, it is interesting to see that the other two biophysical features have been learned implicitly by our ESM transformer, even though it does not use any biophysical features during its training. This shows that the evolutionary information in pre-trained datasets such as UniRef (<xref rid="B48" ref-type="bibr">48</xref>) already contains these features and transformers are able to unveil this information.</p>
      <p>Finally, negligible differences in terms of key performance metrics described in the reliability study under the ‘Results’ section clearly illustrate the efficacy of ADOPT in terms of reliability and accuracy.</p>
    </sec>
  </sec>
  <sec sec-type="conclusions" id="SEC5">
    <title>CONCLUSIONS</title>
    <p>Understanding and accurately predicting protein disorder have been an area of active research in computational biology for more than two decades. Here, we present a sequence-based approach to predict disorder using ESM transformers. These NLP-based methods applied to vast protein databases, e.g. UniProt90, which at the time of writing of this paper consisted of 135 301 051 sequences (see <ext-link xlink:href="https://www.uniprot.org/uniref/" ext-link-type="uri">https://www.uniprot.org/uniref/</ext-link>). These transformers produce amino acid level representations of protein sequences that we use as inputs in our disorder predictors. We show in various tasks (predicting <italic toggle="yes">Z</italic>-scores, classifying residues in order/disorder classes) that our predictors offer superior performance compared to the previous state-of-the-art disorder predictor (<xref rid="B39" ref-type="bibr">39</xref>) and per-residue score correlations to protein disorder of models produced by AlphaFold2 (<xref rid="B46" ref-type="bibr">46</xref>). We study the quality of these residue-level representations by analysing which coordinates of the residue-level representations are relevant in terms of predictive power. We highlight two main advantages of our proposed approach. First, it does not require additional feature engineering or selection of potentially relevant biophysical inputs. Second, its inference capabilities are remarkably fast compared to other publicly available tools. This could aid large-scale studies that were previously not possible.</p>
    <p>In a broader context, our work complements the most recent developments in NLP-based computational biology [see e.g. (<xref rid="B66" ref-type="bibr">66</xref>,<xref rid="B67" ref-type="bibr">67</xref>)]. The common theme of such approaches can be summarized in two steps. First, the aim is to find suitable <italic toggle="yes">embeddings</italic> or <italic toggle="yes">representations</italic> of protein sequences. The second aspect is to use these in relevant <italic toggle="yes">downstream</italic> tasks, e.g. contact map prediction, stability prediction, etc. Downstream use cases are typically less data intense, and this approach is expected to work already reasonably well with datasets of size around 10 000 or above. Note that in the CheZOD training set alone, which was used in this paper, there are &gt;140 000 observations, given that disorder is a residue-level property of interest. In contrast, large transformer models ideally require millions of data points to achieve their full potential. Note that the data points used by transformers are not necessarily experimental observations, but they are purely sequences.</p>
    <p>There are many directions for future research related to this particular approach; however, we would highlight three of them specifically. Clearly, great potential lies in the exploration of other relevant downstream tasks. Reiterating the point made in (<xref rid="B67" ref-type="bibr">67</xref>), a promising way to improve NLP-based techniques, in particular, transformers, in protein science, is to utilize priors, e.g. known protein structures, into these models. This could be a key to enhance the quality of sequence representations. The third area requires novel ideas, but could be invaluable to connect large transformers to molecular dynamics (MD) methods in order to improve simulations and the quality of computed biophysical features. Atomic MD simulations could be used to sample the heterogeneous ensemble of structures in intrinsically disordered regions. The distribution of NMR chemical shifts in these ensembles is directly related to the <italic toggle="yes">Z</italic>-score and can be used to improve the data used to train transformers, while transformers can be used to improve MD force fields.</p>
  </sec>
  <sec sec-type="data-availability" id="SEC6">
    <title>DATA AVAILABILITY</title>
    <p>The data underlying this article are available in Zenodo at <ext-link xlink:href="https://doi.org/10.5281/zenodo.7822077" ext-link-type="uri">https://doi.org/10.5281/zenodo.7822077</ext-link>.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material id="sup1" position="float" content-type="local-data">
      <label>lqad041_Supplemental_File</label>
      <media xlink:href="lqad041_supplemental_file.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <sec id="SEC7">
    <title>SUPPLEMENTARY DATA</title>
    <p><ext-link xlink:href="https://academic.oup.com/nargab/article-lookup/doi/10.1093/nargab/lqad041#supplementary-data" ext-link-type="uri">Supplementary Data</ext-link> are available at NARGAB Online.</p>
  </sec>
  <sec id="SEC8">
    <title>FUNDING</title>
    <p>No external funding.</p>
    <p><italic toggle="yes">Conflict of interest statement</italic>. All authors are employees of and shareholders in Peptone Ltd.</p>
  </sec>
  <ref-list id="REF1">
    <title>REFERENCES</title>
    <ref id="B1">
      <label>1.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Anfinsen</surname><given-names>C.B.</given-names></string-name></person-group><article-title>Principles that govern the folding of protein chains</article-title>. <source>Science</source>. <year>1973</year>; <volume>181</volume>:<fpage>223</fpage>–<lpage>230</lpage>.<pub-id pub-id-type="pmid">4124164</pub-id></mixed-citation>
    </ref>
    <ref id="B2">
      <label>2.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wright</surname><given-names>P.E.</given-names></string-name>, <string-name><surname>Dyson</surname><given-names>H.</given-names></string-name></person-group><article-title>Intrinsically unstructured proteins: re-assessing the protein structure–function paradigm</article-title>. <source>J. Mol. Biol.</source><year>1999</year>; <volume>293</volume>:<fpage>321</fpage>–<lpage>331</lpage>.<pub-id pub-id-type="pmid">10550212</pub-id></mixed-citation>
    </ref>
    <ref id="B3">
      <label>3.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wright</surname><given-names>P.E.</given-names></string-name>, <string-name><surname>Dyson</surname><given-names>H.J.</given-names></string-name></person-group><article-title>Intrinsically disordered proteins in cellular signalling and regulation</article-title>. <source>Nat. Rev. Mol. Cell Biol.</source><year>2015</year>; <volume>16</volume>:<fpage>18</fpage>–<lpage>29</lpage>.<pub-id pub-id-type="pmid">25531225</pub-id></mixed-citation>
    </ref>
    <ref id="B4">
      <label>4.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Santofimia-Castaño</surname><given-names>P.</given-names></string-name>, <string-name><surname>Rizzuti</surname><given-names>B.</given-names></string-name>, <string-name><surname>Xia</surname><given-names>Y.</given-names></string-name>, <string-name><surname>Abian</surname><given-names>O.</given-names></string-name>, <string-name><surname>Peng</surname><given-names>L.</given-names></string-name>, <string-name><surname>Velázquez-Campoy</surname><given-names>A.</given-names></string-name>, <string-name><surname>Neira</surname><given-names>J.L.</given-names></string-name>, <string-name><surname>Iovanna</surname><given-names>J.</given-names></string-name></person-group><article-title>Targeting intrinsically disordered proteins involved in cancer</article-title>. <source>Cell. Mol. Life Sci.</source><year>2020</year>; <volume>77</volume>:<fpage>1695</fpage>–<lpage>1707</lpage>.<pub-id pub-id-type="pmid">31667555</pub-id></mixed-citation>
    </ref>
    <ref id="B5">
      <label>5.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Du</surname><given-names>Z.</given-names></string-name>, <string-name><surname>Uversky</surname><given-names>V.N.</given-names></string-name></person-group><article-title>A comprehensive survey of the roles of highly disordered proteins in type 2 diabetes</article-title>. <source>Int. J. Mol. Sci.</source><year>2017</year>; <volume>18</volume>:<fpage>2010</fpage>.<pub-id pub-id-type="pmid">28934129</pub-id></mixed-citation>
    </ref>
    <ref id="B6">
      <label>6.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cheng</surname><given-names>Y.</given-names></string-name>, <string-name><surname>LeGall</surname><given-names>T.</given-names></string-name>, <string-name><surname>Oldfield</surname><given-names>C.J.</given-names></string-name>, <string-name><surname>Dunker</surname><given-names>A.K.</given-names></string-name>, <string-name><surname>Uversky</surname><given-names>V.N.</given-names></string-name></person-group><article-title>Abundance of intrinsic disorder in protein associated with cardiovascular disease</article-title>. <source>Biochemistry</source>. <year>2006</year>; <volume>45</volume>:<fpage>10448</fpage>–<lpage>10460</lpage>.<pub-id pub-id-type="pmid">16939197</pub-id></mixed-citation>
    </ref>
    <ref id="B7">
      <label>7.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Knowles</surname><given-names>T.P.J.</given-names></string-name>, <string-name><surname>Vendruscolo</surname><given-names>M.</given-names></string-name>, <string-name><surname>Dobson</surname><given-names>C.M.</given-names></string-name></person-group><article-title>The amyloid state and its association with protein misfolding diseases</article-title>. <source>Nat. Rev. Mol. Cell Biol.</source><year>2014</year>; <volume>15</volume>:<fpage>384</fpage>–<lpage>396</lpage>.<pub-id pub-id-type="pmid">24854788</pub-id></mixed-citation>
    </ref>
    <ref id="B8">
      <label>8.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Fuertes</surname><given-names>G.</given-names></string-name>, <string-name><surname>Nevola</surname><given-names>L.</given-names></string-name>, <string-name><surname>Esteban-Martín</surname><given-names>S.</given-names></string-name></person-group><person-group person-group-type="editor"><string-name><surname>Salvi</surname><given-names>N.</given-names></string-name></person-group><article-title>Chapter 9: Perspectives on drug discovery strategies based on IDPs</article-title>. <source>Intrinsically Disordered Proteins</source>. <year>2019</year>; <publisher-loc>NY</publisher-loc><publisher-name>Academic Press</publisher-name><fpage>275</fpage>–<lpage>327</lpage>.</mixed-citation>
    </ref>
    <ref id="B9">
      <label>9.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Romero</surname><given-names>P.</given-names></string-name>, <string-name><surname>Obradovic</surname><given-names>Z.</given-names></string-name>, <string-name><surname>Kissinger</surname><given-names>C.</given-names></string-name>, <string-name><surname>Villafranca</surname><given-names>J.</given-names></string-name>, <string-name><surname>Dunker</surname><given-names>A.</given-names></string-name></person-group><article-title>Identifying disordered regions in proteins from amino acid sequence</article-title>. <source>Proceedings of International Conference on Neural Networks (ICNN’97)</source>. <year>1997</year>; <volume>1</volume>:<fpage>90</fpage>–<lpage>95</lpage>.</mixed-citation>
    </ref>
    <ref id="B10">
      <label>10.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Linding</surname><given-names>R.</given-names></string-name>, <string-name><surname>Russell</surname><given-names>R.B.</given-names></string-name>, <string-name><surname>Neduva</surname><given-names>V.</given-names></string-name>, <string-name><surname>Gibson</surname><given-names>T.J.</given-names></string-name></person-group><article-title>GlobPlot: exploring protein sequences for globularity and disorder</article-title>. <source>Nucleic Acids Res.</source><year>2003</year>; <volume>31</volume>:<fpage>3701</fpage>–<lpage>3708</lpage>.<pub-id pub-id-type="pmid">12824398</pub-id></mixed-citation>
    </ref>
    <ref id="B11">
      <label>11.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dosztányi</surname><given-names>Z.</given-names></string-name>, <string-name><surname>Csizmok</surname><given-names>V.</given-names></string-name>, <string-name><surname>Tompa</surname><given-names>P.</given-names></string-name>, <string-name><surname>Simon</surname><given-names>I.</given-names></string-name></person-group><article-title>IUPred: web server for the prediction of intrinsically unstructured regions of proteins based on estimated energy content</article-title>. <source>Bioinformatics</source>. <year>2005</year>; <volume>21</volume>:<fpage>3433</fpage>–<lpage>3434</lpage>.<pub-id pub-id-type="pmid">15955779</pub-id></mixed-citation>
    </ref>
    <ref id="B12">
      <label>12.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dosztányi</surname><given-names>Z.</given-names></string-name>, <string-name><surname>Csizmók</surname><given-names>V.</given-names></string-name>, <string-name><surname>Tompa</surname><given-names>P.</given-names></string-name>, <string-name><surname>Simon</surname><given-names>I.</given-names></string-name></person-group><article-title>The pairwise energy content estimated from amino acid composition discriminates between folded and intrinsically unstructured proteins</article-title>. <source>J. Mol. Biol.</source><year>2005</year>; <volume>347</volume>:<fpage>827</fpage>–<lpage>839</lpage>.<pub-id pub-id-type="pmid">15769473</pub-id></mixed-citation>
    </ref>
    <ref id="B13">
      <label>13.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Prilusky</surname><given-names>J.</given-names></string-name>, <string-name><surname>Felder</surname><given-names>C.E.</given-names></string-name>, <string-name><surname>Zeev-Ben-Mordehai</surname><given-names>T.</given-names></string-name>, <string-name><surname>Rydberg</surname><given-names>E.H.</given-names></string-name>, <string-name><surname>Man</surname><given-names>O.</given-names></string-name>, <string-name><surname>Beckmann</surname><given-names>J.S.</given-names></string-name>, <string-name><surname>Silman</surname><given-names>I.</given-names></string-name>, <string-name><surname>Sussman</surname><given-names>J.L.</given-names></string-name></person-group><article-title>FoldIndex©: a simple tool to predict whether a given protein sequence is intrinsically unfolded</article-title>. <source>Bioinformatics</source>. <year>2005</year>; <volume>21</volume>:<fpage>3435</fpage>–<lpage>3438</lpage>.<pub-id pub-id-type="pmid">15955783</pub-id></mixed-citation>
    </ref>
    <ref id="B14">
      <label>14.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Galzitskaya</surname><given-names>O.V.</given-names></string-name>, <string-name><surname>Garbuzynskiy</surname><given-names>S.O.</given-names></string-name>, <string-name><surname>Lobanov</surname><given-names>M.Y.</given-names></string-name></person-group><article-title>FoldUnfold: web server for the prediction of disordered regions in protein chain</article-title>. <source>Bioinformatics</source>. <year>2006</year>; <volume>22</volume>:<fpage>2948</fpage>–<lpage>2949</lpage>.<pub-id pub-id-type="pmid">17021161</pub-id></mixed-citation>
    </ref>
    <ref id="B15">
      <label>15.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Schlessinger</surname><given-names>A.</given-names></string-name>, <string-name><surname>Punta</surname><given-names>M.</given-names></string-name>, <string-name><surname>Rost</surname><given-names>B.</given-names></string-name></person-group><article-title>Natively unstructured regions in proteins identified from contact predictions</article-title>. <source>Bioinformatics</source>. <year>2007</year>; <volume>23</volume>:<fpage>2376</fpage>–<lpage>2384</lpage>.<pub-id pub-id-type="pmid">17709338</pub-id></mixed-citation>
    </ref>
    <ref id="B16">
      <label>16.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cheng</surname><given-names>J.</given-names></string-name>, <string-name><surname>Sweredoski</surname><given-names>M.J.</given-names></string-name>, <string-name><surname>Baldi</surname><given-names>P.</given-names></string-name></person-group><article-title>Accurate prediction of protein disordered regions by mining protein structure data</article-title>. <source>Data Min. Knowl. Discov.</source><year>2005</year>; <volume>11</volume>:<fpage>213</fpage>–<lpage>222</lpage>.</mixed-citation>
    </ref>
    <ref id="B17">
      <label>17.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Peng</surname><given-names>K.</given-names></string-name>, <string-name><surname>Radivojac</surname><given-names>P.</given-names></string-name>, <string-name><surname>Vucetic</surname><given-names>S.</given-names></string-name>, <string-name><surname>Dunker</surname><given-names>A.K.</given-names></string-name>, <string-name><surname>Obradovic</surname><given-names>Z.</given-names></string-name></person-group><article-title>Length-dependent prediction of protein intrinsic disorder</article-title>. <source>BMC Bioinformatics</source>. <year>2006</year>; <volume>7</volume>:<fpage>208</fpage>.<pub-id pub-id-type="pmid">16618368</pub-id></mixed-citation>
    </ref>
    <ref id="B18">
      <label>18.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hecker</surname><given-names>J.</given-names></string-name>, <string-name><surname>Yang</surname><given-names>J.Y.</given-names></string-name>, <string-name><surname>Cheng</surname><given-names>J.</given-names></string-name></person-group><article-title>Protein disorder prediction at multiple levels of sensitivity and specificity</article-title>. <source>BMC Genomics</source>. <year>2008</year>; <volume>9</volume>:<fpage>S9</fpage>.</mixed-citation>
    </ref>
    <ref id="B19">
      <label>19.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname><given-names>L.</given-names></string-name>, <string-name><surname>Sauer</surname><given-names>U.H.</given-names></string-name></person-group><article-title>OnD-CRF: predicting order and disorder in proteins conditional random fields</article-title>. <source>Bioinformatics</source>. <year>2008</year>; <volume>24</volume>:<fpage>1401</fpage>–<lpage>1402</lpage>.<pub-id pub-id-type="pmid">18430742</pub-id></mixed-citation>
    </ref>
    <ref id="B20">
      <label>20.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname><given-names>T.</given-names></string-name>, <string-name><surname>Faraggi</surname><given-names>E.</given-names></string-name>, <string-name><surname>Xue</surname><given-names>B.</given-names></string-name>, <string-name><surname>Dunker</surname><given-names>A.K.</given-names></string-name>, <string-name><surname>Uversky</surname><given-names>V.N.</given-names></string-name>, <string-name><surname>Zhou</surname><given-names>Y.</given-names></string-name></person-group><article-title>SPINE-D: accurate prediction of short and long disordered regions by a single neural-network based method</article-title>. <source>J. Biomol. Struct. Dyn.</source><year>2012</year>; <volume>29</volume>:<fpage>799</fpage>–<lpage>813</lpage>.<pub-id pub-id-type="pmid">22208280</pub-id></mixed-citation>
    </ref>
    <ref id="B21">
      <label>21.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Walsh</surname><given-names>I.</given-names></string-name>, <string-name><surname>Martin</surname><given-names>A.J.M.</given-names></string-name>, <string-name><surname>Domenico</surname><given-names>T.D.</given-names></string-name>, <string-name><surname>Tosatto</surname><given-names>S.C.E.</given-names></string-name></person-group><article-title>ESpritz: accurate and fast prediction of protein disorder</article-title>. <source>Bioinformatics</source>. <year>2012</year>; <volume>28</volume>:<fpage>503</fpage>–<lpage>509</lpage>.<pub-id pub-id-type="pmid">22190692</pub-id></mixed-citation>
    </ref>
    <ref id="B22">
      <label>22.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Receveur-Bréchot</surname><given-names>V.</given-names></string-name>, <string-name><surname>Bourhis</surname><given-names>J.</given-names></string-name>, <string-name><surname>Uversky</surname><given-names>V.N.</given-names></string-name>, <string-name><surname>Canard</surname><given-names>B.</given-names></string-name>, <string-name><surname>Longhi</surname><given-names>S.</given-names></string-name></person-group><article-title>Assessing protein disorder and induced folding</article-title>. <source>Proteins: Struct. Funct. Bioinformatics</source>. <year>2006</year>; <volume>62</volume>:<fpage>24</fpage>–<lpage>45</lpage>.</mixed-citation>
    </ref>
    <ref id="B23">
      <label>23.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Iqbal</surname><given-names>S.</given-names></string-name>, <string-name><surname>Hoque</surname><given-names>M.T.</given-names></string-name></person-group><article-title>DisPredict: a predictor of disordered protein using optimized RBF kernel</article-title>. <source>PLoS One</source>. <year>2015</year>; <volume>10</volume>:<fpage>e0141551</fpage>.<pub-id pub-id-type="pmid">26517719</pub-id></mixed-citation>
    </ref>
    <ref id="B24">
      <label>24.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname><given-names>S.</given-names></string-name>, <string-name><surname>Weng</surname><given-names>S.</given-names></string-name>, <string-name><surname>Ma</surname><given-names>J.</given-names></string-name>, <string-name><surname>Tang</surname><given-names>Q.</given-names></string-name></person-group><article-title>DeepCNF-D: predicting protein order/disorder regions by weighted deep convolutional neural fields</article-title>. <source>Int. J. Mol. Sci.</source><year>2015</year>; <volume>16</volume>:<fpage>17315</fpage>–<lpage>17330</lpage>.<pub-id pub-id-type="pmid">26230689</pub-id></mixed-citation>
    </ref>
    <ref id="B25">
      <label>25.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hanson</surname><given-names>J.</given-names></string-name>, <string-name><surname>Yang</surname><given-names>Y.</given-names></string-name>, <string-name><surname>Paliwal</surname><given-names>K.</given-names></string-name>, <string-name><surname>Zhou</surname><given-names>Y.</given-names></string-name></person-group><article-title>Improving protein disorder prediction by deep bidirectional long short-term memory recurrent neural networks</article-title>. <source>Bioinformatics</source>. <year>2016</year>; <volume>33</volume>:<fpage>685</fpage>–<lpage>692</lpage>.</mixed-citation>
    </ref>
    <ref id="B26">
      <label>26.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname><given-names>S.</given-names></string-name>, <string-name><surname>Ma</surname><given-names>J.</given-names></string-name>, <string-name><surname>Xu</surname><given-names>J.</given-names></string-name></person-group><article-title>AUCpreD: proteome-level protein disorder prediction by AUC-maximized deep convolutional neural fields</article-title>. <source>Bioinformatics</source>. <year>2016</year>; <volume>32</volume>:<fpage>i672</fpage>–<lpage>i679</lpage>.<pub-id pub-id-type="pmid">27587688</pub-id></mixed-citation>
    </ref>
    <ref id="B27">
      <label>27.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hanson</surname><given-names>J.</given-names></string-name>, <string-name><surname>Paliwal</surname><given-names>K.K.</given-names></string-name>, <string-name><surname>Litfin</surname><given-names>T.</given-names></string-name>, <string-name><surname>Zhou</surname><given-names>Y.</given-names></string-name></person-group><article-title>SPOT-Disorder2: improved protein intrinsic disorder prediction by ensembled deep learning</article-title>. <source>Genomics Proteomics Bioinformatics</source>. <year>2019</year>; <volume>17</volume>:<fpage>645</fpage>–<lpage>656</lpage>.<pub-id pub-id-type="pmid">32173600</pub-id></mixed-citation>
    </ref>
    <ref id="B28">
      <label>28.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mirabello</surname><given-names>C.</given-names></string-name>, <string-name><surname>Wallner</surname><given-names>B.</given-names></string-name></person-group><article-title>rawMSA: end-to-end deep learning using raw multiple sequence alignments</article-title>. <source>PLoS One</source>. <year>2019</year>; <volume>14</volume>:<fpage>e0220182</fpage>.<pub-id pub-id-type="pmid">31415569</pub-id></mixed-citation>
    </ref>
    <ref id="B29">
      <label>29.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Erdős</surname><given-names>G.</given-names></string-name>, <string-name><surname>Dosztányi</surname><given-names>Z.</given-names></string-name></person-group><article-title>Analyzing protein disorder with IUPred2A</article-title>. <source>Curr. Protoc. Bioinformatics</source>. <year>2020</year>; <volume>70</volume>:<fpage>e99</fpage>.<pub-id pub-id-type="pmid">32237272</pub-id></mixed-citation>
    </ref>
    <ref id="B30">
      <label>30.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hu</surname><given-names>G.</given-names></string-name>, <string-name><surname>Katuwawala</surname><given-names>A.</given-names></string-name>, <string-name><surname>Wang</surname><given-names>K.</given-names></string-name>, <string-name><surname>Wu</surname><given-names>Z.</given-names></string-name>, <string-name><surname>Ghadermarzi</surname><given-names>S.</given-names></string-name>, <string-name><surname>Gao</surname><given-names>J.</given-names></string-name>, <string-name><surname>Kurgan</surname><given-names>L.</given-names></string-name></person-group><article-title>flDPnn: accurate intrinsic disorder prediction with putative propensities of disorder functions</article-title>. <source>Nat. Commun.</source><year>2021</year>; <volume>12</volume>:<fpage>4438</fpage>.<pub-id pub-id-type="pmid">34290238</pub-id></mixed-citation>
    </ref>
    <ref id="B31">
      <label>31.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ishida</surname><given-names>T.</given-names></string-name>, <string-name><surname>Kinoshita</surname><given-names>K.</given-names></string-name></person-group><article-title>PrDOS: prediction of disordered protein regions from amino acid sequence</article-title>. <source>Nucleic Acids Res.</source><year>2007</year>; <volume>35</volume>:<fpage>W460</fpage>–<lpage>W464</lpage>.<pub-id pub-id-type="pmid">17567614</pub-id></mixed-citation>
    </ref>
    <ref id="B32">
      <label>32.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Deng</surname><given-names>X.</given-names></string-name>, <string-name><surname>Eickholt</surname><given-names>J.</given-names></string-name>, <string-name><surname>Cheng</surname><given-names>J.</given-names></string-name></person-group><article-title>PreDisorder: <italic toggle="yes">ab initio</italic> sequence-based prediction of protein disordered regions</article-title>. <source>BMC Bioinformatics</source>. <year>2009</year>; <volume>10</volume>:<fpage>436</fpage>–<lpage>436</lpage>.<pub-id pub-id-type="pmid">20025768</pub-id></mixed-citation>
    </ref>
    <ref id="B33">
      <label>33.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kozlowski</surname><given-names>L.P.</given-names></string-name>, <string-name><surname>Bujnicki</surname><given-names>J.M.</given-names></string-name></person-group><article-title>MetaDisorder: a meta-server for the prediction of intrinsic disorder in proteins</article-title>. <source>BMC Bioinformatics</source>. <year>2012</year>; <volume>13</volume>:<fpage>111</fpage>–<lpage>111</lpage>.<pub-id pub-id-type="pmid">22624656</pub-id></mixed-citation>
    </ref>
    <ref id="B34">
      <label>34.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Necci</surname><given-names>M.</given-names></string-name>, <string-name><surname>Piovesan</surname><given-names>D.</given-names></string-name>, <string-name><surname>Hoque</surname><given-names>M.T.</given-names></string-name>, <string-name><surname>Walsh</surname><given-names>I.</given-names></string-name>, <string-name><surname>Iqbal</surname><given-names>S.</given-names></string-name>, <string-name><surname>Vendruscolo</surname><given-names>M.</given-names></string-name>, <string-name><surname>Sormanni</surname><given-names>P.</given-names></string-name>, <string-name><surname>Wang</surname><given-names>C.</given-names></string-name>, <string-name><surname>Raimondi</surname><given-names>D.</given-names></string-name>, <string-name><surname>Sharma</surname><given-names>R.</given-names></string-name><etal>et al</etal>.</person-group><article-title>Critical assessment of protein intrinsic disorder prediction</article-title>. <source>Nat. Methods</source>. <year>2021</year>; <volume>18</volume>:<fpage>472</fpage>–<lpage>481</lpage>.<pub-id pub-id-type="pmid">33875885</pub-id></mixed-citation>
    </ref>
    <ref id="B35">
      <label>35.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hatos</surname><given-names>A.</given-names></string-name>, <string-name><surname>Hajdu-Soltész</surname><given-names>B.</given-names></string-name>, <string-name><surname>Monzon</surname><given-names>A.M.</given-names></string-name>, <string-name><surname>Palopoli</surname><given-names>N.</given-names></string-name>, <string-name><surname>Álvarez</surname><given-names>L.</given-names></string-name>, <string-name><surname>Aykac-Fas</surname><given-names>B.</given-names></string-name>, <string-name><surname>Bassot</surname><given-names>C.</given-names></string-name>, <string-name><surname>Benítez</surname><given-names>G.I.</given-names></string-name>, <string-name><surname>Bevilacqua</surname><given-names>M.</given-names></string-name>, <string-name><surname>Chasapi</surname><given-names>A.</given-names></string-name><etal>et al</etal>.</person-group><article-title>DisProt: intrinsic protein disorder annotation in 2020</article-title>. <source>Nucleic Acids Res.</source><year>2019</year>; <volume>48</volume>:<fpage>D269</fpage>–<lpage>D276</lpage>.</mixed-citation>
    </ref>
    <ref id="B36">
      <label>36.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nielsen</surname><given-names>J.T.</given-names></string-name>, <string-name><surname>Mulder</surname><given-names>F.A.A.</given-names></string-name></person-group><article-title>There is diversity in disorder—in all chaos there is a cosmos, in all disorder a secret order</article-title>. <source>Front. Mol. Biosci.</source><year>2016</year>; <volume>3</volume>:<fpage>4</fpage>.<pub-id pub-id-type="pmid">26904549</pub-id></mixed-citation>
    </ref>
    <ref id="B37">
      <label>37.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ulrich</surname><given-names>E.L.</given-names></string-name>, <string-name><surname>Akutsu</surname><given-names>H.</given-names></string-name>, <string-name><surname>Doreleijers</surname><given-names>J.F.</given-names></string-name>, <string-name><surname>Harano</surname><given-names>Y.</given-names></string-name>, <string-name><surname>Ioannidis</surname><given-names>Y.E.</given-names></string-name>, <string-name><surname>Lin</surname><given-names>J.</given-names></string-name>, <string-name><surname>Livny</surname><given-names>M.</given-names></string-name>, <string-name><surname>Mading</surname><given-names>S.</given-names></string-name>, <string-name><surname>Maziuk</surname><given-names>D.</given-names></string-name>, <string-name><surname>Miller</surname><given-names>Z.</given-names></string-name><etal>et al</etal>.</person-group><article-title>BioMagResBank</article-title>. <source>Nucleic Acids Res.</source><year>2007</year>; <volume>36</volume>:<fpage>D402</fpage>–<lpage>D408</lpage>.<pub-id pub-id-type="pmid">17984079</pub-id></mixed-citation>
    </ref>
    <ref id="B38">
      <label>38.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tamiola</surname><given-names>K.</given-names></string-name>, <string-name><surname>Acar</surname><given-names>B.</given-names></string-name>, <string-name><surname>Mulder</surname><given-names>F.A.A.</given-names></string-name></person-group><article-title>Sequence-specific random coil chemical shifts of intrinsically disordered proteins</article-title>. <source>J. Am. Chem. Soc.</source><year>2010</year>; <volume>132</volume>:<fpage>18000</fpage>–<lpage>18003</lpage>.<pub-id pub-id-type="pmid">21128621</pub-id></mixed-citation>
    </ref>
    <ref id="B39">
      <label>39.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dass</surname><given-names>R.</given-names></string-name>, <string-name><surname>Mulder</surname><given-names>F.A.A.</given-names></string-name>, <string-name><surname>Nielsen</surname><given-names>J.T.</given-names></string-name></person-group><article-title>ODiNPred: comprehensive prediction of protein order and disorder</article-title>. <source>Sci. Rep.</source><year>2020</year>; <volume>10</volume>:<fpage>14780</fpage>.<pub-id pub-id-type="pmid">32901090</pub-id></mixed-citation>
    </ref>
    <ref id="B40">
      <label>40.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hanson</surname><given-names>J.</given-names></string-name>, <string-name><surname>Yang</surname><given-names>Y.</given-names></string-name>, <string-name><surname>Paliwal</surname><given-names>K.</given-names></string-name>, <string-name><surname>Zhou</surname><given-names>Y.</given-names></string-name></person-group><article-title>Improving protein disorder prediction by deep bidirectional long short-term memory recurrent neural networks</article-title>. <source>Bioinformatics</source>. <year>2016</year>; <volume>33</volume>:<fpage>685</fpage>–<lpage>692</lpage>.</mixed-citation>
    </ref>
    <ref id="B41">
      <label>41.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chatzigeorgiou</surname><given-names>M.</given-names></string-name>, <string-name><surname>Constantoudis</surname><given-names>V.</given-names></string-name>, <string-name><surname>Diakonos</surname><given-names>F.</given-names></string-name>, <string-name><surname>Karamanos</surname><given-names>K.</given-names></string-name>, <string-name><surname>Papadimitriou</surname><given-names>C.</given-names></string-name>, <string-name><surname>Kalimeri</surname><given-names>M.</given-names></string-name>, <string-name><surname>Papageorgiou</surname><given-names>H.</given-names></string-name></person-group><article-title>Multifractal correlations in natural language written texts: effects of language family and long word statistics</article-title>. <source>Phys. A: Stat. Mech. Appl.</source><year>2017</year>; <volume>469</volume>:<fpage>173</fpage>–<lpage>182</lpage>.</mixed-citation>
    </ref>
    <ref id="B42">
      <label>42.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Vaswani</surname><given-names>A.</given-names></string-name>, <string-name><surname>Shazeer</surname><given-names>N.</given-names></string-name>, <string-name><surname>Parmar</surname><given-names>N.</given-names></string-name>, <string-name><surname>Uszkoreit</surname><given-names>J.</given-names></string-name>, <string-name><surname>Jones</surname><given-names>L.</given-names></string-name>, <string-name><surname>Gomez</surname><given-names>A.N.</given-names></string-name>, <string-name><surname>Kaiser</surname><given-names>L.</given-names></string-name>, <string-name><surname>Polosukhin</surname><given-names>I.</given-names></string-name></person-group><person-group person-group-type="editor"><string-name><surname>Guyon</surname><given-names>I.</given-names></string-name>, <string-name><surname>Luxburg</surname><given-names>U.V.</given-names></string-name>, <string-name><surname>Bengio</surname><given-names>S.</given-names></string-name>, <string-name><surname>Wallach</surname><given-names>H.</given-names></string-name>, <string-name><surname>Fergus</surname><given-names>R.</given-names></string-name>, <string-name><surname>Vishwanathan</surname><given-names>S.</given-names></string-name>, <string-name><surname>Garnett</surname><given-names>R.</given-names></string-name></person-group><article-title>Attention is all you need</article-title>. <source>Advances in Neural Information Processing Systems</source>. <year>2017</year>; <volume>30</volume>:<publisher-loc>Red Hook, NY</publisher-loc><publisher-name>Curran Associates, Inc</publisher-name>.</mixed-citation>
    </ref>
    <ref id="B43">
      <label>43.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Devlin</surname><given-names>J.</given-names></string-name>, <string-name><surname>Chang</surname><given-names>M.-W.</given-names></string-name>, <string-name><surname>Lee</surname><given-names>K.</given-names></string-name>, <string-name><surname>Toutanova</surname><given-names>K.</given-names></string-name></person-group><article-title>Bert: pre-training of deep bidirectional transformers for language understanding</article-title>. <source>Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)</source>. <year>2019</year>; <fpage>4171</fpage>–<lpage>4186</lpage>.</mixed-citation>
    </ref>
    <ref id="B44">
      <label>44.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Radford</surname><given-names>A.</given-names></string-name>, <string-name><surname>Wu</surname><given-names>J.</given-names></string-name>, <string-name><surname>Child</surname><given-names>R.</given-names></string-name>, <string-name><surname>Luan</surname><given-names>D.</given-names></string-name>, <string-name><surname>Amodei</surname><given-names>D.</given-names></string-name>, <string-name><surname>Sutskever</surname><given-names>I.</given-names></string-name></person-group><article-title>Language models are unsupervised multitask learners</article-title>. <source>OpenAI Blog</source>. <year>2019</year>; <volume>1</volume>:<fpage>9</fpage>.</mixed-citation>
    </ref>
    <ref id="B45">
      <label>45.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rives</surname><given-names>A.</given-names></string-name>, <string-name><surname>Meier</surname><given-names>J.</given-names></string-name>, <string-name><surname>Sercu</surname><given-names>T.</given-names></string-name>, <string-name><surname>Goyal</surname><given-names>S.</given-names></string-name>, <string-name><surname>Lin</surname><given-names>Z.</given-names></string-name>, <string-name><surname>Liu</surname><given-names>J.</given-names></string-name>, <string-name><surname>Guo</surname><given-names>D.</given-names></string-name>, <string-name><surname>Ott</surname><given-names>M.</given-names></string-name>, <string-name><surname>Zitnick</surname><given-names>C.L.</given-names></string-name>, <string-name><surname>Ma</surname><given-names>J.</given-names></string-name><etal>et al</etal>.</person-group><article-title>Biological structure and function emerge from scaling unsupervised learning to 250 million protein sequences</article-title>. <source>Proc. Natl Acad. Sci. U.S.A.</source><year>2021</year>; <volume>118</volume>:<fpage>e2016239118</fpage>.<pub-id pub-id-type="pmid">33876751</pub-id></mixed-citation>
    </ref>
    <ref id="B46">
      <label>46.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jumper</surname><given-names>J.</given-names></string-name>, <string-name><surname>Evans</surname><given-names>R.</given-names></string-name>, <string-name><surname>Pritzel</surname><given-names>A.</given-names></string-name>, <string-name><surname>Green</surname><given-names>T.</given-names></string-name>, <string-name><surname>Figurnov</surname><given-names>M.</given-names></string-name>, <string-name><surname>Ronneberger</surname><given-names>O.</given-names></string-name>, <string-name><surname>Tunyasuvunakool</surname><given-names>K.</given-names></string-name>, <string-name><surname>Bates</surname><given-names>R.</given-names></string-name>, <string-name><surname>Žídek</surname><given-names>A.</given-names></string-name>, <string-name><surname>Potapenko</surname><given-names>A.</given-names></string-name><etal>et al</etal>.</person-group><article-title>Highly accurate protein structure prediction with AlphaFold</article-title>. <source>Nature</source>. <year>2021</year>; <volume>596</volume>:<fpage>583</fpage>–<lpage>589</lpage>.<pub-id pub-id-type="pmid">34265844</pub-id></mixed-citation>
    </ref>
    <ref id="B47">
      <label>47.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wishart</surname><given-names>D.S.</given-names></string-name>, <string-name><surname>Sykes</surname><given-names>B.D.</given-names></string-name>, <string-name><surname>Richards</surname><given-names>F.M.</given-names></string-name></person-group><article-title>The chemical shift index: a fast and simple method for the assignment of protein secondary structure through NMR spectroscopy</article-title>. <source>Biochemistry</source>. <year>1992</year>; <volume>31</volume>:<fpage>1647</fpage>–<lpage>1651</lpage>.<pub-id pub-id-type="pmid">1737021</pub-id></mixed-citation>
    </ref>
    <ref id="B48">
      <label>48.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Suzek</surname><given-names>B.E.</given-names></string-name>, <string-name><surname>Wang</surname><given-names>Y.</given-names></string-name>, <string-name><surname>Huang</surname><given-names>H.</given-names></string-name>, <string-name><surname>McGarvey</surname><given-names>P.B.</given-names></string-name>, <string-name><surname>Wu</surname><given-names>C.H.</given-names></string-name><collab>UniProt Consortium</collab></person-group><article-title>UniRef clusters: a comprehensive and scalable alternative for improving sequence similarity searches</article-title>. <source>Bioinformatics</source>. <year>2015</year>; <volume>31</volume>:<fpage>926</fpage>–<lpage>932</lpage>.<pub-id pub-id-type="pmid">25398609</pub-id></mixed-citation>
    </ref>
    <ref id="B49">
      <label>49.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bairoch</surname><given-names>A.</given-names></string-name>, <string-name><surname>Apweiler</surname><given-names>R.</given-names></string-name>, <string-name><surname>Wu</surname><given-names>C.H.</given-names></string-name>, <string-name><surname>Barker</surname><given-names>W.C.</given-names></string-name>, <string-name><surname>Boeckmann</surname><given-names>B.</given-names></string-name>, <string-name><surname>Ferro</surname><given-names>S.</given-names></string-name>, <string-name><surname>Gasteiger</surname><given-names>E.</given-names></string-name>, <string-name><surname>Huang</surname><given-names>H.</given-names></string-name>, <string-name><surname>Lopez</surname><given-names>R.</given-names></string-name>, <string-name><surname>Magrane</surname><given-names>M.</given-names></string-name><etal>et al</etal>.</person-group><article-title>The Universal Protein Resource (UniProt)</article-title>. <source>Nucleic Acids Res.</source><year>2005</year>; <volume>33</volume>:<fpage>D154</fpage>–<lpage>D159</lpage>.<pub-id pub-id-type="pmid">15608167</pub-id></mixed-citation>
    </ref>
    <ref id="B50">
      <label>50.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mirdita</surname><given-names>M.</given-names></string-name>, <string-name><surname>von den Driesch</surname><given-names>L.</given-names></string-name>, <string-name><surname>Galiez</surname><given-names>C.</given-names></string-name>, <string-name><surname>Martin</surname><given-names>M.J.</given-names></string-name>, <string-name><surname>Söding</surname><given-names>J.</given-names></string-name>, <string-name><surname>Steinegger</surname><given-names>M.</given-names></string-name></person-group><article-title>Uniclust databases of clustered and deeply annotated protein sequences and alignments</article-title>. <source>Nucleic Acids Res.</source><year>2017</year>; <volume>45</volume>:<fpage>D170</fpage>–<lpage>D176</lpage>.<pub-id pub-id-type="pmid">27899574</pub-id></mixed-citation>
    </ref>
    <ref id="B51">
      <label>51.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Steinegger</surname><given-names>M.</given-names></string-name>, <string-name><surname>Meier</surname><given-names>M.</given-names></string-name>, <string-name><surname>Mirdita</surname><given-names>M.</given-names></string-name>, <string-name><surname>Vöhringer</surname><given-names>H.</given-names></string-name>, <string-name><surname>Haunsberger</surname><given-names>S.J.</given-names></string-name>, <string-name><surname>Söding</surname><given-names>J.</given-names></string-name></person-group><article-title>HH-suite3 for fast remote homology detection and deep protein annotation</article-title>. <source>BMC Bioinformatics</source>. <year>2019</year>; <volume>20</volume>:<fpage>473</fpage>.<pub-id pub-id-type="pmid">31521110</pub-id></mixed-citation>
    </ref>
    <ref id="B52">
      <label>52.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rao</surname><given-names>R.</given-names></string-name>, <string-name><surname>Liu</surname><given-names>J.</given-names></string-name>, <string-name><surname>Verkuil</surname><given-names>R.</given-names></string-name>, <string-name><surname>Meier</surname><given-names>J.</given-names></string-name>, <string-name><surname>Canny</surname><given-names>J.F.</given-names></string-name>, <string-name><surname>Abbeel</surname><given-names>P.</given-names></string-name>, <string-name><surname>Sercu</surname><given-names>T.</given-names></string-name>, <string-name><surname>Rives</surname><given-names>A.</given-names></string-name></person-group><article-title>MSA transformer</article-title>. <source>Proceedings of the 38th International Conference on Machine Learning</source>. <year>2021</year>; <volume>139</volume>:<fpage>8844</fpage>–<lpage>8856</lpage>.</mixed-citation>
    </ref>
    <ref id="B53">
      <label>53.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Hastie</surname><given-names>T.</given-names></string-name>, <string-name><surname>Tibshirani</surname><given-names>R.</given-names></string-name>, <string-name><surname>Friedman</surname><given-names>J.</given-names></string-name></person-group><source>The Elements of Statistical Learning: Data Mining, Inference and Prediction</source>. <year>2009</year>; <edition>2nd edn</edition><publisher-loc>Berlin</publisher-loc><publisher-name>Springer</publisher-name>.</mixed-citation>
    </ref>
    <ref id="B54">
      <label>54.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mirdita</surname><given-names>M.</given-names></string-name>, <string-name><surname>Steinegger</surname><given-names>M.</given-names></string-name>, <string-name><surname>Breitwieser</surname><given-names>F.</given-names></string-name>, <string-name><surname>Söding</surname><given-names>J.</given-names></string-name>, <string-name><surname>Levy Karin</surname><given-names>E.</given-names></string-name></person-group><article-title>Fast and sensitive taxonomic assignment to metagenomic contigs</article-title>. <source>Bioinformatics</source>. <year>2021</year>; <volume>37</volume>:<fpage>3029</fpage>–<lpage>3031</lpage>.<pub-id pub-id-type="pmid">33734313</pub-id></mixed-citation>
    </ref>
    <ref id="B55">
      <label>55.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ilzhoefer</surname><given-names>D.</given-names></string-name>, <string-name><surname>Heinzinger</surname><given-names>M.</given-names></string-name>, <string-name><surname>Rost</surname><given-names>B.</given-names></string-name></person-group><article-title>SETH predicts nuances of residue disorder from protein embeddings</article-title>. <source>Front Bioinform.</source><year>2022</year>; <volume>2</volume>:<fpage>1019597</fpage>.<pub-id pub-id-type="pmid">36304335</pub-id></mixed-citation>
    </ref>
    <ref id="B56">
      <label>56.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Meinshausen</surname><given-names>N.</given-names></string-name>, <string-name><surname>Bühlmann</surname><given-names>P.</given-names></string-name></person-group><article-title>Stability selection</article-title>. <source>J. R. Stat. Soc. Ser. B: Stat. Methodol.</source><year>2010</year>; <volume>72</volume>:<fpage>417</fpage>–<lpage>473</lpage>.</mixed-citation>
    </ref>
    <ref id="B57">
      <label>57.</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Emenecker</surname><given-names>R.J.</given-names></string-name>, <string-name><surname>Griffith</surname><given-names>D.</given-names></string-name>, <string-name><surname>Holehouse</surname><given-names>A.S.</given-names></string-name></person-group><article-title>Metapredict V2: an update to Metapredict, a fast, accurate, and easy-to-use predictor of consensus disorder and structure</article-title>. <year>2022</year>; <comment>bioRxiv doi:</comment><comment>09 June 2022, preprint: not peer reviewed</comment><pub-id pub-id-type="doi">10.1101/2022.06.06.494887</pub-id>.</mixed-citation>
    </ref>
    <ref id="B58">
      <label>58.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Emenecker</surname><given-names>R.J.</given-names></string-name>, <string-name><surname>Griffith</surname><given-names>D.</given-names></string-name>, <string-name><surname>Holehouse</surname><given-names>A.S.</given-names></string-name></person-group><article-title>Metapredict: a fast, accurate, and easy-to-use predictor of consensus disorder and structure</article-title>. <source>Biophys. J.</source><year>2021</year>; <volume>120</volume>:<fpage>4312</fpage>–<lpage>4319</lpage>.<pub-id pub-id-type="pmid">34480923</pub-id></mixed-citation>
    </ref>
    <ref id="B59">
      <label>59.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Theillet</surname><given-names>F.-X.</given-names></string-name>, <string-name><surname>Kalmar</surname><given-names>L.</given-names></string-name>, <string-name><surname>Tompa</surname><given-names>P.</given-names></string-name>, <string-name><surname>Han</surname><given-names>K.-H.</given-names></string-name>, <string-name><surname>Selenko</surname><given-names>P.</given-names></string-name>, <string-name><surname>Dunker</surname><given-names>A.K.</given-names></string-name>, <string-name><surname>Daughdrill</surname><given-names>G.W.</given-names></string-name>, <string-name><surname>Uversky</surname><given-names>V.N.</given-names></string-name></person-group><article-title>The alphabet of intrinsic disorder</article-title>. <source>Intrinsically Disord. Proteins</source>. <year>2013</year>; <volume>1</volume>:<fpage>e24360</fpage>.<pub-id pub-id-type="pmid">28516008</pub-id></mixed-citation>
    </ref>
    <ref id="B60">
      <label>60.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Feige</surname><given-names>M.J.</given-names></string-name>, <string-name><surname>Braakman</surname><given-names>I.</given-names></string-name>, <string-name><surname>Hendershot</surname><given-names>L.M.</given-names></string-name></person-group><article-title>Chapter 1.1: Disulfide bonds in protein folding and stability</article-title>. <source>Oxidative Folding of Proteins: Basic Principles, Cellular Regulation and Engineering</source>. <year>2018</year>; <publisher-loc>London</publisher-loc><publisher-name>The Royal Society of Chemistry</publisher-name><fpage>1</fpage>–<lpage>33</lpage>.</mixed-citation>
    </ref>
    <ref id="B61">
      <label>61.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mariani</surname><given-names>V.</given-names></string-name>, <string-name><surname>Biasini</surname><given-names>M.</given-names></string-name>, <string-name><surname>Barbato</surname><given-names>A.</given-names></string-name>, <string-name><surname>Schwede</surname><given-names>T.</given-names></string-name></person-group><article-title>lDDT: a local superposition-free score for comparing protein structures and models using distance difference tests</article-title>. <source>Bioinformatics</source>. <year>2013</year>; <volume>29</volume>:<fpage>2722</fpage>–<lpage>2728</lpage>.<pub-id pub-id-type="pmid">23986568</pub-id></mixed-citation>
    </ref>
    <ref id="B62">
      <label>62.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Akdel</surname><given-names>M.</given-names></string-name>, <string-name><surname>Pires</surname><given-names>D.E.V.</given-names></string-name>, <string-name><surname>Porta Pardo</surname><given-names>E.</given-names></string-name>, <string-name><surname>Jänes</surname><given-names>J.</given-names></string-name>, <string-name><surname>Zalevsky</surname><given-names>A.O.</given-names></string-name>, <string-name><surname>Mészáros</surname><given-names>B.</given-names></string-name>, <string-name><surname>Bryant</surname><given-names>P.</given-names></string-name>, <string-name><surname>Good</surname><given-names>L.L.</given-names></string-name>, <string-name><surname>Laskowski</surname><given-names>R.A.</given-names></string-name>, <string-name><surname>Pozzati</surname><given-names>G.</given-names></string-name><etal>et al</etal>.</person-group><article-title>A structural biology community assessment of AlphaFold2 applications</article-title>. <source>Nat. Struct. Mol. Biol.</source><year>2022</year>; <volume>29</volume>:<fpage>1056</fpage>–<lpage>1067</lpage>.<pub-id pub-id-type="pmid">36344848</pub-id></mixed-citation>
    </ref>
    <ref id="B63">
      <label>63.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tunyasuvunakool</surname><given-names>K.</given-names></string-name>, <string-name><surname>Adler</surname><given-names>J.</given-names></string-name>, <string-name><surname>Wu</surname><given-names>Z.</given-names></string-name>, <string-name><surname>Green</surname><given-names>T.</given-names></string-name>, <string-name><surname>Zielinski</surname><given-names>M.</given-names></string-name>, <string-name><surname>Žídek</surname><given-names>A.</given-names></string-name>, <string-name><surname>Bridgland</surname><given-names>A.</given-names></string-name>, <string-name><surname>Cowie</surname><given-names>A.</given-names></string-name>, <string-name><surname>Meyer</surname><given-names>C.</given-names></string-name>, <string-name><surname>Laydon</surname><given-names>A.</given-names></string-name><etal>et al</etal>.</person-group><article-title>Highly accurate protein structure prediction for the human proteome</article-title>. <source>Nature</source>. <year>2021</year>; <volume>596</volume>:<fpage>590</fpage>–<lpage>596</lpage>.<pub-id pub-id-type="pmid">34293799</pub-id></mixed-citation>
    </ref>
    <ref id="B64">
      <label>64.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Piovesan</surname><given-names>D.</given-names></string-name>, <string-name><surname>Monzon</surname><given-names>A.M.</given-names></string-name>, <string-name><surname>Tosatto</surname><given-names>S.C.E.</given-names></string-name></person-group><article-title>Intrinsic protein disorder and conditional folding in AlphaFoldDB</article-title>. <source>Protein Sci.</source><year>2022</year>; <volume>31</volume>:<fpage>e4466</fpage>.<pub-id pub-id-type="pmid">36210722</pub-id></mixed-citation>
    </ref>
    <ref id="B65">
      <label>65.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wilson</surname><given-names>C.J.</given-names></string-name>, <string-name><surname>Choy</surname><given-names>W.-Y.</given-names></string-name>, <string-name><surname>Karttunen</surname><given-names>M.</given-names></string-name></person-group><article-title>AlphaFold2: a role for disordered protein/region prediction?</article-title>. <source>Int. J. Mol. Sci.</source><year>2022</year>; <volume>23</volume>:<fpage>4591</fpage>.<pub-id pub-id-type="pmid">35562983</pub-id></mixed-citation>
    </ref>
    <ref id="B66">
      <label>66.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rao</surname><given-names>R.</given-names></string-name>, <string-name><surname>Bhattacharya</surname><given-names>N.</given-names></string-name>, <string-name><surname>Thomas</surname><given-names>N.</given-names></string-name>, <string-name><surname>Duan</surname><given-names>Y.</given-names></string-name>, <string-name><surname>Chen</surname><given-names>X.</given-names></string-name>, <string-name><surname>Canny</surname><given-names>J.</given-names></string-name>, <string-name><surname>Abbeel</surname><given-names>P.</given-names></string-name>, <string-name><surname>Song</surname><given-names>Y.S.</given-names></string-name></person-group><article-title>Evaluating protein transfer learning with TAPE</article-title>. <source>Adv. Neural Inf. Process. Syst.</source><year>2019</year>; <volume>32</volume>:<fpage>9689</fpage>–<lpage>9701</lpage>.<pub-id pub-id-type="pmid">33390682</pub-id></mixed-citation>
    </ref>
    <ref id="B67">
      <label>67.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bepler</surname><given-names>T.</given-names></string-name>, <string-name><surname>Berger</surname><given-names>B.</given-names></string-name></person-group><article-title>Learning the protein language: evolution, structure, and function</article-title>. <source>Cell Syst.</source><year>2021</year>; <volume>12</volume>:<fpage>654</fpage>–<lpage>669</lpage>.<pub-id pub-id-type="pmid">34139171</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
