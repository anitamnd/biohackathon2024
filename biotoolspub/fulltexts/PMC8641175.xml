<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">BMC Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">BMC Bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>BMC Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1471-2105</issn>
    <publisher>
      <publisher-name>BioMed Central</publisher-name>
      <publisher-loc>London</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">8641175</article-id>
    <article-id pub-id-type="publisher-id">4499</article-id>
    <article-id pub-id-type="doi">10.1186/s12859-021-04499-5</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Research</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>BreakNet: detecting deletions using long reads and a deep learning approach</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Luo</surname>
          <given-names>Junwei</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Ding</surname>
          <given-names>Hongyu</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Shen</surname>
          <given-names>Jiquan</given-names>
        </name>
        <address>
          <email>sjq@hpu.edu.cn</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Zhai</surname>
          <given-names>Haixia</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Wu</surname>
          <given-names>Zhengjiang</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Yan</surname>
          <given-names>Chaokun</given-names>
        </name>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Luo</surname>
          <given-names>Huimin</given-names>
        </name>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="GRID">grid.412097.9</institution-id><institution-id institution-id-type="ISNI">0000 0000 8645 6375</institution-id><institution>College of Computer Science and Technology, </institution><institution>Henan Polytechnic University, </institution></institution-wrap>Jiaozuo, 454003 China </aff>
      <aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="GRID">grid.256922.8</institution-id><institution-id institution-id-type="ISNI">0000 0000 9139 560X</institution-id><institution>School of Computer Science and Information Engineering, </institution><institution>Henan University, </institution></institution-wrap>Kaifeng, 475001 China </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>2</day>
      <month>12</month>
      <year>2021</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>2</day>
      <month>12</month>
      <year>2021</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2021</year>
    </pub-date>
    <volume>22</volume>
    <elocation-id>577</elocation-id>
    <history>
      <date date-type="received">
        <day>14</day>
        <month>9</month>
        <year>2021</year>
      </date>
      <date date-type="accepted">
        <day>29</day>
        <month>11</month>
        <year>2021</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2021</copyright-statement>
      <license>
        <ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p><bold>Open Access</bold>This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>. The Creative Commons Public Domain Dedication waiver (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/publicdomain/zero/1.0/">http://creativecommons.org/publicdomain/zero/1.0/</ext-link>) applies to the data made available in this article, unless otherwise stated in a credit line to the data.</license-p>
      </license>
    </permissions>
    <abstract id="Abs1">
      <sec>
        <title>Background</title>
        <p id="Par1">Structural variations (SVs) occupy a prominent position in human genetic diversity, and deletions form an important type of SV that has been suggested to be associated with genetic diseases. Although various deletion calling methods based on long reads have been proposed, a new approach is still needed to mine features in long-read alignment information. Recently, deep learning has attracted much attention in genome analysis, and it is a promising technique for calling SVs.</p>
      </sec>
      <sec>
        <title>Results</title>
        <p id="Par2">In this paper, we propose BreakNet, a deep learning method that detects deletions by using long reads. BreakNet first extracts feature matrices from long-read alignments. Second, it uses a time-distributed convolutional neural network (CNN) to integrate and map the feature matrices to feature vectors. Third, BreakNet employs a bidirectional long short-term memory (BLSTM) model to analyse the produced set of continuous feature vectors in both the forward and backward directions. Finally, a classification module determines whether a region refers to a deletion. On real long-read sequencing datasets, we demonstrate that BreakNet outperforms Sniffles, SVIM and cuteSV in terms of their F1 scores. The source code for the proposed method is available from GitHub at <ext-link ext-link-type="uri" xlink:href="https://github.com/luojunwei/BreakNet">https://github.com/luojunwei/BreakNet</ext-link>.</p>
      </sec>
      <sec>
        <title>Conclusions</title>
        <p id="Par3">Our work shows that deep learning can be combined with long reads to call deletions more effectively than existing methods.</p>
      </sec>
      <sec>
        <title>Supplementary Information</title>
        <p>The online version contains supplementary material available at 10.1186/s12859-021-04499-5.</p>
      </sec>
    </abstract>
    <funding-group>
      <award-group>
        <funding-source>
          <institution>Young Elite Teachers in Henan Province</institution>
        </funding-source>
        <award-id>2020GGJS050</award-id>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution>Doctor Foundation of Henan Polytechnic University</institution>
        </funding-source>
        <award-id>B2018-36</award-id>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution>National Natural Science Foundation of China</institution>
        </funding-source>
        <award-id>61972134</award-id>
        <award-id>61802113</award-id>
        <principal-award-recipient>
          <name>
            <surname>Luo</surname>
            <given-names>Junwei</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution>Henan Provincial Department of Science and Technology Research Project</institution>
        </funding-source>
        <award-id>192102210118</award-id>
        <award-id>182102310946</award-id>
        <principal-award-recipient>
          <name>
            <surname>Luo</surname>
            <given-names>Junwei</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
    </funding-group>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>© The Author(s) 2021</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="Sec1">
    <title>Background</title>
    <p id="Par10">Genetic structural variants (SVs) normally include deletions, insertions, inversions and duplications of gene segments with variation lengths greater than 50 bp [<xref ref-type="bibr" rid="CR1">1</xref>]. Compared to single-nucleotide polymorphisms (SNPs) and insertions and deletions (INDELs), SVs occupy a more prominent position in human genetic diversity and have a significant impact on gene functioning and gene regulation [<xref ref-type="bibr" rid="CR2">2</xref>]. For example, the deletion of 16p11.2 (AUTS14; MIM611913) is observed for autism spectrum disorder [<xref ref-type="bibr" rid="CR3">3</xref>]. Multiple deletions are considered responsible for schizophrenia [<xref ref-type="bibr" rid="CR4">4</xref>], a chronic, debilitating illness that affects ~ 1% of the population. The accurate and comprehensive detection of SVs is particularly important, but the detection of SVs is much more difficult than SNP detection. Sequencing and alignment errors usually interfere with the characterization of variant regions and affect the variant detection results.</p>
    <p id="Par11">Many computational methods have been proposed. Existing methods can be divided into three categories: de novo assembly-based approaches, short-read alignment-based approaches, and long-read alignment-based approaches.</p>
    <p id="Par12">De novo assembly-based approaches can leverage both short and long reads and can use the assembled sequence or construct an assembly graph to detect SVs. De novo assembly methods can theoretically find all types of variations and are less affected by the reference sequence. However, this type of method is computationally expensive and has difficulty in terms of reconstructing haplotype sequences [<xref ref-type="bibr" rid="CR5">5</xref>]. These shortcomings have limited the development of de novo assembly-based methods for variant detection.</p>
    <p id="Par13">Short-read alignment-based approaches directly analyse read alignments and detect SVs. Methods based on short-read sequencing technologies have been well studied; they operate by extracting SV signatures such as read depths, discordant read pairs, and split reads to find candidate sites and detect SVs [<xref ref-type="bibr" rid="CR6">6</xref>]. Note that the signatures used in SV callers have major impacts on their performance. For example, BreakDancer relies on the distances and orientation of reads to call SVs [<xref ref-type="bibr" rid="CR7">7</xref>], and it exhibits less sensitivity to small variations because the sizes of SVs may blend into the normal paired read distribution, and callers cannot be detected easily. Delly not only uses discordant reads as SV signatures but also takes split reads into account and shows better sensitivity to small variations [<xref ref-type="bibr" rid="CR8">8</xref>]. LUMPY integrates discordant reads, read depths, and split reads as SV signatures to detect SVs and achieves high accuracy and sensitivity with respect to large SVs [<xref ref-type="bibr" rid="CR9">9</xref>].</p>
    <p id="Par14">Due to technological advances and the widespread use of third-generation sequencing technologies, the greatly increased lengths of reads have helped aligners produce high-quality alignments. Longer reads can overlap better in highly repetitive or low-complexity regions that are prone to SVs [<xref ref-type="bibr" rid="CR10">10</xref>]. Several studies have shown that long read-based methods can find a substantial number of SVs that are missed by short-read methods [<xref ref-type="bibr" rid="CR11">11</xref>–<xref ref-type="bibr" rid="CR13">13</xref>]. However, long reads are commonly accompanied by high sequencing error rates, and compared to that of second-generation sequencing technology, the sequencing error rate of third-generation sequencing technology is more than ten times higher. Third-generation sequencing methods also suffer from higher sequencing costs than those of short-read approaches when sequencing at the same coverage levels. Despite these disadvantages, many long read-based SV detection methods have been proposed and have achieved better performance than short read-based methods.</p>
    <p id="Par15">Sniffles is a long read-based SV caller [<xref ref-type="bibr" rid="CR14">14</xref>]. By preforming parameter estimation at the beginning, Sniffles updates its model to fit the given data and uses a statistical model to reduce the number of false-positive calls. PBHoney is a long read-based SV detection tool designed to work with PacBio data [<xref ref-type="bibr" rid="CR15">15</xref>]. It uses two different approaches to detect SVs. The first approach is called PBHoney-spot. By learning the stochastic natures of PacBio reads, PBHoney-spot is able to detect abnormal increases or decreases in the error rates of long reads. The second approach is PBHoney-tail. By extracting soft-clip sequences from read alignments and realigning them to the reference genome, realignments are clustered by their locations and orientations. The SV identification method (SVIM) uses both intra- and inter-alignment signatures to call SVs [<xref ref-type="bibr" rid="CR16">16</xref>]. Intra-alignment signatures include large gaps in references and reads, and they can be extracted from CIGAR strings. Inter-alignment signatures include discordant alignment positions and abnormal read alignment orientations. The SVIM uses a graph-based cluster to separate and merge SV signatures and classify them into different classes. cuteSV uses a heuristic method to merge small SVs into large SVs, thereby producing more homogenous SV signatures. cuteSV uses a clustering-and-refinement approach to improve breakpoint accuracy and reduce the number of generated false positives [<xref ref-type="bibr" rid="CR17">17</xref>]. The set of PacBio SV calling and analysis tools (PBSV) is an SV detection method developed by PacBio. By selecting abnormal reads and realigning them to the reference genome, PBSV exhibits better sensitivity to large insertions than other approaches.</p>
    <p id="Par16">Deep learning has gained much attention in recent years and has outperformed existing methods in many fields, such as image recognition and speech translation. In recent years, deep learning-based methods have been used by several genome variation callers [<xref ref-type="bibr" rid="CR18">18</xref>–<xref ref-type="bibr" rid="CR21">21</xref>]. Unlike traditional SV detection methods that rely on handcrafted designs, deep learning models can integrate information by themselves. This enables a deep learning model to find more useful information and improve SV calling. DeepVariant was the first application deep learning to the detection of SNPs; it uses short-read data to detect variants and achieves higher performance than traditional methods. DeepSV also uses short-read data with a deep learning approach, but this method focuses on large genome deletions.</p>
    <p id="Par17">However, read alignment-based SV calling still faces many difficulties. For example, due to the complexity of SVs and high sequence error rates, current methods suffer from low sensitivity to low-coverage data. Here, we present BreakNet, a deletion detection method based on long reads and deep learning. BreakNet uses a time-distributed convolutional neural network (CNN) model to extract deletion signatures and analyse the signatures with a bidirectional long short-term memory (BLSTM) model in both the forward and backward directions. BreakNet achieves better performance than existing methods and has better sensitivity to lower-coverage data.</p>
  </sec>
  <sec id="Sec2">
    <title>Methods</title>
    <p id="Par18">BreakNet uses the read alignment file produced by long reads and the corresponding reference genome as input, and it outputs deletion regions. BreakNet contains four main modules (Fig. <xref rid="Fig1" ref-type="fig">1</xref>). The first module is a feature matrix generation module, which splits the reference sequence into subregions, and then each subregion is transformed into a feature matrix based on alignment information. The second module is a CNN module, which maps the features to feature vectors. The third module is a bidirectional recurrent neural network (BRNN) module, which analyses the feature vectors associated with multiple time steps in both the forward and backward directions and integrates more deletion information. The fourth module is a classification module, which makes predictive judgements regarding the vectors output from the BRNN module and determines whether deletion has occurred.<fig id="Fig1"><label>Fig. 1</label><caption><p>BreakNet module for detecting deletions</p></caption><graphic xlink:href="12859_2021_4499_Fig1_HTML" id="MO1"/></fig></p>
    <sec id="Sec3">
      <title>Feature matrix generation module</title>
      <p id="Par19">The feature matrix generation module first divides the reference into subregions of length <italic>m</italic> (200 bp by default). This module extracts long reads that can be aligned in each subregion. Then, the module extracts the CIGAR string of each aligned long read and finds the positions that refer to a deletion (D operations in a CIGAR string).</p>
      <p id="Par20">We assume that the number of aligned long reads is <italic>p</italic>. Then, the <italic>i-th</italic> aligned long read is converted to an <italic>m-tuple</italic>
<inline-formula id="IEq1"><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\left( {d_{i1} , d_{i2} \cdots d_{im} } \right)$$\end{document}</tex-math><mml:math id="M2"><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>⋯</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi mathvariant="italic">im</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math><inline-graphic xlink:href="12859_2021_4499_Article_IEq1.gif"/></alternatives></inline-formula>, where <italic>d</italic><sub><italic>ij</italic></sub> represents whether the <italic>j-th</italic> position in this subregion refers to a deletion based on the CIGAR string of the <italic>i-th</italic> aligned long read. When the <italic>j-th</italic> position is a deletion, <italic>d</italic><sub><italic>ij</italic></sub> is set to 1; otherwise, it is set to 0.</p>
      <p id="Par21">Then, these aligned long reads are sorted based on their deletion counts in descending order. Note that the numbers of aligned long reads for various sub-regions are commonly different, and the row number of each matrix is also different. To generate a matrix with the same size, we set the number of rows to <italic>n</italic> (18 by default). If <italic>p</italic> is greater than or equal to <italic>n</italic>, this module selects the first <italic>n</italic> rows to produce the matrix. Otherwise, the elements in the remaining <italic>n – p</italic> rows are set to 0.</p>
    </sec>
    <sec id="Sec4">
      <title>CNN module</title>
      <p id="Par22">In this module, we adopt 100 continuous transposed feature matrices as inputs. Each feature matrix is fed into a time-distributed CNN, which outputs a 160-dimensional feature vector to the next module. The CNN module consists of several operations, which include average Pooling, max pooling and 2D convolution (conv2D). In detail, this module first applies a 1 × 2 average pooling layer to downsample the input matrix and reduce the computational cost. Then, this module uses 6 convolutional blocks to map each feature matrix to the output vector. Each convolutional block consists of a conv2D layer, a squeeze-and-excitation (SE) optimization layer and a max pooling layer [<xref ref-type="bibr" rid="CR22">22</xref>]. As an example, the convolution of a matrix can be computed by the following equation:<disp-formula id="Equ1"><label>1</label><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$O_{{m^{\prime},{ }n^{\prime}}} \left[ {row,col} \right] = \mathop \sum \limits_{i = 0}^{a - 1} \mathop \sum \limits_{j = 0}^{b - 1} w_{ij} \times I_{m,n} \left[ {row + i,col + j} \right]$$\end{document}</tex-math><mml:math id="M4" display="block"><mml:mrow><mml:msub><mml:mi>O</mml:mi><mml:mrow><mml:msup><mml:mi>m</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:mrow/><mml:msup><mml:mi>n</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:mrow></mml:msub><mml:mfenced close="]" open="["><mml:mrow><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>w</mml:mi><mml:mo>,</mml:mo><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:munderover><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mi>b</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:munderover><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow></mml:msub><mml:mo>×</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mfenced close="]" open="["><mml:mrow><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>w</mml:mi><mml:mo>+</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>l</mml:mi><mml:mo>+</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:math><graphic xlink:href="12859_2021_4499_Article_Equ1.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq2"><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$I_{m \times n}$$\end{document}</tex-math><mml:math id="M6"><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mo>×</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12859_2021_4499_Article_IEq2.gif"/></alternatives></inline-formula> and <inline-formula id="IEq3"><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$O_{{m^{\prime}, n^{\prime}}}$$\end{document}</tex-math><mml:math id="M8"><mml:msub><mml:mi>O</mml:mi><mml:mrow><mml:msup><mml:mi>m</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi>n</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12859_2021_4499_Article_IEq3.gif"/></alternatives></inline-formula> are the input and output matrices, respectively, <inline-formula id="IEq4"><alternatives><tex-math id="M9">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$w_{a*b}$$\end{document}</tex-math><mml:math id="M10"><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mrow/><mml:mo>∗</mml:mo><mml:mi>b</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12859_2021_4499_Article_IEq4.gif"/></alternatives></inline-formula> is the weight matrix of the convolution kernel, and <inline-formula id="IEq5"><alternatives><tex-math id="M11">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$row, col$$\end{document}</tex-math><mml:math id="M12"><mml:mrow><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>w</mml:mi><mml:mo>,</mml:mo><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="12859_2021_4499_Article_IEq5.gif"/></alternatives></inline-formula> are the rows and columns of the output matrix. Next, we use a rectified linear unit (<italic>ReLU</italic>) as the activation function to add nonlinearity.<disp-formula id="Equ2"><label>2</label><alternatives><tex-math id="M13">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$x_{a} = ReLu\left( x \right) = \left\{ {\begin{array}{*{20}l} {0,} \hfill &amp; {if\; m &lt; 0} \hfill \\ {x,} \hfill &amp; {if\; m \ge 0} \hfill \\ \end{array} } \right.$$\end{document}</tex-math><mml:math id="M14" display="block"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>a</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>L</mml:mi><mml:mi>u</mml:mi><mml:mfenced close=")" open="("><mml:mi>x</mml:mi></mml:mfenced><mml:mo>=</mml:mo><mml:mfenced open="{"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mspace width="0.277778em"/><mml:mi>m</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:mrow/><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo></mml:mrow></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mspace width="0.277778em"/><mml:mi>m</mml:mi><mml:mo>≥</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mfenced></mml:mrow></mml:math><graphic xlink:href="12859_2021_4499_Article_Equ2.gif" position="anchor"/></alternatives></disp-formula></p>
      <p id="Par23">To enhance the performance of the network, we use SE optimization to add weights to each computed convolution channel, and the network can adaptively adjust the weight of each feature map. Similar to EfficientNet [<xref ref-type="bibr" rid="CR23">23</xref>], the CNN module uses a 2D global average pooling layer and two 1 × 1 conv2D layers as an implementation of the SE module. Finally, we apply a max pooling operation on the weighted convolution to reduce the number of parameters.</p>
    </sec>
    <sec id="Sec5">
      <title>BRNN module</title>
      <p id="Par24">The BRNN module takes a matrix with dimensions of <inline-formula id="IEq6"><alternatives><tex-math id="M15">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\left( { T, F} \right)$$\end{document}</tex-math><mml:math id="M16"><mml:mfenced close=")" open="("><mml:mrow><mml:mi>T</mml:mi><mml:mo>,</mml:mo><mml:mi>F</mml:mi></mml:mrow></mml:mfenced></mml:math><inline-graphic xlink:href="12859_2021_4499_Article_IEq6.gif"/></alternatives></inline-formula> as input. <italic>F</italic> is set to 160, representing the 160-dimensional vector produced from the CNN module. <italic>T</italic> is the time step of the BRNN module, and each time step includes a hidden representation of one feature matrix. These matrices for each time step must satisfy backward and forward relations in the read alignment. In the BRNN module, we use two BLSTM layers, where each layer includes 64 LSTM units and is able to capture both the forward and reverse information about the input feature vector. The value of an LSTM cell can be calculated recursively using the following formulas.<disp-formula id="Equ3"><label>3</label><alternatives><tex-math id="M17">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$I_{t} = sigmoid\left( {W_{I} x_{t} + U_{I} h_{t - 1} + b_{I} } \right)$$\end{document}</tex-math><mml:math id="M18" display="block"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>g</mml:mi><mml:mi>m</mml:mi><mml:mi>o</mml:mi><mml:mi>i</mml:mi><mml:mi>d</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mi>I</mml:mi></mml:msub><mml:msub><mml:mi>x</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>U</mml:mi><mml:mi>I</mml:mi></mml:msub><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mi>I</mml:mi></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:math><graphic xlink:href="12859_2021_4499_Article_Equ3.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ4"><label>4</label><alternatives><tex-math id="M19">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$F_{t} = sigmoid\left( {W_{f} x_{t} + U_{f} h_{t - 1} + b_{f} } \right)$$\end{document}</tex-math><mml:math id="M20" display="block"><mml:mrow><mml:msub><mml:mi>F</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>g</mml:mi><mml:mi>m</mml:mi><mml:mi>o</mml:mi><mml:mi>i</mml:mi><mml:mi>d</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mi>f</mml:mi></mml:msub><mml:msub><mml:mi>x</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>U</mml:mi><mml:mi>f</mml:mi></mml:msub><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mi>f</mml:mi></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:math><graphic xlink:href="12859_2021_4499_Article_Equ4.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ5"><label>5</label><alternatives><tex-math id="M21">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$O_{t} = sigmoid\left( {W_{O} x_{t} + U_{O} h_{t - 1} + b_{O} } \right)$$\end{document}</tex-math><mml:math id="M22" display="block"><mml:mrow><mml:msub><mml:mi>O</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>g</mml:mi><mml:mi>m</mml:mi><mml:mi>o</mml:mi><mml:mi>i</mml:mi><mml:mi>d</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mi>O</mml:mi></mml:msub><mml:msub><mml:mi>x</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>U</mml:mi><mml:mi>O</mml:mi></mml:msub><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mi>O</mml:mi></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:math><graphic xlink:href="12859_2021_4499_Article_Equ5.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ6"><label>6</label><alternatives><tex-math id="M23">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$C_{t} = F_{t} C_{t - 1} + I_{t} \odot {\text{tanh}}\left( {W_{C} x_{t} + U_{C} h_{t - 1} + b_{C} } \right)$$\end{document}</tex-math><mml:math id="M24" display="block"><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>F</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>⊙</mml:mo><mml:mtext>tanh</mml:mtext><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mi>C</mml:mi></mml:msub><mml:msub><mml:mi>x</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>U</mml:mi><mml:mi>C</mml:mi></mml:msub><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mi>C</mml:mi></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:math><graphic xlink:href="12859_2021_4499_Article_Equ6.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ7"><label>7</label><alternatives><tex-math id="M25">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$h_{t} = O_{t} \odot tanh\left( {C_{t} } \right)$$\end{document}</tex-math><mml:math id="M26" display="block"><mml:mrow><mml:msub><mml:mi>h</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>O</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>⊙</mml:mo><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>h</mml:mi><mml:mfenced close=")" open="("><mml:msub><mml:mi>C</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:math><graphic xlink:href="12859_2021_4499_Article_Equ7.gif" position="anchor"/></alternatives></disp-formula><inline-formula id="IEq7"><alternatives><tex-math id="M27">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$I,F,O$$\end{document}</tex-math><mml:math id="M28"><mml:mrow><mml:mi>I</mml:mi><mml:mo>,</mml:mo><mml:mi>F</mml:mi><mml:mo>,</mml:mo><mml:mi>O</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="12859_2021_4499_Article_IEq7.gif"/></alternatives></inline-formula> represent the activation vectors of the input gate, forget gate and output gates, respectively. <inline-formula id="IEq8"><alternatives><tex-math id="M29">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$C$$\end{document}</tex-math><mml:math id="M30"><mml:mi>C</mml:mi></mml:math><inline-graphic xlink:href="12859_2021_4499_Article_IEq8.gif"/></alternatives></inline-formula> represents the state vector of the cell. <inline-formula id="IEq9"><alternatives><tex-math id="M31">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$W, U, b$$\end{document}</tex-math><mml:math id="M32"><mml:mrow><mml:mi>W</mml:mi><mml:mo>,</mml:mo><mml:mi>U</mml:mi><mml:mo>,</mml:mo><mml:mi>b</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="12859_2021_4499_Article_IEq9.gif"/></alternatives></inline-formula> are the parameters of the LSTM cell.<inline-formula id="IEq10"><alternatives><tex-math id="M33">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$x,h$$\end{document}</tex-math><mml:math id="M34"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>h</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="12859_2021_4499_Article_IEq10.gif"/></alternatives></inline-formula> are the input and output vectors of the LSTM cell, respectively. The output vector of an LSTM cell depends on the current input vector, the output vector of the hidden layer at the previous time step and the information stored in the LSTM cell.</p>
    </sec>
    <sec id="Sec6">
      <title>Classification module</title>
      <p id="Par25">The classification module uses two fully connected layers to classify the vectors output by the BRNN module. Dropout is used after each fully connected layer to improve the generality of the network. Finally, a sigmoid function is used to calculate the output values of the fully connected layers. If the final output is greater than 0.5, the related subregion is a deletion; otherwise, this subregion is not a deletion.</p>
    </sec>
    <sec id="Sec7">
      <title>Breakpoint estimation</title>
      <p id="Par26">For a deletion whose size is larger than the window size, the deletion will present in multiple subregions and corresponds to multiple feature matrices. Then these adjacent sub-regions will be merged as a large region which refers to a large deletion.</p>
      <p id="Par27">Next, for each region which is determined as a deletion, BreakNet will assign a more precise deletion location and size. For a long read which is aligned in this region, BreakNet extracts its’ deletion location and size from CIGAR string if its’ deletion size is larger than 20 bp. After processing all these long reads, BreakNet can get a deletion set {(<italic>L</italic><sub><italic>1</italic></sub><italic>, S</italic><sub><italic>1</italic></sub>), (<italic>L</italic><sub><italic>2</italic></sub><italic>, S</italic><sub><italic>2</italic></sub>), … (<italic>L</italic><sub><italic>t</italic></sub><italic>, S</italic><sub><italic>t</italic></sub>)}, <italic>L</italic><sub><italic>i</italic></sub> and <italic>S</italic><sub><italic>i</italic></sub> separately represent the location and size of <italic>i</italic>-th deletion information from CIGAR strings. Then, BreakNet will classify (<italic>L</italic><sub><italic>i</italic></sub><italic>, S</italic><sub><italic>i</italic></sub>) and (<italic>L</italic><sub><italic>j</italic></sub><italic>, S</italic><sub><italic>j</italic></sub>) into the same cluster, if |<italic>L</italic><sub><italic>i</italic></sub><italic> – L</italic><sub><italic>j</italic></sub>| &lt; 40. After iteratively processing all elements in the deletion set, BreakNet selects the cluster which contains the most elements. And BreakNet calculates the average location and size of all elements in the cluster, which are the final location and size of the deletion about the region.</p>
    </sec>
    <sec id="Sec8">
      <title>Model training</title>
      <p id="Par28">Through the high-confidence call set of one sample, we determine the real deletion regions in the sample. Then, we label the subregions that overlap with the real deletion as 1, while the rest are labelled as 0. The model learns its parameters by minimizing a loss function.</p>
      <p id="Par29">However, the high-confidence call set used in this study has two key features. One is that the information provided in the call set may not be comprehensive, and some of the variances are not provided in this call set. Second, the information provided in the call set is relatively accurate, and there are few false positives. Therefore, based on the above characteristics, we design a new loss function to satisfy the following requirements. First, if a deletion predicted by the model is not provided by the high-confidence call set, the loss function should produce a smaller loss value and gradient. Second, if a deletion is provided by the high-confidence call set and not detected by this model, the loss function should yield a larger loss value and gradient.<disp-formula id="Equ8"><label>8</label><alternatives><tex-math id="M35">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\ln \left( {prediction - label + 1 + a} \right)^{2}$$\end{document}</tex-math><mml:math id="M36" display="block"><mml:mrow><mml:mo>ln</mml:mo><mml:msup><mml:mfenced close=")" open="("><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo>-</mml:mo><mml:mi>l</mml:mi><mml:mi>a</mml:mi><mml:mi>b</mml:mi><mml:mi>e</mml:mi><mml:mi>l</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>a</mml:mi></mml:mrow></mml:mfenced><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math><graphic xlink:href="12859_2021_4499_Article_Equ8.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq11"><alternatives><tex-math id="M37">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$prediction$$\end{document}</tex-math><mml:math id="M38"><mml:mrow><mml:mi mathvariant="italic">prediction</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="12859_2021_4499_Article_IEq11.gif"/></alternatives></inline-formula> is the output value of the model,<inline-formula id="IEq12"><alternatives><tex-math id="M39">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$label$$\end{document}</tex-math><mml:math id="M40"><mml:mrow><mml:mi mathvariant="italic">label</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="12859_2021_4499_Article_IEq12.gif"/></alternatives></inline-formula> is the label of the input data point and <inline-formula id="IEq13"><alternatives><tex-math id="M41">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$a$$\end{document}</tex-math><mml:math id="M42"><mml:mi>a</mml:mi></mml:math><inline-graphic xlink:href="12859_2021_4499_Article_IEq13.gif"/></alternatives></inline-formula> is a hypermeter used to adjust the maximum output value of this loss function. We set <inline-formula id="IEq14"><alternatives><tex-math id="M43">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$a$$\end{document}</tex-math><mml:math id="M44"><mml:mi>a</mml:mi></mml:math><inline-graphic xlink:href="12859_2021_4499_Article_IEq14.gif"/></alternatives></inline-formula> to 0.001 in this paper.</p>
      <p id="Par30">Because deletions are usually rare, ~ 99% of the training samples are negative. To ensure that sufficient positive samples are included at each training step, we first adequately shuffle the training data and use a large batch size. We use the Adam optimizer for training and set the learning rate to 0.001.</p>
      <p id="Par31">Two techniques are employed to prevent overfitting during the model training process. First, we add dropout layers to each fully connected layer and set the dropout probability to 0.4. Second, we use the early stopping technique during training. By examining the performance of the model on the validation set, we save the parameters with the best performance. Additionally, if the model does not perform better after 10 epochs, we stop the training process and save the best model parameters as the final model.</p>
      <p id="Par32">We use TensorFlow 2.4 to implement the CNN, BRNN, and classification modules.</p>
    </sec>
  </sec>
  <sec id="Sec9">
    <title>Results</title>
    <sec id="Sec10">
      <title>Data set</title>
      <p id="Par33">In this paper we used several read alignment files from four well studied individuals, HG002, HG00514, HG00733 and NA19240. The details of these datasets are shown in Table <xref rid="Tab1" ref-type="table">1</xref>.<table-wrap id="Tab1"><label>Table 1</label><caption><p>The detail of datasets</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left"/><th align="left">HG002 CLR</th><th align="left">HG002 CCS</th><th align="left">HG00514</th><th align="left">HG00733</th><th align="left">NA19240</th></tr></thead><tbody><tr><td align="left">Read count</td><td align="left">29,157,344</td><td align="left">6,596,012</td><td align="left">12,430,587</td><td align="left">13,521,896</td><td align="left">20,452,822</td></tr><tr><td align="left">Average length</td><td align="left">7937</td><td align="left">13,478</td><td align="left">11,800</td><td align="left">12,295</td><td align="left">6503</td></tr><tr><td align="left">Coverage</td><td align="left">69X</td><td align="left">28X</td><td align="left">42X</td><td align="left">45X</td><td align="left">39X</td></tr><tr><td align="left">Aligner</td><td align="left">NGMLR</td><td align="left">PBMM2</td><td align="left">BWA</td><td align="left">BWA</td><td align="left">BWA</td></tr></tbody></table></table-wrap></p>
      <p id="Par34">We benchmarked BreakNet, SVIM (v2.0.0), cuteSV (v1.0.6) and Sniffles (v1.0.12a) with several real sequencing datasets. Four PacBio datasets (HG002 CLR, HG002 CCS, HG00514 CLR, and HG00733 CLR) were used. The support read parameters of the SVIM, cuteSV and Sniffles were set to 10/4/4/3 and 3/2 for the HG002 CLR 69X, 35X, 20X, and 10X datasets and the HG002 CCS 28X and 10X datasets, respectively. For the HG00514 and HG00733 data, we set the support read parameters of Sniffles, cuteSV, and the SVIM to 3/2/1. Deletion sizes smaller than 50 bp were removed. Truvari (v2.0.1) was used to obtain the evaluation metrics (precision, recall, and F1 score) and assess the performance of the different deletion callers.</p>
      <p id="Par35">For the HG00514 and HG00733 samples, we collected a call set from a previous study [<xref ref-type="bibr" rid="CR24">24</xref>] and considered it the ground truth. For the HG002 dataset, two deletion call sets, Tier 1 and Tier 2, for this sample (made by the Genome in a Bottle Consortium (GIAB)) were used. According to the GIAB [<xref ref-type="bibr" rid="CR25">25</xref>], the Tier 1 region should include 100% true deletions, and we used the Tier 1 region to assess the precision, recall and F1 score of each caller. The Tier 2 regions were defined as additional regions in which there was strong evidence regarding the presence of an SV, but the corresponding sequence and size could not be determined with confidence [<xref ref-type="bibr" rid="CR25">25</xref>]. This may be useful for benchmarking a tool’s ability to detect more challenging SVs’. The results of the performance comparison for the HG002 Tier 2 region are provided in the supplementary materials. Note that, GIAB released high quality result (~ 90%) comes from PBSV. To be fair, the callers are not compared with PBSV.</p>
    </sec>
    <sec id="Sec11">
      <title>Data partition for BreakNet</title>
      <p id="Par36">We partition the dataset into a training set, test set and validation set. The read alignments of chromosomes 1–10 from the HG002 PacBio Continuous Long Reads (CLR), HG002 PacBio Circular Consensus Sequencing (CCS) and NA19240 PacBio CLR data are used as the training set. The read alignment files of HG002 and NA19240 are generated by the NGMLR aligner, pbmm2 aligner and Burrows-Wheeler aligner (BWA). By training the model using the data produced by different aligners, the model can adapt to the varying characteristics of the different alignment tools. The validation set is used to provide an unbiased estimate of the model's performance, and this set is not directly involved in the training process. By analysing the performance of the model on the validation set and tuning the hyperparameters during training, the validation set can help to improve the performance of the model and prevent overfitting. In this paper, the read alignments of chromosome 11 from HG002 and NA19240 are used as the validation set.</p>
      <p id="Par37">For the test set, we use the read alignments of chromosomes 12–22 from the HG002 CCS and CLR data and the read alignments of chromosomes 1–22 from the HG00514 and HG00733 data as the test set. The read alignments of HG002 CLR and HG002 CCS and HG00514 and HG00733 are produced by the NGMLR, pbmm2 and BWA aligners, respectively.</p>
    </sec>
    <sec id="Sec12">
      <title>SV detection results on the HG002 dataset</title>
      <p id="Par38">We benchmarked BreakNet, cuteSV, the SVIM and Sniffles on the HG002 CLR 69X chromosome 12–22 data. The SVIM achieved the highest F1 scores and recall on the Tier 1 region. On the more challenging Tier 2 region, BreakNet outperformed the other callers in terms of recall by 3–4%. Furthermore, we randomly downsampled the HG002 chromosome 12–22 data to 10 × , 20 × , and 35 × to assess the capabilities of the SV callers on low-coverage datasets. As shown in Table <xref rid="Tab2" ref-type="table">2</xref>, BreakNet achieved higher F1 scores on the 10X and 20X downsampled Tier 1 regions. This demonstrated that BreakNet is a better option for cost-sensitive sequencing plans (low coverage). For the low-coverage Tier 2 region, the highest sensitivity was obtained by BreakNet with respect to more challenge deletions.<table-wrap id="Tab2"><label>Table 2</label><caption><p>Performance comparison of SV caller on HG002 data</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left"/><th align="left">Coverage</th><th align="left"/><th align="left">BreakNet</th><th align="left">SVIM</th><th align="left">cuteSV</th><th align="left">SNIFFLES</th></tr></thead><tbody><tr><td align="left">CLR</td><td align="left">69X</td><td align="left">Precision</td><td char="." align="char">0.9704</td><td char="." align="char">0.9678</td><td char="." align="char"><bold>0.9707</bold></td><td char="." align="char">0.9604</td></tr><tr><td align="left"/><td align="left"/><td align="left">Recalll</td><td char="." align="char">0.9169</td><td char="." align="char"><bold>0.9341</bold></td><td char="." align="char">0.9282</td><td char="." align="char">0.9224</td></tr><tr><td align="left"/><td align="left"/><td align="left">F1</td><td char="." align="char">0.9429</td><td char="." align="char"><bold>0.9507</bold></td><td char="." align="char">0.9492</td><td char="." align="char">0.9410</td></tr><tr><td align="left"/><td align="left">35X</td><td align="left">Precision</td><td char="." align="char">0.9469</td><td char="." align="char">0.9653</td><td char="." align="char"><bold>0.9775</bold></td><td char="." align="char">0.9556</td></tr><tr><td align="left"/><td align="left"/><td align="left">Recall</td><td char="." align="char">0.9169</td><td char="." align="char">0.9292</td><td char="." align="char">0.8955</td><td char="." align="char">0.9160</td></tr><tr><td align="left"/><td align="left"/><td align="left">F1</td><td char="." align="char">0.9316</td><td char="." align="char"><bold>0.9468</bold></td><td char="." align="char">0.9351</td><td char="." align="char">0.9355</td></tr><tr><td align="left"/><td align="left">20X</td><td align="left">Precision</td><td char="." align="char">0.9524</td><td char="." align="char"><bold>0.9722</bold></td><td char="." align="char">0.9790</td><td char="." align="char">0.9720</td></tr><tr><td align="left"/><td align="left"/><td align="left">Recall</td><td char="." align="char"><bold>0.8776</bold></td><td char="." align="char">0.8389</td><td char="." align="char">0.8203</td><td char="." align="char">0.7983</td></tr><tr><td align="left"/><td align="left"/><td align="left">F1</td><td char="." align="char"><bold>0.9135</bold></td><td char="." align="char">0.9004</td><td char="." align="char">0.8926</td><td char="." align="char">0.8770</td></tr><tr><td align="left"/><td align="left">10X</td><td align="left">Precision</td><td char="." align="char">0.9213</td><td char="." align="char"><bold>0.9790</bold></td><td char="." align="char">0.9819</td><td char="." align="char">0.9785</td></tr><tr><td align="left"/><td align="left"/><td align="left">Recall</td><td char="." align="char"><bold>0.8134</bold></td><td char="." align="char">0.6704</td><td char="." align="char">0.6646</td><td char="." align="char">0.6470</td></tr><tr><td align="left"/><td align="left"/><td align="left">F1</td><td char="." align="char"><bold>0.8640</bold></td><td char="." align="char">0.7959</td><td char="." align="char">0.7925</td><td char="." align="char">0.7790</td></tr><tr><td align="left">CCS</td><td align="left">28X</td><td align="left">Precision</td><td char="." align="char">0.9552</td><td char="." align="char"><bold>0.9400</bold></td><td char="." align="char">0.9492</td><td char="." align="char">0.9020</td></tr><tr><td align="left"/><td align="left"/><td align="left">Recall</td><td char="." align="char">0.9350</td><td char="." align="char">0.9430</td><td char="." align="char">0.9336</td><td char="." align="char">0.8325</td></tr><tr><td align="left"/><td align="left"/><td align="left">F1</td><td char="." align="char"><bold>0.9450</bold></td><td char="." align="char">0.9415</td><td char="." align="char">0.9414</td><td char="." align="char">0.8657</td></tr><tr><td align="left"/><td align="left">10X</td><td align="left">Precision</td><td char="." align="char">0.9424</td><td char="." align="char"><bold>0.9360</bold></td><td char="." align="char">0.9609</td><td char="." align="char">0.9110</td></tr><tr><td align="left"/><td align="left"/><td align="left">Recall</td><td char="." align="char">0.9282</td><td char="." align="char">0.8940</td><td char="." align="char">0.8398</td><td char="." align="char">0.6357</td></tr><tr><td align="left"/><td align="left"/><td align="left">F1</td><td char="." align="char"><bold>0.9353</bold></td><td char="." align="char">0.9146</td><td char="." align="char">0.8965</td><td char="." align="char">0.7490</td></tr></tbody></table><table-wrap-foot><p>Bold values represent best results</p></table-wrap-foot></table-wrap></p>
      <p id="Par39">For PacBio CCS chromosomes 12–22 in the 28X Tier 1 region, BreakNet achieved better F1 scores, which were 0.35% higher than those of the runner-up method (the SVIM). Furthermore, we randomly downsampled this dataset to 10 × and evaluated the compared callers. BreakNet achieved the highest F1 scores and lowest performance loss (~ 1% vs. ~ 3 ~ 11%) in comparison with to the other callers. The results of the performance comparison among the various callers for the Tier 2 region are provided in the supplementary materials (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Table S1).</p>
    </sec>
    <sec id="Sec13">
      <title>SV detection results on the HG00514 and HG00733 datasets</title>
      <p id="Par40">We used two other PacBio CLR datasets from two well-studied human samples (HG00514 and HG00733) to benchmark the compared SV callers. BreakNet simultaneously achieved the highest precision, recall and F1 scores on these two datasets, as shown in Table <xref rid="Tab3" ref-type="table">3</xref>. Compared to the runner-up method (Sniffles), BreakNet achieved performance improvements of ~ 4–6% in terms of the F1 scores; this was mainly due to the higher sensitivity of BreakNet. Sniffles achieved better performance than to cuteSV and the SVIM with respect to the precision and F1 scores. Furthermore, we randomly downsampled these two datasets to 24X/21X and 10X and analysed the performance of various callers on the corresponding low-coverage datasets. BreakNet achieved the best performance on these datasets in terms of the recall and F1 score metrics. Sniffles attained the best overall precision on these four downsampled datasets.<table-wrap id="Tab3"><label>Table 3</label><caption><p>Performance comparison of SV caller on HG00514 and HG00733 data</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left"/><th align="left"/><th align="left"/><th align="left">BreakNet</th><th align="left">Sniffles</th><th align="left">cuteSV</th><th align="left">SVIM</th></tr></thead><tbody><tr><td align="left">HG00514</td><td align="left">42X</td><td align="left">Precision</td><td char="." align="char"><bold>0.7197</bold></td><td char="." align="char">0.6772</td><td char="." align="char">0.4539</td><td char="." align="char">0.5547</td></tr><tr><td align="left"/><td align="left"/><td align="left">Recall</td><td char="." align="char"><bold>0.351</bold></td><td char="." align="char">0.3137</td><td char="." align="char">0.3286</td><td char="." align="char">0.2261</td></tr><tr><td align="left"/><td align="left"/><td align="left">F1</td><td char="." align="char"><bold>0.4721</bold></td><td char="." align="char">0.4290</td><td char="." align="char">0.3811</td><td char="." align="char">0.3213</td></tr><tr><td align="left"/><td align="left">21X</td><td align="left">Precision</td><td char="." align="char">0.5900</td><td char="." align="char"><bold>0.7358</bold></td><td char="." align="char">0.4660</td><td char="." align="char">0.4407</td></tr><tr><td align="left"/><td align="left"/><td align="left">Recall</td><td char="." align="char">0.2624</td><td char="." align="char">0.2898</td><td char="." align="char"><bold>0.3442</bold></td><td char="." align="char">0.1632</td></tr><tr><td align="left"/><td align="left"/><td align="left">F1</td><td char="." align="char">0.3633</td><td char="." align="char"><bold>0.4158</bold></td><td char="." align="char">0.3960</td><td char="." align="char">0.2382</td></tr><tr><td align="left"/><td align="left">10X</td><td align="left">Precision</td><td char="." align="char">0.5552</td><td char="." align="char"><bold>0.5986</bold></td><td char="." align="char">0.5562</td><td char="." align="char">0.2593</td></tr><tr><td align="left"/><td align="left"/><td align="left">Recall</td><td char="." align="char"><bold>0.3310</bold></td><td char="." align="char">0.2585</td><td char="." align="char">0.3013</td><td char="." align="char">0.3003</td></tr><tr><td align="left"/><td align="left"/><td align="left">F1</td><td char="." align="char"><bold>0.4147</bold></td><td char="." align="char">0.3611</td><td char="." align="char">0.3909</td><td char="." align="char">0.2783</td></tr><tr><td align="left">HG00733</td><td align="left">48X</td><td align="left">Precision</td><td char="." align="char"><bold>0.7160</bold></td><td char="." align="char">0.6528</td><td char="." align="char">0.4834</td><td char="." align="char">0.5166</td></tr><tr><td align="left"/><td align="left"/><td align="left">Recall</td><td char="." align="char"><bold>0.3578</bold></td><td char="." align="char">0.3076</td><td char="." align="char">0.2932</td><td char="." align="char">0.2277</td></tr><tr><td align="left"/><td align="left"/><td align="left">F1</td><td char="." align="char"><bold>0.4772</bold></td><td char="." align="char">0.4182</td><td char="." align="char">0.3650</td><td char="." align="char">0.3162</td></tr><tr><td align="left"/><td align="left">24X</td><td align="left">Precision</td><td char="." align="char"><bold>0.7598</bold></td><td char="." align="char">0.7197</td><td char="." align="char">0.4250</td><td char="." align="char">0.5981</td></tr><tr><td align="left"/><td align="left"/><td align="left">Recall</td><td char="." align="char"><bold>0.3386</bold></td><td char="." align="char">0.2832</td><td char="." align="char">0.3379</td><td char="." align="char">0.2218</td></tr><tr><td align="left"/><td align="left"/><td align="left">F1</td><td char="." align="char"><bold>0.4685</bold></td><td char="." align="char">0.4065</td><td char="." align="char">0.3765</td><td char="." align="char">0.3235</td></tr><tr><td align="left"/><td align="left">10X</td><td align="left">Precision</td><td char="." align="char">0.5444</td><td char="." align="char"><bold>0.6440</bold></td><td char="." align="char">0.5117</td><td char="." align="char">0.2361</td></tr><tr><td align="left"/><td align="left"/><td align="left">Recall</td><td char="." align="char"><bold>0.3364</bold></td><td char="." align="char">0.2510</td><td char="." align="char">0.2959</td><td char="." align="char">0.3147</td></tr><tr><td align="left"/><td align="left"/><td align="left">F1</td><td char="." align="char"><bold>0.4158</bold></td><td char="." align="char">0.3611</td><td char="." align="char">0.375</td><td char="." align="char">0.2700</td></tr></tbody></table><table-wrap-foot><p>Bold values represent best results</p></table-wrap-foot></table-wrap></p>
    </sec>
    <sec id="Sec14">
      <title>Window size and deletion size</title>
      <p id="Par41">For verifying the influence of the widow size on the detection results, we separately set the widow size to 50 bp, 100 bp, 200 bp, 400 bp, 800 bp and run BreadNet. The HG002 CLR 69X chromosome 1 and chromosome 2 are used to generate training and test data separately. The training and test results are shown in the supplementary materials (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Fig. S1).</p>
      <p id="Par42">Considering the performance of each caller with different deletion sizes, BreakNet also can achieve better performance for deletion sizes below 4000 bp, especially on the low-coverage data. The results of the performance comparison among the various callers with different deletion sizes are provided in the supplementary materials (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Fig. S2).</p>
    </sec>
    <sec id="Sec15">
      <title>Loss function</title>
      <p id="Par43">To verify the effectiveness of our proposed loss function, we trained BreakNet with the new loss function (Formula <xref rid="Equ8" ref-type="">8</xref>) and the log loss function. Training the model with the new loss function was faster and yielded a higher area under the receiver operating characteristic curve (AUC) during each training epoch. As shown in Fig. <xref rid="Fig2" ref-type="fig">2</xref>, the new loss function used only five training epochs and achieved better AUC values than those output by the log loss function with ten training epochs (0.848 vs. 0.828). Because the training data involved a class-imbalanced dataset, the new loss function produced larger gradients for data that were incorrectly predicted to be negative and helped the model complete training faster. Simultaneously, the large gradients produced by the new loss function also reduced the impact of incorrectly labelled data on model training.<fig id="Fig2"><label>Fig. 2</label><caption><p>Effect of using new loss and log loss functions on the AUC values of the model training</p></caption><graphic xlink:href="12859_2021_4499_Fig2_HTML" id="MO2"/></fig></p>
    </sec>
    <sec id="Sec16">
      <title>Running time and peak memory</title>
      <p id="Par44">We perform all callers on a PC with a 64-core, 128-thread CPU (AMD Ryzen Threadripper 3990X @4.8 GHz). We use a single RTX 3090 video card to train the model. The running time and peak memory usage of BreakNet on HG002 are provided in the supplementary materials (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Table S2 and Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Table S3). As shown in Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Table S2 and Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Table S3, the efficiency of BreakNet has a poor performance. BreakNet needs to generate lots of feature matrices, which consumes more resource. Note that, the training time of BreakNet is time consuming (~ 30 days). We supply the module that has been trained for users. And the users only need generate the feature matrices and could apply the trained module to obtain the detection results. In Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Table S2, we ignore the training time. For the same species, no matter the sequencing coverage, the number of feature matrices is the same for BreakNet. Hence, the peak memory usage of BreakNet varies little.</p>
    </sec>
  </sec>
  <sec id="Sec17">
    <title>Discussion</title>
    <p id="Par45">Long-read sequencing technologies are promising for discovering SVs. Due to the high sequencing errors and the complexity of SVs, it is still nontrivial to fully take advantage of long-read technologies. In this study, we developed BreakNet to detect deletions based on a deep learning method and long reads. We tested BreakNet on several well-studied datasets, and it could achieve better performance than three other SV callers. However, long-read sequencing still incurs a greater computational cost than short-read sequencing when the same coverage is required. Previously developed methods require high data coverage to detect sensitive call deletions, and low-coverage data have a great impact on sensitivity. BreakNet achieved more stable performance than the other approaches on low-coverage data, especially on the HG002 CLR 10X dataset. BreakNet outperformed the runner-up method (the SVIM) by 6%.</p>
    <p id="Par46">In this paper, we only took deletions into consideration, but other types of variations, such as insertions, inversions, and copy number variations, play important roles in human health. We will examine the calling of other types of SVs in future work.</p>
  </sec>
  <sec id="Sec18">
    <title>Conclusions</title>
    <p id="Par47">In this paper, we present BreakNet, which is a deletion detection method that utilizes long reads and deep learning. Compared to state-of-the-art SV callers, BreakNet yields better F1 scores on most datasets and provides better sensitivity and F1 scores on low-coverage data. Limited by the features extracted by BreakNet, only deletions can be efficiently detected. The extraction of more features to call other types of SVs will be investigated in our future work.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Information</title>
    <sec id="Sec19">
      <p>
        <supplementary-material content-type="local-data" id="MOESM1">
          <media xlink:href="12859_2021_4499_MOESM1_ESM.doc">
            <caption>
              <p>
                <bold>Additional file 1.</bold>
              </p>
            </caption>
          </media>
        </supplementary-material>
      </p>
    </sec>
  </sec>
</body>
<back>
  <glossary>
    <title>Abbreviations</title>
    <def-list>
      <def-item>
        <term>BAM</term>
        <def>
          <p id="Par4">Binary sequence alignment</p>
        </def>
      </def-item>
      <def-item>
        <term>CNN</term>
        <def>
          <p id="Par5">Convolutional neural network</p>
        </def>
      </def-item>
      <def-item>
        <term>BRNN</term>
        <def>
          <p id="Par6">Bidirectional recurrent neural networks</p>
        </def>
      </def-item>
      <def-item>
        <term>SNPs</term>
        <def>
          <p id="Par7">Single nucleotide polymorphisms</p>
        </def>
      </def-item>
      <def-item>
        <term>INDELs</term>
        <def>
          <p id="Par8">Small insertion and/or deletion</p>
        </def>
      </def-item>
      <def-item>
        <term>SVs</term>
        <def>
          <p id="Par9">Structural variations</p>
        </def>
      </def-item>
    </def-list>
  </glossary>
  <fn-group>
    <fn>
      <p>
        <bold>Publisher's Note</bold>
      </p>
      <p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
    </fn>
  </fn-group>
  <ack>
    <title>Acknowledgements</title>
    <p>Not applicable.</p>
  </ack>
  <notes notes-type="author-contribution">
    <title>Authors' contributions</title>
    <p>JL, HD, and JS participated in the design of the study and the analysis of the experimental results. HD, HZ and ZW performed the implementation. HL and CY prepared the tables and figures. The authors read and approved the final manuscript.</p>
  </notes>
  <notes notes-type="funding-information">
    <title>Funding</title>
    <p>This work has been supported in part by the National Natural Science Foundation of China under Grant Nos. 61972134, 61602156, 61802113, Henan Provincial Department of Science and Technology Research Project under Grant Nos. 192102210118, 182102310946, Young Elite Teachers in Henan Province No. 2020GGJS050, Doctor Foundation of Henan Polytechnic University under Grant No. B2018-36.</p>
  </notes>
  <notes notes-type="data-availability">
    <title>Availability of data and materials</title>
    <p>The HG002 data can be downloaded from https:// ftp.ncbi.nih.gov/giab/ftp/data/AshkenazimTrio. The high confidence callset and the high confidence regions of HG002 were provided by GIAB and downloaded from <ext-link ext-link-type="uri" xlink:href="https://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/analysis/NISTSVsIntegrationv0.6/HG002SVsTier1v0.6.vcf.gz">https://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/analysis/NISTSVsIntegrationv0.6/HG002SVsTier1v0.6.vcf.gz</ext-link>, <ext-link ext-link-type="uri" xlink:href="https://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/analysis">https://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/analysis</ext-link>/NIST SVs Integrationv0.6/HG002SVs Tier1v0.6.bed. The alignment files of samples HG00514, HG00733 and NA19240 can be downloaded from <ext-link ext-link-type="uri" xlink:href="ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/datacollections/hgsvsvdiscovery/working/20160905smithmpacbioaligns/">ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/datacollections/hgsvsvdiscovery/working/20160905smithmpacbioaligns/</ext-link>. The high confidence callset for these three indi- viduals are collected from previous study [<xref ref-type="bibr" rid="CR22">22</xref>], and download from NCBI dbVAR: <ext-link ext-link-type="uri" xlink:href="ftp://ftp.ncbi.nlm.nih.gov/pub/dbVar/data/Homosapiens/bystudy/vcf/n-std152.GRCh37.variantcall.vcf.gz">ftp://ftp.ncbi.nlm.nih.gov/pub/dbVar/data/Homosapiens/bystudy/vcf/n-std152.GRCh37.variantcall.vcf.gz</ext-link>. The software and sample result as part of this project are readily avail- able from GitHub at <ext-link ext-link-type="uri" xlink:href="https://github.com/luojunwei/BreakNet">https://github.com/luojunwei/BreakNet</ext-link>.</p>
  </notes>
  <notes>
    <title>Declarations</title>
    <notes id="FPar1">
      <title>Ethics approval and consent to participate</title>
      <p id="Par48">Not applicable.</p>
    </notes>
    <notes id="FPar2">
      <title>Consent for publication</title>
      <p id="Par49">Not applicable.</p>
    </notes>
    <notes id="FPar3" notes-type="COI-statement">
      <title>Competing interests</title>
      <p id="Par50">The authors declare that they have no competing interests.</p>
    </notes>
  </notes>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <label>1.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Sudmant</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Rausch</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Gardner</surname>
            <given-names>E</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>An integrated map of structural variation in 2,504 human genomes</article-title>
        <source>Nature</source>
        <year>2015</year>
        <volume>526</volume>
        <fpage>75</fpage>
        <lpage>81</lpage>
        <pub-id pub-id-type="doi">10.1038/nature15394</pub-id>
        <?supplied-pmid 26432246?>
        <pub-id pub-id-type="pmid">26432246</pub-id>
      </element-citation>
    </ref>
    <ref id="CR2">
      <label>2.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Redon</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Ishikawa</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Fitch</surname>
            <given-names>K</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Global variation in copy number in the human genome</article-title>
        <source>Nature</source>
        <year>2006</year>
        <volume>444</volume>
        <fpage>444</fpage>
        <lpage>454</lpage>
        <pub-id pub-id-type="doi">10.1038/nature05329</pub-id>
        <?supplied-pmid 17122850?>
        <pub-id pub-id-type="pmid">17122850</pub-id>
      </element-citation>
    </ref>
    <ref id="CR3">
      <label>3.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Weiss</surname>
            <given-names>LA</given-names>
          </name>
          <name>
            <surname>Shen</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Korn</surname>
            <given-names>JM</given-names>
          </name>
          <name>
            <surname>Arking</surname>
            <given-names>DE</given-names>
          </name>
          <name>
            <surname>Miller</surname>
            <given-names>DT</given-names>
          </name>
          <name>
            <surname>Fossdal</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Saemundsen</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Stefansson</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Ferreira</surname>
            <given-names>MA</given-names>
          </name>
          <name>
            <surname>Green</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Platt</surname>
            <given-names>OS</given-names>
          </name>
          <name>
            <surname>Ruderfer</surname>
            <given-names>DM</given-names>
          </name>
          <name>
            <surname>Walsh</surname>
            <given-names>CA</given-names>
          </name>
          <name>
            <surname>Altshuler</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Chakravarti</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Tanzi</surname>
            <given-names>RE</given-names>
          </name>
          <name>
            <surname>Stefansson</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Santangelo</surname>
            <given-names>SL</given-names>
          </name>
          <name>
            <surname>Gusella</surname>
            <given-names>JF</given-names>
          </name>
          <name>
            <surname>Sklar</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Wu</surname>
            <given-names>BL</given-names>
          </name>
          <name>
            <surname>Daly</surname>
            <given-names>MJ</given-names>
          </name>
          <collab>Autism Consortium</collab>
        </person-group>
        <article-title>Association between microdeletion and microduplication at 16p112 and autism</article-title>
        <source>N Engl J Med</source>
        <year>2008</year>
        <volume>358</volume>
        <issue>7</issue>
        <fpage>667</fpage>
        <lpage>675</lpage>
        <pub-id pub-id-type="doi">10.1056/NEJMoa075974</pub-id>
        <?supplied-pmid 18184952?>
        <pub-id pub-id-type="pmid">18184952</pub-id>
      </element-citation>
    </ref>
    <ref id="CR4">
      <label>4.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Stefansson</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Rujescu</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Cichon</surname>
            <given-names>S</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Large recurrent microdeletions associated with schizophrenia</article-title>
        <source>Nature</source>
        <year>2008</year>
        <volume>455</volume>
        <fpage>232</fpage>
        <lpage>236</lpage>
        <pub-id pub-id-type="doi">10.1038/nature07229</pub-id>
        <?supplied-pmid 18668039?>
        <pub-id pub-id-type="pmid">18668039</pub-id>
      </element-citation>
    </ref>
    <ref id="CR5">
      <label>5.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Mahmoud</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Gobet</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Cruz-Dávalos</surname>
            <given-names>DI</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Structural variant calling: the long and the short of it</article-title>
        <source>Genome Biol</source>
        <year>2019</year>
        <volume>20</volume>
        <fpage>246</fpage>
        <pub-id pub-id-type="doi">10.1186/s13059-019-1828-7</pub-id>
        <?supplied-pmid 31747936?>
        <pub-id pub-id-type="pmid">31747936</pub-id>
      </element-citation>
    </ref>
    <ref id="CR6">
      <label>6.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Alkan</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Coe</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Eichler</surname>
            <given-names>E</given-names>
          </name>
        </person-group>
        <article-title>Genome structural variation discovery and genotyping</article-title>
        <source>Nat Rev Genet</source>
        <year>2011</year>
        <volume>12</volume>
        <fpage>363</fpage>
        <lpage>376</lpage>
        <pub-id pub-id-type="doi">10.1038/nrg2958</pub-id>
        <?supplied-pmid 21358748?>
        <pub-id pub-id-type="pmid">21358748</pub-id>
      </element-citation>
    </ref>
    <ref id="CR7">
      <label>7.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Wallis</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>McLellan</surname>
            <given-names>M</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>BreakDancer: an algorithm for high-resolution mapping of genomic structural variation</article-title>
        <source>Nat Methods</source>
        <year>2009</year>
        <volume>6</volume>
        <fpage>677</fpage>
        <lpage>681</lpage>
        <pub-id pub-id-type="doi">10.1038/nmeth.1363</pub-id>
        <?supplied-pmid 19668202?>
        <pub-id pub-id-type="pmid">19668202</pub-id>
      </element-citation>
    </ref>
    <ref id="CR8">
      <label>8.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Rausch</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Zichner</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Schlattl</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Stütz</surname>
            <given-names>AM</given-names>
          </name>
          <name>
            <surname>Benes</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Korbel</surname>
            <given-names>JO</given-names>
          </name>
        </person-group>
        <article-title>DELLY: structural variant discovery by integrated paired-end and split-read analysis</article-title>
        <source>Bioinformatics</source>
        <year>2012</year>
        <volume>28</volume>
        <issue>18</issue>
        <fpage>i333</fpage>
        <lpage>i339</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/bts378</pub-id>
        <?supplied-pmid 22962449?>
        <pub-id pub-id-type="pmid">22962449</pub-id>
      </element-citation>
    </ref>
    <ref id="CR9">
      <label>9.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Layer</surname>
            <given-names>RM</given-names>
          </name>
          <name>
            <surname>Chiang</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Quinlan</surname>
            <given-names>AR</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>LUMPY: a probabilistic framework for structural variant discovery</article-title>
        <source>Genome Biol</source>
        <year>2014</year>
        <volume>15</volume>
        <fpage>R84</fpage>
        <pub-id pub-id-type="doi">10.1186/gb-2014-15-6-r84</pub-id>
        <?supplied-pmid 24970577?>
        <pub-id pub-id-type="pmid">24970577</pub-id>
      </element-citation>
    </ref>
    <ref id="CR10">
      <label>10.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hastings</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Lupski</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Rosenberg</surname>
            <given-names>S</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Mechanisms of change in gene copy number</article-title>
        <source>Nat Rev Genet</source>
        <year>2009</year>
        <volume>10</volume>
        <fpage>551</fpage>
        <lpage>564</lpage>
        <pub-id pub-id-type="doi">10.1038/nrg2593</pub-id>
        <?supplied-pmid 19597530?>
        <pub-id pub-id-type="pmid">19597530</pub-id>
      </element-citation>
    </ref>
    <ref id="CR11">
      <label>11.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chaisson</surname>
            <given-names>MJ</given-names>
          </name>
          <name>
            <surname>Tesler</surname>
            <given-names>G</given-names>
          </name>
        </person-group>
        <article-title>Mapping single molecule sequencing reads using basic local alignment with successive refinement (BLASR): application and theory</article-title>
        <source>BMC Bioinform</source>
        <year>2012</year>
        <volume>13</volume>
        <fpage>238</fpage>
        <pub-id pub-id-type="doi">10.1186/1471-2105-13-238</pub-id>
      </element-citation>
    </ref>
    <ref id="CR12">
      <label>12.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>English</surname>
            <given-names>AC</given-names>
          </name>
          <name>
            <surname>Salerno</surname>
            <given-names>WJ</given-names>
          </name>
          <name>
            <surname>Hampton</surname>
            <given-names>OA</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Assessing structural variation in a personal genome—towards a human reference diploid genome</article-title>
        <source>BMC Genomics</source>
        <year>2015</year>
        <volume>16</volume>
        <fpage>286</fpage>
        <pub-id pub-id-type="doi">10.1186/s12864-015-1479-3</pub-id>
        <?supplied-pmid 25886820?>
        <pub-id pub-id-type="pmid">25886820</pub-id>
      </element-citation>
    </ref>
    <ref id="CR13">
      <label>13.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Merker</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Wenger</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Sneddon</surname>
            <given-names>T</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Long-read genome sequencing identifies causal structural variation in a Mendelian disease</article-title>
        <source>Genet Med</source>
        <year>2018</year>
        <volume>20</volume>
        <fpage>159</fpage>
        <lpage>163</lpage>
        <pub-id pub-id-type="doi">10.1038/gim.2017.86</pub-id>
        <?supplied-pmid 28640241?>
        <pub-id pub-id-type="pmid">28640241</pub-id>
      </element-citation>
    </ref>
    <ref id="CR14">
      <label>14.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Sedlazeck</surname>
            <given-names>FJ</given-names>
          </name>
          <name>
            <surname>Rescheneder</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Smolka</surname>
            <given-names>M</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Accurate detection of complex structural variations using single-molecule sequencing</article-title>
        <source>Nat Methods</source>
        <year>2018</year>
        <volume>15</volume>
        <fpage>461</fpage>
        <lpage>468</lpage>
        <pub-id pub-id-type="doi">10.1038/s41592-018-0001-7</pub-id>
        <?supplied-pmid 29713083?>
        <pub-id pub-id-type="pmid">29713083</pub-id>
      </element-citation>
    </ref>
    <ref id="CR15">
      <label>15.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>English</surname>
            <given-names>AC</given-names>
          </name>
          <name>
            <surname>Salerno</surname>
            <given-names>WJ</given-names>
          </name>
          <name>
            <surname>Reid</surname>
            <given-names>JG</given-names>
          </name>
        </person-group>
        <article-title>PBHoney: identifying genomic variants via long-read discordance and interrupted mapping</article-title>
        <source>BMC Bioinform</source>
        <year>2014</year>
        <volume>15</volume>
        <fpage>180</fpage>
        <pub-id pub-id-type="doi">10.1186/1471-2105-15-180</pub-id>
      </element-citation>
    </ref>
    <ref id="CR16">
      <label>16.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Heller</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Vingron</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>SVIM: structural variant identification using mapped long reads</article-title>
        <source>Bioinformatics</source>
        <year>2019</year>
        <volume>35</volume>
        <issue>17</issue>
        <fpage>2907</fpage>
        <lpage>2915</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btz041</pub-id>
        <?supplied-pmid 30668829?>
        <pub-id pub-id-type="pmid">30668829</pub-id>
      </element-citation>
    </ref>
    <ref id="CR17">
      <label>17.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Jiang</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Jiang</surname>
            <given-names>Y</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Long-read-based human genomic structural variation detection with cuteSV</article-title>
        <source>Genome Biol</source>
        <year>2020</year>
        <volume>21</volume>
        <fpage>189</fpage>
        <pub-id pub-id-type="doi">10.1186/s13059-020-02107-y</pub-id>
        <?supplied-pmid 32746918?>
        <pub-id pub-id-type="pmid">32746918</pub-id>
      </element-citation>
    </ref>
    <ref id="CR18">
      <label>18.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lan</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Lai</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>Q</given-names>
          </name>
          <name>
            <surname>Wu</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>YP</given-names>
          </name>
        </person-group>
        <article-title>LDICDL: LncRNA-disease association identification based on Collaborative Deep Learning</article-title>
        <source>IEEE/ACM Trans Comput Biol Bioinform</source>
        <year>2020</year>
        <pub-id pub-id-type="doi">10.1109/TCBB.2020.3034910</pub-id>
        <?supplied-pmid 33125333?>
        <pub-id pub-id-type="pmid">33125333</pub-id>
      </element-citation>
    </ref>
    <ref id="CR19">
      <label>19.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lan</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Peng</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Wu</surname>
            <given-names>F</given-names>
          </name>
        </person-group>
        <article-title>Computational approaches for prioritizing candidate disease genes based on PPI networks</article-title>
        <source>Tsinghua Science and Technology</source>
        <year>2015</year>
        <volume>20</volume>
        <issue>5</issue>
        <fpage>500</fpage>
        <lpage>512</lpage>
        <pub-id pub-id-type="doi">10.1109/TST.2015.7297749</pub-id>
      </element-citation>
    </ref>
    <ref id="CR20">
      <label>20.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Poplin</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Chang</surname>
            <given-names>PC</given-names>
          </name>
          <name>
            <surname>Alexander</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Schwartz</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Colthurst</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Ku</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Newburger</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Dijamco</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Nguyen</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Afshar</surname>
            <given-names>PT</given-names>
          </name>
          <name>
            <surname>Gross</surname>
            <given-names>SS</given-names>
          </name>
          <name>
            <surname>Dorfman</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>McLean</surname>
            <given-names>CY</given-names>
          </name>
          <name>
            <surname>DePristo</surname>
            <given-names>MA</given-names>
          </name>
        </person-group>
        <article-title>A universal SNP and small-indel variant caller using deep neural networks</article-title>
        <source>Nat Biotechnol</source>
        <year>2018</year>
        <volume>36</volume>
        <issue>10</issue>
        <fpage>983</fpage>
        <lpage>987</lpage>
        <pub-id pub-id-type="doi">10.1038/nbt.4235</pub-id>
        <?supplied-pmid 30247488?>
        <pub-id pub-id-type="pmid">30247488</pub-id>
      </element-citation>
    </ref>
    <ref id="CR21">
      <label>21.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Cai</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Wu</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Gao</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>DeepSV: accurate calling of genomic deletions from high-throughput sequencing data using deep convolutional neural network</article-title>
        <source>BMC Bioinform</source>
        <year>2019</year>
        <volume>20</volume>
        <fpage>665</fpage>
        <pub-id pub-id-type="doi">10.1186/s12859-019-3299-y</pub-id>
      </element-citation>
    </ref>
    <ref id="CR22">
      <label>22.</label>
      <mixed-citation publication-type="other">Hu J, Shen L, Sun G. Squeeze-and-excitation networks. In: 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition; 2018. p. 7132–41. 10.1109/CVPR.2018.00745.</mixed-citation>
    </ref>
    <ref id="CR23">
      <label>23.</label>
      <mixed-citation publication-type="other">Tan M, Le QV. EfficientNet: rethinking model scaling for convolutional neural networks. 2019. <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1905.11946">arXiv:1905.11946</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR24">
      <label>24.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chaisson</surname>
            <given-names>MJP</given-names>
          </name>
          <name>
            <surname>Sanders</surname>
            <given-names>AD</given-names>
          </name>
          <name>
            <surname>Zhao</surname>
            <given-names>X</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Multi-platform discovery of haplotype-resolved structural variation in human genomes</article-title>
        <source>Nat Commun</source>
        <year>2019</year>
        <volume>10</volume>
        <fpage>1784</fpage>
        <pub-id pub-id-type="doi">10.1038/s41467-018-08148-z</pub-id>
        <?supplied-pmid 30992455?>
        <pub-id pub-id-type="pmid">30992455</pub-id>
      </element-citation>
    </ref>
    <ref id="CR25">
      <label>25.</label>
      <mixed-citation publication-type="other">
        <ext-link ext-link-type="uri" xlink:href="https://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/analysis/NIST_SVs_Integration_v0.6/README_SV_v0.6.txt">https://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/analysis/NIST_SVs_Integration_v0.6/README_SV_v0.6.txt</ext-link>
      </mixed-citation>
    </ref>
  </ref-list>
</back>
