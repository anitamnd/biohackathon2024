<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">J Cheminform</journal-id>
    <journal-id journal-id-type="iso-abbrev">J Cheminform</journal-id>
    <journal-title-group>
      <journal-title>Journal of Cheminformatics</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1758-2946</issn>
    <publisher>
      <publisher-name>Springer International Publishing</publisher-name>
      <publisher-loc>Cham</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">6041224</article-id>
    <article-id pub-id-type="publisher-id">286</article-id>
    <article-id pub-id-type="doi">10.1186/s13321-018-0286-7</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Research Article</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Molecular generative model based on conditional variational autoencoder for de novo molecular design</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Lim</surname>
          <given-names>Jaechang</given-names>
        </name>
        <address>
          <email>ljchang94@kaist.ac.kr</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Ryu</surname>
          <given-names>Seongok</given-names>
        </name>
        <address>
          <email>god_seongok@kaist.ac.kr</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Kim</surname>
          <given-names>Jin Woo</given-names>
        </name>
        <address>
          <email>starhouse@kaist.ac.kr</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-7152-2111</contrib-id>
        <name>
          <surname>Kim</surname>
          <given-names>Woo Youn</given-names>
        </name>
        <address>
          <email>wooyoun@kaist.ac.kr</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0001 2292 0500</institution-id><institution-id institution-id-type="GRID">grid.37172.30</institution-id><institution>Department of Chemistry, </institution><institution>KAIST, </institution></institution-wrap>291 Daehak-ro, Daejeon, 34141 Republic of Korea </aff>
      <aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0001 2292 0500</institution-id><institution-id institution-id-type="GRID">grid.37172.30</institution-id><institution>KI for Artificial Intelligence, </institution><institution>KAIST, </institution></institution-wrap>291 Daehak-ro, Daejeon, 34141 Republic of Korea </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>11</day>
      <month>7</month>
      <year>2018</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>11</day>
      <month>7</month>
      <year>2018</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2018</year>
    </pub-date>
    <volume>10</volume>
    <elocation-id>31</elocation-id>
    <history>
      <date date-type="received">
        <day>14</day>
        <month>3</month>
        <year>2018</year>
      </date>
      <date date-type="accepted">
        <day>29</day>
        <month>6</month>
        <year>2018</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2018</copyright-statement>
      <license license-type="OpenAccess">
        <license-p><bold>Open Access</bold>This article is distributed under the terms of the Creative Commons Attribution 4.0 International License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted use, distribution, and reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/publicdomain/zero/1.0/">http://creativecommons.org/publicdomain/zero/1.0/</ext-link>) applies to the data made available in this article, unless otherwise stated.</license-p>
      </license>
    </permissions>
    <abstract id="Abs1">
      <p id="Par1">We propose a molecular generative model based on the conditional variational autoencoder for de novo molecular design. It is specialized to control multiple molecular properties simultaneously by imposing them on a latent space. As a proof of concept, we demonstrate that it can be used to generate drug-like molecules with five target properties. We were also able to adjust a single property without changing the others and to manipulate it beyond the range of the dataset.<graphic position="anchor" xlink:href="13321_2018_286_Figa_HTML" id="MO100"/></p>
      <sec>
        <title>Electronic supplementary material</title>
        <p>The online version of this article (10.1186/s13321-018-0286-7) contains supplementary material, which is available to authorized users.</p>
      </sec>
    </abstract>
    <kwd-group xml:lang="en">
      <title>Keywords</title>
      <kwd>Molecular design</kwd>
      <kwd>Conditional variational autoencoder</kwd>
      <kwd>Deep learning</kwd>
    </kwd-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100003725</institution-id>
            <institution>National Research Foundation of Korea</institution>
          </institution-wrap>
        </funding-source>
        <award-id>NRF-2017R1E1A1A01078109</award-id>
        <principal-award-recipient>
          <name>
            <surname>Kim</surname>
            <given-names>Woo Youn</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
    </funding-group>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>© The Author(s) 2018</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="Sec1">
    <title>Background</title>
    <p id="Par2">The ultimate goal of molecular design for new materials and drugs is to directly generate molecules with the desired properties. This is apparently challenging work because a molecular space is extraordinarily vast, discrete, and disorganized with diverse types of molecules. For instance, <inline-formula id="IEq1"><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$10^{8}$$\end{document}</tex-math><mml:math id="M2"><mml:msup><mml:mn>10</mml:mn><mml:mn>8</mml:mn></mml:msup></mml:math><inline-graphic xlink:href="13321_2018_286_Article_IEq1.gif"/></alternatives></inline-formula> molecules have been synthesized [<xref ref-type="bibr" rid="CR1">1</xref>], whereas it is estimated that there are <inline-formula id="IEq2"><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$10^{23}$$\end{document}</tex-math><mml:math id="M4"><mml:msup><mml:mn>10</mml:mn><mml:mn>23</mml:mn></mml:msup></mml:math><inline-graphic xlink:href="13321_2018_286_Article_IEq2.gif"/></alternatives></inline-formula>–<inline-formula id="IEq3"><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$10^{60}$$\end{document}</tex-math><mml:math id="M6"><mml:msup><mml:mn>10</mml:mn><mml:mn>60</mml:mn></mml:msup></mml:math><inline-graphic xlink:href="13321_2018_286_Article_IEq3.gif"/></alternatives></inline-formula> drug-like molecules [<xref ref-type="bibr" rid="CR2">2</xref>]. Despite advances in experimental techniques, it is too demanding to find molecules suitable for specific applications only through experiments.</p>
    <p id="Par3">Computer-aided molecular design has attracted much attention as a promising solution to overcome the experimental limitation [<xref ref-type="bibr" rid="CR3">3</xref>–<xref ref-type="bibr" rid="CR6">6</xref>]. Fast calculation methods along with reasonable accuracy and very low cost enable high-throughput virtual screening to find molecules with target properties. A common strategy is to select computationally top molecules out of millions of molecules in a virtual library and then verify them experimentally, leading to a significant reduction in time and efforts. Molecules in the library may not meet the given criteria. In this case, traditional optimization methods such as a genetic algorithm can be used to further improve molecular properties beyond the criteria by structural modifications [<xref ref-type="bibr" rid="CR7">7</xref>–<xref ref-type="bibr" rid="CR9">9</xref>]. However, they have a fundamental limitation in terms of efficiency because many trials and errors are inevitable to optimize molecular properties in a huge molecular space.</p>
    <p id="Par4">Recently emerging generative models based on deep learning techniques may offer a viable solution for more efficient molecular design. Gómez-Bombarelli et al. adopted a variational autoencoder [<xref ref-type="bibr" rid="CR10">10</xref>] to optimize the molecular properties in a latent space in which molecules are expressed as a real vector [<xref ref-type="bibr" rid="CR11">11</xref>]. The key advantage of this method is that a gradient-based optimization becomes feasible because the latent space is continuous and differentiable. It has been successfully applied to improving the partition coefficient of drug candidates and the delayed fluorescent emission rate of organic light emitting diode candidates. Blaschke et al. employed the adversarial autoencoder [<xref ref-type="bibr" rid="CR12">12</xref>] (AAE) and the Bayesian optimization to generate ligands specific to the dopamine type 2 receptor [<xref ref-type="bibr" rid="CR13">13</xref>]. Kadurin et al. [<xref ref-type="bibr" rid="CR14">14</xref>] compared the VAE and AAE as a molecular generation model in terms of the reconstruction error and variability of the output molecular fingerprints. In addition to those autoencoder-based models, a generative model developed for natural language processing has also been used for molecular design [<xref ref-type="bibr" rid="CR15">15</xref>–<xref ref-type="bibr" rid="CR18">18</xref>]. Molecular structures can be expressed with SMILES. Then, this model learns the probability distribution of the next character of a given piece of SMILES. Yuan et al. [<xref ref-type="bibr" rid="CR16">16</xref>] designed potential inhibitors for a target protein and tested them in experiments. Based on the natural language processing model, Segler et al. [<xref ref-type="bibr" rid="CR17">17</xref>] and Gupta et al. [<xref ref-type="bibr" rid="CR18">18</xref>] applied transfer learning to molecular design for certain biological activities. This approach is especially useful when there is not enough data to train artificial neural networks in the normal way. Olivecrona et al. [<xref ref-type="bibr" rid="CR19">19</xref>], Guimaraes et al. [<xref ref-type="bibr" rid="CR20">20</xref>], and Jaques et al. [<xref ref-type="bibr" rid="CR21">21</xref>] proposed a reinforcement learning method to modify a pre-trained molecular generative model so as to impose several properties in molecules generated from the generative model.</p>
    <p id="Par5">We note that various molecular properties are correlated with each other. Therefore, adjusting one target property by structural modifications may cause an undesired change in other properties. To avoid this problem in rational molecular design, one has to control several properties at the same time. Here, we propose a molecular generative model using the conditional variational autoencoder (CVAE) [<xref ref-type="bibr" rid="CR22">22</xref>] suitable for multivariable control. In addition to the advantages of using the latent space, our method can incorporate the information of molecular properties in the encoding process and manipulate them in the decoding process.</p>
    <p id="Par6">As a proof of concept, we used the CVAE to generate drug-like molecules satisfying five target properties at the same time: molecular weight (MW), partition coefficient (LogP), number of hydrogen bond donor (HBD), number of hydrogen acceptor (HBA), and topological polar surface area (TPSA). We were able to produce a number of molecules with the specific values of the five target properties within a given range. It was also possible to adjust a single target property without changing the others. Furthermore, we were able to generate molecules with properties beyond the range of the database.</p>
  </sec>
  <sec id="Sec2">
    <title>Method</title>
    <sec id="Sec3">
      <title>Conditional variational autoencoder (CVAE)</title>
      <p id="Par7">We selected the CVAE as a molecular generator. It is one of the most popular generative models which generates objects similar to but not identical to a given dataset. In particular, it is distinguished from the VAE in that it can impose certain conditions in the encoding and decoding processes. To elucidate the difference between VAE and CVAE, we compared their objective functions with one another. The objective function of the VAE is given by<disp-formula id="Equ1"><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} E[\text {log}P(X|z)]-D_{KL}[Q(z|X)\parallel P(z)], \end{aligned}$$\end{document}</tex-math><mml:math id="M8" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>E</mml:mi><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mtext>log</mml:mtext><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>X</mml:mi><mml:mo stretchy="false">|</mml:mo><mml:mi>z</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo stretchy="false">]</mml:mo></mml:mrow><mml:mo>-</mml:mo><mml:msub><mml:mi>D</mml:mi><mml:mrow><mml:mi mathvariant="italic">KL</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mi>Q</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>z</mml:mi><mml:mo stretchy="false">|</mml:mo><mml:mi>X</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo stretchy="false">‖</mml:mo><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>z</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo stretchy="false">]</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="13321_2018_286_Article_Equ1.gif" position="anchor"/></alternatives></disp-formula>where <italic>E</italic> denotes an expectation value, <italic>P</italic> and <italic>Q</italic> are probability distributions, <inline-formula id="IEq4"><alternatives><tex-math id="M9">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$D_{KL}$$\end{document}</tex-math><mml:math id="M10"><mml:msub><mml:mi>D</mml:mi><mml:mrow><mml:mi mathvariant="italic">KL</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="13321_2018_286_Article_IEq4.gif"/></alternatives></inline-formula> is the Kullback-Leibler divergence, and <italic>X</italic> and <italic>z</italic> indicate the data and latent spaces, respectively. The first and second terms are often called the reconstruction error and the KL term, respectively. In an autoencoder, <italic>Q</italic>(<italic>z</italic>|<italic>X</italic>) and <italic>P</italic>(<italic>X</italic>|<italic>z</italic>) are approximated by an encoder and a decoder, respectively. A key difference of the CVAE from the VAE is to embed the conditional information in the objective function of the VAE, leading to the revised objective function as follow:<disp-formula id="Equ2"><alternatives><tex-math id="M11">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} E[\text {log}P(X|z,c)]-D_{KL}[Q(z|X,c)\parallel P(z|c)], \end{aligned}$$\end{document}</tex-math><mml:math id="M12" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>E</mml:mi><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mtext>log</mml:mtext><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>X</mml:mi><mml:mo stretchy="false">|</mml:mo><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo stretchy="false">]</mml:mo></mml:mrow><mml:mo>-</mml:mo><mml:msub><mml:mi>D</mml:mi><mml:mrow><mml:mi mathvariant="italic">KL</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mi>Q</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>z</mml:mi><mml:mo stretchy="false">|</mml:mo><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo stretchy="false">‖</mml:mo><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>z</mml:mi><mml:mo stretchy="false">|</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo stretchy="false">]</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="13321_2018_286_Article_Equ2.gif" position="anchor"/></alternatives></disp-formula>where <italic>c</italic> denotes a condition vector. The condition vector <italic>c</italic> is directly involved in the encoding and decoding processes. In our model, the molecular properties we want to control were represented as the condition vector. As a result, the CVAE can generate molecules with the target properties imposed by the condition vector.</p>
      <p id="Par8">Incorporating molecular properties in the VAE to generate molecules with desirable properties are also possible through a two-step model proposed by Gómez-Bombarelli et al. In this method, the VAE is trained jointly with an additional neural network for property prediction. Subsequently, a Gaussian process model creates a mapping from the resulting latent space to the associated molecular properties. Finally, property optimization in the resulting latent space is performed by a gradient descent optimization method.</p>
      <p id="Par9">The key difference of our CVAE model from the jointly trained VAE model is that the molecular properties are directly incorporated into both the encoder and decoder. The resulting latent vector is composed of two parts: the first part is for the target molecular properties, while the second part involves the molecular structures and the other properties. Therefore, the desired molecular properties can be embedded in a target molecular structure simply by setting a condition vector. In other words, one can control the structure and the properties independently except for some cases in which the properties are strongly coupled to a molecular scaffold. This is particularly useful to incorporate a certain property in a given molecule just with a marginal structure modification. After all, the CVAE is less sensitive to the continuity and smoothness of the latent space, because it does not require the derivative of the latent space with respect to the latent vector of the molecular structure. Another technical difference of the CVAE from the jointly trained VAE is that it does not need any further optimization process, which is inevitable in the jointly trained VAE for each different property value.</p>
    </sec>
    <sec id="Sec4">
      <title>Molecular representation and model construction</title>
      <p id="Par10">We represented molecules with SMILES codes to take advantage of state-of-the-art deep learning techniques that are specialized in dealing with texts and sequences. Each SMILES code was canonicalized for a unique molecular representation. One ‘E’ was padded on the end of the SMILES code to indicate the end of the string. Subsequently, each character including ‘E’ is represented with a one-hot vector, resulting in an input matrix. Each one-hot vector of the input matrix is transformed to an embedding vector with the size of 300, and then the input matrix is concatenated with a predefined condition vector. The first, second, and last entries of the condition vector are filled with information consisting of the MW, LogP, and TPSA, respectively, while the remaining two entries are labeled by the HBD and HBA as shown in Fig. <xref rid="Fig1" ref-type="fig">1</xref>. The values of MW, logP, and TPSA are normalized from -1.0 to 1.0. HBD and HBA are expressed with a one-hot vector, because they are integer numbers.</p>
      <p id="Par11">The resulting matrix is subjected to the encoder of the CVAE to generate a latent vector. We adopted the so-called recurrent neural network (RNN) with an LSTM cell for both the encoder and decoder of the CVAE [<xref ref-type="bibr" rid="CR23">23</xref>]. They are made of a 3-layer RNN with 500 hidden nodes on each layer. A softmax layer was used in each output of the decoder cell, and a cross entropy was used as the cost function of the reconstruction error. The latent vector concatenated with the condition vector becomes an input of the decoder at each time step of the RNN cell. Finally, the output vector of each decoder cell is transformed to a vector whose size is equal to that of the one-hot vector of the input matrix. The softmax activation function is applied to each transformed vector. The encoder and decoder are optimized to minimize the cost function of the CVAE. To generate a molecule with the target properties imposed by the condition vector, the cell of the RNN decoder are unrolled for 120 times. All characters before ‘E’ were taken in the stochastic write-out process, and if ‘E’ did not appear in the 120 characters, the result was considered as invalid. Each output vector of the decoder cell represents the probability distribution of the SMILES code characters and ‘E’. Finally, the output vector is converted to a SMILES code. It should be noted that even a single wrong character in the resulting SMILES code gives rise to an invalid molecule. To increase the rate of valid SMILES codes, we used the stochastic write-out method which samples each character of SMILES according to a probability distribution. As a result, a single set of latent and condition vectors may give a number of different molecules. We performed 100 times the stochastic write-out per one latent vector and took all valid molecules except duplicated ones for later analysis.</p>
    </sec>
    <sec id="Sec5">
      <title>Dataset and hyperparameters</title>
      <p id="Par12">RDKit [<xref ref-type="bibr" rid="CR24">24</xref>], an open source cheminformatics package, was used for checking out the validity of the generated SMILES codes and calculating the five target properties of the molecules.</p>
      <p id="Par13">The total dataset is made of molecules randomly selected from the ZINC dataset [<xref ref-type="bibr" rid="CR25">25</xref>]. Generally, with more data, the performance becomes better. Typical deep learning models need hundreds of thousands of data points. We checked out the convergence of the results with respect to the size of the data in our case. The use of 5,000,000 ZINC molecules did not increase both the validation and the success rates of generating molecules with the target properties compared to those from 500,000 ZINC molecules. Thus, we adopted the dataset of the 500,000 molecules, 80% of which were used for training, and the rest was used for the test. The distribution of the five target properties in the total dataset is shown in Fig. <xref rid="Fig2" ref-type="fig">2</xref>. The learning rate was set to 0.0001 and exponentially decayed at a rate of 0.97. The model was trained until converged. In the performance evaluation of the CVAE, if each target property of the generated molecules was different from the given target value with the 10% error range of the average value of the total dataset, we regarded those molecules as successful. The source code is available from GitHub (<ext-link ext-link-type="uri" xlink:href="https://github.com/jaechanglim/CVAE">https://github.com/jaechanglim/CVAE</ext-link>).<fig id="Fig1"><label>Fig. 1</label><caption><p>Schematic representation of conditional variational autoencoder for molecular design</p></caption><graphic xlink:href="13321_2018_286_Fig1_HTML" id="MO3"/></fig>
<fig id="Fig2"><label>Fig. 2</label><caption><p>Distribution of molecular weight, LogP, HBD, HBA, and TPSA in the total dataset (500,000)</p></caption><graphic xlink:href="13321_2018_286_Fig2_HTML" id="MO4"/></fig></p>
    </sec>
  </sec>
  <sec id="Sec6">
    <title>Result</title>
    <p id="Par14">As the first application, we demonstrated that the CVAE method can generate molecules with specific values for the five target properties by applying it to Aspirin and Tamiflu. The values of the (MW, LogP, HBD, HBA, and TPSA) for Aspirin and Tamiflu are (180.04, 1.31, 1, 3, and 63.6) and (312.2, 1.285, 2, 5, and 90.64), respectively. The condition vector of each molecule was made by those values. Latent vectors to be concatenated with the condition vector were sampled by adding a Gaussian type noise to the latent vector of a molecule selected randomly in the training set. Figure <xref rid="Fig3" ref-type="fig">3</xref>a, b show nine molecules produced with the condition vector of Aspirin and Tamiflu, respectively. All of them had similar properties to those of Aspirin and Tamiflu within an error range of 10%, respectively. However, the molecular structures in Fig. <xref rid="Fig3" ref-type="fig">3</xref> are considerably different from those of the original molecules because of the latent vectors chosen randomly from the training set.</p>
    <p id="Par15">The second application was to generate molecules similar in both properties and structure to the mother molecule by sampling latent vectors around that of the mother. Figure <xref rid="Fig4" ref-type="fig">4</xref> shows the molecules generated in such a way from Aspirin. They look very similar to Aspirin and also have similar properties with those of Aspirin within an error range of 10%.<fig id="Fig3"><label>Fig. 3</label><caption><p>Molecules generated by the CVAE with the condition vector made of the five target properties of <bold>a</bold> Aspirin and <bold>b</bold> Tamiflu</p></caption><graphic xlink:href="13321_2018_286_Fig3_HTML" id="MO5"/></fig>
<fig id="Fig4"><label>Fig. 4</label><caption><p>Molecules generated by the CVAE with the condition vector made of the five target properties of Aspirin and the latent vector slightly modified from that of Aspirin</p></caption><graphic xlink:href="13321_2018_286_Fig4_HTML" id="MO6"/></fig></p>
    <p id="Par16">As the third case study, we tested whether the CVAE method can change only a single property without changing the others. The condition vector was constructed with the MW, HBD, HBA, and TPSA of Tamiflu, and we varied LogP from 0.0 to 3.0. Latent vectors were sampled around that of Tamiflu. Figure <xref rid="Fig5" ref-type="fig">5</xref> shows the result. All the molecules have similar properties to the original ones except LogP as desired. The molecules from the top left to the bottom right have gradually increasing LogP values from − 0.23 to 3.55. In some cases, however, such a delicate control of individual properties was not possible. For instance, we could not generate molecules with a LogP beyond 4.0. It is probably because LogP is not completly independent from the other four properties, so a substantial change in LogP entails a change in the other properties. Moreover, it was difficult to adjust the MW and TPSA independently because the MW and TPSA are highly correlated with one another.<fig id="Fig5"><label>Fig. 5</label><caption><p>Molecules generated by the CVAE with the condition vector made of MW, HBD, HBA, and TPSA of Tamiflu and continuously changing LogP</p></caption><graphic xlink:href="13321_2018_286_Fig5_HTML" id="MO7"/></fig></p>
    <p id="Par17">Finally, we investigated the possibility to change a specific molecular property beyond the range of a training set. Latent vectors were sampled around molecules in the training set. In the condition vector, the four properties were given randomly except for a single target property. The target property was set to 10% larger than its maximum value in the training set (e.g., 5.5 for LogP and 165 for TPSA). Figure <xref rid="Fig6" ref-type="fig">6</xref> shows the resulting molecules. Indeed, it was able to generate molecules with a LogP larger than 5.5 (Fig. <xref rid="Fig6" ref-type="fig">6</xref>a) and molecules with a TPSA larger than 165 (Fig. <xref rid="Fig6" ref-type="fig">6</xref>b). We compared the distribution of the LogP and TPSA for 1000 randomly selected molecules from the training set and 1000 generated molecules with property values outside of the range of the dataset (toward larger values). Figure <xref rid="Fig7" ref-type="fig">7</xref> shows that the distribution of the target properties are shifted to larger values, leading to an increased ratio of molecules with property values outside of the range. The rate of valid molecules is relatively low compared to the case of generating molecules with property values in the range of the dataset.<fig id="Fig6"><label>Fig. 6</label><caption><p><bold>a</bold> Molecules with LogP larger than 5.5. <bold>b</bold> Molecules with TPSA larger than 165</p></caption><graphic xlink:href="13321_2018_286_Fig6_HTML" id="MO8"/></fig>
<fig id="Fig7"><label>Fig. 7</label><caption><p>Distribution of <bold>a</bold> LogP and <bold>b</bold> TPSA for 1000 randomly selected molecules in training set and 1000 generated molecules with LogP and TPSA outside of the range of the dataset, respectively</p></caption><graphic xlink:href="13321_2018_286_Fig7_HTML" id="MO9"/></fig>
<table-wrap id="Tab1"><label>Table 1</label><caption><p>Numbers of attempts and valid molecules for generating 100 molecules whose five properties are the same with those of Aspirin, Tamiflu, Lenalidomide, Rivaroxaban, and Pregabalin</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left"/><th align="left" colspan="3">Condition</th><th align="left" colspan="3">Random</th></tr><tr><th align="left"/><th align="left">Attempts</th><th align="left">Number of valid molecules</th><th align="left">Success rate (100/attempts, %)</th><th align="left">Attempts</th><th align="left">Number of valid molecules</th><th align="left">Success rate (100/attempts, %)</th></tr></thead><tbody><tr><td align="left">Aspirin</td><td align="left">28,840</td><td align="left">32,567</td><td align="left">0.34</td><td align="left">758,199</td><td align="left">711,660</td><td align="left">0.014</td></tr><tr><td align="left">Tamiflu</td><td align="left">15,960</td><td align="left">34,696</td><td align="left">0.62</td><td align="left">798,183</td><td align="left">741,960</td><td align="left">0.013</td></tr><tr><td align="left">Lenalidomide</td><td align="left">50,200</td><td align="left">89,230</td><td align="left">0.19</td><td align="left">865,695</td><td align="left">822,060</td><td align="left">0.012</td></tr><tr><td align="left">Rivaroxaban</td><td align="left">92,620</td><td align="left">47,574</td><td align="left">0.11</td><td align="left">866,205</td><td align="left">817,800</td><td align="left">0.012</td></tr><tr><td align="left">Pregabalin</td><td align="left">77,680</td><td align="left">84,371</td><td align="left">0.13</td><td align="left">782,010</td><td align="left">723,360</td><td align="left">0.014</td></tr></tbody></table></table-wrap></p>
    <p id="Par18">We analyzed the latent space constructed by the CVAE. Two principle axes were extracted by principal component analysis. Figure <xref rid="Fig8" ref-type="fig">8</xref> shows the two components of the latent vectors of 1000 randomly selected molecules from the test set with their MW, LogP and TPSA values. Molecules with similar properties are likely located around a same region of the latent space in the jointly trained VAE. In our CVAE model, the latent vector is comprised of two parts as explained in the method section. Therefore, a specific region in the latent space does not necessarily have a correlation with the target molecular properties which are controlled by the condition vector. This is good because the separation of information enables a more flexible control of the molecular structure and properties when generating new molecules.<fig id="Fig8"><label>Fig. 8</label><caption><p>The latent space of 1000 randomly selected molecules with MW, LogP and TPSA values</p></caption><graphic xlink:href="13321_2018_286_Fig8_HTML" id="MO10"/></fig></p>
    <p id="Par19">Apart from the successful applications of the CVAE method, it has a drawback that should be resolved. The success rate of generating desirable molecules is very low. We tested how many attempts were required to generate 100 molecules with the five desired properties and how many valid molecules were generated during those attempts. We also compared when the condition vector is set randomly or to target properties to show the effect of the condition vector for generating desirable molecules.</p>
    <p id="Par20">Table <xref rid="Tab1" ref-type="table">1</xref> summarizes the number of attempts for generating 100 molecules whose five properties are same as those of aspirin, Tamiflu, Lenalidomide, Rivaroxaban, and Pregabalin, respectively. Lenalidomide, Rivaroxaban, and Pregabalin are top selling small molecule drugs in 2016 [<xref ref-type="bibr" rid="CR26">26</xref>]. In Table <xref rid="Tab1" ref-type="table">1</xref>, ‘condition’ means that the condition vector was set as the five properties of the target molecules, whereas ‘random’ means that the condition vector was randomly made. The number of valid molecules in Table <xref rid="Tab1" ref-type="table">1</xref> indicates the number of valid molecules generated during the attempts to create molecules with the five desired properties. For example, 100 aspirin-like molecules and 32,567 valid moleculces were obtained from 28,840 attempts to create aspirin-like molecules. The reason why the number of valid molecules is larger than the number of attempts is that the stochastic write-out process is performed 100 times for each attempt. All successful molecules (100 per each target molecule) are reported in the Supporting Information. It should be noted that the success rate dramatically dropped when the condition vector is randomly set. It clearly manifests that the successful molecules generated by the CVAE in the example studies were not the result of many random trials.<table-wrap id="Tab2"><label>Table 2</label><caption><p>Number of generation attempts and number of valid molecules for three different sampling methods of latent vectors</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Sampling method</th><th align="left">Average number of valid molecules</th><th align="left">Average number of attempts</th><th align="left">Success rate (100/attempts, %)</th></tr></thead><tbody><tr><td align="left">Around target molecules</td><td align="left">67640.5</td><td align="left">199340.1</td><td align="left">0.05</td></tr><tr><td align="left">Around known molecules</td><td align="left">31799.4</td><td align="left">21659.9</td><td align="left">0.46</td></tr><tr><td align="left">Random</td><td align="left">50316.4</td><td align="left">78888.2</td><td align="left">0.12</td></tr></tbody></table><table-wrap-foot><p>The generation process was continued until 100 molecules with the five target properties were successfully created from a single target molecule, and it was repeated for 100 target molecules selected randomly from the ZINC dataset. The table shows the average values over the 100 target molecules</p></table-wrap-foot></table-wrap>
</p>
    <p id="Par21">We further analyzed the performance of the CVAE by investigating the change in the success rate and the number of valid molecules according to latent vector sampling methods. We employed three different sampling methods: random, around the latent vectors of known molecules, and around the latent vectors of target molecules. For all the sampling methods, the condition vector was constructed using the five properties of the target molecules. The generation process was continued until 100 molecules with the five target properties were successfully created from a single target molecule, and it was repeated for 100 different target molecules selected randomly from the ZINC dataset. Table <xref rid="Tab2" ref-type="table">2</xref> shows the average values for the success rate and the number of valid molecules over the 100 target molecules. It was unexpected that sampling latent vectors around a target molecule was the most ineffective in terms of the success rate and valid molecules because of the high rate of duplicated molecules. In this case, the structure of the generated molecules was very similar to that of the target molecule as shown in Fig. <xref rid="Fig4" ref-type="fig">4</xref>. Sampling latent vectors around those of known molecules performed best. Because the known molecules were randomly selected from the ZINC set, their structures and properties would be considerably different from those of a target molecule. Nonetheless, we were able to generate molecules with the desired properties from those latent vectors with a relatively high success rate. It manifests that the condition vector appropriately modified the molecular structures to have the target properties. Finally, it was also possible to generate desirable molecules from completely random latent vectors but with a low success rate.</p>
    <p id="Par22">We suspect that at some part the overall low success rates regardless of the latent vector sampling methods are due to the strong correlation between the five target properties. In addition, it is known that the discrete nature of SMILES causes a high rate of invalid molecules in the decoding process from latent vectors to molecules [<xref ref-type="bibr" rid="CR27">27</xref>]. The stochastic write-out method circumvents this problem, but more fundamental solutions should be devised. More severely, SMILES does not have the 3D conformational information of molecular structures. Therefore, it must have limitations in applications in which conformational effects are critical. Molecular graph representation incorporating conformational information can be a promising alternative. Encoding molecular graphs seems to be straightforward, but decoding from a latent space to molecular graphs is still an open problem. Recently, significant progress along this line has been made [<xref ref-type="bibr" rid="CR28">28</xref>–<xref ref-type="bibr" rid="CR30">30</xref>]. Such a better molecular representation may also improve the success rate of molecular generation. We expect that the success rate may be further improved by using the grammar variational autoencoder [<xref ref-type="bibr" rid="CR27">27</xref>] and the reinforcement learning [<xref ref-type="bibr" rid="CR19">19</xref>, <xref ref-type="bibr" rid="CR20">20</xref>].</p>
  </sec>
  <sec id="Sec7">
    <title>Conclusion</title>
    <p id="Par23">We proposed a new molecular design strategy based on the conditional variational autoencoder. Instead of high-throughput virtual screening, our method as one of the deep learning-based generative models directly produces molecules with desirable target properties. In particular, its strength is controlling multiple target properties simultaneously by imposing them on a condition vector. We demonstrated that it was possible to generate drug-like molecules with specific values for the five target properties (MW, LogP, HBD, HBA, and TPSA) within an error range of 10%. In addition, we were able to selectively control LogP without changing the other properties and to increase a specific property beyond the range of the training set. Thus, this new method has attractive applicability for efficient molecular design.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Electronic supplementary material</title>
    <sec id="Sec8">
      <p>Below is the link to the electronic supplementary material.
<supplementary-material content-type="local-data" id="MOESM1"><media xlink:href="13321_2018_286_MOESM1_ESM.docx"><caption><p>Supplementary material 1 (docx 791 KB)</p></caption></media></supplementary-material>
</p>
    </sec>
  </sec>
</body>
<back>
  <fn-group>
    <fn>
      <p>
        <bold>Electronic supplementary material</bold>
      </p>
      <p>The online version of this article (10.1186/s13321-018-0286-7) contains supplementary material, which is available to authorized users.</p>
    </fn>
  </fn-group>
  <ack>
    <title>Author's contributions</title>
    <p>Jaechang Lim, Seongok Ryu, Jin Woo Kim, and Woo Youn Kim organized this work. Jaechang Lim and Woo Youn Kim wrote the paper. All authors read and approved the final manuscript. </p>
    <sec id="FPar1">
      <title>Acknowledgements</title>
      <p id="Par25">This work was supported by Basic Science Research Programs through the National Research Foundation of Korea (NRF) funded by the Ministry of Science, ICT and Future Planning (NRF-2017R1E1A1A01078109).</p>
    </sec>
    <sec id="FPar2">
      <title>Competing interests</title>
      <p id="Par26">The authors declare that they have no competing interests.</p>
    </sec>
    <sec id="d29e1049">
      <title>Publisher’s Note</title>
      <p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
    </sec>
  </ack>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <label>1.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kim</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Thiessen</surname>
            <given-names>PA</given-names>
          </name>
          <name>
            <surname>Bolton</surname>
            <given-names>EE</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Fu</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Gindulyte</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Han</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>He</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>He</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Shoemaker</surname>
            <given-names>BA</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Yu</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Bryant</surname>
            <given-names>SH</given-names>
          </name>
        </person-group>
        <article-title>PubChem substance and compound databases</article-title>
        <source>Nucl Acids Res</source>
        <year>2016</year>
        <volume>44</volume>
        <issue>D1</issue>
        <fpage>D1202</fpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkv951</pub-id>
        <pub-id pub-id-type="pmid">26400175</pub-id>
      </element-citation>
    </ref>
    <ref id="CR2">
      <label>2.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Polishchuk</surname>
            <given-names>PG</given-names>
          </name>
          <name>
            <surname>Madzhidov</surname>
            <given-names>TI</given-names>
          </name>
          <name>
            <surname>Varnek</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Estimation of the size of drug-like chemical space based on GDB-17 data</article-title>
        <source>J Comput Aided Mol Des</source>
        <year>2013</year>
        <volume>27</volume>
        <issue>8</issue>
        <fpage>675</fpage>
        <pub-id pub-id-type="doi">10.1007/s10822-013-9672-4</pub-id>
        <pub-id pub-id-type="pmid">23963658</pub-id>
      </element-citation>
    </ref>
    <ref id="CR3">
      <label>3.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Shoichet</surname>
            <given-names>BK</given-names>
          </name>
        </person-group>
        <article-title>Virtual screening of chemical libraries</article-title>
        <source>Nature</source>
        <year>2004</year>
        <volume>432</volume>
        <issue>7019</issue>
        <fpage>862</fpage>
        <pub-id pub-id-type="doi">10.1038/nature03197</pub-id>
        <pub-id pub-id-type="pmid">15602552</pub-id>
      </element-citation>
    </ref>
    <ref id="CR4">
      <label>4.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Scior</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Bender</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Tresadern</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Medina-Franco</surname>
            <given-names>JL</given-names>
          </name>
          <name>
            <surname>Martínez-Mayorga</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Langer</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Cuanalo-Contreras</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Agrafiotis</surname>
            <given-names>DK</given-names>
          </name>
        </person-group>
        <article-title>Recognizing pitfalls in virtual screening: a critical review</article-title>
        <source>J Chem Inf Model</source>
        <year>2012</year>
        <volume>52</volume>
        <issue>4</issue>
        <fpage>867</fpage>
        <pub-id pub-id-type="doi">10.1021/ci200528d</pub-id>
        <pub-id pub-id-type="pmid">22435959</pub-id>
      </element-citation>
    </ref>
    <ref id="CR5">
      <label>5.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Cheng</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>Q</given-names>
          </name>
          <name>
            <surname>Zhou</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Bryant</surname>
            <given-names>SH</given-names>
          </name>
        </person-group>
        <article-title>Structure-based virtual screening for drug discovery: a problem-centric review</article-title>
        <source>AAPS J</source>
        <year>2012</year>
        <volume>14</volume>
        <issue>1</issue>
        <fpage>133</fpage>
        <pub-id pub-id-type="doi">10.1208/s12248-012-9322-0</pub-id>
        <pub-id pub-id-type="pmid">22281989</pub-id>
      </element-citation>
    </ref>
    <ref id="CR6">
      <label>6.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Reymond</surname>
            <given-names>JL</given-names>
          </name>
          <name>
            <surname>van Deursen</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Blum</surname>
            <given-names>LC</given-names>
          </name>
          <name>
            <surname>Ruddigkeit</surname>
            <given-names>L</given-names>
          </name>
        </person-group>
        <article-title>Chemical space as a source for new drugs</article-title>
        <source>MedChemComm</source>
        <year>2010</year>
        <volume>1</volume>
        <issue>1</issue>
        <fpage>30</fpage>
        <pub-id pub-id-type="doi">10.1039/c0md00020e</pub-id>
      </element-citation>
    </ref>
    <ref id="CR7">
      <label>7.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Miyao</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Kaneko</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Funatsu</surname>
            <given-names>K</given-names>
          </name>
        </person-group>
        <article-title>Ring-system-based exhaustive structure generation for inverse-QSPR/QSAR</article-title>
        <source>Mol Inf</source>
        <year>2014</year>
        <volume>33</volume>
        <issue>11–12</issue>
        <fpage>764</fpage>
      </element-citation>
    </ref>
    <ref id="CR8">
      <label>8.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hartenfeller</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Schneider</surname>
            <given-names>G</given-names>
          </name>
        </person-group>
        <article-title>Enabling future drug discovery by de novo design</article-title>
        <source>Wiley Interdiscip Rev Computat Mol Sci</source>
        <year>2011</year>
        <volume>1</volume>
        <issue>5</issue>
        <fpage>742</fpage>
        <pub-id pub-id-type="doi">10.1002/wcms.49</pub-id>
      </element-citation>
    </ref>
    <ref id="CR9">
      <label>9.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Rupakheti</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Virshup</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Beratan</surname>
            <given-names>DN</given-names>
          </name>
        </person-group>
        <article-title>Strategy to discover diverse optimal molecules in the small molecule universe</article-title>
        <source>J Chem Inf Model</source>
        <year>2015</year>
        <volume>55</volume>
        <issue>3</issue>
        <fpage>529</fpage>
        <pub-id pub-id-type="doi">10.1021/ci500749q</pub-id>
        <pub-id pub-id-type="pmid">25594586</pub-id>
      </element-citation>
    </ref>
    <ref id="CR10">
      <label>10.</label>
      <mixed-citation publication-type="other">Kingma DP, Welling M (2013) Auto-encoding variational bayes. <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1312.6114">arXiv:1312.6114</ext-link></mixed-citation>
    </ref>
    <ref id="CR11">
      <label>11.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Gómez-Bombarelli</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Wei</surname>
            <given-names>JN</given-names>
          </name>
          <name>
            <surname>Duvenaud</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Hernández-Lobato</surname>
            <given-names>JM</given-names>
          </name>
          <name>
            <surname>Sánchez-Lengeling</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Sheberla</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Aguilera-Iparraguirre</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Hirzel</surname>
            <given-names>TD</given-names>
          </name>
          <name>
            <surname>Adams</surname>
            <given-names>RP</given-names>
          </name>
          <name>
            <surname>Aspuru-Guzik</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Automatic chemical design using a data-driven continuous representation of molecules</article-title>
        <source>ACS Cent Sci</source>
        <year>2018</year>
        <volume>4</volume>
        <issue>2</issue>
        <fpage>268</fpage>
        <lpage>276</lpage>
        <pub-id pub-id-type="doi">10.1021/acscentsci.7b00572</pub-id>
        <pub-id pub-id-type="pmid">29532027</pub-id>
      </element-citation>
    </ref>
    <ref id="CR12">
      <label>12.</label>
      <mixed-citation publication-type="other">Makhzani A, Shlens J, Jaitly N, Goodfellow I, Frey B (2015) Adversarial autoencoders. <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1511.05644">arXiv:1511.05644</ext-link></mixed-citation>
    </ref>
    <ref id="CR13">
      <label>13.</label>
      <mixed-citation publication-type="other">Blaschke T, Olivecrona M, Engkvist O, Bajorath J, Chen H (2017) Application of generative autoencoder in de novo molecular design. <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1711.07839">arXiv:1711.07839</ext-link></mixed-citation>
    </ref>
    <ref id="CR14">
      <label>14.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kadurin</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Nikolenko</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Khrabrov</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Aliper</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Zhavoronkov</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>druGAN: an advanced generative adversarial autoencoder model for de novo generation of new molecules with desired molecular properties in silico</article-title>
        <source>Mol Pharm</source>
        <year>2017</year>
        <volume>14</volume>
        <issue>9</issue>
        <fpage>3098</fpage>
        <pub-id pub-id-type="doi">10.1021/acs.molpharmaceut.7b00346</pub-id>
        <pub-id pub-id-type="pmid">28703000</pub-id>
      </element-citation>
    </ref>
    <ref id="CR15">
      <label>15.</label>
      <mixed-citation publication-type="other">Bjerrum EJ, Threlfall R (2017) Molecular generation with recurrent neural networks (RNNs). <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1705.04612">arXiv:1705.04612</ext-link></mixed-citation>
    </ref>
    <ref id="CR16">
      <label>16.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Yuan</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Jiang</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Nambiar</surname>
            <given-names>DK</given-names>
          </name>
          <name>
            <surname>Liew</surname>
            <given-names>LP</given-names>
          </name>
          <name>
            <surname>Hay</surname>
            <given-names>MP</given-names>
          </name>
          <name>
            <surname>Bloomstein</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Lu</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Turner</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Le</surname>
            <given-names>QT</given-names>
          </name>
          <name>
            <surname>Tibshirani</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Khatri</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Moloney</surname>
            <given-names>MG</given-names>
          </name>
          <name>
            <surname>Koong</surname>
            <given-names>AC</given-names>
          </name>
        </person-group>
        <article-title>Chemical space mimicry for drug discovery</article-title>
        <source>J Chem Inf Model</source>
        <year>2017</year>
        <volume>57</volume>
        <issue>4</issue>
        <fpage>875</fpage>
        <pub-id pub-id-type="doi">10.1021/acs.jcim.6b00754</pub-id>
        <pub-id pub-id-type="pmid">28257191</pub-id>
      </element-citation>
    </ref>
    <ref id="CR17">
      <label>17.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Segler</surname>
            <given-names>MHS</given-names>
          </name>
          <name>
            <surname>Kogej</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Tyrchan</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Waller</surname>
            <given-names>MP</given-names>
          </name>
        </person-group>
        <article-title>Generative recurrent networks for de novo drug design</article-title>
        <source>ACS Cent Sci</source>
        <year>2018</year>
        <volume>4</volume>
        <issue>1</issue>
        <fpage>120</fpage>
        <lpage>131</lpage>
        <pub-id pub-id-type="doi">10.1021/acscentsci.7b00512</pub-id>
        <pub-id pub-id-type="pmid">29392184</pub-id>
      </element-citation>
    </ref>
    <ref id="CR18">
      <label>18.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Gupta</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Müller</surname>
            <given-names>AT</given-names>
          </name>
          <name>
            <surname>Huisman</surname>
            <given-names>BJH</given-names>
          </name>
          <name>
            <surname>Fuchs</surname>
            <given-names>JA</given-names>
          </name>
          <name>
            <surname>Schneider</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Schneider</surname>
            <given-names>G</given-names>
          </name>
        </person-group>
        <article-title>Generative recurrent networks for de novo drug design</article-title>
        <source>Mol Inf</source>
        <year>2017</year>
      </element-citation>
    </ref>
    <ref id="CR19">
      <label>19.</label>
      <mixed-citation publication-type="other">Olivecrona M, Blaschke T, Engkvist O, Chen H (2017) Molecular de novo design through deep reinforcement learning. J Cheminform 9(1):1. <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1704.07555">arXiv:1704.07555</ext-link></mixed-citation>
    </ref>
    <ref id="CR20">
      <label>20.</label>
      <mixed-citation publication-type="other">Guimaraes GL, Sanchez-Lengeling B, Outeiral C, Farias PLC, Aspuru-Guzik A (2017) Objective-reinforced generative adversarial networks (ORGAN) for sequence generation models. <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1705.10843">arXiv:1705.10843</ext-link></mixed-citation>
    </ref>
    <ref id="CR21">
      <label>21.</label>
      <mixed-citation publication-type="other">Jaques N, Gu S, Bahdanau D, Hernández-Lobato JM, Turner RE, Eck D (2016) Sequence tutor: conservative fine-tuning of sequence generation models with KL-control. <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1611.02796">arXiv:1611.02796</ext-link></mixed-citation>
    </ref>
    <ref id="CR22">
      <label>22.</label>
      <mixed-citation publication-type="other">D.P Kingma, D.J Rezende, S Mohamed, M Welling, (2014) Semi-supervised learning with deep generative models, pp 1–9. <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1406.5298">arXiv:1406.5298</ext-link></mixed-citation>
    </ref>
    <ref id="CR23">
      <label>23.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hochreiter</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Urgen Schmidhuber</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Long short-term memory</article-title>
        <source>Neural Comput</source>
        <year>1997</year>
        <volume>9</volume>
        <issue>8</issue>
        <fpage>1735</fpage>
        <pub-id pub-id-type="doi">10.1162/neco.1997.9.8.1735</pub-id>
        <pub-id pub-id-type="pmid">9377276</pub-id>
      </element-citation>
    </ref>
    <ref id="CR24">
      <label>24.</label>
      <mixed-citation publication-type="other">RDKit. <ext-link ext-link-type="uri" xlink:href="http://www.rdkit.org/">http://www.rdkit.org/</ext-link>. Accessed Sept 2017</mixed-citation>
    </ref>
    <ref id="CR25">
      <label>25.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Irwin</surname>
            <given-names>JJ</given-names>
          </name>
          <name>
            <surname>Sterling</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Mysinger</surname>
            <given-names>MM</given-names>
          </name>
          <name>
            <surname>Bolstad</surname>
            <given-names>ES</given-names>
          </name>
          <name>
            <surname>Coleman</surname>
            <given-names>RG</given-names>
          </name>
        </person-group>
        <article-title>ZINC: a free tool to discover chemistry for biology</article-title>
        <source>J Chem Inf Model</source>
        <year>2012</year>
        <volume>52</volume>
        <issue>7</issue>
        <fpage>1757</fpage>
        <pub-id pub-id-type="doi">10.1021/ci3001277</pub-id>
        <pub-id pub-id-type="pmid">22587354</pub-id>
      </element-citation>
    </ref>
    <ref id="CR26">
      <label>26.</label>
      <mixed-citation publication-type="other">Top selling small molecule drugs in 2016. <ext-link ext-link-type="uri" xlink:href="https://www.genengnews.com/the-lists/the-top-15-best-selling-drugs-of-2016/77900868">https://www.genengnews.com/the-lists/the-top-15-best-selling-drugs-of-2016/77900868</ext-link>. Accessed Jan 2018</mixed-citation>
    </ref>
    <ref id="CR27">
      <label>27.</label>
      <mixed-citation publication-type="other">Kusner MJ, Paige B, Hernández-Lobato JM (2017) Grammar variational autoencoder. <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1703.01925">arXiv:1703.01925</ext-link></mixed-citation>
    </ref>
    <ref id="CR28">
      <label>28.</label>
      <mixed-citation publication-type="other">Wang H, Wang J, Wang J, Zhao M, Zhang W, Zhang F, Xie X, Guo M (2017) GraphGAN: graph representation learning with generative adversarial nets. <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1711.08267">arXiv:1711.08267</ext-link></mixed-citation>
    </ref>
    <ref id="CR29">
      <label>29.</label>
      <mixed-citation publication-type="other">You J, Ying R, Ren X, Hamilton WL, Leskovec J (2018) GraphRNN: a deep generative model for graphs. <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1802.08773">arXiv:1802.08773</ext-link></mixed-citation>
    </ref>
    <ref id="CR30">
      <label>30.</label>
      <mixed-citation publication-type="other">W Jin, R Barzilay, T Jaakkola (2018) Junction tree variational autoencoder for molecular graph generation. <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1802.04364">arXiv:1802.04364</ext-link></mixed-citation>
    </ref>
  </ref-list>
</back>
