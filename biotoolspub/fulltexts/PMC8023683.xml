<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id>
    <journal-id journal-id-type="publisher-id">bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1367-4803</issn>
    <issn pub-type="epub">1367-4811</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">8023683</article-id>
    <article-id pub-id-type="pmid">33367627</article-id>
    <article-id pub-id-type="doi">10.1093/bioinformatics/btaa1074</article-id>
    <article-id pub-id-type="publisher-id">btaa1074</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Original Papers</subject>
        <subj-group subj-group-type="category-toc-heading">
          <subject>Sequence Analysis</subject>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI01060</subject>
      </subj-group>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI01060</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Identification of sub-Golgi protein localization by use of deep representation learning features</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0001-5390-7616</contrib-id>
        <name>
          <surname>Lv</surname>
          <given-names>Zhibin</given-names>
        </name>
        <aff><institution>Institute of Fundamental and Frontier Sciences, University of Electronic Science and Technology of China</institution>, Chengdu, <country country="CN">China</country></aff>
        <xref rid="btaa1074-FM1" ref-type="author-notes"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Wang</surname>
          <given-names>Pingping</given-names>
        </name>
        <aff><institution>Center for Bioinformatics, School of Life Science and Technology, Harbin Institute of Technology</institution>, Harbin 150000, <country country="CN">China</country></aff>
        <xref rid="btaa1074-FM1" ref-type="author-notes"/>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0001-6406-1142</contrib-id>
        <name>
          <surname>Zou</surname>
          <given-names>Quan</given-names>
        </name>
        <xref rid="btaa1074-cor1" ref-type="corresp"/>
        <aff><institution>Institute of Fundamental and Frontier Sciences, University of Electronic Science and Technology of China</institution>, Chengdu, <country country="CN">China</country></aff>
        <aff><institution>Center for Informational Biology, University of Electronic Science and Technology of China</institution>, Chengdu, <country country="CN">China</country></aff>
        <aff><institution>Yangtze Delta Region Institute (Quzhou), University of Electronic Science and Technology of China</institution>, Quzhou, Zhejiang, <country country="CN">China</country></aff>
        <!--zouquan@nclab.net-->
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Jiang</surname>
          <given-names>Qinghua</given-names>
        </name>
        <xref rid="btaa1074-cor1" ref-type="corresp"/>
        <aff><institution>Center for Bioinformatics, School of Life Science and Technology, Harbin Institute of Technology</institution>, Harbin 150000, <country country="CN">China</country></aff>
        <!--qhjiang@hit.edu.cn-->
      </contrib>
    </contrib-group>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Xu</surname>
          <given-names>Jinbo</given-names>
        </name>
        <role>Associate Editor</role>
      </contrib>
    </contrib-group>
    <author-notes>
      <fn id="btaa1074-FM1">
        <p>The authors wish it to be known that, in their opinion, the first two authors should be regarded as Joint First Authors.</p>
      </fn>
      <corresp id="btaa1074-cor1">To whom correspondence should be addressed. <email>zouquan@nclab.net</email> or <email>qhjiang@hit.edu.cn</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <day>15</day>
      <month>12</month>
      <year>2020</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2020-12-26">
      <day>26</day>
      <month>12</month>
      <year>2020</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>26</day>
      <month>12</month>
      <year>2020</year>
    </pub-date>
    <volume>36</volume>
    <issue>24</issue>
    <fpage>5600</fpage>
    <lpage>5609</lpage>
    <history>
      <date date-type="received">
        <day>31</day>
        <month>8</month>
        <year>2020</year>
      </date>
      <date date-type="rev-recd">
        <day>10</day>
        <month>12</month>
        <year>2020</year>
      </date>
      <date date-type="editorial-decision">
        <day>13</day>
        <month>12</month>
        <year>2020</year>
      </date>
      <date date-type="accepted">
        <day>14</day>
        <month>12</month>
        <year>2020</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>Â© The Author(s) 2020. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2021</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbynclicense">https://creativecommons.org/licenses/by-nc/4.0/</ali:license_ref>
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by-nc/4.0/">http://creativecommons.org/licenses/by-nc/4.0/</ext-link>), which permits non-commercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited. For commercial re-use, please contact journals.permissions@oup.com</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="btaa1074.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Motivation</title>
        <p>The Golgi apparatus has a key functional role in protein biosynthesis within the eukaryotic cell with malfunction resulting in various neurodegenerative diseases. For a better understanding of the Golgi apparatus, it is essential to identification of sub-Golgi protein localization. Although some machine learning methods have been used to identify sub-Golgi localization proteins by sequence representation fusion, more accurate sub-Golgi protein identification is still challenging by existing methodology.</p>
      </sec>
      <sec id="s2">
        <title>Results</title>
        <p>we developed a protein sub-Golgi localization identification protocol using deep representation learning features with 107 dimensions. By this protocol, we demonstrated that instead of multi-type protein sequence feature representation fusion as in previous state-of-the-art sub-Golgi-protein localization classifiers, it is sufficient to exploit only one type of feature representation for more accurately identification of sub-Golgi proteins. Compared with independent testing results for benchmark datasets, our protocol is able to perform generally, reliably and robustly for sub-Golgi protein localization prediction.</p>
      </sec>
      <sec id="s3">
        <title>Availabilityand implementation</title>
        <p>A use-friendly webserver is freely accessible at <ext-link xlink:href="http://isGP-DRLF.aibiochem.net" ext-link-type="uri">http://isGP-DRLF.aibiochem.net</ext-link> and the prediction code is accessible at <ext-link xlink:href="https://github.com/zhibinlv/isGP-DRLF" ext-link-type="uri">https://github.com/zhibinlv/isGP-DRLF</ext-link>.</p>
      </sec>
      <sec id="s5">
        <title>Supplementary information</title>
        <p><xref rid="sup1" ref-type="supplementary-material">Supplementary data</xref> are available at <italic toggle="yes">Bioinformatics</italic> online.</p>
      </sec>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>National Natural Science Foundation of China</institution>
            <institution-id institution-id-type="DOI">10.13039/501100001809</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>62001090</award-id>
        <award-id>91935302</award-id>
        <award-id>61922020</award-id>
        <award-id>61822108</award-id>
        <award-id>61771331</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>China Postdoctoral Science Foundation</institution>
            <institution-id institution-id-type="DOI">10.13039/501100002858</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>2020M673184</award-id>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="10"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 Introduction</title>
    <p>As an important organelle in eukaryotic cells, the Golgi apparatus (GA) acts to process, sort and transport proteins synthesized by the endoplasmic reticulum (<xref rid="btaa1074-B59" ref-type="bibr">Tao et al., 2020</xref>), which are then delivered to specific compartments of the cell or secreted from the cell (<xref rid="btaa1074-B25" ref-type="bibr">Holthuis <italic toggle="yes">et al.</italic>, 2014</xref>). GA malfunction can result in Parkinsonâs disease (<xref rid="btaa1074-B23" ref-type="bibr">Fujita et al., 2006</xref>), Alzheimerâs disease (<xref rid="btaa1074-B24" ref-type="bibr">Gonatas et al., 1998</xref>) and other neurodegenerative disorders (<xref rid="btaa1074-B40" ref-type="bibr">Ligon et al., 2020</xref>). Thus it is essential to understand the functional details of the GA (<xref rid="btaa1074-B52" ref-type="bibr">Ravichandran et al., 2020</xref>) such as protein localization in the cis-Golgi (cis-Golgi protein) or in the trans-Golgi (trans-Golgi protein) (<xref rid="btaa1074-B13" ref-type="bibr">De Tito <italic toggle="yes">et al.</italic>, 2020</xref>). Such an understanding would clarify GA function (<xref rid="btaa1074-B9" ref-type="bibr">Berry <italic toggle="yes">et al.</italic>, 2017</xref>) and would provide clues to aid drug discovery and development (<xref rid="btaa1074-B56" ref-type="bibr">Stoeber et al., 2018</xref>).</p>
    <p>Over the past decade, several machine learning-based methods for identification of sub-Golgi proteins localization (<xref rid="btaa1074-B73" ref-type="bibr">Yang et al., 2019b</xref>), including proteins cis- and trans-Golgi localization, have been developed using a few benchmark datasets (<xref rid="btaa1074-B16" ref-type="bibr">Ding et al., 2011</xref>, <xref rid="btaa1074-B15" ref-type="bibr">2013</xref>; <xref rid="btaa1074-B70" ref-type="bibr">Yang et al., 2016b</xref>; <xref rid="btaa1074-B80" ref-type="bibr">Zhao et al., 2019</xref>). The previously reported protein sub-Golgi localization classifiers shared some common aspects to achieve high identification accuracy. The first was to use sequence feature fusion for better protein sequence representation (<xref rid="btaa1074-B1" ref-type="bibr">Ahmad <italic toggle="yes">et al.</italic>, 2019</xref>; <xref rid="btaa1074-B50" ref-type="bibr">Rahman et al., 2018</xref>; <xref rid="btaa1074-B64" ref-type="bibr">Wang et al., 2020a</xref>). To the best of our knowledge, the most widely used features for high performance sub-Golgi protein classifiers are the fusion of a position specific scoring matrix (PSSM) (<xref rid="btaa1074-B33" ref-type="bibr">Jiao et al., 2016b</xref>; <xref rid="btaa1074-B53" ref-type="bibr">Shen et al., 2019a</xref>,<xref rid="btaa1074-B54" ref-type="bibr">b</xref>; <xref rid="btaa1074-B70" ref-type="bibr">Yang <italic toggle="yes">et al.</italic>, 2016b</xref>), dipeptide composition frequency (<xref rid="btaa1074-B16" ref-type="bibr">Ding <italic toggle="yes">et al.</italic>, 2011</xref>, <xref rid="btaa1074-B15" ref-type="bibr">2013</xref>; <xref rid="btaa1074-B42" ref-type="bibr">Lv <italic toggle="yes">et al.</italic>, 2019b</xref>; <xref rid="btaa1074-B50" ref-type="bibr">Rahman <italic toggle="yes">et al.</italic>, 2018</xref>), pseudo amino acid physical and chemical properties (<xref rid="btaa1074-B33" ref-type="bibr">Jiao <italic toggle="yes">et al.</italic>, 2016b</xref>,<xref rid="btaa1074-B34" ref-type="bibr">c</xref>; <xref rid="btaa1074-B80" ref-type="bibr">Zhao <italic toggle="yes">et al.</italic>, 2019</xref>; <xref rid="btaa1074-B81" ref-type="bibr">Zhou et al., 2019</xref>) and their derivative features. The second was to use an over-sampling method to overcome the lack of sub-Golgi protein localization balance in training benchmark datasets (<xref rid="btaa1074-B2" ref-type="bibr">Ahmad <italic toggle="yes">et al.</italic>, 2017</xref>, <xref rid="btaa1074-B1" ref-type="bibr">2019</xref>; <xref rid="btaa1074-B42" ref-type="bibr">Lv <italic toggle="yes">et al.</italic>, 2019b</xref>; <xref rid="btaa1074-B50" ref-type="bibr">Rahman <italic toggle="yes">et al.</italic>, 2018</xref>; <xref rid="btaa1074-B70" ref-type="bibr">Yang <italic toggle="yes">et al.</italic>, 2016b</xref>). In addition, to feature fusion and data over-sampling, the employed selection technologies included analysis of variance (ANOVA) (<xref rid="btaa1074-B17" ref-type="bibr">Ding <italic toggle="yes">et al.</italic>, 2016</xref>; <xref rid="btaa1074-B58" ref-type="bibr">Tang et al., 2018</xref>), Fisher method, minimum redundancy maximum relevance (mRMR), random forest recursive feature elimination (RF-RFE) and other methods that selected the best features in the vector space(<xref rid="btaa1074-B2" ref-type="bibr">Ahmad <italic toggle="yes">et al.</italic>, 2017</xref>, <xref rid="btaa1074-B1" ref-type="bibr">2019</xref>; <xref rid="btaa1074-B15" ref-type="bibr">Ding <italic toggle="yes">et al.</italic>, 2013</xref>; <xref rid="btaa1074-B34" ref-type="bibr">Jiao <italic toggle="yes">et al.</italic>, 2016c</xref>; <xref rid="btaa1074-B50" ref-type="bibr">Rahman <italic toggle="yes">et al.</italic>, 2018</xref>; <xref rid="btaa1074-B65" ref-type="bibr">Wang et al., 2020b</xref>; <xref rid="btaa1074-B70" ref-type="bibr">Yang <italic toggle="yes">et al.</italic>, 2016b</xref>). By combining the above techniques, the reported protein sub-Golgi localization classifier (isGPT) (<xref rid="btaa1074-B50" ref-type="bibr">Rahman <italic toggle="yes">et al.</italic>, 2018</xref>) was with the best independent testing scores (ACCâ=â95.3%, MCCâ=â0.85, Snâ=â84.6% and Sp = 98.0%). The good performance of isGPT was attained by carefully selected 2800 fusion features from the original feature space with 18Â 840 dimensions. The fusion features of isGPT were derived by combination of six types of protein sequence representation methods that included amino acid composition, dipeptides composition, tripeptide composition, n-gapped-dipeptides composition, position specific features and pseudo amino acid composition (<xref rid="btaa1074-B50" ref-type="bibr">Rahman <italic toggle="yes">et al.</italic>, 2018</xref>).</p>
    <p>Feature extraction plays an important role in protein sequence analysis and an appropriate and selected feature representation such as that used by isGPT (<xref rid="btaa1074-B50" ref-type="bibr">Rahman <italic toggle="yes">et al.</italic>, 2018</xref>) greatly improves the accuracy of protein sequence analysis (<xref rid="btaa1074-B41" ref-type="bibr">Lv <italic toggle="yes">et al.</italic>, 2019a</xref>). Given its automatic feature extraction and powerful feature representation capabilities, deep learning has been widely used in sequence analysis of proteins, DNA and RNA (<xref rid="btaa1074-B46" ref-type="bibr">Min <italic toggle="yes">et al.</italic>, 2017</xref>; <xref rid="btaa1074-B61" ref-type="bibr">Wang et al., 2017</xref>; <xref rid="btaa1074-B66" ref-type="bibr">Xu, 2019</xref>; <xref rid="btaa1074-B67" ref-type="bibr">Xu et al., 2017</xref>, <xref rid="btaa1074-B68" ref-type="bibr">2019</xref>). Deep learning is a form of machine learning that automatically learns feature representation by capturing parameters in a neural network (<xref rid="btaa1074-B20" ref-type="bibr">Eraslan <italic toggle="yes">et al.</italic>, 2019</xref>; <xref rid="btaa1074-B29" ref-type="bibr">Jiang <italic toggle="yes">et al.</italic>, 2019b</xref>). Based on this principle, pre-trained deep learning networks can be used for feature extraction from new data or migrated for application to other similar tasks such as image recognition and natural language processing, which are known as transfer learning (<xref rid="btaa1074-B76" ref-type="bibr">Zhang et al., 2016</xref>; <xref rid="btaa1074-B82" ref-type="bibr">Zhou et al., 2020</xref>). In 2019, <xref rid="btaa1074-B3" ref-type="bibr">Alley <italic toggle="yes">et al.</italic> (2019)</xref> proposed a self-supervised and universal protein sequence deep representation learning tool, UniRep, which was trained using UniRef50 (a dataset with tens of millions of protein sequences) to better represent natural and de-novo designed proteins. Also, some other preprint papers such as TAPE (<xref rid="btaa1074-B51" ref-type="bibr">Rao <italic toggle="yes">et al.</italic>, 2019</xref>), BiLSTM embedding model (<xref rid="btaa1074-B8" ref-type="bibr">Bepler <italic toggle="yes">et al.</italic>, 2019</xref>), PRoBERTa (<xref rid="btaa1074-B47" ref-type="bibr">Nambiar <italic toggle="yes">et al.</italic>, 2020</xref>) and MULocDeep (<xref rid="btaa1074-B30" ref-type="bibr">Jiang <italic toggle="yes">et al.</italic>, 2020a</xref>) have used similar ideas to encode protein sequences in a deep representations learning way and have obtained good results in many protein-sequence analysis applications.</p>
    <p>In this work, we utilized UniRep to extract deep representation learning features for sub-Golgi protein sequences. Then, by using synthetic minority over-sampling (SMOTE) and light gradient boosting machine (LGBM) feature selection methods, we developed a high performance support vector machine based sub-Golgi protein localization classifier named as isGP-DRLF. The leave-one-out cross-validation scores of isGP-DRLF based on D5 dataset with only one type of feature representation vectors was ACCâ=â99.2%, MCCâ=â0.98, Snâ=â100% and Spâ=â98.4%, while the independent testing score metrics for isGP-DRLF was ACCâ=â96.4%, MCCâ=â0.90, Spâ=â84.6% and Snâ=â100%. The isGP-DRLF based on D3 dataset was with independent testing scores of ACCâ=â98.4%, MCCâ=â0.95, Snâ=â100% and Spâ=â98.0%, which improved by the relative value of 3.25%, 11.7%, 18.2% and 0.0% compared to the previously reported best independent-testing sub-Golgi protein classifier (isGPT) with six types of feature representation vectors. While isGPT used 2800-dimension fusion features for prediction, our isGP-DRLF used only 107-dimension features without any feature fusion. Herein, for sub-Golgi protein localization prediction, the effect of LGBM feature selection was better than that of ANOVA and MRMD feature selection technologies. The support vector machine algorithm is the best sub-Golgi protein identification algorithm in this study. A user-friendly isGP-DRLF webserver is available at <ext-link xlink:href="http://isGP-DRLF.aibiochem.net" ext-link-type="uri">http://isGP-DRLF.aibiochem.net</ext-link> for small sequence dataset computing. For a large dataset computing, the users could also download the trained model from <ext-link xlink:href="https://github.com/zhibinlv/isGP-DRLF" ext-link-type="uri">https://github.com/zhibinlv/isGP-DRLF</ext-link>. By using UMAP(uniform manifold approximation and projection) method (<xref rid="btaa1074-B45" ref-type="bibr">Mcinnes <italic toggle="yes">et al.</italic>, 2018</xref>) feature visualization technology, we found out that UniRep feature could be better to represent proteins than other features (single feature type or fused features types) to distinguish proteins in cis-Golgi from those in trans-Golgi. Thus, isGP-DRLF could employ merely one type of feature representation, a protein sequence deep representation learning feature, to carry out a powerful prediction tool for sub-Golgi proteins localization, although it abandoned the feature fusion methods as many state-of-the-art models did.</p>
  </sec>
  <sec>
    <title>2 Materials and methods</title>
    <sec>
      <title>2.1 Datasets</title>
      <p>There are several benchmark datasets (<xref rid="btaa1074-B16" ref-type="bibr">Ding <italic toggle="yes">et al.</italic>, 2011</xref>, <xref rid="btaa1074-B15" ref-type="bibr">2013</xref>; <xref rid="btaa1074-B70" ref-type="bibr">Yang <italic toggle="yes">et al.</italic>, 2016b</xref>; <xref rid="btaa1074-B80" ref-type="bibr">Zhao <italic toggle="yes">et al.</italic>, 2019</xref>) with different sequence homologies and numbers for sub-Golgi protein identification modeling (see the details of datasets labeled D0, D1, D2, D3 and D4 in <xref rid="sup1" ref-type="supplementary-material">Supplementary Table S1</xref>). Considering the availability of the benchmark datasets and the performance of the sub-Golgi protein classifiers based on various datasets, we used benchmark dataset D3 for model training and D4 for model independent testing. D3 has been widely used for several state-of-the-art protein sub-Golgi localization classifiers (<xref rid="btaa1074-B2" ref-type="bibr">Ahmad <italic toggle="yes">et al.</italic>, 2017</xref>, <xref rid="btaa1074-B1" ref-type="bibr">2019</xref>; <xref rid="btaa1074-B50" ref-type="bibr">Rahman <italic toggle="yes">et al.</italic>, 2018</xref>; <xref rid="btaa1074-B70" ref-type="bibr">Yang <italic toggle="yes">et al.</italic>, 2016b</xref>), available at <ext-link xlink:href="https://www.mdpi.com/1422-0067/17/2/218" ext-link-type="uri">https://www.mdpi.com/1422-0067/17/2/218</ext-link> and D4 for independent testing available at <ext-link xlink:href="http://lin-group.cn/server/SubGolgi/data" ext-link-type="uri">http://lin-group.cn/server/SubGolgi/data</ext-link><underline>.</underline> To prevent from homology or sequence similarity bias and from overfitting due to insufficient data entries, we have created a new updating training benchmark dataset downloaded from the latest Universal Protein KnowledgeBase (UniProtKB Version 2020_05) (<xref rid="btaa1074-B28" ref-type="bibr">Jiang <italic toggle="yes">et al.</italic>, 2019a</xref>). We firstly searched protein sequence on the website <ext-link xlink:href="https://www.uniprot.org/locations/" ext-link-type="uri">https://www.uniprot.org/locations/</ext-link> by using searching keywords listed in <xref rid="sup1" ref-type="supplementary-material">Supplementary Table S1</xref> footnote a. Please see the dataset set up searching example in <xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S0</xref> in <xref rid="sup1" ref-type="supplementary-material">Supplementary Materials</xref>. Then we got a temporary dataset. The D4 was merged into temporary dataset. Then we removed the redundant sequences from the temporary dataset using PSI-CD-HIT (<xref rid="btaa1074-B31" ref-type="bibr">Jiang <italic toggle="yes">et al.</italic>, 2020b</xref>) with a 25% identity cutoff. Finally, the independent testing sequences in D4 were excluded from the temporary dataset to avoid overfitting, and the new benchmark dataset D5 was created, which consists of 82 cis-Golgi proteins and 1065 trans-Golgi proteins for training. D5 was included in the <xref rid="sup1" ref-type="supplementary-material">Supplementary Materials</xref>. For real application, we download Human sub-Golgi proteome sequences from UniProtKB_2020_05 by using key words listed in <xref rid="sup1" ref-type="supplementary-material">Supplementary Table S1</xref> footnote b.</p>
    </sec>
    <sec>
      <title>2.2 Feature representation</title>
      <p>Here we used protein sequence unified representation (UniRep) (<xref rid="btaa1074-B3" ref-type="bibr">Alley <italic toggle="yes">et al.</italic>, 2019</xref>) to convert protein sequences into feature vectors. UniRep was proposed in 2019 and uses a totally different feature representation method than the previously and extensively used protein sequence feature extraction methods (<xref rid="btaa1074-B2" ref-type="bibr">Ahmad <italic toggle="yes">et al.</italic>, 2017</xref>, <xref rid="btaa1074-B1" ref-type="bibr">2019</xref>; <xref rid="btaa1074-B42" ref-type="bibr">Lv <italic toggle="yes">et al.</italic>, 2019b</xref>; <xref rid="btaa1074-B50" ref-type="bibr">Rahman <italic toggle="yes">et al.</italic>, 2018</xref>; <xref rid="btaa1074-B70" ref-type="bibr">Yang <italic toggle="yes">et al.</italic>, 2016b</xref>; <xref rid="btaa1074-B81" ref-type="bibr">Zhou <italic toggle="yes">et al.</italic>, 2019</xref>). Details of UniRep are found in reference (<xref rid="btaa1074-B3" ref-type="bibr">Alley <italic toggle="yes">et al.</italic>, 2019</xref>). Briefly, UniRep used a slightly modified version of the original multiplicative long short-term memory architecture (mLSTM) (<xref rid="btaa1074-B37" ref-type="bibr">Krause <italic toggle="yes">et al.</italic>, 2016</xref>) in <xref rid="btaa1074-F1" ref-type="fig">FigureÂ 1</xref> as deep representation learner to self-supervised learning for prediction of the next following amino acid in a sequence. UniRef50 downloaded from UniProt was used to train UniRep to perform next amino-acid prediction in the protein sequences (<xref rid="btaa1074-B7" ref-type="bibr">Bateman <italic toggle="yes">et al.</italic>, 2019</xref>). The protein feature vectors derived from UniRep have been used as the input for secondary structure, stability, diverse functions and semantic similarity of protein prediction or clustering, resulting in more efficiency for protein engineering tasks (<xref rid="btaa1074-B3" ref-type="bibr">Alley <italic toggle="yes">et al.</italic>, 2019</xref>; <xref rid="btaa1074-B49" ref-type="bibr">Qi <italic toggle="yes">et al.</italic>, 2020</xref>). In this work, each of sub-Golgi-localized protein sequences were firstly converted into an integer sequence according to following function: 
<disp-formula id="E1"><label>(1)</label><mml:math id="M1" display="block" overflow="scroll"><mml:mi>f</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo></mml:math></disp-formula>
Â <disp-formula id="E2"><mml:math id="M2" display="block" overflow="scroll"><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1,2</mml:mn><mml:mo>â¦</mml:mo><mml:mo>,</mml:mo><mml:mn>21</mml:mn><mml:mo>,</mml:mo><mml:mi mathvariant="normal">Â </mml:mi><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mi mathvariant="normal">Â </mml:mi><mml:mo>â</mml:mo><mml:mi mathvariant="normal">Â </mml:mi><mml:mn>20</mml:mn><mml:mi mathvariant="normal">Â </mml:mi><mml:mi mathvariant="normal">canonical</mml:mi><mml:mi mathvariant="normal">Â </mml:mi><mml:mi mathvariant="normal">amino</mml:mi><mml:mi mathvariant="normal">Â </mml:mi><mml:mi mathvariant="normal">acid</mml:mi></mml:math></disp-formula>
Â <disp-formula id="E3"><mml:math id="M3" display="block" overflow="scroll"><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>22</mml:mn><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mi mathvariant="normal">Â </mml:mi><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>â</mml:mo><mml:mfenced open="[" close="]" separators="|"><mml:mrow><mml:mi>O</mml:mi></mml:mrow></mml:mfenced></mml:math></disp-formula>
Â <disp-formula id="E4"><mml:math id="M4" display="block" overflow="scroll"><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>23</mml:mn><mml:mo>,</mml:mo><mml:mi mathvariant="normal">Â </mml:mi><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mi mathvariant="normal">Â </mml:mi><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>â</mml:mo><mml:mfenced open="[" close="]" separators="|"><mml:mrow><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mi>Z</mml:mi><mml:mo>,</mml:mo><mml:mi>J</mml:mi></mml:mrow></mml:mfenced></mml:math></disp-formula>where <inline-formula id="IE1"><mml:math id="IM1" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is the <italic toggle="yes">j</italic>th amino acid of the sequence, and <inline-formula id="IE2"><mml:math id="IM2" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is one of the canonical and non-canonical amino-acid symbols (X, B, Z, J). The integer sequence <inline-formula id="IE3"><mml:math id="IM3" display="inline" overflow="scroll"><mml:mi>f</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>,</mml:mo><mml:mi mathvariant="normal">Â </mml:mi><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1,2</mml:mn><mml:mo>,</mml:mo><mml:mo>â¦</mml:mo><mml:mo>,</mml:mo><mml:mi>L</mml:mi><mml:mi mathvariant="normal">Â </mml:mi></mml:math></inline-formula>(length of protein sequence) was embedded into 1900-long feature vectors via the UniRep method for future supervised prediction. The 1900 dimension features are calculated from the average output hidden states <inline-formula id="IE4"><mml:math id="IM4" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> in the UniRep model. The UniRep calculation details please see <xref rid="btaa1074-B3" ref-type="bibr">Alley <italic toggle="yes">et al.</italic> (2019)</xref>. For comparison, some preprint works of the state-of-the-art of protein sequence deep representation embed features including TAPE from <xref rid="btaa1074-B51" ref-type="bibr">Rao <italic toggle="yes">et al.</italic> (2019)</xref> and BiLSTM embedding from <xref rid="btaa1074-B8" ref-type="bibr">Bepler <italic toggle="yes">et al.</italic> (2019)</xref> were used. See the <xref rid="sup1" ref-type="supplementary-material">Supplementary Text S1</xref> for the details.</p>
      <fig position="float" id="btaa1074-F1">
        <label>Fig. 1.</label>
        <caption>
          <p>Modeling overview. The Golgi protein sequence is firstly convert into 1900âD features by use of the deep representation learning model, UniRep. Then 1900âD features are fed into ten classifiers; or 1900âD feature vectors are filtered by LGBM feature selection technology to reduce into 250 dimension vectors, which then fed into ten classifiers with SMOTE or not. In the next step, the top 2 classifiers are selected for further optimization with LGBM, ANOVA and MRMD feature selection. Finally, the optimal model (SVM) is used in the isGP-DRLF webserver</p>
        </caption>
        <graphic xlink:href="btaa1074f1" position="float"/>
      </fig>
    </sec>
    <sec>
      <title>2.3 Feature selection</title>
      <p>Compared to 304 training samples in D3, there are too many redundant features for a 1900-dimension UniRep feature vector of each protein sequence, which would result in overfitting of the machine learning model. In this study, three feature selection techniques were proposed to filter valid features for sub-Golgi classification. The first was ANOVA, which sorted features by measuring the ratio of their variance between and within groups (<xref rid="btaa1074-B10" ref-type="bibr">Blanca <italic toggle="yes">et al.</italic>, 2017</xref>; <xref rid="btaa1074-B57" ref-type="bibr">Tang et al., 2016</xref>). ANOVA has been widely used in bioinformatics, medical research and other fields (<xref rid="btaa1074-B35" ref-type="bibr">Jung <italic toggle="yes">et al.</italic>, 2019</xref>; <xref rid="btaa1074-B60" ref-type="bibr">Tavakkolkhah et al., 2018</xref>). The second was the LGBM algorithm (<xref rid="btaa1074-B36" ref-type="bibr">Ke <italic toggle="yes">et al.</italic>, 2017</xref>), which selected the best feature space based on feature importance values calculated by the LGBM model. Recently, LGBM feature selection methods were well applied to RNA pseudouridine site and DNA N-4-Methycytosine sites prediction (<xref rid="btaa1074-B43" ref-type="bibr">Lv <italic toggle="yes">et al.</italic>, 2020a</xref>; <xref rid="btaa1074-B44" ref-type="bibr">Lv <italic toggle="yes">et al.</italic>, 2020b</xref>). LGBM is available at <ext-link xlink:href="https://lightgbm.readthedocs.io" ext-link-type="uri">https://lightgbm.readthedocs.io</ext-link>. The third was max relevance max distance(MRMD) method (<ext-link xlink:href="http://lab.malab.cn/soft/MRMD3.0/index.html" ext-link-type="uri">http://lab.malab.cn/soft/MRMD3.0/index.html</ext-link>) (<xref rid="btaa1074-B83" ref-type="bibr">Zou et al., 2016</xref>), which is an integrated tool based PageRank strategy to use multiple different popular feature ranking algorithms to determine the properly reduced feature space.</p>
    </sec>
    <sec>
      <title>2.4 Imbalanced data processing</title>
      <p>The training benchmark dataset D3 and D5 are class imbalanced datasets, in which the number of cis-Golgi proteins is much less than that of trans-Golgi proteins. Reported sub-Golgi classifiers have demonstrated such class imbalance to significantly impact real application performance (<xref rid="btaa1074-B42" ref-type="bibr">Lv <italic toggle="yes">et al.</italic>, 2019b</xref>). That is, training results are more likely to identify the majority while ignoring the minority of classes. To overcome this and depending on sufficient quantity, under-sampling is used when sufficient sample is available and over-sampling is used when insufficient sample is available (<xref rid="btaa1074-B22" ref-type="bibr">Fernandez <italic toggle="yes">et al.</italic>, 2018</xref>). In the case of sub-Golgi classification, over-sampling is often applied using SMOTE (<xref rid="btaa1074-B6" ref-type="bibr">Barua <italic toggle="yes">et al.</italic>, 2014</xref>), which has been integrated as a module in the imbalanced-learn toolkit (<ext-link xlink:href="https://github.com/scikit-learn-contrib/imbalanced-learn" ext-link-type="uri">https://github.com/scikit-learn-contrib/imbalanced-learn</ext-link>) (<xref rid="btaa1074-B38" ref-type="bibr">Lemaitre <italic toggle="yes">et al.</italic>, 2017</xref>).</p>
    </sec>
    <sec>
      <title>2.5 Classifiers</title>
      <p>In order to determine the most suitable machine learning algorithm, we tested ten popular machine learning algorithms. They were Logistic Regression (LR), KNN, Decision Tree (DT), Gaussian Naive Bayes (GB), Bagging, Random Forest (RF) (<xref rid="btaa1074-B55" ref-type="bibr">Shi et al., 2019</xref>; <xref rid="btaa1074-B62" ref-type="bibr">Wang et al., 2019a</xref>, <xref rid="btaa1074-B65" ref-type="bibr">2020b</xref>), Ada Boosting (AB), Light Gradient Boosting Machine (LGBM), Support Vector Machine (SVM) (<xref rid="btaa1074-B27" ref-type="bibr">Huo <italic toggle="yes">et al.</italic>, 2020</xref>; <xref rid="btaa1074-B63" ref-type="bibr">Wang et al., 2019b</xref>) and Linear Discriminant Analysis (LDA). They are out-of-the-box tools in the scikit-learn toolkit (<ext-link xlink:href="https://github.com/scikit-learn/" ext-link-type="uri">https://github.com/scikit-learn/</ext-link>) (<xref rid="btaa1074-B48" ref-type="bibr">Pedregosa <italic toggle="yes">et al.</italic>, 2011</xref>). The default hyper-parameters were used for first-round classifier filtering and the top 2 classifiers were selected for hyper-parameter optimization to determine the optimal classifier. Please see the detail in the <xref rid="sup1" ref-type="supplementary-material">Supplementary Text S2</xref>.</p>
    </sec>
    <sec>
      <title>2.6 Evaluation metrics and methods</title>
      <p>As for most binary classification machine learning methods, four standard metrics including accuracy(ACC), sensitivity (Sn), specificity(Sp) and Matthew correlation coefficient(MCC) were adopted to evaluate the performance of the trained models (<xref rid="btaa1074-B18" ref-type="bibr">Ding <italic toggle="yes">et al.</italic>, 2017</xref>, <xref rid="btaa1074-B19" ref-type="bibr">2019</xref>; <xref rid="btaa1074-B26" ref-type="bibr">Hong <italic toggle="yes">et al.</italic>, 2020</xref>; <xref rid="btaa1074-B39" ref-type="bibr">Li <italic toggle="yes">et al.</italic>, 2020</xref>; <xref rid="btaa1074-B71" ref-type="bibr">Yang et al., 2018</xref>, <xref rid="btaa1074-B72" ref-type="bibr">2019a</xref>; <xref rid="btaa1074-B75" ref-type="bibr">Zeng et al., 2018</xref>, <xref rid="btaa1074-B74" ref-type="bibr">2019</xref>). They were calculated as <xref rid="E5" ref-type="disp-formula">equation (2)</xref> to <xref rid="E8" ref-type="disp-formula">(5)</xref>. For TP, TN, FP and FN when short of the predicted sample number of true positive, true negative, false positive and false negative. In this study, we denoted proteins at the cis-Golgi location as positive samples and proteins at the trans-Golgi location as negative samples. 
<disp-formula id="E5"><label>(2)</label><mml:math id="M5" display="block" overflow="scroll"><mml:mi mathvariant="normal">ACC</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>T</mml:mi><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mfrac></mml:math></disp-formula>
Â <disp-formula id="E6"><label>(3)</label><mml:math id="M6" display="block" overflow="scroll"><mml:mi mathvariant="normal">Sn</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mfrac></mml:math></disp-formula>
Â <disp-formula id="E7"><label>(4)</label><mml:math id="M7" display="block" overflow="scroll"><mml:mi mathvariant="normal">Sp</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:mfrac></mml:math></disp-formula>
Â <disp-formula id="E8"><label>(5)</label><mml:math id="M8" display="block" overflow="scroll"><mml:mi mathvariant="normal">MCC</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>Ã</mml:mo><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mo>-</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi><mml:mo>Ã</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:msqrt><mml:mfenced separators="|"><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:mfenced><mml:mo>Ã</mml:mo><mml:mfenced separators="|"><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mfenced><mml:mo>Ã</mml:mo><mml:mfenced separators="|"><mml:mrow><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:mfenced><mml:mo>Ã</mml:mo><mml:mfenced separators="|"><mml:mrow><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mfenced></mml:msqrt></mml:mrow></mml:mfrac></mml:math></disp-formula></p>
      <p>The area value (auROC) under the receiver operating characteristic (ROC) curve was also applied for model evaluation (<xref rid="btaa1074-B11" ref-type="bibr">Dao <italic toggle="yes">et al.</italic>, 2020a</xref>,<xref rid="btaa1074-B12" ref-type="bibr">b</xref>; <xref rid="btaa1074-B21" ref-type="bibr">Feng <italic toggle="yes">et al.</italic>, 2019</xref>; <xref rid="btaa1074-B79" ref-type="bibr">Zhang et al., 2008</xref>). ROC was constructed by plotting the true positive rate with respect to the false positive rate, with auROC ranging from 0 to 1. An auROC of 1 indicated prefect prediction while an auROC of 0.5 indicated random predictions for both positive and negative samples.</p>
      <p>In addition to the evaluation metrics, 10-fold and leave-one-out (LOO) cross validation (<xref rid="btaa1074-B14" ref-type="bibr">Deng <italic toggle="yes">et al.</italic>, 2020</xref>; <xref rid="btaa1074-B77" ref-type="bibr">Zhang et al., 2019a</xref>,<xref rid="btaa1074-B78" ref-type="bibr">b</xref>) and independent testing protocols were utilized (<xref rid="btaa1074-B32" ref-type="bibr">Jiao <italic toggle="yes">et al.</italic>, 2016a</xref>). Please see the detail in the <xref rid="sup1" ref-type="supplementary-material">Supplementary Text S3</xref>.</p>
    </sec>
  </sec>
  <sec>
    <title>3 Results</title>
    <sec>
      <title>3.1 Initial performances of different classifiers</title>
      <p>First, we used ten widely used machine learning algorithms to classify cis-Golgi and trans-Golgi protein sequences represented by the 1900-dimension deep learning features without data balancing or feature selection. The 10-fold cross-validation accuracy box plotting and ROC curves of these ten classifiers are shown in <xref rid="btaa1074-F2" ref-type="fig">FigureÂ 2A and B</xref>. The support vector machine classifier with the best average accuracy was 77.3% with an auROC value of 0.765, and an MCC value of 0.379 (see <xref rid="sup1" ref-type="supplementary-material">Supplementary Table S2</xref>). Here the low value of ACC, MCC and auROC might be caused by data unbalancing, that was the positive sample and negative samples were far beyond equal.</p>
      <fig position="float" id="btaa1074-F2">
        <label>Fig. 2.</label>
        <caption>
          <p>Ten-fold cross-validation accuracy metrics of Boxplots and ROC curves for ten classifiers (LR: Logistic Regression, KNN: K-nearest Neighbors, DT: Decision Tree, NB: Gaussian Naive Bayes, Bagging: Bagging, RF: Random Forest, AB: Ada Boosting, LGBM: Light Gradient Boosting Machine, SVM: Supporting Vector Machine, LDA: Linear Discriminant Analysis) using different feature processing technologies. <bold>A</bold> and <bold>B</bold> utilized UniRep feature vectors with 1900 dimensions; <bold>C</bold> and <bold>D</bold> used SMOTE to balance the UniRep feature vectors with 1900 dimensions; for <bold>E</bold> and <bold>F</bold>, based on the previous steps, 250 features were selected by using the LGBM feature selection method. Green Triangles and orange lines in A, C and E are the average accuracy values and the median accuracy values for the 10-fold cross-validation. In either case, SVM classifier had the highest average accuracy (77.32%, 90.31% and 90.76%, respectively) and the highest average auROC value (0.765, 0.940 and 0.958, respectively)</p>
        </caption>
        <graphic xlink:href="btaa1074f2" position="float"/>
      </fig>
      <p>Second, to further improve the classifiersâ accuracy, we then used SMOTE to balance the positive and negative samples with results shown in <xref rid="btaa1074-F2" ref-type="fig">FigureÂ 2C, D</xref> and <xref rid="sup1" ref-type="supplementary-material">Supplementary Table S2</xref>. After SMOTE data balancing processing, except ACC for KNN model, all 10-fold cross-validation evaluation metrics were greatly improved, especially the MCC values. The SVM classifier was again top ranked for its high accuracy and auROC value.</p>
      <p>The training dataset D3 contains 304 sequence with 87 cis-Golgi located protein sequence and 217 trains-Golgi located protein sequences. Obviously, the 1900 dimensional features are far more than the training sample numbers that would cause feature dimension redundancy and potential overfitting, so for the third step, we used LGBM feature selection technology to sort the 1900 deep representation learning features by their importance value with selection of the top 250 features for model fitting. The results are shown in <xref rid="btaa1074-F2" ref-type="fig">FigureÂ 2E, F</xref> and <xref rid="sup1" ref-type="supplementary-material">Supplementary Table S2</xref>. After feature dimension reduction, performance of some machine learning algorithms declined. For example, the accuracy of Gaussian Naive Bayes (NB), LR and AB decreased by the absolute value of 14%, 0.7% and 0.85%, respectively. The accuracy of the other seven classifiers rose by the absolute values ranging from 0.4% to 7.5%, among which SVM ranked top at ACCâ=â90.76%. LGBM ranked second best at ACCâ=â90.57%. Since the performance SVM and LGBM were quite close, both were chosen for subsequent optimization and comparison.</p>
    </sec>
    <sec>
      <title>3.2 Effect of feature selection technologies on SVM and LGBM classifiers</title>
      <p>To determine the optimal feature space for SVM and LGBM classifiers, we used a two-step feature optimizing strategy. In the first step, we used three feature selection technologies, (ANOVA, MRMD and LGBM) to calculate the feature importance values like F-score for ANOVA, page-ranked values for MRMD and Gini-based feature importance values for LGBM to yield three descending order lists for deep representation learning features. In the second step, for each feature list obtained by different methods, we selected the top 200 features and used a feature-by-feature incremental strategy to determine the optimal feature vector space for SVM and LGBM classifiers. The 10-fold cross-validation accuracy results are shown in <xref rid="btaa1074-F3" ref-type="fig">FigureÂ 3A</xref>. For example, the black curve with the ANOVA_SVM legend is the accuracy of the SVM model varying by the increasing number of features selected by the ANOVA method.</p>
      <fig position="float" id="btaa1074-F3">
        <label>Fig. 3.</label>
        <caption>
          <p>(<bold>A</bold>) Based on benchmark dataset D3, the average 10-fold cross-validation accuracy varied with the feature numbers for LGBM and SVM classifiers based on ANOVA, MRMD and LGBM feature selection technology. The best SVM had an accuracy of 92.16% with 158 features. The best LGBM classifier had an accuracy of 93.08% with 64 features. Both were based on LGBM feature selection technology. (<bold>B</bold>) Ten-fold cross-validation and LOO metrics for comparison of the best SVM (based on benchmark dataset D3 and D5) and LGBM classifier (based on benchmark dataset D3). (<bold>C</bold>) Independent test metrics on benchmark testing dataset D4 for the best SVM and LGBM classifier obtained by LOO using benchmark dataset D3 and D5</p>
        </caption>
        <graphic xlink:href="btaa1074f3" position="float"/>
      </fig>
      <p>Initially, as the number of features increased, each accuracy curve for the model increased sharply and then approached fluctuating plateaus. For the accuracy value of each curve plateau, both SVM and LGBM classifiers with feature space were determined by LGBM feature selection (the LGBM_SVM model is the purple curve and the LGBM_LGBM model is the golden curve in <xref rid="btaa1074-F3" ref-type="fig">Fig.Â 3A</xref>). Each was more accurate than those based on ANOVA and MRMD methods. The maximum accuracy of the LGBM_LGBM model was 93.08% with 64 features and was more than the 92.16% for the LGBM_SVM model with 158 features. The accuracy of the LGBM_LGBM model were less than the LGBM_SVM model with feature numbers ranging 140 to 200.</p>
      <p>Considering the stability, robustness and generalization of the model, LGBM_SVM was selected as the final prediction model based on the following facts. The fluctuating purple and golden curves as well as the violin-box plotting insets, which are statistical accuracy values for feature numbers ranging from 35 to 200, are shown in <xref rid="btaa1074-F3" ref-type="fig">FigureÂ 3A</xref>. For the LGBM_SVM model, the accuracy fluctuated less with a smaller deviation. Since the LOO cross-validation model is more robust and stable, we compared two models by different cross-validation evaluation methods. Despite the 10-fold cross validation metrics (ACC, MCC, Sn and auROC, but not Sp) for the LGBM_LGBM (LGBM_10Fold) model were better than the LGBM_SVM (SVM_10 Fold) model, as shown in the bar graph in <xref rid="btaa1074-F3" ref-type="fig">FigureÂ 3B</xref>, the LOO cross validation metrics (ACC, MCC, Sn, Sp and auROC) for LGBM_SVM (SVM_LOO) exceeded those of LGBM_LGBM (SVM_LOO). Moreover, the independent testing scores for SVM (SVM_LOO) were greater than the scores for LGBM (LGBM_LOO) as shown in <xref rid="btaa1074-F3" ref-type="fig">FigureÂ 3C</xref>.</p>
      <p>Although <xref rid="btaa1074-B70" ref-type="bibr">Yang <italic toggle="yes">et al.</italic> (2016b</xref>) have been considering that the training dataset D3 and test dataset D4 may be similar sequences shared by them, they have used CD-HIT tool to obtain sequences with a 40% identity, resulting in D3 dataset. However, the sample numbers of training dataset D3 is not enough to eliminate the overfitting of training model. As we could see from learning curves in <xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S2A</xref> and B, model SVM-D3_1900Features (with 1900 features) and SVM-D3_158Features (with 158 selected features) are overfitting to some extent. Although the overfitting degree of SVM-D3_158Features is lower than that of SVM-D3_1900Features after feature selection and SMOTE, the overfitting is still present and it should not be ignored as the overfitting affects the reliability and robustness of the applied models.</p>
      <p>In this work to overcome overfitting, the means of increasing the number of training dataset samples and decreasing sequence homology were adopted. That is, we construct a new dataset D5 with homology identity value smaller than 25% using PSI-CD-HIT as described in Section 2.1. Based on new benchmark dataset D5, we have used the modeling flow as showed in <xref rid="btaa1074-F1" ref-type="fig">FigureÂ 1</xref> to optimize the SVM model combined with SMOTE and LGBM feature selection technology. As results displayed in <xref rid="btaa1074-F3" ref-type="fig">FigureÂ 3B</xref>, the 10-fold and LOO cross-validation scores SVM model (SVM-D5) with 107 features (see <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S1</xref>) trained on D5 were of great improvement over those of SVM model (SVM-D5) with 158 features trained on D3. For instance, the 10-fold and LOO accuracy of SVM-D5 were both 99.2%, which was increased by the relative values of 7.59% and 7.12% to the values of SVM-D3 (92.2% and 92.6%). Evidently showing in <xref rid="btaa1074-F3" ref-type="fig">FigureÂ 3B</xref>, the training data volume increasing from 304 sequences in D3 to 1147 sequences in D5, the performance of SVM-D5 improved markedly over that of SVM-D3. Furthermore, while the increase of training data volume, the over-fitting of SVM-D5 (with 158 features) was greatly reduced compared with SVM-D3 as showed in the learning-curves of <xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S2</xref>. Obviously, the overfitting of SVM-D5 with 107 features trained on D5 was overcome and could be ignored as it can be seen from <xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S2</xref>.</p>
    </sec>
    <sec>
      <title>3.3 Comparison with the state-of-the-art deep representation feature types</title>
      <p>For comparison, four types of deep representation feature from two preprint works were used for selection of best feature type for the sub-Golgi prediction task. The leave-one-out cross-validation and testing results of SVM model trained on D3 and D5 dataset using BiLSTM-lm, BiLSTM-ssa, TAPE-pooled and TAPE-avg features respectively are listed in <xref rid="btaa1074-T1" ref-type="table">TableÂ 1</xref>. For models trained on D3, the model using UniRep features obtained the best leave-one-out cross-validation accuracy scores and independent testing scores. For models trained on D5, the model using UniRep features got the value 99.2% of leave-one-out cross-validation accuracy, a little smaller than the value of models using BiLSTM-lm, BiLSTM-ssa, TAPE-avg by the relative values of 0.2%, 0.6% and 0.5%, separately. While the independent testing accuracy of model using UniRep feature is 96.4%, much greater than the value of models using BiLSTM-lm, BiLSTM-ssa, TAPE-avg by the relative values of 4.5%, 10.1% and 8.2%.</p>
      <table-wrap position="float" id="btaa1074-T1">
        <label>Table1.</label>
        <caption>
          <p>Evaluation metrics comparisons of support vector machine classifiers based on different state-of-the-art deep representation learning features</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="char" char="[" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="2" colspan="1">Feature type</th>
              <th rowspan="2" colspan="1">Trained dataset (identity)</th>
              <th rowspan="2" colspan="1">Feature dimensions</th>
              <th colspan="5" rowspan="1">LOO cross-validation<hr/></th>
              <th colspan="5" rowspan="1">Independent testing<hr/></th>
            </tr>
            <tr>
              <th rowspan="1" colspan="1">ACC (%)</th>
              <th rowspan="1" colspan="1">MCC</th>
              <th rowspan="1" colspan="1">Sn (%)</th>
              <th rowspan="1" colspan="1">Sp (%)</th>
              <th rowspan="1" colspan="1">auROC</th>
              <th rowspan="1" colspan="1">ACC (%)</th>
              <th rowspan="1" colspan="1">MCC</th>
              <th rowspan="1" colspan="1">Sn (%)</th>
              <th rowspan="1" colspan="1">Sp (%)</th>
              <th rowspan="1" colspan="1">auROC</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="2" colspan="1">UniRep</td>
              <td rowspan="1" colspan="1">D3 (40%)</td>
              <td rowspan="1" colspan="1">158</td>
              <td rowspan="1" colspan="1">92.6</td>
              <td rowspan="1" colspan="1">0.85</td>
              <td rowspan="1" colspan="1">94.9</td>
              <td rowspan="1" colspan="1">90.3</td>
              <td rowspan="1" colspan="1">0.964</td>
              <td rowspan="1" colspan="1">98.4</td>
              <td rowspan="1" colspan="1">0.95</td>
              <td rowspan="1" colspan="1">100</td>
              <td rowspan="1" colspan="1">98.0</td>
              <td rowspan="1" colspan="1">0.995</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">D5 (25%)</td>
              <td rowspan="1" colspan="1">107</td>
              <td rowspan="1" colspan="1">99.2</td>
              <td rowspan="1" colspan="1">0.98</td>
              <td rowspan="1" colspan="1">100</td>
              <td rowspan="1" colspan="1">98.4</td>
              <td rowspan="1" colspan="1">0.999</td>
              <td rowspan="1" colspan="1">96.4</td>
              <td rowspan="1" colspan="1">0.90</td>
              <td rowspan="1" colspan="1">100</td>
              <td rowspan="1" colspan="1">84.6</td>
              <td rowspan="1" colspan="1">0.994</td>
            </tr>
            <tr>
              <td rowspan="2" colspan="1">BiLSTM-lm</td>
              <td rowspan="1" colspan="1">D3 (40%)</td>
              <td rowspan="1" colspan="1">77</td>
              <td rowspan="1" colspan="1">88.7</td>
              <td rowspan="1" colspan="1">0.78</td>
              <td rowspan="1" colspan="1">85.2</td>
              <td rowspan="1" colspan="1">92.1</td>
              <td rowspan="1" colspan="1">0.917</td>
              <td rowspan="1" colspan="1">92.1</td>
              <td rowspan="1" colspan="1">0.75</td>
              <td rowspan="1" colspan="1">96.1</td>
              <td rowspan="1" colspan="1">76.9</td>
              <td rowspan="1" colspan="1">0.983</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">D5 (25%)</td>
              <td rowspan="1" colspan="1">152</td>
              <td rowspan="1" colspan="1">99.4</td>
              <td rowspan="1" colspan="1">0.99</td>
              <td rowspan="1" colspan="1">99.9</td>
              <td rowspan="1" colspan="1">98.9</td>
              <td rowspan="1" colspan="1">0.999</td>
              <td rowspan="1" colspan="1">92.2</td>
              <td rowspan="1" colspan="1">0.75</td>
              <td rowspan="1" colspan="1">100</td>
              <td rowspan="1" colspan="1">61.5</td>
              <td rowspan="1" colspan="1">0.989</td>
            </tr>
            <tr>
              <td rowspan="2" colspan="1">BiLSTM-ssa</td>
              <td rowspan="1" colspan="1">D3 (40%)</td>
              <td rowspan="1" colspan="1">93</td>
              <td rowspan="1" colspan="1">91.7</td>
              <td rowspan="1" colspan="1">0.83</td>
              <td rowspan="1" colspan="1">90.7</td>
              <td rowspan="1" colspan="1">92.6</td>
              <td rowspan="1" colspan="1">0.946</td>
              <td rowspan="1" colspan="1">90.6</td>
              <td rowspan="1" colspan="1">0.71</td>
              <td rowspan="1" colspan="1">94.1</td>
              <td rowspan="1" colspan="1">76.9</td>
              <td rowspan="1" colspan="1">0.975</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">D5 (25%)</td>
              <td rowspan="1" colspan="1">48</td>
              <td rowspan="1" colspan="1">99.8</td>
              <td rowspan="1" colspan="1">0.99</td>
              <td rowspan="1" colspan="1">100</td>
              <td rowspan="1" colspan="1">99.7</td>
              <td rowspan="1" colspan="1">0.999</td>
              <td rowspan="1" colspan="1">87.5</td>
              <td rowspan="1" colspan="1">0.58</td>
              <td rowspan="1" colspan="1">100</td>
              <td rowspan="1" colspan="1">38.5</td>
              <td rowspan="1" colspan="1">0.956</td>
            </tr>
            <tr>
              <td rowspan="2" colspan="1">TAPE-pooled</td>
              <td rowspan="1" colspan="1">D3 (40%)</td>
              <td rowspan="1" colspan="1">77</td>
              <td rowspan="1" colspan="1">90.3</td>
              <td rowspan="1" colspan="1">0.81</td>
              <td rowspan="1" colspan="1">89.9</td>
              <td rowspan="1" colspan="1">90.7</td>
              <td rowspan="1" colspan="1">0.941</td>
              <td rowspan="1" colspan="1">90.6</td>
              <td rowspan="1" colspan="1">0.70</td>
              <td rowspan="1" colspan="1">96.0</td>
              <td rowspan="1" colspan="1">69.2</td>
              <td rowspan="1" colspan="1">0.966</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">D5 (25%)</td>
              <td rowspan="1" colspan="1">53</td>
              <td rowspan="1" colspan="1">98.7</td>
              <td rowspan="1" colspan="1">0.97</td>
              <td rowspan="1" colspan="1">100</td>
              <td rowspan="1" colspan="1">97.5</td>
              <td rowspan="1" colspan="1">0.999</td>
              <td rowspan="1" colspan="1">90.6</td>
              <td rowspan="1" colspan="1">0.69</td>
              <td rowspan="1" colspan="1">98.0</td>
              <td rowspan="1" colspan="1">61.5</td>
              <td rowspan="1" colspan="1">0.927</td>
            </tr>
            <tr>
              <td rowspan="2" colspan="1">TAPE-avg</td>
              <td rowspan="1" colspan="1">D3 (40%)</td>
              <td rowspan="1" colspan="1">67</td>
              <td rowspan="1" colspan="1">91.9</td>
              <td rowspan="1" colspan="1">0.84</td>
              <td rowspan="1" colspan="1">94.0</td>
              <td rowspan="1" colspan="1">89.9</td>
              <td rowspan="1" colspan="1">0.963</td>
              <td rowspan="1" colspan="1">96.4</td>
              <td rowspan="1" colspan="1">0.91</td>
              <td rowspan="1" colspan="1">100</td>
              <td rowspan="1" colspan="1">96.1</td>
              <td rowspan="1" colspan="1">0.985</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">D5 (25%)</td>
              <td rowspan="1" colspan="1">73</td>
              <td rowspan="1" colspan="1">99.7</td>
              <td rowspan="1" colspan="1">0.99</td>
              <td rowspan="1" colspan="1">100</td>
              <td rowspan="1" colspan="1">99.3</td>
              <td rowspan="1" colspan="1">0.999</td>
              <td rowspan="1" colspan="1">89.1</td>
              <td rowspan="1" colspan="1">0.64</td>
              <td rowspan="1" colspan="1">100</td>
              <td rowspan="1" colspan="1">46.1</td>
              <td rowspan="1" colspan="1">0.989</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
      <p>Considering both scores of leave-one-out cross-validation and independent testing of different models based on the 5 types of feature listed in <xref rid="btaa1074-T1" ref-type="table">TableÂ 1</xref>, the SVM model with 107 deep representation learning features (after leave-one-out cross validation) is the final optimal model on the webserver, isGP-DRLF (Identify Sub-Golgi Protein via Deep Representation Learning Features).</p>
    </sec>
    <sec>
      <title>3.4 Comparison with the state-of-the-art classifiers</title>
      <p>To further evaluate the performance of our classifiers, we compared isGP-DRLF with state-of-the-art classifiers in Supplement <xref rid="sup1" ref-type="supplementary-material">Table S3</xref>. <xref rid="sup1" ref-type="supplementary-material">Supplementary Table S3</xref> summarizes the LOO cross-validation metrics of published classifiers based on different benchmark training dataset D0, D1, D2 and D3 listed in Supplement <xref rid="sup1" ref-type="supplementary-material">Table S1</xref>. Classifiers based on the D3 dataset were superior to other classifiers based on D0, D1 and D2. Apart from the isGP-DRLF of this study and Dingâs SVM model (<xref rid="btaa1074-B15" ref-type="bibr">Ding <italic toggle="yes">et al.</italic>, 2013</xref>), other reported sub-Golgi classifiers had to fuse multi-type features to attain acceptable results. The isGP-DRLF was far better than Dingâs SVM model (<xref rid="btaa1074-B15" ref-type="bibr">Ding <italic toggle="yes">et al.</italic>, 2013</xref>) as judged by LOO cross-validation (<xref rid="sup1" ref-type="supplementary-material">Supplementary Table S3</xref>) and independent testing scores (<xref rid="sup1" ref-type="supplementary-material">Supplementary Table S4</xref>). The six models based on the D3 training are shown in Supplement <xref rid="sup1" ref-type="supplementary-material">Tables S3 and S4</xref> and in the main text <xref rid="btaa1074-T2" ref-type="table">TableÂ 2</xref>. KNN sub-Golgi localization protein classifier developed by <xref rid="btaa1074-B1" ref-type="bibr">Ahmad <italic toggle="yes">et al.</italic> (2019)</xref> had Split Amino Acid Composition (SAAC), 3gap Dipeptide Composition (3gDPC) and Position Specific Scoring Matrix (PSSM) fusion features and realized a best LOO accuracy of 98.2% with independent test accuracy of 94.0%. Our isGP-DRLF based on D5 had 107 UniRep features and achieved 99.2% LOO accuracy and independent test accuracy of 96.4%. Evidently, given the independent testing results of the models based on D3 and D5 in this study, isGP-DRLF is better at predicting unknown sub-Golgi protein sequences.</p>
      <table-wrap position="float" id="btaa1074-T2">
        <label>Table2.</label>
        <caption>
          <p>Evaluation metrics comparisons of the state-of-the-art classifiers</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="2" colspan="1">Classifier</th>
              <th rowspan="2" colspan="1">Trained dataset</th>
              <th rowspan="2" colspan="1">Feature type numbers</th>
              <th rowspan="2" colspan="1">Features dimensions</th>
              <th colspan="4" rowspan="1">LOO Cross-validation<hr/></th>
              <th colspan="4" rowspan="1">Independent testing<hr/></th>
            </tr>
            <tr>
              <th rowspan="1" colspan="1">ACC (%)</th>
              <th rowspan="1" colspan="1">MCC</th>
              <th rowspan="1" colspan="1">Sn (%)</th>
              <th rowspan="1" colspan="1">Sp (%)</th>
              <th rowspan="1" colspan="1">ACC (%)</th>
              <th rowspan="1" colspan="1">MCC</th>
              <th rowspan="1" colspan="1">Sn (%)</th>
              <th rowspan="1" colspan="1">Sp (%)</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">SVM (this study)</td>
              <td rowspan="1" colspan="1">D3</td>
              <td rowspan="1" colspan="1">1</td>
              <td rowspan="1" colspan="1">158</td>
              <td rowspan="1" colspan="1">92.6</td>
              <td rowspan="1" colspan="1">0.85</td>
              <td rowspan="1" colspan="1">94.9</td>
              <td rowspan="1" colspan="1">90.3</td>
              <td rowspan="1" colspan="1">98.4</td>
              <td rowspan="1" colspan="1">0.95</td>
              <td rowspan="1" colspan="1">100</td>
              <td rowspan="1" colspan="1">98.0</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">SVM (this study)</td>
              <td rowspan="1" colspan="1">D5</td>
              <td rowspan="1" colspan="1">1</td>
              <td rowspan="1" colspan="1">107</td>
              <td rowspan="1" colspan="1">99.2</td>
              <td rowspan="1" colspan="1">0.98</td>
              <td align="center" rowspan="1" colspan="1">100%</td>
              <td rowspan="1" colspan="1">98.4</td>
              <td rowspan="1" colspan="1">96.4</td>
              <td rowspan="1" colspan="1">0.90</td>
              <td rowspan="1" colspan="1">100</td>
              <td rowspan="1" colspan="1">84.6</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">KNN (<xref rid="btaa1074-B2" ref-type="bibr">Ahmad <italic toggle="yes">et al.</italic>, 2017</xref>)</td>
              <td rowspan="1" colspan="1">D3</td>
              <td rowspan="1" colspan="1">3</td>
              <td rowspan="1" colspan="1">83</td>
              <td rowspan="1" colspan="1">94.9</td>
              <td rowspan="1" colspan="1">0.90</td>
              <td rowspan="1" colspan="1">97.2</td>
              <td rowspan="1" colspan="1">92.6</td>
              <td rowspan="1" colspan="1">94.8</td>
              <td rowspan="1" colspan="1">0.86</td>
              <td rowspan="1" colspan="1">94.0</td>
              <td rowspan="1" colspan="1">93.9</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">KNN (<xref rid="btaa1074-B1" ref-type="bibr">Ahmad <italic toggle="yes">et al.</italic>, 2019</xref>)</td>
              <td rowspan="1" colspan="1">D3</td>
              <td rowspan="1" colspan="1">3</td>
              <td rowspan="1" colspan="1">180</td>
              <td rowspan="1" colspan="1">98.2</td>
              <td rowspan="1" colspan="1">0.96</td>
              <td rowspan="1" colspan="1">98.6</td>
              <td rowspan="1" colspan="1">97.7</td>
              <td rowspan="1" colspan="1">94.0</td>
              <td rowspan="1" colspan="1">0.84</td>
              <td rowspan="1" colspan="1">81.5</td>
              <td rowspan="1" colspan="1">96.9</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">RF (<xref rid="btaa1074-B70" ref-type="bibr">Yang <italic toggle="yes">et al.</italic>, 2016b</xref>)</td>
              <td rowspan="1" colspan="1">D3</td>
              <td rowspan="1" colspan="1">4</td>
              <td rowspan="1" colspan="1">55</td>
              <td rowspan="1" colspan="1">88.5</td>
              <td rowspan="1" colspan="1">0.68</td>
              <td rowspan="1" colspan="1">88.9</td>
              <td rowspan="1" colspan="1">88.0</td>
              <td rowspan="1" colspan="1">93.8</td>
              <td rowspan="1" colspan="1">0.82</td>
              <td rowspan="1" colspan="1">92.3</td>
              <td rowspan="1" colspan="1">94.1</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">SVM (<xref rid="btaa1074-B50" ref-type="bibr">Rahman <italic toggle="yes">et al.</italic>, 2018</xref>)</td>
              <td rowspan="1" colspan="1">D3</td>
              <td rowspan="1" colspan="1">6</td>
              <td rowspan="1" colspan="1">2800</td>
              <td rowspan="1" colspan="1">95.9</td>
              <td rowspan="1" colspan="1">0.92</td>
              <td rowspan="1" colspan="1">95.9</td>
              <td rowspan="1" colspan="1">92.6</td>
              <td rowspan="1" colspan="1">95.3</td>
              <td rowspan="1" colspan="1">0.85</td>
              <td rowspan="1" colspan="1">84.6</td>
              <td rowspan="1" colspan="1">98.0</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
      <p>Considering the independent testing dataset D4 consisting of 64 sequence and to test the model practical application capacity, we also applied isGP-DRLF to the human sub-Golgi proteome dataset with 423 sequence. The sequence location distribution is drawn in <xref rid="btaa1074-F4" ref-type="fig">FigureÂ 4A</xref>. It attained 91.8% accuracy for reviewed human sub-Golgi proteome while it predicted that about 28% unreviewed human sub-Golgi proteome would be located in cis-Golgi and 72% would be located in trans-Golgi (see <xref rid="btaa1074-F4" ref-type="fig">Fig.Â 4B and D</xref>). While among state-of-the-art predictors listed in <xref rid="btaa1074-T2" ref-type="table">TableÂ 2</xref>, now only Linâs subGolgi2 webserver is available (<ext-link xlink:href="http://lin-group.cn/server/subGolgi2" ext-link-type="uri">http://lin-group.cn/server/subGolgi2</ext-link>) (<xref rid="btaa1074-B15" ref-type="bibr">Ding <italic toggle="yes">et al.</italic>, 2013</xref>). The subGolgi2 is a predictor using 2 gap dipeptide composition (2gDPC) features and we also tested it with human sub-Golgi proteome dataset and results are shown in <xref rid="btaa1074-F4" ref-type="fig">FigureÂ 4C and D</xref>. For reviewed sequences, subGolgi2 got accuracy of 77.3%, by the relative value of 16% lower than that of isGP-DRLF.</p>
      <fig position="float" id="btaa1074-F4">
        <label>Fig. 4.</label>
        <caption>
          <p>Human sub-Golgi proteome sequence distribution and the results of isGP-DRLF and suGolgi2 tested on human sub-Golgi proteome dataset</p>
        </caption>
        <graphic xlink:href="btaa1074f4" position="float"/>
      </fig>
      <p>To explain the difference between the models and feature representation capability, we used UMAP(uniform manifold approximation and projection) method (<xref rid="btaa1074-B45" ref-type="bibr">Mcinnes <italic toggle="yes">et al.</italic>, 2018</xref>) to reduce the UniRep feature space and 2 gap dipeptide composition features space dimensions into two and the dimension reduction results were shown in in the <xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S3</xref>. From <xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S3A</xref> and B, it found out that it was better to use UniRep features than use 2gDPC features for identifying proteins located in cis-Golgi from proteins located in trans-Golgi. Also, as displayed in <xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S3A</xref> to H for protein sub-Golgi localization task, UniRep features are superior to some widely used feature types listed in <xref rid="sup1" ref-type="supplementary-material">Supplementary Table S3</xref>. The strong sequence feature representation capability of UniRep enables us to use only one feature type to achieve good classification accuracy without using features fusion technology.</p>
    </sec>
    <sec>
      <title>3.5 Webserver implementation</title>
      <p>The isGP-DRLF is now available at <ext-link xlink:href="http://isGP-DRLF.aibiochem.net" ext-link-type="uri">http://isGP-DRLF.aibiochem.net</ext-link> and its interface is shown in <xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S4</xref>. The webserver allows input of FASTA format protein sequences and identifies whether a protein is found in cis-Golgi or trans-Golgi. The users could paste FASTA format Golgi protein sequence in the left blank box and click the submit button to calculate. After a while, the prediction results will be showed in the right table. Before starting a new task, the users have to clear the input box first to reactivate the submit button and then paste new sequence in the blank input box. Due to limited computing resources, do not input more than 5 sequences at a time. For larger dataset computing, the users could download the python script and the trained model from <ext-link xlink:href="https://github.com/zhibinlv/isGP-DRLF" ext-link-type="uri">https://github.com/zhibinlv/isGP-DRLF</ext-link>.</p>
    </sec>
  </sec>
  <sec>
    <title>4 Conclusion</title>
    <p>A novel state-of-the-art sub-Golgi protein localization classifier, isGP-DRLF, was developed by use of protein sequence deep representation learning feature vectors. Combined with over-sampling, imbalanced data processing and LGBM feature selection, isGP-DRLF achieved the best independent testing evaluation accuracy values (ACCâ=â96.4%) for sub-Golgi protein prediction, which increases by 1.15% relative to the corresponding best value (ACCâ=â95.3%) for the previously reported models isGPT (<xref rid="btaa1074-B50" ref-type="bibr">Rahman <italic toggle="yes">et al.</italic>, 2018</xref>) listed in <xref rid="btaa1074-T2" ref-type="table">TableÂ 2</xref>. For independent testing error rate, the absolute error rate value of isGP-DRLF is 3.6%, which reduced by 23.4% relative to the absolute error rate value 4.7% of the previous best-reported model isGPT (<xref rid="btaa1074-B50" ref-type="bibr">Rahman <italic toggle="yes">et al.</italic>, 2018</xref>). The isGP-DRLF employs just one type of sequence representation feature with performance superior to other state-of-the-art sub-Golgi classifiers fusing multiple types of feature representations. This study shows that protein sequence deep representation learning is a type of very discriminating feature vector that distinguishes multiple sequences, which will be useful in the future for a more accurate prediction of protein multi-subcellular localization (<xref rid="btaa1074-B4" ref-type="bibr">Armenteros <italic toggle="yes">et al.</italic>, 2017</xref>) and for recognition of protein chemical modification sites, signal peptide without a requirement for multi-type feature fusion (<xref rid="btaa1074-B5" ref-type="bibr">Armenteros <italic toggle="yes">et al.</italic>, 2019</xref>; <xref rid="btaa1074-B69" ref-type="bibr">Yang et al., 2016a</xref>). The current model only applies to sub-Golgi prediction. In the future, we will apply deep presentation learning features for eukaryotic proteins multiple subcellular and suborganellar localization prediction, functioning like DeepLoc (<xref rid="btaa1074-B4" ref-type="bibr">Armenteros <italic toggle="yes">et al.</italic>, 2017</xref>) or MULocDeep (<xref rid="btaa1074-B30" ref-type="bibr">Jiang <italic toggle="yes">et al.</italic>, 2020a</xref>).</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material id="sup1" position="float" content-type="local-data">
      <label>btaa1074_Supplementary_Data</label>
      <media xlink:href="btaa1074_supplementary_data.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ack id="ack1">
    <title>Acknowledgements</title>
    <p>The authors are really appreciated to the three anonymous reviewers. Their constructive comments are very helpful for strengthening the presentation of this paper.</p>
    <sec>
      <title>Funding</title>
      <p>The work was funded by the National Natural Science Foundation of China [62001090, 91935302, 61922020, 61822108 and 61771331], and by the China Postdoctoral Science Foundation [2020M673184].</p>
      <p><italic toggle="yes">Conflict of Interest</italic>: none declared.</p>
    </sec>
  </ack>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="btaa1074-B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ahmad</surname><given-names>J.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2019</year>) 
<article-title>MFSC: multi-voting based feature selection for classification of Golgi proteins by adopting the general form of Chou's PseAAC components</article-title>. <source>J. Theor. Biol</source>., <volume>463</volume>, <fpage>99</fpage>â<lpage>109</lpage>.<pub-id pub-id-type="pmid">30562500</pub-id></mixed-citation>
    </ref>
    <ref id="btaa1074-B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ahmad</surname><given-names>J.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2017</year>) 
<article-title>Intelligent computational model for classification of sub-Golgi protein using oversampling and fisher feature selection methods</article-title>. <source>Artif. Intell. Med</source>., <volume>78</volume>, <fpage>14</fpage>â<lpage>22</lpage>.<pub-id pub-id-type="pmid">28764869</pub-id></mixed-citation>
    </ref>
    <ref id="btaa1074-B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Alley</surname><given-names>E.C.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2019</year>) 
<article-title>Unified rational protein engineering with sequence-based deep representation learning</article-title>. <source>Nat. Methods</source>, <volume>16</volume>, <fpage>1315</fpage>â<lpage>1322</lpage>.<pub-id pub-id-type="pmid">31636460</pub-id></mixed-citation>
    </ref>
    <ref id="btaa1074-B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Armenteros</surname><given-names>J.J.A.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2017</year>) 
<article-title>DeepLoc: prediction of protein subcellular localization using deep learning</article-title>. <source>Bioinformatics</source>, <volume>33</volume>, <fpage>4049</fpage>â<lpage>4049</lpage>.<pub-id pub-id-type="pmid">29028934</pub-id></mixed-citation>
    </ref>
    <ref id="btaa1074-B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Armenteros</surname><given-names>J.J.A.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2019</year>) 
<article-title>SignalP 5.0 improves signal peptide predictions using deep neural networks</article-title>. <source>Nat. Biotechnol</source>., <volume>37</volume>, <fpage>420</fpage>.<pub-id pub-id-type="pmid">30778233</pub-id></mixed-citation>
    </ref>
    <ref id="btaa1074-B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Barua</surname><given-names>S.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2014</year>) 
<article-title>MWMOTE-majority weighted minority oversampling technique for imbalanced data set learning</article-title>. <source>IEEE Trans. Knowl. Data Eng</source>., <volume>26</volume>, <fpage>405</fpage>â<lpage>425</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa1074-B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bateman</surname><given-names>A.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2019</year>) 
<article-title>UniProt: a worldwide hub of protein knowledge</article-title>. <source>Nucleic Acids Res</source>., <volume>47</volume>, <fpage>D506</fpage>â<lpage>D515</lpage>.<pub-id pub-id-type="pmid">30395287</pub-id></mixed-citation>
    </ref>
    <ref id="btaa1074-B8">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Bepler</surname><given-names>T.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2019</year>) Learning protein sequence embeddings using information from structure. <fpage>arXiv:1902.08661</fpage>.</mixed-citation>
    </ref>
    <ref id="btaa1074-B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Berry</surname><given-names>K.P.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2017</year>) 
<article-title>Spine dynamics: are they all the same?</article-title> Â <source>Neuron</source>, <volume>96</volume>, <fpage>43</fpage>â<lpage>55</lpage>.<pub-id pub-id-type="pmid">28957675</pub-id></mixed-citation>
    </ref>
    <ref id="btaa1074-B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Blanca</surname><given-names>M.J.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2017</year>) 
<article-title>Non-normal data: is ANOVA still a valid option?</article-title> Â <source>Psicothema</source>, <volume>29</volume>, <fpage>552</fpage>â<lpage>557</lpage>.<pub-id pub-id-type="pmid">29048317</pub-id></mixed-citation>
    </ref>
    <ref id="btaa1074-B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dao</surname><given-names>F.Y.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2020a</year>) 
<article-title>Computational identification of N6-methyladenosine sites in multiple tissues of mammals</article-title>. <source>Comput. Struct. Biotechnol. J</source>., <volume>18</volume>, <fpage>1084</fpage>â<lpage>1091</lpage>.<pub-id pub-id-type="pmid">32435427</pub-id></mixed-citation>
    </ref>
    <ref id="btaa1074-B12">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dao</surname><given-names>F.Y.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2020b</year>) 
<article-title>A computational platform to identify origins of replication sites in eukaryotes</article-title>. <source>Brief Bioinf</source>., 10.1093/bib/bbaa1017.</mixed-citation>
    </ref>
    <ref id="btaa1074-B13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>De Tito</surname><given-names>S.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2020</year>) 
<article-title>The Golgi as an Assembly Line to the Autophagosome</article-title>. <source>Trends Biochem. Sci</source>., <volume>45</volume>, <fpage>484</fpage>â<lpage>496</lpage>.<pub-id pub-id-type="pmid">32307224</pub-id></mixed-citation>
    </ref>
    <ref id="btaa1074-B14">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Deng</surname><given-names>Y.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2020</year>) 
<article-title>A multimodal deep learning framework for predicting drug-drug interaction events</article-title>. <source>Bioinformatics</source>, <volume>36</volume>, <fpage>4316</fpage>â<lpage>4322</lpage>.<pub-id pub-id-type="pmid">32407508</pub-id></mixed-citation>
    </ref>
    <ref id="btaa1074-B15">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ding</surname><given-names>H.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2013</year>) 
<article-title>Prediction of Golgi-resident protein types by using feature selection technique</article-title>. <source>Chemom. Intell. Lab. Syst</source>., <volume>124</volume>, <fpage>9</fpage>â<lpage>13</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa1074-B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ding</surname><given-names>H.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2011</year>) 
<article-title>Identify golgi protein types with modified mahalanobis discriminant algorithm and pseudo amino acid composition</article-title>. <source>Protein Peptide Lett</source>., <volume>18</volume>, <fpage>58</fpage>â<lpage>63</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa1074-B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ding</surname><given-names>H.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2016</year>) 
<article-title>PHYPred: a tool for identifying bacteriophage enzymes and hydrolases</article-title>. <source>Virologica Sinica</source>, <volume>31</volume>, <fpage>350</fpage>â<lpage>352</lpage>.<pub-id pub-id-type="pmid">27151186</pub-id></mixed-citation>
    </ref>
    <ref id="btaa1074-B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ding</surname><given-names>Y.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2017</year>) 
<article-title>Identification of drug-target interactions via multiple information integration</article-title>. <source>Inf. Sci</source>., <volume>418â419</volume>, <fpage>546</fpage>â<lpage>560</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa1074-B19">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ding</surname><given-names>Y.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2019</year>) 
<article-title>Identification of drug-side effect association via multiple information integration with centered kernel alignment</article-title>. <source>Neurocomputing</source>, <volume>325</volume>, <fpage>211</fpage>â<lpage>224</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa1074-B20">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Eraslan</surname><given-names>G.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2019</year>) 
<article-title>Deep learning: new computational modelling techniques for genomics</article-title>. <source>Nat. Rev. Genet</source>., <volume>20</volume>, <fpage>389</fpage>â<lpage>403</lpage>.<pub-id pub-id-type="pmid">30971806</pub-id></mixed-citation>
    </ref>
    <ref id="btaa1074-B21">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Feng</surname><given-names>C.Q.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2019</year>) 
<article-title>iTerm-PseKNC: a sequence-based tool for predicting bacterial transcriptional terminators</article-title>. <source>Bioinformatics</source>, <volume>35</volume>, <fpage>1469</fpage>â<lpage>1477</lpage>.<pub-id pub-id-type="pmid">30247625</pub-id></mixed-citation>
    </ref>
    <ref id="btaa1074-B22">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fernandez</surname><given-names>A.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2018</year>) 
<article-title>SMOTE for learning from imbalanced data: progress and challenges, marking the 15-year anniversary</article-title>. <source>J. Artif. Intell. Res</source>., <volume>61</volume>, <fpage>863</fpage>â<lpage>905</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa1074-B23">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fujita</surname><given-names>Y.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2006</year>) 
<article-title>Fragmentation of Golgi apparatus of nigral neurons with alpha-synuclein-positive inclusions in patients with Parkinson's disease</article-title>. <source>Acta Neuropathol</source>., <volume>112</volume>, <fpage>261</fpage>â<lpage>265</lpage>.<pub-id pub-id-type="pmid">16855830</pub-id></mixed-citation>
    </ref>
    <ref id="btaa1074-B24">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gonatas</surname><given-names>N.K.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>1998</year>) 
<article-title>The involvement of the Golgi apparatus in the pathogenesis of amyotrophic lateral sclerosis, Alzheimer's disease, and ricin intoxication</article-title>. <source>Histochem. Cell Biol</source>., <volume>109</volume>, <fpage>591</fpage>â<lpage>600</lpage>.<pub-id pub-id-type="pmid">9681637</pub-id></mixed-citation>
    </ref>
    <ref id="btaa1074-B25">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Holthuis</surname><given-names>J.C.M.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2014</year>) 
<article-title>Lipid landscapes and pipelines in membrane homeostasis</article-title>. <source>Nature</source>, <volume>510</volume>, <fpage>48</fpage>â<lpage>57</lpage>.<pub-id pub-id-type="pmid">24899304</pub-id></mixed-citation>
    </ref>
    <ref id="btaa1074-B26">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hong</surname><given-names>Z.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2020</year>) 
<article-title>Identifying enhancerâpromoter interactions with neural network based on pre-trained DNA vectors and attention mechanism</article-title>. <source>Bioinformatics</source>, <volume>36</volume>, <fpage>1037</fpage>â<lpage>1043</lpage>.<pub-id pub-id-type="pmid">31588505</pub-id></mixed-citation>
    </ref>
    <ref id="btaa1074-B27">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Huo</surname><given-names>Y.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2020</year>) 
<article-title>SGL-SVM: a novel method for tumor classification via support vector machine with sparse group Lasso</article-title>. <source>J. Theor. Biol</source>., <volume>486</volume>, <fpage>110098</fpage>.<pub-id pub-id-type="pmid">31786183</pub-id></mixed-citation>
    </ref>
    <ref id="btaa1074-B28">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jiang</surname><given-names>Y.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2019a</year>) 
<article-title>A dynamic programing approach to integrate gene expression data and network information for pathway model generation</article-title>. <source>Bioinformatics</source>, <volume>36</volume>, <fpage>169</fpage>â<lpage>176</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa1074-B29">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Jiang</surname><given-names>Y.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2019b</year>) <part-title>DeepDom: predicting protein domain boundary from sequence alone using stacked bidirectional LSTM</part-title>. In: <person-group person-group-type="editor"><string-name><surname>Altman</surname><given-names>R.B.</given-names></string-name></person-group> Â <etal>et al</etal> (eds.) <source>Pacific Symposium on Biocomputing 2019</source>. pp. <fpage>66</fpage>â<lpage>75</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa1074-B30">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Jiang</surname><given-names>Y.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2020a</year>) MULocDeep: a deep-learning framework for protein subcellular and suborganellar localization prediction with residue-level interpretation. doi: 10.21203/rs.21203.rs-40744/v21201.</mixed-citation>
    </ref>
    <ref id="btaa1074-B31">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jiang</surname><given-names>Y.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2020b</year>) 
<article-title>IMPRes-Pro: a high dimensional multiomics integration method for in silico hypothesis generation</article-title>. <source>Methods</source>, <volume>173</volume>, <fpage>16</fpage>â<lpage>23</lpage>.<pub-id pub-id-type="pmid">31220603</pub-id></mixed-citation>
    </ref>
    <ref id="btaa1074-B32">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jiao</surname><given-names>Y.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2016a</year>) 
<article-title>Performance measures in evaluating machine learning based bioinformatics predictors for classifications</article-title>. <source>Quant. Biol</source>., <volume>4</volume>, <fpage>320</fpage>â<lpage>330</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa1074-B33">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jiao</surname><given-names>Y.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2016b</year>) 
<article-title>Predicting Golgi-resident protein types using pseudo amino acid compositions: approaches with positional specific physicochemical properties</article-title>. <source>J. Theor. Biol</source>., <volume>391</volume>, <fpage>35</fpage>â<lpage>42</lpage>.<pub-id pub-id-type="pmid">26702543</pub-id></mixed-citation>
    </ref>
    <ref id="btaa1074-B34">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jiao</surname><given-names>Y.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2016c</year>) 
<article-title>Prediction of Golgi-resident protein types using general form of Chou's pseudo-amino acid compositions: approaches with minimal redundancy maximal relevance feature selection</article-title>. <source>J. Theor. Biol</source>., <volume>402</volume>, <fpage>38</fpage>â<lpage>44</lpage>.<pub-id pub-id-type="pmid">27155042</pub-id></mixed-citation>
    </ref>
    <ref id="btaa1074-B35">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jung</surname><given-names>Y.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2019</year>) 
<article-title>Transformed low-rank ANOVA models for high-dimensional variable selection</article-title>. <source>Stat. Methods Med. Res</source>., <volume>28</volume>, <fpage>1230</fpage>â<lpage>1246</lpage>.<pub-id pub-id-type="pmid">29384042</pub-id></mixed-citation>
    </ref>
    <ref id="btaa1074-B36">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Ke</surname><given-names>G.L.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2017</year>) <part-title>LightGBM: a highly efficient gradient boosting decision tree</part-title>. In: <person-group person-group-type="editor"><string-name><surname>Guyon</surname><given-names>I.</given-names></string-name></person-group> Â <etal>et al</etal> (eds.) <source>Advances in Neural Information Processing Systems 30</source>. 
<publisher-name>Neural Information Processing Systems (NIPS</publisher-name>), 
<publisher-loc>La Jolla</publisher-loc>.</mixed-citation>
    </ref>
    <ref id="btaa1074-B37">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Krause</surname><given-names>B.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2016</year>) 
<article-title>Multiplicative LSTM for sequence modelling</article-title>. <source>arXiv e-Prints</source>, <fpage>arXiv:1609.07959</fpage>.</mixed-citation>
    </ref>
    <ref id="btaa1074-B38">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lemaitre</surname><given-names>G.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2017</year>) 
<article-title>Imbalanced-learn: a Python toolbox to tackle the curse of imbalanced datasets in machine learning</article-title>. <source>J. Mach. Learn. Res</source>., <volume>18</volume>, <fpage>5</fpage>.</mixed-citation>
    </ref>
    <ref id="btaa1074-B39">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Li</surname><given-names>J.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2020</year>) 
<article-title>DeepAVP: a dual-channel deep neural network for identifying variable-length antiviral peptides</article-title>. <source>IEEE J. Biomed. Health Inf</source>., <volume>24</volume>, <fpage>3012</fpage>â<lpage>3019</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa1074-B40">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ligon</surname><given-names>C.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2020</year>) 
<article-title>A selective role for a component of the autophagy pathway in coupling the Golgi apparatus to dendrite polarity in pyramidal neurons</article-title>. <source>Neurosci. Lett</source>., <volume>730</volume>, <fpage>7</fpage>.</mixed-citation>
    </ref>
    <ref id="btaa1074-B41">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lv</surname><given-names>Z.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2019a</year>) 
<article-title>Protein function prediction: from traditional classifier to deep learning</article-title>. <source>Proteomics</source>, <volume>19</volume>, <fpage>1900119</fpage>.</mixed-citation>
    </ref>
    <ref id="btaa1074-B42">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lv</surname><given-names>Z.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2019b</year>) 
<article-title>A random forest sub-golgi protein classifier optimized via dipeptide and amino acid composition features</article-title>. <source>Front. Bioeng. Biotechnol</source>., <volume>7</volume>, <fpage>215</fpage>.<pub-id pub-id-type="pmid">31552241</pub-id></mixed-citation>
    </ref>
    <ref id="btaa1074-B43">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lv</surname><given-names>Z.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2020a</year>) 
<article-title><italic toggle="yes">Escherichia coli</italic> DNA N-4-methycytosine site prediction accuracy improved by light gradient boosting machine feature selection technology</article-title>. <source>IEEE Access</source>, <volume>8</volume>, <fpage>14851</fpage>â<lpage>14859</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa1074-B44">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lv</surname><given-names>Z.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2020b</year>) 
<article-title>RF-PseU: a random forest predictor for RNA pseudouridine sites</article-title>. <source>Front. Bioeng. Biotechnol</source>., <volume>8</volume>, <fpage>134</fpage>.<pub-id pub-id-type="pmid">32175316</pub-id></mixed-citation>
    </ref>
    <ref id="btaa1074-B45">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mcinnes</surname><given-names>L.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2018</year>) 
<article-title>UMAP: uniform manifold approximation and projection for dimension reduction</article-title>. <source>J. Open Source Softw</source>., <volume>3</volume>, <fpage>861</fpage>.</mixed-citation>
    </ref>
    <ref id="btaa1074-B46">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Min</surname><given-names>S.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2017</year>) 
<article-title>Deep learning in bioinformatics</article-title>. <source>Brief. Bioinf</source>., <volume>18</volume>, <fpage>851</fpage>â<lpage>869</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa1074-B47">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nambiar</surname><given-names>A.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2020</year>) 
<article-title>Transforming the language of life: transformer neural networks for protein prediction tasks</article-title>. <source>BioRxiv</source>, <volume>2020</volume>.2006.2015.153643.</mixed-citation>
    </ref>
    <ref id="btaa1074-B48">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pedregosa</surname><given-names>F.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2011</year>) 
<article-title>Scikit-learn: machine learning in Python</article-title>. <source>J. Mach. Learn. Res</source>., <volume>12</volume>, <fpage>2825</fpage>â<lpage>2830</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa1074-B49">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Qi</surname><given-names>Y.F.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2020</year>) 
<article-title>DenseCPD: improving the accuracy of neural-network-based computational protein sequence design with DenseNet</article-title>. <source>J. Chem Inf. Model</source>., <volume>60</volume>, <fpage>1245</fpage>â<lpage>1252</lpage>.<pub-id pub-id-type="pmid">32126171</pub-id></mixed-citation>
    </ref>
    <ref id="btaa1074-B50">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rahman</surname><given-names>M.S.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2018</year>) 
<article-title>isGPT: an optimized model to identify sub-Golgi protein types using SVM and Random Forest based feature selection</article-title>. <source>Artif. Intell. Med</source>., <volume>84</volume>, <fpage>90</fpage>â<lpage>100</lpage>.<pub-id pub-id-type="pmid">29183738</pub-id></mixed-citation>
    </ref>
    <ref id="btaa1074-B51">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Rao</surname><given-names>R.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2019</year>) Evaluating Protein Transfer Learning with TAPE. <fpage>arXiv:1906.08230</fpage>.</mixed-citation>
    </ref>
    <ref id="btaa1074-B52">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ravichandran</surname><given-names>Y.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2020</year>) 
<article-title>The Golgi apparatus and cell polarity: roles of the cytoskeleton, the Golgi matrix, and Golgi membranes</article-title>. <source>Curr. Opin. Cell Biol</source>., <volume>62</volume>, <fpage>104</fpage>â<lpage>113</lpage>.<pub-id pub-id-type="pmid">31751898</pub-id></mixed-citation>
    </ref>
    <ref id="btaa1074-B53">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Shen</surname><given-names>Y.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2019a</year>) 
<article-title>Critical evaluation of web-based prediction tools for human protein subcellular localization</article-title>. <source>Brief. Bioinf</source>., <volume>21</volume>, <fpage>1628</fpage>â<lpage>1640</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa1074-B54">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Shen</surname><given-names>Y.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2019b</year>) 
<article-title>Identification of protein subcellular localization via integrating evolutionary and physicochemical information into Chouâs general PseAAC</article-title>. <source>J. Theor. Biol</source>., <volume>462</volume>, <fpage>230</fpage>â<lpage>239</lpage>.<pub-id pub-id-type="pmid">30452958</pub-id></mixed-citation>
    </ref>
    <ref id="btaa1074-B55">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Shi</surname><given-names>H.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2019</year>) 
<article-title>Predicting drug-target interactions using Lasso with random forest based on evolutionary information and chemical structure</article-title>. <source>Genomics</source>, <volume>111</volume>, <fpage>1839</fpage>â<lpage>1852</lpage>.<pub-id pub-id-type="pmid">30550813</pub-id></mixed-citation>
    </ref>
    <ref id="btaa1074-B56">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Stoeber</surname><given-names>M.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2018</year>) 
<article-title>A genetically encoded biosensor reveals location bias of opioid drug action</article-title>. <source>Neuron</source>, <volume>98</volume>, <fpage>963</fpage>â<lpage>976.e5</lpage>.<pub-id pub-id-type="pmid">29754753</pub-id></mixed-citation>
    </ref>
    <ref id="btaa1074-B57">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tang</surname><given-names>H.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2016</year>) 
<article-title>Identification of immunoglobulins using Chou's pseudo amino acid composition with feature selection technique</article-title>. <source>Mol. bioSyst</source>., <volume>12</volume>, <fpage>1269</fpage>â<lpage>1275</lpage>.<pub-id pub-id-type="pmid">26883492</pub-id></mixed-citation>
    </ref>
    <ref id="btaa1074-B58">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tang</surname><given-names>H.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2018</year>) 
<article-title>HBPred: a tool to identify growth hormone-binding proteins</article-title>. <source>Int. J. Biol. Sci</source>., <volume>14</volume>, <fpage>957</fpage>â<lpage>964</lpage>.<pub-id pub-id-type="pmid">29989085</pub-id></mixed-citation>
    </ref>
    <ref id="btaa1074-B59">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tao</surname><given-names>Y.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2020</year>) 
<article-title>Golgi apparatus: an emerging platform for innate immunity</article-title>. <source>Trends Cell Biol</source>., <volume>30</volume>, <fpage>467</fpage>â<lpage>477</lpage>.<pub-id pub-id-type="pmid">32413316</pub-id></mixed-citation>
    </ref>
    <ref id="btaa1074-B60">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tavakkolkhah</surname><given-names>P.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2018</year>) 
<article-title>Detection of network motifs using three-way ANOVA</article-title>. <source>PLoS One</source>, <volume>13</volume>, <fpage>e0201382</fpage>.<pub-id pub-id-type="pmid">30080876</pub-id></mixed-citation>
    </ref>
    <ref id="btaa1074-B61">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname><given-names>S.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2017</year>) 
<article-title>Accurate de novo prediction of protein contact map by ultra-deep learning model</article-title>. <source>PLoS Comput. Biol</source>., <volume>13</volume>, <fpage>34</fpage>.</mixed-citation>
    </ref>
    <ref id="btaa1074-B62">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname><given-names>X.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2019a</year>) 
<article-title>Proteinâprotein interaction sites prediction by ensemble random forests with synthetic minority oversampling technique</article-title>. <source>Bioinformatics</source>, <volume>35</volume>, <fpage>2395</fpage>â<lpage>2402</lpage>.<pub-id pub-id-type="pmid">30520961</pub-id></mixed-citation>
    </ref>
    <ref id="btaa1074-B63">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname><given-names>Y.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2019b</year>) 
<article-title>Pancreatic cancer biomarker detection by two support vector strategies for recursive feature elimination</article-title>. <source>Biomarkers Med</source>., <volume>13</volume>, <fpage>105</fpage>â<lpage>121</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa1074-B64">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname><given-names>H.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2020a</year>) 
<article-title>Identification of membrane protein types via multivariate information fusion with Hilbert-Schmidt Independence Criterion</article-title>. <source>Neurocomputing</source>, <volume>383</volume>, <fpage>257</fpage>â<lpage>269</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa1074-B65">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname><given-names>Z.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2020b</year>) 
<article-title>Identification of highest-affinity binding sites of yeast transcription factor families</article-title>. <source>J. Chem. Inf. Model</source>., <volume>60</volume>, <fpage>1876</fpage>â<lpage>1883</lpage>.<pub-id pub-id-type="pmid">31944107</pub-id></mixed-citation>
    </ref>
    <ref id="btaa1074-B66">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Xu</surname><given-names>J.B.</given-names></string-name></person-group> (<year>2019</year>) 
<article-title>Distance-based protein folding powered by deep learning</article-title>. <source>Proc. Natl. Acad. Sci. USA</source>, <volume>116</volume>, <fpage>16856</fpage>â<lpage>16865</lpage>.<pub-id pub-id-type="pmid">31399549</pub-id></mixed-citation>
    </ref>
    <ref id="btaa1074-B67">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Xu</surname><given-names>J.B.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2017</year>) <source>Folding Large Proteins by Ultra-Deep Learning</source>. 
<publisher-name>Assoc Computing Machinery</publisher-name>, 
<publisher-loc>New York</publisher-loc>.</mixed-citation>
    </ref>
    <ref id="btaa1074-B68">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Xu</surname><given-names>J.B.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2019</year>) 
<article-title>Analysis of distance-based protein structure prediction by deep learning in CASP13</article-title>. <source>Proteins</source>, <volume>87</volume>, <fpage>1069</fpage>â<lpage>1081</lpage>.<pub-id pub-id-type="pmid">31471916</pub-id></mixed-citation>
    </ref>
    <ref id="btaa1074-B69">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yang</surname><given-names>A.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2016a</year>) 
<article-title>A chemical biology route to site-specific authentic protein modifications</article-title>. <source>Science</source>, <volume>354</volume>, <fpage>623</fpage>â<lpage>626</lpage>.<pub-id pub-id-type="pmid">27708052</pub-id></mixed-citation>
    </ref>
    <ref id="btaa1074-B70">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yang</surname><given-names>R.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2016b</year>) 
<article-title>A novel feature extraction method with feature selection to identify golgi-resident protein types from imbalanced data</article-title>. <source>Int. J. Mol. Sci</source>., <volume>17</volume>, <fpage>218</fpage>â<lpage>217</lpage>.<pub-id pub-id-type="pmid">26861308</pub-id></mixed-citation>
    </ref>
    <ref id="btaa1074-B71">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yang</surname><given-names>H.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2018</year>) 
<article-title>iRNA-2OM: a sequence-based predictor for identifying 2'-O-methylation sites in <italic toggle="yes">Homo sapiens</italic></article-title>. <source>J. Comput. Biol. J. Comput. Mol. Cell Biol</source>., <volume>25</volume>, <fpage>1266</fpage>â<lpage>1277</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa1074-B72">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yang</surname><given-names>H.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2019a</year>) 
<article-title>A comparison and assessment of computational method for identifying recombination hotspots in <italic toggle="yes">Saccharomyces cerevisiae</italic></article-title>. <source>Brief. Bioinf</source>., 10.1093/bib/bbz1123.</mixed-citation>
    </ref>
    <ref id="btaa1074-B73">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yang</surname><given-names>W.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2019b</year>) 
<article-title>A brief survey of machine learning methods in protein sub-golgi localization</article-title>. <source>Curr. Bioinf</source>., <volume>14</volume>, <fpage>234</fpage>â<lpage>240</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa1074-B74">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zeng</surname><given-names>X.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2019</year>) 
<article-title>deepDR: a network-based deep learning approach to in silico drug repositioning</article-title>. <source>Bioinformatics</source>, <volume>35</volume>, <fpage>5191</fpage>â<lpage>5198</lpage>.<pub-id pub-id-type="pmid">31116390</pub-id></mixed-citation>
    </ref>
    <ref id="btaa1074-B75">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zeng</surname><given-names>X.X.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2018</year>) 
<article-title>Prediction of potential disease-associated microRNAs using structural perturbation method</article-title>. <source>Bioinformatics</source>, <volume>34</volume>, <fpage>2425</fpage>â<lpage>2432</lpage>.<pub-id pub-id-type="pmid">29490018</pub-id></mixed-citation>
    </ref>
    <ref id="btaa1074-B76">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname><given-names>L.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2016</year>) 
<article-title>LSDT: latent sparse domain transfer learning for visual adaptation</article-title>. <source>IEEE Trans. Image Process</source>, <volume>25</volume>, <fpage>1177</fpage>â<lpage>1191</lpage>.<pub-id pub-id-type="pmid">26766374</pub-id></mixed-citation>
    </ref>
    <ref id="btaa1074-B77">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname><given-names>W.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2019a</year>) 
<article-title>SFLLN: a sparse feature learning ensemble method with linear neighborhood regularization for predicting drugâdrug interactions</article-title>. <source>Inf. Sci</source>., <volume>497</volume>, <fpage>189</fpage>â<lpage>201</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa1074-B78">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname><given-names>W.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2019b</year>) 
<article-title>A fast linear neighborhood similarity-based network link inference method to predict microRNA-disease associations</article-title>. <source>IEEE/ACM Trans. Comput. Biol. Bioinf</source>., doi:10.1109/TCBB.2019.2931546.</mixed-citation>
    </ref>
    <ref id="btaa1074-B79">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname><given-names>W.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2008</year>) 
<article-title>A Bayesian regression approach to the prediction of MHC-II binding affinity</article-title>. <source>Comput. Methods Programs Biomed</source>., <volume>92</volume>, <fpage>1</fpage>â<lpage>7</lpage>.<pub-id pub-id-type="pmid">18562039</pub-id></mixed-citation>
    </ref>
    <ref id="btaa1074-B80">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhao</surname><given-names>W.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2019</year>) 
<article-title>Predicting protein sub-Golgi locations by combining functional domain enrichment scores with pseudo-amino acid compositions</article-title>. <source>J. Theor. Biol</source>., <volume>473</volume>, <fpage>38</fpage>â<lpage>43</lpage>.<pub-id pub-id-type="pmid">31051179</pub-id></mixed-citation>
    </ref>
    <ref id="btaa1074-B81">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhou</surname><given-names>H.Y.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2019</year>) 
<article-title>Predicting golgi-resident protein types using conditional covariance minimization with XGBoost based on multiple features fusion</article-title>. <source>IEEE Access</source>, <volume>7</volume>, <fpage>144154</fpage>â<lpage>144164</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa1074-B82">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhou</surname><given-names>M.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2020</year>) 
<article-title>Progress in neural NLP: modeling, learning, and reasoning</article-title>. <source>Engineering</source>, <volume>6</volume>, <fpage>275</fpage>â<lpage>290</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa1074-B83">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zou</surname><given-names>Q.</given-names></string-name></person-group> Â <etal>et al</etal> (<year>2016</year>) 
<article-title>A novel features ranking metric with application to scalable visual and bioinformatics data classification</article-title>. <source>Neurocomputing</source>, <volume>173</volume>, <fpage>346</fpage>â<lpage>354</lpage>.</mixed-citation>
    </ref>
  </ref-list>
</back>
