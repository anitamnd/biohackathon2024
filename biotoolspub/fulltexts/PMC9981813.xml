<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD with MathML3 v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1-mathml3.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?all-math-mml yes?>
<?use-mml?>
<?properties open_access?>
<?properties manuscript?>
<?origin nihpa?>
<?iso-abbr Neuroimage?>
<?submitter-system nihms?>
<?submitter-canonical-name Elsevier?>
<?submitter-canonical-id ELSEVIERAM?>
<?submitter-userid 8068823?>
<?submitter-authority myNCBI?>
<?submitter-login elsevieram?>
<?submitter-name Elsevier Author Support?>
<?domain nihpa?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-journal-id">9215515</journal-id>
    <journal-id journal-id-type="pubmed-jr-id">20498</journal-id>
    <journal-id journal-id-type="nlm-ta">Neuroimage</journal-id>
    <journal-id journal-id-type="iso-abbrev">Neuroimage</journal-id>
    <journal-title-group>
      <journal-title>NeuroImage</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1053-8119</issn>
    <issn pub-type="epub">1095-9572</issn>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">9981813</article-id>
    <article-id pub-id-type="pmid">36064140</article-id>
    <article-id pub-id-type="doi">10.1016/j.neuroimage.2022.119609</article-id>
    <article-id pub-id-type="manuscript">nihpa1850027</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Article</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Curation of BIDS (CuBIDS): A workflow and software package for streamlining reproducible curation of large BIDS datasets</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Covitz</surname>
          <given-names>Sydney</given-names>
        </name>
        <xref rid="A1" ref-type="aff">a</xref>
        <xref rid="A2" ref-type="aff">b</xref>
        <xref rid="A3" ref-type="aff">c</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Tapera</surname>
          <given-names>Tinashe M.</given-names>
        </name>
        <xref rid="A1" ref-type="aff">a</xref>
        <xref rid="A2" ref-type="aff">b</xref>
        <xref rid="A3" ref-type="aff">c</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Adebimpe</surname>
          <given-names>Azeez</given-names>
        </name>
        <xref rid="A1" ref-type="aff">a</xref>
        <xref rid="A2" ref-type="aff">b</xref>
        <xref rid="A3" ref-type="aff">c</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Alexander-Bloch</surname>
          <given-names>Aaron F.</given-names>
        </name>
        <xref rid="A2" ref-type="aff">b</xref>
        <xref rid="A3" ref-type="aff">c</xref>
        <xref rid="A4" ref-type="aff">d</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Bertolero</surname>
          <given-names>Maxwell A.</given-names>
        </name>
        <xref rid="A1" ref-type="aff">a</xref>
        <xref rid="A2" ref-type="aff">b</xref>
        <xref rid="A3" ref-type="aff">c</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Feczko</surname>
          <given-names>Eric</given-names>
        </name>
        <xref rid="A8" ref-type="aff">h</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Franco</surname>
          <given-names>Alexandre R.</given-names>
        </name>
        <xref rid="A5" ref-type="aff">e</xref>
        <xref rid="A6" ref-type="aff">f</xref>
        <xref rid="A7" ref-type="aff">g</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Gur</surname>
          <given-names>Raquel E.</given-names>
        </name>
        <xref rid="A2" ref-type="aff">b</xref>
        <xref rid="A3" ref-type="aff">c</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Gur</surname>
          <given-names>Ruben C.</given-names>
        </name>
        <xref rid="A2" ref-type="aff">b</xref>
        <xref rid="A3" ref-type="aff">c</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Hendrickson</surname>
          <given-names>Timothy</given-names>
        </name>
        <xref rid="A8" ref-type="aff">h</xref>
        <xref rid="A9" ref-type="aff">i</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Houghton</surname>
          <given-names>Audrey</given-names>
        </name>
        <xref rid="A8" ref-type="aff">h</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Mehta</surname>
          <given-names>Kahini</given-names>
        </name>
        <xref rid="A1" ref-type="aff">a</xref>
        <xref rid="A2" ref-type="aff">b</xref>
        <xref rid="A3" ref-type="aff">c</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Murtha</surname>
          <given-names>Kristin</given-names>
        </name>
        <xref rid="A1" ref-type="aff">a</xref>
        <xref rid="A2" ref-type="aff">b</xref>
        <xref rid="A3" ref-type="aff">c</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Perrone</surname>
          <given-names>Anders J.</given-names>
        </name>
        <xref rid="A8" ref-type="aff">h</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Robert-Fitzgerald</surname>
          <given-names>Tim</given-names>
        </name>
        <xref rid="A10" ref-type="aff">j</xref>
        <xref rid="A11" ref-type="aff">k</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Schabdach</surname>
          <given-names>Jenna M.</given-names>
        </name>
        <xref rid="A2" ref-type="aff">b</xref>
        <xref rid="A3" ref-type="aff">c</xref>
        <xref rid="A4" ref-type="aff">d</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Shinohara</surname>
          <given-names>Russell T</given-names>
        </name>
        <xref rid="A10" ref-type="aff">j</xref>
        <xref rid="A11" ref-type="aff">k</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Vogel</surname>
          <given-names>Jacob W.</given-names>
        </name>
        <xref rid="A1" ref-type="aff">a</xref>
        <xref rid="A2" ref-type="aff">b</xref>
        <xref rid="A3" ref-type="aff">c</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Zhao</surname>
          <given-names>Chenying</given-names>
        </name>
        <xref rid="A1" ref-type="aff">a</xref>
        <xref rid="A2" ref-type="aff">b</xref>
        <xref rid="A12" ref-type="aff">l</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Fair</surname>
          <given-names>Damien A.</given-names>
        </name>
        <xref rid="A8" ref-type="aff">h</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Milham</surname>
          <given-names>Michael P.</given-names>
        </name>
        <xref rid="A5" ref-type="aff">e</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Cieslak</surname>
          <given-names>Matthew</given-names>
        </name>
        <xref rid="A1" ref-type="aff">a</xref>
        <xref rid="A2" ref-type="aff">b</xref>
        <xref rid="A3" ref-type="aff">c</xref>
        <xref rid="FN1" ref-type="author-notes">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Satterthwaite</surname>
          <given-names>Theodore D.</given-names>
        </name>
        <xref rid="A1" ref-type="aff">a</xref>
        <xref rid="A2" ref-type="aff">b</xref>
        <xref rid="A3" ref-type="aff">c</xref>
        <xref rid="A10" ref-type="aff">j</xref>
        <xref rid="FN1" ref-type="author-notes">1</xref>
        <xref rid="CR1" ref-type="corresp">*</xref>
      </contrib>
    </contrib-group>
    <aff id="A1"><label>a</label>Lifespan Informatics and Neuroimaging Center (PennLINC), Department of Psychiatry, Perelman School of Medicine, University of Pennsylvania, Philadelphia, PA 19104, USA</aff>
    <aff id="A2"><label>b</label>Penn/CHOP Lifespan Brain Institute, Perelman School of Medicine, Children’s Hospital of Philadelphia Research Institute, Philadelphia, PA 19104, USA</aff>
    <aff id="A3"><label>c</label>Department of Psychiatry, Perelman School of Medicine, University of Pennsylvania, Philadelphia, PA 19104, USA</aff>
    <aff id="A4"><label>d</label>Children’s Hospital of Philadelphia, 3401 Civic Center Blvd, Philadelphia, PA 19104, United States</aff>
    <aff id="A5"><label>e</label>Child Mind Institute, 101 E 56th St, New York, NY 10022</aff>
    <aff id="A6"><label>f</label>Center for Biomedical Imaging and Neuromodulation, Nathan Kline Institute for Psychiatric Research, Orangeburg, NY 10962, USA</aff>
    <aff id="A7"><label>g</label>Department of Psychiatry, NYU Grossman School of Medicine, New York, NY 10016, USA</aff>
    <aff id="A8"><label>h</label>Masonic Institute for the Developing Brain, University of Minnesota, Minneapolis, MN, United States</aff>
    <aff id="A9"><label>i</label>University of Minnesota Informatics Institute, University of Minnesota, Minneapolis, MN, United States</aff>
    <aff id="A10"><label>j</label>Center for Biomedical Image Computation and Analytics, University of Pennsylvania, Philadelphia, PA 19104, USA</aff>
    <aff id="A11"><label>k</label>Penn Statistics in Imaging and Visualization Center, Department of Biostatistics, Epidemiology and Informatics, University of Pennsylvania, Philadelphia, PA 19104, USA</aff>
    <aff id="A12"><label>l</label>Department of Bioengineering, School of Engineering and Applied Science, University of Pennsylvania, Philadelphia, PA 19104, USA</aff>
    <author-notes>
      <corresp id="CR1"><label>*</label>Corresponding author at: Richards Medical Labs, A504, 3700 Hamilton Walk, Philadelphia, PA 19104. <email>sattertt@pennmedicine.upenn.edu</email> (T.D. Satterthwaite).</corresp>
      <fn fn-type="equal" id="FN1">
        <label>1</label>
        <p id="P1">Contributed equally as senior authors</p>
      </fn>
    </author-notes>
    <pub-date pub-type="nihms-submitted">
      <day>15</day>
      <month>11</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="ppub">
      <month>11</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="epub">
      <day>03</day>
      <month>9</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>07</day>
      <month>5</month>
      <year>2023</year>
    </pub-date>
    <volume>263</volume>
    <fpage>119609</fpage>
    <lpage>119609</lpage>
    <permissions>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbyncndlicense">https://creativecommons.org/licenses/by-nc-nd/4.0/</ali:license_ref>
        <license-p>This is an open access article under the CC BY-NC-ND license (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by-nc-nd/4.0/">http://creativecommons.org/licenses/by-nc-nd/4.0/</ext-link>)</license-p>
      </license>
    </permissions>
    <abstract id="ABS1">
      <p id="P2">The Brain Imaging Data Structure (BIDS) is a specification accompanied by a software ecosystem that was designed to create reproducible and automated workflows for processing neuroimaging data. BIDS Apps flexibly build workflows based on the metadata detected in a dataset. However, even BIDS valid metadata can include incorrect values or omissions that result in inconsistent processing across sessions. Additionally, in large-scale, heterogeneous neuroimaging datasets, hidden variability in metadata is difficult to detect and classify. To address these challenges, we created a Python-based software package titled “Curation of BIDS” (CuBIDS), which provides an intuitive workflow that helps users validate and manage the curation of their neuroimaging datasets. CuBIDS includes a robust implementation of BIDS validation that scales to large samples and incorporates DataLad—a version control software package for data—as an optional dependency to ensure reproducibility and provenance tracking throughout the entire curation process. CuBIDS provides tools to help users perform quality control on their images’ metadata and identify unique combinations of imaging parameters. Users can then execute BIDS Apps on a subset of participants that represent the full range of acquisition parameters that are present, accelerating pipeline testing on large datasets.</p>
    </abstract>
    <kwd-group>
      <kwd>BIDS</kwd>
      <kwd>MRI</kwd>
      <kwd>Brain</kwd>
      <kwd>Neuroimaging</kwd>
      <kwd>Software</kwd>
      <kwd>Curation</kwd>
      <kwd>Validation</kwd>
      <kwd>Metadata</kwd>
      <kwd>Version control</kwd>
      <kwd>Heterogeneity</kwd>
    </kwd-group>
  </article-meta>
</front>
<body>
  <sec id="S1">
    <label>1.</label>
    <title>Introduction</title>
    <p id="P3">The Brain Imaging Data Structure (BIDS) specification provides a standardized format for organizing and describing neuroimaging data (<xref rid="R6" ref-type="bibr">Gorgolewski et al., 2016</xref>). BIDS relies on specific nested directory structures and filename conventions and requires that each MR image file (e.g. Neuroimaging Informatics Technology Initiative or NIfTI) be accompanied by a JavaScript Object Notation (JSON) sidecar—a data dictionary detailing its corresponding image’s metadata. BIDS is especially helpful when dealing with large, multimodal studies; as the number of subjects and runs increases, generalizable structures and standards become not only beneficial but essential. Pipelines that ingest BIDS datasets—commonly referred to in the BIDS software ecosystem as “BIDS Apps ” (<xref rid="R8" ref-type="bibr">Gorgolewski et al., 2017</xref>)—such as fMRIPrep and QSIPrep—rely heavily on correct specification of BIDS, as they build workflows based on the metadata encountered (<xref rid="R5" ref-type="bibr">Esteban et al., 2019</xref>; <xref rid="R3" ref-type="bibr">Cieslak et al., 2021</xref>). While generally an important and useful feature, this workflow construction structure can also be a vulnerability: if the BIDS metadata is inaccurate, a BIDS app may build an inappropriate (but technically “correct”) preprocessing pipeline. For example, a fieldmap with no IntendedFor field specified in its JSON sidecar is not technically incorrect but rather incomplete. When a participant containing a fieldmap missing an IntendedFor field is run through a MRI image type processing pipeline such as fMRIPrep and QSIPrep, the pipeline will execute with neither errors nor warnings but will skip distortion correction. Curating the dataset with CuBIDS before running it through such pipelines will allow users to easily identify all instances of fieldmaps missing IntendedFor references—CuBIDS places those scans in separate groups. Users must understand and verify that the metadata present in BIDS is correct. This usually requires meticulous curation—the process of checking and fixing filename or metadata issues present in a dataset. In the context of the lifecycle of a neuroimaging dataset, the CuBIDS curation workflow begins directly after the data has been organized into a BIDS directory structure with BIDS-like filenames.</p>
    <p id="P4">While large, multi-modal neuroimaging datasets constitute extremely valuable data resources, they also frequently possess substantial heterogeneity in their image acquisition parameters. BIDS provides an ideal structure for organizing neuroimaging data, but the size and complexity of large-scale datasets can render curation both tedious and difficult. Data curation can be an ad-hoc process that involves substantial manual intervention; such manual curation is usually neither well tracked nor reproducible. Thus, curation constitutes a major vulnerability in the field-wide effort to create reproducible, analytic workflows for neuroimaging data. Finally, many current BIDS tools, including the BIDS Validator, MatlabBIDS, and PyBIDS (<xref rid="R16" ref-type="bibr">Yarkoni et al., 2019</xref>), that parse and interact with BIDS datasets were optimized for small fMRI studies and may behave erratically when given large quantities of heterogeneous data.</p>
    <p id="P5">With these challenges in mind, we developed “Curation of BIDS” (CuBIDS): a software package that provides easy-to-use workflows that help users curate large BIDS datasets. CuBIDS provides users with customizable features to visualize heterogeneity in complex BIDS datasets and includes a robust, scalable implementation of BIDS validation that can be applied to arbitrarily-sized datasets. Critically, CuBIDS renders curation reproducible via an easy-to-use, wrapped implementation of DataLad (<xref rid="R9" ref-type="bibr">Halchenko et al., 2021</xref>) as an optional feature the user can access at will. Finally, CuBIDS provides tools to identify unique combinations of imaging parameters in a dataset so that users can test BIDS Apps on a subset of participants that represents the parameter space of the entire dataset. This option dramatically speeds up pipeline testing, as users can be assured that they have tested a BIDS App on the full range of acquisition parameters present in a dataset. As described below, CuBIDS facilitates an understanding of what is present in an MRI BIDS dataset, allows for reproducible BIDS curation, and accelerates successful data processing at scale.</p>
  </sec>
  <sec id="S2">
    <label>2.</label>
    <title>Materials and methods</title>
    <p id="P6">The standard lifecycle of a neuroimaging study begins with acquisition and ends with image analysis and hypothesis testing. CuBIDS’ role in this process begins directly after the data has been organized into a BIDS directory structure with BIDS-like filenames. The CuBIDS workflow ends with curated data in a repository, allowing for further exploration, pooling, meta-analysis, and runs of preprocessing pipelines. As curation occurs quite early in this timeline of preparing neuroimaging data for analysis, decisions made during curation will affect every subsequent stage.</p>
    <sec id="S3">
      <label>2.1.</label>
      <title>Data and code availability statement</title>
      <p id="P7">A copy of the small, example dataset whose curation we walk through in the <xref rid="S15" ref-type="sec">Results</xref> section is compressed into a ZipFile and submitted with this paper under “<xref rid="SD1" ref-type="supplementary-material">Supplementary Material</xref>.” Additionally, the Philadelphia Neurodevelopmental Cohort (PNC), the dataset whose curation we summarize in the second portion of the Results, is publicly available in the Database of Genotypes and Phenotypes (dbGaP accession phs000607.v3.p2). The source code for CuBIDS is publicly available at <ext-link xlink:href="https://github.com/PennLINC/CuBIDS" ext-link-type="uri">https://github.com/PennLINC/CuBIDS</ext-link>, the documentation for our software is available at <ext-link xlink:href="https://cubids.readthedocs.io/en/latest/" ext-link-type="uri">https://cubids.readthedocs.io/en/latest/</ext-link>, and our package is available for download on the Python Package Manager (pypi) <ext-link xlink:href="https://pypi.org/project/cubids/" ext-link-type="uri">https://pypi.org/project/cubids/</ext-link>.</p>
    </sec>
    <sec id="S4">
      <label>2.2.</label>
      <title>Ethics statement</title>
      <p id="P8">No new data was collected specifically for this paper. The Philadelphia Neurodevelopmental Cohort (PNC) (<xref rid="R14" ref-type="bibr">Satterthwaite et al., 2014</xref>) was approved by IRBs of The University of Pennsylvania and Children’s Hospital of Philadelphia. All adult participants in the PNC provided informed consent to participate; minors provided assent alongside the informed consent of their parents or guardian.</p>
    </sec>
    <sec id="S5">
      <label>2.3.</label>
      <title>Overview</title>
      <p id="P9">CuBIDS provides a workflow that aids users in curating large, heterogeneous BIDS datasets. CuBIDS summarizes a dataset’s metadata, enabling users to visualize and understand the variability in critical scanning parameters and fix errors when they are present. To do this, CuBIDS features several command line interface (CLI) programs (<xref rid="T1" ref-type="table">Table 1</xref>). Notably, all CuBIDS CLI programs wrap DataLad as an optional dependency so that the user can implement reproducible tracking at any stage of curation or revert to a prior state of their data. If the user wants to apply DataLad version control while using CuBIDS, they can run the CLI programs with the <monospace>---use-datalad</monospace> optional flag set.</p>
    </sec>
    <sec id="S6">
      <label>2.4.</label>
      <title>Software development practices</title>
      <p id="P10">We applied test-driven development while building CuBIDS, prioritizing writing tests for each new feature concurrent with its construction. We integrated CircleCI—a web-based continuous integration testing platform—into our GitHub repository so that each new commit is run through the full suite of tests. We apply a standardized approach to fixing bugs and adding features: first creating an issue on our GitHub page and then creating a new branch of our code base named specifically for fixing that issue. Once the issue is fixed on the new branch, a pull request merges the new branch into the main branch with the issue tagged. If all continuous integration tests pass and the merge is successful, the issue gets automatically closed. Centering our development process around both tests and issues has ensured the integrity of the code and facilitated both organization and documentation.</p>
    </sec>
    <sec id="S7">
      <label>2.5.</label>
      <title>Installation, setup, and version control</title>
      <p id="P11">We recommend users install CuBIDS inside an Anaconda-based Python environment. Users can install Anaconda/Miniconda/Miniforge, create and activate an environment, and then obtain CuBIDS locally by either installing from the Python Package Manager (Pypi) using pip or cloning directly from the CuBIDS GitHub repository. Documentation regarding use of CuBIDS is publicly available on our Read the Docs page. Notably, CuBIDS commands incorporate version control using DataLad as an optional dependency. Checking their BIDS dataset into DataLad and operationalizing command line programs with the <monospace>---use-datalad</monospace> flag set allows users to access several extra version-control based functionalities. These include tracking changes they make to their dataset, reverting their dataset back to earlier versions, and automatically saving changes CuBIDS makes to the data with detailed commit messages. If users would like to access this functionality, they must separately install both DataLad and Git Annex (a dependency of Data-Lad). Although users can run CuBIDS programs without DataLad, opting to leverage the version control capabilities is recommended, as it renders the CuBIDS workflow portion of curation fully reproducible.</p>
    </sec>
    <sec id="S8">
      <label>2.6.</label>
      <title>Definitions</title>
      <p id="P12">The CuBIDS workflow relies upon five main concepts, all delineating different ways to categorize and catalog data: Key, Parameter, Acquisition, Dominant, and Variant Groups. The first is a “Key Group” -- the set of runs whose filenames share all BIDS filename key-value pairs, except for subject and session. For example, CuBIDS would place a T1w NIfTI file named <monospace>sub-X_ses-A_acq-refaced_T1w.nii.gz</monospace>, which contains the BIDS key-value pair “acq-refaced”—in the following Key Group: <monospace>acquisition-refaced_datatype-anat_suffix-T1w</monospace>. Notably, Key Groups only consider the scan’s BIDS filename; they do not account for the variance in metadata fields that might be present in the JSON sidecars.</p>
      <p id="P13">For this reason, within each Key Group, we define a “Parameter Group” as the set of runs with identical metadata parameters contained in their sidecars. Parameter Groups exist within Key Groups and are denoted numerically—each Key Group will have <italic toggle="yes">n</italic> Parameter Groups, where <italic toggle="yes">n</italic> is the number of unique sets of scanning parameters present in that Key Group. For example, a T1w can belong to Key Group <monospace>acquisition-refaced_datatype-anat_suffix-T1w</monospace> and Parameter Group 1. CuBIDS defines Parameter Groups within Key Groups because differences in parameters can affect how BIDS Apps will configure their pipelines (e.g. Fieldmap availability, multiband factor, etc.).</p>
      <p id="P14">Next, we define a “Dominant Group” as the Parameter Group that contains the most runs in its Key Group. Analogously, we define a “Variant Group” as any Parameter Group that is non-dominant. This is an important term because (as described below) CuBIDS can optionally rename all Variant Groups in an automated and reproducible fashion.</p>
      <p id="P15">Finally, we define an “Acquisition Group” as a collection of sessions across participants that contain the exact same set of Key and Parameter Groups. Since Key Groups are based on the BIDS filenames—and therefore both MRI image type and acquisition specific—each BIDS session directory contains images that belong to a set of Parameter Groups. CuBIDS assigns each session—or set of Parameter Groups—to an Acquisition Group such that all sessions in an Acquisition Group possesses an identical set of acquisitions and metadata parameters across all MRI image types present in the dataset. We find Acquisition Groups to be a particularly useful categorization of BIDS data, as they identify homogeneous sets of sessions (not individual scans) in a large dataset. They are also useful for expediting the testing of pipelines; if a BIDS App runs successfully on a single subject from each Acquisition Group, one can be confident that it will handle all combinations of scanning parameters in the entire dataset. These various sets of methods by which one can group a BIDS dataset are critical to the CuBIDS workflow (see <xref rid="F1" ref-type="fig">Fig. 1</xref>).</p>
    </sec>
    <sec id="S9">
      <label>2.7.</label>
      <title>Accounting for NIfTI header information</title>
      <p id="P16">Information from NIfTI headers—including number of volumes, voxel size, image dimensions, and image obliquity—is often important but is usually absent from JSON sidecars. We created a program, <monospace>cubids-add-nifti-info</monospace>, that reads information from the NIfTI header and adds it to the JSON sidecar. For example, knowing the number of volumes in a run may be particularly useful when performing an initial quality assessment—i.e., identifying and removing runs with unexpectedly short durations (i.e., 20 vol in an fMRI timeseries). Similarly, runs with vastly different voxel sizes or fields of view may be easily identified and removed if desired.</p>
    </sec>
    <sec id="S10">
      <label>2.8.</label>
      <title>BIDS validation</title>
      <p id="P17">An essential first stage of curation is validation: finding the errors present in a BIDS dataset. This step is usually accomplished using the BIDS Validator. However, while BIDS validation is essential to the curation process, the standalone BIDS Validator can exhibit unstable file I/O behavior when validating large datasets (<italic toggle="yes">n</italic>&gt;100). As a result, it sometimes fails unpredictably. To combat this issue, <monospace>cubids-validate</monospace> checks the BIDS layout using a wrapped, stable, scalable version of the standard BIDS Validator. To ensure scalability, <monospace>cubids-validate</monospace> parallelizes validation across participants, validating each subject directory on its own and deferring the detection of parameters that may vary across subjects. Thereafter, <monospace>cubids-validate</monospace> aggregates all validation errors found across participants in an easy-to-read TSV (see <xref rid="F2" ref-type="fig">Fig. 2</xref>), which is accompanied by a data dictionary JSON sidecar. This table includes one row for each file that contains a BIDS validation error and displays that filename along with a description of the error (see <xref rid="F2" ref-type="fig">Fig. 2</xref>)).</p>
      <p id="P18">In designing <monospace>cubids-validate</monospace>, we also intended to separate metadata heterogeneity detection from BIDS error detection. By default, the validator does both—providing large amounts of unactionable information concerning the metadata variance in the terminal output. For example, if a sample includes participants with different sets of scans, the standalone BIDS Validator will print warnings alerting the user to the presence of incongruencies across subjects, often producing copious output that can obscure critical issues. If there are errors or forms of inconsistency users would prefer excluded from the CuBIDS validation TSV, they can run <monospace>cubids-validate</monospace> with optional BIDS Validator flags such as <monospace>---ignore_nifti_headers</monospace>, which disregards NIfTI header content during validation and <monospace>--ignore_subject_consistency</monospace>, which we set as the default and skips checking that any given file for one subject is present for all other subjects. Furthermore, we implemented <monospace>--sequential</monospace>, which parallelizes validation by running the BIDS Validator sequentially on each subject (i.e. treating each participant as a standalone BIDS dataset and performing validation inside a temporary filesystem directory) (see <xref rid="F2" ref-type="fig">Fig. 2B</xref>), and <monospace>---sequential-subjects</monospace>, which filters the sequential run to only include the listed subjects, e.g. <monospace>--sequential-subjects sub-01 sub-05 sub-09</monospace>. These flags allow users to focus the validation process exclusively on the issues and subjects they would like to evaluate, and the sequential option, which parallelizes validation, addresses the standalone BIDS Validator’s scalability issue.</p>
    </sec>
    <sec id="S11">
      <label>2.9.</label>
      <title>Grouping: heterogeneity detection and classification</title>
      <p id="P19">While <monospace>cubids-validate</monospace> will find and display BIDS validation errors present in a dataset, it does not identify metadata parameters that might be inconsistent or omitted. For this reason, we developed <monospace>cubids-group</monospace>: a grouping function that classifies the heterogeneity present in a BIDS dataset and displays it in readable TSVs. Each grouping output is accompanied by a data dictionary JSON sidecar. The input to <monospace>cubids-group</monospace> is the path to the root of a BIDS Dataset, and the program produces four outputs, each of which gives a different view of the underlying data. The first (and most important) is <monospace>summary.tsv</monospace>, which contains one row per Parameter Group, and one column per metadata parameter present in the dataset. To understand the relative prevalence of each group, the program also counts, and includes in <monospace>summary.tsv</monospace>, the number of files in each Key and Parameter Group; this documentation is very useful for visualizing metadata heterogeneity across the entire dataset.</p>
      <p id="P20">The next output of <monospace>cubids-group</monospace> is <monospace>files.tsv</monospace>, which contains one row per NIfTI file in the BIDS directory. This table keeps track of every scan’s assignment to Key and Parameter Groups and includes a field that allows users to easily identify the Key and Parameter Groups to which each image belongs. The next two grouping outputs organize the dataset by Acquisition Group. <monospace>AcqGrouping.tsv</monospace> organizes the dataset by session and tags each one with its Acquisition Group number. Finally, <monospace>AcqGroupInfo.txt</monospace> lists all Key Groups that belong to a given Acquisition Group along with the number of sessions each group possesses.</p>
      <p id="P21">When applied to large datasets, <monospace>cubids-group</monospace> will often reveal issues within a BIDS dataset, some of which validation alone does not always catch. Such issues include missing metadata parameters and runs with low numbers of volumes or unusual image and voxel dimensions. For this reason, <monospace>cubids-group</monospace> can aid users in performing first pass quality assurance on their BIDS dataset. Since <monospace>summary.tsv</monospace> breaks down the dataset by Parameter Group with one column per scanning parameter, users can then search that TSV by desired parameters. Next, users can set a threshold or requirement for a certain parameter (e.g. number of volumes or dimension/voxel size) and use <monospace>cubids-purge</monospace> to remove runs that do not possess the desired values for those parameters. For example, a user may want to remove all fMRI runs with a low number of volumes before data processing with a BIDS App such as fMRIPrep.</p>
    </sec>
    <sec id="S12">
      <label>2.10.</label>
      <title>Applying changes</title>
      <p id="P22">The <monospace>cubids-apply</monospace> program provides an easy way for users to manipulate their datasets. Specifically, <monospace>cubids-apply</monospace> can rename files according to the users’ specification in a tracked and organized way. Here, the <monospace>summary.tsv</monospace> functions as an interface modifications; users can mark Parameter Groups they want to rename (or delete) in a dedicated column of the <monospace>summary.tsv</monospace> and pass that edited TSV as an argument to <monospace>cubids-apply</monospace>.</p>
      <p id="P23">Additionally, <monospace>cubids-apply</monospace> can automatically rename files in Variant Groups based on their scanning parameters that vary from those in their Key Groups’ Dominant Parameter Groups. Renaming is automatically suggested when the <monospace>summary.tsv</monospace> is generated from a <monospace>cubids-group</monospace> run, with the suggested new name listed in the TSV’s “Rename Key Group” column. CuBIDS populates this column for all Variant Groups—e.g., every Parameter Group except the Dominant one. Specifically, CuBIDS will suggest renaming all Non-Dominant Parameter Groups to include VARIANT* in their acquisition field where * is the reason the Parameter Group varies from the Dominant Group. For example, when CuBIDS encounters a Parameter Group with a repetition time that varies from the one present in the Dominant Group, it will automatically suggest renaming all runs in that Variant Group to include <monospace>acquisition-VARIANTRepetitionTime</monospace> in their filenames. When the user runs <monospace>cubids-apply</monospace>, filenames will get renamed according to the auto-generated names in the “Rename Key Group” column in the <monospace>summary.tsv</monospace> (see <xref rid="F3" ref-type="fig">Fig. 3</xref>)).</p>
    </sec>
    <sec id="S13">
      <label>2.11.</label>
      <title>Customizable configuration</title>
      <p id="P24">CuBIDS also features an optional, customizable, MRI image type-specific configuration file. This file can be passed as an argument to <monospace>cubids-group</monospace> and <monospace>cubids-apply</monospace> using the ---<monospace>config</monospace> flag and allows users to customize grouping settings based on image type and parameter. Each Key Group is associated with one (and only one) MRI image type, as BIDS filenames include MRI image type-specific values as their suffixes. This easy-to-modify configuration file provides several benefits to curation. First, it allows users to add and remove metadata parameters from the set that determines groupings. This can be very useful if a user deems a specific metadata parameter irrelevant and wishes to collapse variation based on that parameter into a single Parameter Group. Second, the configuration file allows users to apply tolerances for parameters with numerical values. This functionality allows users to avoid very small differences in scanning parameters (i.e., a TR of 3.0 s vs 3.0001 s) being split into different Parameter Groups. Third, the configuration file allows users to determine which scanning parameters are listed in the <monospace>acquisition</monospace> field when auto-renaming is applied to Variant Groups.</p>
    </sec>
    <sec id="S14">
      <label>2.12.</label>
      <title>Exemplar testing</title>
      <p id="P25">In addition to facilitating curation of large, heterogeneous BIDS datasets, CuBIDS also prepares datasets for testing BIDS Apps. This portion of the CuBIDS workflow relies on the concept of the Acquisition Group: a set of sessions that have identical scan types and metadata across all MRI image types present in the session set. Specifically, <monospace>cubids-copy-exemplars</monospace> copies one subject from each Acquisition Group into a separate directory, which we call an Exemplar Dataset. Since the Exemplar Dataset contains one randomly selected subject from each unique Acquisition Group in the dataset, it will be a valid BIDS dataset that spans the entire metadata parameter space of the full study. If users run <monospace>copy-exemplars</monospace> with the ---<monospace>use-datalad</monospace> flag, the program will ensure that the Exemplar Dataset is tracked and saved in DataLad. If the user chooses to forgo this flag, the Exemplar Dataset will be a standard directory located on the filesystem. Once the Exemplar Dataset has been created, a user can test it with a BIDS App (e.g., fMRIPrep or QSIPrep) to ensure that each unique set of scanning parameters will pass through the pipelines successfully. Because BIDS Apps auto-configure workflows based on the metadata encountered, they will process all runs in each Acquisition Group in the same way. By first verifying that BIDS Apps perform as intended on the small sub-sample of participants present in the Exemplar Dataset (that spans the full variation of the metadata), users can confidently move forward processing the data of the complete BIDS dataset.</p>
    </sec>
  </sec>
  <sec id="S15">
    <label>3.</label>
    <title>Results</title>
    <p id="P26">The CuBIDS workflow is currently being used in neuroimaging labs at a number of institutions including the University of Pennsylvania, the Children’s Hospital of Philadelphia, the Child Mind Institute, and the University of Minnesota’s Masonic Institute for the Developing Brain. To demonstrate the utility of CuBIDS, here we apply the software to two datasets. First, we curate a small example dataset that is included in the software’s GitHub repository and can be downloaded here. Second, we apply CuBIDS to the large-scale data of the Philadelphia Neurodevelopmental Cohort.</p>
    <sec id="S16">
      <label>3.1.</label>
      <title>The CuBIDS workflow for curating a BIDS dataset (example dataset)</title>
      <p id="P27">The following walkthrough displays the process of curating a dataset using CuBIDS on a Linux machine. This example walkthrough is also documented on the CuBIDS Read the Docs page. To do so, we use an example dataset that is bundled with the software. For this demonstration, we install CuBIDS inside a conda environment. Note that if you are using an Apple M1 chip machine, you will need to install Miniforge instead of Miniconda. Once we have conda installed we create and activate a new environment using the following commands:</p>
      <preformat position="float" xml:space="preserve">
conda create -n test-env python=3.8
conda activate test-env
</preformat>
      <p id="P30">To obtain CuBIDS locally, we can use pip to download our software from the Python Package Manager (Pypi) using the following command:</p>
      <preformat position="float" xml:space="preserve">
pip install CuBIDS
</preformat>
      <p id="P32">Alternatively, we can clone from the CuBIDS GitHub repository using the following command:</p>
      <preformat position="float" xml:space="preserve">
git clone <ext-link xlink:href="https://github.com/PennLINC/CuBIDS.git" ext-link-type="uri">https://github.com/PennLINC/CuBIDS.git</ext-link>
</preformat>
      <p id="P34">Now that we have a copy of the source code, we can install it by running</p>
      <preformat position="float" xml:space="preserve">
cd CuBIDS
pip install -e.
</preformat>
      <p id="P37">We will now need to install some dependencies of CuBIDS. To do this, we first must install nodejs. We can accomplish this using the following command:</p>
      <preformat position="float" xml:space="preserve">
conda install nodejs
</preformat>
      <p id="P39">Now that we have npm installed, we can install the bids-validator using the following command:</p>
      <preformat position="float" xml:space="preserve">
npm install -g bids-validator@1.7.2
</preformat>
      <p id="P41">In this example, we use the bids-validator v1.7.2. using a different version of the validator may result in slightly different validation TSV printouts, but CuBIDS is compatible with all versions of the validator at or above v1.6.2. Throughout this example walkthrough, we use DataLad for version control, so we will also need to install both DataLad and git-annex, the large file storage software DataLad runs under the hood. Installation instructions for DataLad and git-annex can be found here.</p>
      <p id="P42">Now that we have installed CuBIDS and all necessary dependencies, we are ready to begin the curation process on our example dataset. We create a <monospace>CuBIDS_Test</monospace> directory to function as the working directory and navigate to it as follows:</p>
      <preformat position="float" xml:space="preserve">
mkdir $PWD/CuBIDS_Test
cd CuBIDS_Test
</preformat>
      <p id="P45">Throughout this walkthrough, we will run all commands from the <monospace>CuBIDS_Test</monospace> directory. Next, we download <monospace>BIDS_Dataset.zip</monospace> (a ZipFile containing the example dataset) and unzip as follows:</p>
      <preformat position="float" xml:space="preserve">
curl -sSLO <ext-link xlink:href="https://github.com/PennLINC/CuBIDS/raw/main/cubids/testdata/BIDS_Dataset.zip" ext-link-type="uri">https://github.com/PennLINC/CuBIDS/raw/main/cubids/testdata/BIDS_Dataset.zip</ext-link>
unzip BIDS_Dataset.zip
rm BIDS_Dataset.zip
</preformat>
      <p id="P49">As a first step, we use CuBIDS to identify the metadata fields present in the dataset. This is accomplished with the following command:</p>
      <preformat position="float" xml:space="preserve">
cubids-print-metadata-fields BIDS_Dataset
</preformat>
      <p id="P51">This command returns a total of 66 fields, including acquisition parameters and other metadata fields present in the dataset’s JSON sidecars. Some of these fields contain simulated protected health information (PHI) such as <monospace>PatientName</monospace> that we wish to remove. Completing this step prior to checking the BIDS dataset into DataLad is critical, as we must ensure PHI is not tracked as part of version control. To remove the <monospace>PatientName</monospace> field from the sidecars, we can use the command:</p>
      <preformat position="float" xml:space="preserve">
  cubids-remove-metadata-fields BIDS_Dataset
--fields PatientName
</preformat>
      <p id="P54">If we were to run <monospace>cubids-print-metadata-fields</monospace> once more, we would see that <monospace>PatientName</monospace> is no longer present in the dataset. Now that all PHI has been removed from the metadata, we are ready to check our dataset into DataLad. To do this, we run the following command:</p>
      <preformat position="float" xml:space="preserve">
datalad create -c text2git BIDS_Dataset_DataLad
</preformat>
      <p id="P56">The creation of our DataLad dataset will be accordingly reflected in the dataset’s version control history, or “git log” (see example in <xref rid="F4" ref-type="fig">Fig. 4A</xref>). At any point in the CuBIDS workflow, we can view a summary of our dataset’s version history by running the following commands:</p>
      <preformat position="float" xml:space="preserve">
cd BIDS_Dataset_DataLad
git log --oneline
cd ..
</preformat>
      <p id="P60">Next, we copy the contents of our BIDS dataset into the newly created and currently empty DataLad dataset:</p>
      <preformat position="float" xml:space="preserve">
cp -r BIDS_Dataset/* BIDS_Dataset_DataLad
</preformat>
      <p id="P62">In addition to being able to access the version history of our data, any point in this workflow, we can also check the status of untracked (not yet saved) changes using the datalad status command, as seen below:</p>
      <preformat position="float" xml:space="preserve">
datalad status -d BIDS_Dataset_DataLad
</preformat>
      <p id="P64">This command produces a description of the changes we have made to the data since the last commit (see <xref rid="F4" ref-type="fig">Fig. 4B</xref>). The command above shows all files untracked, as we have copied the BIDS data into <monospace>BIDS_Dataset_DataLad</monospace> but have not yet saved those changes. Our next step is to run save. It is best practice to provide a detailed commit message, for example:</p>
      <preformat position="float" xml:space="preserve">
   datalad save -d BIDS_Dataset_DataLad -m
"checked dataset into datalad"
</preformat>
      <p id="P67">This commit is reflected in our git log (see <xref rid="F4" ref-type="fig">Fig. 4C</xref>). Now that the dataset is checked into DataLad, at any point in the workflow going forward, we can run the following command to revert the dataset back to the previous commit:</p>
      <preformat position="float" xml:space="preserve">
cubids-undo BIDS_Datast_DataLad
</preformat>
      <p id="P69">At this stage, we also recommend removing the <monospace>BIDS_Dataset</monospace> directory — its contents are safely copied into and tracked in <monospace>BIDS_Dataset_DataLad</monospace>.</p>
      <p id="P71">Next, we seek to add new fields regarding our image parameters that are only reflected in the NIfTI header to our metadata; these include important details such as image dimensions, number of volumes, image obliquity, and voxel sizes. To do this, we run:</p>
      <preformat position="float" xml:space="preserve">
   cubids-add-nifti-info BIDS_Dataset_DataLad
--use-datalad
</preformat>
      <p id="P74">This command adds the NIfTI header information to the JSON sidecars and saves those changes. In order to ensure that this command has been executed properly, we can run <monospace>cubids-print-metadata-fields</monospace> once more, which reveals that NIfTI header information has been successfully included in the metadata. Since we ran <monospace>add-nifti-info</monospace> with the --<monospace>use-datalad</monospace> flag set, CuBIDS will automatically save the changes made to the dataset to the git log (see <xref rid="F4" ref-type="fig">Fig. 4D</xref>)).</p>
      <p id="P75">The above panels display the version history of the small, example DataLad dataset we curated to display the effectiveness of the CuBIDS workflow. These panels are screenshots of the git history of the dataset taken after each change was made to the data. A shasum (yellow string of letters and numbers to the left of each commit message) is assigned to each commit, and each commit is recorded with a message (white text describing the changes made to the data). If users would like more information about each commit, they can run the <monospace>git log</monospace> command without the <monospace>oneline</monospace> flag to get a detailed summary of each commit. This summary will include files that were changed, exact changes that were made to each file, date and time of the commit, and information about the git user who made the changes. At any point in the workflow after checking the dataset into DataLad, we can use <monospace>cubids-undo</monospace> to revert the dataset back to the previous commit.</p>
      <p id="P76">The next step in the CuBIDS workflow is to understand what BIDS validation errors may be present (using <monospace>cubids-validate</monospace>) as well as the structure, heterogeneity, and metadata errors present in the dataset (using <monospace>cubids-group</monospace>). Notably, neither of these two programs requires write access to the data, as each simply reads in the contents of the data and creates TSVs that parse the metadata and validation errors present. Validation can be accomplished by running the following command:</p>
      <preformat position="float" xml:space="preserve">
  cubids-validate BIDS_Dataset_DataLad v0
--sequential
</preformat>
      <p id="P79">The use of the sequential flag forces the validator to treat each participant as its own BIDS dataset. This command produces <monospace>v0_validation.tsv</monospace> (see <xref rid="SD1" ref-type="supplementary-material">Supplementary Data 1A</xref>).</p>
      <p id="P80">This initial validation run reveals that Phase Encoding Direction (PED) is not specified for one of the BOLD task-rest scans. We can clearly see that we either need to find the PED for this run elsewhere and edit that sidecar to include it or remove that run from the dataset, as this missing scanning parameter will render field map correction impossible. For the purpose of this demonstration, we elect to remove the scan. To do this, we run the following command:</p>
      <preformat position="float" xml:space="preserve">
   cubids-purge BIDS_Dataset_DataLad no_ped.txt
--use-datalad
</preformat>
      <p id="P83">Here, <monospace>no_ped.txt</monospace> (see <xref rid="SD1" ref-type="supplementary-material">Supplementary Data 1B</xref>) is a text file containing the <bold>full path</bold> to the dwi run flagged in <monospace>v0_validation.txt</monospace> for missing PED. The user must create this file before running <monospace>cubids-purge</monospace> (a command such as echo <monospace>$PWD/BIDS_Dataset_DataLad/sub-02/ses-phdiff/func/sub-02_ses-phdiff_task-rest_bold.nii.gz &gt; no_ped.txt</monospace> will work).</p>
      <p id="P84">We elect to use <monospace>cubids-purge</monospace> instead of simply removing the run because <monospace>cubids-purge</monospace> will ensure all associated files, including sidecars and IntendedFor references in the sidecars of fieldmaps, are also deleted. This change will be reflected in the git history (see <xref rid="F4" ref-type="fig">Fig. 4E</xref>).</p>
      <p id="P85">Returning again to <monospace>v0_validation.tsv</monospace>, we can also see that there is one DWI run missing TotalReadoutTime, a metadata field necessary for certain pipelines. In this case, we determine that TotalReadoutTime (TRT) was erroneously omitted from the DWI sidecars. For the purpose of this example, we assume we are able to obtain the TRT value for this run (perhaps by asking the scanner technician). Once we have this value, we manually add it to the sidecar for which it is missing by opening <monospace>BIDS_Dataset_DataLad/sub-03/ses-phdiff/dwi/sub-03_ses-phdiff_acq-HASC55AP_dwi.json</monospace> in an editor and adding the following line:</p>
      <p id="P87"><monospace>"TotalReadoutTime": 0.0717598</monospace>, on a new line anywhere inside the curly braces between lines containing parameters and their values, save the changes, and close the JSON file. We then save the latest changes to the dataset with a detailed commit message as follows:</p>
      <preformat position="float" xml:space="preserve">
   datalad save -d BIDS_Dataset_DataLad
-m "Added TotalReadoutTime to
sub-03_ses-phdiff_acq-HASC55AP_dwi.nii.json"
</preformat>
      <p id="P91">This change will be reflected in the git history (see <xref rid="F4" ref-type="fig">Fig. 4F</xref>).</p>
      <p id="P92">To verify that there are no remaining validation errors, we rerun validation with the following command:</p>
      <preformat position="float" xml:space="preserve">
  cubids-validate BIDS_Dataset_DataLad v1
--sequential
</preformat>
      <p id="P95">This command will produce no TSV output and instead print “<monospace>No issues/warnings parsed, your dataset is BIDS valid</monospace>” to the terminal, which indicates that the dataset is now free from BIDS validation errors and warnings.</p>
      <p id="P96">Along with parsing the BIDS validation errors in our dataset, it is important to understand the dataset’s structure, heterogeneity, and metadata errors. To accomplish these tasks, we use <monospace>cubids-group</monospace>. Large datasets almost inevitably contain multiple validation and metadata errors. As such, it is typically useful to run both <monospace>cubids-validate</monospace> and <monospace>cubids-group</monospace> in parallel, as validation errors are better understood within the context of a dataset’s heterogeneity. Additionally, being able to see both the metadata errors that grouping reveals alongside BIDS errors that the validator catches gives users a more comprehensive view of the issues they will need to fix during the curation process. Note that if users choose to provide just a pass in just a filename prefix (e.g. v0) for the second argument, then CuBIDS will put the four grouping outputs in <monospace>bids_dir/code/CuBIDS</monospace>. If users provide a path (e.g. <monospace>$PWD/v0</monospace>), then output files will go to the specified location. The command to run the grouping function is as follows:</p>
      <preformat position="float" xml:space="preserve">
cubids-group BIDS_Dataset_DataLad v0
</preformat>
      <p id="P98">As noted in <xref rid="T1" ref-type="table">Table 1</xref>, this command will produce four tables that display the dataset’s heterogeneity in different ways. First, <monospace>v0_summary.tsv</monospace> contains all detected Key and Parameter groups and provides a high-level overview of the heterogeneity in the entire dataset (see <xref rid="SD1" ref-type="supplementary-material">Supplementary Data 1C</xref>). Second, <monospace>v0_files.tsv</monospace> (see <xref rid="SD1" ref-type="supplementary-material">Supplementary Data 1D</xref>) maps each imaging file in the BIDS directory to a Key and Parameter group. Third, <monospace>v0_AcqGrouping.tsv</monospace> (see <xref rid="SD1" ref-type="supplementary-material">Supplementary Data 1E</xref>) maps each session in the dataset to an Acquisition Group. Finally, <monospace>v0_AcqGroupInfo.txt</monospace> (see <xref rid="SD1" ref-type="supplementary-material">Supplementary Data 1F</xref>) lists the set of scanning parameters present in each Acquisition Group.</p>
      <p id="P99">The next step in the CuBIDS curation process is to examine <monospace>v0_summary.tsv</monospace>, which allows for automated metadata quality assurance (QA)—the identification of incomplete, incorrect, or unusable parameter groups based on acquisition fields such as dimension and voxel sizes, number of volumes, etc. While <monospace>v0_validation.tsv</monospace> identified all BIDS validation errors present in the dataset, it will not identify several issues that might be present with the sidecars. Such issues include instances of erroneous metadata and missing sidecar fields, which may impact successful execution of BIDS Apps.</p>
      <p id="P100">Examining <monospace>v0_summary.tsv</monospace> (see <xref rid="SD1" ref-type="supplementary-material">Supplementary Data 1C</xref>) we can see that one DWI Parameter Group—<monospace>acquisition-HASC55AP_datatype-dwi_suffix-dwi--2</monospace>--contains only one image (see “Counts” column) with only 10 vol (see “NumVolumes” column). Since the majority of DWI runs in this dataset have 61 vol, CuBIDS assigns this single run to a “Non-Dominant”, or “Variant” Parameter Group and populates that Parameter Group’s “RenameKeyGroup” column in <monospace>v0_summary.tsv</monospace> with <monospace>acquisition-HASC55APVARIANTNumVolumes_datatype-dwi_suffix-dwi</monospace>. For the purpose of this demonstration, we elect to remove this run because it does not have enough volumes to be usable for most analyses. To do this, we can either use <monospace>cubids-purge</monospace>, or we can edit <monospace>v0_summary.tsv</monospace> by adding “0” to the “MergeInto” column in the row (Parameter Group) we want to remove. For this walkthrough, we chose the latter. To do this, we open <monospace>v0_summary.tsv</monospace> in an editor, navigate to row 4, which contains all information for Key Group <monospace>acquisition-HASC55AP_datatype-dwi_suffix-dwi</monospace> Parameter Group 2. If we scroll to the NumVolumes column (row 4, column S), we see this Parameter Group has only 10 vol, which explains why it received an auto-generated Rename Key Group value of <monospace>acquisition-HASC55APVARIANTNumVolumes_datatype-dwi_suffix-dwi</monospace>. Remaining in this same row, we navigate back to column C, which is labeled “MergeInto” and manually a “0” to the cell in row 4 column C. This will ensure all runs in that Parameter Group (in this example, just one scan) are removed when we run <monospace>cubids-apply</monospace>. We then export and save the TSV in our <monospace>CuBIDS_Test</monospace> working directory as <monospace>v0_edited_summary.tsv</monospace> (see <xref rid="SD1" ref-type="supplementary-material">Supplementary Data 1 G</xref>). We will then save this edited version of <monospace>v0_summary.tsv</monospace> as <monospace>v0_edited_summary.tsv</monospace>, which will be passed into <monospace>cubids-apply</monospace> in our next curation step.</p>
      <p id="P101">Now that all metadata issues have been remedied--both the validation and summary outputs appear problem-free--we are ready to rename our files based on their Rename Key Group values and apply the requested deletion in <monospace>v0_edited_summary.tsv</monospace>. The <monospace>cubids-apply</monospace> function renames runs in each Variant Parameter Group according to the metadata parameters with a flag “<monospace>VARIANT</monospace>”, which is useful because the user will then be able to see, in each scan’s filename, which metadata parameters associated with that run vary from those in the acquisition’s Dominant Group. Note that like in <monospace>cubids-group, cubids-apply</monospace> requires full paths to the BIDS Dataset, summary and files TSVs, and output prefix. If the edited summary and files TSVs are located in the <monospace>bids_dir/code/CuBIDS</monospace> directory, the user may just pass in those filenames. Otherwise, specifying the path to those files is necessary. We execute <monospace>cubids-apply</monospace> with the following command:</p>
      <preformat position="float" xml:space="preserve">
   cubids-apply BIDS_Dataset_DataLad
v0_edited_summary.tsv v0_files.tsv v1
--use-datalad
</preformat>
      <p id="P105">Checking our git log, we can see that all changes from apply have been saved (see <xref rid="F4" ref-type="fig">Fig. 4G</xref>). As a final step, we can check the four grouping TSVs <monospace>cubids-apply</monospace> produces (see <xref rid="SD1" ref-type="supplementary-material">Supplementary Data 1H</xref>-<xref rid="SD1" ref-type="supplementary-material">K</xref>) to ensure they look as expected--that all files with variant scanning parameters have been renamed to indicate the parameters that vary in the acquisition fields of their filenames (and therefore Key Group names).</p>
      <p id="P106">At this stage, the curation of the dataset is complete; next is preprocessing. CuBIDS facilitates this subsequent step through the creation of an Exemplar Dataset: a subset of the full dataset that spans the full variation of acquisitions and parameters by including one subject from each Acquisition Group. By testing only one subject per Acquisition Group, users are able to pinpoint both the specific metadata values and runs that may be associated with pipeline failures; these acquisition groups could then be evaluated in more detail and flagged for remediation or exclusion. The Exemplar Dataset can easily be created with the <monospace>cubids-copy-exemplars</monospace> command, to which we pass in <monospace>v1_AcqGrouping.tsv</monospace>—the post-apply acquisition grouping TSV (see <xref rid="SD1" ref-type="supplementary-material">Supplementary Data 1 J</xref>).</p>
      <preformat position="float" xml:space="preserve">
  cubids-copy-exemplars BIDS_Dataset_DataLad
Exemplar_Dataset v1_AcqGrouping.tsv
--use-datalad
</preformat>
      <p id="P110">Since we used the <monospace>use-datalad</monospace> flag, <monospace>Exemplar_Dataset</monospace> is a DataLad dataset with the version history tracked in its git log (see <xref rid="F4" ref-type="fig">Fig. 4H</xref>). Once a preprocessing pipeline completes successfully on the Exemplar Dataset, the full dataset can be executed with confidence, as a pipeline’s behavior on the full range of metadata heterogeneity in the dataset will have already been discovered during exemplar testing.</p>
    </sec>
    <sec id="S17">
      <label>3.2.</label>
      <title>Application to a large-scale study of brain development</title>
      <p id="P111">In addition to applying the CuBIDS workflow to a toy dataset, here we describe the workflow applied to the Philadelphia Neurodevelopmental Cohort (PNC), a multimodal dataset of <italic toggle="yes">n</italic> = 1601 participants. The PNC data is publicly available (<xref rid="R14" ref-type="bibr">Satterthwaite et al., 2014</xref>) and is one of many datasets encompassing the forthcoming Reproducible Brain Chart (RBC)—a large, developmental neuroimaging aggregation initiative led jointly by the University of Pennsylvania and the Child Mind Institute. CuBIDS was developed, in part, to help manage the data for RBC. The curated version of the dataset will be publicly available as part of the forthcoming RBC data release. The PNC curation workflow involved iterative rounds of checking and fixing due to the heterogeneity and size of the dataset, so the following section will be a summary of how we used CuBIDS to curate this dataset (rather than a step-by-step walkthrough).</p>
      <p id="P112">One of our early curation actions was to take inventory regarding the metadata heterogeneity of PNC by obtaining the initial summary table. To do this, we ran <monospace>cubids-group</monospace>, which requires approximately 15 min to finish on PNC. For smaller datasets including our toy dataset from the walkthrough described above, <monospace>cubids-group</monospace> completes in just seconds. Examining the initial summary table (see <xref rid="SD2" ref-type="supplementary-material">Supplementary Data 2B</xref>), we find that PNC contains 144 Parameter Groups—runs containing both identical BIDS filename key-value pairs and identical metadata parameters present in their sidecars. The summary table is organized by MRI image type, so we can easily see that some MRI image types and acquisitions in the dataset are much more heterogeneous with respect to their metadata parameters than are others. For example, from the table, we can see that PNC has only one Key Group for T1w runs and only three Parameter Groups. Furthermore, according to the “Counts” column of the tsv, the vast majority of T1w runs (<italic toggle="yes">n</italic> = 1597), are in the Dominant Parameter Group. By contrast, in this same summary table we can see that there are 62 different Parameter Groups in the dataset for task-frac2back BOLD fMRI scans. Examining the “RenameKeyGroup” column of those frac2back rows in the summary table, we can see that the primary source of variance is the number of volumes acquired.</p>
      <p id="P113">Our team relied upon the summary table to make a number of curation decisions—especially inclusion/exclusion based on metadata. The summary table provided a platform for collaboration and discussion among the team that was curating, validating, and modifying the dataset. Since PNC was curated with DataLad and is saved as a DataLad Dataset, a detailed history of the curation decisions can be found in the commit history. Each change to the dataset was saved with a commit message, so all modifications we made to the dataset are tracked and tagged with a shasum. If we want to restore PNC to a previous curation stage, we can so using <monospace>cubids-undo</monospace>.</p>
      <p id="P114">Modifications to PNC during the curation stage, documented in the dataset’s git log, include creating and adding previously missing events tsvs, adding NIfTI header information to all sidecars in the dataset (using the <monospace>cubids-add-nifti-info</monospace> command), removing DWI runs that do not have enough volumes to successfully run through diffusion preprocessing pipelines (e.g. QSIPrep), and adding Parallel Reduction Factor in Plane to two sidecars that were initially missing this field. Once the validation and grouping outputs revealed we had no more BIDS and metadata issues to fix, we ran <monospace>cubids-apply</monospace> on the dataset to produce a new set of TSVs (see <xref rid="SD2" ref-type="supplementary-material">Supplementary Data 2 G</xref>-<xref rid="SD2" ref-type="supplementary-material">J</xref>). As can be seen in the summary table (see <xref rid="SD2" ref-type="supplementary-material">Supplementary Data 2G</xref>) generated by <monospace>cubids-apply</monospace>, all runs in Variant (e.g., non-Dominant) Groups were renamed based on the scanning parameters that are variant (see <xref rid="F3" ref-type="fig">Fig. 3</xref>).</p>
      <p id="P115">We then executed the final step of the <monospace>CuBIDS</monospace> workflow, which entailed running <monospace>cubids-copy-exemplars</monospace>. This command creates the Exemplar Dataset—a DataLad-tracked BIDS dataset containing one subject from each Acquisition Group (see <xref rid="SD2" ref-type="supplementary-material">Supplementary Data 2I</xref>). The final, curated version of PNC contains 1601 participants, 15,077 scans, and 65 Acquisition Groups. Thus, the Exemplar Dataset contains only 65 participants but spans the entire dataset’s parameter space, reducing the scope of the pipeline testing by 96%. We then used this Exemplar Dataset to test MRI image type-specific preprocessing pipelines such as fMRIPrep and QSIPrep.</p>
      <p id="P116">For large datasets especially, exemplar testing can be a necessary step; users will often need to go back and re-curate aspects of the BIDS data based on metadata errors that only become apparent during pipeline runs on the Exemplar Dataset. For example, after we ran the PNC Exemplar Dataset through QSIPrep, we noticed that one participant (whose Acquisition Group includes 34 participants), failed to complete the pipeline successfully. After examining the error log, we realized that for this participant, the number of bvals did not match the number of volumes in the scan’s sidecar (which was pulled directly from the NIfTI header and added to the sidecar during the <monospace>cubids-add-nifti-info</monospace> step of curation). Since all participants in the same Acquisition Group possess identical scanning parameters, when a pipeline encounters a metadata error in an Exemplar Subject, all participants in that Acquisition Group will have that same error and thus require the same fix. Accordingly, we used <monospace>cubids-purge</monospace> to remove all DWI runs from that Exemplar Group and reran <monospace>cubids-group</monospace> to obtain our final CuBIDS outputs (see <xref rid="SD2" ref-type="supplementary-material">Supplementary Data 2K</xref>-<xref rid="SD2" ref-type="supplementary-material">N</xref>). Since all other Exemplar Subjects passed through QSIPrep successfully, we were then able to run the pipeline through the entire dataset without concern that erroneous metadata would impact preprocessing.</p>
    </sec>
  </sec>
  <sec id="S18">
    <label>4.</label>
    <title>Discussion</title>
    <p id="P117">Ample recent evidence has emphasized the challenges to reproducibility in neuroimaging research (<xref rid="R11" ref-type="bibr">Kang et al., 2016</xref>). Although often overlooked, curation can be a critical part of the scientific workflow. Because curation is often the first step after data acquisition, errors in curation can ramify throughout each subsequent stage. BIDS apps adapt to metadata encountered in an automatic and flexible way, which can be a vulnerability in ensuring datasets are processed identically. If BIDS data are improperly curated, pre-processing pipelines may mis-configure, with the potential to impact eventual results. Curation challenges are particularly acute in large-scale data resources, which continue to proliferate (e.g., UK Biobank, ABCD, PNC, HBN, HCP, etc.) (<xref rid="R2" ref-type="bibr">Bycroft et al., 2018</xref>; <xref rid="R12" ref-type="bibr">Karcher and Barch, 2021</xref>; <xref rid="R14" ref-type="bibr">Satterthwaite et al., 2014</xref>; <xref rid="R1" ref-type="bibr">Alexander et al., 2017</xref>; <xref rid="R15" ref-type="bibr">Van Essen et al., 2013</xref>). In large datasets, curation is often an iterative, manual process that is neither well documented nor reproducible. To address these challenges, CuBIDS allows for reproducible data curation at scale. As discussed below, our software provides five main advantages: stability in validation, reproducibility in curation, the ability to identify and manage heterogeneity, transparency in naming, and accelerated pipeline testing.</p>
    <sec id="S19">
      <label>4.1.</label>
      <title>Stable BIDS validation at scale</title>
      <p id="P118">The BIDS Validator is the current standard tool for validation of all BIDS datasets. It is widely used and plays an essential role in the standard BIDS workflow; it effectively identifies the ways in which a dataset does not comply with BIDS standards. However, it does not scale well, at times failing unpredictably on larger samples. Furthermore, when run in a Linux shell, the validator prints (often a large volume) of text describing the errors and warnings to the terminal screen. For large datasets with many errors and warnings, such information is often quite difficult to visualize and comprehend. We wrapped the BIDS Validator in the <monospace>cubids-validate</monospace> CLI to address these challenges, creating a scalable implementation that yields a readable TSV. This allows users to easily identify the range of validation issues that may be present in a large-scale dataset.</p>
    </sec>
    <sec id="S20">
      <label>4.2.</label>
      <title>Reproducible data curation</title>
      <p id="P119">Curation of large, heterogeneous BIDS datasets is an iterative, multistep task. However, this process is often not reproducible, which, in turn, may compromise the reproducibility of subsequent workflows. Without version control, any decision made during the curation process—such as inclusion/exclusion decisions or editing metadata—will go unrecorded. Further, if the person curating the data makes a mistake, they will have no clear way to undo that mistake and revert the data to a prior state. In leveraging CuBIDS’ use of DataLad, users can save each change made to a dataset with a detailed commit message (e.g. “Removed all DWI runs with less than 30 vol ”). If a user erroneously changes the data and wants to undo those changes, <monospace>cubids-undo</monospace> reverts the most recent commit.</p>
    </sec>
    <sec id="S21">
      <label>4.3.</label>
      <title>Parsing heterogeneity in large-scale data resources</title>
      <p id="P120">While <monospace>cubids-validate</monospace> will catch instances where the data does not comply with BIDS format, it has important limitations. For example, validation does not always account for missing JSON sidecars or empty NIfTI headers. In addition, it will neither identify runs that have errant metadata values nor those with parameters that might render the runs unusable. This functionality is provided by <monospace>cubids-group</monospace>, which produces parameter-based summary tables that parse the dataset based on metadata, allowing for users to visualize and assess metadata quality in ways that validation cannot.</p>
      <p id="P121">This functionality is especially critical in the curation of large datasets. Scaling up both the number of participants and the number of scanners within a single data resource has the potential to introduce a massive amount of heterogeneity to that study’s eventual BIDS dataset. Heterogeneity in scanning parameters can result in heterogeneity in preprocessing pipelines; if users are do not appreciate the metadata heterogeneity in their dataset, they may be surprised by inconsistencies in preprocessing settings and outcomes. Further, parameter groups could be explicitly modeled when accounting for batch effects rather than just using scanner or site. Thus, being able to identify and correct metadata errors in a heterogeneous dataset is a critical part of the data curation process, as such decisions may impact the derived images from preprocessing pipelines.</p>
    </sec>
    <sec id="S22">
      <label>4.4.</label>
      <title>Enhancing transparency with dominant and variant groups</title>
      <p id="P122">In order to provide transparent documentation of parameter heterogeneity, the <monospace>cubids-apply</monospace> function renames runs in each MRI image type according to their variant metadata parameters. For example, if the majority of BOLD task-rest runs in a dataset are Oblique but sub-X’s image is not oblique, CuBIDS users can choose to accept and apply the automatically suggested renaming of “<monospace>acq-VARIANTObliquity</monospace>” to that run’s filename. When performing sensitivity analyses on derivatives from datasets that have been curated using CuBIDS, researchers may choose to exclude any runs in Non-Dominant Groups to ensure that scanning parameters variance does not affect their results. Alternatively, researchers could use image harmonization tools (e.g., ComBat) to ensure that such variation does not impact analyses (<xref rid="R7" ref-type="bibr">Fortin et al., 2018</xref>).</p>
    </sec>
    <sec id="S23">
      <label>4.5.</label>
      <title>Accelerating pipeline testing with exemplar datasets</title>
      <p id="P123">Even after careful curation, the best way to verify successful image processing is empirical testing. In a highly heterogeneous dataset, pipeline testing often reveals errors that were not immediately apparent on initial curation, which usually require minor additional adjustments to the metadata or exclusion of specific scans. Finding such edge cases while processing a large dataset can slow down the workflow, so it is advantageous to conduct pipeline testing before full deployment on a large data set. CuBIDS facilitates this process through the creation of Exemplar Datasets that include data from each Acquisition Group and thus span the full variation of the metadata present. After successful testing on the Exemplar Dataset, the likelihood that unexpected outcomes occur when the full dataset is processed is dramatically reduced. Furthermore, resource usage can be monitored during the exemplar runs to estimate the runtime and storage demands for processing the entire dataset.</p>
    </sec>
    <sec id="S24">
      <label>4.6.</label>
      <title>Limitations</title>
      <p id="P124">CuBIDS possesses several limitations that should be acknowledged. First, at present, CuBIDS does not possess a GUI, so running the software requires basic knowledge of the terminal and Linux machines. However, such skills are likely to be a prerequisite for curating large-scale imaging datasets. Second, if users are curating BIDS Datasets with <italic toggle="yes">n</italic>&gt;2500 participants and using the DataLad-enabled version control option, CuBIDS programs that rely on saving changes made to the dataset might experience runtimes that extend to over an hour—due to the need for DataLad to index such a large dataset. Third, our <monospace>add-nifti-info</monospace> program does pull Obliquity, Number of Volumes, Dimension Size, Image Orientation, and Voxel Sizes from the NIfTI header and adds those values to the sidecars. However, we do not currently cross-reference existing sidecar metadata with NIFTI header values. This additional functionality would be a good future direction for the software but is currently outside the scope of this paper. Finally, CuBIDS is currently only able to handle MRI BIDS, not other MRI image types, and can only be run on disk—either a local machine or a high performance computing cluster; users cannot currently run CuBIDS using either cloud-based computing (e.g., Amazon’s S3) or neuroimaging databases such as the eXtensible Neuroimaging Archive Toolkit (XNAT), Longitudinal Online Research and Imaging System (LORIS), Collaborative Informatics Neuroimaging Suite (COINS), and the commercial platform Flywheel (<xref rid="R10" ref-type="bibr">Herrick et al., 2016</xref>; <xref rid="R4" ref-type="bibr">Das et al., 2012</xref>; <xref rid="R13" ref-type="bibr">Landis et al., 2016</xref>). Such functionality may be added to the software in future releases.</p>
    </sec>
  </sec>
  <sec id="S25">
    <label>5.</label>
    <title>Conclusions</title>
    <p id="P125">Curating large, heterogeneous neuroimaging datasets can be a difficult and frustrating task. As the size and heterogeneity of data resources continues to expand, tools that allow for reproducible curation are not only helpful but necessary. CuBIDS facilitates efficient identification and correction of issues present in the metadata of heterogeneous BIDS datasets in a reproducible manner. Furthermore, CuBIDS Exemplar Datasets allow users to verify that BIDS Apps perform as intended on a small sub-sample of participants that spans the entire parameter space of the dataset, accelerating the processing of all data from the complete study. Together, CuBIDS allows users to simultaneously streamline curation and ameliorate metadata issues while maximizing reproducibility.</p>
  </sec>
  <sec sec-type="supplementary-material" id="SM1">
    <title>Supplementary Material</title>
    <supplementary-material id="SD1" position="float" content-type="local-data">
      <label>1</label>
      <media xlink:href="NIHMS1850027-supplement-1.zip" id="d64e1103" position="anchor"/>
    </supplementary-material>
    <supplementary-material id="SD2" position="float" content-type="local-data">
      <label>2</label>
      <media xlink:href="NIHMS1850027-supplement-2.zip" id="d64e1106" position="anchor"/>
    </supplementary-material>
    <supplementary-material id="SD3" position="float" content-type="local-data">
      <label>3</label>
      <media xlink:href="NIHMS1850027-supplement-3.docx" id="d64e1109" position="anchor"/>
    </supplementary-material>
  </sec>
</body>
<back>
  <ack id="S26">
    <title>Acknowledgements</title>
    <p id="P126">This study was supported by grants from the National Institutes of Health: R01MH120482, R37MH125829, R01MH113550, R01EB022573, RF1MH116920, R01MH112847, R01MH123550, R01NS112274, R01MH123563. Additional support was provided by the CHOP-Penn Lifespan Brain Institute, the Penn Brain Science Center, and the Center for Biomedical Image Computing and Analytics</p>
  </ack>
  <fn-group>
    <fn id="FN2">
      <p id="P127">APPENDIX A. SUPPLEMENTARY MATERIAL</p>
      <p id="P128">Supplementary Data 1 (for toy dataset in Results)</p>
      <p id="P129">Supplementary Data files 1A-O are zipped into Supplementary_Data_1.zip (submitted as supplementary material)</p>
    </fn>
    <fn fn-type="COI-statement" id="FN3">
      <p id="P130">Declaration of Competing Interest</p>
      <p id="P131">The authors of Curation of BIDS (CuBIDS) declare that they have no competing or conflicting interests.</p>
    </fn>
    <fn id="FN4">
      <p id="P132">Credit authorship contribution statement</p>
      <p id="P133"><bold>Sydney Covitz:</bold> Software, Writing – original draft, Writing – review &amp; editing, Conceptualization. <bold>Tinashe M. Tapera:</bold> Writing – review &amp; editing. <bold>Azeez Adebimpe:</bold> Writing – review &amp; editing. <bold>Aaron F. Alexander-Bloch:</bold> Writing – review &amp; editing. <bold>Maxwell A. Bertolero:</bold> Writing – review &amp; editing. <bold>Eric Feczko:</bold> Writing – review &amp; editing. <bold>Alexandre R. Franco:</bold> Writing – review &amp; editing, Data curation. <bold>Raquel E. Gur:</bold> Writing – review &amp; editing. <bold>Ruben C. Gur:</bold> Writing – review &amp; editing. <bold>Timothy Hendrickson:</bold> Software, Writing – review &amp; editing, Data curation. <bold>Audrey Houghton:</bold> Writing – review &amp; editing. <bold>Kahini Mehta:</bold> Writing – review &amp; editing, Data curation. <bold>Kristin Murtha:</bold> Writing – review &amp; editing. <bold>Anders J. Perrone:</bold> Software, Writing – review &amp; editing. <bold>Tim Robert-Fitzgerald:</bold> Writing – review &amp; editing. <bold>Jenna M. Schabdach:</bold> Writing – review &amp; editing. <bold>Russell T Shinohara:</bold> Writing – review &amp; editing. <bold>Jacob W. Vogel:</bold> Writing – review &amp; editing. <bold>Chenying Zhao:</bold> Writing – review &amp; editing. <bold>Damien A. Fair:</bold> Software, Writing – review &amp; editing, Data curation. <bold>Michael P. Milham:</bold> Writing – review &amp; editing, Data curation. <bold>Matthew Cieslak:</bold> Software, Writing – original draft, Writing – review &amp; editing, Conceptualization, Supervision. <bold>Theodore D. Satterthwaite:</bold> Software, Writing – original draft, Writing – review &amp; editing, Data curation, Conceptualization, Supervision.</p>
    </fn>
    <fn id="FN5">
      <p id="P134">Data and code availability statement</p>
      <p id="P135">A copy of the small, example dataset whose curation we walk through in the <xref rid="S15" ref-type="sec">Results</xref> section is compressed into a ZipFile and available for download here. Additionally, the Philadelphia Neurodevelopmental Cohort (PNC), the dataset whose curation we summarize in the second portion of the Results, is publicly available in the Database of Genotypes and Phenotypes (dbGaP accession phs000607.v3.p2).</p>
      <p id="P136">The source code for CuBIDS is publicly available at <ext-link xlink:href="https://github.com/PennLINC/CuBIDS" ext-link-type="uri">https://github.com/PennLINC/CuBIDS</ext-link>, the documentation for our software is available at <ext-link xlink:href="https://cubids.readthedocs.io/en/latest/" ext-link-type="uri">https://cubids.readthedocs.io/en/latest/</ext-link>, and our package is available for download on the Python Package Manager (pypi) <ext-link xlink:href="https://pypi.org/project/cubids/" ext-link-type="uri">https://pypi.org/project/cubids/</ext-link>.</p>
    </fn>
    <fn id="FN6">
      <p id="P137">Supplementary materials</p>
      <p id="P138">Supplementary material associated with this article can be found, in the online version, at doi:<ext-link xlink:href="10.1016/j.neuroimage.2022.119609" ext-link-type="doi">10.1016/j.neuroimage.2022.119609</ext-link>.</p>
    </fn>
  </fn-group>
  <ref-list>
    <title>References</title>
    <ref id="R1">
      <mixed-citation publication-type="journal"><name><surname>Alexander</surname><given-names>L</given-names></name>, <name><surname>Escalera</surname><given-names>J</given-names></name>, <name><surname>Ai</surname><given-names>L</given-names></name>, <etal/>, <year>2017</year>. <article-title>An open resource for transdiagnostic research in pediatric mental health and learning disorders</article-title>. <source>Sci. Data</source><volume>4</volume>, <fpage>170181</fpage>. doi: <pub-id pub-id-type="doi">10.1038/sdata.2017.181</pub-id>.<pub-id pub-id-type="pmid">29257126</pub-id></mixed-citation>
    </ref>
    <ref id="R2">
      <mixed-citation publication-type="journal"><name><surname>Bycroft</surname><given-names>C</given-names></name>, <name><surname>Freeman</surname><given-names>C</given-names></name>, <name><surname>Petkova</surname><given-names>D</given-names></name>, <etal/>, <year>2018</year>. <article-title>The UK Biobank resource with deep phenotyping and genomic data</article-title>. <source>Nature</source><volume>562</volume>, <fpage>203</fpage>–<lpage>209</lpage>. doi: <pub-id pub-id-type="doi">10.1038/s41586-018-0579-z</pub-id>.<pub-id pub-id-type="pmid">30305743</pub-id></mixed-citation>
    </ref>
    <ref id="R3">
      <mixed-citation publication-type="journal"><name><surname>Cieslak</surname><given-names>M</given-names></name>, <name><surname>Cook</surname><given-names>PA</given-names></name>, <name><surname>He</surname><given-names>X</given-names></name>, <etal/>, <year>2021</year>. <article-title>QSIPrep: an integrative platform for preprocessing and reconstructing diffusion MRI data</article-title>. <source>Nat. Methods</source><volume>18</volume>, <fpage>775</fpage>–<lpage>778</lpage>. doi: <pub-id pub-id-type="doi">10.1038/s41592-021-01185-5</pub-id>.<pub-id pub-id-type="pmid">34155395</pub-id></mixed-citation>
    </ref>
    <ref id="R4">
      <mixed-citation publication-type="journal"><name><surname>Das</surname><given-names>S</given-names></name>, <name><surname>Zijdenbos</surname><given-names>AP</given-names></name>, <name><surname>Harlap</surname><given-names>J</given-names></name>, <name><surname>Vins</surname><given-names>D</given-names></name>, <name><surname>Evans</surname><given-names>AC</given-names></name>, <year>2012</year>. <article-title>LORIS: a web-based data management system for multi-center studies</article-title>. <source>Front. Neuroinformatics</source><volume>5</volume>, <fpage>37</fpage>. doi: <pub-id pub-id-type="doi">10.3389/fninf.2011.00037</pub-id>.</mixed-citation>
    </ref>
    <ref id="R5">
      <mixed-citation publication-type="journal"><name><surname>Esteban</surname><given-names>O</given-names></name>, <name><surname>Markiewicz</surname><given-names>CJ</given-names></name>, <name><surname>Blair</surname><given-names>RW</given-names></name>, <etal/>, <year>2019</year>. <article-title>fMRIPrep: a robust preprocessing pipeline for functional MRI</article-title>. <source>Nat. Methods</source><volume>16</volume> (<issue>1</issue>), <fpage>111</fpage>–<lpage>116</lpage>. doi: <pub-id pub-id-type="doi">10.1038/s41592-018-0235-4</pub-id>.<pub-id pub-id-type="pmid">30532080</pub-id></mixed-citation>
    </ref>
    <ref id="R6">
      <mixed-citation publication-type="journal"><name><surname>Gorgolewski</surname><given-names>K</given-names></name>, <name><surname>Auer</surname><given-names>T</given-names></name>, <name><surname>Calhoun</surname><given-names>V</given-names></name>, <etal/>, <year>2016</year>. <article-title>The brain imaging data structure, a format for organizing and describing outputs of neuroimaging experiments</article-title>. <source>Sci. Data</source><volume>3</volume>, <fpage>160044</fpage>. doi: <pub-id pub-id-type="doi">10.1038/sdata.2016.44</pub-id>.<pub-id pub-id-type="pmid">27326542</pub-id></mixed-citation>
    </ref>
    <ref id="R7">
      <mixed-citation publication-type="journal"><name><surname>Fortin</surname><given-names>JP</given-names></name>, <name><surname>Cullen</surname><given-names>N</given-names></name>, <name><surname>Sheline</surname><given-names>YI</given-names></name>, <name><surname>Taylor</surname><given-names>WD</given-names></name>, <name><surname>Aselcioglu</surname><given-names>I</given-names></name>, <name><surname>Cook</surname><given-names>PA</given-names></name>, <name><surname>Adams</surname><given-names>P</given-names></name>, <name><surname>Cooper</surname><given-names>C</given-names></name>, <name><surname>Fava</surname><given-names>M</given-names></name>, <name><surname>McGrath</surname><given-names>PJ</given-names></name>, <name><surname>McInnis</surname><given-names>M</given-names></name>, <name><surname>Phillips</surname><given-names>ML</given-names></name>, <name><surname>Trivedi</surname><given-names>MH</given-names></name>, <name><surname>Weissman</surname><given-names>MM</given-names></name>, <name><surname>Shinohara</surname><given-names>RT</given-names></name>, <year>2018</year>. <article-title>Harmonization of cortical thickness measurements across scanners and sites</article-title>. <source>Neuroimage</source><volume>167</volume>, <fpage>104</fpage>–<lpage>120</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.neuroimage.2017.11.024</pub-id>, 2018 <month>Feb</month><day>15</day>.<pub-id pub-id-type="pmid">29155184</pub-id></mixed-citation>
    </ref>
    <ref id="R8">
      <mixed-citation publication-type="journal"><name><surname>Gorgolewski</surname><given-names>K</given-names></name>, <etal/>, <year>2017</year>. <article-title>BIDS apps: improving ease of use, accessibility, and reproducibility of neuroimaging data analysis methods</article-title>. <source>PLoS Comput. Biol</source> doi: <pub-id pub-id-type="doi">10.1371/journal.pcbi.1005209</pub-id>.</mixed-citation>
    </ref>
    <ref id="R9">
      <mixed-citation publication-type="journal"><name><surname>Halchenko</surname></name>, <etal/>, <year>2021</year>. <article-title>DataLad: distributed system for joint management of code, data, and their relationship</article-title>. <source>J. Open Source Softw</source><volume>6</volume> (<issue>63</issue>), <fpage>3262</fpage>. doi: <pub-id pub-id-type="doi">10.21105/joss.03262</pub-id>.</mixed-citation>
    </ref>
    <ref id="R10">
      <mixed-citation publication-type="journal"><name><surname>Herrick</surname><given-names>R</given-names></name>, <name><surname>Horton</surname><given-names>W</given-names></name>, <name><surname>Olsen</surname><given-names>T</given-names></name>, <name><surname>McKay</surname><given-names>M</given-names></name>, <name><surname>Archie</surname><given-names>KA</given-names></name>, <name><surname>Marcus</surname><given-names>DS</given-names></name>, <year>2016</year>. <article-title>XNAT central: open sourcing imaging research data</article-title>. <source>Neuroimage</source><volume>124</volume>, <fpage>1093</fpage>–<lpage>1096</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.neuroimage.2015.06.076</pub-id>.<pub-id pub-id-type="pmid">26143202</pub-id></mixed-citation>
    </ref>
    <ref id="R11">
      <mixed-citation publication-type="journal"><name><surname>Kang</surname><given-names>J</given-names></name>, <etal/>, <year>2016</year>. <article-title>Editorial: recent advances and challenges on big data analysis in neuroimaging</article-title>. <source>Front. Neurosci</source> doi: <pub-id pub-id-type="doi">10.3389/fnins.2016.00505</pub-id>.</mixed-citation>
    </ref>
    <ref id="R12">
      <mixed-citation publication-type="journal"><name><surname>Karcher</surname><given-names>NR</given-names></name>, <name><surname>Barch</surname><given-names>DM</given-names></name>, <year>2021</year>. <article-title>The ABCD study: understanding the development of risk for mental and physical health outcomes</article-title>. <source>Neuropsychopharmacology</source><volume>46</volume>, <fpage>131</fpage>–<lpage>142</lpage>. doi: <pub-id pub-id-type="doi">10.1038/s41386-020-0736-6</pub-id>.<pub-id pub-id-type="pmid">32541809</pub-id></mixed-citation>
    </ref>
    <ref id="R13">
      <mixed-citation publication-type="journal"><name><surname>Landis</surname><given-names>D</given-names></name>, <name><surname>Courtney</surname><given-names>W</given-names></name>, <name><surname>Dieringer</surname><given-names>C</given-names></name>, <name><surname>Kelly</surname><given-names>R</given-names></name>, <name><surname>King</surname><given-names>M</given-names></name>, <name><surname>Miller</surname><given-names>B</given-names></name>, <etal/>, <year>2016</year>. <article-title>COINS data exchange: an open platform for compiling, curating, and disseminating neuroimaging data</article-title>. <source>Neuroimage</source><volume>124</volume>, <fpage>1084</fpage>–<lpage>1088</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.neuroimage.2015.05.049</pub-id>.<pub-id pub-id-type="pmid">26019122</pub-id></mixed-citation>
    </ref>
    <ref id="R14">
      <mixed-citation publication-type="journal"><name><surname>Satterthwaite</surname><given-names>T</given-names></name>, <name><surname>Elliott</surname><given-names>M</given-names></name>, <name><surname>Ruparel</surname><given-names>K</given-names></name>, <name><surname>Prabhakaran</surname><given-names>K</given-names></name>, <name><surname>Calkins</surname><given-names>M</given-names></name>, <name><surname>Hopson</surname><given-names>R</given-names></name>, <name><surname>Jackson</surname><given-names>C</given-names></name>, <name><surname>Keefe</surname><given-names>J</given-names></name>, <name><surname>Riley</surname><given-names>M</given-names></name>, <name><surname>Mensh</surname><given-names>Frank</given-names></name>, <name><surname>Sleiman</surname><given-names>Patrick</given-names></name>, <name><surname>Verma</surname><given-names>Ragini</given-names></name>, <name><surname>Davatzikos</surname><given-names>Christos</given-names></name>, <name><surname>Gur</surname><given-names>Ruben</given-names></name>, <name><surname>Gur</surname><given-names>Raquel</given-names></name>., <year>2014</year>. <article-title>Neuroimaging of the philadelphia neurodevelopmental cohort</article-title>. <source>Neuroimage</source><volume>86</volume>. doi: <pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.07.064</pub-id>.</mixed-citation>
    </ref>
    <ref id="R15">
      <mixed-citation publication-type="journal"><name><surname>Van Essen</surname><given-names>DC</given-names></name>, <etal/>, <year>2013</year>. <article-title>The WU-Minn Human Connectome project: an overview</article-title>. <source>Neuroimage</source><volume>80</volume>, <fpage>62</fpage>–<lpage>79</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.05.041</pub-id>, ISSN 1053-8119.<pub-id pub-id-type="pmid">23684880</pub-id></mixed-citation>
    </ref>
    <ref id="R16">
      <mixed-citation publication-type="journal"><name><surname>Yarkoni</surname></name>, <etal/>, <year>2019</year>. <article-title>PyBIDS: python tools for BIDS datasets</article-title>. <source>J. Open Source Softw</source><volume>4</volume> (<issue>40</issue>), <fpage>1294</fpage>. doi: <pub-id pub-id-type="doi">10.21105/Joss.01294</pub-id>.<pub-id pub-id-type="pmid">32775955</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
<floats-group>
  <fig position="float" id="F1">
    <label>Fig. 1.</label>
    <caption>
      <title>CuBIDS workflow.</title>
      <p id="P139">The CuBIDS workflow begins after the generation of NIfTI files and JSON sidecars and ends directly before the execution of pre-processing pipelines. We start with a BIDS dataset, which can be validated using CuBIDS’ robust version of the BIDS-validator. After purging the dataset of any sensitive fields, users can move to the next workflow stage: detecting Parameter Groups. Users can then rename or delete Parameter Groups. At any point in the workflow, users can implement version control to track changes made to the data using an easy-to-use, wrapped version of DataLad. Finally, users test one Exemplar Subject from each Acquisition Group on BIDS Apps to ensure each set of scanning parameters can run through pipelines error-free. CuBIDS includes command line programs for each step of the workflow (see <xref rid="T1" ref-type="table">Table 1</xref>).</p>
    </caption>
    <graphic xlink:href="nihms-1850027-f0001" position="float"/>
  </fig>
  <fig position="float" id="F2">
    <label>Fig 2.</label>
    <caption>
      <title>Stable, scalable BIDS validation.</title>
      <p id="P140">CuBIDS wraps a stable version of the BIDS Validator and adds a few additional features including the ability to reorganize the validator output into an easy to read, tabular structure and save it as a TSV. <bold>A)</bold> The standard BIDS Validator’s default option (<xref rid="R6" ref-type="bibr">Gorgolewski et al., 2016</xref>) validates an entire BIDS dataset and outputs a summary of the errors and warnings it discovers to the terminal screen. <bold>B)</bold> In addition to visualizing the output in a scalable and easy-to-read format, <monospace>cubids-validate</monospace> includes the standard BIDS Validator’s ability to ignore cross-session comparisons or metadata from NIfTI headers while also adding an option for sequential participant-by-participant validation. This feature, which we recommend users leverage, parallelizes validation and validates each subject directory as its own BIDS dataset.</p>
    </caption>
    <graphic xlink:href="nihms-1850027-f0002" position="float"/>
  </fig>
  <fig position="float" id="F3">
    <label>Fig. 3.</label>
    <caption>
      <title>Parsing the dataset by Parameter Group.</title>
      <p id="P141">The <monospace>summary.tsv</monospace> file is a <monospace>cubids-group</monospace> output that contains one row per Parameter Group and one column per scanning parameter. Thus, this TSV summarizes all metadata present within a dataset. <bold>A)</bold> Before <monospace>cubids-apply</monospace> is run, a given Key Group may have multiple Parameter Groups, each containing a different set of scanning parameters. This summary table includes a “Rename Key Group” column that auto-configures when <monospace>cubids-apply</monospace> is run and labels each non-dominant Parameter Group as a Variant Group based on the scanning parameters that differentiate that group from the Dominant Group. Specifically, CuBIDS represents this variance by adding “VARIANT*”—where * indicates the metadata parameters that cause those files to vary from the Dominant Group—to the “acq” field of those files in non-dominant Parameter Groups. For example, in <bold>A)</bold>, the metadata in the Param Group 2 image differs from that of the Dominant Group (Param Group 1) image because that run is missing a fieldmap. The result of running <monospace>cubids-apply</monospace> can be seen in <bold>B)</bold> where the Param Group 2 image ends up in a new Key group because CuBIDS added “VARIANTNoFmap” to the acquisition field of its filename when <monospace>cubids-apply</monospace> was run.</p>
    </caption>
    <graphic xlink:href="nihms-1850027-f0003" position="float"/>
  </fig>
  <fig position="float" id="F4">
    <label>Fig. 4.</label>
    <caption>
      <p id="P142">Version history throughout the curation process.</p>
    </caption>
    <graphic xlink:href="nihms-1850027-f0004" position="float"/>
  </fig>
  <table-wrap position="float" id="T1" orientation="landscape">
    <label>Table 1</label>
    <caption>
      <title>CuBIDS command line interface programs.</title>
      <p id="P143">CuBIDS features several command line interface (CLI) programs that help users curate and process BIDS datasets. We use the color-coded backgrounds to map each program to a stage in the curation workflow seen in <xref rid="F1" ref-type="fig">Fig. 1</xref>. These programs were built for the steps of a study’s curation process. Some programs—such as <monospace>print-metadata-fields, group, validate</monospace>, and <monospace>copy-exemplars</monospace>--require only “read” access to the data and aid the user in visualizing a dataset’s heterogeneity. Others—such as <monospace>apply, purge, undo</monospace>, and <monospace>remove-metadata-fields</monospace>—require "write" access, as they involve modifying metadata, changing filenames, or removing entire subjects altogether.</p>
    </caption>
    <table frame="box" rules="all">
      <colgroup span="1">
        <col align="left" valign="middle" span="1"/>
        <col align="left" valign="middle" span="1"/>
        <col align="left" valign="middle" span="1"/>
        <col align="left" valign="middle" span="1"/>
        <col align="left" valign="middle" span="1"/>
      </colgroup>
      <thead>
        <tr>
          <th align="left" valign="top" rowspan="1" colspan="1">COMMAND</th>
          <th align="left" valign="top" rowspan="1" colspan="1">POSITIONAL ARGUMENTS</th>
          <th align="left" valign="top" rowspan="1" colspan="1">OPTIONAL ARGUMENTS</th>
          <th align="left" valign="top" rowspan="1" colspan="1">OUTPUT FILES</th>
          <th align="left" valign="top" rowspan="1" colspan="1">DESCRIPTION</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1">
            <preformat position="float" xml:space="preserve">cubids-print-metadata-fields</preformat>
          </td>
          <td align="left" valign="top" rowspan="1" colspan="1"><preformat position="float" xml:space="preserve">bids_dir</preformat><break/><break/>the root of a BIDS dataset. It should contain sub-X directories and dataset_description.json</td>
          <td align="left" valign="top" rowspan="1" colspan="1"/>
          <td align="left" valign="top" rowspan="1" colspan="1"/>
          <td align="left" valign="top" rowspan="1" colspan="1">Prints out all sidecar field names present in the dataset</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1">
            <preformat position="float" xml:space="preserve">cubids-remove-metadata-fields</preformat>
          </td>
          <td align="left" valign="top" rowspan="1" colspan="1">
            <preformat position="float" xml:space="preserve">bids_dir</preformat>
          </td>
          <td align="left" valign="top" rowspan="1" colspan="1"><preformat position="float" xml:space="preserve">--fields FIELDS [FIELDS …]</preformat><break/>space-separated list of metadata fields to remove (default: [])</td>
          <td align="left" valign="top" rowspan="1" colspan="1"/>
          <td align="left" valign="top" rowspan="1" colspan="1">Removes a desired list of metadata fields and can be used to delete Patient Health Information (PHI) from datasets</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1">
            <preformat position="float" xml:space="preserve">cubids-add-nifti-info</preformat>
          </td>
          <td align="left" valign="top" rowspan="1" colspan="1">
            <preformat position="float" xml:space="preserve">bids_dir</preformat>
          </td>
          <td align="left" valign="top" rowspan="1" colspan="1"><preformat position="float" xml:space="preserve">--use-datalad</preformat><break/>ensure that there are no untracked changes before finding groups and save dataset after NifTI info is added to sidecars (default: False)<break/><break/><preformat position="float" xml:space="preserve">--force-unlock</preformat><break/>unlock dataset before adding NifTI information (default: False)</td>
          <td align="left" valign="top" rowspan="1" colspan="1"/>
          <td align="left" valign="top" rowspan="1" colspan="1">Adds the following information from the headers of images in NifTI format: Obliquity, NumVolumes, Dim*Size, ImageOrientation, VoxelSizeDim* to its corresponding sidecar</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1">
            <preformat position="float" xml:space="preserve">cubids-validate</preformat>
          </td>
          <td align="left" valign="top" rowspan="1" colspan="1"><preformat position="float" xml:space="preserve">bids_dir</preformat><break/>the root of a BIDS dataset. It should contain sub-X directories and dataset_description.json<break/><break/><preformat position="float" xml:space="preserve">output_prefix</preformat><break/>file prefix to which tabulated output file(s) are written. If users pass in just a filename prefix (e.g. <monospace>V1</monospace>), then CuBIDS will put the four grouping outputs in <monospace>bids_dir/code/CuBIDS</monospace>. If the user a path (e.g. <monospace>/Users/scovitz/BIDS/V1</monospace>), then output files will go to the specified location.</td>
          <td align="left" valign="top" rowspan="1" colspan="1"><preformat position="float" xml:space="preserve">--sequential</preformat><break/>run the BIDS Validator sequentially on each subject (default: False)<break/><break/><preformat position="float" xml:space="preserve">--ignore_nifti_headers</preformat><break/>disregard NlfTI header content during validation (default: False)<break/><break/><preformat position="float" xml:space="preserve">--ignore_subject_consistency</preformat><break/>skip checking that any given file for one subject is present for all other subjects (default: False)<break/><break/><preformat position="float" xml:space="preserve">--sequential-subjects</preformat><break/><preformat position="float" xml:space="preserve">SEQUENTIAL_SUBJECTS</preformat><break/>List: Filter the sequential run to only include the listed subjects, e.g. --sequential-subjects sub-01 sub-02 sub-03 (default: None)</td>
          <td align="left" valign="top" rowspan="1" colspan="1"><preformat position="float" xml:space="preserve">output_prefix_validation.tsTSV</preformat><break/><break/>TSV file with one row per file containing a BIDS validation error. Columns: files, type, severity, description, code, url, subject</td>
          <td align="left" valign="top" rowspan="1" colspan="1">Stable, robust version of the BIDS-validator</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1">
            <preformat position="float" xml:space="preserve">cubids-group</preformat>
          </td>
          <td align="left" valign="top" rowspan="1" colspan="1">
            <preformat position="float" xml:space="preserve">bids_dir</preformat>
            <break/>
            <break/>
            <preformat position="float" xml:space="preserve">output_prefix</preformat>
          </td>
          <td align="left" valign="top" rowspan="1" colspan="1"><preformat position="float" xml:space="preserve">--acq-group-level ACQ GROUP LEVEL</preformat><break/>Levelat which acquisition groups are created options: "subject" or "session" (default: subject)<break/><break/><preformat position="float" xml:space="preserve">--config CONFIG</preformat><break/>path to a config file for grouping (default: None)</td>
          <td align="left" valign="top" rowspan="1" colspan="1">
            <preformat position="float" xml:space="preserve">output_prefix_summary.tsv</preformat>
            <break/>
            <break/>
            <preformat position="float" xml:space="preserve">output_prefix_files.tsv</preformat>
            <break/>
            <break/>
            <preformat position="float" xml:space="preserve">output_prefix_AcqGrouping.tsv</preformat>
            <break/>
            <break/>
            <preformat position="float" xml:space="preserve">output_prefix_AcqGroupInfo.txt</preformat>
          </td>
          <td align="left" valign="top" rowspan="1" colspan="1">Produces four files that display the heterogenelt y present in the dataset in a user-friendly format</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1">
            <preformat position="float" xml:space="preserve">cubids-purge</preformat>
          </td>
          <td align="left" valign="top" rowspan="1" colspan="1"><preformat position="float" xml:space="preserve">bids_dir</preformat><break/>the root of a BIDS dataset. It should contain sub-X directories and dataset_description.json<break/><break/><preformat position="float" xml:space="preserve">scans</preformat><break/>path to the txt file of runs whose associations should be purged</td>
          <td align="left" valign="top" rowspan="1" colspan="1"><preformat position="float" xml:space="preserve">--use-datalad</preformat><break/>save deletions after purge runs (default: False)</td>
          <td align="left" valign="top" rowspan="1" colspan="1"/>
          <td align="left" valign="top" rowspan="1" colspan="1">Takes in a list of NlfTI images and removes them and all their association files and IntendedFor references from the dataset</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1">
            <preformat position="float" xml:space="preserve">cubids-apply</preformat>
          </td>
          <td align="left" valign="top" rowspan="1" colspan="1"><preformat position="float" xml:space="preserve">bids_dir</preformat><break/><break/><preformat position="float" xml:space="preserve">edited_summary_tsv</preformat><break/>the *_summary.csv that has been edited in the Mergelnto and RenameKeyGroup columns.<break/><break/><preformat position="float" xml:space="preserve">files_tsv</preformat><break/>the *_files.csv that the *_summary.csv corresponds to.<break/><break/>**Note: If the edited summary and files tsvs are located at <monospace>bids_dir/code/CuBIDS</monospace>, users may pass just the filename, if not, they mut pass the path to the file.<break/><break/><preformat position="float" xml:space="preserve">output_prefix</preformat><break/>file prefix to which tabulated validator output is written. If users pass in just a filename prefix (e.g. <monospace>V1</monospace>), then CuBIDS will put the four grouping outputs in <monospace>bids_dir/code/CuBIDS</monospace>. If the user a path (e.g. <monospace>/Users/scovitz/BIDS/V1</monospace>), then output files will go to the specified location.</td>
          <td align="left" valign="top" rowspan="1" colspan="1"><preformat position="float" xml:space="preserve">--use-datalad</preformat><break/>save changes applied to the dataset (default: False)<break/><break/><preformat position="float" xml:space="preserve">--acq-group-level</preformat><break/><preformat position="float" xml:space="preserve">ACQ_GROUP_LEVEL</preformat><break/>level at which acquisition groups are created options: "subject" or "session" (default: subject)<break/><break/><preformat position="float" xml:space="preserve">--config CONFIG</preformat><break/>path to a config file for grouping (default: None)</td>
          <td align="left" valign="top" rowspan="1" colspan="1">
            <preformat position="float" xml:space="preserve">output_prefix_summary.tsv</preformat>
            <break/>
            <break/>
            <preformat position="float" xml:space="preserve">output_prefix_files.tsv</preformat>
            <break/>
            <break/>
            <preformat position="float" xml:space="preserve">output_prefix_AcqGrouping.tsv</preformat>
            <break/>
            <break/>
            <preformat position="float" xml:space="preserve">output_prefix_AcqGroupInfo.txt</preformat>
          </td>
          <td align="left" valign="top" rowspan="1" colspan="1">Applies the user’s edits to the *_summary.tsv file to the BIDS dataset</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1">
            <preformat position="float" xml:space="preserve">cubids-copy-exemplars</preformat>
          </td>
          <td align="left" valign="top" rowspan="1" colspan="1"><preformat position="float" xml:space="preserve">bids_dir</preformat><break/>path to the root of a BIDS dataset. It should contain sub-X directories and dataset_description.json<break/><break/><preformat position="float" xml:space="preserve">exemplars_dir</preformat><break/>path to the root of a BIDS dataset containing one subject from each Acquisition Group. It should contain sub-X directories and dataset_description.json<break/><break/><preformat position="float" xml:space="preserve">exemplars_tsv</preformat><break/>path to the .csv file that lists one subject from each Acquisition Group (*_AcqGrouping.csv from the cubids-group output)</td>
          <td align="left" valign="top" rowspan="1" colspan="1"><preformat position="float" xml:space="preserve">--use-datalad</preformat><break/>ensure that there are no untracked changes before finding groups and save exemplar dataset post creation (default: False)<break/><break/><preformat position="float" xml:space="preserve">--min-group-size</preformat><break/><preformat position="float" xml:space="preserve">MIN_GROUP_SIZE</preformat><break/>minimum number of subjects an Acquisition Group must have in order to be included in the exemplar dataset (default: 1)</td>
          <td align="left" valign="top" rowspan="1" colspan="1"/>
          <td align="left" valign="top" rowspan="1" colspan="1">copies one subject from each exemplar group into a separate directory</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1">
            <preformat position="float" xml:space="preserve">cubids-undo</preformat>
          </td>
          <td align="left" valign="top" rowspan="1" colspan="1">
            <preformat position="float" xml:space="preserve">bids_dir</preformat>
          </td>
          <td align="left" valign="top" rowspan="1" colspan="1"/>
          <td align="left" valign="top" rowspan="1" colspan="1"/>
          <td align="left" valign="top" rowspan="1" colspan="1">reverts dataset to its state prior to the most recent saved modifications (only available to users using the DataLad-based version control option)</td>
        </tr>
      </tbody>
    </table>
  </table-wrap>
</floats-group>
