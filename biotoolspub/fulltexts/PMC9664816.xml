<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">BMC Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">BMC Bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>BMC Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1471-2105</issn>
    <publisher>
      <publisher-name>BioMed Central</publisher-name>
      <publisher-loc>London</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">9664816</article-id>
    <article-id pub-id-type="publisher-id">5033</article-id>
    <article-id pub-id-type="doi">10.1186/s12859-022-05033-x</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Research</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>iEnhancer-DCLA: using the original sequence to identify enhancers and their strength based on a deep learning framework</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Liao</surname>
          <given-names>Meng</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Zhao</surname>
          <given-names>Jian-ping</given-names>
        </name>
        <address>
          <email>zhaojianping@126.com</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Tian</surname>
          <given-names>Jing</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Zheng</surname>
          <given-names>Chun-Hou</given-names>
        </name>
        <address>
          <email>zhengch99@126.com</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="GRID">grid.413254.5</institution-id><institution-id institution-id-type="ISNI">0000 0000 9544 7024</institution-id><institution>College of Mathematics and System Sciences, </institution><institution>Xinjiang University, </institution></institution-wrap>Ürümqi, China </aff>
      <aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="GRID">grid.252245.6</institution-id><institution-id institution-id-type="ISNI">0000 0001 0085 4987</institution-id><institution>School of Computer Science and Technology, </institution><institution>Anhui University, </institution></institution-wrap>Hefei, China </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>14</day>
      <month>11</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>14</day>
      <month>11</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2022</year>
    </pub-date>
    <volume>23</volume>
    <elocation-id>480</elocation-id>
    <history>
      <date date-type="received">
        <day>29</day>
        <month>8</month>
        <year>2022</year>
      </date>
      <date date-type="accepted">
        <day>2</day>
        <month>11</month>
        <year>2022</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2022</copyright-statement>
      <license>
        <ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p><bold>Open Access</bold>This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>. The Creative Commons Public Domain Dedication waiver (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/publicdomain/zero/1.0/">http://creativecommons.org/publicdomain/zero/1.0/</ext-link>) applies to the data made available in this article, unless otherwise stated in a credit line to the data.</license-p>
      </license>
    </permissions>
    <abstract id="Abs1">
      <p id="Par1">Enhancers are small regions of DNA that bind to proteins, which enhance the transcription of genes. The enhancer may be located upstream or downstream of the gene. It is not necessarily close to the gene to be acted on, because the entanglement structure of chromatin allows the positions far apart in the sequence to have the opportunity to contact each other. Therefore, identifying enhancers and their strength is a complex and challenging task. In this article, a new prediction method based on deep learning is proposed to identify enhancers and enhancer strength, called iEnhancer-DCLA. Firstly, we use word2vec to convert k-mers into number vectors to construct an input matrix. Secondly, we use convolutional neural network and bidirectional long short-term memory network to extract sequence features, and finally use the attention mechanism to extract relatively important features. In the task of predicting enhancers and their strengths, this method has improved to a certain extent in most evaluation indexes. In summary, we believe that this method provides new ideas in the analysis of enhancers.</p>
      <sec>
        <title>Supplementary Information</title>
        <p>The online version contains supplementary material available at 10.1186/s12859-022-05033-x.</p>
      </sec>
    </abstract>
    <kwd-group xml:lang="en">
      <title>Keywords</title>
      <kwd>Enhancer</kwd>
      <kwd>Word embedding</kwd>
      <kwd>k-mers</kwd>
      <kwd>Convolutional neural network</kwd>
      <kwd>Bidirectional long short-term memory network</kwd>
      <kwd>Attention mechanism</kwd>
    </kwd-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution>the open fund of Information Materials and Intelligent Sensing Laboratory of Anhui Province</institution>
        </funding-source>
        <award-id>IMIS202105</award-id>
        <award-id>IMIS202105</award-id>
        <award-id>IMIS202105</award-id>
        <principal-award-recipient>
          <name>
            <surname>Zhao</surname>
            <given-names>Jian-ping</given-names>
          </name>
          <name>
            <surname>Tian</surname>
            <given-names>Jing</given-names>
          </name>
          <name>
            <surname>Zheng</surname>
            <given-names>Chun-Hou</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
    </funding-group>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>© The Author(s) 2022</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="Sec1" sec-type="introduction">
    <title>Introduction</title>
    <p id="Par2">Gene enhancers are non-coding segments of DNA that play a central role in regulating transcriptional processes that control development, cell identity, and evolution [<xref ref-type="bibr" rid="CR1">1</xref>]. Recently, a large number of enhancers of humans and other species (both eukaryotes and prokaryotes) have been recognized [<xref ref-type="bibr" rid="CR2">2</xref>]. The number of enhancers in mammals ranges from 50,000 to 100,000. Most enhancers are located in intron region and intergenic region, and a few are located in exon region [<xref ref-type="bibr" rid="CR3">3</xref>]. The enhancer contains a variety of genetic marker sites, the most common is the transcription factor binding site. Enhancers regulate gene expression by interacting with their target gene promoters. This interaction may be in cis or in trans. Cis action refers to the enhancer and its action site genes on the same chromosome, while trans action refers to the enhancer and its action site genes on different chromosomes [<xref ref-type="bibr" rid="CR4">4</xref>]. On average, each promoter interacts with 4.9 enhancers [<xref ref-type="bibr" rid="CR5">5</xref>]. Super-enhancers (SEs) are large clusters of transcriptionally active enhancers, often located near cell-specific functional genes. Although super enhancers have been widely used in many studies, there is no clear definition [<xref ref-type="bibr" rid="CR6">6</xref>]. In addition, many human diseases have been shown to be affected by genetic variations in enhancers [<xref ref-type="bibr" rid="CR7">7</xref>], such as various cancers [<xref ref-type="bibr" rid="CR8">8</xref>] and inflammatory bowel disease [<xref ref-type="bibr" rid="CR9">9</xref>]. Therefore, the identification of enhancers and the prediction of their action sites have always been a hot topic in related fields.</p>
    <p id="Par3">One of the basic problems of enhancer research is enhancer prediction. In order to find the properties and functions of enhancers, it is necessary to identify the locations of enhancers on the genome. For a long time in the past, the prediction of enhancers has relied on biological experimental techniques. For example, Conservative analysis was performed using sequence conserved data and transcription factor binding site data to predict enhancers. [<xref ref-type="bibr" rid="CR10">10</xref>–<xref ref-type="bibr" rid="CR12">12</xref>]. And using DNase I hypersensitivity sites sequencing data to identify enhancers based on chromatin accessibility [<xref ref-type="bibr" rid="CR13">13</xref>]. However, these methods result in a high false-positive rate because the data contain sequences of other regulatory elements that are not enhancers binding to transcription factors. In addition, the method of predicting enhancers using ChIP-seq data of transcription factors and ChIP-seq data of transcription coactivator P300 has been widely used [<xref ref-type="bibr" rid="CR14">14</xref>–<xref ref-type="bibr" rid="CR16">16</xref>], but it is not effective to distinguish strong enhancers from weak enhancers. Prediction based on eRNA data is another approach [<xref ref-type="bibr" rid="CR17">17</xref>–<xref ref-type="bibr" rid="CR19">19</xref>]. The enhancer transcribes eRNA, which is detected by sequencing technology and mapped back to the original genome to obtain the location information of the enhancer. The disadvantages are that a large sample size is required, and all methods for determining the location of enhancers based on eRNA data cannot be used to predict unexpressed enhancers.</p>
    <p id="Par4">Biological experiments are time-consuming and costly. With the rapid development of machine learning and deep learning, many prediction models have been built to identify enhancers and their strength. iEnhancer-2 L is the first predictive model that can identify not only intensifiers but also their strength [<xref ref-type="bibr" rid="CR20">20</xref>]. iEnhancer − 2 L uses pseudo k-tuple nucleotide composition (PseKNC) as the encoding method of sequence characteristics. EhancerPred uses bi-Bayes and pseudo-nucleotide composition as feature extraction method [<xref ref-type="bibr" rid="CR21">21</xref>]. iEnhancer-EL is an upgraded version of iEnhancer-2 L [<xref ref-type="bibr" rid="CR22">22</xref>]. Its two stages consist of 16 key individual classifiers, all of which are selected from 171 basic classifiers formed based on subsequence profile, kmer and PseKNC. The above three machine learning models are based on support vector machines (SVM) to construct classifiers. iEnhancer -ECNN uses one-hot encoding and k-mers to process the data, and uses CNN to construct the ensemble model [<xref ref-type="bibr" rid="CR23">23</xref>]. But one-hot encoding is vulnerable to the problem of dimensionality disaster and ignores the correlation information between k-mer words. iEnhancer -XG combines five features (k-spectrum profile, mismatch k-tuple, subsequence profile, position-specific scoring matrix) and constructs a two-layer predictor using “XGBoost” as the basic classifier [<xref ref-type="bibr" rid="CR24">24</xref>]. iEnhancer-EBLSTM uses 3-mer to encode the input DNA sequences and then predicts enhancers by bidirectional LSTM [<xref ref-type="bibr" rid="CR25">25</xref>]. These methods can identify and classify enhancers and their strength. But the accuracy of layers 1 and 2 predictors needs to be improved further, and it should be possible to develop better models using the new deep learning framework.</p>
    <p id="Par5">In this study, we propose a new deep learning prediction framework called iEnhancer-DCLA. In the first stage of the model, enhancers are identified. In the second stage, we classified enhancers’ strength. The main idea of the model is to combine word embedding and k-mers to encode sequence data, and then use CNN, Bi-LSTM and attention mechanism to extract features and classify them. Meanwhile, we use SHapley Additive explanation [<xref ref-type="bibr" rid="CR26">26</xref>] algorithm to explain the influence of the features extracted from the model. The experimental results in the independent test dataset show that this method has better performance than some existing methods. The source codes and data are freely at <ext-link ext-link-type="uri" xlink:href="https://github.com/WamesM/iEnhancer-DCLA">https://github.com/WamesM/iEnhancer-DCLA</ext-link>.</p>
  </sec>
  <sec id="Sec2" sec-type="materials|methods">
    <title>Materials and methods</title>
    <sec id="Sec3">
      <title>Benchmark dataset</title>
      <p id="Par6">The benchmark dataset used in this article is divided into two parts: the training dataset and the independent test dataset. The dataset used in our experiment was obtained from the study of Liu et al. [<xref ref-type="bibr" rid="CR20">20</xref>]. In order to facilitate a fair comparison with previous studies, this dataset has also been used to classify enhancers in later studies, such as in the development of EnhancerPred [<xref ref-type="bibr" rid="CR21">21</xref>], iEnhancer-EL [<xref ref-type="bibr" rid="CR22">22</xref>], iEnhancer- ECNN [<xref ref-type="bibr" rid="CR23">23</xref>], and iEnhancer- XG [<xref ref-type="bibr" rid="CR24">24</xref>]. In this dataset, enhancer sequences of 9 different cell lines were collected, from which a 200 bp fragment of the same length was extracted. The CDHIT [<xref ref-type="bibr" rid="CR27">27</xref>] software was then used to exclude paired sequences with sequence similarity greater than 20%. The training dataset included 1484 enhancer sequence samples (742 strong enhancers and 742 weak enhancers) and 1484 non-enhancer sequence samples. To evaluate the generalization performance of our model, the independent test dataset is set up. The independent test dataset includes 200 enhancer sequence samples (100 strong enhancers and 100 weak enhancers) and 200 non-enhancer sequence samples.</p>
    </sec>
    <sec id="Sec4">
      <title>Sequence representation</title>
      <p id="Par7">In many deep learning algorithms for processing biological sequences, the method of using natural language processing technology to extract features from the original DNA sequence is widely used [<xref ref-type="bibr" rid="CR28">28</xref>–<xref ref-type="bibr" rid="CR30">30</xref>]. K-mer analysis is an effective method in DNA sequence analysis. K-mer splits a sequence into substrings of k bases. When the step size is 1, the DNA sequence with length l is divided into (l − k + 1) k-mers. For example, when we set k = 7, the sequence ‘ACGTCGACG’ is split into three 7-mers: ‘ACGTCGA’, ‘CGTCGAC’, and ‘GTCGACG’. This makes the sequence easier to calculate and understand. We treat the entire DNA sequence as a sentence, and the k-mer fragments as words. We derive the distributed representation matrix by connecting the dna2vec [<xref ref-type="bibr" rid="CR31">31</xref>] method. Dna2vec is based on the popular word embedding model word2vec [<xref ref-type="bibr" rid="CR32">32</xref>]. In our model, dna2vec was pretrained with hg38 human components chr1 to chr22, and then adapted to our predictive task using our datasets. Finally, each k-mer word is represented as a 100-dimensional vector. In this experiment, we set k to 7 and converted each 200 bp enhancer sequences into a (194,100) matrix.</p>
    </sec>
    <sec id="Sec5">
      <title>Model architecture</title>
      <p id="Par8">We propose a two-stage deep learning prediction model using DNA sequences of enhancers for classification. The first stage is to identify enhancers. The second stage is to identify the strength of enhancers. In fact, the first stage has the same network structure as the second stage. The only difference between the two stages is the dataset used. During the training in the first stage, all data are used as training dataset and are classified as enhancers and non-enhancers. In the second stage, only the enhancers are used in the experiment and are classified as strong enhancers and weak enhancers. The workflow of the model is shown in Fig. <xref rid="Fig1" ref-type="fig">1</xref>. The model consists of five modules, including sequence words embedding input, convolutional neural network extracting sequence features, bidirectional long short-term memory network extracting sequence long-term dependence information, attention mechanism extracting relatively more important features, and predicting output.<fig id="Fig1"><label>Fig. 1</label><caption><p>Model structure. It includes feature representation based on dna2vec method, two convolutional layers, two pooling layers, bidirectional long short-term memory network layer, attention layer and finally two fully connected layers</p></caption><graphic xlink:href="12859_2022_5033_Fig1_HTML" id="MO1"/></fig></p>
      <sec id="Sec6">
        <title>Convolutional neural network (CNN)</title>
        <p id="Par9">CNN is a kind of Feedforward Neural Networks with deep structure and convolution computation, which is one of the representative algorithms of deep learning [<xref ref-type="bibr" rid="CR33">33</xref>, <xref ref-type="bibr" rid="CR34">34</xref>]. Our convolution module consists of one-dimensional convolution layer, rectified linear layer (ReLU) [<xref ref-type="bibr" rid="CR35">35</xref>], batch normalization layer and max pooling layer. In order to avoid overfitting, a dropout layer [<xref ref-type="bibr" rid="CR36">36</xref>] with a dropout rate of 0.2 was used in the middle. In the first convolutional layer, the number of convolutional kernels is set to 256, the size of the convolutional kernels is set to 8, the stride is set to 1, and the length of max pooling layer is set to 2. In the second convolutional layer, the number of convolutional kernels is set to 128, the size of the convolutional kernels is set to 8, the stride is set to 1, and the length of max pooling layer is set to 2.</p>
      </sec>
      <sec id="Sec7">
        <title>Bidirectional long short-term memory network (LSTM)</title>
        <p id="Par10">LSTM is a special type of recurrent neural network that can learn long-term dependency information. On many issues, LSTM has achieved great success and been widely used, such as DeepD2V [<xref ref-type="bibr" rid="CR37">37</xref>]. Because DNA sequences are double-stranded, we use Bi-LSTM to capture the long-term dependence of the sequence. Bi-LSTM layer is composed of forward and reverse parts to learn features. The calculation formula is as follows:<disp-formula id="Equ1"><label>1</label><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${f_t}=\sigma \left( {{W_f}{x_t}+{U_f}{h_{t - 1}}+{b_f}} \right)$$\end{document}</tex-math><mml:math id="M2" display="block"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>σ</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mi>f</mml:mi></mml:msub><mml:msub><mml:mi>x</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>U</mml:mi><mml:mi>f</mml:mi></mml:msub><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mi>f</mml:mi></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:math><graphic xlink:href="12859_2022_5033_Article_Equ1.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ2"><label>2</label><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${i_t}=\sigma \left( {{W_i}{x_t}+{U_i}{h_{t - 1}}+{b_i}} \right)$$\end{document}</tex-math><mml:math id="M4" display="block"><mml:mrow><mml:msub><mml:mi>i</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>σ</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mi>x</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>U</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:math><graphic xlink:href="12859_2022_5033_Article_Equ2.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ3"><label>3</label><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\widetilde {{{C_t}}}=\tanh \left( {{W_C}{x_t}+{U_C}{h_{t - 1}}+{b_C}} \right)$$\end{document}</tex-math><mml:math id="M6" display="block"><mml:mrow><mml:mover accent="true"><mml:msub><mml:mi>C</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mo>tanh</mml:mo><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mi>C</mml:mi></mml:msub><mml:msub><mml:mi>x</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>U</mml:mi><mml:mi>C</mml:mi></mml:msub><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mi>C</mml:mi></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:math><graphic xlink:href="12859_2022_5033_Article_Equ3.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ4"><label>4</label><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${C_t}={f_t} \odot {C_{t - 1}}+{i_t} \odot \widetilde {{{C_t}}}$$\end{document}</tex-math><mml:math id="M8" display="block"><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>⊙</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>i</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>⊙</mml:mo><mml:mover accent="true"><mml:msub><mml:mi>C</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow></mml:math><graphic xlink:href="12859_2022_5033_Article_Equ4.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ5"><label>5</label><alternatives><tex-math id="M9">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${o_t}=\sigma \left( {{W_o}{x_t}+{U_o}{h_{t - 1}}+{b_o}} \right)$$\end{document}</tex-math><mml:math id="M10" display="block"><mml:mrow><mml:msub><mml:mi>o</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>σ</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mi>o</mml:mi></mml:msub><mml:msub><mml:mi>x</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>U</mml:mi><mml:mi>o</mml:mi></mml:msub><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mi>o</mml:mi></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:math><graphic xlink:href="12859_2022_5033_Article_Equ5.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ6"><label>6</label><alternatives><tex-math id="M11">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${h_t}={o_t} \odot \tanh \left( {{C_t}} \right)$$\end{document}</tex-math><mml:math id="M12" display="block"><mml:mrow><mml:msub><mml:mi>h</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>o</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>⊙</mml:mo><mml:mo>tanh</mml:mo><mml:mfenced close=")" open="("><mml:msub><mml:mi>C</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:math><graphic xlink:href="12859_2022_5033_Article_Equ6.gif" position="anchor"/></alternatives></disp-formula></p>
        <p id="Par11">The Eq. (<xref rid="Equ1" ref-type="">1</xref>) represents the forgetting gate to decide which information should be discarded or retained. The Eqs. (<xref rid="Equ2" ref-type="">2</xref>) and (<xref rid="Equ3" ref-type="">3</xref>) represent the input gate, which is used to decide which information to update and create a new candidate value vector. The Eq. (<xref rid="Equ4" ref-type="">4</xref>) is used to calculate the current cell state. The Eq. (<xref rid="Equ5" ref-type="">5</xref>) represents the output gate, which is used to calculate the value of the next hidden state. Where <inline-formula id="IEq1"><alternatives><tex-math id="M13">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${W}_{f}$$\end{document}</tex-math><mml:math id="M14"><mml:msub><mml:mi>W</mml:mi><mml:mi>f</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5033_Article_IEq1.gif"/></alternatives></inline-formula>, <inline-formula id="IEq2"><alternatives><tex-math id="M15">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${W}_{i}$$\end{document}</tex-math><mml:math id="M16"><mml:msub><mml:mi>W</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5033_Article_IEq2.gif"/></alternatives></inline-formula>, <inline-formula id="IEq3"><alternatives><tex-math id="M17">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${W}_{C}$$\end{document}</tex-math><mml:math id="M18"><mml:msub><mml:mi>W</mml:mi><mml:mi>C</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5033_Article_IEq3.gif"/></alternatives></inline-formula>, <inline-formula id="IEq4"><alternatives><tex-math id="M19">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${W}_{o}$$\end{document}</tex-math><mml:math id="M20"><mml:msub><mml:mi>W</mml:mi><mml:mi>o</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5033_Article_IEq4.gif"/></alternatives></inline-formula>, <inline-formula id="IEq5"><alternatives><tex-math id="M21">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${U}_{f}$$\end{document}</tex-math><mml:math id="M22"><mml:msub><mml:mi>U</mml:mi><mml:mi>f</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5033_Article_IEq5.gif"/></alternatives></inline-formula>, <inline-formula id="IEq6"><alternatives><tex-math id="M23">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${U}_{i}$$\end{document}</tex-math><mml:math id="M24"><mml:msub><mml:mi>U</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5033_Article_IEq6.gif"/></alternatives></inline-formula>, <inline-formula id="IEq7"><alternatives><tex-math id="M25">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${U}_{C}$$\end{document}</tex-math><mml:math id="M26"><mml:msub><mml:mi>U</mml:mi><mml:mi>C</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5033_Article_IEq7.gif"/></alternatives></inline-formula>, <inline-formula id="IEq8"><alternatives><tex-math id="M27">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${U}_{o}$$\end{document}</tex-math><mml:math id="M28"><mml:msub><mml:mi>U</mml:mi><mml:mi>o</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5033_Article_IEq8.gif"/></alternatives></inline-formula> are weights, and <inline-formula id="IEq9"><alternatives><tex-math id="M29">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${b}_{f}$$\end{document}</tex-math><mml:math id="M30"><mml:msub><mml:mi>b</mml:mi><mml:mi>f</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5033_Article_IEq9.gif"/></alternatives></inline-formula>, <inline-formula id="IEq10"><alternatives><tex-math id="M31">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${b}_{i}$$\end{document}</tex-math><mml:math id="M32"><mml:msub><mml:mi>b</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5033_Article_IEq10.gif"/></alternatives></inline-formula>, <inline-formula id="IEq11"><alternatives><tex-math id="M33">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${b}_{C}$$\end{document}</tex-math><mml:math id="M34"><mml:msub><mml:mi>b</mml:mi><mml:mi>C</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5033_Article_IEq11.gif"/></alternatives></inline-formula>, and <inline-formula id="IEq12"><alternatives><tex-math id="M35">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${b}_{o}$$\end{document}</tex-math><mml:math id="M36"><mml:msub><mml:mi>b</mml:mi><mml:mi>o</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5033_Article_IEq12.gif"/></alternatives></inline-formula> are biases. We set the number of neurons into the Bi-LSTM layer to 64.</p>
      </sec>
      <sec id="Sec8">
        <title>Attention</title>
        <p id="Par12">In the field of Artificial Intelligence (AI), attention mechanism has become an important part of neural network structure. It has a large number of applications in natural language processing, statistical learning, speech and computer [<xref ref-type="bibr" rid="CR38">38</xref>, <xref ref-type="bibr" rid="CR39">39</xref>]. The core of the attention mechanism is to introduce attention weight to the features learned in the previous layer and assign different weight to each feature to learn the relatively more important features.<disp-formula id="Equ7"><label>7</label><alternatives><tex-math id="M37">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${u_i}=\tanh \left( {{W_s}{h_i}+{b_s}} \right)$$\end{document}</tex-math><mml:math id="M38" display="block"><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mo>tanh</mml:mo><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:msub><mml:mi>h</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:math><graphic xlink:href="12859_2022_5033_Article_Equ7.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ8"><label>8</label><alternatives><tex-math id="M39">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\alpha _i}=\frac{{\exp \left( {u_{i}^{T}{u_s}} \right)}}{{\sum\nolimits_{{i=1}}^{L} {\exp \left( {u_{i}^{T}{u_s}} \right)} }}$$\end{document}</tex-math><mml:math id="M40" display="block"><mml:mrow><mml:msub><mml:mi>α</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mo>exp</mml:mo><mml:mfenced close=")" open="("><mml:mrow><mml:msubsup><mml:mi>u</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mi>T</mml:mi></mml:msubsup><mml:msub><mml:mi>u</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow><mml:mi>L</mml:mi></mml:msubsup><mml:mrow><mml:mo>exp</mml:mo><mml:mfenced close=")" open="("><mml:mrow><mml:msubsup><mml:mi>u</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mi>T</mml:mi></mml:msubsup><mml:msub><mml:mi>u</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:math><graphic xlink:href="12859_2022_5033_Article_Equ8.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ9"><label>9</label><alternatives><tex-math id="M41">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$A=\sum\nolimits_{{i=1}}^{L} {{\alpha _i} * {h_i}}$$\end{document}</tex-math><mml:math id="M42" display="block"><mml:mrow><mml:mi>A</mml:mi><mml:mo>=</mml:mo><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow><mml:mi>L</mml:mi></mml:msubsup><mml:mrow><mml:msub><mml:mi>α</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow/><mml:mo>∗</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math><graphic xlink:href="12859_2022_5033_Article_Equ9.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq13"><alternatives><tex-math id="M43">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${W}_{s}$$\end{document}</tex-math><mml:math id="M44"><mml:msub><mml:mi>W</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5033_Article_IEq13.gif"/></alternatives></inline-formula>, <inline-formula id="IEq14"><alternatives><tex-math id="M45">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${b}_{s}$$\end{document}</tex-math><mml:math id="M46"><mml:msub><mml:mi>b</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5033_Article_IEq14.gif"/></alternatives></inline-formula> and <inline-formula id="IEq15"><alternatives><tex-math id="M47">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${u}_{s}$$\end{document}</tex-math><mml:math id="M48"><mml:msub><mml:mi>u</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5033_Article_IEq15.gif"/></alternatives></inline-formula> are the variables that need to be learned; <inline-formula id="IEq16"><alternatives><tex-math id="M49">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\alpha }_{i}$$\end{document}</tex-math><mml:math id="M50"><mml:msub><mml:mi>α</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5033_Article_IEq16.gif"/></alternatives></inline-formula>obtained through calculation represents the importance of <inline-formula id="IEq17"><alternatives><tex-math id="M51">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${h}_{i}$$\end{document}</tex-math><mml:math id="M52"><mml:msub><mml:mi>h</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5033_Article_IEq17.gif"/></alternatives></inline-formula>; <inline-formula id="IEq18"><alternatives><tex-math id="M53">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${h}_{i}$$\end{document}</tex-math><mml:math id="M54"><mml:msub><mml:mi>h</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5033_Article_IEq18.gif"/></alternatives></inline-formula> is the output of bi-LSTM layer at the i time; A represents the feature vector after finally passing through the attention mechanism layer. We set up 64 output units in the attention layer.</p>
        <p id="Par13">Finally, the model is connected to two fully connected layers for prediction, and the sigmoid activation function is used to calculate the probability of classification into a certain category. Dimension changes of iEnhaner-DCLA under each module in Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Fig. S1.</p>
      </sec>
    </sec>
    <sec id="Sec9">
      <title>Evaluation parameters</title>
      <p id="Par14">In order to evaluate the performance of the model objectively and comprehensively, we use the following metrics to evaluate the predictive performance of the model: (1) Accuracy (ACC), (2) Sensitivity (Sn), (3) Specificity (Sp), (4) Matthews correlation coefficient (MCC), (5) Area Under the ROC Curve (AUC), (6) Area Under the Precision Recall Curve (AUPR), (7) F1-score. The formula of evaluation index is as follows:<disp-formula id="Equ10"><label>10</label><alternatives><tex-math id="M55">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ACC=\frac{{TP+TN}}{{TP+TN+FP+FN}}$$\end{document}</tex-math><mml:math id="M56" display="block"><mml:mrow><mml:mi>A</mml:mi><mml:mi>C</mml:mi><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>T</mml:mi><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math><graphic xlink:href="12859_2022_5033_Article_Equ10.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ11"><label>11</label><alternatives><tex-math id="M57">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Sn=\frac{{TP}}{{TP+FN}}$$\end{document}</tex-math><mml:math id="M58" display="block"><mml:mrow><mml:mi>S</mml:mi><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">TP</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math><graphic xlink:href="12859_2022_5033_Article_Equ11.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ12"><label>12</label><alternatives><tex-math id="M59">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Sp=\frac{{TN}}{{TN+FP}}$$\end{document}</tex-math><mml:math id="M60" display="block"><mml:mrow><mml:mi>S</mml:mi><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">TN</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math><graphic xlink:href="12859_2022_5033_Article_Equ12.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ13"><label>13</label><alternatives><tex-math id="M61">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$MCC=\frac{{TP \times TN - FP \times FN}}{{\sqrt {\left( {TP+FP} \right)\left( {TP+FN} \right)\left( {TN+FP} \right)+\left( {TN+FN} \right)} }}$$\end{document}</tex-math><mml:math id="M62" display="block"><mml:mrow><mml:mi>M</mml:mi><mml:mi>C</mml:mi><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>×</mml:mo><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mo>-</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi><mml:mo>×</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow><mml:msqrt><mml:mrow><mml:mfenced close=")" open="("><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:mfenced><mml:mfenced close=")" open="("><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mfenced><mml:mfenced close=")" open="("><mml:mrow><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:mfenced close=")" open="("><mml:mrow><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msqrt></mml:mfrac></mml:mrow></mml:math><graphic xlink:href="12859_2022_5033_Article_Equ13.gif" position="anchor"/></alternatives></disp-formula>where TP, FP, TN and FN represent true positive, false positive, true negative and false negative values respectively.</p>
    </sec>
  </sec>
  <sec id="Sec10">
    <title>Results and discussions</title>
    <sec id="Sec11">
      <title>Analysis of DNA sequences</title>
      <p id="Par15">In recent years, nucleotide compositions of DNA sequences have been widely used to identify functional elements [<xref ref-type="bibr" rid="CR40">40</xref>, <xref ref-type="bibr" rid="CR41">41</xref>]. In order to display the distribution of nucleotide of enhancer sequence intuitively. Figure <xref rid="Fig2" ref-type="fig">2</xref> shows the difference in nucleotide compositions between enhancers and non-enhancers and between strong enhancers and weak enhancers, respectively. As shown in Fig. <xref rid="Fig2" ref-type="fig">2</xref>A, the four bases are distributed evenly in the sequence of the enhancers, while non-enhancers accumulate adenine (A) and thymine (T). Non-enhancers contain more than 30% adenine and thymine, and less than 20% cytosine(C) and guanine(G). As shown in Fig. <xref rid="Fig2" ref-type="fig">2</xref>B, the strong enhancers are rich in more C, G than A, T, while the weak enhancers have the opposite trend, rich in more A, T. These results indicate that there are differences in nucleotide compositions between enhancers and non-enhancers, and between strong enhancers and weak enhancers, which helps us build models to distinguish them.<fig id="Fig2"><label>Fig. 2</label><caption><p><bold>A</bold> Nucleotide compositions of enhancers and non-enhancers. <bold>B</bold> Nucleotide compositions of strong and weak enhancers</p></caption><graphic xlink:href="12859_2022_5033_Fig2_HTML" id="MO2"/></fig></p>
    </sec>
    <sec id="Sec12">
      <title>Parameter optimization</title>
      <p id="Par16">We set the upper limit of the training period as 90 epochs, and monitored the change of accuracy on the validation set during training. When the accuracy on the validation set reached a relatively high value and stopped improving in the following 20 Epochs, the training was terminated, and the weight with the highest accuracy on the validation set was saved as the test. Table <xref rid="Tab1" ref-type="table">1</xref> shows the parameter selection we set in the experiment.<table-wrap id="Tab1"><label>Table 1</label><caption><p>Hyper-parameters optimization</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Hyper-Parameters</th><th align="left">Range</th><th align="left">Recommendation</th></tr></thead><tbody><tr><td align="left">Convolutional layer number</td><td align="left">[1, 2, 3, 4]</td><td align="left">2</td></tr><tr><td align="left">Convolutional neurons number</td><td align="left">[16, 32, 64, 128, 256]</td><td align="left">128,256</td></tr><tr><td align="left">Convolutional kernel size</td><td align="left">[3, 6, 8, 16, 20, 30]</td><td align="left">8</td></tr><tr><td align="left">Max Pooling layer size</td><td align="left">[2, 4, 6, 8]</td><td align="left">2</td></tr><tr><td align="left">Dropout rates</td><td align="left">[0.1, 0.2, 0.3, 0.5]</td><td align="left">0.2</td></tr><tr><td align="left">Number of neurons in Bi-LSTM</td><td align="left">[16, 32, 50, 64]</td><td align="left">64</td></tr><tr><td align="left">Optimizer</td><td align="left">[SGD, Adam]</td><td align="left">Adam</td></tr><tr><td align="left">Learning rate</td><td align="left">[2e−6, 5e−6, 8e−6, 2e−5]</td><td align="left">5e−6, 2e−6</td></tr><tr><td align="left">Batch Size</td><td align="left">[16, 32, 64, 128]</td><td align="left">32</td></tr></tbody></table></table-wrap></p>
      <p id="Par17">In sequence representation, the model is based on k-mer method to embed words by connecting DNA2vec. In previous studies, different k values were selected for different model frames [<xref ref-type="bibr" rid="CR42">42</xref>]. In order to test the effect of different values of k-mers, we conducted numerical experiments with k ranging from 3 to 8. As shown in Table <xref rid="Tab2" ref-type="table">2</xref>, when k is 7, the model has better performance in general.<table-wrap id="Tab2"><label>Table 2</label><caption><p>The results of iEnhancer-DCLA with different values of k-mers on two layers</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Stages</th><th align="left">k-mers</th><th align="left">Acc (%)</th><th align="left">Sn (%)</th><th align="left">Sp (%)</th><th align="left">MCC</th></tr></thead><tbody><tr><td align="left" rowspan="6">First layer</td><td char="." align="char">3</td><td char="." align="char">76.00</td><td char="." align="char">73.00</td><td char="." align="char"><bold>79.00</bold></td><td char="." align="char">0.5209</td></tr><tr><td char="." align="char">4</td><td char="." align="char">75.25</td><td char="." align="char">80.50</td><td char="." align="char">70.00</td><td char="." align="char">0.5078</td></tr><tr><td char="." align="char">5</td><td char="." align="char">76.25</td><td char="." align="char">77.50</td><td char="." align="char">75.00</td><td char="." align="char">0.5252</td></tr><tr><td char="." align="char">6</td><td char="." align="char">74.50</td><td char="." align="char"><bold>83.50</bold></td><td char="." align="char">65.50</td><td char="." align="char">0.4981</td></tr><tr><td char="." align="char">7</td><td char="." align="char"><bold>78.25</bold></td><td char="." align="char">78.00</td><td char="." align="char">78.50</td><td char="." align="char"><bold>0.5650</bold></td></tr><tr><td char="." align="char">8</td><td char="." align="char">75.75</td><td char="." align="char">71.00</td><td char="." align="char">80.50</td><td char="." align="char">0.5173</td></tr><tr><td align="left" rowspan="6">Second layer</td><td char="." align="char">3</td><td char="." align="char">69.50</td><td char="." align="char">81.00</td><td char="." align="char">58.00</td><td char="." align="char">0.4007</td></tr><tr><td char="." align="char">4</td><td char="." align="char">73.00</td><td char="." align="char"><bold>96.00</bold></td><td char="." align="char">50.00</td><td char="." align="char">0.5181</td></tr><tr><td char="." align="char">5</td><td char="." align="char">76.50</td><td char="." align="char">95.00</td><td char="." align="char">58.00</td><td char="." align="char"><bold>0.5705</bold></td></tr><tr><td char="." align="char">6</td><td char="." align="char">76.00</td><td char="." align="char">85.00</td><td char="." align="char">67.00</td><td char="." align="char">0.5286</td></tr><tr><td char="." align="char">7</td><td char="." align="char"><bold>78.00</bold></td><td char="." align="char">87.00</td><td char="." align="char"><bold>69.00</bold></td><td char="." align="char">0.5693</td></tr><tr><td char="." align="char">8</td><td char="." align="char">74.00</td><td char="." align="char">92.00</td><td char="." align="char">56.00</td><td char="." align="char">0.5145</td></tr></tbody></table><table-wrap-foot><p>The highest value achieved on each metric is marked in bold</p></table-wrap-foot></table-wrap></p>
    </sec>
    <sec id="Sec13">
      <title>The effect of different encoding methods</title>
      <p id="Par18">In the past process of DNA sequence processing, one-hot coding has been widely used in various models [<xref ref-type="bibr" rid="CR23">23</xref>]. One-hot encoding is to encode four bases into four binary numbers, corresponding to each nucleotide has three values set as 0, the other sets as 1. However, if one-hot encoding is carried out for each word, the dimension of the vocabulary will be very large and there will be great sparsity, which will increase the calculation cost. In this paper, we compare the performance of word embedding encoding and one-hot encoding. As shown in Table <xref rid="Tab3" ref-type="table">3</xref>, dna2vec performs better than one-hot encoding at both layers. In Fig. <xref rid="Fig3" ref-type="fig">3</xref>, we compare the AUC, AUPR and F1 score of the two encoding methods, it shows that dna2vec has a better performance than one-hot encoding in most of the evaluation indicators for the identification of enhancers and their strength.<table-wrap id="Tab3"><label>Table 3</label><caption><p> A comparison of two layers using two different encoding schemes</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Stages</th><th align="left">Encoding</th><th align="left">Acc(%)</th><th align="left">Sn(%)</th><th align="left">Sp(%)</th><th align="left">MCC</th></tr></thead><tbody><tr><td align="left" rowspan="2">First layer</td><td align="left">One-hot</td><td char="." align="char">75.00</td><td char="." align="char">71.00</td><td char="." align="char"><bold>79.00</bold></td><td char="." align="char">0.5016</td></tr><tr><td align="left">Dna2vec</td><td char="." align="char"><bold>78.25</bold></td><td char="." align="char"><bold>78.00</bold></td><td char="." align="char">78.50</td><td char="." align="char"><bold>0.5650</bold></td></tr><tr><td align="left" rowspan="2">Second layer</td><td align="left">One-hot</td><td char="." align="char">72.50</td><td char="." align="char">87.00</td><td char="." align="char">58.00</td><td char="." align="char">0.4702</td></tr><tr><td align="left">Dna2vec</td><td char="." align="char"><bold>78.00</bold></td><td char="." align="char"><bold>87.00</bold></td><td char="." align="char"><bold>69.00</bold></td><td char="." align="char"><bold>0.5693</bold></td></tr></tbody></table><table-wrap-foot><p>The highest value achieved on each metric is marked in bold</p></table-wrap-foot></table-wrap><fig id="Fig3"><label>Fig. 3</label><caption><p> A Comparison of AUC, AUPR and F1 scores at two layers using different encoding schemes</p></caption><graphic xlink:href="12859_2022_5033_Fig3_HTML" id="MO3"/></fig></p>
    </sec>
    <sec id="Sec14">
      <title>Discussion on effects of each module of the model</title>
      <p id="Par19">We also discuss the influence of each module of A on the classification effect. In order to select the best model, we constructed four deep learning models, including CNN, BiLSTM, CNN combined with BiLSTM, CNN combined with BiLSTM and attention mechanism. Tables <xref rid="Tab4" ref-type="table">4</xref> and <xref rid="Tab5" ref-type="table">5</xref> list the classification performance of the different models. CNN-BiLSTM-Attention achieves the best performance in two stages. In addition, the experiments also show that the higher-order features selected after the attention mechanism are beneficial to improve the prediction ability of the model.</p>
      <p id="Par20">Recurrent neural network is a kind of recursive neural network which takes sequence data as input and carries on recursion in the evolution direction of sequence and all nodes are linked by chain. Gate Recurrent Unit (GRU) is a Recurrent Neural Network (RNN). Compared with LSTM, there are only two gates in GRU model: update gate and reset gate. Simple RNN has no long-term memory, GRU and LSTM can avoid the problem of gradient disappearance. We compare the performance of CNN + RNN, CNN + GRU and CNN + LSTM for the long - term dependence information of extracted sequence. As shown in Fig. <xref rid="Fig4" ref-type="fig">4</xref>, CNN + LSTM brings better predictive performance to the model at both stages. We believe that CNN + LSTM solves the problems of gradient disappearance and gradient explosion in the training process of long sequences and can perform better in long sequences.<table-wrap id="Tab4"><label>Table 4</label><caption><p>Performance comparison of various deep learning models on identifying enhancers</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Stages</th><th align="left">Model</th><th align="left">Acc(%)</th><th align="left">Sn(%)</th><th align="left">Sp(%)</th><th align="left">MCC</th></tr></thead><tbody><tr><td align="left" rowspan="4">First layer</td><td align="left">CNN</td><td char="." align="char">75.00</td><td char="." align="char">79.00</td><td char="." align="char">71.00</td><td char="." align="char">0.5016</td></tr><tr><td align="left">BiLSTM</td><td char="." align="char">74.00</td><td char="." align="char">82.50</td><td char="." align="char">65.50</td><td char="." align="char">0.4871</td></tr><tr><td align="left">CNN-BiLSTM</td><td char="." align="char">76.75</td><td char="." align="char">78.00</td><td char="." align="char">75.50</td><td char="." align="char">0.5352</td></tr><tr><td align="left">CNN-BiLSTM-Attention</td><td char="." align="char">78.25</td><td char="." align="char">78.00</td><td char="." align="char">78.50</td><td char="." align="char">0.5650</td></tr></tbody></table></table-wrap><table-wrap id="Tab5"><label>Table 5</label><caption><p>Performance comparison of various deep learning models on identifying enhancers strength</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Stages</th><th align="left">Model</th><th align="left">Acc(%)</th><th align="left">Sn(%)</th><th align="left">Sp(%)</th><th align="left">MCC</th></tr></thead><tbody><tr><td align="left" rowspan="4">First layer</td><td align="left">CNN</td><td char="." align="char">70.50</td><td char="." align="char">92.00</td><td char="." align="char">49.00</td><td char="." align="char">0.4541</td></tr><tr><td align="left">BiLSTM</td><td char="." align="char">73.00</td><td char="." align="char">89.00</td><td char="." align="char">57.00</td><td char="." align="char">0.4855</td></tr><tr><td align="left">CNN-BiLSTM</td><td char="." align="char">75.50</td><td char="." align="char">92.00</td><td char="." align="char">59.00</td><td char="." align="char">0.4855</td></tr><tr><td align="left">CNN-BiLSTM-Attention</td><td char="." align="char">78.00</td><td char="." align="char">87.00</td><td char="." align="char">69.00</td><td char="." align="char">0.5693</td></tr></tbody></table></table-wrap><fig id="Fig4"><label>Fig. 4</label><caption><p> A Comparison of the influence of three different sequence correlation information extraction structures on our model (Bi-RNN, Bi-GRU, Bi-LSTM).</p></caption><graphic xlink:href="12859_2022_5033_Fig4_HTML" id="MO4"/></fig></p>
    </sec>
    <sec id="Sec15">
      <title>Model interpretation</title>
      <p id="Par21">Many models established by deep learning methods lack interpretability. For us, the model is like a black box, and we only need to design the network structure and relevant parameters to get the results. In recent years, the interpretability of models has gradually become an important research direction of machine learning and deep learning. For example, the ‘SHAP’ method proposed in 2017 can be used to explain various models [<xref ref-type="bibr" rid="CR26">26</xref>]. We use the SHAP method to explain the interaction between features and the eventual impact of each feature on model classification. We use UMAP [<xref ref-type="bibr" rid="CR43">43</xref>] dimensionality reduction visualization technology to map the embedding layer and attention mechanism layer of iEnhancer-DCLA into two-dimensional space for feature representation in Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Fig. S2. After passing through the attention mechanism layer, the data has an obvious tendency to cluster into two categories, which can be considered that the model has extracted effective sequence features. We pass the model through the feature vector behind the attention layer to the SHAP method. The Fig. <xref rid="Fig5" ref-type="fig">5</xref> shows the sum and average shapley values of all features of all samples, which can reflect the importance of features. It can be seen that the extracted feature 13 has the most significant influence on the final effect of the model. To understand how a single feature affects the output of the model, feature 13 is compared with other sample features. As shown in Fig. <xref rid="Fig6" ref-type="fig">6</xref>, red represents feature 27 with a higher shapley value and blue represents a lower value. When feature 13 has a smaller shapley value, feature 27 has a higher value, and when feature 13 has a higher value, feature 27 brings a lower shapley value. The feature coloring of feature 13 shows that it has a negative correlation with feature 27.<fig id="Fig5"><label>Fig. 5</label><caption><p>The 20 most influential features of iEnhancer-DCLA.</p></caption><graphic xlink:href="12859_2022_5033_Fig5_HTML" id="MO5"/></fig><fig id="Fig6"><label>Fig. 6</label><caption><p>The interaction between features obtained by iEnhancer-DCLA at the attention layer</p></caption><graphic xlink:href="12859_2022_5033_Fig6_HTML" id="MO6"/></fig></p>
    </sec>
    <sec id="Sec16">
      <title>Model evaluation</title>
      <p id="Par22">In this paper, we adopt 5-fold cross-validation to select the best weight. We randomly divided the training dataset into five equal but disjoint subsets. In each fold, we used one of them as the validation set and four as the training set. This process is repeated until all subsets have been validated once. Tables <xref rid="Tab6" ref-type="table">6</xref> and <xref rid="Tab7" ref-type="table">7</xref> show the results of 5-fold cross-validation on the benchmark data set at two stages, respectively, to test the learning efficiency and stability of the model. Overall, according to four different evaluation metrics for evaluation, the performance of iEnhancer-DCLA remains consistent across 5-folds.<table-wrap id="Tab6"><label>Table 6</label><caption><p>The cross-validation results achieved by the iEnhancer-DCLA on identifying enhancers</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Stages</th><th align="left">Tra : Val (4:1)</th><th align="left">Acc(%)</th><th align="left">Sn(%)</th><th align="left">Sp(%)</th><th align="left">MCC</th></tr></thead><tbody><tr><td align="left" rowspan="6">First layer</td><td align="left">1</td><td char="." align="char">86.83</td><td char="." align="char">88.34</td><td char="." align="char">85.31</td><td char="." align="char">0.7369</td></tr><tr><td align="left">2</td><td char="." align="char">84.54</td><td char="." align="char">84.57</td><td char="." align="char">84.50</td><td char="." align="char">0.6907</td></tr><tr><td align="left">3</td><td char="." align="char">81.91</td><td char="." align="char">85.11</td><td char="." align="char">78.71</td><td char="." align="char">0.6395</td></tr><tr><td align="left">4</td><td char="." align="char">80.73</td><td char="." align="char">81.06</td><td char="." align="char">80.39</td><td char="." align="char">0.6146</td></tr><tr><td align="left">5</td><td char="." align="char">82.61</td><td char="." align="char">81.81</td><td char="." align="char">83.42</td><td char="." align="char">0.6524</td></tr><tr><td align="left">Mean</td><td char="." align="char">83.32</td><td char="." align="char">84.18</td><td char="." align="char">82.45</td><td char="." align="char">0.6668</td></tr></tbody></table></table-wrap><table-wrap id="Tab7"><label>Table 7</label><caption><p>The cross-validation results achieved by the iEnhancer-DCLA on identifying enhancers strength</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Stages</th><th align="left">Tra : Val (4:1)</th><th align="left">Acc(%)</th><th align="left">Sn(%)</th><th align="left">Sp(%)</th><th align="left">MCC</th></tr></thead><tbody><tr><td align="left" rowspan="6">Second layer</td><td align="left">1</td><td char="." align="char">84.16</td><td char="." align="char">86.39</td><td char="." align="char">81.94</td><td char="." align="char">0.6840</td></tr><tr><td align="left">2</td><td char="." align="char">83.36</td><td char="." align="char">92.86</td><td char="." align="char">73.85</td><td char="." align="char">0.6795</td></tr><tr><td align="left">3</td><td char="." align="char">82.35</td><td char="." align="char">83.96</td><td char="." align="char">80.73</td><td char="." align="char">0.6472</td></tr><tr><td align="left">4</td><td char="." align="char">83.09</td><td char="." align="char">87.06</td><td char="." align="char">79.11</td><td char="." align="char">0.6638</td></tr><tr><td align="left">5</td><td char="." align="char">83.56</td><td char="." align="char">96.09</td><td char="." align="char">71.02</td><td char="." align="char">0.6933</td></tr><tr><td align="left">Mean</td><td char="." align="char">83.30</td><td char="." align="char">89.27</td><td char="." align="char">77.33</td><td char="." align="char">0.6736</td></tr></tbody></table></table-wrap></p>
    </sec>
    <sec id="Sec17">
      <title>Performance comparison with existing methods</title>
      <p id="Par23">
The identification of enhancers and their strength is a complex and important problem. Generally speaking, training different datasets will get different prediction results. In order to objectively evaluate the prediction performance of our model, we select the same evaluation indicators. These methods and our method use the same dataset training and independent test dataset testing. As shown in Table <xref rid="Tab8" ref-type="table">8</xref>, in the first layer of the independent test dataset, our model is slightly lower than iEnhancer-ECNN in the thousandths of Sn, but superior to other methods. Sp is only lower than that of iEnhancer-EBLSTM, which is better than other models. iEnhancer -DCLA is better than other models in ACC, and MCC. In the second layer of the independent test dataset, our method is only below iEnhancer-2 L in Sp. There is a certain deviation between Sn and Sp in our model. In practical application, we prefer to confirm that they are real enhancers, so a higher Sn is acceptable. In the other three evaluation parameters, ACC and Sn values of our model increased by more than 10% and 6% respectively, and MCC increased by more than 0.2. We also retrieved the AUC values of some models for comparison. The AUC values of iEnhancer-2 L, EnhancerPred and iEnhancer-EL were 0.8062, 0.8013 and 0.8173 in the first layer, respectively. As shown in Fig. <xref rid="Fig7" ref-type="fig">7</xref>A, the AUC value of our model is 0.8269, which is superior to the above model. In the second layer, the AUC values of the above models for comparison are 0.6678, 0.5790, 0.6801 respectively. As shown in Fig.<xref rid="Fig7" ref-type="fig">7</xref>B, the AUC value of iEnhancer-DCLA was 0.8226, an increase of 0.14. In summary, our proposed the iEnhancer-DCLA shows the best performance in most evaluation parameters, and can learn the features of enhancer sequences well and make good predictions.<table-wrap id="Tab8"><label>Table 8</label><caption><p>Identifying enhancers (First layer) and their strengths (Second layer) in the independent test datasets compared to other existing methods</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Stages</th><th align="left">Method</th><th align="left">Acc(%)</th><th align="left">Sn(%)</th><th align="left">Sp(%)</th><th align="left">MCC</th></tr></thead><tbody><tr><td align="left" rowspan="7">First layer</td><td align="left">iEnhancer-2L</td><td char="." align="char">73.00</td><td char="." align="char">75.00</td><td char="." align="char">71.00</td><td char="." align="char">0.4604</td></tr><tr><td align="left">EnhancerPred</td><td char="." align="char">74.00</td><td char="." align="char">73.50</td><td char="." align="char">74.50</td><td char="." align="char">0.4800</td></tr><tr><td align="left">iEnhancer-EL</td><td char="." align="char">74.75</td><td char="." align="char">71.00</td><td char="." align="char">78.50</td><td char="." align="char">0.4964</td></tr><tr><td align="left">iEnhancer-ECNN</td><td char="." align="char">76.90</td><td char="." align="char"><bold>78.50</bold></td><td char="." align="char">75.20</td><td char="." align="char">0.5370</td></tr><tr><td align="left">iEnhancer-XG</td><td char="." align="char">75.75</td><td char="." align="char">74.00</td><td char="." align="char">77.50</td><td char="." align="char">0.5150</td></tr><tr><td align="left">iEnhancer-EBLSTM</td><td char="." align="char">77.20</td><td char="." align="char">75.50</td><td char="." align="char"><bold>79.50</bold></td><td char="." align="char">0.5340</td></tr><tr><td align="left">iEnhancer-DCLA</td><td char="." align="char"><bold>78.25</bold></td><td char="." align="char">78.00</td><td char="." align="char">78.50</td><td char="." align="char"><bold>0.5650</bold></td></tr><tr><td align="left" rowspan="7">Second layer</td><td align="left">iEnhancer-2L</td><td char="." align="char">60.50</td><td char="." align="char">47.00</td><td char="." align="char"><bold>74.00</bold></td><td char="." align="char">0.2181</td></tr><tr><td align="left">EnhancerPred</td><td char="." align="char">55.00</td><td char="." align="char">45.00</td><td char="." align="char">65.00</td><td char="." align="char">0.1021</td></tr><tr><td align="left">iEnhancer-EL</td><td char="." align="char">61.00</td><td char="." align="char">54.00</td><td char="." align="char">68.00</td><td char="." align="char">0.2222</td></tr><tr><td align="left">iEnhancer-ECNN</td><td char="." align="char">67.80</td><td char="." align="char">79.10</td><td char="." align="char">56.40</td><td char="." align="char">0.3680</td></tr><tr><td align="left">iEnhancer-XG</td><td char="." align="char">63.50</td><td char="." align="char">70.00</td><td char="." align="char">57.00</td><td char="." align="char">0.2720</td></tr><tr><td align="left">iEnhancer-EBLSTM</td><td char="." align="char">65.80</td><td char="." align="char">81.20</td><td char="." align="char">53.60</td><td char="." align="char">0.3240</td></tr><tr><td align="left">iEnhancer-DCLA</td><td char="." align="char"><bold>78.00</bold></td><td char="." align="char"><bold>87.00</bold></td><td char="." align="char">69.00</td><td char="." align="char"><bold>0.5693</bold></td></tr></tbody></table><table-wrap-foot><p>The highest value achieved on each metric is marked in bold</p></table-wrap-foot></table-wrap><fig id="Fig7"><label>Fig. 7</label><caption><p>The ROC curve for classifying in the independent test datasets: <bold>A</bold> Layer 1: (Identify Enhancers) <bold>B</bold> Layer 2: (Identify Enhancers’ Strength)</p></caption><graphic xlink:href="12859_2022_5033_Fig7_HTML" id="MO7"/></fig></p>
    </sec>
  </sec>
  <sec id="Sec18">
    <title>Conclusion</title>
    <p id="Par24">Enhancers are DNA sequences that increase promoter activity and thus gene transcription frequency. Identification of enhancers and their strength is of great significance for drug development and synthetic biology. In this study, we developed a new deep learning model called iEnhancer-DCLA. This model firstly combines word embedding and k-mer analysis as sequence encoding methods, and then uses CNN, Bi-LSTM and attention mechanism to extract features and complete classification tasks. We use cross-validation to select the best weights for testing. The experimental results show that word embedding can express DNA sequences well, and the proposed model performs better than other existing advanced models using the same benchmark dataset in identifying enhancers and predicting their strength. In addition, in order to further improve the prediction effect of the model, our subsequent work is mainly focused on exploring sequence coding schemes, feature extraction methods and data augmentation.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Information</title>
    <sec id="Sec19">
      <p>
        <supplementary-material content-type="local-data" id="MOESM1">
          <media xlink:href="12859_2022_5033_MOESM1_ESM.docx">
            <caption>
              <p><bold>Additional file 1: Fig. S1.</bold> Dimension changes of iEnhaner-DCLA under eachmodule. <bold>Fig. S2.</bold> Two-dimensional feature representation ofenhancers and non-enhancers’ data before and after model training.</p>
            </caption>
          </media>
        </supplementary-material>
      </p>
    </sec>
  </sec>
</body>
<back>
  <fn-group>
    <fn>
      <p>
        <bold>Publisher’s Note</bold>
      </p>
      <p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
    </fn>
  </fn-group>
  <ack>
    <title>Acknowledgements</title>
    <p>This work supported by the grant of National Key R&amp;D Program of China (No.2021YFE0102100.), and supported by grants from the National Natural Science Foundation of China (Nos. U19A2064, 61873001).</p>
  </ack>
  <notes notes-type="author-contribution">
    <title>Authors’ contributions</title>
    <p>LM contributions are built a deep learning model to predict the enhancers and their strength and numerical experiments. ZJP contribution lies in the embellishment of the article. ZCH contribution lies in the thought guidance of the method. All authors read and approved the final manuscript.</p>
  </notes>
  <notes notes-type="funding-information">
    <title>Funding</title>
    <p>Not applicable.</p>
  </notes>
  <notes notes-type="data-availability">
    <title>Availability of data materials</title>
    <p>All the raw data are available at <ext-link ext-link-type="uri" xlink:href="http://bioinformatics.hitsz.edu.cn/iEnhancer-2L/">http://bioinformatics.hitsz.edu.cn/iEnhancer-2 L/</ext-link> (Liu et al.,2015), and all code scripts used are available at <ext-link ext-link-type="uri" xlink:href="https://github.com/WamesM/i">https://github.com/WamesM/i</ext-link>.</p>
    <p>Enhancer-DCLA.</p>
  </notes>
  <notes>
    <title>Declarations</title>
    <notes id="FPar1">
      <title>Ethics approval and consent to participate</title>
      <p id="Par25">Not applicable.</p>
    </notes>
    <notes id="FPar2">
      <title>Consent for publication</title>
      <p id="Par26">Not applicable.</p>
    </notes>
    <notes id="FPar3" notes-type="COI-statement">
      <title>Competing interests</title>
      <p id="Par27">The authors declare that they have no competing interest.</p>
    </notes>
  </notes>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <label>1.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Corradin</surname>
            <given-names>O</given-names>
          </name>
          <name>
            <surname>Scacheri</surname>
            <given-names>PC</given-names>
          </name>
        </person-group>
        <article-title>Enhancer variants: evaluating functions in common disease</article-title>
        <source>Genome Med</source>
        <year>2014</year>
        <volume>6</volume>
        <issue>10</issue>
        <fpage>85</fpage>
        <pub-id pub-id-type="doi">10.1186/s13073-014-0085-3</pub-id>
        <?supplied-pmid 25473424?>
        <pub-id pub-id-type="pmid">25473424</pub-id>
      </element-citation>
    </ref>
    <ref id="CR2">
      <label>2.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kulaeva</surname>
            <given-names>OI</given-names>
          </name>
          <name>
            <surname>Nizovtseva</surname>
            <given-names>EV</given-names>
          </name>
          <name>
            <surname>Polikanov</surname>
            <given-names>YS</given-names>
          </name>
          <name>
            <surname>Ulianov</surname>
            <given-names>SV</given-names>
          </name>
          <name>
            <surname>Studitsky</surname>
            <given-names>VM</given-names>
          </name>
        </person-group>
        <article-title>Distant activation of transcription: mechanisms of enhancer action</article-title>
        <source>Mol Cell Biol</source>
        <year>2012</year>
        <volume>32</volume>
        <issue>24</issue>
        <fpage>4892</fpage>
        <lpage>7</lpage>
        <pub-id pub-id-type="doi">10.1128/MCB.01127-12</pub-id>
        <?supplied-pmid 23045397?>
        <pub-id pub-id-type="pmid">23045397</pub-id>
      </element-citation>
    </ref>
    <ref id="CR3">
      <label>3.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Birnbaum</surname>
            <given-names>RY</given-names>
          </name>
          <name>
            <surname>Clowney</surname>
            <given-names>EJ</given-names>
          </name>
          <name>
            <surname>Agamy</surname>
            <given-names>O</given-names>
          </name>
          <name>
            <surname>Kim</surname>
            <given-names>MJ</given-names>
          </name>
          <name>
            <surname>Zhao</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Yamanaka</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Pappalardo</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Clarke</surname>
            <given-names>SL</given-names>
          </name>
          <name>
            <surname>Wenger</surname>
            <given-names>AM</given-names>
          </name>
          <name>
            <surname>Nguyen</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Gurrieri</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Everman</surname>
            <given-names>DB</given-names>
          </name>
          <name>
            <surname>Schwartz</surname>
            <given-names>CE</given-names>
          </name>
          <name>
            <surname>Birk</surname>
            <given-names>OS</given-names>
          </name>
          <name>
            <surname>Bejerano</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Lomvardas</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Ahituv</surname>
            <given-names>N</given-names>
          </name>
        </person-group>
        <article-title>Coding exons function as tissue-specific enhancers of nearby genes</article-title>
        <source>Genome Res</source>
        <year>2012</year>
        <volume>22</volume>
        <issue>6</issue>
        <fpage>1059</fpage>
        <lpage>68</lpage>
        <pub-id pub-id-type="doi">10.1101/gr.133546.111</pub-id>
        <?supplied-pmid 22442009?>
        <pub-id pub-id-type="pmid">22442009</pub-id>
      </element-citation>
    </ref>
    <ref id="CR4">
      <label>4.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Sasaki-Iwaoka</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Maruyama</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Endoh</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Komori</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Kato</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Kawashima</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <article-title>A trans-acting enhancer modulates estrogen-mediated transcription of reporter genes in osteoblasts</article-title>
        <source>J Bone Miner Res</source>
        <year>1999</year>
        <volume>14</volume>
        <issue>2</issue>
        <fpage>248</fpage>
        <lpage>55</lpage>
        <pub-id pub-id-type="doi">10.1359/jbmr.1999.14.2.24</pub-id>
        <?supplied-pmid 9933479?>
        <pub-id pub-id-type="pmid">9933479</pub-id>
      </element-citation>
    </ref>
    <ref id="CR5">
      <label>5.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Carleton</surname>
            <given-names>JB</given-names>
          </name>
          <name>
            <surname>Berrett</surname>
            <given-names>KC</given-names>
          </name>
          <name>
            <surname>Gertz</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Dissection of enhancer function using multiplex CRISPR-based enhancer interference in cell lines</article-title>
        <source>J Vis Exp</source>
        <year>2018</year>
        <pub-id pub-id-type="doi">10.3791/57883</pub-id>
        <?supplied-pmid 29912188?>
        <pub-id pub-id-type="pmid">29912188</pub-id>
      </element-citation>
    </ref>
    <ref id="CR6">
      <label>6.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Pott</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Lieb</surname>
            <given-names>JD</given-names>
          </name>
        </person-group>
        <article-title>What are super-enhancers?</article-title>
        <source>Nat Genet</source>
        <year>2015</year>
        <volume>47</volume>
        <issue>1</issue>
        <fpage>8</fpage>
        <lpage>12</lpage>
        <pub-id pub-id-type="doi">10.1038/ng.3167</pub-id>
        <?supplied-pmid 25547603?>
        <pub-id pub-id-type="pmid">25547603</pub-id>
      </element-citation>
    </ref>
    <ref id="CR7">
      <label>7.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhang</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Shi</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Zhu</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Lan</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Xu</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Yuan</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Liao</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Xiao</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>X</given-names>
          </name>
        </person-group>
        <article-title>DiseaseEnhancer: a resource of human disease-associated enhancer catalog</article-title>
        <source>Nucleic Acids Res</source>
        <year>2018</year>
        <volume>46</volume>
        <issue>D1</issue>
        <fpage>D78</fpage>
        <lpage>84</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkx920</pub-id>
        <?supplied-pmid 29059320?>
        <pub-id pub-id-type="pmid">29059320</pub-id>
      </element-citation>
    </ref>
    <ref id="CR8">
      <label>8.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Herz</surname>
            <given-names>HM</given-names>
          </name>
        </person-group>
        <article-title>Enhancer deregulation in cancer and other diseases</article-title>
        <source>BioEssays</source>
        <year>2016</year>
        <volume>38</volume>
        <issue>10</issue>
        <fpage>1003</fpage>
        <lpage>15</lpage>
        <pub-id pub-id-type="doi">10.1002/bies.201600106</pub-id>
        <?supplied-pmid 27570183?>
        <pub-id pub-id-type="pmid">27570183</pub-id>
      </element-citation>
    </ref>
    <ref id="CR9">
      <label>9.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Boyd</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Thodberg</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Vitezic</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Bornholdt</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Vitting-Seerup</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Coskun</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Lo</surname>
            <given-names>BZS</given-names>
          </name>
          <name>
            <surname>Klausen</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Jan Schweiger</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Pedersen</surname>
            <given-names>AG</given-names>
          </name>
          <name>
            <surname>Rapin</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Skovgaard</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Dahlgaard</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Andersson</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Terkelsen</surname>
            <given-names>TB</given-names>
          </name>
          <name>
            <surname>Lilje</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Troelsen</surname>
            <given-names>JT</given-names>
          </name>
          <name>
            <surname>Petersen</surname>
            <given-names>AM</given-names>
          </name>
          <name>
            <surname>Jensen</surname>
            <given-names>KB</given-names>
          </name>
          <name>
            <surname>Gögenur</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Thielsen</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Seidelin</surname>
            <given-names>JB</given-names>
          </name>
          <name>
            <surname>Nielsen</surname>
            <given-names>OH</given-names>
          </name>
          <name>
            <surname>Bjerrum</surname>
            <given-names>JT</given-names>
          </name>
          <name>
            <surname>Sandelin</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Characterization of the enhancer and promoter landscape of inflammatory bowel disease from human colon biopsies</article-title>
        <source>Nat Commun</source>
        <year>2018</year>
        <volume>9</volume>
        <issue>1</issue>
        <fpage>1661</fpage>
        <pub-id pub-id-type="doi">10.1038/s41467-018-03766-z</pub-id>
        <?supplied-pmid 29695774?>
        <pub-id pub-id-type="pmid">29695774</pub-id>
      </element-citation>
    </ref>
    <ref id="CR10">
      <label>10.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Woolfe</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Goodson</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Goode</surname>
            <given-names>DK</given-names>
          </name>
          <name>
            <surname>Snell</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>McEwen</surname>
            <given-names>GK</given-names>
          </name>
          <name>
            <surname>Vavouri</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Smith</surname>
            <given-names>SF</given-names>
          </name>
          <name>
            <surname>North</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Callaway</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Kelly</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Walter</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Abnizova</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Gilks</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Edwards</surname>
            <given-names>YJ</given-names>
          </name>
          <name>
            <surname>Cooke</surname>
            <given-names>JE</given-names>
          </name>
          <name>
            <surname>Elgar</surname>
            <given-names>G</given-names>
          </name>
        </person-group>
        <article-title>Highly conserved non-coding sequences are associated with vertebrate development</article-title>
        <source>PLoS Biol</source>
        <year>2005</year>
        <volume>3</volume>
        <issue>1</issue>
        <fpage>e7</fpage>
        <pub-id pub-id-type="doi">10.1371/journal.pbio.0030007</pub-id>
        <?supplied-pmid 15630479?>
        <pub-id pub-id-type="pmid">15630479</pub-id>
      </element-citation>
    </ref>
    <ref id="CR11">
      <label>11.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Pennacchio</surname>
            <given-names>LA</given-names>
          </name>
          <name>
            <surname>Ahituv</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Moses</surname>
            <given-names>AM</given-names>
          </name>
          <name>
            <surname>Prabhakar</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Nobrega</surname>
            <given-names>MA</given-names>
          </name>
          <name>
            <surname>Shoukry</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Minovitsky</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Dubchak</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Holt</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Lewis</surname>
            <given-names>KD</given-names>
          </name>
          <name>
            <surname>Plajzer-Frick</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Akiyama</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>De Val</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Afzal</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Black</surname>
            <given-names>BL</given-names>
          </name>
          <name>
            <surname>Couronne</surname>
            <given-names>O</given-names>
          </name>
          <name>
            <surname>Eisen</surname>
            <given-names>MB</given-names>
          </name>
          <name>
            <surname>Visel</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Rubin</surname>
            <given-names>EM</given-names>
          </name>
        </person-group>
        <article-title>In vivo enhancer analysis of human conserved non-coding sequences</article-title>
        <source>Nature</source>
        <year>2006</year>
        <volume>444</volume>
        <issue>7118</issue>
        <fpage>499</fpage>
        <lpage>502</lpage>
        <pub-id pub-id-type="doi">10.1038/nature05295</pub-id>
        <?supplied-pmid 17086198?>
        <pub-id pub-id-type="pmid">17086198</pub-id>
      </element-citation>
    </ref>
    <ref id="CR12">
      <label>12.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wasserman</surname>
            <given-names>WW</given-names>
          </name>
          <name>
            <surname>Fickett</surname>
            <given-names>JW</given-names>
          </name>
        </person-group>
        <article-title>Identification of regulatory regions which confer muscle-specific gene expression</article-title>
        <source>J Mol Biol</source>
        <year>1998</year>
        <volume>278</volume>
        <issue>1</issue>
        <fpage>167</fpage>
        <lpage>81</lpage>
        <pub-id pub-id-type="doi">10.1006/jmbi.1998.1700</pub-id>
        <?supplied-pmid 9571041?>
        <pub-id pub-id-type="pmid">9571041</pub-id>
      </element-citation>
    </ref>
    <ref id="CR13">
      <label>13.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Dorschner</surname>
            <given-names>MO</given-names>
          </name>
          <name>
            <surname>Hawrylycz</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Humbert</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Wallace</surname>
            <given-names>JC</given-names>
          </name>
          <name>
            <surname>Shafer</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Kawamoto</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Mack</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Hall</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Goldy</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Sabo</surname>
            <given-names>PJ</given-names>
          </name>
          <name>
            <surname>Kohli</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>Q</given-names>
          </name>
          <name>
            <surname>McArthur</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Stamatoyannopoulos</surname>
            <given-names>JA</given-names>
          </name>
        </person-group>
        <article-title>High-throughput localization of functional elements by quantitative chromatin profiling</article-title>
        <source>Nat Methods</source>
        <year>2004</year>
        <volume>1</volume>
        <issue>3</issue>
        <fpage>219</fpage>
        <lpage>25</lpage>
        <pub-id pub-id-type="doi">10.1038/nmeth721</pub-id>
        <?supplied-pmid 15782197?>
        <pub-id pub-id-type="pmid">15782197</pub-id>
      </element-citation>
    </ref>
    <ref id="CR14">
      <label>14.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Xu</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Yuan</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Fang</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Huss</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Vega</surname>
            <given-names>VB</given-names>
          </name>
          <name>
            <surname>Wong</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Orlov</surname>
            <given-names>YL</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Jiang</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Loh</surname>
            <given-names>YH</given-names>
          </name>
          <name>
            <surname>Yeo</surname>
            <given-names>HC</given-names>
          </name>
          <name>
            <surname>Yeo</surname>
            <given-names>ZX</given-names>
          </name>
          <name>
            <surname>Narang</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Govindarajan</surname>
            <given-names>KR</given-names>
          </name>
          <name>
            <surname>Leong</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Shahab</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Ruan</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Bourque</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Sung</surname>
            <given-names>WK</given-names>
          </name>
          <name>
            <surname>Clarke</surname>
            <given-names>ND</given-names>
          </name>
          <name>
            <surname>Wei</surname>
            <given-names>CL</given-names>
          </name>
          <name>
            <surname>Ng</surname>
            <given-names>HH</given-names>
          </name>
        </person-group>
        <article-title>Integration of external signaling pathways with the core transcriptional network in embryonic stem cells</article-title>
        <source>Cell</source>
        <year>2008</year>
        <volume>133</volume>
        <issue>6</issue>
        <fpage>1106</fpage>
        <lpage>17</lpage>
        <pub-id pub-id-type="doi">10.1016/j.cell.2008.04.043</pub-id>
        <?supplied-pmid 18555785?>
        <pub-id pub-id-type="pmid">18555785</pub-id>
      </element-citation>
    </ref>
    <ref id="CR15">
      <label>15.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Visel</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Blow</surname>
            <given-names>MJ</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Akiyama</surname>
            <given-names>JA</given-names>
          </name>
          <name>
            <surname>Holt</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Plajzer-Frick</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Shoukry</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Wright</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Afzal</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Ren</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Rubin</surname>
            <given-names>EM</given-names>
          </name>
          <name>
            <surname>Pennacchio</surname>
            <given-names>LA</given-names>
          </name>
        </person-group>
        <article-title>ChIP-seq accurately predicts tissue-specific activity of enhancers</article-title>
        <source>Nature</source>
        <year>2009</year>
        <volume>457</volume>
        <issue>7231</issue>
        <fpage>854</fpage>
        <lpage>8</lpage>
        <pub-id pub-id-type="doi">10.1038/nature07730</pub-id>
        <?supplied-pmid 19212405?>
        <pub-id pub-id-type="pmid">19212405</pub-id>
      </element-citation>
    </ref>
    <ref id="CR16">
      <label>16.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>May</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Blow</surname>
            <given-names>MJ</given-names>
          </name>
          <name>
            <surname>Kaplan</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>McCulley</surname>
            <given-names>DJ</given-names>
          </name>
          <name>
            <surname>Jensen</surname>
            <given-names>BC</given-names>
          </name>
          <name>
            <surname>Akiyama</surname>
            <given-names>JA</given-names>
          </name>
          <name>
            <surname>Holt</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Plajzer-Frick</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Shoukry</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Wright</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Afzal</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Simpson</surname>
            <given-names>PC</given-names>
          </name>
          <name>
            <surname>Rubin</surname>
            <given-names>EM</given-names>
          </name>
          <name>
            <surname>Black</surname>
            <given-names>BL</given-names>
          </name>
          <name>
            <surname>Bristow</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Pennacchio</surname>
            <given-names>LA</given-names>
          </name>
          <name>
            <surname>Visel</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Large-scale discovery of enhancers from human heart tissue</article-title>
        <source>Nat Genet</source>
        <year>2011</year>
        <volume>44</volume>
        <issue>1</issue>
        <fpage>89</fpage>
        <lpage>93</lpage>
        <pub-id pub-id-type="doi">10.1038/ng.1006</pub-id>
        <?supplied-pmid 22138689?>
        <pub-id pub-id-type="pmid">22138689</pub-id>
      </element-citation>
    </ref>
    <ref id="CR17">
      <label>17.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lai</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Gardini</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Shiekhattar</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>Integrator mediates the biogenesis of enhancer RNAs</article-title>
        <source>Nature</source>
        <year>2015</year>
        <volume>525</volume>
        <issue>7569</issue>
        <fpage>399</fpage>
        <lpage>403</lpage>
        <pub-id pub-id-type="doi">10.1038/nature14906</pub-id>
        <?supplied-pmid 26308897?>
        <pub-id pub-id-type="pmid">26308897</pub-id>
      </element-citation>
    </ref>
    <ref id="CR18">
      <label>18.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Melgar</surname>
            <given-names>MF</given-names>
          </name>
          <name>
            <surname>Collins</surname>
            <given-names>FS</given-names>
          </name>
          <name>
            <surname>Sethupathy</surname>
            <given-names>P</given-names>
          </name>
        </person-group>
        <article-title>Discovery of active enhancers through bidirectional expression of short transcripts</article-title>
        <source>Genome Biol</source>
        <year>2011</year>
        <volume>12</volume>
        <issue>11</issue>
        <fpage>R113</fpage>
        <pub-id pub-id-type="doi">10.1186/gb-2011-12-11-r113</pub-id>
        <?supplied-pmid 22082242?>
        <pub-id pub-id-type="pmid">22082242</pub-id>
      </element-citation>
    </ref>
    <ref id="CR19">
      <label>19.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Mayer</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>di Iulio</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Maleri</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Eser</surname>
            <given-names>U</given-names>
          </name>
          <name>
            <surname>Vierstra</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Reynolds</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Sandstrom</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Stamatoyannopoulos</surname>
            <given-names>JA</given-names>
          </name>
          <name>
            <surname>Churchman</surname>
            <given-names>LS</given-names>
          </name>
        </person-group>
        <article-title>Native elongating transcript sequencing reveals human transcriptional activity at nucleotide resolution</article-title>
        <source>Cell</source>
        <year>2015</year>
        <volume>161</volume>
        <issue>3</issue>
        <fpage>541</fpage>
        <lpage>54</lpage>
        <pub-id pub-id-type="doi">10.1016/j.cell.2015.03.010</pub-id>
        <?supplied-pmid 25910208?>
        <pub-id pub-id-type="pmid">25910208</pub-id>
      </element-citation>
    </ref>
    <ref id="CR20">
      <label>20.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Liu</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Fang</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Long</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Lan</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Chou</surname>
            <given-names>KC</given-names>
          </name>
        </person-group>
        <article-title>iEnhancer-2L: a two-layer predictor for identifying enhancers and their strength by pseudo k-tuple nucleotide composition</article-title>
        <source>Bioinformatics</source>
        <year>2016</year>
        <volume>32</volume>
        <issue>3</issue>
        <fpage>362</fpage>
        <lpage>9</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btv604</pub-id>
        <?supplied-pmid 26476782?>
        <pub-id pub-id-type="pmid">26476782</pub-id>
      </element-citation>
    </ref>
    <ref id="CR21">
      <label>21.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Jia</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>He</surname>
            <given-names>W</given-names>
          </name>
        </person-group>
        <article-title>EnhancerPred: a predictor for discovering enhancers based on the combination and selection of multiple features</article-title>
        <source>Sci Rep</source>
        <year>2016</year>
        <volume>6</volume>
        <fpage>38741</fpage>
        <pub-id pub-id-type="doi">10.1038/srep38741</pub-id>
        <?supplied-pmid 27941893?>
        <pub-id pub-id-type="pmid">27941893</pub-id>
      </element-citation>
    </ref>
    <ref id="CR22">
      <label>22.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Liu</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Huang</surname>
            <given-names>DS</given-names>
          </name>
          <name>
            <surname>Chou</surname>
            <given-names>KC</given-names>
          </name>
        </person-group>
        <article-title>iEnhancer-EL: identifying enhancers and their strength with ensemble learning approach</article-title>
        <source>Bioinformatics</source>
        <year>2018</year>
        <volume>34</volume>
        <issue>22</issue>
        <fpage>3835</fpage>
        <lpage>42</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/bty458</pub-id>
        <?supplied-pmid 29878118?>
        <pub-id pub-id-type="pmid">29878118</pub-id>
      </element-citation>
    </ref>
    <ref id="CR23">
      <label>23.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Nguyen</surname>
            <given-names>QH</given-names>
          </name>
          <name>
            <surname>Nguyen-Vo</surname>
            <given-names>TH</given-names>
          </name>
          <name>
            <surname>Le</surname>
            <given-names>NQK</given-names>
          </name>
          <name>
            <surname>Do</surname>
            <given-names>TTT</given-names>
          </name>
          <name>
            <surname>Rahardja</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Nguyen</surname>
            <given-names>BP</given-names>
          </name>
        </person-group>
        <article-title>iEnhancer-ECNN: identifying enhancers and their strength using ensembles of convolutional neural networks</article-title>
        <source>BMC Genom</source>
        <year>2019</year>
        <volume>20</volume>
        <issue>Suppl 9</issue>
        <fpage>951</fpage>
        <pub-id pub-id-type="doi">10.1186/s12864-019-6336-3</pub-id>
      </element-citation>
    </ref>
    <ref id="CR24">
      <label>24.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Cai</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Ren</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Fu</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Peng</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Gao</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Zeng</surname>
            <given-names>X</given-names>
          </name>
        </person-group>
        <article-title>iEnhancer-XG: interpretable sequence-based enhancers and their strength predictor</article-title>
        <source>Bioinformatics</source>
        <year>2021</year>
        <volume>37</volume>
        <issue>8</issue>
        <fpage>1060</fpage>
        <lpage>7</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btaa914</pub-id>
        <?supplied-pmid 33119044?>
        <pub-id pub-id-type="pmid">33119044</pub-id>
      </element-citation>
    </ref>
    <ref id="CR25">
      <label>25.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Niu</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Luo</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Teng</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Zhao</surname>
            <given-names>Y</given-names>
          </name>
        </person-group>
        <article-title>iEnhancer-EBLSTM: identifying enhancers and strengths by ensembles of bidirectional long short-term memory</article-title>
        <source>Front Genet</source>
        <year>2021</year>
        <volume>12</volume>
        <fpage>665498</fpage>
        <pub-id pub-id-type="doi">10.3389/fgene.2021.665498</pub-id>
        <?supplied-pmid 33833783?>
        <pub-id pub-id-type="pmid">33833783</pub-id>
      </element-citation>
    </ref>
    <ref id="CR26">
      <label>26.</label>
      <mixed-citation publication-type="other">Lundberg S, Lee SI. A Unified Approach to Interpreting Model Predictions. Nips. 2017;4768-77.</mixed-citation>
    </ref>
    <ref id="CR27">
      <label>27.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Fu</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Niu</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Zhu</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Wu</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>W</given-names>
          </name>
        </person-group>
        <article-title>CD-HIT: accelerated for clustering the next-generation sequencing data</article-title>
        <source>Bioinformatics</source>
        <year>2012</year>
        <volume>28</volume>
        <issue>23</issue>
        <fpage>3150</fpage>
        <lpage>2</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/bts565</pub-id>
        <?supplied-pmid 23060610?>
        <pub-id pub-id-type="pmid">23060610</pub-id>
      </element-citation>
    </ref>
    <ref id="CR28">
      <label>28.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Habibi</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Weber</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Neves</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Wiegandt</surname>
            <given-names>DL</given-names>
          </name>
          <name>
            <surname>Leser</surname>
            <given-names>U</given-names>
          </name>
        </person-group>
        <article-title>Deep learning with word embeddings improves biomedical named entity recognition</article-title>
        <source>Bioinformatics</source>
        <year>2017</year>
        <volume>33</volume>
        <issue>14</issue>
        <fpage>i37</fpage>
        <lpage>48</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btx228</pub-id>
        <?supplied-pmid 28881963?>
        <pub-id pub-id-type="pmid">28881963</pub-id>
      </element-citation>
    </ref>
    <ref id="CR29">
      <label>29.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hamid</surname>
            <given-names>MN</given-names>
          </name>
          <name>
            <surname>Friedberg</surname>
            <given-names>I</given-names>
          </name>
        </person-group>
        <article-title>Identifying antimicrobial peptides using word embedding with deep recurrent neural networks</article-title>
        <source>Bioinformatics</source>
        <year>2019</year>
        <volume>35</volume>
        <issue>12</issue>
        <fpage>2009</fpage>
        <lpage>16</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/bty937</pub-id>
        <?supplied-pmid 30418485?>
        <pub-id pub-id-type="pmid">30418485</pub-id>
      </element-citation>
    </ref>
    <ref id="CR30">
      <label>30.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zou</surname>
            <given-names>Q</given-names>
          </name>
          <name>
            <surname>Xing</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Wei</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>B</given-names>
          </name>
        </person-group>
        <article-title>Gene2vec: gene subsequence embedding for prediction of mammalian N6-methyladenosine sites from mRNA</article-title>
        <source>RNA</source>
        <year>2019</year>
        <volume>25</volume>
        <issue>2</issue>
        <fpage>205</fpage>
        <lpage>18</lpage>
        <pub-id pub-id-type="doi">10.1261/rna.069112.118</pub-id>
        <?supplied-pmid 30425123?>
        <pub-id pub-id-type="pmid">30425123</pub-id>
      </element-citation>
    </ref>
    <ref id="CR31">
      <label>31.</label>
      <mixed-citation publication-type="other">Ng P. dna2vec: Consistent vector representations of variable-length k-mers. 2017.</mixed-citation>
    </ref>
    <ref id="CR32">
      <label>32.</label>
      <mixed-citation publication-type="other">Mikolov T, Corrado G, Kai C, Dean J. Efficient estimation of word representations in vector space. In: Proceedings of the international conference on learning representations (ICLR 2013). 2013.</mixed-citation>
    </ref>
    <ref id="CR33">
      <label>33.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Yasaka</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Akai</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Kunimatsu</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Kiryu</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Abe</surname>
            <given-names>O</given-names>
          </name>
        </person-group>
        <article-title>Deep learning with convolutional neural network in radiology</article-title>
        <source>Jpn J Radiol</source>
        <year>2018</year>
        <volume>36</volume>
        <issue>4</issue>
        <fpage>257</fpage>
        <lpage>72</lpage>
        <pub-id pub-id-type="doi">10.1007/s11604-018-0726-3</pub-id>
        <?supplied-pmid 29498017?>
        <pub-id pub-id-type="pmid">29498017</pub-id>
      </element-citation>
    </ref>
    <ref id="CR34">
      <label>34.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Li</surname>
            <given-names>CC</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>B</given-names>
          </name>
        </person-group>
        <article-title>MotifCNN-fold: protein fold recognition based on fold-specific features extracted by motif-based convolutional neural networks</article-title>
        <source>Br Bioinform</source>
        <year>2020</year>
        <volume>21</volume>
        <issue>6</issue>
        <fpage>2133</fpage>
        <lpage>41</lpage>
        <pub-id pub-id-type="doi">10.1093/bib/bbz133</pub-id>
      </element-citation>
    </ref>
    <ref id="CR35">
      <label>35.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Li</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Luo</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Yuan</surname>
            <given-names>XT</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Sparseness analysis in the pretraining of deep neural networks</article-title>
        <source>IEEE Trans Neural Netw Learn Syst</source>
        <year>2017</year>
        <volume>28</volume>
        <issue>6</issue>
        <fpage>1425</fpage>
        <lpage>38</lpage>
        <pub-id pub-id-type="doi">10.1109/TNNLS.2016.2541681</pub-id>
        <?supplied-pmid 27046912?>
        <pub-id pub-id-type="pmid">27046912</pub-id>
      </element-citation>
    </ref>
    <ref id="CR36">
      <label>36.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Cai</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Fang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Wu</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Hao</surname>
            <given-names>Y</given-names>
          </name>
        </person-group>
        <article-title>Dual-dropout graph convolutional network for predicting synthetic lethality in human cancers</article-title>
        <source>Bioinformatics</source>
        <year>2020</year>
        <volume>36</volume>
        <issue>16</issue>
        <fpage>4458</fpage>
        <lpage>65</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btaa211</pub-id>
        <?supplied-pmid 32221609?>
        <pub-id pub-id-type="pmid">32221609</pub-id>
      </element-citation>
    </ref>
    <ref id="CR37">
      <label>37.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Deng</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Wu</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <article-title>DeepD2V: a novel deep learning-based framework for predicting transcription factor binding sites from combined DNA sequence</article-title>
        <source>Int J Mol Sci</source>
        <year>2021</year>
        <volume>22</volume>
        <issue>11</issue>
        <fpage>5521</fpage>
        <pub-id pub-id-type="doi">10.3390/ijms22115521</pub-id>
        <?supplied-pmid 34073774?>
        <pub-id pub-id-type="pmid">34073774</pub-id>
      </element-citation>
    </ref>
    <ref id="CR38">
      <label>38.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Cho</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Courville</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Bengio</surname>
            <given-names>Y</given-names>
          </name>
        </person-group>
        <article-title>Describing multimedia content using attention-based encoder-decoder networks</article-title>
        <source>IEEE Trans Multimed</source>
        <year>2015</year>
        <volume>17</volume>
        <issue>11</issue>
        <fpage>1875</fpage>
        <lpage>86</lpage>
        <pub-id pub-id-type="doi">10.1109/TMM.2015.2477044</pub-id>
      </element-citation>
    </ref>
    <ref id="CR39">
      <label>39.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>He</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>He</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Song</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Jiang</surname>
            <given-names>YG</given-names>
          </name>
          <name>
            <surname>Chua</surname>
            <given-names>TS</given-names>
          </name>
        </person-group>
        <article-title>NAIS: neural attentive item similarity model for recommendation</article-title>
        <source>IEEE Trans Knowl Data Eng</source>
        <year>2018</year>
        <volume>30</volume>
        <issue>12</issue>
        <fpage>2354</fpage>
        <lpage>66</lpage>
        <pub-id pub-id-type="doi">10.1109/TKDE.2018.2831682</pub-id>
      </element-citation>
    </ref>
    <ref id="CR40">
      <label>40.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lin</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Liang</surname>
            <given-names>ZY</given-names>
          </name>
          <name>
            <surname>Tang</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>W</given-names>
          </name>
        </person-group>
        <article-title>Identifying Sigma70 promoters with novel pseudo nucleotide composition</article-title>
        <source>IEEE/ACM Trans Comput Biol Bioinform</source>
        <year>2019</year>
        <volume>16</volume>
        <issue>4</issue>
        <fpage>1316</fpage>
        <lpage>21</lpage>
        <pub-id pub-id-type="doi">10.1109/TCBB.2017.2666141</pub-id>
        <?supplied-pmid 28186907?>
        <pub-id pub-id-type="pmid">28186907</pub-id>
      </element-citation>
    </ref>
    <ref id="CR41">
      <label>41.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Sabooh</surname>
            <given-names>MF</given-names>
          </name>
          <name>
            <surname>Iqbal</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Khan</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Khan</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Maqbool</surname>
            <given-names>HF</given-names>
          </name>
        </person-group>
        <article-title>Identifying 5-methylcytosine sites in RNA sequence using composite encoding feature into Chou’s PseKNC</article-title>
        <source>J Theor Biol</source>
        <year>2018</year>
        <volume>452</volume>
        <fpage>1</fpage>
        <lpage>9</lpage>
        <pub-id pub-id-type="doi">10.1016/j.jtbi.2018.04.037</pub-id>
        <?supplied-pmid 29727634?>
        <pub-id pub-id-type="pmid">29727634</pub-id>
      </element-citation>
    </ref>
    <ref id="CR42">
      <label>42.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Yang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Singh</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Ma</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Exploiting sequence-based features for predicting enhancer-promoter interactions</article-title>
        <source>Bioinformatics</source>
        <year>2017</year>
        <volume>33</volume>
        <issue>14</issue>
        <fpage>i252</fpage>
        <lpage>60</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btx257</pub-id>
        <?supplied-pmid 28881991?>
        <pub-id pub-id-type="pmid">28881991</pub-id>
      </element-citation>
    </ref>
    <ref id="CR43">
      <label>43.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Jing</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Xue</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Luo</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>autoBioSeqpy: a deep learning tool for the classification of biological sequences</article-title>
        <source>J Chem Inf Model</source>
        <year>2020</year>
        <volume>60</volume>
        <issue>8</issue>
        <fpage>3755</fpage>
        <lpage>64</lpage>
        <pub-id pub-id-type="doi">10.1021/acs.jcim.0c00409</pub-id>
        <?supplied-pmid 32786512?>
        <pub-id pub-id-type="pmid">32786512</pub-id>
      </element-citation>
    </ref>
  </ref-list>
</back>
