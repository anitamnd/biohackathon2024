<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">J Digit Imaging</journal-id>
    <journal-id journal-id-type="iso-abbrev">J Digit Imaging</journal-id>
    <journal-title-group>
      <journal-title>Journal of Digital Imaging</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">0897-1889</issn>
    <issn pub-type="epub">1618-727X</issn>
    <publisher>
      <publisher-name>Springer International Publishing</publisher-name>
      <publisher-loc>Cham</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">9485318</article-id>
    <article-id pub-id-type="pmid">35304674</article-id>
    <article-id pub-id-type="publisher-id">612</article-id>
    <article-id pub-id-type="doi">10.1007/s10278-022-00612-z</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Original Paper</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>XNAT-PIC: Extending XNAT to Preclinical Imaging Centers</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-3066-9357</contrib-id>
        <name>
          <surname>Zullino</surname>
          <given-names>Sara</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Paglialonga</surname>
          <given-names>Alessandro</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Dastrù</surname>
          <given-names>Walter</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-6906-9925</contrib-id>
        <name>
          <surname>Longo</surname>
          <given-names>Dario Livio</given-names>
        </name>
        <address>
          <email>dario.longo@unito.it</email>
          <email>dariolivio.longo@cnr.it</email>
        </address>
        <xref ref-type="aff" rid="Aff3">3</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Aime</surname>
          <given-names>Silvio</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="GRID">grid.7605.4</institution-id><institution-id institution-id-type="ISNI">0000 0001 2336 6580</institution-id><institution>Molecular Imaging Center, Department of Molecular Biotechnology and Health Sciences, </institution><institution>University of Torino, </institution></institution-wrap>Torino, Italy </aff>
      <aff id="Aff2"><label>2</label>Euro-BioImaging ERIC, Torino, Italy </aff>
      <aff id="Aff3"><label>3</label><institution-wrap><institution-id institution-id-type="GRID">grid.5326.2</institution-id><institution-id institution-id-type="ISNI">0000 0001 1940 4177</institution-id><institution>Institute of Biostructures and Bioimaging (IBB), </institution><institution>Italian National Research Council (CNR), </institution></institution-wrap>Via Nizza 52, 10126 Torino, Italy </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>18</day>
      <month>3</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>18</day>
      <month>3</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="ppub">
      <month>8</month>
      <year>2022</year>
    </pub-date>
    <volume>35</volume>
    <issue>4</issue>
    <fpage>860</fpage>
    <lpage>875</lpage>
    <history>
      <date date-type="received">
        <day>26</day>
        <month>2</month>
        <year>2021</year>
      </date>
      <date date-type="rev-recd">
        <day>7</day>
        <month>2</month>
        <year>2022</year>
      </date>
      <date date-type="accepted">
        <day>15</day>
        <month>2</month>
        <year>2022</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2022</copyright-statement>
      <license>
        <ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p><bold>Open Access</bold>This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>.</license-p>
      </license>
    </permissions>
    <abstract id="Abs1">
      <p id="Par1">Molecular imaging generates large volumes of heterogeneous biomedical imagery with an impelling need of guidelines for handling image data. Although several successful solutions have been implemented for human epidemiologic studies, few and limited approaches have been proposed for animal population studies. Preclinical imaging research deals with a variety of machinery yielding tons of raw data but the current practices to store and distribute image data are inadequate. Therefore, standard tools for the analysis of large image datasets need to be established. In this paper, we present an extension of XNAT for Preclinical Imaging Centers (XNAT-PIC). XNAT is a worldwide used, open-source platform for securely hosting, sharing, and processing of clinical imaging studies. Despite its success, neither tools for importing large, multimodal preclinical image datasets nor pipelines for processing whole imaging studies are yet available in XNAT. In order to overcome these limitations, we have developed several tools to expand the XNAT core functionalities for supporting preclinical imaging facilities. Our aim is to streamline the management and exchange of image data within the preclinical imaging community, thereby enhancing the reproducibility of the results of image processing and promoting open science practices.</p>
    </abstract>
    <kwd-group xml:lang="en">
      <title>Keywords</title>
      <kwd>Preclinical imaging</kwd>
      <kwd>XNAT</kwd>
      <kwd>Magnetic resonance imaging</kwd>
      <kwd>Image processing</kwd>
      <kwd>Open science</kwd>
      <kwd>Database</kwd>
    </kwd-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100010677</institution-id>
            <institution>H2020 Health</institution>
          </institution-wrap>
        </funding-source>
        <award-id>824087</award-id>
        <award-id>654248</award-id>
        <award-id>667510</award-id>
        <principal-award-recipient>
          <name>
            <surname>Aime</surname>
            <given-names>Silvio</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
    </funding-group>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>© The Author(s) under exclusive licence to Society for Imaging Informatics in Medicine 2022</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="Sec1">
    <title>Introduction</title>
    <p id="Par2">Preclinical imaging deals with the visualization of small animals, such as mice and rats, for research purposes, in order to assay biological structures and activities in vivo, thus providing quantifiable, spatial and temporal information on healthy and pathological tissues down to both cellular and molecular level [<xref ref-type="bibr" rid="CR1">1</xref>]. Importantly, because of its non-invasiveness, imaging is suitable for longitudinal studies of animal models in the fields of diagnostics, epidemiology and drug development [<xref ref-type="bibr" rid="CR2">2</xref>].</p>
    <p id="Par3">Imaging research generates large amounts of data and information, mostly produced by computers and laboratory instruments. Consequently, it is of utmost importance to provide appropriate data storage to ensure adequate management and organization to the research labs. Data loss not only implies losing processed images and the know-how gained, but also a waste of time and resources. Data sharing among research groups is another critical factor, particularly in scientific collaborations that involve many partners. In the last decade, several image repositories have emerged enabling the discovery of datasets from peer-reviewed publications or research studies in the life science domain, from biological imaging such as electron/fluorescence microscopy and high content screening, to biomedical imaging, such as magnetic resonance imaging (MRI), positron electron tomography (PET), computed tomography (CT) and ultrasound (US) [<xref ref-type="bibr" rid="CR3">3</xref>–<xref ref-type="bibr" rid="CR5">5</xref>]. These resources can now be retrieved online by users through a browser user interface or programmatically by using an application programming interface (API).</p>
    <p id="Par4">For human population studies on biomedical imaging, large data repositories are routinely used by researchers and physicians all over the world. Among them, the Human Connectome Project [<xref ref-type="bibr" rid="CR6">6</xref>] is a compilation of neural data, The Cancer Imaging Archive (TCIA) is a broad collection of cancer image data [<xref ref-type="bibr" rid="CR7">7</xref>], the Alzheimer’s Disease Neuroimaging Initiative (ADNI) is a shared catalogue of image data related to Alzheimer’s disease [<xref ref-type="bibr" rid="CR8">8</xref>] and the Open Access Series of Imaging Studies (OASIS) is a repository of magnetic resonance images [<xref ref-type="bibr" rid="CR9">9</xref>].</p>
    <p id="Par5">The processing of large volumes of biomedical image datasets requires dedicated platforms and proper infrastructures. The Longitudinal Online Research and Imaging System (LORIS) is a flexible online system for data management devoted to multicenter studies that covers all the aspects from data acquisition from multiple sources to storage, processing and dissemination [<xref ref-type="bibr" rid="CR10">10</xref>]. Other examples of extensible data management platforms are The Human Imaging Database (HID) and the Collaborative Informatics and Neuroimaging Suite (COINS) for clinical neuroimaging studies [<xref ref-type="bibr" rid="CR11">11</xref>, <xref ref-type="bibr" rid="CR12">12</xref>]. To tackle the needs of heterogeneous studies, the Medical Imaging Research Management and Associated Information Database (MIRMAID), a web-accessible content management system for medical images, was proposed [<xref ref-type="bibr" rid="CR13">13</xref>]. More recently, Anastasopoulos et al. introduced Nora Imaging, an in-house web platform, to process medical imaging data derived from brain imaging studies [<xref ref-type="bibr" rid="CR14">14</xref>].</p>
    <p id="Par6">The Extensible Neuroimaging Archive Toolkit (XNAT) is an imaging informatics system designed by the Neuroinformatics Research Group at the Washington University to manage images from several sources, to save data in a safe database and to share data among authorized users [<xref ref-type="bibr" rid="CR15">15</xref>, <xref ref-type="bibr" rid="CR16">16</xref>]. It was originally conceived to deal with data management of neuroimaging laboratories, but its increasing success has promoted its use in many other medical imaging fields. Over the years, XNAT has become a large project sustained by active user and developer communities. Indeed, many academic institutions and hospitals build their own data management and process infrastructure upon the XNAT system with the aim to extend its core features and provide new functionalities to meet the needs of researchers and physicians. An XNAT-based framework for managing large-scale clinical studies was developed by Doran et al. along with in-house applications for data selection and uploading [<xref ref-type="bibr" rid="CR17">17</xref>]. GIFT-Cloud is a medical image sharing platform built on top of XNAT 1.6 dedicated to GIFT-Surg, an international scientific project that develops novel imaging techniques for prenatal surgery [<xref ref-type="bibr" rid="CR18">18</xref>]. Moreover, XNAT has been customized for automated quality assessment of retinal optical coherence tomography (OCT) [<xref ref-type="bibr" rid="CR19">19</xref>] and for collaborative research in human sleep medicine [<xref ref-type="bibr" rid="CR20">20</xref>]. XNAT has also been used to promote multicenter reproducibility studies for radiomics [<xref ref-type="bibr" rid="CR21">21</xref>]. The European Population Imaging Infrastructure (EPI2) provides an XNAT-based environment for the implementation of large, prospective epidemiological imaging studies, allowing for permanent and/or temporary storage of medical images. Furthermore, EPI2 develops state-of-the-art image analysis pipelines for high-volume image processing [<xref ref-type="bibr" rid="CR22">22</xref>, <xref ref-type="bibr" rid="CR23">23</xref>]. Lastly, Health-RI offers an XNAT-based service for research projects related to archive, view and process clinical imaging data [<xref ref-type="bibr" rid="CR24">24</xref>, <xref ref-type="bibr" rid="CR25">25</xref>].</p>
    <p id="Par7">Animal population imaging allows researchers to test novel therapies and drugs on small animal models that will be eventually translated into the clinic. On the other hand, it suffers from the lack of standard tools to store, process and share imaging data produced by scientists. Kain et al. have recently proposed the Small Animal Shanoir (SAS), an expansion of the Shanoir platform that was developed for data management dedicated to human neuroimaging repositories [<xref ref-type="bibr" rid="CR26">26</xref>, <xref ref-type="bibr" rid="CR27">27</xref>]. SAS offers a cloud-based solution for exchanging data and analysis tools for small animal imaging studies in the framework of France Life Imaging (FLI).</p>
    <p id="Par8">Small animal imaging facilities are highly specialized centers that provide the research community, both academic institutions and industrial enterprises, with access to cutting-edge imaging technologies. Therefore, animal imaging centers have to deal with the complexity and the variety of preclinical trial datasets. The time needed to perform these studies and the relative costs are prompting imaging scientists to share image data in public repositories. Sharing data from independent research investigations, beyond saving resources, ensures the reproducibility of the experiments, aids the scientific community to get noticed and boosts collaborations among research institutions. The main difficulties arise from the complexity of the analysis and the scarcity of standard applications for sharing and processing preclinical images.</p>
    <p id="Par9">Vendors of preclinical imaging machinery use proprietary formats to store the acquired images. This makes data handling difficult for users with limited experience in data management and image processing. These drawbacks arise significant questions for multimodal image investigations especially in recording, curation and processing of imaging data. Commercial softwares distributed by imaging device manufacturers provide the possibility to export proprietary raw image datasets to internationally recognized data standards, being Digital Imaging and COmmunications in Medicine (DICOM) [<xref ref-type="bibr" rid="CR28">28</xref>] and Neuroimaging Informatics Technology Initiative (NIfTI) [<xref ref-type="bibr" rid="CR29">29</xref>] the most popular ones. Notably, the storage of the parameters related to the image acquisition is poorly supported by NIfTI, as opposed to DICOM [<xref ref-type="bibr" rid="CR30">30</xref>]. Despite DICOM being the internationally acknowledged standard for the interchange and management of medical images, some sections still require coherent semantics to guarantee consistent sharing of image data across several third-party products. In addition, the DICOM standard needs to be updated and expanded to support novel applications and incorporate emerging imaging technologies. In particular, at preclinical level new techniques have been developed such as chemical exchange saturation transfer (CEST) MRI, photoacoustic imaging (PAI) and optical imaging (OI), so that standardization as well as ad hoc DICOM attributes are desirable.</p>
    <p id="Par10">This work aims to develop an XNAT-based platform that meets the needs of the preclinical imaging community. This system is named XNAT-PIC that stands for XNAT for Preclinical Imaging Centers. Our goal is two-fold: we intend to provide the preclinical imaging researchers with tools to easily extract, import and archive biomedical image data and with reusable processes for high-throughput extraction of quantitative features from raw image data, all within an XNAT environment. All the developments are free and open-source. We believe that XNAT-PIC will allow a streamlined exchange and reuse of image data among preclinical imaging facilities.</p>
  </sec>
  <sec id="Sec2">
    <title>Materials and Methods</title>
    <p id="Par11">The Molecular Imaging Center (CIM) hosted at the Department of Molecular Biotechnology and Health Sciences of the University of Torino has deployed an XNAT instance devoted to preclinical imaging available at <ext-link ext-link-type="uri" xlink:href="http://cim-xnat.unito.it">http://cim-xnat.unito.it</ext-link>. XNAT is a free and open-source Java-based web application, exploiting the PostgreSQL database system. Users can personalize an instance and broaden its basic features to support their data and project management needs. The deployment presented in this paper is running on XNAT 1.7.6, using Apache Tomcat 7, Oracle JDK 8, PostgreSQL 11 and Ubuntu 20.04 LTS Operative System.</p>
    <p id="Par12">XNAT natively supports multiple imaging modalities, such as MRI, PET, CT and US with the possibility to extend XNAT datatypes to other imaging methods. XNAT comes with a built-in DICOM image management application that also allows to store images in NIfTI format. It offers key functionalities, for instance importing and downloading images in multiple formats, archiving, distributing data and setting data protection and accessibility. In XNAT, users can either store the raw or processed images on local disks or transfer them through the network to a DICOM C-STORE Service Class Provider (SCP), for instance a picture archive and communications systems (PACS) or another XNAT deployment. Moreover, XNAT comes with a Java-based viewer to access and inspect the images in the archive. This viewer can be customized with plugins to integrate supplementary functionalities specific to the image type of interest.</p>
    <p id="Par13">XNAT for Preclinical Imaging Centers (XNAT-PIC) has been developed to meet the needs of the preclinical imaging community. In particular, XNAT-PIC consists of a suite of tools aimed at converting raw MR image series to DICOM standard, uploading to XNAT and processing large image datasets. This workflow is based on the steps schematically depicted in Fig. <xref rid="Fig1" ref-type="fig">1</xref>:<fig id="Fig1"><label>Fig. 1</label><caption><p>Schematic workflow of image archiving and processing. XNAT-PIC is a suite of tools aimed at facilitating the management and the analysis of preclinical image datasets</p></caption><graphic xlink:href="10278_2022_612_Fig1_HTML" id="MO1"/></fig><list list-type="order"><list-item><p id="Par14">MRI2DICOM, a MR image converter from ParaVision<sup>®</sup> (Bruker, Inc. Billerica, MA) file format to DICOM standard.</p></list-item><list-item><p id="Par15">XNAT-PIC Uploader to upload large, multimodal image datasets in DICOM standard to XNAT.</p></list-item><list-item><p id="Par16">XNAT-PIC Pipelines for processing single or multiple subjects in an XNAT project.</p></list-item></list></p>
    <p id="Par17">MRI2DICOM is a free and open-source tool built in Python 3.7.6 downloadable at <ext-link ext-link-type="uri" xlink:href="https://github.com/szullino/XNAT-PIC">https://github.com/szullino/XNAT-PIC</ext-link> [<xref ref-type="bibr" rid="CR31">31</xref>]. The application uses the numpy 1.15.4 and Pydicom 1.2.1 libraries to handle DICOM files [<xref ref-type="bibr" rid="CR32">32</xref>–<xref ref-type="bibr" rid="CR35">35</xref>]. MRI2DICOM has been designed for and tested on several, different versions of ParaVision<sup>®</sup>, such as 5.1, 6.0.1 and 360.1.1. It accesses the ParaVision<sup>®</sup> data structure, deciphers the binary file (<italic>2dseq</italic>) containing the image and parses the acquisition parameters stored in different files (<italic>visupars</italic>, <italic>method</italic>, <italic>reco</italic>, and <italic>acqp</italic>) into Python dictionaries [<xref ref-type="bibr" rid="CR36">36</xref>]. Lastly, it saves all the relevant information into the DICOM header and image set field, according to the MRI acquisition protocol.</p>
    <p id="Par18">XNAT-PIC Uploader is built in Python 3.7.6. The communication with XNAT is possible through xnatpy 0.3.22, a new and open-source XNAT Python client, and pyAesCrypt 0.4.3, a Python library to encrypt the files containing the XNAT login credentials [<xref ref-type="bibr" rid="CR37">37</xref>, <xref ref-type="bibr" rid="CR38">38</xref>]. PyInstaller 3.5 has been used to bundle the Python applications and all its dependencies into a single package to run MRI2DICOM and XNAT-PIC Uploader as a stand-alone executable, in both Windows and Linux environments [<xref ref-type="bibr" rid="CR39">39</xref>].</p>
    <p id="Par19">XNAT-PIC Pipelines have been designed to process DICOM images stored in XNAT, extract quantitative information and produce parametric maps. These pipelines have been built on top of pre-existing image analysis scripts developed in MATLAB R2020b (The MathWorks, Inc., US) by our group. XNAT-PIC Pipelines can be of two types: <italic>subject level</italic> or <italic>project level pipeline</italic>. <italic>Subject level pipelines</italic> consist of a bash script that invokes MATLAB to perform the computation. A different approach has been used for <italic>project level pipelines</italic>, i.e. to process multiple subjects within the same project. A Python 2.7 virtual environment has been created and the following packages have been installed: (i) the MATLAB Engine API for Python to run MATLAB scripts within a Python session [<xref ref-type="bibr" rid="CR40">40</xref>], (ii) pyxnat-1.2.1.0.post3 that facilitates scripting interactions with the XNAT database [<xref ref-type="bibr" rid="CR41">41</xref>, <xref ref-type="bibr" rid="CR42">42</xref>], (iii) Requests 2.23.0 that makes Hypertext Transfer Protocol (HTTP) requests to communicate with XNAT extremely simple [<xref ref-type="bibr" rid="CR43">43</xref>]. Finally, the <italic>Mask Average Pipeline</italic> has been developed to calculate the mean value in a region of interest (ROI) of a parametric map generated from processing. This pipeline runs on Python 3.8.3 and uses the following libraries: numpy 1.18.5 [<xref ref-type="bibr" rid="CR44">44</xref>] dcmrtstruct2nii 1.0.19 to export DICOM Radiotherapy Structure Set (RTSTRUCT) to NIfTI mask [<xref ref-type="bibr" rid="CR45">45</xref>], the image processing library opencv-python 4.4.0.40 [<xref ref-type="bibr" rid="CR46">46</xref>], and nibabel 3.1.1 for manipulating NIfTI images [<xref ref-type="bibr" rid="CR47">47</xref>].</p>
  </sec>
  <sec id="Sec3">
    <title>Results</title>
    <sec id="Sec4">
      <title>MRI2DICOM Converter</title>
      <p id="Par20">Upon launching, XNAT-PIC offers multiple functions as shown in Fig. <xref rid="Fig2" ref-type="fig">2</xref>A: users can use MRI2DICOM to convert the binary data to DICOM standard or, given the data already in DICOM, users can use XNAT-PIC Uploader to import the MR image sessions to XNAT. If MRI2DICOM has been selected by the user, the converter needs to know the directory of the project in ParaVision<sup>®</sup> format to start the conversion (Fig. <xref rid="Fig2" ref-type="fig">2</xref>B). Once the process is completed, a new folder containing the project in DICOM standard will be created at the same location as the original one in raw format.<fig id="Fig2"><label>Fig. 2</label><caption><p>Snapshots of the XNAT-PIC application. <bold>A</bold> Upon launch, users can choose between converting raw image data to DICOM standard or upload pre-existing DICOM images to XNAT. <bold>B</bold> If the converter has been selected, MRI2DICOM allows the user to browse to the directory of the project in ParaVision<sup>®</sup> format</p></caption><graphic xlink:href="10278_2022_612_Fig2_HTML" id="MO2"/></fig></p>
      <p id="Par21">Commercial software in preclinical imaging poorly conforms to standards regarding data storage and each vendor uses a proprietary format for its data. In order to deal with emerging MRI techniques, a novel set of vocabularies can be introduced as private DICOM attributes specifically devoted to these Information Object Definition (IOD) [<xref ref-type="bibr" rid="CR48">48</xref>]. For example, new dictionary items have been dynamically added to the ‘standard’ DICOM dictionary to describe CEST-MRI datasets. The full list of DICOM attributes is available in DICOM Part 6: Data Dictionary [<xref ref-type="bibr" rid="CR49">49</xref>]. To avoid conflicts of private attributes from different implementers, a block in the (0061, 0010) space has been reserved for this specific use. The complete description of Private Data Elements encoded in the DICOM standard can be found in DICOM Part 5: Data Structure and Encoding [<xref ref-type="bibr" rid="CR50">50</xref>]. Table <xref rid="Tab1" ref-type="table">1</xref> shows the private DICOM dictionary that has been developed for CEST-MRI acquisitions along with the corresponding entry gathered from the <italic>method</italic> file of ParaVision<sup>®</sup> 360.1.1. The value multiplicity (VM) of an attribute defines the number of values contained in that attribute, while the value representation (VR) describes the data type and format of each DICOM attribute.<table-wrap id="Tab1"><label>Table 1</label><caption><p>Private DICOM attributes for CEST-MRI modality gathered from the ParaVision<sup>®</sup>
<italic>method</italic> file. To avoid conflicts of private tags from different vendors, a block in the (0061, 0010) space has been reserved for this specific imaging IOD. <italic>VM</italic>, value multiplicity; <italic>VR</italic>, value representation; <italic>LO</italic>, long string; <italic>DS</italic>, decimal string</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left"><bold>Attribute name</bold></th><th align="left"><bold>Tag</bold></th><th align="left"><bold>VM</bold></th><th align="left"><bold>VR</bold></th><th align="left"><bold>Definition</bold></th><th align="left"><bold>PV360</bold></th></tr></thead><tbody><tr><td align="left"><bold>CEST Parameters Creator</bold></td><td align="left">(1061,0010)</td><td align="left">1</td><td align="left">LO</td><td align="left">Creator of the parameter set</td><td align="left">OWNER</td></tr><tr><td align="left"><bold>Chemical Exchange Saturation Method</bold></td><td align="left">(1061,1001)</td><td align="left">1</td><td align="left">LO</td><td align="left">Method of the acquisition sequence</td><td align="left">Method</td></tr><tr><td align="left"><bold>Saturation type</bold></td><td align="left">(1061,1002)</td><td align="left">1</td><td align="left">LO</td><td align="left"><p>Types of saturation transfer</p><p>mechanisms</p></td><td align="left">PVM_SatTransType</td></tr><tr><td align="left"><bold>Pulse shape</bold></td><td align="left">(1061,1003)</td><td align="left">1</td><td align="left">LO</td><td align="left">Shape of the saturation pulse</td><td align="left">PVM_SatTransPulseEnum</td></tr><tr><td align="left"><bold>B1 saturation</bold></td><td align="left">(1061,1004)</td><td align="left">1</td><td align="left">DS</td><td align="left">B1 field of the RF pulse peak amplitude in μT</td><td align="left">PVM_SatTransPulseAmpl_uT</td></tr><tr><td align="left"><bold>Pulse length</bold></td><td align="left">(1061,1005)</td><td align="left">1</td><td align="left">DS</td><td align="left">Length (duration) of the saturation pulse in ms</td><td align="left">PVM_SatTransPulse</td></tr><tr><td align="left"><bold>Pulse number</bold></td><td align="left">(1061,1006)</td><td align="left">1</td><td align="left">DS</td><td align="left">Number of saturation pulses</td><td align="left">PVM_SatTransNPulses</td></tr><tr><td align="left"><bold>Interpulse delay</bold></td><td align="left">(1061,1007)</td><td align="left">1</td><td align="left">DS</td><td align="left">Interval in ms between pulses in a pulsed saturation scheme</td><td align="left">PVM_SatTransInterpulseDelay</td></tr><tr><td align="left"><bold>Saturation length (ms)</bold></td><td align="left">(1061,1008)</td><td align="left">1</td><td align="left">DS</td><td align="left">Pulse Length × Pulse Number</td><td align="left">PVM_SatTransModuleTime</td></tr><tr><td align="left"><bold>Readout time (ms)</bold></td><td align="left">(1061,1009)</td><td align="left">1</td><td align="left">DS</td><td align="left">Time needed for readout</td><td align="left">computed</td></tr><tr><td align="left"><bold>Pulse length 2 (ms)</bold></td><td align="left">(1061,1010)</td><td align="left">1</td><td align="left">DS</td><td align="left">Length of the second saturation pulse in an uneven irradiation scheme</td><td align="left">PVM_SatTransPulseLength2</td></tr><tr><td align="left"><bold>Duty cycle</bold></td><td align="left">(1061,1011)</td><td align="left">1</td><td align="left">DS</td><td align="left">Fraction of one period where the pulse is active</td><td align="left">computed</td></tr><tr><td align="left"><bold>Recovery time (ms)</bold></td><td align="left">(1061,1012)</td><td align="left">1</td><td align="left">DS</td><td align="left">Time between the end of the readout and the beginning of the next saturation (Repetition Time—Pulse Length – Readout Time)</td><td align="left">computed</td></tr><tr><td align="left"><bold>Measurement number</bold></td><td align="left">(1061,1013)</td><td align="left">1</td><td align="left">DS</td><td align="left">Number of frequency offsets</td><td align="left">PVM_NSatFreq</td></tr><tr><td align="left"><bold>Saturation offset (Hz)</bold></td><td align="left">(1061,1014)</td><td align="left">1</td><td align="left">DS</td><td align="left">Frequency offsets list in Hz</td><td align="left">PVM_SatTransFreqValues</td></tr><tr><td align="left"><bold>Saturation offset (ppm)</bold></td><td align="left">(1061,1015)</td><td align="left">1</td><td align="left">DS</td><td align="left">Frequency offsets list in ppm</td><td align="left">Computed if PVM_SatTransFreqUnit = unit_hz, and viceversa</td></tr></tbody></table></table-wrap></p>
      <p id="Par22">Preclinical investigations may cover a wide variability of studies addressing specific scientific questions. Therefore, the data organization is usually tailored to the study of interest and needs to be matched to the XNAT data hierarchy. The capability of XNAT to manage different imaging data structures has then been extended, including longitudinal studies (several timepoints), treatments protocols (control and treated groups) and drug administrations (doses). The flexibility in managing several experimental conditions has been achieved by developing specific custom variables. Besides the default variables, XNAT users can specify an unlimited number of personalized variables. These custom variables can be reused within other projects, allowing for inter-project standardization. For longitudinal studies, three sets of custom variables have been created: the term ‘group’ refers to the treatment protocol and can have two possible values, ‘treated’ or ‘untreated’ (i.e., control group), ‘timepoint’ is related to the timing of the acquisitions (i.e. before (<italic>t</italic><sub>0</sub>) and after (<italic>t</italic><sub>1</sub>, <italic>t</italic><sub>2</sub>) a treatment, or simply different timepoints) and ‘dose’ refers to a specific drug dosage in therapeutic treatment investigations (Fig. <xref rid="Fig3" ref-type="fig">3</xref>). Notably, XNAT-PIC users can adjust the custom variables accordingly to their data structure, provided that the custom variables are at most three and their naming conventions in XNAT are respected.<fig id="Fig3"><label>Fig. 3</label><caption><p>Schematic representation of the custom variables implemented in XNAT to match a typical data organization in preclinical longitudinal studies: ‘group’ refers to treated and untreated mice; ‘timepoints’ is related to the timing of the acquisition: <italic>t</italic>0 = pre, before treatment; <italic>t</italic>1 = post1w, 1 week after; <italic>t</italic>2 = post2w, 2 weeks after; ‘dose’ refers to amount of drug (dose1 and dose2, respectively) used in this specific experiment</p></caption><graphic xlink:href="10278_2022_612_Fig3_HTML" id="MO3"/></fig></p>
    </sec>
    <sec id="Sec5">
      <title>XNAT-PIC Uploader</title>
      <p id="Par23">Upon conversion to DICOM format, the image dataset can be uploaded to XNAT. XNAT-PIC Uploader is designed to perform single subject uploading or batch uploading. It needs the XNAT webpage address and the login details (Fig. <xref rid="Fig4" ref-type="fig">4</xref>A); then, users can generate a new project or choose an existing one in the list (Fig. <xref rid="Fig4" ref-type="fig">4</xref>B), navigate to the directory of interest and enter the number of custom variables (Fig. <xref rid="Fig4" ref-type="fig">4</xref>C). A pop-up message notifies the user once the dataset is successfully imported to XNAT. The original raw images can be eventually uploaded to the database as project level resources.<fig id="Fig4"><label>Fig. 4</label><caption><p>Snapshots of XNAT-PIC Uploader. <bold>A</bold> Accessing XNAT requires the login details, such as the XNAT web address, username, and password; <bold>B</bold> users can create a new project or click the drop-down menu to select an existing project in the list; <bold>C</bold> custom variables can be entered by typing the number of variables in the 1 to 3 range that corresponds to number of folders in the project directory</p></caption><graphic xlink:href="10278_2022_612_Fig4_HTML" id="MO4"/></fig></p>
      <p id="Par24">Preclinical studies may imply the use of several imaging modalities that further increase the complexity of data management, since the same subject can typically undergo several examinations with different imaging instrumentation. For instance, studies that investigate tumor metabolism and acidosis may require the combined use of 18-fluorodeoxyglucose (FDG) PET technique for measuring tumor glucose uptake and CEST-MRI pH imaging for assessing tumor acidosis [<xref ref-type="bibr" rid="CR48">48</xref>, <xref ref-type="bibr" rid="CR51">51</xref>]. The XNAT-PIC Uploader has been designed to upload image datasets of different modalities to XNAT such as MRI, PET, CT and US, allowing users to efficiently manage large, multimodal imaging studies.</p>
      <p id="Par25">The XNAT-PIC Uploader has been tested and validated on several studies, for instance including data gathered from CEST-MRI experiments, in particular GlucoCEST imaging for assessing tumor metabolism following glucose injection [<xref ref-type="bibr" rid="CR52">52</xref>, <xref ref-type="bibr" rid="CR53">53</xref>]. Figure <xref rid="Fig5" ref-type="fig">5</xref> shows a snapshot of the project and subject webpage in XNAT where the custom variables ‘group’ and ‘timepoints’ have been used to describe the GLINT project.<fig id="Fig5"><label>Fig. 5</label><caption><p>Snapshots of the project (panel <bold>A</bold>) and subject (panel <bold>B</bold>) webpage in XNAT with multiple image sessions (MR, CT and PET, respectively). The custom variable ‘group’ describes the patient status (treated or untreated) and is shown at each level of the XNAT data hierarchy, while the custom variable ‘timepoint’ referring to the timing of the treatment administration is displayed at the subject level (panel <bold>B</bold>) in the Label field</p></caption><graphic xlink:href="10278_2022_612_Fig5_HTML" id="MO5"/></fig></p>
    </sec>
    <sec id="Sec6">
      <title>XNAT-PIC Pipelines</title>
      <p id="Par26">One core activity in XNAT is the execution of pipelines. A pipeline is defined as a sequence of steps. Each step of the pipeline invokes an external application, a shell script or an executable for processing the data. The pipeline is executed by the XNAT Pipeline Engine, a Java-based framework efficiently integrated within the XNAT platform [<xref ref-type="bibr" rid="CR15">15</xref>]. The pipeline engine works with simple data flows on a step-by-step basis and can perform computational tasks on project data. The workflow is defined in an eXtensible Markup Language (XML) document named <italic>pipeline descriptor</italic> and the executables are defined in another XML document named <italic>resource descriptors</italic>.</p>
      <p id="Par27">Pipelines need to be enabled through the <italic>Pipelines</italic> tab in the project webpage. By clicking the <italic>Add More Pipelines</italic> button, the <italic>Pipelines</italic> tab will display a table of pipelines currently installed in XNAT. Users can add and configure a pipeline to be registered for the project.</p>
      <p id="Par28">XNAT is currently designed to run pipelines at subject level only. This is not feasible if one needs to process large-scale image datasets. The urgency was therefore to scale up this approach and create pipelines to process an entire project. Our aim was to ensure the same user experience as originally provided by XNAT when launching a pipeline for all the subjects in a project. The main idea was to build a project level pipeline that can be initiated from any subject within the selected project and iterated over all the subjects in that project. MATLAB R2020b scripts previously developed by our group have been used to build pipelines in XNAT and process a variety of MRI acquisitions, such as T<sub>1</sub>/T<sub>2</sub> mapping and diffusion-weighted imaging (DWI). Two approaches have been designed and tested to process these MR images at subject and project level, respectively.</p>
      <sec id="Sec7">
        <title>Subject Level Pipeline</title>
        <p id="Par29">An XNAT pipeline can be launched via the <italic>Run Pipeline</italic> tool in the <italic>Actions Menu</italic> in the MR Session webpage. A pop-up window lists all the pipelines available for that project. This list contains both the pipeline processing only the current subject and the pipeline processing all the subjects in that project. Figure <xref rid="Fig6" ref-type="fig">6</xref> shows a screenshot of the pop-up windows where users can select between two pipelines: <italic>process_T2</italic> processes the T<sub>2</sub> map of the current subject, while <italic>process_T2_project</italic> processes the T<sub>2</sub> maps of all the subjects in the same project. Upon selection of the subject level pipeline, users are then asked via web browser to tick the scan number to be analyzed. The <italic>pipeline descriptor</italic> contains XML instructions to take this user input, create the working directory, download the DICOM files corresponding to the scan of choice, upload the results of the analysis back to XNAT in a dedicated <italic>resource</italic> folder corresponding to the scan of interest and call the <italic>resource descriptor</italic>. The <italic>resource descriptor</italic> invokes a bash script that passes the DICOM files directory to MATLAB running in background to process those images.<fig id="Fig6"><label>Fig. 6</label><caption><p>Screenshot of the pop-up windows with the list of pipelines available for this project. Users can select between two pipelines: <italic>process_T2</italic> processes the T<sub>2</sub> map of the current subject, while <italic>process_T2_project</italic> processes the T<sub>2</sub> maps of all the subjects in the same project</p></caption><graphic xlink:href="10278_2022_612_Fig6_HTML" id="MO6"/></fig></p>
      </sec>
      <sec id="Sec8">
        <title>Project Level Pipeline</title>
        <p id="Par30">Users may need to process all the subjects of a project in a single run. Therefore, they can select a project level pipeline from the <italic>Run Pipeline</italic> pop-up menu.</p>
        <p id="Par31">In this case, the pipeline descriptor contains XML instructions to create the working directories needed for the processing and call the <italic>resource descriptor</italic>. The <italic>resource descriptor</italic> invokes a bash script running a Python wrapper consisting of a sequence of Python scripts in order to:<list list-type="order"><list-item><p id="Par32">Search for the images within the project that have a specific DICOM attribute describing the acquisition protocol of the scans to be processed.</p></list-item><list-item><p id="Par33">For each subject, create a local folder and then download the corresponding DICOM images.</p></list-item><list-item><p id="Par34">Loop over the subjects and locally execute the MATLAB scripts.</p></list-item><list-item><p id="Par35">Upload the results back to XNAT in a <italic>resource</italic> folder created by the pipeline at subject level.</p></list-item></list></p>
        <p id="Par36">In order to run XNAT-PIC pipelines, two scenarios are possible: (i) generic users can register to our CIM-XNAT instance, upload their image datasets and add the pipelines to their own projects (see: Adding Pipelines To Your Project: <ext-link ext-link-type="uri" xlink:href="https://wiki.xnat.org/documentation/how-to-use-xnat/adding-pipelines-to-your-project">https://wiki.xnat.org/documentation/how-to-use-xnat/adding-pipelines-to-your-project</ext-link>); (ii) XNAT Admins can download XNAT-PIC pipelines from <ext-link ext-link-type="uri" xlink:href="https://github.com/szullino/XNAT-PIC-Pipelines">https://github.com/szullino/XNAT-PIC-Pipelines</ext-link>, install and register the pipelines in their own XNAT instance (see: Installing Pipelines in XNAT: <ext-link ext-link-type="uri" xlink:href="https://wiki.xnat.org/documentation/xnat-administration/configuring-the-pipeline-engine/installing-pipelines-in-xnat">https://wiki.xnat.org/documentation/xnat-administration/configuring-the-pipeline-engine/installing-pipelines-in-xnat</ext-link>).</p>
        <p id="Par37">Table <xref rid="Tab2" ref-type="table">2</xref> lists the processing pipelines currently installed on our XNAT deployment and available for download.<table-wrap id="Tab2"><label>Table 2</label><caption><p>Processing pipelines currently installed on our CIM-XNAT 10.1007/s10278-022-00612-z instance (<ext-link ext-link-type="uri" xlink:href="http://cim-xnat.unito.it">http://cim-xnat.unito.it</ext-link>) and available for download at <ext-link ext-link-type="uri" xlink:href="https://github.com/szullino/XNAT-PIC-Pipelines">https://github.com/szullino/XNAT-PIC-Pipelines</ext-link></p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left"><bold>Name</bold></th><th align="left"><bold>Description</bold></th></tr></thead><tbody><tr><td align="left"><bold>Process DWI</bold></td><td align="left">Pipeline processes DWI map</td></tr><tr><td align="left"><bold>Process DWI project</bold></td><td align="left">Pipeline processes all DWI maps in a project</td></tr><tr><td align="left"><bold>Process T1w SR</bold></td><td align="left">Pipeline processes T<sub>1</sub> Saturation Recovery map</td></tr><tr><td align="left"><bold>Process T1w SR project</bold></td><td align="left">Pipeline processes all T<sub>1</sub> Saturation Recovery maps in a project</td></tr><tr><td align="left"><bold>Process T2</bold></td><td align="left">Pipeline processes T<sub>2</sub> map</td></tr><tr><td align="left"><bold>Process T2 project</bold></td><td align="left">Pipeline processes T<sub>2</sub> maps in a project</td></tr><tr><td align="left"><bold>Mask Average</bold></td><td align="left">Pipeline computes a mean value in the ROI</td></tr></tbody></table></table-wrap></p>
        <p id="Par38">In Fig. <xref rid="Fig7" ref-type="fig">7</xref>, the workflow for processing DWI acquisitions is schematically presented. Post-processed image data and other files are uploaded back to XNAT in the resource folder created at subject level or scan level, according to the full project or standard subject pipeline respectively, and accessible by the user through a <italic>Manage Files</italic> console. The resource folder can contain several subfolders, each of them populated with several files, such as parametric images in several file formats (i.e. NIfTI), MATLAB workspace and log files.<fig id="Fig7"><label>Fig. 7</label><caption><p>Schematic workflow of the <italic>process_DWI</italic> pipeline which retrieves, downloads, and processes the MRI diffusion scan. The output files (text file, log file, NIfTI images and MATLAB workspace) are then uploaded back to XNAT under the corresponding subject, experiment, and scan. This workflow is iterated when the project level <italic>process_DWI_project</italic> pipeline is launched to process all the MRI diffusion scans contained in the project; then, the resource folder is created at subject level</p></caption><graphic xlink:href="10278_2022_612_Fig7_HTML" id="MO7"/></fig></p>
      </sec>
      <sec id="Sec9">
        <title>Mask Average Pipeline</title>
        <p id="Par39">Following the processing, preclinical imaging users are usually interested in performing some simple statistics on the processed images. We have therefore developed a pipeline that applies a mask to a parametric map and compute the mean value in the ROI. Therefore, the XNAT OHIF Viewer 2.0 Plugin has been installed on our XNAT instance [<xref ref-type="bibr" rid="CR54">54</xref>]. The plugin is an integration of the Open Health Imaging Foundation (OHIF) viewer into XNAT [<xref ref-type="bibr" rid="CR55">55</xref>]. Users can create contour-based, such as DICOM RTSTRUCT and Annotation Image Markup (AIM) as well as mask-based DICOM Segmentation (DICOM SEG) ROI Collections, and import/export them to a ROI Collection Assessors in XNAT (Fig. <xref rid="Fig8" ref-type="fig">8</xref>). Once the ROI has been drawn on the T<sub>2</sub>-weighted image and stored to XNAT, the <italic>Mask_Average</italic> pipeline can be launched from the <italic>Run Pipeline</italic> tool. The <italic>pipeline descriptor</italic> contains XML instructions to take the scans corresponding both to the T<sub>2</sub>-weighted acquisition and the parametric map in the resource folder, download the morphological image in DICOM standard and the parametric image in NIfTI format corresponding to the user selection, download the ROI Collection Assessors, create the working directory, upload the results of the analysis back to XNAT in a dedicated <italic>resource</italic> folder corresponding to the scan of interest and call the <italic>resource descriptor</italic>. The <italic>resource descriptor</italic> invokes a bash script passing both the T<sub>2</sub>-weighted DICOM image and the DICOM RT-STRUCT directories to a Python code to be converted into a NIfTI mask by the Python package dcmrtstruct2nii [<xref ref-type="bibr" rid="CR56">56</xref>]. The same bash script passes the resulting mask to a Python script that computes statistical calculations in the ROI and uploads the results back to the database as XNAT resources (Fig. <xref rid="Fig9" ref-type="fig">9</xref>). A typical output of the <italic>Mask_Average</italic> pipeline is shown in Fig. <xref rid="Fig10" ref-type="fig">10</xref>. The XNAT-OHIF plugin is used to draw the ROIs corresponding to the mouse kidneys on the T<sub>2</sub>-weighted l image (Fig. <xref rid="Fig10" ref-type="fig">10</xref>A). The full T<sub>2</sub> map obtained from the <italic>process_T2</italic> pipeline along with the relative T<sub>2</sub> map after masking are shown in Fig. <xref rid="Fig10" ref-type="fig">10</xref>B, C, respectively. A text file with the result of the calculation is depicted in Fig. <xref rid="Fig10" ref-type="fig">10</xref>D.<fig id="Fig8"><label>Fig. 8</label><caption><p>Snapshot of the ROI Collection Assessor webpage in XNAT. The mask represented here is composed by two ROIs, tumor1 and tumor2 respectively, and is saved in the DICOM RT-STRUCT file that needs to be converted in NIfTI format before usage</p></caption><graphic xlink:href="10278_2022_612_Fig8_HTML" id="MO8"/></fig><fig id="Fig9"><label>Fig. 9</label><caption><p>Schematic workflow of the <italic>Mask_Average</italic> pipeline that applies a mask to a parametric map in NIfTI format, computes the mean value in the ROI and uploads the masked parametric map and other output files back to XNAT</p></caption><graphic xlink:href="10278_2022_612_Fig9_HTML" id="MO9"/></fig><fig id="Fig10"><label>Fig. 10</label><caption><p>Outputs generated from the <italic>Mask_Average</italic> pipeline. <bold>A</bold> Reference anatomic T<sub>2</sub>-weighted axial image showing kidneys and corresponding ROIs. <bold>B</bold> T<sub>2</sub> map obtained from <italic>process_T2</italic> pipeline. <bold>C</bold>) The mask is applied to the obtained T<sub>2</sub> map showing only the kidneys. <bold>D</bold>) Output text file reporting statistics for each ROI</p></caption><graphic xlink:href="10278_2022_612_Fig10_HTML" id="MO10"/></fig></p>
      </sec>
    </sec>
  </sec>
  <sec id="Sec10">
    <title>Discussion</title>
    <p id="Par40">Preclinical imaging facilities are usually equipped with a variety of imaging devices, each of them yielding large amounts of data usually stored in several workstations. Storing and sharing preclinical data in a safe, fast and reliable manner is therefore imperative. Furthermore, image analysis is of utmost importance in preclinical applications to unravel the physiological mechanisms of the disease process or investigate the response to a new therapeutic treatment. Despite the urgent needs, few efforts have been done so far to manage preclinical imaging studies and ensure reproducibility through highly standardized image processing methods.</p>
    <p id="Par41">In this work, we have developed XNAT-PIC, a free and open-source application consisting of a MR image converter from proprietary file format to DICOM standard, an uploader to import large and multi-modal imaging studies to XNAT and a catalogue of pipelines for processing preclinical image datasets. MRI2DICOM is a MR image converter from ParaVision<sup>®</sup> file format to DICOM that takes into account emerging MRI methods such as CEST imaging. A controlled vocabulary has been created for the first time to describe CEST-MRI acquisitions. The entries are extracted from the raw image files and used to feed a new, private DICOM dictionary specifically created for this IOD. These DICOM attributes can be then easily accessed and reused by external applications for post-processing. XNAT-PIC Uploader has been designed to overcome an XNAT limitation regarding data upload. There are several options for uploading image sessions in XNAT: the XNAT Desktop Client and the XNAT Upload Assistant are stand-alone applications that can be installed for uploading and downloading data, while the XNAT Compressed Uploader is a tool that runs in the XNAT browser and does not require installation. Other options are the DICOM C-STORE Service Class Provider that can send data directly to the XNAT server and the representational state transfer (REST) API import service, the latter not applicable by non-expert users. To our knowledge, none of these methods is capable of uploading multiple subjects of different imaging modalities. The XNAT-PIC Uploader offers the possibility to upload several subjects screened with different modalities (i.e. MRI, PET, CT and US) related to the same project in a single run through a user-friendly graphical interface. The imaging modalities that can be uploaded using the XNAT-PIC Uploader are the ones currently supported by XNAT, such as MRI, CT, PET and US, for which the DICOM standard fully applies. The use of DICOM for preclinical research applications has been inhibited by the complexity of the standard, the limited awareness of its potential, and the demanding resources for its maintenance. Future work will be needed to include new data types into XNAT related to emerging imaging technologies that are popular in preclinical research, such as PAI and OI. This effort needs to resonate with the development of the DICOM standard and its adoption by the imaging device manufacturers. Indeed, some vendors currently use the US IOD to store PAI objects, while OI is still referred to other (OT). Nevertheless, OI in DICOM falls into the Visible Light IOD as defined in DICOM Part 3: Information Object Definitions, section A.32 ‘Visible Light Information Object Definitions’ [<xref ref-type="bibr" rid="CR57">57</xref>]. The DICOM Standard Committee has established more than thirty Working Groups to expand the Standard for a particular imaging modality, clinical domain or technical field. Importantly, DICOM Working Group 34 ‘Photoacoustic’ is extending the DICOM standard to support PAI [<xref ref-type="bibr" rid="CR57">57</xref>]. Similarly, the DICOM Working Group 30 “Small Animal Imaging” aims at extending and promoting the use of DICOM in preclinical imaging research [<xref ref-type="bibr" rid="CR59">59</xref>]. At present, the list of DICOM IODs is available in DICOM Part 3: Information Object Definitions, Section C.7.3.1.1.1 ‘Modality’ [<xref ref-type="bibr" rid="CR58">58</xref>]. Lastly, XNAT-PIC includes a collection of processing methods routinely used in preclinical imaging such as T<sub>1</sub> and T<sub>2</sub> mapping and DWI, with the aim to extend the offer of XNAT pipelines to other MRI techniques, firstly the emerging CEST-MRI imaging. XNAT-PIC Pipelines are built on top of the XNAT Pipeline Engine which reads an XML document and launches a sequence of steps defined in the XML document. The drawback of this approach is that all the executables and their dependencies have to be pre-installed on the local XNAT instance where the pipeline will be executed. This process requires the intervention of a system administrator. The XNAT Container Service Plugin was released in 2017 and leverages Docker. The operating system with all the executables needs to be packaged and the resulting image can be registered as container to the XNAT site. Unlike an XML pipeline, the Container Service requires a command json file with instruction on which container to use, what is the input and how to handle the output. The advantage of containerization technology relies on the flexibility to distribute and manage such kind of workflow. Since XNAT Container Service Plugin is becoming popular, containerized versions of the XNAT-PIC Pipelines will be developed in the future by our group. Likewise, our intent is to improve the reproducibility of preclinical research and guarantee standardized image processing procedures by offering a free service to integrate custom-built analysis pipeline in the XNAT-PIC workflow upon user request.</p>
    <p id="Par42">The Small Animal Shanoir is another preclinical research solution developed to manage and process imaging datasets. It offers a platform to store and distribute the data, manage the metadata associated to the study and process the images on high performance systems. In addition, the possibility to integrate custom-made processing pipelines and algorithms into SAS provides the reproducibility and accessibility of the research outputs. However, these services are subject to fees for both storage and processing. Interestingly, SAS architecture is based on micro-services, allowing SAS to function as a combination of independent structures that can be easily updated with new features or scaled up. Current, available micro-services in SAS comprise Dicomifier, a generic and open-source Bruker to DICOM or NIfTI converter, and applications to extract T<sub>1</sub> and T<sub>2</sub> relaxation times from MR image data. Recently, other commercial data management systems have been also introduced in preclinical imaging. The Small Animal Big-data warehouse Environment for Research (SABER) supports preclinical workflow and promotes data sharing, although this platform is unavailable on the internet. Flywheel is a commercial data management system to store research data of different imaging modalities in a centralized archive, thus improving productivity and collaboration in life science research [<xref ref-type="bibr" rid="CR60">60</xref>, <xref ref-type="bibr" rid="CR61">61</xref>].</p>
    <p id="Par43">The urgent need to develop the infrastructure and services to support sharing and reusing of scholarly data motivated the establishment of the Findable, Accessible, Interoperable and Reusable (FAIR) Data Principle [<xref ref-type="bibr" rid="CR62">62</xref>]. These rules are necessary to govern the scientific data management and stewardship and are applicable to several entities, such as industry, academia, scientific publishers and funding agencies. The principles may serve as guidance for stakeholders willing to strengthen their data reusability. Unlike similar initiatives committed to human scholarly work, the FAIR Principles are intended to make the data discoverable and readable by both individuals and machines, therefore supporting their reuse [<xref ref-type="bibr" rid="CR62">62</xref>, <xref ref-type="bibr" rid="CR63">63</xref>]. XNAT-PIC was developed in the framework of the demonstrator projects under the auspices of EOSC-Life, a European Union’s Horizon 2020 research and innovation programme. XNAT-PIC is supported by the Multi-Modal Molecular Imaging Italian Node (MMMI) of Euro-BioImaging ERIC, a research infrastructure that offers open access to the most advanced imaging technologies, training and data services in biological and biomedical imaging [<xref ref-type="bibr" rid="CR64">64</xref>]. In this scenario, XNAT-PIC acts as a first step towards data FAIRification in terms of Accessibility and Reusability. Generally, the data stored in an XNAT-based system is accessible upon authentication and authorization procedure: only trusted users have rights to access, manipulate and work with images. Data, tools and processing pipelines developed in XNAT-PIC are fully reusable as they are distributed under GNU General Public License v3 or any later version and available on GitHub. Some work needs still to be done regarding Findability and Interoperability. To date, the possibility to associate the dataset stored in XNAT with a digital object identifier (DOI) or Persistent Identifier is missing, preventing the data to be found by both humans and computers. In addition, machine-readable metadata that are necessary for data discovery are still needed.</p>
    <p id="Par44">The European Open Science Cloud (EOSC) is an EU-funded project based on FAIR principles whose goal is to provide a public data repository compliant to open science principles. EOSC aims at providing ‘all researchers in Europe with seamless access to an open-by-default, efficient and cross-disciplinary environment for storing, accessing, reusing, and processing research data supported by FAIR data principles’ as stated in The Vienna Declaration on the European Open Science Cloud [<xref ref-type="bibr" rid="CR65">65</xref>]. Therefore, all the research materials that relate to scholarly data must be turned into FAIR. This includes the raw material, such as imaging dataset, as well as the tools, workflows and pipelines needed to process the data, allowing to extract and quantify the information. The FAIR revolution also involves the standards, metadata, and ontologies that are necessary to provide significance to both the data itself and any complementary material.</p>
    <p id="Par45">The portfolio of tools devoted to preclinical imaging in XNAT-PIC will be expanded by developing open-source converters for proprietary MR image data formats, such as Aspect Imaging, to DICOM standard and novel MR image processing scripts. Our future plan is to deploy a federated XNAT portal to collect preclinical imaging data from local XNAT installations and make them available to a broader community. The imaging community will largely benefit from this free, cloudified service, since it will enable users to discover image datasets normally not accessible, promoting the free exchange and reuse of data and ensuring higher standards of reproducibility of the experiments.</p>
  </sec>
  <sec id="Sec11">
    <title>Conclusion</title>
    <p id="Par46">While the basic XNAT deployment serves as a system for safely accessing, archiving, and processing clinical imaging studies, XNAT-PIC widens its core features in several ways to support preclinical imaging facilities. Our aim is to overcome the current limitations that arise from the management and the storage of preclinical imagery, thereby facilitating the analysis of biomedical image data.</p>
    <p id="Par47">The advantage of this approach relies in the capability to interface with several imaging modalities, including emerging imaging techniques such as CEST-MRI, manage different preclinical investigation protocols and easily process preclinical image data. We believe that such a workflow may be of interest for preclinical imaging centers, thus allowing the scientific community to efficiently store, process and share biomedical imaging data.</p>
  </sec>
</body>
<back>
  <fn-group>
    <fn>
      <p>
        <bold>Publisher's Note</bold>
      </p>
      <p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
    </fn>
  </fn-group>
  <ack>
    <title>Acknowledgements</title>
    <p>The authors gratefully acknowledge Alessandra Viale (Euro-BioImaging ERIC Med-Hub, Torino) for her encouragement and support in the realization of the project; Stefan Klein, Hakim Achterberg and Marcel Koek (Biomedical Imaging Group Rotterdam, Erasmus Medical Center, Rotterdam) for many fruitful discussions.</p>
  </ack>
  <notes notes-type="author-contribution">
    <title>Author Contribution</title>
    <p>The authors confirm contribution to the paper as follows: S.Z. designed and implemented the project, wrote the code, performed the analysis and drafted the manuscript. A.P. and W.D. contributed to coding and reviewed the manuscript. D.L.L. conceived the study, contributed to coding, interpreted the results and reviewed the manuscript. S.A. supervised the project and reviewed the manuscript. All authors discussed the results and approved the final manuscript.</p>
  </notes>
  <notes notes-type="funding-information">
    <title>Funding</title>
    <p> This project has received funding from the European Union’s Horizon 2020 research and innovation programmes under grant agreement no. 824087 EOSC-Life, no. 654248 CORBEL, no. 667510 GLINT. The Italian Ministry for Education and Research (MIUR) is gratefully acknowledged for yearly FOE funding to the Euro-BioImaging Multi-sited Multi-Modal Molecular Imaging Italian Node (MMMI).</p>
  </notes>
  <notes notes-type="data-availability">
    <title>Availability of Data and Material</title>
    <p>The datasets analyzed in the current study are openly available in the CIM-XNAT repository, <ext-link ext-link-type="uri" xlink:href="http://cim-xnat.unito.it/">http://cim-xnat.unito.it/</ext-link>. Users can access CIM-XNAT with the following credentials: username: xnat-pic-guest, password: preclinical. Upon login, you will be redirect to the XNAT webpage containing two projects related to the data presented in this work.</p>
  </notes>
  <notes notes-type="data-availability">
    <title>Code Availability </title>
    <p>The latest releases of the source codes of XNAT-PIC are available to download from the GitHub repositories <ext-link ext-link-type="uri" xlink:href="https://github.com/szullino/XNAT-PIC-Pipelines">https://github.com/szullino/XNAT-PIC-Pipelines</ext-link> and <ext-link ext-link-type="uri" xlink:href="https://github.com/szullino/XNAT-PIC">https://github.com/szullino/XNAT-PIC</ext-link>. Updates regarding this project are available at: <ext-link ext-link-type="uri" xlink:href="https://www.cim.unito.it/website/research/research_xnat.php">https://www.cim.unito.it/website/research/research_xnat.php</ext-link>. XNAT-PIC is a free software and is distributed under the terms of the GNU General Public License v3 or any later version as stated by the Free Software Foundation.</p>
  </notes>
  <notes>
    <title>Declarations</title>
    <notes id="FPar1">
      <title>Ethics Approval</title>
      <p id="Par48">Not applicable.</p>
    </notes>
    <notes id="FPar2">
      <title>Consent to Participate</title>
      <p id="Par49">Not applicable.</p>
    </notes>
    <notes id="FPar3">
      <title>Consent for Publication</title>
      <p id="Par50">Not Applicable.</p>
    </notes>
    <notes id="FPar4" notes-type="COI-statement">
      <title>Conflict of Interest</title>
      <p id="Par51">The authors declare no competing interests.</p>
    </notes>
  </notes>
  <glossary>
    <title>Abbreviations</title>
    <def-list>
      <def-item>
        <term>ADNI</term>
        <def>
          <p id="Par52">Alzheimer’s Disease Neuroimaging Initiative</p>
        </def>
      </def-item>
      <def-item>
        <term>AIM</term>
        <def>
          <p id="Par53">Annotation Image Markup</p>
        </def>
      </def-item>
      <def-item>
        <term>API</term>
        <def>
          <p id="Par54">Application programming interface</p>
        </def>
      </def-item>
      <def-item>
        <term>CEST</term>
        <def>
          <p id="Par55">Chemical exchange saturation transfer</p>
        </def>
      </def-item>
      <def-item>
        <term>CIM</term>
        <def>
          <p id="Par56">Molecular Imaging Center</p>
        </def>
      </def-item>
      <def-item>
        <term>COINS</term>
        <def>
          <p id="Par57">Collaborative Informatics and Neuroimaging Suite</p>
        </def>
      </def-item>
      <def-item>
        <term>CT</term>
        <def>
          <p id="Par58">Computed tomography</p>
        </def>
      </def-item>
      <def-item>
        <term>DICOM</term>
        <def>
          <p id="Par59">Digital Imaging and COmmunications in Medicine</p>
        </def>
      </def-item>
      <def-item>
        <term>DICOM SEG</term>
        <def>
          <p id="Par60">DICOM Segmentation</p>
        </def>
      </def-item>
      <def-item>
        <term>DOI</term>
        <def>
          <p id="Par61">Digital object identifier</p>
        </def>
      </def-item>
      <def-item>
        <term>DS</term>
        <def>
          <p id="Par62">Decimal string</p>
        </def>
      </def-item>
      <def-item>
        <term>DWI</term>
        <def>
          <p id="Par63">Diffusion-weighted imaging</p>
        </def>
      </def-item>
      <def-item>
        <term>EOSC</term>
        <def>
          <p id="Par64">European Open Science Cloud</p>
        </def>
      </def-item>
      <def-item>
        <term>EPI2</term>
        <def>
          <p id="Par65">European Population Imaging Infrastructure</p>
        </def>
      </def-item>
      <def-item>
        <term>FAIR</term>
        <def>
          <p id="Par66">Findable, Accessible, Interoperable and Reusable</p>
        </def>
      </def-item>
      <def-item>
        <term>FDG</term>
        <def>
          <p id="Par67">18-Fluorodeoxyglucose</p>
        </def>
      </def-item>
      <def-item>
        <term>FLI</term>
        <def>
          <p id="Par68">France Life Imaging</p>
        </def>
      </def-item>
      <def-item>
        <term>HID</term>
        <def>
          <p id="Par69">Human Imaging Database</p>
        </def>
      </def-item>
      <def-item>
        <term>HTTP</term>
        <def>
          <p id="Par70">Hypertext Transfer Protocol</p>
        </def>
      </def-item>
      <def-item>
        <term>IOD</term>
        <def>
          <p id="Par71">Information Object Definition</p>
        </def>
      </def-item>
      <def-item>
        <term>LO</term>
        <def>
          <p id="Par72">Long string</p>
        </def>
      </def-item>
      <def-item>
        <term>LORIS</term>
        <def>
          <p id="Par73">Longitudinal Online Research and Imaging System</p>
        </def>
      </def-item>
      <def-item>
        <term>MIRMAID</term>
        <def>
          <p id="Par74">Medical Imaging Research Management and Associated Information Database</p>
        </def>
      </def-item>
      <def-item>
        <term>MMMI</term>
        <def>
          <p id="Par75">Multi-sited Multi-Modal Molecular Imaging Italian Node</p>
        </def>
      </def-item>
      <def-item>
        <term>MRI</term>
        <def>
          <p id="Par76">Magnetic resonance imaging</p>
        </def>
      </def-item>
      <def-item>
        <term>NIfTI</term>
        <def>
          <p id="Par77">Neuroimaging Informatics Technology Initiative</p>
        </def>
      </def-item>
      <def-item>
        <term>OASIS</term>
        <def>
          <p id="Par78">Open Access Series of Imaging Studies</p>
        </def>
      </def-item>
      <def-item>
        <term>OCT</term>
        <def>
          <p id="Par79">Optical coherence tomography</p>
        </def>
      </def-item>
      <def-item>
        <term>OHIF</term>
        <def>
          <p id="Par80">Open Health Imaging Foundation</p>
        </def>
      </def-item>
      <def-item>
        <term>OI</term>
        <def>
          <p id="Par81">Optical Imaging</p>
        </def>
      </def-item>
      <def-item>
        <term>OT</term>
        <def>
          <p id="Par82">Other</p>
        </def>
      </def-item>
      <def-item>
        <term>PACS</term>
        <def>
          <p id="Par83">Picture archiving and communication system</p>
        </def>
      </def-item>
      <def-item>
        <term>PAI</term>
        <def>
          <p id="Par84">Photoacoustic imaging</p>
        </def>
      </def-item>
      <def-item>
        <term>PET</term>
        <def>
          <p id="Par85">Positron emission tomography</p>
        </def>
      </def-item>
      <def-item>
        <term>REST</term>
        <def>
          <p id="Par86">Representational state transfer</p>
        </def>
      </def-item>
      <def-item>
        <term>ROI</term>
        <def>
          <p id="Par87">Region of interest</p>
        </def>
      </def-item>
      <def-item>
        <term>RTSTRUCT</term>
        <def>
          <p id="Par88">Radiotherapy Structure Set</p>
        </def>
      </def-item>
      <def-item>
        <term>SABER</term>
        <def>
          <p id="Par89">Small Animal Big-data warehouse Environment for Research</p>
        </def>
      </def-item>
      <def-item>
        <term>SAS</term>
        <def>
          <p id="Par90">Small Animal Shanoir</p>
        </def>
      </def-item>
      <def-item>
        <term>SCP</term>
        <def>
          <p id="Par91">Service Class Provider</p>
        </def>
      </def-item>
      <def-item>
        <term>SPECT</term>
        <def>
          <p id="Par92">Single-photon emission computed tomography</p>
        </def>
      </def-item>
      <def-item>
        <term>TCIA</term>
        <def>
          <p id="Par93">The Cancer Imaging Archive</p>
        </def>
      </def-item>
      <def-item>
        <term>VM</term>
        <def>
          <p id="Par94">Value multiplicity</p>
        </def>
      </def-item>
      <def-item>
        <term>VR</term>
        <def>
          <p id="Par95">Value representation</p>
        </def>
      </def-item>
      <def-item>
        <term>XML</term>
        <def>
          <p id="Par96">EXtensible Markup Language</p>
        </def>
      </def-item>
      <def-item>
        <term>XNAT</term>
        <def>
          <p id="Par97">The Extensible Neuroimaging Archive Toolkit</p>
        </def>
      </def-item>
      <def-item>
        <term>XNAT-PIC</term>
        <def>
          <p id="Par98">XNAT for Preclinical Imaging Center</p>
        </def>
      </def-item>
    </def-list>
  </glossary>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <label>1.</label>
      <mixed-citation publication-type="other">F. Kiessling and B. J. Pichler, Eds., <italic>Small Animal Imaging: Basics and Practical Guide</italic>, 2nd Ed. Springer, 2017. 10.1007/978-3-642-12945-2.</mixed-citation>
    </ref>
    <ref id="CR2">
      <label>2.</label>
      <mixed-citation publication-type="other">J. K. Willmann, N. van Bruggen, L. M. Dinkelborg, and S. S. Gambhir, “Molecular imaging in drug development,” <italic>Nature Reviews Drug Discovery</italic>, vol. 7, no. 7. Nature Publishing Group, pp. 591–607, Jul. 01, 2008. 10.1038/nrd2290.</mixed-citation>
    </ref>
    <ref id="CR3">
      <label>3.</label>
      <mixed-citation publication-type="other">J. Ellenberg <italic>et al.</italic>, “A call for public archives for biological image data,” <italic>Nature Methods</italic>, vol. 15, no. 11. Nature Publishing Group, pp. 849–854, Nov. 01, 2018. 10.1038/s41592-018-0195-8.</mixed-citation>
    </ref>
    <ref id="CR4">
      <label>4.</label>
      <mixed-citation publication-type="other">E. Williams <italic>et al.</italic>, “Image Data Resource: A bioimage data integration and publication platform,” <italic>Nature Methods</italic>, vol. 14, no. 8, pp. 775–781, Jul. 2017. 10.1038/nmeth.4326.</mixed-citation>
    </ref>
    <ref id="CR5">
      <label>5.</label>
      <mixed-citation publication-type="other">S. Adebayo <italic>et al.</italic>, “PhenoImageShare: An image annotation and query infrastructure,” <italic>Journal of Biomedical Semantics</italic>, vol. 7, no. 1, p. 35, Jun. 2016. 10.1186/S13326-016-0072-2.</mixed-citation>
    </ref>
    <ref id="CR6">
      <label>6.</label>
      <mixed-citation publication-type="other">“The Human Connectome Project.” <ext-link ext-link-type="uri" xlink:href="http://www.humanconnectomeproject.org/">http://www.humanconnectomeproject.org/</ext-link></mixed-citation>
    </ref>
    <ref id="CR7">
      <label>7.</label>
      <mixed-citation publication-type="other">K. Clark <italic>et al.</italic>, “The cancer imaging archive (TCIA): Maintaining and operating a public information repository,” <italic>Journal of Digital Imaging</italic>, vol. 26, no. 6, pp. 1045–1057, Dec. 2013. 10.1007/s10278-013-9622-7.</mixed-citation>
    </ref>
    <ref id="CR8">
      <label>8.</label>
      <mixed-citation publication-type="other">S. G. Mueller <italic>et al.</italic>, “The Alzheimer’s disease neuroimaging initiative,” <italic>Neuroimaging Clinics of North America</italic>, vol. 15, no. 4. Elsevier, pp. 869–877, Nov. 01, 2005. 10.1016/j.nic.2005.09.008.</mixed-citation>
    </ref>
    <ref id="CR9">
      <label>9.</label>
      <mixed-citation publication-type="other">D. S. Marcus, T. H. Wang, J. Parker, J. G. Csernansky, J. C. Morris, and R. L. Buckner, “Open Access Series of Imaging Studies (OASIS): Cross-sectional MRI data in young, middle aged, nondemented, and demented older adults,” <italic>Journal of Cognitive Neuroscience</italic>, vol. 19, no. 9, pp. 1498–1507, Sep. 2007. 10.1162/jocn.2007.19.9.1498.</mixed-citation>
    </ref>
    <ref id="CR10">
      <label>10.</label>
      <mixed-citation publication-type="other">S. Das, A. P. Zijdenbos, J. Harlap, D. Vins, and A. C. Evans, “LORIS: a web-based data management system for multi-center studies,” <italic>Frontiers in Neuroinformatics</italic>, vol. 5, no. JANUARY 2012, p. 37, Jan. 2012. 10.3389/fninf.2011.00037.</mixed-citation>
    </ref>
    <ref id="CR11">
      <label>11.</label>
      <mixed-citation publication-type="other">I. B. Ozyurt <italic>et al.</italic>, “Federated web-accessible clinical data management within an extensible neuroimaging database,” <italic>Neuroinformatics</italic>, vol. 8, no. 4, pp. 231–249, Dec. 2010. 10.1007/s12021-010-9078-6.</mixed-citation>
    </ref>
    <ref id="CR12">
      <label>12.</label>
      <mixed-citation publication-type="other">A. Scott <italic>et al.</italic>, “Coins: An innovative informatics and neuroimaging tool suite built for large heterogeneous datasets,” <italic>Frontiers in Neuroinformatics</italic>, vol. 5, Dec. 2011. 10.3389/fninf.2011.00033.</mixed-citation>
    </ref>
    <ref id="CR13">
      <label>13.</label>
      <mixed-citation publication-type="other">P. D. Korfiatis, T. L. Kline, D. J. Blezek, S. G. Langer, W. J. Ryan, and B. J. Erickson, “MIRMAID: A Content Management System for Medical Image Analysis Research,” <italic>RadioGraphics</italic>, vol. 35, no. 5, pp. 1461–1468, Sep. 2015. 10.1148/rg.2015140031.</mixed-citation>
    </ref>
    <ref id="CR14">
      <label>14.</label>
      <mixed-citation publication-type="other">C. Anastasopoulos, M. Reisert, and E. Kellner, “‘Nora Imaging’: A Web-Based Platform for Medical Imaging,” <italic>Neuropediatrics</italic>, vol. 48, no. S 01, pp. S1–S45, Apr. 2017. 10.1055/s-0037-1602977.</mixed-citation>
    </ref>
    <ref id="CR15">
      <label>15.</label>
      <mixed-citation publication-type="other">D. S. Marcus, T. R. Olsen, M. Ramaratnam, and R. L. Buckner, “The extensible neuroimaging archive toolkit: An informatics platform for managing, exploring, and sharing neuroimaging data,” <italic>Neuroinformatics</italic>, vol. 5, no. 1, pp. 11–33, 2007. 10.1385/NI:5:1:11.</mixed-citation>
    </ref>
    <ref id="CR16">
      <label>16.</label>
      <mixed-citation publication-type="other">“The Extensible Neuroimaging Archive Toolkit (XNAT).” <ext-link ext-link-type="uri" xlink:href="http://xnat.org/">http://xnat.org/</ext-link></mixed-citation>
    </ref>
    <ref id="CR17">
      <label>17.</label>
      <mixed-citation publication-type="other">S. J. Doran <italic>et al.</italic>, “Informatics in Radiology: Development of a Research PACS for Analysis of Functional Imaging Data in Clinical Research and Clinical Trials,” <italic>RadioGraphics</italic>, vol. 32, no. 7, pp. 2135–2150, 2012. 10.1148/rg.327115138.</mixed-citation>
    </ref>
    <ref id="CR18">
      <label>18.</label>
      <mixed-citation publication-type="other">T. Doel <italic>et al.</italic>, “GIFT-Cloud: A data sharing and collaboration platform for medical imaging research,” 2016. 10.1016/j.cmpb.2016.11.004.</mixed-citation>
    </ref>
    <ref id="CR19">
      <label>19.</label>
      <mixed-citation publication-type="other">J. Wu, C. Jansen, M. Beier, M. Witt, and D. Krefting, “Extending XNAT towards a Cloud-Based Quality Assessment Platform for Retinal Optical Coherence Tomographies,” in <italic>2014 14th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing</italic>, May 2014, pp. 764–773. 10.1109/CCGrid.2014.103.</mixed-citation>
    </ref>
    <ref id="CR20">
      <label>20.</label>
      <mixed-citation publication-type="other">M. Beier <italic>et al.</italic>, “Multicenter data sharing for collaboration in sleep medicine,” <italic>Future Generation Computer Systems</italic>, vol. 67, pp. 466–480, Feb. 2017. 10.1016/j.future.2016.03.025.</mixed-citation>
    </ref>
    <ref id="CR21">
      <label>21.</label>
      <mixed-citation publication-type="other">P. Kalendralis <italic>et al.</italic>, “Multicenter CT phantoms public dataset for radiomics reproducibility tests,” <italic>Medical Physics</italic>, vol. 46, no. 3, pp. 1512–1518, Mar. 2019. 10.1002/mp.13385.</mixed-citation>
    </ref>
    <ref id="CR22">
      <label>22.</label>
      <mixed-citation publication-type="other">“The European Population Imaging Infrastructure (EPI2).” <ext-link ext-link-type="uri" xlink:href="http://populationimaging.eu/">http://populationimaging.eu/</ext-link></mixed-citation>
    </ref>
    <ref id="CR23">
      <label>23.</label>
      <mixed-citation publication-type="other">H. C. Achterberg, M. Koek, and W. J. Niessen, “Fastr: A Workflow Engine for Advanced Data Flows in Medical Image Analysis,” <italic>Frontiers in ICT</italic>, vol. 3, p. 15, Aug. 2016. 10.3389/fict.2016.00015.</mixed-citation>
    </ref>
    <ref id="CR24">
      <label>24.</label>
      <mixed-citation publication-type="other">“Health-RI XNAT.” <ext-link ext-link-type="uri" xlink:href="https://www.health-ri.nl/services/xnat">https://www.health-ri.nl/services/xnat</ext-link></mixed-citation>
    </ref>
    <ref id="CR25">
      <label>25.</label>
      <mixed-citation publication-type="other">S. Klein, E. Vast, J. van Soest, A. Dekker, M. Koek, and W. Niessen, “XNAT imaging platform for BioMedBridges and CTMM TraIT,” <italic>Journal of Clinical Bioinformatics</italic>, vol. 5, no. Suppl 1, p. S18, May 2015. 10.1186/2043-9113-5-s1-s18.</mixed-citation>
    </ref>
    <ref id="CR26">
      <label>26.</label>
      <mixed-citation publication-type="other">M. Kain <italic>et al.</italic>, “Small Animal Shanoir (SAS) A Cloud-Based Solution for Managing Preclinical MR Brain Imaging Studies,” <italic>Frontiers in Neuroinformatics</italic>, vol. 14, p. 20, May 2020. 10.3389/fninf.2020.00020.</mixed-citation>
    </ref>
    <ref id="CR27">
      <label>27.</label>
      <mixed-citation publication-type="other">C. Barillot <italic>et al.</italic>, “Shanoir: Applying the Software as a Service Distribution Model to Manage Brain Imaging Research Repositories,” <italic>Frontiers in ICT</italic>, vol. 3, no. DEC, p. 25, Dec. 2016. 10.3389/fict.2016.00025.</mixed-citation>
    </ref>
    <ref id="CR28">
      <label>28.</label>
      <mixed-citation publication-type="other">“Digital Imaging and COmmunications in Medicine (DICOM).” <ext-link ext-link-type="uri" xlink:href="https://www.dicomstandard.org/">https://www.dicomstandard.org/</ext-link></mixed-citation>
    </ref>
    <ref id="CR29">
      <label>29.</label>
      <mixed-citation publication-type="other">“Neuroimaging Informatics Technology Initiative (NIfTI).” <ext-link ext-link-type="uri" xlink:href="https://nifti.nimh.nih.gov/">https://nifti.nimh.nih.gov/</ext-link></mixed-citation>
    </ref>
    <ref id="CR30">
      <label>30.</label>
      <mixed-citation publication-type="other">P. Mildenberger, M. Eichelberg, and E. Martin, “Introduction to the DICOM standard,” <italic>European Radiology</italic>, vol. 12, no. 4. Springer, pp. 920–927, Apr. 01, 2002. 10.1007/s003300101100.</mixed-citation>
    </ref>
    <ref id="CR31">
      <label>31.</label>
      <mixed-citation publication-type="other">“Python Software Foundation.” <ext-link ext-link-type="uri" xlink:href="https://www.python.org/">https://www.python.org/</ext-link></mixed-citation>
    </ref>
    <ref id="CR32">
      <label>32.</label>
      <mixed-citation publication-type="other">S. van der Walt, S. C. Colbert, and G. Varoquaux, “The NumPy Array: A Structure for Efficient Numerical Computation,” <italic>Computing in Science &amp; Engineering</italic>, vol. 13, no. 2, pp. 22–30, Mar. 2011. 10.1109/MCSE.2011.37.</mixed-citation>
    </ref>
    <ref id="CR33">
      <label>33.</label>
      <mixed-citation publication-type="other">“numpy · PyPI.” <ext-link ext-link-type="uri" xlink:href="https://pypi.org/project/numpy/1.15.4/">https://pypi.org/project/numpy/1.15.4/</ext-link> (accessed Feb. 18, 2021).</mixed-citation>
    </ref>
    <ref id="CR34">
      <label>34.</label>
      <mixed-citation publication-type="other">D. Mason, “SU‐E‐T‐33: Pydicom: An Open Source DICOM Library,” in <italic>Medical Physics</italic>, Jun. 2011, vol. 38, no. 6, p. 3493. 10.1118/1.3611983.</mixed-citation>
    </ref>
    <ref id="CR35">
      <label>35.</label>
      <mixed-citation publication-type="other">“pydicom · PyPI.” <ext-link ext-link-type="uri" xlink:href="https://pypi.org/project/pydicom/1.2.1/">https://pypi.org/project/pydicom/1.2.1/</ext-link> (accessed Feb. 18, 2021).</mixed-citation>
    </ref>
    <ref id="CR36">
      <label>36.</label>
      <mixed-citation publication-type="other">M. Caffini, “Project-Beat--Pyhton.” <ext-link ext-link-type="uri" xlink:href="https://github.com/mcaffini/Project-Beat---Python">https://github.com/mcaffini/Project-Beat---Python</ext-link></mixed-citation>
    </ref>
    <ref id="CR37">
      <label>37.</label>
      <mixed-citation publication-type="other">“xnat · PyPI.” <ext-link ext-link-type="uri" xlink:href="https://pypi.org/project/xnat/0.3.22/">https://pypi.org/project/xnat/0.3.22/</ext-link> (accessed Feb. 18, 2021).</mixed-citation>
    </ref>
    <ref id="CR38">
      <label>38.</label>
      <mixed-citation publication-type="other">“pyAesCrypt · PyPI.” <ext-link ext-link-type="uri" xlink:href="https://pypi.org/project/pyAesCrypt/0.4.3/">https://pypi.org/project/pyAesCrypt/0.4.3/</ext-link> (accessed Feb. 18, 2021).</mixed-citation>
    </ref>
    <ref id="CR39">
      <label>39.</label>
      <mixed-citation publication-type="other">“pyinstaller · PyPI.” <ext-link ext-link-type="uri" xlink:href="https://pypi.org/project/pyinstaller/3.5/">https://pypi.org/project/pyinstaller/3.5/</ext-link> (accessed Feb. 18, 2021).</mixed-citation>
    </ref>
    <ref id="CR40">
      <label>40.</label>
      <mixed-citation publication-type="other">“Get Started with MATLAB Engine API for Python - MATLAB &amp; Simulink.” <ext-link ext-link-type="uri" xlink:href="https://www.mathworks.com/help/matlab/matlab_external/get-started-with-matlab-engine-for-python.html">https://www.mathworks.com/help/matlab/matlab_external/get-started-with-matlab-engine-for-python.html</ext-link> (accessed Feb. 18, 2021).</mixed-citation>
    </ref>
    <ref id="CR41">
      <label>41.</label>
      <mixed-citation publication-type="other">[41]Y. Schwartz <italic>et al.</italic>, “PyXNAT: XNAT in Python,” <italic>Frontiers in Neuroinformatics</italic>, vol. 6, p. 12, May 2012, doi: 10.3389/fninf.2012.00012.</mixed-citation>
    </ref>
    <ref id="CR42">
      <label>42.</label>
      <mixed-citation publication-type="other">“pyxnat · PyPI.” <ext-link ext-link-type="uri" xlink:href="https://pypi.org/project/pyxnat/1.2.1.0.post3/">https://pypi.org/project/pyxnat/1.2.1.0.post3/</ext-link> (accessed Feb. 18, 2021).</mixed-citation>
    </ref>
    <ref id="CR43">
      <label>43.</label>
      <mixed-citation publication-type="other">“requests · PyPI.” <ext-link ext-link-type="uri" xlink:href="https://pypi.org/project/requests/2.23.0/">https://pypi.org/project/requests/2.23.0/</ext-link> (accessed Feb. 18, 2021).</mixed-citation>
    </ref>
    <ref id="CR44">
      <label>44.</label>
      <mixed-citation publication-type="other">“numpy · PyPI.” <ext-link ext-link-type="uri" xlink:href="https://pypi.org/project/numpy/1.18.5/">https://pypi.org/project/numpy/1.18.5/</ext-link> (accessed Feb. 18, 2021).</mixed-citation>
    </ref>
    <ref id="CR45">
      <label>45.</label>
      <mixed-citation publication-type="other">T. Phil, “Sikerdebaard/dcmrtstruct2nii: v1.0.19,” Sep. 19, 2020. <ext-link ext-link-type="uri" xlink:href="https://zenodo.org/record/4037865">https://zenodo.org/record/4037865</ext-link> (accessed Feb. 18, 2021).</mixed-citation>
    </ref>
    <ref id="CR46">
      <label>46.</label>
      <mixed-citation publication-type="other">“opencv-python · PyPI.” <ext-link ext-link-type="uri" xlink:href="https://pypi.org/project/opencv-python/4.4.0.40/">https://pypi.org/project/opencv-python/4.4.0.40/</ext-link> (accessed Feb. 18, 2021).</mixed-citation>
    </ref>
    <ref id="CR47">
      <label>47.</label>
      <mixed-citation publication-type="other">M. Brett <italic>et al.</italic>, “nipy/nibabel: 3.1.1,” Jun. 30, 2020. <ext-link ext-link-type="uri" xlink:href="https://zenodo.org/record/3924343">https://zenodo.org/record/3924343</ext-link> (accessed Feb. 18, 2021).</mixed-citation>
    </ref>
    <ref id="CR48">
      <label>48.</label>
      <mixed-citation publication-type="other">L. Consolino <italic>et al.</italic>, “Non-invasive Investigation of Tumor Metabolism and Acidosis by MRI-CEST Imaging,” <italic>Frontiers in Oncology</italic>, vol. 10. Frontiers Media S.A., p. 161, Feb. 18, 2020. doi: 10.3389/fonc.2020.00161.</mixed-citation>
    </ref>
    <ref id="CR49">
      <label>49.</label>
      <mixed-citation publication-type="other">“DICOM Part 6: Data Dictionary.” <ext-link ext-link-type="uri" xlink:href="http://dicom.nema.org/medical/dicom/current/output/pdf/part06.pdf">http://dicom.nema.org/medical/dicom/current/output/pdf/part06.pdf</ext-link> (accessed Oct. 20, 2021).</mixed-citation>
    </ref>
    <ref id="CR50">
      <label>50.</label>
      <mixed-citation publication-type="other">“DICOM Part 5: Data Structures and Encoding.” <ext-link ext-link-type="uri" xlink:href="http://dicom.nema.org/medical/dicom/current/output/pdf/part05.pdf">http://dicom.nema.org/medical/dicom/current/output/pdf/part05.pdf</ext-link> (accessed Oct. 20, 2021).</mixed-citation>
    </ref>
    <ref id="CR51">
      <label>51.</label>
      <mixed-citation publication-type="other">D. L. Longo <italic>et al.</italic>, “In vivo imaging of tumor metabolism and acidosis by combining PET and MRI-CEST pH imaging,” <italic>Cancer Research</italic>, vol. 76, no. 22, pp. 6463–6470, 2016. 10.1158/0008-5472.CAN-16-0825.</mixed-citation>
    </ref>
    <ref id="CR52">
      <label>52.</label>
      <mixed-citation publication-type="other">K. W. Y. Chan <italic>et al.</italic>, “Natural D -glucose as a biodegradable MRI contrast agent for detecting cancer,” <italic>Magnetic Resonance in Medicine</italic>, vol. 68, no. 6, pp. 1764–1773, Dec. 2012. 10.1002/mrm.24520.</mixed-citation>
    </ref>
    <ref id="CR53">
      <label>53.</label>
      <mixed-citation publication-type="other">S. Walker-Samuel <italic>et al.</italic>, “In vivo imaging of glucose uptake and metabolism in tumors,” <italic>Nature Medicine</italic>, vol. 19, no. 8, pp. 1067–1072, 2013. 10.1038/nm.3252.</mixed-citation>
    </ref>
    <ref id="CR54">
      <label>54.</label>
      <mixed-citation publication-type="other">“XNAT OHIF Viewer 2.0 Plugin.” <ext-link ext-link-type="uri" xlink:href="https://bitbucket.org/icrimaginginformatics/ohif-viewer-xnat-plugin/src/master/">https://bitbucket.org/icrimaginginformatics/ohif-viewer-xnat-plugin/src/master/</ext-link></mixed-citation>
    </ref>
    <ref id="CR55">
      <label>55.</label>
      <mixed-citation publication-type="other">T. Urban <italic>et al.</italic>, “LesionTracker: Extensible open-source zero-footprint web viewer for cancer imaging research and clinical trials,” <italic>Cancer Research</italic>, vol. 77, no. 21, pp. e119–e122, Nov. 2017. 10.1158/0008-5472.CAN-17-0334.</mixed-citation>
    </ref>
    <ref id="CR56">
      <label>56.</label>
      <mixed-citation publication-type="other">“dcmrtstruct2ni: Convert DICOM RT-Struct to nii.” <ext-link ext-link-type="uri" xlink:href="https://pypi.org/project/dcmrtstruct2nii/">https://pypi.org/project/dcmrtstruct2nii/</ext-link></mixed-citation>
    </ref>
    <ref id="CR57">
      <label>57.</label>
      <mixed-citation publication-type="other">“DICOM Part 3: Information Object Definitions.” <ext-link ext-link-type="uri" xlink:href="https://dicom.nema.org/medical/dicom/current/output/html/part03.html">https://dicom.nema.org/medical/dicom/current/output/html/part03.html</ext-link> (accessed Oct. 22, 2021).</mixed-citation>
    </ref>
    <ref id="CR58">
      <label>58.</label>
      <mixed-citation publication-type="other">“Work-Item Proposal: IOD for photoacoustic imaging”, Accessed: Oct. 22, 2021. [Online]. Available: <ext-link ext-link-type="uri" xlink:href="https://www.dicomstandard.org/docs/librariesprovider2/dicomdocuments/work-item-proposal_photoacoustic-imaging-iod-2020-08-20.pdf?sfvrsn=5c3c7973_0">https://www.dicomstandard.org/docs/librariesprovider2/dicomdocuments/work-item-proposal_photoacoustic-imaging-iod-2020-08-20.pdf?sfvrsn=5c3c7973_0</ext-link></mixed-citation>
    </ref>
    <ref id="CR59">
      <label>59.</label>
      <mixed-citation publication-type="other">“WG-30: Small Animal Imaging.” <ext-link ext-link-type="uri" xlink:href="https://www.dicomstandard.org/activity/wgs/wg-30">https://www.dicomstandard.org/activity/wgs/wg-30</ext-link> (accessed Oct. 29, 2021).</mixed-citation>
    </ref>
    <ref id="CR60">
      <label>60.</label>
      <mixed-citation publication-type="other">L. Persoon <italic>et al.</italic>, “A novel data management platform to improve image-guided precision preclinical biological research,” <italic>British Journal of Radiology</italic>, vol. 92, no. 1095, 2019. 10.1259/bjr.20180455.</mixed-citation>
    </ref>
    <ref id="CR61">
      <label>61.</label>
      <mixed-citation publication-type="other">“Flywheel • Informatics Platform for Biomedical Research &amp; Collaboration.” <ext-link ext-link-type="uri" xlink:href="https://flywheel.io/">https://flywheel.io/</ext-link> (accessed Feb. 17, 2021).</mixed-citation>
    </ref>
    <ref id="CR62">
      <label>62.</label>
      <mixed-citation publication-type="other">M. D. Wilkinson <italic>et al.</italic>, “The FAIR Guiding Principles for scientific data management and stewardship,” <italic>Scientific Data</italic>, vol. 3, p. 160018, Mar. 2016. 10.1038/sdata.2016.18.</mixed-citation>
    </ref>
    <ref id="CR63">
      <label>63.</label>
      <mixed-citation publication-type="other">P. Jansen, L. van den Berg, P. van Overveld, and J. W. Boiten, “Research data stewardship for healthcare professionals,” in <italic>Fundamentals of Clinical Data Science</italic>, Springer International Publishing, 2018, pp. 37–53. 10.1007/978-3-319-99713-1_4.</mixed-citation>
    </ref>
    <ref id="CR64">
      <label>64.</label>
      <mixed-citation publication-type="other">“Euro-BioImaging ERIC.” <ext-link ext-link-type="uri" xlink:href="https://www.eurobioimaging.eu/">https://www.eurobioimaging.eu/</ext-link></mixed-citation>
    </ref>
    <ref id="CR65">
      <label>65.</label>
      <mixed-citation publication-type="other">“The Vienna Declaration on the European Open Science Cloud.” <ext-link ext-link-type="uri" xlink:href="https://eosc-launch.eu/declaration/">https://eosc-launch.eu/declaration/</ext-link></mixed-citation>
    </ref>
  </ref-list>
</back>
