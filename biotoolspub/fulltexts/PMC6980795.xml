<?all-math-mml yes?>
<?use-mml?>
<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//NLM//DTD Journal Publishing DTD v3.0 20080202//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName journalpublishing3.dtd?>
<?SourceDTD.Version 3.0?>
<?ConverterInfo.XSLTName nihms2pmcx2.xsl?>
<?ConverterInfo.Version 1?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<?properties manuscript?>
<?origin nihpa?>
<?iso-abbr J Neurosci Methods?>
<?submitter-system nihms?>
<?submitter-canonical-name Elsevier?>
<?submitter-canonical-id ELSEVIERAM?>
<?submitter-userid 8068823?>
<?submitter-authority myNCBI?>
<?submitter-login elsevieram?>
<?submitter-name Elsevier Author Support?>
<?domain nihpa?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-journal-id">7905558</journal-id>
    <journal-id journal-id-type="pubmed-jr-id">5306</journal-id>
    <journal-id journal-id-type="nlm-ta">J Neurosci Methods</journal-id>
    <journal-id journal-id-type="iso-abbrev">J Neurosci Methods</journal-id>
    <journal-title-group>
      <journal-title>Journal of neuroscience methods</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">0165-0270</issn>
    <issn pub-type="epub">1872-678X</issn>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">6980795</article-id>
    <article-id pub-id-type="pmid">31586868</article-id>
    <article-id pub-id-type="doi">10.1016/j.jneumeth.2019.108432</article-id>
    <article-id pub-id-type="manuscript">nihpa1547435</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Article</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>ChaRTr: An R toolbox for modeling choices and response times in
decision-making tasks</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Chandrasekaran</surname>
          <given-names>Chandramouli</given-names>
        </name>
        <xref ref-type="aff" rid="A1">a</xref>
        <xref ref-type="aff" rid="A2">b</xref>
        <xref ref-type="aff" rid="A3">c</xref>
        <xref rid="CR1" ref-type="corresp">*</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Hawkins</surname>
          <given-names>Guy E.</given-names>
        </name>
        <xref ref-type="aff" rid="A4">d</xref>
      </contrib>
    </contrib-group>
    <aff id="A1"><label>a</label>Department of Psychological and Brain Sciences, Boston
University, Boston, MA, USA</aff>
    <aff id="A2"><label>b</label>Department of Anatomy &amp; Neurobiology, Boston University
School of Medicine, Boston, MA, USA</aff>
    <aff id="A3"><label>c</label>Center for Systems Neuroscience, Boston University, Boston,
MA, USA</aff>
    <aff id="A4"><label>d</label>School of Psychology, University of Newcastle,
Australia</aff>
    <author-notes>
      <corresp id="CR1"><label>*</label>Corresponding author at: Department of Anatomy
&amp; Neurobiology, Boston University School of Medicine, Boston, MA, USA.
<email>cchandr1@bu.edu</email> (C. Chandrasekaran),
<email>guy.hawkins@newcastle.edu.au</email> (G.E. Hawkins).</corresp>
    </author-notes>
    <pub-date pub-type="nihms-submitted">
      <day>24</day>
      <month>12</month>
      <year>2019</year>
    </pub-date>
    <pub-date pub-type="epub">
      <day>03</day>
      <month>10</month>
      <year>2019</year>
    </pub-date>
    <pub-date pub-type="ppub">
      <day>01</day>
      <month>12</month>
      <year>2019</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>24</day>
      <month>1</month>
      <year>2020</year>
    </pub-date>
    <volume>328</volume>
    <fpage>108432</fpage>
    <lpage>108432</lpage>
    <!--elocation-id from pubmed: 10.1016/j.jneumeth.2019.108432-->
    <permissions>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbyncndlicense">https://creativecommons.org/licenses/by-nc-nd/4.0/</ali:license_ref>
        <license-p>This is an open access article under the CC BY-NC-ND license
(<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by-nc-nd/4.0/">http://creativecommons.org/licenses/BY-NC-ND/4.0/</ext-link>).</license-p>
      </license>
    </permissions>
    <abstract id="ABS1">
      <sec id="S1">
        <title>Background</title>
        <p id="P1">Decision-making is the process of choosing and performing actions in
response to sensory cues to achieve behavioral goals. Many mathematical
models have been developed to describe the choice behavior and response time
(RT) distributions of observers performing decision-making tasks. However,
relatively few researchers use these models because it demands expertise in
various numerical, statistical, and software techniques.</p>
      </sec>
      <sec id="S2">
        <title>New method</title>
        <p id="P2">We present a toolbox — <italic>Choices and Response Times in
R</italic>, or <italic>ChaRTr</italic> — that provides the user
the ability to implement and test a wide variety of decision-making models
ranging from classic through to modern versions of the diffusion decision
model, to models with urgency signals, or collapsing boundaries.</p>
      </sec>
      <sec id="S3">
        <title>Results</title>
        <p id="P3">In three different case studies, we demonstrate how
<italic>ChaRTr</italic> can be used to effortlessly discriminate between
multiple models of decision-making behavior. We also provide guidance on how
to extend the toolbox to incorporate future developments in decision-making
models.</p>
      </sec>
      <sec id="S4">
        <title>Comparison with existing method(s)</title>
        <p id="P4">Existing software packages surmounted some of the numerical issues
but have often focused on the classical decision-making model, the diffusion
decision model. Recent models that posit roles for urgency, time-varying
decision thresholds, noise in various aspects of the decision-formation
process or low pass filtering of sensory evidence have proven to be
challenging to incorporate in a coherent software framework that permits
quantitative evaluation among these competing classes of decision-making
models.</p>
      </sec>
      <sec id="S5">
        <title>Conclusion</title>
        <p id="P5"><italic>ChaRTr</italic> can be used to make insightful statements
about the cognitive processes underlying observed decision-making behavior
and ultimately for deeper insights into decision mechanisms.</p>
      </sec>
    </abstract>
    <kwd-group>
      <kwd>Decision making</kwd>
      <kwd>Choice</kwd>
      <kwd>Response time (RT)</kwd>
      <kwd>Diffusion decision model</kwd>
      <kwd>DDM</kwd>
      <kwd>Urgency gating</kwd>
      <kwd>AIC</kwd>
      <kwd>BIC</kwd>
      <kwd>Model selection</kwd>
    </kwd-group>
  </article-meta>
</front>
<body>
  <sec id="S6">
    <label>1.</label>
    <title>Introduction</title>
    <p id="P6">Perceptual decision-making is the process of choosing and performing
appropriate actions in response to sensory cues to achieve behavioral goals (<xref rid="R35" ref-type="bibr">Freedman and Assad, 2011</xref>; <xref rid="R49" ref-type="bibr">Hoshi, 2013</xref>; <xref rid="R81" ref-type="bibr">Shadlen and
Newsome, 2001</xref>; <xref rid="R36" ref-type="bibr">Gold and Shadlen,
2007</xref>; <xref rid="R80" ref-type="bibr">Shadlen and Kiani, 2013</xref>;
<xref rid="R57" ref-type="bibr">O’Connell et al., 2018a</xref>). A
sophisticated research effort in multiple fields has led to the formulation of
cognitive process models to describe decision-making behavior (<xref rid="R25" ref-type="bibr">Donkin and Brown, 2018</xref>; <xref rid="R71" ref-type="bibr">Ratcliff et al., 2016</xref>). The majority of these models are grounded in the
“sequential sampling” framework, which posits that decision-making
involves the gradual accumulation of noisy sensory evidence over time until a bound
(or criterion/threshold) is reached (<xref rid="R34" ref-type="bibr">Forstmann et
al., 2016</xref>; <xref rid="R71" ref-type="bibr">Ratcliff et al., 2016</xref>;
<xref rid="R80" ref-type="bibr">Shadlen and Kiani, 2013</xref>; <xref rid="R10" ref-type="bibr">Brunton et al., 2013</xref>; <xref rid="R68" ref-type="bibr">Ratcliff and Rouder, 1998</xref>; <xref rid="R67" ref-type="bibr">Ratcliff and
McKoon, 2008</xref>; <xref rid="R36" ref-type="bibr">Gold and Shadlen,
2007</xref>; <xref rid="R39" ref-type="bibr">Hanks et al., 2014</xref>). Models
derived from the sequential sampling framework are typically elaborated with various
systematic and random components so as to implement assumptions and hypotheses about
the underlying cognitive processes involved in perceptual decision-making (<xref rid="R71" ref-type="bibr">Ratcliff et al., 2016</xref>; <xref rid="R20" ref-type="bibr">Diederich, 1997</xref>).</p>
    <p id="P7">The most prominent sequential sampling model of decision-making is the
diffusion decision model (DDM), which has an impressive history of success in
explaining the behavior of human and animal observers (e.g., <xref rid="R34" ref-type="bibr">Forstmann et al., 2016</xref>; <xref rid="R71" ref-type="bibr">Ratcliff et al., 2016</xref>; <xref rid="R59" ref-type="bibr">Palmer et al.,
2005</xref>; <xref rid="R90" ref-type="bibr">Tsunada et al., 2016</xref>; <xref rid="R21" ref-type="bibr">Ding and Gold, 2012a</xref>,<xref rid="R22" ref-type="bibr">b</xref>). However, recent studies propose alternative
sequential sampling models that do not involve the integration of sensory evidence
over time. Instead, novel sensory evidence is multiplied by an urgency signal that
increases with elapsed decision time, and a decision is made when the signal exceeds
the criterion (<xref rid="R23" ref-type="bibr">Ditterich, 2006a</xref>; <xref rid="R86" ref-type="bibr">Thura et al., 2012</xref>; <xref rid="R18" ref-type="bibr">Cisek et al., 2009</xref>). Another line of research proposes
that observers aim to maximize their reward rate and suggests that the decision
boundary dynamically decreases as the time spent making a decision grows longer.
Such a framework has been argued to provide a better explanation for decision-making
behavior in the face of sensory uncertainty (<xref rid="R26" ref-type="bibr">Drugowitsch et al., 2012</xref>).</p>
    <p id="P8">One approach to distinguish between these different models is to
systematically manipulate the stimulus statistics and/or the task structure and then
test whether behavior is qualitatively consistent with one or another sequential
sampling model (<xref rid="R18" ref-type="bibr">Cisek et al., 2009</xref>; <xref rid="R87" ref-type="bibr">Thura and Cisek, 2014</xref>; <xref rid="R12" ref-type="bibr">Carland et al., 2015</xref>; <xref rid="R10" ref-type="bibr">Brunton et al., 2013</xref>; <xref rid="R79" ref-type="bibr">Scott et al.,
2015</xref>). An alternative approach is to quantitatively analyze the choice
and RT behavior with a large set of candidate models, and then carefully use model
selection techniques to understand the candidate models that best describe the data
(e.g., <xref rid="R43" ref-type="bibr">Hawkins et al., 2015b</xref>; <xref rid="R14" ref-type="bibr">Chandrasekaran et al., 2017</xref>; <xref rid="R60" ref-type="bibr">Purcell and Kiani, 2016</xref>; <xref rid="R32" ref-type="bibr">Evans et al., 2017</xref>). The quantitative modeling and model selection
approach allows the researcher to determine whether a particular model component
(e.g., an urgency signal, or variability in the rate of information accumulation) is
important for generating the observed behavioral data. It also provides a holistic
method for testing model adequacy because the proposed model is judged on its
ability to account for all available data (e.g., <xref rid="R32" ref-type="bibr">Evans et al., 2017</xref>), rather than focusing on a specific subset of the
data.</p>
    <p id="P9">Despite the apparent benefits of model selection, there are technical and
computational challenges in the application of decision-making models to behavioral
data. Some researchers have surmounted these issues by simplifying the process:
using analytical solutions for the predicted mean RT and accuracy from the simplest
form of the DDM, applied to participant-averaged behavioral data (<xref rid="R59" ref-type="bibr">Palmer et al., 2005</xref>; <xref rid="R90" ref-type="bibr">Tsunada et al., 2016</xref>). However, the complete distribution of RTs is
highly informative, and often necessary, to reliably discriminate between the latent
cognitive processes that influence decision-making (<xref rid="R34" ref-type="bibr">Forstmann et al., 2016</xref>; <xref rid="R67" ref-type="bibr">Ratcliff and
McKoon, 2008</xref>; <xref rid="R71" ref-type="bibr">Ratcliff et al.,
2016</xref>; <xref rid="R52" ref-type="bibr">Luce, 1986</xref>). Until recently,
applying sequential sampling models like the DDM to the joint distribution over
choices and RT required bespoke domain knowledge and computational expertise. This
has hindered the widespread adoption of quantitative model selection methods to
study decision-making behavior.</p>
    <p id="P10">Some recent attempts have demystified the application of cognitive models of
decision-making to behavioral data, providing a path for researchers to apply these
methods to their own research questions. For instance, <xref rid="R92" ref-type="bibr">Vandekerckhove and Tuerlinckx (2008)</xref> developed the
Diffusion Modeling and Analysis Toolbox (DMAT), and <xref rid="R93" ref-type="bibr">Voss and Voss (2007)</xref> developed the diffusion model toolbox (fast-dm; for
an updated version see fast-dm-30, <xref rid="R94" ref-type="bibr">Voss et al.,
2015</xref>). Other modern toolboxes have improved the parameter estimation
algorithms and can leverage multiple observers to perform hierarchical Bayesian
inference (<xref rid="R98" ref-type="bibr">Wiecki et al., 2013</xref>). In hBayesDM
(<xref rid="R1" ref-type="bibr">Ahn et al., 2017</xref>) and Dynamic Models of
Choice (<xref rid="R47" ref-type="bibr">Heathcote et al., 2018</xref>) researchers
can apply a range of models to behavior from a wide variety of decision-making
paradigms ranging from choice tasks to reversal learning and inhibition tasks.</p>
    <p id="P11">A common feature across all of the excellent toolboxes currently available
is that they provide code to apply the DDM to data, or the DDM in addition to a few
alternative models. As a consequence, the toolboxes provide no pathway for a
researcher to rigorously compare the quantitative account of the DDM to alternative
theories of the decision making process including models with an urgency signal
(<xref rid="R23" ref-type="bibr">Ditterich, 2006a</xref>), urgency-gating (<xref rid="R18" ref-type="bibr">Cisek et al., 2009</xref>), or collapsing bounds
(<xref rid="R43" ref-type="bibr">Hawkins et al., 2015b</xref>). Simply put, we
currently have no openly available and extensible toolbox for understanding choice
and RT behavior using the many hypothesized models of decision-making. We believe
there is a critical need for examining how these different models perform in terms
of explaining decision-making behavior.</p>
    <p id="P12">The objective of this study was to address this need and provide a
straightforward framework to analyze a range of existing sequential sampling models
of decision-making behavior. Specifically, we aimed to provide an open-source and
extensible framework that permits quantitative implementation and testing of novel
candidate models of decision-making. The outcome of this study is
<italic>ChaRTr</italic>, a novel toolbox in the R programming environment that
can be used to analyze choice and RT data of humans and animals performing
two-alternative forced choice tasks that involve perceptual or other types of
decision-making. R is an open source language that enjoys widespread use and is
maintained by a large community of researchers. <italic>ChaRTr</italic> can be used
to analyze choice and RT behavior from the perspective of a (potentially large)
range of decision-making models and can be readily extended when new models are
developed. These new models can be incorporated into the toolbox with minimal effort
and require only basic working knowledge of R and C programming; we explain the
required skills in this manuscript. Similarly, new optimization routines that are
readily available as R packages can be implemented if desired.</p>
  </sec>
  <sec id="S7">
    <label>2.</label>
    <title>Methods and materials</title>
    <p id="P13">The methods are focused on the specification of various mathematical models
of decision-making, and the parameter estimation and model selection processes. For
reference, the symbols we use to describe the models are shown in <xref rid="T1" ref-type="table">Table 1</xref>. The naming convention for the models we have
developed in <italic>ChaRTr</italic> is to take the main architectural feature of
the model and use it as a prefix to the model.</p>
    <list list-type="bullet" id="L1">
      <list-item>
        <p id="P14">The diffusion decision model, henceforth DDM, refers to the simplest
sequential sampling model.</p>
      </list-item>
      <list-item>
        <p id="P15">cDDM refers to a DDM with collapsing boundaries (<xref rid="R43" ref-type="bibr">Hawkins et al., 2015b</xref>).</p>
      </list-item>
      <list-item>
        <p id="P16">cfkDDM refers to a DDM with collapsing boundaries and a fixed
parameter for the function defining the collapsing boundary (<xref rid="R43" ref-type="bibr">Hawkins et al., 2015b</xref>).</p>
      </list-item>
      <list-item>
        <p id="P17">uDDM refers to a DDM with a linear urgency signal with a slope and
an intercept.</p>
      </list-item>
      <list-item>
        <p id="P18">dDDM refers to a DDM with urgency signal defined by <xref rid="R23" ref-type="bibr">Ditterich (2006a)</xref>.</p>
      </list-item>
      <list-item>
        <p id="P19">UGM refers to an Urgency Gating Model (<xref rid="R18" ref-type="bibr">Cisek et al., 2009</xref>; <xref rid="R86" ref-type="bibr">Thura et al., 2012</xref>).</p>
      </list-item>
      <list-item>
        <p id="P20">bUGM refers to a UGM with a linear urgency signal composed of a
slope and an intercept (<xref rid="R14" ref-type="bibr">Chandrasekaran et
al., 2017</xref>).</p>
      </list-item>
    </list>
    <p id="P21">For reference, the models being considered, the parameters for the models
and the number of parameters in each model are shown in <xref rid="T2" ref-type="table">Table 2</xref>.</p>
    <sec id="S8">
      <label>2.1.</label>
      <title>Mathematical models of decision-making</title>
      <p id="P22">Sequential sampling models of decision-making assume that RT comprises
two components (<xref rid="R67" ref-type="bibr">Ratcliff and McKoon,
2008</xref>; <xref rid="R71" ref-type="bibr">Ratcliff et al., 2016</xref>). The
first component is the decision time, which encompasses processes such as the
accumulation of sensory evidence and additional decision-related factors such as
urgency. The second component is the non-decision time (or residual time), which
involves the time required for processes that must occur to produce a response
but fall outside of the decision-formation process, such as stimulus encoding,
motor preparation and motor execution time.</p>
      <p id="P23">We introduce various models of the decision-making process in
approximately increasing level of complexity, beginning with the simple DDM.</p>
      <sec id="S9">
        <label>2.1.1.</label>
        <title>Simple diffusion decision model (DDM)</title>
        <p id="P24">The diffusion decision model (or DDM) is derived from one of the
oldest interpretations of a statistical test – the sequential
probability ratio test (<xref rid="R96" ref-type="bibr">Wald and Wolfowitz,
1948</xref>) – as a model of a cognitive process – how
decisions are formed over time (<xref rid="R84" ref-type="bibr">Stone,
1960</xref>). The DDM provides the foundation for the decision-making
models implemented in <italic>ChaRTr</italic> and assumes that
decision-formation is described by a one-dimensional diffusion process
(<xref rid="F1" ref-type="fig">Fig. 1A</xref>) with the stochastic
differential equation <disp-formula id="FD1"><label>(1)</label><mml:math display="block" id="M1" overflow="scroll"><mml:mrow><mml:mi>x</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>v</mml:mi><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mi>s</mml:mi><mml:msqrt><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msqrt><mml:mi mathvariant="script">N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></disp-formula> where <italic>x</italic>(<italic>t</italic>) is the state of
the decision-formation process, known as the decision variable, at time
<italic>t</italic>; <italic>v</italic> is the rate of accumulation of
sensory evidence, known as the drift rate; Δ<italic>t</italic> is the
step size of the process; s is the standard deviation of the
moment-to-moment (Brownian) noise of the decision-formation process;
<inline-formula><mml:math display="inline" id="M2" overflow="scroll"><mml:mrow><mml:mi mathvariant="script">N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> refers to a random sample from the standard
normal distribution. A response is made when <italic>x</italic>
(<italic>t</italic> + Δ<italic>t</italic>) ≥
<italic>a</italic><sub><italic>upper</italic></sub> or
<italic>x</italic>(<italic>t</italic> + Δ<italic>t</italic>)
≤ <italic>a</italic><sub><italic>lower</italic></sub>. Whether a
response is correct or incorrect is determined from the boundary that was
crossed and the valence of the drift rate (i.e., <italic>v</italic> &gt;
0 implies the upper boundary corresponds to the correct response,
<italic>v</italic> &lt; 0 implies the lower boundary corresponds to
the correct response). In <xref rid="F1" ref-type="fig">Fig. 1A</xref>, and
in all DDM models in <italic>ChaRTr</italic>, we specify
<italic>a</italic><sub><italic>lower</italic></sub> = 0 and
<italic>a</italic><sub><italic>upper</italic></sub> = A, without loss of
generality. <italic>z</italic> represents the starting state of the evidence
accumulation process (i.e., the position of the decision variable at
<italic>x</italic>(0)) and can be estimated between
<italic>a</italic><sub><italic>lower</italic></sub> and
<italic>a</italic><sub><italic>upper</italic></sub>. When we assume
there is no a priori response bias, <italic>z</italic> is fixed to the
midpoint between <italic>a</italic><sub><italic>lower</italic></sub> and
<italic>a</italic><sub><italic>upper</italic></sub> (i.e.,
<italic>A</italic>/2). The decision time is the first time step
<italic>t</italic> at which the decision variable crosses one of the two
decision boundaries. The predicted RT is given as a sum of the decision time
and the non-decision time
<italic>T</italic><sub><italic>er</italic></sub>.</p>
      </sec>
      <sec id="S10">
        <label>2.1.2.</label>
        <title>DDM with variable starting state, variable drift rate, and variable
non-decision time</title>
        <p id="P25">The (simple) DDM assumes a level of constancy from one decision to
the next in various components of the decision-formation process: it always
commences with the same level of response bias (<italic>z</italic>), the
drift rate takes a single value
(<italic>v</italic><sub><italic>i</italic></sub>, for trials in
experimental condition <italic>i</italic>), and the non-decision time never
varies (<italic>T</italic><sub><italic>er</italic></sub>).</p>
        <p id="P26">None of these simplifying assumptions are likely to hold in
experimental contexts. For example, the relative speed of correct and
erroneous responses can differ, and participants’ arousal may exhibit
random fluctuations over time, possibly due to a level of irreducible neural
noise. Decades of research into decision-making models suggests that these
effects, and others, are often well explained by combining systematic and
random components in each of the starting state, drift rate, and
non-decision time (<xref rid="F1" ref-type="fig">Fig. 1B</xref>). In
<italic>ChaRTr</italic>, we provide variants of the DDM where all of
these parameters can be randomly drawn from their typically assumed
distributions over different trials, <disp-formula id="FD2"><label>(2)</label><mml:math display="block" id="M3" overflow="scroll"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi mathvariant="normal">ij</mml:mi></mml:mrow></mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mi>s</mml:mi><mml:msqrt><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msqrt><mml:mi mathvariant="script">N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></disp-formula>
<disp-formula id="FD3"><label>(3)</label><mml:math display="block" id="M4" overflow="scroll"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>∼</mml:mo><mml:mi mathvariant="script">U</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>z</mml:mi><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>z</mml:mi></mml:msub></mml:mrow><mml:mn>2</mml:mn></mml:mfrac><mml:mo>,</mml:mo><mml:mi>z</mml:mi><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>z</mml:mi></mml:msub></mml:mrow><mml:mn>2</mml:mn></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>
<disp-formula id="FD4"><label>(4)</label><mml:math display="block" id="M5" overflow="scroll"><mml:mrow><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi mathvariant="normal">ij</mml:mi></mml:mrow></mml:msub><mml:mo>∼</mml:mo><mml:mi mathvariant="script">N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>v</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mi>v</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>
<disp-formula id="FD5"><label>(5)</label><mml:math display="block" id="M6" overflow="scroll"><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mtext>er</mml:mtext><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>∼</mml:mo><mml:mi mathvariant="script">U</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mtext>er</mml:mtext></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mn>2</mml:mn></mml:mfrac><mml:mo>,</mml:mo><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mtext>er</mml:mtext></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mn>2</mml:mn></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula> where <italic>i</italic> denotes an experimental condition;
<italic>j</italic> denotes an exemplar trial; <inline-formula><mml:math display="inline" id="M7" overflow="scroll"><mml:mi mathvariant="script">U</mml:mi></mml:math></inline-formula> denotes the uniform distribution.
<italic>ChaRTr</italic> provides flexibility to the user such that they
can assume the decision-formation process involves none, some or all of
these random components. Furthermore, it provides flexibility to assume
distributions for the random components beyond those that have been
typically assumed and studied in the literature. For example, one could
hypothesize that non-decision times are exponentially distributed rather
than uniformly distributed (<xref rid="R73" ref-type="bibr">Ratcliff,
2013</xref>).</p>
      </sec>
      <sec id="S11">
        <label>2.1.3.</label>
        <title>DDM with collapsing decision boundaries (cDDM)</title>
        <p id="P27">The DDM with collapsing boundaries generalizes the classic DDM by
assuming that the sensory evidence required to commit to a decision is not
constant as a function of elapsed decision time. Instead, it assumes that
the decision boundaries gradually decrease as the decision-formation process
grows longer (e.g., <xref rid="R6" ref-type="bibr">Bowman et al.,
2012</xref>; <xref rid="R26" ref-type="bibr">Drugowitsch et al.,
2012</xref>; <xref rid="R42" ref-type="bibr">Hawkins et al.,
2015a</xref>; <xref rid="R53" ref-type="bibr">Milosavljevic et al.,
2010</xref>; <xref rid="R85" ref-type="bibr">Tajima et al.,
2016</xref>). Collapsing boundaries terminate trials with weak sensory
signals (i.e., lower drift rates) at earlier time points than models with
‘fixed’ boundaries (i.e., simple DDM) and otherwise equivalent
parameter settings. The net result of collapsing boundaries is a reduction
in the positive skew (right tail) of the predicted RT distribution relative
to the fixed boundaries DDM. This signature in the predicted RT distribution
holds whether there is variability in parameters across trials (<xref rid="S10" ref-type="sec">Section 2.1.2</xref>) or not (<xref rid="S9" ref-type="sec">Section 2.1.1</xref>).</p>
        <p id="P28">Collapsing boundaries allow the observer to implement a decision
strategy where they do not commit an inordinate amount of time to decisions
that are unlikely to be correct (i.e., decision processes with weak sensory
signals). This allows the observer to sacrifice accuracy for a shorter
decision time, so they can engage in new decisions that might contain
stronger sensory signals and hence a higher chance of a correct response.
When a sequence of decisions varies in signal-to-noise ratio from one trial
to the next, like a typical difficulty manipulation in decision-making
studies, collapsing boundaries are provably more optimal than fixed
boundaries in the sense that they lead to greater predicted reward across
the entirety of the decision sequence (<xref rid="R26" ref-type="bibr">Drugowitsch et al., 2012</xref>; <xref rid="R85" ref-type="bibr">Tajima
et al., 2016</xref>). In this type of decision environment, collapsing
boundaries have provided a better quantitative account of animal behavior,
including monkeys, who might be motivated to obtain rewards to a greater
extent than humans, possibly due to the operant conditioning and fluid/food
restriction procedures used to motivate these animals (<xref rid="R42" ref-type="bibr">Hawkins et al., 2015a</xref>). Whether humans also aim
to maximize reward via collapsing boundaries is less clear (e.g., <xref rid="R33" ref-type="bibr">Evans et al., 2019</xref>).</p>
        <p id="P29"><xref rid="F1" ref-type="fig">Fig. 1C</xref> shows a schematic of a
collapsing boundaries model. In <italic>ChaRTr</italic> we assume the
collapsing boundary follows the cumulative distribution function of the
Weibull distribution, following <xref rid="R42" ref-type="bibr">Hawkins et
al. (2015a)</xref>. The Weibull function is quite flexible and can
approximate many different functions that one might wish to investigate,
including the exponential and hyperbolic functions. We assume the lower and
upper boundaries follow the form <disp-formula id="FD6"><label>(6)</label><mml:math display="block" id="M8" overflow="scroll"><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mtext>lower</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>a</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>exp</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mi>t</mml:mi><mml:mi>λ</mml:mi></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mi>k</mml:mi></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mo>−</mml:mo><mml:msup><mml:mi>a</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>
<disp-formula id="FD7"><label>(7)</label><mml:math display="block" id="M9" overflow="scroll"><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mtext>upper</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>a</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mtext>lower</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></disp-formula> where
<italic>a</italic><sub><italic>lower</italic></sub>(<italic>t</italic>)
and <italic>a</italic><sub><italic>upper</italic></sub>(<italic>t</italic>)
denote the position of the lower and upper boundaries at time
<italic>t</italic>; <italic>a</italic> denotes the position of upper
boundary at <italic>t</italic> = 0 (initial boundary setting, prior to any
collapse); <italic>a</italic>′ denotes the asymptotic boundary
setting, or the extent to which the boundaries collapsed (the maximal
possible collapse – where the upper and lower boundaries meet
– can occur when <italic>a</italic>′ = 1/2); λ and
<italic>k</italic> denote the scale and shape parameters of the Weibull
distribution.</p>
        <p id="P30">The collapsing boundaries are denoted in <italic>ChaRTr</italic> as
cDDM. When the <italic>k</italic> parameter is fixed to a particular value
to aid stronger identifiability in parameter estimation (<xref rid="R42" ref-type="bibr">Hawkins et al., 2015a</xref>), we refer to the
architecture as <italic>cfk</italic> to denote a fixed k value (cfkDDM),
here chosen to be 3 but can be modified in user implementations.</p>
        <p id="P31">The collapsing boundaries, as implemented here, are symmetric,
though they need not be; <italic>ChaRTr</italic> provides flexibility to
modify all features of the boundaries, including symmetry for each response
option, and the functional form. For instance, one might hypothesize that
linear collapsing boundaries are a better description of the
decision-formation process than nonlinear boundaries (<xref rid="R57" ref-type="bibr">O’Connell et al., 2018a</xref>; <xref rid="R55" ref-type="bibr">Murphy et al., 2016</xref>). <italic>ChaRTr</italic>
also permits DDMs with collapsing boundaries to incorporate any combination
of variability in starting state, drift rate, and non-decision time (e.g.,
models of the form
cDDMS<sub><italic>v</italic></sub>S<sub><italic>z</italic></sub>S<sub><italic>t</italic></sub>
and
cfkDDMS<sub><italic>v</italic></sub>S<sub><italic>z</italic></sub>S<sub><italic>t</italic></sub>).</p>
      </sec>
      <sec id="S12">
        <label>2.1.4.</label>
        <title>DDM with an urgency signal (uDDM)</title>
        <p id="P32">The DDM with an urgency signal assumes that the input evidence
– consisting of the sensory signal and noise – is modulated by
an “urgency signal”. This urgency-modulated sensory evidence
is accumulated into the decision variable throughout the decision-formation
process. As the process takes longer, the urgency signal grows in magnitude,
implying that sensory evidence arriving later in the decision-formation
process has a more profound impact on the decision-variable than information
arriving earlier (<xref rid="F1" ref-type="fig">Fig. 1D</xref>). To make the
distinction between an urgency signal and collapsing boundaries clear, the
DDM with an urgency signal assumes a dynamically modulated input signal
combined with boundaries that mirror those in the classic DDM; the DDM with
collapsing boundaries assumes a decision variable that mirrors the classic
DDM combined with dynamically modulated decision boundaries.</p>
        <p id="P33">As with the collapsing boundaries, the urgency signal can take many
functional forms; we have implemented two such forms in
<italic>ChaRTr</italic>. The general implementation of the urgency
signal is <disp-formula id="FD8"><label>(8)</label><mml:math display="block" id="M10" overflow="scroll"><mml:mrow><mml:mi>E</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>v</mml:mi><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mi>s</mml:mi><mml:msqrt><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msqrt><mml:mi mathvariant="script">N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></disp-formula>
<disp-formula id="FD9"><label>(9)</label><mml:math display="block" id="M11" overflow="scroll"><mml:mrow><mml:mi>x</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>E</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>γ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></disp-formula> where <italic>E</italic>(<italic>t</italic>) denotes the
momentary sensory evidence at time <italic>t</italic>;
γ(<italic>t</italic>) denotes the magnitude of the urgency signal
at time <italic>t</italic>. Note that with increasing decision time the
urgency signal magnifies the effect of the sensory signal
(<italic>v</italic>Δ<italic>t</italic>) and the sensory noise
<inline-formula><mml:math display="inline" id="M12" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:msqrt><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msqrt><mml:mi mathvariant="script">N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>.</p>
        <p id="P34">The first urgency signal implemented in <italic>ChaRTr</italic>
follows a 3 parameter logistic function with two scaling factors
(<italic>s</italic><sub><italic>x</italic></sub>,
<italic>s</italic><sub><italic>y</italic></sub>) and a delay
(<italic>d</italic>), originally proposed by <xref rid="R23" ref-type="bibr">Ditterich (2006a</xref>, dDDM)<xref rid="R23" ref-type="bibr">Ditterich, 2006a</xref><xref rid="R23" ref-type="bibr">Ditterich (2006a</xref>, dDDM): <disp-formula id="FD10"><label>(10)</label><mml:math display="block" id="M13" overflow="scroll"><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>exp</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mi>d</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>
<disp-formula id="FD11"><label>(11)</label><mml:math display="block" id="M14" overflow="scroll"><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>exp</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mi>d</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>
<disp-formula id="FD12"><label>(12)</label><mml:math display="block" id="M15" overflow="scroll"><mml:mrow><mml:mi>γ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:msub><mml:mi>S</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mi>y</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula> The second form of urgency signal implemented in
<italic>ChaRTr</italic> follows a simple, linearly increasing function
(uDDM) <disp-formula id="FD13"><label>(13)</label><mml:math display="block" id="M16" overflow="scroll"><mml:mrow><mml:mi>γ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>b</mml:mi><mml:mo>+</mml:mo><mml:mtext>mt</mml:mtext></mml:mrow></mml:math></disp-formula> where <italic>b</italic> is the intercept of the urgency
signal and <italic>m</italic> is the slope.</p>
        <p id="P35">As with the DDMs described above, urgency signal models can
incorporate any combination of variability in starting state, drift rate and
non-decision time, giving rise to a family of different decision-making
models. We also allow for the possibility of variability across decisions in
the intercept term of the linear urgency signal, <disp-formula id="FD14"><label>(14)</label><mml:math display="block" id="M17" overflow="scroll"><mml:mrow><mml:msub><mml:mi>γ</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mtext>mt</mml:mtext></mml:mrow></mml:math></disp-formula>
<disp-formula id="FD15"><label>(15)</label><mml:math display="block" id="M18" overflow="scroll"><mml:mrow><mml:msub><mml:mi>b</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>∼</mml:mo><mml:mi mathvariant="script">U</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>b</mml:mi><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>b</mml:mi></mml:msub></mml:mrow><mml:mn>2</mml:mn></mml:mfrac><mml:mo>,</mml:mo><mml:mi>b</mml:mi><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>b</mml:mi></mml:msub></mml:mrow><mml:mn>2</mml:mn></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula> where <italic>j</italic> denotes an exemplar trial, and
<italic>b</italic> and <italic>s</italic><sub><italic>b</italic></sub>
denote the mean (i.e., midpoint) and range of the uniform distribution
assumed for the urgency signal respectively.</p>
        <p id="P36">In <italic>ChaRTr</italic>, we have assumed that the urgency signal
exerts a multiplicative effect on the sensory evidence (<xref rid="FD9" ref-type="disp-formula">Eq. (9)</xref>). One variation of urgency signal
models proposed in the literature posits that urgency is added to the
sensory evidence, rather than multiplied by it (<xref rid="R40" ref-type="bibr">Hanks et al., 2011</xref>, <xref rid="R39" ref-type="bibr">2014</xref>). In the one-dimensional diffusion models
considered here, additive urgency signals make predictions that cannot be
discriminated from a DDM with collapsing boundaries (<xref rid="R4" ref-type="bibr">Boehm et al., 2016</xref>). That is, for any functional
form of an additive urgency signal, there is a function for the collapsing
boundaries that will generate identical predictions. For this reason we do
not provide an avenue for simulating and estimating additive urgency signal
models in <italic>ChaRTr</italic>, and instead recommend the use of the DDM
with collapsing boundaries.</p>
      </sec>
      <sec id="S13">
        <label>2.1.5.</label>
        <title>Urgency gating model (UGM)</title>
        <p id="P37">In a departure from the classic DDM framework, the urgency gating
model (UGM) proposes there is no integration of evidence, at least not in
the same form as the DDM (<xref rid="R18" ref-type="bibr">Cisek et al.,
2009</xref>; <xref rid="R86" ref-type="bibr">Thura et al., 2012</xref>;
<xref rid="R87" ref-type="bibr">Thura and Cisek, 2014</xref>). Rather,
the UGM assumes that incoming sensory evidence is low-pass filtered, which
prioritizes recent over temporally distant sensory evidence, and this
low-pass filtered signal is modulated by an urgency signal that increases
linearly with time (<xref rid="FD13" ref-type="disp-formula">Eq.
(13)</xref>).</p>
        <p id="P38">Implementation of the UGM in <italic>ChaRTr</italic> uses the
exponential average approach for discrete low-pass filters (smoothing). The
momentary evidence for a decision is a weighted sum of past and present
evidence, which gives rise to the UGM’s pair of governing equations
<disp-formula id="FD16"><label>(16)</label><mml:math display="block" id="M19" overflow="scroll"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mi>τ</mml:mi><mml:mrow><mml:mi>τ</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula>
<disp-formula id="FD17"><label>(17)</label><mml:math display="block" id="M20" overflow="scroll"><mml:mrow><mml:mi>E</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>α</mml:mi><mml:mi>E</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>α</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mi>s</mml:mi><mml:msqrt><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msqrt><mml:mi mathvariant="script">N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></disp-formula> where <italic>τ</italic> is the time constant of the
low-pass filter, which has typically been set to relatively small values of
100 or 200 ms in previous applications of the UGM, and
<italic>α</italic> controls the amount of evidence from previous
time points that influences the momentary evidence at time
<italic>t</italic>. For instance, when <italic>α</italic> = 0
there is no low-pass filtering, and when <italic>τ</italic> = 100 ms
(and Δ<italic>t</italic> is 1 ms) the previous evidence is weighted
by 0.99 and new evidence by 0.01.</p>
        <p id="P39">The decision variable at time <italic>t</italic> is now given as
<disp-formula id="FD18"><label>(18)</label><mml:math display="block" id="M21" overflow="scroll"><mml:mrow><mml:mi>γ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>b</mml:mi><mml:mo>+</mml:mo><mml:mtext>mt</mml:mtext></mml:mrow></mml:math></disp-formula>
<disp-formula id="FD19"><label>(19)</label><mml:math display="block" id="M22" overflow="scroll"><mml:mrow><mml:mi>x</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>E</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>γ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p>
        <p id="P40">The intercept and slope of the urgency signal are set to particular
values in standard applications of the UGM (<italic>b</italic> = 0,
<italic>m</italic> = 1), reducing <xref rid="FD19" ref-type="disp-formula">Eq. (19)</xref> to <disp-formula id="FD20"><label>(20)</label><mml:math display="block" id="M23" overflow="scroll"><mml:mrow><mml:mi>x</mml:mi><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mi>E</mml:mi><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo><mml:mi>t</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p>
        <p id="P41">In <italic>ChaRTr</italic>, we allow for variants of the UGM where
the parameters of the urgency signal are not fixed. For instance, similar to
the DDM with an urgency signal, we can test a UGM where the intercept
(<italic>b</italic>) is freely estimated from data (bUGM), and even an
intercept that varies on a trial-by-trial basis (<xref rid="FD14" ref-type="disp-formula">Eq. (14)</xref>).</p>
      </sec>
    </sec>
    <sec id="S14">
      <label>2.2.</label>
      <title>Fitting models to data</title>
      <sec id="S15">
        <label>2.2.1.</label>
        <title>Parameter estimation</title>
        <p id="P42">In <italic>ChaRTr</italic>, we estimate parameters for each model
and participant independently, using Quantile Maximum Products Estimation
(QMPE; <xref rid="R45" ref-type="bibr">Heathcote et al., 2002</xref>; <xref rid="R44" ref-type="bibr">Heathcote and Brown, 2004</xref>). QMPE uses
the QMP statistic, which is similar to <italic>χ</italic><sup>2</sup>
or multinomial maximum likelihood estimation, and produces estimates that
are asymptotically unbiased and normally distributed with asymptotically
correct standard errors (<xref rid="R9" ref-type="bibr">Brown and Heathcote,
2003</xref>). QMPE quantifies agreement between model predictions and
data by comparing the observed and predicted proportions of data falling
into each of a set of inter-quantile bins. These bins are calculated
separately for the correct and error RT data. In all examples that follow,
we use 9 quantiles calculated from the data (i.e., split the RT data into 10
bins), though the user can specify as many quantiles as they wish. Generally
speaking, we recommend no fewer than 5 quantiles, to prevent loss of
distributional information, and no more than approximately 10 quantiles, to
prevent noisy observations in observed data especially at the tails of the
distribution potentially bearing undue influence on the parameter estimation
routine.</p>
        <p id="P43">Many of the models considered in <italic>ChaRTr</italic> have no
closed-form analytic solution for their predicted distribution. To evaluate
the predictions of each model, we typically simulate 10,000 Monte Carlo
replicates per experimental condition during parameter estimation. Once the
parameter search has terminated, we use 50,000 replicates per experimental
condition to precisely evaluate the model predictions and perform model
selection. In <italic>ChaRTr</italic>, the user can vary the number of
replicates used for parameter estimation and model selection; in previous
applications, we have found these default values provide an appropriate
balance between precision of the model predictions and computational
efficiency. To simulate the models, we use Euler’s method, which
approximates the models’ representation as stochastic differential
equations.</p>
        <p id="P44">Alternatives to our simulation-based approach exist, such as the
integral equation methods of <xref rid="R82" ref-type="bibr">Smith
(2000)</xref> or others that use analytical techniques to calculate
first passage times (<xref rid="R37" ref-type="bibr">Gondan et al.,
2014</xref>; <xref rid="R56" ref-type="bibr">Navarro and Fuss,
2009</xref>), to generate exact distributions. We do not pursue those
methods in <italic>ChaRTr</italic> owing to the model-specific
implementation required, which is inconsistent with
<italic>ChaRTr</italic>’s core philosophy of allowing the user to
rapidly implement a variety of model architectures.</p>
        <p id="P45">We estimate the model parameters using differential evolution to
optimize the goodness of fit (DEoptim package in R, <xref rid="R54" ref-type="bibr">Mullen et al., 2011</xref>). For the type of non-linear
models considered in <italic>ChaRTr</italic>, we have previously found that
differential evolution more reliably recovers the true data generating model
than particle swarm and simplex optimization algorithms (<xref rid="R42" ref-type="bibr">Hawkins et al., 2015a</xref>). DEoptim also allows easy
parallelization and can be used readily in clusters and the cloud with large
number of cores to speed the process of model estimation. However, we again
provide flexibility in this respect; the user can change this default
setting and specify their preferred optimization algorithm (s).</p>
      </sec>
      <sec id="S16">
        <label>2.2.2.</label>
        <title>Model selection</title>
        <p id="P46"><italic>ChaRTr</italic> provides two metrics for quantitative
comparison between models. Each metric is based on the maximized value of
the QMP statistic, which is a goodness-of-fit term that approximates the
continuous maximum likelihood of the data given the model.</p>
        <p id="P47">The DDM is a special case of most of the model variants considered
and will almost always fit more poorly than any of the other variants. We
provide model selection methods that determine if the incorporation of
additional components such as urgency or collapsing bounds provide an
improvement in fit that justifies the increase in model complexity.</p>
        <p id="P48">The raw QMP statistic, as an approximation to the likelihood, can be
used to calculate the Akaike Information Criterion (AIC <xref rid="R3" ref-type="bibr">Akaike, 1974</xref>) and the Bayesian Information
Criterion (BIC; <xref rid="R78" ref-type="bibr">Schwarz, 1978</xref>). We
provide methods to compute AIC and BIC owing to the differing assumptions
underlying the two information criteria (<xref rid="R2" ref-type="bibr">Aho
et al., 2014</xref>), and differing performance with respect to the
modeling goal (<xref rid="R30" ref-type="bibr">Evans, 2019b</xref>).</p>
        <p id="P49"><italic>ChaRTr</italic> also provides functionality to transform the
model selection metrics into model weights, which account for uncertainty in
the model selection procedure and aid interpretation by transformation to
the probability scale. The weight <italic>w</italic> for model
<italic>i</italic>,
<italic>w</italic>(<italic>M</italic><sub><italic>i</italic></sub>),
relative to a set of <italic>m</italic> models, is given by <disp-formula id="FD21"><label>(21)</label><mml:math display="block" id="M24" overflow="scroll"><mml:mrow><mml:mi>w</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>M</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>exp</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mi>Z</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>M</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>m</mml:mi></mml:msubsup><mml:mrow><mml:mi>exp</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mi>Z</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>M</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula> where <italic>Z</italic> is AIC, BIC, or the deviance
(−2× log-likelihood; that is, −2× QMP
statistic). The model weight is interpreted differently depending on the
metric <italic>Z</italic>:</p>
        <list list-type="bullet" id="L2">
          <list-item>
            <p id="P50">Where <italic>Z</italic> is the log-likelihood, the model
weights are relative likelihoods. The log-likelihood should only be
used in the model weight transformation when all models under
consideration have the same number of freely estimated
parameters.</p>
          </list-item>
          <list-item>
            <p id="P51">Where <italic>Z</italic> is the AIC, the model weights
become Akaike weights (<xref rid="R95" ref-type="bibr">Wagenmakers
and Farrell, 2004</xref>).</p>
          </list-item>
          <list-item>
            <p id="P52">Where <italic>Z</italic> is the BIC, and the prior
probability over the <italic>m</italic> models under consideration
is uniform (i.e., each model is assumed to be equally likely before
observing the data), the model weights approximate posterior model
probabilities
(<italic>p</italic>(<italic>M</italic>|<italic>Data</italic>),
<xref rid="R97" ref-type="bibr">Wasserman, 2000</xref>).</p>
          </list-item>
        </list>
        <p id="P53">Although AIC and BIC are provided and easily computed in
<italic>ChaRTr</italic>, their use for discriminating between models
requires careful consideration from the researcher. Our perspective is
influenced by an excellent paper that describes the worldviews for the two
metrics (<xref rid="R2" ref-type="bibr">Aho et al., 2014</xref>). Here, we
provide a succinct summary of the recommendations from <xref rid="R2" ref-type="bibr">Aho et al. (2014)</xref>. Ultimately, whether AIC or BIC
are used depends on the goals of the researcher.</p>
        <p id="P54">If a researcher believes that all of the models implemented in
<italic>ChaRTr</italic> or novel models they develop are all
<italic>wrong</italic> but provide useful descriptions of choice and RT
data, then AIC is more appropriate for model selection. In this scenario,
the goal of model selection is to assess which model will provide the best
predictions for new data. In this sense, AIC is closely linked to cross
validation. As more and more data are collected, the assumption under AIC is
that the model that produces the best predictions will become more and more
complex.</p>
        <p id="P55">In contrast, if a researcher believes that the true model is
implemented in <italic>ChaRTr</italic> or in the set of novel models they
develop, then BIC is likely to be the better tool. In this scenario, the
goal of model selection is to address the question “Which of these
models is correct?”. As more and more data are collected, the
assumption under BIC is that the correct model will be identified. BIC is
thus ideally suited to answer questions about identifying which model was
most likely to have generated the data.</p>
        <p id="P56">The only difference between AIC and BIC is the size of the penalty
term correcting for model complexity. AIC considers false negatives
(“Type II” errors) worse than false positives and errs on the
side of selecting more complex models, and thus can be perceived as favoring
“overfitting” models. In contrast, BIC is more conservative
and considers false positives (“Type I” errors) worse than
false negatives and errs on the side of the selecting simpler models, and
thus could be perceived as favoring “underfitting” models.
Both are valid perspectives and our opinion is that claiming one is better
than the other is not a particularly fruitful endeavor.</p>
        <p id="P57">Thus, our position is that both metrics have utility when a
researcher applies <italic>ChaRTr</italic> to real data. Practically, we
recommend using both AIC and BIC for model comparison as a method for
identifying a set of likely models. We take this approach in the case
studies described below, which leads us to some nuanced conclusions.
Throughout this paper, and in other papers (<xref rid="R15" ref-type="bibr">Chandrasekaran et al., 2018</xref>), we argue that using model
selection techniques such as AIC and BIC to identify a single best model
might not be the best approach. Rather, we suggest researchers use these
metrics judiciously to guide their analyses and ultimately new
experiments.</p>
      </sec>
      <sec id="S17">
        <label>2.2.3.</label>
        <title>Visualization: quantile probability plots</title>
        <p id="P58">Visualization of choice and RT data is critical to understanding
observed and predicted behavior. Such visualization can prove challenging in
studies of rapid decision-making because each cell of the experimental
design (e.g., a particular stimulus difficulty) yields a joint distribution
over the probability of a correct response (accuracy) and separate RT
distributions for correct and error responses. Since most decision-making
tasks manipulate at least one experimental factor across multiple levels,
such as stimulus difficulty, each data set is comprised of a family of joint
distributions over choice probabilities and pairs of RT distributions
(correct, error). Following convention and recommendation (<xref rid="R71" ref-type="bibr">Ratcliff et al., 2016</xref>; <xref rid="R67" ref-type="bibr">Ratcliff and McKoon, 2008</xref>), we visualize these
joint distributions with quantile probability (QP) plots. QP plots are a
compact form to display choice probabilities and RT distributions across
multiple conditions.</p>
        <p id="P59">In a typical QP plot, quantiles of the RT distribution of a
particular type (e.g., correct responses) are plotted as a function of the
proportion of responses of that type. Consider a hypothetical
decision-making experiment with three different levels of stimulus
difficulty; <xref rid="F2" ref-type="fig">Fig. 2</xref> provides a plausible
example of the data from such an experiment. Now assume that for one of the
experimental conditions, the accuracy of the observer was 55%. To display
the choice probabilities, correct RTs and error RTs for this condition, the
QP plot shows a vertical column of <italic>N</italic> markers above the
<italic>x</italic>-axis position ~0.55, where the <italic>N</italic>
markers correspond to the <italic>N</italic> quantiles of the RT
distribution of correct responses (rightmost gray bar in <xref rid="F2" ref-type="fig">Fig. 2</xref>). The QP plot also shows a vertical columns
of <italic>N</italic> markers at the position 1 − 0.55 = 0.45, where
this set of <italic>N</italic> markers correspond to the <italic>N</italic>
quantiles of the distribution of error RTs (leftmost gray bar in <xref rid="F2" ref-type="fig">Fig. 2</xref>). This means that RT distributions
shown to the right of 0.5 on the <italic>x</italic>-axis reflect correct
responses, and those to the left of 0.5 on the <italic>x</italic>-axis
reflect error responses.</p>
        <p id="P60">The default <italic>ChaRTr</italic> QP plot displays 5 quantiles of
the RT distribution: 0.1, 0.3, 0.5, 0.7 and 0.9 (sometimes also referred to
as five percentiles: 10th, 30th, 50th, 70th, 90th). The .1 quantile
summarizes the leading edge of the RT distribution, the 0.5 quantile
(median) summarizes the central tendency of the RT distribution, and the 0.9
quantile summarizes the tail of the RT distribution. The goal of
visualization with QP plots, or other forms of visualization, is to enable
comparison of the descriptive adequacy of a model’s predictions
relative to the observed data.</p>
      </sec>
    </sec>
  </sec>
  <sec id="S18">
    <label>3.</label>
    <title>Results</title>
    <p id="P61">The results section first provides guidance on the use of
<italic>ChaRTr</italic> and how to apply the various models of the
decision-making process to data. The second part of the results section illustrates
the use of <italic>ChaRTr</italic> to analyze choice and RT data from hypothetical
observers, followed by a case study modeling data from two non-human primates (<xref rid="R75" ref-type="bibr">Roitman and Shadlen, 2002</xref>). Code for the
<italic>ChaRTr</italic> toolbox is available at <ext-link ext-link-type="uri" xlink:href="http://sites.bu.edu/chandlab/chartr/">Chartr.chandlab.org/</ext-link> or directly from github at <ext-link ext-link-type="uri" xlink:href="https://github.com/mailchand/ChaRTr">https://github.com/mailchand/ChaRTr</ext-link> and will
eventually be released as an R library.</p>
    <sec id="S19">
      <label>3.1.</label>
      <title>Toolbox flow</title>
      <p id="P62"><xref rid="F3" ref-type="fig">Figs. 3</xref> and <xref rid="F4" ref-type="fig">4</xref> provide flowcharts for <italic>ChaRTr</italic>.
<xref rid="F3" ref-type="fig">Fig. 3</xref> provides an overview of the five
main steps involved in the cognitive modeling process. <xref rid="F4" ref-type="fig">Fig. 4</xref> provides a schematic overview of the steps
involved in the parameter estimation component of the process, which uses the
differential evolution optimization algorithm (<xref rid="R54" ref-type="bibr">Mullen et al., 2011</xref>).</p>
      <p id="P63">The typical steps in <italic>ChaRTr</italic> for estimating the
parameters of a decision-making model from data are as follows:</p>
      <list list-type="order" id="L3">
        <list-item>
          <p id="P64"><bold>Model Specification:</bold> Specify models in the C
programming language, and compile the C code to create the shared
object, Chartr-ModelSpec.so, that is dynamically loaded into the R
workspace. Future versions of <italic>ChaRTr</italic> will use the Rcpp
framework and will not require the compilation and loading of shared
objects (<xref rid="R28" ref-type="bibr">Eddelbuettel and
François, 2011</xref>).</p>
        </list-item>
        <list-item>
          <p id="P65"><bold>Formatting and Loading Data:</bold> Convert raw data into
an appropriate format (choice probabilities, quantiles of RT
distributions for correct and error trials). Save this data object for
each unit of analysis (e.g., a participant, different experimental
conditions for the same participant). Load this data object into the R
workspace.</p>
        </list-item>
        <list-item>
          <p id="P66"><bold>Parameter Specification:</bold> Choose the parameters of
the desired model that need to be estimated along with lower and upper
boundaries on those parameters (i.e., the minimum and maximum value that
each parameter can feasibly take).</p>
        </list-item>
        <list-item>
          <p id="P67"><bold>Parameter Estimation:</bold> Pass the parameters, model
and data to the optimization algorithm (differential evolution). The
algorithm iteratively selects candidate parameter values and evaluates
their goodness of fit to data. This process is repeated until the
goodness of fit no longer improves (<xref rid="F4" ref-type="fig">Fig.
4</xref>).</p>
        </list-item>
        <list-item>
          <p id="P68"><bold>Model Selection:</bold> The parameter estimates from the
search termination point (i.e., the point where goodness of fit no
longer improves), the corresponding goodness of fit statistics and model
predictions are saved for subsequent model selection and
visualization.</p>
        </list-item>
      </list>
      <p id="P69">These 5 steps are repeated for each model and each participant under
consideration. In the next few sections, we elaborate on each of the steps with
examples to illustrate their implementation in <italic>ChaRTr</italic>. We note
that use of <italic>ChaRTr</italic> requires a basic knowledge of R programming,
and if one wishes to design and test a new decision-making model then also C
programming. Owing to the many excellent online resources for both languages (a
simple search of “R program tutorial” will return many helpful
results), we do not provide a tutorial for either language here.</p>
      <p id="P70">
        <graphic xlink:href="nihms-1547435-f0013.jpg" position="float" orientation="portrait"/>
      </p>
      <sec id="S20">
        <label>3.1.1.</label>
        <title>Model specification</title>
        <p id="P71">The difference equation for the model variants implemented in
<italic>ChaRTr</italic> is specified in C code in the file
“Chartr-ModelSpec.c”. An example algorithm for the DDM (<xref rid="S9" ref-type="sec">Section 2.1.1</xref>) is shown in Algorithm 1.
The functions take as input the various parameters that are to be optimized
along with various constants such as the maximum number of time points to
simulate as well as the time step.</p>
        <p id="P72">Once the C code has been specified for the model, the code is
compiled using the following command that uses the SHLIB framework (<xref rid="R62" ref-type="bibr">R Core Team, 2019</xref>) at the terminal
(usually ITERM in mac, Terminal Emulator in linux). The command shown in
<xref rid="T3" ref-type="table">Listing 1</xref> calls the appropriate
compiler (clang on mac, gcc on linux), identifies the appropriate compiler
to run, and loads the appropriate libraries and ensures the correct options
are applied during compilation to create the architecture-specific shared
object.</p>
        <table-wrap id="T3" position="anchor" orientation="portrait">
          <label>Listing 1.</label>
          <caption>
            <p id="P73">Creating a shared library for loading the specified models
into R.</p>
          </caption>
          <table frame="hsides" rules="none">
            <colgroup span="1">
              <col align="left" valign="middle" span="1"/>
            </colgroup>
            <tbody>
              <tr>
                <td align="left" valign="top" rowspan="1" colspan="1">
                  <monospace>$ R CMD SHLIB
chartr-ModelSpec.c</monospace>
                </td>
              </tr>
            </tbody>
          </table>
        </table-wrap>
        <p id="P74">The output of the compilation is a shared object called
<italic>Chartr-ModelSpec</italic>.so that is dynamically loaded into R
for use with the differential evolution optimizer. We anticipate that future
versions of <italic>ChaRTr</italic> will use the Rcpp framework (<xref rid="R28" ref-type="bibr">Eddelbuettel and François,
2011</xref>), which will obviate the need for compiling and loading shared
object libraries.</p>
      </sec>
      <sec id="S21">
        <label>3.1.2.</label>
        <title>Formatting and loading data</title>
        <p id="P75">To estimate the parameters of decision-making models in
<italic>ChaRTr</italic>, the data need to be organized in a separate
comma separated values (CSV) file for each participant in a simple three
column format: “condition, response, RT”.
“condition” is typically a stimulus difficulty parameter,
“response” is correct (1) or incorrect (0), and RT is the
response time (or reaction time when response time and movement can be
separated). For example, in a typical file, data for a single stimulus
difficulty (e.g., one level of motion coherence in a random dot motion task)
would look like <xref rid="T4" ref-type="table">Listing 2</xref>.</p>
        <table-wrap id="T4" position="anchor" orientation="portrait">
          <label>Listing 2.</label>
          <caption>
            <p id="P76">The required raw data format for parameter estimation in
<italic>ChaRTr</italic>.</p>
          </caption>
          <table frame="hsides" rules="none">
            <colgroup span="1">
              <col align="left" valign="middle" span="1"/>
            </colgroup>
            <tbody>
              <tr>
                <td align="left" valign="top" rowspan="1" colspan="1">
                  <monospace>condition, response,
RT</monospace>
                </td>
              </tr>
              <tr>
                <td align="left" valign="top" rowspan="1" colspan="1">
                  <monospace>90,1,0.573</monospace>
                </td>
              </tr>
              <tr>
                <td align="left" valign="top" rowspan="1" colspan="1">
                  <monospace>90,1,0.472</monospace>
                </td>
              </tr>
              <tr>
                <td align="left" valign="top" rowspan="1" colspan="1">
                  <monospace>90,1,0.556</monospace>
                </td>
              </tr>
              <tr>
                <td align="left" valign="top" rowspan="1" colspan="1">
                  <monospace>.</monospace>
                </td>
              </tr>
              <tr>
                <td align="left" valign="top" rowspan="1" colspan="1">
                  <monospace>.</monospace>
                </td>
              </tr>
              <tr>
                <td align="left" valign="top" rowspan="1" colspan="1">
                  <monospace>.</monospace>
                </td>
              </tr>
              <tr>
                <td align="left" valign="top" rowspan="1" colspan="1">
                  <monospace>90,0,0.406</monospace>
                </td>
              </tr>
              <tr>
                <td align="left" valign="top" rowspan="1" colspan="1">
                  <monospace>90,0,0.429</monospace>
                </td>
              </tr>
              <tr>
                <td align="left" valign="top" rowspan="1" colspan="1">
                  <monospace>90,0,0.57</monospace>
                </td>
              </tr>
            </tbody>
          </table>
        </table-wrap>
        <p id="P77">The raw data are converted in
“chartr-processRawData.r” to generate 9 quantiles (10 bins) of
correct and error RTs to be used in the parameter estimation process. It
also stores the data as a R list named <italic>dat</italic>, which includes
four fields: <italic>n</italic>, <italic>p</italic>, <italic>q</italic>,
<italic>pb</italic>.</p>
        <list list-type="bullet" id="L4">
          <list-item>
            <p id="P78"><italic>n</italic> is the number of correct and error
responses in each condition.</p>
          </list-item>
          <list-item>
            <p id="P79"><italic>p</italic> is the proportion of correct responses in
each condition (derived from <italic>n</italic>).</p>
          </list-item>
          <list-item>
            <p id="P80"><italic>q</italic> is the quantiles of the correct and error
RT distributions in each condition.</p>
          </list-item>
          <list-item>
            <p id="P81"><italic>pb</italic> is the number of responses in each bin
of the correct and error RT distributions in each condition (derived
from <italic>n</italic>).</p>
          </list-item>
        </list>
        <p id="P82"><italic>dat</italic> is saved to disk as a new file. The
<italic>dat</italic> file is loaded into the R workspace as required for
the model estimation procedure.</p>
      </sec>
      <sec id="S22">
        <label>3.1.3.</label>
        <title>Parameter specification</title>
        <p id="P83">The next step in model estimation is, for each model, to specify a
list of parameters that can be freely estimated from data along with each
parameter’s lower and upper bound; we provide default suggestions for
the lower and upper boundaries in <italic>ChaRTr</italic>. Model parameters
can be generated by calling the function <italic>paramsandlims</italic> with
two arguments: model name and the number of stimulus difficulty levels in
the experiment. The number of stimulus difficulties is internally converted
into drift rate parameters; for example, if there are <italic>n</italic>
stimulus difficulties, then <italic>paramsandlims</italic> will estimate
<italic>n</italic> independent drift rate parameters. There is also
functionality in <italic>ChaRTr</italic> to specify fixed (non-estimated)
values of some parameters, such as a drift rate of 0 for conditions with
non-informative sensory information (e.g., 0% coherence in a random dot
motion experiment). <italic>paramsandlims</italic> returns a named list with
the following fields: lowers, uppers, parnames, fitUGM. These variables are
used internally in the parameter estimation routines.</p>
      </sec>
      <sec id="S23">
        <label>3.1.4.</label>
        <title>Parameter estimation</title>
        <p id="P84">Steps 1–3 loaded the required data, identified the desired
model to fit and specified the parameters of the model to be estimated. This
information is now passed to the optimization algorithm (differential
evolution). Parameter optimization is an iterative process of proposing
candidate parameter values, accepting or rejecting candidate parameter
values based on their goodness of fit, and repeating. This process continues
until the proposed parameter values no longer improve the model’s
goodness of fit. These are assumed to be the best-fitting parameter values,
or the (approximate) maximum likelihood estimates. <xref rid="F4" ref-type="fig">Fig. 4</xref> provides an overview of the steps involved
in parameter estimation when using the differential evolution optimization
algorithm (<xref rid="R54" ref-type="bibr">Mullen et al., 2011</xref>).</p>
        <p id="P85">The accompanying file “Chartr-DemoFit.r” provides a
complete code example for estimating the parameters of a model with
urgency.</p>
      </sec>
      <sec id="S24">
        <label>3.1.5.</label>
        <title>Model selection</title>
        <p id="P86">Once the best-fitting parameters have been estimated from a set of
candidate models, the final step is to use this information to guide
inference about the relative plausibility of each of the models given the
data. Many different levels of questions can be asked of these models. The
best practices for model selection are described generally in <xref rid="R2" ref-type="bibr">Aho et al. (2014)</xref> and for the specific problem of
behavioral modeling in <xref rid="R46" ref-type="bibr">Heathcote et al.
(2015)</xref>.</p>
        <p id="P87">In <italic>ChaRTr</italic>, we provide functions for converting the
raw QMP statistic that approximates the likelihood. The likelihood is a
goodness-of-fit statistic that can be combined with penalized model
comparison metrics. This could entail comparison between two models at
multiple levels of granularity. For instance, the question could be
“which of the models considered provides the better description of
the data”, or “is a DDM with variable baseline better than a
DDM without a variable baseline”. It could also be used to compare
between a model with collapsing boundaries and a model with drift-rate
variability (<xref rid="R57" ref-type="bibr">O’Connell et al.,
2018a</xref>) or between models with different forms of collapsing
boundaries (<xref rid="R42" ref-type="bibr">Hawkins et al., 2015a</xref>).
All of these questions can be answered using <italic>ChaRTr</italic>. As a
guide, we provide illustrations of model selection analyses using
<italic>ChaRTr</italic> in two case studies presented in <xref rid="S1" ref-type="sec">Section 3.4</xref>. We also apply the model selection
analyses to the behavior of monkeys performing a decision-making task (<xref rid="R75" ref-type="bibr">Roitman and Shadlen, 2002</xref>).</p>
      </sec>
    </sec>
    <sec id="S25">
      <label>3.2.</label>
      <title>Extending ChaRTr</title>
      <p id="P88"><italic>ChaRTr</italic> is designed with the goal of being readily
extensible, to allow the user to specify new models with minimal development
time. This frees the user to focus on the models of scientific interest while
<italic>ChaRTr</italic> takes care of the model estimation and selection
details behind the scenes. Here, we provide an overview of the steps required to
add new models to <italic>ChaRTr</italic>.</p>
      <list list-type="order" id="L5">
        <list-item>
          <p id="P89">Add a new function to “Chartr-ModelSpec.c” with
the parameters needed to be estimated for the model. Specify the model
in C code, following the structure of the pseudo-code example given in
Algorithm 1. Provide the new model with a unique name (i.e., not shared
with any other models in the toolbox), preferably using the convention
defined in <xref rid="T2" ref-type="table">Table 2</xref>.</p>
        </list-item>
        <list-item>
          <p id="P90">Add any new parameters of the model to the function
makeparamlist, and to the <italic>paramsandlims</italic> function in
script “Chartr-HelperFunctions.r”.</p>
        </list-item>
        <list-item>
          <p id="P91">Add the name of the model to the function
<italic>returnListOfModels</italic>, in script
“Chartr-HelperFunctions.r”.</p>
        </list-item>
        <list-item>
          <p id="P92">Make sure additional parameters are passed to the functions
<italic>diffusionC</italic> and <italic>getpreds</italic>, in
scripts “<italic>ChaRTr</italic>-HelperFunctions.r” and
“<italic>ChaRTr</italic>-FitRoutines.r”,
respectively.</p>
        </list-item>
        <list-item>
          <p id="P93">Finally, specify in function <italic>diffusionC</italic> the
code for generating choices and RTs to use for model fitting. For
example, the code for generating the choices and RTs for
DDMS<sub><italic>v</italic></sub>S<sub><italic>z</italic></sub>S<sub><italic>t</italic></sub>
is shown in Listing 3.</p>
        </list-item>
      </list>
      <p id="P94"><bold>Listing 3.</bold> R Code for simulating choices and RTs for the
model
DDMS<italic><sub>v</sub></italic>S<italic><sub>z</sub></italic>S<italic><sub>t</sub></italic>.</p>
      <p id="P95">
        <graphic xlink:href="nihms-1547435-f0014.jpg" position="float" orientation="portrait"/>
      </p>
    </sec>
    <sec id="S26">
      <label>3.3.</label>
      <title>Simulating data from models in ChaRTr</title>
      <p id="P96">Once models are specified, they can be used to generate simulated RTs
and discrimination accuracy for each condition. Simulated data help refine
quantitative hypotheses. They also provide much greater insight into the
dynamics of different decision-making models and how different variables in
these models modulate the predicted RT distributions for correct and error
trials (<xref rid="R67" ref-type="bibr">Ratcliff and McKoon, 2008</xref>).</p>
      <p id="P97"><italic>ChaRTr</italic> provides straightforward methods to simulate
data from decision-making models and generate quantile probability plots to
compactly summarize and visualize RT distributions and accuracy. The function
<italic>paramsandlims</italic>, used above in the parameter estimation
routine, can also be used to generate hypothetical parameters to be passed to
the function <italic>simulateRTs</italic>, which generates a set of simulated
RTs and choice responses. By hypothetical parameters, we mean a set of
reasonable starting values. An example is shown in <xref rid="T5" ref-type="table">Listing 4</xref>. These parameters can be changed by the
user.</p>
      <table-wrap id="T5" position="anchor" orientation="portrait">
        <label>Listing 4.</label>
        <caption>
          <p id="P98">R code for simulating RT and choice responses from the simple
diffusion decision model (DDM).</p>
        </caption>
        <table frame="hsides" rules="none">
          <colgroup span="1">
            <col align="left" valign="middle" span="1"/>
          </colgroup>
          <tbody>
            <tr>
              <td align="left" valign="top" rowspan="1" colspan="1">
                <monospace>source(“chartr-HelperFunctions.r”)</monospace>
              </td>
            </tr>
            <tr>
              <td align="left" valign="top" rowspan="1" colspan="1">
                <monospace>nCoh = 5</monospace>
              </td>
            </tr>
            <tr>
              <td align="left" valign="top" rowspan="1" colspan="1">
                <monospace>nmc =
50000</monospace>
              </td>
            </tr>
            <tr>
              <td align="left" valign="top" rowspan="1" colspan="1">
                <monospace>model =
“DDM”</monospace>
              </td>
            </tr>
            <tr>
              <td align="left" valign="top" rowspan="1" colspan="1">
                <monospace>fP = paramsandlims(model,
nCoh, hypoPars = TRUE)</monospace>
              </td>
            </tr>
            <tr>
              <td align="left" valign="top" rowspan="1" colspan="1">
                <monospace>currParams =
fP$hypoParams</monospace>
              </td>
            </tr>
            <tr>
              <td align="left" valign="top" rowspan="1" colspan="1">
                <monospace>R= simulateRTs(model,
currParams, n=nmc, nds=nCoh)</monospace>
              </td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
      <p id="P99"><xref rid="F5" ref-type="fig">Fig. 5</xref> shows the output of
“Chartr-Demo.r”, which simulates and visualizes choice and RT data
from four models in <italic>ChaRTr</italic>: DDM,
DDMS<sub><italic>v</italic></sub>S<sub><italic>z</italic></sub>S<sub><italic>t</italic></sub>,
UGMS<sub><italic>v</italic></sub>, and
dDDMS<sub><italic>v</italic></sub>. <xref rid="F5" ref-type="fig">Fig.
5A</xref> shows predictions of the simple DDM (see <xref rid="S9" ref-type="sec">Section 2.1.1</xref>), a symmetric, inverted-U shaped QP plot
(<xref rid="R67" ref-type="bibr">Ratcliff and McKoon, 2008</xref>); the
symmetry implies that correct and error RTs are identically distributed. As
variability is introduced to the DDM’s starting state
(<italic>S</italic><sub><italic>z</italic></sub>) and/or drift-rate
(<italic>S</italic><sub><italic>v</italic></sub>; see <xref rid="S10" ref-type="sec">Section 2.1.2</xref>), the QP plot loses its symmetry (<xref rid="F5" ref-type="fig">Fig. 5B</xref>); relative to correct RTs, error RTs
can be faster (due to <italic>S</italic><sub><italic>z</italic></sub>) or slower
(due to <italic>S</italic><sub><italic>v</italic></sub>). <xref rid="F5" ref-type="fig">Fig. 5B</xref> also introduced variability in non-decision
time (<italic>S</italic><sub><italic>t</italic></sub>), which increases the
variance of the fastest responses.</p>
      <p id="P100"><xref rid="F5" ref-type="fig">Fig. 5C</xref> shows predictions of a
standard variant of the UGM model (UGMS<sub><italic>v</italic></sub>) that
assumes variable drift rate, zero intercept, a slope (<italic>β</italic>)
of 1 and a time constant of 100 ms (see <xref rid="S1" ref-type="sec">Section
2.1.5</xref>). The urgency gating mechanism in this model reduces the
positive skew of the RT distributions, and leads to the prediction that error
RTs are always slower than correct RTs (<xref rid="F5" ref-type="fig">Fig.
5C</xref>; <xref rid="R43" ref-type="bibr">Hawkins et al., 2015b</xref>).
Like the UGM, the dDDMS<sub><italic>v</italic></sub> model, another model of
urgency (see <xref rid="S1" ref-type="sec">Section 2.1.4</xref>), also predicts
reduced positive skew of the RT distributions. Unlike the standard UGM, however,
it can also predict error RTs that are faster or slower than correct RTs (<xref rid="F5" ref-type="fig">Fig. 5D</xref>).</p>
      <p id="P101">It is clear from <xref rid="F5" ref-type="fig">Fig. 5</xref> that
various features in data discriminate between various features of the
decision-making models: the relative speed of correct and error RTs, and
critically the shape of complete RT distributions. We now provide three
illustrative case studies that take advantage of the differential predictions of
the models, demonstrating the use of <italic>ChaRTr</italic> for parameter
estimation and selection amongst sets of competing models.</p>
    </sec>
    <sec id="S27">
      <label>3.4.</label>
      <title>Case studies</title>
      <p id="P102">To illustrate the utility of the toolbox, we provide three case studies
where we simulated data from decision-making models in <italic>ChaRTr</italic>
(case studies 1 and 2) or use <italic>ChaRTr</italic> to model data collected
from monkeys performing a decision-making task (case study 3). We use the case
studies to demonstrate the typical model estimation and selection analyses. The
case studies also provide a modest test of model and parameter recovery. That
is, whether <italic>ChaRTr</italic> reliably suggests that the true
data-generating model is in the set of candidate models, and whether it reliably
estimates the parameters of the true data-generating model.</p>
      <sec id="S28">
        <label>3.4.1.</label>
        <title>Case study 1: hypothetical data generated from a DDM with variable drift
rate and non-decision time (DDMS<sub>v</sub>S<sub>t</sub>)</title>
        <p id="P103">For our first case study, we assumed the data came from
hypothetical observers who made decisions in a manner consistent with a DDM
with variable drift rate (<italic>S</italic><sub><italic>v</italic></sub>)
and variable start times (<italic>S</italic><sub><italic>t</italic></sub>).
In <italic>ChaRTr</italic>, this corresponds to simulating data from the
model DDMS<sub><italic>v</italic></sub>S<sub><italic>t</italic></sub>, where
an observer’s RTs exhibit variability due to both the
decision-formation process and the non-decision components. We simulated 300
trials for each of 5 stimulus difficulties, for 5 hypothetical
participants.</p>
        <p id="P104">For each model and hypothetical participant, we repeated the
parameter estimation procedure 5 times, independently. We strongly recommend
this redundant-estimation approach as it greatly reduces the likelihood of
terminating the optimization algorithm in local minima, which can arise in
simulation-based models like those implemented in <italic>ChaRTr</italic>.
Variability occurs due to randomness in simulating predictions of the model
at each iteration of the optimization algorithm, and randomness in the
optimization algorithm itself (for a similar approach see <xref rid="R42" ref-type="bibr">Hawkins et al., 2015a</xref>,<xref rid="R43" ref-type="bibr">b</xref>). We then select the best of the 5 independent
parameter estimation procedures (or ‘runs’) for each model and
participant (i.e., the ‘run’ with the highest value of the QMP
statistic). If computational constraints are not an issue, then we encourage
as many repetitions as possible of the parameter estimation procedure.</p>
        <p id="P105"><xref rid="F6" ref-type="fig">Fig. 6A</xref> and <xref rid="F6" ref-type="fig">B</xref> shows the AICs and BICs for a set of models,
obtained after using <italic>ChaRTr</italic> to fit the choice and RT data
from one of the hypothetical observers. Both information criteria (ICs) are
reported with reference to the DDM (i.e., as difference scores relative to
the DDM). Thus, negative values suggest a more parsimonious account of the
data than the DDM, and positive values suggest the opposite. <xref rid="F6" ref-type="fig">Fig. 6C</xref> shows the Akaike weights and BIC-based
approximate posterior model probabilities (<xref rid="FD21" ref-type="disp-formula">Eq. (21)</xref>) for the top six models.</p>
        <p id="P106">The AIC scores/weights suggest that
DDMS<sub><italic>v</italic></sub>S<sub><italic>t</italic></sub> provides
the best account of the data; by ‘best account’, we mean the
model that provided the most appropriate tradeoff between model fit and
model complexity among the specific set of models under consideration,
according to AIC. This suggests that <italic>ChaRTr</italic> reliably
recovers the generating model as one of the candidate models – a
necessary test for any parameter estimation and model selection analysis. We
strongly recommend this form of <italic>model recovery</italic> analysis
when developing and testing any proposed cognitive model; if a
data-generating model cannot be successfully identified as a set of
candidate models in simulated data, where the true model is known, it is not
a useful measurement model for real data.</p>
        <p id="P107">The BIC scores/weights also suggest that
DDMS<sub><italic>v</italic></sub>S<sub><italic>t</italic></sub> and
DDMS<sub><italic>t</italic></sub> are the best models for describing
the data. However, interestingly, BIC ranks
DDMS<sub><italic>t</italic></sub> higher than
DDMS<sub><italic>v</italic></sub>S<sub><italic>t</italic></sub>.
This result does not suggest that <italic>ChaRTr</italic> is failing to
recover the data generating model. Instead, our interpretation of the
results is that both
DDMS<sub><italic>v</italic></sub>S<sub><italic>t</italic></sub> and
DDMS<sub><italic>t</italic></sub> should be considered candidate
explanations for the data and that they are very close in terms of
explanations for the choice and response time data. That is, the most likely
explanation for the data is a DDM with variable non-decision time. There
might also be a contribution from drift rate variability. As we explained in
the methods, AIC is more focused on false negatives and thus places a lower
penalty on complexity. BIC is more focused on false positives and thus
places a higher penalty on complexity.</p>
        <p id="P108">The models <italic>ChaRTr</italic> ranked 3rd to 6th using both AIC
and BIC were sensibly related to the data-generating model. These models all
assumed that observed RTs were influenced by factors other than sensory
evidence (such as growing impatience), which might mimic the data-generating
model’s RT variability that arose due to factors external to the
decision-formation process (variable non-decision time). The results serve
as an important reminder that model selection should not be used to argue
for the “best” model in an absolute sense. Rather, when
considering the collection of the highest ranked models (e.g., models in
green and orange in <xref rid="F6" ref-type="fig">Fig. 6A</xref> and <xref rid="F6" ref-type="fig">B</xref>) it can be most constructive to rank
useful hypotheses/explanations of the data that can then guide further study
(<xref rid="R11" ref-type="bibr">Burnham et al., 2011</xref>), which is
the approach we have used here. For instance, considering this set of
highly-ranked models provides strong evidence that the true decision process
involves perfect information integration (as opposed to low-pass filtering
of sensory evidence, as in the UGM) and includes variability in non-decision
time components, which were both components of the data-generating
model.</p>
        <p id="P109"><xref rid="F6" ref-type="fig">Fig. 6D</xref> shows the estimated
parameter values for the
DDMS<sub><italic>v</italic></sub>S<sub><italic>t</italic></sub>
model. The parameter estimates were very similar to the data-generating
values, with some minor over- or under-estimation of the drift rate
parameters. This suggests that <italic>ChaRTr</italic> can reasonably
recover the data-generating model <italic>and</italic> parameters. As above,
we also strongly recommend this form of <italic>parameter recovery</italic>
analysis when developing and testing any proposed cognitive model.</p>
        <p id="P110"><xref rid="F6" ref-type="fig">Fig. 6E</xref> shows the model
selection outcomes from another hypothetical observer. When using AIC,
<italic>ChaRTr</italic> again identifies the best fitting model as
DDMS<sub><italic>v</italic></sub>S<sub><italic>t</italic></sub> and
the next best model as DDMS<sub><italic>t</italic></sub>. BIC again prefers
DDMS<sub><italic>t</italic></sub> over
DDMS<sub><italic>v</italic></sub>S<sub><italic>t</italic></sub>. A few
other models also provided good accounts of the data. As was the case for
observer 1, these models predict variability in RTs due to mechanisms
outside the decision-formation process.</p>
        <p id="P111">In the three other hypothetical observers that we simulated, the
pattern of results returned by <italic>ChaRTr</italic> was consistent with
the results shown for the two hypothetical observers in <xref rid="F6" ref-type="fig">Fig. 6</xref>:
DDMS<sub><italic>v</italic></sub>S<sub><italic>t</italic></sub> was
chosen as the best fitting model for all observers by AIC. If we assume the
set of observers are independent, which is true in the case of our
hypothetical example and usually in experiments, we can average the
individual-participant posterior model probabilities to obtain a group-level
estimate. As shown in <xref rid="F6" ref-type="fig">Fig. 6F</xref>, across
the set of observers
DDMS<sub><italic>v</italic></sub>S<sub><italic>t</italic></sub> is
identified as the most plausible model for the data, indicating reasonably
good model recovery; the next-best models are the same as those described
earlier. The results from BIC were again consistent, preferring the
DDMS<sub><italic>t</italic></sub> model over
DDMS<sub><italic>v</italic></sub>S<sub><italic>t</italic></sub> for
this group of hypothetical observers.</p>
        <p id="P112"><xref rid="F7" ref-type="fig">Fig. 7</xref> shows QP plots of the
data from two hypothetical observers overlaid on the predictions from a
range of models. The simple DDM predicted greater variance than was observed
in data, and therefore provided a poor account of the data. When the DDM is
augmented with S<sub><italic>t</italic></sub> and both
S<sub><italic>v</italic></sub> and S<sub><italic>t</italic></sub>,
it provided a much improved account of the data, capturing most of the RT
quantiles and the accuracy patterns. Three other models provided an
almost-equivalent account of the data in terms of log-likelihoods
(DDMS<sub><italic>v</italic></sub>S<sub><italic>z</italic></sub>S<sub><italic>t</italic></sub>,
cfkDDMS<sub><italic>v</italic></sub>S<sub><italic>t</italic></sub>,
dDDMS<sub><italic>v</italic></sub>S<sub><italic>t</italic></sub>),
but they did so with the use of more model parameters than
DDMS<sub><italic>v</italic></sub>S<sub><italic>t</italic></sub> and
DDMS<sub><italic>t</italic></sub>. This led to a larger complexity
penalty for those models and thus larger AICs and BICs in comparison to the
DDMS<sub><italic>v</italic></sub>S<sub><italic>t</italic></sub>
model, as shown in the model selection analysis in <xref rid="F6" ref-type="fig">Fig. 6</xref>.</p>
        <p id="P113">Together, this case study highlights the power of
<italic>ChaRTr</italic> in discriminating between 37 albeit overlapping
models of decision-making and ranking the most likely models. As we have
emphasized, the models selected by AIC and BIC will differ slightly because
of the different penalties assumed for the two methods which underlie their
different philosophies. If we obtained this result in real data, our
interpretation would be that for this population of subjects, the data are
consistent with a model that involves a DDM and variable non-decision time
and that there is also the possibility of variability in the drift rate
parameter. We would also conclude that the most likely models are DDMs
without a dynamic component such as an urgency signal, since the DDMs
performed better than models with collapsing boundaries or urgency.</p>
      </sec>
      <sec id="S29">
        <label>3.4.2.</label>
        <title>Case study 2: hypothetical data generated from a UGM with variable
intercept (bUGMS<sub>v</sub>)</title>
        <p id="P114">In a second case study we simulated data from hypothetical
observers whose decision-formation process was controlled by an urgency
gating model (<xref rid="R18" ref-type="bibr">Cisek et al., 2009</xref>;
<xref rid="R86" ref-type="bibr">Thura et al., 2012</xref>) with a
variable drift rate and an intercept (<xref rid="R14" ref-type="bibr">Chandrasekaran et al., 2017</xref>), termed
bUGMS<sub><italic>v</italic></sub> in <italic>ChaRTr</italic>. We
again assumed five hypothetical subjects, five stimulus difficulties and
simulated 500 trials for each of them. We then fit the data with the
redundant-estimation approach as in case study 1 and evaluated the results
of the model selection analysis, all using routines contained in
<italic>ChaRTr</italic>.</p>
        <p id="P115"><xref rid="F8" ref-type="fig">Fig. 8A</xref> and <xref rid="F8" ref-type="fig">B</xref> shows the AICs and BICs for the set of models
considered for one hypothetical observer’s data, again referenced to
the DDM (i.e., as difference scores relative to the DDM). Negative values
suggest a more parsimonious account of the data than the DDM, and positive
values suggest the opposite. <xref rid="F8" ref-type="fig">Fig. 8C</xref>
shows the Akaike weights and posterior model probabilities for the top six
models. bUGMS<sub><italic>v</italic></sub> provides the best account of the
data for this hypothetical observer according to both AIC and BIC.</p>
        <p id="P116">The models <italic>ChaRTr</italic> ranked 2nd to 6th were also
sensibly related to the data-generating model; they all assumed the
decision-formation process was influenced by factors other than sensory
evidence, such as growing impatience or other variants of the urgency gating
model. The second case study reaffirms our conclusion from the first case
study that model selection may not be put to best use when arguing for a
single “best” model in an absolute sense. This is especially
true when the data-generating model is not decisively recovered from
data.</p>
        <p id="P117">For example, <xref rid="F8" ref-type="fig">Fig. 8D</xref> shows the
top six models identified by <italic>ChaRTr</italic> using AIC and BIC as
providing the best account of another of the hypothetical observers’
data. For this particular hypothetical dataset, many other models provided a
better account than the generative model bUGMS<sub><italic>v</italic></sub>.
This result highlights two important points. First, some models under some
circumstances can mimic each other (i.e., generate similar predictions),
which makes their identification in data difficult. Second, some models may
not be mimicked, but they may require very many data points to reliably
recover. We note that these points are not specific to
<italic>ChaRTr</italic> – they are properties of quantitative
model selection in general and are an important reminder of the necessary
careful steps needed when aiming to select between models (<xref rid="R15" ref-type="bibr">Chandrasekaran et al., 2018</xref>).</p>
        <p id="P118"><xref rid="F8" ref-type="fig">Fig. 8E</xref> shows the Akaike
weights (left panel) and posterior model probabilities (right panel) for the
different models averaged over all five observers considered. Reassuringly,
the most plausible model across the set of observers is the generative model
bUGMS<sub><italic>v</italic></sub> for both AIC and BIC. For AIC,
the next five best models are all conceptually related to the data
generating model. For instance, the next best model was
uDDMS<sub><italic>v</italic></sub> which is a DDM with urgency but
no gating. The third best model was
bUGMS<sub><italic>v</italic></sub>S<sub><italic>b</italic></sub>
which is an urgency gating model with variable intercept.</p>
        <p id="P119">Similarly, when using posterior model probabilities, the most
plausible model across the set of observers is the generative model
bUGMS<sub><italic>v</italic></sub>. Again the next five best models
are all conceptually related to the data generating model. For instance, the
next best model was bUGM which is an urgency gating model with an intercept
and no drift rate variability. The third best model was uDDM which is a DDM
with an urgency signal but no gating.</p>
        <p id="P120">Together these results serve as another reminder of the utility of
<italic>ChaRTr</italic> in the analysis of decision-making models,
including the ability to quantitatively assess a large set of conceptually
similar and dissimilar models. If we were to obtain results like the case
study in a hypothetical experiment, we would reject a simple DDM as an
explanation for our data and suggest that a model with an urgency signal
containing an intercept is a more likely model to explain the data. We would
also likely suggest the presence of a gating component in the data but
qualify our conclusions by saying that additional subjects and larger number
of trials per subject would be needed for more confidence in the result.</p>
      </sec>
      <sec id="S30">
        <label>3.4.3.</label>
        <title>Case study 3: behavioral data from monkeys reported in <xref rid="R75" ref-type="bibr">Roitman and Shadlen (2002)</xref></title>
        <p id="P121">To demonstrate the utility of <italic>ChaRTr</italic> in
understanding experimental data, we model the freely available choice and RT
data from two monkeys performing a random dot motion decision-making task
(<xref rid="R75" ref-type="bibr">Roitman and Shadlen, 2002</xref>). In
this classic variant of the random-dot motion task, the monkeys were trained
to report the direction of coherent motion with eye movements. The
percentage of coherently moving dots was randomized from trial to trial
across six levels (0%, 3.2%, 6.4%, 12.8%, 25.6% and 51.2%). Monkey b
completed 2614 trials and Monkey n completed 3534 trials.</p>
        <p id="P122">We demonstrate that <italic>ChaRTr</italic> replicates key findings
from past analyses of these behavioral data. <xref rid="R75" ref-type="bibr">Roitman and Shadlen (2002)</xref>’s behavioral (and neural) data
were originally interpreted as a neural correlate of the DDM. Later studies
suggested a stronger role for impatience/urgency in these data (<xref rid="R23" ref-type="bibr">Ditterich, 2006a</xref>; <xref rid="R43" ref-type="bibr">Hawkins et al., 2015b</xref>). This is the first result
we wish to reaffirm using <italic>ChaRTr</italic>. The second result we aim
to reaffirm is that <xref rid="R42" ref-type="bibr">Hawkins et al.
(2015a)</xref> showed the urgency gating model provides a better
description of the data than the DDM. We note that recent work suggests the
evidence for impatience/urgency in <xref rid="R75" ref-type="bibr">Roitman
and Shadlen (2002)</xref>’s data might be the result of the
particular training regime their monkeys experienced that is not shared by
other monkey training protocols (<xref rid="R31" ref-type="bibr">Evans and
Hawkins, 2019</xref>).</p>
        <p id="P123"><xref rid="F9" ref-type="fig">Fig. 9A</xref> and <xref rid="F9" ref-type="fig">B</xref> shows the results from <italic>ChaRTr</italic>.
For both monkeys, the four best-performing models all included a DDM with
collapsing bounds, and the worst performing models were largely DDMs without
any form of urgency. As mentioned above, for any functional form of a
collapsing boundary there is a form of additive urgency signal that can
generate identical predictions. So finding that collapsing bound models
describe the data better is consistent with prior observations that
(additive) urgency is an important factor. Together, the results are broadly
consistent with those of <xref rid="R23" ref-type="bibr">Ditterich
(2006a)</xref> and <xref rid="R43" ref-type="bibr">Hawkins et al.
(2015b</xref>) who reported that models with forms of impatience are
systematically better than models without it, for <xref rid="R75" ref-type="bibr">Roitman and Shadlen (2002)</xref>’s data. <xref rid="F9" ref-type="fig">Fig. 9C</xref> and <xref rid="F9" ref-type="fig">D</xref> shows that when the comparison is restricted to a subset of
the <italic>ChaRTr</italic> models – UGMs and DDMs – variants
of the UGM better explain the behavior of the monkeys than variants of the
DDM, which is consistent with the findings of <xref rid="R42" ref-type="bibr">Hawkins et al. (2015a)</xref>.</p>
        <p id="P124">We can use <italic>ChaRTr</italic> to derive more insights into the
behavior of the monkeys in this decision-making task, by examining whether
urgency or the time constant of integration is a more important factor in
explaining their behavior. <xref rid="F10" ref-type="fig">Fig. 10</xref>
shows quantile probability plots for five models:
DDMS<sub><italic>v</italic></sub>S<sub><italic>z</italic></sub>S<sub><italic>t</italic></sub>,
a model from the DDM class without urgency but elaborated with variability
in various parameters (S<sub><italic>v</italic></sub>,
S<sub><italic>z</italic></sub>, S<sub><italic>t</italic></sub>), two
models with urgency and variability in some parameters
(uDDMS<sub><italic>v</italic></sub>S<sub><italic>t</italic></sub>,
uDDMS<sub><italic>v</italic></sub>S<sub><italic>b</italic></sub>),
and two UGM models with variability in parameters
(bUGMS<sub><italic>v</italic></sub>S<sub><italic>b</italic></sub>,
bUGMS<sub><italic>v</italic></sub>S<sub><italic>t</italic></sub>).
As was shown in the model selection outcomes in <xref rid="F9" ref-type="fig">Fig. 9</xref>, the addition of urgency dramatically
improved the ability of the models to account for the decision-making
behavior of the two monkeys.</p>
        <p id="P125">We next used <italic>ChaRTr</italic> for a preliminary analysis of
whether the gating component of the urgency gating model improves model
predictions over and above urgency alone. In both monkeys, we found that the
data are slightly more consistent with models such as
bUGMS<sub><italic>v</italic></sub>S<sub><italic>b</italic></sub> and
bUGMS<sub><italic>v</italic></sub>S<sub><italic>t</italic></sub>,
models that involve urgency and gating with a 100 ms time constant of
integration (<xref rid="F10" ref-type="fig">Fig. 10</xref>). These
observations provide hypotheses for further analyses of the neural data and
further targeted model selection. Together, our conclusions would be that
urgency is the more important factor. However, there might be a modest role
for imperfect integration as well (especially in monkey n).</p>
        <p id="P126">Together, the results in <xref rid="F9" ref-type="fig">Figs.
9</xref> and <xref rid="F10" ref-type="fig">10</xref> highlight the ease
with which <italic>ChaRTr</italic> can be used to make insightful statements
about the latent cognitive processes underlying behavior in decision-making
tasks and ultimately may be a stepping stone for deeper insights into
mechanism (<xref rid="R51" ref-type="bibr">Krakauer et al.,
2017</xref>).</p>
      </sec>
    </sec>
    <sec id="S31">
      <label>3.5.</label>
      <title>Performance</title>
      <p id="P127">In this final section we discuss computational requirements for a full
<italic>ChaRTr</italic> model selection analysis. <xref rid="F11" ref-type="fig">Fig. 11A</xref>–<xref rid="F11" ref-type="fig">C</xref> shows that the average time to estimate the set of 37
<italic>ChaRTr</italic> models for a single run for a single subject is
approximately 88 h. This estimate is based on tests on a node of the Boston
University Shared Computing Cluster (BU SCC, two 14 core 2.4 GHz Xeon
E5–2680V4 processors, 256 GB RAM) for an implementation with 400
particles in the differential evolution optimizer, 10,000 Monte Carlo replicates
per experimental condition, and un-optimized random number generators. We
consider this the baseline performance of <italic>ChaRTr</italic> as it reflects
the initial implementation of the code.</p>
      <p id="P128">We also investigated factors that influenced computation time for the
models. As might be expected, computation time increases as model complexity
(number of parameters) increases, though this is not the sole driver of the time
required for the model fitting analysis. Our parameter estimation approach
(QMPE) is based on quantiles of the RT data, meaning that the size of the data
set does not influence run speed. This is different to alternative estimation
schemes such as maximum likelihood estimation that scales directly with the size
of the data set. However, three other factors that we loosely term
“hyperparameters” increase computational time in
<italic>ChaRTr</italic>: the random number generators, the number of
particles used in the differential evolution algorithm, and the number of Monte
Carlo replicates per experimental condition (i.e., number of simulated trials).
Optimizing these hyperparameters increases the speed of the model fits. Below we
outline how changing these parameters improves the computational performance of
<italic>ChaRTr</italic>.</p>
      <p id="P129">In a recent study, <xref rid="R29" ref-type="bibr">Evans (2019a)</xref>
analyzed models similar to those in <italic>ChaRTr</italic> and found that a
relatively large amount of time is spent generating random numbers for
simulating the models (in particular, sampling the diffusion noise on each time
step of each simulated trial). In our C implementation, random number generation
is performed using the norm_rand() function, and it is the most time consuming
component of the simulation. To reduce the time required for random number
generation, <xref rid="R29" ref-type="bibr">Evans (2019a)</xref> recommended
replacing the norm_rand() function of the random number generation process with
Lookup Tables (LUTs). We implemented the recommended LUTs and compared them to
the speed of our original implementation on the same compute nodes (BU SCC, 28
core systems). Using LUTs for random number generation decreased simulation
time: For the 37 models we considered, the revised implementation was performed
in ~56 h (compare “slow” to “fast” in <xref rid="F11" ref-type="fig">Fig. 11A</xref>–<xref rid="F11" ref-type="fig">C</xref>). This is ~36% faster than the standard
implementation.</p>
      <p id="P130">Second, we considered the number of particles used to explore the
parameter space in the differential evolution optimization algorithm. In
general, a higher number of particles is better as it minimizes the risk of
falling into local minima, though this comes at the cost of computational time.
We reduced the number of particles from 400 to 200 and found that computation
time again halved (<xref rid="F11" ref-type="fig">Fig. 11A</xref>–<xref rid="F11" ref-type="fig">C</xref>). The general rule of thumb proposed for
the number of particles is 10 times the number of parameters to be estimated;
200 particles is consistent with the rule of thumb for the models implemented in
<italic>ChaRTr</italic>.</p>
      <p id="P131">Finally, a key component of the parameter estimation routine is to
simulate thousands of trials for a given set of parameters (i.e., one particle
for one iteration of the differential evolution algorithm) and then assess
whether the simulated data are in close agreement with the observed data. The
speed-up obtained when we halved the number of simulated trials from our
standard of 10,000 to 5000 was ~50% (<xref rid="F11" ref-type="fig">Fig.
11A</xref>–<xref rid="F11" ref-type="fig">C</xref>). For these
hyperparameter settings — LUT random number generation, 200 particles for
the differential evolution optimizer, and 5000 trials for the simulation of the
models — a full model selection analysis was performed in approximately
16 h.</p>
      <p id="P132">One concern is that altering the hyperparameters of the estimation
routine might be detrimental to model selection. This did not occur in either of
our case studies involving simulated data: when using Akaike weights, the
data-generating model and the next most likely models were broadly consistent
even when we used LUTs for the random number generation, combined LUTs with a
smaller number of particles, or combined LUTs, smaller number of particles, and
smaller number of simulated trials (<xref rid="F12" ref-type="fig">Fig.
12A</xref> and <xref rid="F12" ref-type="fig">B</xref>). Similar results
were observed with posterior model probabilities (not shown).</p>
      <p id="P133">This reliability across different hyperparameter settings suggests that
when large computing resources are not available, one could perform an initial
fast assessment using the hyperparameter settings that provide the fastest model
selection analysis to identify a candidate set of models. After that first
phase, a subset of the models that performed best could be re-estimated with
more conservative hyperparameter settings to refine and confirm the results of
the initial assessment.</p>
      <p id="P134">Such an approach may also be particularly important when cross
validation is used instead of model selection metrics. Given the necessity to
run the model fitting code many times with different random seeds to avoid local
minima, even a 10 fold cross validation would lead to enormous numbers of model
fitting runs. For instance for five repeats and 10 fold cross validation, it
would take nearly 50 such repeats which might be very time consuming if the
researcher wishes to test every single model in this process. Using the model
selection metrics to pare down to the most likely set of models and then
pursuing cross validation and different hyperparameter settings is likely
advisable. We leave the judicious choice of these settings to the users of
<italic>ChaRTr</italic>.</p>
    </sec>
  </sec>
  <sec id="S32">
    <label>4.</label>
    <title>Discussion</title>
    <p id="P135">Advances in our understanding of decision making have come from three
fronts: (1) through novel experimental manipulations of sensory stimuli (<xref rid="R7" ref-type="bibr">Brody and Hanks, 2016</xref>; <xref rid="R18" ref-type="bibr">Cisek et al., 2009</xref>; <xref rid="R64" ref-type="bibr">Ratcliff, 2002</xref>; <xref rid="R69" ref-type="bibr">Ratcliff and Rouder,
2000</xref>; <xref rid="R83" ref-type="bibr">Smith and Ratcliff, 2009</xref>;
<xref rid="R87" ref-type="bibr">Thura and Cisek, 2014</xref>) and/or task
manipulations (<xref rid="R39" ref-type="bibr">Hanks et al., 2014</xref>), (2)
recording neural data in a variety of decision-related structures in multiple model
systems (<xref rid="R81" ref-type="bibr">Shadlen and Newsome, 2001</xref>; <xref rid="R76" ref-type="bibr">Schall, 2001</xref>; <xref rid="R14" ref-type="bibr">Chandrasekaran et al., 2017</xref>; <xref rid="R89" ref-type="bibr">Thura et
al., 2014</xref>; <xref rid="R19" ref-type="bibr">Coallier et al., 2015</xref>;
<xref rid="R21" ref-type="bibr">Ding and Gold, 2012a</xref>; <xref rid="R41" ref-type="bibr">Hanks et al., 2015</xref>), and (3) developing and testing
quantitative cognitive models of choices, RTs, and other behavioral readouts from
animal and human observers performing decision-making tasks (<xref rid="R70" ref-type="bibr">Ratcliff and Smith, 2015</xref>). Quantitative modeling is a
lynchpin in generating novel insights into cognitive processes such as
decision-making. However, it has posed significant technical and computational
challenges to the researcher. Widespread and rapid uptake of quantitative modeling
requires software toolboxes that can easily implement the many sophisticated models
of decision-making proposed in the literature.</p>
    <p id="P136">We argue that the ideal toolbox for developing and implementing cognitive
process models of decision-making and evaluating them against choice and RT data
should be simple to use, offer a plurality of cognitive models, provide model
estimation and model selection procedures, provide simple simulation and
visualization tools, and be easily extensible when new hypotheses are developed.
Such a view is broadly consistent with recent research that lays out the best
practices for computational modeling of behavior (<xref rid="R99" ref-type="bibr">Wilson and Collins, 2019</xref>; <xref rid="R46" ref-type="bibr">Heathcote et
al., 2015</xref>). Ready adoption is also facilitated when the toolbox is
implemented in an open-source, free programming language obviating the need for
expensive licenses. The added benefit of an open source toolbox is that researchers
can look “under the hood”, which has at least three benefits: (1)
allow a deeper level of understanding of the models, (2) readily permit extension of
the toolbox, and (3) catch errors in implementation. At the time of development of
this toolbox and submission of this study, no existing toolbox has satisfied all of
these criteria.</p>
    <p id="P137"><italic>ChaRTr</italic> was guided by these pragmatic principles, and is
our attempt to provide a practical toolbox that encompasses a range of cognitive
models of decision-making. Some of the models are grounded in classic random walk
and diffusion models (<xref rid="R63" ref-type="bibr">Ratcliff, 1978</xref>; <xref rid="R84" ref-type="bibr">Stone, 1960</xref>). Others incorporate modern
hypotheses that decision-making behavior might involve signals such as urgency
(<xref rid="R23" ref-type="bibr">Ditterich, 2006a</xref>), collapsing boundaries
(<xref rid="R26" ref-type="bibr">Drugowitsch et al., 2012</xref>), and variable
non-decision times (<xref rid="R72" ref-type="bibr">Ratcliff and Tuerlinckx,
2002</xref>). Since all of the source code is freely available, the toolbox thus
provides a framework where models that are proposed into the future can also be
implemented and contrasted against existing models. We provide a suite of functions
for estimating the parameters of decision-making models, methods to compare
log-likelihoods, and calculating penalized information criteria from these different
models. Finally, the toolbox is developed in the R Statistical Environment, an open
source language that is maintained by an active community of scientists and
statisticians (<xref rid="R61" ref-type="bibr">R Core Team, 2016</xref>).</p>
    <p id="P138">We anticipate that <italic>ChaRTr</italic> will provide a pathway to
standardizing quantitative comparisons between models and across studies, and
ultimately serve as one of the reference implementations for researchers interested
in developing and experimentally testing candidate models of decision-making
processes. <italic>ChaRTr</italic> also codifies the various parameters of
decision-making models, which reflects the hypothesized latent constructs and how
they interact, and provides easy access to many models of behavioral performance in
decision-making tasks including variants of the diffusion decision model, the
urgency gating model, diffusion models with urgency signals, and diffusion models
with collapsing boundaries. <italic>ChaRTr</italic> also offers pedagogical value
because it allows the user to effortlessly simulate the many different models of
decision-making and generate choice and RT data from hypothetical observers.
<italic>ChaRTr</italic> will also allow quantitative evaluation of the
predictions of various decision-making models and help move away from qualitative
intuition-based predictions from these models. Finally, <italic>ChaRTr</italic> is
also sufficiently flexible that users can implement novel models with their own
specific assumptions.</p>
    <p id="P139"><italic>ChaRTr</italic> provides researchers with the resources to apply
and test more than 30 different, albeit overlapping, variants of decision-making
models. We have argued throughout that model selection techniques ought to be used
as a tool for selecting families of models to guide the next generation of
experiments and further analyses, which is in the spirit of <xref rid="R11" ref-type="bibr">Burnham et al. (2011)</xref>; we do not believe model selection
should be used to justify categorical answers (“the best model”). In
this sense, model selection is one tool in the whole gamut of tools that are needed
to understand decision-making (<xref rid="R15" ref-type="bibr">Chandrasekaran et
al., 2018</xref>).</p>
    <p id="P140">The most promising approaches for advancing our understanding of
decision-making will combine the rigorous model selection techniques we advocate
here with novel experimental manipulations of stimulus statistics (<xref rid="R7" ref-type="bibr">Brody and Hanks, 2016</xref>; <xref rid="R18" ref-type="bibr">Cisek et al., 2009</xref>; <xref rid="R32" ref-type="bibr">Evans et al.,
2017</xref>; <xref rid="R89" ref-type="bibr">Thura et al., 2014</xref>), task
contingencies (<xref rid="R48" ref-type="bibr">Heitz and Schall, 2012</xref>; <xref rid="R39" ref-type="bibr">Hanks et al., 2014</xref>; <xref rid="R88" ref-type="bibr">Thura and Cisek, 2016</xref>; <xref rid="R55" ref-type="bibr">Murphy et al., 2016</xref>), and a range of other factors. We believe that
validating and advancing models of decision-making will be facilitated by data that
is freely available for the kinds of model estimation and model selection analyses
we have performed here. Here, we took advantage of the freely available dataset from
<xref rid="R75" ref-type="bibr">Roitman and Shadlen (2002)</xref>. We anticipate
the application of <italic>ChaRTr</italic> to many more decision-making datasets
will help to form a coherent picture of how various latent cognitive processes
affect the behavior of animal and human decision-making. This deeper understanding
of decision-making behavior (<xref rid="R51" ref-type="bibr">Krakauer et al.,
2017</xref>) will in turn facilitate a deeper understanding of decision-related
neural responses (<xref rid="R55" ref-type="bibr">Murphy et al., 2016</xref>; <xref rid="R86" ref-type="bibr">Thura et al., 2012</xref>; <xref rid="R18" ref-type="bibr">Cisek et al., 2009</xref>; <xref rid="R17" ref-type="bibr">Churchland et al., 2008</xref>; <xref rid="R60" ref-type="bibr">Purcell and
Kiani, 2016</xref>; <xref rid="R14" ref-type="bibr">Chandrasekaran et al.,
2017</xref>; <xref rid="R57" ref-type="bibr">O’Connell et al.,
2018a</xref>).</p>
    <p id="P141">Rigorous model selection techniques are even more relevant if we wish to
make further inroads into understanding the neural correlates of decision-making. In
particular, discriminating between multiple candidate models of decision-making is
critical for neurophysiological studies of decision-making that attempt to relate
neural responses in decision-related structures to the features of sequential
sampling models (<xref rid="R23" ref-type="bibr">Ditterich, 2006a</xref>,<xref rid="R24" ref-type="bibr">b</xref>; <xref rid="R81" ref-type="bibr">Shadlen and
Newsome, 2001</xref>; <xref rid="R36" ref-type="bibr">Gold and Shadlen,
2007</xref>; <xref rid="R65" ref-type="bibr">Ratcliff et al., 2003</xref>, <xref rid="R66" ref-type="bibr">2007</xref>; <xref rid="R48" ref-type="bibr">Heitz and
Schall, 2012</xref>; <xref rid="R38" ref-type="bibr">Hanes and Schall,
1996</xref>). For example, one of the most well-established tenets of the neural
basis of decision-making is the gradual ramp-like increase in the firing rates of
individual neurons in decision-related structures such as the lateral intraparietal
area (<xref rid="R81" ref-type="bibr">Shadlen and Newsome, 2001</xref>; <xref rid="R75" ref-type="bibr">Roitman and Shadlen, 2002</xref>), frontal eye fields
(<xref rid="R21" ref-type="bibr">Ding and Gold, 2012a</xref>; <xref rid="R38" ref-type="bibr">Hanes and Schall, 1996</xref>), superior colliculus (<xref rid="R65" ref-type="bibr">Ratcliff et al., 2003</xref>, <xref rid="R66" ref-type="bibr">2007</xref>), prefrontal cortex (<xref rid="R50" ref-type="bibr">Kim and Shadlen, 1999</xref>) and dorsal premotor cortex (<xref rid="R14" ref-type="bibr">Chandrasekaran et al., 2017</xref>; <xref rid="R89" ref-type="bibr">Thura et al., 2014</xref>; <xref rid="R19" ref-type="bibr">Coallier et al., 2015</xref>). However, questions still remain; for example, is
the ramp in a neuron’s response a signature of the evidence integration
process posited by a DDM or is it more consistent with the presence of, say, an
increasing urgency signal. It can be challenging to neurally discriminate between
frameworks without (1) a detailed and ideally quantitative understanding of the
behavior (<xref rid="R51" ref-type="bibr">Krakauer et al., 2017</xref>; <xref rid="R57" ref-type="bibr">O’Connell et al., 2018a</xref>), and (2) a
clear hypothesis about the mapping from the underlying neural mechanisms to the
observed behavior (<xref rid="R77" ref-type="bibr">Schall, 2004</xref>). We believe
<italic>ChaRTr</italic> and other toolboxes of its ilk will play a critical role
in further advancing our understanding of the neural correlates of
decision-making.</p>
    <sec id="S33">
      <label>4.1.</label>
      <title>Future directions</title>
      <p id="P142"><italic>ChaRTr</italic> provides a powerful framework for estimating
and discriminating between candidate decision-making models. Nevertheless, there
is considerable scope for extending its capabilities. Here, we outline a few
future directions we believe would make <italic>ChaRTr</italic>, and other
toolboxes that come in its wake, even more useful for decision-making
researchers.</p>
      <p id="P143">First, <italic>ChaRTr</italic> provides options to estimate sequential
sampling models that assume relative evidence is accumulated over time. A
related and compelling line of research assumes a race model architecture where
a choice between <italic>n</italic> options is represented as a race between
<italic>n</italic> evidence accumulators. The <italic>n</italic> ≥ 2
accumulators collect evidence in favor of their respective response options as a
dynamic race toward their respective thresholds. The first accumulator to reach
the threshold triggers a decision for the corresponding response option. There
are a range of race models that differ in details, including accumulators that
are independent (e.g., <xref rid="R8" ref-type="bibr">Brown and Heathcote,
2008</xref>; <xref rid="R74" ref-type="bibr">Reddi and Carpenter,
2000</xref>) or dependent (e.g., <xref rid="R91" ref-type="bibr">Usher and
McClelland, 2001</xref>). Naturally, these models can be elaborated with
many features of the relative evidence accumulation models implemented in
<italic>ChaRTr</italic>, including variable non-decision times and urgency
(though see <xref rid="R100" ref-type="bibr">Zhang et al., 2014</xref>; <xref rid="R5" ref-type="bibr">Bogacz et al., 2006</xref>, for demonstration of
the equivalence between relative and absolute evidence accumulation models under
certain circumstances). Incorporation of race models in <italic>ChaRTr</italic>
will be a useful extension into the future.</p>
      <p id="P144">Second, the current instantiation of <italic>ChaRTr</italic> assumes
that observers are independent. Recent efforts have proposed the use of
hierarchical Bayesian methods for the DDM and other decision-making models
(<xref rid="R1" ref-type="bibr">Ahn et al., 2017</xref>; <xref rid="R47" ref-type="bibr">Heathcote et al., 2018</xref>; <xref rid="R98" ref-type="bibr">Wiecki et al., 2013</xref>). Bayesian estimation methods
provide at least two advantages over the current framework provided in
<italic>ChaRTr</italic>. First, Bayesian methods incorporate prior knowledge
into the plausible distribution of parameter values and they provide full
posterior distributions for all model parameters. <italic>ChaRTr</italic>
currently provides only the most likely value for a parameter without any
measure of its uncertainty, whereas the full posterior distribution provides
uncertainty in the estimate for each parameter, thus reducing the likelihood of
drawing over-confident conclusions. Second, Bayesian methods are advantageous
when used in contexts where there are only modest numbers of trials per
observer. Hierarchical Bayesian models in particular can enhance statistical
power by providing opportunities for simultaneous estimation of the parameters
of individual observers as well as the population-level distributions from which
they are drawn.</p>
      <p id="P145">Despite these benefits, we emphasize that it is far from
straightforward to extend the models implemented in <italic>ChaRTr</italic> to
Bayesian parameter estimation methods. The goal of <italic>ChaRTr</italic> is
simple and rapid implementation and testing of new models, which takes place via
simulation-based techniques. Bayesian methods require model likelihood
functions, which can be challenging to derive and may not even exist for some of
the models implemented in <italic>ChaRTr</italic>, and as such the extension to
Bayesian methods is not trivial. In future work, we aim to extend the parameter
estimation routines in <italic>ChaRTr</italic> to make use of approximate
Bayesian techniques.</p>
      <p id="P146">Third, the framework in <italic>ChaRTr</italic> is currently only
amenable for analyzing behavior from decision-making tasks where the sensory
stimulus provides constant evidence over time, albeit with noise, and varies
along a single dimension. However, previous research suggests that a powerful
way to dissociate between different models of decision-making is to use
time-varying stimuli (<xref rid="R10" ref-type="bibr">Brunton et al.,
2013</xref>; <xref rid="R7" ref-type="bibr">Brody and Hanks, 2016</xref>;
<xref rid="R18" ref-type="bibr">Cisek et al., 2009</xref>; <xref rid="R64" ref-type="bibr">Ratcliff, 2002</xref>; <xref rid="R69" ref-type="bibr">Ratcliff and Rouder, 2000</xref>; <xref rid="R83" ref-type="bibr">Smith and
Ratcliff, 2009</xref>; <xref rid="R89" ref-type="bibr">Thura et al.,
2014</xref>; <xref rid="R91" ref-type="bibr">Usher and McClelland,
2001</xref>). In a related vein, there has been increased interest in
combining frameworks that posit sensory stimuli are optimally combined and could
drive multisensory decision-making models (<xref rid="R27" ref-type="bibr">Drugowitsch et al., 2014</xref>; <xref rid="R13" ref-type="bibr">Chandrasekaran, 2017</xref>). Future versions of <italic>ChaRTr</italic>
will provide opportunities for implementing and testing models in contexts where
the sensory stimuli have temporal structure (<xref rid="R32" ref-type="bibr">Evans et al., 2017</xref>), or involve multi-sensory integration (<xref rid="R13" ref-type="bibr">Chandrasekaran, 2017</xref>; <xref rid="R16" ref-type="bibr">Chandrasekaran et al., 2019</xref>).</p>
      <p id="P147">Fourth, in <italic>ChaRTr</italic>, we have largely focused on the use
of model-selection metrics rather than predictive tests such as cross
validation. However, cross validation is a powerful tool to guard against
over-fitting and for predicting generalization performance on held out data and
does not explicitly include a penalty term. If one intends to use cross
validation, one could subset the data that is passed into the parameter
estimation routines; say, retain 80% of the data and hold out 20% of the data.
Parameter estimation would then operate on the training data as described below.
Once the best-fitting parameters are identified they could be passed with the
held out 20% of the data to the same functions as the training phase to
calculate the out-of-sample goodness of fit. This process could then be
repeated, say, 10 times, to obtain an estimate of the average out-of-sample
goodness of fit. We anticipate implementing cross validation as an additional
approach in future versions of <italic>ChaRTr</italic>.</p>
      <p id="P148">Finally, <italic>ChaRTr</italic> currently allows the quality of the
evidence signal (drift rate) to vary with an experimental factor (stimulus
difficulty). In future versions of <italic>ChaRTr</italic>, we will provide
capabilities for different model parameters to vary with different experimental
factors. There are a range of other experimental manipulations whose effect will
likely appear in model parameters other than the drift rate; for example,
emphasizing the speed or accuracy of decisions is most likely to affect the
decision boundary, or the speed with which a boundary collapses. Future versions
of <italic>ChaRTr</italic> will allow researchers to test and discriminate
between these hypotheses.</p>
    </sec>
  </sec>
</body>
<back>
  <ack id="S34">
    <title>Acknowledgments</title>
    <p id="P149">CC was supported by a NIH/NINDS R00 award 4R00NS092972-03. GH was supported
by an Australian Research Council (ARC) Discovery Early Career Researcher Award
(DECRA, award DE170100177) and an ARC Discovery Project (award DP180103613). Some of
the model fits for simulated and real data were performed on the Shared Computing
Cluster funded by an ONR DURIP N00014-17-1-2304 grant to Boston University. Some of
the work was done under the auspices of Prof. Krishna Shenoy at Stanford University.
We thank Prof. Shenoy for helpful discussions and advice, and Jessica Verhein and
Megan Wang for insightful discussions.</p>
  </ack>
  <ref-list>
    <title>References</title>
    <ref id="R1">
      <mixed-citation publication-type="journal"><name><surname>Ahn</surname><given-names>WY</given-names></name>, <name><surname>Haines</surname><given-names>N</given-names></name>, <name><surname>Zhang</surname><given-names>L</given-names></name>, <year>2017</year>. <article-title>Revealing neurocomputational
mechanisms of reinforcement learning and decision-making with the hbayesdm
package</article-title>. <source>Comput. Psychiatry</source><volume>1</volume>, <fpage>24</fpage>–<lpage>57</lpage>.</mixed-citation>
    </ref>
    <ref id="R2">
      <mixed-citation publication-type="journal"><name><surname>Aho</surname><given-names>K</given-names></name>, <name><surname>Derryberry</surname><given-names>D</given-names></name>, <name><surname>Peterson</surname><given-names>T</given-names></name>, <year>2014</year>. <article-title>Model selection for ecologists: the
worldviews of AIC and BIC</article-title>. <source>Ecology</source><volume>95</volume>,
<fpage>631</fpage>–<lpage>636</lpage>.<pub-id pub-id-type="pmid">24804445</pub-id></mixed-citation>
    </ref>
    <ref id="R3">
      <mixed-citation publication-type="journal"><name><surname>Akaike</surname><given-names>H</given-names></name>, <year>1974</year>. <article-title>A new look at the statistical model
identification</article-title>. <source>IEEE Trans. Autom. Control</source><volume>19</volume>,
<fpage>716</fpage>–<lpage>723</lpage>.</mixed-citation>
    </ref>
    <ref id="R4">
      <mixed-citation publication-type="journal"><name><surname>Boehm</surname><given-names>U</given-names></name>, <name><surname>Hawkins</surname><given-names>GE</given-names></name>, <name><surname>Brown</surname><given-names>S</given-names></name>, <name><surname>van Rijn</surname><given-names>H</given-names></name>, <name><surname>Wagenmakers</surname><given-names>EJ</given-names></name>, <year>2016</year>. <article-title>Of monkeys and men: impatience in
perceptual decision-making</article-title>. <source>Psychon. Bull.
Rev</source><volume>23</volume>,
<fpage>738</fpage>–<lpage>749</lpage>.<pub-id pub-id-type="pmid">26518307</pub-id></mixed-citation>
    </ref>
    <ref id="R5">
      <mixed-citation publication-type="journal"><name><surname>Bogacz</surname><given-names>R</given-names></name>, <name><surname>Brown</surname><given-names>E</given-names></name>, <name><surname>Moehlis</surname><given-names>J</given-names></name>, <name><surname>Holmes</surname><given-names>P</given-names></name>, <name><surname>Cohen</surname><given-names>JD</given-names></name>, <year>2006</year>. <article-title>The physics of optimal decision
making: a formal analysis of models of performance in two-alternative forced
choice tasks</article-title>. <source>Psychol. Rev</source><volume>113</volume>,
<fpage>700</fpage>–<lpage>765</lpage>.<pub-id pub-id-type="pmid">17014301</pub-id></mixed-citation>
    </ref>
    <ref id="R6">
      <mixed-citation publication-type="journal"><name><surname>Bowman</surname><given-names>NE</given-names></name>, <name><surname>Kording</surname><given-names>KP</given-names></name>, <name><surname>Gottfried</surname><given-names>JA</given-names></name>, <year>2012</year>. <article-title>Temporal integration of olfactory
perceptual evidence in human orbitofrontal cortex</article-title>.
<source>Neuron</source><volume>75</volume>,
<fpage>916</fpage>–<lpage>927</lpage>.<pub-id pub-id-type="pmid">22958830</pub-id></mixed-citation>
    </ref>
    <ref id="R7">
      <mixed-citation publication-type="journal"><name><surname>Brody</surname><given-names>CD</given-names></name>, <name><surname>Hanks</surname><given-names>TD</given-names></name>, <year>2016</year>. <article-title>Neural underpinnings of the evidence
accumulator</article-title>. <source>Curr. Opin. Neurobiol</source><volume>37</volume>,
<fpage>149</fpage>–<lpage>157</lpage>.<pub-id pub-id-type="pmid">26878969</pub-id></mixed-citation>
    </ref>
    <ref id="R8">
      <mixed-citation publication-type="journal"><name><surname>Brown</surname><given-names>SD</given-names></name>, <name><surname>Heathcote</surname><given-names>A</given-names></name>, <year>2008</year>. <article-title>The simplest complete model of choice
reaction time: linear ballistic accumulation</article-title>. <source>Cogn.
Psychol</source><volume>57</volume>,
<fpage>153</fpage>–<lpage>178</lpage>.<pub-id pub-id-type="pmid">18243170</pub-id></mixed-citation>
    </ref>
    <ref id="R9">
      <mixed-citation publication-type="journal"><name><surname>Brown</surname><given-names>S</given-names></name>, <name><surname>Heathcote</surname><given-names>A</given-names></name>, <year>2003</year>. <article-title>QMLE: fast, robust, and efficient
estimation of distribution functions based on quantiles</article-title>.
<source>Behav. Res. Methods Instrum. Comput</source><volume>35</volume>,
<fpage>485</fpage>–<lpage>492</lpage>.<pub-id pub-id-type="pmid">14748492</pub-id></mixed-citation>
    </ref>
    <ref id="R10">
      <mixed-citation publication-type="journal"><name><surname>Brunton</surname><given-names>BW</given-names></name>, <name><surname>Botvinick</surname><given-names>MM</given-names></name>, <name><surname>Brody</surname><given-names>CD</given-names></name>, <year>2013</year>. <article-title>Rats and humans can optimally
accumulate evidence for decision-making</article-title>.
<source>Science</source><volume>340</volume>,
<fpage>95</fpage>–<lpage>98</lpage>.<pub-id pub-id-type="pmid">23559254</pub-id></mixed-citation>
    </ref>
    <ref id="R11">
      <mixed-citation publication-type="journal"><name><surname>Burnham</surname><given-names>KP</given-names></name>, <name><surname>Anderson</surname><given-names>DR</given-names></name>, <name><surname>Huyvaert</surname><given-names>KP</given-names></name>, <year>2011</year>. <article-title>AIC model selection and multi-model
inference in behavioral ecology: some background, observations, and
comparisons</article-title>. <source>Behav. Ecol. Sociobiol</source><volume>65</volume>,
<fpage>23</fpage>–<lpage>35</lpage>.</mixed-citation>
    </ref>
    <ref id="R12">
      <mixed-citation publication-type="journal"><name><surname>Carland</surname><given-names>MA</given-names></name>, <name><surname>Thura</surname><given-names>D</given-names></name>, <name><surname>Cisek</surname><given-names>P</given-names></name>, <year>2015</year>. <article-title>The urgency-gating model can explain
the effects of early evidence</article-title>. <source>Psychon. Bull.
Rev</source><volume>22</volume>,
<fpage>1830</fpage>–<lpage>1838</lpage>.<pub-id pub-id-type="pmid">26452377</pub-id></mixed-citation>
    </ref>
    <ref id="R13">
      <mixed-citation publication-type="journal"><name><surname>Chandrasekaran</surname><given-names>C</given-names></name>, <year>2017</year>. <article-title>Computational principles and models
of multisensory integration</article-title>. <source>Curr. Opin.
Neurobiol</source><volume>43</volume>,
<fpage>25</fpage>–<lpage>34</lpage>.<pub-id pub-id-type="pmid">27918886</pub-id></mixed-citation>
    </ref>
    <ref id="R14">
      <mixed-citation publication-type="journal"><name><surname>Chandrasekaran</surname><given-names>C</given-names></name>, <name><surname>Peixoto</surname><given-names>D</given-names></name>, <name><surname>Newsome</surname><given-names>WT</given-names></name>, <name><surname>Shenoy</surname><given-names>KV</given-names></name>, <year>2017</year>. <article-title>Laminar differences in
decision-related neural activity in dorsal premotor cortex</article-title>.
<source>Nat. Commun</source><volume>8</volume>, <fpage>614</fpage>.<pub-id pub-id-type="pmid">28931803</pub-id></mixed-citation>
    </ref>
    <ref id="R15">
      <mixed-citation publication-type="journal"><name><surname>Chandrasekaran</surname><given-names>C</given-names></name>, <name><surname>Soldado-Magraner</surname><given-names>J</given-names></name>, <name><surname>Peixoto</surname><given-names>D</given-names></name>, <name><surname>Newsome</surname><given-names>WT</given-names></name>, <name><surname>Shenoy</surname><given-names>K</given-names></name>, <name><surname>Sahani</surname><given-names>M</given-names></name>, <year>2018</year>. <article-title>Brittleness in model selection
analysis of single neuron firing rates</article-title>.
<source>bioRxiv</source>.</mixed-citation>
    </ref>
    <ref id="R16">
      <mixed-citation publication-type="journal"><name><surname>Chandrasekaran</surname><given-names>C</given-names></name>, <name><surname>Blurton</surname><given-names>SP</given-names></name>, <name><surname>Gondan</surname><given-names>M</given-names></name>, <year>2019</year>. <article-title>Audiovisual detection at different
intensities and delays</article-title>. <source>J. Math. Psychol</source><volume>91</volume>,
<fpage>159</fpage>–<lpage>175</lpage>.<pub-id pub-id-type="pmid">31404455</pub-id></mixed-citation>
    </ref>
    <ref id="R17">
      <mixed-citation publication-type="journal"><name><surname>Churchland</surname><given-names>AK</given-names></name>, <name><surname>Kiani</surname><given-names>R</given-names></name>, <name><surname>Shadlen</surname><given-names>MN</given-names></name>, <year>2008</year>. <article-title>Decision-making with multiple
alternatives</article-title>. <source>Nat. Neurosci</source><volume>11</volume>,
<fpage>693</fpage>–<lpage>702</lpage>.<pub-id pub-id-type="pmid">18488024</pub-id></mixed-citation>
    </ref>
    <ref id="R18">
      <mixed-citation publication-type="journal"><name><surname>Cisek</surname><given-names>P</given-names></name>, <name><surname>Puskas</surname><given-names>GA</given-names></name>, <name><surname>El-Murr</surname><given-names>S</given-names></name>, <year>2009</year>. <article-title>Decisions in changing conditions: the
urgency-gating model</article-title>. <source>J. Neurosci</source><volume>29</volume>,
<fpage>11560</fpage>–<lpage>11571</lpage>.<pub-id pub-id-type="pmid">19759303</pub-id></mixed-citation>
    </ref>
    <ref id="R19">
      <mixed-citation publication-type="journal"><name><surname>Coallier</surname><given-names>É</given-names></name>, <name><surname>Michelet</surname><given-names>T</given-names></name>, <name><surname>Kalaska</surname><given-names>JF</given-names></name>, <year>2015</year>. <article-title>Dorsal premotor cortex: neural
correlates of reach target decisions based on a color-location matching rule
and conflicting sensory evidence</article-title>. <source>J.
Neurophysiol</source><volume>113</volume>,
<fpage>3543</fpage>–<lpage>3573</lpage>.<pub-id pub-id-type="pmid">25787952</pub-id></mixed-citation>
    </ref>
    <ref id="R20">
      <mixed-citation publication-type="journal"><name><surname>Diederich</surname><given-names>A</given-names></name>, <year>1997</year>. <article-title>Dynamic stochastic models for
decision making under time constraints</article-title>. <source>J. Math.
Psychol</source><volume>41</volume>,
<fpage>260</fpage>–<lpage>274</lpage>.<pub-id pub-id-type="pmid">9325121</pub-id></mixed-citation>
    </ref>
    <ref id="R21">
      <mixed-citation publication-type="journal"><name><surname>Ding</surname><given-names>L</given-names></name>, <name><surname>Gold</surname><given-names>JI</given-names></name>, <year>2012a</year>. <article-title>Neural correlates of perceptual
decision making before, during, and after decision commitment in monkey
frontal eye field</article-title>. <source>Cereb. Cortex</source><volume>22</volume>,
<fpage>1052</fpage>–<lpage>1067</lpage>.<pub-id pub-id-type="pmid">21765183</pub-id></mixed-citation>
    </ref>
    <ref id="R22">
      <mixed-citation publication-type="journal"><name><surname>Ding</surname><given-names>L</given-names></name>, <name><surname>Gold</surname><given-names>JI</given-names></name>, <year>2012b</year>. <article-title>Separate, causal roles of the
caudate in saccadic choice and execution in a perceptual decision
task</article-title>. <source>Neuron</source><volume>75</volume>,
<fpage>865</fpage>–<lpage>874</lpage>.<pub-id pub-id-type="pmid">22958826</pub-id></mixed-citation>
    </ref>
    <ref id="R23">
      <mixed-citation publication-type="journal"><name><surname>Ditterich</surname><given-names>J</given-names></name>, <year>2006a</year>. <article-title>Evidence for time-variant decision
making</article-title>. <source>Eur. J. Neurosci</source><volume>24</volume>,
<fpage>3628</fpage>–<lpage>3641</lpage>.<pub-id pub-id-type="pmid">17229111</pub-id></mixed-citation>
    </ref>
    <ref id="R24">
      <mixed-citation publication-type="journal"><name><surname>Ditterich</surname><given-names>J</given-names></name>, <year>2006b</year>. <article-title>Stochastic models of decisions about
motion direction: behavior and physiology</article-title>. <source>Neural
Netw</source>. <volume>19</volume>,
<fpage>981</fpage>–<lpage>1012</lpage>.<pub-id pub-id-type="pmid">16952441</pub-id></mixed-citation>
    </ref>
    <ref id="R25">
      <mixed-citation publication-type="journal"><name><surname>Donkin</surname><given-names>C</given-names></name>, <name><surname>Brown</surname><given-names>SD</given-names></name>, <year>2018</year>. <article-title>Response times and decision-making.
Stevens’ Handb</article-title>. <source>Exp. Psychol. Cogn. Neurosci.
Methodol</source><volume>349</volume>.</mixed-citation>
    </ref>
    <ref id="R26">
      <mixed-citation publication-type="journal"><name><surname>Drugowitsch</surname><given-names>J</given-names></name>, <name><surname>Moreno-Bote</surname><given-names>R</given-names></name>, <name><surname>Churchland</surname><given-names>AK</given-names></name>, <name><surname>Shadlen</surname><given-names>MN</given-names></name>, <name><surname>Pouget</surname><given-names>A</given-names></name>, <year>2012</year>. <article-title>The cost of accumulating evidence in
perceptual decision making</article-title>. <source>J. Neurosci</source><volume>32</volume>,
<fpage>3612</fpage>–<lpage>3628</lpage>.<pub-id pub-id-type="pmid">22423085</pub-id></mixed-citation>
    </ref>
    <ref id="R27">
      <mixed-citation publication-type="journal"><name><surname>Drugowitsch</surname><given-names>J</given-names></name>, <name><surname>DeAngelis</surname><given-names>GC</given-names></name>, <name><surname>Klier</surname><given-names>EM</given-names></name>, <name><surname>Angelaki</surname><given-names>DE</given-names></name>, <name><surname>Pouget</surname><given-names>A</given-names></name>, <year>2014</year>. <article-title>Optimal multisensory decision-making
in a reaction-time task</article-title>. <source>Elife</source><volume>3</volume>.</mixed-citation>
    </ref>
    <ref id="R28">
      <mixed-citation publication-type="journal"><name><surname>Eddelbuettel</surname><given-names>D</given-names></name>, <name><surname>François</surname><given-names>R</given-names></name>, <year>2011</year>. <article-title>Rcpp: seamless R and C++
integration</article-title>. <source>J. Stat. Softw</source><volume>40</volume>, <fpage>1</fpage>–<lpage>18</lpage>.</mixed-citation>
    </ref>
    <ref id="R29">
      <mixed-citation publication-type="journal"><name><surname>Evans</surname><given-names>NJ</given-names></name>, <year>2019a</year>. <article-title>A method, framework, and tutorial
for efficiently simulating models of decision-making</article-title>.
<source>Behav. Res. Methods</source><fpage>1</fpage>–<lpage>15</lpage>.<pub-id pub-id-type="pmid">29967978</pub-id></mixed-citation>
    </ref>
    <ref id="R30">
      <mixed-citation publication-type="journal"><name><surname>Evans</surname><given-names>NJ</given-names></name>, <year>2019b</year>. <article-title>Assessing the practical differences
between model selection methods in inferences about choice response time
tasks</article-title>. <source>Psychon. Bull. Rev</source><volume>26</volume> (<issue>4</issue>),
<fpage>1070</fpage>–<lpage>1098</lpage>.<pub-id pub-id-type="pmid">30783896</pub-id></mixed-citation>
    </ref>
    <ref id="R31">
      <mixed-citation publication-type="journal"><name><surname>Evans</surname><given-names>NJ</given-names></name>, <name><surname>Hawkins</surname><given-names>GE</given-names></name>, <year>2019</year>. <article-title>When humans behave like monkeys:
feedback delays and extensive practice increase the efficiency of speeded
decisions</article-title>. <source>Cognition</source><volume>184</volume>,
<fpage>11</fpage>–<lpage>18</lpage>.<pub-id pub-id-type="pmid">30553935</pub-id></mixed-citation>
    </ref>
    <ref id="R32">
      <mixed-citation publication-type="journal"><name><surname>Evans</surname><given-names>NJ</given-names></name>, <name><surname>Hawkins</surname><given-names>GE</given-names></name>, <name><surname>Boehm</surname><given-names>U</given-names></name>, <name><surname>Wagenmakers</surname><given-names>EJ</given-names></name>, <name><surname>Brown</surname><given-names>SD</given-names></name>, <year>2017</year>. <article-title>The computations that support simple
decision-making: a comparison between the diffusion and urgency-gating
models</article-title>. <source>Sci. Rep</source><volume>7</volume>, <fpage>16433</fpage>.<pub-id pub-id-type="pmid">29180789</pub-id></mixed-citation>
    </ref>
    <ref id="R33">
      <mixed-citation publication-type="journal"><name><surname>Evans</surname><given-names>NJ</given-names></name>, <name><surname>Hawkins</surname><given-names>GE</given-names></name>, <name><surname>Brown</surname><given-names>S</given-names></name>, <year>2019</year>. <article-title>The role of passing time in
decision-making</article-title>. <source>J. Exp. Psychol.: Learn. Mem.
Cogn</source> (<comment>in press</comment>).</mixed-citation>
    </ref>
    <ref id="R34">
      <mixed-citation publication-type="journal"><name><surname>Forstmann</surname><given-names>BU</given-names></name>, <name><surname>Ratcliff</surname><given-names>R</given-names></name>, <name><surname>Wagenmakers</surname><given-names>EJ</given-names></name>, <year>2016</year>. <article-title>Sequential sampling models in
cognitive neuroscience: advantages, applications, and
extensions</article-title>. <source>Annu. Rev. Psychol</source><volume>67</volume>,
<fpage>641</fpage>–<lpage>666</lpage>.<pub-id pub-id-type="pmid">26393872</pub-id></mixed-citation>
    </ref>
    <ref id="R35">
      <mixed-citation publication-type="journal"><name><surname>Freedman</surname><given-names>DJ</given-names></name>, <name><surname>Assad</surname><given-names>JA</given-names></name>, <year>2011</year>. <article-title>A proposed common neural mechanism
for categorization and perceptual decisions</article-title>. <source>Nat.
Neurosci</source>. <volume>14</volume>, <fpage>143</fpage>.<pub-id pub-id-type="pmid">21270782</pub-id></mixed-citation>
    </ref>
    <ref id="R36">
      <mixed-citation publication-type="journal"><name><surname>Gold</surname><given-names>JI</given-names></name>, <name><surname>Shadlen</surname><given-names>MN</given-names></name>, <year>2007</year>. <article-title>The neural basis of decision
making</article-title>. <source>Annu. Rev. Neurosci</source><volume>30</volume>,
<fpage>535</fpage>–<lpage>574</lpage>.<pub-id pub-id-type="pmid">17600525</pub-id></mixed-citation>
    </ref>
    <ref id="R37">
      <mixed-citation publication-type="journal"><name><surname>Gondan</surname><given-names>M</given-names></name>, <name><surname>Blurton</surname><given-names>SP</given-names></name>, <name><surname>Kesselmeier</surname><given-names>M</given-names></name>, <year>2014</year>. <article-title>Even faster and even more accurate
first-passage time densities and distributions for the Wiener diffusion
model</article-title>. <source>J. Math. Psychol</source><volume>60</volume>,
<fpage>20</fpage>–<lpage>22</lpage>.</mixed-citation>
    </ref>
    <ref id="R38">
      <mixed-citation publication-type="journal"><name><surname>Hanes</surname><given-names>DP</given-names></name>, <name><surname>Schall</surname><given-names>JD</given-names></name>, <year>1996</year>. <article-title>Neural control of voluntary movement
initiation</article-title>. <source>Science</source><volume>274</volume>,
<fpage>427</fpage>–<lpage>430</lpage>.<pub-id pub-id-type="pmid">8832893</pub-id></mixed-citation>
    </ref>
    <ref id="R39">
      <mixed-citation publication-type="journal"><name><surname>Hanks</surname><given-names>T</given-names></name>, <name><surname>Kiani</surname><given-names>R</given-names></name>, <name><surname>Shadlen</surname><given-names>MN</given-names></name>, <year>2014</year>. <article-title>A neural mechanism of speed-accuracy
tradeoff in macaque area LIP</article-title>. <source>Elife</source><volume>3</volume>. <pub-id pub-id-type="doi">10.7554/eLife.02260</pub-id><comment>.</comment></mixed-citation>
    </ref>
    <ref id="R40">
      <mixed-citation publication-type="journal"><name><surname>Hanks</surname><given-names>TD</given-names></name>, <name><surname>Mazurek</surname><given-names>ME</given-names></name>, <name><surname>Kiani</surname><given-names>R</given-names></name>, <name><surname>Hopp</surname><given-names>E</given-names></name>, <name><surname>Shadlen</surname><given-names>MN</given-names></name>, <year>2011</year>. <article-title>Elapsed decision time affects the
weighting of prior probability in a perceptual decision
task</article-title>. <source>J. Neurosci</source><volume>31</volume>,
<fpage>6339</fpage>–<lpage>6352</lpage>.<pub-id pub-id-type="pmid">21525274</pub-id></mixed-citation>
    </ref>
    <ref id="R41">
      <mixed-citation publication-type="journal"><name><surname>Hanks</surname><given-names>TD</given-names></name>, <name><surname>Kopec</surname><given-names>CD</given-names></name>, <name><surname>Brunton</surname><given-names>BW</given-names></name>, <name><surname>Duan</surname><given-names>CA</given-names></name>, <name><surname>Erlich</surname><given-names>JC</given-names></name>, <name><surname>Brody</surname><given-names>CD</given-names></name>, <year>2015</year>. <article-title>Distinct relationships of parietal
and prefrontal cortices to evidence accumulation</article-title>.
<source>Nature</source><volume>520</volume>, <fpage>220</fpage>.<pub-id pub-id-type="pmid">25600270</pub-id></mixed-citation>
    </ref>
    <ref id="R42">
      <mixed-citation publication-type="journal"><name><surname>Hawkins</surname><given-names>GE</given-names></name>, <name><surname>Forstmann</surname><given-names>BU</given-names></name>, <name><surname>Wagenmakers</surname><given-names>EJ</given-names></name>, <name><surname>Ratcliff</surname><given-names>R</given-names></name>, <name><surname>Brown</surname><given-names>SD</given-names></name>, <year>2015a</year>. <article-title>Revisiting the evidence for
collapsing boundaries and urgency signals in perceptual
decision-making</article-title>. <source>J. Neurosci</source><volume>35</volume>,
<fpage>2476</fpage>–<lpage>2484</lpage>.<pub-id pub-id-type="pmid">25673842</pub-id></mixed-citation>
    </ref>
    <ref id="R43">
      <mixed-citation publication-type="journal"><name><surname>Hawkins</surname><given-names>GE</given-names></name>, <name><surname>Wagenmakers</surname><given-names>EJ</given-names></name>, <name><surname>Ratcliff</surname><given-names>R</given-names></name>, <name><surname>Brown</surname><given-names>SD</given-names></name>, <year>2015b</year>. <article-title>Discriminating evidence accumulation
from urgency signals in speeded decision making</article-title>. <source>J.
Neurophysiol</source><volume>114</volume>,
<fpage>40</fpage>–<lpage>47</lpage>.<pub-id pub-id-type="pmid">25904706</pub-id></mixed-citation>
    </ref>
    <ref id="R44">
      <mixed-citation publication-type="journal"><name><surname>Heathcote</surname><given-names>A</given-names></name>, <name><surname>Brown</surname><given-names>SD</given-names></name>, <year>2004</year>. <article-title>Reply to Speckman and Rouder: a
theoretical basis for QML</article-title>. <source>Psychon. Bull.
Rev</source><volume>11</volume>,
<fpage>577</fpage>–<lpage>578</lpage>.</mixed-citation>
    </ref>
    <ref id="R45">
      <mixed-citation publication-type="journal"><name><surname>Heathcote</surname><given-names>A</given-names></name>, <name><surname>Brown</surname><given-names>SD</given-names></name>, <name><surname>Mewhort</surname><given-names>DJK</given-names></name>, <year>2002</year>. <article-title>Quantile maximum likelihood
estimation of response time distributions</article-title>. <source>Psychon.
Bull. Rev</source><volume>9</volume>,
<fpage>394</fpage>–<lpage>401</lpage>.<pub-id pub-id-type="pmid">12120806</pub-id></mixed-citation>
    </ref>
    <ref id="R46">
      <mixed-citation publication-type="book"><name><surname>Heathcote</surname><given-names>A</given-names></name>, <name><surname>Brown</surname><given-names>SD</given-names></name>, <name><surname>Wagenmakers</surname><given-names>EJ</given-names></name>, <year>2015</year>. <part-title>An introduction to good practices in
cognitive modeling</part-title>. In: <name><surname>Forstmann</surname><given-names>BU</given-names></name>, <name><surname>Wagenmakers</surname><given-names>EJ</given-names></name> (Eds.), <source>An Introduction to Model-Based Cognitive
Neuroscience</source>. <publisher-name>Springer</publisher-name>,
<publisher-loc>New York</publisher-loc>.</mixed-citation>
    </ref>
    <ref id="R47">
      <mixed-citation publication-type="journal"><name><surname>Heathcote</surname><given-names>A</given-names></name>, <name><surname>Lin</surname><given-names>YS</given-names></name>, <name><surname>Reynolds</surname><given-names>A</given-names></name>, <name><surname>Strickland</surname><given-names>L</given-names></name>, <name><surname>Gretton</surname><given-names>M</given-names></name>, <name><surname>Matzke</surname><given-names>D</given-names></name>, <year>2018</year>. <article-title>Dynamic models of
choice</article-title>. <source>Behav. Res.
Methods</source>.</mixed-citation>
    </ref>
    <ref id="R48">
      <mixed-citation publication-type="journal"><name><surname>Heitz</surname><given-names>RP</given-names></name>, <name><surname>Schall</surname><given-names>JD</given-names></name>, <year>2012</year>. <article-title>Neural mechanisms of speed-accuracy
tradeoff</article-title>. <source>Neuron</source><volume>76</volume>,
<fpage>616</fpage>–<lpage>628</lpage>.<pub-id pub-id-type="pmid">23141072</pub-id></mixed-citation>
    </ref>
    <ref id="R49">
      <mixed-citation publication-type="journal"><name><surname>Hoshi</surname><given-names>E</given-names></name>, <year>2013</year>. <article-title>Cortico-basal ganglia networks
subserving goal-directed behavior mediated by conditional visuo-goal
association</article-title>. <source>Front. Neural Circuits</source><volume>7</volume>, <fpage>158</fpage>.<pub-id pub-id-type="pmid">24155692</pub-id></mixed-citation>
    </ref>
    <ref id="R50">
      <mixed-citation publication-type="journal"><name><surname>Kim</surname><given-names>JN</given-names></name>, <name><surname>Shadlen</surname><given-names>MN</given-names></name>, <year>1999</year>. <article-title>Neural correlates of a decision in
the dorsolateral prefrontal cortex of the macaque</article-title>.
<source>Nat. Neurosci</source><volume>2</volume>, <fpage>176</fpage>.<pub-id pub-id-type="pmid">10195203</pub-id></mixed-citation>
    </ref>
    <ref id="R51">
      <mixed-citation publication-type="journal"><name><surname>Krakauer</surname><given-names>JW</given-names></name>, <name><surname>Ghazanfar</surname><given-names>AA</given-names></name>, <name><surname>Gomez-Marin</surname><given-names>A</given-names></name>, <name><surname>MacIver</surname><given-names>MA</given-names></name>, <name><surname>Poeppel</surname><given-names>D</given-names></name>, <year>2017</year>. <article-title>Neuroscience needs behavior:
correcting a reductionist bias</article-title>. <source>Neuron</source><volume>93</volume>,
<fpage>480</fpage>–<lpage>490</lpage>.<pub-id pub-id-type="pmid">28182904</pub-id></mixed-citation>
    </ref>
    <ref id="R52">
      <mixed-citation publication-type="book"><name><surname>Luce</surname><given-names>RD</given-names></name>, <year>1986</year>. <source>Response Times</source>.
<publisher-name>Oxford University Press</publisher-name>, <publisher-loc>New
York</publisher-loc>.</mixed-citation>
    </ref>
    <ref id="R53">
      <mixed-citation publication-type="journal"><name><surname>Milosavljevic</surname><given-names>M</given-names></name>, <name><surname>Malmaud</surname><given-names>J</given-names></name>, <name><surname>Huth</surname><given-names>A</given-names></name>, <name><surname>Koch</surname><given-names>C</given-names></name>, <name><surname>Rangel</surname><given-names>A</given-names></name>, <year>2010</year>. <article-title>The drift diffusion model can account
for the accuracy and reactime of value-based choices under high and low time
pressure</article-title>. <source>Judgment Decis. Making</source><volume>5</volume>,
<fpage>437</fpage>–<lpage>449</lpage>.</mixed-citation>
    </ref>
    <ref id="R54">
      <mixed-citation publication-type="journal"><name><surname>Mullen</surname><given-names>K</given-names></name>, <name><surname>Ardia</surname><given-names>D</given-names></name>, <name><surname>Gil</surname><given-names>D</given-names></name>, <name><surname>Windover</surname><given-names>D</given-names></name>, <name><surname>Cline</surname><given-names>J</given-names></name>, <year>2011</year>. <article-title>DEoptim: an R package for global
optimization by differential evolution</article-title>. <source>J. Stat.
Softw</source><volume>40</volume>, <fpage>1</fpage>–<lpage>26</lpage>.</mixed-citation>
    </ref>
    <ref id="R55">
      <mixed-citation publication-type="journal"><name><surname>Murphy</surname><given-names>PR</given-names></name>, <name><surname>Boonstra</surname><given-names>E</given-names></name>, <name><surname>Nieuwenhuis</surname><given-names>S</given-names></name>, <year>2016</year>. <article-title>Global gain modulation generates
time-dependent urgency during perceptual choice in humans</article-title>.
<source>Nat. Commun</source><volume>7</volume>, <fpage>13526</fpage>.<pub-id pub-id-type="pmid">27882927</pub-id></mixed-citation>
    </ref>
    <ref id="R56">
      <mixed-citation publication-type="journal"><name><surname>Navarro</surname><given-names>DJ</given-names></name>, <name><surname>Fuss</surname><given-names>IG</given-names></name>, <year>2009</year>. <article-title>Fast and accurate calculations for
first-passage times in wiener diffusion models</article-title>. <source>J.
Math. Psychol</source><volume>53</volume>,
<fpage>222</fpage>–<lpage>230</lpage>.</mixed-citation>
    </ref>
    <ref id="R57">
      <mixed-citation publication-type="journal"><name><surname>O’Connell</surname><given-names>RG</given-names></name>, <name><surname>Shadlen</surname><given-names>MN</given-names></name>, <name><surname>Wong-Lin</surname><given-names>K</given-names></name>, <name><surname>Kelly</surname><given-names>SP</given-names></name>, <year>2018a</year>. <article-title>Bridging neural and computational
viewpoints on perceptual decision-making</article-title>. <source>Trends
Neurosci</source>.</mixed-citation>
    </ref>
    <ref id="R58">
      <mixed-citation publication-type="journal"><name><surname>O’Connell</surname><given-names>RG</given-names></name>, <name><surname>Shadlen</surname><given-names>MN</given-names></name>, <name><surname>Wong-Lin</surname><given-names>K</given-names></name>, <name><surname>Kelly</surname><given-names>SP</given-names></name>, <year>2018b</year>. <article-title>Bridging neural and computational
viewpoints on perceptual decision-making</article-title>. <source>Trends
Neurosci</source>.</mixed-citation>
    </ref>
    <ref id="R59">
      <mixed-citation publication-type="journal"><name><surname>Palmer</surname><given-names>J</given-names></name>, <name><surname>Huk</surname><given-names>AC</given-names></name>, <name><surname>Shadlen</surname><given-names>MN</given-names></name>, <year>2005</year>. <article-title>The effect of stimulus strength on
the speed and accuracy of a perceptual decision</article-title>. <source>J.
Vis</source><volume>5</volume>,
<fpage>376</fpage>–<lpage>404</lpage>.<pub-id pub-id-type="pmid">16097871</pub-id></mixed-citation>
    </ref>
    <ref id="R60">
      <mixed-citation publication-type="journal"><name><surname>Purcell</surname><given-names>BA</given-names></name>, <name><surname>Kiani</surname><given-names>R</given-names></name>, <year>2016</year>. <article-title>Neural mechanisms of post-error
adjustments of decision policy in parietal cortex</article-title>.
<source>Neuron</source><volume>89</volume>,
<fpage>658</fpage>–<lpage>671</lpage>.<pub-id pub-id-type="pmid">26804992</pub-id></mixed-citation>
    </ref>
    <ref id="R61">
      <mixed-citation publication-type="book"><collab>R Core Team</collab>,
<year>2016</year>. <source>R: A Language and Environment for Statistical
Computing</source>. <publisher-name>R Foundation for Statistical
Computing</publisher-name>, <publisher-loc>Vienna,
Austria</publisher-loc>.</mixed-citation>
    </ref>
    <ref id="R62">
      <mixed-citation publication-type="other"><collab>R Core Team</collab>,
<year>2019</year>. <source>SHLIB: Build Shared Object/dll for Dynamic
Loading</source>.</mixed-citation>
    </ref>
    <ref id="R63">
      <mixed-citation publication-type="journal"><name><surname>Ratcliff</surname><given-names>R</given-names></name>, <year>1978</year>. <article-title>A theory of memory
retrieval</article-title>. <source>Psychol. Rev</source><volume>85</volume>,
<fpage>59</fpage>–<lpage>108</lpage>.</mixed-citation>
    </ref>
    <ref id="R64">
      <mixed-citation publication-type="journal"><name><surname>Ratcliff</surname><given-names>R</given-names></name>, <year>2002</year>. <article-title>A diffusion model account of response
time and accuracy in a brightness discrimination task: fitting real data and
failing to fit fake but plausible data</article-title>. <source>Psychon.
Bull. Rev</source><volume>9</volume>,
<fpage>278</fpage>–<lpage>291</lpage>.<pub-id pub-id-type="pmid">12120790</pub-id></mixed-citation>
    </ref>
    <ref id="R65">
      <mixed-citation publication-type="journal"><name><surname>Ratcliff</surname><given-names>R</given-names></name>, <name><surname>Cherian</surname><given-names>A</given-names></name>, <name><surname>Segraves</surname><given-names>M</given-names></name>, <year>2003</year>. <article-title>A comparison of macaque behavior and
superior colliculus neuronal activity to predictions from models of simple
two-choice decisions</article-title>. <source>J. Neurophysiol</source><volume>90</volume>,
<fpage>1392</fpage>–<lpage>1407</lpage>.<pub-id pub-id-type="pmid">12761282</pub-id></mixed-citation>
    </ref>
    <ref id="R66">
      <mixed-citation publication-type="journal"><name><surname>Ratcliff</surname><given-names>R</given-names></name>, <name><surname>Hasegawa</surname><given-names>YT</given-names></name>, <name><surname>Hasegawa</surname><given-names>YP</given-names></name>, <name><surname>Smith</surname><given-names>PL</given-names></name>, <name><surname>Segraves</surname><given-names>MA</given-names></name>, <year>2007</year>. <article-title>Dual diffusion model for single-cell
recording data from the superior colliculus in a brightness-discrimination
task</article-title>. <source>J. Neurophysiol</source><volume>97</volume>,
<fpage>1756</fpage>–<lpage>1774</lpage>.<pub-id pub-id-type="pmid">17122324</pub-id></mixed-citation>
    </ref>
    <ref id="R67">
      <mixed-citation publication-type="journal"><name><surname>Ratcliff</surname><given-names>R</given-names></name>, <name><surname>McKoon</surname><given-names>G</given-names></name>, <year>2008</year>. <article-title>The diffusion decision model: theory
and data for two-choice decision tasks</article-title>. <source>Neural
Comput</source>. <volume>20</volume>,
<fpage>873</fpage>–<lpage>922</lpage>.<pub-id pub-id-type="pmid">18085991</pub-id></mixed-citation>
    </ref>
    <ref id="R68">
      <mixed-citation publication-type="journal"><name><surname>Ratcliff</surname><given-names>R</given-names></name>, <name><surname>Rouder</surname><given-names>JN</given-names></name>, <year>1998</year>. <article-title>Modeling response times for
two-choice decisions</article-title>. <source>Psychol. Sci</source><volume>9</volume>,
<fpage>347</fpage>–<lpage>356</lpage>.</mixed-citation>
    </ref>
    <ref id="R69">
      <mixed-citation publication-type="journal"><name><surname>Ratcliff</surname><given-names>R</given-names></name>, <name><surname>Rouder</surname><given-names>JN</given-names></name>, <year>2000</year>. <article-title>A diffusion model account of masking
in two-choice letter identification</article-title>. <source>J. Exp.
Psychol.: Human Percept. Perform</source>. <volume>26</volume>,
<fpage>127</fpage>–<lpage>140</lpage>.<pub-id pub-id-type="pmid">10696609</pub-id></mixed-citation>
    </ref>
    <ref id="R70">
      <mixed-citation publication-type="book"><name><surname>Ratcliff</surname><given-names>R</given-names></name>, <name><surname>Smith</surname><given-names>P</given-names></name>, <year>2015</year>. <part-title>Modeling simple decisions and
applications using a diffusion model</part-title>. In: <name><surname>Busemeyer</surname><given-names>JR</given-names></name>, <name><surname>Wang</surname><given-names>Z</given-names></name>, <name><surname>Townsend</surname><given-names>JT</given-names></name>, <name><surname>Eidels</surname><given-names>A</given-names></name> (Eds.), <source>The Oxford Handbook of Computational and Mathematical
Psychology</source>. <publisher-name>Oxford University
Press</publisher-name>, pp.
<fpage>35</fpage>–<lpage>62</lpage>.</mixed-citation>
    </ref>
    <ref id="R71">
      <mixed-citation publication-type="journal"><name><surname>Ratcliff</surname><given-names>R</given-names></name>, <name><surname>Smith</surname><given-names>PL</given-names></name>, <name><surname>Brown</surname><given-names>SD</given-names></name>, <name><surname>McKoon</surname><given-names>G</given-names></name>, <year>2016</year>. <article-title>Diffusion decision model: current
issues and history</article-title>. <source>Trends Cogn. Sci</source><volume>20</volume>,
<fpage>260</fpage>–<lpage>281</lpage>.<pub-id pub-id-type="pmid">26952739</pub-id></mixed-citation>
    </ref>
    <ref id="R72">
      <mixed-citation publication-type="journal"><name><surname>Ratcliff</surname><given-names>R</given-names></name>, <name><surname>Tuerlinckx</surname><given-names>F</given-names></name>, <year>2002</year>. <article-title>Estimating parameters of the
diffusion model: approaches to dealing with contaminant reaction times and
parameter variability</article-title>. <source>Psychon. Bull. Rev</source><volume>9</volume>,
<fpage>438</fpage>–<lpage>481</lpage>.<pub-id pub-id-type="pmid">12412886</pub-id></mixed-citation>
    </ref>
    <ref id="R73">
      <mixed-citation publication-type="journal"><name><surname>Ratcliff</surname><given-names>R</given-names></name>, <year>2013</year>. <article-title>Parameter variability and
distributional assumptions in the diffusion model</article-title>.
<source>Psychol. Rev</source><volume>120</volume>, <fpage>281</fpage>.<pub-id pub-id-type="pmid">23148742</pub-id></mixed-citation>
    </ref>
    <ref id="R74">
      <mixed-citation publication-type="journal"><name><surname>Reddi</surname><given-names>BAJ</given-names></name>, <name><surname>Carpenter</surname><given-names>RHS</given-names></name>, <year>2000</year>. <article-title>The influence of urgency on decision
time</article-title>. <source>Nat. Neurosci</source><volume>3</volume>,
<fpage>827</fpage>–<lpage>830</lpage>.<pub-id pub-id-type="pmid">10903577</pub-id></mixed-citation>
    </ref>
    <ref id="R75">
      <mixed-citation publication-type="journal"><name><surname>Roitman</surname><given-names>JD</given-names></name>, <name><surname>Shadlen</surname><given-names>MN</given-names></name>, <year>2002</year>. <article-title>Responses of neurons in the lateral
intraparietal area during a combined visual discrimination reaction time
task</article-title>. <source>J. Neurosci</source><volume>22</volume>,
<fpage>9475</fpage>–<lpage>9489</lpage>.<pub-id pub-id-type="pmid">12417672</pub-id></mixed-citation>
    </ref>
    <ref id="R76">
      <mixed-citation publication-type="journal"><name><surname>Schall</surname><given-names>JD</given-names></name>, <year>2001</year>. <article-title>Neural basis of deciding, choosing,
and acting</article-title>. <source>Nat. Rev. Neurosci</source><volume>2</volume>, <fpage>33</fpage>–<lpage>42</lpage>.<pub-id pub-id-type="pmid">11253357</pub-id></mixed-citation>
    </ref>
    <ref id="R77">
      <mixed-citation publication-type="journal"><name><surname>Schall</surname><given-names>JD</given-names></name>, <year>2004</year>. <article-title>On building a bridge between brain
and behavior</article-title>. <source>Annu. Rev. Psychol</source><volume>55</volume>,
<fpage>23</fpage>–<lpage>50</lpage>.<pub-id pub-id-type="pmid">14744209</pub-id></mixed-citation>
    </ref>
    <ref id="R78">
      <mixed-citation publication-type="journal"><name><surname>Schwarz</surname><given-names>G</given-names></name>, <year>1978</year>. <article-title>Estimating the dimension of a
model</article-title>. <source>Ann. Stat</source><volume>6</volume>,
<fpage>461</fpage>–<lpage>464</lpage>.</mixed-citation>
    </ref>
    <ref id="R79">
      <mixed-citation publication-type="journal"><name><surname>Scott</surname><given-names>BB</given-names></name>, <name><surname>Constantinople</surname><given-names>CM</given-names></name>, <name><surname>Erlich</surname><given-names>JC</given-names></name>, <name><surname>Tank</surname><given-names>DW</given-names></name>, <name><surname>Brody</surname><given-names>CD</given-names></name>, <year>2015</year>. <article-title>Sources of noise during accumulation
of evidence in unrestrained and voluntarily head-re-strained
rats</article-title>. <source>Elife</source><volume>4</volume>, <fpage>e11308</fpage>.<pub-id pub-id-type="pmid">26673896</pub-id></mixed-citation>
    </ref>
    <ref id="R80">
      <mixed-citation publication-type="journal"><name><surname>Shadlen</surname><given-names>MN</given-names></name>, <name><surname>Kiani</surname><given-names>R</given-names></name>, <year>2013</year>. <article-title>Decision making as a window on
cognition</article-title>. <source>Neuron</source><volume>80</volume>,
<fpage>791</fpage>–<lpage>806</lpage>.<pub-id pub-id-type="pmid">24183028</pub-id></mixed-citation>
    </ref>
    <ref id="R81">
      <mixed-citation publication-type="journal"><name><surname>Shadlen</surname><given-names>MN</given-names></name>, <name><surname>Newsome</surname><given-names>WT</given-names></name>, <year>2001</year>. <article-title>Neural basis of a perceptual decision
in the parietal cortex (area LIP) of the rhesus monkey</article-title>.
<source>J. Neurophysiol</source><volume>86</volume>,
<fpage>1916</fpage>–<lpage>1936</lpage>.<pub-id pub-id-type="pmid">11600651</pub-id></mixed-citation>
    </ref>
    <ref id="R82">
      <mixed-citation publication-type="journal"><name><surname>Smith</surname><given-names>PL</given-names></name>, <year>2000</year>. <article-title>Stochastic dynamic models of response
time and accuracy: a foundational primer</article-title>. <source>J. Math.
Psychol</source><volume>44</volume>,
<fpage>408</fpage>–<lpage>463</lpage>.<pub-id pub-id-type="pmid">10973778</pub-id></mixed-citation>
    </ref>
    <ref id="R83">
      <mixed-citation publication-type="journal"><name><surname>Smith</surname><given-names>PL</given-names></name>, <name><surname>Ratcliff</surname><given-names>R</given-names></name>, <year>2009</year>. <article-title>An integrated theory of attention and
decision making in visual signal detection</article-title>. <source>Psychol.
Rev</source><volume>116</volume>,
<fpage>283</fpage>–<lpage>317</lpage>.<pub-id pub-id-type="pmid">19348543</pub-id></mixed-citation>
    </ref>
    <ref id="R84">
      <mixed-citation publication-type="journal"><name><surname>Stone</surname><given-names>M</given-names></name>, <year>1960</year>. <article-title>Models for choice-reaction
time</article-title>. <source>Psychometrika</source><volume>25</volume>,
<fpage>251</fpage>–<lpage>260</lpage>.</mixed-citation>
    </ref>
    <ref id="R85">
      <mixed-citation publication-type="journal"><name><surname>Tajima</surname><given-names>S</given-names></name>, <name><surname>Drugowitsch</surname><given-names>J</given-names></name>, <name><surname>Pouget</surname><given-names>A</given-names></name>, <year>2016</year>. <article-title>Optimal policy for value-based
decision-making</article-title>. <source>Nat. Commun</source><volume>7</volume>, <fpage>12400</fpage>.<pub-id pub-id-type="pmid">27535638</pub-id></mixed-citation>
    </ref>
    <ref id="R86">
      <mixed-citation publication-type="journal"><name><surname>Thura</surname><given-names>D</given-names></name>, <name><surname>Beauregard-Racine</surname><given-names>J</given-names></name>, <name><surname>Fradet</surname><given-names>CW</given-names></name>, <name><surname>Cisek</surname><given-names>P</given-names></name>, <year>2012</year>. <article-title>Decision making by urgency gating:
theory and experimental support</article-title>. <source>J.
Neurophysiol</source><volume>108</volume>,
<fpage>2912</fpage>–<lpage>2930</lpage>.<pub-id pub-id-type="pmid">22993260</pub-id></mixed-citation>
    </ref>
    <ref id="R87">
      <mixed-citation publication-type="journal"><name><surname>Thura</surname><given-names>D</given-names></name>, <name><surname>Cisek</surname><given-names>P</given-names></name>, <year>2014</year>. <article-title>Deliberation and commitment in the
premotor and primary motor cortex during dynamic decision
making</article-title>. <source>Neuron</source><volume>81</volume>,
<fpage>1401</fpage>–<lpage>1416</lpage>.<pub-id pub-id-type="pmid">24656257</pub-id></mixed-citation>
    </ref>
    <ref id="R88">
      <mixed-citation publication-type="journal"><name><surname>Thura</surname><given-names>D</given-names></name>, <name><surname>Cisek</surname><given-names>P</given-names></name>, <year>2016</year>. <article-title>Modulation of premotor and primary
motor cortical activity during volitional adjustments of speed-accuracy
trade-offs</article-title>. <source>J. Neurosci</source><volume>36</volume>,
<fpage>938</fpage>–<lpage>956</lpage>.<pub-id pub-id-type="pmid">26791222</pub-id></mixed-citation>
    </ref>
    <ref id="R89">
      <mixed-citation publication-type="journal"><name><surname>Thura</surname><given-names>D</given-names></name>, <name><surname>Cos</surname><given-names>I</given-names></name>, <name><surname>Trung</surname><given-names>J</given-names></name>, <name><surname>Cisek</surname><given-names>P</given-names></name>, <year>2014</year>. <article-title>Context-dependent urgency influences
speed-accuracy trade-offs in decision-making and movement execution. J.
Neurosci.</article-title>: <source>Off. J. Soc. Neurosci</source><volume>34</volume>,
<fpage>16442</fpage>–<lpage>16454</lpage>.</mixed-citation>
    </ref>
    <ref id="R90">
      <mixed-citation publication-type="journal"><name><surname>Tsunada</surname><given-names>J</given-names></name>, <name><surname>Liu</surname><given-names>ASK</given-names></name>, <name><surname>Gold</surname><given-names>JI</given-names></name>, <name><surname>Cohen</surname><given-names>YE</given-names></name>, <year>2016</year>. <article-title>Causal contribution of primate
auditory cortex to auditory perceptual decision-making</article-title>.
<source>Nat. Neurosci</source><volume>19</volume>,
<fpage>135</fpage>–<lpage>142</lpage>.<pub-id pub-id-type="pmid">26656644</pub-id></mixed-citation>
    </ref>
    <ref id="R91">
      <mixed-citation publication-type="journal"><name><surname>Usher</surname><given-names>M</given-names></name>, <name><surname>McClelland</surname><given-names>JL</given-names></name>, <year>2001</year>. <article-title>On the time course of perceptual
choice: the leaky competing accumulator model</article-title>.
<source>Psychol. Rev</source><volume>108</volume>,
<fpage>550</fpage>–<lpage>592</lpage>.<pub-id pub-id-type="pmid">11488378</pub-id></mixed-citation>
    </ref>
    <ref id="R92">
      <mixed-citation publication-type="journal"><name><surname>Vandekerckhove</surname><given-names>J</given-names></name>, <name><surname>Tuerlinckx</surname><given-names>F</given-names></name>, <year>2008</year>. <article-title>Diffusion model analysis with MATLAB:
a DMAT primer</article-title>. <source>Behav. Res. Methods</source><volume>40</volume>,
<fpage>61</fpage>–<lpage>72</lpage>.<pub-id pub-id-type="pmid">18411528</pub-id></mixed-citation>
    </ref>
    <ref id="R93">
      <mixed-citation publication-type="journal"><name><surname>Voss</surname><given-names>A</given-names></name>, <name><surname>Voss</surname><given-names>J</given-names></name>, <year>2007</year>. <article-title>Fast-dm: a free program for efficient
diffusion model analysis</article-title>. <source>Behav. Res.
Methods</source><volume>39</volume>,
<fpage>767</fpage>–<lpage>775</lpage>.<pub-id pub-id-type="pmid">18183889</pub-id></mixed-citation>
    </ref>
    <ref id="R94">
      <mixed-citation publication-type="journal"><name><surname>Voss</surname><given-names>A</given-names></name>, <name><surname>Voss</surname><given-names>J</given-names></name>, <name><surname>Lerche</surname><given-names>V</given-names></name>, <year>2015</year>. <article-title>Assessing cognitive processes with
diffusion model analyses: a tutorial based on fast-dm-30</article-title>.
<source>Front. Psychol</source><volume>6</volume>, <fpage>336</fpage>.<pub-id pub-id-type="pmid">25870575</pub-id></mixed-citation>
    </ref>
    <ref id="R95">
      <mixed-citation publication-type="journal"><name><surname>Wagenmakers</surname><given-names>EJ</given-names></name>, <name><surname>Farrell</surname><given-names>S</given-names></name>, <year>2004</year>. <article-title>AIC model selection using Akaike
weights</article-title>. <source>Psychon. Bull. Rev</source><volume>11</volume>,
<fpage>192</fpage>–<lpage>196</lpage>.<pub-id pub-id-type="pmid">15117008</pub-id></mixed-citation>
    </ref>
    <ref id="R96">
      <mixed-citation publication-type="journal"><name><surname>Wald</surname><given-names>A</given-names></name>, <name><surname>Wolfowitz</surname><given-names>J</given-names></name>, <year>1948</year>. <article-title>Optimal character of the sequential
probability ratio test</article-title>. <source>Ann. Math. Stat</source><volume>19</volume>,
<fpage>326</fpage>–<lpage>339</lpage>.</mixed-citation>
    </ref>
    <ref id="R97">
      <mixed-citation publication-type="journal"><name><surname>Wasserman</surname><given-names>L</given-names></name>, <year>2000</year>. <article-title>Bayesian model selection and model
averaging</article-title>. <source>J. Math. Psychol</source><volume>44</volume>,
<fpage>92</fpage>–<lpage>107</lpage>.<pub-id pub-id-type="pmid">10733859</pub-id></mixed-citation>
    </ref>
    <ref id="R98">
      <mixed-citation publication-type="journal"><name><surname>Wiecki</surname><given-names>TV</given-names></name>, <name><surname>Sofer</surname><given-names>I</given-names></name>, <name><surname>Frank</surname><given-names>MJ</given-names></name>, <year>2013</year>. <article-title>HDDM: hierarchical Bayesian
estimation of the drift-diffusion model in Python</article-title>.
<source>Front. Neuroinform</source><volume>7</volume>. <pub-id pub-id-type="doi">10.3389/fninf.2013.00014</pub-id><comment>.</comment></mixed-citation>
    </ref>
    <ref id="R99">
      <mixed-citation publication-type="other"><name><surname>Wilson</surname><given-names>RC</given-names></name>, <name><surname>Collins</surname><given-names>A</given-names></name>, <year>2019</year>. <source>Ten Simple Rules for the Computational
Modeling of Behavioral Data</source>.</mixed-citation>
    </ref>
    <ref id="R100">
      <mixed-citation publication-type="journal"><name><surname>Zhang</surname><given-names>S</given-names></name>, <name><surname>Lee</surname><given-names>MD</given-names></name>, <name><surname>Vandekerckhove</surname><given-names>J</given-names></name>, <name><surname>Maris</surname><given-names>G</given-names></name>, <name><surname>Wagenmakers</surname><given-names>EJ</given-names></name>, <year>2014</year>. <article-title>Time-varying boundaries for diffusion
models of decision making and response time</article-title>. <source>Front.
Psychol</source><volume>5</volume>, <fpage>1364</fpage>.<pub-id pub-id-type="pmid">25538642</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
<floats-group>
  <fig id="F1" orientation="portrait" position="float">
    <label>Fig. 1.</label>
    <caption>
      <p id="P150">Schematic of some sequential sampling models of decision-making
incorporated in <italic>ChaRTr</italic>. (A) The DDM model is the simplest
example of a diffusion model of decision-making. (B) A variant of the DDM with
variable non-decision time (<italic>S</italic><sub><italic>t</italic></sub>),
variable drift-rate (<italic>S</italic><sub><italic>v</italic></sub>) and a
variable start point (<italic>S</italic><sub><italic>z</italic></sub>). (C) A
DDM with collapsing bounds and variability in the non-decision time and drift
rate. The function <italic>A</italic>(<italic>t</italic>) takes the form of a
Weibull function as defined in <xref rid="FD6" ref-type="disp-formula">Eq.
(6)</xref>. (D) A variant of the DDM with variable non-decision time and
drift rate, and an “urgency signal”. This urgency signal grows
with elapsed decision time, which is implemented by multiplying the decision
variable by the increasing function of time γ(<italic>t</italic>) (<xref rid="FD10" ref-type="disp-formula">Eq. (10)</xref>, following <xref rid="R23" ref-type="bibr">Ditterich, 2006a</xref>). (E) UGM with variable
drift rate (<italic>S</italic><sub><italic>v</italic></sub>) and variable non
decision time (<italic>S</italic><sub><italic>t</italic></sub>). In the standard
UGM, the urgency signal is only thought to depend on time and thus starts at 0.
The sensory evidence is passed through a low pass filter (typically a
100–250 ms time constant, <xref rid="R12" ref-type="bibr">Carland et al.,
2015</xref>; <xref rid="R86" ref-type="bibr">Thura et al., 2012</xref>). The
sensory evidence is then multiplied by the urgency signal to produce a decision
variable that is compared to the decision boundaries. (F) Schematic of urgency
signals with an intercept (top panel) and a variable intercept (bottom
panel).</p>
    </caption>
    <graphic xlink:href="nihms-1547435-f0001"/>
  </fig>
  <fig id="F2" orientation="portrait" position="float">
    <label>Fig. 2.</label>
    <caption>
      <p id="P151">A quantile probability (QP) plot of choice and RT data from a
hypothetical decision-making experiment with three levels of stimulus
difficulty. The three difficulty levels are represented as vertical columns
mirrored around the midpoint of the <italic>x</italic>-axis (0.5). In this
example, the lowest accuracy condition had ~55% correct responses, so the RTs
for correct responses in this condition are located at 0.55 on the
<italic>x</italic>-axis and the corresponding RTs for error responses are
located at 1 − 0.55 = 0.45 on the <italic>x</italic>-axis; these two RT
distributions are highlighted in gray bars. For each RT distribution we plot
along the <italic>y</italic>-axis the 10th, 30th, 50th, 70th, 90th percentiles
(i.e., 0.1, 0.3, 0.5, 0.7, 0.9 quantiles), separately for correct and error
responses in each of the three difficulty levels. For clarity, correct responses
are shown in blue and error responses are shown in yellow. (For interpretation
of the references to color in this figure legend, the reader is referred to the
web version of this article.)</p>
    </caption>
    <graphic xlink:href="nihms-1547435-f0002"/>
  </fig>
  <fig id="F3" orientation="portrait" position="float">
    <label>Fig. 3.</label>
    <caption>
      <p id="P152"><italic>ChaRTr</italic> flow chart. Models are specified and once data
is available, the parameters are estimated through the optimization procedure.
Once parameter estimation is complete, the final goodness of fit statistic is
calculated for every model under consideration, which is used for subsequent
model selection analyses.</p>
    </caption>
    <graphic xlink:href="nihms-1547435-f0003"/>
  </fig>
  <fig id="F4" orientation="portrait" position="float">
    <label>Fig. 4.</label>
    <caption>
      <p id="P153">Flow chart for the parameter estimation component of
<italic>ChaRTr</italic>, which uses the differential evolution optimization
algorithm (<xref rid="R54" ref-type="bibr">Mullen et al., 2011</xref>).</p>
    </caption>
    <graphic xlink:href="nihms-1547435-f0004"/>
  </fig>
  <fig id="F5" orientation="portrait" position="float">
    <label>Fig. 5.</label>
    <caption>
      <p id="P154">Quantile probability plots of data simulated from four models in
<italic>ChaRTr</italic>. (A) DDM, (B) DDM with variable drift rates,
starting state and non-decision time
(DDMS<sub><italic>v</italic></sub>S<sub><italic>z</italic></sub>S<sub><italic>t</italic></sub>),
(C) urgency gating model with variable drift rates (UGMS<sub>v</sub>), and (D)
DDM with an urgency signal and a variable drift rate defined as per <xref rid="R23" ref-type="bibr">Ditterich (2006a</xref>, dDDMS)<xref rid="R23" ref-type="bibr">Ditterich, 2006a</xref><xref rid="R23" ref-type="bibr">Ditterich, 2006a</xref><xref rid="R23" ref-type="bibr">Ditterich
(2006a</xref>, dDDMS)<xref rid="R23" ref-type="bibr">Ditterich,
2006a</xref><xref rid="R23" ref-type="bibr">Ditterich, 2006a</xref><xref rid="R23" ref-type="bibr">Ditterich (2006a</xref>, dDDMS)<xref rid="R23" ref-type="bibr">Ditterich, 2006a</xref><xref rid="R23" ref-type="bibr">Ditterich (2006a, dDDMS)</xref><xref rid="R23" ref-type="bibr">Ditterich,
2006a</xref><xref rid="R23" ref-type="bibr">Ditterich (2006a,
dDDMS)</xref><xref rid="R23" ref-type="bibr">Ditterich, 2006a</xref><xref rid="R23" ref-type="bibr">Ditterich (2006a, dDDMS)</xref><xref rid="R23" ref-type="bibr">Ditterich, 2006a</xref><xref rid="R23" ref-type="bibr">Ditterich (2006a, dDDMS)</xref>. Gray points denote data. Lines are drawn
for visualization purposes.</p>
    </caption>
    <graphic xlink:href="nihms-1547435-f0005"/>
  </fig>
  <fig id="F6" orientation="portrait" position="float">
    <label>Fig. 6.</label>
    <caption>
      <p id="P155">Model selection and parameter estimation outcomes from applying a range
of cognitive models of decision-making to choice and RT data from five
hypothetical observers (case study 1). A–C shows outcomes from one
hypothetical observer and E shows outcomes from a second hypothetical observer.
Data were generated using the model
DDMS<sub><italic>v</italic></sub>S<sub><italic>t</italic></sub>. (A) AIC
values for each model with the DDM model as the reference. To guide the eye and
ease readability, bars are colored based on whether they are better or worse
than the DDM in fitting the data. The best model is shown in green, and the next
five best models are shown in orange. The remaining models better than the DDM
are shown in gray and models worse than the DDM are shown in purple. (B) Same as
A but using BIC as the model comparison metric. (C) Akaike weights and BIC-based
approximate posterior model probabilities for the top six models that provided
the best account of the data. <italic>ChaRTr</italic> correctly identifies the
true data-generating model
(DDMS<sub><italic>v</italic></sub>S<sub><italic>t</italic></sub>) as the
one of the most likely candidates for describing the data. (D) Data-generative
and estimated parameter values for the
DDMS<sub><italic>v</italic></sub>S<sub><italic>t</italic></sub> model
shown in A. Close alignment indicates <italic>ChaRTr</italic> recovered the true
parameter values. (E) Akaike weights and posterior model probabilities from
another hypothetical observer. Color conventions as in C. (F) Average akaike
weights and posterior model probabilities across all five hypothetical
observers, assuming the observers are independent. Reassuringly,
DDMS<sub><italic>v</italic></sub>S<sub><italic>t</italic></sub> is
identified as one of the most plausible models for the data. (For interpretation
of the references to color in the print version for this figure legend, the
reader is referred to the web version of this article.).</p>
    </caption>
    <graphic xlink:href="nihms-1547435-f0006"/>
  </fig>
  <fig id="F7" orientation="portrait" position="float">
    <label>Fig. 7.</label>
    <caption>
      <p id="P156">Quantile probability (QP) plots showing correct RTs (blue) and error
RTs (orange) for two hypothetical observers (case study 1), along with the model
predictions (gray dots). Predictions from the four best-fitting models are shown
along with the simplest model the DDM. The best fitting models
DDMS<sub><italic>v</italic></sub>S<sub><italic>t</italic></sub>,
DDMS<sub><italic>t</italic></sub>,
DDMS<sub><italic>v</italic></sub>S<sub><italic>z</italic></sub>S<sub><italic>t</italic></sub>,
cfkDDMS<sub><italic>v</italic></sub>S<sub><italic>t</italic></sub>, and
dDDMS<sub><italic>v</italic></sub>S<sub><italic>t</italic></sub> are
shown. Numbers at the top of each plot show the log likelihood, AIC, and BIC for
the model under consideration. AIC and BIC are computed with respect to the DDM.
Higher values of log-likelihood are better. When assuming the DDM as the base
(reference) model and AIC as the penalized model selection metric, the model
DDMS<sub><italic>v</italic></sub>S<sub><italic>t</italic></sub> provides
the best account of the data. When using BIC as the penalized model selection
metric, the model DDMS<sub><italic>t</italic></sub> provides a better
description of the data. (For interpretation of the references to color in this
figure legend, the reader is referred to the web version of this article.)</p>
    </caption>
    <graphic xlink:href="nihms-1547435-f0007"/>
  </fig>
  <fig id="F8" orientation="portrait" position="float">
    <label>Fig. 8.</label>
    <caption>
      <p id="P157">Model selection and parameter estimation outcomes from applying a range
of cognitive models of decision-making to data from hypothetical observers (case
study 2). Decision-making in these hypothetical observers is controlled by the
model bUGMS<sub><italic>v</italic></sub>. (A) AIC values as a function of model
with the DDM model as the reference for one hypothetical observer, Subj 3. Color
conventions as in <xref rid="F6" ref-type="fig">Fig. 6A</xref>. (B) BIC values
as a function of model with the DDM model as the reference for the same subject
shown in A. (C) Akaike Weights and Posterior model probabilities for the top six
models that provided the best account of Subj 3’s behavior. (D) Results
for another hypothetical subject. (E) Results for the population of hypothetical
subjects. The most probable model for this set of hypothetical observers is the
generative model, bUGMS<sub><italic>v</italic></sub>. However, we note that
other models such as bUGM, UGMS<sub><italic>v</italic></sub>, and
uDDMS<sub><italic>v</italic></sub> provide quite good descriptions of
the behavior. This result is in keeping with the general notion that model
selection ought to be used as a guide to the most likely models and not
necessarily to argue for a “best” model. (For interpretation of
the references to color in this figure legend, the reader is referred to the web
version of this article.)</p>
    </caption>
    <graphic xlink:href="nihms-1547435-f0008"/>
  </fig>
  <fig id="F9" orientation="portrait" position="float">
    <label>Fig. 9.</label>
    <caption>
      <p id="P158">Model selection outcomes from applying a range of cognitive models of
decision-making to data from two monkeys (<xref rid="R75" ref-type="bibr">Roitman and Shadlen, 2002</xref>). (A) and (B) show outcomes from monkeys b
and n to compare models with various forms of urgency vs. simple diffusion
decision models without urgency. For both monkeys, <italic>ChaRTr</italic>
suggests models with urgency are better candidates for describing the data than
DDMs without urgency. (C) and (D) show outcomes from monkeys b and n when
comparing UGM vs. DDM models. For both monkeys, UGM based models substantially
outperform the DDM based models.</p>
    </caption>
    <graphic xlink:href="nihms-1547435-f0009"/>
  </fig>
  <fig id="F10" orientation="portrait" position="float">
    <label>Fig. 10.</label>
    <caption>
      <p id="P159">Quantile probability (QP) plots showing data in blue (corrects) and
yellow crosses (errors) for the two monkeys from <xref rid="R75" ref-type="bibr">Roitman and Shadlen (2002)</xref>, along with the model predictions (gray
dots). Predictions from
DDMS<sub><italic>v</italic></sub>S<sub><italic>z</italic></sub>S<sub><italic>t</italic></sub>
are shown along with four other models
uDDMS<sub><italic>v</italic></sub>S<sub><italic>b</italic></sub>,
bUGMS<sub><italic>v</italic></sub>S<sub><italic>b</italic></sub>,
uDDMS<sub><italic>v</italic></sub>S<sub><italic>t</italic></sub>,
bUGMS<sub><italic>v</italic></sub>S<sub><italic>b</italic></sub>.
Numbers at the top of each plot show the Log likelihood, the AIC and the BIC for
the model under consideration. Higher, that is, more positive values of log
likelihood are better. AIC and BIC are reported assuming
DDMS<sub><italic>v</italic></sub>S<sub><italic>z</italic></sub>S<sub><italic>t</italic></sub>
as the base (reference) model. For both monkeys the model
bUGMS<sub><italic>v</italic></sub>S<sub><italic>b</italic></sub> is the
best model for describing the data out of these candidate set of models. (For
interpretation of the references to color in this figure legend, the reader is
referred to the web version of this article.)</p>
    </caption>
    <graphic xlink:href="nihms-1547435-f0010"/>
  </fig>
  <fig id="F11" orientation="portrait" position="float">
    <label>Fig. 11.</label>
    <caption>
      <p id="P160">Computation time for models in <italic>ChaRTr</italic>. (A) Run time as
a function of the number of parameters in the models for the four different
settings we considered. (B) Computation time for each model under each of the
four settings. (C) Total time for parameter estimation under the different
parameter settings and random number generators. In all panels,
<italic>np</italic> refers to the number of particles used in the
differential evolution algorithm, <italic>n</italic> is the number of Monte
Carlo replicates used for simulation of each of these models. Higher values of
<italic>n</italic> provide more precision but require more time.</p>
    </caption>
    <graphic xlink:href="nihms-1547435-f0011"/>
  </fig>
  <fig id="F12" orientation="portrait" position="float">
    <label>Fig. 12.</label>
    <caption>
      <p id="P161">Optimizing computational speed is not detrimental to model selection
analysis in <italic>ChaRTr</italic>. Akaike weights averaged over five
hypothetical subjects in a model selection analysis with different settings of
the random number generator, number of particles, and number of simulated trials
per particle for case study 1 (A) and case study 2 (B). For both case studies,
<italic>ChaRTr</italic> reliably identifies the correct data-generating
model and in many cases agrees on the second best model for the data. We also
note that the exact ranking of the models slightly differ across hyperparameter
settings, but the set of identified models is consistent.</p>
    </caption>
    <graphic xlink:href="nihms-1547435-f0012"/>
  </fig>
  <table-wrap id="T1" position="float" orientation="landscape">
    <label>Table 1</label>
    <caption>
      <p id="P162">List of symbols used in the decision-making models implemented in
<italic>ChaRTr</italic>.</p>
    </caption>
    <table frame="hsides" rules="groups">
      <colgroup span="1">
        <col align="left" valign="middle" span="1"/>
        <col align="left" valign="middle" span="1"/>
      </colgroup>
      <thead>
        <tr>
          <th align="left" valign="top" rowspan="1" colspan="1">Parameter</th>
          <th align="left" valign="top" rowspan="1" colspan="1">Description</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1"><italic>x</italic>(<italic>t</italic>)</td>
          <td align="left" valign="top" rowspan="1" colspan="1">State of the decision variable at time
<italic>t</italic>.</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1">Δ<italic>t</italic></td>
          <td align="left" valign="top" rowspan="1" colspan="1">Time step of the decision variable.</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1"><italic>z</italic>,
<italic>s<sub>z</sub></italic></td>
          <td align="left" valign="top" rowspan="1" colspan="1">Starting state of the decision variable (i.e.,
<italic>x</italic>(0) = <italic>z</italic>), and
decision-to-decision variability in starting state.
<italic>s<sub>z</sub></italic> is the range of a uniform
distribution with mean (midpoint) <italic>z</italic>.</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1"><italic>v<sub>i</sub></italic>,
<italic>s<sub>v</sub></italic></td>
          <td align="left" valign="top" rowspan="1" colspan="1">Rate at which the decision variable
accumulates decision-relevant information (drift rate,
<italic>v</italic>) in condition <italic>i</italic>, and
decision-to-decision variability in drift rate.
<italic>s<sub>v</sub></italic> is the standard deviation of a normal
distribution with mean <italic>v<sub>i</sub></italic>.</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1"><italic>γ</italic>(<italic>t</italic>)</td>
          <td align="left" valign="top" rowspan="1" colspan="1">Urgency signal that dynamically modulates the
decision variable as a function of <italic>t</italic>. Can take
different functional forms in different models.</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1"><italic>a<sub>upper</sub></italic>,
<italic>a<sub>lower</sub></italic></td>
          <td align="left" valign="top" rowspan="1" colspan="1">Upper and lower response boundaries that
terminate the decision process.</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1"><italic>a<sub>upper</sub></italic>(<italic>t</italic>),
<italic>a<sub>lower</sub></italic>(<italic>t</italic>)</td>
          <td align="left" valign="top" rowspan="1" colspan="1">Upper and lower response boundaries that vary
as a function of <italic>t</italic>.</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1"><italic>T<sub>er</sub></italic>,
<italic>s<sub>t</sub></italic></td>
          <td align="left" valign="top" rowspan="1" colspan="1">Time required for stimulus encoding and motor
preparation/execution (non-decision time), and decision-to-decision
variability in non-decision time. <italic>s<sub>t</sub></italic> is the
range of a uniform distribution with mean (midpoint)
<italic>T<sub>er</sub></italic>.</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1">
            <italic>s</italic>
          </td>
          <td align="left" valign="top" rowspan="1" colspan="1">Within-decision variability in the diffusion
process. Represents the standard deviation of a normal distribution. By
convention, set to a fixed value to satisfy a scaling property of the
model.</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1"><italic>E</italic>(<italic>t</italic>)</td>
          <td align="left" valign="top" rowspan="1" colspan="1">Momentary sensory evidence at time
<italic>t</italic>.</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1"><italic>b</italic>,
<italic>s<sub>b</sub></italic></td>
          <td align="left" valign="top" rowspan="1" colspan="1">Intercept and variability of the intercept in
urgency based models with linear urgency signals.</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1">
            <inline-formula>
              <mml:math display="inline" id="M27" overflow="scroll">
                <mml:mrow>
                  <mml:mi mathvariant="script">N</mml:mi>
                  <mml:mo stretchy="false">(</mml:mo>
                  <mml:mn>0</mml:mn>
                  <mml:mo>,</mml:mo>
                  <mml:mspace width="0.25em"/>
                  <mml:mn>1</mml:mn>
                  <mml:mo stretchy="false">)</mml:mo>
                </mml:mrow>
              </mml:math>
            </inline-formula>
          </td>
          <td align="left" valign="top" rowspan="1" colspan="1">Normal distribution with zero mean and unit
variance.</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1">
            <inline-formula>
              <mml:math display="inline" id="M28" overflow="scroll">
                <mml:mrow>
                  <mml:mi mathvariant="script">U</mml:mi>
                  <mml:mrow>
                    <mml:mo>(</mml:mo>
                    <mml:mrow>
                      <mml:msub>
                        <mml:mi>l</mml:mi>
                        <mml:mn>1</mml:mn>
                      </mml:msub>
                      <mml:mo>,</mml:mo>
                      <mml:msub>
                        <mml:mi>l</mml:mi>
                        <mml:mn>2</mml:mn>
                      </mml:msub>
                    </mml:mrow>
                    <mml:mo>)</mml:mo>
                  </mml:mrow>
                </mml:mrow>
              </mml:math>
            </inline-formula>
          </td>
          <td align="left" valign="top" rowspan="1" colspan="1">Uniform distribution over the interval
<italic>l</italic><sub>1</sub> and
<italic>l</italic><sub>2</sub>.</td>
        </tr>
      </tbody>
    </table>
  </table-wrap>
  <table-wrap id="T2" position="float" orientation="portrait">
    <label>Table 2</label>
    <caption>
      <p id="P163">List of the 37 models available in <italic>ChaRTr</italic> along with
the individual parameters in each model and the total number of parameters.
<italic>n</italic> refers to the number of stimulus conditions used.
<italic>a<sub>U</sub></italic> is the short form of
<italic>a<sub>upper</sub>.</italic></p>
    </caption>
    <table frame="hsides" rules="groups">
      <colgroup span="1">
        <col align="left" valign="middle" span="1"/>
        <col align="left" valign="middle" span="1"/>
        <col align="left" valign="middle" span="1"/>
      </colgroup>
      <thead>
        <tr>
          <th align="left" valign="top" rowspan="1" colspan="1">Abbreviation</th>
          <th align="left" valign="top" rowspan="1" colspan="1">Parameters</th>
          <th align="left" valign="top" rowspan="1" colspan="1">
            <italic>N</italic>
          </th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td align="left" valign="top" colspan="2" rowspan="1">
            <bold>Diffusion decision model
(DDM)</bold>
          </td>
          <td align="left" valign="top" rowspan="1" colspan="1"/>
        </tr>
        <tr>
          <td align="left" valign="top" colspan="3" rowspan="1">References: <xref rid="R63" ref-type="bibr">Ratcliff (1978)</xref>, <xref rid="R68" ref-type="bibr">Ratcliff and Rouder (1998)</xref><xref rid="R63" ref-type="bibr">Ratcliff, 1978</xref><xref rid="R63" ref-type="bibr">Ratcliff (1978)</xref>, <xref rid="R68" ref-type="bibr">Ratcliff
and Rouder (1998)</xref></td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1"> DDM</td>
          <td align="left" valign="top" rowspan="1" colspan="1"><italic>v</italic><sub>1...<italic>n</italic></sub>,
<italic>a<sub>U</sub></italic>,
<italic>T<sub>er</sub></italic></td>
          <td align="left" valign="top" rowspan="1" colspan="1"><italic>n</italic> + 2</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1"> DDMS<italic><sub>v</sub></italic></td>
          <td align="left" valign="top" rowspan="1" colspan="1"><italic>v</italic><sub>1...<italic>n</italic></sub>,
<italic>a<sub>U</sub></italic>, <italic>T<sub>er</sub></italic>,
<italic>S<sub>v</sub></italic></td>
          <td align="left" valign="top" rowspan="1" colspan="1"><italic>n</italic> + 3</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1"> DDMS<italic><sub>t</sub></italic></td>
          <td align="left" valign="top" rowspan="1" colspan="1"><italic>v</italic><sub>1...<italic>n</italic></sub>,
<italic>a<sub>U</sub></italic>, <italic>T<sub>er</sub></italic>,
<italic>S<sub>t</sub></italic></td>
          <td align="left" valign="top" rowspan="1" colspan="1"><italic>n</italic> + 3</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1"> DDMS<italic><sub>v</sub></italic>S<italic><sub>z</sub></italic></td>
          <td align="left" valign="top" rowspan="1" colspan="1"><italic>v</italic><sub>1...<italic>n</italic></sub>,
<italic>a<sub>U</sub></italic>, <italic>T<sub>er</sub></italic>,
<italic>S<sub>v</sub></italic>,
<italic>S<sub>z</sub></italic></td>
          <td align="left" valign="top" rowspan="1" colspan="1"><italic>n</italic> + 4</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1"> DDMS<italic><sub>v</sub></italic>S<italic><sub>t</sub></italic></td>
          <td align="left" valign="top" rowspan="1" colspan="1"><italic>v</italic><sub>1...<italic>n</italic></sub>,
<italic>a<sub>U</sub></italic>, <italic>T<sub>er</sub></italic>,
<italic>S<sub>v</sub></italic>,
<italic>S<sub>t</sub></italic></td>
          <td align="left" valign="top" rowspan="1" colspan="1"><italic>n</italic> + 4</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1"> DDMS<italic><sub>v</sub></italic>S<italic><sub>z</sub></italic>S<italic><sub>t</sub></italic></td>
          <td align="left" valign="top" rowspan="1" colspan="1"><italic>v</italic><sub>1...<italic>n</italic></sub>,
<italic>a<sub>U</sub></italic>, <italic>T<sub>er</sub></italic>,
<italic>S<sub>v</sub></italic>, <italic>S<sub>z</sub></italic>,
<italic>S<sub>t</sub></italic></td>
          <td align="left" valign="top" rowspan="1" colspan="1"><italic>n</italic> + 5</td>
        </tr>
        <tr>
          <td align="left" valign="top" colspan="2" rowspan="1">
            <bold>Collapsing diffusion
decision model (cDDM)</bold>
          </td>
          <td align="left" valign="top" rowspan="1" colspan="1"/>
        </tr>
        <tr>
          <td align="left" valign="top" colspan="3" rowspan="1">References: <xref rid="R26" ref-type="bibr">Drugowitsch et al. (2012)</xref>, <xref rid="R43" ref-type="bibr">Hawkins et al. (2015b)</xref><xref rid="R26" ref-type="bibr">Drugowitsch et al., 2012</xref><xref rid="R26" ref-type="bibr">Drugowitsch et al. (2012)</xref>, <xref rid="R43" ref-type="bibr">Hawkins et al. (2015b)</xref></td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1"> cDDM</td>
          <td align="left" valign="top" rowspan="1" colspan="1"><italic>v</italic><sub>1...<italic>n</italic></sub>,
<italic>a<sub>U</sub></italic>, <italic>T<sub>er</sub></italic>,
<italic>a</italic>′, <italic>k</italic></td>
          <td align="left" valign="top" rowspan="1" colspan="1"><italic>n</italic> + 4</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1"> cDDMS<italic><sub>v</sub></italic></td>
          <td align="left" valign="top" rowspan="1" colspan="1"><italic>v</italic><sub>1...<italic>n</italic></sub>,
<italic>a<sub>U</sub></italic>, <italic>T<sub>er</sub></italic>,
<italic>a</italic>′, <italic>k</italic>,
<italic>S<sub>v</sub></italic></td>
          <td align="left" valign="top" rowspan="1" colspan="1"><italic>n</italic> + 5</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1"> cDDMS<italic><sub>t</sub></italic></td>
          <td align="left" valign="top" rowspan="1" colspan="1"><italic>v</italic><sub>1...<italic>n</italic></sub>,
<italic>a<sub>U</sub></italic>, <italic>T<sub>er</sub></italic>,
<italic>a</italic>′, <italic>k</italic>,
<italic>S<sub>t</sub></italic></td>
          <td align="left" valign="top" rowspan="1" colspan="1"><italic>n</italic> + 5</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1"> cDDMS<italic><sub>v</sub></italic>S<italic><sub>z</sub></italic></td>
          <td align="left" valign="top" rowspan="1" colspan="1"><italic>v</italic><sub>1...<italic>n</italic></sub>,
<italic>a<sub>U</sub></italic>, <italic>T<sub>er</sub></italic>,
<italic>a</italic>′, <italic>k</italic>,
<italic>S<sub>v</sub></italic>,
<italic>S<sub>z</sub></italic></td>
          <td align="left" valign="top" rowspan="1" colspan="1"><italic>n</italic> + 6</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1"> cDDMS<italic><sub>v</sub></italic>S<italic><sub>t</sub></italic></td>
          <td align="left" valign="top" rowspan="1" colspan="1"><italic>v</italic><sub>1...<italic>n</italic></sub>,
<italic>a<sub>U</sub></italic>, <italic>T<sub>er</sub></italic>,
<italic>a</italic>′, <italic>k</italic>,
<italic>S<sub>v</sub></italic>,
<italic>S<sub>t</sub></italic></td>
          <td align="left" valign="top" rowspan="1" colspan="1"><italic>n</italic> + 6</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1"> cDDMS<italic><sub>v</sub></italic>S<italic><sub>z</sub></italic>S<italic><sub>t</sub></italic></td>
          <td align="left" valign="top" rowspan="1" colspan="1"><italic>v</italic><sub>1...<italic>n</italic></sub>,
<italic>a<sub>U</sub></italic>, <italic>T<sub>er</sub></italic>,
<italic>a</italic>′, <italic>k</italic>,
<italic>S<sub>v</sub></italic>, <italic>S<sub>z</sub></italic>,
<italic>S<sub>t</sub></italic></td>
          <td align="left" valign="top" rowspan="1" colspan="1"><italic>n</italic> + 7</td>
        </tr>
        <tr>
          <td align="left" valign="top" colspan="2" rowspan="1">
            <bold>Collapsing diffusion
decision model with fixed</bold>
            <italic>k</italic>
            <bold>(cfkDDM)</bold>
          </td>
          <td align="left" valign="top" rowspan="1" colspan="1"/>
        </tr>
        <tr>
          <td align="left" valign="top" colspan="2" rowspan="1">References: <xref rid="R43" ref-type="bibr">Hawkins et al. (2015b)</xref></td>
          <td align="left" valign="top" rowspan="1" colspan="1"/>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1"> cfkDDM</td>
          <td align="left" valign="top" rowspan="1" colspan="1"><italic>v</italic><sub>1...<italic>n</italic></sub>,
<italic>a<sub>U</sub></italic>, <italic>T<sub>er</sub></italic>,
<italic>a</italic>′</td>
          <td align="left" valign="top" rowspan="1" colspan="1"><italic>n</italic> + 3</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1"> cfkDDMS<italic><sub>v</sub></italic></td>
          <td align="left" valign="top" rowspan="1" colspan="1"><italic>v</italic><sub>1...<italic>n</italic></sub>,
<italic>a<sub>U</sub></italic>, <italic>T<sub>er</sub></italic>,
<italic>a</italic>′, <italic>S<sub>v</sub></italic></td>
          <td align="left" valign="top" rowspan="1" colspan="1"><italic>n</italic> + 4</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1"> cfkDDMS<italic><sub>t</sub></italic></td>
          <td align="left" valign="top" rowspan="1" colspan="1"><italic>v</italic><sub>1...<italic>n</italic></sub>,
<italic>a<sub>U</sub></italic>, <italic>T<sub>er</sub></italic>,
<italic>a</italic>′, <italic>S<sub>t</sub></italic></td>
          <td align="left" valign="top" rowspan="1" colspan="1"><italic>n</italic> + 4</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1"> cfkDDMS<italic><sub>v</sub></italic>S<italic><sub>t</sub></italic></td>
          <td align="left" valign="top" rowspan="1" colspan="1"><italic>v</italic><sub>1...<italic>n</italic></sub>,
<italic>a<sub>U</sub></italic>, <italic>T<sub>er</sub></italic>,
<italic>a</italic>′, <italic>S<sub>v</sub></italic>,
<italic>S<sub>t</sub></italic></td>
          <td align="left" valign="top" rowspan="1" colspan="1"><italic>n</italic> + 5</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1"> cfkDDMS<italic><sub>v</sub></italic>S<italic><sub>z</sub></italic>S<italic><sub>t</sub></italic></td>
          <td align="left" valign="top" rowspan="1" colspan="1"><italic>v</italic><sub>1...<italic>n</italic></sub>,
<italic>a<sub>U</sub></italic>, <italic>T<sub>er</sub></italic>,
<italic>a</italic>′, <italic>S<sub>v</sub></italic>,
<italic>S<sub>z</sub></italic>,
<italic>S<sub>t</sub></italic></td>
          <td align="left" valign="top" rowspan="1" colspan="1"><italic>n</italic> + 6</td>
        </tr>
        <tr>
          <td align="left" valign="top" colspan="2" rowspan="1">
            <bold>Linear urgency diffusion
decision model (uDDM)</bold>
          </td>
          <td align="left" valign="top" rowspan="1" colspan="1"/>
        </tr>
        <tr>
          <td align="left" valign="top" colspan="2" rowspan="1">References: <xref rid="R23" ref-type="bibr">Ditterich (2006a)</xref>, <xref rid="R58" ref-type="bibr">O’Connell et al. (2018b)</xref></td>
          <td align="left" valign="top" rowspan="1" colspan="1"/>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1"> uDDM</td>
          <td align="left" valign="top" rowspan="1" colspan="1"><italic>v</italic><sub>1...<italic>n</italic></sub>,
<italic>a<sub>U</sub></italic>, <italic>T<sub>er</sub></italic>,
<italic>b</italic>, <italic>m</italic></td>
          <td align="left" valign="top" rowspan="1" colspan="1"><italic>n</italic> + 4</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1"> uDDMS<italic><sub>v</sub></italic></td>
          <td align="left" valign="top" rowspan="1" colspan="1"><italic>v</italic><sub>1...<italic>n</italic></sub>,
<italic>a<sub>U</sub></italic>, <italic>T<sub>er</sub></italic>,
<italic>b</italic>, <italic>m</italic>,
<italic>S<sub>v</sub></italic></td>
          <td align="left" valign="top" rowspan="1" colspan="1"><italic>n</italic> + 5</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1"> uDDMS<italic><sub>t</sub></italic></td>
          <td align="left" valign="top" rowspan="1" colspan="1"><italic>v</italic><sub>1...<italic>n</italic></sub>,
<italic>a<sub>U</sub></italic>, <italic>T<sub>er</sub></italic>,
<italic>b</italic>, <italic>m</italic>,
<italic>S<sub>t</sub></italic></td>
          <td align="left" valign="top" rowspan="1" colspan="1"><italic>n</italic> + 5</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1"> uDDMS<italic><sub>v</sub></italic>S<italic><sub>t</sub></italic></td>
          <td align="left" valign="top" rowspan="1" colspan="1"><italic>v</italic><sub>1...<italic>n</italic></sub>,
<italic>a<sub>U</sub></italic>, <italic>T<sub>er</sub></italic>,
<italic>b</italic>, <italic>m</italic>,
<italic>S<sub>v</sub></italic>, <italic>S<sub>t</sub></italic></td>
          <td align="left" valign="top" rowspan="1" colspan="1"><italic>n</italic> + 6</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1"> uDDMS<italic><sub>v</sub></italic>S<italic><sub>b</sub></italic></td>
          <td align="left" valign="top" rowspan="1" colspan="1"><italic>v</italic><sub>1...<italic>n</italic></sub>,
<italic>a<sub>U</sub></italic>, <italic>T<sub>er</sub></italic>,
<italic>b</italic>, <italic>m</italic>,
<italic>S<sub>v</sub></italic>, <italic>S<sub>b</sub></italic></td>
          <td align="left" valign="top" rowspan="1" colspan="1"><italic>n</italic> + 6</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1"> uDDMS<italic><sub>v</sub></italic>S<italic><sub>b</sub></italic>S<italic><sub>t</sub></italic></td>
          <td align="left" valign="top" rowspan="1" colspan="1"><italic>v</italic><sub>1...<italic>n</italic></sub>,
<italic>a<sub>U</sub></italic>, <italic>T<sub>er</sub></italic>,
<italic>b</italic>, <italic>m</italic>,
<italic>S<sub>v</sub></italic>, <italic>S<sub>b</sub></italic>,
<italic>S<sub>t</sub></italic></td>
          <td align="left" valign="top" rowspan="1" colspan="1"><italic>n</italic> + 7</td>
        </tr>
        <tr>
          <td align="left" valign="top" colspan="2" rowspan="1">
            <bold>Ditterich urgency diffusion
decision model (dDDM)</bold>
          </td>
          <td align="left" valign="top" rowspan="1" colspan="1"/>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1">References: <xref rid="R23" ref-type="bibr">Ditterich (2006a)</xref></td>
          <td align="left" valign="top" rowspan="1" colspan="1"/>
          <td align="left" valign="top" rowspan="1" colspan="1"/>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1"> dDDM</td>
          <td align="left" valign="top" rowspan="1" colspan="1"><italic>v</italic><sub>1...<italic>n</italic></sub>,
<italic>a<sub>U</sub></italic>, <italic>T<sub>er</sub></italic>,
<italic>s<sub>x</sub></italic>, <italic>s<sub>y</sub></italic>,
<italic>d</italic></td>
          <td align="left" valign="top" rowspan="1" colspan="1"><italic>n</italic> + 5</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1"> dDDMS<italic><sub>v</sub></italic></td>
          <td align="left" valign="top" rowspan="1" colspan="1"><italic>v</italic><sub>1...<italic>n</italic></sub>,
<italic>a<sub>U</sub></italic>, <italic>T<sub>er</sub></italic>,
<italic>s<sub>x</sub></italic>, <italic>s<sub>y</sub></italic>,
<italic>d</italic>, <italic>S<sub>v</sub></italic></td>
          <td align="left" valign="top" rowspan="1" colspan="1"><italic>n</italic> + 6</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1"> dDDMS<italic><sub>t</sub></italic></td>
          <td align="left" valign="top" rowspan="1" colspan="1"><italic>v</italic><sub>1...<italic>n</italic></sub>,
<italic>a<sub>U</sub></italic>, <italic>T<sub>er</sub></italic>,
<italic>s<sub>x</sub></italic>, <italic>s<sub>y</sub></italic>,
<italic>d</italic>, <italic>S<sub>t</sub></italic></td>
          <td align="left" valign="top" rowspan="1" colspan="1"><italic>n</italic> + 6</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1"> dDDMS<italic><sub>v</sub></italic>S<italic><sub>t</sub></italic></td>
          <td align="left" valign="top" rowspan="1" colspan="1"><italic>v</italic><sub>1...<italic>n</italic></sub>,
<italic>a<sub>U</sub></italic>, <italic>T<sub>er</sub></italic>,
<italic>s<sub>x</sub></italic>, <italic>s<sub>y</sub></italic>,
<italic>d</italic>, <italic>S<sub>v</sub></italic>,
<italic>S<sub>t</sub></italic></td>
          <td align="left" valign="top" rowspan="1" colspan="1"><italic>n</italic> + 7</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1"> dDDMS<italic><sub>v</sub></italic>S<italic><sub>z</sub></italic>S<italic><sub>t</sub></italic></td>
          <td align="left" valign="top" rowspan="1" colspan="1"><italic>v</italic><sub>1...<italic>n</italic></sub>,
<italic>a<sub>U</sub></italic>, <italic>T<sub>er</sub></italic>,
<italic>s<sub>x</sub></italic>, <italic>s<sub>y</sub></italic>,
<italic>d</italic>, <italic>S<sub>v</sub></italic>,
<italic>S<sub>z</sub></italic>,
<italic>S<sub>t</sub></italic></td>
          <td align="left" valign="top" rowspan="1" colspan="1"><italic>n</italic> + 8</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1">
            <bold>Urgency gating model (UGM)</bold>
          </td>
          <td align="left" valign="top" rowspan="1" colspan="1"/>
          <td align="left" valign="top" rowspan="1" colspan="1"/>
        </tr>
        <tr>
          <td align="left" valign="top" colspan="3" rowspan="1">References: <xref rid="R18" ref-type="bibr">Cisek et al. (2009)</xref>, <xref rid="R86" ref-type="bibr">Thura et al. (2012)</xref><xref rid="R18" ref-type="bibr">Cisek et al., 2009</xref><xref rid="R18" ref-type="bibr">Cisek et al. (2009)</xref>, <xref rid="R86" ref-type="bibr">Thura et al. (2012)</xref></td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1"> UGM</td>
          <td align="left" valign="top" rowspan="1" colspan="1"><italic>v</italic><sub>1...<italic>n</italic></sub>,
<italic>a<sub>U</sub></italic>,
<italic>T<sub>er</sub></italic></td>
          <td align="left" valign="top" rowspan="1" colspan="1"><italic>n</italic> + 2</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1"> UGMS<italic><sub>v</sub></italic></td>
          <td align="left" valign="top" rowspan="1" colspan="1"><italic>v</italic><sub>1...<italic>n</italic></sub>,
<italic>a<sub>U</sub></italic>, <italic>T<sub>er</sub></italic>,
<italic>S<sub>v</sub></italic></td>
          <td align="left" valign="top" rowspan="1" colspan="1"><italic>n</italic> + 3</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1"> UGMS<italic><sub>t</sub></italic></td>
          <td align="left" valign="top" rowspan="1" colspan="1"><italic>v</italic><sub>1...<italic>n</italic></sub>,
<italic>a<sub>U</sub></italic>, <italic>T<sub>er</sub></italic>,
<italic>S<sub>t</sub></italic></td>
          <td align="left" valign="top" rowspan="1" colspan="1"><italic>n</italic> + 3</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1"> UGMS<italic><sub>v</sub></italic>S<italic><sub>t</sub></italic></td>
          <td align="left" valign="top" rowspan="1" colspan="1"><italic>v</italic><sub>1...<italic>n</italic></sub>,
<italic>a<sub>U</sub></italic>, <italic>T<sub>er</sub></italic>,
<italic>S<sub>v</sub></italic>,
<italic>S<sub>t</sub></italic></td>
          <td align="left" valign="top" rowspan="1" colspan="1"><italic>n</italic> + 4</td>
        </tr>
        <tr>
          <td align="left" valign="top" colspan="2" rowspan="1">
            <bold>Urgency gating model with
intercept (bUGM)</bold>
          </td>
          <td align="left" valign="top" rowspan="1" colspan="1"/>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1">(<xref rid="R14" ref-type="bibr">Chandrasekaran et al., 2017</xref>)</td>
          <td align="left" valign="top" rowspan="1" colspan="1"/>
          <td align="left" valign="top" rowspan="1" colspan="1"/>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1"> bUGM</td>
          <td align="left" valign="top" rowspan="1" colspan="1"><italic>v</italic><sub>1...<italic>n</italic></sub>,
<italic>a<sub>U</sub></italic>, <italic>T<sub>er</sub></italic>,
<italic>b</italic></td>
          <td align="left" valign="top" rowspan="1" colspan="1"><italic>n</italic> + 3</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1"> bUGMS<italic><sub>v</sub></italic></td>
          <td align="left" valign="top" rowspan="1" colspan="1"><italic>v</italic><sub>1...<italic>n</italic></sub>,
<italic>a<sub>U</sub></italic>, <italic>T<sub>er</sub></italic>,
<italic>b</italic>, <italic>S<sub>v</sub></italic></td>
          <td align="left" valign="top" rowspan="1" colspan="1"><italic>n</italic> + 4</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1"> bUGMS<italic><sub>v</sub></italic>S<italic><sub>t</sub></italic></td>
          <td align="left" valign="top" rowspan="1" colspan="1"><italic>v</italic><sub>1...<italic>n</italic></sub>,
<italic>a<sub>U</sub></italic>, <italic>T<sub>er</sub></italic>,
<italic>b</italic>, <italic>S<sub>v</sub></italic>,
<italic>S<sub>t</sub></italic></td>
          <td align="left" valign="top" rowspan="1" colspan="1"><italic>n</italic> + 5</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1"> bUGMS<italic><sub>v</sub></italic>S<italic><sub>b</sub></italic></td>
          <td align="left" valign="top" rowspan="1" colspan="1"><italic>v</italic><sub>1...<italic>n</italic></sub>,
<italic>a<sub>U</sub></italic>, <italic>T<sub>er</sub></italic>,
<italic>b</italic>, <italic>S<sub>v</sub></italic>,
<italic>S<sub>b</sub></italic></td>
          <td align="left" valign="top" rowspan="1" colspan="1"><italic>n</italic> + 5</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1"> bUGMS<italic><sub>v</sub></italic>S<italic><sub>b</sub></italic>S<italic><sub>t</sub></italic></td>
          <td align="left" valign="top" rowspan="1" colspan="1"><italic>v</italic><sub>1...<italic>n</italic></sub>,
<italic>a<sub>U</sub></italic>, <italic>T<sub>er</sub></italic>,
<italic>b</italic>, <italic>S<sub>v</sub></italic>,
<italic>S<sub>b</sub></italic>,
<italic>S<sub>t</sub></italic></td>
          <td align="left" valign="top" rowspan="1" colspan="1"><italic>n</italic> + 6</td>
        </tr>
      </tbody>
    </table>
  </table-wrap>
</floats-group>
