<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id>
    <journal-id journal-id-type="publisher-id">bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1367-4803</issn>
    <issn pub-type="epub">1367-4811</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">10311349</article-id>
    <article-id pub-id-type="pmid">37387127</article-id>
    <article-id pub-id-type="doi">10.1093/bioinformatics/btad266</article-id>
    <article-id pub-id-type="publisher-id">btad266</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Regulatory and Functional Genomics</subject>
      </subj-group>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI01060</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Reference panel-guided super-resolution inference of Hi-C data</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Zhang</surname>
          <given-names>Yanlin</given-names>
        </name>
        <aff><institution>School of Computer Science, McGill University, Montréal</institution>, Québec H3A 0E9, <country country="CA">Canada</country></aff>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Blanchette</surname>
          <given-names>Mathieu</given-names>
        </name>
        <aff><institution>School of Computer Science, McGill University, Montréal</institution>, Québec H3A 0E9, <country country="CA">Canada</country></aff>
        <xref rid="btad266-cor1" ref-type="corresp"/>
        <!--blanchem@cs.mcgill.ca-->
      </contrib>
    </contrib-group>
    <author-notes>
      <corresp id="btad266-cor1">Corresponding author. School of Computer Science, McGill University, Montréal, Québec H3A 0E9, Canada. E-mail: <email>blanchem@cs.mcgill.ca</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <month>6</month>
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2023-06-30">
      <day>30</day>
      <month>6</month>
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>30</day>
      <month>6</month>
      <year>2023</year>
    </pub-date>
    <volume>39</volume>
    <issue>Suppl 1</issue>
    <issue-title>ISMB/ECCB 2023 Proceedings</issue-title>
    <fpage>i386</fpage>
    <lpage>i393</lpage>
    <permissions>
      <copyright-statement>© The Author(s) 2023. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2023</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="btad266.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Motivation</title>
        <p>Accurately assessing contacts between DNA fragments inside the nucleus with Hi-C experiment is crucial for understanding the role of 3D genome organization in gene regulation. This challenging task is due in part to the high sequencing depth of Hi-C libraries required to support high-resolution analyses. Most existing Hi-C data are collected with limited sequencing coverage, leading to poor chromatin interaction frequency estimation. Current computational approaches to enhance Hi-C signals focus on the analysis of individual Hi-C datasets of interest, without taking advantage of the facts that (i) several hundred Hi-C contact maps are publicly available and (ii) the vast majority of local spatial organizations are conserved across multiple cell types.</p>
      </sec>
      <sec id="s2">
        <title>Results</title>
        <p>Here, we present RefHiC-SR, an attention-based deep learning framework that uses a reference panel of Hi-C datasets to facilitate the enhancement of Hi-C data resolution of a given study sample. We compare RefHiC-SR against tools that do not use reference samples and find that RefHiC-SR outperforms other programs across different cell types, and sequencing depths. It also enables high-accuracy mapping of structures such as loops and topologically associating domains.</p>
      </sec>
      <sec id="s3">
        <title>Availability and implementation</title>
        <p><ext-link xlink:href="https://github.com/BlanchetteLab/RefHiC" ext-link-type="uri">https://github.com/BlanchetteLab/RefHiC</ext-link>.</p>
      </sec>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Genome Quebec</institution>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Canada and Genome Quebec</institution>
          </institution-wrap>
        </funding-source>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="8"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 Introduction</title>
    <p>Technologies such as Hi-C (<xref rid="btad266-B11" ref-type="bibr">Lieberman-Aiden et al. 2009</xref>), and micro-C (<xref rid="btad266-B9" ref-type="bibr">Krietenstein et al. 2020</xref>) capture spatial contacts between DNA fragments in genomes, enabling the inference of various aspects of 3D genome organization. These approaches have revealed a hierarchical spatial organization of topological structures of the genome inside nuclei and spatial patterns such as topologically associating domains (TADs), loops, and compartments. These structures are of vital importance to gene regulation and are dynamic within cells (<xref rid="btad266-B22" ref-type="bibr">Sanborn et al. 2015</xref>). Identifying these spatial patterns, especially at high resolution, requires the availability of high-coverage Hi-C sequencing data. The investigation of fine-scale structures would even require ultrahigh-coverage contact maps (<xref rid="btad266-B9" ref-type="bibr">Krietenstein et al. 2020</xref>).</p>
    <p>While Hi-C and its variants remain the most popular approaches to map chromatin contacts on a genome-wide scale, the analysis of the data they produce is challenging, in large part due to the moderate sequencing depth (typically 200–500 Million valid read pairs) compared with the size of the contact frequency matrices that need to be estimated. The majority of TAD and loop annotation tools are primarily optimized for high-coverage data and may not provide satisfactory results when applied to typical low- to medium-coverage data, though tools like Grinch (<xref rid="btad266-B10" ref-type="bibr">Lee and Roy 2021</xref>) have been proposed to analyze low-coverage data. To close the gap, many efforts have been undertaken to perform <italic toggle="yes">in silico</italic> enhancement of Hi-C contact maps (<xref rid="btad266-B28" ref-type="bibr">Zhang et al. 2018</xref>; <xref rid="btad266-B14" ref-type="bibr">Liu and Wang 2019</xref>; <xref rid="btad266-B13" ref-type="bibr">Liu et al. 2019</xref>; <xref rid="btad266-B3" ref-type="bibr">Cameron et al. 2020</xref>). Given a low-coverage Hi-C dataset, contact map enhancement tools seek to predict a dense, high-resolution version of the contact map aiming to reproduce the map that would be obtained through very deep coverage sequencing of the same library. Super-resolution enhancement could in theory enable high-resolution analysis of low-coverage Hi-C data, e.g. through the application of third-party analysis tools to enhanced maps.</p>
    <p>Most existing contact map enhancement tools are deep learning (DL) approaches and are inspired by super-resolution algorithms in image processing. As a high-resolution (5 kb per bin) contact map for a single human chromosome contains 10 000–50 000 bins, existing applications usually split contact maps into nonoverlapping blocks and enhance each block iteratively. HiCPlus (<xref rid="btad266-B28" ref-type="bibr">Zhang et al. 2018</xref>) was the first DL-based tool proposed for this type of tasks. It is a convolutional neural network (CNN) that contains one hidden layer and is trained from low- and high-coverage contact map pairs (respectively the input and target values) by minimizing the mean square error (MSE) loss. Later, <xref rid="btad266-B14" ref-type="bibr">Liu and Wang (2019)</xref> proposed a deeper CNN with residual connections—HiCNN and trained it following the strategy used in HiCPlus. Similar to super-resolution analysis in computer vision, the MSE loss leads both models to produce blurry predictions (<xref rid="btad266-B13" ref-type="bibr">Liu et al. 2019</xref>). To alleviate the issue of over-smoothness, more recent approaches utilize generative adversarial (GAN) frameworks in model training. For example, HiCGAN (<xref rid="btad266-B13" ref-type="bibr">Liu et al. 2019</xref>) is a CNN built upon a generator containing five residual blocks and a discriminator containing three residual blocks. The generator is trained to produce enhanced contact maps from downsampled contact maps, and the discriminator is trained to distinguish high-coverage contact maps from enhanced contact maps. Liu et al. trained HiCGAN with GAN loss and used the generator for prediction. DeepHiC (<xref rid="btad266-B7" ref-type="bibr">Hong et al. 2019</xref>) furthers model performance by introducing additional terms to the loss function (i.e. MSE, perceptual loss, and total variance) into training. In contrast, conventional tools (<xref rid="btad266-B29" ref-type="bibr">Zhou et al. 2019</xref>; <xref rid="btad266-B3" ref-type="bibr">Cameron et al. 2020</xref>) usually treat contact map enhancement as imputation. They enhance Hi-C signals by fitting a Markov Random Field or performing random walk on a Hi-C graph.</p>
    <p>Although DL models have achieved significant successes in contact map enhancement, there is still room for improvement, particularly in the enhancement of very low-coverage contact maps. First, most existing tools are trained on data containing 250 M valid read pairs [typically a 16-fold downsampled version of a very high-coverage Hi-C dataset produced for human GM12878 cells data by <xref rid="btad266-B19" ref-type="bibr">Rao et al. (2014)</xref>], and can only be effectively used to enhance contact maps containing 200–300 M valid read pairs. In addition, similar to super-resolution analysis in computer vision, contact map enhancement is an ill-posed problem as a single low-coverage contact map may correspond to multiple potential high-coverage contact maps. While existing tools can infer high-fidelity predictions, these may not necessarily be correct predictions, especially in sparse regions, potentially leading to false positives in downstream annotation tasks.</p>
    <p>To address the issue of ill-posedness in single-image super-resolution, computer vision researchers have introduced additional images to assist with the prediction task. For example, some studies have created databases of image patches and used them to improve prediction accuracy (<xref rid="btad266-B25" ref-type="bibr">Yan et al. 2020</xref>; <xref rid="btad266-B24" ref-type="bibr">Xia et al. 2022</xref>). In recent years, incorporating external data have become a popular research direction and have been shown to lead to better models with fewer parameters (<xref rid="btad266-B2" ref-type="bibr">Borgeaud et al. 2021</xref>). Within Hi-C data analysis, our recent approach—RefHiC (<xref rid="btad266-B27" ref-type="bibr">Zhang and Blanchette 2022</xref>) achieves superior performance in annotating topological structures (loops and TADs) from a study sample while using a reference panel of other Hi-C datasets as complement. In reference-based image super-resolution, the reference database is assumed to contain a diverse set of images, regardless of their relationship to the test image. In 3D genome analysis, the conformation of a small region in one cell type may be observed in another cell types (<xref rid="btad266-B27" ref-type="bibr">Zhang and Blanchette 2022</xref>). Therefore, to improve the resolution of a small region of a Hi-C contact map, we use contact maps of the same region as a reference.</p>
    <p>Here, we introduce RefHiC-SR, a model for enhancing Hi-C contact maps. While RefHiC (<xref rid="btad266-B27" ref-type="bibr">Zhang and Blanchette 2022</xref>), our model for topological structure annotation, is limited in its ability to learn features from large patches required in a super-resolution task, RefHiC-SR overcomes these limitations by redesigning the encoder as a modified U-net architecture (<xref rid="btad266-B21" ref-type="bibr">Ronneberger et al. 2015</xref>), and introducing a multiscale attention mechanism. This novel model allows RefHiC-SR to handle large patches in Hi-C matrices while still benefiting from a reference panel.</p>
  </sec>
  <sec>
    <title>2 Materials and methods</title>
    <sec>
      <title>2.1 RefHiC-SR model architecture</title>
      <p>The RefHiC-SR network follows the U-net architecture (<xref rid="btad266-B21" ref-type="bibr">Ronneberger et al. 2015</xref>; <xref rid="btad266-F1" ref-type="fig">Fig. 1</xref>), originally introduced for image segmentation, to enhance the expressiveness of latent features produced by encoding blocks and enable effective handling of large patches (i.e. 200 × 200). It contains (i) a low-level feature extraction block (F) that transforms a Hi-C matrix to multichannel features, (ii) an output block (O) that transforms multi-channel features to an enhanced Hi-C matrix, (iii) multiscale encoding blocks (E1, E2, and E3) that transform low-level features to high-level features at different scales (i.e. keys, values, and query in attention <xref rid="E1" ref-type="disp-formula">Equations 1</xref> and <xref rid="E2" ref-type="disp-formula">2</xref>), (iv) multiscale decoding blocks (D1 and D2) that transform features at different scales, and (v) attention convolutional blocks (A1 and A2) and projecting layers (P1 and P2) that increasing the model complexity and reduces hidden feature dimensions. To inject information from reference samples into the U-net computation graph, in the forward pass, blocks F and E1–E3 compute multiscale embeddings for the study sample and for the <italic toggle="yes">n</italic> reference samples. We denote parts of these embeddings as V1 and V2 (values), K (keys), and Q (query). We then compute combined multiscale representations of all reference samples from these embeddings with an attention mechanism. Finally, we replace skip connections in U-net (<xref rid="btad266-B21" ref-type="bibr">Ronneberger et al. 2015</xref>) with a concatenation of the study sample’s embedding and a transformed attention output at the same scale.</p>
      <fig position="float" id="btad266-F1">
        <label>Figure 1.</label>
        <caption>
          <p>RefHiC-SR architecture. Overview of the RefHiC-SR neural network for enhancing Hi-C contact maps.</p>
        </caption>
        <graphic xlink:href="btad266f1" position="float"/>
      </fig>
      <p>F takes an input of dimension <italic toggle="yes">w</italic> × <italic toggle="yes">w</italic>, where <italic toggle="yes">w</italic> is the window size (<inline-formula id="IE1"><mml:math id="IM1" display="inline" overflow="scroll"><mml:mrow><mml:mi>w</mml:mi><mml:mo>=</mml:mo><mml:mn>200</mml:mn></mml:mrow></mml:math></inline-formula> at 5 kb resolution) and projects the input to a <inline-formula id="IE2"><mml:math id="IM2" display="inline" overflow="scroll"><mml:mrow><mml:mi>w</mml:mi><mml:mo>×</mml:mo><mml:mi>w</mml:mi><mml:mo>×</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:math></inline-formula> embedding (<inline-formula id="IE3"><mml:math id="IM3" display="inline" overflow="scroll"><mml:mrow><mml:mi>d</mml:mi><mml:mo>=</mml:mo><mml:mn>24</mml:mn></mml:mrow></mml:math></inline-formula>). It is built with one rectified linear unit activated (ReLU-activated) convolution layer with <italic toggle="yes">d</italic> 9 × 9 filters. E1, E2, and E3 are three consecutive encoding blocks linked by a max pooling operator with a 2 × 2 kernel and a stride of 2 (i.e. downsampling by 50%). E1, E2, and E3 extract multi-scale features from the input contact maps. E1 is built with two ReLU-activated convolution layers with <italic toggle="yes">d</italic> 3 × 3 filters and a dropout layer with rate = 0.2 between convolution layers. It takes an input of dimension <inline-formula id="IE4"><mml:math id="IM4" display="inline" overflow="scroll"><mml:mrow><mml:mi>w</mml:mi><mml:mo>×</mml:mo><mml:mi>w</mml:mi><mml:mo>×</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:math></inline-formula> and produces an output of the same dimension. E2 is built with the same layers as E1, but it takes an input of dimension <italic toggle="yes">w</italic>/2 × <italic toggle="yes">w</italic>/2 × <italic toggle="yes">d</italic> and produces an output of the same dimension. E3 starts with a batch normalization layer and ends with a flatten layer. It contains three convolution layers: The first two contain <italic toggle="yes">d</italic> 3 × 3 filters, and the last contains one 3 × 3 filter. The first convolution layer in E3 is followed by a dropout layer with rate 0.2 and a max pooling operator with a 2 × 2 kernel and a stride of 2. We did not use batch normalization in blocks F, E1, and E2 as we observed it introduces artifacts in enhanced contact maps. E3 takes as input the downsampled output of E2 and produces embedding of dimension 1 × (w/8)<sup>2</sup>. The attention module (i.e. purple module) takes as query (Q) and keys (K) the outputs of E3, uses as values (V1 and V2) the outputs of E1 and E2 for the <italic toggle="yes">n</italic> reference samples. We define the attention weights <inline-formula id="IE5"><mml:math id="IM5" display="inline" overflow="scroll"><mml:mrow><mml:mo>α</mml:mo><mml:mo>=</mml:mo></mml:mrow></mml:math></inline-formula>softmax<inline-formula id="IE6"><mml:math id="IM6" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">Q</mml:mi><mml:msup><mml:mrow><mml:mi mathvariant="bold">K</mml:mi></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>×</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>, where <inline-formula id="IE7"><mml:math id="IM7" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mo>α</mml:mo></mml:mrow><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> represents the relative amount of attention paid to sample <italic toggle="yes">j</italic> in our reference panel when analyzing the study sample. The attention output <inline-formula id="IE8"><mml:math id="IM8" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">a</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE9"><mml:math id="IM9" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">a</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> at two levels are computed as:
where A1 and A2 are convolution blocks for attention outputs configured similarly to E1 and E2 but preceded by layer normalization. P1 and P2 are built with one ReLU-activated convolution layer with one 3 × 3 filter. They project the concatenation of study-sample embeddings (produced by E1 and E2) and attention embeddings (i.e. <inline-formula id="IE10"><mml:math id="IM10" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">a</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE11"><mml:math id="IM11" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">a</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>) to embeddings with <italic toggle="yes">d</italic> channels. D1 and D2 are built similarly to E2 and E1. D1 takes as input the output of P2; meanwhile, D2 takes as input the concatenation of the output of P1 and the upsampled output of D1. O is built with two ReLU-activated convolution layers with 3 <inline-formula id="IE12"><mml:math id="IM12" display="inline" overflow="scroll"><mml:mo>×</mml:mo></mml:math></inline-formula> 3 filters. It projects the concatenation of the output of F for the study sample and the output of D2 to an enhanced contact map.</p>
      <disp-formula id="E1">
        <label>(1)</label>
        <mml:math id="M1" display="block" overflow="scroll">
          <mml:mrow>
            <mml:mtable>
              <mml:mtr columnalign="left">
                <mml:mtd columnalign="left">
                  <mml:mrow>
                    <mml:msub>
                      <mml:mrow>
                        <mml:mi mathvariant="bold">a</mml:mi>
                      </mml:mrow>
                      <mml:mn>1</mml:mn>
                    </mml:msub>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mo>=</mml:mo>
                    <mml:mtext>softmax</mml:mtext>
                    <mml:mo stretchy="false">(</mml:mo>
                    <mml:mi mathvariant="bold">Q</mml:mi>
                    <mml:msup>
                      <mml:mrow>
                        <mml:mi mathvariant="bold">K</mml:mi>
                      </mml:mrow>
                      <mml:mi>T</mml:mi>
                    </mml:msup>
                    <mml:mo stretchy="false">)</mml:mo>
                    <mml:msub>
                      <mml:mrow>
                        <mml:mi mathvariant="bold">V</mml:mi>
                      </mml:mrow>
                      <mml:mn>1</mml:mn>
                    </mml:msub>
                    <mml:mo>+</mml:mo>
                    <mml:mi mathvariant="normal">A</mml:mi>
                    <mml:mn>1</mml:mn>
                    <mml:mo stretchy="false">(</mml:mo>
                    <mml:mtext>softmax</mml:mtext>
                    <mml:mo stretchy="false">(</mml:mo>
                    <mml:mi mathvariant="bold">Q</mml:mi>
                    <mml:msup>
                      <mml:mrow>
                        <mml:mi mathvariant="bold">K</mml:mi>
                      </mml:mrow>
                      <mml:mi>T</mml:mi>
                    </mml:msup>
                    <mml:mo stretchy="false">)</mml:mo>
                    <mml:msub>
                      <mml:mrow>
                        <mml:mi mathvariant="bold">V</mml:mi>
                      </mml:mrow>
                      <mml:mn>1</mml:mn>
                    </mml:msub>
                    <mml:mo stretchy="false">)</mml:mo>
                  </mml:mrow>
                </mml:mtd>
              </mml:mtr>
            </mml:mtable>
          </mml:mrow>
        </mml:math>
      </disp-formula>
      <disp-formula id="E2">
        <label>(2)</label>
        <mml:math id="M2" display="block" overflow="scroll">
          <mml:mrow>
            <mml:msub>
              <mml:mrow>
                <mml:mi mathvariant="bold">a</mml:mi>
              </mml:mrow>
              <mml:mn>2</mml:mn>
            </mml:msub>
            <mml:mo>=</mml:mo>
            <mml:mtext>softmax</mml:mtext>
            <mml:mo stretchy="false">(</mml:mo>
            <mml:mi mathvariant="bold">Q</mml:mi>
            <mml:msup>
              <mml:mrow>
                <mml:mi mathvariant="bold">K</mml:mi>
              </mml:mrow>
              <mml:mi>T</mml:mi>
            </mml:msup>
            <mml:mo stretchy="false">)</mml:mo>
            <mml:msub>
              <mml:mrow>
                <mml:mi mathvariant="bold">V</mml:mi>
              </mml:mrow>
              <mml:mn>2</mml:mn>
            </mml:msub>
            <mml:mo>+</mml:mo>
            <mml:mi mathvariant="normal">A</mml:mi>
            <mml:mn>2</mml:mn>
            <mml:mo stretchy="false">(</mml:mo>
            <mml:mtext>softmax</mml:mtext>
            <mml:mo stretchy="false">(</mml:mo>
            <mml:mi mathvariant="bold">Q</mml:mi>
            <mml:msup>
              <mml:mrow>
                <mml:mi mathvariant="bold">K</mml:mi>
              </mml:mrow>
              <mml:mi>T</mml:mi>
            </mml:msup>
            <mml:mo stretchy="false">)</mml:mo>
            <mml:msub>
              <mml:mrow>
                <mml:mi mathvariant="bold">V</mml:mi>
              </mml:mrow>
              <mml:mn>2</mml:mn>
            </mml:msub>
            <mml:mo stretchy="false">)</mml:mo>
          </mml:mrow>
        </mml:math>
      </disp-formula>
    </sec>
    <sec>
      <title>2.2 Hi-C data and preprocessing</title>
      <p>RefHiC-SR’s input for an individual sample (i.e. study or reference samples) is defined as a matrix in the shape of <italic toggle="yes">w</italic> × <italic toggle="yes">w</italic>, corresponding to the region of interest with a window of size <italic toggle="yes">w</italic>. <italic toggle="yes">w</italic> is a hyperparameter set to <inline-formula id="IE13"><mml:math id="IM13" display="inline" overflow="scroll"><mml:mrow><mml:mi>w</mml:mi><mml:mo>=</mml:mo><mml:mn>200</mml:mn></mml:mrow></mml:math></inline-formula> at 5 kb resolution. We trained RefHiC-SR with ICE-normalized iterative correction and eigenvector decomposition normalized (ICE-normalized) Hi-C contact maps. RefHiC-SR can also take raw data as input, but using raw data directly can lead to worse prediction due to systematic bias. For model training, we used Hi-C data downsampled from the combined GM12878 Hi-C contact map (<xref rid="btad266-B19" ref-type="bibr">Rao et al. 2014</xref>). The length of TADs and the distance between chromatin loop anchors are usually within 3 Mb. Thus, we restricted our analysis to contact pairs separated by at most 3 Mb. For inference of an entire chromosome, we will first split a contact map into partially overlapping squares <inline-formula id="IE14"><mml:math id="IM14" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> with width <italic toggle="yes">w</italic> indicated by top-left corner <inline-formula id="IE15"><mml:math id="IM15" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> and step <inline-formula id="IE16"><mml:math id="IM16" display="inline" overflow="scroll"><mml:mrow><mml:mi>w</mml:mi><mml:mo>−</mml:mo><mml:mn>20</mml:mn></mml:mrow></mml:math></inline-formula>, where <inline-formula id="IE17"><mml:math id="IM17" display="inline" overflow="scroll"><mml:mrow><mml:mi>j</mml:mi><mml:mo>≥</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:math></inline-formula>. We then apply the trained model to enhance each square. The width of the predicted squares is also <italic toggle="yes">w</italic>. Finally, we extract a <inline-formula id="IE18"><mml:math id="IM18" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>w</mml:mi><mml:mo>−</mml:mo><mml:mn>20</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>×</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>w</mml:mi><mml:mo>−</mml:mo><mml:mn>20</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> matrix by trimming each side to address discontinuity between adjacency matrices. The full-chromosome super-resolution contact map is obtained by tiling the super-resolution submatrices.</p>
    </sec>
    <sec>
      <title>2.3 Model training</title>
      <p>We trained, evaluated, and tested RefHiC-SR on contact maps downsampled from the combined GM12878 Hi-C data. We used chr11 and chr12 for validation, Chromosomes 15–17 for testing, and the rest of autosomes for training. After preparing the input data as mentioned above, we collected 6918, 798, and 813 200 × 200 blocks for training, validation, and testing. RefHiC-SR takes submatrices from the study and reference samples as input in the forward pass. To reduce training computation, we sampled 10 reference samples for each example in each epoch independently. During evaluation, we used all samples in the reference panel. We trained models with a batch size of 46 for 2000 epochs on an RTX6000 GPU and used AdamW optimizer (<xref rid="btad266-B15" ref-type="bibr">Loshchilov and Hutter 2017</xref>; weight_decay = 0.1; learning rate = 1<italic toggle="yes">e</italic>−3). We also used early stopping to prevent overfitting. In the first five training epochs, we warmed up the learning rate from 0 to the initial learning rate (i.e. 1<italic toggle="yes">e</italic>−3) and then reduced the learning rate to 1<italic toggle="yes">e</italic>−6 in the first 95% epochs using the cosine annealing learning rate scheduler. Following RefHiC (<xref rid="btad266-B27" ref-type="bibr">Zhang and Blanchette 2022</xref>), we performed data augmentation by downsampling Hi-C contact maps during training. This transformation preserves topological structures in Hi-C data. Briefly, we downsampled Hi-C training data and stored them on disk in advance. During training, we randomly selected one contact map from these downsampled contact maps for each training example in each epoch independently. We used L1 loss to train RefHiC-SR. It is simple and less prone to be over-smooth.</p>
    </sec>
    <sec>
      <title>2.4 Contrastive pretraining</title>
      <p>We pretrained low-level feature extraction block (F) and encoding blocks (E1–E3) by supervised contrastive learning (<xref rid="btad266-B6" ref-type="bibr">Gao et al. 2021</xref>) using Hi-C contact maps downsampled from the combined GM12878 Hi-C data. For each training example, we defined items extracted from the downsampled contact maps at the same region as similar items and all Hi-C contact map submatrices in the same batch at other regions as negative items. We aimed to train these layers such that the distances of embeddings produced by E3 for a training example and its similar items are as close as possible while of embeddings between a training example and its negative items are as far as possible. Following (<xref rid="btad266-B6" ref-type="bibr">Gao et al. 2021</xref>), we defined the loss for training instance <italic toggle="yes">i</italic> as cross-entropy with in-batch negatives:
where <inline-formula id="IE19"><mml:math id="IM19" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">h</mml:mi></mml:mrow><mml:mi mathvariant="bold">i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, <inline-formula id="IE20"><mml:math id="IM20" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">h</mml:mi></mml:mrow><mml:mi mathvariant="bold">i</mml:mi><mml:mo>+</mml:mo></mml:msubsup></mml:mrow></mml:math></inline-formula>, and <inline-formula id="IE21"><mml:math id="IM21" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">h</mml:mi></mml:mrow><mml:mi mathvariant="bold">j</mml:mi><mml:mo>−</mml:mo></mml:msubsup></mml:mrow></mml:math></inline-formula> are embeddings: <inline-formula id="IE22"><mml:math id="IM22" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">h</mml:mi></mml:mrow><mml:mi mathvariant="bold">i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> represents item <italic toggle="yes">i</italic>, <inline-formula id="IE23"><mml:math id="IM23" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">h</mml:mi></mml:mrow><mml:mi mathvariant="bold">i</mml:mi><mml:mo>+</mml:mo></mml:msubsup></mml:mrow></mml:math></inline-formula> represents one of item <italic toggle="yes">i’</italic>s similar items, <inline-formula id="IE24"><mml:math id="IM24" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">h</mml:mi></mml:mrow><mml:mi mathvariant="bold">j</mml:mi><mml:mo>−</mml:mo></mml:msubsup></mml:mrow></mml:math></inline-formula> represents an item with a label different from <italic toggle="yes">i</italic> (i.e. negative item). <inline-formula id="IE25"><mml:math id="IM25" display="inline" overflow="scroll"><mml:mo>τ</mml:mo></mml:math></inline-formula> is a temperature that controls training, and we set it as 1. We pretrained the encoder for 20 epochs with the LARS using Adam as a base optimizer. We set batch size to 46 and learning rate to 1<italic toggle="yes">e</italic>−3 during training.</p>
      <disp-formula id="E3">
        <label>(3)</label>
        <mml:math id="M3" display="block" overflow="scroll">
          <mml:mrow>
            <mml:msub>
              <mml:mrow>
                <mml:mi>l</mml:mi>
              </mml:mrow>
              <mml:mi>i</mml:mi>
            </mml:msub>
            <mml:mo>=</mml:mo>
            <mml:mo>−</mml:mo>
            <mml:mtext>log</mml:mtext>
            <mml:mo> </mml:mo>
            <mml:mfrac>
              <mml:mrow>
                <mml:msup>
                  <mml:mrow>
                    <mml:mi>e</mml:mi>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mtext>sim</mml:mtext>
                    <mml:mo stretchy="false">(</mml:mo>
                    <mml:msub>
                      <mml:mrow>
                        <mml:mi mathvariant="bold">h</mml:mi>
                      </mml:mrow>
                      <mml:mi mathvariant="bold">i</mml:mi>
                    </mml:msub>
                    <mml:mo>,</mml:mo>
                    <mml:msubsup>
                      <mml:mrow>
                        <mml:mi mathvariant="bold">h</mml:mi>
                      </mml:mrow>
                      <mml:mi mathvariant="bold">i</mml:mi>
                      <mml:mo>+</mml:mo>
                    </mml:msubsup>
                    <mml:mo stretchy="false">)</mml:mo>
                    <mml:mo>/</mml:mo>
                    <mml:mo>τ</mml:mo>
                  </mml:mrow>
                </mml:msup>
              </mml:mrow>
              <mml:mrow>
                <mml:msup>
                  <mml:mrow>
                    <mml:mi>e</mml:mi>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mtext>sim</mml:mtext>
                    <mml:mo stretchy="false">(</mml:mo>
                    <mml:msub>
                      <mml:mrow>
                        <mml:mi mathvariant="bold">h</mml:mi>
                      </mml:mrow>
                      <mml:mi mathvariant="bold">i</mml:mi>
                    </mml:msub>
                    <mml:mo>,</mml:mo>
                    <mml:msubsup>
                      <mml:mrow>
                        <mml:mi mathvariant="bold">h</mml:mi>
                      </mml:mrow>
                      <mml:mi mathvariant="bold">i</mml:mi>
                      <mml:mo>+</mml:mo>
                    </mml:msubsup>
                    <mml:mo stretchy="false">)</mml:mo>
                    <mml:mo>/</mml:mo>
                    <mml:mo>τ</mml:mo>
                  </mml:mrow>
                </mml:msup>
                <mml:mo>+</mml:mo>
                <mml:munder>
                  <mml:mo>∑</mml:mo>
                  <mml:mrow>
                    <mml:mi>j</mml:mi>
                    <mml:menclose notation="updiagonalstrike">
                      <mml:mo>=</mml:mo>
                    </mml:menclose>
                    <mml:mi>i</mml:mi>
                  </mml:mrow>
                </mml:munder>
                <mml:mrow>
                  <mml:msup>
                    <mml:mrow>
                      <mml:mi>e</mml:mi>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mtext>sim</mml:mtext>
                      <mml:mo stretchy="false">(</mml:mo>
                      <mml:msub>
                        <mml:mrow>
                          <mml:mi mathvariant="bold">h</mml:mi>
                        </mml:mrow>
                        <mml:mi mathvariant="bold">i</mml:mi>
                      </mml:msub>
                      <mml:mo>,</mml:mo>
                      <mml:msubsup>
                        <mml:mrow>
                          <mml:mi mathvariant="bold">h</mml:mi>
                        </mml:mrow>
                        <mml:mi mathvariant="bold">j</mml:mi>
                        <mml:mo>−</mml:mo>
                      </mml:msubsup>
                      <mml:mo stretchy="false">)</mml:mo>
                      <mml:mo>/</mml:mo>
                      <mml:mo>τ</mml:mo>
                    </mml:mrow>
                  </mml:msup>
                </mml:mrow>
              </mml:mrow>
            </mml:mfrac>
          </mml:mrow>
        </mml:math>
      </disp-formula>
    </sec>
    <sec>
      <title>2.5 Evaluation metrics</title>
      <p>We extensively compared the performance of RefHiC-SR with alternative tools using different metrics, including MSE, mean absolute error (MAE, a.k.a. L1), Pearson correlation coefficient (PCC), Spearman rank correlation coefficient (SRCC), and widely used metric in super-resolution image analysis, including structural similarity index measure (SSIM) score, and peak signal to noise ratio (PSNR) score (<xref rid="btad266-B7" ref-type="bibr">Hong et al. 2019</xref>) for each of the 200 × 200 submatrix predicted by each tool.</p>
      <p>We compared super-resolution to high-resolution Hi-C contact maps with HiCRep (<xref rid="btad266-B12" ref-type="bibr">Lin et al. 2021</xref>). HiCRep measures the reproducibility of two Hi-C experiments by computing a stratified correlation coefficient (PCC) for two contact maps. Its score ranges from −1 to 1 where a high value indicates high reproducibility. In addition to using PCC to compute HiCRep scores, we also computed HiCRep scores with SRCC.</p>
    </sec>
    <sec>
      <title>2.6 Hi-C data downsampling and Hi-C reference panel</title>
      <p>We used the original and six-level downsampled data of the combined Hi-C contact map for GM12878 cells obtained from <xref rid="btad266-B19" ref-type="bibr">Rao et al. (2014)</xref> to train RefHiC-SR. The reference panel that contains 30 human Hi-C contact map are used to train and evaluate RefHiC-SR. We excluded samples that belong to the study sample’s cell type from the reference panel to prevent potential data leakage.</p>
    </sec>
    <sec>
      <title>2.7 Hyperparameter tuning</title>
      <p>We first evaluate the performance of different convolution blocks in RefHiC-SR by adjusting convolution layer numbers in each block and adding residual connections. We configured most blocks with two convolution layers. Following (<xref rid="btad266-B28" ref-type="bibr">Zhang et al. 2018</xref>; <xref rid="btad266-B7" ref-type="bibr">Hong et al. 2019</xref>), we used 3 × 3 filters in all internal convolution layers, but tested different filter sizes (i.e. 3 × 3, 5 × 5, 9 × 9, and 13 × 13) for the first and last convolution layers. We compared validation errors and determined the optimal filter size as 9 × 9 for both layers. We also compared RefHiC-SR trained with MSE and L1 loss. We observed the model trained with MSE loss overly smooth predictions.</p>
    </sec>
    <sec>
      <title>2.8 Contact map enhancement with alternative tools</title>
      <p>We re-trained HiCPlus, HiCCNN, and DeepHiC with the same data as we used to train RefHiC-SR. Following previous work (<xref rid="btad266-B28" ref-type="bibr">Zhang et al. 2018</xref>; <xref rid="btad266-B7" ref-type="bibr">Hong et al. 2019</xref>; <xref rid="btad266-B14" ref-type="bibr">Liu and Wang 2019</xref>), we trained each model by splitting Hi-C contact maps into 40 × 40 blocks. To train HiCPlus and HiCNN, we adjusted learning rate and used early stopping to prevent overfitting and set other hyperparameters as default. We trained HiCPlus (<xref rid="btad266-B28" ref-type="bibr">Zhang et al. 2018</xref>) for 30 000 epochs with a learning rate of 1<italic toggle="yes">e</italic>−3 and a batch size of 256. We trained HiCNN (<xref rid="btad266-B14" ref-type="bibr">Liu and Wang 2019</xref>) and DeepHiC (<xref rid="btad266-B7" ref-type="bibr">Hong et al. 2019</xref>) for 1000 epochs with a learning rate of 1<italic toggle="yes">e</italic>−4 and a batch size of 256. The maximum training epochs we used are much larger than their original setting, and training losses indicated all models were converged. DeepHiC’s discriminator is too strong to provide gradients to the generator with its original training procedure in our experiment. We changed the discriminative loss weight to 0.0001 and updated the discriminator every ten epochs. Once trained, we applied each model to 200 × 200 overlapped blocks to enhance a whole contact map. Same as RefHiC-SR, we cropped the prediction into a matrix of 180 × 180.</p>
    </sec>
  </sec>
  <sec>
    <title>3 Results</title>
    <p>We introduce RefHiC-SR, a reference panel-informed DL approach for enhancing Hi-C contact maps. Similar to RefHiC (<xref rid="btad266-B27" ref-type="bibr">Zhang and Blanchette 2022</xref>), it utilizes a reference panel containing 30 high-quality Hi-C datasets from multiple human cell types (<xref rid="sup1" ref-type="supplementary-material">Supplementary Table S1</xref>) and employs an attention mechanism to determine which reference samples are most relevant for a given <italic toggle="yes">w</italic> × <italic toggle="yes">w</italic> region of the contact map of the study sample. The enhanced contact map at a given region is then inferred based on a combination of the study sample and the attention-weighted reference samples. RefHiC-SR takes as input a typical ICE normalized (<xref rid="btad266-B8" ref-type="bibr">Imakaev et al. 2012</xref>; <xref rid="btad266-B1" ref-type="bibr">Abdennur and Mirny 2020</xref>) moderate-coverage (sparse) Hi-C contact map and outputs a high-coverage (dense) contact map prediction. Both input and output contact maps are at high resolution (i.e. 5-kb bins). The resulting prediction is referred to as enhanced or super-resolution contact maps. We divided the human autosomes into a training set (Chromosomes 1–10, 13, 14, and 18–22), a validation set (Chromosomes 11 and 12), and a test set (Chromosomes 15–17). All results reported here pertain only to the three test chromosomes. Although we trained RefHiC-SR on GM12878 cells, the model learned is not cell-type specific. We will demonstrate in a later section that we can use the same model to enhance Hi-C data of other cells.</p>
    <p>RefHiC-SR’s neural network takes as input a matrix of 200 bins by 200 bins, and outputs a super-resolution matrix of the same dimension. When applying a trained model to full-chromosome contact map enhancement, we extract from the output matrix a 180 × 180 matrix by trimming each side to address discontinuity between adjacency matrices. The full-chromosome super-resolution contact map is obtained by tiling the super-resolution submatrices. Other super-resolution tools were applied in the same manner.</p>
    <sec>
      <title>3.1 RefHiC-SR accurately enhances low-coverage contact maps</title>
      <p>We first assessed the contact map enhancement performance of RefHiC-SR, in comparison to three approaches: HiCPlus, HiCNN, and DeepHiC on test Chromosomes 15–17 of GM12878 cells. Each model represents one of the three types of DL models in contact map enhancement (i.e. shallow model, deep model, and GAN), with DeepHiC featured as the state-of-the-art model in several studies. We used as input a 5-kb resolution Hi-C dataset produced from 250-M valid read pairs, obtained by downsampling a Hi-C dataset for human GM12878 cells (<xref rid="btad266-B19" ref-type="bibr">Rao et al. 2014</xref>). This is equivalent to a 1/16 downsampling that most existing tools were trained and evaluated at. As existing models are trained from data at 10-kb resolution and with different normalization approaches, it is impractical to benchmark trained models on the same data at 5 kb. Thus, we retrained HiCPlus, HiCNN, and DeepHiC with the same set of training data as we used to train RefHiC-SR (see Section 2). The accuracy of the enhanced contact maps is assessed by comparing it to the full coverage contact map, using seven metrics: (i) MSE, (ii) MAE, (iii) PSNR (<xref rid="btad266-B13" ref-type="bibr">Liu et al. 2019</xref>), (iv) the SSIM (<xref rid="btad266-B7" ref-type="bibr">Hong et al. 2019</xref>), (v) the diagonal-wise PCC, (vi) the diagonal-wise SRCC, and (vii) the HiCRep score (<xref rid="btad266-B26" ref-type="bibr">Yang et al. 2017</xref>) for Hi-C data comparison.</p>
      <p><xref rid="btad266-F2" ref-type="fig">Figure 2a</xref> and <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S1</xref> illustrate the full coverage (target), low coverage (input), and enhanced contact maps and their differences on a typical 1-Mb genomic region (chr17:5000000–6000000). We observed that all enhanced contact maps better match the full coverage contact map than the low-coverage contact map does, with a slightly advantage for RefHiC-SR. RefHiC-SR and DeepHiC are better capturing fine-scale structures such as loops. We then compared the prediction quality on test Chromosomes 15–17. The diagonal-wise PCC and SRCC between the enhanced and full coverage contact maps (<xref rid="btad266-F2" ref-type="fig">Fig. 2b and c and</xref><xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S10</xref>), show that RefHiC-SR is comparable to or outperforms existing tools across all distance ranges. We then compared RefHiC-SR with existing tools at individual 180 × 180 submatrices. The distributions of MSE (<xref rid="btad266-F2" ref-type="fig">Fig. 2d</xref>), MAE (<xref rid="btad266-F2" ref-type="fig">Fig. 2e</xref>), PSNR (<xref rid="btad266-F2" ref-type="fig">Fig. 2f</xref>), and SSIM (<xref rid="btad266-F2" ref-type="fig">Fig. 2g</xref>) show that all tools achieve similar performance, with a slight advantage for RefHiC-SR. Finally, we compared the similarity of super-resolution and full coverage contact maps at the whole-chromosome level with HiCRep (<xref rid="btad266-B26" ref-type="bibr">Yang et al. 2017</xref>). <xref rid="btad266-T1" ref-type="table">Table 1</xref> shows HiCRep scores for test chromosomes. It indicates that RefHiC-SR is among the best across test chromosomes.</p>
      <fig position="float" id="btad266-F2">
        <label>Figure 2.</label>
        <caption>
          <p>Comparison of RefHiC-SR and other tools on GM12878 Hi-C data (250-M valid read pairs, test Chromosomes 15–17). a. Examples of full coverage, low coverage, and enhanced contact maps on a 1-Mb genomic region (chr17:5000000–6000000) and a zoom in portion. Diagonal-wise PCC (b) and SRCC (c). Boxplots of MSE (d), MAE (e), PSNR (f), and SSIM (g) between full coverage and enhanced contact maps.</p>
        </caption>
        <graphic xlink:href="btad266f2" position="float"/>
      </fig>
      <table-wrap position="float" id="btad266-T1">
        <label>Table 1.</label>
        <caption>
          <p>HiCRep scores between high-coverage and 1/16 downsampled (low coverage)/enhanced contact maps of GM12878 cells.<xref rid="tblfn1" ref-type="table-fn"><sup>a</sup></xref></p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1"/>
              <th rowspan="1" colspan="1">PCC</th>
              <th rowspan="1" colspan="1"/>
              <th rowspan="1" colspan="1"/>
              <th rowspan="1" colspan="1">SRCC</th>
              <th rowspan="1" colspan="1"/>
              <th rowspan="1" colspan="1"/>
            </tr>
            <tr>
              <th rowspan="1" colspan="1"/>
              <th rowspan="1" colspan="1">chr15</th>
              <th rowspan="1" colspan="1">chr16</th>
              <th rowspan="1" colspan="1">chr17</th>
              <th rowspan="1" colspan="1">chr15</th>
              <th rowspan="1" colspan="1">chr16</th>
              <th rowspan="1" colspan="1">chr17</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">RefHiC-SR</td>
              <td rowspan="1" colspan="1"><bold>0.898</bold> ± <bold>0.001</bold></td>
              <td rowspan="1" colspan="1"><bold>0.865</bold> ± <bold>0.001</bold></td>
              <td rowspan="1" colspan="1"><bold>0.877</bold> ± <bold>0.003</bold></td>
              <td rowspan="1" colspan="1"><bold>0.845</bold> ± <bold>3e</bold>−<bold>4</bold></td>
              <td rowspan="1" colspan="1">
                <bold>0.845</bold>
                <inline-formula id="IE26">
                  <mml:math id="IM26" display="inline" overflow="scroll">
                    <mml:mo>±</mml:mo>
                  </mml:math>
                </inline-formula>
                <bold>3e−4</bold>
              </td>
              <td rowspan="1" colspan="1">0.824<inline-formula id="IE27"><mml:math id="IM27" display="inline" overflow="scroll"><mml:mo>±</mml:mo></mml:math></inline-formula>0.001</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">DeepHiC</td>
              <td rowspan="1" colspan="1">0.884 ± 6e−4</td>
              <td rowspan="1" colspan="1">0.842 ± 0.001</td>
              <td rowspan="1" colspan="1">0.863 ± 0.004</td>
              <td rowspan="1" colspan="1">0.833 ± 5e−4</td>
              <td rowspan="1" colspan="1">0.830<inline-formula id="IE28"><mml:math id="IM28" display="inline" overflow="scroll"><mml:mo>±</mml:mo></mml:math></inline-formula>4e−4</td>
              <td rowspan="1" colspan="1">0.820<inline-formula id="IE29"><mml:math id="IM29" display="inline" overflow="scroll"><mml:mo>±</mml:mo></mml:math></inline-formula>9e−4</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">HiCNN</td>
              <td rowspan="1" colspan="1">0.888 ± 6e−4</td>
              <td rowspan="1" colspan="1">0.847 ± 0.001</td>
              <td rowspan="1" colspan="1">0.867 ± 0.003</td>
              <td rowspan="1" colspan="1">0.844 ± 4e−4</td>
              <td rowspan="1" colspan="1">0.844<inline-formula id="IE30"><mml:math id="IM30" display="inline" overflow="scroll"><mml:mo>±</mml:mo></mml:math></inline-formula>3e−4</td>
              <td rowspan="1" colspan="1">
                <bold>0.830</bold>
                <inline-formula id="IE31">
                  <mml:math id="IM31" display="inline" overflow="scroll">
                    <mml:mo>±</mml:mo>
                  </mml:math>
                </inline-formula>
                <bold>8e−4</bold>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">HiCPlus</td>
              <td rowspan="1" colspan="1">0.865 ± 4e−4</td>
              <td rowspan="1" colspan="1">0.823 ± 0.001</td>
              <td rowspan="1" colspan="1">0.845 ± 0.003</td>
              <td rowspan="1" colspan="1">0.807 ± 5e−4</td>
              <td rowspan="1" colspan="1">0.804<inline-formula id="IE32"><mml:math id="IM32" display="inline" overflow="scroll"><mml:mo>±</mml:mo></mml:math></inline-formula>5e−4</td>
              <td rowspan="1" colspan="1">0.792<inline-formula id="IE33"><mml:math id="IM33" display="inline" overflow="scroll"><mml:mo>±</mml:mo></mml:math></inline-formula>0.001</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Low coverage (input)</td>
              <td rowspan="1" colspan="1">0.643 ± 0.001</td>
              <td rowspan="1" colspan="1">0.632 ± 0.002</td>
              <td rowspan="1" colspan="1">0.661 ± 0.002</td>
              <td rowspan="1" colspan="1">0.559 ± 5e−4</td>
              <td rowspan="1" colspan="1">0.564<inline-formula id="IE34"><mml:math id="IM34" display="inline" overflow="scroll"><mml:mo>±</mml:mo></mml:math></inline-formula>4e−4</td>
              <td rowspan="1" colspan="1">0.558<inline-formula id="IE35"><mml:math id="IM35" display="inline" overflow="scroll"><mml:mo>±</mml:mo></mml:math></inline-formula>6e−4</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn1">
            <label>a</label>
            <p>HiCRep scores are computed with PCC and SRCC metrics. We computed the standard deviations by repeating the analysis five times on data downsampled with different random seeds.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
    </sec>
    <sec>
      <title>3.2 RefHiC-SR is robust to sequencing depths</title>
      <p>To benchmark RefHiC-SR’s ability to enhance contact maps from Hi-C data at different sequencing depths, we produced downsampled versions (i.e. 1/2, 1/4,…, 1/64, where 1/64 = 62.5 M valid read pairs) of the same GM12878 contact map (<xref rid="btad266-B19" ref-type="bibr">Rao et al. 2014</xref>) and applied RefHiC-SR and other tools to enhance contact map resolutions for test chromosomes. We evaluated the accuracy of enhanced contact maps by comparing them against the full coverage contact maps using HiCRep. Although lower sequencing depths led to less accurate enhancement for all tools (<xref rid="btad266-F3" ref-type="fig">Fig. 3</xref>), RefHiC-SR was most robust to low sequencing depths, clearly outperforming other tools at very low coverage (1/32 = 125 M and 1/64 = 62.5 M). For Hi-C data containing &lt;250 M valid read pairs, RefHiC-SR can produce predictions comparable to the second best tool using only half of the read pairs. To study the performance of each tool at the most extreme case (i.e. 1/64 downsampled data), we repeated the battery of tests originally performed at 1/16 = 250 M downsampled data (<xref rid="sup1" ref-type="supplementary-material">Supplementary Figs S2 and S10</xref>). We observed RefHiC-SR performed the best on all metrics.</p>
      <fig position="float" id="btad266-F3">
        <label>Figure 3.</label>
        <caption>
          <p>Average HiCRep scores from test Chromosomes 15–17 from the GM12878 cell line across downsampling ratios 1/2, 1/4…1/64. HiCRep scores are computed with PCC (a) and SRCC (b) metrics.</p>
        </caption>
        <graphic xlink:href="btad266f3" position="float"/>
      </fig>
    </sec>
    <sec>
      <title>3.3 RefHiC-SR performs well across cell types</title>
      <p>Next, we aimed to assess the performance of RefHiC-SR and other tools, which were all trained on Hi-C data obtained from GM12878 cells, on data from other cell types. We applied each model to the enhancement of Hi-C data from IMR90 and K562 (<xref rid="btad266-B19" ref-type="bibr">Rao et al. 2014</xref>) cell lines (test Chromosomes 15–17 only). We used HiCRep, MAE, MSE, PSNR, and SSIM to evaluate model performance. <xref rid="btad266-T2" ref-type="table">Table 2</xref> shows that RefHiC-SR outperformed other tools by achieving the highest HiCRep scores in both cells. <xref rid="sup1" ref-type="supplementary-material">Supplementary Figs S8 and S9</xref> show that RefHiC-SR outperformed or was comparable to other tools in both cells as evaluated by super-resolution image analysis metrics.</p>
      <table-wrap position="float" id="btad266-T2">
        <label>Table 2.</label>
        <caption>
          <p>HiCRep scores between high- and low-coverage/enhanced contact maps of IMR-90 and K562 cells.<xref rid="tblfn2" ref-type="table-fn"><sup>a</sup></xref></p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="2" colspan="1"/>
              <th colspan="3" align="center" rowspan="1">IMR90<hr/></th>
              <th colspan="3" align="center" rowspan="1">K562<hr/></th>
            </tr>
            <tr>
              <th align="center" rowspan="1" colspan="1">chr15</th>
              <th align="center" rowspan="1" colspan="1">chr16</th>
              <th align="center" rowspan="1" colspan="1">chr17</th>
              <th align="center" rowspan="1" colspan="1">chr15</th>
              <th align="center" rowspan="1" colspan="1">chr16</th>
              <th align="center" rowspan="1" colspan="1">chr17</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">RefHiC-SR</td>
              <td rowspan="1" colspan="1">
                <bold>0.868</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.850</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.878</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.813</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.817</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.825</bold>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">DeepHiC</td>
              <td rowspan="1" colspan="1">0.858</td>
              <td rowspan="1" colspan="1">0.839</td>
              <td rowspan="1" colspan="1">0.866</td>
              <td rowspan="1" colspan="1">0.799</td>
              <td rowspan="1" colspan="1">0.810</td>
              <td rowspan="1" colspan="1">0.812</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">HiCNN</td>
              <td rowspan="1" colspan="1">0.861</td>
              <td rowspan="1" colspan="1">0.842</td>
              <td rowspan="1" colspan="1">0.870</td>
              <td rowspan="1" colspan="1">0.802</td>
              <td rowspan="1" colspan="1">0.804</td>
              <td rowspan="1" colspan="1">0.811</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">HiCPlus</td>
              <td rowspan="1" colspan="1">0.858</td>
              <td rowspan="1" colspan="1">0.840</td>
              <td rowspan="1" colspan="1">0.866</td>
              <td rowspan="1" colspan="1">0.812</td>
              <td rowspan="1" colspan="1">0.817</td>
              <td rowspan="1" colspan="1">0.824</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Low coverage (input)</td>
              <td rowspan="1" colspan="1">0.716</td>
              <td rowspan="1" colspan="1">0.697</td>
              <td rowspan="1" colspan="1">0.722</td>
              <td rowspan="1" colspan="1">0.788</td>
              <td rowspan="1" colspan="1">0.787</td>
              <td rowspan="1" colspan="1">0.806</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn2">
            <label>a</label>
            <p>HiCRep scores are computed with PCC metrics.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
    </sec>
    <sec>
      <title>3.4 RefHiC-SR enables improved loop and TAD boundary annotation</title>
      <p>RefHiC-SR and other resolution enhancement tools are meant to ease downstream analyses, such as TAD and loop annotation, by imputing missing signals in contact maps. Here we show that RefHiC-SR facilitates annotating TAD and loop with off-the-shelf annotation tools, without introducing many false positives.</p>
      <p>We first assessed the ability of RefHiC-SR to produce enhanced maps that enable high-accuracy loop prediction. We applied Mustache (<xref rid="btad266-B20" ref-type="bibr">Roayaei Ardakany et al. 2020</xref>) to annotate loops from the original full coverage GM12878 contact map, the 1/16 downsampled contact map, and enhanced contact maps produced by different tools. For each analysis, we set the same Mustache 5% false discovery rate (FDR) cutoff, keeping other parameters as default, and sorted loops by Mustache-reported FDR. We also included predictions made by RefHiC (<xref rid="btad266-B27" ref-type="bibr">Zhang and Blanchette 2022</xref>) for comparison. The number of predicted loops is quite different among different inputs, with DeepHiC leading to the largest number of predictions (<xref rid="btad266-F4" ref-type="fig">Fig. 4a</xref>). We then evaluated predicted loops by comparing them to loops identified by loop-targeting experimental data [ChIA-PET on CTCF (CCCTC-binding factor) (<xref rid="btad266-B23" ref-type="bibr">Tang et al. 2015</xref>) and RAD21 (ENCODE Project Consortium et al. 2012), and HiChiP on SMC1 (<xref rid="btad266-B16" ref-type="bibr">Mumbach et al. 2016</xref>) and H3K27ac (<xref rid="btad266-B17" ref-type="bibr">Mumbach et al. 2017</xref>)], allowing up to a 5-kb shift (<xref rid="btad266-F4" ref-type="fig">Fig. 4b–e</xref>). When applied to enhanced contact maps, Mustache produced 1245 CTCF-supported loops, 761 RAD21-supported loops, 512 SMC1-supported loops, and 197 H3K27ac-supported loops from RefHiC-SR enhanced contact maps. These numbers exceed those obtained on enhanced maps produced by other tools by 25%–550%, and even those obtained on the full coverage data itself. The accuracy of loop annotated from RefHiC-SR enhanced contact maps is comparable to annotating loops from the full coverage data. In contrast, contact maps enhanced by alternative tools introduced a large number of false positive loop predictions. The combination of RefHiC-SR and Mustache was only beat by RefHiC slightly. We next evaluated the extent to which RefHiC-SR facilitates loop annotation from Hi-C contact maps containing different numbers of valid read pairs. Unexpectedly, coverage reduction leads to an increase in the number of loops being predicted on most tools’ enhanced maps (including RefHiC-SR enhanced, <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S3</xref>). <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S4</xref> shows that as the coverage drops from 256 to 62.5 M valid read pairs, the number of experimentally supported predicted loops remains similar when Mustache is applied to RefHiC-SR enhanced contact maps, but drops significantly using enhanced maps produced by other super-resolution tools.</p>
      <fig position="float" id="btad266-F4">
        <label>Figure 4.</label>
        <caption>
          <p>Comparison of loops and TADs annotated from low coverage, full coverage, and enhanced contact maps. (a) Number of loop annotations. (b–e) Number of ChIA-PET/HiCHIP-supported loop predictions compared against CTCF ChIA-PET (b), SMC1 HiCHIP (c), RAD21 ChIA-PET (d), and H3K27ac HiCHIP (e). Occupancy of ChIP-seq identified CTCF binding site as a function of distance to left (g) and right (h) boundary annotations.</p>
        </caption>
        <graphic xlink:href="btad266f4" position="float"/>
      </fig>
      <p>To evaluate RefHiC-SR’s usefulness for facilitating TAD annotation, we used RobusTAD (<xref rid="btad266-B5" ref-type="bibr">Dali et al. 2018</xref>) to annotate TAD boundaries from the same set of contact maps as above. We also included predictions made by RefHiC (<xref rid="btad266-B27" ref-type="bibr">Zhang and Blanchette 2022</xref>) for comparison. RefHiC made the least predictions. The number of predicted TAD boundaries is similar among full coverage Hi-C data and super-resolution inputs (<xref rid="btad266-F4" ref-type="fig">Fig. 4f</xref>). <xref rid="btad266-F4" ref-type="fig">Figure 4g and h</xref> shows that RobusTAD identified a similar total number of CTCF-supported TAD boundaries from RefHiC-enhanced and full coverage contact maps. In contrast, contact maps enhanced by alternative tools lead to fewer CTCF-supported TAD boundaries. Annotating TAD boundaries from contact maps enhanced from low-coverage data show that boundary annotation is robust to sequencing coverage (<xref rid="sup1" ref-type="supplementary-material">Supplementary Figs S5 and S6</xref>). <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S6</xref> shows that at very low coverage, RefHiC-SR can still help to identify a large number of CTCF-supported TAD boundaries.</p>
      <p>We then repeated the analysis on Hi-C datasets for K562 and IMR-90 cells. <xref rid="sup1" ref-type="supplementary-material">Supplementary Figs S12 and S13</xref> show RefHiC-SR outperformed alternative methods in both loop and TAD annotations.</p>
    </sec>
    <sec>
      <title>3.5 RefHiC-SR implementation</title>
      <p>RefHiC-SR is a Python program available at <ext-link xlink:href="https://github.com/BlanchetteLab/RefHiC" ext-link-type="uri">https://github.com/BlanchetteLab/RefHiC</ext-link> with scripts to reproduce our experiments. We implemented the neural network with the PyTorch library (<xref rid="btad266-B18" ref-type="bibr">Paszke et al. 2019)</xref>. RefHiC-SR can run on either a CPU or GPU, but it performs three times faster on GPU. RefHiC-SR requires at least 3 GB of storage space for saving reference panel data and at least 15-GB RAM for loading reference samples during prediction. RefHiC-SR is efficient and can process the longest human chromosome within 3 min when run on a GPU.</p>
    </sec>
  </sec>
  <sec>
    <title>4 Discussion</title>
    <p>Here, we present RefHiC-SR, a DL framework that utilizes a reference panel to facilitate enhancing Hi-C data resolution for a given study sample. In contrast, existing contact map enhancement algorithms are exclusively study-sample based, and hence their ability to reliably enhance contact maps from typical sequencing depth Hi-C data is limited. Our extensive evaluation demonstrated that RefHiC-SR outperforms existing tools in datasets ranging from very high to very low sequencing coverage, with the most striking improvements observed in the latter case. RefHiC-SR also outperformed a simple global similarity-based baseline (<xref rid="sup1" ref-type="supplementary-material">Supplementary Note S2</xref>), indicating the necessity of designing this model to incorporate the reference panel. Although RefHiC-SR is a machine-learning model trained primarily on GM12878 Hi-C data, the same trained model is effective on different cell types, and at different levels of coverage. Comparison between RefHiC-SR and a Baseline model similar to RefHiC-SR but lacking a reference panel shows RefHiC-SR’s superior to the introduction of a reference panel (<xref rid="sup1" ref-type="supplementary-material">Supplementary Note S1</xref>). The super-resolution contact maps predicted by RefHiC-SR are ready for downstream analysis and do not introduce a significant number of false positives. In contrast, other enhancement tools often introduce false positive annotations in downstream analysis.</p>
    <p>Across the different subfields of data-driven biology, researchers have developed many reference panel enabled approaches to aid the analysis of a study sample. RefHiC-SR is the first approach to enable this type of reference panel based analysis of 3D contact map enhancement. In addition, RefHiC-SR is the only contact map enhancement model that is robust to low sequencing coverage. We believe RefHiC-SR has the potential to become an essential method for enhancing Hi-C contact maps, paving the way to further our understanding of 3D genome organization and functional implications at a finer scale.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material id="sup1" position="float" content-type="local-data">
      <label>btad266_Supplementary_Data</label>
      <media xlink:href="btad266_supplementary_data.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <sec>
    <title>Author contributions</title>
    <p>Y.Z. and M.B. conceived the study. Y.Z. performed analysis. M.B. supervised the project. Y.Z. and M.B. wrote the article. All authors read and approved the final article.</p>
  </sec>
  <sec>
    <title>Supplementary data</title>
    <p><xref rid="sup1" ref-type="supplementary-material">Supplementary data</xref> is available at <italic toggle="yes">Bioinformatics</italic> online.</p>
  </sec>
  <sec sec-type="COI-statement">
    <title>Conflict of interest</title>
    <p>None declared.</p>
  </sec>
  <sec>
    <title>Funding</title>
    <p>This work was supported by Genome Quebec/Canada and Genome Quebec/Oncopole/IVADO (to M.B.) and FRQNT Doctoral (B2X) Research Scholarships (to Y.Z.).</p>
  </sec>
  <sec sec-type="data-availability">
    <title>Data availability</title>
    <p>The data underlying this article are available in zenodo, at <ext-link xlink:href="https://dx.doi.org/10.5281/zenodo.7761968" ext-link-type="uri">https://dx.doi.org/10.5281/zenodo.7761968</ext-link>.</p>
  </sec>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="btad266-B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Abdennur</surname><given-names>N</given-names></string-name>, <string-name><surname>Mirny</surname><given-names>LA.</given-names></string-name></person-group><article-title>Cooler: scalable storage for Hi-C data and other genomically labeled arrays</article-title>. <source>Bioinformatics</source><year>2020</year>;<volume>36</volume>:<fpage>311</fpage>–<lpage>6</lpage>.<pub-id pub-id-type="pmid">31290943</pub-id></mixed-citation>
    </ref>
    <ref id="btad266-B2">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Borgeaud</surname><given-names>S</given-names></string-name>, <string-name><surname>Mensch</surname><given-names>A</given-names></string-name>, <string-name><surname>Hoffmann</surname><given-names>J</given-names></string-name></person-group><etal>et al</etal> Improving language models by retrieving from trillions of tokens. In: <italic toggle="yes">International conference on machine learning</italic>, (pp. 2206-2240). PMLR, 2022.</mixed-citation>
    </ref>
    <ref id="btad266-B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cameron</surname><given-names>CJ</given-names></string-name>, <string-name><surname>Dostie</surname><given-names>J</given-names></string-name>, <string-name><surname>Blanchette</surname><given-names>M.</given-names></string-name></person-group><article-title>HIFI: estimating DNA-DNA interaction frequency from Hi-c data at restriction-fragment resolution</article-title>. <source>Genome Biol</source><year>2020</year>;<volume>21</volume>:<fpage>1</fpage>–<lpage>15</lpage>.</mixed-citation>
    </ref>
    <ref id="btad266-B4">
      <mixed-citation publication-type="journal"><collab>ENCODE Project Consortium</collab><etal>et al</etal><article-title>An integrated encyclopedia of DNA elements in the human genome</article-title>. <source>Nature</source><year>2012</year>;<volume>489</volume>:<fpage>57</fpage>.<pub-id pub-id-type="pmid">22955616</pub-id></mixed-citation>
    </ref>
    <ref id="btad266-B5">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Dali</surname><given-names>R</given-names></string-name>, <string-name><surname>Bourque</surname><given-names>G</given-names></string-name>, <string-name><surname>Blanchette</surname><given-names>M.</given-names></string-name></person-group> Robustad: a tool for robust annotation of topologically associating domain boundaries. bioRxiv <year>2018</year>. <pub-id pub-id-type="doi">10.1101/293175</pub-id>.</mixed-citation>
    </ref>
    <ref id="btad266-B6">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Gao</surname><given-names>T</given-names></string-name>, <string-name><surname>Yao</surname><given-names>X</given-names></string-name>, <string-name><surname>Chen</surname><given-names>D.</given-names></string-name></person-group> Simcse: simple contrastive learning of sentence embeddings. In: <italic toggle="yes"><italic toggle="yes">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</italic>, (pp. 6894–6910), Online and Punta Cana, Dominican Republic</italic>. Association for Computational Linguistics.</mixed-citation>
    </ref>
    <ref id="btad266-B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hong</surname><given-names>H</given-names></string-name>, <string-name><surname>Jiang</surname><given-names>S</given-names></string-name>, <string-name><surname>Li</surname><given-names>H</given-names></string-name></person-group><etal>et al</etal><article-title>DeepHiC: A generative adversarial network for enhancing hi-C data resolution</article-title>. <source><italic toggle="yes">PLoS Comput Biol</italic></source><year>2020</year>;<volume>16</volume>:<fpage>e1007287</fpage>.<pub-id pub-id-type="doi">10.1371/journal.pcbi.1007287</pub-id>.<pub-id pub-id-type="pmid">32084131</pub-id></mixed-citation>
    </ref>
    <ref id="btad266-B8">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Imakaev</surname><given-names>M</given-names></string-name>, <string-name><surname>Fudenberg</surname><given-names>G</given-names></string-name>, <string-name><surname>McCord</surname><given-names>RP</given-names></string-name></person-group><etal>et al</etal><article-title>Iterative correction of Hi-C data reveals hallmarks of chromosome organization</article-title>. <source>Nat Methods</source><year>2012</year>;<volume>9</volume>:<fpage>999</fpage>–<lpage>1003</lpage>.<pub-id pub-id-type="pmid">22941365</pub-id></mixed-citation>
    </ref>
    <ref id="btad266-B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Krietenstein</surname><given-names>N</given-names></string-name>, <string-name><surname>Abraham</surname><given-names>S</given-names></string-name>, <string-name><surname>Venev</surname><given-names>SV</given-names></string-name></person-group><etal>et al</etal><article-title>Ultrastructural details of mammalian chromosome architecture</article-title>. <source>Mol Cell</source><year>2020</year>;<volume>78</volume>:<fpage>554</fpage>–<lpage>65.e7</lpage>.<pub-id pub-id-type="pmid">32213324</pub-id></mixed-citation>
    </ref>
    <ref id="btad266-B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lee</surname><given-names>D-I</given-names></string-name>, <string-name><surname>Roy</surname><given-names>S.</given-names></string-name></person-group><article-title>Grinch: simultaneous smoothing and detection of topological units of genome organization from sparse chromatin contact count matrices with matrix factorization</article-title>. <source>Genome Biol</source><year>2021</year>;<volume>22</volume>:<fpage>1</fpage>–<lpage>31</lpage>.<pub-id pub-id-type="pmid">33397451</pub-id></mixed-citation>
    </ref>
    <ref id="btad266-B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lieberman-Aiden</surname><given-names>E</given-names></string-name>, <string-name><surname>Van Berkum</surname><given-names>NL</given-names></string-name>, <string-name><surname>Williams</surname><given-names>L</given-names></string-name></person-group><etal>et al</etal><article-title>Comprehensive mapping of long-range interactions reveals folding principles of the human genome</article-title>. <source>Science</source><year>2009</year>;<volume>326</volume>:<fpage>289</fpage>–<lpage>93</lpage>.<pub-id pub-id-type="pmid">19815776</pub-id></mixed-citation>
    </ref>
    <ref id="btad266-B12">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lin</surname><given-names>D</given-names></string-name>, <string-name><surname>Sanders</surname><given-names>J</given-names></string-name>, <string-name><surname>Noble</surname><given-names>WS.</given-names></string-name></person-group><article-title>HiCRep. py: fast comparison of Hi-c contact matrices in python</article-title>. <source>Bioinformatics</source><year>2021</year>;<volume>37</volume>:<fpage>2996</fpage>–<lpage>7</lpage>.<pub-id pub-id-type="pmid">33576390</pub-id></mixed-citation>
    </ref>
    <ref id="btad266-B13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Liu</surname><given-names>Q</given-names></string-name>, <string-name><surname>Lv</surname><given-names>H</given-names></string-name>, <string-name><surname>Jiang</surname><given-names>R.</given-names></string-name></person-group><article-title>hicGAN infers super resolution Hi-C data with generative adversarial networks</article-title>. <source>Bioinformatics</source><year>2019</year>;<volume>35</volume>:<fpage>i99</fpage>–<lpage>107</lpage>.<pub-id pub-id-type="pmid">31510693</pub-id></mixed-citation>
    </ref>
    <ref id="btad266-B14">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Liu</surname><given-names>T</given-names></string-name>, <string-name><surname>Wang</surname><given-names>Z.</given-names></string-name></person-group><article-title>HiCNN: a very deep convolutional neural network to better enhance the resolution of Hi-c data</article-title>. <source>Bioinformatics</source><year>2019</year>;<volume>35</volume>:<fpage>4222</fpage>–<lpage>8</lpage>.<pub-id pub-id-type="pmid">31056636</pub-id></mixed-citation>
    </ref>
    <ref id="btad266-B15">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Loshchilov</surname><given-names>I</given-names></string-name>, <string-name><surname>Hutter</surname><given-names>F.</given-names></string-name></person-group> Decoupled weight decay regularization. <italic toggle="yes">arXiv preprint</italic><year>2017</year>. <pub-id pub-id-type="doi">10.48550/arXiv.1711.05101</pub-id>.</mixed-citation>
    </ref>
    <ref id="btad266-B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mumbach</surname><given-names>MR</given-names></string-name>, <string-name><surname>Rubin</surname><given-names>AJ</given-names></string-name>, <string-name><surname>Flynn</surname><given-names>RA</given-names></string-name></person-group><etal>et al</etal><article-title>HiChiP: efficient and sensitive analysis of protein-directed genome architecture</article-title>. <source>Nat Methods</source><year>2016</year>;<volume>13</volume>:<fpage>919</fpage>–<lpage>22</lpage>.<pub-id pub-id-type="pmid">27643841</pub-id></mixed-citation>
    </ref>
    <ref id="btad266-B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mumbach</surname><given-names>MR</given-names></string-name>, <string-name><surname>Satpathy</surname><given-names>AT</given-names></string-name>, <string-name><surname>Boyle</surname><given-names>EA</given-names></string-name></person-group><etal>et al</etal><article-title>Enhancer connectome in primary human cells identifies target genes of disease-associated DNA elements</article-title>. <source>Nat Genet</source><year>2017</year>;<volume>49</volume>:<fpage>1602</fpage>–<lpage>12</lpage>.<pub-id pub-id-type="pmid">28945252</pub-id></mixed-citation>
    </ref>
    <ref id="btad266-B18">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Paszke</surname><given-names>A</given-names></string-name>, <string-name><surname>Gross</surname><given-names>S</given-names></string-name>, <string-name><surname>Massa</surname><given-names>F</given-names></string-name></person-group><etal>et al</etal><part-title>PyTorch: an imperative style, high-performance deep learning library</part-title>. In: <person-group person-group-type="editor"><string-name><surname>Wallach</surname><given-names>H</given-names></string-name>, <string-name><surname>Larochelle</surname><given-names>H</given-names></string-name>, <string-name><surname>Beygelzimer</surname><given-names>A</given-names></string-name></person-group><etal>et al</etal> (eds), <source>Advances in Processing Systems</source>. Vol. <volume>32</volume>, Red Hook, NY, USA: <publisher-name>Curran Associates, Inc</publisher-name>., <year>2019</year>, <fpage>8024</fpage>–<lpage>35</lpage>.</mixed-citation>
    </ref>
    <ref id="btad266-B19">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rao</surname><given-names>SS</given-names></string-name>, <string-name><surname>Huntley</surname><given-names>MH</given-names></string-name>, <string-name><surname>Durand</surname><given-names>NC</given-names></string-name></person-group><etal>et al</etal><article-title>A 3D map of the human genome at kilobase resolution reveals principles of chromatin looping</article-title>. <source>Cell</source><year>2014</year>;<volume>159</volume>:<fpage>1665</fpage>–<lpage>80</lpage>.<pub-id pub-id-type="pmid">25497547</pub-id></mixed-citation>
    </ref>
    <ref id="btad266-B20">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Roayaei Ardakany</surname><given-names>A</given-names></string-name>, <string-name><surname>Gezer</surname><given-names>HT</given-names></string-name>, <string-name><surname>Lonardi</surname><given-names>S</given-names></string-name></person-group><etal>et al</etal><article-title>Mustache: multi-scale detection of chromatin loops from Hi-C and micro-C maps using scale-space representation</article-title>. <source>Genome Biol</source><year>2020</year>;<volume>21</volume>:<fpage>1</fpage>–<lpage>17</lpage>.</mixed-citation>
    </ref>
    <ref id="btad266-B21">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Ronneberger</surname><given-names>O</given-names></string-name>, <string-name><surname>Fischer</surname><given-names>P</given-names></string-name>, <string-name><surname>Brox</surname><given-names>T.</given-names></string-name></person-group> U-net: convolutional networks for biomedical image segmentation. In: <italic toggle="yes">International Conference on Medical Image Computing and Computer-Assisted Intervention</italic>, pp. <fpage>234</fpage>–<lpage>41</lpage>. Switzerland: <publisher-name>Springer</publisher-name>, <year>2015</year>.</mixed-citation>
    </ref>
    <ref id="btad266-B22">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sanborn</surname><given-names>AL</given-names></string-name>, <string-name><surname>Rao</surname><given-names>SS</given-names></string-name>, <string-name><surname>Huang</surname><given-names>S-C</given-names></string-name></person-group><etal>et al</etal><article-title>Chromatin extrusion explains key features of loop and domain formation in wild-type and engineered genomes</article-title>. <source>Proc Natl Acad Sci U S A</source><year>2015</year>;<volume>112</volume>:<fpage>E6456</fpage>–<lpage>65</lpage>.<pub-id pub-id-type="pmid">26499245</pub-id></mixed-citation>
    </ref>
    <ref id="btad266-B23">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tang</surname><given-names>Z</given-names></string-name>, <string-name><surname>Luo</surname><given-names>OJ</given-names></string-name>, <string-name><surname>Li</surname><given-names>X</given-names></string-name></person-group><etal>et al</etal><article-title>CTCF-mediated human 3D genome architecture reveals chromatin topology for transcription</article-title>. <source>Cell</source><year>2015</year>;<volume>163</volume>:<fpage>1611</fpage>–<lpage>27</lpage>.<pub-id pub-id-type="pmid">26686651</pub-id></mixed-citation>
    </ref>
    <ref id="btad266-B24">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Xia</surname><given-names>B</given-names></string-name>, <string-name><surname>Tian</surname><given-names>Y</given-names></string-name>, <string-name><surname>Hang</surname><given-names>Y</given-names></string-name></person-group><etal>et al</etal> Coarse-to-fine embedded patchmatch and multi-scale dynamic aggregation for reference-based super-resolution. <italic toggle="yes">arXiv preprint</italic><year>2022</year>. <pub-id pub-id-type="doi">10.48550/arXiv.2201.04358</pub-id>.</mixed-citation>
    </ref>
    <ref id="btad266-B25">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Yan</surname><given-names>X</given-names></string-name>, <string-name><surname>Zhao</surname><given-names>W</given-names></string-name>, <string-name><surname>Yuan</surname><given-names>K</given-names></string-name></person-group><etal>et al</etal> Towards content-independent multi-reference super-resolution: adaptive pattern matching and feature aggregation. In: <italic toggle="yes">European Conference on Computer Vision</italic>, pp. <fpage>52</fpage>–<lpage>68</lpage>. Switzerland: <publisher-name>Springer</publisher-name>, <year>2020</year>.</mixed-citation>
    </ref>
    <ref id="btad266-B26">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yang</surname><given-names>T</given-names></string-name>, <string-name><surname>Zhang</surname><given-names>F</given-names></string-name>, <string-name><surname>Yardımcı</surname><given-names>GG</given-names></string-name></person-group><etal>et al</etal><article-title>HiCRep: assessing the reproducibility of Hi-C data using a stratum-adjusted correlation coefficient</article-title>. <source>Genome Res</source><year>2017</year>;<volume>27</volume>:<fpage>1939</fpage>–<lpage>49</lpage>.<pub-id pub-id-type="pmid">28855260</pub-id></mixed-citation>
    </ref>
    <ref id="btad266-B27">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname><given-names>Y</given-names></string-name>, <string-name><surname>Blanchette</surname><given-names>M.</given-names></string-name></person-group><article-title>Reference panel guided topological structure annotation of Hi-c data</article-title>. <source>Nat Commun</source><year>2022</year>;<volume>13</volume>:<fpage>1</fpage>–<lpage>12</lpage>.<pub-id pub-id-type="pmid">34983933</pub-id></mixed-citation>
    </ref>
    <ref id="btad266-B28">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname><given-names>Y</given-names></string-name>, <string-name><surname>An</surname><given-names>L</given-names></string-name>, <string-name><surname>Xu</surname><given-names>J</given-names></string-name></person-group><etal>et al</etal><article-title>Enhancing Hi-C data resolution with deep convolutional neural network hicplus</article-title>. <source>Nat Commun</source><year>2018</year>;<volume>9</volume>:<fpage>750</fpage>.<pub-id pub-id-type="pmid">29467363</pub-id></mixed-citation>
    </ref>
    <ref id="btad266-B29">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhou</surname><given-names>J</given-names></string-name>, <string-name><surname>Ma</surname><given-names>J</given-names></string-name>, <string-name><surname>Chen</surname><given-names>Y</given-names></string-name></person-group><etal>et al</etal><article-title>Robust single-cell Hi-C clustering by convolution-and random-walk–based imputation</article-title>. <source>Proc Natl Acad Sci U S A</source><year>2019</year>;<volume>116</volume>:<fpage>14011</fpage>–<lpage>8</lpage>.<pub-id pub-id-type="pmid">31235599</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id>
    <journal-id journal-id-type="publisher-id">bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1367-4803</issn>
    <issn pub-type="epub">1367-4811</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">10311349</article-id>
    <article-id pub-id-type="pmid">37387127</article-id>
    <article-id pub-id-type="doi">10.1093/bioinformatics/btad266</article-id>
    <article-id pub-id-type="publisher-id">btad266</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Regulatory and Functional Genomics</subject>
      </subj-group>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI01060</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Reference panel-guided super-resolution inference of Hi-C data</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Zhang</surname>
          <given-names>Yanlin</given-names>
        </name>
        <aff><institution>School of Computer Science, McGill University, Montréal</institution>, Québec H3A 0E9, <country country="CA">Canada</country></aff>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Blanchette</surname>
          <given-names>Mathieu</given-names>
        </name>
        <aff><institution>School of Computer Science, McGill University, Montréal</institution>, Québec H3A 0E9, <country country="CA">Canada</country></aff>
        <xref rid="btad266-cor1" ref-type="corresp"/>
        <!--blanchem@cs.mcgill.ca-->
      </contrib>
    </contrib-group>
    <author-notes>
      <corresp id="btad266-cor1">Corresponding author. School of Computer Science, McGill University, Montréal, Québec H3A 0E9, Canada. E-mail: <email>blanchem@cs.mcgill.ca</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <month>6</month>
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2023-06-30">
      <day>30</day>
      <month>6</month>
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>30</day>
      <month>6</month>
      <year>2023</year>
    </pub-date>
    <volume>39</volume>
    <issue>Suppl 1</issue>
    <issue-title>ISMB/ECCB 2023 Proceedings</issue-title>
    <fpage>i386</fpage>
    <lpage>i393</lpage>
    <permissions>
      <copyright-statement>© The Author(s) 2023. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2023</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="btad266.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Motivation</title>
        <p>Accurately assessing contacts between DNA fragments inside the nucleus with Hi-C experiment is crucial for understanding the role of 3D genome organization in gene regulation. This challenging task is due in part to the high sequencing depth of Hi-C libraries required to support high-resolution analyses. Most existing Hi-C data are collected with limited sequencing coverage, leading to poor chromatin interaction frequency estimation. Current computational approaches to enhance Hi-C signals focus on the analysis of individual Hi-C datasets of interest, without taking advantage of the facts that (i) several hundred Hi-C contact maps are publicly available and (ii) the vast majority of local spatial organizations are conserved across multiple cell types.</p>
      </sec>
      <sec id="s2">
        <title>Results</title>
        <p>Here, we present RefHiC-SR, an attention-based deep learning framework that uses a reference panel of Hi-C datasets to facilitate the enhancement of Hi-C data resolution of a given study sample. We compare RefHiC-SR against tools that do not use reference samples and find that RefHiC-SR outperforms other programs across different cell types, and sequencing depths. It also enables high-accuracy mapping of structures such as loops and topologically associating domains.</p>
      </sec>
      <sec id="s3">
        <title>Availability and implementation</title>
        <p><ext-link xlink:href="https://github.com/BlanchetteLab/RefHiC" ext-link-type="uri">https://github.com/BlanchetteLab/RefHiC</ext-link>.</p>
      </sec>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Genome Quebec</institution>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Canada and Genome Quebec</institution>
          </institution-wrap>
        </funding-source>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="8"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 Introduction</title>
    <p>Technologies such as Hi-C (<xref rid="btad266-B11" ref-type="bibr">Lieberman-Aiden et al. 2009</xref>), and micro-C (<xref rid="btad266-B9" ref-type="bibr">Krietenstein et al. 2020</xref>) capture spatial contacts between DNA fragments in genomes, enabling the inference of various aspects of 3D genome organization. These approaches have revealed a hierarchical spatial organization of topological structures of the genome inside nuclei and spatial patterns such as topologically associating domains (TADs), loops, and compartments. These structures are of vital importance to gene regulation and are dynamic within cells (<xref rid="btad266-B22" ref-type="bibr">Sanborn et al. 2015</xref>). Identifying these spatial patterns, especially at high resolution, requires the availability of high-coverage Hi-C sequencing data. The investigation of fine-scale structures would even require ultrahigh-coverage contact maps (<xref rid="btad266-B9" ref-type="bibr">Krietenstein et al. 2020</xref>).</p>
    <p>While Hi-C and its variants remain the most popular approaches to map chromatin contacts on a genome-wide scale, the analysis of the data they produce is challenging, in large part due to the moderate sequencing depth (typically 200–500 Million valid read pairs) compared with the size of the contact frequency matrices that need to be estimated. The majority of TAD and loop annotation tools are primarily optimized for high-coverage data and may not provide satisfactory results when applied to typical low- to medium-coverage data, though tools like Grinch (<xref rid="btad266-B10" ref-type="bibr">Lee and Roy 2021</xref>) have been proposed to analyze low-coverage data. To close the gap, many efforts have been undertaken to perform <italic toggle="yes">in silico</italic> enhancement of Hi-C contact maps (<xref rid="btad266-B28" ref-type="bibr">Zhang et al. 2018</xref>; <xref rid="btad266-B14" ref-type="bibr">Liu and Wang 2019</xref>; <xref rid="btad266-B13" ref-type="bibr">Liu et al. 2019</xref>; <xref rid="btad266-B3" ref-type="bibr">Cameron et al. 2020</xref>). Given a low-coverage Hi-C dataset, contact map enhancement tools seek to predict a dense, high-resolution version of the contact map aiming to reproduce the map that would be obtained through very deep coverage sequencing of the same library. Super-resolution enhancement could in theory enable high-resolution analysis of low-coverage Hi-C data, e.g. through the application of third-party analysis tools to enhanced maps.</p>
    <p>Most existing contact map enhancement tools are deep learning (DL) approaches and are inspired by super-resolution algorithms in image processing. As a high-resolution (5 kb per bin) contact map for a single human chromosome contains 10 000–50 000 bins, existing applications usually split contact maps into nonoverlapping blocks and enhance each block iteratively. HiCPlus (<xref rid="btad266-B28" ref-type="bibr">Zhang et al. 2018</xref>) was the first DL-based tool proposed for this type of tasks. It is a convolutional neural network (CNN) that contains one hidden layer and is trained from low- and high-coverage contact map pairs (respectively the input and target values) by minimizing the mean square error (MSE) loss. Later, <xref rid="btad266-B14" ref-type="bibr">Liu and Wang (2019)</xref> proposed a deeper CNN with residual connections—HiCNN and trained it following the strategy used in HiCPlus. Similar to super-resolution analysis in computer vision, the MSE loss leads both models to produce blurry predictions (<xref rid="btad266-B13" ref-type="bibr">Liu et al. 2019</xref>). To alleviate the issue of over-smoothness, more recent approaches utilize generative adversarial (GAN) frameworks in model training. For example, HiCGAN (<xref rid="btad266-B13" ref-type="bibr">Liu et al. 2019</xref>) is a CNN built upon a generator containing five residual blocks and a discriminator containing three residual blocks. The generator is trained to produce enhanced contact maps from downsampled contact maps, and the discriminator is trained to distinguish high-coverage contact maps from enhanced contact maps. Liu et al. trained HiCGAN with GAN loss and used the generator for prediction. DeepHiC (<xref rid="btad266-B7" ref-type="bibr">Hong et al. 2019</xref>) furthers model performance by introducing additional terms to the loss function (i.e. MSE, perceptual loss, and total variance) into training. In contrast, conventional tools (<xref rid="btad266-B29" ref-type="bibr">Zhou et al. 2019</xref>; <xref rid="btad266-B3" ref-type="bibr">Cameron et al. 2020</xref>) usually treat contact map enhancement as imputation. They enhance Hi-C signals by fitting a Markov Random Field or performing random walk on a Hi-C graph.</p>
    <p>Although DL models have achieved significant successes in contact map enhancement, there is still room for improvement, particularly in the enhancement of very low-coverage contact maps. First, most existing tools are trained on data containing 250 M valid read pairs [typically a 16-fold downsampled version of a very high-coverage Hi-C dataset produced for human GM12878 cells data by <xref rid="btad266-B19" ref-type="bibr">Rao et al. (2014)</xref>], and can only be effectively used to enhance contact maps containing 200–300 M valid read pairs. In addition, similar to super-resolution analysis in computer vision, contact map enhancement is an ill-posed problem as a single low-coverage contact map may correspond to multiple potential high-coverage contact maps. While existing tools can infer high-fidelity predictions, these may not necessarily be correct predictions, especially in sparse regions, potentially leading to false positives in downstream annotation tasks.</p>
    <p>To address the issue of ill-posedness in single-image super-resolution, computer vision researchers have introduced additional images to assist with the prediction task. For example, some studies have created databases of image patches and used them to improve prediction accuracy (<xref rid="btad266-B25" ref-type="bibr">Yan et al. 2020</xref>; <xref rid="btad266-B24" ref-type="bibr">Xia et al. 2022</xref>). In recent years, incorporating external data have become a popular research direction and have been shown to lead to better models with fewer parameters (<xref rid="btad266-B2" ref-type="bibr">Borgeaud et al. 2021</xref>). Within Hi-C data analysis, our recent approach—RefHiC (<xref rid="btad266-B27" ref-type="bibr">Zhang and Blanchette 2022</xref>) achieves superior performance in annotating topological structures (loops and TADs) from a study sample while using a reference panel of other Hi-C datasets as complement. In reference-based image super-resolution, the reference database is assumed to contain a diverse set of images, regardless of their relationship to the test image. In 3D genome analysis, the conformation of a small region in one cell type may be observed in another cell types (<xref rid="btad266-B27" ref-type="bibr">Zhang and Blanchette 2022</xref>). Therefore, to improve the resolution of a small region of a Hi-C contact map, we use contact maps of the same region as a reference.</p>
    <p>Here, we introduce RefHiC-SR, a model for enhancing Hi-C contact maps. While RefHiC (<xref rid="btad266-B27" ref-type="bibr">Zhang and Blanchette 2022</xref>), our model for topological structure annotation, is limited in its ability to learn features from large patches required in a super-resolution task, RefHiC-SR overcomes these limitations by redesigning the encoder as a modified U-net architecture (<xref rid="btad266-B21" ref-type="bibr">Ronneberger et al. 2015</xref>), and introducing a multiscale attention mechanism. This novel model allows RefHiC-SR to handle large patches in Hi-C matrices while still benefiting from a reference panel.</p>
  </sec>
  <sec>
    <title>2 Materials and methods</title>
    <sec>
      <title>2.1 RefHiC-SR model architecture</title>
      <p>The RefHiC-SR network follows the U-net architecture (<xref rid="btad266-B21" ref-type="bibr">Ronneberger et al. 2015</xref>; <xref rid="btad266-F1" ref-type="fig">Fig. 1</xref>), originally introduced for image segmentation, to enhance the expressiveness of latent features produced by encoding blocks and enable effective handling of large patches (i.e. 200 × 200). It contains (i) a low-level feature extraction block (F) that transforms a Hi-C matrix to multichannel features, (ii) an output block (O) that transforms multi-channel features to an enhanced Hi-C matrix, (iii) multiscale encoding blocks (E1, E2, and E3) that transform low-level features to high-level features at different scales (i.e. keys, values, and query in attention <xref rid="E1" ref-type="disp-formula">Equations 1</xref> and <xref rid="E2" ref-type="disp-formula">2</xref>), (iv) multiscale decoding blocks (D1 and D2) that transform features at different scales, and (v) attention convolutional blocks (A1 and A2) and projecting layers (P1 and P2) that increasing the model complexity and reduces hidden feature dimensions. To inject information from reference samples into the U-net computation graph, in the forward pass, blocks F and E1–E3 compute multiscale embeddings for the study sample and for the <italic toggle="yes">n</italic> reference samples. We denote parts of these embeddings as V1 and V2 (values), K (keys), and Q (query). We then compute combined multiscale representations of all reference samples from these embeddings with an attention mechanism. Finally, we replace skip connections in U-net (<xref rid="btad266-B21" ref-type="bibr">Ronneberger et al. 2015</xref>) with a concatenation of the study sample’s embedding and a transformed attention output at the same scale.</p>
      <fig position="float" id="btad266-F1">
        <label>Figure 1.</label>
        <caption>
          <p>RefHiC-SR architecture. Overview of the RefHiC-SR neural network for enhancing Hi-C contact maps.</p>
        </caption>
        <graphic xlink:href="btad266f1" position="float"/>
      </fig>
      <p>F takes an input of dimension <italic toggle="yes">w</italic> × <italic toggle="yes">w</italic>, where <italic toggle="yes">w</italic> is the window size (<inline-formula id="IE1"><mml:math id="IM1" display="inline" overflow="scroll"><mml:mrow><mml:mi>w</mml:mi><mml:mo>=</mml:mo><mml:mn>200</mml:mn></mml:mrow></mml:math></inline-formula> at 5 kb resolution) and projects the input to a <inline-formula id="IE2"><mml:math id="IM2" display="inline" overflow="scroll"><mml:mrow><mml:mi>w</mml:mi><mml:mo>×</mml:mo><mml:mi>w</mml:mi><mml:mo>×</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:math></inline-formula> embedding (<inline-formula id="IE3"><mml:math id="IM3" display="inline" overflow="scroll"><mml:mrow><mml:mi>d</mml:mi><mml:mo>=</mml:mo><mml:mn>24</mml:mn></mml:mrow></mml:math></inline-formula>). It is built with one rectified linear unit activated (ReLU-activated) convolution layer with <italic toggle="yes">d</italic> 9 × 9 filters. E1, E2, and E3 are three consecutive encoding blocks linked by a max pooling operator with a 2 × 2 kernel and a stride of 2 (i.e. downsampling by 50%). E1, E2, and E3 extract multi-scale features from the input contact maps. E1 is built with two ReLU-activated convolution layers with <italic toggle="yes">d</italic> 3 × 3 filters and a dropout layer with rate = 0.2 between convolution layers. It takes an input of dimension <inline-formula id="IE4"><mml:math id="IM4" display="inline" overflow="scroll"><mml:mrow><mml:mi>w</mml:mi><mml:mo>×</mml:mo><mml:mi>w</mml:mi><mml:mo>×</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:math></inline-formula> and produces an output of the same dimension. E2 is built with the same layers as E1, but it takes an input of dimension <italic toggle="yes">w</italic>/2 × <italic toggle="yes">w</italic>/2 × <italic toggle="yes">d</italic> and produces an output of the same dimension. E3 starts with a batch normalization layer and ends with a flatten layer. It contains three convolution layers: The first two contain <italic toggle="yes">d</italic> 3 × 3 filters, and the last contains one 3 × 3 filter. The first convolution layer in E3 is followed by a dropout layer with rate 0.2 and a max pooling operator with a 2 × 2 kernel and a stride of 2. We did not use batch normalization in blocks F, E1, and E2 as we observed it introduces artifacts in enhanced contact maps. E3 takes as input the downsampled output of E2 and produces embedding of dimension 1 × (w/8)<sup>2</sup>. The attention module (i.e. purple module) takes as query (Q) and keys (K) the outputs of E3, uses as values (V1 and V2) the outputs of E1 and E2 for the <italic toggle="yes">n</italic> reference samples. We define the attention weights <inline-formula id="IE5"><mml:math id="IM5" display="inline" overflow="scroll"><mml:mrow><mml:mo>α</mml:mo><mml:mo>=</mml:mo></mml:mrow></mml:math></inline-formula>softmax<inline-formula id="IE6"><mml:math id="IM6" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">Q</mml:mi><mml:msup><mml:mrow><mml:mi mathvariant="bold">K</mml:mi></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>×</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>, where <inline-formula id="IE7"><mml:math id="IM7" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mo>α</mml:mo></mml:mrow><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> represents the relative amount of attention paid to sample <italic toggle="yes">j</italic> in our reference panel when analyzing the study sample. The attention output <inline-formula id="IE8"><mml:math id="IM8" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">a</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE9"><mml:math id="IM9" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">a</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> at two levels are computed as:
where A1 and A2 are convolution blocks for attention outputs configured similarly to E1 and E2 but preceded by layer normalization. P1 and P2 are built with one ReLU-activated convolution layer with one 3 × 3 filter. They project the concatenation of study-sample embeddings (produced by E1 and E2) and attention embeddings (i.e. <inline-formula id="IE10"><mml:math id="IM10" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">a</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE11"><mml:math id="IM11" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">a</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>) to embeddings with <italic toggle="yes">d</italic> channels. D1 and D2 are built similarly to E2 and E1. D1 takes as input the output of P2; meanwhile, D2 takes as input the concatenation of the output of P1 and the upsampled output of D1. O is built with two ReLU-activated convolution layers with 3 <inline-formula id="IE12"><mml:math id="IM12" display="inline" overflow="scroll"><mml:mo>×</mml:mo></mml:math></inline-formula> 3 filters. It projects the concatenation of the output of F for the study sample and the output of D2 to an enhanced contact map.</p>
      <disp-formula id="E1">
        <label>(1)</label>
        <mml:math id="M1" display="block" overflow="scroll">
          <mml:mrow>
            <mml:mtable>
              <mml:mtr columnalign="left">
                <mml:mtd columnalign="left">
                  <mml:mrow>
                    <mml:msub>
                      <mml:mrow>
                        <mml:mi mathvariant="bold">a</mml:mi>
                      </mml:mrow>
                      <mml:mn>1</mml:mn>
                    </mml:msub>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mo>=</mml:mo>
                    <mml:mtext>softmax</mml:mtext>
                    <mml:mo stretchy="false">(</mml:mo>
                    <mml:mi mathvariant="bold">Q</mml:mi>
                    <mml:msup>
                      <mml:mrow>
                        <mml:mi mathvariant="bold">K</mml:mi>
                      </mml:mrow>
                      <mml:mi>T</mml:mi>
                    </mml:msup>
                    <mml:mo stretchy="false">)</mml:mo>
                    <mml:msub>
                      <mml:mrow>
                        <mml:mi mathvariant="bold">V</mml:mi>
                      </mml:mrow>
                      <mml:mn>1</mml:mn>
                    </mml:msub>
                    <mml:mo>+</mml:mo>
                    <mml:mi mathvariant="normal">A</mml:mi>
                    <mml:mn>1</mml:mn>
                    <mml:mo stretchy="false">(</mml:mo>
                    <mml:mtext>softmax</mml:mtext>
                    <mml:mo stretchy="false">(</mml:mo>
                    <mml:mi mathvariant="bold">Q</mml:mi>
                    <mml:msup>
                      <mml:mrow>
                        <mml:mi mathvariant="bold">K</mml:mi>
                      </mml:mrow>
                      <mml:mi>T</mml:mi>
                    </mml:msup>
                    <mml:mo stretchy="false">)</mml:mo>
                    <mml:msub>
                      <mml:mrow>
                        <mml:mi mathvariant="bold">V</mml:mi>
                      </mml:mrow>
                      <mml:mn>1</mml:mn>
                    </mml:msub>
                    <mml:mo stretchy="false">)</mml:mo>
                  </mml:mrow>
                </mml:mtd>
              </mml:mtr>
            </mml:mtable>
          </mml:mrow>
        </mml:math>
      </disp-formula>
      <disp-formula id="E2">
        <label>(2)</label>
        <mml:math id="M2" display="block" overflow="scroll">
          <mml:mrow>
            <mml:msub>
              <mml:mrow>
                <mml:mi mathvariant="bold">a</mml:mi>
              </mml:mrow>
              <mml:mn>2</mml:mn>
            </mml:msub>
            <mml:mo>=</mml:mo>
            <mml:mtext>softmax</mml:mtext>
            <mml:mo stretchy="false">(</mml:mo>
            <mml:mi mathvariant="bold">Q</mml:mi>
            <mml:msup>
              <mml:mrow>
                <mml:mi mathvariant="bold">K</mml:mi>
              </mml:mrow>
              <mml:mi>T</mml:mi>
            </mml:msup>
            <mml:mo stretchy="false">)</mml:mo>
            <mml:msub>
              <mml:mrow>
                <mml:mi mathvariant="bold">V</mml:mi>
              </mml:mrow>
              <mml:mn>2</mml:mn>
            </mml:msub>
            <mml:mo>+</mml:mo>
            <mml:mi mathvariant="normal">A</mml:mi>
            <mml:mn>2</mml:mn>
            <mml:mo stretchy="false">(</mml:mo>
            <mml:mtext>softmax</mml:mtext>
            <mml:mo stretchy="false">(</mml:mo>
            <mml:mi mathvariant="bold">Q</mml:mi>
            <mml:msup>
              <mml:mrow>
                <mml:mi mathvariant="bold">K</mml:mi>
              </mml:mrow>
              <mml:mi>T</mml:mi>
            </mml:msup>
            <mml:mo stretchy="false">)</mml:mo>
            <mml:msub>
              <mml:mrow>
                <mml:mi mathvariant="bold">V</mml:mi>
              </mml:mrow>
              <mml:mn>2</mml:mn>
            </mml:msub>
            <mml:mo stretchy="false">)</mml:mo>
          </mml:mrow>
        </mml:math>
      </disp-formula>
    </sec>
    <sec>
      <title>2.2 Hi-C data and preprocessing</title>
      <p>RefHiC-SR’s input for an individual sample (i.e. study or reference samples) is defined as a matrix in the shape of <italic toggle="yes">w</italic> × <italic toggle="yes">w</italic>, corresponding to the region of interest with a window of size <italic toggle="yes">w</italic>. <italic toggle="yes">w</italic> is a hyperparameter set to <inline-formula id="IE13"><mml:math id="IM13" display="inline" overflow="scroll"><mml:mrow><mml:mi>w</mml:mi><mml:mo>=</mml:mo><mml:mn>200</mml:mn></mml:mrow></mml:math></inline-formula> at 5 kb resolution. We trained RefHiC-SR with ICE-normalized iterative correction and eigenvector decomposition normalized (ICE-normalized) Hi-C contact maps. RefHiC-SR can also take raw data as input, but using raw data directly can lead to worse prediction due to systematic bias. For model training, we used Hi-C data downsampled from the combined GM12878 Hi-C contact map (<xref rid="btad266-B19" ref-type="bibr">Rao et al. 2014</xref>). The length of TADs and the distance between chromatin loop anchors are usually within 3 Mb. Thus, we restricted our analysis to contact pairs separated by at most 3 Mb. For inference of an entire chromosome, we will first split a contact map into partially overlapping squares <inline-formula id="IE14"><mml:math id="IM14" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> with width <italic toggle="yes">w</italic> indicated by top-left corner <inline-formula id="IE15"><mml:math id="IM15" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> and step <inline-formula id="IE16"><mml:math id="IM16" display="inline" overflow="scroll"><mml:mrow><mml:mi>w</mml:mi><mml:mo>−</mml:mo><mml:mn>20</mml:mn></mml:mrow></mml:math></inline-formula>, where <inline-formula id="IE17"><mml:math id="IM17" display="inline" overflow="scroll"><mml:mrow><mml:mi>j</mml:mi><mml:mo>≥</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:math></inline-formula>. We then apply the trained model to enhance each square. The width of the predicted squares is also <italic toggle="yes">w</italic>. Finally, we extract a <inline-formula id="IE18"><mml:math id="IM18" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>w</mml:mi><mml:mo>−</mml:mo><mml:mn>20</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>×</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>w</mml:mi><mml:mo>−</mml:mo><mml:mn>20</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> matrix by trimming each side to address discontinuity between adjacency matrices. The full-chromosome super-resolution contact map is obtained by tiling the super-resolution submatrices.</p>
    </sec>
    <sec>
      <title>2.3 Model training</title>
      <p>We trained, evaluated, and tested RefHiC-SR on contact maps downsampled from the combined GM12878 Hi-C data. We used chr11 and chr12 for validation, Chromosomes 15–17 for testing, and the rest of autosomes for training. After preparing the input data as mentioned above, we collected 6918, 798, and 813 200 × 200 blocks for training, validation, and testing. RefHiC-SR takes submatrices from the study and reference samples as input in the forward pass. To reduce training computation, we sampled 10 reference samples for each example in each epoch independently. During evaluation, we used all samples in the reference panel. We trained models with a batch size of 46 for 2000 epochs on an RTX6000 GPU and used AdamW optimizer (<xref rid="btad266-B15" ref-type="bibr">Loshchilov and Hutter 2017</xref>; weight_decay = 0.1; learning rate = 1<italic toggle="yes">e</italic>−3). We also used early stopping to prevent overfitting. In the first five training epochs, we warmed up the learning rate from 0 to the initial learning rate (i.e. 1<italic toggle="yes">e</italic>−3) and then reduced the learning rate to 1<italic toggle="yes">e</italic>−6 in the first 95% epochs using the cosine annealing learning rate scheduler. Following RefHiC (<xref rid="btad266-B27" ref-type="bibr">Zhang and Blanchette 2022</xref>), we performed data augmentation by downsampling Hi-C contact maps during training. This transformation preserves topological structures in Hi-C data. Briefly, we downsampled Hi-C training data and stored them on disk in advance. During training, we randomly selected one contact map from these downsampled contact maps for each training example in each epoch independently. We used L1 loss to train RefHiC-SR. It is simple and less prone to be over-smooth.</p>
    </sec>
    <sec>
      <title>2.4 Contrastive pretraining</title>
      <p>We pretrained low-level feature extraction block (F) and encoding blocks (E1–E3) by supervised contrastive learning (<xref rid="btad266-B6" ref-type="bibr">Gao et al. 2021</xref>) using Hi-C contact maps downsampled from the combined GM12878 Hi-C data. For each training example, we defined items extracted from the downsampled contact maps at the same region as similar items and all Hi-C contact map submatrices in the same batch at other regions as negative items. We aimed to train these layers such that the distances of embeddings produced by E3 for a training example and its similar items are as close as possible while of embeddings between a training example and its negative items are as far as possible. Following (<xref rid="btad266-B6" ref-type="bibr">Gao et al. 2021</xref>), we defined the loss for training instance <italic toggle="yes">i</italic> as cross-entropy with in-batch negatives:
where <inline-formula id="IE19"><mml:math id="IM19" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">h</mml:mi></mml:mrow><mml:mi mathvariant="bold">i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, <inline-formula id="IE20"><mml:math id="IM20" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">h</mml:mi></mml:mrow><mml:mi mathvariant="bold">i</mml:mi><mml:mo>+</mml:mo></mml:msubsup></mml:mrow></mml:math></inline-formula>, and <inline-formula id="IE21"><mml:math id="IM21" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">h</mml:mi></mml:mrow><mml:mi mathvariant="bold">j</mml:mi><mml:mo>−</mml:mo></mml:msubsup></mml:mrow></mml:math></inline-formula> are embeddings: <inline-formula id="IE22"><mml:math id="IM22" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">h</mml:mi></mml:mrow><mml:mi mathvariant="bold">i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> represents item <italic toggle="yes">i</italic>, <inline-formula id="IE23"><mml:math id="IM23" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">h</mml:mi></mml:mrow><mml:mi mathvariant="bold">i</mml:mi><mml:mo>+</mml:mo></mml:msubsup></mml:mrow></mml:math></inline-formula> represents one of item <italic toggle="yes">i’</italic>s similar items, <inline-formula id="IE24"><mml:math id="IM24" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">h</mml:mi></mml:mrow><mml:mi mathvariant="bold">j</mml:mi><mml:mo>−</mml:mo></mml:msubsup></mml:mrow></mml:math></inline-formula> represents an item with a label different from <italic toggle="yes">i</italic> (i.e. negative item). <inline-formula id="IE25"><mml:math id="IM25" display="inline" overflow="scroll"><mml:mo>τ</mml:mo></mml:math></inline-formula> is a temperature that controls training, and we set it as 1. We pretrained the encoder for 20 epochs with the LARS using Adam as a base optimizer. We set batch size to 46 and learning rate to 1<italic toggle="yes">e</italic>−3 during training.</p>
      <disp-formula id="E3">
        <label>(3)</label>
        <mml:math id="M3" display="block" overflow="scroll">
          <mml:mrow>
            <mml:msub>
              <mml:mrow>
                <mml:mi>l</mml:mi>
              </mml:mrow>
              <mml:mi>i</mml:mi>
            </mml:msub>
            <mml:mo>=</mml:mo>
            <mml:mo>−</mml:mo>
            <mml:mtext>log</mml:mtext>
            <mml:mo> </mml:mo>
            <mml:mfrac>
              <mml:mrow>
                <mml:msup>
                  <mml:mrow>
                    <mml:mi>e</mml:mi>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mtext>sim</mml:mtext>
                    <mml:mo stretchy="false">(</mml:mo>
                    <mml:msub>
                      <mml:mrow>
                        <mml:mi mathvariant="bold">h</mml:mi>
                      </mml:mrow>
                      <mml:mi mathvariant="bold">i</mml:mi>
                    </mml:msub>
                    <mml:mo>,</mml:mo>
                    <mml:msubsup>
                      <mml:mrow>
                        <mml:mi mathvariant="bold">h</mml:mi>
                      </mml:mrow>
                      <mml:mi mathvariant="bold">i</mml:mi>
                      <mml:mo>+</mml:mo>
                    </mml:msubsup>
                    <mml:mo stretchy="false">)</mml:mo>
                    <mml:mo>/</mml:mo>
                    <mml:mo>τ</mml:mo>
                  </mml:mrow>
                </mml:msup>
              </mml:mrow>
              <mml:mrow>
                <mml:msup>
                  <mml:mrow>
                    <mml:mi>e</mml:mi>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mtext>sim</mml:mtext>
                    <mml:mo stretchy="false">(</mml:mo>
                    <mml:msub>
                      <mml:mrow>
                        <mml:mi mathvariant="bold">h</mml:mi>
                      </mml:mrow>
                      <mml:mi mathvariant="bold">i</mml:mi>
                    </mml:msub>
                    <mml:mo>,</mml:mo>
                    <mml:msubsup>
                      <mml:mrow>
                        <mml:mi mathvariant="bold">h</mml:mi>
                      </mml:mrow>
                      <mml:mi mathvariant="bold">i</mml:mi>
                      <mml:mo>+</mml:mo>
                    </mml:msubsup>
                    <mml:mo stretchy="false">)</mml:mo>
                    <mml:mo>/</mml:mo>
                    <mml:mo>τ</mml:mo>
                  </mml:mrow>
                </mml:msup>
                <mml:mo>+</mml:mo>
                <mml:munder>
                  <mml:mo>∑</mml:mo>
                  <mml:mrow>
                    <mml:mi>j</mml:mi>
                    <mml:menclose notation="updiagonalstrike">
                      <mml:mo>=</mml:mo>
                    </mml:menclose>
                    <mml:mi>i</mml:mi>
                  </mml:mrow>
                </mml:munder>
                <mml:mrow>
                  <mml:msup>
                    <mml:mrow>
                      <mml:mi>e</mml:mi>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mtext>sim</mml:mtext>
                      <mml:mo stretchy="false">(</mml:mo>
                      <mml:msub>
                        <mml:mrow>
                          <mml:mi mathvariant="bold">h</mml:mi>
                        </mml:mrow>
                        <mml:mi mathvariant="bold">i</mml:mi>
                      </mml:msub>
                      <mml:mo>,</mml:mo>
                      <mml:msubsup>
                        <mml:mrow>
                          <mml:mi mathvariant="bold">h</mml:mi>
                        </mml:mrow>
                        <mml:mi mathvariant="bold">j</mml:mi>
                        <mml:mo>−</mml:mo>
                      </mml:msubsup>
                      <mml:mo stretchy="false">)</mml:mo>
                      <mml:mo>/</mml:mo>
                      <mml:mo>τ</mml:mo>
                    </mml:mrow>
                  </mml:msup>
                </mml:mrow>
              </mml:mrow>
            </mml:mfrac>
          </mml:mrow>
        </mml:math>
      </disp-formula>
    </sec>
    <sec>
      <title>2.5 Evaluation metrics</title>
      <p>We extensively compared the performance of RefHiC-SR with alternative tools using different metrics, including MSE, mean absolute error (MAE, a.k.a. L1), Pearson correlation coefficient (PCC), Spearman rank correlation coefficient (SRCC), and widely used metric in super-resolution image analysis, including structural similarity index measure (SSIM) score, and peak signal to noise ratio (PSNR) score (<xref rid="btad266-B7" ref-type="bibr">Hong et al. 2019</xref>) for each of the 200 × 200 submatrix predicted by each tool.</p>
      <p>We compared super-resolution to high-resolution Hi-C contact maps with HiCRep (<xref rid="btad266-B12" ref-type="bibr">Lin et al. 2021</xref>). HiCRep measures the reproducibility of two Hi-C experiments by computing a stratified correlation coefficient (PCC) for two contact maps. Its score ranges from −1 to 1 where a high value indicates high reproducibility. In addition to using PCC to compute HiCRep scores, we also computed HiCRep scores with SRCC.</p>
    </sec>
    <sec>
      <title>2.6 Hi-C data downsampling and Hi-C reference panel</title>
      <p>We used the original and six-level downsampled data of the combined Hi-C contact map for GM12878 cells obtained from <xref rid="btad266-B19" ref-type="bibr">Rao et al. (2014)</xref> to train RefHiC-SR. The reference panel that contains 30 human Hi-C contact map are used to train and evaluate RefHiC-SR. We excluded samples that belong to the study sample’s cell type from the reference panel to prevent potential data leakage.</p>
    </sec>
    <sec>
      <title>2.7 Hyperparameter tuning</title>
      <p>We first evaluate the performance of different convolution blocks in RefHiC-SR by adjusting convolution layer numbers in each block and adding residual connections. We configured most blocks with two convolution layers. Following (<xref rid="btad266-B28" ref-type="bibr">Zhang et al. 2018</xref>; <xref rid="btad266-B7" ref-type="bibr">Hong et al. 2019</xref>), we used 3 × 3 filters in all internal convolution layers, but tested different filter sizes (i.e. 3 × 3, 5 × 5, 9 × 9, and 13 × 13) for the first and last convolution layers. We compared validation errors and determined the optimal filter size as 9 × 9 for both layers. We also compared RefHiC-SR trained with MSE and L1 loss. We observed the model trained with MSE loss overly smooth predictions.</p>
    </sec>
    <sec>
      <title>2.8 Contact map enhancement with alternative tools</title>
      <p>We re-trained HiCPlus, HiCCNN, and DeepHiC with the same data as we used to train RefHiC-SR. Following previous work (<xref rid="btad266-B28" ref-type="bibr">Zhang et al. 2018</xref>; <xref rid="btad266-B7" ref-type="bibr">Hong et al. 2019</xref>; <xref rid="btad266-B14" ref-type="bibr">Liu and Wang 2019</xref>), we trained each model by splitting Hi-C contact maps into 40 × 40 blocks. To train HiCPlus and HiCNN, we adjusted learning rate and used early stopping to prevent overfitting and set other hyperparameters as default. We trained HiCPlus (<xref rid="btad266-B28" ref-type="bibr">Zhang et al. 2018</xref>) for 30 000 epochs with a learning rate of 1<italic toggle="yes">e</italic>−3 and a batch size of 256. We trained HiCNN (<xref rid="btad266-B14" ref-type="bibr">Liu and Wang 2019</xref>) and DeepHiC (<xref rid="btad266-B7" ref-type="bibr">Hong et al. 2019</xref>) for 1000 epochs with a learning rate of 1<italic toggle="yes">e</italic>−4 and a batch size of 256. The maximum training epochs we used are much larger than their original setting, and training losses indicated all models were converged. DeepHiC’s discriminator is too strong to provide gradients to the generator with its original training procedure in our experiment. We changed the discriminative loss weight to 0.0001 and updated the discriminator every ten epochs. Once trained, we applied each model to 200 × 200 overlapped blocks to enhance a whole contact map. Same as RefHiC-SR, we cropped the prediction into a matrix of 180 × 180.</p>
    </sec>
  </sec>
  <sec>
    <title>3 Results</title>
    <p>We introduce RefHiC-SR, a reference panel-informed DL approach for enhancing Hi-C contact maps. Similar to RefHiC (<xref rid="btad266-B27" ref-type="bibr">Zhang and Blanchette 2022</xref>), it utilizes a reference panel containing 30 high-quality Hi-C datasets from multiple human cell types (<xref rid="sup1" ref-type="supplementary-material">Supplementary Table S1</xref>) and employs an attention mechanism to determine which reference samples are most relevant for a given <italic toggle="yes">w</italic> × <italic toggle="yes">w</italic> region of the contact map of the study sample. The enhanced contact map at a given region is then inferred based on a combination of the study sample and the attention-weighted reference samples. RefHiC-SR takes as input a typical ICE normalized (<xref rid="btad266-B8" ref-type="bibr">Imakaev et al. 2012</xref>; <xref rid="btad266-B1" ref-type="bibr">Abdennur and Mirny 2020</xref>) moderate-coverage (sparse) Hi-C contact map and outputs a high-coverage (dense) contact map prediction. Both input and output contact maps are at high resolution (i.e. 5-kb bins). The resulting prediction is referred to as enhanced or super-resolution contact maps. We divided the human autosomes into a training set (Chromosomes 1–10, 13, 14, and 18–22), a validation set (Chromosomes 11 and 12), and a test set (Chromosomes 15–17). All results reported here pertain only to the three test chromosomes. Although we trained RefHiC-SR on GM12878 cells, the model learned is not cell-type specific. We will demonstrate in a later section that we can use the same model to enhance Hi-C data of other cells.</p>
    <p>RefHiC-SR’s neural network takes as input a matrix of 200 bins by 200 bins, and outputs a super-resolution matrix of the same dimension. When applying a trained model to full-chromosome contact map enhancement, we extract from the output matrix a 180 × 180 matrix by trimming each side to address discontinuity between adjacency matrices. The full-chromosome super-resolution contact map is obtained by tiling the super-resolution submatrices. Other super-resolution tools were applied in the same manner.</p>
    <sec>
      <title>3.1 RefHiC-SR accurately enhances low-coverage contact maps</title>
      <p>We first assessed the contact map enhancement performance of RefHiC-SR, in comparison to three approaches: HiCPlus, HiCNN, and DeepHiC on test Chromosomes 15–17 of GM12878 cells. Each model represents one of the three types of DL models in contact map enhancement (i.e. shallow model, deep model, and GAN), with DeepHiC featured as the state-of-the-art model in several studies. We used as input a 5-kb resolution Hi-C dataset produced from 250-M valid read pairs, obtained by downsampling a Hi-C dataset for human GM12878 cells (<xref rid="btad266-B19" ref-type="bibr">Rao et al. 2014</xref>). This is equivalent to a 1/16 downsampling that most existing tools were trained and evaluated at. As existing models are trained from data at 10-kb resolution and with different normalization approaches, it is impractical to benchmark trained models on the same data at 5 kb. Thus, we retrained HiCPlus, HiCNN, and DeepHiC with the same set of training data as we used to train RefHiC-SR (see Section 2). The accuracy of the enhanced contact maps is assessed by comparing it to the full coverage contact map, using seven metrics: (i) MSE, (ii) MAE, (iii) PSNR (<xref rid="btad266-B13" ref-type="bibr">Liu et al. 2019</xref>), (iv) the SSIM (<xref rid="btad266-B7" ref-type="bibr">Hong et al. 2019</xref>), (v) the diagonal-wise PCC, (vi) the diagonal-wise SRCC, and (vii) the HiCRep score (<xref rid="btad266-B26" ref-type="bibr">Yang et al. 2017</xref>) for Hi-C data comparison.</p>
      <p><xref rid="btad266-F2" ref-type="fig">Figure 2a</xref> and <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S1</xref> illustrate the full coverage (target), low coverage (input), and enhanced contact maps and their differences on a typical 1-Mb genomic region (chr17:5000000–6000000). We observed that all enhanced contact maps better match the full coverage contact map than the low-coverage contact map does, with a slightly advantage for RefHiC-SR. RefHiC-SR and DeepHiC are better capturing fine-scale structures such as loops. We then compared the prediction quality on test Chromosomes 15–17. The diagonal-wise PCC and SRCC between the enhanced and full coverage contact maps (<xref rid="btad266-F2" ref-type="fig">Fig. 2b and c and</xref><xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S10</xref>), show that RefHiC-SR is comparable to or outperforms existing tools across all distance ranges. We then compared RefHiC-SR with existing tools at individual 180 × 180 submatrices. The distributions of MSE (<xref rid="btad266-F2" ref-type="fig">Fig. 2d</xref>), MAE (<xref rid="btad266-F2" ref-type="fig">Fig. 2e</xref>), PSNR (<xref rid="btad266-F2" ref-type="fig">Fig. 2f</xref>), and SSIM (<xref rid="btad266-F2" ref-type="fig">Fig. 2g</xref>) show that all tools achieve similar performance, with a slight advantage for RefHiC-SR. Finally, we compared the similarity of super-resolution and full coverage contact maps at the whole-chromosome level with HiCRep (<xref rid="btad266-B26" ref-type="bibr">Yang et al. 2017</xref>). <xref rid="btad266-T1" ref-type="table">Table 1</xref> shows HiCRep scores for test chromosomes. It indicates that RefHiC-SR is among the best across test chromosomes.</p>
      <fig position="float" id="btad266-F2">
        <label>Figure 2.</label>
        <caption>
          <p>Comparison of RefHiC-SR and other tools on GM12878 Hi-C data (250-M valid read pairs, test Chromosomes 15–17). a. Examples of full coverage, low coverage, and enhanced contact maps on a 1-Mb genomic region (chr17:5000000–6000000) and a zoom in portion. Diagonal-wise PCC (b) and SRCC (c). Boxplots of MSE (d), MAE (e), PSNR (f), and SSIM (g) between full coverage and enhanced contact maps.</p>
        </caption>
        <graphic xlink:href="btad266f2" position="float"/>
      </fig>
      <table-wrap position="float" id="btad266-T1">
        <label>Table 1.</label>
        <caption>
          <p>HiCRep scores between high-coverage and 1/16 downsampled (low coverage)/enhanced contact maps of GM12878 cells.<xref rid="tblfn1" ref-type="table-fn"><sup>a</sup></xref></p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1"/>
              <th rowspan="1" colspan="1">PCC</th>
              <th rowspan="1" colspan="1"/>
              <th rowspan="1" colspan="1"/>
              <th rowspan="1" colspan="1">SRCC</th>
              <th rowspan="1" colspan="1"/>
              <th rowspan="1" colspan="1"/>
            </tr>
            <tr>
              <th rowspan="1" colspan="1"/>
              <th rowspan="1" colspan="1">chr15</th>
              <th rowspan="1" colspan="1">chr16</th>
              <th rowspan="1" colspan="1">chr17</th>
              <th rowspan="1" colspan="1">chr15</th>
              <th rowspan="1" colspan="1">chr16</th>
              <th rowspan="1" colspan="1">chr17</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">RefHiC-SR</td>
              <td rowspan="1" colspan="1"><bold>0.898</bold> ± <bold>0.001</bold></td>
              <td rowspan="1" colspan="1"><bold>0.865</bold> ± <bold>0.001</bold></td>
              <td rowspan="1" colspan="1"><bold>0.877</bold> ± <bold>0.003</bold></td>
              <td rowspan="1" colspan="1"><bold>0.845</bold> ± <bold>3e</bold>−<bold>4</bold></td>
              <td rowspan="1" colspan="1">
                <bold>0.845</bold>
                <inline-formula id="IE26">
                  <mml:math id="IM26" display="inline" overflow="scroll">
                    <mml:mo>±</mml:mo>
                  </mml:math>
                </inline-formula>
                <bold>3e−4</bold>
              </td>
              <td rowspan="1" colspan="1">0.824<inline-formula id="IE27"><mml:math id="IM27" display="inline" overflow="scroll"><mml:mo>±</mml:mo></mml:math></inline-formula>0.001</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">DeepHiC</td>
              <td rowspan="1" colspan="1">0.884 ± 6e−4</td>
              <td rowspan="1" colspan="1">0.842 ± 0.001</td>
              <td rowspan="1" colspan="1">0.863 ± 0.004</td>
              <td rowspan="1" colspan="1">0.833 ± 5e−4</td>
              <td rowspan="1" colspan="1">0.830<inline-formula id="IE28"><mml:math id="IM28" display="inline" overflow="scroll"><mml:mo>±</mml:mo></mml:math></inline-formula>4e−4</td>
              <td rowspan="1" colspan="1">0.820<inline-formula id="IE29"><mml:math id="IM29" display="inline" overflow="scroll"><mml:mo>±</mml:mo></mml:math></inline-formula>9e−4</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">HiCNN</td>
              <td rowspan="1" colspan="1">0.888 ± 6e−4</td>
              <td rowspan="1" colspan="1">0.847 ± 0.001</td>
              <td rowspan="1" colspan="1">0.867 ± 0.003</td>
              <td rowspan="1" colspan="1">0.844 ± 4e−4</td>
              <td rowspan="1" colspan="1">0.844<inline-formula id="IE30"><mml:math id="IM30" display="inline" overflow="scroll"><mml:mo>±</mml:mo></mml:math></inline-formula>3e−4</td>
              <td rowspan="1" colspan="1">
                <bold>0.830</bold>
                <inline-formula id="IE31">
                  <mml:math id="IM31" display="inline" overflow="scroll">
                    <mml:mo>±</mml:mo>
                  </mml:math>
                </inline-formula>
                <bold>8e−4</bold>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">HiCPlus</td>
              <td rowspan="1" colspan="1">0.865 ± 4e−4</td>
              <td rowspan="1" colspan="1">0.823 ± 0.001</td>
              <td rowspan="1" colspan="1">0.845 ± 0.003</td>
              <td rowspan="1" colspan="1">0.807 ± 5e−4</td>
              <td rowspan="1" colspan="1">0.804<inline-formula id="IE32"><mml:math id="IM32" display="inline" overflow="scroll"><mml:mo>±</mml:mo></mml:math></inline-formula>5e−4</td>
              <td rowspan="1" colspan="1">0.792<inline-formula id="IE33"><mml:math id="IM33" display="inline" overflow="scroll"><mml:mo>±</mml:mo></mml:math></inline-formula>0.001</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Low coverage (input)</td>
              <td rowspan="1" colspan="1">0.643 ± 0.001</td>
              <td rowspan="1" colspan="1">0.632 ± 0.002</td>
              <td rowspan="1" colspan="1">0.661 ± 0.002</td>
              <td rowspan="1" colspan="1">0.559 ± 5e−4</td>
              <td rowspan="1" colspan="1">0.564<inline-formula id="IE34"><mml:math id="IM34" display="inline" overflow="scroll"><mml:mo>±</mml:mo></mml:math></inline-formula>4e−4</td>
              <td rowspan="1" colspan="1">0.558<inline-formula id="IE35"><mml:math id="IM35" display="inline" overflow="scroll"><mml:mo>±</mml:mo></mml:math></inline-formula>6e−4</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn1">
            <label>a</label>
            <p>HiCRep scores are computed with PCC and SRCC metrics. We computed the standard deviations by repeating the analysis five times on data downsampled with different random seeds.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
    </sec>
    <sec>
      <title>3.2 RefHiC-SR is robust to sequencing depths</title>
      <p>To benchmark RefHiC-SR’s ability to enhance contact maps from Hi-C data at different sequencing depths, we produced downsampled versions (i.e. 1/2, 1/4,…, 1/64, where 1/64 = 62.5 M valid read pairs) of the same GM12878 contact map (<xref rid="btad266-B19" ref-type="bibr">Rao et al. 2014</xref>) and applied RefHiC-SR and other tools to enhance contact map resolutions for test chromosomes. We evaluated the accuracy of enhanced contact maps by comparing them against the full coverage contact maps using HiCRep. Although lower sequencing depths led to less accurate enhancement for all tools (<xref rid="btad266-F3" ref-type="fig">Fig. 3</xref>), RefHiC-SR was most robust to low sequencing depths, clearly outperforming other tools at very low coverage (1/32 = 125 M and 1/64 = 62.5 M). For Hi-C data containing &lt;250 M valid read pairs, RefHiC-SR can produce predictions comparable to the second best tool using only half of the read pairs. To study the performance of each tool at the most extreme case (i.e. 1/64 downsampled data), we repeated the battery of tests originally performed at 1/16 = 250 M downsampled data (<xref rid="sup1" ref-type="supplementary-material">Supplementary Figs S2 and S10</xref>). We observed RefHiC-SR performed the best on all metrics.</p>
      <fig position="float" id="btad266-F3">
        <label>Figure 3.</label>
        <caption>
          <p>Average HiCRep scores from test Chromosomes 15–17 from the GM12878 cell line across downsampling ratios 1/2, 1/4…1/64. HiCRep scores are computed with PCC (a) and SRCC (b) metrics.</p>
        </caption>
        <graphic xlink:href="btad266f3" position="float"/>
      </fig>
    </sec>
    <sec>
      <title>3.3 RefHiC-SR performs well across cell types</title>
      <p>Next, we aimed to assess the performance of RefHiC-SR and other tools, which were all trained on Hi-C data obtained from GM12878 cells, on data from other cell types. We applied each model to the enhancement of Hi-C data from IMR90 and K562 (<xref rid="btad266-B19" ref-type="bibr">Rao et al. 2014</xref>) cell lines (test Chromosomes 15–17 only). We used HiCRep, MAE, MSE, PSNR, and SSIM to evaluate model performance. <xref rid="btad266-T2" ref-type="table">Table 2</xref> shows that RefHiC-SR outperformed other tools by achieving the highest HiCRep scores in both cells. <xref rid="sup1" ref-type="supplementary-material">Supplementary Figs S8 and S9</xref> show that RefHiC-SR outperformed or was comparable to other tools in both cells as evaluated by super-resolution image analysis metrics.</p>
      <table-wrap position="float" id="btad266-T2">
        <label>Table 2.</label>
        <caption>
          <p>HiCRep scores between high- and low-coverage/enhanced contact maps of IMR-90 and K562 cells.<xref rid="tblfn2" ref-type="table-fn"><sup>a</sup></xref></p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="2" colspan="1"/>
              <th colspan="3" align="center" rowspan="1">IMR90<hr/></th>
              <th colspan="3" align="center" rowspan="1">K562<hr/></th>
            </tr>
            <tr>
              <th align="center" rowspan="1" colspan="1">chr15</th>
              <th align="center" rowspan="1" colspan="1">chr16</th>
              <th align="center" rowspan="1" colspan="1">chr17</th>
              <th align="center" rowspan="1" colspan="1">chr15</th>
              <th align="center" rowspan="1" colspan="1">chr16</th>
              <th align="center" rowspan="1" colspan="1">chr17</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">RefHiC-SR</td>
              <td rowspan="1" colspan="1">
                <bold>0.868</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.850</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.878</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.813</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.817</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.825</bold>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">DeepHiC</td>
              <td rowspan="1" colspan="1">0.858</td>
              <td rowspan="1" colspan="1">0.839</td>
              <td rowspan="1" colspan="1">0.866</td>
              <td rowspan="1" colspan="1">0.799</td>
              <td rowspan="1" colspan="1">0.810</td>
              <td rowspan="1" colspan="1">0.812</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">HiCNN</td>
              <td rowspan="1" colspan="1">0.861</td>
              <td rowspan="1" colspan="1">0.842</td>
              <td rowspan="1" colspan="1">0.870</td>
              <td rowspan="1" colspan="1">0.802</td>
              <td rowspan="1" colspan="1">0.804</td>
              <td rowspan="1" colspan="1">0.811</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">HiCPlus</td>
              <td rowspan="1" colspan="1">0.858</td>
              <td rowspan="1" colspan="1">0.840</td>
              <td rowspan="1" colspan="1">0.866</td>
              <td rowspan="1" colspan="1">0.812</td>
              <td rowspan="1" colspan="1">0.817</td>
              <td rowspan="1" colspan="1">0.824</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Low coverage (input)</td>
              <td rowspan="1" colspan="1">0.716</td>
              <td rowspan="1" colspan="1">0.697</td>
              <td rowspan="1" colspan="1">0.722</td>
              <td rowspan="1" colspan="1">0.788</td>
              <td rowspan="1" colspan="1">0.787</td>
              <td rowspan="1" colspan="1">0.806</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn2">
            <label>a</label>
            <p>HiCRep scores are computed with PCC metrics.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
    </sec>
    <sec>
      <title>3.4 RefHiC-SR enables improved loop and TAD boundary annotation</title>
      <p>RefHiC-SR and other resolution enhancement tools are meant to ease downstream analyses, such as TAD and loop annotation, by imputing missing signals in contact maps. Here we show that RefHiC-SR facilitates annotating TAD and loop with off-the-shelf annotation tools, without introducing many false positives.</p>
      <p>We first assessed the ability of RefHiC-SR to produce enhanced maps that enable high-accuracy loop prediction. We applied Mustache (<xref rid="btad266-B20" ref-type="bibr">Roayaei Ardakany et al. 2020</xref>) to annotate loops from the original full coverage GM12878 contact map, the 1/16 downsampled contact map, and enhanced contact maps produced by different tools. For each analysis, we set the same Mustache 5% false discovery rate (FDR) cutoff, keeping other parameters as default, and sorted loops by Mustache-reported FDR. We also included predictions made by RefHiC (<xref rid="btad266-B27" ref-type="bibr">Zhang and Blanchette 2022</xref>) for comparison. The number of predicted loops is quite different among different inputs, with DeepHiC leading to the largest number of predictions (<xref rid="btad266-F4" ref-type="fig">Fig. 4a</xref>). We then evaluated predicted loops by comparing them to loops identified by loop-targeting experimental data [ChIA-PET on CTCF (CCCTC-binding factor) (<xref rid="btad266-B23" ref-type="bibr">Tang et al. 2015</xref>) and RAD21 (ENCODE Project Consortium et al. 2012), and HiChiP on SMC1 (<xref rid="btad266-B16" ref-type="bibr">Mumbach et al. 2016</xref>) and H3K27ac (<xref rid="btad266-B17" ref-type="bibr">Mumbach et al. 2017</xref>)], allowing up to a 5-kb shift (<xref rid="btad266-F4" ref-type="fig">Fig. 4b–e</xref>). When applied to enhanced contact maps, Mustache produced 1245 CTCF-supported loops, 761 RAD21-supported loops, 512 SMC1-supported loops, and 197 H3K27ac-supported loops from RefHiC-SR enhanced contact maps. These numbers exceed those obtained on enhanced maps produced by other tools by 25%–550%, and even those obtained on the full coverage data itself. The accuracy of loop annotated from RefHiC-SR enhanced contact maps is comparable to annotating loops from the full coverage data. In contrast, contact maps enhanced by alternative tools introduced a large number of false positive loop predictions. The combination of RefHiC-SR and Mustache was only beat by RefHiC slightly. We next evaluated the extent to which RefHiC-SR facilitates loop annotation from Hi-C contact maps containing different numbers of valid read pairs. Unexpectedly, coverage reduction leads to an increase in the number of loops being predicted on most tools’ enhanced maps (including RefHiC-SR enhanced, <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S3</xref>). <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S4</xref> shows that as the coverage drops from 256 to 62.5 M valid read pairs, the number of experimentally supported predicted loops remains similar when Mustache is applied to RefHiC-SR enhanced contact maps, but drops significantly using enhanced maps produced by other super-resolution tools.</p>
      <fig position="float" id="btad266-F4">
        <label>Figure 4.</label>
        <caption>
          <p>Comparison of loops and TADs annotated from low coverage, full coverage, and enhanced contact maps. (a) Number of loop annotations. (b–e) Number of ChIA-PET/HiCHIP-supported loop predictions compared against CTCF ChIA-PET (b), SMC1 HiCHIP (c), RAD21 ChIA-PET (d), and H3K27ac HiCHIP (e). Occupancy of ChIP-seq identified CTCF binding site as a function of distance to left (g) and right (h) boundary annotations.</p>
        </caption>
        <graphic xlink:href="btad266f4" position="float"/>
      </fig>
      <p>To evaluate RefHiC-SR’s usefulness for facilitating TAD annotation, we used RobusTAD (<xref rid="btad266-B5" ref-type="bibr">Dali et al. 2018</xref>) to annotate TAD boundaries from the same set of contact maps as above. We also included predictions made by RefHiC (<xref rid="btad266-B27" ref-type="bibr">Zhang and Blanchette 2022</xref>) for comparison. RefHiC made the least predictions. The number of predicted TAD boundaries is similar among full coverage Hi-C data and super-resolution inputs (<xref rid="btad266-F4" ref-type="fig">Fig. 4f</xref>). <xref rid="btad266-F4" ref-type="fig">Figure 4g and h</xref> shows that RobusTAD identified a similar total number of CTCF-supported TAD boundaries from RefHiC-enhanced and full coverage contact maps. In contrast, contact maps enhanced by alternative tools lead to fewer CTCF-supported TAD boundaries. Annotating TAD boundaries from contact maps enhanced from low-coverage data show that boundary annotation is robust to sequencing coverage (<xref rid="sup1" ref-type="supplementary-material">Supplementary Figs S5 and S6</xref>). <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S6</xref> shows that at very low coverage, RefHiC-SR can still help to identify a large number of CTCF-supported TAD boundaries.</p>
      <p>We then repeated the analysis on Hi-C datasets for K562 and IMR-90 cells. <xref rid="sup1" ref-type="supplementary-material">Supplementary Figs S12 and S13</xref> show RefHiC-SR outperformed alternative methods in both loop and TAD annotations.</p>
    </sec>
    <sec>
      <title>3.5 RefHiC-SR implementation</title>
      <p>RefHiC-SR is a Python program available at <ext-link xlink:href="https://github.com/BlanchetteLab/RefHiC" ext-link-type="uri">https://github.com/BlanchetteLab/RefHiC</ext-link> with scripts to reproduce our experiments. We implemented the neural network with the PyTorch library (<xref rid="btad266-B18" ref-type="bibr">Paszke et al. 2019)</xref>. RefHiC-SR can run on either a CPU or GPU, but it performs three times faster on GPU. RefHiC-SR requires at least 3 GB of storage space for saving reference panel data and at least 15-GB RAM for loading reference samples during prediction. RefHiC-SR is efficient and can process the longest human chromosome within 3 min when run on a GPU.</p>
    </sec>
  </sec>
  <sec>
    <title>4 Discussion</title>
    <p>Here, we present RefHiC-SR, a DL framework that utilizes a reference panel to facilitate enhancing Hi-C data resolution for a given study sample. In contrast, existing contact map enhancement algorithms are exclusively study-sample based, and hence their ability to reliably enhance contact maps from typical sequencing depth Hi-C data is limited. Our extensive evaluation demonstrated that RefHiC-SR outperforms existing tools in datasets ranging from very high to very low sequencing coverage, with the most striking improvements observed in the latter case. RefHiC-SR also outperformed a simple global similarity-based baseline (<xref rid="sup1" ref-type="supplementary-material">Supplementary Note S2</xref>), indicating the necessity of designing this model to incorporate the reference panel. Although RefHiC-SR is a machine-learning model trained primarily on GM12878 Hi-C data, the same trained model is effective on different cell types, and at different levels of coverage. Comparison between RefHiC-SR and a Baseline model similar to RefHiC-SR but lacking a reference panel shows RefHiC-SR’s superior to the introduction of a reference panel (<xref rid="sup1" ref-type="supplementary-material">Supplementary Note S1</xref>). The super-resolution contact maps predicted by RefHiC-SR are ready for downstream analysis and do not introduce a significant number of false positives. In contrast, other enhancement tools often introduce false positive annotations in downstream analysis.</p>
    <p>Across the different subfields of data-driven biology, researchers have developed many reference panel enabled approaches to aid the analysis of a study sample. RefHiC-SR is the first approach to enable this type of reference panel based analysis of 3D contact map enhancement. In addition, RefHiC-SR is the only contact map enhancement model that is robust to low sequencing coverage. We believe RefHiC-SR has the potential to become an essential method for enhancing Hi-C contact maps, paving the way to further our understanding of 3D genome organization and functional implications at a finer scale.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material id="sup1" position="float" content-type="local-data">
      <label>btad266_Supplementary_Data</label>
      <media xlink:href="btad266_supplementary_data.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <sec>
    <title>Author contributions</title>
    <p>Y.Z. and M.B. conceived the study. Y.Z. performed analysis. M.B. supervised the project. Y.Z. and M.B. wrote the article. All authors read and approved the final article.</p>
  </sec>
  <sec>
    <title>Supplementary data</title>
    <p><xref rid="sup1" ref-type="supplementary-material">Supplementary data</xref> is available at <italic toggle="yes">Bioinformatics</italic> online.</p>
  </sec>
  <sec sec-type="COI-statement">
    <title>Conflict of interest</title>
    <p>None declared.</p>
  </sec>
  <sec>
    <title>Funding</title>
    <p>This work was supported by Genome Quebec/Canada and Genome Quebec/Oncopole/IVADO (to M.B.) and FRQNT Doctoral (B2X) Research Scholarships (to Y.Z.).</p>
  </sec>
  <sec sec-type="data-availability">
    <title>Data availability</title>
    <p>The data underlying this article are available in zenodo, at <ext-link xlink:href="https://dx.doi.org/10.5281/zenodo.7761968" ext-link-type="uri">https://dx.doi.org/10.5281/zenodo.7761968</ext-link>.</p>
  </sec>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="btad266-B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Abdennur</surname><given-names>N</given-names></string-name>, <string-name><surname>Mirny</surname><given-names>LA.</given-names></string-name></person-group><article-title>Cooler: scalable storage for Hi-C data and other genomically labeled arrays</article-title>. <source>Bioinformatics</source><year>2020</year>;<volume>36</volume>:<fpage>311</fpage>–<lpage>6</lpage>.<pub-id pub-id-type="pmid">31290943</pub-id></mixed-citation>
    </ref>
    <ref id="btad266-B2">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Borgeaud</surname><given-names>S</given-names></string-name>, <string-name><surname>Mensch</surname><given-names>A</given-names></string-name>, <string-name><surname>Hoffmann</surname><given-names>J</given-names></string-name></person-group><etal>et al</etal> Improving language models by retrieving from trillions of tokens. In: <italic toggle="yes">International conference on machine learning</italic>, (pp. 2206-2240). PMLR, 2022.</mixed-citation>
    </ref>
    <ref id="btad266-B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cameron</surname><given-names>CJ</given-names></string-name>, <string-name><surname>Dostie</surname><given-names>J</given-names></string-name>, <string-name><surname>Blanchette</surname><given-names>M.</given-names></string-name></person-group><article-title>HIFI: estimating DNA-DNA interaction frequency from Hi-c data at restriction-fragment resolution</article-title>. <source>Genome Biol</source><year>2020</year>;<volume>21</volume>:<fpage>1</fpage>–<lpage>15</lpage>.</mixed-citation>
    </ref>
    <ref id="btad266-B4">
      <mixed-citation publication-type="journal"><collab>ENCODE Project Consortium</collab><etal>et al</etal><article-title>An integrated encyclopedia of DNA elements in the human genome</article-title>. <source>Nature</source><year>2012</year>;<volume>489</volume>:<fpage>57</fpage>.<pub-id pub-id-type="pmid">22955616</pub-id></mixed-citation>
    </ref>
    <ref id="btad266-B5">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Dali</surname><given-names>R</given-names></string-name>, <string-name><surname>Bourque</surname><given-names>G</given-names></string-name>, <string-name><surname>Blanchette</surname><given-names>M.</given-names></string-name></person-group> Robustad: a tool for robust annotation of topologically associating domain boundaries. bioRxiv <year>2018</year>. <pub-id pub-id-type="doi">10.1101/293175</pub-id>.</mixed-citation>
    </ref>
    <ref id="btad266-B6">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Gao</surname><given-names>T</given-names></string-name>, <string-name><surname>Yao</surname><given-names>X</given-names></string-name>, <string-name><surname>Chen</surname><given-names>D.</given-names></string-name></person-group> Simcse: simple contrastive learning of sentence embeddings. In: <italic toggle="yes"><italic toggle="yes">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</italic>, (pp. 6894–6910), Online and Punta Cana, Dominican Republic</italic>. Association for Computational Linguistics.</mixed-citation>
    </ref>
    <ref id="btad266-B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hong</surname><given-names>H</given-names></string-name>, <string-name><surname>Jiang</surname><given-names>S</given-names></string-name>, <string-name><surname>Li</surname><given-names>H</given-names></string-name></person-group><etal>et al</etal><article-title>DeepHiC: A generative adversarial network for enhancing hi-C data resolution</article-title>. <source><italic toggle="yes">PLoS Comput Biol</italic></source><year>2020</year>;<volume>16</volume>:<fpage>e1007287</fpage>.<pub-id pub-id-type="doi">10.1371/journal.pcbi.1007287</pub-id>.<pub-id pub-id-type="pmid">32084131</pub-id></mixed-citation>
    </ref>
    <ref id="btad266-B8">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Imakaev</surname><given-names>M</given-names></string-name>, <string-name><surname>Fudenberg</surname><given-names>G</given-names></string-name>, <string-name><surname>McCord</surname><given-names>RP</given-names></string-name></person-group><etal>et al</etal><article-title>Iterative correction of Hi-C data reveals hallmarks of chromosome organization</article-title>. <source>Nat Methods</source><year>2012</year>;<volume>9</volume>:<fpage>999</fpage>–<lpage>1003</lpage>.<pub-id pub-id-type="pmid">22941365</pub-id></mixed-citation>
    </ref>
    <ref id="btad266-B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Krietenstein</surname><given-names>N</given-names></string-name>, <string-name><surname>Abraham</surname><given-names>S</given-names></string-name>, <string-name><surname>Venev</surname><given-names>SV</given-names></string-name></person-group><etal>et al</etal><article-title>Ultrastructural details of mammalian chromosome architecture</article-title>. <source>Mol Cell</source><year>2020</year>;<volume>78</volume>:<fpage>554</fpage>–<lpage>65.e7</lpage>.<pub-id pub-id-type="pmid">32213324</pub-id></mixed-citation>
    </ref>
    <ref id="btad266-B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lee</surname><given-names>D-I</given-names></string-name>, <string-name><surname>Roy</surname><given-names>S.</given-names></string-name></person-group><article-title>Grinch: simultaneous smoothing and detection of topological units of genome organization from sparse chromatin contact count matrices with matrix factorization</article-title>. <source>Genome Biol</source><year>2021</year>;<volume>22</volume>:<fpage>1</fpage>–<lpage>31</lpage>.<pub-id pub-id-type="pmid">33397451</pub-id></mixed-citation>
    </ref>
    <ref id="btad266-B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lieberman-Aiden</surname><given-names>E</given-names></string-name>, <string-name><surname>Van Berkum</surname><given-names>NL</given-names></string-name>, <string-name><surname>Williams</surname><given-names>L</given-names></string-name></person-group><etal>et al</etal><article-title>Comprehensive mapping of long-range interactions reveals folding principles of the human genome</article-title>. <source>Science</source><year>2009</year>;<volume>326</volume>:<fpage>289</fpage>–<lpage>93</lpage>.<pub-id pub-id-type="pmid">19815776</pub-id></mixed-citation>
    </ref>
    <ref id="btad266-B12">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lin</surname><given-names>D</given-names></string-name>, <string-name><surname>Sanders</surname><given-names>J</given-names></string-name>, <string-name><surname>Noble</surname><given-names>WS.</given-names></string-name></person-group><article-title>HiCRep. py: fast comparison of Hi-c contact matrices in python</article-title>. <source>Bioinformatics</source><year>2021</year>;<volume>37</volume>:<fpage>2996</fpage>–<lpage>7</lpage>.<pub-id pub-id-type="pmid">33576390</pub-id></mixed-citation>
    </ref>
    <ref id="btad266-B13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Liu</surname><given-names>Q</given-names></string-name>, <string-name><surname>Lv</surname><given-names>H</given-names></string-name>, <string-name><surname>Jiang</surname><given-names>R.</given-names></string-name></person-group><article-title>hicGAN infers super resolution Hi-C data with generative adversarial networks</article-title>. <source>Bioinformatics</source><year>2019</year>;<volume>35</volume>:<fpage>i99</fpage>–<lpage>107</lpage>.<pub-id pub-id-type="pmid">31510693</pub-id></mixed-citation>
    </ref>
    <ref id="btad266-B14">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Liu</surname><given-names>T</given-names></string-name>, <string-name><surname>Wang</surname><given-names>Z.</given-names></string-name></person-group><article-title>HiCNN: a very deep convolutional neural network to better enhance the resolution of Hi-c data</article-title>. <source>Bioinformatics</source><year>2019</year>;<volume>35</volume>:<fpage>4222</fpage>–<lpage>8</lpage>.<pub-id pub-id-type="pmid">31056636</pub-id></mixed-citation>
    </ref>
    <ref id="btad266-B15">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Loshchilov</surname><given-names>I</given-names></string-name>, <string-name><surname>Hutter</surname><given-names>F.</given-names></string-name></person-group> Decoupled weight decay regularization. <italic toggle="yes">arXiv preprint</italic><year>2017</year>. <pub-id pub-id-type="doi">10.48550/arXiv.1711.05101</pub-id>.</mixed-citation>
    </ref>
    <ref id="btad266-B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mumbach</surname><given-names>MR</given-names></string-name>, <string-name><surname>Rubin</surname><given-names>AJ</given-names></string-name>, <string-name><surname>Flynn</surname><given-names>RA</given-names></string-name></person-group><etal>et al</etal><article-title>HiChiP: efficient and sensitive analysis of protein-directed genome architecture</article-title>. <source>Nat Methods</source><year>2016</year>;<volume>13</volume>:<fpage>919</fpage>–<lpage>22</lpage>.<pub-id pub-id-type="pmid">27643841</pub-id></mixed-citation>
    </ref>
    <ref id="btad266-B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mumbach</surname><given-names>MR</given-names></string-name>, <string-name><surname>Satpathy</surname><given-names>AT</given-names></string-name>, <string-name><surname>Boyle</surname><given-names>EA</given-names></string-name></person-group><etal>et al</etal><article-title>Enhancer connectome in primary human cells identifies target genes of disease-associated DNA elements</article-title>. <source>Nat Genet</source><year>2017</year>;<volume>49</volume>:<fpage>1602</fpage>–<lpage>12</lpage>.<pub-id pub-id-type="pmid">28945252</pub-id></mixed-citation>
    </ref>
    <ref id="btad266-B18">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Paszke</surname><given-names>A</given-names></string-name>, <string-name><surname>Gross</surname><given-names>S</given-names></string-name>, <string-name><surname>Massa</surname><given-names>F</given-names></string-name></person-group><etal>et al</etal><part-title>PyTorch: an imperative style, high-performance deep learning library</part-title>. In: <person-group person-group-type="editor"><string-name><surname>Wallach</surname><given-names>H</given-names></string-name>, <string-name><surname>Larochelle</surname><given-names>H</given-names></string-name>, <string-name><surname>Beygelzimer</surname><given-names>A</given-names></string-name></person-group><etal>et al</etal> (eds), <source>Advances in Processing Systems</source>. Vol. <volume>32</volume>, Red Hook, NY, USA: <publisher-name>Curran Associates, Inc</publisher-name>., <year>2019</year>, <fpage>8024</fpage>–<lpage>35</lpage>.</mixed-citation>
    </ref>
    <ref id="btad266-B19">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rao</surname><given-names>SS</given-names></string-name>, <string-name><surname>Huntley</surname><given-names>MH</given-names></string-name>, <string-name><surname>Durand</surname><given-names>NC</given-names></string-name></person-group><etal>et al</etal><article-title>A 3D map of the human genome at kilobase resolution reveals principles of chromatin looping</article-title>. <source>Cell</source><year>2014</year>;<volume>159</volume>:<fpage>1665</fpage>–<lpage>80</lpage>.<pub-id pub-id-type="pmid">25497547</pub-id></mixed-citation>
    </ref>
    <ref id="btad266-B20">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Roayaei Ardakany</surname><given-names>A</given-names></string-name>, <string-name><surname>Gezer</surname><given-names>HT</given-names></string-name>, <string-name><surname>Lonardi</surname><given-names>S</given-names></string-name></person-group><etal>et al</etal><article-title>Mustache: multi-scale detection of chromatin loops from Hi-C and micro-C maps using scale-space representation</article-title>. <source>Genome Biol</source><year>2020</year>;<volume>21</volume>:<fpage>1</fpage>–<lpage>17</lpage>.</mixed-citation>
    </ref>
    <ref id="btad266-B21">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Ronneberger</surname><given-names>O</given-names></string-name>, <string-name><surname>Fischer</surname><given-names>P</given-names></string-name>, <string-name><surname>Brox</surname><given-names>T.</given-names></string-name></person-group> U-net: convolutional networks for biomedical image segmentation. In: <italic toggle="yes">International Conference on Medical Image Computing and Computer-Assisted Intervention</italic>, pp. <fpage>234</fpage>–<lpage>41</lpage>. Switzerland: <publisher-name>Springer</publisher-name>, <year>2015</year>.</mixed-citation>
    </ref>
    <ref id="btad266-B22">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sanborn</surname><given-names>AL</given-names></string-name>, <string-name><surname>Rao</surname><given-names>SS</given-names></string-name>, <string-name><surname>Huang</surname><given-names>S-C</given-names></string-name></person-group><etal>et al</etal><article-title>Chromatin extrusion explains key features of loop and domain formation in wild-type and engineered genomes</article-title>. <source>Proc Natl Acad Sci U S A</source><year>2015</year>;<volume>112</volume>:<fpage>E6456</fpage>–<lpage>65</lpage>.<pub-id pub-id-type="pmid">26499245</pub-id></mixed-citation>
    </ref>
    <ref id="btad266-B23">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tang</surname><given-names>Z</given-names></string-name>, <string-name><surname>Luo</surname><given-names>OJ</given-names></string-name>, <string-name><surname>Li</surname><given-names>X</given-names></string-name></person-group><etal>et al</etal><article-title>CTCF-mediated human 3D genome architecture reveals chromatin topology for transcription</article-title>. <source>Cell</source><year>2015</year>;<volume>163</volume>:<fpage>1611</fpage>–<lpage>27</lpage>.<pub-id pub-id-type="pmid">26686651</pub-id></mixed-citation>
    </ref>
    <ref id="btad266-B24">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Xia</surname><given-names>B</given-names></string-name>, <string-name><surname>Tian</surname><given-names>Y</given-names></string-name>, <string-name><surname>Hang</surname><given-names>Y</given-names></string-name></person-group><etal>et al</etal> Coarse-to-fine embedded patchmatch and multi-scale dynamic aggregation for reference-based super-resolution. <italic toggle="yes">arXiv preprint</italic><year>2022</year>. <pub-id pub-id-type="doi">10.48550/arXiv.2201.04358</pub-id>.</mixed-citation>
    </ref>
    <ref id="btad266-B25">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Yan</surname><given-names>X</given-names></string-name>, <string-name><surname>Zhao</surname><given-names>W</given-names></string-name>, <string-name><surname>Yuan</surname><given-names>K</given-names></string-name></person-group><etal>et al</etal> Towards content-independent multi-reference super-resolution: adaptive pattern matching and feature aggregation. In: <italic toggle="yes">European Conference on Computer Vision</italic>, pp. <fpage>52</fpage>–<lpage>68</lpage>. Switzerland: <publisher-name>Springer</publisher-name>, <year>2020</year>.</mixed-citation>
    </ref>
    <ref id="btad266-B26">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yang</surname><given-names>T</given-names></string-name>, <string-name><surname>Zhang</surname><given-names>F</given-names></string-name>, <string-name><surname>Yardımcı</surname><given-names>GG</given-names></string-name></person-group><etal>et al</etal><article-title>HiCRep: assessing the reproducibility of Hi-C data using a stratum-adjusted correlation coefficient</article-title>. <source>Genome Res</source><year>2017</year>;<volume>27</volume>:<fpage>1939</fpage>–<lpage>49</lpage>.<pub-id pub-id-type="pmid">28855260</pub-id></mixed-citation>
    </ref>
    <ref id="btad266-B27">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname><given-names>Y</given-names></string-name>, <string-name><surname>Blanchette</surname><given-names>M.</given-names></string-name></person-group><article-title>Reference panel guided topological structure annotation of Hi-c data</article-title>. <source>Nat Commun</source><year>2022</year>;<volume>13</volume>:<fpage>1</fpage>–<lpage>12</lpage>.<pub-id pub-id-type="pmid">34983933</pub-id></mixed-citation>
    </ref>
    <ref id="btad266-B28">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname><given-names>Y</given-names></string-name>, <string-name><surname>An</surname><given-names>L</given-names></string-name>, <string-name><surname>Xu</surname><given-names>J</given-names></string-name></person-group><etal>et al</etal><article-title>Enhancing Hi-C data resolution with deep convolutional neural network hicplus</article-title>. <source>Nat Commun</source><year>2018</year>;<volume>9</volume>:<fpage>750</fpage>.<pub-id pub-id-type="pmid">29467363</pub-id></mixed-citation>
    </ref>
    <ref id="btad266-B29">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhou</surname><given-names>J</given-names></string-name>, <string-name><surname>Ma</surname><given-names>J</given-names></string-name>, <string-name><surname>Chen</surname><given-names>Y</given-names></string-name></person-group><etal>et al</etal><article-title>Robust single-cell Hi-C clustering by convolution-and random-walk–based imputation</article-title>. <source>Proc Natl Acad Sci U S A</source><year>2019</year>;<volume>116</volume>:<fpage>14011</fpage>–<lpage>8</lpage>.<pub-id pub-id-type="pmid">31235599</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
