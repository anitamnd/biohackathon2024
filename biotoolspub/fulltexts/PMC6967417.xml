<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//NLM//DTD Journal Publishing DTD v2.3 20070202//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName journalpublishing.dtd?>
<?SourceDTD.Version 2.3?>
<?ConverterInfo.XSLTName jp2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Front Chem</journal-id>
    <journal-id journal-id-type="iso-abbrev">Front Chem</journal-id>
    <journal-id journal-id-type="publisher-id">Front. Chem.</journal-id>
    <journal-title-group>
      <journal-title>Frontiers in Chemistry</journal-title>
    </journal-title-group>
    <issn pub-type="epub">2296-2646</issn>
    <publisher>
      <publisher-name>Frontiers Media S.A.</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">6967417</article-id>
    <article-id pub-id-type="doi">10.3389/fchem.2019.00895</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Chemistry</subject>
        <subj-group>
          <subject>Original Research</subject>
        </subj-group>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>SPVec: A Word2vec-Inspired Feature Representation Method for Drug-Target Interaction Prediction</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Zhang</surname>
          <given-names>Yu-Fang</given-names>
        </name>
        <xref ref-type="aff" rid="aff1">
          <sup>1</sup>
        </xref>
        <uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/807744/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Wang</surname>
          <given-names>Xiangeng</given-names>
        </name>
        <xref ref-type="aff" rid="aff1">
          <sup>1</sup>
        </xref>
        <uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/745995/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Kaushik</surname>
          <given-names>Aman Chandra</given-names>
        </name>
        <xref ref-type="aff" rid="aff1">
          <sup>1</sup>
        </xref>
        <xref ref-type="aff" rid="aff2">
          <sup>2</sup>
        </xref>
        <uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/800909/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Chu</surname>
          <given-names>Yanyi</given-names>
        </name>
        <xref ref-type="aff" rid="aff1">
          <sup>1</sup>
        </xref>
        <uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/873207/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Shan</surname>
          <given-names>Xiaoqi</given-names>
        </name>
        <xref ref-type="aff" rid="aff1">
          <sup>1</sup>
        </xref>
        <uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/873228/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Zhao</surname>
          <given-names>Ming-Zhu</given-names>
        </name>
        <xref ref-type="aff" rid="aff3">
          <sup>3</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Xu</surname>
          <given-names>Qin</given-names>
        </name>
        <xref ref-type="aff" rid="aff1">
          <sup>1</sup>
        </xref>
        <xref ref-type="corresp" rid="c001">
          <sup>*</sup>
        </xref>
        <uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/807021/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Wei</surname>
          <given-names>Dong-Qing</given-names>
        </name>
        <xref ref-type="aff" rid="aff1">
          <sup>1</sup>
        </xref>
        <xref ref-type="aff" rid="aff4">
          <sup>4</sup>
        </xref>
        <xref ref-type="corresp" rid="c002">
          <sup>*</sup>
        </xref>
      </contrib>
    </contrib-group>
    <aff id="aff1"><sup>1</sup><institution>State Key Laboratory of Microbial Metabolism, and SJTU-Yale Joint Center for Biostatistics and Data Science, School of Life Sciences and Biotechnology, and Joint Laboratory of International Cooperation in Metabolic and Developmental Sciences, Ministry of Education, Shanghai Jiao Tong University</institution>, <addr-line>Shanghai</addr-line>, <country>China</country></aff>
    <aff id="aff2"><sup>2</sup><institution>Wuxi School of Medicine, Jiangnan University</institution>, <addr-line>Wuxi</addr-line>, <country>China</country></aff>
    <aff id="aff3"><sup>3</sup><institution>Instrumental Analysis Center, Shanghai Jiao Tong University</institution>, <addr-line>Shanghai</addr-line>, <country>China</country></aff>
    <aff id="aff4"><sup>4</sup><institution>Peng Cheng Laboratory</institution>, <addr-line>Shenzhen</addr-line>, <country>China</country></aff>
    <author-notes>
      <fn fn-type="edited-by">
        <p>Edited by: Zunnan Huang, Guangdong Medical University, China</p>
      </fn>
      <fn fn-type="edited-by">
        <p>Reviewed by: Francesco Ortuso, University of Catanzaro, Italy; Ling Wang, South China University of Technology, China</p>
      </fn>
      <corresp id="c001">*Correspondence: Qin Xu <email>xuqin523@sjtu.edu.cn</email></corresp>
      <corresp id="c002">Dong-Qing Wei <email>dqwei@sjtu.edu.cn</email></corresp>
      <fn fn-type="other" id="fn001">
        <p>This article was submitted to Medicinal and Pharmaceutical Chemistry, a section of the journal Frontiers in Chemistry</p>
      </fn>
    </author-notes>
    <pub-date pub-type="epub">
      <day>10</day>
      <month>1</month>
      <year>2020</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2019</year>
    </pub-date>
    <volume>7</volume>
    <elocation-id>895</elocation-id>
    <history>
      <date date-type="received">
        <day>11</day>
        <month>10</month>
        <year>2019</year>
      </date>
      <date date-type="accepted">
        <day>12</day>
        <month>12</month>
        <year>2019</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>Copyright Â© 2020 Zhang, Wang, Kaushik, Chu, Shan, Zhao, Xu and Wei.</copyright-statement>
      <copyright-year>2020</copyright-year>
      <copyright-holder>Zhang, Wang, Kaushik, Chu, Shan, Zhao, Xu and Wei</copyright-holder>
      <license xlink:href="http://creativecommons.org/licenses/by/4.0/">
        <license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.</license-p>
      </license>
    </permissions>
    <abstract>
      <p>Drug discovery is an academical and commercial process of global importance. Accurate identification of drug-target interactions (DTIs) can significantly facilitate the drug discovery process. Compared to the costly, labor-intensive and time-consuming experimental methods, machine learning (ML) plays an ever-increasingly important role in effective, efficient and high-throughput identification of DTIs. However, upstream feature extraction methods require tremendous human resources and expert insights, which limits the application of ML approaches. Inspired by the unsupervised representation learning methods like Word2vec, we here proposed SPVec, a novel way to automatically represent raw data such as SMILES strings and protein sequences into continuous, information-rich and lower-dimensional vectors, so as to avoid the sparseness and bit collisions from the cumbersomely manually extracted features. Visualization of SPVec nicely illustrated that the similar compounds or proteins occupy similar vector space, which indicated that SPVec not only encodes compound substructures or protein sequences efficiently, but also implicitly reveals some important biophysical and biochemical patterns. Compared with manually-designed features like MACCS fingerprints and amino acid composition (AAC), SPVec showed better performance with several state-of-art machine learning classifiers such as Gradient Boosting Decision Tree, Random Forest and Deep Neural Network on BindingDB. The performance and robustness of SPVec were also confirmed on independent test sets obtained from DrugBank database. Also, based on the whole DrugBank dataset, we predicted the possibilities of all unlabeled DTIs, where two of the top five predicted novel DTIs were supported by external evidences. These results indicated that SPVec can provide an effective and efficient way to discover reliable DTIs, which would be beneficial for drug reprofiling.</p>
    </abstract>
    <kwd-group>
      <kwd>drug-target interaction</kwd>
      <kwd>representation learning</kwd>
      <kwd>Word2vec</kwd>
      <kwd>machine learning</kwd>
      <kwd>feature embedding</kwd>
    </kwd-group>
    <funding-group>
      <award-group>
        <funding-source id="cn001">National Natural Science Foundation of China<named-content content-type="fundref-id">10.13039/501100001809</named-content></funding-source>
        <award-id rid="cn001">61503244</award-id>
        <award-id rid="cn001">31770772</award-id>
        <award-id rid="cn001">61832019</award-id>
      </award-group>
      <award-group>
        <funding-source id="cn002">Ministry of Science and Technology of the People's Republic of China<named-content content-type="fundref-id">10.13039/501100002855</named-content></funding-source>
        <award-id rid="cn002">2016YFA0501703</award-id>
      </award-group>
    </funding-group>
    <counts>
      <fig-count count="4"/>
      <table-count count="5"/>
      <equation-count count="3"/>
      <ref-count count="46"/>
      <page-count count="11"/>
      <word-count count="7052"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec sec-type="intro" id="s1">
    <title>Introduction</title>
    <p>Drug discovery is an issue of global importance, both academically and commercially. Generally, drugs have interactions with specific molecular targets, which are known as drug-target interactions (DTIs). Accurate identification of DTIs can significantly facilitate the processes of drug discovery. Thus, modern drug development calls for more effective and efficient techniques to identify true DTIs from the vast libraries of chemical compounds and protein targets. Numerous efforts have been poured into predictions of DTIs. However, it is still challenging to identify new drugs and their corresponding targets because of the limited knowledge about complex relationships between chemical space and proteomics space. Since <italic>in vivo</italic> and <italic>in vitro</italic> testings are rather costly and time-consuming (Kuruvilla et al., <xref rid="B25" ref-type="bibr">2002</xref>; Haggarty et al., <xref rid="B18" ref-type="bibr">2003</xref>; Valentin et al., <xref rid="B39" ref-type="bibr">2018</xref>), scientists' focus moves more than ever to <italic>in silico</italic> techniques predict potential drug-target associations on a large scale, in which machine learning (ML) is one of the most attractive approaches.</p>
    <p>Various machine learning methods have been developed in the last decades, in which the most widely used models are binary classifiers like Random Forest (RF) (Ho, <xref rid="B20" ref-type="bibr">1998</xref>), Support Vector Machine (SVM) (Cortes and Vapnik, <xref rid="B8" ref-type="bibr">1995</xref>), Deep Neural Network (DNN) (Liu et al., <xref rid="B27" ref-type="bibr">2017</xref>), Gradient Boosting Decision Tree (GBDT) (Friedman, <xref rid="B13" ref-type="bibr">2001</xref>), and so on. The performance of machine learning methods relies heavily on data representation (or features). Therefore, the design of data preprocessing and data transformation is of great concern to ensure that the data representation can support efficient machine learning algorithms. Numeric methods have been proposed to excavate drug and target features from their chemical structures and genomic sequences, respectively, such as fingerprints (Morgan, <xref rid="B30" ref-type="bibr">1965</xref>; Ewing et al., <xref rid="B10" ref-type="bibr">2006</xref>) and other molecular descriptors (Van Aalten et al., <xref rid="B40" ref-type="bibr">1996</xref>; Hong et al., <xref rid="B21" ref-type="bibr">2008</xref>) for drugs, amino acid composition (AAC) (Nakashima and Nishikawa, <xref rid="B31" ref-type="bibr">1994</xref>) and physico-chemical properties (Cai et al., <xref rid="B3" ref-type="bibr">2002</xref>) of target proteins, and so on. For example, Nascimento et al. (<xref rid="B33" ref-type="bibr">2016</xref>) used ânormalized Smith-Waterman, mismatch and spectrum kernelsâ for the target protein sequences and âthe spectrum, Lambda-k, Marginalized, MinMax, and Tanimoto kernelsâ for the drug's chemical structure to predict DTIs. In the work by Nanni et al. (<xref rid="B32" ref-type="bibr">2014</xref>), the drugs were represented by FP2 fingerprints and the representations on the targets were based on autocovariance, entropy, discrete wavelet, and substitution, and so on. The representation of the drug-target pairs was done by concatenating the target descriptors with the FP2 fingerprints of the drug. In the works by He et al. (<xref rid="B19" ref-type="bibr">2010</xref>), multiple chemical functional groups for drug-related features and pseudo AAC for protein-related features were extracted to describe drug-target pairs. Chen et al. (<xref rid="B4" ref-type="bibr">2012</xref>) integrated protein-protein similarity network, drug-drug similarity network, and known drug-target interaction networks into a heterogeneous network, and then implemented the random walk algorithm on this heterogeneous network for the prediction of DTIs. Rayhan et al. (<xref rid="B36" ref-type="bibr">2017</xref>) exploited their algorithms using both structural and evolutionary information to generate informative features. Based on these traditional features, the performance of machine learning algorithms for predictions of DTIs have been gradually improved to a quite high level. However, these feature extraction methods require tremendous manpower and expert insights, and the effectiveness of these features also requires tremendous computations to be proved. Tedious processes of âfeature engineeringâ have to be done before these features can be fed into downstream ML models. In order to facilitate the application of machine learning technologies, it is necessary to make them less dependent on feature engineering.</p>
    <p>Representation learning (RL) (Bengio et al., <xref rid="B2" ref-type="bibr">2013</xref>) is a way to introduce artificial intelligence (AI) and prior knowledge to automatically learn continuous, information-rich and lower-dimensional vectors from raw data that can be easily and directly used in ML models. An RL algorithm attempts to discover the latent features that describe the structure of a dataset under certain (either explicit or implicit) assumptions. Nowadays, RL has shown an influential role in effectively extracting features and solving the problem in computer vision, pattern recognition and natural language processing (NLP) (Mikolov et al., <xref rid="B28" ref-type="bibr">2013a</xref>; Sharif Razavian et al., <xref rid="B38" ref-type="bibr">2014</xref>). RL aims to automatically learn the representations (or features) from raw data that can be effectively utilized by downstream machine learning models to improve the performance of the model. Word2vec (Mikolov et al., <xref rid="B29" ref-type="bibr">2013b</xref>) is one of the most popular RL methods, making NLP problems easier to tackle. Inspired by the distributed hypotheses that words found in similar environments usually have similar meanings, the Word2vec model predicts the center word based on its neighbor words in the window of a given size. This method simultaneously learn several language concepts such as Collobert and Weston (<xref rid="B6" ref-type="bibr">2008</xref>): (1) the meaning of the word; (2) how words are combined to form a concept (i.e., grammar); (3) how a concept relates to the task. Word2vec effectively removes word-meaning extraction subtasks by providing pre-trained word embeddings for learning algorithms. The word representations computed using Word2vec are very interesting because the learned vectors explicitly encode many linguistic regularities and patterns. Somewhat surprisingly, many of these patterns can be represented as linear translations. For example, the vector of âParisâ minus the vector of âFranceâ plus the vector of âItalyâ is very close to âRome.â In addition to its original utility as a word-embedding method, some of its ideas are effective in sequential data of non-language tasks (Jaeger et al., <xref rid="B22" ref-type="bibr">2018</xref>; Zhang et al., <xref rid="B45" ref-type="bibr">2019</xref>).</p>
    <p>Recently, RL brought several breakthroughs in compound space and protein space. Convolutional neural networks were successfully applied on molecular graphs (Kearnes et al., <xref rid="B24" ref-type="bibr">2016</xref>; Coley et al., <xref rid="B5" ref-type="bibr">2017</xref>) and depictions of molecules (Goh et al., <xref rid="B17" ref-type="bibr">2017b</xref>). Latent semantic structure indexing (LaSSI) (Schneider et al., <xref rid="B37" ref-type="bibr">2017</xref>) techniques were adopted to compute chemical similarity from molecular descriptors. Word2vec (Asgari and Mofrad, <xref rid="B1" ref-type="bibr">2015</xref>) has been adapted to protein sequences (ProtVec) for classification of protein families and predication of disordered proteins. Wan and Zeng (<xref rid="B41" ref-type="bibr">2016</xref>) used term frequency-inverse document frequency (tf-idf) to learn compound representations from Morgan fingerprints. While substructures of a molecule are hashed to a binary fingerprint (possibly sparse) in the case of the fingerprints, the Mol2vec approach, proposed by Jaeger et al. (<xref rid="B22" ref-type="bibr">2018</xref>), forms a vector with continuous and dense values. The SMILES2Vec (Goh et al., <xref rid="B16" ref-type="bibr">2017a</xref>) a model introduces a direct conversion of chemical structures from SMILES (Simplified Molecular-Input Line-Entry System) strings into vectors. These works show that RL technologies represented by Word2vec can automatic learn low-dimensional features from compound and protein feature space and achieve excellent performances, suggesting its advantages in both efficiency and effectiveness.</p>
    <p>In this study, new SPVec vectors were constructed via the combination of SMILES2Vec and ProtVec to represent specific DTIs, where the drug representation was simplified by using SMILES directly. The whole pipeline of DTI prediction in this article is shown in <xref ref-type="fig" rid="F1">Figure 1</xref>, in comparison with a tradition pipeline. Not like RL who can atomically learn lower-dimensional features without human resources and expert insights, traditional feature engineering usually contains a lot of steps, including feature extraction, feature selection and dimensionality reduction, while every step need professional knowledge and extra time. For example, Fingerprint-based features are sparse and high-dimensional, thus dimensional reduction is necessary. Feature importance analysis and feature selection might be indispensable for mixed features, such as physicochemical properties, structural and evolutionary information and interaction information. It only takes several hours for feature presentation by SPVec training on a modern quad-core CPU, while dozens of days are required for traditional feature engineering. To evaluate the performance of SPVec, the constructed vectors was fed into several state-of-art machine learning classifiers such as GBDT, RF and DNN on BindingDB (Gilson et al., <xref rid="B15" ref-type="bibr">2016</xref>). The performance and robustness of SPVec were also confirmed by an external validation using DrugBank database. Also, we predicted the possibilities of all unlabeled DTIs in DrugBank database (Law et al., <xref rid="B26" ref-type="bibr">2014</xref>), where two of the top five predicted novel DTIs were supported by external evidences. The results indicated that SPVec can discover reliable DTIs, which could be beneficial for drug reprofiling.</p>
    <fig id="F1" position="float">
      <label>Figure 1</label>
      <caption>
        <p>Flowchart of the whole pipeline for DTI prediction in this article <bold>(left)</bold> in comparison to the traditional pipeline <bold>(right)</bold>, with the procedures of feature representations squared in dashed lines.</p>
      </caption>
      <graphic xlink:href="fchem-07-00895-g0001"/>
    </fig>
  </sec>
  <sec id="s2">
    <title>Method</title>
    <sec>
      <title>Datasets</title>
      <p>BindingDB is a public, web-accessible database of measured binding affinities, focusing chiefly on the interactions of target proteins with small, drug-like molecules, was utilized to evaluate the performance of SPVec. The whole BindingDB claims to contain 1,756,093 binding data for 7,371 protein targets and 780,240 small molecules (updated on 2019-05-01). Considering the validity of the features represented, inorganic compounds and protein targets with sequence identity &gt; 75% were removed. In addition, considering the druggability, we excluded interactions with IC50 value missing or &gt;300 nM. Finally we got 36,014 small molecular drugs and 2,099 targets from BindingDB, which may generate over 75 million DTI pairs. Among them, 83,676 pairs are known as positive DTIs, and the rest are undetermined and treated as unlabeled data, from which 83,676 drug-target pairs were randomly selected as a negative dataset.</p>
      <p>To further validate our model, we also collected data of DTIs from DrugBank. The data of drugs, targets and their interactions were separated by the date April 20, 2016, with those before it regarded as old while those after it regarded as new. In this way, we constructed five positive datasets as shown in <xref rid="T1" ref-type="table">Table 1</xref>: (1) dataset_1 consists of all old drugs, old targets and their old interaction pairs; (2) dataset_2 consists of all old drugs, old targets and their new interaction pairs; (3) dataset_3 consists of all new drugs, old targets and their interaction pairs; (4) dataset_4 consists of all old drugs, new targets and their interaction pairs; (5) dataset_5 consists of all new drugs, new targets and their interaction pairs. The largest dataset_1 with all old data was used for model training, while the other four datasets with new data were used to validate the robustness of the models. The generation of corresponding negative datasets of these five datasets are same as that from Binding DB, except that the unlabeled data pool of dataset_2 is the rest of positive interactions of dataset_1 and dataset_2 (6068Ã3839-14534-3348).</p>
      <table-wrap id="T1" position="float">
        <label>Table 1</label>
        <caption>
          <p>Number of entries of the five different datasets obtained from DrugBank dataset.</p>
        </caption>
        <table frame="hsides" rules="groups">
          <thead>
            <tr>
              <th valign="top" align="left" rowspan="1" colspan="1">
                <bold>Datasets</bold>
              </th>
              <th valign="top" align="center" rowspan="1" colspan="1">
                <bold>Dataset_1</bold>
              </th>
              <th valign="top" align="center" rowspan="1" colspan="1">
                <bold>Dataset_2</bold>
              </th>
              <th valign="top" align="center" rowspan="1" colspan="1">
                <bold>Dataset_3</bold>
              </th>
              <th valign="top" align="center" rowspan="1" colspan="1">
                <bold>Dataset_4</bold>
              </th>
              <th valign="top" align="center" rowspan="1" colspan="1">
                <bold>Dataset_5</bold>
              </th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Drug</td>
              <td valign="top" align="center" rowspan="1" colspan="1">6,068</td>
              <td valign="top" align="center" rowspan="1" colspan="1">6,068</td>
              <td valign="top" align="center" rowspan="1" colspan="1">537</td>
              <td valign="top" align="center" rowspan="1" colspan="1">6,068</td>
              <td valign="top" align="center" rowspan="1" colspan="1">537</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Target</td>
              <td valign="top" align="center" rowspan="1" colspan="1">3,839</td>
              <td valign="top" align="center" rowspan="1" colspan="1">3,839</td>
              <td valign="top" align="center" rowspan="1" colspan="1">3,839</td>
              <td valign="top" align="center" rowspan="1" colspan="1">160</td>
              <td valign="top" align="center" rowspan="1" colspan="1">160</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Interactions</td>
              <td valign="top" align="center" rowspan="1" colspan="1">15,434</td>
              <td valign="top" align="center" rowspan="1" colspan="1">3,348</td>
              <td valign="top" align="center" rowspan="1" colspan="1">1,735</td>
              <td valign="top" align="center" rowspan="1" colspan="1">264</td>
              <td valign="top" align="center" rowspan="1" colspan="1">37</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
    </sec>
    <sec>
      <title>Feature Representations</title>
      <p>SPVec is a Word2vec-inspired technique to represent latent features of small compounds and target proteins. Word2vec refers to the method that for any word <inline-formula><mml:math id="M1"><mml:mrow><mml:mi mathvariant="script">w</mml:mi></mml:mrow></mml:math></inline-formula> in dictionary <inline-formula><mml:math id="M2"><mml:mrow><mml:mi mathvariant="script">D</mml:mi></mml:mrow></mml:math></inline-formula>, specify a fixed length of the real value vector <italic>V</italic> (<inline-formula><mml:math id="M3"><mml:mrow><mml:mi mathvariant="script">w</mml:mi></mml:mrow></mml:math></inline-formula>) â â<sup>m</sup>, where <italic>V</italic> (<inline-formula><mml:math id="M4"><mml:mrow><mml:mi mathvariant="script">w</mml:mi></mml:mrow></mml:math></inline-formula>) is called the word vector of <inline-formula><mml:math id="M5"><mml:mrow><mml:mi mathvariant="script">w</mml:mi></mml:mrow></mml:math></inline-formula> and <italic>m</italic> is the length of the word vector. All of these vectors form a word vector space, and each vector can be regarded as a point in the space. The lexical or semantic similarity between them can be judged by the âdistanceâ between the points.</p>
      <p>In particular, we mainly used the Skip-gram model implemented with the Negative-sampling (NEG) method to train the Word2vec-like models. The classical Skip-gram model consists of three layers: the input layer, the projection layer, and the output layer. Take a sample (<italic>w, Context</italic> (<italic>w</italic>)) for example, assuming that <italic>Context</italic> (<italic>w</italic>) consists of <italic>c</italic> words before and after <italic>w</italic>, then a brief description of these three layers is as follows: the input layer is the word vector <italic>V</italic> (<inline-formula><mml:math id="M6"><mml:mrow><mml:mi mathvariant="script">w</mml:mi></mml:mrow></mml:math></inline-formula>) â â<sup>m</sup> of the current sample; the projection layer is identity projection, which means projecting <italic>V</italic> (<inline-formula><mml:math id="M7"><mml:mrow><mml:mi mathvariant="script">w</mml:mi></mml:mrow></mml:math></inline-formula>) to <italic>V</italic> (<inline-formula><mml:math id="M8"><mml:mrow><mml:mi mathvariant="script">w</mml:mi></mml:mrow></mml:math></inline-formula>); the output layer is a binary Huffman tree, which takes every word appearing in the corpus as the leaf node and frequency of the word as weight. In the revised Skip-gram model here, the negative samples were generated by relatively simple random NEG method instead of Huffman trees, so as to improve training speed and improve the quality of the resulting word vectors. Given that a negative sample subset <italic>NEG</italic>(<inline-formula><mml:math id="M9"><mml:mrow><mml:mi mathvariant="script">w</mml:mi></mml:mrow></mml:math></inline-formula>) â  â for <inline-formula><mml:math id="M10"><mml:mrow><mml:mi mathvariant="script">w</mml:mi></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="M11"><mml:mo>â</mml:mo><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="script">w</mml:mi></mml:mrow><mml:mo>~</mml:mo></mml:mover><mml:mo>â</mml:mo><mml:mi mathvariant="script">D</mml:mi></mml:math></inline-formula>, we define <inline-formula><mml:math id="M12"><mml:msup><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="script">w</mml:mi></mml:mrow><mml:mo>~</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> as the label of word <inline-formula><mml:math id="M13"><mml:mrow><mml:mi mathvariant="script">w</mml:mi></mml:mrow></mml:math></inline-formula>, where the label of a positive sample is 1, and that of a negative sample is 0. For a given sample (<italic>w, Context</italic> (<italic>w</italic>)), we want to maximize the following function:</p>
      <disp-formula id="E1">
        <label>(1)</label>
        <mml:math id="M14">
          <mml:mtable class="eqnarray" columnalign="right center left">
            <mml:mtr>
              <mml:mtd>
                <mml:mi>g</mml:mi>
                <mml:mrow>
                  <mml:mo stretchy="false">(</mml:mo>
                  <mml:mrow>
                    <mml:mi mathvariant="script">w</mml:mi>
                  </mml:mrow>
                  <mml:mo stretchy="false">)</mml:mo>
                </mml:mrow>
                <mml:mo>=</mml:mo>
                <mml:mstyle displaystyle="true">
                  <mml:munder class="msub">
                    <mml:mrow>
                      <mml:mo>â</mml:mo>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mover accent="true">
                        <mml:mrow>
                          <mml:mi mathvariant="script">w</mml:mi>
                        </mml:mrow>
                        <mml:mi>~</mml:mi>
                      </mml:mover>
                      <mml:mo>â</mml:mo>
                      <mml:mi>C</mml:mi>
                      <mml:mi>o</mml:mi>
                      <mml:mi>n</mml:mi>
                      <mml:mi>t</mml:mi>
                      <mml:mi>e</mml:mi>
                      <mml:mi>x</mml:mi>
                      <mml:mi>t</mml:mi>
                      <mml:mrow>
                        <mml:mo stretchy="false">(</mml:mo>
                        <mml:mrow>
                          <mml:mi mathvariant="script">w</mml:mi>
                        </mml:mrow>
                        <mml:mo stretchy="false">)</mml:mo>
                      </mml:mrow>
                    </mml:mrow>
                  </mml:munder>
                </mml:mstyle>
                <mml:mstyle displaystyle="true">
                  <mml:munder class="msub">
                    <mml:mrow>
                      <mml:mo>â</mml:mo>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mi mathvariant="script">w</mml:mi>
                      <mml:mo>â</mml:mo>
                      <mml:mrow>
                        <mml:mo>{</mml:mo>
                        <mml:mrow>
                          <mml:mi>u</mml:mi>
                        </mml:mrow>
                        <mml:mo>}</mml:mo>
                      </mml:mrow>
                      <mml:mo>âª</mml:mo>
                      <mml:mi>N</mml:mi>
                      <mml:mi>E</mml:mi>
                      <mml:msup>
                        <mml:mrow>
                          <mml:mi>G</mml:mi>
                        </mml:mrow>
                        <mml:mrow>
                          <mml:mover accent="true">
                            <mml:mrow>
                              <mml:mi mathvariant="script">w</mml:mi>
                            </mml:mrow>
                            <mml:mo>~</mml:mo>
                          </mml:mover>
                        </mml:mrow>
                      </mml:msup>
                      <mml:mrow>
                        <mml:mo stretchy="false">(</mml:mo>
                        <mml:mrow>
                          <mml:mi mathvariant="script">w</mml:mi>
                        </mml:mrow>
                        <mml:mo stretchy="false">)</mml:mo>
                      </mml:mrow>
                    </mml:mrow>
                  </mml:munder>
                </mml:mstyle>
                <mml:mi>p</mml:mi>
                <mml:mrow>
                  <mml:mo stretchy="false">(</mml:mo>
                  <mml:mrow>
                    <mml:mi>u</mml:mi>
                    <mml:mo>|</mml:mo>
                    <mml:mover accent="true">
                      <mml:mrow>
                        <mml:mi>w</mml:mi>
                      </mml:mrow>
                      <mml:mo>~</mml:mo>
                    </mml:mover>
                  </mml:mrow>
                  <mml:mo stretchy="false">)</mml:mo>
                </mml:mrow>
              </mml:mtd>
            </mml:mtr>
          </mml:mtable>
        </mml:math>
      </disp-formula>
      <p>where</p>
      <disp-formula id="E2">
        <label>(2)</label>
        <mml:math id="M15">
          <mml:mtable class="eqnarray" columnalign="right center left">
            <mml:mtr>
              <mml:mtd>
                <mml:mi>p</mml:mi>
                <mml:mrow>
                  <mml:mo stretchy="false">(</mml:mo>
                  <mml:mrow>
                    <mml:mi>u</mml:mi>
                    <mml:mo>|</mml:mo>
                    <mml:mover accent="true">
                      <mml:mrow>
                        <mml:mi>w</mml:mi>
                      </mml:mrow>
                      <mml:mo>~</mml:mo>
                    </mml:mover>
                  </mml:mrow>
                  <mml:mo stretchy="false">)</mml:mo>
                </mml:mrow>
                <mml:mo>=</mml:mo>
                <mml:msup>
                  <mml:mrow>
                    <mml:mrow>
                      <mml:mo>[</mml:mo>
                      <mml:mrow>
                        <mml:mi>Ï</mml:mi>
                        <mml:mrow>
                          <mml:mo stretchy="true">(</mml:mo>
                          <mml:mrow>
                            <mml:msup>
                              <mml:mrow>
                                <mml:mi>V</mml:mi>
                                <mml:mrow>
                                  <mml:mo stretchy="false">(</mml:mo>
                                  <mml:mrow>
                                    <mml:mover accent="true">
                                      <mml:mrow>
                                        <mml:mi>w</mml:mi>
                                      </mml:mrow>
                                      <mml:mo>~</mml:mo>
                                    </mml:mover>
                                  </mml:mrow>
                                  <mml:mo stretchy="false">)</mml:mo>
                                </mml:mrow>
                              </mml:mrow>
                              <mml:mrow>
                                <mml:mi>T</mml:mi>
                              </mml:mrow>
                            </mml:msup>
                            <mml:msup>
                              <mml:mrow>
                                <mml:mi>Î¸</mml:mi>
                              </mml:mrow>
                              <mml:mrow>
                                <mml:mi>u</mml:mi>
                              </mml:mrow>
                            </mml:msup>
                          </mml:mrow>
                          <mml:mo stretchy="true">)</mml:mo>
                        </mml:mrow>
                      </mml:mrow>
                      <mml:mo>]</mml:mo>
                    </mml:mrow>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:msup>
                      <mml:mrow>
                        <mml:mi>L</mml:mi>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mi mathvariant="script">w</mml:mi>
                      </mml:mrow>
                    </mml:msup>
                    <mml:mrow>
                      <mml:mo stretchy="false">(</mml:mo>
                      <mml:mrow>
                        <mml:mi>u</mml:mi>
                      </mml:mrow>
                      <mml:mo stretchy="false">)</mml:mo>
                    </mml:mrow>
                  </mml:mrow>
                </mml:msup>
                <mml:mo>Ã</mml:mo>
                <mml:msup>
                  <mml:mrow>
                    <mml:mrow>
                      <mml:mo>[</mml:mo>
                      <mml:mrow>
                        <mml:mn>1</mml:mn>
                        <mml:mo>-</mml:mo>
                        <mml:mi>Ï</mml:mi>
                        <mml:mrow>
                          <mml:mo stretchy="true">(</mml:mo>
                          <mml:mrow>
                            <mml:msup>
                              <mml:mrow>
                                <mml:mi>V</mml:mi>
                                <mml:mrow>
                                  <mml:mo stretchy="false">(</mml:mo>
                                  <mml:mrow>
                                    <mml:mover accent="true">
                                      <mml:mrow>
                                        <mml:mi>w</mml:mi>
                                      </mml:mrow>
                                      <mml:mo>~</mml:mo>
                                    </mml:mover>
                                  </mml:mrow>
                                  <mml:mo stretchy="false">)</mml:mo>
                                </mml:mrow>
                              </mml:mrow>
                              <mml:mrow>
                                <mml:mi>T</mml:mi>
                              </mml:mrow>
                            </mml:msup>
                            <mml:msup>
                              <mml:mrow>
                                <mml:mi>Î¸</mml:mi>
                              </mml:mrow>
                              <mml:mrow>
                                <mml:mi>u</mml:mi>
                              </mml:mrow>
                            </mml:msup>
                          </mml:mrow>
                          <mml:mo stretchy="true">)</mml:mo>
                        </mml:mrow>
                      </mml:mrow>
                      <mml:mo>]</mml:mo>
                    </mml:mrow>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mn>1</mml:mn>
                    <mml:mo>-</mml:mo>
                    <mml:msup>
                      <mml:mrow>
                        <mml:mi>L</mml:mi>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mi mathvariant="script">w</mml:mi>
                      </mml:mrow>
                    </mml:msup>
                    <mml:mrow>
                      <mml:mo stretchy="false">(</mml:mo>
                      <mml:mrow>
                        <mml:mi>u</mml:mi>
                      </mml:mrow>
                      <mml:mo stretchy="false">)</mml:mo>
                    </mml:mrow>
                  </mml:mrow>
                </mml:msup>
                <mml:mo>,</mml:mo>
              </mml:mtd>
            </mml:mtr>
          </mml:mtable>
        </mml:math>
      </disp-formula>
      <p>here <inline-formula><mml:math id="M16"><mml:mi>N</mml:mi><mml:mi>E</mml:mi><mml:msup><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="script">w</mml:mi></mml:mrow><mml:mo>~</mml:mo></mml:mover></mml:mrow></mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="script">w</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> is a generated subset of negative samples when processing words <inline-formula><mml:math id="M17"><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="script">w</mml:mi></mml:mrow><mml:mo>~</mml:mo></mml:mover></mml:math></inline-formula>. For a given corpus <italic>C</italic>, the final objective function is:</p>
      <disp-formula id="E3">
        <label>(3)</label>
        <mml:math id="M18">
          <mml:mtable class="eqnarray" columnalign="right center left">
            <mml:mtr>
              <mml:mtd>
                <mml:mi mathvariant="script">L</mml:mi>
                <mml:mo>=</mml:mo>
                <mml:mo class="qopname">log</mml:mo>
                <mml:mi>G</mml:mi>
                <mml:mo>=</mml:mo>
                <mml:mo class="qopname">log</mml:mo>
                <mml:mstyle displaystyle="true">
                  <mml:munder class="msub">
                    <mml:mrow>
                      <mml:mo>â</mml:mo>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mi mathvariant="script">w</mml:mi>
                      <mml:mo>â</mml:mo>
                      <mml:mi mathvariant="script">C</mml:mi>
                    </mml:mrow>
                  </mml:munder>
                </mml:mstyle>
                <mml:mi>g</mml:mi>
                <mml:mrow>
                  <mml:mo stretchy="false">(</mml:mo>
                  <mml:mrow>
                    <mml:mi>w</mml:mi>
                  </mml:mrow>
                  <mml:mo stretchy="false">)</mml:mo>
                </mml:mrow>
                <mml:mo>.</mml:mo>
              </mml:mtd>
            </mml:mtr>
          </mml:mtable>
        </mml:math>
      </disp-formula>
      <p>Maximizing this objective function can be performed using the stochastic gradient descent technique.</p>
      <p>The same principles in the work by Wan and Zeng (<xref rid="B41" ref-type="bibr">2016</xref>) were followed to choose the hyperparameters of Skip-gram. That is, the embedding dimension was set as <italic>d</italic> = 100, the context window size was set as <italic>c</italic> = 12, and the number of negative examples was set as <italic>k</italic> = 15. Using this revised Skip-gram model, SMILES2Vec and ProtVec models were trained for feature representations of drug compounds and target proteins, respectively, and combined into SPVec to represent their interactions. Different from the works by Jaeger et al. (<xref rid="B22" ref-type="bibr">2018</xref>), we directly use SMILES of drug molecules rather than Morgan fingerprints as âsentencesâ to learn the representations, as SMILES strings are more like âsentencesâ and don't need additional calculations. At the same time, the protocol of Asgari and Mofrad (<xref rid="B1" ref-type="bibr">2015</xref>) was followed in training of ProtVec here, where protein sequences were regarded as âsentencesâ and every three non-overlapping amino acids were regarded as a âword.â</p>
      <p>To benchmark our SPVec approach against classical feature extraction approaches, we also extracted manually-designed features of chemical structures and protein sequences. For the ligands, we adopted the MACCS fingerprint (Corey and Wipke, <xref rid="B7" ref-type="bibr">1969</xref>), one of the most widely used âstructural fingerprintsâ based on pre-defined chemical substructures and finally got 166-dimensional compound feature vectors. At the same time, we considered the 20-dimensional AAC as protein descriptors, which were computed via PROFEAT (Zhang et al., <xref rid="B46" ref-type="bibr">2016</xref>), a web server for computing commonly used protein features from their amino acid sequences.</p>
      <p>The SPVec features compose a 100-dimensional space in such a way that similar objects are modeled into nearby points. To explore biochemical implications from SPVec features, the feature vectors of small molecular drugs and protein targets in DrugBank are projected from this 100-dimensional space into a 3D or 2D space for easier visualization using t-Distributed Stochastic Neighbor Embedding (t-SNE) (Der Maaten and Hinton, <xref rid="B9" ref-type="bibr">2008</xref>), which is a non-linear dimensionality reduction technique for visualization of high dimensional data in a low-dimensional space, generally in two or three dimensions.</p>
    </sec>
    <sec>
      <title>Machine Learning Models</title>
      <p>The feature embeddings learned by SPVec model were then fed into various machine learning models to predict the likelihood of their interactions. The performance in DTIs prediction by three state-of-art machine learning methods RF, GBDT, and DNN was used to evaluate the utility of SPVec embeddings. RF is an ensemble method that combines the probabilistic predictions of a number of decision tree-based classifiers to improve the generalization ability over a single estimator. GBDT is a machine learning technique for regression and classification problems, which produces a prediction model in the form of an ensemble of weak prediction models, typically decision trees. It builds the model in a stage-wise fashion as other boosting methods do, and it generalizes them by allowing optimization of an arbitrary differentiable loss function. DNN is a supervised learning algorithm which could learn non-linear models. It has one or more non-linear hidden layers between the input and output. For each hidden layer, different numbers of hidden neurons can be assigned. Each hidden neuron yields a weighted linear summation of the values from the previous layer, and the non-linear activation function is followed. The weights are learned through backpropagation algorithm or variations upon it. All these models were implemented by Python v3.6 and scikit-learn library (Pedregosa et al., <xref rid="B35" ref-type="bibr">2011</xref>). All the datasets and source codes, as well as a Python module for user-friendly application of the SPVec method are available at <ext-link ext-link-type="uri" xlink:href="https://github.com/dqwei-lab/SPVec">https://github.com/dqwei-lab/SPVec</ext-link>.</p>
    </sec>
  </sec>
  <sec id="s3">
    <title>Results and Discussion</title>
    <sec>
      <title>Biochemical Implications of SPVec Features</title>
      <p>To explore biochemical implications from SPVec features, small molecular drugs in DrugBank are represented into vectors by SMILES2Vec and projected from a 100-dimensional space to a 3D space by t-SNE, shown in <xref ref-type="fig" rid="F2">Figure 2A</xref>, where each point represents a small drug molecule. Since the SMILES2Vec vectors are sums of substructure vectors, they may implicitly capture substructure importance via the vector weight, thus the drugs closer to each other may have more structural and functional similarities. For example, the boxed points stand for part of the top 10 chemicals (because some are masked by other points) similar to Acetophenazine (Drug ID: DB01063), an antipsychotic drug of moderate-potency used in the treatment of disorganized, psychotic thinking and false perceptions. <xref ref-type="fig" rid="F2">Figure 2B</xref> shows the molecular structures of these top 10 similar chemicals, most of which have the phenthiazine substructure (a Sulfur atom and a Nitrogen atom connected with two benzene rings) with neuroleptic and anti-histamine properties. Some of them share the same target. For example, Acepromazine (DrugBank ID: DB01614), Thiethylperazine (DrugBank ID: DB00372) and Acetophenazine have two common targets, D(2) dopamine receptor and D(1A) dopamine receptor. Periciazine (DrugBank ID: DB01608) and Acetophenazine have two common targets, D (1A) dopamine receptor and Androgen receptor). Oppositely, Ceftibuten (DrugBank ID: DB01459), which is relatively far from Acetophenazine, has no Phenthiazine substructure. And in terms of functionalities, Ceftibuten is typically used to treat acute bacterial exacerbations of chronic bronchitis (ABECB), acute bacterial otitis media, pharyngitis, and tonsillitis, which is different from Acepromazine either. Obviously, molecules with similar functional groups are close in the generated SMILES2Vec vector space.</p>
      <fig id="F2" position="float">
        <label>Figure 2</label>
        <caption>
          <p>Biochemical implications from SMILES2Vec features. <bold>(A)</bold> Visualizations of the SMILES2Vec vector space of drugs in DrugBank using t-SNE. <bold>(B)</bold> The top 10 drugs most similar to Acetophenazine (DrugBank ID: DB01063) according to their SMILES2Vec vectors. Red values show their cosine distances with Acetophenazine. The smaller the value, the more similar in the chemical structures.</p>
        </caption>
        <graphic xlink:href="fchem-07-00895-g0002"/>
      </fig>
      <p>Although the ProtVec is only trained based on the primary sequences of proteins, it shows some important biochemical and biophysical implications (Asgari and Mofrad, <xref rid="B1" ref-type="bibr">2015</xref>). In order to study these features, we visualized the distribution of ProtVec vectors by mass, volume, polarity, hydrophobicity. In <xref ref-type="fig" rid="F3">Figure 3</xref>, each point represents a protein, with a color according to its scale in each property. The distribution of these points turns out that proteins with similar biochemical and biophysical properties tend to be closer. This observation indicates that not only encodes protein sequences effectively and efficiently, the ProtVec also implicitly reveals some important biophysical and biochemical patterns of the protein, while AAC only contains information of protein compositions (Nakashima and Nishikawa, <xref rid="B31" ref-type="bibr">1994</xref>).</p>
      <fig id="F3" position="float">
        <label>Figure 3</label>
        <caption>
          <p>Normalized distributions of biochemical and biophysical properties in a 2D space projected by t-SNE from the 100-dimensional ProtVec protein-space. In these plots, each point represents a protein, and the colors indicate the scale for each property.</p>
        </caption>
        <graphic xlink:href="fchem-07-00895-g0003"/>
      </fig>
    </sec>
    <sec>
      <title>Performance of SPVec in Comparison With Traditional Feature Representation Methods</title>
      <p>We tested the performance of DTIs predictions for SPVec combined with three state-of-art ML classifiers (GBDT, RF, and DNN) using BindingDB, and compared with the combination of MACCS and AAC features as a baseline. To validate the performance of SMILES2Vec and ProtVec independently, we also constructed another two feature combinations, that is, MACCS-ProtVec and SMILES2Vec-AAC. A summary of classification performances of these four feature combinations on the BindingDB dataset are shown in <xref rid="T2" ref-type="table">Table 2</xref>, with their ROC curves shown in <xref ref-type="supplementary-material" rid="SM1">Figure S1</xref>. It is obvious that DTIs predictions based on SPVec vectors are relatively improved than those on the classical feature combination (i.e., MACCS-AAC) when using any of the ML classifiers. For predictions by the GBDT, RF, and DNN classifiers, the AUCs using SMILES2Vec-ProtVec are 13.35, 15.67, and 11.66% higher than MACCS-AAC, respectively. When only molecules are characterized via SMILES2Vec, the AUCs of SMILES2Vec-ProtVec are about 8.86%, 11.57%, and 9.09% higher than SMILES2Vec-AAC. And when molecules are characterized via MACCS, the AUCs of MACCS-ProtVec were about 8.91, 9.42, and 6.85% higher than MACCS-AAC. Therefore, in DTIs predictions single feature representations by ProtVec or SMILES2Vec also partly improve the classification performances. It is also reasonable to expect their individual performances in other tasks related to only drugs or proteins, such as compound property predictions and protein classifications. <xref rid="T2" ref-type="table">Table 2</xref> also indicates that features represented by SPVec are quite reliable with different ML models. Based on the datasets from BindingDB, the GBDT, RF, and DNN models resulted in no important difference for classification tasks of DTIs, and all achieved similarly higher AUC score, accuracy, precision, recall, and F1-score.</p>
      <table-wrap id="T2" position="float">
        <label>Table 2</label>
        <caption>
          <p>Results of classification performance of four feature combinations using three classifiers on BindingDB via 10 Ã 5-fold cross-validation, with the highest scores highlighted in the bold font.</p>
        </caption>
        <table frame="hsides" rules="groups">
          <thead>
            <tr>
              <th valign="top" align="left" rowspan="1" colspan="1">
                <bold>Feature combinations</bold>
              </th>
              <th valign="top" align="left" rowspan="1" colspan="1">
                <bold>Model</bold>
              </th>
              <th valign="top" align="center" rowspan="1" colspan="1">
                <bold>AUC</bold>
              </th>
              <th valign="top" align="center" rowspan="1" colspan="1">
                <bold>Accuracy</bold>
              </th>
              <th valign="top" align="center" rowspan="1" colspan="1">
                <bold>Precision</bold>
              </th>
              <th valign="top" align="center" rowspan="1" colspan="1">
                <bold>Recall</bold>
              </th>
              <th valign="top" align="center" rowspan="1" colspan="1">
                <bold>F1-score</bold>
              </th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">SPVec (SMILES2Vec-ProtVec)</td>
              <td valign="top" align="left" rowspan="1" colspan="1">GBDT</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.9923</td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>0.9680</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.9695</td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>0.9667</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>0.9681</bold>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td valign="top" align="left" rowspan="1" colspan="1">RF</td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>0.9927</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.9675</td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>0.9808</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.9540</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.9672</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td valign="top" align="left" rowspan="1" colspan="1">DNN</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.9617</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.9332</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.9287</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.9248</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.9197</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">SMILES2Vec-AAC</td>
              <td valign="top" align="left" rowspan="1" colspan="1">GBDT</td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>0.9037</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>0.8272</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>0.8563</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>0.7873</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>0.8204</bold>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td valign="top" align="left" rowspan="1" colspan="1">RF</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.8770</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.7974</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.8657</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.7050</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.7772</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td valign="top" align="left" rowspan="1" colspan="1">DNN</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.8708</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.8124</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.7993</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.7879</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.7126</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">MACCS-ProtVec</td>
              <td valign="top" align="left" rowspan="1" colspan="1">GBDT</td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>0.9479</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>0.8810</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>0.8908</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>0.8690</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>0.8798</bold>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td valign="top" align="left" rowspan="1" colspan="1">RF</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.9302</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.8542</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.8712</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.8322</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.8512</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td valign="top" align="left" rowspan="1" colspan="1">DNN</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.9136</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.8034</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.8025</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.8097</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.8074</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">MACCS-AAC</td>
              <td valign="top" align="left" rowspan="1" colspan="1">GBDT</td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>0.8588</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>0.7811</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>0.8077</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>0.7392</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>0.7719</bold>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td valign="top" align="left" rowspan="1" colspan="1">RF</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.8360</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.7468</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.8366</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.6150</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.7089</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td valign="top" align="left" rowspan="1" colspan="1">DNN</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.8451</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.7832</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.7884</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.7726</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.7724</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
      <p>The performance of SPVec based DTIs predictions was also compared with earlier results using different popular classical features or modeling methods, as summarized in <xref rid="T3" ref-type="table">Table 3</xref>. Compared with these classical features, the features represented by SPVec are much lower in dimensions, which masterly avoid the âCurse of Dimensionality,â and enable ML models to achieve better performances. Especially when some kinds of features are hard to obtain, such as the 3D molecular and protein descriptors, the advantages of SPVec is more evident. It's worth to note that You et al. (<xref rid="B43" ref-type="bibr">2019</xref>) and Yu et al. (<xref rid="B44" ref-type="bibr">2012</xref>) used DrugBank database with different versions (released on 14 Nov. 2017 and 1 June 2011, respectively), while the datasets for the other predictions (Ezzat et al., <xref rid="B11" ref-type="bibr">2016</xref>, <xref rid="B12" ref-type="bibr">2017</xref>) were from the version 4.3 of DrugBank database (released on 17 Nov. 2015) in which there are 12,674 drug-target interactions between 5,877 drugs and their 3,348 protein interaction partners in total. However, as shown in <xref ref-type="supplementary-material" rid="SM1">Table S1</xref>, the performances of SPVec did not change a lot using the different versions of database. AUC of DNN, GBDT and RF only increased by 0.0315, 0.0039, and 0.0088, respectively. Therefore, the better performance of SPVec compared with earlier results in <xref rid="T3" ref-type="table">Table 3</xref> is still guaranteed.</p>
      <table-wrap id="T3" position="float">
        <label>Table 3</label>
        <caption>
          <p>AUCs of SPVec and other models on DTI predictions using DrugBank.</p>
        </caption>
        <table frame="hsides" rules="groups">
          <thead>
            <tr>
              <th valign="top" align="left" rowspan="1" colspan="1">
                <bold>Drug features</bold>
              </th>
              <th valign="top" align="center" rowspan="1" colspan="1"><bold>Drug</bold><break/><bold>dim</bold>.</th>
              <th valign="top" align="left" rowspan="1" colspan="1">
                <bold>Protein features</bold>
              </th>
              <th valign="top" align="center" rowspan="1" colspan="1"><bold>Protein dim</bold>.</th>
              <th valign="top" align="left" rowspan="1" colspan="1">
                <bold>ML method</bold>
              </th>
              <th valign="top" align="center" rowspan="1" colspan="1">
                <bold>AUC</bold>
              </th>
              <th valign="top" align="left" rowspan="1" colspan="1">
                <bold>References</bold>
              </th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Drug structure information</td>
              <td valign="top" align="center" rowspan="1" colspan="1">2,216</td>
              <td valign="top" align="left" rowspan="1" colspan="1">AAC, DC<xref ref-type="table-fn" rid="TN1"><sup>a</sup></xref> and TC<xref ref-type="table-fn" rid="TN2"><sup>b</sup></xref></td>
              <td valign="top" align="center" rowspan="1" colspan="1">11,943</td>
              <td valign="top" align="left" rowspan="1" colspan="1">DNN</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.81</td>
              <td valign="top" align="center" rowspan="1" colspan="1">You et al., <xref rid="B43" ref-type="bibr">2019</xref><xref ref-type="table-fn" rid="TN3"><sup>c</sup></xref></td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Constitutional, topological and molecular descriptors, 2D autocorrelations, topological charge indices, eigenvalue-based indices</td>
              <td valign="top" align="center" rowspan="1" colspan="1">1,664</td>
              <td valign="top" align="left" rowspan="1" colspan="1">AAC; DC<xref ref-type="table-fn" rid="TN1"><sup>a</sup></xref>; autocorrelation; Composition, Transition, Distribution descriptors; Quasi-sequence-order</td>
              <td valign="top" align="center" rowspan="1" colspan="1">1,080</td>
              <td valign="top" align="left" rowspan="1" colspan="1">RF</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.8950</td>
              <td valign="top" align="center" rowspan="1" colspan="1">Yu et al., <xref rid="B44" ref-type="bibr">2012</xref><xref ref-type="table-fn" rid="TN3"><sup>c</sup></xref></td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Constitutional, topological and geometrical descriptors</td>
              <td valign="top" align="center" rowspan="1" colspan="1">193</td>
              <td valign="top" align="left" rowspan="1" colspan="1">AAC; DC<xref ref-type="table-fn" rid="TN1"><sup>a</sup></xref>; autocorrelation; composition, transition and distribution; quasi-sequence-order; amphiphilic pseudo-amino acid composition and total amino acid properties</td>
              <td valign="top" align="center" rowspan="1" colspan="1">1,260</td>
              <td valign="top" align="left" rowspan="1" colspan="1">DT<break/> RF</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.760<break/> 0.855</td>
              <td valign="top" align="center" rowspan="1" colspan="1">Ezzat et al., <xref rid="B11" ref-type="bibr">2016</xref></td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">PubChem fingerprints indicating presence or absence of 881 known chemical substructures</td>
              <td valign="top" align="center" rowspan="1" colspan="1">881</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Fingerprints of 876 different protein domains that are obtained from the Pfam database</td>
              <td valign="top" align="center" rowspan="1" colspan="1">876</td>
              <td valign="top" align="left" rowspan="1" colspan="1">EnsemDT</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.882</td>
              <td valign="top" align="center" rowspan="1" colspan="1">Ezzat et al., <xref rid="B12" ref-type="bibr">2017</xref></td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1"/>
              <td valign="top" align="left" rowspan="1" colspan="1">RF</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.855</td>
              <td rowspan="1" colspan="1"/>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">SMILES2Vec</td>
              <td valign="top" align="center" rowspan="1" colspan="1">100</td>
              <td valign="top" align="left" rowspan="1" colspan="1">ProtVec</td>
              <td valign="top" align="center" rowspan="1" colspan="1">100</td>
              <td valign="top" align="left" rowspan="1" colspan="1">GBDT</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.9467</td>
              <td valign="top" align="center" rowspan="1" colspan="1">This work</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1"/>
              <td valign="top" align="left" rowspan="1" colspan="1">RF</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.9469</td>
              <td rowspan="1" colspan="1"/>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1"/>
              <td valign="top" align="left" rowspan="1" colspan="1">DNN</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.8637</td>
              <td rowspan="1" colspan="1"/>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="TN1">
            <label>a</label>
            <p>DC, dipeptide composition;</p>
          </fn>
          <fn id="TN2">
            <label>b</label>
            <p>TC, tripeptide composition;</p>
          </fn>
          <fn id="TN3">
            <label>c</label>
            <p><italic>These models are trained on different versions of DrugBank, whose AUCs are only as references</italic>.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
    </sec>
    <sec>
      <title>Evaluation of the Robustness of SPVec</title>
      <p>In order to test the robustness of SPVec in DTIs predictions, especially in the newly found interactions, five datasets were constructed from DrugBank, as described in section Datasets. We used dataset_1 as the training set to learn features and construct the ML models and then tested their performances on the datasets with new data. The classification performances on dataset_1 via 10 Ã 5-fold cross-validation and performances on independent test sets like dataset_1, dataset_2, and dataset_3 using GBDT, RF and DNN are summarized in <xref rid="T4" ref-type="table">Table 4</xref> with their ROC curves shown in <xref ref-type="fig" rid="F4">Figure 4</xref>. As in <xref rid="T4" ref-type="table">Table 4</xref>, the ML approaches equipped with the SPVec features got quite high AUC on the training set, which is similar to the results on BindingDB. Although DNN architecture was outperformed by the tree-based methods GBDT and RF in both cases, we would like to note the possibility that further fine-tuning might a little bit improve the prediction performance of the SPVec-DNN combination. <xref rid="T4" ref-type="table">Table 4</xref> shows that SPVec performed satisfactorily on the test sets, suggesting acceptable generalization capacity and competitive performance of SPVec for the prediction of novel DTIs in drug repositioning or drug rediscovery, which is also suggested by the ROC curves in <xref ref-type="fig" rid="F4">Figure 4</xref>. Among the four test sets, all three classifiers achieve highest AUC on dataset_2 to predict new interactions between old drugs and old targets, while the prediction results on the interactions with new drugs or new targets are much worse, which is extraordinary obvious in the ROC curves of dataset_5 in <xref ref-type="fig" rid="F4">Figure 4</xref>. A possible explanation is that the newly found drugs or targets are not studied adequately and many potential DTIs between them have not been identified yet. Thus, the reduced accuracy of the data impairs the accuracy of the models. It is also worth noting that the negative sample was constructed by randomly selection from the unlabeled data, where the portion of unidentified potential positive DTI pairs may be even higher in smaller datasets. At last, the distributions of the new DTIs in the vector space of the test sets may be deviated from that of the training set, and impair the robustness of the models.</p>
      <table-wrap id="T4" position="float">
        <label>Table 4</label>
        <caption>
          <p>Results of classification performance using three classifiers on datasets obtained from DrugBank, with the highest scores highlighted in the bold font.</p>
        </caption>
        <table frame="hsides" rules="groups">
          <thead>
            <tr>
              <th valign="top" align="left" rowspan="1" colspan="1">
                <bold>Dataset</bold>
              </th>
              <th valign="top" align="left" rowspan="1" colspan="1">
                <bold>Model</bold>
              </th>
              <th valign="top" align="left" rowspan="1" colspan="1">
                <bold>AUC</bold>
              </th>
              <th valign="top" align="left" rowspan="1" colspan="1">
                <bold>Accuracy</bold>
              </th>
              <th valign="top" align="left" rowspan="1" colspan="1">
                <bold>Precision</bold>
              </th>
              <th valign="top" align="left" rowspan="1" colspan="1">
                <bold>Recall</bold>
              </th>
              <th valign="top" align="left" rowspan="1" colspan="1">
                <bold>F1-score</bold>
              </th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">
                <bold>Training set</bold>
              </td>
              <td valign="top" align="left" colspan="6" rowspan="1">
                <bold>10 Ã 5-fold cross-validation</bold>
              </td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Dataset_1</td>
              <td valign="top" align="left" rowspan="1" colspan="1">GBDT</td>
              <td valign="top" align="left" rowspan="1" colspan="1">0.9506</td>
              <td valign="top" align="left" rowspan="1" colspan="1">
                <bold>0.9323</bold>
              </td>
              <td valign="top" align="left" rowspan="1" colspan="1">
                <bold>0.9456</bold>
              </td>
              <td valign="top" align="left" rowspan="1" colspan="1">0.9367</td>
              <td valign="top" align="left" rowspan="1" colspan="1">
                <bold>0.9343</bold>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td valign="top" align="left" rowspan="1" colspan="1">RF</td>
              <td valign="top" align="left" rowspan="1" colspan="1">
                <bold>0.9557</bold>
              </td>
              <td valign="top" align="left" rowspan="1" colspan="1">0.9234</td>
              <td valign="top" align="left" rowspan="1" colspan="1">0.9378</td>
              <td valign="top" align="left" rowspan="1" colspan="1">
                <bold>0.9369</bold>
              </td>
              <td valign="top" align="left" rowspan="1" colspan="1">0.9337</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td valign="top" align="left" rowspan="1" colspan="1">DNN</td>
              <td valign="top" align="left" rowspan="1" colspan="1">0.8952</td>
              <td valign="top" align="left" rowspan="1" colspan="1">0.8732</td>
              <td valign="top" align="left" rowspan="1" colspan="1">0.8345</td>
              <td valign="top" align="left" rowspan="1" colspan="1">0.8437</td>
              <td valign="top" align="left" rowspan="1" colspan="1">0.8654</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">
                <bold>Test sets</bold>
              </td>
              <td valign="top" align="left" colspan="6" rowspan="1">
                <bold>Independent validation</bold>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td valign="top" align="left" rowspan="1" colspan="1">GBDT</td>
              <td valign="top" align="left" rowspan="1" colspan="1">
                <bold>0.8945</bold>
              </td>
              <td valign="top" align="left" rowspan="1" colspan="1">0.8628</td>
              <td valign="top" align="left" rowspan="1" colspan="1">
                <bold>0.8747</bold>
              </td>
              <td valign="top" align="left" rowspan="1" colspan="1">
                <bold>0.8696</bold>
              </td>
              <td valign="top" align="left" rowspan="1" colspan="1">
                <bold>0.8637</bold>
              </td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Dataset_2</td>
              <td valign="top" align="left" rowspan="1" colspan="1">RF</td>
              <td valign="top" align="left" rowspan="1" colspan="1">0.8930</td>
              <td valign="top" align="left" rowspan="1" colspan="1">
                <bold>0.8753</bold>
              </td>
              <td valign="top" align="left" rowspan="1" colspan="1">0.8645</td>
              <td valign="top" align="left" rowspan="1" colspan="1">0.8467</td>
              <td valign="top" align="left" rowspan="1" colspan="1">0.8555</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td valign="top" align="left" rowspan="1" colspan="1">DNN</td>
              <td valign="top" align="left" rowspan="1" colspan="1">0.8201</td>
              <td valign="top" align="left" rowspan="1" colspan="1">0.8026</td>
              <td valign="top" align="left" rowspan="1" colspan="1">0.8138</td>
              <td valign="top" align="left" rowspan="1" colspan="1">0.8199</td>
              <td valign="top" align="left" rowspan="1" colspan="1">0.8144</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td valign="top" align="left" rowspan="1" colspan="1">GBDT</td>
              <td valign="top" align="left" rowspan="1" colspan="1">
                <bold>0.7502</bold>
              </td>
              <td valign="top" align="left" rowspan="1" colspan="1">
                <bold>0.7389</bold>
              </td>
              <td valign="top" align="left" rowspan="1" colspan="1">
                <bold>0.7340</bold>
              </td>
              <td valign="top" align="left" rowspan="1" colspan="1">
                <bold>0.7245</bold>
              </td>
              <td valign="top" align="left" rowspan="1" colspan="1">
                <bold>0.7333</bold>
              </td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Dataset_3</td>
              <td valign="top" align="left" rowspan="1" colspan="1">RF</td>
              <td valign="top" align="left" rowspan="1" colspan="1">0.7448</td>
              <td valign="top" align="left" rowspan="1" colspan="1">0.7299</td>
              <td valign="top" align="left" rowspan="1" colspan="1">0.7198</td>
              <td valign="top" align="left" rowspan="1" colspan="1">0.7243</td>
              <td valign="top" align="left" rowspan="1" colspan="1">0.7230</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td valign="top" align="left" rowspan="1" colspan="1">DNN</td>
              <td valign="top" align="left" rowspan="1" colspan="1">0.6999</td>
              <td valign="top" align="left" rowspan="1" colspan="1">0.6922</td>
              <td valign="top" align="left" rowspan="1" colspan="1">0.6825</td>
              <td valign="top" align="left" rowspan="1" colspan="1">0.6798</td>
              <td valign="top" align="left" rowspan="1" colspan="1">0.6832</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td valign="top" align="left" rowspan="1" colspan="1">GBDT</td>
              <td valign="top" align="left" rowspan="1" colspan="1">
                <bold>0.7356</bold>
              </td>
              <td valign="top" align="left" rowspan="1" colspan="1">
                <bold>0.7223</bold>
              </td>
              <td valign="top" align="left" rowspan="1" colspan="1">
                <bold>0.7167</bold>
              </td>
              <td valign="top" align="left" rowspan="1" colspan="1">
                <bold>0.7177</bold>
              </td>
              <td valign="top" align="left" rowspan="1" colspan="1">
                <bold>0.7201</bold>
              </td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Dataset_4</td>
              <td valign="top" align="left" rowspan="1" colspan="1">RF</td>
              <td valign="top" align="left" rowspan="1" colspan="1">0.7235</td>
              <td valign="top" align="left" rowspan="1" colspan="1">0.7034</td>
              <td valign="top" align="left" rowspan="1" colspan="1">0.7108</td>
              <td valign="top" align="left" rowspan="1" colspan="1">0.7078</td>
              <td valign="top" align="left" rowspan="1" colspan="1">0.71</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td valign="top" align="left" rowspan="1" colspan="1">DNN</td>
              <td valign="top" align="left" rowspan="1" colspan="1">0.7173</td>
              <td valign="top" align="left" rowspan="1" colspan="1">0.6899</td>
              <td valign="top" align="left" rowspan="1" colspan="1">0.6884</td>
              <td valign="top" align="left" rowspan="1" colspan="1">0.6896</td>
              <td valign="top" align="left" rowspan="1" colspan="1">0.6866</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td valign="top" align="left" rowspan="1" colspan="1">GBDT</td>
              <td valign="top" align="left" rowspan="1" colspan="1">
                <bold>0.68</bold>
              </td>
              <td valign="top" align="left" rowspan="1" colspan="1">
                <bold>0.6703</bold>
              </td>
              <td valign="top" align="left" rowspan="1" colspan="1">
                <bold>0.6679</bold>
              </td>
              <td valign="top" align="left" rowspan="1" colspan="1">
                <bold>0.6664</bold>
              </td>
              <td valign="top" align="left" rowspan="1" colspan="1">
                <bold>0.6688</bold>
              </td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Dataset_5</td>
              <td valign="top" align="left" rowspan="1" colspan="1">RF</td>
              <td valign="top" align="left" rowspan="1" colspan="1">0.5689</td>
              <td valign="top" align="left" rowspan="1" colspan="1">0.5605</td>
              <td valign="top" align="left" rowspan="1" colspan="1">0.5398</td>
              <td valign="top" align="left" rowspan="1" colspan="1">0.5321</td>
              <td valign="top" align="left" rowspan="1" colspan="1">0.5411</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td valign="top" align="left" rowspan="1" colspan="1">DNN</td>
              <td valign="top" align="left" rowspan="1" colspan="1">0.6267</td>
              <td valign="top" align="left" rowspan="1" colspan="1">0.6098</td>
              <td valign="top" align="left" rowspan="1" colspan="1">0.607</td>
              <td valign="top" align="left" rowspan="1" colspan="1">0.6122</td>
              <td valign="top" align="left" rowspan="1" colspan="1">0.6114</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
      <fig id="F4" position="float">
        <label>Figure 4</label>
        <caption>
          <p>ROC curves with different models on the test sets obtained from DrugBank.</p>
        </caption>
        <graphic xlink:href="fchem-07-00895-g0004"/>
      </fig>
      <p>Particularly, the SPVec-GBDT method achieves the best performance among these three classifiers in DTIs predictions on the four test sets, with the AUCs as 0.8945, 0.7502, 0.7356, and 0.68, respectively. Although GBDT and RF showed similar results on the first four datasets, GBDT outperformed RF on dataset_5. This indicates that the SPVec-GBDT method may have better generalization capacity to achieve more robust prediction results, even for new drug-target pairs with limited or no interactions information, which may suggest that the SPVec-GBDT prediction model is possibly highly pertinent to the prediction of novel DTIs in drug repositioning.</p>
    </sec>
    <sec>
      <title>Prediction and Validation on Unidentified DTIs</title>
      <p>Although the SPVec vectors with continuous values show competitive performance in the task of DTIs predictions, a dominant issue in the prediction of DTIs is that only confirmed positive interactions are deposited in the databases while those unlabeled interactions are unknown to be really positive or negative. For example, the newly found interactions in Drugbank might be thought negative in dataset_1. To further evaluate the validity of SPVec predictions on DTIs, the possibilities of all unlabeled DTIs in DrugBank dataset were evaluated using SPVec-GBDT and the top five ranked interactions were tested by external supporting evidences from several reference databases like PubChem (Wang et al., <xref rid="B42" ref-type="bibr">2009</xref>), KEGG (Kanehisa and Goto, <xref rid="B23" ref-type="bibr">2000</xref>), ChEMBL (Gaulton et al., <xref rid="B14" ref-type="bibr">2017</xref>) and biomedical literatures. As a result, two of the top five predicted DTIs were confirmed by existing evidences (<xref rid="T5" ref-type="table">Table 5</xref>). The tyrosine-protein kinase Yes (Target ID: P07947, also known as Yes1) has been implicated as a potential therapeutic target in lots of cancers including breast cancers, melanomas, and rhabdomyosarcomas. Saracatinib (Drug ID: DB11805<bold>)</bold> was identified by Patel et al. (<xref rid="B34" ref-type="bibr">2013</xref>) as a potent Yes1 kinase inhibitor with the IC<sub>50</sub> as low as 6.2nM. Our results also predicted the interaction between Pelitinib (Drug ID: DB05524) and membrane-associated tyrosine and threonine-specific cdc2-inhibitory kinase (Target ID: P42262) which was confirmed by PubChem database. Pelitinib (EKB-569) is a potent, low molecular weight, selective, and irreversible inhibitor of epidermal growth factor receptor (EGFR) in development as an anticancer agent, while membrane-associated tyrosine and threonine-specific cdc2-inhibitory kinase is the kinase domain of human myt1. These results demonstrate that the SPVec-DTIs model has highly useful pertinence for the prediction of novel DTIs.</p>
      <table-wrap id="T5" position="float">
        <label>Table 5</label>
        <caption>
          <p>Top five novel DTIs predicted by SPVec-GBDT.</p>
        </caption>
        <table frame="hsides" rules="groups">
          <thead>
            <tr>
              <th valign="top" align="left" rowspan="1" colspan="1">
                <bold>Drug ID</bold>
              </th>
              <th valign="top" align="left" rowspan="1" colspan="1">
                <bold>Target ID</bold>
              </th>
              <th valign="top" align="left" rowspan="1" colspan="1">
                <bold>Drug name</bold>
              </th>
              <th valign="top" align="left" rowspan="1" colspan="1">
                <bold>Target name</bold>
              </th>
              <th valign="top" align="left" rowspan="1" colspan="1">
                <bold>Validation source</bold>
              </th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">DB11805</td>
              <td valign="top" align="left" rowspan="1" colspan="1">P07947</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Saracatinib</td>
              <td valign="top" align="left" rowspan="1" colspan="1">The tyrosine-protein kinase Yes</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Patel et al., <xref rid="B34" ref-type="bibr">2013</xref></td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">DB09282</td>
              <td valign="top" align="left" rowspan="1" colspan="1">P42262</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Molsidomine</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Glutamate receptor 2</td>
              <td valign="top" align="left" rowspan="1" colspan="1">None</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">DB05524</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Q99640</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Pelitinib</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Membrane-associated tyrosine and threonine-specific cdc2-inhibitory kinase</td>
              <td valign="top" align="left" rowspan="1" colspan="1">
                <ext-link ext-link-type="uri" xlink:href="https://pubchem.ncbi.nlm.nih.gov/compound/6445562">https://pubchem.ncbi.nlm.nih.gov/compound/6445562</ext-link>
              </td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">DB03017</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Q16620</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Lauric acid</td>
              <td valign="top" align="left" rowspan="1" colspan="1">BDNF/NT-3 growth factors receptor</td>
              <td valign="top" align="left" rowspan="1" colspan="1">None</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">DB13165</td>
              <td valign="top" align="left" rowspan="1" colspan="1">P11362</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Ripasudil</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Fibroblast growth factor receptor 1</td>
              <td valign="top" align="left" rowspan="1" colspan="1">None</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
    </sec>
  </sec>
  <sec sec-type="conclusions" id="s4">
    <title>Conclusion</title>
    <p>Combining SMILES2Vec and ProtVec, SPVec could transfer SMILES strings of drug compounds and protein sequences into information-rich and lower-dimensional vectors automatically. Visualization of SPVec vectors nicely illustrates that the derived vectors from similar structures locate closely in the vector space, suggesting that they may implicitly reveals some important biophysical and biochemical patterns. Based on BindingDB and DrugBank database, SPVec vectors were fed into several state-of-art machine learning methods like GBDT, RF and DNN to train DTIs prediction models. The results using BindingDB have shown that the proposed models can achieve better prediction performance than manually extracted features like the combination of MACCS and AAC. Also, the results tested on DrugBank datasets indicated that our approach, especially SPVec-GBDT, can discover reliable DTIs in newly found drugs and targets, which might be beneficial for drug re-profiling. At last, all the unlabeled DTIs in DrugBank database was repredicted by the SPVec-GBDT model, and two of the top five predicted novel DTIs were confirmed by external evidences from other databases or biomedical literatures. In addition, SPVec vectors also have the advantages of automatic learning and lower dimensionality, which may significantly speed up training and reduces memory requirements, making it a highly potential method of feature representation for DTI predictions.</p>
  </sec>
  <sec sec-type="data-availability" id="s5">
    <title>Data Availability Statement</title>
    <p>The datasets generated for this study can be found in the <ext-link ext-link-type="uri" xlink:href="https://github.com/dqwei-lab/SPVec">https://github.com/dqwei-lab/SPVec</ext-link>.</p>
  </sec>
  <sec id="s6">
    <title>Author Contributions</title>
    <p>Y-FZ, QX, and D-QW made the conception and designed the study. Y-FZ and XW collected and organized the database. Y-FZ, AK, and YC performed the statistical analysis. QX and Y-FZ wrote the manuscript. XS contributed to part of the first draft of the manuscript. M-ZZ contributed to part of the manuscript. All authors contributed to manuscript revision, read and approved the submitted version.</p>
    <sec>
      <title>Conflict of Interest</title>
      <p>The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p>
    </sec>
  </sec>
</body>
<back>
  <fn-group>
    <fn fn-type="financial-disclosure">
      <p><bold>Funding.</bold> This work was supported by the grants from the National Natural Science Foundation of China (Contract nos. 31770772, 61832019, and 61503244), the Key Research Area Grant 2016YFA0501703 of the Ministry of Science and Technology of China, and Joint Research Funds for Translational Medicine at Shanghai Jiao Tong University (ZH2018ZDA06).</p>
    </fn>
  </fn-group>
  <sec sec-type="supplementary-material" id="s7">
    <title>Supplementary Material</title>
    <p>The Supplementary Material for this article can be found online at: <ext-link ext-link-type="uri" xlink:href="https://www.frontiersin.org/articles/10.3389/fchem.2019.00895/full#supplementary-material">https://www.frontiersin.org/articles/10.3389/fchem.2019.00895/full#supplementary-material</ext-link></p>
    <supplementary-material content-type="local-data" id="SM1">
      <media xlink:href="Table_1.docx">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
  <ref-list>
    <title>References</title>
    <ref id="B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Asgari</surname><given-names>E.</given-names></name><name><surname>Mofrad</surname><given-names>M. R.</given-names></name></person-group> (<year>2015</year>). <article-title>Continuous distributed representation of biological sequences for deep proteomics and genomics</article-title>. <source>PLoS ONE</source>
<volume>10</volume>:<fpage>e0141287</fpage>. <pub-id pub-id-type="doi">10.1371/journal.pone.0141287</pub-id><?supplied-pmid 26555596?><pub-id pub-id-type="pmid">26555596</pub-id></mixed-citation>
    </ref>
    <ref id="B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bengio</surname><given-names>Y.</given-names></name><name><surname>Courville</surname><given-names>A. C.</given-names></name><name><surname>Vincent</surname><given-names>P.</given-names></name></person-group> (<year>2013</year>). <article-title>Representation learning: a review and new perspectives</article-title>. <source>IEEE T. Pattern Anal.</source>
<volume>35</volume>, <fpage>1798</fpage>â<lpage>1828</lpage>. <pub-id pub-id-type="doi">10.1109/TPAMI.2013.50</pub-id><?supplied-pmid 23787338?><pub-id pub-id-type="pmid">23787338</pub-id></mixed-citation>
    </ref>
    <ref id="B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cai</surname><given-names>Y.</given-names></name><name><surname>Liu</surname><given-names>X.</given-names></name><name><surname>Xu</surname><given-names>X.</given-names></name><name><surname>Chou</surname><given-names>K.</given-names></name></person-group> (<year>2002</year>). <article-title>Support vector machines for prediction of protein subcellular location by incorporating quasi-sequence-order effect</article-title>. <source>J. Cell. Biochem.</source>
<volume>84</volume>, <fpage>343</fpage>â<lpage>348</lpage>. <pub-id pub-id-type="doi">10.1002/jcb.10030</pub-id><?supplied-pmid 11787063?><pub-id pub-id-type="pmid">11787063</pub-id></mixed-citation>
    </ref>
    <ref id="B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>X.</given-names></name><name><surname>Liu</surname><given-names>M.</given-names></name><name><surname>Yan</surname><given-names>G.</given-names></name></person-group> (<year>2012</year>). <article-title>Drugâtarget interaction prediction by random walk on the heterogeneous network</article-title>. <source>Mol. Biosyst.</source>
<volume>8</volume>, <fpage>1970</fpage>â<lpage>1978</lpage>. <pub-id pub-id-type="doi">10.1039/c2mb00002d</pub-id><?supplied-pmid 22538619?><pub-id pub-id-type="pmid">22538619</pub-id></mixed-citation>
    </ref>
    <ref id="B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Coley</surname><given-names>C. W.</given-names></name><name><surname>Barzilay</surname><given-names>R.</given-names></name><name><surname>Green</surname><given-names>W. H.</given-names></name><name><surname>Jaakkola</surname><given-names>T. S.</given-names></name><name><surname>Jensen</surname><given-names>K. F.</given-names></name></person-group> (<year>2017</year>). <article-title>Convolutional embedding of attributed molecular graphs for physical property prediction</article-title>. <source>J. Chem. Inf. Model.</source>
<volume>57</volume>:<fpage>1757</fpage>. <pub-id pub-id-type="doi">10.1021/acs.jcim.6b00601</pub-id><?supplied-pmid 28696688?><pub-id pub-id-type="pmid">28696688</pub-id></mixed-citation>
    </ref>
    <ref id="B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Collobert</surname><given-names>R.</given-names></name><name><surname>Weston</surname><given-names>J.</given-names></name></person-group> (<year>2008</year>). <article-title>A unified architecture for natural language processing: deep neural networks with multitask learning</article-title>. <source>ACM</source>
<volume>8</volume>, <fpage>160</fpage>â<lpage>167</lpage>. <pub-id pub-id-type="doi">10.1145/1390156.1390177</pub-id></mixed-citation>
    </ref>
    <ref id="B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Corey</surname><given-names>E. J.</given-names></name><name><surname>Wipke</surname><given-names>W. T.</given-names></name></person-group> (<year>1969</year>). <article-title>Computer-assisted design of complex organic syntheses</article-title>. <source>Science</source>
<volume>166</volume>, <fpage>178</fpage>â<lpage>192</lpage>. <pub-id pub-id-type="doi">10.1126/science.166.3902.178</pub-id><?supplied-pmid 17731475?><pub-id pub-id-type="pmid">17731475</pub-id></mixed-citation>
    </ref>
    <ref id="B8">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cortes</surname><given-names>C.</given-names></name><name><surname>Vapnik</surname><given-names>V.</given-names></name></person-group> (<year>1995</year>). <article-title>Support-vector networks</article-title>. <source>Mach. Learn.</source>
<volume>20</volume>, <fpage>273</fpage>â<lpage>297</lpage>. <pub-id pub-id-type="doi">10.1007/BF00994018</pub-id></mixed-citation>
    </ref>
    <ref id="B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Der Maaten</surname><given-names>L. V.</given-names></name><name><surname>Hinton</surname><given-names>G. E.</given-names></name></person-group> (<year>2008</year>). <article-title>Visualizing data using t-SNE</article-title>. <source>J. Mach. Learn. Res.</source>
<volume>9</volume>, <fpage>2579</fpage>â<lpage>2605</lpage>.</mixed-citation>
    </ref>
    <ref id="B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ewing</surname><given-names>T.</given-names></name><name><surname>Baber</surname><given-names>J. C.</given-names></name><name><surname>Feher</surname><given-names>M.</given-names></name></person-group> (<year>2006</year>). <article-title>Novel 2D fingerprints for ligand-based virtual screening</article-title>. <source>J. Chem. Inf. Model.</source>
<volume>46</volume>, <fpage>2423</fpage>â<lpage>2431</lpage>. <pub-id pub-id-type="doi">10.1021/ci060155b</pub-id><?supplied-pmid 17125184?><pub-id pub-id-type="pmid">17125184</pub-id></mixed-citation>
    </ref>
    <ref id="B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ezzat</surname><given-names>A.</given-names></name><name><surname>Wu</surname><given-names>M.</given-names></name><name><surname>Li</surname><given-names>X. L.</given-names></name><name><surname>Kwoh</surname><given-names>C. K.</given-names></name></person-group> (<year>2016</year>). <article-title>Drug-target interaction prediction via class imbalance-aware ensemble learning</article-title>. <source>BMC Bioinf.</source>
<volume>17</volume>, <fpage>267</fpage>â<lpage>276</lpage>. <pub-id pub-id-type="doi">10.1186/s12859-016-1377-y</pub-id><?supplied-pmid 28155697?><pub-id pub-id-type="pmid">28155697</pub-id></mixed-citation>
    </ref>
    <ref id="B12">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ezzat</surname><given-names>A.</given-names></name><name><surname>Wu</surname><given-names>M.</given-names></name><name><surname>Li</surname><given-names>X. L.</given-names></name><name><surname>Kwoh</surname><given-names>C. K.</given-names></name></person-group> (<year>2017</year>). <article-title>Drug-target interaction prediction using ensemble learning and dimensionality reduction</article-title>. <source>Methods</source>
<volume>129</volume>, <fpage>81</fpage>â<lpage>88</lpage>. <pub-id pub-id-type="doi">10.1016/j.ymeth.2017.05.016</pub-id><?supplied-pmid 28549952?><pub-id pub-id-type="pmid">28549952</pub-id></mixed-citation>
    </ref>
    <ref id="B13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Friedman</surname><given-names>J. H.</given-names></name></person-group> (<year>2001</year>). <article-title>Greedy function approximation: a gradient boosting machine</article-title>. <source>Ann. Stat.</source>
<volume>29</volume>, <fpage>1189</fpage>â<lpage>1232</lpage>. <pub-id pub-id-type="doi">10.1214/aos/1013203451</pub-id></mixed-citation>
    </ref>
    <ref id="B14">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gaulton</surname><given-names>A.</given-names></name><name><surname>Hersey</surname><given-names>A.</given-names></name><name><surname>Nowotka</surname><given-names>M.</given-names></name><name><surname>Bento</surname><given-names>A. P.</given-names></name><name><surname>Chambers</surname><given-names>J.</given-names></name><name><surname>Mendez</surname><given-names>D.</given-names></name><etal/></person-group>. (<year>2017</year>). <article-title>The ChEMBL database in 2017</article-title>. <source>Nucleic Acids Res.</source><volume>45</volume>, <fpage>D945</fpage>â<lpage>D954</lpage>. <pub-id pub-id-type="doi">10.1093/nar/gkw1074</pub-id><?supplied-pmid 27899562?><pub-id pub-id-type="pmid">27899562</pub-id></mixed-citation>
    </ref>
    <ref id="B15">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gilson</surname><given-names>M. K.</given-names></name><name><surname>Liu</surname><given-names>T.</given-names></name><name><surname>Baitaluk</surname><given-names>M.</given-names></name><name><surname>Nicola</surname><given-names>G.</given-names></name><name><surname>Hwang</surname><given-names>L.</given-names></name><name><surname>Chong</surname><given-names>J.</given-names></name></person-group> (<year>2016</year>). <article-title>BindingDB in 2015: a public database for medicinal chemistry, computational chemistry and systems pharmacology</article-title>. <source>Nucleic Acids Res.</source>
<volume>44</volume>, <fpage>1045</fpage>â<lpage>1053</lpage>. <pub-id pub-id-type="doi">10.1093/nar/gkv1072</pub-id><?supplied-pmid 26481362?><pub-id pub-id-type="pmid">26481362</pub-id></mixed-citation>
    </ref>
    <ref id="B16">
      <mixed-citation publication-type="webpage"><person-group person-group-type="author"><name><surname>Goh</surname><given-names>G. B.</given-names></name><name><surname>Hodas</surname><given-names>N. O.</given-names></name><name><surname>Siegel</surname><given-names>C.</given-names></name><name><surname>Vishnu</surname><given-names>A.</given-names></name></person-group> (<year>2017a</year>). <article-title>Smiles2vec: an interpretable general-purpose deep neural network for predicting chemical properties</article-title>. <source>arXiv [Preprint]</source>. Available online at: <ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1712.02034">https://arxiv.org/abs/1712.02034</ext-link> (accessed December 6, 2017).</mixed-citation>
    </ref>
    <ref id="B17">
      <mixed-citation publication-type="webpage"><person-group person-group-type="author"><name><surname>Goh</surname><given-names>G. B.</given-names></name><name><surname>Siegel</surname><given-names>C.</given-names></name><name><surname>Vishnu</surname><given-names>A.</given-names></name><name><surname>Hodas</surname><given-names>N. O.</given-names></name><name><surname>Baker</surname><given-names>N.</given-names></name></person-group> (<year>2017b</year>). <article-title>Chemception: a deep neural network with minimal chemistry knowledge matches the performance of expert-developed QSAR/QSPR models</article-title>. <source>arXiv [Preprint]</source>. Available online at: <ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1706.06689">https://arxiv.org/abs/1706.06689</ext-link> (accessed June 20, 2017).</mixed-citation>
    </ref>
    <ref id="B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Haggarty</surname><given-names>S. J.</given-names></name><name><surname>Koeller</surname><given-names>K. M.</given-names></name><name><surname>Wong</surname><given-names>J. C.</given-names></name><name><surname>Butcher</surname><given-names>R. A.</given-names></name><name><surname>Schreiber</surname><given-names>S. L.</given-names></name></person-group> (<year>2003</year>). <article-title>Multidimensional chemical genetic analysis of diversity-oriented synthesis-derived deacetylase inhibitors using cell-based assays</article-title>. <source>Chem. Biol.</source>
<volume>10</volume>, <fpage>383</fpage>â<lpage>396</lpage>. <pub-id pub-id-type="doi">10.1016/S1074-5521(03)00095-4</pub-id><?supplied-pmid 12770821?><pub-id pub-id-type="pmid">12770821</pub-id></mixed-citation>
    </ref>
    <ref id="B19">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>He</surname><given-names>Z.</given-names></name><name><surname>Zhang</surname><given-names>J.</given-names></name><name><surname>Shi</surname><given-names>X.</given-names></name><name><surname>Hu</surname><given-names>L.</given-names></name><name><surname>Kong</surname><given-names>X.</given-names></name><name><surname>Cai</surname><given-names>Y.</given-names></name><etal/></person-group>. (<year>2010</year>). <article-title>Predicting drug-target interaction networks based on functional groups and biological features</article-title>. <source>PLoS ONE</source><volume>5</volume>:<fpage>e9603</fpage>. <pub-id pub-id-type="doi">10.1371/journal.pone.0009603</pub-id><?supplied-pmid 20300175?><pub-id pub-id-type="pmid">20300175</pub-id></mixed-citation>
    </ref>
    <ref id="B20">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ho</surname><given-names>T. K.</given-names></name></person-group> (<year>1998</year>). <article-title>The random subspace method for constructing decision forests</article-title>. <source>IEEE T. Pattern Anal.</source>
<volume>20</volume>, <fpage>832</fpage>â<lpage>844</lpage>. <pub-id pub-id-type="doi">10.1109/34.709601</pub-id></mixed-citation>
    </ref>
    <ref id="B21">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hong</surname><given-names>H.</given-names></name><name><surname>Xie</surname><given-names>Q.</given-names></name><name><surname>Ge</surname><given-names>W.</given-names></name><name><surname>Qian</surname><given-names>F.</given-names></name><name><surname>Fang</surname><given-names>H.</given-names></name><name><surname>Shi</surname><given-names>L.</given-names></name><etal/></person-group>. (<year>2008</year>). <article-title>Mold(2), molecular descriptors from 2D structures for chemoinformatics and toxicoinformatics</article-title>. <source>J. Chem. Inf. Model.</source><volume>48</volume>, <fpage>1337</fpage>â<lpage>1344</lpage>. <pub-id pub-id-type="doi">10.1021/ci800038f</pub-id><?supplied-pmid 18564836?><pub-id pub-id-type="pmid">18564836</pub-id></mixed-citation>
    </ref>
    <ref id="B22">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jaeger</surname><given-names>S.</given-names></name><name><surname>Fulle</surname><given-names>S.</given-names></name><name><surname>Turk</surname><given-names>S.</given-names></name></person-group> (<year>2018</year>). <article-title>Mol2vec: unsupervised machine learning approach with chemical intuition</article-title>. <source>J. Chem. Inf. Model.</source>
<volume>58</volume>, <fpage>27</fpage>â<lpage>35</lpage>. <pub-id pub-id-type="doi">10.1021/acs.jcim.7b00616</pub-id><?supplied-pmid 29268609?><pub-id pub-id-type="pmid">29268609</pub-id></mixed-citation>
    </ref>
    <ref id="B23">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kanehisa</surname><given-names>M.</given-names></name><name><surname>Goto</surname><given-names>S.</given-names></name></person-group> (<year>2000</year>). <article-title>KEGG: kyoto encyclopedia of genes and genomes</article-title>. <source>Nucleic Acids Res.</source>
<volume>27</volume>, <fpage>29</fpage>â<lpage>34</lpage>. <pub-id pub-id-type="doi">10.1093/nar/28.1.27</pub-id><?supplied-pmid 9847135?><pub-id pub-id-type="pmid">9847135</pub-id></mixed-citation>
    </ref>
    <ref id="B24">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kearnes</surname><given-names>S.</given-names></name><name><surname>Mccloskey</surname><given-names>K.</given-names></name><name><surname>Berndl</surname><given-names>M.</given-names></name><name><surname>Pande</surname><given-names>V.</given-names></name><name><surname>Riley</surname><given-names>P.</given-names></name></person-group> (<year>2016</year>). <article-title>Molecular graph convolutions: moving beyond fingerprints</article-title>. <source>J. Comput. Aid. Mol. Des.</source>
<volume>30</volume>, <fpage>1</fpage>â<lpage>14</lpage>. <pub-id pub-id-type="doi">10.1007/s10822-016-9938-8</pub-id><?supplied-pmid 27558503?><pub-id pub-id-type="pmid">27558503</pub-id></mixed-citation>
    </ref>
    <ref id="B25">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kuruvilla</surname><given-names>F. G.</given-names></name><name><surname>Shamji</surname><given-names>A. F.</given-names></name><name><surname>Sternson</surname><given-names>S. M.</given-names></name><name><surname>Hergenrother</surname><given-names>P. J.</given-names></name><name><surname>Schreiber</surname><given-names>S. L.</given-names></name></person-group> (<year>2002</year>). <article-title>Dissecting glucose signalling with diversity-oriented synthesis and small-molecule microarrays</article-title>. <source>Nature</source>
<volume>416</volume>, <fpage>653</fpage>â<lpage>657</lpage>. <pub-id pub-id-type="doi">10.1038/416653a</pub-id><?supplied-pmid 11948353?><pub-id pub-id-type="pmid">11948353</pub-id></mixed-citation>
    </ref>
    <ref id="B26">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Law</surname><given-names>V.</given-names></name><name><surname>Knox</surname><given-names>C.</given-names></name><name><surname>Djoumbou</surname><given-names>Y.</given-names></name><name><surname>Jewison</surname><given-names>T.</given-names></name><name><surname>Guo</surname><given-names>A.</given-names></name><name><surname>Liu</surname><given-names>Y.</given-names></name><etal/></person-group>. (<year>2014</year>). <article-title>DrugBank 4.0: shedding new light on drug metabolism</article-title>. <source>Nucleic Acids Res.</source><volume>42</volume>, <fpage>1091</fpage>â<lpage>1097</lpage>. <pub-id pub-id-type="doi">10.1093/nar/gkt1068</pub-id><?supplied-pmid 24203711?><pub-id pub-id-type="pmid">24203711</pub-id></mixed-citation>
    </ref>
    <ref id="B27">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>W.</given-names></name><name><surname>Wang</surname><given-names>Z.</given-names></name><name><surname>Liu</surname><given-names>X.</given-names></name><name><surname>Zeng</surname><given-names>N.</given-names></name><name><surname>Liu</surname><given-names>Y.</given-names></name><name><surname>Alsaadi</surname><given-names>F. E.</given-names></name></person-group> (<year>2017</year>). <article-title>A survey of deep neural network architectures and their applications</article-title>. <source>Neurocomputing</source>
<volume>234</volume>, <fpage>11</fpage>â<lpage>26</lpage>. <pub-id pub-id-type="doi">10.1016/j.neucom.2016.12.038</pub-id></mixed-citation>
    </ref>
    <ref id="B28">
      <mixed-citation publication-type="webpage"><person-group person-group-type="author"><name><surname>Mikolov</surname><given-names>T.</given-names></name><name><surname>Chen</surname><given-names>K.</given-names></name><name><surname>Corrado</surname><given-names>G.</given-names></name><name><surname>Dean</surname><given-names>J.</given-names></name></person-group> (<year>2013a</year>). <article-title>Efficient estimation of word representations in vector space</article-title>. <source>arXiv [Preprint]</source>. Available online at: <ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1706.06689">https://arxiv.org/abs/1706.06689</ext-link> (accessed June 20, 2019).</mixed-citation>
    </ref>
    <ref id="B29">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mikolov</surname><given-names>T.</given-names></name><name><surname>Sutskever</surname><given-names>I.</given-names></name><name><surname>Chen</surname><given-names>K.</given-names></name><name><surname>Corrado</surname><given-names>G. S.</given-names></name><name><surname>Dean</surname><given-names>J.</given-names></name></person-group> (<year>2013b</year>). <article-title>Distributed representations of words and phrases and their compositionality</article-title>. <source>ACM</source>
<volume>13</volume>, <fpage>3111</fpage>â<lpage>3119</lpage>.</mixed-citation>
    </ref>
    <ref id="B30">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Morgan</surname><given-names>H. L.</given-names></name></person-group> (<year>1965</year>). <article-title>The generation of a unique machine description for chemical structures-A technique developed at chemical abstracts service</article-title>. <source>J. Chem. Doc.</source>
<volume>5</volume>, <fpage>107</fpage>â<lpage>113</lpage>. <pub-id pub-id-type="doi">10.1021/c160017a018</pub-id></mixed-citation>
    </ref>
    <ref id="B31">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nakashima</surname><given-names>H.</given-names></name><name><surname>Nishikawa</surname><given-names>K.</given-names></name></person-group> (<year>1994</year>). <article-title>Discrimination of intracellular and extracellular proteins using amino acid composition and residue-pair frequencies</article-title>. <source>J. Mol. Biol.</source>
<volume>238</volume>, <fpage>54</fpage>â<lpage>61</lpage>. <pub-id pub-id-type="doi">10.1006/jmbi.1994.1267</pub-id><?supplied-pmid 8145256?><pub-id pub-id-type="pmid">8145256</pub-id></mixed-citation>
    </ref>
    <ref id="B32">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nanni</surname><given-names>L.</given-names></name><name><surname>Lumini</surname><given-names>A.</given-names></name><name><surname>Brahnam</surname><given-names>S.</given-names></name></person-group> (<year>2014</year>). <article-title>A set of descriptors for identifying the proteinâdrug interaction in cellular networking</article-title>. <source>J. Theor. Biol.</source>
<volume>359</volume>, <fpage>120</fpage>â<lpage>128</lpage>. <pub-id pub-id-type="doi">10.1016/j.jtbi.2014.06.008</pub-id><?supplied-pmid 24949993?><pub-id pub-id-type="pmid">24949993</pub-id></mixed-citation>
    </ref>
    <ref id="B33">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nascimento</surname><given-names>A. C. A.</given-names></name><name><surname>PrudÃªncio</surname><given-names>R. B. C.</given-names></name><name><surname>Costa</surname><given-names>I. G.</given-names></name></person-group> (<year>2016</year>). <article-title>A multiple kernel learning algorithm for drug-target interaction prediction</article-title>. <source>BMC Bioinf.</source>
<volume>17</volume>:<fpage>46</fpage>. <pub-id pub-id-type="doi">10.1186/s12859-016-0890-3</pub-id><?supplied-pmid 26801218?><pub-id pub-id-type="pmid">26801218</pub-id></mixed-citation>
    </ref>
    <ref id="B34">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Patel</surname><given-names>P. R.</given-names></name><name><surname>Sun</surname><given-names>H.</given-names></name><name><surname>Li</surname><given-names>S. Q.</given-names></name><name><surname>Shen</surname><given-names>M.</given-names></name><name><surname>Khan</surname><given-names>J.</given-names></name><name><surname>Thomas</surname><given-names>C. J.</given-names></name><etal/></person-group>. (<year>2013</year>). <article-title>Identification of potent yes1 kinase inhibitors using a library screening approach</article-title>. <source>Bioorg. Med. Chem. Lett.</source><volume>23</volume>, <fpage>4398</fpage>â<lpage>4403</lpage>. <pub-id pub-id-type="doi">10.1016/j.bmcl.2013.05.072</pub-id><?supplied-pmid 23787099?><pub-id pub-id-type="pmid">23787099</pub-id></mixed-citation>
    </ref>
    <ref id="B35">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pedregosa</surname><given-names>F.</given-names></name><name><surname>Varoquaux</surname><given-names>G.</given-names></name><name><surname>Gramfort</surname><given-names>A.</given-names></name><name><surname>Michel</surname><given-names>V.</given-names></name><name><surname>Thirion</surname><given-names>B.</given-names></name><name><surname>Grisel</surname><given-names>O.</given-names></name><etal/></person-group> (<year>2011</year>). <article-title>Scikit-learn: machine learning in python</article-title>. <source>J. Mach. Learn. Res.</source>
<volume>12</volume>, <fpage>2825</fpage>â<lpage>2830</lpage>. <pub-id pub-id-type="doi">10.1524/auto.2011.0951</pub-id></mixed-citation>
    </ref>
    <ref id="B36">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rayhan</surname><given-names>F.</given-names></name><name><surname>Ahmed</surname><given-names>S.</given-names></name><name><surname>Shatabda</surname><given-names>S.</given-names></name><name><surname>Farid</surname><given-names>D. M.</given-names></name><name><surname>Mousavian</surname><given-names>Z.</given-names></name><name><surname>Dehzangi</surname><given-names>A.</given-names></name><etal/></person-group>. (<year>2017</year>). <article-title>iDTI-ESBoost: identification of drug target interaction using evolutionary and structural features with boosting</article-title>. <source>Sci. Rep.</source><volume>7</volume>:<fpage>17731</fpage>. <pub-id pub-id-type="doi">10.1038/s41598-017-18025-2</pub-id><?supplied-pmid 29255285?><pub-id pub-id-type="pmid">29255285</pub-id></mixed-citation>
    </ref>
    <ref id="B37">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schneider</surname><given-names>N.</given-names></name><name><surname>Fechner</surname><given-names>N.</given-names></name><name><surname>Landrum</surname><given-names>G. A.</given-names></name><name><surname>Stiefl</surname><given-names>N.</given-names></name></person-group> (<year>2017</year>). <article-title>Chemical topic modeling: exploring molecular data sets using a common text-mining approach</article-title>. <source>J. Chem. Inf. Model.</source>
<volume>57</volume>, <fpage>1816</fpage>â<lpage>1831</lpage>. <pub-id pub-id-type="doi">10.1021/acs.jcim.7b00249</pub-id><?supplied-pmid 28715190?><pub-id pub-id-type="pmid">28715190</pub-id></mixed-citation>
    </ref>
    <ref id="B38">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sharif Razavian</surname><given-names>A.</given-names></name><name><surname>Azizpour</surname><given-names>H.</given-names></name><name><surname>Sullivan</surname><given-names>J.</given-names></name><name><surname>Carlsson</surname><given-names>S.</given-names></name></person-group> (<year>2014</year>). <article-title>CNN features off-the-shelf: an astounding baseline for recognition</article-title>. <source>IEEE</source>
<volume>5</volume>, <fpage>512</fpage>â<lpage>519</lpage>. <pub-id pub-id-type="doi">10.1109/CVPRW.2014.131</pub-id></mixed-citation>
    </ref>
    <ref id="B39">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Valentin</surname><given-names>J.</given-names></name><name><surname>Guillon</surname><given-names>J.</given-names></name><name><surname>Jenkinson</surname><given-names>S.</given-names></name><name><surname>Kadambi</surname><given-names>V. J.</given-names></name><name><surname>Ravikumar</surname><given-names>P.</given-names></name><name><surname>Roberts</surname><given-names>S.</given-names></name><etal/></person-group>. (<year>2018</year>). <article-title><italic>In vitro</italic> secondary pharmacological profiling: an IQ-drusafe industry survey on current practices</article-title>. <source>J. Pharmacol. Tox. Met.</source><volume>93</volume>, <fpage>7</fpage>â<lpage>14</lpage>. <pub-id pub-id-type="doi">10.1016/j.vascn.2018.07.001</pub-id><?supplied-pmid 30030184?><pub-id pub-id-type="pmid">30030184</pub-id></mixed-citation>
    </ref>
    <ref id="B40">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Van Aalten</surname><given-names>D. M. F.</given-names></name><name><surname>Bywater</surname><given-names>R. P.</given-names></name><name><surname>Findlay</surname><given-names>J. B. C.</given-names></name><name><surname>Hendlich</surname><given-names>M.</given-names></name><name><surname>Hooft</surname><given-names>R. W. W.</given-names></name><name><surname>Vriend</surname><given-names>G.</given-names></name></person-group> (<year>1996</year>). <article-title>PRODRG, a program for generating molecular topologies and unique molecular descriptors from coordinates of small molecules</article-title>. <source>J. Comput. Aid. Mol. Des.</source>
<volume>10</volume>, <fpage>255</fpage>â<lpage>262</lpage>. <pub-id pub-id-type="doi">10.1007/BF00355047</pub-id><?supplied-pmid 8808741?><pub-id pub-id-type="pmid">8808741</pub-id></mixed-citation>
    </ref>
    <ref id="B41">
      <mixed-citation publication-type="webpage"><person-group person-group-type="author"><name><surname>Wan</surname><given-names>F.</given-names></name><name><surname>Zeng</surname><given-names>J.</given-names></name></person-group> (<year>2016</year>). <article-title>Deep learning with feature embedding for compound-protein interaction prediction</article-title>. <source>bioRxiv [Preprint]</source>. Available online at: <ext-link ext-link-type="uri" xlink:href="https://www.biorxiv.org/content/10.1101/086033v1">https://www.biorxiv.org/content/10.1101/086033v1</ext-link> (accessed November 07, 2016).</mixed-citation>
    </ref>
    <ref id="B42">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>Y.</given-names></name><name><surname>Xiao</surname><given-names>J.</given-names></name><name><surname>Suzek</surname><given-names>T. O.</given-names></name><name><surname>Jian</surname><given-names>Z.</given-names></name><name><surname>Wang</surname><given-names>J.</given-names></name><name><surname>Bryant</surname><given-names>S. H.</given-names></name></person-group> (<year>2009</year>). <article-title>PubChem: a public information system for analyzing bioactivities of small molecules</article-title>. <source>Nucleic Acids Res.</source>
<volume>37</volume>, <fpage>W623</fpage>â<lpage>W633</lpage>. <pub-id pub-id-type="doi">10.1093/nar/gkp456</pub-id><?supplied-pmid 19498078?><pub-id pub-id-type="pmid">19498078</pub-id></mixed-citation>
    </ref>
    <ref id="B43">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>You</surname><given-names>J.</given-names></name><name><surname>McLeod</surname><given-names>R. D.</given-names></name><name><surname>Hu</surname><given-names>P.</given-names></name></person-group> (<year>2019</year>). <article-title>Predicting drug-target interaction network using deep learning model</article-title>. <source>Comput. Biol. Chem.</source>
<volume>80</volume>, <fpage>90</fpage>â<lpage>101</lpage>. <pub-id pub-id-type="doi">10.1016/j.compbiolchem.2019.03.016</pub-id><?supplied-pmid 30939415?><pub-id pub-id-type="pmid">30939415</pub-id></mixed-citation>
    </ref>
    <ref id="B44">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yu</surname><given-names>H.</given-names></name><name><surname>Chen</surname><given-names>J.</given-names></name><name><surname>Xu</surname><given-names>X.</given-names></name><name><surname>Li</surname><given-names>Y.</given-names></name><name><surname>Zhao</surname><given-names>H.</given-names></name><name><surname>Fang</surname><given-names>Y.</given-names></name><etal/></person-group>. (<year>2012</year>). <article-title>A systematic prediction of multiple drug-target interactions from chemical, genomic, and pharmacological data</article-title>. <source>PLoS ONE</source><volume>7</volume>:<fpage>e37608</fpage>. <pub-id pub-id-type="doi">10.1371/journal.pone.0037608</pub-id><?supplied-pmid 22666371?><pub-id pub-id-type="pmid">22666371</pub-id></mixed-citation>
    </ref>
    <ref id="B45">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>H.</given-names></name><name><surname>Liao</surname><given-names>L.</given-names></name><name><surname>Cai</surname><given-names>Y.</given-names></name><name><surname>Hu</surname><given-names>Y.</given-names></name><name><surname>Wang</surname><given-names>H.</given-names></name></person-group> (<year>2019</year>). <article-title>IVS2vec: a tool of inverse virtual screening based on word2vec and deep learning techniques</article-title>. <source>Methods</source>
<volume>66</volume>, <fpage>57</fpage>â<lpage>65</lpage>. <pub-id pub-id-type="doi">10.1016/j.ymeth.2019.03.012</pub-id></mixed-citation>
    </ref>
    <ref id="B46">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>P.</given-names></name><name><surname>Tao</surname><given-names>L.</given-names></name><name><surname>Zeng</surname><given-names>X.</given-names></name><name><surname>Qin</surname><given-names>C.</given-names></name><name><surname>Chen</surname><given-names>S.</given-names></name><name><surname>Zhu</surname><given-names>F.</given-names></name><etal/></person-group>. (<year>2016</year>). <article-title>A protein network descriptor server and its use in studying protein, disease, metabolic and drug targeted networks</article-title>. <source>Brief. Bioinform.</source><volume>18</volume>, <fpage>1057</fpage>â<lpage>1070</lpage>. <pub-id pub-id-type="doi">10.1093/bib/bbw071</pub-id><?supplied-pmid 27542402?><pub-id pub-id-type="pmid">27542402</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
