<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with OASIS Tables with MathML3 v1.1 20151215//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-archive-oasis-article1-mathml3.dtd?>
<?SourceDTD.Version 1.1?>
<?ConverterInfo.XSLTName jpoasis-nisons2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Appl Plant Sci</journal-id>
    <journal-id journal-id-type="iso-abbrev">Appl Plant Sci</journal-id>
    <journal-id journal-id-type="doi">10.1002/(ISSN)2168-0450</journal-id>
    <journal-id journal-id-type="publisher-id">APS3</journal-id>
    <journal-title-group>
      <journal-title>Applications in Plant Sciences</journal-title>
    </journal-title-group>
    <issn pub-type="epub">2168-0450</issn>
    <publisher>
      <publisher-name>John Wiley and Sons Inc.</publisher-name>
      <publisher-loc>Hoboken</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">7328653</article-id>
    <article-id pub-id-type="doi">10.1002/aps3.11367</article-id>
    <article-id pub-id-type="publisher-id">APS311367</article-id>
    <article-categories>
      <subj-group subj-group-type="overline">
        <subject>Software Note</subject>
      </subj-group>
      <subj-group subj-group-type="heading">
        <subject>Software Notes</subject>
        <subj-group subj-group-type="heading">
          <subject>Invited Special Article</subject>
          <subj-group subj-group-type="heading">
            <subject>Article</subject>
          </subj-group>
        </subj-group>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>LeafMachine: Using machine learning to automate leaf trait extraction from digitized herbarium specimens</article-title>
      <alt-title alt-title-type="right-running-head">LeafMachine: Autonomous leaf measurement</alt-title>
      <alt-title alt-title-type="left-running-head">Weaver et al.</alt-title>
    </title-group>
    <contrib-group>
      <contrib id="aps311367-cr-0001" contrib-type="author" corresp="yes">
        <name>
          <surname>Weaver</surname>
          <given-names>William N.</given-names>
        </name>
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0003-0633-5066</contrib-id>
        <xref ref-type="aff" rid="aps311367-aff-0001">
          <sup>1</sup>
        </xref>
        <xref ref-type="aff" rid="aps311367-curr-0001">
          <sup>2</sup>
        </xref>
        <address>
          <email>willwe@umich.edu</email>
        </address>
      </contrib>
      <contrib id="aps311367-cr-0002" contrib-type="author">
        <name>
          <surname>Ng</surname>
          <given-names>Julienne</given-names>
        </name>
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-2994-6233</contrib-id>
        <xref ref-type="aff" rid="aps311367-aff-0001">
          <sup>1</sup>
        </xref>
      </contrib>
      <contrib id="aps311367-cr-0003" contrib-type="author">
        <name>
          <surname>Laport</surname>
          <given-names>Robert G.</given-names>
        </name>
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0001-5672-0929</contrib-id>
        <xref ref-type="aff" rid="aps311367-aff-0003">
          <sup>3</sup>
        </xref>
      </contrib>
    </contrib-group>
    <aff id="aps311367-aff-0001">
      <label>
        <sup>1</sup>
      </label>
      <named-content content-type="organisation-division">Department of Ecology and Evolutionary Biology</named-content>
      <institution>University of Colorado Boulder</institution>
      <city>Boulder</city>
      <named-content content-type="country-part">Colorado</named-content>
      <postal-code>80309</postal-code>
      <country country="US">USA</country>
    </aff>
    <aff id="aps311367-curr-0001"><label><sup>2</sup></label>Present address:
<named-content content-type="organisation-division">Department of Ecology and Evolutionary Biology</named-content><institution>University of Michigan</institution><city>Ann Arbor</city><named-content content-type="country-part">Michigan</named-content><postal-code>48109</postal-code><country country="US">USA</country></aff>
    <aff id="aps311367-aff-0003">
      <label>
        <sup>3</sup>
      </label>
      <named-content content-type="organisation-division">Department of Biology</named-content>
      <institution>Rhodes College</institution>
      <city>Memphis</city>
      <named-content content-type="country-part">Tennessee</named-content>
      <postal-code>38112</postal-code>
      <country country="US">USA</country>
    </aff>
    <author-notes>
      <corresp id="correspondenceTo"><label>*</label><sup>5</sup>Author for correspondence: <email>willwe@umich.edu</email><break/></corresp>
    </author-notes>
    <pub-date pub-type="epub">
      <day>01</day>
      <month>7</month>
      <year>2020</year>
    </pub-date>
    <pub-date pub-type="collection">
      <month>6</month>
      <year>2020</year>
    </pub-date>
    <volume>8</volume>
    <issue>6</issue>
    <issue-id pub-id-type="doi">10.1002/aps3.v8.6</issue-id>
    <issue-title content-type="special-issue-title">Machine Learning in Plant Biology: Advances Using Herbarium Specimen Images</issue-title>
    <elocation-id>e11367</elocation-id>
    <history>
      <date date-type="received">
        <day>14</day>
        <month>10</month>
        <year>2019</year>
      </date>
      <date date-type="accepted">
        <day>24</day>
        <month>1</month>
        <year>2020</year>
      </date>
    </history>
    <permissions>
      <!--<copyright-statement content-type="issue-copyright"> &#x000a9; 2020 Botanical Society of America <copyright-statement>-->
      <copyright-statement content-type="article-copyright">© 2020 The Authors. <italic>Applications in Plant Sciences</italic> is published by Wiley Periodicals, LLC on behalf of the Botanical Society of America</copyright-statement>
      <license license-type="creativeCommonsBy">
        <license-p>This is an open access article under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link> License, which permits use, distribution and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri content-type="pdf" xlink:href="file:APS3-8-e11367.pdf"/>
    <abstract id="aps311367-abs-0001">
      <sec id="aps311367-sec-0001">
        <title>Premise</title>
        <p>Obtaining phenotypic data from herbarium specimens can provide important insights into plant evolution and ecology but requires significant manual effort and time. Here, we present LeafMachine, an application designed to autonomously measure leaves from digitized herbarium specimens or leaf images using an ensemble of machine learning algorithms.</p>
      </sec>
      <sec id="aps311367-sec-0002">
        <title>Methods and Results</title>
        <p>We trained LeafMachine on 2685 randomly sampled specimens from 138 herbaria and evaluated its performance on specimens spanning 20 diverse families and varying widely in resolution, quality, and layout. LeafMachine successfully extracted at least one leaf measurement from 82.0% and 60.8% of high‐ and low‐resolution images, respectively. Of the unmeasured specimens, only 0.9% and 2.1% of high‐ and low‐resolution images, respectively, were visually judged to have measurable leaves.</p>
      </sec>
      <sec id="aps311367-sec-0003">
        <title>Conclusions</title>
        <p>This flexible autonomous tool has the potential to vastly increase available trait information from herbarium specimens, and inform a multitude of evolutionary and ecological studies.</p>
      </sec>
    </abstract>
    <kwd-group>
      <kwd id="aps311367-kwd-0001">computer vision</kwd>
      <kwd id="aps311367-kwd-0002">herbarium digitization</kwd>
      <kwd id="aps311367-kwd-0003">LeafMachine</kwd>
      <kwd id="aps311367-kwd-0004">leaf morphology</kwd>
      <kwd id="aps311367-kwd-0005">machine learning</kwd>
    </kwd-group>
    <funding-group>
      <award-group id="funding-0001">
        <funding-source>
          <institution-wrap>
            <institution>University of Colorado </institution>
            <institution-id institution-id-type="open-funder-registry">10.13039/100010174</institution-id>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group id="funding-0002">
        <funding-source>
          <institution-wrap>
            <institution>National Science Foundation </institution>
            <institution-id institution-id-type="open-funder-registry">10.13039/100000001</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>NSF‐EF 1550813</award-id>
      </award-group>
    </funding-group>
    <counts>
      <fig-count count="2"/>
      <table-count count="2"/>
      <page-count count="8"/>
      <word-count count="6505"/>
    </counts>
    <custom-meta-group>
      <custom-meta>
        <meta-name>source-schema-version-number</meta-name>
        <meta-value>2.0</meta-value>
      </custom-meta>
      <custom-meta>
        <meta-name>cover-date</meta-name>
        <meta-value>June 2020</meta-value>
      </custom-meta>
      <custom-meta>
        <meta-name>details-of-publishers-convertor</meta-name>
        <meta-value>Converter:WILEY_ML3GV2_TO_JATSPMC version:5.8.5 mode:remove_FC converted:01.07.2020</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
  <notes>
    <p content-type="self-citation">
      <mixed-citation publication-type="journal" id="aps311367-cit-1001"><string-name><surname>Weaver</surname>, <given-names>W. N.</given-names></string-name>, <string-name><given-names>J.</given-names><surname>Ng</surname></string-name>, and <string-name><given-names>R. G.</given-names><surname>Laport</surname></string-name>. <year>2020</year><article-title>LeafMachine: Using machine learning to automate leaf trait extraction from digitized herbarium specimens</article-title>. <source xml:lang="en">Applications in Plant Sciences</source><volume>8</volume>(<issue>6</issue>): <elocation-id>e11367</elocation-id>.</mixed-citation>
    </p>
  </notes>
</front>
<body id="aps311367-body-0001">
  <p>The millions of plant specimens stored in herbaria around the world serve as priceless historical records of global biodiversity (Funk, <xref rid="aps311367-bib-0011" ref-type="ref">2003</xref>). The careful study and use of these specimens have been crucial in answering an assortment of evolutionary and ecological questions (Pyke and Ehrlich, <xref rid="aps311367-bib-0023" ref-type="ref">2010</xref>; Lavoie, <xref rid="aps311367-bib-0015" ref-type="ref">2013</xref>), such as the resolution of taxonomic puzzles and phylogenetic relationships (Ames and Spooner, <xref rid="aps311367-bib-0001" ref-type="ref">2008</xref>; Ng and Smith, <xref rid="aps311367-bib-0020" ref-type="ref">2016</xref>; Ng et al., <xref rid="aps311367-bib-0021" ref-type="ref">2019</xref>), phenological and species distribution responses to climate change (reviewed in Willis et al., <xref rid="aps311367-bib-0031" ref-type="ref">2017</xref>; Jones and Daehler, <xref rid="aps311367-bib-0013" ref-type="ref">2018</xref>; Lang et al., <xref rid="aps311367-bib-0014" ref-type="ref">2019</xref>), and plant–insect interactions through time (Lees et al., <xref rid="aps311367-bib-0016" ref-type="ref">2011</xref>; Meineke and Davies, <xref rid="aps311367-bib-0018" ref-type="ref">2018</xref>). Despite the clear value of herbaria, many collections have been neglected in recent decades as funding and curatorial expertise have waned (Dalton, <xref rid="aps311367-bib-0007" ref-type="ref">2003</xref>; Prather et al., <xref rid="aps311367-bib-0022" ref-type="ref">2004</xref>). Although this has the potential to lead to a tragic underutilization of accumulated scientific knowledge, recent worldwide efforts to digitize herbaria may mitigate these consequences by making troves of information easily available to researchers that was previously only accessible by physical visits to scattered repositories.</p>
  <p>With the surfeit of available data represented by digitized specimens, the advent and development of computer vision and machine learning approaches provide promising solutions to efficiently procure information from otherwise unfathomable data sets (Gehan and Kellogg, <xref rid="aps311367-bib-0012" ref-type="ref">2017</xref>). For example, a number of machine learning tools have been developed to automate the identification of species from herbarium specimens (e.g., Unger et al., <xref rid="aps311367-bib-0028" ref-type="ref">2016</xref>; Wilf et al., <xref rid="aps311367-bib-0030" ref-type="ref">2016</xref>; Carranza‐Rojas et al., <xref rid="aps311367-bib-0003" ref-type="ref">2017</xref>), and these tools could be used to tackle the chronic backlog of unprocessed, unidentified, and misidentified plant specimens in herbaria. However, beyond their applications for species identification, digitized specimens harbor a wealth of available, but underutilized phenotypic information. Phenotypic trait measurements can provide important insights into the ecology and evolution of a species, but collecting these data manually can be a time‐consuming task. Multiple software solutions have been developed to rapidly capture plant phenotype information from digital images with minimal user input (e.g., LeafAnalyser, Weight et al., <xref rid="aps311367-bib-0029" ref-type="ref">2008</xref>; LeafProcessor, Backhaus et al., <xref rid="aps311367-bib-0002" ref-type="ref">2010</xref>; LeafJ, Maloof et al., <xref rid="aps311367-bib-0017" ref-type="ref">2013</xref>; Easy Leaf Area, Easlon and Bloom, <xref rid="aps311367-bib-0009" ref-type="ref">2014</xref>), including several applications that leverage the processing power of ubiquitous mobile devices for real‐time identification and/or feature extraction (e.g., LeafSnap, <ext-link ext-link-type="uri" xlink:href="http://www.leafsnap.com">www.leafsnap.com</ext-link>; LeafScan, <ext-link ext-link-type="uri" xlink:href="http://www.leafscanapp.com">www.leafscanapp.com</ext-link>; Petiole, <ext-link ext-link-type="uri" xlink:href="http://www.petioleapp.com">www.petioleapp.com</ext-link>). While employing varying degrees of automation, these applications largely still require manual user input or the creation of specifically prepared images (i.e., isolated leaves on a white background with a known scale) for accurate feature processing. Thus, fully automated computational approaches that can take advantage of the large number of already‐digitized herbarium specimens to efficiently and accurately identify and measure particular plant characteristics (e.g., leaf size, floral features) represent extremely valuable scientific tools that can overcome current limitations on data set inclusivity and magnitude.</p>
  <p>Here, we describe the development of LeafMachine, an open‐source machine learning software package designed to autonomously identify, analyze, and extract trait information from digitized herbarium specimens or leaf images using a rigorous training and ground‐truthing regimen. LeafMachine is currently focused on extracting leaf area and perimeter, as these traits have been shown to provide important insights into the ecology and evolutionary history of plant species (e.g., Cornwell et al., <xref rid="aps311367-bib-0006" ref-type="ref">2014</xref>; Edwards et al., <xref rid="aps311367-bib-0010" ref-type="ref">2016</xref>). LeafMachine is designed to be flexible, accommodating the vast diversity of shapes, colors, textures, and associated materials on herbarium specimens (e.g., different species, preservation quality, mounting materials, labels, text, annotations). LeafMachine also has the potential to be adapted to identify and measure other plant traits (e.g., flowers, fruit, evidence of herbivory) or even traits associated with other organisms (e.g., lizard scales, butterfly wings).</p>
  <sec id="aps311367-sec-0005">
    <title>METHODS AND RESULTS</title>
    <sec id="aps311367-sec-0006">
      <title>LeafMachine overview</title>
      <p>LeafMachine is a suite of machine learning algorithms that (i) identifies leaves and other components of a digitized herbarium specimen or leaf image using a pixel‐wise semantic segmentation convolutional neural network (CNN), and (ii) verifies whether each identified leaf is a single, measurable leaf using a support vector machine (SVM) algorithm (Fig. <xref rid="aps311367-fig-0001" ref-type="fig">1</xref>). We specifically focused our development and evaluation of LeafMachine to accurately identify and measure single leaves from a diverse selection of mostly perennial broad‐leaved angiosperms to reduce the number of preservation or architectural challenges that are common with grasses, herbs, gymnosperms, and other non‐flowering plants (e.g., small, obscure, folded, developmentally modified, or otherwise not obvious leaves). LeafMachine was developed in MATLAB (MathWorks, Natick, Massachusetts, USA), and can be readily implemented by users on computer systems running MATLAB (version R2019b or later) in Windows, Mac OS X, and Linux (example system configurations can be found in Appendix <xref rid="aps311367-sup-0001" ref-type="supplementary-material">S1</xref> and the user manual [available on GitHub, see Data Availability]). All LeafMachine algorithms can be downloaded from GitHub (<ext-link ext-link-type="uri" xlink:href="https://github.com/Gene-Weaver/LeafMachine/tree/V.2.0/Networks">https://github.com/Gene‐Weaver/LeafMachine/tree/V.2.0/Networks</ext-link>).</p>
      <fig fig-type="Figure" xml:lang="en" id="aps311367-fig-0001" orientation="portrait" position="float">
        <label>Figure 1</label>
        <caption>
          <p>Workflow of LeafMachine to process a herbarium specimen image. (A) LeafMachine accepts images as a batch input. (B) With each image, LeafMachine uses a modified DeepLabV3+ convolutional neural network (CNN) to segment the image into five segmentation classes, including a ‘leaf’ class for identified leaves. The CNN was trained with 280 ground‐truth images and validated with 71 ground‐truth images. (C) The CNN outputs a binary mask for each segmentation class (‘leaf’ class shown). (D) With the ‘leaf’ class binary mask, LeafMachine then crops the image into different leaf candidate masks (LCMs), each only containing one binary component, and uses an AdaBoost support vector machine (SVM) to further classify LCMs as a single, measurable leaf (check mark), partial leaf (not shown), leaf clump (cross), or not a leaf (rejected; not shown). The SVM was trained using 33,830 leaf candidate masks that were extracted from the CNN training set and manually sorted into ‘leaf,’ ‘partial leaf,’ ‘leaf clump,’ or ‘reject’ categories. (E) LeafMachine then overlays the LCMs onto the original image as output for user verification, as well as (F) a CSV file containing leaf area and perimeter measurements, and processing information.</p>
        </caption>
        <graphic id="nlm-graphic-1" xlink:href="APS3-8-e11367-g001"/>
      </fig>
    </sec>
    <sec id="aps311367-sec-0007">
      <title>Training the CNN to identify different specimen components</title>
      <p>We randomly sampled digitized herbarium images to create a training data set. Although LeafMachine was not specifically designed to measure the morphological properties of grasses, herbs, and non‐flowering plants, we included taxa with these life histories in the training data set to maximize correct leaf classifications and enhance the generalizability of our machine learning algorithm. Some images were photographs taken in‐person at the Rocky Mountain (RM) and Missouri Botanical Garden (MO) herbaria (herbarium codes follow Thiers, <xref rid="aps311367-bib-0027" ref-type="ref">2020</xref>), while the rest were obtained from 136 well‐curated, digitized herbaria with Darwin Core files that were accessed through online consortiums (e.g., SERNEC, <ext-link ext-link-type="uri" xlink:href="http://sernecportal.org/">http://sernecportal.org/</ext-link>; SEINET, <ext-link ext-link-type="uri" xlink:href="http://swbiodiversity.org/seinet/">http://swbiodiversity.org/seinet/</ext-link>) using a custom MATLAB script (<ext-link ext-link-type="uri" xlink:href="https://github.com/Gene-Weaver/LeafMachine/blob/V.2.0/SandboxFunctions/downloadSubsetDWCimagesFixed.m">https://github.com/Gene‐Weaver/LeafMachine/blob/V.2.0/SandboxFunctions/downloadSubsetDWCimagesFixed.m</ext-link>) (Appendix <xref rid="aps311367-sup-0002" ref-type="supplementary-material">S2</xref>). Herbarium collections ranged from 131 (WFU) to 429,181 imaged specimens (NLU). We downloaded high‐ and low‐resolution images, as defined by each herbarium (high = 2304 × 3072 pixels to 6879 × 9893 pixels, median = 3800 × 5700 pixels; low = 397 × 600 pixels to 2448 × 3264 pixels, median = 1400 × 1600 pixels), for 10 randomly chosen specimens from each herbarium (20 total images per herbarium). Our training set therefore captured a range of leaf shapes, phenological stages, preservation and image quality, lighting conditions, colors, orientations, mounting and labeling conventions, and specimen age (Appendix <xref rid="aps311367-sup-0003" ref-type="supplementary-material">S3</xref>). Image files that were corrupted prior to or during download were deleted and not replaced, resulting in some specimens only having either a high‐ or low‐resolution image. This resulted in a total of 2685 training images (comprising both high‐ and low‐resolution images) that included ~1000 species spanning ~165 families (Appendix <xref rid="aps311367-sup-0004" ref-type="supplementary-material">S4</xref>).</p>
      <p>Pixel‐wise semantic segmentation algorithms require ground‐truth masks to instruct the neural network on how to classify each pixel in the training image. To create these, we subset the 2685‐image training set and manually classified the pixels of 425 images into one of five segmentation classes (‘leaf,’ ‘stem,’ ‘fruit/flower,’ ‘text,’ ‘background’). These segmentation classes represented apparent, functional definitions for machine learning purposes rather than strictly anatomically or developmentally correct botanical terms (e.g., grass leaf blades, conifer needles, and leaf petioles were typically classified as ‘stems’ in appearance for training the CNN because our focus was on identifying broad leaves). Although the current version of LeafMachine is focused on identifying leaves, we included non‐leaf segmentation classes to aid future development of LeafMachine’s capabilities to extract usable data from these other classes. We manually classified pixels by painting a colored layer over training images for each segmentation class with the MATLAB image labeler tool to signify that the painted pixels corresponded to the respective segmentation class. This resulted in ground‐truth images that were identical in dimension to the training image and that only contained the manually painted pixel masks for each segmentation class. Of the 425 ground‐truth images, we reserved 280 to train the CNN, 71 to validate the CNN during training, and 74 to evaluate the accuracy of the trained CNN algorithm (Appendix <xref rid="aps311367-sup-0004" ref-type="supplementary-material">S4</xref>). Given that our training images ranged from 0.2–68.0 megapixels and training a CNN requires that images are all uniformly sized, we dynamically cropped each training image and its associated ground‐truth image into 360 × 360 pixel chips using a custom script (<ext-link ext-link-type="uri" xlink:href="https://github.com/Gene-Weaver/LeafMachine/blob/V.2.0/SandboxFunctions/dynamicCrop.m">https://github.com/Gene‐Weaver/LeafMachine/blob/V.2.0/SandboxFunctions/dynamicCrop.m</ext-link>). The dynamic cropping process first crops a chip from the top left corner of the full image, then proceeds to crop in 180‐pixel sliding windows moving left to right until reaching the edge of the image. The process is then repeated 180 pixels below the first row until the entire training image has been cropped into 50% overlapping chips. This method produced 122,949 training chips and 20,422 validation chips, which became the training and validation input for the semantic segmentation algorithm.</p>
      <p>We used a modified DeepLabV3+ CNN architecture for our semantic segmentation algorithm. The DeepLabV3+ CNN can achieve well‐resolved, computationally efficient segmentation masks around complex objects with the use of atrous separable convolutions and atrous spatial pyramid pooling (Chen et al., <xref rid="aps311367-bib-0004" ref-type="ref">2018</xref>). We further modified the algorithm to adjust the learning rate of the tensors in the segmentation to be weighted by the pixel frequency of each segmentation class for each training image. We also took advantage of transfer learning and spliced the pre‐trained feature extraction layers from a MATLAB‐provided ResNet18 network (included in the Deep Learning Toolbox) to enhance classification performance and reduce training time. Additional information about training LeafMachine can be found in the user manual (available on GitHub, see Data Availability).</p>
      <p>To evaluate the accuracy of image segmentation by LeafMachine’s CNN, we calculated the proportion of pixels LeafMachine correctly predicted from the remaining 74 ground‐truthed images that were not used to train and validate the CNN. The global accuracy of the CNN across the five segmentation classes was 91.8%, although this figure is skewed by a disproportionately large number of ‘background’ pixels. Weighting the global accuracy by the proportion of ground‐truth pixels in each class, the intersection over union (IoU; also called the Jaccard index) was 88.8% and the mean IoU for the ‘leaf’ segmentation class was 55.2% (Table <xref rid="aps311367-tbl-0001" ref-type="table">1A</xref>). Additional information about LeafMachine’s CNN evaluation, including confusion matrices, can be found in the LeafMachine user manual (available on GitHub, see Data Availability).</p>
      <table-wrap id="aps311367-tbl-0001" xml:lang="en" content-type="Table" orientation="portrait" position="float">
        <label>Table 1</label>
        <caption>
          <p>Evaluation of each step LeafMachine takes to process a herbarium specimen image (see also Fig. <xref rid="aps311367-fig-0001" ref-type="fig">1</xref>). (A) The accuracy of LeafMachine’s convolutional neural network (CNN) to segment specimen images into five classes (including a ‘leaf’ class) was calculated as the intersection over union (the proportion of pixels correctly predicted, weighted by the proportion of ground‐truth pixels in each class) using a set of 74 ground‐truthed images. (B) The accuracy of LeafMachine’s support vector machine (SVM) algorithm to identify single, measurable leaves from specimens was evaluated using 1000 randomly sampled high‐ and low‐resolution images from 21,316 processed specimens from SWMT and COLO representing 20 families. (C) LeafMachine’s leaf measurement accuracy was evaluated by processing 12 custom‐created herbarium specimen images (Appendix <xref rid="aps311367-sup-0005" ref-type="supplementary-material">S5</xref>) and comparing LeafMachine leaf measurements to manual measurements in ImageJ. Comparing the binary masks from LeafMachine‐ and ImageJ‐processed images, 38 and 42 high‐ and low‐resolution leaves, respectively, were identified to be comparable and were used to assess differences in leaf measurements.</p>
        </caption>
        <table frame="hsides" rules="groups">
          <col style="border-right:solid 1px #000000" span="1"/>
          <col style="border-right:solid 1px #000000" span="1"/>
          <thead valign="top">
            <tr style="border-bottom:solid 1px #000000">
              <th align="left" valign="top" rowspan="1" colspan="1">Steps taken by LeafMachine to process a specimen image</th>
              <th align="left" valign="top" rowspan="1" colspan="1">Evaluation</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td align="left" rowspan="1" colspan="1">
                <p>
                  <bold>(A) CNN</bold>
                </p>
                <p>Identifying different specimen components</p>
                <p>(see also Fig. <xref rid="aps311367-fig-0001" ref-type="fig">1B</xref>)</p>
              </td>
              <td align="left" rowspan="1" colspan="1">
                <p>
                  <underline underline-style="single">Intersection over union</underline>
                </p>
                <list list-type="bullet" id="aps311367-list-0001">
                  <list-item>
                    <p>All segmentation classes: 88.8%</p>
                  </list-item>
                  <list-item>
                    <p>Leaf segmentation class: 55.2%</p>
                  </list-item>
                </list>
              </td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">
                <p>
                  <bold>(B) SVM</bold>
                </p>
                <p>Identifying single leaves</p>
                <p>(see also Fig. <xref rid="aps311367-fig-0001" ref-type="fig">1D</xref>)</p>
              </td>
              <td align="left" rowspan="1" colspan="1">
                <p>
                  <underline underline-style="single">True positive</underline>
                </p>
                <list list-type="bullet" id="aps311367-list-0002">
                  <list-item>
                    <p>Identified at least one leaf: 82.0% high‐resolution, 60.8% low‐resolution</p>
                  </list-item>
                  <list-item>
                    <p>Identified all measurable leaves on a specimen: 42.4% high‐resolution, 39.1% low‐resolution</p>
                  </list-item>
                </list>
                <p>
                  <underline underline-style="single">False negative</underline>
                </p>
                <list list-type="bullet" id="aps311367-list-0003">
                  <list-item>
                    <p>Misidentified leaf: 0.9% high‐resolution, 2.1% low‐resolution</p>
                  </list-item>
                </list>
              </td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">
                <p>
                  <bold>(C) Leaf measurements</bold>
                </p>
                <p>Measuring leaves compared to ImageJ</p>
                <p>(see also Fig. <xref rid="aps311367-fig-0001" ref-type="fig">1F</xref>, Appendix <xref rid="aps311367-sup-0006" ref-type="supplementary-material">S6</xref>)</p>
              </td>
              <td align="left" rowspan="1" colspan="1">
                <p>
                  <underline underline-style="single">Average difference</underline>
                </p>
                <list list-type="bullet" id="aps311367-list-0004">
                  <list-item>
                    <p>High‐resolution: 145.4 mm<sup>2</sup> (257.0 mm<sup>2</sup> SD)</p>
                  </list-item>
                  <list-item>
                    <p>Low‐resolution: 149.3 mm<sup>2</sup> (250.9 mm<sup>2</sup> SD)</p>
                  </list-item>
                </list>
              </td>
            </tr>
          </tbody>
        </table>
        <permissions>
          <copyright-holder>John Wiley &amp; Sons, Ltd</copyright-holder>
        </permissions>
      </table-wrap>
    </sec>
    <sec id="aps311367-sec-0008">
      <title>Training the SVM to identify single leaves</title>
      <p>To create a training data set for the SVM, we ran the trained CNN on all 2685 images in the training data set. For each specimen, the CNN outputs five binary masks that correspond to the five segmentation classes. For those binary masks classified as belonging to the ‘leaf’ segmentation class, we cropped and saved each solitary object to create isolated binary mask objects (herein called <italic>leaf candidate masks</italic> [LCMs]). LeafMachine’s CNN produced 197,191 LCMs that we manually sorted into one of four categories: ‘leaf’ (6033 LCMs), ‘partial leaf’ (6375 LCMs), ‘leaf clump’ (1422 LCMs), or ‘reject’ (i.e., not a leaf; 183,361 LCMs). To reduce SVM bias toward the ‘reject’ category, we only included 20,000 random LCMs from the reject category during training (33,830 LCMs total). We chose 11 variables to train the SVM: nine computationally derived shape variables of the LCMs (area, perimeter, bounding box ratio, major axis length, minor axis length, eccentricity, equivalent diameter, extent, and roundness), one categorical variable (family name, if available), and one inherited variable (the original image size in megapixels; Di Ruberto and Putzu, <xref rid="aps311367-bib-0008" ref-type="ref">2014</xref>; Zhang et al., <xref rid="aps311367-bib-0032" ref-type="ref">2016</xref>). We used the MATLAB Classification Learner app to design an AdaBoost Decision Tree architecture with 20% holdout validation, a learning rate of 0.1, 50 splits, and 100 learners to decide on the validity of each LCM.</p>
    </sec>
    <sec id="aps311367-sec-0009">
      <title>Adjusting pixel classifications</title>
      <p>Inaccurately classified pixels within a LCM, such as sections of a vein misclassified as a stem, will appear as holes in the final leaf prediction. We therefore provided a flood‐fill operation in LeafMachine (using the MatLab imfill() command) to fill all holes (including true holes that are the result of herbivory and specimen damage) occurring within the leaf boundary of the ‘leaf,’ ‘partial leaf,’ and ‘leaf clump’ categories to produce more refined masks.</p>
    </sec>
    <sec id="aps311367-sec-0010">
      <title>Evaluation of LeafMachine</title>
      <p>We evaluated LeafMachine’s ability to (i) correctly identify leaves, and (ii) accurately measure identified leaves. To test LeafMachine’s ability to correctly identify single leaves, we ran the software on herbarium specimen images from the Rhodes College (SWMT) and University of Colorado Boulder (COLO) herbaria. We focused on 20 angiosperm families that primarily comprise trees, shrubs, and lianas to represent a mix of growth forms and life histories with generally simple broad leaves (but also include some herbaceous taxa, and taxa with compound leaves): Aceraceae, Adoxaceae, Anacardiaceae, Betulaceae, Cannabaceae, Caprifoliaceae, Ericaceae, Fagaceae, Lauraceae, Magnoliaceae, Malvaceae, Myrtaceae, Oleaceae, Platanaceae, Rhamnaceae, Salicaceae, Sapindaceae, Solanaceae, Ulmaceae, and Vitaceae (Table <xref rid="aps311367-tbl-0002" ref-type="table">2</xref>). This resulted in 718 and 9970 processed specimens from SWMT and COLO, respectively. We ran LeafMachine on both high‐ and low‐resolution images of each specimen (SWMT: low = 1250 × 1875 pixels, high = 4000 × 6000 pixels; COLO: low = 1400 × 2100 pixels, high = 3744 × 5616 pixels), resulting in a total of 21,316 processed images. This required 631 compute hours across a variety of computational resources (image processing times for example computer configurations can be found in Appendix <xref rid="aps311367-sup-0001" ref-type="supplementary-material">S1</xref>). LeafMachine made at least one leaf measurement for 78.9% of processed images. Only 1.5% of the high‐resolution and 3.9% of the low‐resolution images did not have any ‘leaf,’ ‘partial leaf,’ or ‘leaf clump’ categories identified, with most of these images being specimens without leaves (e.g., early phenological stages of bud break/leaf out), or photographs or seed packets pasted onto a specimen sheet. Of the families processed, Malvaceae and Salicaceae specimens had the highest proportion of measurable leaves at high resolutions, while Solanaceae and Sapindaceae had the lowest proportion of measurable leaves (Table <xref rid="aps311367-tbl-0002" ref-type="table">2</xref>).</p>
      <table-wrap id="aps311367-tbl-0002" xml:lang="en" content-type="Table" orientation="portrait" position="float">
        <label>Table 2</label>
        <caption>
          <p>The 20 angiosperm families used to test LeafMachine, the total number of digitized specimens for each family, and the proportion of specimens from which LeafMachine identified and measured at least one single leaf.<xref ref-type="fn" rid="aps311367-note-0001"><sup>a</sup></xref>
</p>
        </caption>
        <table frame="hsides" rules="groups">
          <col style="border-right:solid 1px #000000" span="1"/>
          <col style="border-right:solid 1px #000000" span="1"/>
          <col style="border-right:solid 1px #000000" span="1"/>
          <col style="border-right:solid 1px #000000" span="1"/>
          <thead valign="bottom">
            <tr style="border-bottom:solid 1px #000000">
              <th align="left" rowspan="2" valign="bottom" colspan="1">Family</th>
              <th align="left" rowspan="2" valign="bottom" colspan="1">No. of digitized specimens</th>
              <th align="left" colspan="2" style="border-bottom:solid 1px #000000" valign="bottom" rowspan="1">% images with at least one leaf measurement</th>
            </tr>
            <tr style="border-bottom:solid 1px #000000">
              <th align="left" valign="bottom" rowspan="1" colspan="1">High‐resolution</th>
              <th align="left" valign="bottom" rowspan="1" colspan="1">Low‐resolution</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td align="left" rowspan="1" colspan="1">Aceraceae</td>
              <td align="char" char="." rowspan="1" colspan="1">504</td>
              <td align="char" char="." rowspan="1" colspan="1">90.7</td>
              <td align="char" char="." rowspan="1" colspan="1">74.2</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Adoxaceae</td>
              <td align="char" char="." rowspan="1" colspan="1">98</td>
              <td align="char" char="." rowspan="1" colspan="1">89.8</td>
              <td align="char" char="." rowspan="1" colspan="1">79.6</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Anacardiaceae</td>
              <td align="char" char="." rowspan="1" colspan="1">456</td>
              <td align="char" char="." rowspan="1" colspan="1">93.0</td>
              <td align="char" char="." rowspan="1" colspan="1">75.9</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Betulaceae</td>
              <td align="char" char="." rowspan="1" colspan="1">940</td>
              <td align="char" char="." rowspan="1" colspan="1">92.3</td>
              <td align="char" char="." rowspan="1" colspan="1">69.1</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Cannabaceae</td>
              <td align="char" char="." rowspan="1" colspan="1">80</td>
              <td align="char" char="." rowspan="1" colspan="1">91.3</td>
              <td align="char" char="." rowspan="1" colspan="1">70.0</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Caprifoliaceae</td>
              <td align="char" char="." rowspan="1" colspan="1">706</td>
              <td align="char" char="." rowspan="1" colspan="1">91.9</td>
              <td align="char" char="." rowspan="1" colspan="1">71.7</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Ericaceae</td>
              <td align="char" char="." rowspan="1" colspan="1">508</td>
              <td align="char" char="." rowspan="1" colspan="1">88.4</td>
              <td align="char" char="." rowspan="1" colspan="1">69.3</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Fagaceae</td>
              <td align="char" char="." rowspan="1" colspan="1">1507</td>
              <td align="char" char="." rowspan="1" colspan="1">81.8</td>
              <td align="char" char="." rowspan="1" colspan="1">61.6</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Lauraceae</td>
              <td align="char" char="." rowspan="1" colspan="1">17</td>
              <td align="char" char="." rowspan="1" colspan="1">88.2</td>
              <td align="char" char="." rowspan="1" colspan="1">82.4</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Magnoliaceae</td>
              <td align="char" char="." rowspan="1" colspan="1">25</td>
              <td align="char" char="." rowspan="1" colspan="1">80.0</td>
              <td align="char" char="." rowspan="1" colspan="1">100.0</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Malvaceae</td>
              <td align="char" char="." rowspan="1" colspan="1">494</td>
              <td align="char" char="." rowspan="1" colspan="1">98.2</td>
              <td align="char" char="." rowspan="1" colspan="1">92.5</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Myrtaceae</td>
              <td align="char" char="." rowspan="1" colspan="1">1</td>
              <td align="char" char="." rowspan="1" colspan="1">100.0</td>
              <td align="char" char="." rowspan="1" colspan="1">100.0</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Oleaceae</td>
              <td align="char" char="." rowspan="1" colspan="1">488</td>
              <td align="char" char="." rowspan="1" colspan="1">96.9</td>
              <td align="char" char="." rowspan="1" colspan="1">84.4</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Platanaceae</td>
              <td align="char" char="." rowspan="1" colspan="1">6</td>
              <td align="char" char="." rowspan="1" colspan="1">83.3</td>
              <td align="char" char="." rowspan="1" colspan="1">83.3</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Rhamnaceae</td>
              <td align="char" char="." rowspan="1" colspan="1">724</td>
              <td align="char" char="." rowspan="1" colspan="1">96.8</td>
              <td align="char" char="." rowspan="1" colspan="1">83.1</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Salicaceae</td>
              <td align="char" char="." rowspan="1" colspan="1">2534</td>
              <td align="char" char="." rowspan="1" colspan="1">98.4</td>
              <td align="char" char="." rowspan="1" colspan="1">80.7</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Sapindaceae</td>
              <td align="char" char="." rowspan="1" colspan="1">84</td>
              <td align="char" char="." rowspan="1" colspan="1">72.6</td>
              <td align="char" char="." rowspan="1" colspan="1">91.7</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Solanaceae</td>
              <td align="char" char="." rowspan="1" colspan="1">1148</td>
              <td align="char" char="." rowspan="1" colspan="1">79.0</td>
              <td align="char" char="." rowspan="1" colspan="1">33.1</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Ulmaceae</td>
              <td align="char" char="." rowspan="1" colspan="1">29</td>
              <td align="char" char="." rowspan="1" colspan="1">86.2</td>
              <td align="char" char="." rowspan="1" colspan="1">96.6</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Vitaceae</td>
              <td align="char" char="." rowspan="1" colspan="1">23</td>
              <td align="char" char="." rowspan="1" colspan="1">95.7</td>
              <td align="char" char="." rowspan="1" colspan="1">100.0</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot id="aps311367-ntgp-0001">
          <fn id="aps311367-note-0001">
            <label>
              <sup>a</sup>
            </label>
            <p>All digitized herbarium specimen images available for these families from the Rhodes College (SWMT) and the University of Colorado Boulder (COLO) herbaria were processed by LeafMachine.</p>
          </fn>
        </table-wrap-foot>
        <permissions>
          <copyright-holder>John Wiley &amp; Sons, Ltd</copyright-holder>
        </permissions>
      </table-wrap>
      <p>From the processed images, we evaluated LeafMachine’s ability to correctly identify leaves by randomly sampling 1000 high‐ and low‐resolution images in which at least one ‘leaf’ was identified, and 1000 high‐ and low‐resolution images in which a ‘partial leaf’ or ‘leaf clump’ was identified (4000 total images). The evaluated high‐ and low‐resolution images were paired to additionally evaluate LeafMachine’s performance on different image resolutions. From those images in which a ‘leaf’ was identified, we visually inspected each image to determine whether the ‘leaf’ identified by LeafMachine was indeed a correctly identified single leaf (true positive) or, instead, a ‘partial leaf,’ ‘leaf clump,’ or something else (false positive) (Fig. <xref rid="aps311367-fig-0002" ref-type="fig">2</xref>). We found that 82.0% of the high‐resolution and 60.8% of the low‐resolution images that contained measurable leaves (from visual assessment) had leaf morphometric information for at least one leaf (true positives) (Table <xref rid="aps311367-tbl-0001" ref-type="table">1B</xref>). For most images, LeafMachine identified and measured multiple leaves, with ~40% of all autonomous leaf identifications/measurements representing actual leaf measurements upon visual inspection (true positives; 42.4% high‐resolution, 39.1% low‐resolution; Table <xref rid="aps311367-tbl-0001" ref-type="table">1B</xref>). Many of the autonomous false positive leaf measurements appeared to result from issues with specimen preparation/preservation (e.g., leaf overlap, folding, degradation, breakage, or otherwise confusing leaf arrangements).</p>
      <fig fig-type="Figure" xml:lang="en" id="aps311367-fig-0002" orientation="portrait" position="float">
        <label>Figure 2</label>
        <caption>
          <p>High‐ (A, C) and low‐ (B, D) resolution herbarium specimen images (Rhodes College herbarium barcode numbers SWMT09145 [A, B] and SWMT01894 [C, D]) processed by LeafMachine. In both high‐resolution images, LeafMachine identified that the specimens contained a single, measurable leaf (outlined in green; true positive) and a leaf clump (outlined in orange; true negative), while only a leaf clump was identified in the low‐resolution images (false negative). This reflects our general finding that higher‐resolution images result in better leaf identification and measurement by LeafMachine.</p>
        </caption>
        <graphic id="nlm-graphic-3" xlink:href="APS3-8-e11367-g002"/>
      </fig>
      <p>Similarly, we inspected each of the images in which a ‘partial leaf’ or ‘leaf clump’ was identified to determine whether a measurable leaf was actually present in the images (false negative) or not (true negative) (Fig. <xref rid="aps311367-fig-0002" ref-type="fig">2</xref>). We found that only 0.9% of high‐resolution and 2.1% of low‐resolution ‘partial leaf’ and ‘leaf clump’ images contained leaves visually assessed to be measurable (i.e., possessed at least one recognizable, intact, non‐overlapping leaf; false negative) (Table <xref rid="aps311367-tbl-0001" ref-type="table">1B</xref>). Otherwise, the majority of ‘partial leaf’ or ‘leaf clump’ images did not appear to be easily measurable by manual methods because of overlapping leaves or otherwise confusing leaf arrangements. Thus, LeafMachine was adequately capable of identifying and measuring leaves for the majority of herbarium specimens when such leaves were present.</p>
      <p>To evaluate LeafMachine’s leaf measurement accuracy, we created 12 validation specimens by collecting, drying, and mounting leaves of several taxa with varying leaf sizes, shapes, textures, and colors on herbarium sheets with a ruler, label, and miscellaneous objects (e.g., washers, pens) often (or potentially) found in digitized herbarium images (Appendix <xref rid="aps311367-sup-0005" ref-type="supplementary-material">S5</xref>). We photographed these validation specimens at COLO using standard digitization practices (Nelson et al., <xref rid="aps311367-bib-0019" ref-type="ref">2015</xref>) to obtain images at the median high and low resolutions of images in our training data set. We seeded these images into the set of SWMT and COLO images processed by LeafMachine and compared the leaf area measurements from LeafMachine to manual measurements obtained in ImageJ (version 1.52k; Schneider et al., <xref rid="aps311367-bib-0026" ref-type="ref">2012</xref>), software commonly used for leaf measurements. We measured leaves in ImageJ by converting images to 8‐bit color and used default thresholding to isolate leaves from the background. Individual leaf masks were selected with the wand tool and “filled” (Edit→Fill) prior to obtaining pixel areas via “Analyze Particles” (Reinking, <xref rid="aps311367-bib-0024" ref-type="ref">2007</xref>). We only compared measurements of those leaves in which LeafMachine created a binary mask that represented a whole, filled‐in leaf (i.e., the whole area within the leaf outline was measured). As LeafMachine currently only outputs measurements in pixels, we manually converted pixel measurements to square millimeters (mm<sup>2</sup>) using the ruler in each image.</p>
      <p>Identification and measurement of validation image leaves proved more successful than the full herbarium image data sets, with successful measurements for all 12 images. For the high‐resolution images, 76.9% (40/52) of ‘leaves’ were correctly identified and measured, while 93.2% (41/44) of ‘leaves’ were correctly identified and measured in the low‐resolution images, indicating that simplified specimen images result in more reliable output than typical digitized herbarium specimen collections. The measurements produced by LeafMachine tended to be slightly smaller than those produced by ImageJ (38 comparable high‐resolution leaves: mean difference = 145.4 mm<sup>2</sup>, SD = 257.0 mm<sup>2</sup>; 42 comparable low‐resolution leaves: mean difference = 149.3 mm<sup>2</sup>, SD = 250.9 mm<sup>2</sup>; Table <xref rid="aps311367-tbl-0001" ref-type="table">1C</xref>, Appendix <xref rid="aps311367-sup-0006" ref-type="supplementary-material">S6</xref>), likely due to differences in how leaves were thresholded in ImageJ and whether all pixels enclosed by the perimeter were included in the measurements or not. For example, measurements in ImageJ were influenced by shadows and fuzzy leaf boundaries, which differed between the high‐ and low‐resolution images. The same shadows and leaf boundaries appear to have been interpreted differently, and more conservatively, by LeafMachine. Additionally, we made considerable efforts in ImageJ to ensure all pixels enclosed by a leaf boundary were included in area measurements, sometimes manually filling initially unrecognized portions of leaves. LeafMachine made autonomous decisions about pixel inclusion, and may have excluded some pixels that differed qualitatively from included pixels, resulting in slightly lower estimates of leaf area even when the “fill holes” option was selected.</p>
      <p>Despite the daunting challenges presented by variable image resolution among herbaria, broad variation among analyzed taxa, and the incredible diversity of specimen mounting/presentation techniques, LeafMachine was able to successfully identify and measure at least one leaf in the majority of analyzed images. The compounding of biological variation with specimen variability likely contributed to LeafMachine producing only half as many successful individual leaf measurements. Nevertheless, LeafMachine in its current form represents an amazingly flexible autonomous tool that can accommodate a range of broadleaf specimens typically found in herbarium collections for rapid, autonomous leaf measurement. This is especially true for high‐resolution images of taxa for which specimen images are more consistent, leaf margins are more clearly defined, leaf shape is more easily determined, and pixel characteristics can more confidently be classified as belonging to ‘leaf’ or ‘non‐leaf’ (e.g., Malvaceae, Salicaceae). We intentionally designed and trained LeafMachine to recognize the leaf morphometric features of primarily woody perennial angiosperm taxa with relatively simple leaf shapes. Yet, the inclusion of grasses, herbs, gymnosperms, and other non‐flowering plants in the training data set helped improve correct leaf classifications by presenting unusual shape masks (relative to our target taxa) to the algorithms that could be excluded as ‘non‐leaves,’ while at the same time providing the basis for the recognition of their morphological features that could broaden future applications of the software.</p>
      <p>While we recognize the current limitations of LeafMachine, and strongly encourage manual verification of outputs, we also anticipate rapid refinement via improved training data and streamlined computational algorithms. Currently, LeafMachine struggles with images containing leaf overlap and folding, specimen breakage or other degradation, cluttered leaf arrangements, deeply lobed leaves, very large leaf blades, images with poor lighting or yellowed mounting paper, and extraneous materials (e.g., washers, fragment packets). We also documented differences in performance between high‐ and low‐resolution images, with higher resolutions generally resulting in better leaf identification (although not for our custom‐created validation specimens). Autonomous ruler identification and scale conversion also remain a challenge given the diversity, orientation, and placement of rulers in digitized herbarium specimens. The addition of an autonomous ruler detection feature, which is currently in development, will greatly streamline workflows. Specially prepared images, or data set customization for simpler herbarium images, could circumvent many of these issues, as well as ameliorate the biological and human‐introduced complexity contained within herbarium collections, resulting in more tractable subjects for the current version of LeafMachine. For example, we found that our algorithms performed exceptionally well in identifying and measuring leaf blades presented in uncomplicated settings, such as those represented in our 12 validation specimens. Carefully curated leaf specimen image sets would result in greatly improved identification and measurement performance of the software for individual users. Moreover, LeafMachine accurately identified the leaf blades of some taxa that were not included in the 20‐family test set (e.g., ferns; data not shown), suggesting that LeafMachine’s algorithms could be relatively easily optimized for identifying and measuring features of novel data sets with appropriate training data sets.</p>
    </sec>
  </sec>
  <sec sec-type="conclusions" id="aps311367-sec-0011">
    <title>CONCLUSIONS</title>
    <p>Leaf area and shape have repeatedly been shown to provide insights into the ecology and evolutionary history of plant species (e.g., Cornwell et al., <xref rid="aps311367-bib-0006" ref-type="ref">2014</xref>; Edwards et al., <xref rid="aps311367-bib-0010" ref-type="ref">2016</xref>). Yet, obtaining leaf measurements that encapsulate individual‐, population‐, and species‐level differences is deceptively time‐consuming and labor‐intensive with currently available image processing software (e.g., ImageJ; tpsDig2, Rohlf, <xref rid="aps311367-bib-0025" ref-type="ref">2015</xref>; MASS, Chuanromanee et al., <xref rid="aps311367-bib-0005" ref-type="ref">2019</xref>), which rely heavily upon manual user input to specify leaf boundaries for measurement, or purpose‐built phenotyping software (Weight et al., <xref rid="aps311367-bib-0029" ref-type="ref">2008</xref>; Backhaus et al., <xref rid="aps311367-bib-0002" ref-type="ref">2010</xref>; Maloof et al., <xref rid="aps311367-bib-0017" ref-type="ref">2013</xref>; Easlon and Bloom, <xref rid="aps311367-bib-0009" ref-type="ref">2014</xref>) that require specially curated images for efficient processing. LeafMachine alleviates these tasks by leveraging machine learning to completely automate the process of extracting data from digitized herbarium specimens and leaf images for applications beyond species identification. Using a rigorous training regimen, individual leaf selection and measurement is automated via a CNN and SVM, with uncertainties and failures categorized for manual verification and processing. This allows users to quickly generate “first‐pass” data from large, historical data sets, while simultaneously allowing subsequent optimization for data generation on problematic specimen images. However, customized leaf image data sets could easily be designed to result in simpler image segmentation (e.g., similar to our validation specimens; Appendix <xref rid="aps311367-sup-0005" ref-type="supplementary-material">S5</xref>), thus circumventing the major challenges facing current machine learning approaches, and allowing confident, rapid, and fully autonomous trait data acquisition.</p>
    <p>By processing broad‐leaved angiosperm specimens across 20 families from two well‐curated digitized herbaria, which represent a diversity of life histories, growth forms, colors, textures, resolution, orientation, and mounting and labeling conventions, we demonstrated that LeafMachine can autonomously extract leaf morphometric data from digitized herbarium specimens in a time‐efficient manner similar to, or faster than, standard manual and computer‐aided methods. Although biological and human‐introduced variation in herbarium data sets present daunting challenges to this version of LeafMachine, we anticipate rapid development and improvement of the current application, and machine learning applications in general, that will result in significant performance enhancements in the next few years. These advancements will result in even greater time savings for large data sets and significantly streamlined workflows. Moreover, our novel application of machine learning has the potential to incorporate additional tools, such as autonomous ruler detection for scale, optical character recognition, and natural language processing, vastly increasing available trait information and specimen metadata to inform evolutionary and ecological studies.</p>
  </sec>
  <sec id="aps311367-sec-0013">
    <title>AUTHOR CONTRIBUTIONS</title>
    <p>W.N.W. developed LeafMachine and wrote the accompanying user manual; R.G.L. conceived the idea for the software; J.N. and R.G.L. tested and provided feedback and direction on LeafMachine; J.N. and R.G.L. drafted the manuscript with input from W.N.W.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supporting information</title>
    <supplementary-material content-type="local-data" id="aps311367-sup-0001">
      <caption>
        <p><bold>APPENDIX S1.</bold> Hardware and operating system (OS) configurations of the five computers used to test LeafMachine.</p>
      </caption>
      <media xlink:href="APS3-8-e11367-s001.docx">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material content-type="local-data" id="aps311367-sup-0002">
      <caption>
        <p><bold>APPENDIX S2.</bold> The high‐ and low‐resolution herbarium specimen images used to train LeafMachine’s convolutional neural network (CNN).</p>
      </caption>
      <media xlink:href="APS3-8-e11367-s002.xlsx">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material content-type="local-data" id="aps311367-sup-0003">
      <caption>
        <p><bold>APPENDIX S3.</bold> Specimen age distribution of the 1343‐specimen (2685 images) training image data set. The oldest specimen was collected in 1845 and the most recent specimen was collected in 2017. Collection years were obtained from the Darwin Core files associated with each image; 579 specimens lacked collection dates.</p>
      </caption>
      <media xlink:href="APS3-8-e11367-s003.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material content-type="local-data" id="aps311367-sup-0004">
      <caption>
        <p><bold>APPENDIX S4.</bold> Counts of families, genera, and species included in the ground‐truth image data sets.</p>
      </caption>
      <media xlink:href="APS3-8-e11367-s004.xlsx">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material content-type="local-data" id="aps311367-sup-0005">
      <caption>
        <p><bold>APPENDIX S5.</bold> Twelve custom‐created validation specimen images used to evaluate LeafMachine’s accuracy in leaf measurements (A–L).</p>
      </caption>
      <media xlink:href="APS3-8-e11367-s005.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material content-type="local-data" id="aps311367-sup-0006">
      <caption>
        <p><bold>APPENDIX S6.</bold> Differences in LeafMachine’s leaf area measurements compared to manual measurements in ImageJ for leaves from 12 custom‐created high‐ and low‐resolution herbarium specimen images (see also Appendix S5).</p>
      </caption>
      <media xlink:href="APS3-8-e11367-s006.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ack id="aps311367-sec-0012">
    <title>Acknowledgments</title>
    <p>The authors thank A. Kantor for help labeling training images, E. Aronson and H. Ghasemi for testing and providing feedback on LeafMachine, J. R. Allen for assistance with obtaining images and digitizing validation images at COLO, and two anonymous reviewers for helpful comments. University of Colorado’s Research Computing provided invaluable computational resources during development. This work was supported by a Microsoft AI for Earth grant to all authors and a National Science Foundation grant to J.N. and R.G.L. (NSF‐EF 1550813).</p>
  </ack>
  <sec sec-type="data-availability" id="aps311367-sec-0015">
    <title>Data Availability</title>
    <p>LeafMachine was developed using MATLAB (version R2019b; MathWorks, Natick, Massachusetts, USA). The source code, software, and user manual are available at <ext-link ext-link-type="uri" xlink:href="https://github.com/Gene-Weaver/LeafMachine" specific-use="software is-supplemented-by">https://github.com/Gene‐Weaver/LeafMachine</ext-link>. The software can be implemented by end users in MATLAB.</p>
  </sec>
  <ref-list content-type="cited-references" id="aps311367-bibl-0001">
    <title>LITERATURE CITED</title>
    <ref id="aps311367-bib-0001">
      <mixed-citation publication-type="journal" id="aps311367-cit-0001"><string-name><surname>Ames</surname>, <given-names>M.</given-names></string-name>, and <string-name><given-names>D. M.</given-names><surname>Spooner</surname></string-name>. <year>2008</year><article-title>DNA from herbarium specimens settles a controversy about origins of the European potato</article-title>. <source xml:lang="en">American Journal of Botany</source><volume>95</volume>: <fpage>252</fpage>–<lpage>257</lpage>.<pub-id pub-id-type="pmid">21632349</pub-id></mixed-citation>
    </ref>
    <ref id="aps311367-bib-0002">
      <mixed-citation publication-type="journal" id="aps311367-cit-0002"><string-name><surname>Backhaus</surname>, <given-names>A.</given-names></string-name>, <string-name><given-names>A.</given-names><surname>Kuwabara</surname></string-name>, <string-name><given-names>M.</given-names><surname>Bauch</surname></string-name>, <string-name><given-names>N.</given-names><surname>Monk</surname></string-name>, <string-name><given-names>G.</given-names><surname>Sanguinetti</surname></string-name>, and <string-name><given-names>A.</given-names><surname>Fleming</surname></string-name>. <year>2010</year><article-title>LEAFPROCESSOR: A new leaf phenotyping tool using contour bending energy and shape cluster analysis</article-title>. <source xml:lang="en">New Phytologist</source><volume>187</volume>: <fpage>251</fpage>–<lpage>261</lpage>.<pub-id pub-id-type="pmid">20456045</pub-id></mixed-citation>
    </ref>
    <ref id="aps311367-bib-0003">
      <mixed-citation publication-type="journal" id="aps311367-cit-0003"><string-name><surname>Carranza‐Rojas</surname>, <given-names>J.</given-names></string-name>, <string-name><given-names>H.</given-names><surname>Goeau</surname></string-name>, <string-name><given-names>P.</given-names><surname>Bonnet</surname></string-name>, <string-name><given-names>E.</given-names><surname>Mata‐Montero</surname></string-name>, and <string-name><given-names>A.</given-names><surname>Joly</surname></string-name>. <year>2017</year><article-title>Going deeper in the automated identification of herbarium specimens</article-title>. <source xml:lang="en">BMC Evolutionary Biology</source><volume>17</volume>: <fpage>181</fpage>.<pub-id pub-id-type="pmid">28797242</pub-id></mixed-citation>
    </ref>
    <ref id="aps311367-bib-0004">
      <mixed-citation publication-type="book" id="aps311367-cit-0004"><string-name><surname>Chen</surname>, <given-names>L.‐C.</given-names></string-name>, <string-name><given-names>Y.</given-names><surname>Zhu</surname></string-name>, <string-name><given-names>G.</given-names><surname>Papandreou</surname></string-name>, <string-name><given-names>F.</given-names><surname>Schroff</surname></string-name>, and <string-name><given-names>H.</given-names><surname>Adam</surname></string-name>. <year>2018</year><chapter-title>Encoder‐decoder with atrous separable convolution for semantic image segmentation</chapter-title><italic>In</italic><person-group person-group-type="editor"><name name-style="western"><surname>Ferrari</surname><given-names>V.</given-names></name></person-group>, <person-group person-group-type="editor"><name name-style="western"><surname>Hebert</surname><given-names>M.</given-names></name></person-group>, <person-group person-group-type="editor"><name name-style="western"><surname>Sminchisescu</surname><given-names>C.</given-names></name></person-group>, and <person-group person-group-type="editor"><name name-style="western"><surname>Weiss</surname><given-names>Y.</given-names></name></person-group> [eds.], <source xml:lang="en">Computer Vision – ECCV 2018: 15th European Conference, Munich, Germany, September 8–14, 2018</source>, <fpage>833</fpage>–<lpage>851</lpage>. <publisher-name>Springer</publisher-name>, <publisher-loc>Cham, Switzerland</publisher-loc>.</mixed-citation>
    </ref>
    <ref id="aps311367-bib-0005">
      <mixed-citation publication-type="journal" id="aps311367-cit-0005"><string-name><surname>Chuanromanee</surname>, <given-names>T. S.</given-names></string-name>, <string-name><given-names>J. I.</given-names><surname>Cohen</surname></string-name>, and <string-name><given-names>G. L.</given-names><surname>Ryan</surname></string-name>. <year>2019</year><article-title>Morphological Analysis of Size and Shape (MASS): An integrative software program for morphometric analyses of leaves</article-title>. <source xml:lang="en">Applications in Plant Sciences</source><volume>7</volume>: <elocation-id>e11288</elocation-id>.<pub-id pub-id-type="pmid">31572629</pub-id></mixed-citation>
    </ref>
    <ref id="aps311367-bib-0006">
      <mixed-citation publication-type="journal" id="aps311367-cit-0006"><string-name><surname>Cornwell</surname>, <given-names>W. K.</given-names></string-name>, <string-name><given-names>M.</given-names><surname>Westoby</surname></string-name>, <string-name><given-names>D. S.</given-names><surname>Falster</surname></string-name>, <string-name><given-names>R. G.</given-names><surname>FitzJohn</surname></string-name>, <string-name><given-names>B. C.</given-names><surname>O’Meara</surname></string-name>, <string-name><given-names>M. W.</given-names><surname>Pennell</surname></string-name>, <string-name><given-names>D. J.</given-names><surname>McGlinn</surname></string-name>, et al. <year>2014</year><article-title>Functional distinctiveness of major plant lineages</article-title>. <source xml:lang="en">Journal of Ecology</source><volume>102</volume>: <fpage>345</fpage>–<lpage>356</lpage>.</mixed-citation>
    </ref>
    <ref id="aps311367-bib-0007">
      <mixed-citation publication-type="journal" id="aps311367-cit-0007"><string-name><surname>Dalton</surname>, <given-names>R.</given-names></string-name><year>2003</year><article-title>Natural history collections in crisis as funding is slashed</article-title>. <source xml:lang="en">Nature</source><volume>423</volume>: <fpage>6940</fpage>.</mixed-citation>
    </ref>
    <ref id="aps311367-bib-0008">
      <mixed-citation publication-type="miscellaneous" id="aps311367-cit-0008"><string-name><surname>Di Ruberto</surname>, <given-names>C.</given-names></string-name>, and <string-name><given-names>L.</given-names><surname>Putzu</surname></string-name>. <year>2014</year><article-title>A fast leaf recognition algorithm based on SVM classifier and high dimensional feature vector. 2014 International Conference on Computer Vision Theory and Applications (VISAPP), Lisbon, Portugal, 5–8 January 2014</article-title>, <fpage>601</fpage>–<lpage>609</lpage>.</mixed-citation>
    </ref>
    <ref id="aps311367-bib-0009">
      <mixed-citation publication-type="journal" id="aps311367-cit-0009"><string-name><surname>Easlon</surname>, <given-names>H. M.</given-names></string-name>, and <string-name><given-names>A. J.</given-names><surname>Bloom</surname></string-name>. <year>2014</year><article-title>Easy Leaf Area: Automated digital image analysis for rapid and accurate measurement of leaf area</article-title>. <source xml:lang="en">Applications in Plant Sciences</source><volume>2</volume>: <fpage>1400033</fpage>.</mixed-citation>
    </ref>
    <ref id="aps311367-bib-0010">
      <mixed-citation publication-type="journal" id="aps311367-cit-0010"><string-name><surname>Edwards</surname>, <given-names>E. J.</given-names></string-name>, <string-name><given-names>E. L.</given-names><surname>Spriggs</surname></string-name>, <string-name><given-names>D. S.</given-names><surname>Chatelet</surname></string-name>, and <string-name><given-names>M. J.</given-names><surname>Donoghue</surname></string-name>. <year>2016</year><article-title>Unpacking a century‐old mystery: Winter buds and the latitudinal gradient in leaf form</article-title>. <source xml:lang="en">American Journal of Botany</source><volume>103</volume>: <fpage>975</fpage>–<lpage>978</lpage>.<pub-id pub-id-type="pmid">27221280</pub-id></mixed-citation>
    </ref>
    <ref id="aps311367-bib-0011">
      <mixed-citation publication-type="journal" id="aps311367-cit-0011"><string-name><surname>Funk</surname>, <given-names>V.</given-names></string-name><year>2003</year><article-title>The importance of herbaria</article-title>. <source xml:lang="en">Plant Science Bulletin</source><volume>49</volume>: <fpage>94</fpage>–<lpage>95</lpage>.</mixed-citation>
    </ref>
    <ref id="aps311367-bib-0012">
      <mixed-citation publication-type="journal" id="aps311367-cit-0012"><string-name><surname>Gehan</surname>, <given-names>M. A.</given-names></string-name>, and <string-name><given-names>E. A.</given-names><surname>Kellogg</surname></string-name>. <year>2017</year><article-title>High‐throughput phenotyping</article-title>. <source xml:lang="en">American Journal of Botany</source><volume>104</volume>: <fpage>1</fpage>–<lpage>4</lpage>.</mixed-citation>
    </ref>
    <ref id="aps311367-bib-0013">
      <mixed-citation publication-type="journal" id="aps311367-cit-0013"><string-name><surname>Jones</surname>, <given-names>C. A.</given-names></string-name>, and <string-name><given-names>C. C.</given-names><surname>Daehler</surname></string-name>. <year>2018</year><article-title>Herbarium specimens can reveal impacts of climate change on plant phenology; a review of methods and applications</article-title>. <source xml:lang="en">PeerJ</source><volume>6</volume>: <elocation-id>e4576</elocation-id>.<pub-id pub-id-type="pmid">29632745</pub-id></mixed-citation>
    </ref>
    <ref id="aps311367-bib-0014">
      <mixed-citation publication-type="journal" id="aps311367-cit-0014"><string-name><surname>Lang</surname>, <given-names>P. L. M.</given-names></string-name>, <string-name><given-names>F. M.</given-names><surname>Willems</surname></string-name>, <string-name><given-names>J. F.</given-names><surname>Scheepens</surname></string-name>, <string-name><given-names>H. A.</given-names><surname>Burbano</surname></string-name>, and <string-name><given-names>O.</given-names><surname>Bossdorf</surname></string-name>. <year>2019</year><article-title>Using herbaria to study global environmental change</article-title>. <source xml:lang="en">New Phytologist</source><volume>221</volume>: <fpage>110</fpage>–<lpage>122</lpage>.<pub-id pub-id-type="pmid">30160314</pub-id></mixed-citation>
    </ref>
    <ref id="aps311367-bib-0015">
      <mixed-citation publication-type="journal" id="aps311367-cit-0015"><string-name><surname>Lavoie</surname>, <given-names>C.</given-names></string-name><year>2013</year><article-title>Biological collections in an ever changing world: Herbaria as tools for biogeographical and environmental studies</article-title>. <source xml:lang="en">Perspectives in Plant Ecology, Evolution and Systematics</source><volume>15</volume>: <fpage>68</fpage>–<lpage>76</lpage>.</mixed-citation>
    </ref>
    <ref id="aps311367-bib-0016">
      <mixed-citation publication-type="journal" id="aps311367-cit-0016"><string-name><surname>Lees</surname>, <given-names>D. C.</given-names></string-name>, <string-name><given-names>H. W.</given-names><surname>Lack</surname></string-name>, <string-name><given-names>R.</given-names><surname>Rougerie</surname></string-name>, <string-name><given-names>A.</given-names><surname>Hernandez‐Lopez</surname></string-name>, <string-name><given-names>T.</given-names><surname>Raus</surname></string-name>, <string-name><given-names>N. D.</given-names><surname>Avtzis</surname></string-name>, <string-name><given-names>S.</given-names><surname>Augustin</surname></string-name>, and <string-name><given-names>C.</given-names><surname>Lopez‐Vaamonde</surname></string-name>. <year>2011</year><article-title>Tracking origins of invasive herbivores through herbaria and archival DNA: The case of the horse‐chestnut leaf miner</article-title>. <source xml:lang="en">Frontiers in Ecology and the Environment</source><volume>9</volume>: <fpage>322</fpage>–<lpage>328</lpage>.</mixed-citation>
    </ref>
    <ref id="aps311367-bib-0017">
      <mixed-citation publication-type="journal" id="aps311367-cit-0017"><string-name><surname>Maloof</surname>, <given-names>J. N.</given-names></string-name>, <string-name><given-names>K.</given-names><surname>Nozue</surname></string-name>, <string-name><given-names>M. R.</given-names><surname>Mumbach</surname></string-name>, and <string-name><given-names>C. M.</given-names><surname>Palmer</surname></string-name>. <year>2013</year><article-title>LeafJ: An ImageJ plugin for semi‐automated leaf shape measurement</article-title>. <source xml:lang="en">JoVE (Journal of Visualized Experiments)</source><volume>71</volume>: <pub-id pub-id-type="doi">10.3791/50028</pub-id>.</mixed-citation>
    </ref>
    <ref id="aps311367-bib-0018">
      <mixed-citation publication-type="journal" id="aps311367-cit-0018"><string-name><surname>Meineke</surname>, <given-names>E. K.</given-names></string-name>, and <string-name><given-names>T. J.</given-names><surname>Davies</surname></string-name>. <year>2018</year><article-title>Museum specimens provide novel insights into changing plant–herbivore interactions</article-title>. <source xml:lang="en">Philosophical Transactions of the Royal Society B Biological Sciences</source><volume>374</volume>: <fpage>20170393</fpage>.</mixed-citation>
    </ref>
    <ref id="aps311367-bib-0019">
      <mixed-citation publication-type="journal" id="aps311367-cit-0019"><string-name><surname>Nelson</surname>, <given-names>G.</given-names></string-name>, <string-name><given-names>P.</given-names><surname>Sweeney</surname></string-name>, <string-name><given-names>L. E.</given-names><surname>Wallace</surname></string-name>, <string-name><given-names>R. K.</given-names><surname>Rabeler</surname></string-name>, <string-name><given-names>D.</given-names><surname>Allard</surname></string-name>, <string-name><given-names>H.</given-names><surname>Brown</surname></string-name>, <string-name><given-names>J. R.</given-names><surname>Carter</surname></string-name>, et al. <year>2015</year><article-title>Digitization workflows for flat sheets and packets of plants, algae, and fungi</article-title>. <source xml:lang="en">Applications in Plant Sciences</source><volume>3</volume>(<issue>9</issue>): <fpage>1500054</fpage>.</mixed-citation>
    </ref>
    <ref id="aps311367-bib-0020">
      <mixed-citation publication-type="journal" id="aps311367-cit-0020"><string-name><surname>Ng</surname>, <given-names>J.</given-names></string-name>, and <string-name><given-names>S. D.</given-names><surname>Smith</surname></string-name>. <year>2016</year><article-title>Widespread flower color convergence in Solanaceae via alternate biochemical pathways</article-title>. <source xml:lang="en">New Phytologist</source><volume>209</volume>: <fpage>407</fpage>–<lpage>417</lpage>.<pub-id pub-id-type="pmid">26224118</pub-id></mixed-citation>
    </ref>
    <ref id="aps311367-bib-0021">
      <mixed-citation publication-type="journal" id="aps311367-cit-0021"><string-name><surname>Ng</surname>, <given-names>J.</given-names></string-name>, <string-name><given-names>W. N.</given-names><surname>Weaver</surname></string-name>, and <string-name><given-names>R. G.</given-names><surname>Laport</surname></string-name>. <year>2019</year><article-title>Testing Darwin’s Naturalization Conundrum using phylogenetic relationships: Generalizable patterns across disparate communities?</article-title><source xml:lang="en">Diversity and Distributions</source><volume>25</volume>: <fpage>361</fpage>–<lpage>373</lpage>.</mixed-citation>
    </ref>
    <ref id="aps311367-bib-0022">
      <mixed-citation publication-type="journal" id="aps311367-cit-0022"><string-name><surname>Prather</surname>, <given-names>L. A.</given-names></string-name>, <string-name><given-names>O.</given-names><surname>Alvarez‐Fuentes</surname></string-name>, <string-name><given-names>M. H.</given-names><surname>Mayfield</surname></string-name>, and <string-name><given-names>C. J.</given-names><surname>Ferguson</surname></string-name>. <year>2004</year><article-title>The decline of plant collecting in the United States: A threat to the infrastructure of biodiversity studies</article-title>. <source xml:lang="en">Systematic Botany</source><volume>29</volume>: <fpage>15</fpage>–<lpage>28</lpage>.</mixed-citation>
    </ref>
    <ref id="aps311367-bib-0023">
      <mixed-citation publication-type="journal" id="aps311367-cit-0023"><string-name><surname>Pyke</surname>, <given-names>G. H.</given-names></string-name>, and <string-name><given-names>P. R.</given-names><surname>Ehrlich</surname></string-name>. <year>2010</year><article-title>Biological collections and ecological/environmental research: A review, some observations and a look to the future</article-title>. <source xml:lang="en">Biological Reviews</source><volume>5</volume>: <fpage>247</fpage>–<lpage>266</lpage>.</mixed-citation>
    </ref>
    <ref id="aps311367-bib-0024">
      <mixed-citation publication-type="miscellaneous" id="aps311367-cit-0024"><string-name><surname>Reinking</surname>, <given-names>L.</given-names></string-name><year>2007</year><article-title>Examples of image analysis using ImageJ</article-title>. Website <ext-link ext-link-type="uri" xlink:href="https://imagej.nih.gov/ij/docs/pdfs/examples.pdf">https://imagej.nih.gov/ij/docs/pdfs/examples.pdf</ext-link> [accessed 8 January 2020].</mixed-citation>
    </ref>
    <ref id="aps311367-bib-0025">
      <mixed-citation publication-type="journal" id="aps311367-cit-0025"><string-name><surname>Rohlf</surname>, <given-names>F. J.</given-names></string-name><year>2015</year><article-title>The tps series of software</article-title>. <source xml:lang="en">Hystrix</source><volume>26</volume>: <fpage>9</fpage>–<lpage>12</lpage>.</mixed-citation>
    </ref>
    <ref id="aps311367-bib-0026">
      <mixed-citation publication-type="journal" id="aps311367-cit-0026"><string-name><surname>Schneider</surname>, <given-names>C. A.</given-names></string-name>, <string-name><given-names>W. S.</given-names><surname>Rasband</surname></string-name>, and <string-name><given-names>K. W.</given-names><surname>Eliceiri</surname></string-name>. <year>2012</year><article-title>NIH Image to ImageJ: 25 years of image analysis</article-title>. <source xml:lang="en">Nature Methods</source><volume>9</volume>: <fpage>671</fpage>–<lpage>675</lpage>.<pub-id pub-id-type="pmid">22930834</pub-id></mixed-citation>
    </ref>
    <ref id="aps311367-bib-0027">
      <mixed-citation publication-type="miscellaneous" id="aps311367-cit-0027"><string-name><surname>Thiers</surname>, <given-names>B.</given-names></string-name><year>2020</year><article-title>Index Herbariorum: A global directory of public herbaria and associated staff. New York Botanical Garden's Virtual Herbarium</article-title>. Website <ext-link ext-link-type="uri" xlink:href="http://sweetgum.nybg.org/science/ih/">http://sweetgum.nybg.org/science/ih/</ext-link> [accessed 8 January 2020].</mixed-citation>
    </ref>
    <ref id="aps311367-bib-0028">
      <mixed-citation publication-type="journal" id="aps311367-cit-0028"><string-name><surname>Unger</surname>, <given-names>J.</given-names></string-name>, <string-name><given-names>D.</given-names><surname>Merhof</surname></string-name>, and <string-name><given-names>S.</given-names><surname>Renner</surname></string-name>. <year>2016</year><article-title>Computer vision applied to herbarium specimens of German trees: Testing the future utility of the millions of herbarium specimen images for automated identification</article-title>. <source xml:lang="en">BMC Evolutionary Biology</source><volume>16</volume>: <fpage>248</fpage>.<pub-id pub-id-type="pmid">27852219</pub-id></mixed-citation>
    </ref>
    <ref id="aps311367-bib-0029">
      <mixed-citation publication-type="journal" id="aps311367-cit-0029"><string-name><surname>Weight</surname>, <given-names>C.</given-names></string-name>, <string-name><given-names>D.</given-names><surname>Parnham</surname></string-name>, and <string-name><given-names>R.</given-names><surname>Waites</surname></string-name>. <year>2008</year><article-title>LeafAnalyser: A computation method for rapid and large‐scale analyses of leaf shape variation</article-title>. <source xml:lang="en">Plant Journal</source><volume>53</volume>: <fpage>578</fpage>–<lpage>586</lpage>.<pub-id pub-id-type="pmid">18028263</pub-id></mixed-citation>
    </ref>
    <ref id="aps311367-bib-0030">
      <mixed-citation publication-type="journal" id="aps311367-cit-0030"><string-name><surname>Wilf</surname>, <given-names>P.</given-names></string-name>, <string-name><given-names>S.</given-names><surname>Zhang</surname></string-name>, <string-name><given-names>S.</given-names><surname>Chikkerur</surname></string-name>, <string-name><given-names>S. A.</given-names><surname>Little</surname></string-name>, <string-name><given-names>S. L.</given-names><surname>Wing</surname></string-name>, and <string-name><given-names>T.</given-names><surname>Serre</surname></string-name>. <year>2016</year><article-title>Computer vision cracks the leaf code</article-title>. <source xml:lang="en">Proceedings of the National Academy of Sciences USA</source><volume>113</volume>: <fpage>3305</fpage>–<lpage>3310</lpage>.</mixed-citation>
    </ref>
    <ref id="aps311367-bib-0031">
      <mixed-citation publication-type="journal" id="aps311367-cit-0031"><string-name><surname>Willis</surname>, <given-names>C. G.</given-names></string-name>, <string-name><given-names>E. R.</given-names><surname>Ellwood</surname></string-name>, <string-name><given-names>R. B.</given-names><surname>Primack</surname></string-name>, <string-name><given-names>C. C.</given-names><surname>Davis</surname></string-name>, <string-name><given-names>K. D.</given-names><surname>Pearson</surname></string-name>, <string-name><given-names>A. S.</given-names><surname>Gallinat</surname></string-name>, <string-name><given-names>J. M.</given-names><surname>Yost</surname></string-name>, et al. <year>2017</year><article-title>Old plants, new tricks: Phenological research using herbarium specimens</article-title>. <source xml:lang="en">Trends in Ecology &amp; Evolution</source><volume>32</volume>: <fpage>531</fpage>–<lpage>546</lpage>.<pub-id pub-id-type="pmid">28465044</pub-id></mixed-citation>
    </ref>
    <ref id="aps311367-bib-0032">
      <mixed-citation publication-type="book" id="aps311367-cit-0032"><string-name><surname>Zhang</surname>, <given-names>X.</given-names></string-name>, <string-name><given-names>Y.</given-names><surname>Liu</surname></string-name>, <string-name><given-names>H.</given-names><surname>Lin</surname></string-name>, and <string-name><given-names>Y.</given-names><surname>Liu</surname></string-name>. <year>2016</year><chapter-title>Research on SVM plant leaf identification method based on CSA</chapter-title><italic>In</italic><person-group person-group-type="editor"><name name-style="western"><surname>Che</surname><given-names>W.</given-names></name></person-group>, <person-group person-group-type="editor"><name name-style="western"><surname>Han</surname><given-names>Q.</given-names></name></person-group>, <person-group person-group-type="editor"><name name-style="western"><surname>Wang</surname><given-names>H.</given-names></name></person-group>, <person-group person-group-type="editor"><name name-style="western"><surname>Jing</surname><given-names>W.</given-names></name></person-group>, <person-group person-group-type="editor"><name name-style="western"><surname>Peng</surname><given-names>S.</given-names></name></person-group>, <person-group person-group-type="editor"><name name-style="western"><surname>Lin</surname><given-names>J.</given-names></name></person-group>, <person-group person-group-type="editor"><name name-style="western"><surname>Sun</surname><given-names>G.</given-names></name></person-group>, et al. (eds.), <source xml:lang="en">ICYCSEE 2016: Social Computing</source>, <fpage>171</fpage>–<lpage>179</lpage>. Communications in Computer and Information Science, vol. 624. <publisher-name>Springer</publisher-name>, <publisher-loc>Singapore</publisher-loc>.</mixed-citation>
    </ref>
  </ref-list>
</back>
