<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id>
    <journal-id journal-id-type="publisher-id">bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1367-4803</issn>
    <issn pub-type="epub">1367-4811</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">10101696</article-id>
    <article-id pub-id-type="pmid">36975610</article-id>
    <article-id pub-id-type="doi">10.1093/bioinformatics/btad162</article-id>
    <article-id pub-id-type="publisher-id">btad162</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Original Paper</subject>
        <subj-group subj-group-type="category-toc-heading">
          <subject>Gene Expression</subject>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI01060</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Con-AAE: contrastive cycle adversarial autoencoders for single-cell multi-omics alignment and integration</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0001-9961-0017</contrib-id>
        <name>
          <surname>Wang</surname>
          <given-names>Xuesong</given-names>
        </name>
        <aff><institution>Department of Computer Science and Engineering, The Chinese University of Hong Kong (CUHK)</institution>, Hong Kong SAR 999077, <country country="CN">China</country></aff>
        <aff><institution>The Chinese University of Hong Kong (CUHK) Shenzhen Research Institute</institution>, Nanshan, Shenzhen 518057, <country country="CN">China</country></aff>
        <aff><institution>School of Software Engineering, University of Science and Technology of China (USTC)</institution>, Hefei 230026, <country country="CN">China</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Hu</surname>
          <given-names>Zhihang</given-names>
        </name>
        <aff><institution>Department of Computer Science and Engineering, The Chinese University of Hong Kong (CUHK)</institution>, Hong Kong SAR 999077, <country country="CN">China</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Yu</surname>
          <given-names>Tingyang</given-names>
        </name>
        <aff><institution>Department of Mathematics, The Chinese University of Hong Kong (CUHK)</institution>, <addr-line>Hong Kong SAR </addr-line>999077, <country country="CN">China</country></aff>
        <aff><institution>Department of Information Engineering, The Chinese University of Hong Kong (CUHK)</institution>, Hong Kong SAR 999077, <country country="CN">China</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Wang</surname>
          <given-names>Yixuan</given-names>
        </name>
        <aff><institution>Department of Computer Science and Engineering, The Chinese University of Hong Kong (CUHK)</institution>, Hong Kong SAR 999077, <country country="CN">China</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Wang</surname>
          <given-names>Ruijie</given-names>
        </name>
        <aff><institution>Department of Computer Science and Engineering, The Chinese University of Hong Kong (CUHK)</institution>, Hong Kong SAR 999077, <country country="CN">China</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Wei</surname>
          <given-names>Yumeng</given-names>
        </name>
        <aff><institution>Department of Computer Science and Engineering, The Chinese University of Hong Kong (CUHK)</institution>, Hong Kong SAR 999077, <country country="CN">China</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Shu</surname>
          <given-names>Juan</given-names>
        </name>
        <aff><institution>Department of Statistics, Purdue University</institution>, West Lafayette, IN 47907, <country country="US">United States</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Ma</surname>
          <given-names>Jianzhu</given-names>
        </name>
        <aff><institution>Department of Electrical Engineering, Tsinghua University</institution>, Beijing 100084, <country country="CN">China</country></aff>
        <aff><institution>Institute for AI Industry Research, Tsinghua University</institution>, Beijing 100084, <country country="CN">China</country></aff>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-3664-6722</contrib-id>
        <name>
          <surname>Li</surname>
          <given-names>Yu</given-names>
        </name>
        <aff><institution>Department of Computer Science and Engineering, The Chinese University of Hong Kong (CUHK)</institution>, Hong Kong SAR 999077, <country country="CN">China</country></aff>
        <aff><institution>The Chinese University of Hong Kong (CUHK) Shenzhen Research Institute</institution>, Nanshan, Shenzhen 518057, <country country="CN">China</country></aff>
        <!--liyu@cse.cuhk.edu.hk-->
        <xref rid="btad162-cor1" ref-type="corresp"/>
      </contrib>
    </contrib-group>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Mathelier</surname>
          <given-names>Anthony</given-names>
        </name>
        <role>Associate Editor</role>
      </contrib>
    </contrib-group>
    <author-notes>
      <corresp id="btad162-cor1">Corresponding author. Department of Computer Science and Engineering, The Chinese University of Hong Kong (CUHK), Chung Chi Rd, Ma Liu Shui 999077, China. Tel: +852 3943 8397. E-mail: <email>liyu@cse.cuhk.edu.hk</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <month>4</month>
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2023-03-28">
      <day>28</day>
      <month>3</month>
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>28</day>
      <month>3</month>
      <year>2023</year>
    </pub-date>
    <volume>39</volume>
    <issue>4</issue>
    <elocation-id>btad162</elocation-id>
    <history>
      <date date-type="received">
        <day>19</day>
        <month>10</month>
        <year>2022</year>
      </date>
      <date date-type="rev-recd">
        <day>21</day>
        <month>3</month>
        <year>2023</year>
      </date>
      <date date-type="editorial-decision">
        <day>23</day>
        <month>3</month>
        <year>2023</year>
      </date>
      <date date-type="accepted">
        <day>27</day>
        <month>3</month>
        <year>2023</year>
      </date>
      <date date-type="corrected-typeset">
        <day>13</day>
        <month>4</month>
        <year>2023</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2023. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2023</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="btad162.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Motivation</title>
        <p>We have entered the multi-omics era and can measure cells from different aspects. Hence, we can get a more comprehensive view by integrating or matching data from different spaces corresponding to the same object. However, it is particularly challenging in the single-cell multi-omics scenario because such data are very sparse with extremely high dimensions. Though some techniques can be used to measure scATAC-seq and scRNA-seq simultaneously, the data are usually highly noisy due to the limitations of the experimental environment.</p>
      </sec>
      <sec id="s2">
        <title>Results</title>
        <p>To promote single-cell multi-omics research, we overcome the above challenges, proposing a novel framework, contrastive cycle adversarial autoencoders, which can align and integrate single-cell RNA-seq data and single-cell ATAC-seq data. Con-AAE can efficiently map the above data with high sparsity and noise from different spaces to a coordinated subspace, where alignment and integration tasks can be easier. We demonstrate its advantages on several datasets.</p>
      </sec>
      <sec id="s3">
        <title>Availability and implementation</title>
        <p>Zenodo link: <ext-link xlink:href="https://zenodo.org/badge/latestdoi/368779433" ext-link-type="uri">https://zenodo.org/badge/latestdoi/368779433</ext-link>. github: <ext-link xlink:href="https://github.com/kakarotcq/Con-AAE" ext-link-type="uri">https://github.com/kakarotcq/Con-AAE</ext-link>.</p>
      </sec>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Chinese University of Hong Kong</institution>
            <institution-id institution-id-type="DOI">10.13039/501100004853</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>4937025</award-id>
        <award-id>4937026</award-id>
        <award-id>5501517</award-id>
        <award-id>5501329</award-id>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="7"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 Introduction</title>
    <p>Single-cell multi-omics methods promise great opportunities to understand the cellular system more comprehensively. To achieve that, we should integrate multi-omics data, which describe cells from different perspective. Profiling multi-omics for the same set of single cells have become available (<xref rid="btad162-B13" ref-type="bibr">Gala et al. 2021</xref>), such as single-cell RNA sequencing (scRNA-seq) and single-cell Assay for Transposase Accessible Chromatin sequencing (scATAC-seq), which describe the same cell from different perspectives. However, these techniques are not widely used due to the low sensitivity of one of the data modalities. Consequently, lots of computational methods have been proposed to integrate multi-omics data (<xref rid="btad162-F1" ref-type="fig">Fig. 1a</xref>). We term this task as ‘integration’. More specifically, we want to obtain the high-throughput paired multi-omics data for every single cell, referred to ‘alignment’. On the other hand, even for data within the same modality, the data distribution can be inconsistent because of the subtle differences in measurement processes (<xref rid="btad162-B7" ref-type="bibr">Cao et al. 2018</xref>). This is the basic problem to be considered in the integration process.</p>
    <fig position="float" id="btad162-F1">
      <label>Figure 1.</label>
      <caption>
        <p>(a) scRNA-seq and scATAC-seq data measure different aspects of the same cell. We aim at identifying the correspondence between the two kinds of data from the same set of cells. (b) The Con-AAE framework uses two autoencoders to map the two kinds of sequence data into two low-dimensional manifolds, forcing the two spaces to be as unified as possible with the adversarial loss and latent cycle-consistency loss. We train the models without pairwise information for the alignment task but consider the data noise explicitly by utilizing self-supervised contrastive learning. We feed the annotated data for the integration task to help the model learn</p>
      </caption>
      <graphic xlink:href="btad162f1" position="float"/>
    </fig>
    <p>Some computational methods have been proposed to deal with these two crucial but challenging problems, aligning and integrating data from different omics. People usually integrate and align multi-omics data in the learned low-dimensional embedding space using dimension reduction techniques, such as principal component analysis (PCA) (<xref rid="btad162-B4" ref-type="bibr">Bersanelli et al. 2016</xref>; <xref rid="btad162-B2" ref-type="bibr">Argelaguet et al. 2018</xref>) and non-linear successors of the classic canonical correlation analysis (CCA) (<xref rid="btad162-B27" ref-type="bibr">Stanley et al. 2020</xref>). The typical examples are Seurat (<xref rid="btad162-B28" ref-type="bibr">Stuart et al. 2019</xref>) and deep classic canonical correlation (DCCA) (<xref rid="btad162-B1" ref-type="bibr">Andrew et al. 2013</xref>). Seurat (<xref rid="btad162-B28" ref-type="bibr">Stuart et al. 2019</xref>) relies on the linear mapping of PCA and aligns the embedding vectors based on linear methods Mutual Nearest Neighbors and CCA, which weaken its ability to handle non-linear geometrical transformations across cellular modalities (<xref rid="btad162-B9" ref-type="bibr">Cao et al. 2022</xref>). DCCA can be effective for non-linear transformation benefiting from deep learning. However, according to the results of our experiments, it is not robust enough when the signal-to-noise ratio (SNR) is low. We also try Maximum Mean Discrepancy (MMD) (<xref rid="btad162-B6" ref-type="bibr">Borgwardt et al. 2006</xref>) to replace CCA in the embedding space, but the performance is also not good enough. Several methods requiring no correspondence information are derived under advanced machine-learning techniques, such as Pamona (<xref rid="btad162-B9" ref-type="bibr">Cao et al. 2022</xref>), MATCHER (<xref rid="btad162-B31" ref-type="bibr">Welch et al. 2017</xref>), MMD-MA (<xref rid="btad162-B26" ref-type="bibr">Singh et al. 2020</xref>), UnionCom (<xref rid="btad162-B8" ref-type="bibr">Cao et al. 2020</xref>), and SCOT (<xref rid="btad162-B12" ref-type="bibr">Demetci et al. 2022</xref>). Although these methods are unsupervised and achieve good performance with encouraging results (<xref rid="btad162-B12" ref-type="bibr">Demetci et al. 2022</xref>), they are not robust enough to noise. Deep learning methods are promising to provide alignment and transfer learning between datasets (<xref rid="btad162-B19" ref-type="bibr">Li et al. 2019</xref>, <xref rid="btad162-B18" ref-type="bibr">2020</xref>). Deep generative models, such as CycleGAN (<xref rid="btad162-B34" ref-type="bibr">Zhu et al. 2017</xref>), MAGAN (<xref rid="btad162-B30" ref-type="bibr">Wang et al. 2017</xref>), RadialGAN (<xref rid="btad162-B32" ref-type="bibr">Yoon et al. 2018</xref>), and starGAN (<xref rid="btad162-B10" ref-type="bibr">Choi et al. 2018</xref>), are used to learn a non-linear mapping from one domain to another and achieve great performance on some single modality task. But the above transitions are almost within the same modality and can be disturbed by noise or sparsity in the data (<xref rid="btad162-B27" ref-type="bibr">Stanley et al. 2020</xref>). The scenario of multi-omics translation and alignment is much more complicated. Some other works propose models to align multi-omics data based on multiple autoencoders (<xref rid="btad162-B22" ref-type="bibr">Ma and Zhang 2019</xref>; <xref rid="btad162-B33" ref-type="bibr">Zhang et al. 2019</xref>; <xref rid="btad162-B11" ref-type="bibr">Dai Yang et al. 2021</xref>). However, such methods also can be seriously affected by noise or sparsity, which is a fundamental characteristic of single-cell data.</p>
    <p>To promote the single-cell multi-omics data analysis, we propose a framework based on Contrastive cycle adversarial Autoencoders (Con-AAE), which can integrate multi-omics data (<xref rid="btad162-F1" ref-type="fig">Fig. 1b</xref>).</p>
    <p>Con-AAE uses two autoencoders to map two modality data into two low-dimensional manifolds under the constrain of adversarial loss, trying to develop representations for each modality that are separated but cannot be identified by an adversarial network in a coordinated subspace (<xref rid="btad162-B14" ref-type="bibr">Guo et al. 2019</xref>). However, only using the adversarial loss may lead to model collapse. To avoid the problem, we further propose a novel cycle-consistency loss. For instance, we have two autoencoders for two modalities, scATAC-seq data and scRNA-seq data. The embedding produced by the scRNA-seq encoder will go through the scATAC-seq decoder and encoder successively to produce another cycled embedding. We can check the consistency between the original embedding and the cycled embedding. In addition to the above two loss terms, we train the models without pairwise information for the alignment task but consider the data noise explicitly by taking advantage of self-supervised contrastive learning. For the integration task, we train the framework with annotated data. We extensively perform experiments on four real-world datasets, and a group of simulated datasets consisting of various distributions. The four real-world datasets consist of scATAC-seq and scRNA-seq data from the same set of cells. The comprehensive experiments on both simulated and real-world datasets show that our method has better performance and is more robust than the other state-of-art methods.</p>
  </sec>
  <sec>
    <title>2 Materials and methods</title>
    <p>In this section, we give our framework in details below with <xref rid="btad162-F1" ref-type="fig">Fig. 1b</xref>, which illustrates the whole pipeline. To start with, we formalize the integration problem as,
</p>
    <disp-formula id="E1">
      <label>(1)</label>
      <mml:math id="M1" display="block" overflow="scroll">
        <mml:mrow>
          <mml:mo>∀</mml:mo>
          <mml:mi>R</mml:mi>
          <mml:mo>∈</mml:mo>
          <mml:msub>
            <mml:mrow>
              <mml:mi>P</mml:mi>
            </mml:mrow>
            <mml:mi>R</mml:mi>
          </mml:msub>
          <mml:mo> </mml:mo>
          <mml:mi mathvariant="italic">and</mml:mi>
          <mml:mo> </mml:mo>
          <mml:mo>∀</mml:mo>
          <mml:mi>A</mml:mi>
          <mml:mo>∈</mml:mo>
          <mml:msub>
            <mml:mrow>
              <mml:mi>P</mml:mi>
            </mml:mrow>
            <mml:mi>A</mml:mi>
          </mml:msub>
          <mml:mo>,</mml:mo>
          <mml:mi mathvariant="script" class="calligraphy">D</mml:mi>
          <mml:mo stretchy="false">(</mml:mo>
          <mml:mi>f</mml:mi>
          <mml:mo stretchy="false">(</mml:mo>
          <mml:mi>R</mml:mi>
          <mml:mo stretchy="false">)</mml:mo>
          <mml:mo stretchy="false">)</mml:mo>
          <mml:mo>=</mml:mo>
          <mml:mi mathvariant="script" class="calligraphy">D</mml:mi>
          <mml:mo stretchy="false">(</mml:mo>
          <mml:mi>h</mml:mi>
          <mml:mo stretchy="false">(</mml:mo>
          <mml:mi>A</mml:mi>
          <mml:mo stretchy="false">)</mml:mo>
          <mml:mo stretchy="false">)</mml:mo>
          <mml:mo>.</mml:mo>
        </mml:mrow>
      </mml:math>
    </disp-formula>
    <p>We denote <italic toggle="yes">R</italic> as vectors of scRNA-seq domain and <italic toggle="yes">A</italic> as vectors of scATAC-seq domain. We would like to find two mappings <italic toggle="yes">f</italic> and <italic toggle="yes">h</italic> such that for any samples from <italic toggle="yes">R</italic> and <italic toggle="yes">A</italic>, <italic toggle="yes">f</italic> and <italic toggle="yes">h</italic> would maps the scRNA-seq profile and scATAC-seq profile to a coordinated subspace, where a discriminator <inline-formula id="IE1"><mml:math id="IM1" display="inline" overflow="scroll"><mml:mi mathvariant="script" class="calligraphy">D</mml:mi></mml:math></inline-formula> cannot distinguish <italic toggle="yes">f</italic>(<italic toggle="yes">R</italic>) and <italic toggle="yes">h</italic>(<italic toggle="yes">A</italic>). Due to the disparity between the original distributions of different omics data being complicated and non-linear, how to find a pair of <italic toggle="yes">f</italic> and <italic toggle="yes">h</italic> is a major problem.</p>
    <p>In addition to map scRNA-seq data and scATAC-seq data to a coordinated subspace. The identity labels are available, and, therefore, it can be trained in a supervised way to maintain the cluster structure of cells. For <inline-formula id="IE2"><mml:math id="IM2" display="inline" overflow="scroll"><mml:mrow><mml:mo>∀</mml:mo><mml:mi>x</mml:mi><mml:mo>∈</mml:mo></mml:mrow></mml:math></inline-formula>{scRNA-seq embedding}<inline-formula id="IE3"><mml:math id="IM3" display="inline" overflow="scroll"><mml:mo>∪</mml:mo></mml:math></inline-formula>{scATAC-seq embedding}, we want to train a classifier <italic toggle="yes">g</italic> such that,
</p>
    <disp-formula id="E2">
      <label>(2)</label>
      <mml:math id="M2" display="block" overflow="scroll">
        <mml:mrow>
          <mml:mi>g</mml:mi>
          <mml:mo stretchy="false">(</mml:mo>
          <mml:mi>x</mml:mi>
          <mml:mo stretchy="false">)</mml:mo>
          <mml:mo>=</mml:mo>
          <mml:mi mathvariant="italic">label</mml:mi>
          <mml:mo stretchy="false">(</mml:mo>
          <mml:mi>x</mml:mi>
          <mml:mo stretchy="false">)</mml:mo>
          <mml:mo>.</mml:mo>
        </mml:mrow>
      </mml:math>
    </disp-formula>
    <p>Our main model is built upon the framework of Adversarial Auto-Encoders (<xref rid="btad162-B23" ref-type="bibr">Makhzani et al. 2016</xref>) specialized for modality task, integrating our novel embedding consistency module. The intuition behind is that multi-omics from a single-cell data should obtain commonality, and their mappings could live in a coordinated subspace, which therefore makes alignment and integration possible.</p>
    <sec>
      <title>2.1 Adversarial autoencoders</title>
      <p>The usage of adversarial autoencoders aims to constrain embeddings for each modality in a coordinated subspace, where embeddings mapped from different omics are close to each other. Therefore, as shown in <xref rid="btad162-F2" ref-type="fig">Fig. 2b</xref>, we are using a coupled set of encoders <inline-formula id="IE4"><mml:math id="IM4" display="inline" overflow="scroll"><mml:mrow><mml:mo>{</mml:mo><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> (<xref rid="btad162-B16" ref-type="bibr">Hira et al. 2021</xref>) to map {scATACs-eq, scRNA-seq} into manifolds <inline-formula id="IE5"><mml:math id="IM5" display="inline" overflow="scroll"><mml:mrow><mml:mo>{</mml:mo><mml:msub><mml:mrow><mml:mi>Z</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>Z</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula>, and decoders <inline-formula id="IE6"><mml:math id="IM6" display="inline" overflow="scroll"><mml:mrow><mml:mo>{</mml:mo><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> could decode the embedded manifolds back to the original distribution. The reconstruction loss is defined as follows,
whereas <italic toggle="yes">d</italic> stands for indicated distance in the embedding space. Discriminator <inline-formula id="IE7"><mml:math id="IM7" display="inline" overflow="scroll"><mml:mi mathvariant="script" class="calligraphy">D</mml:mi></mml:math></inline-formula> tries to align these embedded manifolds and works in the sense that input <inline-formula id="IE8"><mml:math id="IM8" display="inline" overflow="scroll"><mml:mrow><mml:mi>x</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mrow><mml:mi>Z</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mi mathvariant="script" class="calligraphy">D</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE9"><mml:math id="IM9" display="inline" overflow="scroll"><mml:mrow><mml:mi>x</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mrow><mml:mi>Z</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mi mathvariant="script" class="calligraphy">D</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>.
</p>
      <disp-formula id="E3">
        <label>(3)</label>
        <mml:math id="M3" display="block" overflow="scroll">
          <mml:mrow>
            <mml:mtable>
              <mml:mtr columnalign="left">
                <mml:mtd columnalign="left">
                  <mml:mrow>
                    <mml:msub>
                      <mml:mrow>
                        <mml:mi>L</mml:mi>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mi mathvariant="italic">recon</mml:mi>
                      </mml:mrow>
                    </mml:msub>
                  </mml:mrow>
                </mml:mtd>
                <mml:mtd columnalign="left">
                  <mml:mrow>
                    <mml:mo>=</mml:mo>
                    <mml:msub>
                      <mml:mrow>
                        <mml:mi mathvariant="double-struck">E</mml:mi>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mi>x</mml:mi>
                        <mml:mo>∼</mml:mo>
                        <mml:msub>
                          <mml:mrow>
                            <mml:mi>p</mml:mi>
                          </mml:mrow>
                          <mml:mrow>
                            <mml:mi mathvariant="italic">rna</mml:mi>
                          </mml:mrow>
                        </mml:msub>
                      </mml:mrow>
                    </mml:msub>
                    <mml:mi>d</mml:mi>
                    <mml:mo stretchy="false">(</mml:mo>
                    <mml:mi>x</mml:mi>
                    <mml:mo>,</mml:mo>
                    <mml:msub>
                      <mml:mrow>
                        <mml:mi>D</mml:mi>
                      </mml:mrow>
                      <mml:mi>j</mml:mi>
                    </mml:msub>
                    <mml:mo stretchy="false">(</mml:mo>
                    <mml:msub>
                      <mml:mrow>
                        <mml:mi>E</mml:mi>
                      </mml:mrow>
                      <mml:mi>j</mml:mi>
                    </mml:msub>
                    <mml:mo stretchy="false">(</mml:mo>
                    <mml:mi>x</mml:mi>
                    <mml:mo stretchy="false">)</mml:mo>
                    <mml:mo stretchy="false">)</mml:mo>
                    <mml:mo stretchy="false">)</mml:mo>
                  </mml:mrow>
                </mml:mtd>
              </mml:mtr>
              <mml:mtr columnalign="left">
                <mml:mtd columnalign="left">
                  <mml:mrow/>
                </mml:mtd>
                <mml:mtd columnalign="left">
                  <mml:mrow>
                    <mml:mo>+</mml:mo>
                    <mml:mo> </mml:mo>
                    <mml:msub>
                      <mml:mrow>
                        <mml:mi mathvariant="double-struck">E</mml:mi>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mi>x</mml:mi>
                        <mml:mo>∼</mml:mo>
                        <mml:msub>
                          <mml:mrow>
                            <mml:mi>p</mml:mi>
                          </mml:mrow>
                          <mml:mrow>
                            <mml:mi mathvariant="italic">atac</mml:mi>
                          </mml:mrow>
                        </mml:msub>
                      </mml:mrow>
                    </mml:msub>
                    <mml:mi>d</mml:mi>
                    <mml:mo stretchy="false">(</mml:mo>
                    <mml:mi>x</mml:mi>
                    <mml:mo>,</mml:mo>
                    <mml:msub>
                      <mml:mrow>
                        <mml:mi>D</mml:mi>
                      </mml:mrow>
                      <mml:mi>i</mml:mi>
                    </mml:msub>
                    <mml:mo stretchy="false">(</mml:mo>
                    <mml:msub>
                      <mml:mrow>
                        <mml:mi>E</mml:mi>
                      </mml:mrow>
                      <mml:mi>i</mml:mi>
                    </mml:msub>
                    <mml:mo stretchy="false">(</mml:mo>
                    <mml:mi>x</mml:mi>
                    <mml:mo stretchy="false">)</mml:mo>
                    <mml:mo stretchy="false">)</mml:mo>
                    <mml:mo stretchy="false">)</mml:mo>
                    <mml:mo>,</mml:mo>
                  </mml:mrow>
                </mml:mtd>
              </mml:mtr>
            </mml:mtable>
          </mml:mrow>
        </mml:math>
      </disp-formula>
      <disp-formula id="E4">
        <label>(4)</label>
        <mml:math id="M4" display="block" overflow="scroll">
          <mml:mrow>
            <mml:mtable>
              <mml:mtr columnalign="left">
                <mml:mtd columnalign="left">
                  <mml:mrow>
                    <mml:msub>
                      <mml:mrow>
                        <mml:mi>L</mml:mi>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mi mathvariant="italic">adv</mml:mi>
                      </mml:mrow>
                    </mml:msub>
                  </mml:mrow>
                </mml:mtd>
                <mml:mtd columnalign="left">
                  <mml:mrow>
                    <mml:mo>=</mml:mo>
                    <mml:msub>
                      <mml:mrow>
                        <mml:mi mathvariant="double-struck">E</mml:mi>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mi>x</mml:mi>
                        <mml:mo>∼</mml:mo>
                        <mml:msub>
                          <mml:mrow>
                            <mml:mi>p</mml:mi>
                          </mml:mrow>
                          <mml:mrow>
                            <mml:mi mathvariant="italic">rna</mml:mi>
                          </mml:mrow>
                        </mml:msub>
                      </mml:mrow>
                    </mml:msub>
                    <mml:mo stretchy="false">[</mml:mo>
                    <mml:mtext>log</mml:mtext>
                    <mml:mo> </mml:mo>
                    <mml:mi mathvariant="script" class="calligraphy">D</mml:mi>
                    <mml:mo stretchy="false">(</mml:mo>
                    <mml:msub>
                      <mml:mrow>
                        <mml:mi>E</mml:mi>
                      </mml:mrow>
                      <mml:mi>j</mml:mi>
                    </mml:msub>
                    <mml:mo stretchy="false">(</mml:mo>
                    <mml:mi>x</mml:mi>
                    <mml:mo stretchy="false">)</mml:mo>
                    <mml:mo stretchy="false">)</mml:mo>
                    <mml:mo stretchy="false">]</mml:mo>
                  </mml:mrow>
                </mml:mtd>
              </mml:mtr>
              <mml:mtr columnalign="left">
                <mml:mtd columnalign="left">
                  <mml:mrow/>
                </mml:mtd>
                <mml:mtd columnalign="left">
                  <mml:mrow>
                    <mml:mo>+</mml:mo>
                    <mml:mo> </mml:mo>
                    <mml:msub>
                      <mml:mrow>
                        <mml:mi mathvariant="double-struck">E</mml:mi>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mi>x</mml:mi>
                        <mml:mo>∼</mml:mo>
                        <mml:msub>
                          <mml:mrow>
                            <mml:mi>p</mml:mi>
                          </mml:mrow>
                          <mml:mrow>
                            <mml:mi mathvariant="italic">atac</mml:mi>
                          </mml:mrow>
                        </mml:msub>
                      </mml:mrow>
                    </mml:msub>
                    <mml:mo stretchy="false">[</mml:mo>
                    <mml:mtext>log</mml:mtext>
                    <mml:mo stretchy="false">(</mml:mo>
                    <mml:mn>1</mml:mn>
                    <mml:mo>−</mml:mo>
                    <mml:mi mathvariant="script" class="calligraphy">D</mml:mi>
                    <mml:mo stretchy="false">(</mml:mo>
                    <mml:msub>
                      <mml:mrow>
                        <mml:mi>E</mml:mi>
                      </mml:mrow>
                      <mml:mi>i</mml:mi>
                    </mml:msub>
                    <mml:mo stretchy="false">(</mml:mo>
                    <mml:mi>x</mml:mi>
                    <mml:mo stretchy="false">)</mml:mo>
                    <mml:mo stretchy="false">)</mml:mo>
                    <mml:mo stretchy="false">)</mml:mo>
                    <mml:mo stretchy="false">]</mml:mo>
                    <mml:mo>.</mml:mo>
                  </mml:mrow>
                </mml:mtd>
              </mml:mtr>
            </mml:mtable>
          </mml:mrow>
        </mml:math>
      </disp-formula>
      <fig position="float" id="btad162-F2">
        <label>Figure 2.</label>
        <caption>
          <p>(a) The embedding produced by the first encoder will go through the second decoder and encoder successfully to produce another cycled embedding. We can check the consistency between the original embedding and the cycled embedding. (b) The contrastive loss minimizes the distance between positive pairs and maximizes the distance between negative pairs. This loss makes our method more robust to noise</p>
        </caption>
        <graphic xlink:href="btad162f2" position="float"/>
      </fig>
      <p>The above losses <italic toggle="yes">L</italic><sub>recon</sub> and <italic toggle="yes">L</italic><sub>adv</sub> are trained together with the same weights.</p>
    </sec>
    <sec>
      <title>2.2 Cycle-consistency loss</title>
      <p>The backbone framework enforces the embedding manifolds to align gradually. However, a critical problem underlying is that since scRNA-seq and scATAC-seq data are sparse in a high dimensional domain, the training procedure above only aligns and trains on those regions where the data exist.</p>
      <p>For instance, if a region <italic toggle="yes">A</italic> in the embedding space around <inline-formula id="IE10"><mml:math id="IM10" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>x</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:msup><mml:mi>x</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>∈</mml:mo></mml:mrow></mml:math></inline-formula>{scRNA-seq} does not involve any existing <inline-formula id="IE11"><mml:math id="IM11" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mi>x</mml:mi><mml:mo>∈</mml:mo></mml:mrow></mml:math></inline-formula>{scATAC-seq}. Then, neither the decoder <italic toggle="yes">D<sub>i</sub></italic> nor the encoder <italic toggle="yes">E<sub>i</sub></italic> is trained on <italic toggle="yes">A</italic>, thus they would not compute in a “reverse” mapping way, and the result of <inline-formula id="IE12"><mml:math id="IM12" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> would be unreasonable or may not lie on the aligned manifold. This critical problem causes the difficulty of inferring from scRNA-seq profile to scATAC-seq profile directly.</p>
      <p>Therefore, we introduce a cycle-consistency loss shown in <xref rid="btad162-F2" ref-type="fig">Fig. 2a</xref> (<xref rid="btad162-B34" ref-type="bibr">Zhu et al. 2017</xref>; <xref rid="btad162-B17" ref-type="bibr">Hu and Wang 2019</xref>) to resolve this problem,
</p>
      <disp-formula id="E5">
        <label>(5)</label>
        <mml:math id="M5" display="block" overflow="scroll">
          <mml:mrow>
            <mml:mtable>
              <mml:mtr columnalign="left">
                <mml:mtd columnalign="left">
                  <mml:mrow>
                    <mml:msub>
                      <mml:mrow>
                        <mml:mi>L</mml:mi>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mi mathvariant="italic">cyc</mml:mi>
                      </mml:mrow>
                    </mml:msub>
                  </mml:mrow>
                </mml:mtd>
                <mml:mtd columnalign="left">
                  <mml:mrow>
                    <mml:mo>=</mml:mo>
                    <mml:msub>
                      <mml:mrow>
                        <mml:mi mathvariant="double-struck">E</mml:mi>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mi>x</mml:mi>
                        <mml:mo>∼</mml:mo>
                        <mml:msub>
                          <mml:mrow>
                            <mml:mi>p</mml:mi>
                          </mml:mrow>
                          <mml:mrow>
                            <mml:mi mathvariant="italic">rna</mml:mi>
                          </mml:mrow>
                        </mml:msub>
                      </mml:mrow>
                    </mml:msub>
                    <mml:mo stretchy="false">[</mml:mo>
                    <mml:mi>d</mml:mi>
                    <mml:mo stretchy="false">(</mml:mo>
                    <mml:msub>
                      <mml:mrow>
                        <mml:mi>E</mml:mi>
                      </mml:mrow>
                      <mml:mi>j</mml:mi>
                    </mml:msub>
                    <mml:mo stretchy="false">(</mml:mo>
                    <mml:mi>x</mml:mi>
                    <mml:mo stretchy="false">)</mml:mo>
                    <mml:mo>,</mml:mo>
                    <mml:msub>
                      <mml:mrow>
                        <mml:mi>E</mml:mi>
                      </mml:mrow>
                      <mml:mi>i</mml:mi>
                    </mml:msub>
                    <mml:msub>
                      <mml:mrow>
                        <mml:mi>D</mml:mi>
                      </mml:mrow>
                      <mml:mi>i</mml:mi>
                    </mml:msub>
                    <mml:msub>
                      <mml:mrow>
                        <mml:mi>E</mml:mi>
                      </mml:mrow>
                      <mml:mi>j</mml:mi>
                    </mml:msub>
                    <mml:mo stretchy="false">(</mml:mo>
                    <mml:mi>x</mml:mi>
                    <mml:mo stretchy="false">)</mml:mo>
                    <mml:mo stretchy="false">)</mml:mo>
                    <mml:mo stretchy="false">]</mml:mo>
                  </mml:mrow>
                </mml:mtd>
              </mml:mtr>
              <mml:mtr columnalign="left">
                <mml:mtd columnalign="left">
                  <mml:mrow/>
                </mml:mtd>
                <mml:mtd columnalign="left">
                  <mml:mrow>
                    <mml:mo>+</mml:mo>
                    <mml:mo> </mml:mo>
                    <mml:msub>
                      <mml:mrow>
                        <mml:mi mathvariant="double-struck">E</mml:mi>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mi>x</mml:mi>
                        <mml:mo>∼</mml:mo>
                        <mml:msub>
                          <mml:mrow>
                            <mml:mi>p</mml:mi>
                          </mml:mrow>
                          <mml:mrow>
                            <mml:mi mathvariant="italic">atac</mml:mi>
                          </mml:mrow>
                        </mml:msub>
                      </mml:mrow>
                    </mml:msub>
                    <mml:mo stretchy="false">[</mml:mo>
                    <mml:mi>d</mml:mi>
                    <mml:mo stretchy="false">(</mml:mo>
                    <mml:msub>
                      <mml:mrow>
                        <mml:mi>E</mml:mi>
                      </mml:mrow>
                      <mml:mi>i</mml:mi>
                    </mml:msub>
                    <mml:mo stretchy="false">(</mml:mo>
                    <mml:mi>x</mml:mi>
                    <mml:mo stretchy="false">)</mml:mo>
                    <mml:mo>,</mml:mo>
                    <mml:msub>
                      <mml:mrow>
                        <mml:mi>E</mml:mi>
                      </mml:mrow>
                      <mml:mi>j</mml:mi>
                    </mml:msub>
                    <mml:msub>
                      <mml:mrow>
                        <mml:mi>D</mml:mi>
                      </mml:mrow>
                      <mml:mi>j</mml:mi>
                    </mml:msub>
                    <mml:msub>
                      <mml:mrow>
                        <mml:mi>E</mml:mi>
                      </mml:mrow>
                      <mml:mi>i</mml:mi>
                    </mml:msub>
                    <mml:mo stretchy="false">(</mml:mo>
                    <mml:mi>x</mml:mi>
                    <mml:mo stretchy="false">)</mml:mo>
                    <mml:mo stretchy="false">)</mml:mo>
                    <mml:mo stretchy="false">]</mml:mo>
                    <mml:mo>.</mml:mo>
                  </mml:mrow>
                </mml:mtd>
              </mml:mtr>
            </mml:mtable>
          </mml:mrow>
        </mml:math>
      </disp-formula>
      <p><italic toggle="yes">L</italic><sub>cyc</sub> aims to train the set of encoder–decoder on the domain where different omics data may not exist, which enforces the smoothness and consistency in those regions. In this way, we could compare the embedding of <inline-formula id="IE13"><mml:math id="IM13" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mi>x</mml:mi><mml:mo>∈</mml:mo></mml:mrow></mml:math></inline-formula>{scATAC-seq} directly with the existing scRNA-seq embedding around it.</p>
    </sec>
    <sec>
      <title>2.3 Contrastive loss</title>
      <p>The above framework works in an unsupervised manner such that the embedded latent manifolds of multi-omics align properly.</p>
      <p>We could further improve our work on both tasks by taking advantage of the ground-truth cell type labels. The cell type labels could refer to biological cell types or the labels of data batches collected from different times or platforms. Following the idea of contrastive learning (<xref rid="btad162-B25" ref-type="bibr">Schroff et al. 2015</xref>; <xref rid="btad162-B15" ref-type="bibr">Han et al. 2022</xref>), we employ a contrastive loss in embedding space. It enforces smaller In-Batch distance and larger Between-Batch distance. In-Batch refers to different modality data collected from the same cluster and <italic toggle="yes">vice versa</italic>. We equally treat both modalities in contrastive training, which benefits the alignment task in the sense that multi-omics of the same single-cell data should obviously belong to the same cluster. We show that lowering the In-Batch distance indeed improves the alignment accuracy in the below ablation studies. On the other hand, contrastive training benefits integration by enabling the decision boundary to be smoother and more robust.</p>
      <p>In practice, we first encode data from two modalities to the embedding space. Define the embedding by <inline-formula id="IE14"><mml:math id="IM14" display="inline" overflow="scroll"><mml:mrow><mml:mi>z</mml:mi><mml:mo>∈</mml:mo><mml:mi mathvariant="double-struck">Z</mml:mi></mml:mrow></mml:math></inline-formula>. Given <italic toggle="yes">z<sup>a</sup></italic> as anchor vector in embedding space, we select <italic toggle="yes">z<sup>p</sup></italic> such that <inline-formula id="IE15"><mml:math id="IM15" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="italic">argma</mml:mi><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mi>p</mml:mi></mml:msup></mml:mrow></mml:msub><mml:mo>{</mml:mo><mml:mi>d</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mi>a</mml:mi></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mi>p</mml:mi></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>}</mml:mo><mml:mo>,</mml:mo><mml:mi mathvariant="italic">label</mml:mi><mml:mo>{</mml:mo><mml:msup><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mi>a</mml:mi></mml:msup><mml:mo>}</mml:mo><mml:mo>=</mml:mo><mml:mi mathvariant="italic">label</mml:mi><mml:mo>{</mml:mo><mml:msup><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mi>p</mml:mi></mml:msup><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula>, which is named hard positive. The intuition of hard positive is to find a vector furthest from the anchor within same cluster. Similarly, we have <italic toggle="yes">z<sup>n</sup></italic> as hard negative such that <inline-formula id="IE16"><mml:math id="IM16" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="italic">argmi</mml:mi><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msup></mml:mrow></mml:msub><mml:mo>{</mml:mo><mml:mi>d</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mi>a</mml:mi></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>}</mml:mo><mml:mo>,</mml:mo><mml:mi mathvariant="italic">label</mml:mi><mml:mo>{</mml:mo><mml:msup><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mi>a</mml:mi></mml:msup><mml:mo>}</mml:mo><mml:mo>≠</mml:mo><mml:mi mathvariant="italic">label</mml:mi><mml:mo>{</mml:mo><mml:msup><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msup><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula>. <italic toggle="yes">z<sup>n</sup></italic> is defined as the closest vector from a different cluster. The objective immediately follows,
</p>
      <disp-formula id="E6">
        <label>(6)</label>
        <mml:math id="M6" display="block" overflow="scroll">
          <mml:mrow>
            <mml:mi>d</mml:mi>
            <mml:mo stretchy="false">(</mml:mo>
            <mml:msup>
              <mml:mrow>
                <mml:mi>z</mml:mi>
              </mml:mrow>
              <mml:mi>a</mml:mi>
            </mml:msup>
            <mml:mo>,</mml:mo>
            <mml:msup>
              <mml:mrow>
                <mml:mi>z</mml:mi>
              </mml:mrow>
              <mml:mi>p</mml:mi>
            </mml:msup>
            <mml:mo stretchy="false">)</mml:mo>
            <mml:mo>+</mml:mo>
            <mml:mo>α</mml:mo>
            <mml:mo>&lt;</mml:mo>
            <mml:mi>d</mml:mi>
            <mml:mo stretchy="false">(</mml:mo>
            <mml:msup>
              <mml:mrow>
                <mml:mi>z</mml:mi>
              </mml:mrow>
              <mml:mi>a</mml:mi>
            </mml:msup>
            <mml:mo>,</mml:mo>
            <mml:msup>
              <mml:mrow>
                <mml:mi>z</mml:mi>
              </mml:mrow>
              <mml:mi>n</mml:mi>
            </mml:msup>
            <mml:mo stretchy="false">)</mml:mo>
            <mml:mo>,</mml:mo>
            <mml:mo>∀</mml:mo>
            <mml:mo stretchy="false">(</mml:mo>
            <mml:msup>
              <mml:mrow>
                <mml:mi>z</mml:mi>
              </mml:mrow>
              <mml:mi>a</mml:mi>
            </mml:msup>
            <mml:mo>,</mml:mo>
            <mml:msup>
              <mml:mrow>
                <mml:mi>z</mml:mi>
              </mml:mrow>
              <mml:mi>p</mml:mi>
            </mml:msup>
            <mml:mo>,</mml:mo>
            <mml:msup>
              <mml:mrow>
                <mml:mi>z</mml:mi>
              </mml:mrow>
              <mml:mi>n</mml:mi>
            </mml:msup>
            <mml:mo stretchy="false">)</mml:mo>
            <mml:mo>∈</mml:mo>
            <mml:mi mathvariant="double-struck">Z</mml:mi>
            <mml:mo>.</mml:mo>
          </mml:mrow>
        </mml:math>
      </disp-formula>
      <p>Above, <italic toggle="yes">α</italic> is the margin defined accordingly by us. Thus, by the contrastive loss, we tend to optimize,
</p>
      <disp-formula id="E7">
        <label>(7)</label>
        <mml:math id="M7" display="block" overflow="scroll">
          <mml:mrow>
            <mml:mtable>
              <mml:mtr columnalign="left">
                <mml:mtd columnalign="left">
                  <mml:mrow>
                    <mml:msub>
                      <mml:mrow>
                        <mml:mi>L</mml:mi>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mi mathvariant="italic">con</mml:mi>
                      </mml:mrow>
                    </mml:msub>
                  </mml:mrow>
                </mml:mtd>
                <mml:mtd columnalign="left">
                  <mml:mrow>
                    <mml:mo>=</mml:mo>
                    <mml:msub>
                      <mml:mrow>
                        <mml:mi mathvariant="double-struck">E</mml:mi>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:msup>
                          <mml:mrow>
                            <mml:mi>z</mml:mi>
                          </mml:mrow>
                          <mml:mi>a</mml:mi>
                        </mml:msup>
                        <mml:mo>∼</mml:mo>
                        <mml:mi>Z</mml:mi>
                      </mml:mrow>
                    </mml:msub>
                    <mml:mo stretchy="false">[</mml:mo>
                    <mml:mi>d</mml:mi>
                    <mml:mo stretchy="false">(</mml:mo>
                    <mml:msup>
                      <mml:mrow>
                        <mml:mi>z</mml:mi>
                      </mml:mrow>
                      <mml:mi>a</mml:mi>
                    </mml:msup>
                    <mml:mo>,</mml:mo>
                    <mml:msup>
                      <mml:mrow>
                        <mml:mi>z</mml:mi>
                      </mml:mrow>
                      <mml:mi>p</mml:mi>
                    </mml:msup>
                    <mml:mo stretchy="false">)</mml:mo>
                    <mml:mo>−</mml:mo>
                    <mml:mi>d</mml:mi>
                    <mml:mo stretchy="false">(</mml:mo>
                    <mml:msup>
                      <mml:mrow>
                        <mml:mi>z</mml:mi>
                      </mml:mrow>
                      <mml:mi>a</mml:mi>
                    </mml:msup>
                    <mml:mo>,</mml:mo>
                    <mml:msup>
                      <mml:mrow>
                        <mml:mi>z</mml:mi>
                      </mml:mrow>
                      <mml:mi>n</mml:mi>
                    </mml:msup>
                    <mml:mo stretchy="false">)</mml:mo>
                    <mml:mo>+</mml:mo>
                    <mml:mo>α</mml:mo>
                    <mml:mo stretchy="false">]</mml:mo>
                    <mml:mo>.</mml:mo>
                  </mml:mrow>
                </mml:mtd>
              </mml:mtr>
              <mml:mtr columnalign="left">
                <mml:mtd columnalign="left">
                  <mml:mrow>
                    <mml:msub>
                      <mml:mrow>
                        <mml:mi>L</mml:mi>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mi mathvariant="italic">con</mml:mi>
                      </mml:mrow>
                    </mml:msub>
                  </mml:mrow>
                </mml:mtd>
                <mml:mtd columnalign="left">
                  <mml:mrow>
                    <mml:mo>=</mml:mo>
                    <mml:msub>
                      <mml:mrow>
                        <mml:mi mathvariant="double-struck">E</mml:mi>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mi>x</mml:mi>
                        <mml:mo>∼</mml:mo>
                        <mml:mo>{</mml:mo>
                        <mml:mi mathvariant="italic">RNA</mml:mi>
                        <mml:mo>}</mml:mo>
                      </mml:mrow>
                    </mml:msub>
                    <mml:mo stretchy="false">[</mml:mo>
                    <mml:mi>d</mml:mi>
                    <mml:mo stretchy="false">(</mml:mo>
                    <mml:msub>
                      <mml:mrow>
                        <mml:mi>E</mml:mi>
                      </mml:mrow>
                      <mml:mi>j</mml:mi>
                    </mml:msub>
                    <mml:mo stretchy="false">(</mml:mo>
                    <mml:mi>x</mml:mi>
                    <mml:mo stretchy="false">)</mml:mo>
                    <mml:mo>,</mml:mo>
                    <mml:msup>
                      <mml:mrow>
                        <mml:mi>z</mml:mi>
                      </mml:mrow>
                      <mml:mi>p</mml:mi>
                    </mml:msup>
                    <mml:mo stretchy="false">)</mml:mo>
                    <mml:mo>−</mml:mo>
                    <mml:mi>d</mml:mi>
                    <mml:mo stretchy="false">(</mml:mo>
                    <mml:msub>
                      <mml:mrow>
                        <mml:mi>E</mml:mi>
                      </mml:mrow>
                      <mml:mi>j</mml:mi>
                    </mml:msub>
                    <mml:mo stretchy="false">(</mml:mo>
                    <mml:mi>x</mml:mi>
                    <mml:mo stretchy="false">)</mml:mo>
                    <mml:mo>,</mml:mo>
                    <mml:msup>
                      <mml:mrow>
                        <mml:mi>z</mml:mi>
                      </mml:mrow>
                      <mml:mi>n</mml:mi>
                    </mml:msup>
                    <mml:mo stretchy="false">)</mml:mo>
                    <mml:mo>+</mml:mo>
                    <mml:mo>α</mml:mo>
                    <mml:mo stretchy="false">]</mml:mo>
                  </mml:mrow>
                </mml:mtd>
              </mml:mtr>
              <mml:mtr columnalign="left">
                <mml:mtd columnalign="left"/>
                <mml:mtd columnalign="left">
                  <mml:mo>+</mml:mo>
                  <mml:mo> </mml:mo>
                  <mml:mrow>
                    <mml:msub>
                      <mml:mrow>
                        <mml:mi>E</mml:mi>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mi>x</mml:mi>
                        <mml:mo>∼</mml:mo>
                        <mml:mo>{</mml:mo>
                        <mml:mi mathvariant="italic">ATAC</mml:mi>
                        <mml:mo>}</mml:mo>
                      </mml:mrow>
                    </mml:msub>
                    <mml:mo stretchy="false">[</mml:mo>
                    <mml:mi>d</mml:mi>
                    <mml:mo stretchy="false">(</mml:mo>
                    <mml:msub>
                      <mml:mrow>
                        <mml:mi>E</mml:mi>
                      </mml:mrow>
                      <mml:mi>i</mml:mi>
                    </mml:msub>
                    <mml:mo stretchy="false">(</mml:mo>
                    <mml:mi>x</mml:mi>
                    <mml:mo stretchy="false">)</mml:mo>
                    <mml:mo>,</mml:mo>
                    <mml:msup>
                      <mml:mrow>
                        <mml:mi>z</mml:mi>
                      </mml:mrow>
                      <mml:mi>p</mml:mi>
                    </mml:msup>
                    <mml:mo stretchy="false">)</mml:mo>
                    <mml:mo>−</mml:mo>
                    <mml:mi>d</mml:mi>
                    <mml:mo stretchy="false">(</mml:mo>
                    <mml:msub>
                      <mml:mrow>
                        <mml:mi>E</mml:mi>
                      </mml:mrow>
                      <mml:mi>i</mml:mi>
                    </mml:msub>
                    <mml:mo stretchy="false">(</mml:mo>
                    <mml:mi>x</mml:mi>
                    <mml:mo stretchy="false">)</mml:mo>
                    <mml:mo>,</mml:mo>
                    <mml:msup>
                      <mml:mrow>
                        <mml:mi>z</mml:mi>
                      </mml:mrow>
                      <mml:mi>n</mml:mi>
                    </mml:msup>
                    <mml:mo stretchy="false">)</mml:mo>
                    <mml:mo>+</mml:mo>
                    <mml:mo>α</mml:mo>
                    <mml:mo stretchy="false">]</mml:mo>
                    <mml:mo>.</mml:mo>
                  </mml:mrow>
                </mml:mtd>
              </mml:mtr>
            </mml:mtable>
          </mml:mrow>
        </mml:math>
      </disp-formula>
      <p><xref rid="btad162-F2" ref-type="fig">Figure 2b</xref> shows that after training, instances within the same cluster are pushed towards each other, and those from the different clusters are forced away. Thus, the decision boundary of the labels tends to be smoother and more robust, which also benefits the alignment task.</p>
    </sec>
    <sec>
      <title>2.4 Simple classifier</title>
      <p>We introduce a simple classifier in the coordinated subspace to further promote the framework’s performance. This simple classifier takes both embeddings encoded from scRNA-seq and scATAC-seq as input and predicts their labels for cell types. As <xref rid="btad162-F1" ref-type="fig">Fig. 1b</xref> shows, our model forces the embeddings from the same cell type into a cluster, making it easier to match embeddings from different modalities. We employ cross-entropy loss to optimize the simple classifier at the same time as we optimize the coupled autoencoders. We adapt the classifier as <italic toggle="yes">C</italic>. The predicted result for an embedding <italic toggle="yes">z<sub>k</sub></italic> is a vector of <inline-formula id="IE17"><mml:math id="IM17" display="inline" overflow="scroll"><mml:mrow><mml:mn>1</mml:mn><mml:mo>×</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:math></inline-formula> shape. <italic toggle="yes">m</italic> is the number of cell types. Then, we have <inline-formula id="IE18"><mml:math id="IM18" display="inline" overflow="scroll"><mml:mrow><mml:mi>C</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mi>m</mml:mi></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></inline-formula> and denote <italic toggle="yes">c<sub>k</sub></italic> as the predicted probability of real cell types for <italic toggle="yes">z<sub>k</sub></italic>. We try to minimize the loss <italic toggle="yes">L</italic><sub>classifier</sub> as:
<inline-formula id="IE19"><mml:math id="IM19" display="inline" overflow="scroll"><mml:mrow><mml:mo>{</mml:mo><mml:msub><mml:mrow><mml:mi>Z</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>Z</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> is denoted as embeddings encoded from scRNA-seq and scATAC-seq.</p>
      <disp-formula id="E8">
        <label>(8)</label>
        <mml:math id="M8" display="block" overflow="scroll">
          <mml:mrow>
            <mml:msub>
              <mml:mrow>
                <mml:mi>L</mml:mi>
              </mml:mrow>
              <mml:mrow>
                <mml:mi mathvariant="italic">classifier</mml:mi>
              </mml:mrow>
            </mml:msub>
            <mml:mo>=</mml:mo>
            <mml:msub>
              <mml:mrow>
                <mml:mi mathvariant="double-struck">E</mml:mi>
              </mml:mrow>
              <mml:mrow>
                <mml:msub>
                  <mml:mrow>
                    <mml:mi>z</mml:mi>
                  </mml:mrow>
                  <mml:mi>k</mml:mi>
                </mml:msub>
                <mml:mo>∼</mml:mo>
                <mml:mo>{</mml:mo>
                <mml:msub>
                  <mml:mrow>
                    <mml:mi>Z</mml:mi>
                  </mml:mrow>
                  <mml:mi>i</mml:mi>
                </mml:msub>
                <mml:mo>,</mml:mo>
                <mml:msub>
                  <mml:mrow>
                    <mml:mi>Z</mml:mi>
                  </mml:mrow>
                  <mml:mi>j</mml:mi>
                </mml:msub>
                <mml:mo>}</mml:mo>
              </mml:mrow>
            </mml:msub>
            <mml:mo stretchy="false">[</mml:mo>
            <mml:mo>−</mml:mo>
            <mml:mi>ln</mml:mi>
            <mml:msub>
              <mml:mrow>
                <mml:mi>c</mml:mi>
              </mml:mrow>
              <mml:mi>k</mml:mi>
            </mml:msub>
            <mml:mo stretchy="false">]</mml:mo>
            <mml:mo>.</mml:mo>
          </mml:mrow>
        </mml:math>
      </disp-formula>
    </sec>
    <sec>
      <title>2.5 Training procedure</title>
      <p>In the above sections, we proposed several losses related to different objectives. Following the training procedure of Generative Adversarial Nets (<xref rid="btad162-B11" ref-type="bibr">Dai Yang et al. 2021</xref>), we adopt a two-stage training scheme where <italic toggle="yes">L</italic><sub>adv</sub> and <inline-formula id="IE20"><mml:math id="IM20" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">recon</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">cyc</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">con</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">classifier</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> are trained separately as the pseudo-code in <xref rid="btad162-BOX1" ref-type="boxed-text">Algorithm 1</xref>.<boxed-text id="btad162-BOX1" position="float"><label>Algorithm 1:</label><caption><p>Training Procedure</p></caption><p> <bold>while</bold> numbers of training iterations <bold>do</bold></p><p>  <bold>while</bold> <italic toggle="yes">k</italic><sub>1</sub> steps <bold>do</bold></p><p>   sample mini-batch <inline-formula id="IE21"><mml:math id="IM21" display="inline" overflow="scroll"><mml:mrow><mml:mo>{</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mi>m</mml:mi></mml:msub><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> from {scRNA-seq}</p><p>   sample mini-batch <inline-formula id="IE22"><mml:math id="IM22" display="inline" overflow="scroll"><mml:mrow><mml:mo>{</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mi>m</mml:mi></mml:msub><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> from {scATAC-seq}</p><p>  Search positives and negatives <italic toggle="yes">z<sup>a</sup></italic>, <italic toggle="yes">z<sup>p</sup></italic> for each <inline-formula id="IE23"><mml:math id="IM23" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mi>m</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>.</p><p>   Update <inline-formula id="IE24"><mml:math id="IM24" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> by descending its stochastic gradient <inline-formula id="IE25"><mml:math id="IM25" display="inline" overflow="scroll"><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>m</mml:mi></mml:mfrac><mml:mo>∇</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">recon</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">cyc</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">con</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">classifier</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">adv</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula></p><p>  <bold>end while</bold></p><p>  <bold>while</bold> <italic toggle="yes">k</italic><sub>2</sub> steps <bold>do</bold></p><p>   sample mini-batch <inline-formula id="IE26"><mml:math id="IM26" display="inline" overflow="scroll"><mml:mrow><mml:mo>{</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mi>m</mml:mi></mml:msub><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> from {scRNA-seq}</p><p>   sample mini-batch <inline-formula id="IE27"><mml:math id="IM27" display="inline" overflow="scroll"><mml:mrow><mml:mo>{</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mi>m</mml:mi></mml:msub><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> from {scATAC-seq}</p><p>   Update Discriminator <inline-formula id="IE28"><mml:math id="IM28" display="inline" overflow="scroll"><mml:mi mathvariant="script" class="calligraphy">D</mml:mi></mml:math></inline-formula> by descending its stochastic gradient <inline-formula id="IE29"><mml:math id="IM29" display="inline" overflow="scroll"><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>2</mml:mn><mml:mi>m</mml:mi></mml:mrow></mml:mfrac><mml:mo>∇</mml:mo><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">adv</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula></p><p>  <bold>end while</bold></p><p> <bold>end while</bold></p></boxed-text> In this way, the Discriminator <inline-formula id="IE30"><mml:math id="IM30" display="inline" overflow="scroll"><mml:mi mathvariant="script" class="calligraphy">D</mml:mi></mml:math></inline-formula> competes against the encoder–decoder <inline-formula id="IE31"><mml:math id="IM31" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> until the training ends and reaches the equilibrium.</p>
    </sec>
  </sec>
  <sec>
    <title>3 Results</title>
    <sec>
      <title>3.1 Evaluation criteria</title>
      <p>We utilize two existing manners (<xref rid="btad162-B11" ref-type="bibr">Dai Yang et al. 2021</xref>) to evaluate integration and alignment, respectively. (i) We match samples from RNA-seq to scATAC-seq in the coordinated subspace. For each embedding encoded from scATAC-seq, we calculate the Euclidean distance between it and each embedding encoded from scRNA-seq in coordinated space and find the closest pair. We regard it as a correct match if they are from the same cell type. Then, we evaluate the integration performance by the fraction of such correct matching in the test set. (ii) Like step in (i), we still calculate the distance between samples from scRNA-seq and samples from scATAC-seq in the coordinated subspace. For each embedding encoded from scATAC-seq, instead of picking the nearest encoded scRNA-seq sample, we choose the <italic toggle="yes">k</italic> closest scRNA-seq embeddings. We calculate <italic toggle="yes">k</italic>-nearest neighbours accuracy as:
where <italic toggle="yes">n</italic> is the cell numbers in test set. <italic toggle="yes">R</italic> is the set of RNA-seq samples and <italic toggle="yes">A</italic> is denoted as the set of ATAC-seq samples. We denote <italic toggle="yes">r<sub>i</sub></italic> as a sample from <italic toggle="yes">R</italic>, <italic toggle="yes">a<sub>i</sub></italic> as a sample from A. <inline-formula id="IE32"><mml:math id="IM32" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:msup><mml:mi>a</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE33"><mml:math id="IM33" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:msup><mml:mi>r</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> are the encoded versions of <italic toggle="yes">a<sub>i</sub></italic> and <italic toggle="yes">r<sub>i</sub></italic>, respectively. <inline-formula id="IE34"><mml:math id="IM34" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mi>i</mml:mi><mml:mi>k</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula> contains the <italic toggle="yes">k</italic> nearest <inline-formula id="IE35"><mml:math id="IM35" display="inline" overflow="scroll"><mml:msup><mml:mi>r</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:math></inline-formula> to <inline-formula id="IE36"><mml:math id="IM36" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:msup><mml:mi>a</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>. We denote <italic toggle="yes">k</italic> as 10, 20, 30, 40, and 50, evaluating alignment performance. We call this evaluation way <inline-formula id="IE37"><mml:math id="IM37" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="italic">recall</mml:mi><mml:mo>@</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:math></inline-formula>.</p>
      <disp-formula id="E9">
        <label>(9)</label>
        <mml:math id="M9" display="block" overflow="scroll">
          <mml:mrow>
            <mml:mi mathvariant="italic">kNN</mml:mi>
            <mml:mo stretchy="false">(</mml:mo>
            <mml:mi>A</mml:mi>
            <mml:mo>,</mml:mo>
            <mml:mi>R</mml:mi>
            <mml:mo stretchy="false">)</mml:mo>
            <mml:mo>=</mml:mo>
            <mml:mfrac>
              <mml:mrow>
                <mml:munder>
                  <mml:mo>∑</mml:mo>
                  <mml:mi>i</mml:mi>
                </mml:munder>
                <mml:mn>1</mml:mn>
                <mml:mrow>
                  <mml:mo>(</mml:mo>
                  <mml:mrow>
                    <mml:msub>
                      <mml:mrow>
                        <mml:msup>
                          <mml:mi>a</mml:mi>
                          <mml:mo>′</mml:mo>
                        </mml:msup>
                      </mml:mrow>
                      <mml:mi>i</mml:mi>
                    </mml:msub>
                    <mml:mo>∈</mml:mo>
                    <mml:msubsup>
                      <mml:mrow>
                        <mml:mi>r</mml:mi>
                      </mml:mrow>
                      <mml:mi>i</mml:mi>
                      <mml:mi>k</mml:mi>
                    </mml:msubsup>
                  </mml:mrow>
                  <mml:mo>)</mml:mo>
                </mml:mrow>
              </mml:mrow>
              <mml:mi>n</mml:mi>
            </mml:mfrac>
            <mml:mo>,</mml:mo>
          </mml:mrow>
        </mml:math>
      </disp-formula>
    </sec>
    <sec>
      <title>3.2 Compared with SOTA</title>
      <p>Instead of assuming all datasets share the same underlying structure or specifying parts of hyperparameters like some traditional machine-learning methods (<xref rid="btad162-B31" ref-type="bibr">Welch et al. 2017</xref>; <xref rid="btad162-B28" ref-type="bibr">Stuart et al. 2019</xref>; <xref rid="btad162-B8" ref-type="bibr">Cao et al. 2020</xref>; <xref rid="btad162-B12" ref-type="bibr">Demetci et al. 2022</xref>; <xref rid="btad162-B26" ref-type="bibr">Singh et al. 2020</xref>; <xref rid="btad162-B9" ref-type="bibr">Cao et al. 2022</xref>), we obtain more information from datasets with partial correspondence information (batch label or cell types label). We select several state-of-art methods based on deep learning like ours, including Cross-Modal (<xref rid="btad162-B11" ref-type="bibr">Dai Yang et al. 2021</xref>), Cross-Modal-anchor (pairwise information added), DCCA (<xref rid="btad162-B1" ref-type="bibr">Andrew et al. 2013</xref>), CycleGAN (<xref rid="btad162-B34" ref-type="bibr">Zhu et al. 2017</xref>), and scJoint (<xref rid="btad162-B20" ref-type="bibr">Lin et al. 2022</xref>). Moreover, we also compare our method with machine-learning methods for integration, including MOFA+ (<xref rid="btad162-B3" ref-type="bibr">Argelaguet et al. 2020</xref>), Seurat (<xref rid="btad162-B28" ref-type="bibr">Stuart et al. 2019</xref>), Pamona (<xref rid="btad162-B9" ref-type="bibr">Cao et al. 2022</xref>), MMD-MA (<xref rid="btad162-B26" ref-type="bibr">Singh et al. 2020</xref>), UnionCom (<xref rid="btad162-B8" ref-type="bibr">Cao et al. 2020</xref>), and SCOT (<xref rid="btad162-B12" ref-type="bibr">Demetci et al. 2022</xref>). For Seurat (<xref rid="btad162-B28" ref-type="bibr">Stuart et al. 2019</xref>), we convert scATAC-seq data to predicted gene count matrix by Cicero (<xref rid="btad162-B24" ref-type="bibr">Pliner et al. 2018</xref>) then integrate them. We apply Con-AAE and these methods on simulated and real-world datasets.</p>
      <p>We generate 24 sets of different sizes and SNRs. The generating process can be found in Supplementary Section B. The simulated datasets contain data of four different sizes, 1200, 2100, 3000, and 6000, each of which has six versions of SNR, 0, 5, 10, 15, 20, and 25, respectively. We implement all methods on the simulated datasets. The results in <xref rid="btad162-F3" ref-type="fig">Fig. 3</xref> show that Con-AAE’s performance is stable and has the best performance in most cases regardless of data size and SNR, demonstrating our method’s robustness and scalability. We also calculate the alignment performance on the simulated datasets. We set <italic toggle="yes">k</italic>=10, 20, 30, 40, and 50, so there are 120(5 × 24) results for each method. <xref rid="btad162-F4" ref-type="fig">Figure 4</xref> shows the performance of all results in box plots. We can see that the upper edge, lower edge, median, and upper and lower quartiles of Con-AAE are higher in most cases than other tools. Our method’s performance is almost consistent against different data sizes and noise levels. In contrast, the other methods may perform well in some settings but poorly in others. The results indicate that Con-AAE is robust and stable enough to have the potential to handle the complicated single-cell multi-omics alignment and integration problems with a low SNR ratio.</p>
      <fig position="float" id="btad162-F3">
        <label>Figure 3.</label>
        <caption>
          <p>The figure shows the integration performance on 24 simulated datasets with various data sizes and SNR. The horizontal axis represents the SNR, and the vertical axis represents the percentage of correct integration. The Con-AAE outperforms other methods in most cases. As the SNR ratio decreases and the size of the dataset grows, the performance of all the methods degrades significantly. However, Con-AAE still has excellent performance, demonstrating its scalability and robustness</p>
        </caption>
        <graphic xlink:href="btad162f3" position="float"/>
      </fig>
      <fig position="float" id="btad162-F4">
        <label>Figure 4.</label>
        <caption>
          <p>The box plot shows the alignment performance on 24 simulated datasets with various data sizes and SNR. In most cases, Con-AAE has almost the highest upper edge, lower edge, median, and upper and lower quartiles, which indicates that the overall performance distribution of Con-AAE is higher than that of other methods</p>
        </caption>
        <graphic xlink:href="btad162f4" position="float"/>
      </fig>
      <p>We care about the methods’ performance on the real-world datasets the most, although the real-world datasets with ground-truth information are limited. Still, Con-AAE shows superior performance. On the sci-CAR dataset, Con-AAE outperforms the other methods by up to 36.2% on the integration task, as shown in the upper part of <xref rid="btad162-F5" ref-type="fig">Fig. 5</xref>. For alignment, Con-AAE always has better performance than all the other methods no matter what <italic toggle="yes">k</italic> is (the bottom part of <xref rid="btad162-F5" ref-type="fig">Fig. 5</xref>). On the SNARE-seq dataset, more obviously, Con-AAE also has dominant performance on each evaluation metric. The improvement on the integration task is up to 53.1% (<xref rid="btad162-F5" ref-type="fig">Fig. 5</xref>). On the other hand, the performance on <inline-formula id="IE38"><mml:math id="IM38" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="italic">recall</mml:mi><mml:mo>@</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:math></inline-formula> is better than others no matter what <italic toggle="yes">k</italic> is (<xref rid="btad162-F5" ref-type="fig">Fig. 5</xref>). We also conduct all methods on more complex cases, more than 9000 cells of 19 cell types from 10X PBMC, which can be downloaded at <ext-link xlink:href="https://support.10xgenomics.com/single-cell-multiome-atac-gex/datasets/1.0.0/pbmc_granulocyte_sorted_10k" ext-link-type="uri">https://support.10xgenomics.com/single-cell-multiome-atac-gex/datasets/1.0.0/pbmc_granulocyte_sorted_10k</ext-link>, and 34 774 cells of 23 cell types from SHARE-seq (<xref rid="btad162-B21" ref-type="bibr">Ma et al. 2020</xref>). Our results in <xref rid="btad162-F5" ref-type="fig">Fig. 5</xref> indicate that Con-AAE still performs excellently in more complex situations while most other tools get poorer performance. Due to insufficient memory processing technology, several tools cannot deal with large datasets like SHARE-seq. Again, Con-AAE is consistently better than the other competing methods.</p>
      <fig position="float" id="btad162-F5">
        <label>Figure 5.</label>
        <caption>
          <p>Con-AAE compares with SOTA methods on the four real-world datasets. The upside is the integration performance, and the downside is alignment performance. The horizontal axis of the upside and the vertical axis of the downside are percentages. Con-AAE has the best performance on both criteria. Note that the identification of cell pairwise correspondences between single cells is termed “anchor” (<xref rid="btad162-B28" ref-type="bibr">Stuart et al. 2019</xref>). Cross-Modal-anchor indicates that “anchor” information is provided when training Cross-Modal</p>
        </caption>
        <graphic xlink:href="btad162f5" position="float"/>
      </fig>
    </sec>
    <sec>
      <title>3.3 Ablation studies</title>
      <p>We perform comprehensive ablation studies on the sci-CAR dataset, and the results show the effectiveness of different components.</p>
      <p>There are three parts in (<xref rid="sup1" ref-type="supplementary-material">Supplementary Table S6</xref>). The first part indicates there is no adversarial loss in embedding space. The second part indicates an MMD loss (<xref rid="btad162-B5" ref-type="bibr">Bińkowski et al. 2018</xref>) instead of an adversarial loss. And the last part indicates whether there is an adversarial loss in the embedding space. Most items in the third part are better than the corresponding items in the other two parts, demonstrating that the adversarial loss works better than MMD loss on this problem.</p>
      <p>Five items represent different combination of loss functions in each part of (<xref rid="sup1" ref-type="supplementary-material">Supplementary Table S6</xref>). The first row represents the basic framework, consisting of two coupled autoencoders and a simple one-layer classifier. The anchor one means pairwise information provided, which indicates that it is a supervised learning model instead of an unsupervised one. “cyc” and “contra” denote cycle-consistency loss and contrastive loss, respectively. As shown in the table, adding “cyc” and “contra” improves the model. Apparently, Con-AAE has the best performance. Cycle-consistency loss and contrastive loss alone can improve the performance to some degree, but Con-AEE is more robust and has better scalability.</p>
      <p>Impressively, Con-AAE has better performance even compared to some supervised methods with the pairwise information provided. Within <xref rid="sup1" ref-type="supplementary-material">Supplementary Table S6</xref>, we compare our approach with methods fed pairwise information. We train them using the pairwise information as the supervision for such methods. For Con-AAE, we still perform unsupervised learning using cycle-consistency loss and contrastive loss. Even without the supervised information, Con-AAE can still outperform the basic supervised anchor methods consistently on both tasks. It suggests that cycle-consistency loss and contrastive loss can force our model to learn a coordinated subspace for the two kinds of single-cell omics data, making the alignment and integration much easier. We also try to combine Con-AAE with the pairwise information. The supervised information can help our method further, but the degree is very slight (<xref rid="sup1" ref-type="supplementary-material">Supplementary Table S9</xref>). We suppose that in the real data, the pairwise information may contain noise, which is common in the single-cell field. Because of the contrastive loss, which makes Con-AAE a robust method, such weak supervision does not help our model too much.</p>
    </sec>
    <sec>
      <title>3.4 Visualization</title>
      <p>To further demonstrate our model’s performance and make integration the effect more intuitive, we transfer the label from scRNA-seq to scATAC when integrating them. Firstly, we encode scRNA-seq and scATAC-seq into a low-dimensional coordinated subspace with Con-AAE. Assuming the labels of scRNA-seq are known, for each embedding encoded from scATAC-seq, we assign it with the label by the nearest (calculated with Euclidean) scRNA-seq embedding. We conduct the transferring process on four real-world datasets test set with the help of Con-AAE and visualize embeddings by t-SNE (<xref rid="btad162-B29" ref-type="bibr">Van der Maaten and Hinton 2008</xref>). We can see that the transferred labels are almost consistent with real labels in <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S1</xref>, which visually demonstrates the good integration by Con-AAE. In addition, the excellent clustering effect also reflects the power of contrastive learning. We also conduct the same process with other tools, as <xref rid="sup1" ref-type="supplementary-material">Supplementary Figs S2–S10</xref> show. Most tools perform poorly on large datasets with more than 10 or even 20 cell types, while Con-AAE still performs well on complex datasets benefitting from the power of contrastive learning.</p>
    </sec>
  </sec>
  <sec>
    <title>4 Discussion</title>
    <p>In this article, we propose a novel framework, Con-AAE, aiming at integrating and aligning the multi-omics data at the single-cell level. On the one hand, our proposed method can map different modalities into a coordinated subspace with the help of an adversarial loss and a novel cycle-consistency loss. On the other hand, we apply a novel self-supervised contrastive loss in the embedding space to improve the robustness and scalability of the entire framework. Comprehensive experimental results on the simulated and real datasets show that the proposed framework can outperform the other state-of-the-art methods for both alignment and integration tasks. Detailed ablation studies also dissect and demonstrate the effectiveness of each component in the framework. Our method will be helpful for both the single-cell multi-omics research and the general multi-modality learning tasks in computational biology.</p>
    <p>For future work, we aim to extend our work from a two-domain task to a multiple-domain study, allowing it to integrate and align multiple omics. Besides integration and alignment between sequence modalities, we intend to perform our method on different kinds of biological data, including but not limited to images, geometrical spatial structure, etc. Obviously, it is exciting to investigate the spatial transcriptomics data. We will also develop methods for translating modalities. By doing so, we hope to build a system that could benefit various downstream analyses in single-cell multi-omics and spatial multi-omics.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material id="sup1" position="float" content-type="local-data">
      <label>btad162_Supplementary_Data</label>
      <media xlink:href="btad162_supplementary_data.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <sec>
    <title>Supplementary data</title>
    <p><xref rid="sup1" ref-type="supplementary-material">Supplementary data</xref> is available at <italic toggle="yes">Bioinformatics</italic> online.</p>
    <p>Conflict of interest: None declared.</p>
  </sec>
  <sec>
    <title>Funding</title>
    <p>This work was supported by Chinese University of Hong Kong (CUHK) [award numbers 4937025, 4937026, 5501517, 5501329].</p>
  </sec>
  <sec sec-type="data-availability">
    <title>Data availability</title>
    <p>All processed data except SHARE-seq can be found at: <ext-link xlink:href="https://github.com/kakarotcq/Con-AAE/tree/main/data" ext-link-type="uri">https://github.com/kakarotcq/Con-AAE/tree/main/data</ext-link>. SHARE-seq data can be found through GSE140203 on NCBI.</p>
  </sec>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="btad162-B1">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Andrew</surname><given-names>G</given-names></string-name>, <string-name><surname>Arora</surname><given-names>R.</given-names></string-name>, <string-name><surname>Bilmes</surname><given-names>J.</given-names></string-name></person-group><etal>et al</etal> Deep canonical correlation analysis. In: <italic toggle="yes">International Conference on Machine Learning</italic>. <fpage>1247</fpage>–<lpage>55</lpage>. PMLR, <year>2013</year>.</mixed-citation>
    </ref>
    <ref id="btad162-B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Argelaguet</surname><given-names>R</given-names></string-name>, <string-name><surname>Velten</surname><given-names>B</given-names></string-name>, <string-name><surname>Arnol</surname><given-names>D</given-names></string-name></person-group><etal>et al</etal><article-title>Multi-omics factor analysis—a framework for unsupervised integration of multi-omics data sets</article-title>. <source>Mol Syst Biol</source><year>2018</year>;<volume>14</volume>:<fpage>e8124</fpage>.<pub-id pub-id-type="pmid">29925568</pub-id></mixed-citation>
    </ref>
    <ref id="btad162-B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Argelaguet</surname><given-names>R</given-names></string-name>, <string-name><surname>Arnol</surname><given-names>D</given-names></string-name>, <string-name><surname>Bredikhin</surname><given-names>D</given-names></string-name></person-group><etal>et al</etal><article-title>MOFA+: a statistical framework for comprehensive integration of multi-modal single-cell data</article-title>. <source>Genome Biol</source><year>2020</year>;<volume>21</volume>:<fpage>1</fpage>–<lpage>17</lpage>.</mixed-citation>
    </ref>
    <ref id="btad162-B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bersanelli</surname><given-names>M</given-names></string-name>, <string-name><surname>Mosca</surname><given-names>E</given-names></string-name>, <string-name><surname>Remondini</surname><given-names>D</given-names></string-name></person-group><etal>et al</etal><article-title>Methods for the integration of multi-omics data: mathematical aspects</article-title>. <source>BMC Bioinformatics</source><year>2016</year>;<volume>17</volume>:<fpage>167</fpage>–<lpage>77</lpage>.<pub-id pub-id-type="pmid">27091357</pub-id></mixed-citation>
    </ref>
    <ref id="btad162-B5">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Bińkowski</surname><given-names>M</given-names></string-name></person-group><etal>et al</etal> Demystifying MMD GANs. In: <italic toggle="yes">International Conference on Learning Representations</italic> <year>2018</year>.</mixed-citation>
    </ref>
    <ref id="btad162-B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Borgwardt</surname><given-names>KM</given-names></string-name>, <string-name><surname>Gretton</surname><given-names>A</given-names></string-name>, <string-name><surname>Rasch</surname><given-names>MJ</given-names></string-name></person-group><etal>et al</etal><article-title>Integrating structured biological data by kernel maximum mean discrepancy</article-title>. <source>Bioinformatics</source><year>2006</year>;<volume>22</volume>:<fpage>e49</fpage>–<lpage>57</lpage>.<pub-id pub-id-type="pmid">16873512</pub-id></mixed-citation>
    </ref>
    <ref id="btad162-B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cao</surname><given-names>J</given-names></string-name>, <string-name><surname>Cusanovich</surname><given-names>DA</given-names></string-name>, <string-name><surname>Ramani</surname><given-names>V</given-names></string-name></person-group><etal>et al</etal><article-title>Joint profiling of chromatin accessibility and gene expression in thousands of single cells</article-title>. <source>Science</source><year>2018</year>;<volume>361</volume>:<fpage>1380</fpage>–<lpage>5</lpage>.<pub-id pub-id-type="pmid">30166440</pub-id></mixed-citation>
    </ref>
    <ref id="btad162-B8">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cao</surname><given-names>K</given-names></string-name>, <string-name><surname>Bai</surname><given-names>X</given-names></string-name>, <string-name><surname>Hong</surname><given-names>Y</given-names></string-name></person-group><etal>et al</etal><article-title>Unsupervised topological alignment for single-cell multi-omics integration</article-title>. <source>Bioinformatics</source><year>2020</year>;<volume>36</volume>:<fpage>i48</fpage>–<lpage>56</lpage>.<pub-id pub-id-type="pmid">32657382</pub-id></mixed-citation>
    </ref>
    <ref id="btad162-B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cao</surname><given-names>K</given-names></string-name>, <string-name><surname>Hong</surname><given-names>Y</given-names></string-name>, <string-name><surname>Wan</surname><given-names>L</given-names></string-name></person-group><etal>et al</etal><article-title>Manifold alignment for heterogeneous single-cell multi-omics data integration using Pamona</article-title>. <source>Bioinformatics</source><year>2022</year>;<volume>38</volume>:<fpage>211</fpage>–<lpage>9</lpage>.</mixed-citation>
    </ref>
    <ref id="btad162-B10">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Choi</surname><given-names>Y</given-names></string-name>, <string-name><surname>Choi</surname><given-names>M</given-names></string-name>, <string-name><surname>Kim</surname><given-names>M</given-names></string-name></person-group><etal>et al</etal> StarGAN: unified generative adversarial networks for multi-domain image-to-image translation. In: <italic toggle="yes">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</italic>. <fpage>8789</fpage>–<lpage>97</lpage>. <year>2018</year>.</mixed-citation>
    </ref>
    <ref id="btad162-B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dai Yang</surname><given-names>K</given-names></string-name>, <string-name><surname>Belyaeva</surname><given-names>A</given-names></string-name>, <string-name><surname>Venkatachalapathy</surname><given-names>S</given-names></string-name></person-group><etal>et al</etal><article-title>Multi-domain translation between single-cell imaging and sequencing data using autoencoders</article-title>. <source>Nat Commun</source><year>2021</year>;<volume>12</volume>:<fpage>1</fpage>–<lpage>10</lpage>.<pub-id pub-id-type="pmid">33397941</pub-id></mixed-citation>
    </ref>
    <ref id="btad162-B12">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Demetci</surname><given-names>P</given-names></string-name></person-group><etal>et al</etal> Scot: Single-cell multi-omics alignment with optimal transport. <italic toggle="yes">J Computat Biol</italic> 2022;<volume>29</volume>(<issue>1</issue>):<fpage>3</fpage>–<lpage>1</lpage>.</mixed-citation>
    </ref>
    <ref id="btad162-B13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gala</surname><given-names>R</given-names></string-name>, <string-name><surname>Budzillo</surname><given-names>A</given-names></string-name>, <string-name><surname>Baftizadeh</surname><given-names>F</given-names></string-name></person-group><etal>et al</etal><article-title>Consistent cross-modal identification of cortical neurons with coupled autoencoders</article-title>. <source>Nat Comput Sci</source><year>2021</year>;<volume>1</volume>:<fpage>120</fpage>–<lpage>7</lpage>.<pub-id pub-id-type="pmid">35356158</pub-id></mixed-citation>
    </ref>
    <ref id="btad162-B14">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Guo</surname><given-names>W</given-names></string-name>, <string-name><surname>Wang</surname><given-names>J</given-names></string-name>, <string-name><surname>Wang</surname><given-names>S</given-names></string-name></person-group><etal>et al</etal><article-title>Deep multimodal representation learning: a survey</article-title>. <source>IEEE Access</source><year>2019</year>;<volume>7</volume>:<fpage>63373</fpage>–<lpage>94</lpage>.</mixed-citation>
    </ref>
    <ref id="btad162-B15">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Han</surname><given-names>W</given-names></string-name>, <string-name><surname>Cheng</surname><given-names>Y</given-names></string-name>, <string-name><surname>Chen</surname><given-names>J</given-names></string-name></person-group><etal>et al</etal><article-title>Self-supervised contrastive learning for integrative single cell RNA-seq data analysis</article-title>. <source>Brief Bioinform</source><year>2022</year>;<volume>23</volume>:<fpage>bbac377</fpage>.<pub-id pub-id-type="pmid">36089561</pub-id></mixed-citation>
    </ref>
    <ref id="btad162-B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hira</surname><given-names>MT</given-names></string-name></person-group><etal>et al</etal><article-title>Integrated multi-omics analysis of ovarian cancer using variational autoencoders</article-title>. <source>Sci Rep</source><year>2021</year>;<volume>11</volume>:<fpage>1</fpage>–<lpage>16</lpage>.<pub-id pub-id-type="pmid">33414495</pub-id></mixed-citation>
    </ref>
    <ref id="btad162-B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hu</surname><given-names>Z</given-names></string-name>, <string-name><surname>Wang</surname><given-names>JTL.</given-names></string-name></person-group><italic toggle="yes">Generative Adversarial Networks for Video Prediction with Action Control</italic>. In: Seghrouchni AEF, Sarne D (eds), Artificial Intelligence. IJCAI 2019 International Workshops - Macao, China, August 10-12, 2019, Revised Selected Best Papers, Lecture Notes in Computer Science, Vol. <volume>12158</volume>, Springer, <year>2019</year>, <fpage>87</fpage>–<lpage>105</lpage>.</mixed-citation>
    </ref>
    <ref id="btad162-B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Li</surname><given-names>H</given-names></string-name>, <string-name><surname>Tian</surname><given-names>S</given-names></string-name>, <string-name><surname>Li</surname><given-names>Y</given-names></string-name></person-group><etal>et al</etal><article-title>Modern deep learning in bioinformatics</article-title>. <source>J Mol Cell Biol</source><year>2020</year>;<volume>12</volume>:<fpage>823</fpage>–<lpage>7</lpage>.<pub-id pub-id-type="pmid">32573721</pub-id></mixed-citation>
    </ref>
    <ref id="btad162-B19">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Li</surname><given-names>Y</given-names></string-name>, <string-name><surname>Huang</surname><given-names>C</given-names></string-name>, <string-name><surname>Ding</surname><given-names>L</given-names></string-name></person-group><etal>et al</etal><article-title>Deep learning in bioinformatics: introduction, application, and perspective in the big data era</article-title>. <source>Methods</source><year>2019</year>;<volume>166</volume>:<fpage>4</fpage>–<lpage>21</lpage>.<pub-id pub-id-type="pmid">31022451</pub-id></mixed-citation>
    </ref>
    <ref id="btad162-B20">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lin</surname><given-names>Y</given-names></string-name>, <string-name><surname>Wu</surname><given-names>T-Y</given-names></string-name>, <string-name><surname>Wan</surname><given-names>S</given-names></string-name></person-group><etal>et al</etal><article-title>ScJoint integrates atlas-scale single-cell RNA-seq and ATAC-seq data with transfer learning</article-title>. <source>Nat Biotechnol</source><year>2022</year>;<volume>40</volume>:<fpage>703</fpage>–<lpage>10</lpage>.<pub-id pub-id-type="pmid">35058621</pub-id></mixed-citation>
    </ref>
    <ref id="btad162-B21">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ma</surname><given-names>S</given-names></string-name>, <string-name><surname>Zhang</surname><given-names>B</given-names></string-name>, <string-name><surname>LaFave</surname><given-names>LM</given-names></string-name></person-group><etal>et al</etal><article-title>Chromatin potential identified by shared single-cell profiling of RNA and chromatin</article-title>. <source>Cell</source><year>2020</year>;<volume>183</volume>:<fpage>1103</fpage>–<lpage>16.e20</lpage>.<pub-id pub-id-type="pmid">33098772</pub-id></mixed-citation>
    </ref>
    <ref id="btad162-B22">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ma</surname><given-names>T</given-names></string-name>, <string-name><surname>Zhang</surname><given-names>A.</given-names></string-name></person-group><article-title>Integrate multi-omics data with biological interaction networks using Multi-view Factorization AutoEncoder (MAE)</article-title>. <source>BMC Genomics</source><year>2019</year>;<volume>20</volume>:<fpage>1</fpage>–<lpage>11</lpage>.<pub-id pub-id-type="pmid">30606130</pub-id></mixed-citation>
    </ref>
    <ref id="btad162-B23">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Makhzani</surname><given-names>A</given-names></string-name></person-group><etal>et al</etal> Adversarial autoencoders. In: <italic toggle="yes">International Conference on Learning Representations</italic><year>2016</year>.</mixed-citation>
    </ref>
    <ref id="btad162-B24">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pliner</surname><given-names>HA</given-names></string-name>, <string-name><surname>Packer</surname><given-names>JS</given-names></string-name>, <string-name><surname>McFaline-Figueroa</surname><given-names>JL</given-names></string-name></person-group><etal>et al</etal><article-title>Cicero predicts cis-regulatory DNA interactions from single-cell chromatin accessibility data</article-title>. <source>Mol Cell</source><year>2018</year>;<volume>71</volume>:<fpage>858</fpage>–<lpage>71.e8</lpage>.<pub-id pub-id-type="pmid">30078726</pub-id></mixed-citation>
    </ref>
    <ref id="btad162-B25">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Schroff</surname><given-names>F</given-names></string-name></person-group><etal>et al</etal> FaceNet: a unified embedding for face recognition and clustering. In: <italic toggle="yes">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</italic>. <fpage>815</fpage>–<lpage>23</lpage>. <year>2015</year>.</mixed-citation>
    </ref>
    <ref id="btad162-B26">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Singh</surname><given-names>R</given-names></string-name>, <string-name><surname>Demetci</surname><given-names>P</given-names></string-name>, <string-name><surname>Bonora</surname><given-names>G</given-names></string-name></person-group><etal>et al</etal> Unsupervised manifold alignment for single-cell multi-omics data. In: <italic toggle="yes">Proceedings of the 11th ACM International Conference on Bioinformatics, Computational Biology and Health Informatics</italic>. <fpage>1</fpage>–<lpage>10</lpage>. <year>2020</year>.</mixed-citation>
    </ref>
    <ref id="btad162-B27">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Stanley</surname><given-names>JS</given-names></string-name>, <string-name><surname>Gigante</surname><given-names>S</given-names></string-name>, <string-name><surname>Wolf</surname><given-names>G</given-names><suffix>III</suffix></string-name></person-group><etal>et al</etal> Harmonic alignment. In: <italic toggle="yes">Proceedings of the 2020 SIAM International Conference on Data Mining</italic>. <fpage>316</fpage>–<lpage>24</lpage>. SIAM, <year>2020</year>.</mixed-citation>
    </ref>
    <ref id="btad162-B28">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Stuart</surname><given-names>T</given-names></string-name>, <string-name><surname>Butler</surname><given-names>A</given-names></string-name>, <string-name><surname>Hoffman</surname><given-names>P</given-names></string-name></person-group><etal>et al</etal><article-title>Comprehensive integration of single-cell data</article-title>. <source>Cell</source><year>2019</year>;<volume>177</volume>:<fpage>1888</fpage>–<lpage>902.e21</lpage>.<pub-id pub-id-type="pmid">31178118</pub-id></mixed-citation>
    </ref>
    <ref id="btad162-B29">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Van der Maaten</surname><given-names>L</given-names></string-name>, <string-name><surname>Hinton</surname><given-names>G.</given-names></string-name></person-group><article-title>Visualizing data using t-SNE</article-title>. <source>J Mach Learn Res</source><year>2008</year>;<volume>9</volume>:<fpage>2579</fpage>–<lpage>605</lpage>.</mixed-citation>
    </ref>
    <ref id="btad162-B30">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Wang</surname><given-names>R</given-names></string-name>, <string-name><surname>Cully</surname><given-names>A</given-names></string-name>, <string-name><surname>Chang</surname><given-names>HJ</given-names></string-name></person-group><etal>et al</etal> MAGAN: margin adaptation for generative adversarial networks. arXiv, arXiv:1704.03817, <year>2017</year>. <ext-link xlink:href="https://research.birmingham.ac.uk/en/publications/magan-margin-adaptation-for-generative-adversarial-networks" ext-link-type="uri">https://research.birmingham.ac.uk/en/publications/magan-margin-adaptation-for-generative-adversarial-networks</ext-link>.</mixed-citation>
    </ref>
    <ref id="btad162-B31">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Welch</surname><given-names>JD</given-names></string-name>, <string-name><surname>Hartemink</surname><given-names>AJ</given-names></string-name>, <string-name><surname>Prins</surname><given-names>JF</given-names></string-name></person-group><etal>et al</etal><article-title>Matcher: manifold alignment reveals correspondence between single cell transcriptome and epigenome dynamics</article-title>. <source>Genome Biol</source><year>2017</year>;<volume>18</volume>:<fpage>1</fpage>–<lpage>19</lpage>.<pub-id pub-id-type="pmid">28077169</pub-id></mixed-citation>
    </ref>
    <ref id="btad162-B32">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Yoon</surname><given-names>J</given-names></string-name></person-group><etal>et al</etal> RadialGAN: leveraging multiple datasets to improve target-specific predictive models using generative adversarial networks. In: <italic toggle="yes">International Conference on Machine Learning</italic>. <fpage>5699</fpage>–<lpage>707</lpage>. PMLR, <year>2018</year>.</mixed-citation>
    </ref>
    <ref id="btad162-B33">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Zhang</surname><given-names>X</given-names></string-name>, <string-name><surname>Zhang</surname><given-names>J</given-names></string-name>, <string-name><surname>Sun</surname><given-names>K</given-names></string-name></person-group><etal>et al</etal> Integrated multi-omics analysis using variational autoencoders: application to pan-cancer classification. In: <italic toggle="yes">2019 IEEE International Conference on Bioinformatics and Biomedicine (BIBM).</italic><fpage>765</fpage>–<lpage>9</lpage>. IEEE, <year>2019</year>.</mixed-citation>
    </ref>
    <ref id="btad162-B34">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Zhu</surname><given-names>J-Y</given-names></string-name>, <string-name><surname>Park</surname><given-names>T</given-names></string-name>, <string-name><surname>Isola</surname><given-names>P</given-names></string-name></person-group><etal>et al</etal> Unpaired image-to-image translation using cycle-consistent adversarial networks. In: <italic toggle="yes">Proceedings of the IEEE International Conference on Computer Vision</italic>. <fpage>2223</fpage>–<lpage>32</lpage>. <year>2017</year>.</mixed-citation>
    </ref>
  </ref-list>
</back>
