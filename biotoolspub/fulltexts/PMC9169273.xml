<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">J Cheminform</journal-id>
    <journal-id journal-id-type="iso-abbrev">J Cheminform</journal-id>
    <journal-title-group>
      <journal-title>Journal of Cheminformatics</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1758-2946</issn>
    <publisher>
      <publisher-name>Springer International Publishing</publisher-name>
      <publisher-loc>Cham</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">9169273</article-id>
    <article-id pub-id-type="publisher-id">609</article-id>
    <article-id pub-id-type="doi">10.1186/s13321-022-00609-4</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Software</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>RanDepict: Random chemical structure depiction generator</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" equal-contrib="no">
        <name>
          <surname>Brinkhaus</surname>
          <given-names>Henning Otto</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author" equal-contrib="no">
        <name>
          <surname>Rajan</surname>
          <given-names>Kohulan</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author" equal-contrib="no">
        <name>
          <surname>Zielesny</surname>
          <given-names>Achim</given-names>
        </name>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes" equal-contrib="no">
        <name>
          <surname>Steinbeck</surname>
          <given-names>Christoph</given-names>
        </name>
        <address>
          <email>christoph.steinbeck@uni-jena.de</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="GRID">grid.9613.d</institution-id><institution-id institution-id-type="ISNI">0000 0001 1939 2794</institution-id><institution>Institute for Inorganic and Analytical Chemistry, </institution><institution>Friedrich-Schiller-University Jena, </institution></institution-wrap>Lessingstr. 8, 07743 Jena, Germany </aff>
      <aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="GRID">grid.454254.6</institution-id><institution-id institution-id-type="ISNI">0000 0004 0647 4362</institution-id><institution>Institute for Bioinformatics and Chemoinformatics, </institution><institution>Westphalian University of Applied Sciences, </institution></institution-wrap>August-Schmidt-Ring 10, D-45665 Recklinghausen, Germany </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>6</day>
      <month>6</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>6</day>
      <month>6</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2022</year>
    </pub-date>
    <volume>14</volume>
    <elocation-id>31</elocation-id>
    <history>
      <date date-type="received">
        <day>28</day>
        <month>2</month>
        <year>2022</year>
      </date>
      <date date-type="accepted">
        <day>9</day>
        <month>5</month>
        <year>2022</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2022</copyright-statement>
      <license>
        <ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p><bold>Open Access</bold>This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>. The Creative Commons Public Domain Dedication waiver (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/publicdomain/zero/1.0/">http://creativecommons.org/publicdomain/zero/1.0/</ext-link>) applies to the data made available in this article, unless otherwise stated in a credit line to the data.</license-p>
      </license>
    </permissions>
    <abstract id="Abs1">
      <p id="Par1">The development of deep learning-based optical chemical structure recognition (OCSR) systems has led to a need for datasets of chemical structure depictions. The diversity of the features in the training data is an important factor for the generation of deep learning systems that generalise well and are not overfit to a specific type of input. In the case of chemical structure depictions, these features are defined by the depiction parameters such as bond length, line thickness, label font style and many others. Here we present RanDepict, a toolkit for the creation of diverse sets of chemical structure depictions. The diversity of the image features is generated by making use of all available depiction parameters in the depiction functionalities of the CDK, RDKit, and Indigo. Furthermore, there is the option to enhance and augment the image with features such as curved arrows, chemical labels around the structure, or other kinds of distortions. Using depiction feature fingerprints, RanDepict ensures diversely picked image features. Here, the depiction and augmentation features are summarised in binary vectors and the MaxMin algorithm is used to pick diverse samples out of all valid options. By making all resources described herein publicly available, we hope to contribute to the development of deep learning-based OCSR systems.</p>
      <sec>
        <title>Graphical Abstract</title>
        <p id="Par2">
          <graphic position="anchor" xlink:href="13321_2022_609_Figa_HTML" id="d32e244"/>
        </p>
      </sec>
    </abstract>
    <kwd-group xml:lang="en">
      <title>Keywords</title>
      <kwd>CDK</kwd>
      <kwd>Chemical image depiction</kwd>
      <kwd>Depiction generator image augmentation</kwd>
      <kwd>Indigo</kwd>
      <kwd>RDKit</kwd>
      <kwd>OCSR</kwd>
    </kwd-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100007569</institution-id>
            <institution>Carl-Zeiss-Stiftung</institution>
          </institution-wrap>
        </funding-source>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution>ChemBioSys</institution>
        </funding-source>
        <award-id>CRC1127</award-id>
        <award-id>CRC1127</award-id>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution>Friedrich-Schiller-Universität Jena (1010)</institution>
        </funding-source>
      </award-group>
      <open-access>
        <p>Open Access funding enabled and organized by Projekt DEAL.</p>
      </open-access>
    </funding-group>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>© The Author(s) 2022</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="Sec1" sec-type="introduction">
    <title>Introduction</title>
    <p id="Par10">Since 2019, there has been a lot of development in the field of deep learning-based optical chemical structure recognition (OCSR) [<xref ref-type="bibr" rid="CR1">1</xref>–<xref ref-type="bibr" rid="CR7">7</xref>]. This indicates a paradigm shift as convolutional neural networks (CNN) as encoders in combination with recurrent neural networks (RNN) or transformers as decoders replace the rule-based systems that have previously defined the standard in the field [<xref ref-type="bibr" rid="CR8">8</xref>].</p>
    <p id="Par11">The rule-based systems typically apply a workflow of binarisation, vectorisation, the detection of specific structural elements like dashed lines and wedges, optical character recognition (OCR), graph compilation and additional post-processing steps. Every single step in these workflows can be fine-tuned to achieve optimal results. In 2021, Clevert et al. have shown that the openly available rule-based systems surprisingly fail on the common benchmark datasets when slight image perturbations like rotation and shearing are introduced [<xref ref-type="bibr" rid="CR3">3</xref>]. This lack of robustness is a clear indication that these systems have been overfitted to the benchmark datasets and that there is a need for more diverse benchmark data.</p>
    <p id="Par12">A machine-learning system learns to adapt its actions based on given environment information. Consequently, the quality of the environment information is a crucial factor for the system learning to solve a specific task [<xref ref-type="bibr" rid="CR9">9</xref>]. Machine-learning systems are able to learn best when the input data they receive is similar to the data they have been trained on. In the case of most deep learning-based OCSR systems, the training data consists of images with depictions of chemical structures which are mapped to string representations of the underlying molecular graph. To be able to generalise well across a variety of different depiction styles, a machine-learning model needs to be trained on these depiction styles as well. Additionally, chemical structure depictions often contain non-structural elements like atom numbering or mechanism arrows which need to be considered as common noise types (Fig. <xref rid="Fig1" ref-type="fig">1</xref>). This is particularly relevant for real-world chemical data extraction applications, since the only openly available deep learning-based segmentation tool for chemical structures, DECIMER Segmentation, tends to include these non-structural elements in its output segments [<xref ref-type="bibr" rid="CR10">10</xref>]. Hence, there is a need for a tool for the generation of chemical structure depictions of various depiction styles with additional non-structural elements.</p>
    <p id="Par13">
      <fig id="Fig1">
        <label>Fig. 1</label>
        <caption>
          <p>Examples of structure depictions from chemical publications extracted using DECIMER Segmentation which contain non-structural elements like atom labels (left) [<xref ref-type="bibr" rid="CR11">11</xref>], reaction arrows (middle) [<xref ref-type="bibr" rid="CR12">12</xref>] and identity labels (right) [<xref ref-type="bibr" rid="CR13">13</xref>]</p>
        </caption>
        <graphic xlink:href="13321_2022_609_Fig1_HTML" id="d32e356"/>
      </fig>
    </p>
    <p id="Par14">We present RanDepict, a toolkit for generating diverse representations of chemical structures. It addresses the problem of the generation of diverse training data for OCSR tools by pseudo-randomly setting the available depiction parameters when depicting a structure with one out of three cheminformatics toolkits (Chemistry Development Kit (CDK) [<xref ref-type="bibr" rid="CR14">14</xref>], RDKit [<xref ref-type="bibr" rid="CR15">15</xref>] and Indigo [<xref ref-type="bibr" rid="CR16">16</xref>]). Various augmentations such as image perturbations or non-structural elements like labels and curved arrows can also be added. Instead of pseudo-randomly picking depiction and augmentation parameters, there also is the option to generate the images based on depiction feature fingerprints. Here, the depiction and augmentation parameters are represented as bit arrays and RDKit’s implementation of the MaxMin algorithm [<xref ref-type="bibr" rid="CR17">17</xref>] is used to pick diverse samples out of all valid fingerprints.</p>
    <p id="Par15">By making it publicly accessible, we hope to contribute to the development of robust deep learning-based OCSR systems by providing diverse training and benchmark datasets. RanDepict’s source code is publicly available on GitHub.</p>
  </sec>
  <sec id="Sec2">
    <title>Implementation</title>
    <p id="Par16">RanDepict is written using Python 3 [<xref ref-type="bibr" rid="CR18">18</xref>]. The chemical structure depictions are generated using the CDK, RDKit and Indigo. As CDK is Java-based, its classes are accessed in Python via JPype [<xref ref-type="bibr" rid="CR19">19</xref>].</p>
    <p id="Par17">When a chemical structure depiction is generated, one of the three above-mentioned cheminformatics toolkits is picked randomly. Then, the depiction functions arbitrarily define all available parameters. Among these parameters are bond length, thickness, style, kékulisation, font type and size of atom labels, rotation of molecules, the distance between lines and labels and the abbreviation of chemical substructures. Here, the abbreviation of chemical substructures means that, for example, a tertiary butyl group is abbreviated as tBu instead of drawing the full branched chain. Additionally, atom numbering and chirality labels are included in the depiction parameters as they are added by the cheminformatics toolkits and not by separate functions.</p>
    <p id="Par18">Various non-structural features can be added to the structure depiction. Along with atom numbering and chirality labels, there are also curved mechanism arrows, straight reaction arrows, chemical identity labels, rest group labels, and reaction condition labels.</p>
    <p id="Par19">The arrow images are randomly picked from a set of available images, resized, rotated, and pasted in a position where they do (curved arrows) or do not (reaction arrows) overlap with the chemical structure depiction.</p>
    <p id="Par20">The labels are generated by arbitrarily combining a variety of available text elements. For example, a chemical identity label is generated as a number (e.g., ‘1’), a number-letter combination (e.g., ‘1a’), a number-number combination (e.g., ‘1–4’) or a number-letter-letter combination (‘1a–d’). Similarly, rest group labels are generated by combining rest group variables (e.g., ‘R’, ‘X’) with randomly picked superatom labels. The list of superatoms that is used here was originally published along with the rule-based OCSR system OSRA [<xref ref-type="bibr" rid="CR20">20</xref>]. Reaction condition labels are generated by combining the name of a chemical compound, a solvent, and a time. The font size and type for the labels are randomly chosen. The available font types include standard fonts like Arial and Times New Roman but also fewer common fonts that contain, for example, Asian or Greek-style characters. This ensures that there are diverse types of non-structural elements around the chemical structure that a potential deep learning-based OCSR system can learn to ignore as noise. Furthermore, the image augmentation library imgaug is used to add additional image perturbations. This includes a mild rotation, shearing, salt and pepper noise, brightness and colour adjustments, JPEG compression and pixelation.</p>
    <p id="Par21">Every image created by RanDepict with the desired shape of (m, n) is slightly distorted and resized. Therefore, it is first generated with a shape of (m<sub>dist</sub>, n<sub>dist</sub>) where m<sub>dist</sub> and n<sub>dist</sub> are randomly drawn from [0.9*m, 1.1*m] and [0.9*n, 1.1*n]. Then, it is resized to the desired shape (m, n) with a randomly picked resizing method. The purpose of this procedure is the introduction of the artefacts of different resizing methods in the image data.</p>
    <p id="Par22">Whenever a (pseudo-)random decision is made, the seed attribute of the RandomDepictor class is used as a seed for the pseudo-random choice and then altered systematically. This ensures that the creation of datasets with RanDepict is reproducible under the condition that the tool is fed the same SMILES input and the same initial seed.</p>
    <p id="Par23">Since the entire depiction parameters constitute a high-dimensional feature space, random sampling does not necessarily guarantee even coverage. Instead of choosing parameters randomly, RanDepict can use depiction feature fingerprints to deal with this issue. This means that all depiction parameters as well as the presence or absence of the different augmentation types are summarised in bit arrays. Here, a 1 or a 0 in every position represents the presence or absence of a certain feature (exemplary illustration in Fig. <xref rid="Fig2" ref-type="fig">2</xref>). After computing all possible valid fingerprints, RDKit’s implementation of the MaxMin algorithm [<xref ref-type="bibr" rid="CR17">17</xref>] is used to pick diverse samples. This way, diversity of depiction features is ensured.</p>
    <p id="Par24">
      <fig id="Fig2">
        <label>Fig. 2</label>
        <caption>
          <p>Exemplary illustration of depiction feature fingerprints</p>
        </caption>
        <graphic xlink:href="13321_2022_609_Fig2_HTML" id="d32e429"/>
      </fig>
    </p>
    <p id="Par25">The set of all possible valid fingerprints is determined as the combination of all valid fingerprint building blocks in a given order. Here, a fingerprint building block is a valid subset of values that are linked to certain positions in the whole fingerprint which express one depiction feature. A valid fingerprint is a combination of values that does not lead to contradicting statements about the underlying chemical structure depiction.</p>
    <p id="Par26">Let an exemplary chemical structure depiction be defined by the two features kékulisation and bond width. The kékulisation is defined on position 0 of the fingerprint. The resulting building block for this feature is (0, 1) as the first position of the fingerprint can take these two values to refer to whether the kékulisation is being applied or not. Assuming that the bond width can be thin, medium, or bold, these options would be described by positions 1–3 of the fingerprint. The building blocks for the feature bond width would be (1,0,0), (0,1,0) and (0,0,1). Other combinations for these positions would be invalid as, for example, the combination (1,0,1) on these fingerprint positions would refer to the bond width being thin and bold at the same time. The combination of the valid building blocks for all features in the given order defines the set of all fingerprint combinations. In the aforementioned example, this results in (0,1,0,0), (0,0,1,0), (0,0,0,1), (1,1,0,0), (1,0,1,0) and (1,0,0,1) as the set of valid fingerprints.</p>
    <p id="Par27">The building blocks of the fingerprints are generated automatically. A pseudo-random decision during the depiction creation just needs to be flagged as relevant for the fingerprint. RanDepict recognises this and automatically generates a fingerprint scheme. This way, the code for the fingerprint generation does not need to be adapted in the case of modifications in the depiction creation process.</p>
    <p id="Par28">During the fingerprint generation process, every binary decision (kékulisation in the example above) is simply allocated to one position in the bit array. When categorical decisions (bond width in the example above) are allocated to as many positions as there are categories where every position then indicates the presence or absence of a certain category and only one of them can have the value 1. Numerical ranges are split into three subranges which are then treated like categories. For example, if the bond width could be described by an integer with the possible values [1, 2, 3, 4, 5, 6] this would be allocated to three positions in the fingerprint. These positions would be linked to the subsets [1, 2], [3, 4] and [5, 6]. This means that the fingerprint does not always define an exact value for certain parameters but only specifies a range. When creating a depiction from a fingerprint, the parameter is randomly drawn from this subrange. This is necessary to reduce the number of possible fingerprints as the combinatorial explosion complicates computing all possible fingerprint combinations otherwise.</p>
    <p id="Par29">The three cheminformatics toolkits offer varying amounts of adjustable parameters. During the creation of a CDK depiction, 15 parameters are set. When using RDKit and Indigo, 10 and 8 parameters are adjustable. The ranges of possible values for these parameters differ between the tools. Hence, fingerprints for CDK, RDKit and Indigo depictions and the additional augmentations are four separate entities. The augmentation fingerprints only describe the presence or absence of an augmentation feature but do not comprise the specific parameters which are set. The varying parameter numbers and ranges lead to strongly differing numbers of valid depiction feature fingerprints: 2,799,360 for the CDK fingerprints, 18,432 for RDKit fingerprints, 864 for Indigo and 2048 for the augmentations. When generating a dataset from the fingerprints the user can specify the desired proportions of CDK, RDKit and Indigo depictions as well as the proportion of structures with added augmentations. They default to 55% (CDK), 30% (RDKit) and 15% (Indigo), 50% (augmented).</p>
  </sec>
  <sec id="Sec3" sec-type="results">
    <title>Results</title>
    <p id="Par30">RanDepict was designed to allow the generation of diverse chemical structure depictions using only a few lines of code. After generating a RandomDepictor object, the method random_depiction can be used to generate depictions of chemical structures. These depictions are generated by using randomly picked parameters in CDK, RDKit and Indigo without additional elements (Fig. <xref rid="Fig3" ref-type="fig">3</xref>). The object can be called as a function to generate chemical structure depictions with additional non-structural elements and augmentations (Fig. <xref rid="Fig4" ref-type="fig">4</xref>). There are various examples for the batch generation of structure depiction datasets with and without the usage of the feature fingerprint picking functionality in the documentation.</p>
    <p id="Par31">
      <table-wrap id="Taba">
        <table frame="hsides" rules="groups">
          <tbody>
            <tr>
              <td align="left">from RanDepict import RandomDepictor</td>
            </tr>
            <tr>
              <td align="left">smiles = “CN1C = NC2 = C1C(= O)N(C(= O)N2C)C”</td>
            </tr>
            <tr>
              <td align="left">with RandomDepictor() as depictor:</td>
            </tr>
            <tr>
              <td align="left">    # Generate chemical structure depictions</td>
            </tr>
            <tr>
              <td align="left">    image = depictor.random_depiction(smiles)</td>
            </tr>
            <tr>
              <td align="left">    # Generate augmented chemical structure depictions</td>
            </tr>
            <tr>
              <td align="left">    augmented_image = depictor(smiles)</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
    </p>
    <p id="Par32">
      <fig id="Fig3">
        <label>Fig. 3</label>
        <caption>
          <p>Depictions of caffeine with various depiction styles generated with RanDepict with feature fingerprint picking without additional augmentations</p>
        </caption>
        <graphic xlink:href="13321_2022_609_Fig3_HTML" id="d32e496"/>
      </fig>
    </p>
    <p id="Par33">
      <fig id="Fig4">
        <label>Fig. 4</label>
        <caption>
          <p>Depictions of caffeine with various depiction styles and additional non-structural features and noise types generated with RanDepict using feature fingerprint picking</p>
        </caption>
        <graphic xlink:href="13321_2022_609_Fig4_HTML" id="d32e507"/>
      </fig>
    </p>
    <p id="Par34">On a compute server with two Intel(R) Xeon(R) Silver 4114 CPUs and 64 GB of RAM, the runtime was evaluated for the generation of 100, 200, 400, 800, 1600, 3200 and 6400 chemical structure depictions with an image size of 299 × 299 (Fig. <xref rid="Fig5" ref-type="fig">5</xref>) using one CPU core. This was done with and without the addition of augmentations and the usage of the feature fingerprints. The linear regression results of the different runs clearly indicate that the runtime increases linearly with a growing amount of depictions.</p>
    <p id="Par35">
      <fig id="Fig5">
        <label>Fig. 5</label>
        <caption>
          <p>Runtime analysis of chemical structure depiction generation with RanDepict with and without augmentations and the application of the feature fingerprint picking functionality. The dotted lines represent linear regression results for each case</p>
        </caption>
        <graphic xlink:href="13321_2022_609_Fig5_HTML" id="d32e523"/>
      </fig>
    </p>
    <p id="Par36">Based on the regression analysis, the generation of one million chemical structure depictions without the feature fingerprints takes 19 h without augmentations and 31 h with augmentations. For the generation of large datasets consisting of millions of structures, it is recommended to split the input SMILES lists and run the generation in parallel on multiple nodes in a cluster or using a cloud service. As long as the initial seed is set differently in every parallel instance, different sets of parameters are picked.</p>
    <p id="Par37">The same extrapolation applied to the generation of one million structures using feature fingerprint selection results in 127 h without augmentations and 138 h with augmentations. The user could split up the input SMILES lists here, too, and initialise the MaxMin picking mechanism with different seeds on every instance in a computing cluster to ensure different sets of parameters are picked. Nevertheless, the creation of datasets from fingerprints is significantly slower than the generation with random parameter sampling. Depending on the desired dataset size, the user can decide whether to use depiction feature fingerprints. The feature fingerprint picking functionality is highly recommended for the generation of smaller test and benchmark sets as it ensures a diverse selection of features.</p>
  </sec>
  <sec id="Sec4" sec-type="conclusion">
    <title>Conclusions</title>
    <p id="Par38">RanDepict: a toolkit for generating chemical structure depictions. It features diverse structure depiction elements, as well as non-structural elements and image augmentations.</p>
    <p id="Par39">If desired, the diversity of depiction features is ensured by representing the entirety of features in bit arrays (feature fingerprints) and picking diverse sets using the MaxMin algorithm. Even though fingerprint picking is a time-consuming process, we highly recommend using it for the generation of smaller test sets where the random sampling of depiction features may not necessarily lead to a dataset that represents the entire feature space.</p>
    <p id="Par40">The complete source code of RanDepict, scripts for the generation of Figs. <xref rid="Fig3" ref-type="fig">3</xref> and <xref rid="Fig4" ref-type="fig">4</xref>, the runtime determination as well as other examples for the usage and detailed documentation of RanDepict are openly accessible on GitHub and Read the Docs. It is possible to install RanDepict as a package via pip. We hope that our work will contribute to the standardisation of training and test datasets in the field of OCSR.</p>
  </sec>
</body>
<back>
  <glossary>
    <title>Abbreviations</title>
    <def-list>
      <def-item>
        <term>CDK</term>
        <def>
          <p id="Par3">Chemistry development kit</p>
        </def>
      </def-item>
      <def-item>
        <term>CNN</term>
        <def>
          <p id="Par4">Convolutional neural network</p>
        </def>
      </def-item>
      <def-item>
        <term>JPEG</term>
        <def>
          <p id="Par5">Joint Photographic Experts Group</p>
        </def>
      </def-item>
      <def-item>
        <term>OCSR</term>
        <def>
          <p id="Par6">Optical chemical structure recognition</p>
        </def>
      </def-item>
      <def-item>
        <term>OSRA</term>
        <def>
          <p id="Par7">Optical structure recognition application</p>
        </def>
      </def-item>
      <def-item>
        <term>RNN</term>
        <def>
          <p id="Par8">Recurrent neural network</p>
        </def>
      </def-item>
      <def-item>
        <term>SMILES</term>
        <def>
          <p id="Par9">Simplified molecular input line entry specification</p>
        </def>
      </def-item>
    </def-list>
  </glossary>
  <fn-group>
    <fn>
      <p>
        <bold>Publisher’s note</bold>
      </p>
      <p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
    </fn>
  </fn-group>
  <notes notes-type="author-contribution">
    <title>Author contributions</title>
    <p> HOB developed the Python software and performed the analysis, KR and HOB initiated, designed, tested, applied, and validated the application features. CS and AZ conceived the project and supervised the work. All authors read and approved the final manuscript.</p>
  </notes>
  <notes notes-type="funding-information">
    <title>Funding</title>
    <p>Open Access funding enabled and organized by Projekt DEAL. This work was supported by the Carl-Zeiss-Foundation and by the German Research Foundation within the framework CRC1127 ChemBioSys.</p>
  </notes>
  <notes notes-type="data-availability">
    <title>Availability of data and materials</title>
    <p>Project name: RanDepict. Project home page: <ext-link ext-link-type="uri" xlink:href="https://github.com/OBrink/RanDepict">https://github.com/OBrink/RanDepict</ext-link>,  <ext-link ext-link-type="uri" xlink:href="https://pypi.org/project/RanDepict/">https://pypi.org/project/RanDepict/</ext-link>. Operating system(s): Linux, macOS and Windows 10. Programming language: Python 3. Other requirements: Python packages: numpy &gt;= 1.19, imgaug, scikit-image, epam.indigo, jpype1, ipyplot, rdkit-pypi, imagecorruptions, pillow &gt;= 8.2.0; Java Libraries: CDK 2.5. License: MIT. Any restrictions to use by non-academics: Not applicable.</p>
  </notes>
  <notes>
    <title>Declarations</title>
    <notes id="FPar1" notes-type="COI-statement">
      <title>Competing interests</title>
      <p id="Par41">AZ is co-founder of GNWI—Gesellschaft für Naturwissenschaftliche Informatik mbH, Dortmund, Germany.</p>
    </notes>
  </notes>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <label>1.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Oldenhof</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Arany</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Moreau</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Simm</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>ChemGrapher: optical graph recognition of chemical compounds by deep learning</article-title>
        <source>J Chem Inf Model</source>
        <year>2020</year>
        <volume>60</volume>
        <fpage>4506</fpage>
        <lpage>4517</lpage>
        <pub-id pub-id-type="doi">10.1021/acs.jcim.0c00459</pub-id>
        <pub-id pub-id-type="pmid">32924466</pub-id>
      </element-citation>
    </ref>
    <ref id="CR2">
      <label>2.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Khokhlov</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Krasnov</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Fedorov</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Sosnin</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>Image2SMILES: transformer-based molecular optical recognition engine</article-title>
        <source>Chem Methods</source>
        <year>2022</year>
        <pub-id pub-id-type="doi">10.1002/cmtd.202100069</pub-id>
      </element-citation>
    </ref>
    <ref id="CR3">
      <label>3.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Clevert</surname>
            <given-names>D-A</given-names>
          </name>
          <name>
            <surname>Le</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Winter</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Montanari</surname>
            <given-names>F</given-names>
          </name>
        </person-group>
        <article-title>Img2Mol - accurate SMILES recognition from molecular graphical depictions</article-title>
        <source>Chem Sci</source>
        <year>2021</year>
        <volume>12</volume>
        <fpage>14174</fpage>
        <lpage>14181</lpage>
        <pub-id pub-id-type="doi">10.1039/D1SC01839F</pub-id>
        <pub-id pub-id-type="pmid">34760202</pub-id>
      </element-citation>
    </ref>
    <ref id="CR4">
      <label>4.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Rajan</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Zielesny</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Steinbeck</surname>
            <given-names>C</given-names>
          </name>
        </person-group>
        <article-title>DECIMER 1.0: deep learning for chemical image recognition using transformers</article-title>
        <source>J Cheminform</source>
        <year>2021</year>
        <volume>13</volume>
        <fpage>61</fpage>
        <pub-id pub-id-type="doi">10.1186/s13321-021-00538-8</pub-id>
        <pub-id pub-id-type="pmid">34404468</pub-id>
      </element-citation>
    </ref>
    <ref id="CR5">
      <label>5.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Rajan</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Zielesny</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Steinbeck</surname>
            <given-names>C</given-names>
          </name>
        </person-group>
        <article-title>DECIMER: towards deep learning for chemical image recognition</article-title>
        <source>J Cheminform</source>
        <year>2020</year>
        <volume>12</volume>
        <fpage>65</fpage>
        <pub-id pub-id-type="doi">10.1186/s13321-020-00469-w</pub-id>
        <pub-id pub-id-type="pmid">33372621</pub-id>
      </element-citation>
    </ref>
    <ref id="CR6">
      <label>6.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Weir</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Thompson</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Woodward</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Choi</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Braun</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Martínez</surname>
            <given-names>TJ</given-names>
          </name>
        </person-group>
        <article-title>ChemPix: automated recognition of hand-drawn hydrocarbon structures using deep learning</article-title>
        <source>Chem Sci</source>
        <year>2021</year>
        <volume>12</volume>
        <fpage>10622</fpage>
        <lpage>10633</lpage>
        <pub-id pub-id-type="doi">10.1039/D1SC02957F</pub-id>
        <pub-id pub-id-type="pmid">34447555</pub-id>
      </element-citation>
    </ref>
    <ref id="CR7">
      <label>7.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Staker</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Marshall</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Abel</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>McQuaw</surname>
            <given-names>CM</given-names>
          </name>
        </person-group>
        <article-title>Molecular structure extraction from documents using deep learning</article-title>
        <source>J Chem Inf Model</source>
        <year>2019</year>
        <volume>59</volume>
        <fpage>1017</fpage>
        <lpage>1029</lpage>
        <pub-id pub-id-type="doi">10.1021/acs.jcim.8b00669</pub-id>
        <pub-id pub-id-type="pmid">30758950</pub-id>
      </element-citation>
    </ref>
    <ref id="CR8">
      <label>8.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Rajan</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Brinkhaus</surname>
            <given-names>HO</given-names>
          </name>
          <name>
            <surname>Zielesny</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Steinbeck</surname>
            <given-names>C</given-names>
          </name>
        </person-group>
        <article-title>A review of optical chemical structure recognition tools</article-title>
        <source>J Cheminform</source>
        <year>2020</year>
        <volume>12</volume>
        <fpage>60</fpage>
        <pub-id pub-id-type="doi">10.1186/s13321-020-00465-0</pub-id>
        <pub-id pub-id-type="pmid">33372625</pub-id>
      </element-citation>
    </ref>
    <ref id="CR9">
      <label>9.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wang</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Ma</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Zhou</surname>
            <given-names>L</given-names>
          </name>
        </person-group>
        <article-title>A brief review of machine learning and its application</article-title>
        <source>2009 Int Conf Inf Eng Comput Sci</source>
        <year>2009</year>
        <pub-id pub-id-type="doi">10.1109/iciecs.2009.5362936</pub-id>
      </element-citation>
    </ref>
    <ref id="CR10">
      <label>10.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Rajan</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Brinkhaus</surname>
            <given-names>HO</given-names>
          </name>
          <name>
            <surname>Sorokina</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Zielesny</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Steinbeck</surname>
            <given-names>C</given-names>
          </name>
        </person-group>
        <article-title>DECIMER-Segmentation: automated extraction of chemical structure depictions from scientific literature</article-title>
        <source>J Cheminform</source>
        <year>2021</year>
        <volume>13</volume>
        <fpage>20</fpage>
        <pub-id pub-id-type="doi">10.1186/s13321-021-00496-1</pub-id>
        <pub-id pub-id-type="pmid">33685498</pub-id>
      </element-citation>
    </ref>
    <ref id="CR11">
      <label>11.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Runeberg</surname>
            <given-names>PA</given-names>
          </name>
          <name>
            <surname>Agustin</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Eklund</surname>
            <given-names>PC</given-names>
          </name>
        </person-group>
        <article-title>Formation of tetrahydrofurano-, aryltetralin, and butyrolactone norlignans through the epoxidation of 9-norlignans</article-title>
        <source>Molecules</source>
        <year>2020</year>
        <pub-id pub-id-type="doi">10.3390/molecules25051160</pub-id>
      </element-citation>
    </ref>
    <ref id="CR12">
      <label>12.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhang</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Wei</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Huang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Guo</surname>
            <given-names>D-A</given-names>
          </name>
        </person-group>
        <article-title>Metabolomics combined with multivariate statistical analysis for screening of chemical markers between andgentiana scabra and gentiana rigescens</article-title>
        <source>Molecules</source>
        <year>2020</year>
        <pub-id pub-id-type="doi">10.3390/molecules25051228</pub-id>
      </element-citation>
    </ref>
    <ref id="CR13">
      <label>13.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Luo</surname>
            <given-names>X-W</given-names>
          </name>
          <name>
            <surname>Gao</surname>
            <given-names>C-H</given-names>
          </name>
          <name>
            <surname>Lu</surname>
            <given-names>H-M</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>J-M</given-names>
          </name>
          <name>
            <surname>Su</surname>
            <given-names>Z-Q</given-names>
          </name>
          <name>
            <surname>Tao</surname>
            <given-names>H-M</given-names>
          </name>
          <name>
            <surname>Zhou</surname>
            <given-names>X-F</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>Y-H</given-names>
          </name>
        </person-group>
        <article-title>HPLC-DAD-guided isolation of diversified chaetoglobosins from the coral-associated fungus C2F17</article-title>
        <source>Molecules</source>
        <year>2020</year>
        <pub-id pub-id-type="doi">10.3390/molecules25051237</pub-id>
      </element-citation>
    </ref>
    <ref id="CR14">
      <label>14.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Steinbeck</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Han</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Kuhn</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Horlacher</surname>
            <given-names>O</given-names>
          </name>
          <name>
            <surname>Luttmann</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Willighagen</surname>
            <given-names>E</given-names>
          </name>
        </person-group>
        <article-title>The chemistry development kit (CDK): an open-source Java library for chemo- and bioinformatics</article-title>
        <source>J Chem Inf Comput Sci</source>
        <year>2003</year>
        <volume>43</volume>
        <fpage>493</fpage>
        <lpage>500</lpage>
        <pub-id pub-id-type="doi">10.1021/ci025584y</pub-id>
        <pub-id pub-id-type="pmid">12653513</pub-id>
      </element-citation>
    </ref>
    <ref id="CR15">
      <label>15.</label>
      <mixed-citation publication-type="other">RDKit: Open-source cheminformatics. <ext-link ext-link-type="uri" xlink:href="https://www.rdkit.org/">https://www.rdkit.org/</ext-link>. Accessed 16 May 2022</mixed-citation>
    </ref>
    <ref id="CR16">
      <label>16.</label>
      <mixed-citation publication-type="other">Indigo Toolkit. <ext-link ext-link-type="uri" xlink:href="https://lifescience.opensource.epam.com/indigo/">https://lifescience.opensource.epam.com/indigo/</ext-link>. Accessed 25 Jun 2020</mixed-citation>
    </ref>
    <ref id="CR17">
      <label>17.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ashton</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Barnard</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Casset</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Charlton</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Downs</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Gorse</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Holliday</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Lahana</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Willett</surname>
            <given-names>P</given-names>
          </name>
        </person-group>
        <article-title>Identification of diverse database subsets using property-based and fragment-based molecular descriptions</article-title>
        <source>Quant Struct Act Relatsh</source>
        <year>2002</year>
        <volume>21</volume>
        <fpage>598</fpage>
        <lpage>604</lpage>
        <pub-id pub-id-type="doi">10.1002/qsar.200290002</pub-id>
      </element-citation>
    </ref>
    <ref id="CR18">
      <label>18.</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Van</surname>
            <given-names>RG</given-names>
          </name>
          <name>
            <surname>Drake</surname>
            <given-names>F</given-names>
          </name>
        </person-group>
        <source>Python 3 reference manual</source>
        <year>2009</year>
        <publisher-loc>Scotts Valley</publisher-loc>
        <publisher-name>CreateSpace</publisher-name>
      </element-citation>
    </ref>
    <ref id="CR19">
      <label>19.</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Nelson</surname>
            <given-names>KE</given-names>
          </name>
          <name>
            <surname>Scherer</surname>
            <given-names>MK</given-names>
          </name>
          <name>
            <surname>Others</surname>
          </name>
        </person-group>
        <source>JPype</source>
        <year>2020</year>
        <publisher-loc>Livermore</publisher-loc>
        <publisher-name>Lawrence Livermore National Lab (LLNL)</publisher-name>
      </element-citation>
    </ref>
    <ref id="CR20">
      <label>20.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Filippov</surname>
            <given-names>IV</given-names>
          </name>
          <name>
            <surname>Nicklaus</surname>
            <given-names>MC</given-names>
          </name>
        </person-group>
        <article-title>Optical structure recognition software to recover chemical information: OSRA, an open source solution</article-title>
        <source>J Chem Inf Model</source>
        <year>2009</year>
        <volume>49</volume>
        <fpage>740</fpage>
        <lpage>743</lpage>
        <pub-id pub-id-type="doi">10.1021/ci800067r</pub-id>
        <pub-id pub-id-type="pmid">19434905</pub-id>
      </element-citation>
    </ref>
  </ref-list>
</back>
