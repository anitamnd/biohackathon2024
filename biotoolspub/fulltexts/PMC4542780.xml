<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//NLM//DTD Journal Publishing DTD v2.3 20070202//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName journalpublishing.dtd?>
<?SourceDTD.Version 2.3?>
<?ConverterInfo.XSLTName jp2nlmx2.xsl?>
<?ConverterInfo.Version 2?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id>
    <journal-id journal-id-type="publisher-id">bioinformatics</journal-id>
    <journal-id journal-id-type="hwp">bioinfo</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1367-4803</issn>
    <issn pub-type="epub">1367-4811</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">4542780</article-id>
    <article-id pub-id-type="pmid">26072487</article-id>
    <article-id pub-id-type="doi">10.1093/bioinformatics/btv258</article-id>
    <article-id pub-id-type="publisher-id">btv258</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Ismb/Eccb 2015 Proceedings Papers Committee July 10 to July 14, 2015, Dublin, Ireland</subject>
        <subj-group subj-group-type="heading">
          <subject>Systems</subject>
        </subj-group>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Gene network inference by fusing data from diverse distributions</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Žitnik</surname>
          <given-names>Marinka</given-names>
        </name>
        <xref ref-type="aff" rid="btv258-AFF1">
          <sup>1</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Zupan</surname>
          <given-names>Blaž</given-names>
        </name>
        <xref ref-type="aff" rid="btv258-AFF1">
          <sup>1</sup>
        </xref>
        <xref ref-type="aff" rid="btv258-AFF1">
          <sup>2</sup>
        </xref>
        <xref ref-type="corresp" rid="btv258-COR1">*</xref>
      </contrib>
      <aff id="btv258-AFF1"><sup>1</sup>Faculty of Computer and Information Science, University of Ljubljana, Ljubljana, Slovenia and <sup>2</sup>Department of Molecular and Human Genetics, Baylor College of Medicine, Houston, TX, USA</aff>
    </contrib-group>
    <author-notes>
      <corresp id="btv258-COR1">*To whom correspondence should be addressed.</corresp>
    </author-notes>
    <pub-date pub-type="ppub">
      <day>15</day>
      <month>6</month>
      <year>2015</year>
    </pub-date>
    <pub-date pub-type="epub">
      <day>10</day>
      <month>6</month>
      <year>2015</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>10</day>
      <month>6</month>
      <year>2015</year>
    </pub-date>
    <!-- PMC Release delay is 0 months and 0 days and was based on the
							<pub-date pub-type="epub"/>. -->
    <volume>31</volume>
    <issue>12</issue>
    <fpage>i230</fpage>
    <lpage>i239</lpage>
    <permissions>
      <copyright-statement>© The Author 2015. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2015</copyright-year>
      <license license-type="creative-commons" xlink:href="http://creativecommons.org/licenses/by-nc/3.0/">
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License(<uri xlink:type="simple" xlink:href="http://creativecommons.org/licenses/by-nc/3.0/">http://creativecommons.org/licenses/by-nc/3.0/</uri>),which permits non-commercial reuse, distribution, and reproduction in any medium, provided the original work is properly cited. For commercial re-use, please contact journals.permissions@oup.com</license-p>
      </license>
    </permissions>
    <abstract>
      <p><bold>Motivation:</bold> Markov networks are undirected graphical models that are widely used to infer relations between genes from experimental data. Their state-of-the-art inference procedures assume the data arise from a Gaussian distribution. High-throughput omics data, such as that from next generation sequencing, often violates this assumption. Furthermore, when collected data arise from multiple related but otherwise nonidentical distributions, their underlying networks are likely to have common features. New principled statistical approaches are needed that can deal with different data distributions and jointly consider collections of datasets.</p>
      <p><bold>Results:</bold> We present <sc>FuseNet</sc>, a Markov network formulation that infers networks from a collection of nonidentically distributed datasets. Our approach is computationally efficient and general: given any number of distributions from an exponential family, <sc>FuseNet</sc> represents model parameters through shared latent factors that define neighborhoods of network nodes. In a simulation study, we demonstrate good predictive performance of <sc>FuseNet</sc> in comparison to several popular graphical models. We show its effectiveness in an application to breast cancer RNA-sequencing and somatic mutation data, a novel application of graphical models. Fusion of datasets offers substantial gains relative to inference of separate networks for each dataset. Our results demonstrate that network inference methods for non-Gaussian data can help in accurate modeling of the data generated by emergent high-throughput technologies.</p>
      <p><bold>Availability and implementation:</bold> Source code is at <ext-link ext-link-type="uri" xlink:href="https://github.com/marinkaz/fusenet">https://github.com/marinkaz/fusenet</ext-link>.</p>
      <p>
        <bold>Contact:</bold>
        <email>blaz.zupan@fri.uni-lj.si</email>
      </p>
      <p><bold>Supplementary information:</bold><ext-link ext-link-type="uri" xlink:href="http://bioinformatics.oxfordjournals.org/lookup/suppl/doi:10.1093/bioinformatics/btv258/-/DC1">Supplementary information</ext-link> is available at <italic>Bioinformatics</italic> online. </p>
    </abstract>
    <counts>
      <page-count count="10"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 Introduction</title>
    <p>Undirected graphical models or Markov networks are a popular class of statistical tools for probabilistic description of complex associations in high-dimensional data (cf. <xref rid="btv258-B29" ref-type="bibr">Rue and Held, 2005</xref>). Biological processes in a cell involve complex interactions between genes and it is important to understand, which genes conditionally depend on each other. These dependencies can be inferred from the experimental data and represented in a gene network. As a popular approach to network modeling, Markov networks are particularly appealing because they focus on finding such conditional dependence relationships. Intuitively, the existence of a link between genes A and B in a Markov network indicates that the behavior of gene A is still predictive of gene B given all available measurements about gene A and its immediate neighbors in a network. Hence, Markov networks can help us to find a rich set of direct dependencies between genes that are stronger than gene correlations (<xref rid="btv258-B2" ref-type="bibr">Allen and Liu, 2013</xref>).</p>
    <p>Markov networks have been well studied in bioinformatics and numerous applications are concerned with inferring the network structure primarily from microarray and next generation sequencing gene expression data (<xref rid="btv258-B15" ref-type="bibr">Kotera <italic>et al.</italic>, 2012</xref>; <xref rid="btv258-B11" ref-type="bibr">Gallopin <italic>et al.</italic>, 2013</xref>; <xref rid="btv258-B31" ref-type="bibr">Segal <italic>et al.</italic>, 2003</xref>). They are complementary but not superior to other gene network inference approaches (<xref rid="btv258-B19" ref-type="bibr">Marbach <italic>et al.</italic>, 2012</xref>). However, the increasing variety of data generating technologies and heterogeneity of resulting data draw attention to two challenges in the context of Markov network inference: inference from non-Gaussian distributed data, and simultaneous inference from many datasets.</p>
    <p>In bioinformatics, many datasets are high dimensional, contain a limited number of samples with a large number of zeros, and come from skewed distributions. Most existing methods assume that data follow a Gaussian distribution. While this assumption holds for typical log ratio expression values from microarray data, it is violated for measurements obtained from sequencing technologies. For example, gene expression levels from RNA-sequencing count how many times a transcript maps to a specific genomic location (<xref rid="btv258-B40" ref-type="bibr">Wang <italic>et al.</italic>, 2009</xref>) and as such these data are not Gaussian (<xref rid="btv258-B2" ref-type="bibr">Allen and Liu, 2013</xref>). The Gaussian assumption is also violated for categorical datasets, such as data on mutation types and copy number variation data (<xref rid="btv258-B12" ref-type="bibr">Hudson <italic>et al.</italic>, 2010</xref>). While it would be possible to design a network inference for each specific data type, we could benefit from a procedure that can treat a wide class of distributions and can jointly consider all available data during network inference (<xref rid="btv258-B37" ref-type="bibr">Žitnik and Zupan, 2015</xref>).</p>
    <p>We have developed a novel approach, called <sc>FuseNet</sc>, for inference of undirected networks from a number of high-dimensional datasets (<xref ref-type="fig" rid="btv258-F1">Fig. 1</xref>). Our approach builds upon recent theoretical results about Markov networks (<xref rid="btv258-B41" ref-type="bibr">Yang <italic>et al.</italic>, 2012</xref>, <xref rid="btv258-B42" ref-type="bibr">2013</xref>) and, unlike the previous works in Markov modeling, can be applied to settings where data arise from multiple related but otherwise nonidentical distributions. To achieve this level of modeling flexibility, we represent model parameters with latent factors. <sc>FuseNet</sc> implements data fusion through sharing of latent factors that are common to all datasets and distributions, and handles data diversity through inference of factors specific to a particular dataset.
<fig id="btv258-F1" position="float"><label>Fig. 1.</label><caption><p>An overview of <sc>FuseNet</sc> in a toy application to network inference. <sc>FuseNet</sc>’s input is a collection of datasets that can follow different exponential family distributions. The example from the figure uses two datasets: (<bold>a</bold>) gene expressions from next-generation sequencing follow the Poisson distribution, and (<bold>b</bold>) somatic mutation data follow the multinomial distribution. (<bold>c</bold>) <sc>FuseNet</sc> infers a network by collectively modeling dependencies between any two genes conditioned on the rest of the genes. The absence of an edge between <italic>s</italic><sub>2</sub> and <italic>s</italic><sub>3</sub> (dotted line in grey) implies that <italic>s</italic><sub>2</sub> acts independently of <italic>s</italic><sub>3</sub> given <italic>s</italic><sub>1</sub> and <italic>s</italic><sub>4</sub>, the neighbors of <italic>s</italic><sub>2</sub>. The <inline-formula><mml:math id="MM1"><mml:mo>⊥</mml:mo></mml:math></inline-formula> symbol stands for conditional independence. Genes <italic>s</italic><sub>1</sub> and <italic>s</italic><sub>2</sub> are linked because data profiles of <italic>s</italic><sub>2</sub> in (<bold>a</bold>, <bold>b</bold>) are still predictive of the profile values of <italic>s</italic><sub>1</sub> given <italic>s</italic><sub>4</sub>, the neighbor of <italic>s</italic><sub>2</sub>. (<bold>d</bold>) Shown are <sc>FuseNet</sc>-inferred coefficients that relate <italic>s</italic><sub>2</sub> to all other genes. Nonzero values indicate gene dependency. In the resulting network, gene <italic>s</italic><sub>2</sub> has two neighbors, <italic>s</italic><sub>1</sub> and <italic>s</italic><sub>4</sub></p></caption><graphic xlink:href="btv258f1p"/></fig>
</p>
    <p>In simulation studies, <sc>FuseNet</sc> recovers the true networks underlying the observed data more accurately than several alternative approaches. The improved performance demonstrates that <sc>FuseNet</sc> can find conditional dependencies between genes that could not be reconstructed with Gaussian-based approaches. In a case study with breast cancer RNA-sequencing expression values and somatic mutation data, we demonstrate the benefits of joint network inference from multiple related datasets. The networks inferred collectively from both types of data show greater functional enrichment than networks learned from any data type alone.</p>
  </sec>
  <sec id="SEC2">
    <title>2 Related work</title>
    <p>The most straightforward approach to network inference is a similarity-based approach, which assumes that functionally related genes are likely to share high similarity with respect to a given dataset. A well-known network obtained with this approach is the <italic>S. cerevisiae</italic> genetic interaction network by <xref rid="btv258-B7" ref-type="bibr">Costanzo <italic>et al.</italic> (2010)</xref>. Whenever the similarity value between two genes is above a threshold they are linked by an edge, which is referred to as a direct network inference approach (<xref rid="btv258-B15" ref-type="bibr">Kotera <italic>et al.</italic>, 2012</xref>). In contrast to direct network inference, model-based network inference via graphical models focuses on local dependencies between genes, where each gene is directly affected by a relatively small number of genes. Edges estimated by a graphical model can be related to causal inference (<xref rid="btv258-B26" ref-type="bibr">Pearl and Verma, 1991</xref>).</p>
    <p>The problem of learning a network structure associated with an undirected graphical model has seen a wide range of applications ranging from social networks and image and speech processing (<xref rid="btv258-B22" ref-type="bibr">Metzler and Croft, 2005</xref>; <xref rid="btv258-B38" ref-type="bibr">Wang <italic>et al.</italic>, 2013</xref>) to genomics. Applications in bioinformatics include estimation of molecular pathways from protein interaction and gene expression data (<xref rid="btv258-B31" ref-type="bibr">Segal <italic>et al.</italic>, 2003</xref>; <xref rid="btv258-B32" ref-type="bibr">Stingo and Vannucci, 2011</xref>), reconstruction of gene regulatory networks from microarray data (<xref rid="btv258-B19" ref-type="bibr">Marbach <italic>et al.</italic>, 2012</xref>), inference of a cancer signaling network from proteomic data (<xref rid="btv258-B23" ref-type="bibr">Mukherjee and Speed, 2008</xref>) and reconstruction of genetic interaction networks from integrated experimental data (<xref rid="btv258-B13" ref-type="bibr">Isci <italic>et al.</italic>, 2014</xref>). Methods applied to these problems and many other recent gene network inference algorithms (<xref rid="btv258-B3" ref-type="bibr">Anjum <italic>et al.</italic>, 2009</xref>; <xref rid="btv258-B10" ref-type="bibr">Friedman <italic>et al.</italic>, 2008</xref>; <xref rid="btv258-B21" ref-type="bibr">Meinshausen and Bühlmann, 2006</xref>; <xref rid="btv258-B27" ref-type="bibr">Ravikumar <italic>et al.</italic>, 2010</xref>; <xref rid="btv258-B30" ref-type="bibr">Schäfer and Strimmer, 2005</xref>) estimate Gaussian or binary Markov networks, i.e. they assume that data follow an approximately Gaussian distribution.</p>
    <p>Although non-Gaussian data are becoming increasingly common in biology, until now, very few network inference algorithms have been proposed for their treatment. When dealing with non-Gaussian data, some authors simply use methods that are based on a Gaussian assumption (<xref rid="btv258-B5" ref-type="bibr">Cai <italic>et al.</italic>, 2012</xref>). We show in experiments that this decision may result in poor predictive performance. Recently, various extensions of Gaussian Markov networks have been proposed that first Gaussianize the data, using for example a copula transform (<xref rid="btv258-B18" ref-type="bibr">Liu <italic>et al.</italic>, 2009</xref>, <xref rid="btv258-B17" ref-type="bibr">2012</xref>; <xref rid="btv258-B25" ref-type="bibr">Murray <italic>et al.</italic>, 2013</xref>) or a log transform, and then apply algorithms that rely on an assumption of normality. While these approaches perform better than naïve application of Gaussian-based methods to untransformed data, they are ill-suited to data generated by next generation sequencing technologies (<xref rid="btv258-B2" ref-type="bibr">Allen and Liu, 2013</xref>). A handful of recent algorithms (<xref rid="btv258-B2" ref-type="bibr">Allen and Liu, 2013</xref>; <xref rid="btv258-B11" ref-type="bibr">Gallopin <italic>et al.</italic>, 2013</xref>) have considered Markov networks for non-Gaussian data, using for example the Poisson distribution for RNA-sequencing read counts. In contrast to our <sc>FuseNet</sc>, these methods cannot integrate datasets across different data types, thereby limiting their ability to fuse information from many datasets.</p>
    <p>Our work presented here is similar in spirit to our recently developed methodology for data fusion via collective matrix factorization (<xref rid="btv258-B37" ref-type="bibr">Žitnik and Zupan, 2015</xref>). The methodology therein can jointly model any number of datasets that can be represented with matrices. Unlike existing data integration approaches, it does not require transforming data into a common data space (e.g. a gene space). We applied this methodology to mining disease-disease associations (<xref rid="btv258-B35" ref-type="bibr">Žitnik <italic>et al.</italic>, 2013</xref>), predicting drug toxicity (<xref rid="btv258-B36" ref-type="bibr">Žitnik and Zupan, 2014</xref>) and gene functions (<xref rid="btv258-B37" ref-type="bibr">Žitnik and Zupan, 2015</xref>) and observed substantial gains in predictive accuracy. While both our work here and in <xref rid="btv258-B37" ref-type="bibr">Žitnik and Zupan (2015)</xref> rely on latent factor models, they are substantially different from one another. First, <sc>FuseNet</sc> builds on the Markov network theory, whereas previously we considered matrix decomposition. Second, <sc>FuseNet</sc> is a probabilistic model that explicitly considers various data distributions, and third, <sc>FuseNet</sc> is a network inference approach, whereas our previous works focused on matrix completion.</p>
  </sec>
  <sec>
    <title>3 Methods</title>
    <p><sc>FuseNet</sc> takes as its input a collection of datasets where each dataset consists of a set of gene profiles (<xref ref-type="fig" rid="btv258-F1">Fig. 1</xref>). Gene profiles can be heterogeneous and belong to different data types, e.g. data can be continuous, discrete or categorical. For example, measurements from RNA-sequencing represent the numbers of fragments that were mapped to a specific genomic location (<xref rid="btv258-B40" ref-type="bibr">Wang <italic>et al.</italic>, 2009</xref>). The RNA-sequencing expression values are then non-negative and integer valued and, hence, are not approximately Gaussian, but rather follow the Poisson or negative binomial distribution. This is in contrast to copy number variation data and mutation data, i.e. single-base substitutions, short indels, or multiple base substitutions, that might be modeled better with multinomial or categorical distributions. On the other end of spectrum are microarray gene expression data, which are approximately Gaussian distributed.</p>
    <p>The crucial feature of <sc>FuseNet</sc> is the representation of model parameters via latent factors. This feature, together with the sharing of latent factors between datasets, allows us to infer a network by simultaneously considering many datasets that each can arise from a different exponential family distribution (Section 3.7).</p>
    <p>We exemplify <sc>FuseNet</sc> by deriving Markov network models for two distributions from an exponential family, the Poisson distribution (Section 3.3) and the multinomial distribution (Section 3.5). Since the exponential family includes not only Gaussian but also binomial, multinomial, Poisson, gamma distributions and others, <sc>FuseNet</sc> can achieve great flexibility in estimating gene networks from diverse data (Section 3.6) and also comes with an efficient algorithm for network structure estimation (Section 3.8).</p>
    <p>Our work provides two novel contributions over current approaches to gene network inference discussed in Related work:
<list list-type="bullet"><list-item><p><sc>FuseNet</sc> simultaneously infers networks from datasets that may be generated by nonidentical distributions, and</p></list-item><list-item><p><sc>FuseNet</sc> estimates large-scale genomic networks from increasingly common non-Gaussian distributed data.</p></list-item></list>
</p>
  </sec>
  <sec id="SEC3.1">
    <title>3.1 Preliminaries</title>
    <sec id="SEC3.1.1">
      <title>3.1.1 Markov networks</title>
      <p>A Markov network specifies conditional dependence relationships between genes. In particular, if there is no edge between genes <italic>s</italic> and <italic>t</italic> then this implies that the behavior of <italic>s</italic> is independent of <italic>t</italic> given the set of immediate neighbors of <italic>s</italic>. From this local property (<xref rid="btv258-B24" ref-type="bibr">Murphy, 2012</xref>), one can easily see that two genes (nodes) are conditionally independent given the rest of the genes iff there is no direct edge between them. The conditional independence (Markov) properties permit a rich set of dependencies among the nodes and hence, the connectivity of a Markov network can reveal complex relationships between its nodes (<xref rid="btv258-B2" ref-type="bibr">Allen and Liu, 2013</xref>; <xref rid="btv258-B14" ref-type="bibr">Jalali <italic>et al.</italic>, 2011</xref>).</p>
    </sec>
    <sec id="SEC3.1.2">
      <title>3.1.2 Exponential family</title>
      <p>The probability distributions that we study in this article are specific examples of a broad class of distributions called the exponential family (<xref rid="btv258-B8" ref-type="bibr">Duda and Hart, 1973</xref>). Members of the exponential family have many important properties in common. Given parameters <italic>θ</italic>, the exponential family of distributions over <italic>X</italic> is defined to be the set of distributions of the form:
<disp-formula id="btv258-M1"><label>(1)</label><mml:math id="MM2"><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>X</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>exp</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>θ</mml:mi><mml:mi>B</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>X</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>C</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>X</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mi>D</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>θ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>
where <italic>B</italic>(<italic>X</italic>) are sufficient statistics, <italic>C</italic>(<italic>X</italic>) is a base measure and <inline-formula><mml:math id="MM3"><mml:mrow><mml:mi>D</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>θ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> is a log-normalization constant (<xref rid="btv258-B24" ref-type="bibr">Murphy, 2012</xref>). The exponential family includes many widely used distributions, such as Bernoulli, binomial, Poisson, gamma, multinomial and Gaussian distributions.</p>
    </sec>
    <sec id="SEC3.1.3">
      <title>3.1.3 Parameterization of Markov networks</title>
      <p>Let <inline-formula><mml:math id="MM4"><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>X</mml:mi></mml:mstyle><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>p</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> be a random vector with <italic>X<sub>i</sub></italic> being a random variable. Suppose <inline-formula><mml:math id="MM5"><mml:mrow><mml:mi>G</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>V</mml:mi><mml:mo>,</mml:mo><mml:mi>E</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> is an undirected graph with <italic>p</italic> nodes representing <italic>p</italic> variables in <bold>X</bold>, <inline-formula><mml:math id="MM6"><mml:mrow><mml:mo>|</mml:mo><mml:mi>V</mml:mi><mml:mo>|</mml:mo><mml:mo>=</mml:mo><mml:mi>p</mml:mi></mml:mrow></mml:math></inline-formula>. Then the corresponding undirected graphical model is any distribution defined on <bold>X</bold> that satisfies Markov independence assumptions with respect to graph <italic>G</italic> (<xref rid="btv258-B24" ref-type="bibr">Murphy, 2012</xref>). By the Hammersley-Clifford theorem (<xref rid="btv258-B24" ref-type="bibr">Murphy, 2012</xref>), any such distribution of <bold>X</bold> decomposes according to graph <italic>G</italic> in the following way. Let <inline-formula><mml:math id="MM7"><mml:mi mathvariant="script">C</mml:mi></mml:math></inline-formula> be a set of maximal cliques (fully connected subgraphs) in graph <italic>G</italic> and let <inline-formula><mml:math id="MM8"><mml:mrow><mml:mo>{</mml:mo><mml:msub><mml:mi>ϕ</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mi>c</mml:mi><mml:mo>∈</mml:mo><mml:mi mathvariant="script">C</mml:mi><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> be “clique potential” functions. By the Hammersley-Clifford theorem, any distribution of <italic>X</italic> within the graphical model family defined by <italic>G</italic> can be represented as an exponential of a weighted sum of potential functions over the maximal cliques <inline-formula><mml:math id="MM9"><mml:mi mathvariant="script">C</mml:mi></mml:math></inline-formula>:
<disp-formula id="btv258-M2"><label>(2)</label><mml:math id="MM10"><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>X</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>∝</mml:mo><mml:mi>exp</mml:mi><mml:mo stretchy="true">(</mml:mo><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mo>∈</mml:mo><mml:mi mathvariant="script">C</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mi>c</mml:mi></mml:msub></mml:mrow></mml:mstyle><mml:msub><mml:mi>ϕ</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mo stretchy="true">(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mo stretchy="true">)</mml:mo><mml:mo stretchy="true">)</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>
where <inline-formula><mml:math id="MM11"><mml:mrow><mml:mo>{</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>c</mml:mi><mml:mo>∈</mml:mo><mml:mi mathvariant="script">C</mml:mi><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> are the weights of potential functions.</p>
      <p>An important question is how one would select potential functions <inline-formula><mml:math id="MM12"><mml:mrow><mml:mo>{</mml:mo><mml:msub><mml:mi>ϕ</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>c</mml:mi><mml:mo>∈</mml:mo><mml:mi mathvariant="script">C</mml:mi><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> to obtain various multivariate extensions of univariate distributions. Recently, <xref rid="btv258-B41" ref-type="bibr">Yang <italic>et al.</italic> (2012)</xref> showed that if a node-conditional univariate distribution, i.e. distribution of a random variable conditioned on all other variables, belongs to an exponential family, <italic>it necessarily</italic> follows that the joint distribution of <bold>X</bold> has the form:
<disp-formula id="btv258-M3"><label>(3)</label><mml:math id="MM13"><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>X</mml:mi></mml:mstyle><mml:mo stretchy="true">)</mml:mo><mml:mo>∝</mml:mo><mml:mi>exp</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mo>∈</mml:mo><mml:mi>V</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:mstyle><mml:mi>B</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mo>∈</mml:mo><mml:mi>V</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>∈</mml:mo><mml:mi mathvariant="script">N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:munder><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle><mml:mi>B</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mi>B</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>+</mml:mo><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mo>∈</mml:mo><mml:mi>V</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:mi mathvariant="script">N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:munder><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle><mml:mi>B</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mstyle displaystyle="false"><mml:munderover><mml:mo>∏</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mi>k</mml:mi></mml:munderover><mml:mi>B</mml:mi></mml:mstyle><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mo>∈</mml:mo><mml:mi>V</mml:mi></mml:mrow></mml:munder><mml:mi>C</mml:mi></mml:mstyle><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>
where the cliques are of size at most <italic>k</italic>, <inline-formula><mml:math id="MM14"><mml:mrow><mml:mi mathvariant="script">N</mml:mi><mml:mo stretchy="true">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:math></inline-formula> are neighbors of node <italic>s</italic>, <italic>B</italic> represent sufficient statistics and <italic>C</italic> is the base measure of the a given exponential family distribution (cf. Proposition 1 and Proposition 2 in <xref rid="btv258-B41" ref-type="bibr">Yang <italic>et al.</italic> (2012)</xref>). These results tell us that the joint distribution specified in <xref ref-type="disp-formula" rid="btv258-M3">Eq. (3)</xref> has the most general form under the assumption of exponential family node-conditional distributions. Hence, learning a graphical model from the data can be reduced to learning weights <inline-formula><mml:math id="MM15"><mml:mrow><mml:mo>{</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo>}</mml:mo><mml:mo>∪</mml:mo><mml:mo>{</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>}</mml:mo><mml:mo>∪</mml:mo><mml:mo>…</mml:mo><mml:mo>∪</mml:mo><mml:mo>{</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> of distribution-specific sufficient statistics.</p>
    </sec>
  </sec>
  <sec id="SEC3.2">
    <title>3.2 Problem definition</title>
    <p>Suppose we are given a collection <inline-formula><mml:math id="MM16"><mml:mi mathvariant="script">D</mml:mi></mml:math></inline-formula> of <italic>n</italic> observations, <inline-formula><mml:math id="MM17"><mml:mrow><mml:mi mathvariant="script">D</mml:mi><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>x</mml:mi></mml:mstyle><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>x</mml:mi></mml:mstyle><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>x</mml:mi></mml:mstyle><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="MM18"><mml:mrow><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>x</mml:mi></mml:mstyle><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> is a <italic>p</italic>-dimensional vector drawn i.i.d. from a specific distribution of the form in <xref ref-type="disp-formula" rid="btv258-M3">Equation (3)</xref>. This distribution has parameters <inline-formula><mml:math id="MM19"><mml:mrow><mml:mo>{</mml:mo><mml:msubsup><mml:mi>θ</mml:mi><mml:mi>c</mml:mi><mml:mo>*</mml:mo></mml:msubsup><mml:mo>,</mml:mo><mml:mi>c</mml:mi><mml:mo>∈</mml:mo><mml:mi mathvariant="script">C</mml:mi><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> and is associated with a graph <inline-formula><mml:math id="MM20"><mml:mrow><mml:mi>G</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>V</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mi>E</mml:mi><mml:mo>*</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> on <italic>p</italic> nodes. Graph <italic>G</italic> encodes Markov independence properties between the respective variables. The goal of learning the structure of <italic>G</italic> is to infer an edge set <inline-formula><mml:math id="MM21"><mml:mrow><mml:msup><mml:mi>E</mml:mi><mml:mo>*</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula> that corresponds to distribution, which generated observations in <inline-formula><mml:math id="MM22"><mml:mi mathvariant="script">D</mml:mi></mml:math></inline-formula>. We can express <inline-formula><mml:math id="MM23"><mml:mrow><mml:msup><mml:mi>E</mml:mi><mml:mo>*</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula> as a function of parameters <inline-formula><mml:math id="MM24"><mml:mrow><mml:mo>{</mml:mo><mml:msubsup><mml:mi>θ</mml:mi><mml:mi>c</mml:mi><mml:mo>*</mml:mo></mml:msubsup><mml:mo>,</mml:mo><mml:mi>c</mml:mi><mml:mo>∈</mml:mo><mml:mi mathvariant="script">C</mml:mi><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> and write it as:
<disp-formula><mml:math id="MM25"><mml:mrow><mml:msup><mml:mi>E</mml:mi><mml:mo>*</mml:mo></mml:msup><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>∈</mml:mo><mml:mi>V</mml:mi><mml:mo>×</mml:mo><mml:mi>V</mml:mi><mml:mo>:</mml:mo><mml:mo>∃</mml:mo><mml:mtext> clique </mml:mtext><mml:mi>c</mml:mi><mml:mo>∈</mml:mo><mml:mi mathvariant="script">C</mml:mi><mml:mo>:</mml:mo><mml:mo>{</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>}</mml:mo><mml:mo>⊆</mml:mo><mml:mi>c</mml:mi><mml:mo>∧</mml:mo><mml:msubsup><mml:mi>θ</mml:mi><mml:mi>c</mml:mi><mml:mo>*</mml:mo></mml:msubsup><mml:mo>≠</mml:mo><mml:mn>0</mml:mn><mml:mo>}</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula>
</p>
    <p>Hence, learning the network structure reduces to the problem of estimating weights <inline-formula><mml:math id="MM26"><mml:mrow><mml:mo>{</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>θ</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>c</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>c</mml:mi><mml:mo>∈</mml:mo><mml:mi mathvariant="script">C</mml:mi><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> that should be as close as possible to the true but otherwise unknown parameters <inline-formula><mml:math id="MM27"><mml:mrow><mml:mo>{</mml:mo><mml:msubsup><mml:mi>θ</mml:mi><mml:mi>c</mml:mi><mml:mo>*</mml:mo></mml:msubsup><mml:mo>,</mml:mo><mml:mi>c</mml:mi><mml:mo>∈</mml:mo><mml:mi mathvariant="script">C</mml:mi><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula>.</p>
    <p>In this article, we focus largely on a special case of pairwise Markov networks, where the joint distribution has cliques of size at most two:
<disp-formula id="btv258-M4"><label>(4)</label><mml:math id="MM28"><mml:mrow><mml:mtext>   </mml:mtext><mml:mi>P</mml:mi><mml:mo stretchy="true">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>X</mml:mi></mml:mstyle><mml:mo stretchy="true">)</mml:mo><mml:mtext> </mml:mtext><mml:mo>∝</mml:mo><mml:mtext> </mml:mtext><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:munder><mml:munder accentunder="true"><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mo>∈</mml:mo><mml:mi>V</mml:mi></mml:mrow></mml:munder><mml:msubsup><mml:mi>θ</mml:mi><mml:mi>s</mml:mi><mml:mo>*</mml:mo></mml:msubsup><mml:mi>B</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo stretchy="false">︸</mml:mo></mml:munder><mml:mrow><mml:mtext>set of nodes</mml:mtext></mml:mrow></mml:munder><mml:mtext> </mml:mtext><mml:mo>+</mml:mo><mml:munder><mml:munder accentunder="true"><mml:mrow><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>∈</mml:mo><mml:mi>V</mml:mi><mml:mo>×</mml:mo><mml:mi>V</mml:mi></mml:mrow></mml:munder></mml:mstyle><mml:msubsup><mml:mi>θ</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>*</mml:mo></mml:msubsup><mml:mi>B</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mi>B</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo stretchy="false">︸</mml:mo></mml:munder><mml:mrow><mml:mtext>set of dges</mml:mtext></mml:mrow></mml:munder><mml:mtext> </mml:mtext><mml:mo>+</mml:mo><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mo>∈</mml:mo><mml:mi>V</mml:mi></mml:mrow></mml:munder><mml:mtext> </mml:mtext></mml:mstyle><mml:mi>C</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo stretchy="true">)</mml:mo><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:math></disp-formula>
with entries <inline-formula><mml:math id="MM29"><mml:mrow><mml:msubsup><mml:mi>θ</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>*</mml:mo></mml:msubsup><mml:mo>≠</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> if <inline-formula><mml:math id="MM30"><mml:mrow><mml:mi>t</mml:mi><mml:mo>∈</mml:mo><mml:mi mathvariant="script">N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="MM31"><mml:mrow><mml:msubsup><mml:mi>θ</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>*</mml:mo></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> if <inline-formula><mml:math id="MM32"><mml:mrow><mml:mi>t</mml:mi><mml:menclose notation="updiagonalstrike"><mml:mo>∉</mml:mo></mml:menclose><mml:mi mathvariant="script">N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>. Following the work of <xref rid="btv258-B27" ref-type="bibr">Ravikumar <italic>et al.</italic> (2010)</xref>, <xref rid="btv258-B14" ref-type="bibr">Jalali <italic>et al.</italic> (2011)</xref> and <xref rid="btv258-B2" ref-type="bibr">Allen and Liu (2013)</xref>, we approach the problem of Markov network structure learning via neighborhood estimation, where we obtain the global network estimate <inline-formula><mml:math id="MM33"><mml:mover accent="true"><mml:mi>E</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></inline-formula> by stitching together the estimated neighborhoods of the nodes. The overall network structure is then:
<disp-formula id="btv258-M5"><label>(5)</label><mml:math id="MM34"><mml:mrow><mml:mover accent="true"><mml:mi>E</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:munder><mml:mo>⋃</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mo>∈</mml:mo><mml:mi>V</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>∈</mml:mo><mml:mover accent="true"><mml:mi mathvariant="script">N</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:munder></mml:mstyle><mml:mo>{</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>}</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>
where (<italic>s</italic>, <italic>t</italic>) denotes an edge between <italic>s</italic> and <italic>t</italic> and <inline-formula><mml:math id="MM35"><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="script">N</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:mi>t</mml:mi><mml:mo>∈</mml:mo><mml:mi>V</mml:mi><mml:mi mathvariant="normal">∖</mml:mi><mml:mo>{</mml:mo><mml:mi>s</mml:mi><mml:mo>}</mml:mo><mml:mo>:</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>θ</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>≠</mml:mo><mml:mn>0</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> is the estimated neighborhood of node <italic>s</italic>.</p>
    <p>In the remainder of this section, we formulate two pairwise Markov networks, which assume either Poisson or multinomial data distribution. These two exponential family models are taken as an example through which we specify a general scheme for network inference from multiple potentially nonidentical data distributions.</p>
  </sec>
  <sec id="SEC3.3">
    <title>3.3 Poisson model specification</title>
    <p>Following the work of <xref rid="btv258-B41" ref-type="bibr">Yang <italic>et al.</italic> (2012)</xref> and <xref rid="btv258-B2" ref-type="bibr">Allen and Liu (2013)</xref>, we define a Poisson Markov network model by specifying a distribution where all node-conditional distributions follow a univariate Poisson distribution. Our Poisson Markov network model is then a series of locally defined models, one for every variable (node). A local model for <italic>s</italic> is given by a distribution of <italic>X<sub>s</sub></italic> conditioned on all other variables:
<disp-formula id="btv258-M6"><label>(6)</label><mml:math id="MM36"><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>V</mml:mi><mml:mi mathvariant="normal">∖</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>∼</mml:mo><mml:mtext> Poisson </mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mo>{</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>u</mml:mi></mml:mstyle><mml:mi>s</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>∈</mml:mo><mml:mi>V</mml:mi><mml:mi mathvariant="normal">∖</mml:mi><mml:mo>{</mml:mo><mml:mi>s</mml:mi><mml:mo>}</mml:mo></mml:mrow></mml:munder><mml:mtext> </mml:mtext></mml:mstyle><mml:msubsup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>u</mml:mi></mml:mstyle><mml:mi>s</mml:mi><mml:mi>T</mml:mi></mml:msubsup><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle><mml:mi>T</mml:mi></mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>u</mml:mi></mml:mstyle><mml:mi>t</mml:mi></mml:msub><mml:msub><mml:mi>X</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>}</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>
where <inline-formula><mml:math id="MM37"><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>V</mml:mi><mml:mi mathvariant="normal">∖</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:mi>t</mml:mi><mml:mo>∈</mml:mo><mml:mi>V</mml:mi><mml:mi mathvariant="normal">∖</mml:mi><mml:mo>{</mml:mo><mml:mi>s</mml:mi><mml:mo>}</mml:mo><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> denotes the rest of the variables, and <inline-formula><mml:math id="MM38"><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>u</mml:mi></mml:mstyle><mml:mi>s</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mi mathvariant="double-struck">R</mml:mi><mml:mi>r</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="MM39"><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle><mml:mo>∈</mml:mo><mml:msup><mml:mi mathvariant="double-struck">R</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mo>×</mml:mo><mml:mi>r</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> are model parameters. An <italic>r</italic>-dimensional vector <inline-formula><mml:math id="MM40"><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>u</mml:mi></mml:mstyle><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is a latent factor for node <italic>s</italic> that consists of <italic>r</italic> latent components. For now, we assume that the number of latent components <italic>r</italic> is given; we will later discuss how to automatically determine <italic>r</italic>. Notice that the latent factor of node <italic>s</italic>, <inline-formula><mml:math id="MM41"><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>u</mml:mi></mml:mstyle><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, represents the strength of membership of node <italic>s</italic> to <italic>r</italic> latent components and <bold>W</bold> models the interactions between all combinations of <italic>r</italic> latent components. The formulation of the Poisson conditional distribution in <xref ref-type="disp-formula" rid="btv258-M6">Equation (6)</xref> ensures that node pair-wise weights are symmetric, which is an appealing property when studying undirected graphical models. In particular, the contribution of <italic>X<sub>t</sub></italic> towards <inline-formula><mml:math id="MM42"><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>V</mml:mi><mml:mi mathvariant="normal">∖</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> is the same as is the contribution of <italic>X<sub>s</sub></italic> towards <inline-formula><mml:math id="MM43"><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>V</mml:mi><mml:mi mathvariant="normal">∖</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>.</p>
    <p>We refer to our model as a model parameterized via latent factorization, since model parameters <inline-formula><mml:math id="MM44"><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>u</mml:mi></mml:mstyle><mml:mi>s</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mtext> </mml:mtext><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>u</mml:mi></mml:mstyle><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and <bold>W</bold> form a factorization of the edge weight <italic>θ<sub>st</sub></italic>, which is specified by a Markov network model in <xref ref-type="disp-formula" rid="btv258-M4">Equation (4)</xref>. The importance of latent factor parameterization will be obvious later in Section 3.7 when we discuss collective network inference from many datasets.</p>
    <p>Recall the univariate Poisson distribution is given by the mass function <inline-formula><mml:math id="MM45"><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>X</mml:mi><mml:mo>=</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msup><mml:mi>λ</mml:mi><mml:mi>x</mml:mi></mml:msup><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mo>−</mml:mo><mml:mi>λ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>/</mml:mo><mml:mi>x</mml:mi><mml:mo>!</mml:mo></mml:mrow></mml:math></inline-formula>, where <italic>λ</italic> is the shape parameter. Our model extends the univariate Poisson in a natural and strict sense to the multivariate graphical model setting. The latter can be obtained from the univariate Poisson by setting the shape parameter to <inline-formula><mml:math id="MM46"><mml:mrow><mml:mi>λ</mml:mi><mml:mo>=</mml:mo><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>u</mml:mi></mml:mstyle><mml:mi>s</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mstyle displaystyle="false"><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>∈</mml:mo><mml:mi>V</mml:mi><mml:mi mathvariant="normal">∖</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:msubsup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>u</mml:mi></mml:mstyle><mml:mi>s</mml:mi><mml:mi>T</mml:mi></mml:msubsup></mml:mrow></mml:mstyle><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle><mml:mi>T</mml:mi></mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>u</mml:mi></mml:mstyle><mml:mi>t</mml:mi></mml:msub><mml:msub><mml:mi>X</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>. We then write the expression in <xref ref-type="disp-formula" rid="btv258-M6">Equation (6)</xref> as:
<disp-formula id="btv258-M7"><label>(7)</label><mml:math id="MM47"><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>V</mml:mi><mml:mi mathvariant="normal">∖</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>exp</mml:mi><mml:mo>{</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>u</mml:mi></mml:mstyle><mml:mi>s</mml:mi></mml:msub><mml:msub><mml:mi>X</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mi>log</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo>!</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>∈</mml:mo><mml:mi>V</mml:mi><mml:mi mathvariant="normal">∖</mml:mi><mml:mo>{</mml:mo><mml:mi>s</mml:mi><mml:mo>}</mml:mo></mml:mrow></mml:munder><mml:mo stretchy="false">(</mml:mo></mml:mstyle><mml:msubsup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>u</mml:mi></mml:mstyle><mml:mi>s</mml:mi><mml:mi>T</mml:mi></mml:msubsup><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle><mml:mi>T</mml:mi></mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>u</mml:mi></mml:mstyle><mml:mi>t</mml:mi></mml:msub><mml:msub><mml:mi>X</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:msub><mml:mi>X</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>−</mml:mo><mml:mi>exp</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>u</mml:mi></mml:mstyle><mml:mi>s</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msubsup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>u</mml:mi></mml:mstyle><mml:mi>s</mml:mi><mml:mi>T</mml:mi></mml:msubsup><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle><mml:mi>T</mml:mi></mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>u</mml:mi></mml:mstyle><mml:mi>t</mml:mi></mml:msub><mml:msub><mml:mi>X</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>}</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>
</p>
    <p>Intuitively, variable <italic>X<sub>s</sub></italic> in <xref ref-type="disp-formula" rid="btv258-M7">Equation (7)</xref> can be viewed as the response variable in a latent factor Poisson regression in which the other variables <inline-formula><mml:math id="MM48"><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>V</mml:mi><mml:mi mathvariant="normal">∖</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> play the role of the predictors. Variables with strong relationships with gene <italic>s</italic> will have nonzero regression coefficients, and these will be connected to node <italic>s</italic> in the inferred graph.</p>
  </sec>
  <sec id="SEC3.4">
    <title>3.4 Optimization of the Poisson model</title>
    <p>The node-conditional distributions specified in <xref ref-type="disp-formula" rid="btv258-M7">Equation (7)</xref> define a global distribution that factors according to the cliques of the underlying graph <italic>G</italic> that we would like to estimate. We obtain edge set <inline-formula><mml:math id="MM49"><mml:mover accent="true"><mml:mi>E</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></inline-formula> by stitching node neighborhoods as prescribed by <xref ref-type="disp-formula" rid="btv258-M5">Equation (5)</xref>, where we define the neighborhood of node <italic>s</italic> as <inline-formula><mml:math id="MM50"><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="script">N</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:mi>t</mml:mi><mml:mo>∈</mml:mo><mml:mi>V</mml:mi><mml:mi mathvariant="normal">∖</mml:mi><mml:mo>{</mml:mo><mml:mi>s</mml:mi><mml:mo>}</mml:mo><mml:mo>:</mml:mo><mml:msubsup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>u</mml:mi></mml:mstyle><mml:mi>s</mml:mi><mml:mi>T</mml:mi></mml:msubsup><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle><mml:mi>T</mml:mi></mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>u</mml:mi></mml:mstyle><mml:mi>t</mml:mi></mml:msub><mml:mo>≠</mml:mo><mml:mn>0</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula>. This means that edge (<italic>s</italic>, <italic>t</italic>) is included in the network if the estimated product of respective latent factors of variables <italic>X<sub>s</sub></italic> and <italic>X<sub>t</sub></italic> is nonzero.</p>
    <p>To estimate edge set <inline-formula><mml:math id="MM51"><mml:mover accent="true"><mml:mi>E</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></inline-formula>, we have to determine the node neighborhoods of all nodes in <italic>V</italic>. To achieve this goal, we solve a sparsity constrained conditional maximum likelihood estimation problem:
<disp-formula id="btv258-M8"><label>(8)</label><mml:math id="MM52"><mml:mrow><mml:munder><mml:mrow><mml:mi>min</mml:mi><mml:mo>⁡</mml:mo></mml:mrow><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>U</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle></mml:mrow></mml:munder><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mo>∈</mml:mo><mml:mi>V</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:msub><mml:mi>ℓ</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:mstyle><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>U</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle><mml:mo>;</mml:mo><mml:mi mathvariant="script">D</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>α</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mtext>Reg</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>U</mml:mi></mml:mstyle><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mtext>Reg</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula>
</p>
    <p>Here, <bold>U</bold> is a matrix with node latent factors placed in the columns, <inline-formula><mml:math id="MM53"><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>U</mml:mi></mml:mstyle><mml:mo>=</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>u</mml:mi></mml:mstyle><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>u</mml:mi></mml:mstyle><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>u</mml:mi></mml:mstyle><mml:mi>n</mml:mi></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></inline-formula>.</p>
    <p><xref ref-type="disp-formula" rid="btv258-M8">Equation (8)</xref> consists of two parts, which we discuss next. Terms involving Reg represent the elastic net penalties (<xref rid="btv258-B44" ref-type="bibr">Zou and Hastie, 2005</xref>). The penalty is defined for <bold>U</bold> as <inline-formula><mml:math id="MM54"><mml:mrow><mml:mtext>Reg</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>U</mml:mi></mml:mstyle><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>λ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>U</mml:mi></mml:mstyle><mml:mo>|</mml:mo><mml:msubsup><mml:mo>|</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mo>+</mml:mo><mml:mi>λ</mml:mi><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>U</mml:mi></mml:mstyle><mml:mo>|</mml:mo><mml:msub><mml:mo>|</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="MM55"><mml:mrow><mml:mi>λ</mml:mi><mml:mo>≥</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> is a regularization parameter controlling the amount of sparsity in the node neighborhood. The definition of the penalty term for <bold>W</bold> is analogous. Notice that the <inline-formula><mml:math id="MM56"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> norm is the sum of 2-norms of the columns, <inline-formula><mml:math id="MM57"><mml:mrow><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>U</mml:mi></mml:mstyle><mml:mo>|</mml:mo><mml:msub><mml:mo>|</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mstyle displaystyle="false"><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>p</mml:mi></mml:msubsup><mml:mo>|</mml:mo></mml:mstyle><mml:mo>|</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>u</mml:mi></mml:mstyle><mml:mi>s</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msubsup><mml:mo>|</mml:mo><mml:mn>2</mml:mn><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula>, and the <inline-formula><mml:math id="MM58"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> norm is the sum of 1-norms of the columns, <inline-formula><mml:math id="MM59"><mml:mrow><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>U</mml:mi></mml:mstyle><mml:mo>|</mml:mo><mml:msub><mml:mo>|</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mstyle displaystyle="false"><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>p</mml:mi></mml:msubsup><mml:mo>|</mml:mo></mml:mstyle><mml:mo>|</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>u</mml:mi></mml:mstyle><mml:mi>s</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mo>|</mml:mo><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>. Since latent factors are affected by the strength of regularization, the choice of parameter <italic>λ</italic> is important. Procedure for selection of <italic>λ</italic> is described in <ext-link ext-link-type="uri" xlink:href="http://bioinformatics.oxfordjournals.org/lookup/suppl/doi:10.1093/bioinformatics/btv258/-/DC1">Supplementary Section 1</ext-link>.</p>
    <p>The crucial part of <xref ref-type="disp-formula" rid="btv258-M8">Equation (8)</xref> is, however, the sum of the node-wise Poisson likelihood functions. Given node <italic>s</italic> and <italic>n</italic> realizations of the associated random variable <italic>X<sub>s</sub></italic>, the Poisson likelihood function <inline-formula><mml:math id="MM60"><mml:mrow><mml:msub><mml:mi>ℓ</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> follows directly from <xref ref-type="disp-formula" rid="btv258-M7">Equation (7)</xref> and can be written as:
<disp-formula id="btv258-M9"><label>(9)</label><mml:math id="MM61"><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:msub><mml:mi>ℓ</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>U</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle><mml:mo>;</mml:mo><mml:mi mathvariant="script">D</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>n</mml:mi></mml:mfrac><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>∏</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:mi>P</mml:mi></mml:mstyle><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>x</mml:mi></mml:mstyle><mml:mi>s</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>|</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>V</mml:mi><mml:mi mathvariant="normal">∖</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>X</mml:mi></mml:mstyle><mml:mrow><mml:mi mathvariant="normal">∖</mml:mi><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>n</mml:mi></mml:mfrac><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:mo stretchy="false">(</mml:mo></mml:mstyle><mml:msubsup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>x</mml:mi></mml:mstyle><mml:mi>s</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:msubsup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>X</mml:mi></mml:mstyle><mml:mrow><mml:mi mathvariant="normal">∖</mml:mi><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:msubsup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>U</mml:mi></mml:mstyle><mml:mrow><mml:mi mathvariant="normal">∖</mml:mi><mml:mi>s</mml:mi></mml:mrow><mml:mi>T</mml:mi></mml:msubsup><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle><mml:mi>T</mml:mi></mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>u</mml:mi></mml:mstyle><mml:mi>s</mml:mi></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>−</mml:mo><mml:mi>exp</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>X</mml:mi></mml:mstyle><mml:mrow><mml:mi mathvariant="normal">∖</mml:mi><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:msubsup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>U</mml:mi></mml:mstyle><mml:mrow><mml:mi mathvariant="normal">∖</mml:mi><mml:mi>s</mml:mi></mml:mrow><mml:mi>T</mml:mi></mml:msubsup><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle><mml:mi>T</mml:mi></mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>
where <inline-formula><mml:math id="MM62"><mml:mrow><mml:msubsup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>x</mml:mi></mml:mstyle><mml:mi>s</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> is the <italic>i</italic>-th realization of <italic>X<sub>s</sub></italic> in data <inline-formula><mml:math id="MM63"><mml:mrow><mml:mi mathvariant="script">D</mml:mi><mml:mo>,</mml:mo><mml:mtext> </mml:mtext><mml:msubsup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>X</mml:mi></mml:mstyle><mml:mrow><mml:mi mathvariant="normal">∖</mml:mi><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> denotes the <italic>i</italic>-th realization of the rest of the variables <inline-formula><mml:math id="MM64"><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>V</mml:mi><mml:mi mathvariant="normal">∖</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, and <bold>U</bold> and <bold>W</bold> are matrix unknowns. Notice that node-wise terms are ignored here for simplicity.</p>
  </sec>
  <sec id="SEC3.5">
    <title>3.5 Multinomial model specification and optimization</title>
    <p>We now develop a multinomial Markov network model that relies on latent factor parameterization of the model parameters and follows the same paradigm as our Poisson model described in the previous section. The multinomial model presented here is a natural extension of the multinomial graphical model described by <xref rid="btv258-B14" ref-type="bibr">Jalali <italic>et al.</italic> (2011)</xref>.</p>
    <p>We start with the neighborhood recovery of one fixed node <italic>s</italic> and then combine the neighborhood sets across nodes to estimate the network. The multinomial model assumes that each variable <italic>X<sub>i</sub></italic> from a random vector <bold>X</bold> follows a multinomial distribution with potentially different parameters. This means that <italic>X<sub>i</sub></italic> can take any value from a small discrete set <inline-formula><mml:math id="MM65"><mml:mrow><mml:mo>{</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>m</mml:mi><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> of cardinality <italic>m</italic>. Probabilities of different values are not independent so that, given any <italic>m</italic> – 1 of the probabilities, the probability of the remaining value is fixed. It is convenient to express the distribution in terms of only <italic>m</italic> – 1 values, thereby leaving <italic>m</italic> – 1 probability parameters that need to be estimated.</p>
    <p>The distribution of <italic>X<sub>s</sub></italic> conditioned on other variables <inline-formula><mml:math id="MM66"><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>V</mml:mi><mml:mi mathvariant="normal">∖</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>:</mml:mo><mml:mi>t</mml:mi><mml:mo>∈</mml:mo><mml:mi>V</mml:mi><mml:mi mathvariant="normal">∖</mml:mi><mml:mo>{</mml:mo><mml:mi>s</mml:mi><mml:mo>}</mml:mo><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> is given by:
<disp-formula id="btv258-M10"><label>(10)</label><mml:math id="MM67"><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mtext> </mml:mtext><mml:mo>=</mml:mo><mml:mtext> </mml:mtext><mml:mi>j</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>V</mml:mi><mml:mi mathvariant="normal">∖</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>exp</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>∈</mml:mo><mml:mi>V</mml:mi><mml:mi mathvariant="normal">∖</mml:mi><mml:mo>{</mml:mo><mml:mi>s</mml:mi><mml:mo>}</mml:mo></mml:mrow></mml:munder><mml:mrow><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mi>k</mml:mi></mml:munder><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mo>;</mml:mo><mml:mi>j</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle><mml:msub><mml:mi mathvariant="script">I</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mtext> </mml:mtext><mml:mo>+</mml:mo><mml:mtext> </mml:mtext><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mi>l</mml:mi></mml:munder><mml:mrow><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo></mml:mrow></mml:mstyle><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mtext> </mml:mtext><mml:mo>+</mml:mo><mml:mtext> </mml:mtext><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>∈</mml:mo><mml:mi>V</mml:mi><mml:mi mathvariant="normal">∖</mml:mi><mml:mo>{</mml:mo><mml:mi>s</mml:mi><mml:mo>}</mml:mo></mml:mrow></mml:munder><mml:mtext> </mml:mtext></mml:mstyle><mml:mtext> </mml:mtext><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mi>k</mml:mi></mml:munder><mml:mtext> </mml:mtext></mml:mstyle><mml:mtext> </mml:mtext><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mo>;</mml:mo><mml:mi>l</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi mathvariant="script">I</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula>
for all <inline-formula><mml:math id="MM68"><mml:mrow><mml:mi>j</mml:mi><mml:mo>∈</mml:mo><mml:mo>{</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mi>m</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula>. Here, <italic>θ<sub>sj</sub></italic> represents a node-wise term that models the probability of variable <italic>X<sub>s</sub></italic> taking value <italic>j</italic>. The other model parameter is <inline-formula><mml:math id="MM69"><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mo>;</mml:mo><mml:mi>j</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, which models dependency between variable <italic>X<sub>s</sub></italic> and variable <italic>X<sub>t</sub></italic> when they take values <italic>j</italic> and <italic>k</italic>, respectively. We can view <xref ref-type="disp-formula" rid="btv258-M10">Equation (10)</xref> as a multiclass logistic (softmax) regression, where <italic>X<sub>s</sub></italic> is the response variable and indicator functions associated with other variables:
<disp-formula><mml:math id="MM70"><mml:mrow><mml:mo>{</mml:mo><mml:msub><mml:mi mathvariant="script">I</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>∈</mml:mo><mml:mi>V</mml:mi><mml:mi mathvariant="normal">∖</mml:mi><mml:mo>{</mml:mo><mml:mi>s</mml:mi><mml:mo>}</mml:mo><mml:mo>,</mml:mo><mml:mi>k</mml:mi><mml:mo>∈</mml:mo><mml:mo>{</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>m</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>}</mml:mo><mml:mo>}</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>
where <inline-formula><mml:math id="MM71"><mml:mrow><mml:msub><mml:mi mathvariant="script">I</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mtext> if </mml:mtext><mml:msub><mml:mi>X</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>k</mml:mi><mml:mtext> else </mml:mtext><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>, are the predictors.</p>
    <p>We now proceed by writing model parameters <italic>θ<sub>sj</sub></italic> and <inline-formula><mml:math id="MM72"><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mo>;</mml:mo><mml:mi>j</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> in the form of a product of latent factors. We gather node-wise terms <italic>θ<sub>sj</sub></italic> into a matrix <inline-formula><mml:math id="MM73"><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>Q</mml:mi></mml:mstyle><mml:mo>∈</mml:mo><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>R</mml:mi></mml:mstyle><mml:mrow><mml:mi>p</mml:mi><mml:mo>×</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>m</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>. We factorize <inline-formula><mml:math id="MM74"><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mo>;</mml:mo><mml:mi>j</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> as <inline-formula><mml:math id="MM75"><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mo>;</mml:mo><mml:mi>j</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>u</mml:mi></mml:mstyle><mml:mi>s</mml:mi><mml:mi>T</mml:mi></mml:msubsup><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>Q</mml:mi></mml:mstyle><mml:mrow><mml:mi>s</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle><mml:mi>T</mml:mi></mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>Q</mml:mi></mml:mstyle><mml:mrow><mml:mi>t</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>u</mml:mi></mml:mstyle><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>. Here, <inline-formula><mml:math id="MM76"><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>u</mml:mi></mml:mstyle><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="MM77"><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>u</mml:mi></mml:mstyle><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> are <italic>r</italic>-dimensional latent factors and <inline-formula><mml:math id="MM78"><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle><mml:mo>∈</mml:mo><mml:msup><mml:mi mathvariant="double-struck">R</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mo>×</mml:mo><mml:mi>r</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> encodes interactions between latent components in the same way as is described in Section 3.3.</p>
    <p>To estimate the latent factors and node-wise terms from the data we solve the following convex optimization program:
<disp-formula id="btv258-M11"><label>(11)</label><mml:math id="MM79"><mml:mrow><mml:munder><mml:mrow><mml:mi>min</mml:mi><mml:mo>⁡</mml:mo></mml:mrow><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>U</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>Q</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle></mml:mrow></mml:munder><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mo>∈</mml:mo><mml:mi>V</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:msub><mml:mi>ℓ</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:mstyle><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>U</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>Q</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle><mml:mo>;</mml:mo><mml:mi mathvariant="script">D</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>α</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mtext> Reg </mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>U</mml:mi></mml:mstyle><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mtext> Reg </mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>Q</mml:mi></mml:mstyle><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mtext>Reg </mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>
where definitions of <bold>U</bold>, <bold>W</bold> and Reg are the same is in the previous section. Here, the node-wise multinomial likelihood function <inline-formula><mml:math id="MM80"><mml:mrow><mml:msub><mml:mi>ℓ</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> for node <italic>s</italic> follows from <xref ref-type="disp-formula" rid="btv258-M10">Equation (10)</xref> and can be written as:
<disp-formula id="btv258-M12"><label>(12)</label><mml:math id="MM81"><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:msub><mml:mi>ℓ</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>U</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:mtext> </mml:mtext><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>Q</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:mtext> </mml:mtext><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle><mml:mo>;</mml:mo><mml:mtext> </mml:mtext><mml:mi mathvariant="script">D</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>n</mml:mi></mml:mfrac><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>∏</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:mi>P</mml:mi></mml:mstyle><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>x</mml:mi></mml:mstyle><mml:mi>s</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>|</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>V</mml:mi><mml:mi mathvariant="normal">∖</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>X</mml:mi></mml:mstyle><mml:mrow><mml:mi mathvariant="normal">∖</mml:mi><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>n</mml:mi></mml:mfrac><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:mo stretchy="false">(</mml:mo></mml:mstyle><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>Q</mml:mi></mml:mstyle><mml:mrow><mml:mi>s</mml:mi><mml:msubsup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>x</mml:mi></mml:mstyle><mml:mi>s</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mtext>     </mml:mtext><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>∈</mml:mo><mml:mi>V</mml:mi><mml:mi mathvariant="normal">∖</mml:mi><mml:mo>{</mml:mo><mml:mi>s</mml:mi><mml:mo>}</mml:mo></mml:mrow></mml:munder><mml:mtext> </mml:mtext></mml:mstyle><mml:mtext> </mml:mtext><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mi>k</mml:mi></mml:munder><mml:mrow><mml:msubsup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>u</mml:mi></mml:mstyle><mml:mi>s</mml:mi><mml:mi>T</mml:mi></mml:msubsup></mml:mrow></mml:mstyle><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>Q</mml:mi></mml:mstyle><mml:mrow><mml:mi>s</mml:mi><mml:msubsup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>x</mml:mi></mml:mstyle><mml:mi>s</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:msub><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle><mml:mi>T</mml:mi></mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>Q</mml:mi></mml:mstyle><mml:mrow><mml:mi>t</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>u</mml:mi></mml:mstyle><mml:mi>t</mml:mi></mml:msub><mml:msub><mml:mi mathvariant="script">I</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>x</mml:mi></mml:mstyle><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mtext>  </mml:mtext><mml:mo>+</mml:mo><mml:mtext>   </mml:mtext><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mi>l</mml:mi></mml:munder><mml:mrow><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo></mml:mrow></mml:mstyle><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>Q</mml:mi></mml:mstyle><mml:mrow><mml:mi>s</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mtext> </mml:mtext><mml:mo>+</mml:mo><mml:mtext>        </mml:mtext><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>∈</mml:mo><mml:mi>V</mml:mi><mml:mi mathvariant="normal">∖</mml:mi><mml:mo>{</mml:mo><mml:mi>s</mml:mi><mml:mo>}</mml:mo></mml:mrow></mml:munder><mml:mtext> </mml:mtext></mml:mstyle><mml:mtext>   </mml:mtext><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mi>k</mml:mi></mml:munder><mml:mtext> </mml:mtext></mml:mstyle><mml:msubsup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>u</mml:mi></mml:mstyle><mml:mi>s</mml:mi><mml:mi>T</mml:mi></mml:msubsup><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>Q</mml:mi></mml:mstyle><mml:mrow><mml:mi>s</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle><mml:mi>T</mml:mi></mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>Q</mml:mi></mml:mstyle><mml:mrow><mml:mi>t</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>u</mml:mi></mml:mstyle><mml:mi>t</mml:mi></mml:msub><mml:msub><mml:mi mathvariant="script">I</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>x</mml:mi></mml:mstyle><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>
where <inline-formula><mml:math id="MM82"><mml:mrow><mml:msubsup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>x</mml:mi></mml:mstyle><mml:mi>s</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>∈</mml:mo><mml:mo>{</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>m</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> is the <italic>i</italic>-th realization of <italic>X<sub>s</sub></italic> in data <inline-formula><mml:math id="MM83"><mml:mrow><mml:mi mathvariant="script">D</mml:mi><mml:mo>,</mml:mo><mml:mtext> </mml:mtext><mml:msubsup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>X</mml:mi></mml:mstyle><mml:mrow><mml:mi mathvariant="normal">∖</mml:mi><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> denotes the <italic>i</italic>-th realization of the rest of the variables <inline-formula><mml:math id="MM84"><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>V</mml:mi><mml:mi mathvariant="normal">∖</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, and <bold>U</bold>, <bold>Q</bold> and <bold>W</bold> are matrix unknowns. Given latent factor estimates <bold>U</bold> and <bold>W</bold>, and the estimate of node-wise terms <bold>Q</bold>, we determine the neighborhood for node <italic>s</italic> as <inline-formula><mml:math id="MM85"><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="script">N</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:mi>t</mml:mi><mml:mo>∈</mml:mo><mml:mi>V</mml:mi><mml:mi mathvariant="normal">∖</mml:mi><mml:mo>{</mml:mo><mml:mi>s</mml:mi><mml:mo>}</mml:mo><mml:mo>:</mml:mo><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:msubsup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>u</mml:mi></mml:mstyle><mml:mi>s</mml:mi><mml:mi>T</mml:mi></mml:msubsup></mml:mrow></mml:mstyle><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>Q</mml:mi></mml:mstyle><mml:mrow><mml:mi>s</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle><mml:mi>T</mml:mi></mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>Q</mml:mi></mml:mstyle><mml:mrow><mml:mi>t</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>u</mml:mi></mml:mstyle><mml:mi>t</mml:mi></mml:msub><mml:mo>≠</mml:mo><mml:mn>0</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula>. This means that edge (<italic>s</italic>, <italic>t</italic>) is included in the network if product <inline-formula><mml:math id="MM86"><mml:mrow><mml:msubsup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>u</mml:mi></mml:mstyle><mml:mi>s</mml:mi><mml:mi>T</mml:mi></mml:msubsup><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>Q</mml:mi></mml:mstyle><mml:mrow><mml:mi>s</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle><mml:mi>T</mml:mi></mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>Q</mml:mi></mml:mstyle><mml:mrow><mml:mi>t</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>u</mml:mi></mml:mstyle><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> does not vanish over at least one choice of categories <italic>j</italic> and <italic>k</italic>.</p>
  </sec>
  <sec id="SEC3.6">
    <title>3.6 Other exponential family distributions</title>
    <p>So far, we described in Section 3.3–3.5, the Poisson model and the multinomial model that are suitable for separately inferring the edge set of a Poisson or a multinomial Markov network. In this section, we would like to allude to the fact that a procedure with derivations very similar to those in the above sections can be applied to any exponential family distribution.</p>
    <p>From <xref ref-type="disp-formula" rid="btv258-M1">Equation (1)</xref>, we see that the unnormalized probability of an exponential family distribution can be expressed as an exponential of a weighted linear combination of sufficient statistics. These sufficient statistics correspond to clique potential functions (see Sec. 3.1.3). Under the assumption of joint distribution having cliques of size at most two, node-conditional distributions take the form:
<disp-formula><mml:math id="MM87"><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>V</mml:mi><mml:mi mathvariant="normal">∖</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>∝</mml:mo><mml:mi>exp</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mi>B</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mtext>   </mml:mtext><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>∈</mml:mo><mml:mi mathvariant="script">N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:munder><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle><mml:mi>B</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mi>B</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>C</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></disp-formula>
where <inline-formula><mml:math id="MM88"><mml:mrow><mml:mo>{</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>s</mml:mi><mml:mo>∈</mml:mo><mml:mi>V</mml:mi><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="MM89"><mml:mrow><mml:mo>{</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>∈</mml:mo><mml:mi>V</mml:mi><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> are parameters that shall be estimated from the data.</p>
    <p><sc>FuseNet</sc> yields a general framework for including data from any exponential family distribution, such as Gaussian, binomial, Poisson or multinomial distributions, in its predictive model by simply expressing weights <inline-formula><mml:math id="MM90"><mml:mrow><mml:mo>{</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>s</mml:mi><mml:mo>∈</mml:mo><mml:mi>V</mml:mi><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="MM91"><mml:mrow><mml:mo>{</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>∈</mml:mo><mml:mi>V</mml:mi><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> of a given distribution as products of <italic>appropriately</italic> selected latent factors. Here, factorization of the weights is <italic>appropriate</italic> if it allows fusion of data from diverse distributions, such that factorization consists of both latent factors that are shared between different distributions and factors that are specific to a particular distribution (<xref rid="btv258-B37" ref-type="bibr">Žitnik and Zupan, 2015</xref>), a property that we describe in the following section.</p>
  </sec>
  <sec id="SEC3.7">
    <title>3.7 Collective inference of a gene network</title>
    <p>We proceed by formulating a collective network inference model, wherein a network is jointly estimated from multiple nonidentical data distributions.</p>
    <p>Let <inline-formula><mml:math id="MM92"><mml:mrow><mml:msub><mml:mi mathvariant="script">D</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>x</mml:mi></mml:mstyle><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>x</mml:mi></mml:mstyle><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>x</mml:mi></mml:mstyle><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> be a set of <italic>n<sub>x</sub></italic> observations of a random vector <italic>X</italic>, where each <italic>p</italic>-dimensional vector <inline-formula><mml:math id="MM93"><mml:mrow><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>x</mml:mi></mml:mstyle><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> is drawn from a distribution <italic>P<sub>x</sub></italic> of the form of <xref ref-type="disp-formula" rid="btv258-M4">Equation (4)</xref> and let <inline-formula><mml:math id="MM94"><mml:mrow><mml:msub><mml:mi mathvariant="script">D</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>y</mml:mi></mml:mstyle><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>y</mml:mi></mml:mstyle><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>y</mml:mi></mml:mstyle><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> be a set of <italic>n<sub>y</sub></italic> observations where each <italic>p</italic>-dimensional vector <inline-formula><mml:math id="MM95"><mml:mrow><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>y</mml:mi></mml:mstyle><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> is drawn from distribution <italic>P<sub>y</sub></italic> of the form of <xref ref-type="disp-formula" rid="btv258-M4">Equation (4)</xref>. Importantly, distributions <italic>P<sub>x</sub></italic> and <italic>P<sub>y</sub></italic> are not necessarily identical in terms of their parameters or distribution type. For example, <italic>P<sub>x</sub></italic> might denote the Poisson distribution and <italic>P<sub>y</sub></italic> might be the multinomial distribution or they could both describe multinomial distributions that have different parameters. For simplicity of notation we provide here the formulation for the case with only two datasets, <inline-formula><mml:math id="MM96"><mml:mrow><mml:msub><mml:mi mathvariant="script">D</mml:mi><mml:mi>x</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="MM97"><mml:mrow><mml:msub><mml:mi mathvariant="script">D</mml:mi><mml:mi>y</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, but notice that our analysis generalizes to any number of datasets.</p>
    <p>In collective network inference, we solve for:
<disp-formula id="btv258-M13"><label>(13)</label><mml:math id="MM98"><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:munder><mml:mrow><mml:mi>min</mml:mi><mml:mo>⁡</mml:mo></mml:mrow><mml:mrow><mml:mover><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>U</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>Q</mml:mi></mml:mstyle><mml:mi>x</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>Q</mml:mi></mml:mstyle><mml:mi>y</mml:mi></mml:msub><mml:mo>,</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle><mml:mi>x</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle><mml:mi>y</mml:mi></mml:msub></mml:mrow></mml:mover></mml:mrow></mml:munder></mml:mstyle><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mo>∈</mml:mo><mml:mi>V</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>ℓ</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mo>;</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mi>x</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo></mml:mrow></mml:mstyle><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>U</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>Q</mml:mi></mml:mstyle><mml:mi>x</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle><mml:mi>x</mml:mi></mml:msub><mml:mo>;</mml:mo><mml:msub><mml:mi mathvariant="script">D</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>+</mml:mo><mml:msub><mml:mi>ℓ</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mo>;</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mi>y</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>U</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>Q</mml:mi></mml:mstyle><mml:mi>y</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle><mml:mi>y</mml:mi></mml:msub><mml:mo>;</mml:mo><mml:msub><mml:mi mathvariant="script">D</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mtext>reg</mml:mtext><mml:mo>.</mml:mo><mml:mtext> param</mml:mtext><mml:mo>.</mml:mo><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>
where regularization parameters depend on the form of data distributions. In a specific scenario in which <italic>P<sub>x</sub></italic> and <italic>P<sub>y</sub></italic> are the Poisson and the multinomial distributions, respectively, we set <inline-formula><mml:math id="MM99"><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>Q</mml:mi></mml:mstyle><mml:mi>x</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>I</mml:mi></mml:mstyle></mml:mrow></mml:math></inline-formula>. We specify the regularization according to the Poisson model in <xref ref-type="disp-formula" rid="btv258-M8">Equation (8)</xref> and the multinomial model in <xref ref-type="disp-formula" rid="btv258-M11">Equation (11)</xref> as:
<disp-formula><mml:math id="MM100"><mml:mrow><mml:mi>λ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mtext> Reg </mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>U</mml:mi></mml:mstyle><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mtext> Reg </mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle><mml:mi>x</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mtext> Reg </mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>Q</mml:mi></mml:mstyle><mml:mi>y</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mtext> Reg </mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle><mml:mi>y</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>
where <inline-formula><mml:math id="MM101"><mml:mrow><mml:mtext> Reg</mml:mtext></mml:mrow></mml:math></inline-formula> is the elastic net penalty defined in Section 3.3. The estimated neighborhood of node <italic>s</italic>, which corresponds to a random variable <inline-formula><mml:math id="MM102"><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:mi>X</mml:mi></mml:mrow></mml:math></inline-formula>, are then nodes whose behavior depends on behavior of <italic>s</italic> according to any of considered data distributions, <inline-formula><mml:math id="MM103"><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="script">N</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:mi>t</mml:mi><mml:mo>∈</mml:mo><mml:mi>V</mml:mi><mml:mi mathvariant="normal">∖</mml:mi><mml:mo>{</mml:mo><mml:mi>s</mml:mi><mml:mo>}</mml:mo><mml:mo>:</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>θ</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mo>;</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mi>x</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo>≠</mml:mo><mml:mn>0</mml:mn><mml:mo>⋁</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>θ</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mo>;</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mi>y</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo>≠</mml:mo><mml:mn>0</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula>. In our specific scenario, parameters <inline-formula><mml:math id="MM104"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>θ</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mo>;</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mi>x</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="MM105"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>θ</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mo>;</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mi>y</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> would be given by <inline-formula><mml:math id="MM106"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>θ</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mo>;</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mi>x</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>u</mml:mi></mml:mstyle><mml:mi>s</mml:mi><mml:mi>T</mml:mi></mml:msubsup><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle><mml:mi>T</mml:mi></mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>u</mml:mi></mml:mstyle><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="MM107"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>θ</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mo>;</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mi>y</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mstyle displaystyle="false"><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:msubsup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>u</mml:mi></mml:mstyle><mml:mi>s</mml:mi><mml:mi>T</mml:mi></mml:msubsup></mml:mrow></mml:mstyle><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle><mml:mi>T</mml:mi></mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>u</mml:mi></mml:mstyle><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>.</p>
    <p>It is important to notice the coupling of the parameters in <sc>FuseNet</sc> through which data fusion is achieved (<xref rid="btv258-B37" ref-type="bibr">Žitnik and Zupan, 2015</xref>). As is evident from <xref ref-type="disp-formula" rid="btv258-M13">Equation (13)</xref>, the latent factor of node <italic>s</italic>, <inline-formula><mml:math id="MM108"><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>u</mml:mi></mml:mstyle><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, participates both in terms associated with <italic>P<sub>x</sub></italic> and terms related to <italic>P<sub>y</sub></italic>. Hence, a good estimate of <inline-formula><mml:math id="MM109"><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>u</mml:mi></mml:mstyle><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> should simultaneously minimize both <inline-formula><mml:math id="MM110"><mml:mrow><mml:msub><mml:mi>ℓ</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mo>;</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mi>x</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="MM111"><mml:mrow><mml:msub><mml:mi>ℓ</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mo>;</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mi>y</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, but should do so in a way that statistics internal to both data distributions are considered. To account for the fact that datasets may disagree and differ in how accurately they capture biological signals, <sc>FuseNet</sc> has parameters that are specific to every distribution. In particular, we allow that interactions between latent components in <inline-formula><mml:math id="MM112"><mml:mrow><mml:msub><mml:mi mathvariant="script">D</mml:mi><mml:mi>x</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> are different from those in <inline-formula><mml:math id="MM113"><mml:mrow><mml:msub><mml:mi mathvariant="script">D</mml:mi><mml:mi>y</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and hence, the model has one latent matrix <bold>W</bold> for each distribution. An additional parameter <bold>Q</bold> captures the characteristics of a particular exponential family distribution, <italic>e.g.</italic>, the bias associated with <italic>m</italic> categories in the multinomial distribution.</p>
  </sec>
  <sec id="SEC3.8">
    <title>3.8 Learning the models in practice</title>
    <p>Now that we defined the <sc>FuseNet</sc> model, we explain how to solve related optimization problems. Notice that the exact optimization problem one needs to solve depends on a particular data setting, i.e. a particular combination of considered exponential family distributions.</p>
    <p>There has been a strong line of work on developing fast algorithms to solve sparse regression problems that are similar to <xref ref-type="disp-formula" rid="btv258-M8">Equations (8)</xref> and <xref ref-type="disp-formula" rid="btv258-M11">(11)</xref> including the work by <xref rid="btv258-B16" ref-type="bibr">Krishnapuram <italic>et al.</italic> (2005)</xref>, <xref rid="btv258-B20" ref-type="bibr">Meier <italic>et al.</italic> (2008)</xref>, <xref rid="btv258-B14" ref-type="bibr">Jalali <italic>et al.</italic> (2011)</xref> and <xref rid="btv258-B2" ref-type="bibr">Allen and Liu (2013)</xref>. Existing algorithms for undirected graphical model selection assume that model parameters are independent of each other. This, however, is not true in <sc>FuseNet</sc> due to reasons discussed in Section 3.7 that are important to achieve data fusion. Consequently, this also means that we cannot use off-the-shelf optimization solvers.</p>
    <p>We propose to fit our <sc>FuseNet</sc> by computing cyclical coordinate descent along the path of regularization parameter <italic>λ</italic> (see <ext-link ext-link-type="uri" xlink:href="http://bioinformatics.oxfordjournals.org/lookup/suppl/doi:10.1093/bioinformatics/btv258/-/DC1">Supplementary Section 1</ext-link>). Parameters of <sc>FuseNet</sc> inference algorithm, i.e. regularization and latent dimensionality, are selected in data-dependent way via stability selection. Interested reader is referred to <ext-link ext-link-type="uri" xlink:href="http://bioinformatics.oxfordjournals.org/lookup/suppl/doi:10.1093/bioinformatics/btv258/-/DC1">Supplementary Section 1</ext-link>.</p>
  </sec>
  <sec id="SEC4">
    <title>4 Experimental setup</title>
    <p>We compare the performance of <sc>FuseNet</sc> to several state-of-the-art Markov network models in estimating the true underlying network structure.</p>
    <sec id="SEC4.1">
      <title>4.1 Performance evaluation</title>
      <p>The success of network recovery is evaluated by comparison to the gold standard networks, when they are available, and by functional enrichment of the inferred networks.</p>
      <sec id="SEC4.1.1">
        <title>4.1.1 Assessing the accuracy of network recovery</title>
        <p>Simulated data come with complete and unambiguous true underlying networks, hence we can assess the performance of the algorithms as follows. We report receiver operator curves (ROC) computed by varying the regularization parameter <italic>λ</italic>, precision recall (PR) curves, and true and false positive rates for fixed <italic>λ</italic> as estimated via stability selection. The true positive rate is estimated as proportion of the edges found by a network inference algorithm that are also in the true network. The false positive rate represents proportion of the edges in the inferred network that are not present in the true network. An algorithm with a perfect performance achieves an area under the ROC curve of 1, precision of 1 and recall of 1, a true positive rate of 1 and a false positive rate of 0.</p>
      </sec>
      <sec id="SEC4.1.2">
        <title>4.1.2 Quantifying the functional content of inferred networks</title>
        <p>We employ two approaches to evaluate the ‘functional correctness’ of the networks inferred from cancer data. First, we use SANTA (<xref rid="btv258-B6" ref-type="bibr">Cornish and Markowetz, 2014</xref>) to quantify the strength of association between sets of functionally related genes from the Gene Ontology (GO) (<xref rid="btv258-B4" ref-type="bibr">Ashburner <italic>et al.</italic>, 2000</xref>) and the inferred network. Second, we overlay the inferred network with gene information from the GO and for every GO term assess how community-like a subnetwork of genes that belong to a particular GO term is. Communities are sets of genes with many connections between the members and few connections to the rest of the network. Four different structural notions of network communities exist in networks and we report the values of their representative scoring functions (<xref rid="btv258-B43" ref-type="bibr">Yang and Leskovec, 2012</xref>). We refer the reader to <ext-link ext-link-type="uri" xlink:href="http://bioinformatics.oxfordjournals.org/lookup/suppl/doi:10.1093/bioinformatics/btv258/-/DC1">Supplementary Section 4</ext-link> for mathematical details.</p>
      </sec>
    </sec>
    <sec id="SEC4.2">
      <title>4.2 Considered gene network inference algorithms</title>
      <p>In the experiments, we consider the Poisson <sc>FuseNet</sc> (Section 3.3), the multinomial <sc>FuseNet</sc> (Section 3.5) and <sc>FuseNet</sc> with fusion of Poisson and multinomial data distributions (Section 3.7). We compare our models to the Graphical Lasso (GLASSO) (<xref rid="btv258-B9" ref-type="bibr">Friedman <italic>et al.</italic>, 2007</xref>), which is a widely used Markov network model based on a Gaussian assumption. To see how <sc>FuseNet</sc> relates to techniques that perform data preprocessing, we consider the GLASSO after applying a log transform to the data plus one (e.g. cf. <xref rid="btv258-B11" ref-type="bibr">Gallopin <italic>et al.</italic>, 2013</xref>) and the GLASSO with the nonparanormal Gaussian copula transformation (NPN-Copula) (<xref rid="btv258-B18" ref-type="bibr">Liu <italic>et al.</italic>, 2009</xref>). We also compare <sc>FuseNet</sc> with two Markov network models that are designed for non-Gaussian distributed data: the Local Poisson Graphical Model (LPGM) (<xref rid="btv258-B2" ref-type="bibr">Allen and Liu, 2013</xref>), and the Multinomial Markov Network Model (Mult-GM) (<xref rid="btv258-B14" ref-type="bibr">Jalali <italic>et al.</italic>, 2011</xref>). The crucial parameter of these methods is degree of regularization, which controls sparsity of the networks. We select the value for regularization via stability selection (see <ext-link ext-link-type="uri" xlink:href="http://bioinformatics.oxfordjournals.org/lookup/suppl/doi:10.1093/bioinformatics/btv258/-/DC1">Supplementary Section 1</ext-link>).</p>
    </sec>
  </sec>
  <sec id="SEC5">
    <title>5 Data</title>
    <p>Network inference algorithms are evaluated based on simulated data and large-scale cancer genomic datasets.</p>
    <sec id="SEC5.1">
      <title>5.1 Multivariate data simulation</title>
      <p>Four network structures are simulated: (i) the Erdős Rényi random network, where an edge between each pair of nodes is set with equal probability and independently of other edges; (ii) a hub network, where each node is connected to one of three hub nodes; (iii) a scale-free network, in which node degree distribution follows a power-law; and (iv) a small-world network, in which most nodes are not neighbors of each other but most nodes can be reached from every other by a small number of hops. We refer the reader to <ext-link ext-link-type="uri" xlink:href="http://bioinformatics.oxfordjournals.org/lookup/suppl/doi:10.1093/bioinformatics/btv258/-/DC1">Supplementary Section 2</ext-link> for detailed description of the procedures used for data simulation.</p>
    </sec>
    <sec id="SEC5.2">
      <title>5.2 Cancer genomic data</title>
      <p>We apply network inference algorithms to two examples of non-Gaussian high-throughput genomic data to learn (i) an mRNA expression network, (ii) a somatic mutation network and (iii) a collectively inferred gene network based on both data types.</p>
      <p>We download breast cancer (BRCA-US) gene expression data measured by next generation sequencing and breast cancer (BRCA-US) simple somatic mutation data from the International Cancer Genome Consortium (ICGC) (<xref rid="btv258-B12" ref-type="bibr">Hudson <italic>et al.</italic>, 2010</xref>) portal (release 17). We follow the steps in <xref rid="btv258-B2" ref-type="bibr">Allen and Liu (2013)</xref> and process RNA-sequencing data to be approximately Poisson. Data preprocessing, whose detailed steps are described in <ext-link ext-link-type="uri" xlink:href="http://bioinformatics.oxfordjournals.org/lookup/suppl/doi:10.1093/bioinformatics/btv258/-/DC1">Supplementary Section 3</ext-link>, results in a matrix with rows as the subjects (<inline-formula><mml:math id="MM114"><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mtext>exp</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>012</mml:mn></mml:mrow></mml:math></inline-formula>) and columns as genes (<inline-formula><mml:math id="MM115"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mtext>exp</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>657</mml:mn></mml:mrow></mml:math></inline-formula>). These genes form the nodes of our Poisson breast cancer mRNA network.</p>
      <p>Breast cancer simple somatic mutation data include single base substitutions, multiple base substitutions and short indels. Mutation data are converted into a matrix with rows as subjects (<inline-formula><mml:math id="MM116"><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mtext>mut</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>954</mml:mn></mml:mrow></mml:math></inline-formula>) and columns as genes containing mutations or variations (500 genes). Each matrix entry is categorized into one of three groups based on the type of mutation: no mutation, single base substitution, insertion/deletion of &lt; 200 base pairs.</p>
      <p>For the collectively inferred network, we consider both gene expression profiles and somatic mutation data provided by the ICGC assuming the Poisson model for the RNA-seq data and the multinomial model for the mutation data. We refer the reader to <ext-link ext-link-type="uri" xlink:href="http://bioinformatics.oxfordjournals.org/lookup/suppl/doi:10.1093/bioinformatics/btv258/-/DC1">Supplementary Section 3</ext-link> for more details.</p>
    </sec>
  </sec>
  <sec>
    <title>6 Results and discussion</title>
    <sec id="SEC6.1">
      <title>6.1 Network recovery with simulated data</title>
      <p>In every simulation, we generated a dataset of observations based on a simulated network and then applied different network inference algorithms to determine whether the algorithms successfully recovered complex relationships between data variables.</p>
      <p>We simulated four network types, which are known to resemble the structure of real biological networks (<xref rid="btv258-B2" ref-type="bibr">Allen and Liu, 2013</xref>; <xref rid="btv258-B7" ref-type="bibr">Costanzo <italic>et al.</italic>, 2010</xref>). We report receiver operator curves computed by varying the regularization parameter <italic>λ</italic> in <xref ref-type="fig" rid="btv258-F3">Figure 3</xref> and <ext-link ext-link-type="uri" xlink:href="http://bioinformatics.oxfordjournals.org/lookup/suppl/doi:10.1093/bioinformatics/btv258/-/DC1">Supplementary Figure S4</ext-link>, boxplots of true and false positive rates for fixed <italic>λ</italic> as determined by stability selection in <xref ref-type="fig" rid="btv258-F3">Figure 3</xref>, <ext-link ext-link-type="uri" xlink:href="http://bioinformatics.oxfordjournals.org/lookup/suppl/doi:10.1093/bioinformatics/btv258/-/DC1">Supplementary Figures S2</ext-link> and <ext-link ext-link-type="uri" xlink:href="http://bioinformatics.oxfordjournals.org/lookup/suppl/doi:10.1093/bioinformatics/btv258/-/DC1">S4</ext-link>. Further, we evaluated precision and recall of the networks estimated from different data distributions in <ext-link ext-link-type="uri" xlink:href="http://bioinformatics.oxfordjournals.org/lookup/suppl/doi:10.1093/bioinformatics/btv258/-/DC1">Supplementary Figures S2–S5</ext-link>.</p>
      <p>Experimental evidence indicates that <sc>FuseNet</sc> outperforms Gaussian-based competitors (GLASSO, Log-GLASSO and NPN-Copula) as well as existing methods that are designed specifically for the Poisson and the multinomial data (LPGM in <xref ref-type="fig" rid="btv258-F2">Fig. 2</xref> and Mult-GM in <xref ref-type="fig" rid="btv258-F3">Fig. 3</xref>). The overall good performance of <sc>FuseNet</sc> is consistent across the four types of network structure and the two data distributions that we considered in experiments.
<fig id="btv258-F2" position="float"><label>Fig. 2.</label><caption><p>Application of gene network inference algorithms to multinomial-distributed simulated data. Simulation studies on four network types were performed: random (see <ext-link ext-link-type="uri" xlink:href="http://bioinformatics.oxfordjournals.org/lookup/suppl/doi:10.1093/bioinformatics/btv258/-/DC1">Supplementary Fig. S2</ext-link>), hub, scale-free and small world. For each graph type, we generated <italic>n</italic> = 300 observations at a high signal-to-noise ratio (SNR) with <italic>P</italic> = 50 variables (nodes) taking values from an alphabet of size <italic>m</italic> = 3. Boxplots are shown for multinomial <sc>FuseNet</sc> (proposed here) and the multinomial graphical model (Mult-GM) (<xref rid="btv258-B14" ref-type="bibr">Jalali <italic>et al.</italic>, 2011</xref>)</p></caption><graphic xlink:href="btv258f2p"/></fig>
<fig id="btv258-F3" position="float"><label>Fig. 3.</label><caption><p>Application of gene network inference algorithms to Poisson-distributed simulated data. Simulation studies on four network types were performed: random (see <ext-link ext-link-type="uri" xlink:href="http://bioinformatics.oxfordjournals.org/lookup/suppl/doi:10.1093/bioinformatics/btv258/-/DC1">Supplementary Fig. S4</ext-link>), hub, scale-free and small world. These graph structures appear in many real biological networks. For each graph type, we generated data with <italic>n</italic> = 200 observations with <italic>P</italic> = 100 variables (nodes) at a low (first row) and high (second row) signal-to-noise ratio (SNR). Receiver operating curves and boxplots are shown for Poisson <sc>FuseNet</sc> (proposed here), the Local Poisson Graphical Model (LPGM) (<xref rid="btv258-B2" ref-type="bibr">Allen and Liu, 2013</xref>), the Graphical Lasso (GLASSO) (<xref rid="btv258-B9" ref-type="bibr">Friedman <italic>et al.</italic>, 2007</xref>), the GLASSO on log-transformed data (Log-GLASSO) (e.g. cf. <xref rid="btv258-B11" ref-type="bibr">Gallopin <italic>et al.</italic>, 2013</xref>) and the GLASSO on data transformed through nonparanormal Gaussian copula (NPN-Copula) (<xref rid="btv258-B18" ref-type="bibr">Liu <italic>et al.</italic>, 2009</xref>)</p></caption><graphic xlink:href="btv258f3p"/></fig>
</p>
      <p>The improved statistical power of <sc>FuseNet</sc> and LPGM over methods that during network inference rely heavily on the assumption of normality is particularly impressive. Results in <xref ref-type="fig" rid="btv258-F3">Figure 3</xref> suggest that in situations where this assumption is not satisfied, we can expect reduced prediction performance if we naively apply Gaussian-based methods, (GLASSO) or if we perform insufficient data preprocessing (Log-GLASSO). However, we note that sophisticated techniques that replace Gaussian distributed data by the transformed data obtained, e.g. through a semiparametric Gaussian copula (NPN-Copula; <xref rid="btv258-B18" ref-type="bibr">Liu <italic>et al.</italic> (2009)</xref>), can give substantial gains in accuracy over the naive analysis. These observations are not surprising as disregarding information about data distribution can adversely affect performance of prediction models. Our results demonstrate that employing the ‘correct’ statistical model, in this case <sc>FuseNet</sc> or LPGM, can lead to more accurate network inference.</p>
      <p>Next, we try to understand which algorithmic component of <sc>FuseNet</sc> contributes most to its good performance relative to existing algorithms for network structure learning. The primary difference between <sc>FuseNet</sc> and non-Gaussian-based methods considered here, LPGM and Mult-GM, is representation of model parameters with products of latent factors. In LPGM and similarly in Mult-GM, a prediction model is fitted locally by an algorithm, which performs a series of independent penalized regressions. This is in contrast with <sc>FuseNet</sc>, where different model parameters are not entirely independent of each other but rather rely on borrowing strength from each other via factorization. Our results on simulated data suggest that representation of model parameters through the use of latent factors is beneficial. Furthermore, latent parameterization can improve performance of network recovery beyond what is possible with models that do not use latent factors. On the downside, we note that due to coupling of model parameters, <sc>FuseNet</sc> is not trivially parallelizable, which is otherwise true for LPGM and Mult-GM.</p>
      <p>Results shown in <xref ref-type="fig" rid="btv258-F2">Figures 2</xref> and <xref ref-type="fig" rid="btv258-F3">3</xref> are reported for datasets with a few hundred observations (<italic>n</italic>) and a few tens of variables (<italic>p</italic>; see figure captions). We note that reported results are consistent with experiments done in various high-dimensional scenarios even when the number of variables is greater than the number of observations (<italic>p</italic> &gt; <italic>n</italic>). Results therein reveal the same trend, namely, the overall strong performance of <sc>FuseNet</sc> in recovering true networks from non-Gaussian data.</p>
    </sec>
    <sec id="SEC6.2">
      <title>6.2 Functional content of genomic networks</title>
      <p>An important challenge in cancer systems biology is to uncover complex dependencies between genes implicated in cancer. Since our knowledge about genome-scale gene networks is incomplete and only a few functional modules are known for higher organisms (<xref rid="btv258-B28" ref-type="bibr">Rolland <italic>et al.</italic>, 2014</xref>), our aim is to quantify associations between the inferred gene networks and known cellular functions and phenotypes, and to assess the significance of these associations.</p>
      <sec id="SEC6.2.1">
        <title>6.2.1 Comparison of <sc>FuseNet</sc> variants with existing methods</title>
        <p>To characterize how functionally informative the inferred networks are, we employ four structural definitions of network communities (<xref ref-type="fig" rid="btv258-F4">Fig. 4</xref> and <ext-link ext-link-type="uri" xlink:href="http://bioinformatics.oxfordjournals.org/lookup/suppl/doi:10.1093/bioinformatics/btv258/-/DC1">Supplementary Figs S6</ext-link> and <ext-link ext-link-type="uri" xlink:href="http://bioinformatics.oxfordjournals.org/lookup/suppl/doi:10.1093/bioinformatics/btv258/-/DC1">S7</ext-link>). These represent four possible notions of association between a given GO term and the inferred network (<xref rid="btv258-B43" ref-type="bibr">Yang and Leskovec, 2012</xref>). The triangle participation ratio quantifies how well genes that are members of a given GO term are linked to each other in the inferred network. The cut ratio captures the abundance of external connectivity, i.e. edges between genes of a GO term and the rest of the network, whereas conductance and flake-ODF consider both internal and external network connectivity. Through these four measures we are able to estimate the overall concordance of inferred gene networks and known functional annotation of genes. For these reasons, networks that score higher on many measures should be considered more informative across a wider spectrum of cellular functions.
<fig id="btv258-F4" position="float"><label>Fig. 4.</label><caption><p>The strength of association between gene sets from the Gene Ontology (GO) and networks inferred with <sc>FuseNet</sc>. Inferred networks were overlaid with GO terms and subnetworks induced by each GO term were assessed for how well they corresponded to network communities. Four different scoring functions were used to quantify the presence of different structural notions of communities (<ext-link ext-link-type="uri" xlink:href="http://bioinformatics.oxfordjournals.org/lookup/suppl/doi:10.1093/bioinformatics/btv258/-/DC1">Supplementary Section S4</ext-link>) that can appear in biological networks: flake-over-median-degree (flake-ODF), cut ratio, triangle participation ratio (TPR) and conductance. Considering breast cancer RNA-sequencing (RNA-seq) and somatic mutation data (Mut), these boxplots show the gains that fusion of data from different distributions (Mut &amp; RNA-seq) can offer over network inference from any dataset alone, either RNA-seq or Mut. Poisson <sc>FuseNet</sc> was used with RNA-sequencing data, multinomial <sc>FuseNet</sc> with somatic mutation data and fully-specified <sc>FuseNet</sc> for joint consideration of RNA-sequencing and mutation data</p></caption><graphic xlink:href="btv258f4p"/></fig>
</p>
        <p><xref ref-type="fig" rid="btv258-F4">Figure 4</xref> shows that gene network inferred by <sc>FuseNet</sc> through fusion of breast cancer RNA-sequencing data and somatic mutation data is more concordant with functional annotation data in the GO than are networks inferred by <sc>FuseNet</sc> from either RNA-sequencing or somatic mutation data alone. We note that we used Poisson <sc>FuseNet</sc> to infer network from RNA-sequencing data, multinomial <sc>FuseNet</sc> to infer network from somatic mutation data and collective <sc>FuseNet</sc> for joint network inference from RNA-sequencing and mutation data. These results demonstrate that combining data through the use of latent factors can perform better than independent modeling of each dataset alone.</p>
        <p>For each of the four community scoring measures in <xref ref-type="fig" rid="btv258-F4">Figure 4</xref>, we compared score distributions of GO terms across three networks inferred by <sc>FuseNet</sc> using Kolmogorov-Smirnov tests. We concluded that the network inferred by <sc>FuseNet</sc> through fusion of RNA-sequencing and mutation data associates with GO significantly more strongly than the other two networks (<italic>P</italic> value &lt; 1 × 10<sup>−5</sup> on all four measures from <xref ref-type="fig" rid="btv258-F4">Fig. 4</xref>). This experiment shows how cancer genomic data provide different levels of information about cellular machinery, highlighting that it is possible to infer a network that better explains the mechanisms of cancer by combining multiple datasets in a principled statistical way.</p>
        <p>We further compared <sc>FuseNet</sc> to existing network inference methods on cancer data. The comparison was made only with LPGM, as this was the best performing method in our study on simulated data (Section 6.1) and in the cancer-data study of <xref rid="btv258-B2" ref-type="bibr">Allen and Liu (2013)</xref>. <ext-link ext-link-type="uri" xlink:href="http://bioinformatics.oxfordjournals.org/lookup/suppl/doi:10.1093/bioinformatics/btv258/-/DC1">Supplementary Figure S6</ext-link> shows the functional content of the networks inferred from RNA-sequencing data by either Poisson <sc>FuseNet</sc> or LPGM. On a related note, <ext-link ext-link-type="uri" xlink:href="http://bioinformatics.oxfordjournals.org/lookup/suppl/doi:10.1093/bioinformatics/btv258/-/DC1">Supplementary Figure S7</ext-link> shows enrichment of the networks inferred from somatic mutation data by either multinomial <sc>FuseNet</sc> or Mult-GM. Notice that LPGM and Mult-GM were designed for data that are approximately Poisson distributed, such as measurements from RNA-sequencing, and multinomially distributed, such as various types of gene variations, respectively. These results demonstrate that networks inferred by <sc>FuseNet</sc> can better capture known GO annotations than networks obtained by methods such as LPGM and Mult-GM, whose prediction models do not have factorized representation. These observations are consistent across four complementary structural definitions of GO terms, where every GO term is viewed as a network community defined by its member genes.</p>
      </sec>
      <sec id="SEC6.2.2">
        <title>6.2.2 Networks via breast cancer data</title>
        <p>We employ SANTA (<xref rid="btv258-B6" ref-type="bibr">Cornish and Markowetz, 2014</xref>) to quantify the functional content of gene networks. SANTA extends the concept of gene set enrichment analysis to networks. We observed that GO terms indeed cluster more strongly on Poisson <sc>FuseNet</sc>’s networks than on networks inferred by GLASSO and Log-GLASSO (<italic>P</italic> value &lt; 1 × 10<sup>−6</sup>, RNA-seq network), NPN-Copula (<italic>P</italic> value &lt; 1 × 10<sup>−</sup><sup>5</sup>, RNA-seq network) and LPGM (<italic>P</italic> value &lt; 1 × 10<sup>−4</sup>, RNA-seq network). These results suggest that network edges inferred by <sc>FuseNet</sc> might represent more accurate indication of shared cellular functions than edges inferred by other considered methods. This effect was independent of the GO term size and was strongest for specific cellular functions such as ‘centrosome cycle’ (<italic>P</italic> value &lt; 1 × 10<sup>−9</sup>), ‘cellular response to DNA damage stimulus’ (<italic>P</italic> value &lt; 1 × 10<sup>−9</sup>), ‘apoptotic process’ (<italic>P</italic> value &lt; 1 × 10<sup>−9</sup>) and ‘regulation of cytokinesis’ (<italic>P</italic> value &lt; 1 × 10<sup>−8</sup>). We observed similar results when inferring networks from somatic mutation data. Gene network inferred by multinomial <sc>FuseNet</sc> was functionally richer than network inferred by Mult-GM. Here, the functional content of a network was quantified with SANTA as proportion of evaluated GO terms whose association strength with the network had <italic>P</italic> value &lt; 1 × 10<sup>−5</sup>.</p>
        <p>Interactions that are captured by fusing both cancer related datasets recovered many gene–gene associations that have been previously linked to increased breast cancer predisposition and metastasis. For example, <sc>FuseNet</sc> revealed a hypothesized transcriptional regulatory <italic>GATA3</italic> module (<xref rid="btv258-B39" ref-type="bibr">Wang <italic>et al.</italic>, 2014</xref>) consisting of fully connected <italic>GATA3</italic>, <italic>PTCH1</italic>, <italic>NFIB</italic> and <italic>PPARA</italic>. <italic>GATA3</italic> is an important transcriptional regulator in breast cancer (<xref rid="btv258-B33" ref-type="bibr">Theodorou <italic>et al.</italic>, 2013</xref>), and low expression levels of <italic>GATA3</italic> are associated with a poor prognosis (<xref rid="btv258-B1" ref-type="bibr">Albergaria <italic>et al.</italic>, 2009</xref>). It has been shown by <xref rid="btv258-B39" ref-type="bibr">Wang <italic>et al.</italic> (2014)</xref> that <italic>PTCH1</italic>, <italic>PPARA</italic> and <italic>NFIB</italic> exhibit epistatic interactions with <italic>GATA3</italic>, have negatively correlated expression levels with <italic>GATA3</italic> and that <italic>GATA3</italic> binds to gene regions near <italic>NFIB</italic>, <italic>PTCH1</italic> and <italic>PPARA</italic> in breast epithelial tumor cell line.</p>
        <p>Other interactions identified in our network include <italic>ATM</italic> and <italic>BRCA1</italic>, <italic>ATM</italic> and <italic>BRCA2</italic>, and <italic>CHEK2</italic> and <italic>BRCA2</italic>, which are known gene-gene interactions whose mutations affect breast cancer susceptibility (<xref rid="btv258-B34" ref-type="bibr">Turnbull <italic>et al.</italic>, 2012</xref>).</p>
        <p>Another transcriptional module that was found by <sc>FuseNet</sc> consists of <italic>FLI1</italic>, <italic>JAK2</italic> and <italic>CCND2</italic>. This module has been only recently associated with breast cancer patient outcome (<xref rid="btv258-B39" ref-type="bibr">Wang <italic>et al.</italic>, 2014</xref>). Interestingly, <italic>FLI1</italic> module has been captured by <sc>FuseNet</sc> when fusing RNA-sequencing and mutation data but has been missed when using <sc>FuseNet</sc> with any of the two cancer datasets in isolation, as well as by any other inference algorithm considered in this study. One possible explanation for the latter result might be observations made by <xref rid="btv258-B39" ref-type="bibr">Wang <italic>et al.</italic> (2014)</xref>. Wang <italic>et al.</italic> examined The Cancer Genome Atlas breast cancer patient survival data and found that low expression <italic>or</italic> mutation in one or more members of the <italic>FLI1</italic> module is associated with reduced overall survival time in all patients. The illustrative example of <italic>FLI1</italic> module highlights an advantage of <sc>FuseNet</sc> over methods considering a single dataset during network inference.</p>
      </sec>
    </sec>
  </sec>
  <sec>
    <title>7 Conclusion</title>
    <p><sc>FuseNet</sc> is an approach for automatic inference of gene networks from data arising from potentially many nonidentical distributions. It is based on the theory of Markov networks, where the inferred network edges denote a type of direct dependence that is stronger than merely correlated measurements. An appealing property of <sc>FuseNet</sc> is its ability to estimate network edges by fusing potentially many datasets. In the case studies, <sc>FuseNet</sc>’s models outperform several state-of-the-art undirected graphical models. We show that <sc>FuseNet</sc>’s high performance is attributed to the ability to model non-Gaussian distributions and fusion of data through sharing of latent representations. Our work here has broadened the class of off-the-shelf network inference algorithms for simultaneously considering a wide range of parametric distributions and has combined Markov network inference with data fusion.</p>
  </sec>
  <sec>
    <title>Funding</title>
    <p>This work was supported by <funding-source>ARRS</funding-source> (<award-id>P2-0209, J2-5480</award-id>), <award-id>EU FP7</award-id> (<award-id>Health-F5-2010-242038</award-id>) and <funding-source>NIH</funding-source> (<award-id>P01-HD39691</award-id>).</p>
    <p><italic>Conflict of Interest</italic>: none declared.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material id="PMC_1" content-type="local-data">
      <caption>
        <title>Supplementary Data</title>
      </caption>
      <media mimetype="text" mime-subtype="html" xlink:href="supp_31_12_i230__index.html"/>
      <media xlink:role="associated-file" mimetype="application" mime-subtype="pdf" xlink:href="supp_btv258_Zupan_280_sup_1.pdf"/>
    </supplementary-material>
  </sec>
</body>
<back>
  <ref-list>
    <title>References</title>
    <ref id="btv258-B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Albergaria</surname><given-names>A.</given-names></name><etal/></person-group><italic>.</italic> (<year>2009</year>) 
<article-title>Expression of FOXA1 and GATA3 in breast cancer: the prognostic significance in hormone receptor-negative tumours</article-title>. <source>Breast Cancer Res.</source><italic>,</italic>
<volume>11</volume>, <fpage>R40</fpage>.<pub-id pub-id-type="pmid">19549328</pub-id></mixed-citation>
    </ref>
    <ref id="btv258-B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Allen</surname><given-names>G.I.</given-names></name><name><surname>Liu</surname><given-names>Z.</given-names></name></person-group> (<year>2013</year>) 
<article-title>A local poisson graphical model for inferring networks from sequencing data</article-title>. <source>IEEE Trans. NanoBiosci.</source><italic>,</italic>
<volume>12</volume>, <fpage>189</fpage>–<lpage>198</lpage>.</mixed-citation>
    </ref>
    <ref id="btv258-B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Anjum</surname><given-names>S.</given-names></name><etal/></person-group><italic>.</italic> (<year>2009</year>) 
<article-title>A boosting approach to structure learning of graphs with and without prior knowledge</article-title>. <source>Bioinformatics</source><italic>,</italic>
<volume>25</volume>, <fpage>2929</fpage>–<lpage>2936</lpage>.<pub-id pub-id-type="pmid">19696047</pub-id></mixed-citation>
    </ref>
    <ref id="btv258-B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ashburner</surname><given-names>M.</given-names></name><etal/></person-group><italic>.</italic> (<year>2000</year>) 
<article-title>Gene Ontology: tool for the unification of biology</article-title>. <source>Nat. Genet.</source><italic>,</italic>
<volume>25</volume>, <fpage>25</fpage>–<lpage>29</lpage>.<pub-id pub-id-type="pmid">10802651</pub-id></mixed-citation>
    </ref>
    <ref id="btv258-B5">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Cai</surname><given-names>Y.</given-names></name><etal/></person-group> (<year>2012</year>) 
<article-title>Utilizing RNA-seq data for cancer network inference</article-title>. In: <person-group person-group-type="editor"><name><surname>Pal</surname><given-names>R.</given-names></name><name><surname>Ressom</surname><given-names>H.</given-names></name></person-group> (eds), <source>IEEE GENSIPS</source>. 
<publisher-loc>IEEE, Piscataway, NJ, USA</publisher-loc><italic>,</italic> pp. <fpage>46</fpage>–<lpage>49</lpage>.</mixed-citation>
    </ref>
    <ref id="btv258-B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cornish</surname><given-names>A.J.</given-names></name><name><surname>Markowetz</surname><given-names>F.</given-names></name></person-group> (<year>2014</year>) 
<article-title>SANTA: quantifying the functional content of molecular networks</article-title>. <source>PLoS Comput. Biol.</source><italic>,</italic>
<volume>10</volume>, <fpage>e1003808</fpage>.<pub-id pub-id-type="pmid">25210953</pub-id></mixed-citation>
    </ref>
    <ref id="btv258-B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Costanzo</surname><given-names>M.</given-names></name><etal/></person-group><italic>.</italic> (<year>2010</year>) 
<article-title>The genetic landscape of a cell</article-title>. <source>Science</source><italic>,</italic>
<volume>327</volume>, <fpage>425</fpage>–<lpage>431</lpage>.<pub-id pub-id-type="pmid">20093466</pub-id></mixed-citation>
    </ref>
    <ref id="btv258-B8">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Duda</surname><given-names>R.O.</given-names></name><name><surname>Hart</surname><given-names>P.E.</given-names></name></person-group> (<year>1973</year>) <source>Pattern Classification and Scene Analysis</source><italic>.</italic>
<publisher-loc>Wiley, New Jersey, NJ, USA</publisher-loc>.</mixed-citation>
    </ref>
    <ref id="btv258-B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Friedman</surname><given-names>J.</given-names></name><etal/></person-group> (<year>2007</year>) 
<article-title>Sparse inverse covariance estimation with the lasso</article-title>. <source>Biostatistics</source><italic>,</italic>
<volume>9</volume>, <fpage>432</fpage>–<lpage>441</lpage>.<pub-id pub-id-type="pmid">18079126</pub-id></mixed-citation>
    </ref>
    <ref id="btv258-B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Friedman</surname><given-names>J.</given-names></name><etal/></person-group> (<year>2008</year>) 
<article-title>Sparse inverse covariance estimation with the graphical lasso</article-title>. <source>Biostatistics</source><italic>,</italic>
<volume>9</volume>, <fpage>432</fpage>–<lpage>441</lpage>.<pub-id pub-id-type="pmid">18079126</pub-id></mixed-citation>
    </ref>
    <ref id="btv258-B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gallopin</surname><given-names>M.</given-names></name><etal/></person-group> (<year>2013</year>) 
<article-title>A hierarchical Poisson log-normal model for network inference from RNA sequencing data</article-title>. <source>PLoS One</source><italic>,</italic>
<volume>8</volume>, <fpage>e77503</fpage>.<pub-id pub-id-type="pmid">24147011</pub-id></mixed-citation>
    </ref>
    <ref id="btv258-B12">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hudson</surname><given-names>T.J.</given-names></name><etal/></person-group><italic>.</italic> (<year>2010</year>) 
<article-title>International network of cancer genome projects</article-title>. <source>Nature</source><italic>,</italic>
<volume>464</volume>, <fpage>993</fpage>–<lpage>998</lpage>.<pub-id pub-id-type="pmid">20393554</pub-id></mixed-citation>
    </ref>
    <ref id="btv258-B13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Isci</surname><given-names>S.</given-names></name><etal/></person-group><italic>.</italic> (<year>2014</year>) 
<article-title>Bayesian network prior: network analysis of biological data using external knowledge</article-title>. <source>Bioinformatics</source><italic>,</italic>
<volume>30</volume>, <fpage>860</fpage>–<lpage>867</lpage>.<pub-id pub-id-type="pmid">24215027</pub-id></mixed-citation>
    </ref>
    <ref id="btv258-B14">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Jalali</surname><given-names>A.</given-names></name><etal/></person-group> (<year>2011</year>) 
<article-title>On learning discrete graphical models using group-sparse regularization</article-title>. In: <person-group person-group-type="editor"><name><surname>Dudík</surname><given-names>M.</given-names></name></person-group> (ed.), <source>AISTATS</source>. 
<publisher-loc>MLR, Boston, MA, USA</publisher-loc><italic>,</italic> pp. <fpage>378</fpage>–<lpage>387</lpage>.</mixed-citation>
    </ref>
    <ref id="btv258-B15">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kotera</surname><given-names>M.</given-names></name><etal/></person-group> (<year>2012</year>) 
<article-title>GENIES: gene network inference engine based on supervised analysis</article-title>. <source>Nucleic Acids Res.</source><italic>,</italic>
<volume>40</volume>, <fpage>W162</fpage>–<lpage>W167</lpage>.<pub-id pub-id-type="pmid">22610856</pub-id></mixed-citation>
    </ref>
    <ref id="btv258-B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Krishnapuram</surname><given-names>B.</given-names></name><etal/></person-group><italic>.</italic> (<year>2005</year>) 
<article-title>Sparse multinomial logistic regression: fast algorithms and generalization bounds</article-title>. <source>IEEE TPAMI</source><italic>,</italic>
<volume>27</volume>, <fpage>957</fpage>–<lpage>968</lpage>.</mixed-citation>
    </ref>
    <ref id="btv258-B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>H.</given-names></name><etal/></person-group><italic>.</italic> (<year>2012</year>) 
<article-title>High-dimensional semiparametric Gaussian copula graphical models</article-title>. <source>Ann. Stat.</source><italic>,</italic>
<volume>40</volume>, <fpage>2293</fpage>–<lpage>2326</lpage>.</mixed-citation>
    </ref>
    <ref id="btv258-B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>H.</given-names></name><etal/></person-group> (<year>2009</year>) 
<article-title>The nonparanormal: Semiparametric estimation of high dimensional undirected graphs</article-title>. <source>JMLR</source><italic>,</italic>
<volume>10</volume>, <fpage>2295</fpage>–<lpage>2328</lpage>.</mixed-citation>
    </ref>
    <ref id="btv258-B19">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Marbach</surname><given-names>D.</given-names></name><etal/></person-group><italic>.</italic> (<year>2012</year>) 
<article-title>Wisdom of crowds for robust gene network inference</article-title>. <source>Nat. Methods</source><italic>,</italic>
<volume>9</volume>, <fpage>796</fpage>–<lpage>804</lpage>.<pub-id pub-id-type="pmid">22796662</pub-id></mixed-citation>
    </ref>
    <ref id="btv258-B20">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meier</surname><given-names>L.</given-names></name><etal/></person-group> (<year>2008</year>) 
<article-title>The group lasso for logistic regression</article-title>. <source>J. R. Stat. Soc.</source>, <volume>70</volume>, <fpage>53</fpage>–<lpage>71</lpage>.</mixed-citation>
    </ref>
    <ref id="btv258-B21">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meinshausen</surname><given-names>N.</given-names></name><name><surname>Bühlmann</surname><given-names>P.</given-names></name></person-group> (<year>2006</year>) 
<article-title>High-dimensional graphs and variable selection with the lasso</article-title>. <source>Ann. Stat.</source><italic>,</italic>
<volume>34</volume>, <fpage>1436</fpage>–<lpage>1462</lpage>. </mixed-citation>
    </ref>
    <ref id="btv258-B22">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Metzler</surname><given-names>D.</given-names></name><name><surname>Croft</surname><given-names>W.B.</given-names></name></person-group> (<year>2005</year>) 
<article-title>A Markov random field model for term dependencies</article-title>. In: <person-group person-group-type="editor"><name><surname>Marchionini</surname><given-names>G.</given-names></name><etal/></person-group> (eds), <source>ACM SIGIR</source>. 
<publisher-loc>ACM, New York, NY, USA</publisher-loc><italic>,</italic> pp. <fpage>472</fpage>–<lpage>479</lpage>.</mixed-citation>
    </ref>
    <ref id="btv258-B23">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mukherjee</surname><given-names>S.</given-names></name><name><surname>Speed</surname><given-names>T.P.</given-names></name></person-group> (<year>2008</year>) 
<article-title>Network inference using informative priors</article-title>. <source>Proc. Natl. Acad. Sci. USA</source><italic>,</italic>
<volume>105</volume>, <fpage>14313</fpage>–<lpage>14318</lpage>.<pub-id pub-id-type="pmid">18799736</pub-id></mixed-citation>
    </ref>
    <ref id="btv258-B24">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Murphy</surname><given-names>K.P.</given-names></name></person-group> (<year>2012</year>) <source>Machine Learning: a Probabilistic Perspective</source><italic>.</italic>
<publisher-name>MIT Press</publisher-name>, 
<publisher-loc>Boston, MA, USA</publisher-loc>.</mixed-citation>
    </ref>
    <ref id="btv258-B25">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Murray</surname><given-names>J.S.</given-names></name><etal/></person-group><italic>.</italic> (<year>2013</year>) 
<article-title>Bayesian Gaussian copula factor models for mixed data</article-title>. <source>J. Am. Stat. Assoc.</source><italic>,</italic>
<volume>108</volume>, <fpage>656</fpage>–<lpage>665</lpage>.<pub-id pub-id-type="pmid">23990691</pub-id></mixed-citation>
    </ref>
    <ref id="btv258-B26">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Pearl</surname><given-names>J.</given-names></name><name><surname>Verma</surname><given-names>T.</given-names></name></person-group> (<year>1991</year>) 
<article-title>A theory of inferred causation</article-title>. In: <source>Conference on the Principles of Knowledge Representation and Reasoning</source><italic>,</italic> pp. <fpage>441</fpage>–<lpage>452</lpage>.</mixed-citation>
    </ref>
    <ref id="btv258-B27">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ravikumar</surname><given-names>P.</given-names></name><etal/></person-group><italic>.</italic> (<year>2010</year>) 
<article-title>High-dimensional ising model selection using </article-title><inline-formula><mml:math id="MM117"><mml:mrow><mml:msub><mml:mi>ℓ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>
<article-title>-regularized logistic regression</article-title>. <source>Ann. Stat.</source><italic>,</italic>
<volume>38</volume>, <fpage>1287</fpage>–<lpage>1319</lpage>.</mixed-citation>
    </ref>
    <ref id="btv258-B28">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rolland</surname><given-names>T.</given-names></name><etal/></person-group><italic>.</italic> (<year>2014</year>) 
<article-title>A proteome-scale map of the human interactome network</article-title>. <source>Cell</source><italic>,</italic>
<volume>159</volume>, <fpage>1212</fpage>–<lpage>1226</lpage>.<pub-id pub-id-type="pmid">25416956</pub-id></mixed-citation>
    </ref>
    <ref id="btv258-B29">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Rue</surname><given-names>H.</given-names></name><name><surname>Held</surname><given-names>L.</given-names></name></person-group> (<year>2005</year>) <source>Gaussian Markov Random Fields: Theory and Applications</source><italic>.</italic>
<publisher-name>CRC Press</publisher-name>, 
<publisher-loc>Abingdon, UK</publisher-loc>.</mixed-citation>
    </ref>
    <ref id="btv258-B30">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schäfer</surname><given-names>J.</given-names></name><name><surname>Strimmer</surname><given-names>K.</given-names></name></person-group> (<year>2005</year>) 
<article-title>An empirical Bayes approach to inferring large-scale gene association networks</article-title>. <source>Bioinformatics</source><italic>,</italic>
<volume>21</volume>, <fpage>754</fpage>–<lpage>764</lpage>.<pub-id pub-id-type="pmid">15479708</pub-id></mixed-citation>
    </ref>
    <ref id="btv258-B31">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Segal</surname><given-names>E.</given-names></name><etal/></person-group> (<year>2003</year>) 
<article-title>Discovering molecular pathways from protein interaction and gene expression data</article-title>. <source>Bioinformatics</source><italic>,</italic>
<volume>19</volume>, <fpage>i264</fpage>–<lpage>i272</lpage>.<pub-id pub-id-type="pmid">12855469</pub-id></mixed-citation>
    </ref>
    <ref id="btv258-B32">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stingo</surname><given-names>F. C.</given-names></name><name><surname>Vannucci</surname><given-names>M.</given-names></name></person-group> (<year>2011</year>) 
<article-title>Variable selection for discriminant analysis with Markov random field priors for the analysis of microarray data</article-title>. <source>Bioinformatics</source><italic>,</italic>
<volume>27</volume>, <fpage>495</fpage>–<lpage>501</lpage>.<pub-id pub-id-type="pmid">21159623</pub-id></mixed-citation>
    </ref>
    <ref id="btv258-B33">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Theodorou</surname><given-names>V.</given-names></name><etal/></person-group><italic>.</italic> (<year>2013</year>) 
<article-title>GATA3 acts upstream of FOXA1 in mediating ESR1 binding by shaping enhancer accessibility</article-title>. <source>Genome Res.</source><italic>,</italic>
<volume>23</volume>, <fpage>12</fpage>–<lpage>22</lpage>.<pub-id pub-id-type="pmid">23172872</pub-id></mixed-citation>
    </ref>
    <ref id="btv258-B34">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Turnbull</surname><given-names>C.</given-names></name><etal/></person-group><italic>.</italic> (<year>2012</year>) 
<article-title>Gene-gene interactions in breast cancer susceptibility</article-title>. <source>Hum. Mol. Genet.</source><italic>,</italic>
<volume>21</volume>, <fpage>958</fpage>–<lpage>962</lpage>.<pub-id pub-id-type="pmid">22072393</pub-id></mixed-citation>
    </ref>
    <ref id="btv258-B35">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Žitnik</surname><given-names>M.</given-names></name><etal/></person-group><italic>.</italic> (<year>2013</year>) 
<article-title>Discovering disease-disease associations by fusing systems-level molecular data</article-title>. <source>Sci. Rep.</source><italic>,</italic>
<volume>3</volume>, <fpage>e3202</fpage>.</mixed-citation>
    </ref>
    <ref id="btv258-B36">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Žitnik</surname><given-names>M.</given-names></name><name><surname>Zupan</surname><given-names>B.</given-names></name></person-group> (<year>2014</year>) 
<article-title>Matrix factorization-based data fusion for drug-induced liver injury prediction</article-title>. <source>Syst. Biomed.</source><italic>,</italic>
<volume>2</volume>, <fpage>e28527</fpage>.</mixed-citation>
    </ref>
    <ref id="btv258-B37">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Žitnik</surname><given-names>M.</given-names></name><name><surname>Zupan</surname><given-names>B.</given-names></name></person-group> (<year>2015</year>) 
<article-title>Data fusion by matrix factorization</article-title>. <source>IEEE TPAMI</source><italic>,</italic>
<volume>37</volume>, <fpage>41</fpage>–<lpage>53</lpage>.</mixed-citation>
    </ref>
    <ref id="btv258-B38">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>C.</given-names></name><etal/></person-group> (<year>2013</year>) 
<article-title>Markov random field modeling, inference &amp; learning in computer vision &amp; image understanding: a survey</article-title>. <source>Comput. Vis. Image Underst.</source><italic>,</italic>
<volume>117</volume>, <fpage>1610</fpage>–<lpage>1627</lpage>.</mixed-citation>
    </ref>
    <ref id="btv258-B39">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>X.</given-names></name><etal/></person-group> (<year>2014</year>) 
<article-title>Widespread genetic epistasis among cancer genes</article-title>. <source>Nat. Commun.</source><italic>,</italic>
<volume>5</volume>, <fpage>4828</fpage>.<pub-id pub-id-type="pmid">25407795</pub-id></mixed-citation>
    </ref>
    <ref id="btv258-B40">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>Z.</given-names></name><etal/></person-group> (<year>2009</year>) 
<article-title>RNA-Seq: a revolutionary tool for transcriptomics</article-title>. <source>Nat. Rev. Genet.</source><italic>,</italic>
<volume>10</volume>, <fpage>57</fpage>–<lpage>63</lpage>.<pub-id pub-id-type="pmid">19015660</pub-id></mixed-citation>
    </ref>
    <ref id="btv258-B41">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Yang</surname><given-names>E.</given-names></name><etal/></person-group> (<year>2012</year>) 
<article-title>Graphical models via generalized linear models</article-title>. In: <source>NIPS</source><italic>,</italic> pp. <fpage>1358</fpage>–<lpage>1366</lpage>.</mixed-citation>
    </ref>
    <ref id="btv258-B42">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Yang</surname><given-names>E.</given-names></name><etal/></person-group> (<year>2013</year>) 
<article-title>On Poisson graphical models</article-title>. In: <person-group person-group-type="editor"><name><surname>Welling</surname><given-names>M.</given-names></name><name><surname>Ghahramani</surname><given-names>Z.</given-names></name></person-group> (eds), <source>NIPS</source><italic>,</italic> pp. <fpage>1718</fpage>–<lpage>1726</lpage>.</mixed-citation>
    </ref>
    <ref id="btv258-B43">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Yang</surname><given-names>J.</given-names></name><name><surname>Leskovec</surname><given-names>J.</given-names></name></person-group> (<year>2012</year>) 
<article-title>Defining and evaluating network communities based on ground-truth</article-title>. In: <person-group person-group-type="editor"><name><surname>Tang</surname><given-names>J.</given-names></name><etal/></person-group> (eds), <source>ACM MDS</source>. 
<publisher-loc>ACM, New York, NY, USA</publisher-loc><italic>.</italic></mixed-citation>
    </ref>
    <ref id="btv258-B44">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zou</surname><given-names>H.</given-names></name><name><surname>Hastie</surname><given-names>T.</given-names></name></person-group> (<year>2005</year>) 
<article-title>Regularization and variable selection via the elastic net</article-title>. <source>J. R. Stat. Soc. B</source><italic>,</italic>
<volume>67</volume>, <fpage>301</fpage>–<lpage>320</lpage>.</mixed-citation>
    </ref>
  </ref-list>
</back>
