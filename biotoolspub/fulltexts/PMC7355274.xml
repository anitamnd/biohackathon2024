<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1 20151215//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.1?>
<?ConverterInfo.XSLTName jp2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id>
    <journal-id journal-id-type="publisher-id">bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1367-4803</issn>
    <issn pub-type="epub">1367-4811</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">7355274</article-id>
    <article-id pub-id-type="doi">10.1093/bioinformatics/btaa434</article-id>
    <article-id pub-id-type="publisher-id">btaa434</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Studies of Phenotypes and Clinical Applications</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Identifying diagnosis-specific genotype–phenotype associations via joint multitask sparse canonical correlation analysis and classification</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Du</surname>
          <given-names>Lei</given-names>
        </name>
        <xref ref-type="aff" rid="btaa434-aff1">b1</xref>
        <xref ref-type="corresp" rid="btaa434-cor1"/>
        <!--<email>dulei@nwpu.edu.cn</email>-->
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Liu</surname>
          <given-names>Fang</given-names>
        </name>
        <xref ref-type="aff" rid="btaa434-aff1">b1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Liu</surname>
          <given-names>Kefei</given-names>
        </name>
        <xref ref-type="aff" rid="btaa434-aff2">b2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Yao</surname>
          <given-names>Xiaohui</given-names>
        </name>
        <xref ref-type="aff" rid="btaa434-aff2">b2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Risacher</surname>
          <given-names>Shannon L</given-names>
        </name>
        <xref ref-type="aff" rid="btaa434-aff3">b3</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Han</surname>
          <given-names>Junwei</given-names>
        </name>
        <xref ref-type="aff" rid="btaa434-aff1">b1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Guo</surname>
          <given-names>Lei</given-names>
        </name>
        <xref ref-type="aff" rid="btaa434-aff1">b1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Saykin</surname>
          <given-names>Andrew J</given-names>
        </name>
        <xref ref-type="aff" rid="btaa434-aff3">b3</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Shen</surname>
          <given-names>Li</given-names>
        </name>
        <xref ref-type="aff" rid="btaa434-aff2">b2</xref>
        <xref ref-type="corresp" rid="btaa434-cor1"/>
        <!--<email>Li.Shen@pennmedicine.upenn.edu</email>-->
      </contrib>
      <contrib contrib-type="author">
        <collab>for the Alzheimer’s Disease Neuroimaging Initiative</collab>
        <xref ref-type="author-notes" rid="btaa434-FM1"/>
      </contrib>
    </contrib-group>
    <aff id="btaa434-aff1"><label>b1</label><institution>Department of intelligent science and technology, School of Automation, Northwestern Polytechnical University</institution>, Xi’an 710072, <country country="CN">China</country></aff>
    <aff id="btaa434-aff2"><label>b2</label><institution>Department of Biostatistics, Epidemiology and Informatics, University of Pennsylvania Perelman School of Medicine</institution>, Philadelphia, PA 19104, <country country="US">USA</country></aff>
    <aff id="btaa434-aff3"><label>b3</label><institution>Department of Radiology and Imaging Sciences, Indiana University School of Medicine</institution>, Indianapolis, IN 46202, <country country="US">USA</country></aff>
    <author-notes>
      <fn id="btaa434-FM1">
        <p>Data used in preparation of this article were obtained from the Alzheimer’s Disease Neuroimaging Initiative (ADNI) database (adni.loni.usc.edu). As such, the investigators within the ADNI contributed to the design and implementation of ADNI and/or provided data but did not participate in analysis or writing of this report. A complete listing of ADNI investigators can be found at: <ext-link ext-link-type="uri" xlink:href="http://adni.loni.usc.edu/wp-content/uploads/how_to_apply/ADNI_Acknowledgement_List.pdf">http://adni.loni.usc.edu/wp-content/uploads/how_to_apply/ADNI_Acknowledgement_List.pdf</ext-link>.</p>
      </fn>
      <corresp id="btaa434-cor1">To whom correspondence should be addressed. E-mail: <email>dulei@nwpu.edu.cn</email> or <email>Li.Shen@pennmedicine.upenn.edu</email></corresp>
    </author-notes>
    <pub-date pub-type="ppub">
      <month>7</month>
      <year>2020</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2020-07-13">
      <day>13</day>
      <month>7</month>
      <year>2020</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>13</day>
      <month>7</month>
      <year>2020</year>
    </pub-date>
    <!-- PMC Release delay is 0 months and 0 days and was based on the <pub-date pub-type="epub"/>. -->
    <volume>36</volume>
    <issue>Suppl 1</issue>
    <issue-title>ISMB 2020 Proceedings</issue-title>
    <fpage>i371</fpage>
    <lpage>i379</lpage>
    <permissions>
      <copyright-statement>© The Author(s) 2020. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2020</copyright-year>
      <license license-type="cc-by-nc" xlink:href="http://creativecommons.org/licenses/by-nc/4.0/">
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by-nc/4.0/">http://creativecommons.org/licenses/by-nc/4.0/</ext-link>), which permits non-commercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited. For commercial re-use, please contact journals.permissions@oup.com</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="btaa434.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Motivation</title>
        <p>Brain imaging genetics studies the complex associations between genotypic data such as single nucleotide polymorphisms (SNPs) and imaging quantitative traits (QTs). The neurodegenerative disorders usually exhibit the diversity and heterogeneity, originating from which different diagnostic groups might carry distinct imaging QTs, SNPs and their interactions. Sparse canonical correlation analysis (SCCA) is widely used to identify bi-multivariate genotype–phenotype associations. However, most existing SCCA methods are unsupervised, leading to an inability to identify diagnosis-specific genotype–phenotype associations.</p>
      </sec>
      <sec id="s2">
        <title>Results</title>
        <p>In this article, we propose a new joint multitask learning method, named MT–SCCALR, which absorbs the merits of both SCCA and logistic regression. MT–SCCALR learns genotype–phenotype associations of multiple tasks jointly, with each task focusing on identifying one diagnosis-specific genotype–phenotype pattern. Meanwhile, MT–SCCALR cannot only select relevant SNPs and imaging QTs for each diagnostic group alone, but also allows the selection of those shared by multiple diagnostic groups. We derive an efficient optimization algorithm whose convergence to a local optimum is guaranteed. Compared with two state-of-the-art methods, MT–SCCALR yields better or similar canonical correlation coefficients and classification performances. In addition, it owns much better discriminative canonical weight patterns of great interest than competitors. This demonstrates the power and capability of MTSCCAR in identifying diagnostically heterogeneous genotype–phenotype patterns, which would be helpful to understand the pathophysiology of brain disorders.</p>
      </sec>
      <sec id="s3">
        <title>Availability and implementation</title>
        <p>The software is publicly available at <ext-link ext-link-type="uri" xlink:href="https://github.com/dulei323/MTSCCALR">https://github.com/dulei323/MTSCCALR</ext-link>.</p>
      </sec>
      <sec id="s6">
        <title>Supplementary information</title>
        <p><xref ref-type="supplementary-material" rid="sup1">Supplementary data</xref> are available at <italic>Bioinformatics</italic> online.</p>
      </sec>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>National Natural Science Foundation of China</institution>
            <institution-id institution-id-type="DOI">10.13039/501100001809</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>61973255</award-id>
        <award-id>61602384</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Natural Science Basic Research Program of Shaanxi</institution>
          </institution-wrap>
        </funding-source>
        <award-id>2020JM-142</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>China Postdoctoral Science Foundation</institution>
            <institution-id institution-id-type="DOI">10.13039/501100002858</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>2017M613202</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Postdoctoral Science Foundation of Shaanxi</institution>
          </institution-wrap>
        </funding-source>
        <award-id>2017BSHEDZZ81</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Northwestern Polytechnical University</institution>
            <institution-id institution-id-type="DOI">10.13039/501100002663</institution-id>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>National Institutes of Health</institution>
            <institution-id institution-id-type="DOI">10.13039/100000002</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>R01 EB022574</award-id>
        <award-id>RF1 AG063481</award-id>
        <award-id>U19 AG024904</award-id>
        <award-id>P30 AG10133</award-id>
        <award-id>R01 AG19771</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>University of Pennsylvania and Indiana University</institution>
          </institution-wrap>
        </funding-source>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="9"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 Introduction</title>
    <p>Alzheimer’s disease (AD) is a severe neurodegenerative disorder incurring heavy economic and emotional costs to patients and their families (Alzheimer's Association<xref rid="btaa434-B1" ref-type="bibr">, 2013</xref>). Generally, AD, as well as other neurodegenerative and neuropsychiatric disorders, exhibits the heterogeneity and diversity (<xref rid="btaa434-B19" ref-type="bibr">Lam <italic>et al.</italic>, 2013</xref>; <xref rid="btaa434-B37" ref-type="bibr">Wang <italic>et al.</italic>, 2015</xref>), supported by mounting evidence that the sporadic AD could be multiple diseases instead of a single disease (<xref rid="btaa434-B2" ref-type="bibr">Au <italic>et al.</italic>, 2015</xref>). Therefore, uncovering the diagnosis-specific, including subgroup-specific and normal ageing-specific, genetic factors, imaging phenotypes and their interactions is an important and meaningful research topic. This could underpin AD subgroup identification, thereby help with mechanistic understanding of this neurodegenerative disorder.</p>
    <p>Brain imaging genetics provides us a powerful opportunity to gain new in-depth insights into the genetic basis of the phenotypic characteristics of the brain (<xref rid="btaa434-B30" ref-type="bibr">Shen and Thompson, 2020</xref>). Within this area, the genetic variations such as single nucleotide polymorphisms (SNPs) and brain imaging quantitative traits (QTs) are jointly analyzed with expectation to understand the normal and disordered brain function and behavior (<xref rid="btaa434-B29" ref-type="bibr">Saykin <italic>et al.</italic>, 2015</xref>; <xref rid="btaa434-B32" ref-type="bibr">Shen <italic>et al.</italic>, 2014</xref>).</p>
    <p>Given a large number of SNPs and imaging QTs, the univariate methods and the regression based methods have limited capability. The univariate methods treat each marker (SNP or QT) independently and thus they inevitably overlook the relationship within SNPs and imaging QTs (<xref rid="btaa434-B31" ref-type="bibr">Shen <italic>et al.</italic>, 2010</xref>). The regression-based methods alleviate this issue by looking into multiple SNPs’ (QTs’) impact on a single imaging QT (SNP) or a few candidate imaging QTs (SNPs). Obviously, they cannot select features of interest for SNPs and imaging QTs simultaneously, which, however, is a critical issue in imaging genetics.</p>
    <p>The above drawback can be addressed by bi-multivariate learning methods, such as sparse canonical correlation analysis (SCCA), partial least squares regression (<xref rid="btaa434-B4" ref-type="bibr">Beaton <italic>et al.</italic>, 2014</xref>) and reduced rank regression (<xref rid="btaa434-B34" ref-type="bibr">Vounou <italic>et al.</italic>, 2010</xref>). Among which SCCA and its variants become more and more popular due to its simplicity but powerful detection capability (<xref rid="btaa434-B6" ref-type="bibr">Chen <italic>et al.</italic>, 2013</xref>; <xref rid="btaa434-B8" ref-type="bibr">Du <italic>et al.</italic>, 2016</xref>, <xref rid="btaa434-B10" ref-type="bibr">2018</xref>, <xref rid="btaa434-B11" ref-type="bibr">2019a</xref>; <xref rid="btaa434-B39" ref-type="bibr">Witten and Tibshirani, 2009</xref>). However, SCCA is unsupervised and thus the diagnosis information is usually overlooked. This might lead to discovering disease irrelevant SNP–QT associations even though the discriminative information among distinct diagnostic groups has been implied in imaging QTs. Many efforts have been made in this direction to enable supervised SCCA. For example, <xref rid="btaa434-B40" ref-type="bibr">Yan <italic>et al.</italic> (2017)</xref> proposed discriminative SCCA (DSCCA) which considers the relationship within the same diagnostic group and that between groups. They later designed another outcome-relevant SCCA (<xref rid="btaa434-B41" ref-type="bibr">Yan <italic>et al.</italic>, 2018</xref>) to make use of the diagnosis information through regularization with the similarity matrix among subjects. <xref rid="btaa434-B45" ref-type="bibr">Zille <italic>et al.</italic> (2018)</xref> proposed a fused method in which the diagnosis information is considered by the regression objective while the SNP–QT association is captured by the SCCA objective simultaneously. A common critical issue holding by methods above is that they find out only one feature subset in terms of SNP–QT associations for all diagnostic groups. According to the feature selection taxonomy in the machine learning community (<xref rid="btaa434-B3" ref-type="bibr">Baggenstoss, 1999</xref>; <xref rid="btaa434-B27" ref-type="bibr">Pineda-Bautista <italic>et al.</italic>, 2011</xref>), these SCCAs fall into the traditional feature selection category, in contrast to the class-specific [or diagnosis-specific (The <italic>diagnosis-specific</italic> and <italic>class-specific</italic> are alternatively used throughout this article without distinction.)] feature selection (<xref rid="btaa434-B27" ref-type="bibr">Pineda-Bautista <italic>et al.</italic>, 2011</xref>), as they only select a single feature subset to discriminate all classes. Obviously, the identified SNP–QT associations are not diagnosis-specific. Nevertheless, identifying diagnosis-specific imaging genetic patterns could be of great interest and meaning, to which the targeted in-depth investigation, subgroup identification and personalized medication could be applied (<xref rid="btaa434-B24" ref-type="bibr">Mukherjee <italic>et al.</italic>, 2018</xref>).</p>
    <p>On this account, the diagnosis-specific feature selection methods which select a feature subset (possibly different) for each diagnostic group (<xref rid="btaa434-B27" ref-type="bibr">Pineda-Bautista <italic>et al.</italic>, 2011</xref>) is more desirable and essential. This topic is in agreement with class-specific feature selection. For example, <xref rid="btaa434-B37" ref-type="bibr">Wang <italic>et al.</italic> (2015)</xref> used the multitask support vector machine (SVM) to learn multiple heterogeneous classification tasks together. This method is somewhat difficult to interpret due to its nonobvious modeling strategy, and it only identifies imaging markers which is insufficient to subtype identification. The joint SCCA (JSCCA) (<xref rid="btaa434-B14" ref-type="bibr">Fang <italic>et al.</italic>, 2016</xref>) studied the imaging genetic associations within each diagnostic group via a modified multiview SCCA (mSCCA). However, its shortcoming is conspicuous as many undesirable associations could dominate the association of interest when conducting SCCA within a single diagnostic group (<xref rid="btaa434-B22" ref-type="bibr">Lorena <italic>et al.</italic>, 2008</xref>). Strictly speaking, both methods are beyond the diagnosis-specific feature selection due to their nonstandard modeling paradigm (<xref rid="btaa434-B27" ref-type="bibr">Pineda-Bautista <italic>et al.</italic>, 2011</xref>; <xref rid="btaa434-B38" ref-type="bibr">Wang <italic>et al.</italic>, 2016</xref>; <xref rid="btaa434-B44" ref-type="bibr">Zhang and Wu, 2015</xref>). Thus, both of them are inadequate for diagnosis-specific identification. It is straightforward to employ well-studied diagnosis-specific algorithms for imaging genetics (<xref rid="btaa434-B27" ref-type="bibr">Pineda-Bautista <italic>et al.</italic>, 2011</xref>). Unfortunately, they are classification-based methods indicating that they can only identify label-relevant features. As a result, the primary mission of brain imaging genetics, i.e. identifying meaningful SNP–QT associations, is overlooked.</p>
    <p>To address the issues above, we propose a novel multitask bi-multivariate learning method with feature selection to identify diagnosis-specific genotype–phenotype patterns for each patient group as well as normal controls. The proposed method, named MT–SCCALR, integrates multitask SCCA and multitask logistic regression (LR) in a unified model. The advantages of MT–SCCALR are fourfold. First, different to existing unsupervised and supervised SCCAs, MT–SCCALR can identify diagnosis-specific SNP–QT associations by jointly learning multiple SCCA tasks and LR tasks. The identified diagnosis-specific feature set, including SNPs and imaging QTs, is exclusively held by a specific diagnostic group. Second, better than JSCCA which incurs undesirable diagnosis-irrelevant features, MT–SCCALR follows sophisticated class-specific modeling strategy, and thus could avoid the diagnosis-irrelevant QTs, SNPs and their associations. Third, using regularization techniques, MT–SCCALR not only selects features such as SNPs and QTs for each diagnostic group, but also those that are commonly carried by all subjects, enabling a hierarchical strategy for feature selection. Fourth, an efficient iteration optimization algorithm is derived, which is demonstrated to converge to a local optimum.</p>
    <p>To evaluate the performance of MT–SCCALR, we use four synthetic datasets with distinct characters and a real neuroimaging genetic dataset downloaded from the Alzheimer’s disease neuroimaging initiative (ADNI) database (<xref rid="btaa434-B23" ref-type="bibr">Mueller <italic>et al.</italic>, 2005</xref>). There are 755 non-Hispanic Caucasian participants with their 18-Fr florbetapir PET scans and genotyping data contained. We aim to detect the diagnosis-specific associations between these imaging QTs and SNPs. Compared with two state-of-the-art methods (<xref rid="btaa434-B14" ref-type="bibr">Fang <italic>et al.</italic>, 2016</xref>; <xref rid="btaa434-B40" ref-type="bibr">Yan <italic>et al.</italic>, 2017</xref>), the experimental results show that MT–SCCALR performs better than or similarly to benchmarks in terms of correlation coefficients and classification accuracies. Interestingly, the canonical weights reveal that our method successfully identifies QTs, SNPs and their associations being specific for each diagnostic group while those competitors cannot. In a word, the proposed integrated multitask SCCA and multitask LR offers a very promising new strategy for brain imaging genetics.</p>
  </sec>
  <sec>
    <title>2 Materials and methods</title>
    <p>In this article, lowercase letters denote vectors, and uppercase ones denote matrices. <inline-formula id="IE1"><mml:math id="IM1"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE2"><mml:math id="IM2"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> denote the <italic>i</italic>th row and <italic>j</italic>th column of matrix <inline-formula id="IE3"><mml:math id="IM3"><mml:mrow><mml:mi mathvariant="bold">X</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>. <inline-formula id="IE4"><mml:math id="IM4"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mrow><mml:mo>‖</mml:mo><mml:mi mathvariant="bold">x</mml:mi><mml:mo>‖</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> denotes the Euclidean norm, <inline-formula id="IE5"><mml:math id="IM5"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mrow><mml:mo>‖</mml:mo><mml:mi mathvariant="bold">X</mml:mi><mml:mo>‖</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mi>j</mml:mi></mml:munder><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mo> </mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> denotes the element-wise <inline-formula id="IE6"><mml:math id="IM6"><mml:mrow><mml:msub><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>-norm, <inline-formula id="IE7"><mml:math id="IM7"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mrow><mml:mo>‖</mml:mo><mml:mi mathvariant="bold">X</mml:mi><mml:mo>‖</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mrow><mml:mo>‖</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msup></mml:mrow><mml:mo>‖</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> denotes the <inline-formula id="IE8"><mml:math id="IM8"><mml:mrow><mml:msub><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>-norm, and <inline-formula id="IE9"><mml:math id="IM9"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mrow><mml:mo>‖</mml:mo><mml:mi mathvariant="bold">X</mml:mi><mml:mo>‖</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mi mathvariant="normal">F</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msqrt><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mi>j</mml:mi></mml:munder><mml:mrow><mml:msubsup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mrow></mml:mrow></mml:msqrt></mml:mrow></mml:math></inline-formula> denotes the Frobenius norm.</p>
    <sec>
      <title>2.1 Overview</title>
      <p>To identify diagnosis-specific features in imaging genetics, it is straightforward to train multiple classifiers independently with respect to different tasks. For example, we can build a classifier to discriminate HC from AD, and build another classifier to discriminate between MCI and AD. However, this strategy treats these tasks as independent and isolated models, hence the underlying interacting relationships among tasks might be overlooked. Another critical issue is that it is somewhat difficult to interpret the identified features as it is not a rigorous model for class-specific feature selection (<xref rid="btaa434-B27" ref-type="bibr">Pineda-Bautista <italic>et al.</italic>, 2011</xref>).</p>
      <p>In this article, we formally define the diagnosis-specific feature selection model for imaging genetics following the strategy in traditional feature selection community (<xref rid="btaa434-B27" ref-type="bibr">Pineda-Bautista <italic>et al.</italic>, 2011</xref>; <xref rid="btaa434-B44" ref-type="bibr">Zhang and Wu, 2015</xref>). <xref ref-type="fig" rid="btaa434-F1">Figure 1</xref> presents the framework of the diagnosis-specific feature selection workflow. First, the whole target population is divided into different groups such as healthy control (HC), mild cognitive impairment (MCI) and AD. If possible, the AD patients can be further split into AD subgroups, e.g. the typical, limbic-predominant, or hippocampal-sparing groups (<xref rid="btaa434-B15" ref-type="bibr">Ferreira <italic>et al.</italic>, 2017</xref>). Second, the class binarization is applied to construct multiple classification tasks via the one-versus-all [OVA, or one-against-all (OAA)] decomposition strategy. The OVA has shown, in general, good performance for all datasets (<xref rid="btaa434-B22" ref-type="bibr">Lorena <italic>et al.</italic>, 2008</xref>). In particular, each task in our method is to classify a specific diagnostic group out of those subjects not in this group, e.g. HC versus non-HC or MCI versus non-MCI. This is of great importance and meaning as doing this is helpful to understand the in-depth and unique characters for the diagnostic group of interest, making personalized clinical diagnosis and treatment possible. Besides, if necessary, the class balancing techniques such as oversampling will be used to overcome the class imbalance issue (<xref rid="btaa434-B27" ref-type="bibr">Pineda-Bautista <italic>et al.</italic>, 2011</xref>). Third, the novel heterogeneous multitask method, i.e. the joint multitask SCCA and multitask LR, is proposed to simultaneously and systematically considering the different diagnostic groups’ relatedness. The SCCA objective is used to learn the association between QTs and SNPs, and the LR objective is used to learn discriminating features. In addition, the class-specific as well as class-consistent characteristics of both imaging QTs and SNPs are also considered by newly designed penalties. Finally, we obtain the dementia-related, including both MCI and AD, and the normal ageing-related imaging QTs and SNPs. These diagnosis-specific feature sets would be of more interest than a single set for all diagnosis groups.
</p>
      <fig id="btaa434-F1" orientation="portrait" position="float">
        <label>Fig. 1.</label>
        <caption>
          <p>Framework of diagnosis-specific imaging genetic pattern identification with three diagnostic groups: HC, MCI and AD. There certainly can be more than three diagnostic groups</p>
        </caption>
        <graphic xlink:href="btaa434f1"/>
      </fig>
      <p>The class binarization and class balancing are easy to implement (<xref rid="btaa434-B27" ref-type="bibr">Pineda-Bautista <italic>et al.</italic>, 2011</xref>). Thus we focus on discussing the MT–SCCALR algorithm which is also the major contribution of this study.</p>
    </sec>
    <sec>
      <title>2.2 The diagnosis-specific feature selection model for imaging genetics</title>
      <p>MT–SCCALR is a heterogeneous multitask method with class-specific feature selection which fuses the bi-multivariate (SCCA) associations identification and classification (multiclass LR). Suppose we are given <italic>n</italic> participants with <italic>p</italic> SNPs and <italic>q</italic> imaging QTs from <italic>C</italic> diagnostic groups, we then use <inline-formula id="IE10"><mml:math id="IM10"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>×</mml:mo><mml:mi>p</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> to load the genetic data, <inline-formula id="IE11"><mml:math id="IM11"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">Y</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>×</mml:mo><mml:mi>q</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> to collect the imaging QT data and <inline-formula id="IE12"><mml:math id="IM12"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">z</mml:mi></mml:mrow><mml:mi>l</mml:mi></mml:msup><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>×</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> to collect the diagnostic label vector of subject <italic>l</italic>. Generally, in <inline-formula id="IE13"><mml:math id="IM13"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">z</mml:mi></mml:mrow><mml:mi>l</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula>, only one element is one and others are zeros. Then we directly learn two canonical weight matrices as <inline-formula id="IE14"><mml:math id="IM14"><mml:mrow><mml:mi mathvariant="bold">U</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="true">[</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mn>11</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mo>⋯</mml:mo></mml:mtd><mml:mtd><mml:mrow><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mi>C</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>⋯</mml:mo></mml:mtd><mml:mtd><mml:mo>⋯</mml:mo></mml:mtd><mml:mtd><mml:mo>⋯</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mo>⋯</mml:mo></mml:mtd><mml:mtd><mml:mrow><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>C</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo stretchy="true">]</mml:mo></mml:mrow><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>×</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>, and <inline-formula id="IE15"><mml:math id="IM15"><mml:mrow><mml:mi mathvariant="bold">V</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="true">[</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mn>11</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mo>⋯</mml:mo></mml:mtd><mml:mtd><mml:mrow><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mi>C</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>⋯</mml:mo></mml:mtd><mml:mtd><mml:mo>⋯</mml:mo></mml:mtd><mml:mtd><mml:mo>⋯</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>q</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mo>⋯</mml:mo></mml:mtd><mml:mtd><mml:mrow><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>q</mml:mi><mml:mi>C</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo stretchy="true">]</mml:mo></mml:mrow><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>q</mml:mi><mml:mo>×</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>, where <italic>u<sub>ic</sub></italic> is the weight of the <italic>i</italic>th SNP for the <italic>c</italic>th task, and <italic>v<sub>jc</sub></italic> is the weight of the <italic>j</italic>th imaging QT for the <italic>c</italic>th task. Obviously, these two canonical weight matrices can capture the local feature importance for both SNPs and imaging QTs with respect to each class, indicating their class-specific influence. In contrast, the traditional SCCA learns a canonical weight vector for SNPs and QTs, resulting in inability to select diagnosis-specific features. To identify the class-specific features and account for their interrelationships, we fuse the LR objective and the SCCA objective, i.e.
<disp-formula id="E1"><label>(1)</label><mml:math id="M1"><mml:mrow><mml:munder><mml:mrow><mml:mi>min</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold">U</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold">V</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mrow><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mrow><mml:mtext>LR</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">V</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mrow><mml:mtext>SCCA</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">U</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold">V</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p>
      <p>In this model, <inline-formula id="IE16"><mml:math id="IM16"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mrow><mml:mtext>LR</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> identifies the discriminating imaging QTs by conducting multitask classification for <italic>C</italic> tasks. After that, <inline-formula id="IE17"><mml:math id="IM17"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mrow><mml:mtext>SCCA</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> jointly learns the bi-multivariate associations between imaging QTs and SNPs for multiple tasks. It is worth mentioning that we do not include the logistic term between SNPs and the class label as associations between QTs and SNPs will finally encourage the identified SNPs being discriminating. This is reasonable and will make our model concise.</p>
      <p>The model above encounters severe overfitting problem as generally the number of SNPs or imaging QTs is much larger than the sample size. Therefore, the sparsity regularization technique is utilized. On this account, our MT–SCCALR model becomes
<disp-formula id="E2"><label>(2)</label><mml:math id="M2"><mml:mrow><mml:munder><mml:mrow><mml:mi>min</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold">U</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold">V</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mrow><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mrow><mml:mtext>LR</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">V</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mrow><mml:mtext>SCCA</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">U</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold">V</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mo>Ω</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">U</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mo>Ω</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">V</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p>
      <p>The <inline-formula id="IE18"><mml:math id="IM18"><mml:mrow><mml:mo>Ω</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">U</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> is the sparsity-inducing penalty to identify those SNPs of interest, and <inline-formula id="IE19"><mml:math id="IM19"><mml:mrow><mml:mo>Ω</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">V</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> is to identify relevant imaging QTs. In this class-specific multitask model, <inline-formula id="IE20"><mml:math id="IM20"><mml:mrow><mml:mo>Ω</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">U</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE21"><mml:math id="IM21"><mml:mrow><mml:mo>Ω</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">V</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> are designed to incorporate three types of regularization methods for feature selection, i.e. the class-consistent sparsity, the class-specific sparsity in terms of selecting features jointly and individually for SNPs and imaging QTs.</p>
      <p>To sum up, the multitask SCCA term captures the SNP–QT associations. The LR term captures the QT–diagnosis relationship. The sparsity-inducing terms help select relevant QTs and SNPs holding by a specific diagnosis group while accounting for those shared by multiple groups. Therefore, this novel fusion model is endowed with a diverse feature selection, especially the interesting class-specific feature selection. Next, we will present each term of MT–SCCALR in details.</p>
    </sec>
    <sec>
      <title>2.3 The OVA multiclass classification via the LR</title>
      <p>The LR is a popular classification method due to its simplicity but efficiency. In the proposed model, we regress the class label on imaging QTs by the LR objective to learn their associations. In the multiclass setting, we train multiple binary classifiers by the multitask modeling, i.e.
<disp-formula id="E3"><label>(3)</label><mml:math id="M3"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mrow><mml:mtext>LR</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">V</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>C</mml:mi></mml:munderover><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub></mml:mrow></mml:munderover><mml:mo> </mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mtext>log</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">y</mml:mi></mml:mrow><mml:mi>c</mml:mi><mml:mi>l</mml:mi></mml:msubsup><mml:msub><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">y</mml:mi></mml:mrow><mml:mi>c</mml:mi><mml:mi>l</mml:mi></mml:msubsup><mml:msub><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:mo stretchy="false">]</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where <italic>n<sub>c</sub></italic> is the sample size for each classification task. <italic>n<sub>c’</sub></italic>s could be equal without class balancing or unequal after class balancing. <italic>z<sub>lc</sub></italic> is the corresponding class label of the <italic>l</italic>th subject for the <italic>c</italic>th task, and <inline-formula id="IE22"><mml:math id="IM22"><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">y</mml:mi></mml:mrow><mml:mi>c</mml:mi><mml:mi>l</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula> is the data vector of the <italic>l</italic>th subject for the <italic>c</italic>th task. This objective is usually called the negative log-likelihood and is convex (<xref rid="btaa434-B43" ref-type="bibr">Zaidi and Webb, 2017</xref>).</p>
    </sec>
    <sec>
      <title>2.4 The bi-multivariate association identification via the multitask SCCA</title>
      <p>Conventional SCCA cannot identify class-specific SNP–QT associations as it only learns a single feature subset for all classes. The multitask SCCA (<xref rid="btaa434-B12" ref-type="bibr">Du <italic>et al.</italic>, 2019b</xref>) systematically considers the relatedness among multiple SCCA tasks and thus can be applied to handle class-specific SNP–QT associations identification. Denoting data matrices with respect to the <italic>c</italic>th SCCA task as <inline-formula id="IE23"><mml:math id="IM23"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE24"><mml:math id="IM24"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">Y</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, the multitask SCCA is defined as
<disp-formula id="E4"><label>(4)</label><mml:math id="M4"><mml:mtable><mml:mtr><mml:mtd><mml:munder><mml:mrow><mml:mi>min</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub></mml:mrow></mml:munder><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>C</mml:mi></mml:munderover><mml:mo>−</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mi>c</mml:mi><mml:mo>⊤</mml:mo></mml:msubsup><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mi>c</mml:mi><mml:mo>⊤</mml:mo></mml:msubsup><mml:msub><mml:mrow><mml:mi mathvariant="bold">Y</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:mo> </mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi mathvariant="normal">s</mml:mi><mml:mo>.</mml:mo><mml:mi mathvariant="normal">t</mml:mi><mml:mo>.</mml:mo><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mo>‖</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub></mml:mrow><mml:mo>‖</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn><mml:mi mathvariant="normal">2</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mo>‖</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">Y</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub></mml:mrow><mml:mo>‖</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn><mml:mi mathvariant="normal">2</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mo>∀</mml:mo><mml:mi>c</mml:mi><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p>
      <p>According to (<xref rid="btaa434-B12" ref-type="bibr">Du <italic>et al.</italic>, 2019b</xref>), this equation can be equivalently rewritten as
<disp-formula id="E5"><label>(5)</label><mml:math id="M5"><mml:mtable><mml:mtr><mml:mtd><mml:munder><mml:mrow><mml:mi>min</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub></mml:mrow></mml:munder><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>C</mml:mi></mml:munderover><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mrow><mml:mo>‖</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">Y</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub></mml:mrow><mml:mo>‖</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mn>2</mml:mn><mml:mi mathvariant="normal">2</mml:mi></mml:msubsup></mml:mrow><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:mo> </mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi mathvariant="normal">s</mml:mi><mml:mo>.</mml:mo><mml:mi mathvariant="normal">t</mml:mi><mml:mo>.</mml:mo><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mo>‖</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub></mml:mrow><mml:mo>‖</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn><mml:mi mathvariant="normal">2</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mo>‖</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">Y</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub></mml:mrow><mml:mo>‖</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn><mml:mi mathvariant="normal">2</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mo>∀</mml:mo><mml:mi>c</mml:mi><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>based on <inline-formula id="IE25"><mml:math id="IM25"><mml:mrow><mml:mo>∀</mml:mo><mml:mi>c</mml:mi><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mrow><mml:mo>‖</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub></mml:mrow><mml:mo>‖</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mn>2</mml:mn><mml:mi mathvariant="normal">2</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE26"><mml:math id="IM26"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mrow><mml:mo>‖</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">Y</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub></mml:mrow><mml:mo>‖</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mn>2</mml:mn><mml:mi mathvariant="normal">2</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>.</p>
      <p>This objective jointly learns bi-multivariate associations and thus, in general, outperforms conventional SCCAs (<xref rid="btaa434-B12" ref-type="bibr">Du <italic>et al.</italic>, 2019b</xref>). It is worth noting that in this model, <inline-formula id="IE27"><mml:math id="IM27"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE28"><mml:math id="IM28"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">Y</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> correspond to the whole population but not only subjects in the <italic>c</italic>th class. For example, suppose the <italic>c</italic>th task is MCI versus non-MCI as shown in <xref ref-type="fig" rid="btaa434-F1">Figure 1</xref>, <inline-formula id="IE29"><mml:math id="IM29"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE30"><mml:math id="IM30"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">Y</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> contain all subjects other than only MCI subjects. On the contrary, in JSCCA model, both <inline-formula id="IE31"><mml:math id="IM31"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE32"><mml:math id="IM32"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">Y</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> come from only the MCI group (<xref rid="btaa434-B14" ref-type="bibr">Fang <italic>et al.</italic>, 2016</xref>). As we analyzed earlier, features identified by our model possess stronger discriminating ability than that of JSCCA whose might be out of interest.</p>
      <sec>
        <label>2.4.1</label>
        <title>Regularization for imaging QTs via class-consistent and class-specific sparsity</title>
        <p>The brain disorder such as AD usually exhibits the heterogeneity for multiple diagnostic groups (<xref rid="btaa434-B19" ref-type="bibr">Lam <italic>et al.</italic>, 2013</xref>; <xref rid="btaa434-B37" ref-type="bibr">Wang <italic>et al.</italic>, 2015</xref>). This diversity and complexity raise three critical questions. First, an imaging QT could present similar degenerative pattern among all diagnostic groups, because that both dementia brain and normal ageing brain suffer from functional and structural degeneration. Second, more commonly, an imaging QT probably exhibits diverse and different degenerative patterns across multiple diagnostic groups. The hippocampal-sparing AD patients show similar atrophy to normal aging in hippocampus (<xref rid="btaa434-B25" ref-type="bibr">Murray and Dickson, 2008</xref>), while typical AD patients suffer from pronouncedly severer hippocampus atrophy compared to normal ageing subjects. The last but not the least, the network or graph structure has been clearly observed by autopsy or noninvasive imaging techniques (<xref rid="btaa434-B5" ref-type="bibr">Bullmore and Sporns, 2009</xref>). Thus, a damage to the network structure might be a sign of dementia. On the contrary, this implies that an intact network might only exist in normal ageing subjects but not AD patients.</p>
        <p>Therefore, to consider the complexity of brain disorders, we defined <inline-formula id="IE33"><mml:math id="IM33"><mml:mrow><mml:mo>Ω</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">V</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> as follows
<disp-formula id="E6"><label>(6)</label><mml:math id="M6"><mml:mrow><mml:mo>Ω</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold">V</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mrow><mml:mi>v</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mrow><mml:mrow><mml:mo>‖</mml:mo><mml:mi mathvariant="bold">V</mml:mi><mml:mo>‖</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mrow><mml:mi>v</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mrow><mml:mrow><mml:mo>‖</mml:mo><mml:mi mathvariant="bold">V</mml:mi><mml:mo>‖</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mrow><mml:mi>v</mml:mi><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>C</mml:mi></mml:munderover><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mrow><mml:mo>‖</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub></mml:mrow><mml:mo>‖</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="italic">GGL</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where <inline-formula id="IE34"><mml:math id="IM34"><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mrow><mml:mi>v</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mrow><mml:mi>v</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE35"><mml:math id="IM35"><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mrow><mml:mi>v</mml:mi><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> are nonnegative parameters and can be obtained by cross-validation or holdout.</p>
        <p>The first term is the <inline-formula id="IE36"><mml:math id="IM36"><mml:mrow><mml:msub><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>-norm which is defined as follows
<disp-formula id="E7"><label>(7)</label><mml:math id="M7"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mrow><mml:mo>‖</mml:mo><mml:mi mathvariant="bold">V</mml:mi><mml:mo>‖</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>q</mml:mi></mml:munderover><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mrow><mml:mo>‖</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msup></mml:mrow><mml:mo>‖</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>q</mml:mi></mml:munderover><mml:mrow><mml:msqrt><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>C</mml:mi></mml:munderover><mml:mrow><mml:msubsup><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mi>c</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mrow></mml:msqrt></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p>
        <p>This penalty encourages the task-consistent sparsity, indicating that elements of vector <inline-formula id="IE37"><mml:math id="IM37"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>q</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> will be zeros or nonzeros simultaneously. As a result, an imaging QT presenting similar degenerative pattern for all groups will be selected or discarded jointly. Using this penalty is more practical since by finding out QTs shared among multiple diagnostic groups, the identified class-specific QTs could be more helpful.</p>
        <p>The second regularizer is the <inline-formula id="IE38"><mml:math id="IM38"><mml:mrow><mml:msub><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>-norm (<inline-formula id="IE39"><mml:math id="IM39"><mml:mrow><mml:msub><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>-norm for matrices) which is defined as
<disp-formula id="E8"><label>(8)</label><mml:math id="M8"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mrow><mml:mo>‖</mml:mo><mml:mi mathvariant="bold">V</mml:mi><mml:mo>‖</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>q</mml:mi></mml:munderover><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mrow><mml:mo>‖</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msup></mml:mrow><mml:mo>‖</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>q</mml:mi></mml:munderover><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>C</mml:mi></mml:munderover><mml:mrow><mml:mo> </mml:mo><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula></p>
        <p>This <inline-formula id="IE40"><mml:math id="IM40"><mml:mrow><mml:msub><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>-norm penalty first prompts the individual sparsity for an imaging QT across all classes, and then prompts the sparsity for all imaging QTs. This is important and meaningful as it cannot only select relevant imaging QTs, but also determinate whether an imaging QT is relevant for a specific class. Similar to <inline-formula id="IE41"><mml:math id="IM41"><mml:mrow><mml:msub><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>-norm, although <inline-formula id="IE42"><mml:math id="IM42"><mml:mrow><mml:msub><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>-norm is nonsmooth, it is convex and thus is easy to optimize.</p>
        <p>The third term is the graph-guided pairwise group Lasso (<italic>GGL</italic>) (<xref rid="btaa434-B9" ref-type="bibr">Du <italic>et al.</italic>, 2017</xref>, <xref rid="btaa434-B13" ref-type="bibr">2020</xref>) whose definition is
<disp-formula id="E9"><label>(9)</label><mml:math id="M9"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mrow><mml:mo>‖</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub></mml:mrow><mml:mo>‖</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="italic">GGL</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>∈</mml:mo><mml:mi>E</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:msqrt><mml:mrow><mml:msubsup><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mi>c</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mi>c</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:msqrt></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where <italic>E</italic> is the edge set of the graph in which those highly correlated nodes are connected. Given the network structure of the brain (knowledge-guided), or considering the brain as a completed graph (data-driven), this penalty captures the high-level structure information among imaging QTs. As shown in <xref rid="btaa434-B9" ref-type="bibr">Du <italic>et al.</italic> (2017</xref>, <xref rid="btaa434-B13" ref-type="bibr">2020</xref>), it holds the capability to assign similar weights for highly correlated imaging QTs, and thus can help identify the network structure. Moreover, using this penalty within each diagnostic group, we could capture the network holding by a specific group alone. Finally, the <italic>GGL</italic> penalty is convex, indicating that it can be easily solved.</p>
        <p>In summary, combining these three regularizers together can well address three questions raised at the beginning of this subsection. On this account, plugging <inline-formula id="IE43"><mml:math id="IM43"><mml:mrow><mml:mo>Ω</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">V</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> into MT–SCCALR will make it a more reasonable model, and thus yield class-consistent and class-specific feature subsets of interest.</p>
      </sec>
      <sec>
        <label>2.4.2</label>
        <title>Regularization for SNPs via class-consistent and class-specific sparsity</title>
        <p>Once those relevant imaging QTs, including both class-consistent and class-specific ones, are correctly identified, they could guide us to identify those class-consistent and class-specific SNPs as well. It is well known that SNPs usually affect the brain structure and function at both group level [linkage disequilibrium (LD) structure (<xref rid="btaa434-B28" ref-type="bibr">Reich <italic>et al.</italic>, 2001</xref>)] and individual level. In particular, at the individual level, a SNP could affect normal ageing brain and dementia brain at the same time, while another SNP might only influence the dementia one. This requires both class-consistent and class-specific feature selection for an individual SNP. In addition, at the group level, SNPs within the same LD or gene might jointly affect the brain structure and function (<xref rid="btaa434-B36" ref-type="bibr">Wang <italic>et al.</italic>, 2012b</xref>). An important thing is that, the genetic variation might happen to patients but not HCs, resulting in that an LD structure could only exist in healthy subjects. For this reason, we define the <inline-formula id="IE44"><mml:math id="IM44"><mml:mrow><mml:mo>Ω</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold">U</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> as
<disp-formula id="E10"><label>(10)</label><mml:math id="M10"><mml:mrow><mml:mo>Ω</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold">U</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mrow><mml:mi>u</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mrow><mml:mrow><mml:mo>‖</mml:mo><mml:mi mathvariant="bold">U</mml:mi><mml:mo>‖</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mrow><mml:mi>u</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mrow><mml:mrow><mml:mo>‖</mml:mo><mml:mi mathvariant="bold">U</mml:mi><mml:mo>‖</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mrow><mml:mi>u</mml:mi><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>C</mml:mi></mml:munderover><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mrow><mml:mo>‖</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub></mml:mrow><mml:mo>‖</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="italic">FGL</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>with <inline-formula id="IE45"><mml:math id="IM45"><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mrow><mml:mi>u</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mrow><mml:mi>u</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE46"><mml:math id="IM46"><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mrow><mml:mi>u</mml:mi><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> being nonnegative tuning parameters. Both <inline-formula id="IE47"><mml:math id="IM47"><mml:mrow><mml:msub><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>-norm and <inline-formula id="IE48"><mml:math id="IM48"><mml:mrow><mml:msub><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>-norm are the same to that in <xref ref-type="disp-formula" rid="E7">Eqs. (7</xref>–<xref ref-type="disp-formula" rid="E8">8)</xref>. They encourage class-consistent and class-specific feature selection for a single SNP.</p>
        <p>In addition, the third term in <xref ref-type="disp-formula" rid="E10">Eq. (10)</xref> is the fused pairwise group Lasso (<italic>FGL</italic>) imposed on each <inline-formula id="IE49"><mml:math id="IM49"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> (<xref rid="btaa434-B13" ref-type="bibr">Du <italic>et al.</italic>, 2020</xref>), i.e.
<disp-formula id="E11"><label>(11)</label><mml:math id="M11"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mrow><mml:mo>‖</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub></mml:mrow><mml:mo>‖</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="italic">FGL</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:munderover><mml:mrow><mml:msqrt><mml:mrow><mml:msubsup><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>c</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mi>c</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:msqrt></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p>
        <p>This penalty endows the model with a chain of smoothness across all elements of <inline-formula id="IE50"><mml:math id="IM50"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, encouraging the selection of two adjacent and strongly correlated variables (<xref rid="btaa434-B13" ref-type="bibr">Du <italic>et al.</italic>, 2020</xref>). This penalty shows clearly grouping effects and thus could be used to automatically identify group structures. This plays a key role in our model as it considers the feature selection at a higher level. In this article, we use this penalty within each diagnostic group via the data-driven setup with expectation to identify the group structure that only exists in a specific group.</p>
      </sec>
    </sec>
    <sec>
      <title>2.5 The optimization and convergence</title>
      <p>Now we explicitly write both objectives and penalties with respect to imaging phenotypes and genotypes,
<disp-formula id="E12"><label>(12)</label><mml:math id="M12"><mml:mtable><mml:mtr><mml:mtd><mml:munder><mml:mrow><mml:mi>min</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold">U</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold">V</mml:mi></mml:mrow></mml:munder><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>C</mml:mi></mml:munderover><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub></mml:mrow></mml:munderover><mml:mo> </mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mtext>log</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">y</mml:mi></mml:mrow><mml:mi>c</mml:mi><mml:mi>l</mml:mi></mml:msubsup><mml:msub><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">y</mml:mi></mml:mrow><mml:mi>c</mml:mi><mml:mi>l</mml:mi></mml:msubsup><mml:msub><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:mo stretchy="false">]</mml:mo><mml:mo>+</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>C</mml:mi></mml:munderover><mml:mrow/><mml:msubsup><mml:mrow><mml:mrow><mml:mo>‖</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">Y</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub></mml:mrow><mml:mo>‖</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn><mml:mi mathvariant="normal">2</mml:mi></mml:msubsup></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mrow><mml:mi>v</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mrow><mml:mo>‖</mml:mo><mml:mi mathvariant="bold">V</mml:mi><mml:mo>‖</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mrow><mml:mi>v</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mrow><mml:mo>‖</mml:mo><mml:mi mathvariant="bold">V</mml:mi><mml:mo>‖</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mrow><mml:mi>v</mml:mi><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>C</mml:mi></mml:munderover><mml:mrow/><mml:msub><mml:mrow><mml:mo>‖</mml:mo><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>‖</mml:mo><mml:msub><mml:mrow/><mml:mrow><mml:mi mathvariant="italic">GGL</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mrow><mml:mi>u</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mrow><mml:mo>‖</mml:mo><mml:mi mathvariant="bold">U</mml:mi><mml:mo>‖</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mrow><mml:mi>u</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mrow><mml:mo>‖</mml:mo><mml:mi mathvariant="bold">U</mml:mi><mml:mo>‖</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mrow><mml:mi>u</mml:mi><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>C</mml:mi></mml:munderover><mml:mrow/><mml:msub><mml:mrow><mml:mo>‖</mml:mo><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>‖</mml:mo><mml:msub><mml:mrow/><mml:mrow><mml:mi mathvariant="italic">FGL</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi mathvariant="normal">s</mml:mi><mml:mo>.</mml:mo><mml:mi mathvariant="normal">t</mml:mi><mml:mo>.</mml:mo><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mo>‖</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub></mml:mrow><mml:mo>‖</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn><mml:mi mathvariant="normal">2</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mo>‖</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">Y</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub></mml:mrow><mml:mo>‖</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn><mml:mi mathvariant="normal">2</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mo>∀</mml:mo><mml:mi>c</mml:mi><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p>
      <p>Mathematically, <xref ref-type="disp-formula" rid="E12">Eq. (12)</xref> is neither convex nor smooth. To handle this issue, by replacing <inline-formula id="IE51"><mml:math id="IM51"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mrow><mml:mo>‖</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub></mml:mrow><mml:mo>‖</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mn>2</mml:mn><mml:mi mathvariant="normal">2</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> with <inline-formula id="IE52"><mml:math id="IM52"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mrow><mml:mo>‖</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub></mml:mrow><mml:mo>‖</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mn>2</mml:mn><mml:mi mathvariant="normal">2</mml:mi></mml:msubsup><mml:mo>≤</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE53"><mml:math id="IM53"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mrow><mml:mo>‖</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">Y</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub></mml:mrow><mml:mo>‖</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mn>2</mml:mn><mml:mi mathvariant="normal">2</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> with <inline-formula id="IE54"><mml:math id="IM54"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mrow><mml:mo>‖</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">Y</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub></mml:mrow><mml:mo>‖</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mn>2</mml:mn><mml:mi mathvariant="normal">2</mml:mi></mml:msubsup><mml:mo>≤</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>, we analyze that <xref ref-type="disp-formula" rid="E12">Eq. (12)</xref> is convex if we consider <bold>V</bold> as a constant, and vice versa. Fortunately, this biconvexity has been well studied previously (<xref rid="btaa434-B16" ref-type="bibr">Gorski <italic>et al.</italic>, 2007</xref>), based on which we can solve <bold>U</bold> and <bold>V</bold> alternatively after smoothing those nonsmooth penalties such as <inline-formula id="IE55"><mml:math id="IM55"><mml:mrow><mml:mo>Ω</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">U</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE56"><mml:math id="IM56"><mml:mrow><mml:mo>Ω</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">V</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>.</p>
      <sec>
        <label>2.5.1</label>
        <title>The solution to V</title>
        <p>First, we fix <bold>U</bold> to solve <bold>V</bold>. The Lagrangian of <xref ref-type="disp-formula" rid="E12">Eq. (12)</xref> with respect to <bold>V</bold> can be simplified as
<disp-formula id="E13"><label>(13)</label><mml:math id="M13"><mml:mtable><mml:mtr><mml:mtd><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>C</mml:mi></mml:munderover><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub></mml:mrow></mml:munderover><mml:mo> </mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mtext>log</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">y</mml:mi></mml:mrow><mml:mi>c</mml:mi><mml:mi>l</mml:mi></mml:msubsup><mml:msub><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">y</mml:mi></mml:mrow><mml:mi>c</mml:mi><mml:mi>l</mml:mi></mml:msubsup><mml:msub><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:mo stretchy="false">]</mml:mo><mml:mo>+</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>C</mml:mi></mml:munderover><mml:mrow/><mml:msubsup><mml:mrow><mml:mrow><mml:mo>‖</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">Y</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub></mml:mrow><mml:mo>‖</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn><mml:mi mathvariant="normal">2</mml:mi></mml:msubsup></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mrow><mml:mi>v</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mrow><mml:mo>‖</mml:mo><mml:mi mathvariant="bold">V</mml:mi><mml:mo>‖</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mrow><mml:mi>v</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mrow><mml:mo>‖</mml:mo><mml:mi mathvariant="bold">V</mml:mi><mml:mo>‖</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mrow><mml:mi>v</mml:mi><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>C</mml:mi></mml:munderover><mml:mrow/><mml:msub><mml:mrow><mml:mo>‖</mml:mo><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>‖</mml:mo><mml:msub><mml:mrow/><mml:mrow><mml:mi mathvariant="italic">GGL</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mo>γ</mml:mo></mml:mrow><mml:mi>v</mml:mi></mml:msub><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>C</mml:mi></mml:munderover><mml:mrow/><mml:msubsup><mml:mrow><mml:mrow><mml:mo>‖</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">Y</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub></mml:mrow><mml:mo>‖</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn><mml:mi mathvariant="normal">2</mml:mi></mml:msubsup></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>by discarding those constants.</p>
        <p>Using the subgradient of these penalties, we can obtain the derivative of <xref ref-type="disp-formula" rid="E13">Eq. (13)</xref> with respect to each <inline-formula id="IE57"><mml:math id="IM57"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>. Letting it be zero yields [When <inline-formula id="IE58"><mml:math id="IM58"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mrow><mml:mo>‖</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msup></mml:mrow><mml:mo>‖</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>, we regularize the <italic>j</italic>th diagonal element of <inline-formula id="IE59"><mml:math id="IM59"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">D</mml:mi><mml:mo stretchy="false">˜</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> as <inline-formula id="IE60"><mml:math id="IM60"><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>2</mml:mn><mml:msub><mml:mrow><mml:mrow><mml:mrow><mml:mo>‖</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msup><mml:mo>+</mml:mo><mml:mo>ξ</mml:mo></mml:mrow><mml:mo>‖</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:math></inline-formula>, where <italic>ξ</italic> is a very small positive value. <inline-formula id="IE61"><mml:math id="IM61"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">D</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE62"><mml:math id="IM62"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">D</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> can be regularized similarly. It is easy to prove that when <inline-formula id="IE63"><mml:math id="IM63"><mml:mrow><mml:mo>ξ</mml:mo><mml:mo>→</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>, the regularized problem is equivalent to problem <xref ref-type="disp-formula" rid="E13">Eq. (13)</xref>.]
<disp-formula id="E14"><label>(14)</label><mml:math id="M14"><mml:mtable><mml:mtr><mml:mtd><mml:mfrac><mml:mrow><mml:mo>∂</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mi>R</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">V</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo>∂</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">Y</mml:mi></mml:mrow><mml:mi>c</mml:mi><mml:mo>⊤</mml:mo></mml:msubsup><mml:msub><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mn>2</mml:mn><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mrow><mml:mi>v</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">D</mml:mi><mml:mo stretchy="true">˜</mml:mo></mml:mover></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mn>2</mml:mn><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mrow><mml:mi>v</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">D</mml:mi><mml:mo stretchy="true">¯</mml:mo></mml:mover></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mn>2</mml:mn><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mrow><mml:mi>v</mml:mi><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="bold">D</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>+</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mo>γ</mml:mo></mml:mrow><mml:mi>v</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">Y</mml:mi></mml:mrow><mml:mi>c</mml:mi><mml:mo>⊤</mml:mo></mml:msubsup><mml:msub><mml:mrow><mml:mi mathvariant="bold">Y</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>where <inline-formula id="IE64"><mml:math id="IM64"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">D</mml:mi><mml:mo stretchy="false">˜</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> is a diagonal matrix with the <italic>j</italic>th element being <inline-formula id="IE65"><mml:math id="IM65"><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>2</mml:mn><mml:msub><mml:mrow><mml:mrow><mml:mrow><mml:mo>‖</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msup></mml:mrow><mml:mo>‖</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mfrac><mml:mo stretchy="true">(</mml:mo><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>q</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, and <inline-formula id="IE66"><mml:math id="IM66"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">D</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> is a diagonal matrix where the <italic>j</italic>th element is <inline-formula id="IE67"><mml:math id="IM67"><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>2</mml:mn><mml:msub><mml:mrow><mml:mrow><mml:mrow><mml:mo>‖</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>‖</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:math></inline-formula><inline-formula id="IE68"><mml:math id="IM68"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>q</mml:mi><mml:mo>;</mml:mo><mml:mo> </mml:mo><mml:mtext>and</mml:mtext><mml:mo> </mml:mo><mml:mi mathvariant="normal">c</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi mathvariant="normal">C</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>. <inline-formula id="IE69"><mml:math id="IM69"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">D</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> is also a diagonal matrix with its <italic>j</italic>th element being <inline-formula id="IE70"><mml:math id="IM70"><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>∈</mml:mo><mml:mi>E</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>2</mml:mn><mml:msqrt><mml:mrow><mml:msubsup><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mi>c</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mi>c</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:msqrt></mml:mrow></mml:mfrac></mml:mrow></mml:mrow></mml:math></inline-formula><inline-formula id="IE71"><mml:math id="IM71"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>q</mml:mi><mml:mo>;</mml:mo><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>q</mml:mi><mml:mo>;</mml:mo><mml:mo> </mml:mo><mml:mtext>and</mml:mtext><mml:mo> </mml:mo><mml:mi mathvariant="normal">c</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi mathvariant="normal">C</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> (<xref rid="btaa434-B9" ref-type="bibr">Du <italic>et al.</italic>, 2017</xref>). Obviously, <inline-formula id="IE72"><mml:math id="IM72"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">D</mml:mi><mml:mo stretchy="false">˜</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">D</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE73"><mml:math id="IM73"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">D</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> depend on the independent variable <bold>V</bold>, and thus they are unknown. On this account, the iterative algorithm can be a solver which first guesses an initial value of <bold>V</bold>, and then calculates these diagonal matrices.</p>
        <p>Once <inline-formula id="IE74"><mml:math id="IM74"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">D</mml:mi><mml:mo stretchy="false">˜</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">D</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE75"><mml:math id="IM75"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">D</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> are available, we can solve <xref ref-type="disp-formula" rid="E14">Eq. (14)</xref> correspondingly. However, we cannot find a closed-form solution due to the nontrivial derivative of the logistic term. Thus we address this using the Newton’s method which depends on the Hessian matrix. Based on this, solving <xref ref-type="disp-formula" rid="E14">Eq. (14)</xref> is equivalent to solve
<disp-formula id="E15"><label>(15)</label><mml:math id="M15"><mml:mtable><mml:mtr><mml:mtd><mml:munder><mml:mrow><mml:mi>min</mml:mi></mml:mrow><mml:mi mathvariant="bold">V</mml:mi></mml:munder><mml:msub><mml:mrow><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mi>R</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">V</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>C</mml:mi></mml:munderover><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mrow><mml:mo>‖</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">Y</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub></mml:mrow><mml:mo>‖</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mn>2</mml:mn><mml:mi mathvariant="normal">2</mml:mi></mml:msubsup></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mrow><mml:mi>v</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mi>T</mml:mi><mml:mi>r</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">V</mml:mi></mml:mrow><mml:mo>⊤</mml:mo></mml:msup><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">D</mml:mi><mml:mo stretchy="false">˜</mml:mo></mml:mover></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mi mathvariant="bold">V</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mrow><mml:mi>v</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mi>T</mml:mi><mml:mi>r</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">V</mml:mi></mml:mrow><mml:mo>⊤</mml:mo></mml:msup><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">D</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mi mathvariant="bold">V</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mrow><mml:mi>v</mml:mi><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mi>T</mml:mi><mml:mi>r</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">V</mml:mi></mml:mrow><mml:mo>⊤</mml:mo></mml:msup><mml:msub><mml:mrow><mml:mi mathvariant="bold">D</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mi mathvariant="bold">V</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mo>γ</mml:mo></mml:mrow><mml:mi>v</mml:mi></mml:msub><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>C</mml:mi></mml:munderover><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mi>c</mml:mi><mml:mo>⊤</mml:mo></mml:msubsup></mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">Y</mml:mi></mml:mrow><mml:mi>c</mml:mi><mml:mo>⊤</mml:mo></mml:msubsup><mml:msub><mml:mrow><mml:mi mathvariant="bold">Y</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p>
        <p>According to <xref rid="btaa434-B18" ref-type="bibr">Krishnapuram <italic>et al.</italic> (2005)</xref> and <xref rid="btaa434-B20" ref-type="bibr">Lee <italic>et al.</italic> (2006)</xref>, we first obtain the first-order derivative of the logistic objective with respect to each <italic>v<sub>jc</sub></italic><disp-formula id="E16"><label>(16)</label><mml:math id="M16"><mml:mrow><mml:mfrac><mml:mrow><mml:mo>∂</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mi>R</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">V</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo>∂</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub></mml:mrow></mml:munderover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>|</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">y</mml:mi></mml:mrow><mml:mi>c</mml:mi><mml:mi>l</mml:mi></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where <inline-formula id="IE76"><mml:math id="IM76"><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>|</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">y</mml:mi></mml:mrow><mml:mi>c</mml:mi><mml:mi>l</mml:mi></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> is the class posterior probability (<xref rid="btaa434-B43" ref-type="bibr">Zaidi and Webb, 2017</xref>). Here we use <inline-formula id="IE77"><mml:math id="IM77"><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>c</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> denote the <italic>l</italic>th row and <italic>j</italic>th column element of matrix <inline-formula id="IE78"><mml:math id="IM78"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">Y</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>.</p>
        <p>Then we can calculate the second-order derivative based on <xref ref-type="disp-formula" rid="E16">Eq. (16)</xref>,
<disp-formula id="E17"><label>(17)</label><mml:math id="M17"><mml:mrow><mml:mfrac><mml:mrow><mml:mo>∂</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mi>R</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">V</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo>∂</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>∂</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub></mml:mrow></mml:munderover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>|</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">y</mml:mi></mml:mrow><mml:mi>c</mml:mi><mml:mi>l</mml:mi></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>|</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">y</mml:mi></mml:mrow><mml:mi>c</mml:mi><mml:mi>l</mml:mi></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p>
        <p>After both the first-order and second-order derivatives have been obtained, we can easily calculate the gradient (or subgradient) vector <inline-formula id="IE79"><mml:math id="IM79"><mml:mrow><mml:mi mathvariant="bold">g</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> and the Hessian matrix <inline-formula id="IE80"><mml:math id="IM80"><mml:mrow><mml:mi mathvariant="bold">H</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> of <xref ref-type="disp-formula" rid="E15">Eq. (15)</xref> regarding <inline-formula id="IE81"><mml:math id="IM81"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>. Therefore, the solution to each <inline-formula id="IE82"><mml:math id="IM82"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> can be finally attained via
<disp-formula id="E18"><label>(18)</label><mml:math id="M18"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">H</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mi mathvariant="bold">g</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p>
      </sec>
      <sec>
        <label>2.5.2</label>
        <title>The solution to U</title>
        <p>Given <bold>V</bold>, the solution to <bold>U</bold> can be attained as well. First, we write the Lagrangian of <xref ref-type="disp-formula" rid="E12">Eq. (12)</xref> with <bold>U</bold> being unknown variable,
<disp-formula id="E19"><label>(19)</label><mml:math id="M19"><mml:mtable><mml:mtr><mml:mtd><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>C</mml:mi></mml:munderover><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mrow><mml:mo>‖</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">Y</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub></mml:mrow><mml:mo>‖</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mn>2</mml:mn><mml:mi mathvariant="normal">2</mml:mi></mml:msubsup></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mrow><mml:mi>u</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mrow><mml:mo>‖</mml:mo><mml:mi mathvariant="bold">U</mml:mi><mml:mo>‖</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mrow><mml:mi>u</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mrow><mml:mo>‖</mml:mo><mml:mi mathvariant="bold">U</mml:mi><mml:mo>‖</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mrow><mml:mi>u</mml:mi><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>C</mml:mi></mml:munderover><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mrow><mml:mo>‖</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub></mml:mrow><mml:mo>‖</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="italic">FGL</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mo>γ</mml:mo></mml:mrow><mml:mi>u</mml:mi></mml:msub><mml:msubsup><mml:mrow><mml:mrow><mml:mo>‖</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub></mml:mrow><mml:mo>‖</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn><mml:mi mathvariant="normal">2</mml:mi></mml:msubsup></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>where those constants are discarded. If we treat <inline-formula id="IE83"><mml:math id="IM83"><mml:mrow><mml:mi mathvariant="double-struck">Y</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">Y</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">Y</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></inline-formula> as dependent variables and <inline-formula id="IE84"><mml:math id="IM84"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>’s as independent variables, this equation becomes a multiregression task learning method with class-consistent and class-specific feature selection. To solve this multitask problem, we take its derivative with respect to <inline-formula id="IE85"><mml:math id="IM85"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and set it to zero, i.e.
<disp-formula id="E20"><label>(20)</label><mml:math id="M20"><mml:mrow><mml:mo>−</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mi>c</mml:mi><mml:mo>⊤</mml:mo></mml:msubsup><mml:msub><mml:mrow><mml:mi mathvariant="bold">Y</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mrow><mml:mi>u</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">D</mml:mi><mml:mo stretchy="false">˜</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mrow><mml:mi>u</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">D</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mrow><mml:mi>u</mml:mi><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="bold">D</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mo>γ</mml:mo></mml:mrow><mml:mi>u</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mi>c</mml:mi><mml:mo>⊤</mml:mo></mml:msubsup><mml:msub><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0.</mml:mn></mml:mrow></mml:math></disp-formula></p>
        <p>Similarly to solving <bold>V</bold>, <inline-formula id="IE86"><mml:math id="IM86"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">D</mml:mi><mml:mo stretchy="false">˜</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> here is a diagonal matrix whose <italic>i</italic>th element is <inline-formula id="IE87"><mml:math id="IM87"><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>2</mml:mn><mml:mrow><mml:mo>‖</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msup></mml:mrow></mml:mrow><mml:msub><mml:mrow><mml:mo>�</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mfrac><mml:mo stretchy="true">(</mml:mo><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, and <inline-formula id="IE88"><mml:math id="IM88"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">D</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> is a diagonal matrix with the <italic>i</italic>th element being <inline-formula id="IE89"><mml:math id="IM89"><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>2</mml:mn><mml:msub><mml:mrow><mml:mrow><mml:mrow><mml:mo>‖</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>‖</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:math></inline-formula><inline-formula id="IE90"><mml:math id="IM90"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo>;</mml:mo><mml:mo> </mml:mo><mml:mtext>and</mml:mtext><mml:mo> </mml:mo><mml:mi mathvariant="normal">c</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi mathvariant="normal">C</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>. Finally, <inline-formula id="IE91"><mml:math id="IM91"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">D</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> is a diagonal matrix whose <italic>i</italic>th diagonal entry is <inline-formula id="IE92"><mml:math id="IM92"><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>2</mml:mn><mml:msqrt><mml:mrow><mml:msubsup><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mi>c</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>c</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:msqrt></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>2</mml:mn><mml:msqrt><mml:mrow><mml:msubsup><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>c</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mi>c</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:msqrt></mml:mrow></mml:mfrac></mml:mrow></mml:math></inline-formula><inline-formula id="IE93"><mml:math id="IM93"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo>;</mml:mo><mml:mo> </mml:mo><mml:mtext>and</mml:mtext><mml:mo> </mml:mo><mml:mi mathvariant="normal">c</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi mathvariant="normal">C</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> [The first element of <inline-formula id="IE94"><mml:math id="IM94"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">D</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> is <inline-formula id="IE95"><mml:math id="IM95"><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>2</mml:mn><mml:msqrt><mml:mrow><mml:msubsup><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mi>c</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mi>c</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:msqrt></mml:mrow></mml:mfrac></mml:mrow></mml:math></inline-formula>, and the <italic>p</italic>th element is <inline-formula id="IE96"><mml:math id="IM96"><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>2</mml:mn><mml:msqrt><mml:mrow><mml:msubsup><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>p</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mi>c</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>c</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:msqrt></mml:mrow></mml:mfrac></mml:mrow></mml:math></inline-formula>. See <xref rid="btaa434-B13" ref-type="bibr">Du <italic>et al.</italic> (2020)</xref> for details.].</p>
        <p>Using the iteration algorithm, we can obtain the closed-form equation regarding each <inline-formula id="IE97"><mml:math id="IM97"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, i.e.
<disp-formula id="E21"><label>(21)</label><mml:math id="M21"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mrow><mml:mi>u</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">D</mml:mi><mml:mo stretchy="false">˜</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mrow><mml:mi>u</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">D</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mrow><mml:mi>u</mml:mi><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="bold">D</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mo>γ</mml:mo></mml:mrow><mml:mi>u</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mi>c</mml:mi><mml:mo>⊤</mml:mo></mml:msubsup><mml:msub><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mi>c</mml:mi><mml:mo>⊤</mml:mo></mml:msubsup><mml:msub><mml:mrow><mml:mi mathvariant="bold">Y</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p>
        <p>Now we have the building blocks for optimizing <xref ref-type="disp-formula" rid="E12">Eq. (12)</xref>. The final solution can be attained via iteratively and alternatively optimizing <bold>V</bold> and <bold>U</bold>. The pseudocode is presented in Algorithm 1 which is guaranteed to converge to a local optimum. In this algorithm, Steps 1 and 5 are easily and very fast to calculate. Step 3 involves computing the Hessian matrix which can be obtained efficiently based on (<xref rid="btaa434-B21" ref-type="bibr">Lin <italic>et al.</italic>, 2007</xref>). At last, Steps 4 and 6 can be attained by efficiently solving a system of linear equations (<xref rid="btaa434-B35" ref-type="bibr">Wang <italic>et al.</italic>, 2012a</xref>,<xref rid="btaa434-B36" ref-type="bibr">b</xref>).</p>
        <p>
          <boxed-text id="btaa434-BOX1" position="float" orientation="portrait">
            <label>Algorithm 1</label>
            <caption>
              <p>The MT-SCCALR algorithm</p>
            </caption>
            <p>
              <bold>Require:</bold>
            </p>
            <p> The genotype data <inline-formula id="IE98"><mml:math id="IM98"><mml:mrow><mml:mi mathvariant="bold">X</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>×</mml:mo><mml:mi>p</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> and imaging phenotype data <inline-formula id="IE99"><mml:math id="IM99"><mml:mrow><mml:mi mathvariant="bold">Y</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>×</mml:mo><mml:mi>q</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> of <italic>C</italic> diagnostic groups. The pre-tuned <inline-formula id="IE100"><mml:math id="IM100"><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mrow><mml:mi>v</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mrow><mml:mi>v</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mrow><mml:mi>v</mml:mi><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, <italic>γ<sub>v</sub></italic>, <inline-formula id="IE101"><mml:math id="IM101"><mml:mrow><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mrow><mml:mi>u</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mrow><mml:mi>u</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mrow><mml:mi>u</mml:mi><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, and <italic>γ<sub>u</sub></italic>.</p>
            <p>
              <bold>Ensure:</bold>
            </p>
            <p> Canonical weights <bold>V</bold> and <bold>U</bold>.</p>
            <p>1: Class binarization and class balancing, initialize <inline-formula id="IE102"><mml:math id="IM102"><mml:mrow><mml:mi mathvariant="bold">U</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>×</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE103"><mml:math id="IM103"><mml:mrow><mml:mi mathvariant="bold">V</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>q</mml:mi><mml:mo>×</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>;</p>
            <p>2: <bold>while</bold> not convergence <bold>do</bold></p>
            <p>3:  Calculate the first-order and second-order derivatives of <xref ref-type="disp-formula" rid="E15">Eq. (15)</xref>;</p>
            <p>4:  Solve <inline-formula id="IE104"><mml:math id="IM104"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> according to <xref ref-type="disp-formula" rid="E18">Eq. (18)</xref>, and scale <inline-formula id="IE105"><mml:math id="IM105"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> so that <inline-formula id="IE106"><mml:math id="IM106"><mml:mrow><mml:mrow><mml:mo>‖</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">Y</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub></mml:mrow></mml:mrow><mml:msubsup><mml:mrow><mml:mo>‖</mml:mo></mml:mrow><mml:mn>2</mml:mn><mml:mi mathvariant="normal">2</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>;</p>
            <p>5:  Update <inline-formula id="IE107"><mml:math id="IM107"><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">D</mml:mi><mml:mo>˜</mml:mo></mml:mover></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">D</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE108"><mml:math id="IM108"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">D</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>;</p>
            <p>6:  Solve <inline-formula id="IE109"><mml:math id="IM109"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> according to <xref ref-type="disp-formula" rid="E21">Eq. (21)</xref>, and scale <inline-formula id="IE110"><mml:math id="IM110"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> as that <inline-formula id="IE111"><mml:math id="IM111"><mml:mrow><mml:mrow><mml:mo>‖</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub></mml:mrow></mml:mrow><mml:msubsup><mml:mrow><mml:mo>‖</mml:mo></mml:mrow><mml:mn>2</mml:mn><mml:mi mathvariant="normal">2</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>;</p>
            <p>7: <bold>end while</bold></p>
            <p>8: Sorting each <inline-formula id="IE112"><mml:math id="IM112"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE113"><mml:math id="IM113"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> in descending order based on their absolute value respectively.</p>
          </boxed-text>
        </p>
      </sec>
      <sec>
        <label>2.5.3</label>
        <title>Convergence analysis</title>
        <p>We have the following theorem for the MT–SCCALR Algorithm.<statement id="mthst1"><p><sc>Theorem</sc> 1. The Algorithm 1 decreases the objective in each iteration.</p><p>The proof is contained in <xref ref-type="supplementary-material" rid="sup1">Supplementary Material</xref> due to space limitation. We have known that MT–SCCALR is biconvex, and obviously, <xref ref-type="disp-formula" rid="E12">Eq. (12)</xref> has the lower bound of zero, hence a local optimum can be attained finally by running Algorithm 1. To ensure efficiency, we stop our algorithm when both <inline-formula id="IE114"><mml:math id="IM114"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>max</mml:mi></mml:mrow></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mrow><mml:mrow><mml:mi>max</mml:mi></mml:mrow></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">U</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo>−</mml:mo><mml:mi mathvariant="bold">U</mml:mi></mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mo>≤</mml:mo><mml:mo>ϵ</mml:mo></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE115"><mml:math id="IM115"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>max</mml:mi></mml:mrow></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:msub><mml:mrow><mml:mrow><mml:mi>max</mml:mi></mml:mrow></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">V</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo>−</mml:mo><mml:mi mathvariant="bold">V</mml:mi></mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mo>≤</mml:mo><mml:mo>ϵ</mml:mo></mml:mrow></mml:math></inline-formula> hold. In addition, we empirically set the tolerance error <inline-formula id="IE116"><mml:math id="IM116"><mml:mrow><mml:mo>ϵ</mml:mo><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mn>10</mml:mn></mml:mrow></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> in this article for all experiments, and certainly, <italic>ϵ</italic> can be obtained based on experiments.</p></statement></p>
      </sec>
    </sec>
  </sec>
  <sec>
    <title>3 Experimental results and discussions</title>
    <sec>
      <title>3.1 Experimental design</title>
      <p>We compared our method with two most related SCCA method, i.e. the discriminate SCCA (DSCCA) (<xref rid="btaa434-B40" ref-type="bibr">Yan <italic>et al.</italic>, 2017</xref>) and the JSCCA (<xref rid="btaa434-B14" ref-type="bibr">Fang <italic>et al.</italic>, 2016</xref>), which directly identify imaging QTs and SNPs with discriminating ability. DSCCA extended the traditional SCCA by the locality preserving projection penalty. Its identified imaging QTs and proteomic markers can successfully discriminate between every two diagnostic groups such as HC versus AD. JSCCA was a type of mSCCA (<xref rid="btaa434-B39" ref-type="bibr">Witten and Tibshirani, 2009</xref>) which learns the association between QTs and SNPs within the same diagnostic group. Therefore, using DSCCA and JSCCA as benchmarks, our approach was compared with the state-of-the-art discriminating SCCA method, assuring a practical and meaningful performance evaluation. Of note, our primary aim in this study was to identify meaningful diagnosis-specific features other than just classification. Thus we did not compare to methods which use one versus one classification or a nonobvious modeling strategy (<xref rid="btaa434-B37" ref-type="bibr">Wang <italic>et al.</italic>, 2015</xref>).</p>
      <p>To find out suitable parameters, we used the fivefold cross-validation strategy to fine-tune them. Generally, we set parameters to those which generate the highest testing canonical correlation coefficients (CCC) and classification accuracy. There were in total eight parameters in the original model which was time intensive. To alleviate this issue for both MT–SCCALR and benchmarks, we fixed <inline-formula id="IE117"><mml:math id="IM117"><mml:mrow><mml:msub><mml:mrow><mml:mo>γ</mml:mo></mml:mrow><mml:mi>v</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE118"><mml:math id="IM118"><mml:mrow><mml:msub><mml:mrow><mml:mo>γ</mml:mo></mml:mrow><mml:mi>u</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> because that they mainly affect the amplitude of <bold>U</bold> and <bold>V</bold> (<xref rid="btaa434-B7" ref-type="bibr">Chen and Liu, 2012</xref>). In addition, we also used several heuristic rules to further reduce the time effort. Specifically, if we prefer the class-specific feature selection as in this study, we could use large parameters for <inline-formula id="IE119"><mml:math id="IM119"><mml:mrow><mml:msub><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>-norm, <italic>FGL</italic>-norm and <italic>GGL</italic>-norm. On the contrary, we might sometimes desire for the class-consistent feature selection, and then we could set large parameters for the <inline-formula id="IE120"><mml:math id="IM120"><mml:mrow><mml:msub><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>-norm. This could yield reasonable results as only focusing on the CCC might lead to undesirable features. Besides, we used a two-stage tuning procedure which first tuned parameters from <inline-formula id="IE121"><mml:math id="IM121"><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mn>10</mml:mn></mml:mrow></mml:mrow><mml:mi>i</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula> (<inline-formula id="IE122"><mml:math id="IM122"><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula>) with a large interval, and then further tuned them from a relative smaller interval <inline-formula id="IE123"><mml:math id="IM123"><mml:mrow><mml:mo>Γ</mml:mo><mml:mo>±</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mn>0.1</mml:mn><mml:mo>,</mml:mo><mml:mn>0.2</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></inline-formula>, where Γ was the optimal parameters obtained from the first stage. Usually, this two-stage parameter tuning could yield better performance, compared to blindly grid search, for both correlation coefficients and feature selection. In experiments, we only tuned parameters in the first loop where the first fold was used for testing and the remaining folds were used for training, and these tuned parameters were used for all experiments to generate final results. According to experiments, this setup will not affect the performance significantly and could reduce the time consumption significantly. All methods used the same experimental setup to assure a fair comparison.</p>
    </sec>
    <sec>
      <title>3.2 Simulation study</title>
      <p>We generated four simulation datasets based on different ground truths to make a thorough comparison. We assumed three groups of imaging data <bold>Y</bold> and genotype data <bold>X</bold>. The first two datasets (<italic>n </italic>=<italic> </italic>100, <italic>p </italic>=<italic> </italic>120 and <italic>q </italic>=<italic> </italic>150) contained the same true signal but different noise levels. The third dataset (<italic>n </italic>=<italic> </italic>100, <italic>p </italic>=<italic> </italic>120 and <italic>q </italic>=<italic> </italic>150) mainly simulated a task-specific situation while the fourth one (<italic>n </italic>=<italic> </italic>200, <italic>p </italic>=<italic> </italic>400 and <italic>q </italic>=<italic> </italic>300) primarily simulated a task-consistent situation. Specifically, in the fourth dataset, there was a successive relationship among classes to simulate the relationship between HC and MCI, and that between MCI and AD. All four datasets are generated as follows. First, we created two sparse matrices <inline-formula id="IE124"><mml:math id="IM124"><mml:mrow><mml:mi mathvariant="bold">U</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="script">R</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>×</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE125"><mml:math id="IM125"><mml:mrow><mml:mi mathvariant="bold">V</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="script">R</mml:mi></mml:mrow><mml:mrow><mml:mi>q</mml:mi><mml:mo>×</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>. Within both <bold>U</bold> and <bold>V</bold>, there are features shared by all tasks and specifically hold by a single task. We then generated a latent vector <inline-formula id="IE126"><mml:math id="IM126"><mml:mrow><mml:mi mathvariant="bold">z</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="script">R</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>×</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>, based on which we generated three pairs of <inline-formula id="IE127"><mml:math id="IM127"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:mo>∼</mml:mo><mml:mi>N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">I</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>×</mml:mo><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE128"><mml:math id="IM128"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">Y</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:mo>∼</mml:mo><mml:mi>N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">I</mml:mi></mml:mrow><mml:mrow><mml:mi>q</mml:mi><mml:mo>×</mml:mo><mml:mi>q</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> to form three diagnostic groups. We showed the ground truth in <xref ref-type="fig" rid="btaa434-F2">Figure 2</xref> (top row).
</p>
      <fig id="btaa434-F2" orientation="portrait" position="float">
        <label>Fig. 2.</label>
        <caption>
          <p>Canonical weights on synthetic data. Row 1–4: Ground truth, DSCCA, JSCCA and MT–SCCALR respectively. For each data, canonical weights <bold>U</bold> is shown on the left, and <bold>V</bold> is shown on the right. In each panel, there are three rows (each row contains fivefold canonical weights) corresponding to three tasks</p>
        </caption>
        <graphic xlink:href="btaa434f2"/>
      </fig>
      <p>As we mainly focus on the identified class-specific features, in <xref ref-type="fig" rid="btaa434-F2">Figure 2</xref>, we first showed the heatmaps of canonical weights which indicate the importance of features. DSCCA identified one canonical weight vector for all classes, and then we stacked it for <italic>C</italic> times to make its heatmap available. JSCCA generated one canonical weight vector for <bold>u</bold> and <italic>C</italic> canonical weight vectors for <bold>V</bold>, and thus we only stacked <bold>u</bold> for <italic>C</italic> times. In this figure, the features identified by MT–SCCALR were consistent to the ground truth, while DSCCA cannot. JSCCA performed slightly better than DSCCA, and they both had little capability in identifying class-specific features. From Data 4, we observed that if there were no class-specific features, all three methods could find out these class-consistent features. These results demonstrated that MT–SCCALR had more diverse feature selection ability than DSCCA and JSCCA. In <xref ref-type="fig" rid="btaa434-F3">Figure 3</xref>, we showed the testing CCCs and testing classification accuracies which were obtained by SVM based on LIBSVM (<ext-link ext-link-type="uri" xlink:href="https://www.csie.ntu.edu.tw/&amp;sim;cjlin/libsvm/">https://www.csie.ntu.edu.tw/∼cjlin/libsvm/</ext-link>) software package. The CCCs and classification performance showed no significant difference between MT–SCCALR and DSCCA, and they both performed better than JSCCA, especially on the CCCs. This demonstrated that MT–SCCALR had similar CCCs and classification performance to benchmarks, but identified much better class-specific features while those benchmarks cannot.
</p>
      <fig id="btaa434-F3" orientation="portrait" position="float">
        <label>Fig. 3.</label>
        <caption>
          <p>Comparison of the mean CCCs and classification accuracy obtained from fivefold testing trials on synthetic data</p>
        </caption>
        <graphic xlink:href="btaa434f3"/>
      </fig>
    </sec>
    <sec>
      <title>3.3 Real neuroimaging genetic study</title>
      <p>The real brain imaging and genotyping data were obtained from the ADNI (adni.loni.usc.edu) database. The primary goal of the initiative is to test whether serial magnetic resonance imaging (MRI), or other biological markers, and clinical and neuropsychological assessments can be combined to measure the progression of MCI and early AD. For up-to-date information, see <ext-link ext-link-type="uri" xlink:href="http://www.adni-info.org">www.adni-info.org</ext-link>.</p>
      <p>There are 755 non-Hispanic Caucasian participants, including 182 HC, 292 MCI and 281 AD, whose baseline 18-Fr florbetapir PET scans were collected. We used the pipeline to preprocess these PET scans such as average, alignment, resample, smoothness and normalization to obtain the standardized uptake value ratio (SUVR) images (<xref rid="btaa434-B17" ref-type="bibr">Jagust <italic>et al.</italic>, 2010</xref>). To reduce the time consumption and boost the statistical power, we extracted the region of interest level amyloid measurements instead of the voxel level measurements. We finally generated 116 mean amyloid measurements spanning the whole brain according to the MarsBaR AAL atlas (<xref rid="btaa434-B33" ref-type="bibr">Tzourio-Mazoyer <italic>et al.</italic>, 2002</xref>), and used them as imaging QTs. Moreover, these imaging QTs were preadjusted to remove the effects of the baseline age, gender, handedness and years of education (<xref rid="btaa434-T1" ref-type="table">Table 1</xref>).
</p>
      <table-wrap id="btaa434-T1" orientation="portrait" position="float">
        <label>Table 1.</label>
        <caption>
          <p>Participant characteristics</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1"/>
              <th rowspan="1" colspan="1">HC</th>
              <th rowspan="1" colspan="1">MCI</th>
              <th rowspan="1" colspan="1">AD</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">Number</td>
              <td rowspan="1" colspan="1">182</td>
              <td rowspan="1" colspan="1">292</td>
              <td rowspan="1" colspan="1">281</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Gender (M/F, %)</td>
              <td rowspan="1" colspan="1">48.90/51.10</td>
              <td rowspan="1" colspan="1">48.63/51.37</td>
              <td rowspan="1" colspan="1">53.38/46.62</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Handedness (R/L, %)</td>
              <td rowspan="1" colspan="1">89.56/10.44</td>
              <td rowspan="1" colspan="1">88.70/11.30</td>
              <td rowspan="1" colspan="1">90.39/9.61</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Age (mean±SD)</td>
              <td rowspan="1" colspan="1">73.93±5.51</td>
              <td rowspan="1" colspan="1">70.90±6.84</td>
              <td rowspan="1" colspan="1">72.61±8.15</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Education (mean±SD)</td>
              <td rowspan="1" colspan="1">16.43±2.68</td>
              <td rowspan="1" colspan="1">16.18±2.68</td>
              <td rowspan="1" colspan="1">15.95±2.82</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
      <p>The genotyping data were genotyped by the Human 610-Quad or OmniExpress Array platform (Illumina, Inc., San Diego, CA, USA), and preprocessed following standard quality control and imputation procedures. There were 1692 SNPs included which were collected from the neighbor of AD risk gene <italic>APOE</italic> according to the ANNOVAR annotation. In this study, we intend to study bi-multivariate associations between regional imaging amyloid depositions and SNPs, and with focus on identifying diagnosis-specific amyloid depositions and SNPs, as well as their interactions.</p>
      <sec>
        <label>3.3.1</label>
        <title>Identification and interpretation of imaging QTs</title>
        <p>We applied all three methods to this real neuroimaging genetic data. The selected imaging QTs are highlighted in <xref ref-type="fig" rid="btaa434-F4">Figure 4</xref>, in which there are three columns for both MT–SCCALR and JSCCA. We stacked the canonical weight vector of DSCCA for three times. We observed that DSCCA did not hold the diagnosis-specific feature selection capability due to the nature of its modeling method. JSCCA identified multiple weights corresponding to multiple diagnostic groups, showing a somewhat diverse feature selection. Our method performed the best among three methods as we could observe a much clear diagnosis-specific feature selection profiles. Besides, MT-SCCALR showed a clearly group feature selection patterns due to the structure identification penalties such as <italic>FGL</italic> and <italic>GGL</italic>.
</p>
        <fig id="btaa434-F4" orientation="portrait" position="float">
          <label>Fig. 4.</label>
          <caption>
            <p>Canonical weights (mean) of imaging QTs from fivefold cross-validation trials. Each row corresponds to an SCCA method: (1) DSCCA; (2) JSCCA and (3) MT–SCCALR</p>
          </caption>
          <graphic xlink:href="btaa434f4"/>
        </fig>
        <p>We further investigated the meaning of the selected imaging QTs. MT–SCCALR identified three canonical weight vectors in accordance to three diagnostic groups, i.e. HC, MCI and AD. Most of the HC-specific signals were from the frontal areas, indicating that a subject’s health condition could be determined based on the amyloid burden of these areas. Besides, the cingulum and the precuneus were also highlighted by MT–SCCALR. Interestingly, most of the AD-specific signals were from the frontal area too but with oppositive signs, which matches our intuition. It is obvious that oppositive weights of these areas for HCs and ADs tell us that there are an oppositive amyloid deposition pattern for these two groups. In contrast, both DSCCA and JSCCA cannot draw this in-depth conclusion. For MCI-specific imaging QTs, our method reported signals from the bilateral calcarine, lingual, fusiform and temporal. It seems strange as the frontal areas were not identified, but the truth is not. In general, MCIs have intermediate amyloid burden and thus using the deposition measurement from the frontal might not discriminate MCI subjects from those non-MCI subjects. Moreover, these brain areas had been shown to be related to MCI (<xref rid="btaa434-B26" ref-type="bibr">Pan <italic>et al.</italic>, 2017</xref>), confirming the detection power of our method. Of note, both DSCCA and JSCCA could not identify heterogeneous imaging QTs. The results together demonstrated that the diagnosis-specific feature selection is of great interest and meaning.</p>
      </sec>
      <sec>
        <label>3.3.2</label>
        <title>Identification and interpretation of SNPs</title>
        <p>We presented the identified SNPs in <xref ref-type="fig" rid="btaa434-F5">Figure 5</xref>. In this figure, both DSCCA and JSCCA only identified one canonical weight vector for all tasks, and we stacked them for three times. We observed that all three methods identified rs429358 (<italic>APOE</italic>), i.e. the well-known AD-risk loci. Taking the top five selected SNPs as examples, DSCCA identified two additional AD associated locus rs7412 (<italic>APOE</italic>) (<xref rid="btaa434-B42" ref-type="bibr">Yi <italic>et al.</italic>, 2014</xref>) and rs10119 (<italic>TOMM40</italic>), with further investigation being warranted for rs4803792 and rs203711. JSCCA also identified SNPs from AD-associated genes such as <italic>APOC1</italic> (rs7247707, rs10414043 and rs7256200) and <italic>APOE</italic> (rs1081105), indicating its better identification than DSCCA. MT-SCCALR exhibited distinct patterns as it assigned different weight values (importance) for each SNP for different groups. At first glance, the SNPs for HC, MCI and AD were similar. However, similar to that for imaging QTs, our method yielded oppositive feature signs for HC versus non-HC, and AD versus non-AD tasks. This is interesting as it reveals that HCs and ADs hold different genotypes which provide us a more in-depth clue. Compared to benchmarks which only tell us that a SNP is relevant or irrelevant, our method not only reveals whether a SNP is relevant, but also implies the directionality of the genetic effect. One may argue that we can swap both signs for imaging QTs and SNPs simultaneously, but the directionality of the imaging genetic correlation stays the same. Therefore, based on the heterogeneous multitasking, our method could successfully identify a diverse diagnosis-specific SNPs. These results suggest that MT-SCCALR is quite promising and might possess enhanced feature selection ability in imaging genetics.
</p>
        <fig id="btaa434-F5" orientation="portrait" position="float">
          <label>Fig. 5.</label>
          <caption>
            <p>Canonical weights (mean) of SNPs from fivefold cross-validation trials. Each row corresponds to an SCCA method: (1) DSCCA; (2) JSCCA and (3) MT–SCCALR</p>
          </caption>
          <graphic xlink:href="btaa434f5"/>
        </fig>
      </sec>
      <sec>
        <label>3.3.3</label>
        <title>Bi-multivariate association and classification</title>
        <p>Finally, the testing CCC and classification accuracy are shown in <xref ref-type="fig" rid="btaa434-F6">Figure 6</xref>, in which a higher value indicated a stronger association or more accurate prediction. It is clear that DSCCA estimated the highest CCCs as it used all sample size to yield the CCC. Our method obtained better CCCs than JSCCA due to the OAA class binarization. Using the top ten selected features, including both imaging QTs and SNPs, of each method, we used LIBSVM (<ext-link ext-link-type="uri" xlink:href="https://www.csie.ntu.edu.tw/&amp;sim;cjlin/libsvm/">https://www.csie.ntu.edu.tw/∼cjlin/libsvm/</ext-link>) software package to implement SVM using the linear kernel with default setting. The classification results showed that all three methods performed similarly, implying that it is difficult to separate this real imaging genetic data (<xref rid="btaa434-B35" ref-type="bibr">Wang <italic>et al.</italic>, 2012a</xref>). On the contrary, this confirms the necessity and meaning of the diagnosis-specific feature selection, which could be helpful to subgroups identification. As a result, following the multitask modeling, MT–SCCALR showed a promising performance in multiclass imaging genetics.
</p>
        <fig id="btaa434-F6" orientation="portrait" position="float">
          <label>Fig. 6.</label>
          <caption>
            <p>Comparison of the mean CCCs and classification accuracy obtained from fivefold testing trials on ADNI</p>
          </caption>
          <graphic xlink:href="btaa434f6"/>
        </fig>
      </sec>
    </sec>
  </sec>
  <sec>
    <title>4 Conclusion</title>
    <p>Identifying diagnosis-specific genetic markers and brain imaging measurements is an important task in precision medicine. AD is a severe neurodegenerative disorder presenting significant heterogeneity and diversity (<xref rid="btaa434-B19" ref-type="bibr">Lam <italic>et al.</italic>, 2013</xref>; <xref rid="btaa434-B37" ref-type="bibr">Wang <italic>et al.</italic>, 2015</xref>). Most existing bi-multivariate learning methods were unsupervised. Although a few studies made progress on supervised bi-multivariate learning, they could not identify diagnosis-specific biomarkers. We formally defined the framework of diagnosis-specific feature selection for imaging genetics, and proposed a computational method to identify diagnosis-specific, as well as diagnosis-consistent, feature subsets. Different to existing supervised SCCA, MT–SCCALR learned canonical weight matrices with each column corresponding to a diagnostic group. Using fused LR and SCCA, as well as the regularization, our model could identify meaningful and distinct imaging QTs and SNPs for each group. The algorithm was proved to converge to a local optimum.</p>
    <p>Experiments on both synthetic data and real neuroimaging genetic data were conducted. Compared with two state-of-the-art methods [DSCCA (<xref rid="btaa434-B40" ref-type="bibr">Yan <italic>et al.</italic>, 2017</xref>) and JSCCA (<xref rid="btaa434-B14" ref-type="bibr">Fang <italic>et al.</italic>, 2016</xref>)], MT–SCCALR obtained similar correlation coefficients and classification accuracies to DSCCA and JSCCA. But it outperformed both benchmarks on revealing canonical weights on both synthetic and real data. In particular, our method successfully identified diagnosis-specific features including QTs and SNPs, while those benchmarks cannot. We also demonstrated that within each diagnostic group, the identified imaging QTs and SNPs were inconsistent, indicating that different diagnostic groups could carry different feature subsets. This is more reasonable and practical than existing methods as mounting evidences suggest that the sporadic AD might not be a single disease (<xref rid="btaa434-B2" ref-type="bibr">Au <italic>et al.</italic>, 2015</xref>). These results reveal that MT-SCCALR gains a promising success in diverse feature selection for multiple diagnostic groups in imaging genetics as well as multiple omics analysis. However, as the calculation of Hessian matrix and gradient of <italic>GGL</italic> penalty is time-intensive, we suggest using brain region-based imaging measurements other than voxel-based ones. An interesting future direction could be to make our method able to stratify different AD patients instead of only identifying diagnosis-specific features.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material content-type="local-data" id="sup1">
      <label>btaa434_Supplementary_Data</label>
      <media xlink:href="btaa434_supplementary_data.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ack id="ack1">
    <title>Acknowledgements</title>
    <p>Data collection and sharing for this project was funded by the ADNI (National Institutes of Health Grant U01 AG024904) and DOD ADNI (Department of Defense award number W81XWH-12-2-0012). ADNI is funded by the National Institute on Aging, the National Institute of Biomedical Imaging and Bioengineering and through generous contributions from the following: AbbVie, Alzheimer’s Association; Alzheimer’s Drug Discovery Foundation; Araclon Biotech; BioClinica, Inc.; Biogen; Bristol-Myers Squibb Company; CereSpir, Inc.; Cogstate; Eisai Inc.; Elan Pharmaceuticals, Inc.; Eli Lilly and Company; EuroImmun; F. HoffmannLa Roche Ltd and its affiliated company Genentech, Inc.; Fujirebio; GE Healthcare; IXICO Ltd.; Janssen Alzheimer Immunotherapy Research &amp; Development, LLC.; Johnson &amp; Johnson Pharmaceutical Research &amp; Development LLC.; Lumosity; Lundbeck; Merck &amp; Co., Inc.; Meso Scale Diagnostics, LLC.; NeuroRx Research; Neurotrack Technologies; Novartis Pharmaceuticals Corporation; Pfizer Inc.; Piramal Imaging; Servier; Takeda Pharmaceutical Company; and Transition Therapeutics. The Canadian Institutes of Health Research is providing funds to support ADNI clinical sites in Canada. Private sector contributions are facilitated by the Foundation for the National Institutes of Health (<ext-link ext-link-type="uri" xlink:href="http://www.fnih.org">www.fnih.org</ext-link>). The grantee organization is the Northern California Institute for Research and Education, and the study is coordinated by the Alzheimer’s Therapeutic Research Institute at the University of Southern California. ADNI data are disseminated by the Laboratory for Neuro Imaging at the University of Southern California.</p>
    <sec>
      <title>Funding</title>
      <p>This work was supported by the National Natural Science Foundation of China [61973255, 61602384]; Natural Science Basic Research Program of Shaanxi [2020JM-142]; China Postdoctoral Science Foundation [2017M613202] and Postdoctoral Science Foundation of Shaanxi [2017BSHEDZZ81] at Northwestern Polytechnical University. This work was also supported by the National Institutes of Health [R01 EB022574, RF1 AG063481, U19 AG024904, P30 AG10133, R01 AG19771] at University of Pennsylvania and Indiana University.</p>
      <p><italic>Conflict of Interest</italic>: none declared.</p>
    </sec>
  </ack>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="btaa434-B1">
      <mixed-citation publication-type="journal">Alzheimer's Association (<year>2013</year>) 
<article-title>2013 Alzheimer’s disease facts and figures</article-title>. <source>Alzheimers Dement</source>., <volume>9</volume>, <fpage>208</fpage>–<lpage>245</lpage>.<pub-id pub-id-type="pmid">23507120</pub-id></mixed-citation>
    </ref>
    <ref id="btaa434-B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Au</surname><given-names>R.</given-names></name></person-group><etal>et al</etal> (<year>2015</year>) 
<article-title>Back to the future: Alzheimer’s disease heterogeneity revisited. <italic>Alzheimer’s &amp; Dementia: diagnosis</italic></article-title>. <source>Assess. Dis. Monit</source>., <volume>1</volume>, <fpage>368</fpage>–<lpage>370</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa434-B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Baggenstoss</surname><given-names>P.M.</given-names></name></person-group> (<year>1999</year>) 
<article-title>Class-specific feature sets in classification</article-title>. <source>IEEE Trans. Signal Process</source>., <volume>47</volume>, <fpage>3428</fpage>–<lpage>3432</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa434-B4">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Beaton</surname><given-names>D.</given-names></name></person-group><etal>et al</etal> (<year>2014</year>) Imaging genetics with partial least squares for mixed-data types (MiMoPLS). In: <italic>International Conference on Partial Least Squares and Related Methods</italic>, pp. 73–91. Springer, Paris, France.</mixed-citation>
    </ref>
    <ref id="btaa434-B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Bullmore</surname><given-names>E.T.</given-names></name>, <name name-style="western"><surname>Sporns</surname><given-names>O.</given-names></name></person-group> (<year>2009</year>) 
<article-title>Complex brain networks: graph theoretical analysis of structural and functional systems</article-title>. <source>Nat. Rev. Neurosci</source>., <volume>10</volume>, <fpage>186</fpage>–<lpage>198</lpage>.<pub-id pub-id-type="pmid">19190637</pub-id></mixed-citation>
    </ref>
    <ref id="btaa434-B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Chen</surname><given-names>J.</given-names></name></person-group><etal>et al</etal> (<year>2013</year>) 
<article-title>Structure-constrained sparse canonical correlation analysis with an application to microbiome data analysis</article-title>. <source>Biostatistics</source>, <volume>14</volume>, <fpage>244</fpage>–<lpage>258</lpage>.<pub-id pub-id-type="pmid">23074263</pub-id></mixed-citation>
    </ref>
    <ref id="btaa434-B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Chen</surname><given-names>X.</given-names></name>, <name name-style="western"><surname>Liu</surname><given-names>H.</given-names></name></person-group> (<year>2012</year>) 
<article-title>An efficient optimization algorithm for structured sparse CCA, with applications to eQTL mapping</article-title>. <source>Stat. Biosci</source>., <volume>4</volume>, <fpage>3</fpage>–<lpage>26</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa434-B8">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Du</surname><given-names>L.</given-names></name></person-group><etal>et al</etal>; for the Alzheimer’s Disease Neuroimaging Initiative. (<year>2016</year>) 
<article-title>Structured sparse canonical correlation analysis for brain imaging genetics: an improved GraphNet method</article-title>. <source>Bioinformatics</source>, <volume>32</volume>, <fpage>1544</fpage>–<lpage>1551</lpage>.<pub-id pub-id-type="pmid">26801960</pub-id></mixed-citation>
    </ref>
    <ref id="btaa434-B9">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Du</surname><given-names>L.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) Identifying associations between brain imaging phenotypes and genetic factors via a novel structured SCCA approach. In: <italic>International Conference on Information Processing in Medical Imaging</italic>, pp. <fpage>543</fpage>–<lpage>555</lpage>. Springer, Boone, North Carolina, USA.</mixed-citation>
    </ref>
    <ref id="btaa434-B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Du</surname><given-names>L.</given-names></name></person-group><etal>et al</etal>; for the Alzheimer’s Disease Neuroimaging Initiative. (<year>2018</year>) 
<article-title>A novel SCCA approach via truncated <inline-formula id="IE129"><mml:math id="IM129"><mml:mrow><mml:msub><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>-norm and truncated group lasso for brain imaging genetics</article-title>. <source>Bioinformatics</source>, <volume>34</volume>, <fpage>278</fpage>–<lpage>285</lpage>.<pub-id pub-id-type="pmid">28968815</pub-id></mixed-citation>
    </ref>
    <ref id="btaa434-B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Du</surname><given-names>L.</given-names></name></person-group><etal>et al</etal>; Alzheimer’s Disease Neuroimaging Initiative. (<year>2019</year>a) 
<article-title>Identifying progressive imaging genetic patterns via multi-task sparse canonical correlation analysis: a longitudinal study of the ADNI cohort</article-title>. <source>Bioinformatics</source>, <volume>35</volume>, <fpage>i474</fpage>–<lpage>i483</lpage>.<pub-id pub-id-type="pmid">31510645</pub-id></mixed-citation>
    </ref>
    <ref id="btaa434-B12">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Du</surname><given-names>L.</given-names></name></person-group><etal>et al</etal> (<year>2019</year>b) Multi-task sparse canonical correlation analysis with application to multi-modal brain imaging genetics. <italic>IEEE ACM Trans. Comput. Biol. Bioinf.</italic>, doi: 10.1109/TCBB.2019.2947428.</mixed-citation>
    </ref>
    <ref id="btaa434-B13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Du</surname><given-names>L.</given-names></name></person-group><etal>et al</etal> (<year>2020</year>) 
<article-title>Detecting genetic associations with brain imaging phenotypes in Alzheimer’s disease via a novel structured SCCA approach</article-title>. <source>Med. Image Anal</source>., <volume>61</volume>, <fpage>101656</fpage>.<pub-id pub-id-type="pmid">32062154</pub-id></mixed-citation>
    </ref>
    <ref id="btaa434-B14">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Fang</surname><given-names>J.</given-names></name></person-group><etal>et al</etal> (<year>2016</year>) 
<article-title>Joint sparse canonical correlation analysis for detecting differential imaging genetics modules</article-title>. <source>Bioinformatics</source>, <volume>32</volume>, <fpage>3480</fpage>–<lpage>3488</lpage>.<pub-id pub-id-type="pmid">27466625</pub-id></mixed-citation>
    </ref>
    <ref id="btaa434-B15">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Ferreira</surname><given-names>D.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) 
<article-title>Distinct subtypes of Alzheimer’s disease based on patterns of brain atrophy: longitudinal trajectories and clinical applications</article-title>. <source>Sci. Rep</source>., <volume>7</volume>, <fpage>46263</fpage>.<pub-id pub-id-type="pmid">28417965</pub-id></mixed-citation>
    </ref>
    <ref id="btaa434-B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Gorski</surname><given-names>J.</given-names></name></person-group><etal>et al</etal> (<year>2007</year>) 
<article-title>Biconvex sets and optimization with biconvex functions: a survey and extensions</article-title>. <source>Math. Method Oper. Res</source>., <volume>66</volume>, <fpage>373</fpage>–<lpage>407</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa434-B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Jagust</surname><given-names>W.J.</given-names></name></person-group><etal>et al</etal> (<year>2010</year>) 
<article-title>The Alzheimer’s disease neuroimaging initiative positron emission tomography core</article-title>. <source>Alzheimers Dement</source>., <volume>6</volume>, <fpage>221</fpage>–<lpage>229</lpage>.<pub-id pub-id-type="pmid">20451870</pub-id></mixed-citation>
    </ref>
    <ref id="btaa434-B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Krishnapuram</surname><given-names>B.</given-names></name></person-group><etal>et al</etal> (<year>2005</year>) 
<article-title>Sparse multinomial logistic regression: fast algorithms and generalization bounds</article-title>. <source>IEEE Trans. Pattern Anal. Mach. Intell</source>., <volume>27</volume>, <fpage>957</fpage>–<lpage>968</lpage>.<pub-id pub-id-type="pmid">15943426</pub-id></mixed-citation>
    </ref>
    <ref id="btaa434-B19">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Lam</surname><given-names>B.</given-names></name></person-group><etal>et al</etal> (<year>2013</year>) 
<article-title>Clinical, imaging, and pathological heterogeneity of the Alzheimer’s disease syndrome</article-title>. <source>Alzheimer’s Res. Therapy</source>, <volume>5</volume>, <fpage>1</fpage>–<lpage>14</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa434-B20">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Lee</surname><given-names>S.-I.</given-names></name></person-group><etal>et al</etal> (<year>2006</year>) 
<article-title>Efficient L1 regularized logistic regression</article-title>. <source>AAAI</source>, <volume>6</volume>, <fpage>401</fpage>–<lpage>408</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa434-B21">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Lin</surname><given-names>C.-J.</given-names></name></person-group><etal>et al</etal> (<year>2007</year>) Trust region newton methods for large-scale logistic regression. In: <italic>International Conference on Machine Learning</italic>, pp. <fpage>561</fpage>–<lpage>568</lpage>. ACM, Corvallis, Oregon, USA .</mixed-citation>
    </ref>
    <ref id="btaa434-B22">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Lorena</surname><given-names>A.C.</given-names></name></person-group><etal>et al</etal> (<year>2008</year>) 
<article-title>A review on the combination of binary classifiers in multiclass problems</article-title>. <source>Artif. Intell. Rev</source>., <volume>30</volume>, <fpage>19</fpage>–<lpage>37</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa434-B23">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Mueller</surname><given-names>S.G.</given-names></name></person-group><etal>et al</etal> (<year>2005</year>) 
<article-title>The Alzheimer’s disease neuroimaging initiative</article-title>. <source>NeuroImage Clin. N. Am</source>., <volume>15</volume>, <fpage>869</fpage>–<lpage>877</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa434-B24">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Mukherjee</surname><given-names>S.</given-names></name></person-group><etal>et al</etal> (<year>2018</year>) Genetic data and cognitively defined late-onset Alzheimer’s disease subgroups. <italic>Mol. Psychiatr.</italic> doi: <pub-id pub-id-type="doi">10.1038/s41380-018-0298-8</pub-id> .</mixed-citation>
    </ref>
    <ref id="btaa434-B25">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Murray</surname><given-names>M.E.</given-names></name>, <name name-style="western"><surname>Dickson</surname><given-names>D.</given-names></name></person-group> (<year>2008</year>) 
<article-title>O1-01-02: Alzheimer’s disease with relative hippocampal sparing: a distinct clinicopathologic variant</article-title>. <source>Alzheimers Dement</source>., <volume>4</volume>, <fpage>T106</fpage>.</mixed-citation>
    </ref>
    <ref id="btaa434-B26">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Pan</surname><given-names>P.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) 
<article-title>Aberrant spontaneous low-frequency brain activity in amnestic mild cognitive impairment: a meta-analysis of resting-state fMRI studies</article-title>. <source>Ageing Res. Rev</source>., <volume>35</volume>, <fpage>12</fpage>–<lpage>21</lpage>.<pub-id pub-id-type="pmid">28017880</pub-id></mixed-citation>
    </ref>
    <ref id="btaa434-B27">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Pineda-Bautista</surname><given-names>B.B.</given-names></name></person-group><etal>et al</etal> (<year>2011</year>) 
<article-title>General framework for class-specific feature selection</article-title>. <source>Expert Syst. Appl</source>., <volume>38</volume>, <fpage>10018</fpage>–<lpage>10024</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa434-B28">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Reich</surname><given-names>D.E.</given-names></name></person-group><etal>et al</etal> (<year>2001</year>) 
<article-title>Linkage disequilibrium in the human genome</article-title>. <source>Nature</source>, <volume>411</volume>, <fpage>199</fpage>–<lpage>204</lpage>.<pub-id pub-id-type="pmid">11346797</pub-id></mixed-citation>
    </ref>
    <ref id="btaa434-B29">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Saykin</surname><given-names>A.J.</given-names></name></person-group><etal>et al</etal>; Alzheimer's Disease Neuroimaging Initiative. (<year>2015</year>) 
<article-title>Genetic studies of quantitative MCI and AD phenotypes in ADNI: progress, opportunities, and plans</article-title>. <source>Alzheimers Dement</source>., <volume>11</volume>, <fpage>792</fpage>–<lpage>814</lpage>.<pub-id pub-id-type="pmid">26194313</pub-id></mixed-citation>
    </ref>
    <ref id="btaa434-B30">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Shen</surname><given-names>L.</given-names></name>, <name name-style="western"><surname>Thompson</surname><given-names>P.M.</given-names></name></person-group> (<year>2020</year>) 
<article-title>Brain imaging genomics: integrated analysis and machine learning</article-title>. <source>Proc. IEEE</source>, <volume>108</volume>, <fpage>125</fpage>–<lpage>162</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa434-B31">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Shen</surname><given-names>L.</given-names></name></person-group><etal>et al</etal> (<year>2010</year>) 
<article-title>Whole genome association study of brain-wide imaging phenotypes for identifying quantitative trait loci in MCI and AD: a study of the ADNI cohort</article-title>. <source>NeuroImage</source>, <volume>53</volume>, <fpage>1051</fpage>–<lpage>1063</lpage>.<pub-id pub-id-type="pmid">20100581</pub-id></mixed-citation>
    </ref>
    <ref id="btaa434-B32">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Shen</surname><given-names>L.</given-names></name></person-group><etal>et al</etal>; Alzheimer's Disease Neuroimaging Initiative. (<year>2014</year>) 
<article-title>Genetic analysis of quantitative phenotypes in AD and MCI: imaging, cognition and biomarkers</article-title>. <source>Brain Imaging Behav</source>., <volume>8</volume>, <fpage>183</fpage>–<lpage>207</lpage>.<pub-id pub-id-type="pmid">24092460</pub-id></mixed-citation>
    </ref>
    <ref id="btaa434-B33">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Tzourio-Mazoyer</surname><given-names>N.</given-names></name></person-group><etal>et al</etal> (<year>2002</year>) 
<article-title>Automated anatomical labeling of activations in SPM using a macroscopic anatomical parcellation of the MNI MRI single-subject brain</article-title>. <source>NeuroImage</source>, <volume>15</volume>, <fpage>273</fpage>–<lpage>289</lpage>.<pub-id pub-id-type="pmid">11771995</pub-id></mixed-citation>
    </ref>
    <ref id="btaa434-B34">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Vounou</surname><given-names>M.</given-names></name></person-group><etal>et al</etal> (<year>2010</year>) 
<article-title>Discovering genetic associations with high-dimensional neuroimaging phenotypes: a sparse reduced-rank regression approach</article-title>. <source>NeuroImage</source>, <volume>53</volume>, <fpage>1147</fpage>–<lpage>1159</lpage>.<pub-id pub-id-type="pmid">20624472</pub-id></mixed-citation>
    </ref>
    <ref id="btaa434-B35">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Wang</surname><given-names>H.</given-names></name></person-group><etal>et al</etal>; for the Alzheimer's Disease Neuroimaging Initiative. (<year>2012</year>a) 
<article-title>Identifying disease sensitive and quantitative trait-relevant biomarkers from multidimensional heterogeneous imaging genetics data via sparse multimodal multitask learning</article-title>. <source>Bioinformatics</source>, <volume>28</volume>, <fpage>i127</fpage>–<lpage>i136</lpage>.<pub-id pub-id-type="pmid">22689752</pub-id></mixed-citation>
    </ref>
    <ref id="btaa434-B36">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Wang</surname><given-names>H.</given-names></name></person-group><etal>et al</etal> (<year>2012</year>b) 
<article-title>Identifying quantitative trait loci via group-sparse multitask regression and feature selection: an imaging genetics study of the ADNI cohort</article-title>. <source>Bioinformatics</source>, <volume>28</volume>, <fpage>229</fpage>–<lpage>237</lpage>.<pub-id pub-id-type="pmid">22155867</pub-id></mixed-citation>
    </ref>
    <ref id="btaa434-B37">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Wang</surname><given-names>X.</given-names></name></person-group><etal>et al</etal> (<year>2015</year>) Classification of MRI under the presence of disease heterogeneity using multi-task learning: application to bipolar disorder. In: <italic>International Conference on Medical Image Computing and Computer-Assisted Intervention</italic>, pp. <fpage>125</fpage>–<lpage>132</lpage>. Springer, Munich, Germany.</mixed-citation>
    </ref>
    <ref id="btaa434-B38">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Wang</surname><given-names>L.</given-names></name></person-group><etal>et al</etal> (<year>2016</year>) 
<article-title>Feature selection methods for big data bioinformatics: a survey from the search perspective</article-title>. <source>Methods</source>, <volume>111</volume>, <fpage>21</fpage>–<lpage>31</lpage>.<pub-id pub-id-type="pmid">27592382</pub-id></mixed-citation>
    </ref>
    <ref id="btaa434-B39">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Witten</surname><given-names>D.M.</given-names></name>, <name name-style="western"><surname>Tibshirani</surname><given-names>R.J.</given-names></name></person-group> (<year>2009</year>) 
<article-title>Extensions of sparse canonical correlation analysis with applications to genomic data</article-title>. <source>Stat. Appl. Genet. Mol</source>., <volume>8</volume>, <fpage>1</fpage>–<lpage>27</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa434-B40">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Yan</surname><given-names>J.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) Identification of discriminative imaging proteomics associations in Alzheimer’s disease via a novel sparse correlation model. In: <italic>Pacific Symposium on Biocomputing 2017</italic>, pp. <fpage>94</fpage>–<lpage>104</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa434-B41">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Yan</surname><given-names>J.</given-names></name></person-group><etal>et al</etal> (<year>2018</year>) Joint exploration and mining of memory-relevant brain anatomic and connectomic patterns via a three-way association model. In: <italic>International Symposium on Biomedical Imaging</italic>, pp. <fpage>6</fpage>–<lpage>9</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa434-B42">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Yi</surname><given-names>L.</given-names></name></person-group><etal>et al</etal> (<year>2014</year>) 
<article-title>A non-invasive, rapid method to genotype late-onset Alzheimer’s disease-related apolipoprotein E gene polymorphisms</article-title>. <source>Neural Regen. Res</source>., <volume>9</volume>, <fpage>69</fpage>.<pub-id pub-id-type="pmid">25206745</pub-id></mixed-citation>
    </ref>
    <ref id="btaa434-B43">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Zaidi</surname><given-names>N.A.</given-names></name>, <name name-style="western"><surname>Webb</surname><given-names>G.I.</given-names></name></person-group> (<year>2017</year>) A fast trust-region newton method for softmax logistic regression. In: <italic>SIAM International Conference on Data Mining</italic>, pp. <fpage>705</fpage>–<lpage>713</lpage>. SIAM, Houston, Texas, USA.</mixed-citation>
    </ref>
    <ref id="btaa434-B44">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Zhang</surname><given-names>M.-L.</given-names></name>, <name name-style="western"><surname>Wu</surname><given-names>L.</given-names></name></person-group> (<year>2015</year>) 
<article-title>Lift: multi-label learning with label-specific features</article-title>. <source>IEEE Trans. Pattern Anal. Mach. Intell</source>., <volume>37</volume>, <fpage>107</fpage>–<lpage>120</lpage>.<pub-id pub-id-type="pmid">26353212</pub-id></mixed-citation>
    </ref>
    <ref id="btaa434-B45">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Zille</surname><given-names>P.</given-names></name></person-group><etal>et al</etal> (<year>2018</year>) 
<article-title>Enforcing co-expression within a brain-imaging genomics regression framework</article-title>. <source>IEEE Trans. Med. Imaging</source>, <volume>37</volume>, <fpage>2561</fpage>–<lpage>2571</lpage>.<pub-id pub-id-type="pmid">28678703</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
