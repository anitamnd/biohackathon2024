<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Nat Commun</journal-id>
    <journal-id journal-id-type="iso-abbrev">Nat Commun</journal-id>
    <journal-title-group>
      <journal-title>Nature Communications</journal-title>
    </journal-title-group>
    <issn pub-type="epub">2041-1723</issn>
    <publisher>
      <publisher-name>Nature Publishing Group UK</publisher-name>
      <publisher-loc>London</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">6726615</article-id>
    <article-id pub-id-type="publisher-id">11994</article-id>
    <article-id pub-id-type="doi">10.1038/s41467-019-11994-0</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Article</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Deep learning extends de novo protein modelling coverage of genomes using iteratively predicted structural constraints</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" equal-contrib="yes">
        <name>
          <surname>Greener</surname>
          <given-names>Joe G.</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author" equal-contrib="yes">
        <name>
          <surname>Kandathil</surname>
          <given-names>Shaun M.</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Jones</surname>
          <given-names>David T.</given-names>
        </name>
        <address>
          <email>d.t.jones@ucl.ac.uk</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ISNI">0000000121901201</institution-id><institution-id institution-id-type="GRID">grid.83440.3b</institution-id><institution>Department of Computer Science, </institution><institution>University College London, </institution></institution-wrap>Gower Street, London, WC1E 6BT UK </aff>
      <aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0004 1795 1830</institution-id><institution-id institution-id-type="GRID">grid.451388.3</institution-id><institution>The Francis Crick Institute, </institution></institution-wrap>1 Midland Road, London, NW1 1AT UK </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>4</day>
      <month>9</month>
      <year>2019</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>4</day>
      <month>9</month>
      <year>2019</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2019</year>
    </pub-date>
    <volume>10</volume>
    <elocation-id>3977</elocation-id>
    <history>
      <date date-type="received">
        <day>1</day>
        <month>4</month>
        <year>2019</year>
      </date>
      <date date-type="accepted">
        <day>14</day>
        <month>8</month>
        <year>2019</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2019</copyright-statement>
      <license license-type="OpenAccess">
        <license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. The images or other third party material in this article are included in the article’s Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this license, visit <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>.</license-p>
      </license>
    </permissions>
    <abstract id="Abs1">
      <p id="Par1">The inapplicability of amino acid covariation methods to small protein families has limited their use for structural annotation of whole genomes. Recently, deep learning has shown promise in allowing accurate residue-residue contact prediction even for shallow sequence alignments. Here we introduce DMPfold, which uses deep learning to predict inter-atomic distance bounds, the main chain hydrogen bond network, and torsion angles, which it uses to build models in an iterative fashion. DMPfold produces more accurate models than two popular methods for a test set of CASP12 domains, and works just as well for transmembrane proteins. Applied to all Pfam domains without known structures, confident models for 25% of these so-called dark families were produced in under a week on a small 200 core cluster. DMPfold provides models for 16% of human proteome UniProt entries without structures, generates accurate models with fewer than 100 sequences in some cases, and is freely available.</p>
    </abstract>
    <abstract id="Abs2" abstract-type="web-summary">
      <p id="Par2">Prediction of protein structures on the scale of genomes remains a challenge. Here the authors introduce a protein structure prediction method that uses deep learning to predict inter-atomic distances, torsion angles and hydrogen bonds, and apply it to predict the structures of 1475 Pfam domains.</p>
    </abstract>
    <kwd-group kwd-group-type="npg-subject">
      <title>Subject terms</title>
      <kwd>Computational biology and bioinformatics</kwd>
      <kwd>Machine learning</kwd>
      <kwd>Protein structure predictions</kwd>
      <kwd>Proteome informatics</kwd>
    </kwd-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution>European Research Council Advanced Grant “ProCovar” (project ID 695558)</institution>
        </funding-source>
      </award-group>
    </funding-group>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>© The Author(s) 2019</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="Sec1" sec-type="introduction">
    <title>Introduction</title>
    <p id="Par3">In recent years, the ability to accurately predict residue-residue contacts in protein structures from a family of protein sequences has increased dramatically, mainly due to the recent breakthrough in developing statistical models which can separate direct from indirect correlation effects<sup><xref ref-type="bibr" rid="CR1">1</xref>,<xref ref-type="bibr" rid="CR2">2</xref></sup>. Methods to generate accurate protein models from predicted contacts, which may be incomplete or have many false positives, have received far less attention. Model generation is usually treated as a separate step from contact prediction<sup><xref ref-type="bibr" rid="CR3">3</xref></sup>.</p>
    <p id="Par4">Existing approaches for template-free model generation using predicted residue-residue contacts tend to fall into two categories. Well established fragment-based methods such as Rosetta<sup><xref ref-type="bibr" rid="CR4">4</xref></sup> and FRAGFOLD<sup><xref ref-type="bibr" rid="CR5">5</xref></sup> add constraints from predicted contacts to an existing fragment assembly pipeline. Fragment-based methods have performed well in the biennial Critical Assessment of protein Structure Prediction (CASP) experiments<sup><xref ref-type="bibr" rid="CR6">6</xref></sup> but take a large amount of computing power, produce a variable fraction of native-like models and are dependent on native-like fragments being available. For complex beta-sheet topologies, particularly those with high contact order, fragment assembly often fails to produce a viable model, despite attempts at overcoming these limitations<sup><xref ref-type="bibr" rid="CR7">7</xref></sup>.</p>
    <p id="Par5">An attractive, but far less popular approach to de novo modelling has been to use distance geometry to project contact information into 3-D space, similar to the procedures used in NMR structure determination e.g., the DRAGON method of Taylor and Aszódi<sup><xref ref-type="bibr" rid="CR8">8</xref></sup>. More recently, however, distance geometry-based approaches have become more widely used thanks to the improvements in covariation-based contact predictions. For example, CONFOLD2<sup><xref ref-type="bibr" rid="CR9">9</xref></sup> and EVfold<sup><xref ref-type="bibr" rid="CR10">10</xref></sup> add constraints from predicted contacts to standard inter-atomic distance constraints, then use software such as CNS<sup><xref ref-type="bibr" rid="CR11">11</xref></sup> to generate coordinates from these constraints. CONFOLD2 integrates secondary structure and predicted contacts in a two-stage modelling approach, where unsatisfied contacts are filtered out after initial model generation. These methods are computationally cheaper than fragment assembly but produce poor models without a large number of sufficiently accurate predicted contacts. They are also susceptible to producing mirrored topologies where the secondary structures have the correct handedness, but the overall 3-D packing of the secondary structural elements is itself a mirror of the native structure<sup><xref ref-type="bibr" rid="CR12">12</xref>,<xref ref-type="bibr" rid="CR13">13</xref></sup>.</p>
    <p id="Par6">At the recent CASP13 experiment, methods using deep learning approaches to predict distances to use in model building appeared for the first time. AlphaFold used predicted distance likelihoods to generate protein family-specific potentials of mean force that could be directly minimised to generate accurate models. Raptor-X used predicted distances as constraints in CNS to generate models<sup><xref ref-type="bibr" rid="CR14">14</xref></sup>. Two recently proposed deep learning methods attempt to generate model coordinates directly from sequence data by end-to-end training<sup><xref ref-type="bibr" rid="CR15">15</xref>,<xref ref-type="bibr" rid="CR16">16</xref></sup>. Whilst promising, these end-to-end trained methods have not yet shown anything close to state-of-the-art performance in protein modelling, probably because they do not make use of the recent advances in sequence covariation analysis.</p>
    <p id="Par7">Here, we introduce DMPfold, a development of our DeepMetaPSICOV (DMP) contact predictor<sup><xref ref-type="bibr" rid="CR17">17</xref></sup>. Rather than predicting contacts, DMPfold predicts inter-atomic distance bounds, torsion angles and hydrogen bonds and uses these constraints to build models. An iterative process of model generation and constraint refinement is used to filter out unsatisfied constraints. Other modifications to the neural network architectures also differentiate DMPfold from DMP; see the Methods section. We show that DMPfold produces more accurate models than CONFOLD2 and Rosetta for the CASP12 free modelling (FM) domains, with particularly good performance when asked to generate just a single best model. It can also produce high quality models for a set of biologically important transmembrane proteins without any modification for the different prediction task.</p>
    <p id="Par8">Validating the accuracy of a protein structure prediction method is necessary, but an important follow-up question, of more interest to the wider biological research community, is how useful these new methods are in practical terms. In order to demonstrate the utility of DMPfold, we run it on Pfam<sup><xref ref-type="bibr" rid="CR18">18</xref></sup>, a database of protein families. The advantage of this is that it allows these de novo models to be mapped easily to whole genomes so that genome-wide coverage can be assessed. A number of previous studies have also done this<sup><xref ref-type="bibr" rid="CR13">13</xref>,<xref ref-type="bibr" rid="CR19">19</xref>,<xref ref-type="bibr" rid="CR20">20</xref></sup>, so this represents a good indication of how effective deep learning is on an important structural biology problem. First, we show the accuracy of DMPfold on a validation set of over 1000 Pfam families with structures that are known, but not similar to those used in the training of DMPfold. Second, we use this set to develop and verify an accurate estimator of final model accuracy. Finally, we provide to the community models for 1475 Pfam families that are currently lacking structures. Using our predictor of model accuracy, 83% of these models are predicted to have the correct fold. We estimate the increase this provides in the structural coverage of various organisms. This consolidates recent advances in protein structure prediction into a freely available tool that takes just a few hours to run on a standard desktop computer for a typical 200 residue protein domain, making high quality protein structure prediction readily available to the research community. The source code, documentation, trained neural network models and Pfam 3-D models are available at <ext-link ext-link-type="uri" xlink:href="https://github.com/psipred/DMPfold">https://github.com/psipred/DMPfold</ext-link>.</p>
  </sec>
  <sec id="Sec2" sec-type="results">
    <title>Results</title>
    <sec id="Sec3">
      <title>DMPfold on CASP12 targets</title>
      <p id="Par9">This work focuses on the ability of DMPfold to produce accurate models and to carry out genome-scale structure prediction. The ability of DMP to predict residue-residue contacts is assessed separately<sup><xref ref-type="bibr" rid="CR17">17</xref></sup>. In order to compare DMPfold to existing model generation methods that utilise contacts, we convert predicted distances from DMPfold to predicted contacts by summing up the likelihoods in distance bins up to 8 Å. These contacts are then used to generate models with CONFOLD2<sup><xref ref-type="bibr" rid="CR9">9</xref></sup> and Rosetta<sup><xref ref-type="bibr" rid="CR4">4</xref></sup> (in a process similar to the PconsFold<sup><xref ref-type="bibr" rid="CR3">3</xref></sup> protocol), representing one distance geometry and one fragment-based method. Since the contact information is the same across the compared methods, we are comparing the ability to generate models from a set of predicted distances or the equivalent contacts.</p>
      <p id="Par10">The CASP12 set of FM domains with public structures available was used to compare the methods. There are no structures in the DMPfold training set in the same ECOD<sup><xref ref-type="bibr" rid="CR21">21</xref></sup> T-group as these domains. This set contains 22 domains ranging from 55 to 356 residues in length. Figure <xref rid="Fig1" ref-type="fig">1</xref> shows example models generated by DMPfold. Supplementary Fig. <xref rid="MOESM1" ref-type="media">1</xref> shows the DMPfold run time of the CASP12 FM domains. Table <xref rid="Tab1" ref-type="table">1</xref> shows the performance of each method on this set when different numbers of generated models are considered. We use TM-score as a measure of global similarity between a model and the native structure<sup><xref ref-type="bibr" rid="CR22">22</xref></sup>. It can be seen that DMPfold has the best top-1 and top-5 performance of the 3 methods. In fact, DMPfold shows little variation in generated structures for a given input, and effectively produces a single output. This top-1 accuracy is very useful in practical terms, as a biologist requiring a predicted structure would prefer to work with a single model rather than 5 different possible models. Rosetta can produce models with a better mean TM-score amongst a pool of 2000, but finding this most accurate model from the rest is a difficult, and in many cases impossible task. In addition, even when running Rosetta 2000 times, it still gives a structure with a TM-score above 0.5 for one fewer domain than DMPfold generating just a single model. DMPfold is therefore a robust and computationally efficient way to use covariation to obtain accurate 3-D protein models directly from available sequence data alone.<fig id="Fig1"><label>Fig. 1</label><caption><p>Examples of DMPfold models. In each case the model is shown in orange and the native structure, if available, is shown in blue. <bold>a</bold> CASP12 FM domains. <bold>b</bold> A membrane protein from the FILM3 set. <bold>c</bold> Pfam families with available structures, used as a validation set. <bold>d</bold> CASP13 FM target T1010-D1, where DMPfold produced the best model at CASP13 (native structure not public). <bold>e</bold> Models displaying novel folds for Pfam families without structures</p></caption><graphic xlink:href="41467_2019_11994_Fig1_HTML" id="d29e394"/></fig><table-wrap id="Tab1"><label>Table 1</label><caption><p>TM-scores of models generated by each method on CASP12 FM domains</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Method</th><th>Best from <italic>n</italic> models</th><th>Mean TM-score</th><th>Median TM-score</th><th>Minimum TM-score</th><th>Maximum TM-score</th><th>TM-scores above 0.5</th></tr></thead><tbody><tr><td>DMPfold</td><td>1</td><td>0.46</td><td>0.49</td><td>0.20</td><td>0.75</td><td>11/22</td></tr><tr><td>DMPfold</td><td>5</td><td>0.46</td><td>0.49</td><td>0.20</td><td>0.75</td><td>11/22</td></tr><tr><td>CONFOLD2</td><td>1</td><td>0.38</td><td>0.35</td><td>0.16</td><td>0.69</td><td>5/22</td></tr><tr><td>CONFOLD2</td><td>5</td><td>0.42</td><td>0.42</td><td>0.17</td><td>0.69</td><td>8/22</td></tr><tr><td>Rosetta</td><td>1</td><td>0.38</td><td>0.36</td><td>0.17</td><td>0.73</td><td>4/22</td></tr><tr><td>Rosetta</td><td>5</td><td>0.43</td><td>0.41</td><td>0.20</td><td>0.73</td><td>8/22</td></tr><tr><td>Rosetta</td><td>2000</td><td>0.50</td><td>0.49</td><td>0.25</td><td>0.75</td><td>10/22</td></tr></tbody></table><table-wrap-foot><p>In each case a number of models is generated and the highest TM-score to the native structure from the models is recorded for that domain. The mean, median, minimum and maximum are across these highest scores for the 22 CASP12 FM domains with available structures</p></table-wrap-foot></table-wrap></p>
      <p id="Par11">The distribution of TM-scores across the best of 5 models generated for each domain is shown in Fig. <xref rid="Fig2" ref-type="fig">2a</xref>. DMPfold generally produces better models than CONFOLD2 and Rosetta, and is able to produce high-quality models with a TM-score of at least 0.7 for 3 domains with accurate contact predictions. The per-domain accuracy of models generated by DMPfold and CONFOLD2, which both use CNS to generate models from distance constraints, is compared in Fig. <xref rid="Fig2" ref-type="fig">2b</xref>. The corresponding plot for Rosetta is shown in Fig. <xref rid="Fig2" ref-type="fig">2c</xref>. The benefit of iterations to DMPfold is shown by the fact that 19 of 22 domains show higher TM-score at the last iteration than at the first iteration, as shown in Fig. <xref rid="Fig2" ref-type="fig">2d</xref>. Over the course of the iterations, 3 domains move from a TM-score below 0.5 to a TM-score above 0.5. The benefits of using distance constraints rather than contact constraints were also examined. DMPfold was run with 8 Å constraints for residue pairs with a cumulative likelihood of at least 0.5 for bins up to 8 Å. Other aspects such as the iterations, torsion constraints and H-bond constraints were not changed. In this case the TM-scores have mean 0.43, median 0.43 and 10 domains have TM-score above 0.5. By comparison to Table <xref rid="Tab1" ref-type="table">1</xref>, it can be seen that using distances produces better models than using contacts alone.<fig id="Fig2"><label>Fig. 2</label><caption><p>DMPfold results on CASP12 FM domains compared to existing methods. <bold>a</bold> Distribution of TM-scores for the best of the top 5 models for each CASP12 FM domain. <bold>b</bold> Comparison of DMPfold and CONFOLD2 best of top 5 models. The dashed line indicates the point of equal quality models between the two methods, which both use CNS. <bold>c</bold> Similar to <bold>b</bold> but for Rosetta. <bold>d</bold> The change in TM-score and absolute distance error with DMPfold iterations for each domain. Domains are ordered by decreasing iteration 3 TM-score</p></caption><graphic xlink:href="41467_2019_11994_Fig2_HTML" id="d29e635"/></fig></p>
      <p id="Par12">The importance of the three constraint types (distance, torsion and H-bond) to DMPfold is shown in Supplementary Table <xref rid="MOESM1" ref-type="media">1</xref>. Whilst distance constraints are required for successful structure prediction, adding torsion and H-bond constraints to the distance constraints does lead to improved performance, and the best performance is achieved when all three constraint types are combined. The prediction of hydrogen bonds using deep learning and use of these in model generation is a novel contribution of DMPfold. The hydrogen bond predictor is accurate, with a mean of 79% of predicted hydrogen bonds present according to DSSP<sup><xref ref-type="bibr" rid="CR23">23</xref></sup> across the CASP12 FM domains. These predictions take into account the directionality of the hydrogen bonds (i.e., which residue is acting as donor and which is acting as acceptor), which further helps constrain the models.</p>
      <p id="Par13">Comparing DMPfold to the CASP12 server models indicates methodological progress in the field, and is a fair comparison as DMPfold in this case uses sequence data from the time (see the Methods section). The leading servers Zhang-Server and BAKER-ROSETTASERVER both obtained TM-scores above 0.5 for 8 of the 22 FM domains when considering the top model only, compared to 11 of 22 for DMPfold.</p>
      <p id="Par14">The accuracy of the DMPfold distance predictions can also be assessed. For the CASP12 FM domains, predictions where the bin with the maximum likelihood is less than 15 Å were compared to the true distances. The absolute error between the centre of the bin with maximum likelihood and the true distances has a mean of 5.6 Å and a median of 3.1 Å, indicating predictions good enough to build accurate models. Thirteen of 22 cases show lower mean absolute error at the last iteration than at the first iteration, as shown in Fig. <xref rid="Fig2" ref-type="fig">2d</xref>. The usefulness of distance bounds for modelling is highlighted by the number of bounds used that were correct, i.e., satisfied in the native structure. At the last iteration an average of 1399 out of 3640 bounds (38.4%) were satisfied per domain. This compares to an average of 125 out of 226 (55.1%) contacts that were correct, where a contact is considered present if the sum of likelihoods in bins up to 8 Å is at least 0.5. Therefore using distance bounds gives more than 10 times the number of correct structural constraints than using contacts alone for modelling.</p>
    </sec>
    <sec id="Sec4">
      <title>DMPfold on transmembrane targets</title>
      <p id="Par15">Despite structure determination advances in recent years, transmembrane proteins (TMPs) still have very sparse structural coverage even though they play critical roles in the cell<sup><xref ref-type="bibr" rid="CR24">24</xref></sup>. A general method for model generation should be applicable to TMPs without modification. We ran DMPfold without modification on the FILM3 dataset of TMPs<sup><xref ref-type="bibr" rid="CR25">25</xref></sup>, all of which have sizeable sequence families. There was no overlap with the DMPfold training set. Of the 28 proteins, all but 2 had a DMPfold top model with a TM-score of at least 0.5 to the native structure. The mean TM-score of these top models was 0.74, compared to 0.60 for the final refined model in the FILM3 paper results. The same sequence alignments were used for DMPfold as in the FILM3 paper, making this a fair comparison. The distribution of TM-scores and per-protein values for each method are compared in Fig. <xref rid="Fig3" ref-type="fig">3</xref>. These results show that DMPfold is able to generate high quality models for TMPs without specific consideration of TMP properties.<fig id="Fig3"><label>Fig. 3</label><caption><p>Performance of DMPfold on transmembrane proteins. <bold>a</bold> Distribution of TM-scores for the FILM3 TMP dataset. One model is generated for each of the 28 proteins. The FILM3 results are the final refined models from the FILM3 paper<sup><xref ref-type="bibr" rid="CR25">25</xref></sup>. <bold>b</bold> The per-protein correlation of TM-scores. The dashed line indicates the point of equal quality models between the two methods</p></caption><graphic xlink:href="41467_2019_11994_Fig3_HTML" id="d29e686"/></fig></p>
    </sec>
    <sec id="Sec5">
      <title>DMPfold on Pfam families</title>
      <p id="Par16">A Pfam validation set was constructed consisting of 1154 Pfam families with available structures that were not related to the proteins in the DMPfold training set. These structures were either annotated in Pfam or found using HHsearch with an <italic>E</italic>-value threshold of 0.001; see the Methods section. DMPfold was run on target sequences from these families to return a single structure per family. The accuracy of the models is shown in Fig. <xref rid="Fig4" ref-type="fig">4b</xref>. Similar to the CASP12 results and other recent top methods, 52% of models have a TM-score (using TM-align; see the Methods section) of at least 0.5 to the known structural template, indicating the correct fold. The subset of families with structural templates that have an HHsearch <italic>E</italic>-value below 1E-6 gives 66% of models with a TM-score of at least 0.5, indicating that some incorrect predictions may be due to differences between the target sequence and the template. Interestingly, the performance of DMPfold is reasonably robust when predicting folds not seen in the training set: 46% of models in a unique ECOD X-group from the training set (i.e., which have dissimilar structure and no homology to any protein used in training) have a TM-score of at least 0.5 to the known structure. To give users a better indication of the reliability of a given model, we developed a simple neural network to predict the TM-score of a model from its sequence length, family effective sequence count and a measure of how well the final model matches the initial distance prediction distributions. This network has a precision of 82.5% under cross-validation when predicting whether the TM-score is greater than 0.5. Of the models incorrectly predicted to have a TM-score of at least 0.5, 56.3% turn out to still have a TM-score of at least 0.4, indicating that many of the false positive models may still be useful in terms of approximate chain topology. The correlation between real and predicted TM-scores is shown in Supplementary Fig. <xref rid="MOESM1" ref-type="media">2</xref> and has a Pearson correlation coefficient of 0.733 under cross-validation.<fig id="Fig4"><label>Fig. 4</label><caption><p>DMPfold run on Pfam families. <bold>a</bold> Number of Pfam families at each stage of the analysis. Each set is a subset of the previous set. <bold>b</bold> The TM-scores using TM-align of generated models to the native structure for the validation set of Pfam families with available structures not used for DMPfold training. <bold>c</bold> Overlap of high confidence models provided by DMPfold with two other studies that generated models for Pfam families. <bold>d</bold> Comparison of models after refinement provided by ref. <sup><xref ref-type="bibr" rid="CR19">19</xref></sup> with our models where a native structure is available. <bold>e</bold> Comparison of high confidence models provided by ref. <sup><xref ref-type="bibr" rid="CR13">13</xref></sup> with our models where a native structure is available. These are not the same families as in <bold>d</bold></p></caption><graphic xlink:href="41467_2019_11994_Fig4_HTML" id="d29e738"/></fig></p>
      <p id="Par17">We ran DMPfold on the 5214 Pfam families without an annotated structure or available template in the PDB and a target sequence length between 50 and 800 residues. The lower limit of 50 was chosen for comparison to the Baker group study<sup><xref ref-type="bibr" rid="CR19">19</xref></sup>, which used this limit. The numbers at each stage of the modelling pipeline are shown in Fig. <xref rid="Fig4" ref-type="fig">4a</xref>. After filtering for those predicted to have a TM-score of at least 0.5, 1475 Pfam families remained. This represents models for 25.0% of the so-called dark Pfam families<sup><xref ref-type="bibr" rid="CR26">26</xref></sup>. Two recent studies have also made predicted structures available for Pfam families<sup><xref ref-type="bibr" rid="CR13">13</xref>,<xref ref-type="bibr" rid="CR19">19</xref>,<xref ref-type="bibr" rid="CR20">20</xref></sup>. The overlap of our provided models with the Baker group study and PconsFam is shown in Fig. <xref rid="Fig4" ref-type="fig">4c</xref>. We provide 977 models not in either of the other sets. We predict 231 novel folds by comparing structures to the whole PDB with TM-align, and treating models as novel folds if the highest TM-score to the PDB is lower than 0.5. This criterion is the same as used in ref. <sup><xref ref-type="bibr" rid="CR19">19</xref></sup>. This relatively low discovery rate of novel folds is similar to that observed in the various experimental structural genomics projects, e.g. ref. <sup><xref ref-type="bibr" rid="CR27">27</xref></sup>. Some potentially novel folds and validation set structures are shown in Fig. <xref rid="Fig1" ref-type="fig">1</xref>.</p>
      <p id="Par18">The accuracy of models present in both our Pfam validation set and in the sets provided by the previous studies are shown in Fig. <xref rid="Fig4" ref-type="fig">4d, e</xref>. DMPfold gives similar quality models to the Baker group study despite not having an explicit refinement step, not using metagenomic sequences and taking considerably less compute resources. DMPfold generates better models than PconsFam in every case, indicating how the field has progressed from using predicted contacts alone for generating models to the use of richer constraints, particularly distance distributions.</p>
      <p id="Par19">As shown in Fig. <xref rid="Fig5" ref-type="fig">5a</xref>, DMPfold is able to generate models for Pfam families with few sequences available. When the alignment contains 50–100 sequences the chance of generating a model with the correct fold is 22%. This rises to 38% for alignments with 100–200 sequences, 57% for 200–500 sequences, 58% for 500–1000 sequences, 66% for 10<sup>3</sup>–10<sup>4</sup> sequences and 84% for 10<sup>4</sup> or more sequences. Improved success on smaller alignments is a major advantage of DMPfold that makes it applicable to many proteins previously inaccessible to tertiary structure prediction. It also indicates general development in the field from approaches such as PSICOV<sup><xref ref-type="bibr" rid="CR28">28</xref></sup> and CCMpred<sup><xref ref-type="bibr" rid="CR29">29</xref></sup>, which require large alignments to work. This shows the advantage of using deep learning approaches that can make use of sparse data and use a trained knowledge of proteins to fill in the gaps and make more accurate predictions.<fig id="Fig5"><label>Fig. 5</label><caption><p>DMPfold predictions are robust to variations in MSA composition and sequence length. Evaluations are made on the Pfam validation set. <bold>a</bold> Correlation of TM-align score with alignment depth and effective sequence count <italic>N</italic><sub>eff</sub>, defined in the Methods section. The Pearson correlation coefficients are shown. DMPfold is able to generate accurate models for some Pfam families with fewer than 100 sequences in the sequence alignment. <bold>b</bold> There is little correlation of model accuracy with target sequence length. <bold>c</bold> In order to compare with ref. <sup><xref ref-type="bibr" rid="CR19">19</xref></sup>, we calculated the <italic>N</italic><sub>f</sub> with their criteria and plotted the mean model accuracy of models in bins of <italic>N</italic><sub>f</sub> values. <italic>N</italic><sub>f</sub> values were calculated as described in ref. <sup><xref ref-type="bibr" rid="CR19">19</xref></sup>, where an 80% identity threshold was used for clustering. Values were read off the graph in Fig. <xref rid="Fig2" ref-type="fig">2</xref> of ref. <sup><xref ref-type="bibr" rid="CR19">19</xref></sup> and added here. It is important to note that the proteins used to obtain our values were different to theirs. It can be seen that DMPfold is effective at lower effective sequence counts</p></caption><graphic xlink:href="41467_2019_11994_Fig5_HTML" id="d29e859"/></fig></p>
      <p id="Par20">Comparing to the Baker group study further shows the ability of DMPfold to work with shallower alignments. Model accuracy at different alignment sizes, represented by an effective sequence count <italic>N</italic><sub>f</sub>, is shown in Fig. <xref rid="Fig5" ref-type="fig">5c</xref>. It can be seen that DMPfold has a relatively flat line, and is able to generate accurate models even when relatively few sequences are available. Also shown superimposed on the plot is a similar plot from the Baker group study. Although these two lines are not directly comparable because different proteins were used in each set, they are indicative of DMPfold being able to give good performance even with shallower sequence alignments. For deeper alignments, DMPfold is able to give unrefined models of a quality close to the refined models from the earlier study.</p>
      <p id="Par21">There is little correlation of model accuracy with sequence length, as shown in Fig. <xref rid="Fig5" ref-type="fig">5b</xref>. The prediction of residue pair distances and iterative improvement of models allows domains up to around 600 residues in length to be modelled accurately. Beyond this, the accuracy falls with the default parameters used. This dropoff in accuracy may also stem from the DMP training set, which had a maximum chain length of 500 residues. In addition, some of these longer proteins have multiple structural domains despite being from one Pfam family, which can make modelling and assessment hard. Mirror topology effects can also be an issue—see the Discussion. We recommend that users treat DMPfold models for proteins of more than 500 residues with caution and consider splitting them up. The benefit of iterations to DMPfold is shown in Fig. <xref rid="Fig6" ref-type="fig">6</xref>. In the example shown, a loop moves from an initially incorrect predicted position to a more native-like position after 2 iterative predictions. One future use of DMPfold could be as a refinement tool for structures that are broadly correct.<fig id="Fig6"><label>Fig. 6</label><caption><p>An example of model accuracy increasing after iterations. The model is for Pfam family PF13642. <bold>a</bold> Distance maps of the initial prediction, the prediction after iterations and the native structure. In each case the value at <italic>i</italic>, <italic>j</italic> is the centre of the distance bin with the maximum likelihood between residues <italic>i</italic> and <italic>j</italic>. <bold>b</bold> The change of the absolute error in distance from the initial prediction to the prediction after iterations. A negative value indicates an improvement with the iterations. <bold>c</bold> The improvement is shown on the structure. The native structure (PDB ID 2L6O) is in blue, the initial model is in orange and the model after iterations is in green. The loop region indicated in red throughout, and the following helix, are closer to the native structure in the prediction after iterations than the initial prediction</p></caption><graphic xlink:href="41467_2019_11994_Fig6_HTML" id="d29e908"/></fig></p>
      <p id="Par22">The compute time required to generate a model from a 200 residue sequence is about 3 h on a standard single-core desktop computer (see Supplementary Fig. <xref rid="MOESM1" ref-type="media">1</xref>), including the time required to build the multiple sequence alignments (MSAs) from the target sequence. Model generation takes about 1.5 h of this time. This means that any researcher can generate 3-D models for proteins of interest, as the DMPfold software and data is freely available. Also, this efficiency means that we will be easily able to maintain a continuously updated set of de novo modelled Pfam domains, which will be distributed via the Genome3D resource<sup><xref ref-type="bibr" rid="CR30">30</xref></sup>.</p>
    </sec>
    <sec id="Sec6">
      <title>Newly modellable regions in model proteomes</title>
      <p id="Par23">Limiting ourselves to high-confidence predictions in dark Pfam families, we evaluated the extent to which our predictions extend the structural coverage of the proteomes for <italic>Homo sapiens</italic> and 13 other model organisms. The left-hand pie chart in Fig. <xref rid="Fig7" ref-type="fig">7</xref> shows the number of residues in UniProt<sup><xref ref-type="bibr" rid="CR31">31</xref></sup> entries for each taxon for which DMPfold can provide confident models. The values for this pie chart were summed over the various proteomes considered; full data appear in Supplementary Table <xref rid="MOESM1" ref-type="media">2</xref>. In terms of the total numbers of amino acid residues covered by DMPfold predictions for the taxa in Supplementary Table <xref rid="MOESM1" ref-type="media">2</xref>, we find that our predictions lead to a modest fractional increase in coverage of at most 4.3% and typically no more than 2% of existing structural coverage (depending on the specific proteome considered). This reflects the fact that these dark families are significantly less abundant (on average) than families with existing structural coverage in the individual proteomes considered (assessed by one-sided Wilcoxon rank-sum test at <italic>α</italic> = 0.05), which may be a bias that arises from structure determination efforts, especially the structural genomics initiatives, focussing more attention on larger sequence families, especially those that repeat frequently across model organism proteomes<sup><xref ref-type="bibr" rid="CR32">32</xref></sup>. For additional perspective, we also calculated the number of UniProt entries for each taxon for which DMPfold produces a new model, and the number of entries out of these for which no other PDB hits or templates can be detected. A summary of this data appears in the right-hand pie chart of Fig. <xref rid="Fig7" ref-type="fig">7</xref> and the raw data appear in Supplementary Table <xref rid="MOESM1" ref-type="media">3</xref>. We find that across the proteomes considered, most entries are already covered at least partially by PDB structures, DMPfold typically provides new annotations for thousands of UniProt entries across the various proteomes, and the majority of these models cover entries that are not covered (even partially) by PDB structures. 2.5% of all the UniProt entries considered get their first structural annotations from high-confidence DMPfold models (green fraction of right-hand pie chart in Fig. <xref rid="Fig7" ref-type="fig">7</xref>).<fig id="Fig7"><label>Fig. 7</label><caption><p>Coverage of proteomes by DMPfold models. Left: Pie chart showing the fraction of Pfam-annotated amino acid residues in a number of proteomes for which templates or PDB matches are available (blue). Of the remaining residues, the fractions covered by high-confidence DMPfold models (red) and lower-confidence models (orange) are marked. Right: Pie chart of UniProt entries in several proteomes. Entries are first split into whether or not they are (at least partially) covered by PDB matches or templates. Within each split, we then assess the fraction of entries that either have or do not have high-confidence DMPfold models available. The green fraction indicates entries for which de novo models provide the only structural information currently available. Data for each fraction of each pie chart are summed over several proteomes (full data in Supplementary Tables <xref rid="MOESM1" ref-type="media">2</xref> and <xref rid="MOESM1" ref-type="media">3</xref>)</p></caption><graphic xlink:href="41467_2019_11994_Fig7_HTML" id="d29e970"/></fig></p>
    </sec>
  </sec>
  <sec id="Sec7" sec-type="discussion">
    <title>Discussion</title>
    <p id="Par24">In the last few years, contacts predicted from covariation data have become accurate enough to produce good quality protein models. However, contact prediction and model generation have generally been treated as separate steps. DMPfold combines the two stages in an iterative process, allowing constraints to be refined based on the models produced. Prediction of distances rather than binary contacts provides considerably more information for model building. Modifications such as these will be necessary for template-free modelling to move from identifying the correct fold to generating high-quality models useful for studies such as ligand binding. Nevertheless, methods that can generate models for thousands of target sequences in days on a standard research cluster are going to become increasingly important as we move further into the modern genomic era.</p>
    <p id="Par25">As expected, more accurate contact predictions (and, by extension, more accurate distance predictions) give more accurate models. Of the 12 CASP12 FM domains with top <italic>L</italic> predicted contact accuracy of at least 0.5, 8 have a TM-score of at least 0.5 to the native structure. As the volume of available sequence data increases, the corresponding increase in distance information should lead to more accurate DMPfold models.</p>
    <p id="Par26">In the recent CASP13 experiment, a prototype version of DMPfold was ready in time to make predictions for about two thirds of the prediction targets, and the current version used for the last third. Results from the CASP website indicate that our group, Jones-UCL, submitted models with the correct fold (TM-align score at least 0.5) for 24 of 43 (56%) FM domains. Results for other leading methods using deep learning to predict distances included 31/43 (72%) for A7D (AlphaFold from DeepMind) and 24/43 (56%) for RaptorX-DeepModeller<sup><xref ref-type="bibr" rid="CR14">14</xref></sup>. For comparison, the leading group in CASP12 achieved 22/56 (39%) of predictions with the correct fold. In CASP13, a number of groups employing deep learning techniques, including us, moved this fraction up to around 60%. Whilst our CASP13 results were not quite at the level of the best-ranked method, AlphaFold, DMPfold gives competitive results with a much shorter computation time<sup><xref ref-type="bibr" rid="CR33">33</xref></sup> and is freely available software. DMPfold makes the recent advances in protein structure prediction available to the community to run at genome-scale.</p>
    <p id="Par27">In principle, DMPfold is also applicable to multi-domain proteins in its current form. However, in testing we noticed that in some cases, individual domains can be predicted as topological mirror images<sup><xref ref-type="bibr" rid="CR12">12</xref></sup>. These are distinct from simple mirror images in that topological mirror images have the correct stereochemistry and handedness of alpha-helices (as a result of CNS structure calculations), but differ in the overall topology of the protein chain. In addition, in our predictions they also have seemingly well-packed hydrophobic cores, making it non-trivial to distinguish a mirror topology from the correct fold. During testing, we observed that for predictions on some two-domain proteins, DMPfold often produces structures in which one domain is in the correct fold, while the other is a topological mirror. A rudimentary experiment using distance data sampled from native structures suggests that this problem arises due to an insufficient number of inter-domain distance constraints being supplied to the CNS calculation. We expect that further improvements in the accuracy of the distance predictions in DMPfold, as well as the method by which distance constraints are assigned, will alleviate this problem.</p>
    <p id="Par28">As we stated earlier, the models provided for the 1475 Pfam families had an 82.5% likelihood of having a correct fold. It is also noteworthy that there will be a number of correct models for the remainder of the modelled 5214 dark Pfam families that did not pass the filtering criteria. Assuming the TM-score prediction results on the validation set are comparable, we can estimate that 18% of the rejected 3739 families, equalling around 670 families, will have models with the correct fold. Considering additional information, such as conserved functional sites, could help identify some of these cases. By combining this with the filtered models we predict the overall number of correct folds we predict for dark families to be 1887. The continual increase in the number of available sequences will also make more families amenable to modelling in the next few years. Based on the change from Pfam 29.0 to 32.0, there is an increase of around 40% per year in the number of Pfam sequences. In one year this would move around 273 of the 3739 (7%) Pfam dark families without reliable DMPfold models from fewer than 50 sequences in the alignment to more than 50 sequences. This change should make these families more likely to be modelled accurately in a year’s time (see Fig. <xref rid="Fig5" ref-type="fig">5</xref>). While this paper was under review, 9 of the Pfam families modelled at high confidence had a structure released in PDB for the first time. 8 of these 9 models have a TM-align score of at least 0.5 to the deposited structure, with a mean TM-align score of 0.62; see Supplementary Table <xref rid="MOESM1" ref-type="media">4</xref>. This set acts as a further validation set for DMPfold, and the fraction of correct folds matches the precision of the model accuracy predictor. The one model with TM-align score less than 0.5 corresponded to a de novo-modelled region of a 4 Å resolution cryo-EM structure, which may not be reliable.</p>
    <p id="Par29">One important difference between this study and the earlier study from the Baker group is that we decided against including metagenomic sequences in our alignments. There were two main reasons for this. Firstly, and most importantly, we wanted to emphasise the methodological improvement afforded by the use of deep learning in de novo structure prediction here rather than simply the growth in sequence data since the earlier study was performed. Secondly, we felt that the difficulty in tracking the provenance of metagenome data (e.g., the lack of reliable source organism information in many cases) makes the choice of using it in the public annotation of genome data rather ambivalent. Sticking to sequences taken directly from the well-curated UniProt data bank<sup><xref ref-type="bibr" rid="CR31">31</xref></sup> makes it far easier to maintain the annotations and to use phylogeny, for example, to link structure to function downstream of the modelling process. Obviously on a case by case basis, or where the accuracy and coverage of 3-D modelling are the sole factors to consider (in the CASP experiment for example), then the sensible approach would be to include as many homologous sequences as possible from any available source.</p>
    <p id="Par30">An obvious limitation of the current study is that it only explores the de novo modelling potential for the parts of proteomes which match Pfam domains. Considering an average ‘proteome’ as the sum of all UniProt entries across the proteomes listed in Supplementary Tables <xref rid="MOESM1" ref-type="media">2</xref> and <xref rid="MOESM1" ref-type="media">3</xref>, on average just under half of the entries have at least one Pfam annotation. For the human proteome this is only 27.9% of entries, however, although in terms of amino acid residues, just over half (50.4%) is covered by Pfam annotations.</p>
    <p id="Par31">How much of the remaining half of the human genome could still be correctly modelled by DMPfold is hard to assess. The remainder will, of course, include a mixture of disordered or unstructured proteins, coiled-coil regions and other general low-complexity features. Some of it, however, will be modellable regions which Pfam simply has not reached due to a lack of homologous sequences in standard databases. Even the disordered domains could have a viable native structure under the right conditions e.g., through formation of multimers or binding to cognate ligands. For future work, it would be interesting to scan the proteome regions where no Pfam domains can be found and simply look for high-complexity sequences which produce reasonably deep alignments with HHblits. DMPfold could, in those cases, provide models which could help identify these regions as potential new superfamilies or help identify them as distant members of existing families through structure-based comparison. A further application of DMPfold could also be to help provide models which could distinguish true protein-coding genes from pseudogenes or mistranslated regions.</p>
    <p id="Par32">Although the fact that we are able to confidently annotate 25% (1475/5908) of the dark Pfam domains using DMPfold shows the power of deep learning and sequence covariation assisted de novo modelling, the additional coverage of the proteomes, perhaps at first sight, looks surprisingly low. Only an extra 1.56% of the human proteome by residue is covered by domains with new structures determined by DMPfold. This is not that surprising, however, as the largest families, which might often appear in multiple tandem repeats in a single protein, will have been prioritised for experimental structure determination in the past. The fact that we have been able to structurally annotate a further 790 human proteins with high confidence (or 8525 proteins across all 14 model organism genomes), where no prior structural information was known at all, is the key result. These very dark proteins could be keys to new biology yet to be discovered in the genomes, particularly those domains which are predicted to have entirely novel folds.</p>
  </sec>
  <sec id="Sec8">
    <title>Methods</title>
    <sec id="Sec9">
      <title>Deep learning components</title>
      <p id="Par33">An overview of the DMPfold pipeline is shown in Fig. <xref rid="Fig8" ref-type="fig">8</xref>. DMPfold uses a set of deep neural networks similar in architecture and methods of training to our DeepMetaPSICOV (DMP) contact prediction method, which is described separately<sup><xref ref-type="bibr" rid="CR17">17</xref></sup>. However, in this case the neural networks are used to predict inter-residue distance probability distributions (between Cβ atoms or Cα atoms for glycine), main chain hydrogen bond (H-bond) donor/acceptor pairs and torsion angles rather than just contact maps. DMP and DMPfold use exactly the same input features as shown in Supplementary Table <xref rid="MOESM1" ref-type="media">5</xref>, and are meta-approaches that combine different sources of covariation data from alignments using a deep residual neural network to predict contacts, along with the raw residue-residue covariance matrix as employed in the DeepCov contact prediction method<sup><xref ref-type="bibr" rid="CR34">34</xref></sup>.<fig id="Fig8"><label>Fig. 8</label><caption><p>Overview of the DMPfold pipeline. Initially inter-residue Cβ distances, H-bonds and torsion angles are predicted from DMP inputs. These are used to generate models with CNS, and a single model is used as additional input to refine the distances and H-bonds. After 3 iterations a final set of models is returned</p></caption><graphic xlink:href="41467_2019_11994_Fig8_HTML" id="d29e1053"/></fig></p>
      <p id="Par34">For predicting main chain H-bonds, the neural network architecture is exactly the same as that of DMP itself (Fig. <xref rid="Fig9" ref-type="fig">9b</xref>). The only difference is that the output map represents H-bond donor (rows) and acceptor (columns) contacts, where the donor (N) is within 3.5 Å of the acceptor (O). Unlike a normal contact map, therefore, the H-bond map is not expected to be symmetric.<fig id="Fig9"><label>Fig. 9</label><caption><p>DMPfold model architectures. DMPfold uses three predictors, all of which are deep, fully convolutional residual networks. Each uses a total of 18 residual blocks, comprising convolutional layers with a mixture of standard and dilated 5 × 5 filters. Where numbers are included in parentheses, these are the dimensions of the tensor output by the respective layer. For the iterative versions of the distance and H-bond predictors, the input tensor includes an extra feature channel composed of values taken from structures in the prior iteration (for a total of 502 channels). See the Methods section for full details</p></caption><graphic xlink:href="41467_2019_11994_Fig9_HTML" id="d29e1067"/></fig></p>
      <p id="Par35">The DMPfold distance predictor differs slightly from the architecture of DMP. The key difference is that instead of predicting binary contacts between residue pairs, the DMPfold distance predictor outputs a probability distribution in the form of a distance histogram for each residue pair. This is achieved by the use of a softmax output layer with 20 output channels, with each channel corresponding to the likelihood of each residue pair being between two predefined distances. The distance bins used for the output channels are 3.5–4.5 Å; 7 bins running from 4.5 Å to 8 Å in steps of 0.5 Å; 11 bins running from 8 Å to 19 Å in steps of 1 Å; and a final bin for all distances 19 Å or greater. As the underlying distance matrix must be symmetric, symmetry of the final output tensor (<italic>O</italic>) is enforced (for inference only) as follows:<disp-formula id="Equ1"><label>1</label><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$O_{{\mathrm{final}}} = {\mathrm{Softmax}}(O + O^{\mathrm{T}})$$\end{document}</tex-math><mml:math id="M2"><mml:msub><mml:mrow><mml:mi>O</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">final</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi mathvariant="normal">Softmax</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>O</mml:mi><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi>O</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math><graphic xlink:href="41467_2019_11994_Article_Equ1.gif" position="anchor"/></alternatives></disp-formula>This symmetry enforcement also serves to ensemble the independent upper and lower triangle prediction outputs of the DMPfold network.</p>
      <p id="Par36">The model architecture is shown in Fig. <xref rid="Fig9" ref-type="fig">9a</xref>. Predicting distance distributions is clearly a more complex problem than simply predicting binary contacts, and so to increase the representation power of the DMP network architecture, rather than increasing the number of layers, which would have required too much GPU memory during training, we replaced the usual two convolutional layers in each residual block with a single convolutional maxout layer<sup><xref ref-type="bibr" rid="CR35">35</xref></sup>, with 4 hidden maxout units per layer. Rather than relying on a separate nonlinearity e.g., the ReLU activation functions used in DMP, a maxout unit takes the maximum feature across multiple affine feature maps to produce a learned intrinsic nonlinearity. A single maxout network layer with more than two hidden maxout units works on its own as an efficient universal approximator of any continuous function, and so the ability of multiple convolutional layers to approximate arbitrary continuous functions can be reproduced by just a single maxout layer. The maxout layer used for initial dimensionality reduction (from 501 channels to 64) is the same as the one used in DMP itself and thus has 3 hidden maxout units rather than the 4 used in the residual blocks. The dilation rate <italic>d</italic> for each residual block is shown in Supplementary Table <xref rid="MOESM1" ref-type="media">6</xref>. As halving the number of convolutions per block reduces the maximum receptive field size, an additional dilation of 128 was added to the maxout network to compensate.</p>
      <p id="Par37">Training of all models was performed using the Adam optimiser<sup><xref ref-type="bibr" rid="CR36">36</xref></sup> for 75 epochs with default parameters (<italic>β</italic><sub>1</sub> = 0.9, <italic>β</italic><sub>2</sub> = 0.999, maximum learning rate of 10<sup>–3</sup>), the final model weights were those that produced the lowest cross-entropy loss on the validation set (5% of the training cases held out). Minibatches of size one were used for forward and backward passes due to GPU memory limitations, although gradients were accumulated and averaged across minibatches of size 8. All other aspects of training, including data augmentation procedures were out as previously described for DMP<sup><xref ref-type="bibr" rid="CR17">17</xref></sup>. The training set here was based on the same 6729 protein chains, ≤500 residues in length, with non-redundancy at the 25% sequence identity level and no unresolved main chain atoms. A 5% subset was kept aside for validation rather than training, and any chains corresponding to CASP11 targets were also excluded from training for validation of the 3-D modelling procedures (see below). A further 9 chains were excluded from training as they overlapped with proteins in the FILM3 test set. No additional cross-validation was required for the CASP12 test set, as the data set was assembled from data available prior to the start of the CASP12 experiment, including the HHblits<sup><xref ref-type="bibr" rid="CR37">37</xref></sup> HMM library (uniprot20 2016_02 release).</p>
    </sec>
    <sec id="Sec10">
      <title>Model generation using CNS</title>
      <p id="Par38">CNS<sup><xref ref-type="bibr" rid="CR11">11</xref></sup> is used to generate models from pseudo-NOE information derived from the DMP distance distributions, H-bond maps and torsion angles. In the first iteration of DMPfold, the contact maps and H-bonding maps (asymmetric donor-acceptor pair maps) are predicted. Upper and lower distance bounds, and predicted H-bonds are converted into NOE-like constraints. For the Cβ-Cβ distances (Cα atoms for glycines), the bounds for the maximum likelihood bin is taken as the starting point. These bounds are then grown accretively to encompass neighbouring bins in order of likelihood until the total likelihood reaches a set threshold. A total likelihood threshold of 0.4 was found to be optimal, though the overall method is relatively insensitive to changes in this threshold. This method of selecting bounds means that less confident predictions result in wider bounds. Bounds are not generated for cases where the maximum likelihood bin is the unbounded last bin, and the last bin is also excluded from the likelihood accretion procedure. This means that all upper bounds provided to CNS are &lt;19 Å. For the binary output H-bond prediction network, a binary likelihood threshold of 0.85 was used to decide whether to consider the predicted H-bond or not. Again, although 0.85 was found to be slightly optimal, other threshold values over 0.4 perform almost equally well. The main chain H..O and N..O distance constraints input to CNS for the predicted H-bonds are fixed according to the values observed in highly resolved crystal structures.</p>
    </sec>
    <sec id="Sec11">
      <title>Additional constraint types and iterative predictions</title>
      <p id="Par39">In addition to the distance-based constraints, DMPfold also generates dihedral angle constraints from predicted main chain torsion angles. Torsion angle predictions are generated with the same deep residual maxout network, but with the 20-dimensional softmax output layer replaced by a bidirectional recurrent LSTM layer<sup><xref ref-type="bibr" rid="CR38">38</xref></sup> with 128 hidden units (BLSTM in Fig. <xref rid="Fig9" ref-type="fig">9c</xref>), which embeds each row of the final 2-D 64-channel feature map in a single 256-D vector (concatenation of 128-D final timestep output states of the forward and reverse direction LSTM passes). As each row ends up embedded in a single vector, the LSTM layer thus transforms the 3-D tensor (64 features × L × L) into a 2-D tensor (256 features × L), which is finally reduced in dimensions to three final feature channels (3 × L), interpreted as φ, ψ, and ω angles in radians for each residue. The mean squared errors of the sines and cosines of these angles was used as the loss function. The accuracy of torsion angle prediction was observed to be comparable with the current state-of-the-art<sup><xref ref-type="bibr" rid="CR39">39</xref>,<xref ref-type="bibr" rid="CR40">40</xref></sup>, with an average MAE (mean absolute error) of 18.8° for φ and 26.7° for ψ on a benchmark set of CASP11 FM and TBM-hard targets. As the network did not demonstrate any ability to predict rare cis-peptide conformations (ω ≈ 0°), ω angle predictions were not used as modelling constraints. Accuracy estimates of predicted φ, ψ, and ω angles were produced by training a second network with identical architecture to predict the errors of angle predictions for the training set i.e., to predict the reliability of predictions from the first network. The loss function in this case is simply the mean squared absolute error in the predicted torsion angles. These error estimates are then used to populate the deviation fields of the CNS dihedral angle constraints file. As we saw no real benefit from calculating the dihedral constraints iteratively, for simplicity we calculate just a single set of dihedral constraints in the first iteration and used them throughout the subsequent modelling cycles.</p>
      <p id="Par40">Using the initial input constraints, a predefined number of models are generated and clustered by structural similarity. The representative structure of the largest cluster is taken, selected by estimated model accuracy using a combination of MODCHECK<sup><xref ref-type="bibr" rid="CR41">41</xref></sup> Cβ potentials of mean force and all atom MODELLER<sup><xref ref-type="bibr" rid="CR42">42</xref></sup> DOPE-HR scores, and this model used to seed the next iteration. The same distance and H-bond procedures described above are used, but with an additional input feature channel added, namely the Cβ-Cβ distance matrix calculated from the seed structure. This allows new distances and H-bonds to be predicted using prior information of likely Cβ-Cβ distances from the previous iteration of 3-D modelling. In this way, the combined contact prediction and structure generation procedure can evolve a better prediction at each iteration. To train these iterated models, a standard unseeded DMPfold run was carried out for each training set protein, generating 6729 ensembles of 20 models per target. At each epoch of training the iterated neural network models, structures were selected at random from the ensembles and the calculated distance matrices used to populate the extra feature channel. In this study we only trained one set of iterated models, but in the future, a small amount of improvement might be achievable by training further iterated neural network models, where DMPfold is re-run after each iteration of training to produce seed inputs for the next iteration.</p>
      <p id="Par41">Typically fewer than 5 iterations are needed for convergence—we use 3 iterations throughout the work reported in this paper. A set of 30 FM-category domains from CASP11, which had no protein domains in the same ECOD H-group level<sup><xref ref-type="bibr" rid="CR21">21</xref></sup> as the DMPfold training set, was used to select optimum parameters (i.e., the likelihood thresholds used to derive upper and lower distance bounds) for the DMPfold model generation steps.</p>
    </sec>
    <sec id="Sec12">
      <title>Enforcement of non-overlap between training and test sets</title>
      <p id="Par42">In order to assess the generalisation ability of any trained deep learning model, it is crucial to ensure that the set of examples used to train the model does not share any obvious overlap with examples used to test the model. For proteins, a criterion based on sequence identity between any training and test example is commonly used. However, this is generally insufficient to rule out an evolutionary relationship or structural similarity, as many related proteins share less than 20% sequence identity. It is much more preferable to use a structural classification database such as CATH, SCOPe or ECOD. We use the evolutionary classification of domains (ECOD) database<sup><xref ref-type="bibr" rid="CR21">21</xref></sup> to define our train-test split for all benchmarks in this paper.</p>
    </sec>
    <sec id="Sec13">
      <title>Calculation of effective sequence counts</title>
      <p id="Par43">Effective sequence counts (<italic>N</italic><sub>eff</sub>) were determined as per ref. <sup><xref ref-type="bibr" rid="CR34">34</xref></sup>. Briefly, sequences in each MSA were clustered using CD-HIT<sup><xref ref-type="bibr" rid="CR43">43</xref></sup> at a sequence identity threshold of 62%. The number of clusters returned by CD-HIT was taken as the <italic>N</italic><sub>eff</sub>. When comparing results against the Baker group study<sup><xref ref-type="bibr" rid="CR19">19</xref></sup>, we used the same calculation of effective sequence count as in that work, which we denote <italic>N</italic><sub>f</sub>.</p>
    </sec>
    <sec id="Sec14">
      <title>Running DMPfold on CASP12 targets</title>
      <p id="Par44">All of the input alignments were generated using HHblits<sup><xref ref-type="bibr" rid="CR37">37</xref></sup> with the Feb 2016 release of the uniprot20 HMM library<sup><xref ref-type="bibr" rid="CR31">31</xref></sup>. This ensured that only sequences available at the start of the CASP12 experiment were considered. To compare to contact-based methods, DMPfold distance predictions were converted to predicted contacts by summing up likelihoods for distance bins below 8 Å for a given residue pair and sorting residue pairs by the resulting sum. We find that these contact predictions closely match the accuracy of using DMP to predict contacts. CONFOLD2 was run with default parameters and secondary structure predictions from PSIPRED<sup><xref ref-type="bibr" rid="CR44">44</xref></sup>. Rosetta was run similarly to the approach in the PconsFold protocol<sup><xref ref-type="bibr" rid="CR3">3</xref></sup>. Fragment generation was carried out with default parameters and the non-redundant sequence database. Since the database of structures used for fragments was assembled before CASP12 took place, there are no homologous proteins to the CASP12 FM domains in this set. The Rosetta <italic>AbinitoRelax</italic> protocol was run with the “-abinitio:increase_cycles 10” and “use_filters” options. The top <italic>L</italic> predicted contacts were used as constraints where <italic>L</italic> is the sequence length.</p>
    </sec>
    <sec id="Sec15">
      <title>Running DMPfold on transmembrane targets</title>
      <p id="Par45">The sequence alignments used to generate DMPfold models for the FILM3 dataset were identical to the sequence alignments from the FILM3 paper<sup><xref ref-type="bibr" rid="CR25">25</xref></sup>, allowing direct comparison to the results presented there. None of the targets in this set are homologous to any training example, as assessed by ECOD database classification at the T-group level.</p>
    </sec>
    <sec id="Sec16">
      <title>Running DMPfold on Pfam families</title>
      <p id="Par46">Pfam 32.0 (September 2018 release) was used<sup><xref ref-type="bibr" rid="CR18">18</xref></sup>. The set of dark families available for modelling was taken to be the set of 8700 lacking an annotated structure minus those families with likely templates not annotated in Pfam—these were found by running HHsearch<sup><xref ref-type="bibr" rid="CR45">45</xref></sup> of the Pfam seed HMM against the standard HHsearch PDB70 HMM library and taking hits with an <italic>E</italic>-value threshold of 1.0. The number of families remaining was 5908. A representative target sequence was found for each family using hmmsearch<sup><xref ref-type="bibr" rid="CR46">46</xref></sup> to search the UniRef90 database with the Pfam HMM and taking the closest subsequence match by <italic>E</italic>-value. The 5214 families with target sequence lengths between 50 and 800 were taken forward for de novo modelling. Alignments were generated for each target sequence using HHblits<sup><xref ref-type="bibr" rid="CR37">37</xref></sup> searches against the 2018_08 version of the UniClust30 database. DMPfold was run from these alignments and the top model for each family was taken forward for further analysis. Potential novel folds were determined as those with a maximum TM-score using TM-align (normalised by the model length) of 0.5 or less to any structure in the PDB.</p>
      <p id="Par47">The Pfam validation set consisted of families with available structures that were not used for the training of DMPfold. Highly likely templates not annotated in Pfam were found by running HHsearch of sequences in the PDB against the Pfam HMM and taking hits with an <italic>E</italic>-value threshold of 0.001. Structures were determined as not being used for DMPfold training if they were in a different ECOD<sup><xref ref-type="bibr" rid="CR21">21</xref></sup> T-group to all structures in the DMPfold training set. The validation set consisted of 1154 Pfam families once target sequences outside the 50–800 residue range had been excluded. For each family, a single PDB structure was chosen for comparison to the model. In the case of the Pfam structural annotations, this is the structure with the highest alignment score to the target sequence. In the case of the HHsearch PDB hits, this is the closest hit by <italic>E</italic>-value. TM-scores were calculated using TM-align<sup><xref ref-type="bibr" rid="CR47">47</xref></sup> rather than TM-score as the target sequence and PDB sequence are often very different and so not easily aligned by sequence. The maximum of the TM-scores normalised by the model or the PDB chain was taken, as it is possible that each could fail to cover the whole length of the other.</p>
    </sec>
    <sec id="Sec17">
      <title>Estimating model accuracy</title>
      <p id="Par48">To produce a useful estimate of model accuracy we trained a small fully connected neural network to predict the likely TM-score for a given model. The inputs to this model were the target sequence length, the effective number of sequences in the alignment, the sum of distance histogram likelihoods, and the average distance histogram likelihood. The histogram likelihoods were derived from the softmax outputs of the first iteration distance histogram prediction where the likelihoods of the bins selected by each pairwise distance in the model were summed (or averaged), standardised in the usual way using the individual feature means and standard deviations. The EMA neural network comprised the 4 feature inputs, two fully connected hidden layers of 10 units per layer, with 10 softmax outputs corresponding to the TM-score ranges (0 ≤ <italic>s</italic> &lt; 0.1, …, 0.9 &lt; <italic>s</italic> ≤ 1.0). A SELU activation function<sup><xref ref-type="bibr" rid="CR48">48</xref></sup> was used for the hidden layers and a cross-entropy loss function used for training with the Adam optimisation algorithm<sup><xref ref-type="bibr" rid="CR36">36</xref></sup> and a maximum learning rate of 10<sup>−3</sup>. An expected TM-score was calculated for a model by calculating an average of each output bin ranges (midpoint TM-score) weighted by the softmax output for the bin.</p>
      <p id="Par49">To estimate the accuracy of this method for discriminating models with a correct fold, the network was trained 100 times on the Pfam validation set of 3-D models with random training/validation/test splits of the data each time. Using a predicted TM-score threshold of 0.5, we found that the validation set models with correct folds (observed TM-score &gt; 0.5) could be recognised with a mean precision of 82.5% and a recall of 82.2%.</p>
    </sec>
    <sec id="Sec18">
      <title>Estimating structural coverage in proteomes</title>
      <p id="Par50">We used the proteome mapping files from Pfam to assess the additional coverage provided by our predictions. After resolving secondary UniProt accessions and removing deleted entries, we counted the number of residues annotated with Pfam IDs and assess what number of residues (a) could already be annotated with 3-D structures by homology; (b) can now be confidently modelled using DMPfold; or (c) cannot be modelled either by homology or using high-confidence DMPfold models. For (b) we limited ourselves to dark Pfam families (see section “Running DMPfold on Pfam families”) that could be modelled with high confidence. Pfam annotations on each UniProt entry were demarcated by the envelope coordinates provided by the Pfam assignments for the given proteome. We also assessed the number of whole UniProt entries covered at least partially by PDB entries or templates, and the number that have no structural coverage at all. We then assessed the number of entries in each category that were (at least partially) covered by high-confidence DMPfold predictions for dark Pfams. These analyses were carried out for a number of proteomes, including <italic>Homo sapiens</italic> and several model organisms.</p>
    </sec>
    <sec id="Sec19">
      <title>Reporting summary</title>
      <p id="Par51">Further information on research design is available in the <xref rid="MOESM3" ref-type="media">Nature Research Reporting Summary</xref> linked to this article.</p>
    </sec>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary information</title>
    <sec id="Sec20">
      <p>
        <supplementary-material content-type="local-data" id="MOESM1">
          <media xlink:href="41467_2019_11994_MOESM1_ESM.pdf">
            <caption>
              <p>Supplementary Information</p>
            </caption>
          </media>
        </supplementary-material>
        <supplementary-material content-type="local-data" id="MOESM2">
          <media xlink:href="41467_2019_11994_MOESM2_ESM.pdf">
            <caption>
              <p>Peer Review File</p>
            </caption>
          </media>
        </supplementary-material>
        <supplementary-material content-type="local-data" id="MOESM3">
          <media xlink:href="41467_2019_11994_MOESM3_ESM.pdf">
            <caption>
              <p>Reporting Summary</p>
            </caption>
          </media>
        </supplementary-material>
      </p>
    </sec>
  </sec>
</body>
<back>
  <fn-group>
    <fn>
      <p><bold>Peer review information:</bold><italic>Nature Communications</italic> thanks Mohammed AlQuraishi and other anonymous reviewer(s) for their contribution to the peer review of this work. Peer reviewer reports are available.</p>
    </fn>
    <fn>
      <p><bold>Publisher’s note:</bold> Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
    </fn>
    <fn>
      <p>These authors contributed equally: Joe G. Greener, Shaun M. Kandathil.</p>
    </fn>
  </fn-group>
  <sec>
    <title>Supplementary information</title>
    <p><bold>Supplementary Information</bold> accompanies this paper at 10.1038/s41467-019-11994-0.</p>
  </sec>
  <ack>
    <title>Acknowledgements</title>
    <p>We thank members of the group for valuable discussions and comments. This work was supported by the European Research Council Advanced Grant “ProCovar” (project ID 695558). This work was supported by the Francis Crick Institute which receives its core funding from Cancer Research UK (FC001002), the UK Medical Research Council (FC001002), and the Wellcome Trust (FC001002).</p>
  </ack>
  <notes notes-type="author-contribution">
    <title>Author contributions</title>
    <p>D.T.J. conceived the research, carried out the machine learning experiments and developed DMPfold. S.M.K. and J.G.G. carried out the benchmarking and genome annotation experiments. All authors contributed to the writing of the paper.</p>
  </notes>
  <notes notes-type="data-availability">
    <title>Data availability</title>
    <p>The trained neural network models and Pfam 3-D models are available at <ext-link ext-link-type="uri" xlink:href="https://github.com/psipred/DMPfold">https://github.com/psipred/DMPfold</ext-link>. All other relevant data are available from the authors upon reasonable request.</p>
  </notes>
  <notes notes-type="data-availability">
    <title>Code availability</title>
    <p>The deep learning components of DMPfold are implemented in PyTorch<sup><xref ref-type="bibr" rid="CR49">49</xref></sup>. The source code and documentation are available at <ext-link ext-link-type="uri" xlink:href="https://github.com/psipred/DMPfold">https://github.com/psipred/DMPfold</ext-link>.</p>
  </notes>
  <notes notes-type="COI-statement">
    <title>Competing interests</title>
    <p id="Par52">The authors declare no competing interests.</p>
  </notes>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <label>1.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>de Juan</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Pazos</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Valencia</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Emerging methods in protein co-evolution</article-title>
        <source>Nat. Rev. Genet.</source>
        <year>2013</year>
        <volume>14</volume>
        <fpage>249</fpage>
        <lpage>261</lpage>
        <pub-id pub-id-type="doi">10.1038/nrg3414</pub-id>
        <pub-id pub-id-type="pmid">23458856</pub-id>
      </element-citation>
    </ref>
    <ref id="CR2">
      <label>2.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Monastyrskyy</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>D’Andrea</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Fidelis</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Tramontano</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Kryshtafovych</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>New encouraging developments in contact prediction: Assessment of the CASP11 results</article-title>
        <source>Protein. Struct. Funct. Bioinf.</source>
        <year>2015</year>
        <volume>84</volume>
        <fpage>131</fpage>
        <lpage>144</lpage>
        <pub-id pub-id-type="doi">10.1002/prot.24943</pub-id>
      </element-citation>
    </ref>
    <ref id="CR3">
      <label>3.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Michel</surname>
            <given-names>M</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>PconsFold: improved contact predictions improve protein models</article-title>
        <source>Bioinformatics</source>
        <year>2014</year>
        <volume>30</volume>
        <fpage>i482</fpage>
        <lpage>i488</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btu458</pub-id>
        <pub-id pub-id-type="pmid">25161237</pub-id>
      </element-citation>
    </ref>
    <ref id="CR4">
      <label>4.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Bender</surname>
            <given-names>BJ</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Protocols for molecular modeling with Rosetta3 and RosettaScripts</article-title>
        <source>Biochemistry</source>
        <year>2016</year>
        <volume>55</volume>
        <fpage>4748</fpage>
        <lpage>4763</lpage>
        <pub-id pub-id-type="doi">10.1021/acs.biochem.6b00444</pub-id>
        <pub-id pub-id-type="pmid">27490953</pub-id>
      </element-citation>
    </ref>
    <ref id="CR5">
      <label>5.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kosciolek</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Jones</surname>
            <given-names>DT</given-names>
          </name>
        </person-group>
        <article-title>De novo structure prediction of globular proteins aided by sequence variation-derived contacts</article-title>
        <source>PLoS ONE</source>
        <year>2014</year>
        <volume>9</volume>
        <fpage>e92197</fpage>
        <pub-id pub-id-type="doi">10.1371/journal.pone.0092197</pub-id>
        <pub-id pub-id-type="pmid">24637808</pub-id>
      </element-citation>
    </ref>
    <ref id="CR6">
      <label>6.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ovchinnikov</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Park</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Kim</surname>
            <given-names>DE</given-names>
          </name>
          <name>
            <surname>DiMaio</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Baker</surname>
            <given-names>D</given-names>
          </name>
        </person-group>
        <article-title>Protein structure prediction using Rosetta in CASP12</article-title>
        <source>Protein. Struct. Funct. Bioinf.</source>
        <year>2018</year>
        <volume>86</volume>
        <fpage>113</fpage>
        <lpage>121</lpage>
        <pub-id pub-id-type="doi">10.1002/prot.25390</pub-id>
      </element-citation>
    </ref>
    <ref id="CR7">
      <label>7.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kim</surname>
            <given-names>DE</given-names>
          </name>
          <name>
            <surname>Chivian</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Malmström</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Baker</surname>
            <given-names>D</given-names>
          </name>
        </person-group>
        <article-title>Automated prediction of domain boundaries in CASP6 targets using Ginzu and RosettaDOM</article-title>
        <source>Protein. Struct. Funct. Bioinf.</source>
        <year>2005</year>
        <volume>61</volume>
        <fpage>193</fpage>
        <lpage>200</lpage>
        <pub-id pub-id-type="doi">10.1002/prot.20737</pub-id>
      </element-citation>
    </ref>
    <ref id="CR8">
      <label>8.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Aszódi</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Gradwell</surname>
            <given-names>MJ</given-names>
          </name>
          <name>
            <surname>Taylor</surname>
            <given-names>WR</given-names>
          </name>
        </person-group>
        <article-title>Global fold determination from a small number of distance restraints</article-title>
        <source>J. Mol. Biol.</source>
        <year>1995</year>
        <volume>251</volume>
        <fpage>308</fpage>
        <lpage>326</lpage>
        <pub-id pub-id-type="doi">10.1006/jmbi.1995.0436</pub-id>
        <pub-id pub-id-type="pmid">7643405</pub-id>
      </element-citation>
    </ref>
    <ref id="CR9">
      <label>9.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Adhikari</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Cheng</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>CONFOLD2: improved contact-driven ab initio protein structure modeling</article-title>
        <source>BMC Bioinform.</source>
        <year>2018</year>
        <volume>19</volume>
        <fpage>22</fpage>
        <pub-id pub-id-type="doi">10.1186/s12859-018-2032-6</pub-id>
      </element-citation>
    </ref>
    <ref id="CR10">
      <label>10.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Marks</surname>
            <given-names>DS</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Protein 3D structure computed from evolutionary sequence variation</article-title>
        <source>PLoS ONE</source>
        <year>2011</year>
        <volume>6</volume>
        <fpage>e28766</fpage>
        <pub-id pub-id-type="doi">10.1371/journal.pone.0028766</pub-id>
        <pub-id pub-id-type="pmid">22163331</pub-id>
      </element-citation>
    </ref>
    <ref id="CR11">
      <label>11.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Brunger</surname>
            <given-names>AT</given-names>
          </name>
        </person-group>
        <article-title>Version 1.2 of the crystallography and NMR system</article-title>
        <source>Nat. Protoc.</source>
        <year>2007</year>
        <volume>2</volume>
        <fpage>2728</fpage>
        <lpage>2733</lpage>
        <pub-id pub-id-type="doi">10.1038/nprot.2007.406</pub-id>
        <pub-id pub-id-type="pmid">18007608</pub-id>
      </element-citation>
    </ref>
    <ref id="CR12">
      <label>12.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Pastore</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Atkinson</surname>
            <given-names>RA</given-names>
          </name>
          <name>
            <surname>Saudek</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Williams</surname>
            <given-names>RJ</given-names>
          </name>
        </person-group>
        <article-title>Topological mirror images in protein structure computation: an underestimated problem</article-title>
        <source>Protein. Struct. Funct. Bioinf.</source>
        <year>1991</year>
        <volume>10</volume>
        <fpage>22</fpage>
        <lpage>32</lpage>
        <pub-id pub-id-type="doi">10.1002/prot.340100104</pub-id>
      </element-citation>
    </ref>
    <ref id="CR13">
      <label>13.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Michel</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Menéndez Hurtado</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Uziela</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Elofsson</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Large-scale structure prediction by improved contact predictions and model quality assessment</article-title>
        <source>Bioinformatics</source>
        <year>2017</year>
        <volume>33</volume>
        <fpage>i23</fpage>
        <lpage>i29.</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btx239</pub-id>
        <pub-id pub-id-type="pmid">28881974</pub-id>
      </element-citation>
    </ref>
    <ref id="CR14">
      <label>14.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Xu</surname>
            <given-names>Jinbo</given-names>
          </name>
        </person-group>
        <article-title>Distance-based protein folding powered by deep learning</article-title>
        <source>Proceedings of the National Academy of Sciences</source>
        <year>2019</year>
        <volume>116</volume>
        <issue>34</issue>
        <fpage>16856</fpage>
        <lpage>16865</lpage>
        <pub-id pub-id-type="doi">10.1073/pnas.1821309116</pub-id>
      </element-citation>
    </ref>
    <ref id="CR15">
      <label>15.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>AlQuraishi</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>End-to-end differentiable learning of protein structure</article-title>
        <source>Cell Syst.</source>
        <year>2019</year>
        <volume>8</volume>
        <fpage>292</fpage>
        <lpage>301</lpage>
        <pub-id pub-id-type="doi">10.1016/j.cels.2019.03.006</pub-id>
        <pub-id pub-id-type="pmid">31005579</pub-id>
      </element-citation>
    </ref>
    <ref id="CR16">
      <label>16.</label>
      <mixed-citation publication-type="other">Anonymous. Learning protein structure with a differentiable simulator. ICLR 2019 Conference Blind Submission. (2018).</mixed-citation>
    </ref>
    <ref id="CR17">
      <label>17.</label>
      <mixed-citation publication-type="other">Kandathil S. M., Greener J. G., Jones D. T. Prediction of interresidue contacts with DeepMetaPSICOV in CASP13. <italic>Proteins Struct. Funct. Bioinf</italic>. (2019).</mixed-citation>
    </ref>
    <ref id="CR18">
      <label>18.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>El-Gebali</surname>
            <given-names>S</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>The Pfam protein families database in 2019</article-title>
        <source>Nucleic Acids Res.</source>
        <year>2019</year>
        <volume>47</volume>
        <fpage>D427</fpage>
        <lpage>D432.</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gky995</pub-id>
        <pub-id pub-id-type="pmid">30357350</pub-id>
      </element-citation>
    </ref>
    <ref id="CR19">
      <label>19.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ovchinnikov</surname>
            <given-names>S</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Protein structure determination using metagenome sequence data</article-title>
        <source>Science</source>
        <year>2017</year>
        <volume>355</volume>
        <fpage>294</fpage>
        <lpage>298</lpage>
        <pub-id pub-id-type="doi">10.1126/science.aah4043</pub-id>
        <pub-id pub-id-type="pmid">28104891</pub-id>
      </element-citation>
    </ref>
    <ref id="CR20">
      <label>20.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lamb</surname>
            <given-names>John</given-names>
          </name>
          <name>
            <surname>Jarmolinska</surname>
            <given-names>Aleksandra I.</given-names>
          </name>
          <name>
            <surname>Michel</surname>
            <given-names>Mirco</given-names>
          </name>
          <name>
            <surname>Menéndez-Hurtado</surname>
            <given-names>David</given-names>
          </name>
          <name>
            <surname>Sulkowska</surname>
            <given-names>Joanna I.</given-names>
          </name>
          <name>
            <surname>Elofsson</surname>
            <given-names>Arne</given-names>
          </name>
        </person-group>
        <article-title>PconsFam: An Interactive Database of Structure Predictions of Pfam Families</article-title>
        <source>Journal of Molecular Biology</source>
        <year>2019</year>
        <volume>431</volume>
        <issue>13</issue>
        <fpage>2442</fpage>
        <lpage>2448</lpage>
        <pub-id pub-id-type="doi">10.1016/j.jmb.2019.01.047</pub-id>
        <pub-id pub-id-type="pmid">30796988</pub-id>
      </element-citation>
    </ref>
    <ref id="CR21">
      <label>21.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Schaeffer</surname>
            <given-names>RD</given-names>
          </name>
          <name>
            <surname>Liao</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Cheng</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Grishin</surname>
            <given-names>NV</given-names>
          </name>
        </person-group>
        <article-title>ECOD: new developments in the evolutionary classification of domains</article-title>
        <source>Nucleic Acids Res.</source>
        <year>2017</year>
        <volume>45</volume>
        <fpage>D296</fpage>
        <lpage>D302.</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkw1137</pub-id>
        <pub-id pub-id-type="pmid">27899594</pub-id>
      </element-citation>
    </ref>
    <ref id="CR22">
      <label>22.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Skolnick</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Scoring function for automated assessment of protein structure template quality</article-title>
        <source>Protein. Struct. Funct. Bioinf.</source>
        <year>2004</year>
        <volume>57</volume>
        <fpage>702</fpage>
        <lpage>710</lpage>
        <pub-id pub-id-type="doi">10.1002/prot.20264</pub-id>
      </element-citation>
    </ref>
    <ref id="CR23">
      <label>23.</label>
      <mixed-citation publication-type="other">Kabsch, W. &amp; Sander, C. Dictionary of protein secondary structure: Pattern recognition of hydrogen-bonded and geometrical features. <italic>Biopolymers</italic><bold>22</bold>, 2577–2637 (1983).</mixed-citation>
    </ref>
    <ref id="CR24">
      <label>24.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hopf</surname>
            <given-names>TA</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Three-dimensional structures of membrane proteins from genomic sequencing</article-title>
        <source>Cell</source>
        <year>2012</year>
        <volume>149</volume>
        <fpage>1607</fpage>
        <lpage>1621</lpage>
        <pub-id pub-id-type="doi">10.1016/j.cell.2012.04.012</pub-id>
        <pub-id pub-id-type="pmid">22579045</pub-id>
      </element-citation>
    </ref>
    <ref id="CR25">
      <label>25.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Nugent</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Jones</surname>
            <given-names>DT</given-names>
          </name>
        </person-group>
        <article-title>Accurate de novo structure prediction of large transmembrane protein domains using fragment-assembly and correlated mutation analysis</article-title>
        <source>Proc. Natl Acad. Sci. USA</source>
        <year>2012</year>
        <volume>109</volume>
        <fpage>E1540</fpage>
        <lpage>E1547</lpage>
        <pub-id pub-id-type="doi">10.1073/pnas.1120036109</pub-id>
        <pub-id pub-id-type="pmid">22645369</pub-id>
      </element-citation>
    </ref>
    <ref id="CR26">
      <label>26.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Perdigão</surname>
            <given-names>N</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Unexpected features of the dark proteome</article-title>
        <source>Proc. Natl Acad. Sci. USA.</source>
        <year>2015</year>
        <volume>112</volume>
        <fpage>15898</fpage>
        <lpage>15903</lpage>
        <pub-id pub-id-type="doi">10.1073/pnas.1508380112</pub-id>
        <pub-id pub-id-type="pmid">26578815</pub-id>
      </element-citation>
    </ref>
    <ref id="CR27">
      <label>27.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Dessailly</surname>
            <given-names>BH</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>PSI-2: structural genomics to cover protein domain family space</article-title>
        <source>Structure</source>
        <year>2009</year>
        <volume>17</volume>
        <fpage>869</fpage>
        <lpage>881</lpage>
        <pub-id pub-id-type="doi">10.1016/j.str.2009.03.015</pub-id>
        <pub-id pub-id-type="pmid">19523904</pub-id>
      </element-citation>
    </ref>
    <ref id="CR28">
      <label>28.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Jones</surname>
            <given-names>DT</given-names>
          </name>
          <name>
            <surname>Buchan</surname>
            <given-names>DWA</given-names>
          </name>
          <name>
            <surname>Cozzetto</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Pontil</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>PSICOV: precise structural contact prediction using sparse inverse covariance estimation on large multiple sequence alignments</article-title>
        <source>Bioinformatics</source>
        <year>2012</year>
        <volume>28</volume>
        <fpage>184</fpage>
        <lpage>190</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btr638</pub-id>
        <pub-id pub-id-type="pmid">22101153</pub-id>
      </element-citation>
    </ref>
    <ref id="CR29">
      <label>29.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Seemayer</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Gruber</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Söding</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>CCMpred–fast and precise prediction of protein residue-residue contacts from correlated mutations</article-title>
        <source>Bioinformatics</source>
        <year>2014</year>
        <volume>30</volume>
        <fpage>3128</fpage>
        <lpage>3130</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btu500</pub-id>
        <pub-id pub-id-type="pmid">25064567</pub-id>
      </element-citation>
    </ref>
    <ref id="CR30">
      <label>30.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lewis</surname>
            <given-names>TE</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Genome3D: exploiting structure to help users understand their sequences</article-title>
        <source>Nucleic Acids Res.</source>
        <year>2015</year>
        <volume>43</volume>
        <fpage>D382</fpage>
        <lpage>D386</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gku973</pub-id>
        <pub-id pub-id-type="pmid">25348407</pub-id>
      </element-citation>
    </ref>
    <ref id="CR31">
      <label>31.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <collab>UniProt Consortium T.</collab>
        </person-group>
        <article-title>UniProt: the universal protein knowledgebase</article-title>
        <source>Nucleic Acids Res.</source>
        <year>2018</year>
        <volume>46</volume>
        <fpage>2699</fpage>
        <pub-id pub-id-type="doi">10.1093/nar/gky092</pub-id>
        <pub-id pub-id-type="pmid">29425356</pub-id>
      </element-citation>
    </ref>
    <ref id="CR32">
      <label>32.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Somody</surname>
            <given-names>JC</given-names>
          </name>
          <name>
            <surname>MacKinnon</surname>
            <given-names>SS</given-names>
          </name>
          <name>
            <surname>Windemuth</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Structural coverage of the proteome for pharmaceutical applications</article-title>
        <source>Drug Disco. Today</source>
        <year>2017</year>
        <volume>22</volume>
        <fpage>1792</fpage>
        <lpage>1799</lpage>
        <pub-id pub-id-type="doi">10.1016/j.drudis.2017.08.004</pub-id>
      </element-citation>
    </ref>
    <ref id="CR33">
      <label>33.</label>
      <mixed-citation publication-type="other">Jumper, J. De novo protein folding using statistical potentials from deep learning. CASP13 presentation (2018).</mixed-citation>
    </ref>
    <ref id="CR34">
      <label>34.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Jones</surname>
            <given-names>DT</given-names>
          </name>
          <name>
            <surname>Kandathil</surname>
            <given-names>SM</given-names>
          </name>
        </person-group>
        <article-title>High precision in protein contact prediction using fully convolutional neural networks and minimal sequence features</article-title>
        <source>Bioinformatics</source>
        <year>2018</year>
        <volume>34</volume>
        <fpage>3308</fpage>
        <lpage>3315</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/bty341</pub-id>
        <pub-id pub-id-type="pmid">29718112</pub-id>
      </element-citation>
    </ref>
    <ref id="CR35">
      <label>35.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Goodfellow</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Warde-Farley</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Mirza</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Courville</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Bengio</surname>
            <given-names>Y</given-names>
          </name>
        </person-group>
        <article-title>Maxout networks</article-title>
        <source>PMLR</source>
        <year>2013</year>
        <volume>28</volume>
        <fpage>1319</fpage>
        <lpage>1327</lpage>
      </element-citation>
    </ref>
    <ref id="CR36">
      <label>36.</label>
      <mixed-citation publication-type="other">Kingma, D. P., Ba, J. Adam: a method for stochastic optimization. Proceedings of the 3rd International Conference on Learning Representations (ICLR) (2015).</mixed-citation>
    </ref>
    <ref id="CR37">
      <label>37.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Remmert</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Biegert</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Hauser</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Söding</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>HHblits: lightning-fast iterative protein sequence searching by HMM-HMM alignment</article-title>
        <source>Nat. Methods</source>
        <year>2011</year>
        <volume>9</volume>
        <fpage>173</fpage>
        <lpage>175</lpage>
        <pub-id pub-id-type="doi">10.1038/nmeth.1818</pub-id>
        <pub-id pub-id-type="pmid">22198341</pub-id>
      </element-citation>
    </ref>
    <ref id="CR38">
      <label>38.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hochreiter</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Schmidhuber</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Long short-term memory</article-title>
        <source>Neural Comput.</source>
        <year>1997</year>
        <volume>9</volume>
        <fpage>1735</fpage>
        <lpage>1780</lpage>
        <pub-id pub-id-type="doi">10.1162/neco.1997.9.8.1735</pub-id>
        <pub-id pub-id-type="pmid">9377276</pub-id>
      </element-citation>
    </ref>
    <ref id="CR39">
      <label>39.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Heffernan</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Paliwal</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Zhou</surname>
            <given-names>Y</given-names>
          </name>
        </person-group>
        <article-title>Capturing non-local interactions by long short-term memory bidirectional recurrent neural networks for improving prediction of protein secondary structure, backbone angles, contact numbers and solvent accessibility</article-title>
        <source>Bioinformatics</source>
        <year>2017</year>
        <volume>33</volume>
        <fpage>2842</fpage>
        <lpage>2849</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btx218</pub-id>
        <pub-id pub-id-type="pmid">28430949</pub-id>
      </element-citation>
    </ref>
    <ref id="CR40">
      <label>40.</label>
      <mixed-citation publication-type="other">Li, H., Hou, J., Adhikari, B., Lyu, Q., Cheng, J. Deep learning methods for protein torsion angle prediction. <italic>BMC Bioinform</italic>. <bold>18</bold>, 417 (2017).</mixed-citation>
    </ref>
    <ref id="CR41">
      <label>41.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Pettitt</surname>
            <given-names>CS</given-names>
          </name>
          <name>
            <surname>McGuffin</surname>
            <given-names>LJ</given-names>
          </name>
          <name>
            <surname>Jones</surname>
            <given-names>DT</given-names>
          </name>
        </person-group>
        <article-title>Improving sequence-based fold recognition by using 3D model quality assessment</article-title>
        <source>Bioinformatics</source>
        <year>2005</year>
        <volume>21</volume>
        <fpage>3509</fpage>
        <lpage>3515</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/bti540</pub-id>
        <pub-id pub-id-type="pmid">15955780</pub-id>
      </element-citation>
    </ref>
    <ref id="CR42">
      <label>42.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Webb</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Sali</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Comparative protein structure modeling using MODELLER</article-title>
        <source>Curr. Protoc. Protein Sci.</source>
        <year>2016</year>
        <volume>54</volume>
        <fpage>5.6.1</fpage>
        <lpage>5.6.37</lpage>
      </element-citation>
    </ref>
    <ref id="CR43">
      <label>43.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Fu</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Niu</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Zhu</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Wu</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>W</given-names>
          </name>
        </person-group>
        <article-title>CD-HIT: accelerated for clustering the next generation sequencing data</article-title>
        <source>Bioinformatics</source>
        <year>2012</year>
        <volume>28</volume>
        <fpage>3150</fpage>
        <lpage>3152</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/bts565</pub-id>
        <pub-id pub-id-type="pmid">23060610</pub-id>
      </element-citation>
    </ref>
    <ref id="CR44">
      <label>44.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Jones</surname>
            <given-names>DT</given-names>
          </name>
        </person-group>
        <article-title>Protein secondary structure prediction based on position-specific scoring matrices</article-title>
        <source>J. Mol. Biol.</source>
        <year>1999</year>
        <volume>292</volume>
        <fpage>195</fpage>
        <lpage>202</lpage>
        <pub-id pub-id-type="doi">10.1006/jmbi.1999.3091</pub-id>
        <pub-id pub-id-type="pmid">10493868</pub-id>
      </element-citation>
    </ref>
    <ref id="CR45">
      <label>45.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zimmermann</surname>
            <given-names>L</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>A completely reimplemented MPI bioinformatics toolkit with a new HHpred server at its core</article-title>
        <source>J. Mol. Biol.</source>
        <year>2018</year>
        <volume>430</volume>
        <fpage>2237</fpage>
        <lpage>2243</lpage>
        <pub-id pub-id-type="doi">10.1016/j.jmb.2017.12.007</pub-id>
        <pub-id pub-id-type="pmid">29258817</pub-id>
      </element-citation>
    </ref>
    <ref id="CR46">
      <label>46.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Potter</surname>
            <given-names>SC</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>HMMER web server: 2018 update</article-title>
        <source>Nucleic Acids Res.</source>
        <year>2018</year>
        <volume>46</volume>
        <fpage>W200</fpage>
        <lpage>W204</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gky448</pub-id>
        <pub-id pub-id-type="pmid">29905871</pub-id>
      </element-citation>
    </ref>
    <ref id="CR47">
      <label>47.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Skolnick</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>TM-align: a protein structure alignment algorithm based on the TM-score</article-title>
        <source>Nucleic Acids Res.</source>
        <year>2005</year>
        <volume>33</volume>
        <fpage>2302</fpage>
        <lpage>2309</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gki524</pub-id>
        <pub-id pub-id-type="pmid">15849316</pub-id>
      </element-citation>
    </ref>
    <ref id="CR48">
      <label>48.</label>
      <mixed-citation publication-type="other">Klambauer, G., Unterthiner, T., May, A. Self-normalizing neural networks. <italic>Adv. Neural. Inf. Process. Syst.</italic><bold>30</bold>, 971–980 (2017).</mixed-citation>
    </ref>
    <ref id="CR49">
      <label>49.</label>
      <mixed-citation publication-type="other">Paszke, A. et al. Automatic differentiation in PyTorch. <italic>NIPS Autodiff Workshop</italic><ext-link ext-link-type="uri" xlink:href="https://github.com/pytorch/pytorch/blob/master/CITATION">https://github.com/pytorch/pytorch/blob/master/CITATION</ext-link> (2017).</mixed-citation>
    </ref>
  </ref-list>
</back>
