<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id>
    <journal-id journal-id-type="publisher-id">bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1367-4803</issn>
    <issn pub-type="epub">1367-4811</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">9805591</article-id>
    <article-id pub-id-type="pmid">36440906</article-id>
    <article-id pub-id-type="doi">10.1093/bioinformatics/btac760</article-id>
    <article-id pub-id-type="publisher-id">btac760</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Original Paper</subject>
        <subj-group subj-group-type="category-toc-heading">
          <subject>Bioimage Informatics</subject>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI01060</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>AutoDeconJ: a GPU-accelerated ImageJ plugin for 3D light-field deconvolution with optimal iteration numbers predicting</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0003-1597-6244</contrib-id>
        <name>
          <surname>Su</surname>
          <given-names>Changqing</given-names>
        </name>
        <aff><institution>School of Mechanical, Electrical &amp; Information Engineering, Shandong University</institution>, Weihai 264209, <country country="CN">China</country></aff>
        <aff><institution>National Engineering Laboratory for Video Technology (NELVT), Peking University</institution>, Beijing 100871, <country country="CN">China</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Gao</surname>
          <given-names>Yuhan</given-names>
        </name>
        <aff><institution>Lishui Institute of Hangzhou Dianzi University</institution>, Hangzhou 323000, <country country="CN">China</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0001-5319-0934</contrib-id>
        <name>
          <surname>Zhou</surname>
          <given-names>You</given-names>
        </name>
        <aff><institution>School of Electronic Science and Engineering, Nanjing University</institution>, Nanjing 210023, <country country="CN">China</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Sun</surname>
          <given-names>Yaoqi</given-names>
        </name>
        <aff><institution>Lishui Institute of Hangzhou Dianzi University</institution>, Hangzhou 323000, <country country="CN">China</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Yan</surname>
          <given-names>Chenggang</given-names>
        </name>
        <aff><institution>School of Mechanical, Electrical &amp; Information Engineering, Shandong University</institution>, Weihai 264209, <country country="CN">China</country></aff>
        <aff><institution>Lishui Institute of Hangzhou Dianzi University</institution>, Hangzhou 323000, <country country="CN">China</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Yin</surname>
          <given-names>Haibing</given-names>
        </name>
        <aff><institution>Lishui Institute of Hangzhou Dianzi University</institution>, Hangzhou 323000, <country country="CN">China</country></aff>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0001-7815-3603</contrib-id>
        <name>
          <surname>Xiong</surname>
          <given-names>Bo</given-names>
        </name>
        <aff><institution>National Engineering Laboratory for Video Technology (NELVT), Peking University</institution>, Beijing 100871, <country country="CN">China</country></aff>
        <xref rid="btac760-cor1" ref-type="corresp"/>
        <!--boxiong11@outlook.com-->
      </contrib>
    </contrib-group>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Peng</surname>
          <given-names>Hanchuan</given-names>
        </name>
        <role>Associate Editor</role>
      </contrib>
    </contrib-group>
    <author-notes>
      <corresp id="btac760-cor1">To whom correspondence should be addressed. Email: <email>boxiong11@outlook.com</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <month>1</month>
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2022-11-28">
      <day>28</day>
      <month>11</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>28</day>
      <month>11</month>
      <year>2022</year>
    </pub-date>
    <volume>39</volume>
    <issue>1</issue>
    <elocation-id>btac760</elocation-id>
    <history>
      <date date-type="received">
        <day>24</day>
        <month>8</month>
        <year>2022</year>
      </date>
      <date date-type="rev-recd">
        <day>25</day>
        <month>10</month>
        <year>2022</year>
      </date>
      <date date-type="editorial-decision">
        <day>18</day>
        <month>11</month>
        <year>2022</year>
      </date>
      <date date-type="accepted">
        <day>24</day>
        <month>11</month>
        <year>2022</year>
      </date>
      <date date-type="corrected-typeset">
        <day>02</day>
        <month>12</month>
        <year>2022</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2022. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2022</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="btac760.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Motivation</title>
        <p>Light-field microscopy (LFM) is a compact solution to high-speed 3D fluorescence imaging. Usually, we need to do 3D deconvolution to the captured raw data. Although there are deep neural network methods that can accelerate the reconstruction process, the model is not universally applicable for all system parameters. Here, we develop AutoDeconJ, a GPU-accelerated ImageJ plugin for 4.4× faster and more accurate deconvolution of LFM data. We further propose an image quality metric for the deconvolution process, aiding in automatically determining the optimal number of iterations with higher reconstruction accuracy and fewer artifacts.</p>
      </sec>
      <sec id="s2">
        <title>Results</title>
        <p>Our proposed method outperforms state-of-the-art light-field deconvolution methods in reconstruction time and optimal iteration numbers prediction capability. It shows better universality of different light-field point spread function (PSF) parameters than the deep learning method. The fast, accurate and general reconstruction performance for different PSF parameters suggests its potential for mass 3D reconstruction of LFM data.</p>
      </sec>
      <sec id="s3">
        <title>Availability and implementation</title>
        <p>The codes, the documentation and example data are available on an open source at: <ext-link xlink:href="https://github.com/Onetism/AutoDeconJ.git" ext-link-type="uri">https://github.com/Onetism/AutoDeconJ.git</ext-link>.</p>
      </sec>
      <sec id="s5">
        <title>Supplementary information</title>
        <p><xref rid="sup1" ref-type="supplementary-material">Supplementary data</xref> are available at <italic toggle="yes">Bioinformatics</italic> online.</p>
      </sec>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>National Natural Science Foundation of China</institution>
            <institution-id institution-id-type="DOI">10.13039/501100001809</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>61931008</award-id>
        <award-id>U21B2024</award-id>
        <award-id>62071415</award-id>
        <award-id>62071219</award-id>
        <award-id>62088102</award-id>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="5"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 Introduction</title>
    <p>The wonder of life’s activity lies in its ability to coordinate all its cells and tissues in an elegantly compact system to carry out its functions in an orderly manner. To get a glimpse of this mystery and explore the interrelationships between these parts, various imaging techniques have been proposed gradually, such as two-photon microscopy (<xref rid="btac760-B1" ref-type="bibr">Albota <italic toggle="yes">et al.</italic>, 1998</xref>), plane illumination methods (<xref rid="btac760-B4" ref-type="bibr">Huisken <italic toggle="yes">et al.</italic>, 2004</xref>) and confocal microscopy (<xref rid="btac760-B12" ref-type="bibr">Schulz <italic toggle="yes">et al.</italic>, 2013</xref>), allowing high spatial resolution 3D imaging (<xref rid="btac760-B9" ref-type="bibr">Planchon <italic toggle="yes">et al.</italic>, 2011</xref>; <xref rid="btac760-B16" ref-type="bibr">Wu <italic toggle="yes">et al.</italic>, 2021</xref>; <xref rid="btac760-B18" ref-type="bibr">Xiong <italic toggle="yes">et al.</italic>, 2021</xref>; <xref rid="btac760-B19" ref-type="bibr">Yang <italic toggle="yes">et al.</italic>, 2017</xref>). However, much of the interaction between cells and tissues occurs transiently in three dimensions (<xref rid="btac760-B10" ref-type="bibr">Prevedel <italic toggle="yes">et al.</italic>, 2014</xref>), perhaps in milliseconds or even microseconds. It requires imaging systems with the high spatiotemporal resolution, but the trade-off between space and time can hardly be effectively addressed. Most of the existing techniques prefer to reconstruct a 3D volume by recording a certain number of 2D images (<xref rid="btac760-B6" ref-type="bibr">Keller <italic toggle="yes">et al.</italic>, 2008</xref>), which is equivalent to sacrificing temporal resolution for 3D spatial resolution.</p>
    <p>Light-field microscopy (LFM) has been emerging as a crucial volumetric imaging method due to its ability to capture 3D information in a tomographic manner within a snapshot (<xref rid="btac760-B18" ref-type="bibr">Xiong <italic toggle="yes">et al.</italic>, 2021</xref>; <xref rid="btac760-B3" ref-type="bibr">Cohen <italic toggle="yes">et al.</italic>, 2014</xref>). In view of its excellent volumetric imaging speed (<xref rid="btac760-B17" ref-type="bibr">Wang <italic toggle="yes">et al.</italic>, 2021</xref>), it is exceptionally well suited for high-speed volumetric imaging. As a result, a growing number of biological and medical researchers have paid special attention to applying it in their fields of studies, such as whole-animal 3D imaging of neuronal activity (<xref rid="btac760-B10" ref-type="bibr">Prevedel <italic toggle="yes">et al.</italic>, 2014</xref>), 3D behavioral phenotyping (<xref rid="btac760-B13" ref-type="bibr">Shaw <italic toggle="yes">et al.</italic>, 2018</xref>) and high-speed volumetric brain imaging (<xref rid="btac760-B20" ref-type="bibr">Zhang <italic toggle="yes">et al.</italic>, 2021</xref>). Despite these advantages having led to the rapid development of applications, the presence of post-processing steps for light-field images and the low throughput of the reconstruction algorithm at this stage limit its application for long-timescale real-time observation (<xref rid="btac760-B17" ref-type="bibr">Wang <italic toggle="yes">et al.</italic>, 2021</xref>). 3D Richardson–Lucy (RL) deconvolution algorithm has been widely applied to enhance the resolution of LFM, and <xref rid="btac760-B10" ref-type="bibr">Prevedel <italic toggle="yes">et al.</italic> (2014)</xref> have provided software for 3D volume reconstruction in MATLAB based on RL deconvolution (<xref rid="btac760-B10" ref-type="bibr">Prevedel <italic toggle="yes">et al.</italic>, 2014</xref>). The subsequent related deconvolution methods are also implemented based on RL deconvolution, such as phase-space deconvolution (<xref rid="btac760-B7" ref-type="bibr">Lu <italic toggle="yes">et al.</italic>, 2019</xref>) and high-resolution LFM (<xref rid="btac760-B8" ref-type="bibr">Li <italic toggle="yes">et al.</italic>, 2019</xref>). However, the reconstruction speed of these deconvolution methods is relatively slow, not enough for real-time observation. Although <xref rid="btac760-B10" ref-type="bibr">Prevedel <italic toggle="yes">et al.</italic> (2014)</xref> have introduced the GPU acceleration to the deconvolution of LFM data, it is only adopted in part of the convolution operation, thus limiting the overall acceleration performance. Moreover, it is inconvenient to utilize multiple GPUs simultaneously in MATLAB, which will limit its extension to large-size inputs due to the memory size of the image processor unit (GPU). The deep network XLFMNet (<xref rid="btac760-B14" ref-type="bibr">Vizcaino <italic toggle="yes">et al.</italic>, 2021</xref>) and VCD-Net (<xref rid="btac760-B17" ref-type="bibr">Wang <italic toggle="yes">et al.</italic>, 2021</xref>) have been proposed to boost the reconstruction throughput to a fantastic level. However, LFM data with different point spread function (PSF) parameters require training separate specific networks, which makes it trouble for biological researchers since biological observation usually requires different objectives. On the other hand, the trained network is only able to reconstruct the same type of data as the training data. Similarly, the image size in deep learning-based reconstruction is also limited by the memory of the GPU.</p>
    <p>Here, to ensure the generality for different system parameters and convenience for users, we design AutoDeconJ, a plugin in ImageJ (<xref rid="btac760-B11" ref-type="bibr">Schindelin <italic toggle="yes">et al.</italic>, 2012</xref>) for 4.4× faster compared to the Matlab GUI program and accurate deconvolution of LFM data, improving both computational efficiency and convenience of interface interaction. We also add a module to measure the iteration result, predicting the optimal number of iterations. All the main functions of MATLAB versions (<xref rid="btac760-B10" ref-type="bibr">Prevedel <italic toggle="yes">et al.</italic>, 2014</xref>) are integrated into AutoDeconJ and optimized to take advantage of the parallel processing capacity on the GPU. We first put the time-consuming part of the computation on the GPU, including the part of PSF computing and deconvolution. To maximize the efficiency of parallel computing and solve the problem of insufficient memory on GPU, we also introduce a multi-GPU framework, in which the PSF computation and the reconstruction process of different axial layers in 3D imaging can be evenly distributed to different GPUs, thus doubling the throughput directly. The reconstruction speed is proportional to the number of GPUs in use theoretically. The RL deconvolution algorithm is an iterative process where the number of stop iterations is usually determined by empirical values (<xref rid="btac760-B7" ref-type="bibr">Lu <italic toggle="yes">et al.</italic>, 2019</xref>; <xref rid="btac760-B10" ref-type="bibr">Prevedel <italic toggle="yes">et al.</italic>, 2014</xref>). As the input data change, the empirical value may also change, which is highly inconvenient for the reconstruction of large amounts of different light-field data. Hence, we introduce a prediction module that can predict the optimal number of iterations based on the intermediate iterative results. ImageJ is a cross-platform application widely used in biological research (<xref rid="btac760-B11" ref-type="bibr">Schindelin <italic toggle="yes">et al.</italic>, 2012</xref>), and we thus choose it as our basis in the form of a plugin for all researchers to facilitate their use. We verify the ability of AutoDeconJ in the light-field fluorescence data of <italic toggle="yes">Caenorhabditis elegans</italic>, which comes from an open-source dataset (<xref rid="btac760-B10" ref-type="bibr">Prevedel <italic toggle="yes">et al.</italic>, 2014</xref>). Our developed AutoDeconJ shows its excellent facilitation to light-field reconstruction, including the large data throughput and accurate prediction for iterations. To further demonstrate the performance of AutoDeconJ, we test it on the fluorescence beads data and MCF10A cells data.</p>
  </sec>
  <sec>
    <title>2 Materials and methods</title>
    <sec>
      <title>2.1 GPU acceleration</title>
      <p>The difference between AutoDeconJ and the previously released MATLAB GUI program (<xref rid="btac760-B10" ref-type="bibr">Prevedel <italic toggle="yes">et al.</italic>, 2014</xref>) is that AutoDeconJ takes full advantage of the highly parallel computation of the GPU. In the MATLAB GUI program, the calculation of the PSF is all performed on the CPU, which needs a substantial amount of computation. Specifically, the computation time in a single computational cycle is more than millions of microseconds which makes this entire step very time-consuming on the CPU serial data processing model. AutoDeconJ has two significant improvements compared to the MATLAB GUI program. The first improvement is in the acceleration of the calculation of PSF. AutoDeconJ transfers the main time-consuming parts in PSF calculating to the GPU. The speed of PSF calculation can be improved by exploiting the parallel computation (e.g. it achieves more than 20 times improvement in the experiment of <italic toggle="yes">C.elegans</italic>). Another one is our proposed strategy of data processing which is shown in <xref rid="btac760-F1" ref-type="fig">Figure 1</xref>. AutoDeconJ puts most of the operations to GPU during the deconvolution process, and only transfers the final results back to the CPU, avoiding transferring the intermediate results frequently between CPU and GPU, which is time-consuming. In addition, AutoDeconJ also provides support for multi-GPU collaboration to cope with the problem of insufficient memory. After all, not every researcher can afford expensive professional GPUs with large memory. We divide the 3D layers to be reconstructed evenly among different GPUs according to the number of GPUs so that we can handle large-size reconstructions and increase the reconstruction speed exponentially.</p>
      <fig position="float" id="btac760-F1">
        <label>Fig. 1.</label>
        <caption>
          <p>The acceleration framework of AutoDeconJ. AutoDeconJ puts the main time-consuming parts, including PSF computation and light-field reconstruction on the GPUs. First, the source of PSF needs to be selected in three ways: computing by specific parameters, reading from a MAT file or reading from a TIFF file. The default is computing by specific parameters. And then, AutoDeconJ will estimate the required memory size to facilitate the following memory allocation for multi-card operation. Whether the PSF is read from a file or calculated based on parameters, the PSF is evenly distributed to each card according to the memory size, which is used directly for the next reconstruction to reduce the time consumption of data transfer between GPU and CPU</p>
        </caption>
        <graphic xlink:href="btac760f1" position="float"/>
      </fig>
    </sec>
    <sec>
      <title>2.2 Image quality metric</title>
      <p>In the field of image processing, the discrete cosine transform (DCT) has been widely applied to transfer spatial information to the spectral domains, because of its great de-correlation and lossless property (<xref rid="btac760-B5" ref-type="bibr">Kristan <italic toggle="yes">et al.</italic>, 2006</xref>). The most common mathematical method is to project an image onto an orthonormal basis in which the amplitudes are called the DCT coefficients. Compared to the discrete Fourier transform, the obvious advantage of the DCT is that its coefficients are only represented by real numbers without the complicated complex number operations (<xref rid="btac760-B2" ref-type="bibr">Blinn, 1993</xref>). Its computing efficiency thus can be significantly improved, making it applicable to some real-time systems. The DCT coefficient transformed from an image function <inline-formula id="IE1"><mml:math id="IM1" display="inline" overflow="scroll"><mml:mrow><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> can be obtained via <xref rid="E1" ref-type="disp-formula">Eq. (1)</xref>.
<disp-formula id="E1"><label>(1)</label><mml:math id="M1" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:munder><mml:mrow><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mi>u</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>M</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mi>v</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mi>N</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:math></disp-formula>where <inline-formula id="IE2"><mml:math id="IM2" display="inline" overflow="scroll"><mml:mrow><mml:mi>x</mml:mi><mml:mo>∈</mml:mo><mml:mo>{</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>N</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula>, <inline-formula id="IE3"><mml:math id="IM3" display="inline" overflow="scroll"><mml:mrow><mml:mi>y</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>M</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, <inline-formula id="IE4"><mml:math id="IM4" display="inline" overflow="scroll"><mml:mi>M</mml:mi></mml:math></inline-formula> is the number of pixels along the height, and <inline-formula id="IE5"><mml:math id="IM5" display="inline" overflow="scroll"><mml:mi>N</mml:mi></mml:math></inline-formula> is the number of pixels along the width in the image. <inline-formula id="IE6"><mml:math id="IM6" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mi>u</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>M</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mi>v</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mi>N</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> is the basis functions defined by the following expressions:
<disp-formula id="E2"><label>(2)</label><mml:math id="M2" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mi>u</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>M</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>c</mml:mi><mml:mo>(</mml:mo><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>M</mml:mi><mml:mo>)</mml:mo><mml:mo>*</mml:mo><mml:mo> </mml:mo><mml:mtext>cos</mml:mtext><mml:mo stretchy="true">(</mml:mo><mml:mfrac><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mi>x</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>π</mml:mo><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mi>M</mml:mi></mml:mrow></mml:mfrac><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:math></disp-formula><disp-formula id="E3"><label>(3)</label><mml:math id="M3" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mi>v</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mi>N</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>c</mml:mi><mml:mo>(</mml:mo><mml:mi>v</mml:mi><mml:mo>,</mml:mo><mml:mi>N</mml:mi><mml:mo>)</mml:mo><mml:mo>*</mml:mo><mml:mo> </mml:mo><mml:mtext>cos</mml:mtext><mml:mo stretchy="true">(</mml:mo><mml:mfrac><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mi>y</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>π</mml:mo><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mi>N</mml:mi></mml:mrow></mml:mfrac><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:math></disp-formula><disp-formula id="E4"><label>(4)</label><mml:math id="M4" display="block" overflow="scroll"><mml:mrow><mml:mi>c</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>φ</mml:mo><mml:mo>,</mml:mo><mml:mi>Z</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mtable><mml:mtr><mml:mtd><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:msqrt><mml:mi>Z</mml:mi></mml:msqrt></mml:mrow></mml:mfrac><mml:mo>;</mml:mo><mml:mo>φ</mml:mo><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msqrt><mml:mrow><mml:mfrac><mml:mn>2</mml:mn><mml:mi>Z</mml:mi></mml:mfrac></mml:mrow></mml:msqrt><mml:mo>;</mml:mo><mml:mtext>otherwise</mml:mtext><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mrow></mml:math></disp-formula></p>
      <p>In general, microscopic observations are made to obtain as much high frequency information as possible. However, due to the limitations of the acquisition system, the resolution information it can obtain is usually in the range of a certain cut-off frequency. We usually pay more attention to information close to the cut-off frequency in the cut-off frequency range rather than near direct current. The relationship between the number of iterations and the image spectrum is illustrated in <xref rid="btac760-F2" ref-type="fig">Figure 2a and c</xref>, where the source light-field image is obtained from the open-source dataset provided in <xref rid="btac760-B10" ref-type="bibr">Prevedel <italic toggle="yes">et al.</italic> (2014)</xref>. We only take the maximum projection along the z-axis for each iterative result with RL deconvolution.</p>
      <fig position="float" id="btac760-F2">
        <label>Fig. 2.</label>
        <caption>
          <p>Performance of the image quality metric. The source light-field data is obtained from the open-source dataset provided in <xref rid="btac760-B10" ref-type="bibr">Prevedel <italic toggle="yes">et al.</italic> (2014)</xref>. (<bold>a</bold>) The maximum projection along the z-axis for each result with the RL deconvolution at 1, 7 and 20 iterations. The image in the lower-right corner is a magnification of the white area. (<bold>b</bold>) The gray value along solid lines in the lower-right corner of the diagram in (a). (<bold>c</bold>) The DCT transform corresponding to the deconvolution result in (a). The coefficients with higher values are shown in light gray, and those with lower values are shown in dark gray. The red numbers are the DCT entropy values of the red triangle in the upper left corner whose size is determined by <xref rid="E6" ref-type="disp-formula">Eq. (6)</xref>, and the white numbers indicate the overall DCT entropy value. By visual comparison of the red region as well as the values, it can be observed that with the increase of the iterations, the entropy value in the low-frequency region circled in red will increase first and then become smaller again but the overall entropy keeps rising. (<bold>d</bold>) Normalized curve of DCT entropy values with the number of iterations for the red region in (c), where the maximum DCT entropy value corresponds to the number of iterations of 7, which is consistent with the empirical value</p>
        </caption>
        <graphic xlink:href="btac760f2" position="float"/>
      </fig>
      <p>The deconvolution of the light-filed images can be considered a process of rearrangement of the aliased signal in the low- and high-frequency regions, which is reflected in the energy increase in the cut-off frequency range and the extension of effective spectral range in the spectrum of the image. Even the effective spectral range of the reconstructed results will exceed the original cut-off frequency to some extent, due to the additional information introduced by the PSF. Proper deconvolution operations can restore the high-frequency detail while maintaining low-frequency features. However, excessive deconvolution operations will destroy the original structural information of the image, which is reflected in the DCT-transformed image with the periodic spectrum shift, as it has shown in <xref rid="btac760-F2" ref-type="fig">Figure 2a–c</xref>. During the process of iteration, the maximum amount of information will be presented in and around the cut-off frequency range when the information has been restored to the best. Since the recovery of 3D information is limited, there should be a boundary to the effective spectral region whose size is related to the maximum resolution the optical system can obtain, as shown in <xref rid="btac760-F2" ref-type="fig">Figure 2c</xref>. A standard metric to measure the region with uniform distribution is the Shannon entropy (<xref rid="btac760-B5" ref-type="bibr">Kristan <italic toggle="yes">et al.</italic>, 2006</xref>), defined as
<disp-formula id="E5"><label>(5)</label><mml:math id="M5" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">entropy</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:mi mathvariant="double-struck">S</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mrow><mml:mrow><mml:mo> </mml:mo><mml:mtext>log</mml:mtext><mml:mo> </mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:math></disp-formula>where <inline-formula id="IE7"><mml:math id="IM7" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is a probability function defined on the region <inline-formula id="IE8"><mml:math id="IM8" display="inline" overflow="scroll"><mml:mi mathvariant="double-struck">S</mml:mi></mml:math></inline-formula>. Theoretically, we should calculate the entropy of the region area bounded by an arc in the upper left corner, since the region is determined by the cut-off frequency which usually is a quarter circle or ellipse. The cut-off frequency could be calculated from the resolution limit of the system. The entropy of the region area bounded by an arc in the upper left corner represents the amount of information collected by the system within its own limit resolution. The entropy increase during the iteration means the reconstruction algorithm restores more valid information. However, in order to reduce the computational consumption, <inline-formula id="IE9"><mml:math id="IM9" display="inline" overflow="scroll"><mml:mi mathvariant="double-struck">S</mml:mi></mml:math></inline-formula> is selected as a triangular region in the upper left corner in DCT, whose size is defined as
<disp-formula id="E6"><label>(6)</label><mml:math id="M6" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">G</mml:mi></mml:mrow><mml:mi mathvariant="double-struck">S</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mi mathvariant="double-struck">S</mml:mi></mml:msub><mml:mo>∗</mml:mo><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mi mathvariant="double-struck">S</mml:mi></mml:msub><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mo>,</mml:mo></mml:math></disp-formula>where <inline-formula id="IE10"><mml:math id="IM10" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mi mathvariant="double-struck">S</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is the number of pixels along the width, and <inline-formula id="IE11"><mml:math id="IM11" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mi mathvariant="double-struck">S</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is the number of pixels along the height in the region <inline-formula id="IE12"><mml:math id="IM12" display="inline" overflow="scroll"><mml:mi mathvariant="double-struck">S</mml:mi></mml:math></inline-formula>.</p>
      <p>For the DCT of an image, assuming that the pixel size is <inline-formula id="IE13"><mml:math id="IM13" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mi>u</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, then the spectral range corresponding to the DCT image is <inline-formula id="IE14"><mml:math id="IM14" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>2</mml:mn><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mi>u</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. Assuming that the limit of the resolution for a wide-field microscope is <inline-formula id="IE15"><mml:math id="IM15" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">psf</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, and its corresponding frequency position <inline-formula id="IE16"><mml:math id="IM16" display="inline" overflow="scroll"><mml:mi>P</mml:mi></mml:math></inline-formula> in the DCT image can be defined by:
<disp-formula id="E7"><label>(7)</label><mml:math id="M7" display="block" overflow="scroll"><mml:mrow><mml:mfrac><mml:mi>P</mml:mi><mml:mi>W</mml:mi></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mfrac bevelled="true"><mml:mn>1</mml:mn><mml:mrow><mml:mn>2</mml:mn><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">psf</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow><mml:mrow><mml:mfrac bevelled="true"><mml:mn>1</mml:mn><mml:mrow><mml:mn>2</mml:mn><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mi>u</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula><disp-formula id="E8"><label>(8)</label><mml:math id="M8" display="block" overflow="scroll"><mml:mrow><mml:mi>P</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mi>u</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">psf</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mi>W</mml:mi></mml:mrow></mml:math></disp-formula>where <inline-formula id="IE17"><mml:math id="IM17" display="inline" overflow="scroll"><mml:mi>W</mml:mi></mml:math></inline-formula> is the pixel number of a dimension (such as <inline-formula id="IE18"><mml:math id="IM18" display="inline" overflow="scroll"><mml:mi>M</mml:mi></mml:math></inline-formula> and <inline-formula id="IE19"><mml:math id="IM19" display="inline" overflow="scroll"><mml:mi>N</mml:mi></mml:math></inline-formula> in <xref rid="E1" ref-type="disp-formula">Eq. (1)</xref>) in the DCT image. According to the <xref rid="E8" ref-type="disp-formula">Eq. (8)</xref>, <inline-formula id="IE20"><mml:math id="IM20" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mi mathvariant="double-struck">S</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE21"><mml:math id="IM21" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mi mathvariant="double-struck">S</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> can be obtained by:
<disp-formula id="E9"><label>(9)</label><mml:math id="M9" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mi mathvariant="double-struck">S</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mi>u</mml:mi></mml:msub><mml:mo>*</mml:mo><mml:mi>N</mml:mi><mml:mo>/</mml:mo><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">psf</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></disp-formula><disp-formula id="E10"><label>(10)</label><mml:math id="M10" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mi mathvariant="double-struck">S</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mi>u</mml:mi></mml:msub><mml:mo>*</mml:mo><mml:mi>M</mml:mi><mml:mo>/</mml:mo><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">psf</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></disp-formula></p>
      <p>It is well known that we can estimate the size of the Airy spot from the diffraction theory. For the objective lens, the size of one Airy unit is <inline-formula id="IE22"><mml:math id="IM22" display="inline" overflow="scroll"><mml:mrow><mml:mfrac><mml:mrow><mml:mn>1.22</mml:mn><mml:mo>λ</mml:mo></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mi>A</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math></inline-formula> (<xref rid="btac760-B15" ref-type="bibr">Wang <italic toggle="yes">et al.</italic>, 2010</xref>), where <inline-formula id="IE23"><mml:math id="IM23" display="inline" overflow="scroll"><mml:mrow><mml:mi>N</mml:mi><mml:mi>A</mml:mi></mml:mrow></mml:math></inline-formula> is the numerical aperture of the objective lens and <inline-formula id="IE24"><mml:math id="IM24" display="inline" overflow="scroll"><mml:mo>λ</mml:mo></mml:math></inline-formula> is the wavelength of emission light. The above-mentioned <inline-formula id="IE25"><mml:math id="IM25" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">psf</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> refers to the smallest resolvable distance between two Airy spots. <inline-formula id="IE26"><mml:math id="IM26" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">psf</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> can be determined by
<disp-formula id="E11"><label>(11)</label><mml:math id="M11" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">psf</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>0.61</mml:mn><mml:mo>λ</mml:mo></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mi>A</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula></p>
      <p>However, LFM sacrifices spatial resolution to capture additional angular information. Here, assuming that <italic toggle="yes">N</italic><sub>num</sub> is the virtual pixels for each microlens, which also represents the angular resolution. From the DCT image of the 20th iteration of <italic toggle="yes">C.elegans</italic> data (<italic toggle="yes">N</italic><sub>num</sub> = 15), as shown in <xref rid="btac760-F2" ref-type="fig">Figure 2c</xref>, it can be found that the spectral period in the DCT image is only half of the <italic toggle="yes">N</italic><sub>num</sub>. As such, in LFM, assuming that <inline-formula id="IE27"><mml:math id="IM27" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>u</mml:mi><mml:mo>_</mml:mo><mml:mi>L</mml:mi><mml:mi>F</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> is the pixel size of light-field microscopy data, its corresponding frequency position <inline-formula id="IE28"><mml:math id="IM28" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mi>F</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> in the DCT image should be:
<disp-formula id="E12"><label>(12)</label><mml:math id="M12" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mi>F</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>u</mml:mi><mml:mo>_</mml:mo><mml:mi>L</mml:mi><mml:mi>F</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">psf</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mi>W</mml:mi><mml:mo>/</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">N</mml:mi><mml:mtext>num</mml:mtext></mml:mrow><mml:mn>2</mml:mn></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>and the pixel size <inline-formula id="IE29"><mml:math id="IM29" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>u</mml:mi><mml:mo>_</mml:mo><mml:mi>L</mml:mi><mml:mi>F</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> can be defined as:
<disp-formula id="E13"><label>(13)</label><mml:math id="M13" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>u</mml:mi><mml:mo>_</mml:mo><mml:mi>L</mml:mi><mml:mi>F</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mi>L</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>Q</mml:mi><mml:mo>*</mml:mo><mml:mi mathvariant="italic">N</mml:mi><mml:mtext>num</mml:mtext></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula>where <inline-formula id="IE30"><mml:math id="IM30" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mi>L</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> is the microlens pitch size, and <inline-formula id="IE31"><mml:math id="IM31" display="inline" overflow="scroll"><mml:mi>Q</mml:mi></mml:math></inline-formula> is the magnification of the objective lens. In the LFM, assuming that <inline-formula id="IE32"><mml:math id="IM32" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="double-struck">S</mml:mi><mml:mo>_</mml:mo><mml:mi>L</mml:mi><mml:mi>F</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> is the number of pixels along the width of <inline-formula id="IE33"><mml:math id="IM33" display="inline" overflow="scroll"><mml:mi mathvariant="double-struck">S</mml:mi></mml:math></inline-formula> and <inline-formula id="IE34"><mml:math id="IM34" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="double-struck">S</mml:mi><mml:mo>_</mml:mo><mml:mi>L</mml:mi><mml:mi>F</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> is the number of pixels along the height of <inline-formula id="IE35"><mml:math id="IM35" display="inline" overflow="scroll"><mml:mi mathvariant="double-struck">S</mml:mi></mml:math></inline-formula>. According to the <xref rid="E12" ref-type="disp-formula">Eq. (12)</xref>, <inline-formula id="IE36"><mml:math id="IM36" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="double-struck">S</mml:mi><mml:mo>_</mml:mo><mml:mi>L</mml:mi><mml:mi>F</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE37"><mml:math id="IM37" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="double-struck">S</mml:mi><mml:mo>_</mml:mo><mml:mi>L</mml:mi><mml:mi>F</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> can be obtained by:
<disp-formula id="E14"><label>(14)</label><mml:math id="M14" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="double-struck">S</mml:mi><mml:mo>_</mml:mo><mml:mi>L</mml:mi><mml:mi>F</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mo>*</mml:mo><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>u</mml:mi><mml:mo>_</mml:mo><mml:mi>L</mml:mi><mml:mi>F</mml:mi></mml:mrow></mml:msub><mml:mo>*</mml:mo><mml:mi>N</mml:mi><mml:mo>/</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="italic">N</mml:mi><mml:mtext>num</mml:mtext><mml:mo>*</mml:mo><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">psf</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:math></disp-formula><disp-formula id="E15"><label>(15)</label><mml:math id="M15" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="double-struck">S</mml:mi><mml:mo>_</mml:mo><mml:mi>L</mml:mi><mml:mi>F</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mo>*</mml:mo><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>u</mml:mi><mml:mo>_</mml:mo><mml:mi>L</mml:mi><mml:mi>F</mml:mi></mml:mrow></mml:msub><mml:mo>*</mml:mo><mml:mi>M</mml:mi><mml:mo>/</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="italic">N</mml:mi><mml:mtext>num</mml:mtext><mml:mo>*</mml:mo><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">psf</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></disp-formula></p>
      <p>The final image metric expression, called DCT entropy, is as follows:
<disp-formula id="E16"><label>(16)</label><mml:math id="M16" display="block" overflow="scroll"><mml:mrow><mml:mi>D</mml:mi><mml:mi>C</mml:mi><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>p</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mover><mml:mo>=</mml:mo><mml:mtext> </mml:mtext></mml:mover><mml:mo>−</mml:mo><mml:mfrac><mml:mn>2</mml:mn><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">S</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:mrow><mml:mi>u</mml:mi><mml:mo>&lt;</mml:mo><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="double-struck">S</mml:mi><mml:mo>_</mml:mo><mml:mi>L</mml:mi><mml:mi>F</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mi>v</mml:mi><mml:mo>&lt;</mml:mo><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="double-struck">S</mml:mi><mml:mo>_</mml:mo><mml:mi>L</mml:mi><mml:mi>F</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:munder><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:mstyle><mml:msub><mml:mrow><mml:mrow><mml:mi>abslog</mml:mi></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>where <inline-formula id="IE38"><mml:math id="IM38" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mo>•</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> is the 2-norm of a matrix and <inline-formula id="IE39"><mml:math id="IM39" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mo>*</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> is DCT which can be referred to <xref rid="E1" ref-type="disp-formula">Eq. (1)</xref>. As for DCT entropy calculation in the wide-field microscopy, the range of <inline-formula id="IE40"><mml:math id="IM40" display="inline" overflow="scroll"><mml:mi>u</mml:mi></mml:math></inline-formula> is determined by <xref rid="E9" ref-type="disp-formula">Eq. (9)</xref> and the range of <inline-formula id="IE41"><mml:math id="IM41" display="inline" overflow="scroll"><mml:mi>v</mml:mi></mml:math></inline-formula> is determined by <xref rid="E10" ref-type="disp-formula">Eq. (10)</xref>, while others remain the same. As in <xref rid="btac760-F2" ref-type="fig">Figure 2d</xref>, we calculate the DCT entropy in the region limited by the optical resolution of reconstructed images with different iteration numbers (1–50) and plot the normalized curves accordingly. The results show that the entropy maximum is at the results of the seventh iteration, which is consistent with the empirical value. In practice, we can stop iteration when the DCT entropy value shows a decreasing trend. In order to demonstrate the calculation of DCT entropy must be restricted in the limited region, we also calculate the DCT entropy of the whole DCT (WDCT) spectrum of the x–y MIP images with the corresponding iterative numbers shown in <xref rid="btac760-F2" ref-type="fig">Figure 2c</xref>, which is marked by the white numbers and named WDCT entropy. As the number of iterations increases, the WDCT keeps rising while the quality of the reconstruction does not. We further demonstrate the performance of our image quality metric on data acquired with standard wide-field microscopy, which shows good performance on iteration number prediction with the RL, RL-TV and landweber algorithms. More details can be found in the <xref rid="sup1" ref-type="supplementary-material">Supplementary materials</xref>.</p>
    </sec>
  </sec>
  <sec>
    <title>3 Results</title>
    <p>Here, we present AutoDeconJ, an ImageJ plugin with a GPU acceleration framework and iterative prediction module for light-field deconvolution. Compared to the specificity and the complicated preparation process of reconstruction by deep learning, the main improvement of AutoDeconJ is to provide a universal tool for light-field reconstruction with a decent data throughput, a friendly interactive interface and the potential to scale to large input sizes. AutoDeconJ is convenient for the user without a background in computer science. In addition, the introduction of the novel iterative criterion in AutoDeconJ can further enhance the user’s ability to cope with different kinds of input data.</p>
    <sec>
      <title>3.1 Availability</title>
      <p>Benefiting from ImageJ with powerful cross-platform capability, AutoDeconJ can run on any system with ImageJ or Fiji installed. For details required for ImageJ installation, see the official website <italic toggle="yes">imagej.net</italic> for more information. AutoDeconJ requires the NVIDIA cards support by CUDA8.0 or later. See <ext-link xlink:href="https://developer.nvidia.com" ext-link-type="uri">https://developer.nvidia.com</ext-link><italic toggle="yes">f</italic>or more details about CUDA. If AutoDeconJ needs to run under multiple NVIDIA cards, please ensure that the system is equipped with multiple NVIDIA cards. Our recommendation for these cards is to support the scalable link interface or NVLINK, which can further enhance the reconstruction speed. For a detailed user manual, please see <xref rid="sup1" ref-type="supplementary-material">supplementary materials</xref>. The ImageJ plugin source code is already available on <ext-link xlink:href="https://github.com/Onetism/AutoDeconJ.git" ext-link-type="uri">https://github.com/Onetism/AutoDeconJ.git</ext-link>. Please clone it to the local folder, then follow the tutorial to compile it and move the jar package to the/<italic toggle="yes">plugin</italic>/folder (where ImageJ is installed) to complete the installation.</p>
    </sec>
    <sec>
      <title>3.2 Comparison</title>
      <p>During development, the main target was to design a universal tool. As such, a final comparison of AutoDeconJ to the Matlab GUI program was performed using the datasets provided in <xref rid="btac760-B10" ref-type="bibr">Prevedel <italic toggle="yes">et al.</italic> (2014)</xref>, including the fluorescence beads data and MCF10A cells data. In summary, AutoDeconJ performs as well as the Matlab GUI program in terms of reconstruction quality but requires less time-consuming. It also provides a more friendly interactive interface and a better data throughput. Furthermore, the optimal iteration number predicted by our proposed prediction module is consistent with empirical values, which can be used as a reference for the iterative reconstruction of new light-field data. Specific details of the comparison are provided in the <xref rid="sup1" ref-type="supplementary-material">Supplementary materials</xref>. In the end, we also demonstrate the poor data migration capability of the state-of-the-art VCD-Net network on simulated data, which is also presented in the <xref rid="sup1" ref-type="supplementary-material">Supplementary materials</xref>.</p>
    </sec>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material id="sup1" position="float" content-type="local-data">
      <label>btac760_Supplementary_Data</label>
      <media xlink:href="btac760_supplementary_data.zip">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <sec>
    <title>Funding</title>
    <p>This work was supported by National Natural Science Foundation of China [61931008, U21B2024, 62071415, 62071219 and 62088102].</p>
    <p><italic toggle="yes">Conflict of Interest</italic>: none declared.</p>
  </sec>
  <sec sec-type="data-availability">
    <title>Data availability</title>
    <p>The example data for C. elegans in <xref rid="btac760-F2" ref-type="fig">figure 2</xref> are available at <ext-link xlink:href="https://static-content.springer.com/esm/art%3A10.1038%2Fnmeth.2964/MediaObjects/41592_2014_BFnmeth2964_MOESM189_ESM.zip" ext-link-type="uri">https://static-content.springer.com/esm/art%3A10.1038%2Fnmeth.2964/MediaObjects/41592_2014_BFnmeth2964_MOESM189_ESM.zip</ext-link> and the data in supplementary material are available from the corresponding authors upon reasonable request.</p>
  </sec>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="btac760-B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Albota</surname><given-names>M.</given-names></string-name></person-group><etal>et al</etal> (<year>1998</year>) <article-title>Design of organic molecules with large two-photon absorption cross sections</article-title>. <source>Science</source>, <volume>281</volume>, <fpage>1653</fpage>–<lpage>1656</lpage>.<pub-id pub-id-type="pmid">9733507</pub-id></mixed-citation>
    </ref>
    <ref id="btac760-B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Blinn</surname><given-names>J.F.</given-names></string-name></person-group> (<year>1993</year>) <article-title>What's that deal with the DCT?</article-title><source>IEEE Comput. Grap. Appl</source>., <volume>13</volume>, <fpage>78</fpage>–<lpage>83</lpage>.</mixed-citation>
    </ref>
    <ref id="btac760-B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cohen</surname><given-names>N.</given-names></string-name></person-group><etal>et al</etal> (<year>2014</year>) <article-title>Enhancing the performance of the light field microscope using wavefront coding</article-title>. <source>Opt. Express</source>, <volume>22</volume>, <fpage>24817</fpage>–<lpage>24839</lpage>.<pub-id pub-id-type="pmid">25322056</pub-id></mixed-citation>
    </ref>
    <ref id="btac760-B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Huisken</surname><given-names>J.</given-names></string-name></person-group><etal>et al</etal> (<year>2004</year>) <article-title>Optical sectioning deep inside live embryos by selective plane illumination microscopy</article-title>. <source>Science</source>, <volume>305</volume>, <fpage>1007</fpage>–<lpage>1009</lpage>.<pub-id pub-id-type="pmid">15310904</pub-id></mixed-citation>
    </ref>
    <ref id="btac760-B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kristan</surname><given-names>M.</given-names></string-name></person-group><etal>et al</etal> (<year>2006</year>) <article-title>A Bayes-spectral-entropy-based measure of camera focus using a discrete cosine transform</article-title>. <source>Patt. Recogn. Lett</source>., <volume>27</volume>, <fpage>1431</fpage>–<lpage>1439</lpage>.</mixed-citation>
    </ref>
    <ref id="btac760-B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Keller</surname><given-names>P.J.</given-names></string-name></person-group><etal>et al</etal> (<year>2008</year>) <article-title>Reconstruction of zebrafish early embryonic development by scanned light sheet microscopy</article-title>. <source>Science</source>, <volume>322</volume>, <fpage>1065</fpage>–<lpage>1069</lpage>.<pub-id pub-id-type="pmid">18845710</pub-id></mixed-citation>
    </ref>
    <ref id="btac760-B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lu</surname><given-names>Z.</given-names></string-name></person-group><etal>et al</etal> (<year>2019</year>) <article-title>Phase-space deconvolution for light field microscopy</article-title>. <source>Opt. Express</source>., <volume>27</volume>, <fpage>18131</fpage>–<lpage>18145</lpage>.<pub-id pub-id-type="pmid">31252761</pub-id></mixed-citation>
    </ref>
    <ref id="btac760-B8">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Li</surname><given-names>H.</given-names></string-name></person-group><etal>et al</etal> (<year>2019</year>) <article-title>Fast, volumetric live-cell imaging using high-resolution light-field microscopy</article-title>. <source>Biomed. Opt. Express</source>., <volume>10</volume>, <fpage>29</fpage>–<lpage>49</lpage>.<pub-id pub-id-type="pmid">30775081</pub-id></mixed-citation>
    </ref>
    <ref id="btac760-B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Planchon</surname><given-names>T.A.</given-names></string-name></person-group><etal>et al</etal> (<year>2011</year>) <article-title>Rapid three-dimensional isotropic imaging of living cells using Bessel beam plane illumination</article-title>. <source>Nat. Methods</source>, <volume>8</volume>, <fpage>417</fpage>–<lpage>423</lpage>.<pub-id pub-id-type="pmid">21378978</pub-id></mixed-citation>
    </ref>
    <ref id="btac760-B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Prevedel</surname><given-names>R.</given-names></string-name></person-group><etal>et al</etal> (<year>2014</year>) <article-title>Simultaneous whole-animal 3D imaging of neuronal activity using light-field microscopy</article-title>. <source>Nat. Methods</source>, <volume>11</volume>, <fpage>727</fpage>–<lpage>730</lpage>.<pub-id pub-id-type="pmid">24836920</pub-id></mixed-citation>
    </ref>
    <ref id="btac760-B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Schindelin</surname><given-names>J.</given-names></string-name></person-group><etal>et al</etal> (<year>2012</year>) <article-title>Fiji: an open-source platform for biological-image analysis</article-title>. <source>Nat. Methods</source>, <volume>9</volume>, <fpage>676</fpage>–<lpage>682</lpage>.<pub-id pub-id-type="pmid">22743772</pub-id></mixed-citation>
    </ref>
    <ref id="btac760-B12">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Schulz</surname><given-names>O.</given-names></string-name></person-group><etal>et al</etal> (<year>2013</year>) <article-title>Resolution doubling in fluorescence microscopy with confocal spinning-disk image scanning microscopy</article-title>. <source>Proc. Natl. Acad. Sci. USA</source>, <volume>110</volume>, <fpage>21000</fpage>–<lpage>21005</lpage>.<pub-id pub-id-type="pmid">24324140</pub-id></mixed-citation>
    </ref>
    <ref id="btac760-B13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Shaw</surname><given-names>M.</given-names></string-name></person-group><etal>et al</etal> (<year>2018</year>) <article-title>Three-dimensional behavioural phenotyping of freely moving <italic toggle="yes">C. elegans</italic> using quantitative light field microscopy</article-title>. <source>PLoS One</source>, <volume>13</volume>, <fpage>e0200108</fpage>.<pub-id pub-id-type="pmid">29995960</pub-id></mixed-citation>
    </ref>
    <ref id="btac760-B14">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Vizcaino</surname><given-names>J.P.</given-names></string-name></person-group><etal>et al</etal> (<year>2021</year>) Real-time light field 3D microscopy via sparsity-driven learned deconvolution. In: <italic toggle="yes">2021 IEEE International Conference on Computational Photography (ICCP), Haifa, Israel.</italic> IEEE. pp. <fpage>1</fpage>–<lpage>11</lpage>.</mixed-citation>
    </ref>
    <ref id="btac760-B15">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname><given-names>Y.</given-names></string-name></person-group><etal>et al</etal> (<year>2010</year>) <article-title>Integrated photoacoustic and fluorescence confocal microscopy</article-title>. <source>IEEE Trans. Biomed. Eng</source>., <volume>57</volume>, <fpage>2576</fpage>–<lpage>2578</lpage>.<pub-id pub-id-type="pmid">20639165</pub-id></mixed-citation>
    </ref>
    <ref id="btac760-B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wu</surname><given-names>J.M.</given-names></string-name></person-group><etal>et al</etal> (<year>2021</year>) <article-title>Iterative tomography with digital adaptive optics permits hour-long intravital observation of 3D subcellular dynamics at millisecond scale</article-title>. <source>Cell</source>, <volume>184</volume>, <fpage>3318</fpage>–<lpage>3332.e17</lpage>.<pub-id pub-id-type="pmid">34038702</pub-id></mixed-citation>
    </ref>
    <ref id="btac760-B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname><given-names>Z.Q.</given-names></string-name></person-group><etal>et al</etal> (<year>2021</year>) <article-title>Real-time volumetric reconstruction of biological dynamics with light-field microscopy and deep learning</article-title>. <source>Nat. Methods</source>, <volume>18</volume>, <fpage>551</fpage>–<lpage>556</lpage>.<pub-id pub-id-type="pmid">33574612</pub-id></mixed-citation>
    </ref>
    <ref id="btac760-B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Xiong</surname><given-names>B.</given-names></string-name></person-group><etal>et al</etal> (<year>2021</year>) <article-title>Mirror-enhanced scanning light-field microscopy for long-term high-speed 3D imaging with isotropic resolution</article-title>. <source>Light. Sci. Appl</source>., <volume>10</volume>, <fpage>227</fpage>.<pub-id pub-id-type="pmid">34737265</pub-id></mixed-citation>
    </ref>
    <ref id="btac760-B19">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yang</surname><given-names>W.</given-names></string-name></person-group><etal>et al</etal> (<year>2017</year>) <article-title>In vivo imaging of neural activity</article-title>. <source>Nat. Methods</source>, <volume>14</volume>, <fpage>349</fpage>–<lpage>359</lpage>.<pub-id pub-id-type="pmid">28362436</pub-id></mixed-citation>
    </ref>
    <ref id="btac760-B20">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname><given-names>Z.</given-names></string-name></person-group><etal>et al</etal> (<year>2021</year>) <article-title>Imaging volumetric dynamics at high speed in mouse and zebrafish brain with confocal light field microscopy</article-title>. <source>Nat. Biotechnol</source>., <volume>39</volume>, <fpage>74</fpage>–<lpage>83</lpage>.<pub-id pub-id-type="pmid">32778840</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
